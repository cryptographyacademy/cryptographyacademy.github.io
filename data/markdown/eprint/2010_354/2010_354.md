# **High-Speed Software Implementation of the Optimal Ate Pairing over Barreto–Naehrig Curves**

Jean-Luc Beuchat<sup>1</sup> , Jorge E. Gonz´alez-D´ıaz<sup>2</sup> , Shigeo Mitsunari<sup>3</sup> , Eiji Okamoto<sup>1</sup> , Francisco Rodr´ıguez-Henr´ıquez<sup>2</sup> , and Tadanori Teruya<sup>1</sup>

**Abstract.** This paper describes the design of a fast software library for the computation of the optimal ate pairing on a Barreto–Naehrig elliptic curve. Our library is able to compute the optimal ate pairing over a 254-bit prime field F*p*, in just 2*.*33 million of clock cycles on a single core of an Intel Core i7 2*.*8GHz processor, which implies that the pairing computation takes 0*.*832msec. We are able to achieve this performance by a careful implementation of the base field arithmetic through the usage of the customary Montgomery multiplier for prime fields. The prime field is constructed via the Barreto–Naehrig polynomial parametrization of the prime *p* given as, *p* = 36*t* <sup>4</sup> + 36*t* <sup>3</sup> + 24*t* <sup>2</sup> + 6*t*+ 1, with *t* = 2<sup>62</sup> *−*2 <sup>54</sup> + 2<sup>44</sup> This selection of *t* allows us to obtain important savings for both the Miller loop as well as the final exponentiation steps of the optimal ate pairing.

**Keywords:** Tate pairing, optimal pairing, Barreto–Naehrig curve, ordinary curve, finite field arithmetic, bilinear pairing software implementation.

### **1 Introduction**

The protocol solutions provided by pairing-based cryptography can only be made practical if one can efficiently compute bilinear pairings at high levels of security. Back in 1986, Victor Miller proposed in [26, 27] an iterative algorithm that can evaluate rational functions from scalar multiplications of divisors, thus allowing to compute bilinear pairings at a linear complexity cost with respect to the size of the input. Since then, several authors have found further algorithmic improvements to decrease the complexity of Miller's algorithm by reducing its loop length [3, 4, 12, 20, 21, 38], and by constructing pairing-friendly elliptic curves [5, 14, 29] and pairing-friendly tower extensions of finite fields [6, 24].

<sup>1</sup> Graduate School of Systems and Information Engineering, University of Tsukuba, 1-1-1 Tennodai, Tsukuba, Ibaraki, 305-8573, Japan

<sup>2</sup> Computer Science Department, Centro de Investigaci´on y de Estudios Avanzados del IPN, Av. Instituto Polit´ecnico Nacional No. 2508, 07300 M´exico City, M´exico

<sup>3</sup> Cybozu Labs, Inc., Akasaka Twin Tower East 15F, 2-17-22 Akasaka, Minato-ku, Tokyo 107-0052

Roughly speaking, an asymmetric bilinear pairing can be defined as the non-degenerate bilinear mapping,  $\hat{e}: \mathbb{G}_1 \times \mathbb{G}_2 \to \mathbb{G}_3$ , where both  $\mathbb{G}_1$ ,  $\mathbb{G}_2$  are finite cyclic additive groups with prime order r, whereas  $\mathbb{G}_3$  is a multiplicative cyclic group whose order is also r. Additionally, as it was mentioned above, for cryptographic applications it is desirable that pairings can be computed efficiently. When  $\mathbb{G}_1 = \mathbb{G}_2$ , we say that the pairing is symmetric, otherwise, if  $\mathbb{G}_1 \neq \mathbb{G}_2$ , the pairing is asymmetric [15].

Arguably the  $\eta_T$  pairing [3] is the most efficient algorithm for symmetric pairings that are always defined over supersingular curves. In the case of asymmetric pairings, recent breakthroughs include the ate pairing [21], the R-ate pairing [25], and the optimal ate pairing [38].

Several authors have presented software implementations of bilinear pairings targeting the 128-bit security level [1,8,10,16,18,23,31,32]. By taking advantage of the eight cores of a dual quad-core Intel Xeon 45nm, the software library presented in [1] takes 3.02 millions of cycles to compute the  $\eta_T$  pairing on a supersingular curve defined over  $\mathbb{F}_{2^{1223}}$ . Authors in [8] report 5.42 millions of cycles to compute the  $\eta_T$  pairing on a supersingular curve defined over  $\mathbb{F}_{3^{509}}$  on an Intel Core i7 45nm processor using eight cores. The software library presented in [32] takes 4.470 millions of cycles to compute the optimal ate pairing on a 257-bit BN curve using only one core of an Intel Core 2 Quad Q6600 processor.

This paper addresses the efficient software implementation of asymmetric bilinear pairings at high security levels. We present a library <sup>1</sup> that performs the optimal ate pairing over a 254-bit Barreto–Naehrig (BN) curve in just 2.33 million of clock cycles on a single core of an Intel i7 2.8GHz processor, which implies that the optimal ate pairing is computed in 0.832msec. To the best of our knowledge, this is the first time that a software or a hardware accelerator reports a high security level pairing computation either symmetric or asymmetric, either on one core or on a multi-core platform, in less than one millisecond. After a careful selection of a pairing-friendly elliptic curve and the tower field (Sections 2 and 3), we describe the computational complexity associated to the execution of the optimal ate pairing (Section 4). Then, we describe our approach to implement arithmetic over the underlying field  $\mathbb{F}_p$  and to perform tower field arithmetic (Section 5), and we give benchmarking results of our software library (Section 6).

#### 2 Optimal Ate Pairing over Barreto-Naehrig Curves

Barreto and Naehrig [5] described a method to construct pairing-friendly ordinary elliptic curves over a prime field  $\mathbb{F}_p$ . Barreto–Naehrig curves (or BN curves) are defined by the equation  $E: y^2 = x^3 + b$ , where  $b \neq 0$ . Their embedding degree k is equal to 12. Furthermore, the number of  $\mathbb{F}_p$ -rational points of E, denoted by r in the following, is a prime. The characteristic p of the prime field, the group order r, and the trace of Frobenius  $t_r$  of the curve are parametrized as

<sup>&</sup>lt;sup>1</sup> An open source code for benchmarking our software library is available at http://homepage1.nifty.com/herumi/crypt/ate-pairing.html

follows [5]:

$$p(t) = 36t^4 + 36t^3 + 24t^2 + 6t + 1,$$


$$r(t) = 36t^4 + 36t^3 + 18t^2 + 6t + 1,$$


$$t_r(t) = 6t^2 + 1,$$
(1)

where  $t \in \mathbb{Z}$  is an arbitrary integer such that p = p(t) and r = r(t) are both prime numbers. Additionally, t must be large enough to guarantee an adequate security level. For a security level equivalent to AES-128, we should select t such that  $\log_2(r(t)) \geq 256$  and  $3000 \leq k \cdot \log_2(p(t)) \leq 5000$  [14]. For this to be possible t should have roughly 64 bits.

Let E[r] denote the r-torsion subgroup of E and  $\pi_p$  be the Frobenius endomorphism  $\pi_p: E \to E$  given by  $\pi_p(x,y) = (x^p,y^p)$ . We define  $\mathbb{G}_1 = E[r] \cap \operatorname{Ker}(\pi_p - [1]) = E(\mathbb{F}_p)[r]$ ,  $\mathbb{G}_2 = E[r] \cap \operatorname{Ker}(\pi_p - [p]) \subseteq E(\mathbb{F}_{p^{12}})[r]$ , and  $\mathbb{G}_3 = \mu_r \subset \mathbb{F}_{p^{12}}$  (i.e. the group of r-th roots of unity). Since we work with a BN curve, r is a prime and  $\mathbb{G}_1 = E(\mathbb{F}_p)[r] = E(\mathbb{F}_p)$ . The optimal ate pairing on the BN curve E is a non-degenerate and bilinear pairing given by the map [30, 32, 38]:

$$a_{\text{opt}}: \mathbb{G}_2 \times \mathbb{G}_1 \longrightarrow \mathbb{G}_3$$

$$(Q, P) \longmapsto \left( f_{6t+2,Q}(P) \cdot l_{[6t+2]Q, \pi_p(Q)}(P) \cdot l_{[6t+2]Q + \pi_p(Q), -\pi_p^2(Q)}(P) \right)^{\frac{p^{12}-1}{r}},$$

where

- $-f_{s,Q}$ , for  $s \in \mathbb{N}$  and  $Q \in \mathbb{G}_2$ , is a family of normalized  $\mathbb{F}_{p^{12}}$ -rational functions with divisor  $(f_{s,Q}) = s(Q) ([s]Q) (s-1)(\mathcal{O})$ , where  $\mathcal{O}$  denotes the point at infinity.
- $-l_{Q_1,Q_2}$  is the equation of the line corresponding to the addition of  $Q_1 \in \mathbb{G}_2$  with  $Q_2 \in \mathbb{G}_2$ .

Algorithm 1 shows how we compute the optimal ate pairing in this work. Our approach can be seen as a signed-digit version of the algorithm utilized in [32], where both point additions and point subtractions are allowed. The Miller loop (lines 3–10) calculates the value of the rational function  $f_{6t+2,Q}$  at point P. In lines 11–13 the product of the line functions  $l_{[6t+2]Q,\pi_p(Q)}(P) \cdot l_{[6t+2]Q+\pi_p(Q),-\pi_p^2(Q)}(P)$  is multiplied by  $f_{6t+2,Q}(P)$ . The so-called final exponentiation is computed in line 14. A detailed summary of the computational costs associated to Algorithm 1 can be found in Section 4.

The BN curves admit a sextic twist  $E'/\mathbb{F}_{p^2}: y^2=x^3+b/\xi$  defined over  $\mathbb{F}_{p^2}$ , where  $\xi\in\mathbb{F}_{p^2}$  is an element that is neither a square nor a cube in  $\mathbb{F}_{p^2}$ , and that has to be carefully selected such that  $r|\#E'(\mathbb{F}_{p^2})$  holds. This means that pairing computations can be restricted to points P and Q' that belong to  $E(\mathbb{F}_p)$  and  $E'(\mathbb{F}_{p^2})$ , respectively, since we can represent the points in  $\mathbb{G}_2$  by points on the twist [5,21,38].

### **Algorithm 1** Optimal ate pairing over Barreto–Naehrig curves.

```
Input: P ∈ G1 and Q ∈ G2.
Output: aopt(Q, P).
1. Write s = 6t + 2 as s =
                           ∑L−1
                             i=0 si2
                                    i
                                     , where si ∈ {−1, 0, 1};
2. T ← Q, f ← 1;
3. for i = L − 2 to 0 do
4. f ← f
            2
             · lT ,T (P); T ← 2T;
5. if si = −1 then
6. f ← f · lT ,−Q(P); T ← T − Q;
7. else if si = 1 then
8. f ← f · lT ,Q(P); T ← T + Q;
9. end if
10. end for
11. Q1 ← πp(Q); Q2 ← πp2 (Q);
12. f ← f · lT ,Q1
                (P); T ← T + Q1;
13. f ← f · lT ,−Q2
                 (P); T ← T − Q2;
14. f ← f
          (p
           12−1)/r;
15. return f;
```

# **3 Tower Extension Field Arithmetic**

Since *k* = 12 = 2<sup>2</sup> *·* 3, the tower extensions can be created using irreducible binomials only. This is because *x <sup>k</sup>−β* is irreducible over F*<sup>p</sup>* provided that *β ∈* F*<sup>p</sup>* is neither a square nor a cube in F*<sup>p</sup>* [24]. Hence, the tower extension can be constructed by simply adjoining a cube or square root of such element *β* and then the cube or square root of the previous root. This process should be repeated until the desired extension of the tower has been reached.

Accordingly, we decided to represent F*p*<sup>12</sup> using the same tower extension of [18], namely, we first construct a quadratic extension, which is followed by a cubic extension and then by a quadratic one, using the following irreducible binomials:

$$\mathbb{F}_{p^2} = \mathbb{F}_p[u]/(u^2 - \beta), \text{ where } \beta = -5,$$

$$\mathbb{F}_{p^6} = \mathbb{F}_{p^2}[v]/(v^3 - \xi), \text{ where } \xi = u,$$

$$\mathbb{F}_{p^{12}} = \mathbb{F}_{p^6}[w]/(w^2 - v).$$
(2)

We adopted the tower extension of Equation (2), mainly because field elements *f ∈* F*p*<sup>12</sup> can be seen as a quadratic extension of F*p*<sup>6</sup> , and hence they can be represented as *f* = *g* +*hw*, with *g*, *h ∈* F*p*<sup>6</sup> . This towering will help us to exploit the fact that in the hard part of the final exponentiation we will deal with field elements *f ∈* F*p*<sup>12</sup> that become *unitary* [35, 36], *i.e.*, elements that belong to the cyclotomic subgroup G*<sup>Φ</sup>*<sup>6</sup> (F*p*<sup>2</sup> ) as defined in [17]. Such elements satisfy, *f p* <sup>6</sup>+1 = 1, which means that *f <sup>−</sup>*<sup>1</sup> = *f p* 6 = *g − hw*. In other words, inversion of such elements can be accomplished by simple conjugation. This nice feature opens the door for using addition-subtraction chains in the final exponentiation step, which is especially valuable for our binary signed choice of the parameter *t*. We also stress that our specific t selection permits to use  $\xi = u \in \mathbb{F}_p$ , which will yield important savings in the arithmetic computational cost as discussed next.

#### 3.1 Computational Costs of the Tower Extension Field Arithmetic

The tower extension arithmetic algorithms used in this work were directly adopted from [18]. Let (a, m, s, i),  $(\tilde{a}, \tilde{m}, \tilde{s}, \tilde{i})$ , and (A, M, S, I) denote the cost of field addition, multiplication, squaring, and inversion in  $\mathbb{F}_p$ ,  $\mathbb{F}_{p^2}$ , and  $\mathbb{F}_{p^6}$ , respectively. From our implementation (see Section 5), we observed experimentally that m = s = 8a and i = 48.3m. We summarize the towering arithmetic costs as follows:

- In the field  $\mathbb{F}_{p^2}$ , we used Karatsuba multiplication and the complex method for squaring, at a cost of 3 and 2 field multiplications in  $\mathbb{F}_p$ , respectively. Inversion of an element  $A = a_0 + a_1 u \in \mathbb{F}_{p^2}$ , can be found from the identity,  $(a_0 + a_1 u)^{-1} = (a_0 a_1 u)/(a_0^2 \beta a_1^2)$ . Using once again the Karatsuba method, field multiplication in  $\mathbb{F}_{p^6}$  can be computed at a cost of  $6\tilde{m}$  plus several addition operations. All these three operations require the multiplication in the base field by the constant coefficient  $\beta \in \mathbb{F}_p$  of the irreducible binomial  $u^2 \beta$ . We refer to this operation as  $m_\beta$  Additionally, we sometimes need to compute the multiplication of an arbitrary element in  $\mathbb{F}_{p^2}$  times the constant  $\xi = u \in \mathbb{F}_p$  at a cost of one multiplication by the constant  $\beta$ . We refer to this operation as  $m_\xi$ , but it is noticed that the cost of  $m_\xi$  is essentially the same of that of  $m_\beta$ .
- Squaring in  $\mathbb{F}_{p^6}$  can be computed via the formula derived in [9] at a cost of  $2\tilde{m} + 3\tilde{s}$  plus some addition operations. Inversion in the sextic extension can be computed at a cost of  $9\tilde{m} + 3\tilde{s} + 4m_{\beta} + 5\tilde{a} + \tilde{i}$  [34].
- Since our field towering constructed  $\mathbb{F}_{p^{12}}$  as a quadratic extension of  $\mathbb{F}_{p^6}$ , the arithmetic costs of the quadratic extension apply. Hence, a field multiplication, squaring and inversion costs in  $\mathbb{F}_{p^{12}}$  are, 3M+5A, 2M+5A and 2M+2S+2A+I, respectively. However, if  $f \in \mathbb{F}_{p^{12}}$ , belongs to the cyclotomic subgroup  $\mathbb{G}_{\Phi_6}(\mathbb{F}_{p^2})$ , its field squaring  $f^2$  can be reduced to three squarings in  $\mathbb{F}_{p^4}$  [17].

Table 1 lists the computational costs of the tower extension field arithmetic in terms of the  $\mathbb{F}_{p^2}$  field arithmetic operations, namely,  $(\tilde{a}, \tilde{m}, \tilde{s}, \tilde{i})$ .

#### 3.2 Frobenius Operator

Raising an element  $f \in \mathbb{F}_{p^{12}} = \mathbb{F}_{p^6}[w]/(w^2 - v)$  to the *p*-power, is an arithmetic operation needed in the final exponentiation (line 14) of the optimal ate pairing (Algorithm 1). We briefly describe in the following how to compute  $f^p$  efficiently.

We first remark that the field extension  $\mathbb{F}_{p^{12}}$  can be also represented as a sextic extension of the quadratic field, i.e.,  $\mathbb{F}_{p^{12}} = \mathbb{F}_{p^2}[W]/(W^6 - u)$ , with W = w. Hence, we can write  $f = g + hw \in \mathbb{F}_{p^{12}}$ , with  $g, h \in \mathbb{F}_{p^6}$  such that,  $g = g_0 + g_1v + g_2v^2$ ,  $h = h_0 + h_1v + h_2v^2$ , where  $g_i, h_i \in \mathbb{F}_{p^2}$ , for i = 1, 2, 3. This

|   | ${\bf Field}  \bigg  {\bf Add./Sub.}$ |                  | Mult.                                    | Squaring                                            | Inversion                                                                                          |  |
|---|---------------------------------------|------------------|------------------------------------------|-----------------------------------------------------|----------------------------------------------------------------------------------------------------|--|
|   | $\mathbb{F}_{p^2}$                    | $\tilde{a} = 2a$ | $\tilde{m} = 3m + 3a + m_{\beta}$        | $\tilde{s} = 2m + 3a + m_{\beta}$                   | $\tilde{i} = 4m + m_{\beta} + 2a + i$                                                              |  |
|   | $\mathbb{F}_{p^6}$                    | $3\tilde{a}$     | $6\tilde{m} + 2m_{\beta} + 15\tilde{a}$  | $2\tilde{m} + 3\tilde{s} + 2m_{\beta} + 8\tilde{a}$ | $9\tilde{m} + 3\tilde{s} + 4m_{\beta} + 4\tilde{a} + \tilde{i}$                                    |  |
|   | $\mathbb{F}_{p^{12}}$                 | $6\tilde{a}$     | $18\tilde{m} + 6m_{\beta} + 60\tilde{a}$ | $12\tilde{m} + 4m_{\beta} + 45\tilde{a}$            | $\begin{vmatrix} 25\tilde{m} + 9\tilde{s} + 12m_{\beta} \\ +61\tilde{a} + \tilde{i} \end{vmatrix}$ |  |
| G | $\Phi_6(\mathbb{F}_{p^2})$            | $6\tilde{a}$     | $18\tilde{m} + 6m_{\beta} + 60\tilde{a}$ | $9\tilde{s} + 4m_{\beta} + 30\tilde{a}$             | Conjugation                                                                                        |  |

Table 1. Computational costs of the tower extension field arithmetic.

means that f can be equivalently written as,  $f = g + hw = g_0 + h_0W + g_1W^2 + h_1W^3 + g_2W^4 + h_2W^5$ .

We note that the p-power of an arbitrary element in the quadratic extension field  $\mathbb{F}_{p^2}$  can be computed essentially free of cost as follows. Let  $b \in \mathbb{F}_{p^2}$  be an arbitrary element that can be represented as  $b = b_0 + b_1 u$ . Then,  $(b)^{p^{2i}} = b$  and  $(b)^{p^{2i-1}} = \bar{b}$ , with  $\bar{b} = b_0 - b_1 u$ , for  $i \in \mathbb{N}$ .

Let  $\bar{g}_i$ ,  $\bar{h}_i$ , denote the conjugates of  $g_i$ ,  $h_i$ , for i=1,2,3 respectively. Then, using the identity  $W^p = u^{(p-1)/6}W$ , we can write,  $(W^i)^p = \gamma_{1,i}W^i$ , with  $\gamma_{1,i} = u^{i(p-1)/6}$ , for  $i=1,\ldots,5$ . From the definitions given above, we can compute  $f^p$  as,

$$f^{p} = (g_{0} + h_{0}W + g_{1}W^{2} + h_{1}W^{3} + g_{2}W^{4} + h_{2}W^{5})^{p}$$

$$= \bar{g}_{0} + \bar{h}_{0}W^{p} + \bar{g}_{1}W^{2p} + \bar{h}_{1}W^{3p} + \bar{g}_{2}W^{4p} + \bar{h}_{2}W^{5p}$$

$$= \bar{g}_{0} + \bar{h}_{0}\gamma_{1,1}W + \bar{g}_{1}\gamma_{1,2}W^{2} + \bar{h}_{1}\gamma_{1,3}W^{3} + \bar{g}_{2}\gamma_{1,4}W^{4} + \bar{h}_{2}\gamma_{1,5}W^{5}.$$

The equation above has a computational cost of 5 multiplications in  $\mathbb{F}_p$  and 5 conjugations in  $\mathbb{F}_{p^2}$ . We can follow a similar procedure for computing  $f^{p^2}$  and  $f^{p^3}$ , which are arithmetic operations required in the hard part of the final exponentiation of Algorithm 1. For that, we must pre-compute and store the per-field constants  $\gamma_{1,i} = u^{i \cdot (p-1)/6}$ ,  $\gamma_{2,i} = \gamma_{1,i} \cdot \bar{\gamma}_{1,i}$ , and  $\gamma_{3,i} = \gamma_{1,i} \cdot \gamma_{2,i}$  for  $i = 1, \ldots, 5$ .

#### 4 Computational Cost of the Optimal Ate Pairing

In this work we considered several choices of the parameter t, required for defining p(t), r(t), and  $t_r(t)$  of Equation (1). We found 64-bit values of t with Hamming weight as low as 2 that yield the desired properties for p, r, and  $t_r$ . For example, the binomial  $t=2^{63}-2^{49}$  guarantees that p and r as defined in Equation (1) are both 258-bit prime numbers. However, due to the superior efficiency on its associated base field arithmetic, we decided to use the trinomial  $t=2^{62}-2^{54}+2^{44}$ , which guarantees that p and r as defined in Equation (1)

are 254-bit prime numbers. Since the automorphism group  $\operatorname{Aut}(E)$  is a cyclic group of order 6 [30], it is possible to slightly improve Pollard's rho attack and get a speedup of  $\sqrt{6}$  [11]. Therefore, we achieve a 126-bit security level with our choice of parameters. The curve equation is  $E: Y^2 = X^3 + 5$  and we followed the procedure outlined in [6,36] in order to find a generator  $P = (x_P, y_P) = (1, \sqrt{6})$  for the group  $E(\mathbb{F}_p)$ , and one generator  $Q' = (x_{Q'}, y_{Q'})$  for the group  $E'(\mathbb{F}_{p^2})[r]$ , given as,

```
\begin{split} x_{Q'} &= 0 \text{x} 19B0BEA4AFE4C330DA93CC3533DA38A9F430B471C6F8A536E81962ED967909B5} \\ &\quad + 0 \text{x} A1CF585585A61C6E9880B1F2A5C539F7D906FFF238FA6341E1DE1A2E45C3F72} u \\ y_{Q'} &= 0 \text{x} 17ABD366EBBD65333E49C711A80A0CF6D24ADF1B9B3990EEDCC91731384D2627} \\ &\quad + 0 \text{x} EE97D6DE9902A27D00E952232A78700863BC9AA9BE960C32F5BF9FD0A32D345} u \end{split}
```

In this Section, we show that our selection of t yields important savings in the Miller loop and the hard part of the final exponentiation step of Algorithm 1.

#### 4.1 Miller Loop

We remark that the parameter 6t + 2 of Algorithm 1 has a bitlength L = 65, with a Hamming weight of 7. This implies that the execution of the Miller loop requires 64 doubling step computations in line 4, and 6 addition/subtraction steps in lines 6 and 8.

It is noted that the equation of the tangent line at  $T \in \mathbb{G}_2$  evaluated at P defines a sparse element in  $\mathbb{F}_{p^{12}}$  (half of the coefficients are equal to zero). The same observation holds for the equation of the line through the points T and  $\pm Q$  evaluated at P. This sparsity allows us to reduce the number of operations on the underlying field when performing accumulation steps (lines 4, 6, 8, 12, and 13 of Algorithm 1).

We perform an interleaved computation of the tangent line at point T (respectively, the line through the points T and Q) evaluated at the base point P, with a point doubling (respectively, point addition) using the formulae given in [2]. We recall that the field extension  $\mathbb{F}_{p^{12}}$  can be also represented as,  $\mathbb{F}_{p^{12}} = \mathbb{F}_{p^2}[W]/(W^6 - u)$ , with W = w.

**Doubling step (line 4).** We represent the point  $T \in E'(\mathbb{F}_{p^2})$  in Jacobian coordinates as  $T = (X_T, Y_T, Z_T)$ . The formulae for doubling T, *i.e.*, the equations that define the point  $R = 2T = (X_R, Y_R, Z_R)$  are,

$$X_R = 9X_T^4 - 8X_TY_T^2, Y_R = 3X_T^2(4X_TY_T^2 - X_R) - 8Y_T^4, Z_R = 2Y_TZ_T.$$

Let the point  $P \in E(\mathbb{F}_p)$  be represented in affine coordinates as  $P = (x_P, y_P)$ . Then, the tangent line at T evaluated at P can be calculated as [32],

$$l_{T,T}(P) = 2Z_R Z_T^2 y_P - (6X_T^2 Z_T^2 x_P) W + (6X_T^3 - 4Y_T^2) W^2 \in \mathbb{F}_{n^{12}}.$$

Hence, the computational cost of the interleaving computation of the tangent line and the doubling of the point T is,  $3\tilde{m} + 8\tilde{s} + 16\tilde{a} + 4m$ . Other operations

included in line 4 are  $f^2$  and the product  $f^2 \cdot l_{T,T}(P)$ , which can be computed at a cost of,  $12\tilde{m} + 45\tilde{a} + 4m_{\beta}$  and  $13\tilde{m} + 39\tilde{a} + 2m_{\beta}$ , respectively. In summary, the computational cost associated to line 4 of Algorithm 1 is given as,  $28\tilde{m} + 8\tilde{s} + 100\tilde{a} + 4m + 6m_{\beta}$ .

Addition step (lines 6 and 8). Let  $Q = (X_Q, Y_Q, Z_Q)$  and  $T = (X_T, Y_T, Z_T)$  represent the points Q and  $T \in E'(\mathbb{F}_{p^2})$  in Jacobian coordinates. Then the point  $R = T + Q = (X_R, Y_R, Z_R)$ , can be computed as,

$$\begin{split} X_R &= (2Y_QZ_T^3 - 2Y_T)^2 - 4(X_QZ_T^2 - X_T)^3 - 8(X_QZ_T^2 - X_T)^2X_T, \\ Y_R &= (2Y_QZ_T^3 - 2Y_T)(4(X_QZ_T^2 - X_T)^2X_T - X_R) - 8Y_T(X_QZ_T^2 - X_T)^3, \\ Z_R &= 2Z_T(X_QZ_T^2 - X_T). \end{split}$$

Once again, let the point  $P \in E(\mathbb{F}_p)$  be represented in affine coordinates as  $P = (x_P, y_P)$ . Then, the line through T and Q evaluated at the point P is given as.

$$l_{T,Q}(P) = 2Z_R y_P - 4x_P (Y_Q Z_T^3 + Y_T) W + (4X_Q (Y_Q Z_T^3 X_Q - Y_T) - 2Y_Q Z_R) W^2 \in \mathbb{F}_{p^{12}}.$$

The combined cost of computing  $l_{T,Q}(P)$  and the point addition R = T + Q is,  $7\tilde{m} + 7\tilde{s} + 25\tilde{a} + 4m$ . Finally we must accumulate the value of  $l_{T,Q}(P)$  by performing the product  $f \cdot l_{T,Q}(P)$  at a cost of,  $13\tilde{m} + 39\tilde{a} + 2m_{\beta}$ .

Therefore, the computational cost associated to line 6 of Algorithm 1 is given as,  $20\tilde{m} + 7\tilde{s} + 64\tilde{a} + 4m + 2m_{\beta}$ . This is the same cost of line 8.

Frobenius application and final addition step (lines 11–13). In this step we add to the value accumulated in  $f = f_{6t+2,Q}(P)$ , the product of the lines through the points  $Q_1, -Q_2 \in E'(\mathbb{F}_{p^2})$ , namely,  $l_{[6t+2]Q,Q_1}(P) \cdot l_{[6t+2]Q+Q_1,-Q_2}(P)$ .

The points  $Q_1, Q_2$  can be found by applying the Frobenius operator as,  $Q_1 = \pi_p(Q), Q_2 = \pi_p^2(Q)$ . The total cost of computing lines 11–13 is given as,  $40\tilde{m} + 14\tilde{s} + 128\tilde{a} + 4m + 4m_{\beta}$ .

Let us recall that from our selection of t, 6t + 2 is a 65-bit number with a low Hamming weight of  $7.^2$  This implies that the Miller loop of the optimal ate pairing can be computed using only 64 point doubling steps and 6 point addition/subtraction steps. Therefore, the total cost of the Miller loop portion of Algorithm 1 is approximately given as,

Cost of Miller loop =
$$64 \cdot (28\tilde{m} + 8\tilde{s} + 100\tilde{a} + 4m + 6m_{\beta}) + 6 \cdot (20\tilde{m} + 7\tilde{s} + 64\tilde{a} + 4m + 2m_{\beta}) + 40\tilde{m} + 14\tilde{s} + 128\tilde{a} + 14m + 4m_{\beta}$$

=  $1952\tilde{m} + 568\tilde{s} + 6912\tilde{a} + 294m + 400m_{\beta}$ .

<sup>&</sup>lt;sup>2</sup> We note that in the binary signed representation with digit set  $\{-1,0,1\}$ , the integers  $t=2^{62}-2^{54}+2^{44}$  and  $6t+2=2^{64}+2^{63}-2^{56}-2^{55}+2^{46}+2^{45}+2$  have a signed bitlength of 63 and 65, respectively.

#### 4.2 Final Exponentiation

Line 14 of Algorithm 1 performs the final exponentiation step, by raising  $f \in \mathbb{F}_{p^{12}}$  to the power  $e = (p^{12} - 1)/r$ . We computed the final exponentiation by following the procedure described by Scott *et al.* in [36], where the exponent *e* is split into three coefficients as,

$$e = \frac{p^{12} - 1}{r} = (p^6 - 1) \cdot (p^2 + 1) \cdot \frac{p^4 - p^2 + 1}{r}.$$
 (3)

As it was discussed in Section 3, we can take advantage of the fact that raising f to the power  $p^6$  is equivalent to one conjugation. Hence, one can compute  $f^{(p^6-1)} = \bar{f} \cdot f^{-1}$ , which costs one field inversion and one field multiplication in  $\mathbb{F}_{p^{12}}$ . Moreover, after raising to the power  $p^6-1$ , the resulting field element becomes a member of the cyclotomic subgroup  $\mathbb{G}_{\Phi_6}(\mathbb{F}_{p^2})$ , which implies that inversion of such elements can be computed by simply conjugation (see Table 1). Furthermore, from the discussion in Section 3.2 raising to the power  $p^2+1$ , can be done with five field multiplications in the base field  $\mathbb{F}_p$ , plus one field multiplication in  $\mathbb{F}_{p^{12}}$ . The processing of the third coefficient in Equation (3) is referred as the hard part of the final exponentiation, i.e, the task of computing  $m^{(p^4-p^2+1)/r}$ , with  $m \in \mathbb{F}_{p^{12}}$ . In order to accomplish that, Scott et al. described in [36] a clever procedure that requires the calculation of ten temporary values, namely.

$$m^t, m^{t^2}, m^{t^3}, m^p, m^{p^2}, m^{p^3}, m^{(tp)}, m^{(t^2p)}, m^{(t^3p)}, m^{(t^2p^2)},$$

which are the building blocks required for constructing a vectorial addition chain whose evaluation yields the final exponentiation  $f^e$ , by performing 13 and 4 field multiplication and squaring operations over  $\mathbb{F}_{p^{12}}$ , respectively.<sup>3</sup> Taking advantage of the Frobenius operator efficiency, the temporary values  $m^p$ ,  $m^{p^3}$ ,  $m^{(tp)}$ ,  $m^{(t^2p)}$ ,  $m^{(t^3p)}$ , and  $m^{(t^2p^2)}$  can be computed at a cost of just 35 field multiplications over  $\mathbb{F}_p$  (see Section 3.2). Therefore, the most costly computation of the hard part of the final exponentiation is the calculation of  $m^t$ ,  $m^{t^2} = (m^t)^t$ ,  $m^{t^3} = (m^{t^2})^t$ . From our choice,  $t = 2^{62} - 2^{54} + 2^{44}$ , we can compute these three temporary values at a combined cost of  $62 \cdot 3 = 186$  cyclotomic squarings plus  $2 \cdot 3 = 6$  field multiplications over  $\mathbb{F}_{p^{12}}$ . This is cheaper than the t selection used in [32] that requires  $4 \cdot 3 = 12$  more field multiplications over  $\mathbb{F}_{p^{12}}$ .

Consulting Table 1, we can approximately estimate the total computational cost associated to the final exponentiation as,

F. Exp. cost =
$$(25\tilde{m} + 9\tilde{s} + 12m_{\beta} + 61\tilde{a} + \tilde{i}) + (18\tilde{m} + 6m_{\beta} + 60\tilde{a}) + (18\tilde{m} + 6m_{\beta} + 60\tilde{a}) + 10m + 13 \cdot (18\tilde{m} + 6m_{\beta} + 60\tilde{a}) + 4 \cdot (9\tilde{s} + 4m_{\beta} + 30\tilde{a}) + 70m + 186 \cdot (9\tilde{s} + 4m_{\beta} + 30\tilde{a}) + 6 \cdot (18\tilde{m} + 6m_{\beta} + 60\tilde{a})$$

=  $403\tilde{m} + 1719\tilde{s} + 7021\tilde{a} + 80m + 898m_{\beta} + \tilde{i}$ .

<sup>&</sup>lt;sup>3</sup> We remark that the cost of the field squaring operations is that of the elements in the cyclotomic subgroup  $\mathbb{G}_{\Phi_6}(\mathbb{F}_{p^2})$  listed in the last row of Table 1.

**Table 2.** A Comparison of arithmetic operations required by the computation of the ate pairing variants.

|                       |             | $\tilde{m}$ | $\tilde{s}$ | $\tilde{a}$ | $ \tilde{i} $ | $m_{\xi}$ |
|-----------------------|-------------|-------------|-------------|-------------|---------------|-----------|
| Hankerson et al. [18] | Miller Loop | 2277        | 356         | 6712        | 1             | 412       |
| R-ate pairing         | Final Exp.  | 1616        | 1197        | 8977        | 1             | 1062      |
| n-ate pairing         | Total       | 3893        | 1553        | 15689       | 2             | 1474      |
| Naehrig et al. [32]   | Miller Loop | 2022        | 590         | 7140        |               | 410       |
| Optimal ate pairing   | Final Exp.  | 678         | 1719        | 7921        | 1             | 988       |
| Optimal are pairing   | Total       | 2700        | 2309        | 15061       | 1             | 1398      |
| This work             | Miller Loop | 1952        | 568         | 6912        |               | 400       |
|                       | Final Exp.  | 403         | 1719        | 7021        | 1             | 898       |
| Optimal ate pairing   | Total       | 2355        | 2287        | 13933       | 1             | 1298      |

Table 2 presents a comparison of  $\mathbb{F}_{p^2}$  arithmetic operations of our work against the reference pairing software libraries [18, 32]. From Table 2, we observe that our approach saves about 39.5% and 13%  $\mathbb{F}_{p^2}$  multiplications when compared against [18] and [32], respectively. We recall that in our work, the cost of the operation  $m_{\xi}$  is essentially the same of that of  $m_{\beta}$ . This is not the case in [18, 32], where the operation  $m_{\xi}$  is considerably more costly than  $m_{\beta}$ .

### 5 Software Implementation of Field Arithmetic

In this work, we target the x86-64 instruction set [22]. Our software library is written in C++ and can be used on several platforms: 64-bit Windows 7 with Visual Studio 2008 Professional, 64-bit Linux 2.6 and Mac OS X 10.5 with gcc 4.4.1 or later, etc. In order to improve the runtime performance of our pairing library, we made an extensive use of Xbyak [28], a x86/x64 just-in-time assembler for the C++ language.

#### 5.1 Implementation of Prime Field Arithmetic

The x86-64 instruction set has a **mul** operation which multiplies two 64-bit unsigned integers and returns a 128-bit unsigned integer. The execution of this operation takes about 3 cycles on Intel Core i7 and AMD Opteron processors. Compared to previous architectures, the gap between multiplication and addition/subtraction in terms of cycles is much smaller. This means that we have to be careful when selecting algorithms to perform prime field arithmetic: the schoolbook method is for instance faster than Karatsuba multiplication in the case of 256-bit operands.

An element  $x \in \mathbb{F}_p$  is represented as  $x = (x_3, x_2, x_1, x_0)$ , where  $x_i, 0 \le i \le 3$ , are 64-bit integers. The addition and the subtraction over  $\mathbb{F}_p$  are performed in a straightforward manner, *i.e.*, we add/subtract the operands followed by reduction into  $\mathbb{F}_p$ . Multiplication and inversion over  $\mathbb{F}_p$  are accomplished according

to the well-known Montgomery multiplication and Montgomery inversion algorithms, respectively [19].

#### **5.2 Implementation of Quadratic Extension Field Arithmetic**

This section describes our optimizations for some operations over F*p*<sup>2</sup> defined in Equation (2).

**Multiplication.** We implemented the multiplication over the quadratic extension field F*p*<sup>2</sup> using a Montgomery multiplication scheme split into two steps:

- 1. The straightforward multiplication of two 256-bit integers (producing a 512 bit integer), denoted as, **mul256**.
- 2. The Montgomery reduction from a 512-bit integer to a 256-bit integer. This operation is denoted by **mod512**.

According to our implementation, **mul256** (resp. **mod512**) contains 16 (resp. 20) **mul** operations and its execution takes about 55 (resp. 100) cycles.

Let *P*(*u*) = *u* <sup>2</sup> + 5 be the irreducible binomial defining the quadratic extension F*p*<sup>2</sup> . Let *A, B, C ∈* F*p*<sup>2</sup> such that, *A* = *a*<sup>0</sup> + *a*1*u*, *B* = *b*<sup>0</sup> + *b*1*u*, and *C* = *c*0+*c*1*u* = *A·B*. Then, *c*<sup>0</sup> = *a*0*b*0*−*5*a*1*b*<sup>1</sup> and *c*<sup>1</sup> = (*a*0+*a*1)(*b*0+*b*1)*−a*0*b*0*−a*1*b*1. Hence, in order to obtain the field multiplication over the quadratic extension field, we must compute three multiplications over F*p*, and it may seem that three **mod512** operations are necessary. However, we can keep the results of the products **mul256**(*a*0*, b*0), **mul256**(*a*1*, b*1), and **mul256**(*a*<sup>0</sup> + *a*1*, b*<sup>0</sup> + *b*1) in three temporary 512-bit integer values. Then, we can add or subtract them without reduction, followed by a final call to **mod512** in order to get *c*0*, c*<sup>1</sup> *∈* F*p*. This approach yields the saving of one **mod512** operation as shown in Algorithm 2. We stress that the **addNC**/**subNC** functions in lines 1, 2, 6, and 7 of Algorithm 2, stand for addition/subtraction between 256-bit or 512-bit integers without checking the output carry. We explain next the rationale for using addition/subtraction without output carry check.

The addition *x* + *y,* and subtraction *x − y,* of two elements *x*, *y ∈* F*<sup>p</sup>* include an unpredictable branch check to figure out whether *x* + *y ≥ p* or *x < y*. This is a costly check that is convenient to avoid as much as possible. Fortunately, our selected prime *p* satisfies 7*p < N*, with *N* = 2<sup>256</sup>, and the function **mod512** can reduce operands *x*, whenever, *x < pN*. This implies that we can add up to seven times without performing an output carry check. In line 8, *d*<sup>0</sup> is equal to (*a*<sup>0</sup> + *a*1)(*b*<sup>0</sup> + *b*1) *− a*0*b*<sup>0</sup> *− a*1*b*<sup>1</sup> = *a*0*b*<sup>1</sup> + *a*1*b*<sup>0</sup> *<* 2*p* <sup>2</sup> *< pN*. Hence, we can use **addNC**/**subNC** for step 1, 2, 6, and 7. In line 9, we multiply *d*<sup>2</sup> by the constant value 5, which can be computed with no carry operation. By applying these modifications, we manage to reduce the cost of the field multiplication over F*p*<sup>2</sup> from about 640 cycles (required by a non-optimized procedure) to just 440 cycles.

In line 10, *d*<sup>1</sup> = *a*0*b*<sup>0</sup> *−* 5*a*1*b*1. We perform this operation as a 512-bit integer subtraction with carry operation followed by a **mod512** reduction. Let *x* be a 512-bit integer such that *x* = *a*0*b*<sup>0</sup> *−* 5*a*1*b*<sup>1</sup> and let *t* be a 256-bit integer. The aforementioned carry operation can be accomplished as follows: if *x <* 0, then *t ← p*, otherwise *t ←* 0, then *d*<sup>1</sup> *← x* + *tN*, where this addition operation only uses the 256 most significant bits of *x*.

### **Algorithm 2** Optimized multiplication over F*p*<sup>2</sup> .

```
Input: A and B ∈ Fp2 such that A = a0 + a1u and B = b0 + b1u.
Output: C = A · B ∈ Fp2 .
1. s ← addNC(a0, a1);
2. t ← addNC(b0, b1);
3. d0 ← mul256(s, t);
4. d1 ← mul256(a0, b0);
5. d2 ← mul256(a1, b1);
6. d0 ← subNC(d0, d1);
7. d0 ← subNC(d0, d2);
8. c1 ← mod512(d0);
9. d2 ← 5d2;
10. d1 ← d1 − d2;
11. c0 ← mod512(d1);
12. return C ← c0 + c1u;
```

**Squaring.** Algorithm 3 performs field squaring where some carry operations have been reduced, as explained next. Let *A* = *a*0+*a*1*u ∈* F*p*<sup>2</sup> , *C* = *A*<sup>2</sup> = *c*0+*c*1*u*, and let *x* = (*a*<sup>0</sup> + *p − a*1)(*a*<sup>0</sup> + 5*a*1). Then *c*<sup>0</sup> = *x −* 4*a*0*a*<sup>1</sup> mod *p*. However, we observe that *x ≤* 2*p ·* 6*p* = 12*p* <sup>2</sup> *< N*<sup>2</sup> where *N* = 2<sup>256</sup>. Also we have that,

$$x - 4a_0a_1 \ge a_0(a_0 + 5a_1) - 4a_0a_1 = a_0(a_0 + a_1) \ge 0,$$

which implies,

$$\max(x - 4a_0a_1) = \max(a_0(a_0 + p) + 5a_1(p - a_1))$$

<  $p \cdot 2p + 5(p/2)(p - p/2) < pN$ .

We conclude that we can safely add/subtract the operands in Algorithm 3 without carry check.

**Fast reduction for multiplication by small constant values.** The procedures of point doubling/addition and line evaluation in Miller loop, and the operations *mξ, m<sup>β</sup>* in the tower field arithmetic, involve field multiplications of an arbitrary element *A ∈* F*p*<sup>2</sup> by small constant values 3, 4, 5, and 8.

We first remark that *m<sup>ξ</sup>* requires the calculation of a field multiplication by the constant *u*. Given *A* = *a*<sup>0</sup> + *a*1*u ∈* F*p*<sup>2</sup> , then *A · u* = *β · a*<sup>1</sup> + *a*0*u* = *−*5*a*<sup>1</sup> + *a*0*u*. Computing this operation using shift-and-add expressions such as

### **Algorithm 3** Optimized squaring over F*p*<sup>2</sup> .

```
Input: A ∈ Fp2 such that A = a0 + a1u.
Output: C = A
               2 ∈ Fp2 .
1. t ← addNC(a1, a1);
2. d1 ← mul256(t, a0);
3. t ← addNC(a0, p);
4. t ← subNC(t, a1);
5. c1 ← 5a1;
6. c1 ← addNC(c1, a0);
7. d0 ← mul256(t, c1);
8. c1 ← mod512(d1);
9. d1 ← addNC(d1, d1);
10. d0 ← subNC(d0, d1);
11. c0 ← mod512(d0);
12. return C ← c0 + c1u;
```

5*n* = *n* + (*n ≪* 2) for *n ∈* F*<sup>p</sup>* may be tempting as a means to avoid full multiplication calculations. Nevertheless, in our implementation we preferred to compute those multiplication-by-constant operations using the x86-64 **mul** instruction, since the cost in clock cycles of **mul** is almost the same or even a little cheaper than the one associated to the shift-and-add method.

Multiplications by small constant values require the reduction modulo *p* of an integer *x* smaller than 8*p*. Note that we need five 64-bit registers to store *x* = (*x*4*, x*3*, x*2*, x*1*, x*0). However, one can easily see that *x*<sup>4</sup> = 0 or *x*<sup>4</sup> = 1, and then one can prove that *x* div 2<sup>253</sup> = (*x*<sup>4</sup> *≪* 3)*|*(*x*<sup>3</sup> *≫* 61). Division by 2<sup>253</sup> involves only three logical operations and it can be efficiently performed on our target processor. Furthermore, the prime *p* we selected has the following nice property:

$$(ip) \text{ div } 2^{253} = \begin{cases} i & \text{if } 0 \le i \le 9, \\ i+1 & \text{if } 10 \le i \le 14. \end{cases}$$

Hence, we built a small look-up table *p*-Tbl defined as follows:

$$p\text{-Tbl}[i] = \begin{cases} ip & \text{if } 0 \le i \le 9, \\ (i-1)p & \text{if } 10 \le i \le 14. \end{cases}$$
 (4)

We then get *|x − p*-Tbl[*x ≫* 253]*| < p*. Algorithm 4 summarizes how we apply this strategy to perform a modulo *p* reduction.

### **6 Implementation Results**

We list in Table 3 the timings that we achieved on different architectures. Our library is able to evaluate the optimal ate pairing over a 254-bit prime field F*p*, in just 2*.*33 million of clock cycles on a single core of an Intel Core i7 2*.*8GHz processor, which implies that the pairing computation takes 0*.*832msec. To our

### **Algorithm 4** Fast reduction *x* mod *p*.

**Input:** *x ∈* Z such that 0 *≤ x <* 13*p* and represented as *x* = (*x*4*, x*3*, x*2*, x*1*, x*0), where *xi,* 0 *≤ i ≤* 4, are 64-bit integers. Let *p*-Tbl be the precomputed look-up table defined in Equation (4).

```
Output: z = x mod p.
1. q ← (x4 ≪ 3)|(x3 ≫ 61); (q ← ⌊x/2
                                                             253⌋)
2. z ← x − p-Tbl[q];
3. if z < 0 then
4. z ← z + p;
5. end if
6. return z;
```

best knowledge, we are the first to compute a cryptographic pairing in less than one millisecond at this level of security on a desktop computer.

According to the second column of Table 3, the costs (in clock cycles) that were measured for the F*p*<sup>2</sup> arithmetic when implemented in the Core i7 processor are ˜*m* = 435 and ˜*s* = 342. Additionally, we measured ˜*a* = 40, and ˜*i* = 7504. Now, from Table 2, one can see that the predicted computational cost of the optimal ate pairing is given as,

```
Opt. ate pairing cost = 2355 ˜m + 2287˜s + 13933˜a +˜i
                      = 2355 · 435 + 2287 · 342 + 13933 · 40 + 7504
                      = 2,371,403.
```

We observe that the experimental results presented in Table 3 have a reasonable match with the computational cost prediction given in Section 4.

For comparison purpose, we also report the performance of the software library for BN curves developed by Naehrig *et al.* [32], which is the best software implementation that we know of.<sup>4</sup> Naehrig *et al.* combined several state-of-the art optimization techniques to write a software that is more than twice as fast as the previous reference implementation by Hankerson *et al.* [18]. Perhaps the most original contribution in [32] is the implementation of the arithmetic over the quadratic extension F*p*<sup>2</sup> based on a tailored use of SIMD floating point instructions. Working in the case of hardware realizations of pairings, Fan *et al.* [13] suggested to take advantage of the polynomial form of *p*(*t*) and introduced a new hybrid modular multiplication algorithm. The operands *a* and *b ∈* F*<sup>p</sup>* are converted to degree-4 polynomials *a*(*t*) and *b*(*t*), and multiplied according to Montgomery's algorithm in the polynomial ring. Coefficients of the results must be reduced modulo *t*. Fan *et al* noticed that, if *t* = 2*<sup>m</sup>* + *s*, where *s* is a small constant, this step consists of a multiplication by *s* instead of a division by *t*.

Table 4 summarizes the best results published in the open literature since 2007. All the works featured in Table 4, targeted a level of security equivalent to that of AES-128. Aranha *et al.* [1] and Beuchat *et al.* [8] considered supersingular

<sup>4</sup> The results on the Core 2 Quad processor are reprinted from [32]. We downloaded the library [33] and made our own experiments on an Opteron platform.

**Table 3.** Cycle counts of multiplication over F*p*<sup>2</sup> , squaring over F*p*<sup>2</sup> , and optimal ate pairing on different machines.

|                         | Our results     |                     |             |                                     |  |
|-------------------------|-----------------|---------------------|-------------|-------------------------------------|--|
|                         |                 | Core i7a Opteronb   | Core 2 Duoc | Athlon 64 X2d                       |  |
| Multiplication over Fp2 | 435             | 443                 | 558         | 473                                 |  |
| Squaring over Fp2       | 342             | 355                 | 445         | 376                                 |  |
| Miller loop             |                 | 1,330,000 1,360,000 | 1,680,000   | 1,480,000                           |  |
| Final exponentiation    |                 | 1,000,000 1,040,000 | 1,270,000   | 1,081,000                           |  |
| Optimal ate pairing     |                 | 2,330,000 2,400,000 | 2,950,000   | 2,561,000                           |  |
|                         | dclxvi [32, 33] |                     |             |                                     |  |
|                         | Core i7         |                     |             | Opteronb Core 2 Quade Athlon 64 X2d |  |
| Multiplication over Fp2 | –               | 695                 | 693         | 1714                                |  |
| Squaring over Fp2       | –               | 614                 | 558         | 1207                                |  |
| Miller loop             | –               | 2,480,000           | 2,260,000   | 5,760,000                           |  |
| Final exponentiation    | –               | 2,520,000           | 2,210,000   | 5,510,000                           |  |
| Optimal ate pairing     | –               | 5,000,000           | 4,470,000   | 11,270,000                          |  |

a Intel Core i7 860 (2*.*8GHz), Windows 7, Visual Studio 2008 Professional

elliptic curves in characteristic 2 and 3, respectively. All other authors worked with ordinary curves.

Several authors studied multi-core implementations of a cryptographic pairing [1, 8, 16]. In the light of the results reported in Table 4, it seems that the acceleration achieved by an *n*-core implementation is always less than the ideal *n×* speedup. This is related to the extra arithmetic operations needed to combine the partial results generated by each core, and the dependencies between the different operations involved in the final exponentiation. The question that arises is therefore: how many cores should be utilized to compute a cryptographic pairing? We believe that the best answer is the one provided by Grabher *et al.*: "if the requirement is for two pairing evaluations, the slightly moronic conclusion is that one can perform one pairing on each core [. . . ], doubling the performance versus two sequential invocations of any other method that does not already use multi-core parallelism internally" [16].

### **7 Conclusion**

In this paper we have presented a software library that implements the optimal ate pairing over a Barreto–Naehrig curve at the 126-bit security level. To the best of our knowledge, we are the first to have reported the computation of a bilinear pairing at a level of security roughly equivalent to that of AES-128 in

<sup>b</sup> Quad-Core AMD Opteron 2376 (2*.*3GHz), Linux 2.6.18, gcc 4.4.1

c Intel Core 2 Duo T7100 (1*.*8GHz), Windows 7, Visual Studio 2008 Professional

<sup>d</sup> Athlon 64 X2 Dual Core 6000+(3GHz), Linux 2.6.23, gcc 4.1.2

e Intel Core 2 Quad Q6600 (2394MHz), Linux 2.6.28, gcc 4.3.3

**Table 4.** A comparison of cycles and timings required by the computation of the ate pairing variants. The frequency is given in GHz and the timings are in milliseconds.

|                       | Algo. | Architecture                          | Cycles     | Freq. Calc. | time  |
|-----------------------|-------|---------------------------------------|------------|-------------|-------|
| Devegili et al. [10]  | ate   | Intel Pentium IV                      | 69,600,000 | 3.0         | 23.20 |
| Naehrig et al. [31]   | ate   | Intel Core 2 Duo                      | 29,650,000 | 2.2         | 13.50 |
|                       | ate   | Intel Core 2 Duo (1 core) 23,319,673  |            |             | 9.72  |
| Grabher et al. [16]   |       | Intel Core 2 Duo (2 cores) 14,429,439 |            | 2.4         | 6.01  |
| Aranha et al. [1]     | ηT    | Intel Xeon 45nm (1 core) 17,400,000   |            | 2.0         | 8.70  |
|                       |       | Intel Xeon 45nm (8 cores)             | 3,020,000  |             | 1.51  |
| Beuchat et al. [8]    | ηT    | Intel Core i7 (1 core)                | 15,138,000 | 2.9         | 5.22  |
|                       |       | Intel Core i7 (8 cores)               | 5,423,000  |             | 1.87  |
| Hankerson et al. [18] | R-ate | Intel Core 2                          | 10,000,000 | 2.4         | 4.10  |
| Naehrig et al. [32]   | aopt  | Intel Core 2 Quad Q6600               | 4,470,000  | 2.4         | 1.80  |
| This work             | aopt  | Intel Core i7                         | 2,330,000  | 2.8         | 0.83  |

less than one millisecond on a single core of an Intel Core i7 2*.*8GHz processor. The speedup achieved in this work is a combination of two main factors:

- **–** A careful programming of the underlying field arithmetic based on Montgomery multiplication that allowed us to perform a field multiplication over F*<sup>p</sup>* and F*p*<sup>2</sup> in just 160 and 435 cycles, respectively, when working in an Opteron-based machine. We remark that in contrast with [32], we did not make use of the 128-bit multimedia arithmetic instructions.
- **–** A binary signed selection of the parameter *t* that allowed us to obtain significant savings in both the Miller loop and the final exponentiation of the optimal ate pairing.

Our selection of *t* yields a prime *p* = *p*(*t*) that has a bitlength of just 254 bits. This size is slightly below than what Freeman *et al.* [14] recommend for achieving a high security level. If for certain scenarios, it becomes strictly necessary to meet or exceed the 128-bit level of security, we recommend to select *t* = 2<sup>63</sup> *−*2 <sup>49</sup> that produces a prime *p* = *p*(*t*) with a bitlength of 258 bits. However, we warn the reader that since a 258-bit prime implies that more than four 64-bit register will be required to store field elements, the performance of the arithmetic library will deteriorate.

Consulting the cycle count costs listed in Table 3, one can see that for our implementation the cost of the final exponentiation step is nearly 25% cheaper than that of the Miller loop.

Authors in [13,32] proposed to exploit the polynomial parametrization of the prime *p* as a means to speed up the underlying field arithmetic. We performed extensive experiments trying to apply this idea to our particular selection of *t* with no success. Instead, the customary Montgomery multiplier algorithm appears to achieve a performance that is very hard to beat by other multiplication schemes, whether integer-based or polynomial-based multipliers.

The software library presented in this work computes a bilinear pairing at a high security level at a speed that is faster than the best hardware accelerators published in the open literature (see for instance [7, 13, 23, 37]). We believe that this situation is unrealistic and therefore we will try to design a hardware architecture that can compute 128-bit security bilinear pairing in shorter timings. Our future work will also include a study of the parallelization possibilities on pairing-based protocols that specify the computation of many bilinear pairing during their execution.

### **8 Acknowledgements**

We thank Michael Naehrig, Ruben Niederhagen, and Peter Schwabe for making their pairing software library [33] freely available for research purposes.

The authors also want to thank Diego Aranha, Paulo S.L.M. Barreto, Darrel Hankerson, Alfred Menezes, and the anonymous referees for their valuable comments.

### **References**

- 1. D.F. Aranha, J. L´opez, and D. Hankerson. High-speed parallel software implementation of the *η<sup>T</sup>* pairing. In J. Pieprzyk, editor, *Topics in Cryptology–CT-RSA 2010*, volume 5985 of *Lecture Notes in Computer Science*, pages 89–105. Springer, 2010.
- 2. C. Arene, T. Lange, M. Naehrig, and C. Ritzenthaler. Faster computation of the Tate pairing. Cryptology ePrint Archive, Report 2009/155, 2009. Available at http://eprint.iacr.org/2009/155.pdf.
- 3. P.S.L.M. Barreto, S.D. Galbraith, C. O h ´ Eigeartaigh, and M. Scott. Efficient pair- ´ ing computation on supersingular Abelian varieties. *Designs, Codes and Cryptography*, 42:239–271, 2007.
- 4. P.S.L.M. Barreto, H.Y. Kim, B. Lynn, and M. Scott. Efficient algorithms for pairing-based cryptosystems. In M. Yung, editor, *Advances in Cryptology– CRYPTO 2002*, number 2442 in Lecture Notes in Computer Science, pages 354– 368. Springer, 2002.
- 5. P.S.L.M. Barreto and M. Naehrig. Pairing-friendly elliptic curves of prime order. In B. Preneel and S. Tavares, editors, *Selected Areas in Cryptography–SAC 2005*, volume 3897 of *Lecture Notes in Computer Science*, pages 319–331. Springer, 2006.
- 6. N. Benger and M. Scott. Constructing tower extensions for the implementation of pairing-based cryptography. Cryptology ePrint Archive, Report 2009/556, 2009. Available at http://eprint.iacr.org/2009/556.pdf.
- 7. J.-L. Beuchat, J. Detrey, N. Estibals, E. Okamoto, and F. Rodr´ıguez-Henr´ıquez. Fast architectures for the *η<sup>T</sup>* pairing over small-characteristic supersingular elliptic curves. Cryptology ePrint Archive, Report 2009/398, 2009. Available at http: //eprint.iacr.org/2009/398.pdf.
- 8. J.-L. Beuchat, E. L´opez-Trejo, L. Mart´ınez-Ramos, S. Mitsunari, and F. Rodr´ıguez-Henr´ıquez. Multi-core implementation of the Tate pairing over supersingular elliptic curves. In J.A. Garay, A. Miyaji, and A. Otsuka, editors, *Cryptology and Network Security–CANS 2009*, number 5888 in Lecture Notes in Computer Science, pages 413–432. Springer, 2009.

- 9. J. Chung and M.A. Hasan. Asymmetric squaring formulae. In P. Kornerup and J.-M. Muller, editors, *Proceedings of the 18th IEEE Symposium on Computer Arithmetic*, pages 113–122. IEEE Computer Society, 2007.
- 10. A.J. Devegili, M. Scott, and R. Dahab. Implementing cryptographic pairings over Barreto–Naehrig curves. In T. Takagi, T. Okamoto, E. Okamoto, and T. Okamoto, editors, *Pairing-Based Cryptography–Pairing 2007*, volume 4575 of *Lecture Notes in Computer Science*, pages 197–207. Springer, 2007.
- 11. I. Duursma, P. Gaudry, and F. Morain. Speeding up the discrete log computation on curves with automorphisms. In K.-Y. Lam, E. Okamoto, and C. Xing, editors, *Advances in Cryptology–ASIACRYPT 1999*, volume 1716 of *Lecture Notes in Computer Science*, pages 103–121. Springer, 1999.
- 12. I. Duursma and H.S. Lee. Tate pairing implementation for hyperelliptic curves *y* <sup>2</sup> = *x <sup>p</sup> − x* + *d*. In C.S. Laih, editor, *Advances in Cryptology–ASIACRYPT 2003*, number 2894 in Lecture Notes in Computer Science, pages 111–123. Springer, 2003.
- 13. J. Fan, F. Vercauteren, and I. Verbauwhede. Faster F*p*-arithmetic for cryptographic pairings on Barreto–Naehrig curves. In C. Clavier and K. Gaj, editors, *Cryptographic Hardware and Embedded Systems–CHES 2009*, number 5747 in Lecture Notes in Computer Science, pages 240–253. Springer, 2009.
- 14. D. Freeman, M. Scott, and E. Teske. A taxonomy of pairing-friendly elliptic curves. *Journal of Cryptology*, 23(2):224–280, April 2010.
- 15. S. Galbraith, K. Paterson, and N. Smart. Pairings for cryptographers. *Discrete Applied Mathematics*, 156:3113–3121, January 2008.
- 16. P. Grabher, J. Großsch¨adl, and D. Page. On software parallel implementation of cryptographic pairings. In *Selected Areas in Cryptography–SAC 2008*, number 5381 in Lecture Notes in Computer Science, pages 34–49. Springer, 2008.
- 17. R. Granger and M. Scott. Faster squaring in the cyclotomic subgroup of sixth degree extensions. Cryptology ePrint Archive, Report 2009/565, 2009. Available at http://eprint.iacr.org/2009/565.pdf.
- 18. D. Hankerson, A. Menezes, and M. Scott. Software implementation of pairings. In M. Joye and G. Neven, editors, *Identity-based Cryptography*, Cryptology and Information Security Series, chapter 12, pages 188–206. IOS Press, 2009.
- 19. D. Hankerson, A. Menezes, and S. Vanstone. *Guide to Elliptic Curve Cryptography*. Springer-Verlag New York, Inc., 2004.
- 20. F. Hess. Pairing lattices. In S.D. Galbraith and K.G. Paterson, editors, *Pairing-Based Cryptography–Pairing 2008*, number 5209 in Lecture Notes in Computer Science, pages 18–38. Springer, 2008.
- 21. F. Hess, N. Smart, and F. Vercauteren. The Eta pairing revisited. *IEEE Transactions on Information Theory*, 52(10):4595–4602, October 2006.
- 22. Intel Corporation. *Intel 64 and IA-32 Architectures Software Developer's Manuals*. Available at http://www.intel.com/products/processor/manuals/.
- 23. D. Kammler, D. Zhang, P. Schwabe, H. Scharwaechter, M. Langenberg, D. Auras, G. Ascheid, and R. Mathar. Designing an ASIP for cryptographic pairings over Barreto–Naehrig curves. In C. Clavier and K. Gaj, editors, *Cryptographic Hardware and Embedded Systems–CHES 2009*, number 5747 in Lecture Notes in Computer Science, pages 254–271. Springer, 2009.
- 24. N. Koblitz and A. Menezes. Pairing-based cryptography at high security levels. Cryptology ePrint Archive, Report 2005/076, 2005. Available at http://eprint. iacr.org/2005/076.pdf.
- 25. E. Lee, H.-S. Lee, and C.-M. Park. Efficient and generalized pairing computation on abelian varieties. Cryptology ePrint Archive, Report 2008/040, 2008. Available at http://eprint.iacr.org/2008/040.pdf.

- 26. V.S. Miller. Short programs for functions on curves. Available at http://crypto. stanford.edu/miller, 1986.
- 27. V.S. Miller. The Weil pairing, and its efficient calculation. *Journal of Cryptology*, 17(4):235–261, September 2004.
- 28. S. Mitsunari. Xbyak: JIT assembler for C++. Available at http://homepage1. nifty.com/herumi/soft/xbyak\_e.html.
- 29. A. Miyaji, M. Nakabayashi, and S. Takano. New explicit conditions of elliptic curve traces for FR-reduction. *IEICE Trans. Fundamentals*, E84:1234–1243, 2001.
- 30. M. Naehrig. *Constructive and Computational Aspects of Cryptographic Pairings*. PhD thesis, Technische Universiteit Eindhoven, 2009. Available at http://www. cryptojedi.org/users/michael/data/thesis/2009-05-13-diss.pdf.
- 31. M. Naehrig, P.S.L.M. Barreto, and P. Schwabe. On compressible pairings and their computation. In S. Vaudenay, editor, *Progress in Cryptology–AFRICACRYPT 2008*, volume 5023 of *Lecture Notes in Computer Science*, pages 371–388. Springer, 2008.
- 32. M. Naehrig, R. Niederhagen, and P. Schwabe. New software speed records for cryptographic pairings. Cryptology ePrint Archive, Report 2010/186, 2010. Available at http://eprint.iacr.org/2010/186.pdf.
- 33. P. Schwabe. Software library of "New software speed records for cryptographic pairings", Accessed June, 4, 2010. Available at http://cryptojedi.org/crypto/ #dclxvi.
- 34. M. Scott. Implementing cryptographic pairings. In T. Takagi, T. Okamoto, E. Okamoto, and T. Okamoto, editors, *Pairing-Based Cryptography–Pairing 2007*, volume 4575 of *Lecture Notes in Computer Science*, pages 177–196. Springer, 2007.
- 35. M. Scott and P.S.L.M. Barreto. Compressed pairings. In M.K. Franklin, editor, *Advances in Cryptology–CRYPTO 2004*, volume 3152 of *Lecture Notes in Computer Science*, pages 140–156. Springer, 2004.
- 36. M. Scott, N. Benger, M. Charlemagne, L.J. Dominguez Perez, and E.J. Kachisa. On the final exponentiation for calculating pairings on ordinary elliptic curves. Cryptology ePrint Archive, Report 2008/490, 2008. Available at http://eprint. iacr.org/2008/490.pdf.
- 37. C. Shu, S. Kwon, and K. Gaj. Reconfigurable computing approach for Tate pairing cryptosystems over binary fields. *IEEE Transactions on Computers*, 58(9):1221– 1237, September 2009.
- 38. F. Vercauteren. Optimal pairings. *IEEE Transactions on Information Theory*, 56(1):455–461, January 2010.

#### Algorithms Α

### A.1 Arithmetic over $\mathbb{F}_{p^2}$

```
Algorithm 5 Addition in \mathbb{F}_{p^2} = \mathbb{F}_p[u]/(u^2 - \beta).
```

Require:  $A = a_0 + a_1 u \in \mathbb{F}_{p^2}$  and  $B = b_0 + b_1 u \in \mathbb{F}_{p^2}$ .

**Ensure:**  $C = c_0 + c_1 u = A + B \in \mathbb{F}_{n^2}$ .

- 1.  $c_0 \leftarrow a_0 + b_0$ ;
- 2.  $c_1 \leftarrow a_1 + b_1$ ;
- 3. **return**  $C = c_0 + c_1 u$ ;

# **Algorithm 6** Subtraction in $\mathbb{F}_{p^2} = \mathbb{F}_p[u]/(u^2 - \beta)$ .

Require:  $A = a_0 + a_1 u \in \mathbb{F}_{p^2}$  and  $B = b_0 + b_1 u \in \mathbb{F}_{p^2}$ . Ensure:  $C = c_0 + c_1 u = A - B \in \mathbb{F}_{p^2}$ .

- 1.  $c_0 \leftarrow a_0 b_0$ ;
- 2.  $c_1 \leftarrow a_1 b_1$ ;
- 3. **return**  $C = c_0 + c_1 u$ ;

# $\overline{\textbf{Algorithm 7}} \, \overline{\textbf{Multiplication by } b_0 \in \mathbb{F}_p.$

Require:  $A = a_0 + a_1 u \in \mathbb{F}_{p^2}$  and  $b_0 \in \mathbb{F}_p$ .

**Ensure:**  $C = c_0 + c_1 u = A \cdot b_0 \in \mathbb{F}_{p^2}$ .

- 1.  $c_0 \leftarrow a_0 \cdot b_0$ ;
- $2. \ c_1 \leftarrow a_1 \cdot b_0;$
- 3. **return**  $C = c_0 + c_1 u$ ;

### **Algorithm 8** Inverse in $\mathbb{F}_{p^2} = \mathbb{F}_p[u]/(u^2 - \beta)$ .

Require:  $A = a_0 + a_1 u \in \mathbb{F}_{p^2}$ . Ensure:  $C = c_0 + c_1 u = A^{-1} \in \mathbb{F}_{p^2}$ .

- 1.  $t_0 \leftarrow a_0^2$ ; 2.  $t_1 \leftarrow a_1^2$ ;
- 3.  $t_0 \leftarrow t_0 \beta \cdot t1;$ 4.  $t_1 \leftarrow t_0^{-1};$
- 5.  $c_0 \leftarrow a_0 \cdot t_1;$
- 6.  $c_1 \leftarrow -1 \cdot a_1 \cdot t_1$ ;
- 7. **return**  $C = c_0 + c_1 u$ ;

### A.2 Arithmetic over $\mathbb{F}_{n^4}$

```
Algorithm 9 Squaring in \mathbb{F}_{p^4} = \mathbb{F}_{p^2}[V]/(V^2 - \xi).

Require: A = a_0 + a_1 V \in \mathbb{F}_{p^4}.

Ensure: C = c_0 + c_1 V = A^2 \in \mathbb{F}_{p^2}.

1. t_0 \leftarrow a_0^2;
2. t_1 \leftarrow a_1^2;
3. c_0 \leftarrow t_1 \cdot \xi;
4. c_0 \leftarrow c_0 + t_0;
5. c_1 \leftarrow a_0 + a_1;
6. c_1 \leftarrow c_1^2 - t_0 - t_1;
7. return C = c_0 + c_1 V;
```

#### A.3 Arithmetic over $\mathbb{F}_{n^6}$

```
Algorithm 10 Addition in \mathbb{F}_{p^6} = \mathbb{F}_{p^2}[v]/(v^3 - \xi).

Require: A = a_0 + a_1v + a_2v^2 \in \mathbb{F}_{p^6} and B = b_0 + b_1v + b_2v^2 \in \mathbb{F}_{p^6}.

Ensure: C = c_0 + c_1v + c_2v^2 = A + B \in \mathbb{F}_{p^6}.

1. c_0 \leftarrow a_0 + b_0;
2. c_1 \leftarrow a_1 + b_1;
3. c_2 \leftarrow a_2 + b_2;
4. return C = c_0 + c_1v + c_2v^2;
```

```
Algorithm 11 Subtraction in \mathbb{F}_{p^6} = \mathbb{F}_{p^2}[v]/(v^3 - \xi).

Require: A = a_0 + a_1v + a_2v^2 \in \mathbb{F}_{p^6} and B = b_0 + b_1v + b_2v^2 \in \mathbb{F}_{p^6}.

Ensure: C = c_0 + c_1v + c_2v^2 = A - B \in \mathbb{F}_{p^6}.

1. c_0 \leftarrow a_0 - b_0;
2. c_1 \leftarrow a_1 - b_1;
3. c_2 \leftarrow a_2 - b_2;
4. return C = c_0 + c_1v + c_2v^2;
```

```
Algorithm 12 Multiplication by \gamma

Require: A \in \mathbb{F}_{p^6}, where A = a_0 + a_1v + a_2v^2; a_i \in \mathbb{F}_{p^6}.

Ensure: C = A \cdot \gamma, C \in \mathbb{F}_{p^6}, where C = c_0 + c_1v + c_2v^2; c_i \in \mathbb{F}_{p^2}.

1. c_0 \leftarrow a_2 \cdot \xi;

2. return C \leftarrow c_0 + a_0v + a_1v^2;
```

#### **Algorithm 13** Multiplication in F*p*<sup>6</sup> = F*p*<sup>2</sup> [*v*]*/*(*v* <sup>3</sup> *− ξ*).

```
Require: A = a0 + a1v + a2v
                                2 ∈ Fp6 and B = b0 + b1v + b2v
                                                                 2 ∈ Fp6 .
Ensure: C = c0 + c1v + c2v
                              2 = A · B ∈ Fp6 .
 1. t0 ← a0 · b0;
 2. t1 ← a1 · b1;
 3. t2 ← a2 · b2;
 4. c0 ← [(a1 + a2) · (b1 + b2) − t1 − t2] · ξ + t0;
 5. c1 ← (a0 + a1) · (b0 + b1) − t0 − t1 + ξ · t2;
 6. c2 ← (a0 + a2) · (b0 + b2) − t0 − t2 + t1;
 7. return C = c0 + c1v + c2v
                                 2
                                  ;
```

Algorithm 15 computes the product of *A ∈* F*p*<sup>6</sup> by a constant *b ∈* F*p*<sup>2</sup> . However, it can be also used to compute the product of *A* by a constant *b ′ ∈* F*<sup>p</sup>* using Algorithm 7, instead of the general multiplication in F*p*<sup>2</sup> .

### **Algorithm 14** Multiplication by *b*<sup>0</sup> *∈* F*p*<sup>2</sup> .

```
Require: A = a0 + a1v + a2v
                               2 ∈ Fp6 and b0 ∈ Fp2 .
Ensure: C = c0 + c1v + c2v
                             2 = A · b0 ∈ Fp6 .
 1. c0 ← a0 · b0;
 2. c1 ← a1 · b0;
 3. c2 ← a2 · b0;
 4. return C = c0 + c1v + c2v
                                2
                                  ;
```

### **Algorithm 15** Multiplication by *b*<sup>0</sup> + *b*1*v*.

```
Require: A = a0 + a1v + a2v
                                2 ∈ Fp6 and b0, b1 ∈ Fp2
Ensure: C = c0 + c1v + c2v
                              2 = A · (b0 + b1v) ∈ Fp6 .
 1. t0 ← a0 · b0;
 2. t1 ← a1 · b1;
 3. c0 ← ((a1 + a2) · (b1) − t1) · ξ + t0;
 4. c1 ← (a0 + a1) · (b0 + b1) − t0 − t1;
 5. c2 ← a2 · b0 + t1;
 6. return C = c0 + c1v + c2v
                                 2
                                  ;
```

# **Algorithm 16** Squaring in $\mathbb{F}_{p^6} = \mathbb{F}_{p^2}[v]/(v^3 - \xi)$ .

```
Require: A = a_0 + a_1v + a_2v^2 \in \mathbb{F}_{p^6}.

Ensure: C = c_0 + c_1v + c_2v^2 = A^2 \in \mathbb{F}_{p^6}.

1. c_4 \leftarrow 2(a_0 \cdot a_1);

2. c_5 \leftarrow a_2^2;

3. c_1 \leftarrow c_5 \cdot \xi + c_4;

4. c_2 \leftarrow c_4 - c_5;

5. c_3 \leftarrow a_0^2;

6. c_4 \leftarrow a_0 - a_1 + a_2;

7. c_5 \leftarrow 2(a_1 \cdot a_2);

8. c_4 \leftarrow c_4^2;

9. c_0 \leftarrow c_5 \cdot \xi + c_3;

10. c_2 \leftarrow c_2 + c_4 + c_5 - c_3;

11. return C = c_0 + c_1v + c_2v^2;
```

### **Algorithm 17** Inverse in $\mathbb{F}_{p^6} = \mathbb{F}_{p^2}[v]/(v^3 - \xi)$ .

```
Require: A = a_0 + a_1 v + a_2 v^2 \in \mathbb{F}_{p^6}.
Ensure: C = c_0 + c_1 v + c_2 v^2 = A^{-1} \in \mathbb{F}_{p^6}.
 1. t_0 \leftarrow a_0^2;
2. t_1 \leftarrow a_1^2;
 3. t_2 \leftarrow a_2^2;
 4. t_3 \leftarrow a_0 \cdot a_1;
 5. t_4 \leftarrow a_0 \cdot a_2;
 6. t_5 \leftarrow a_2 \cdot a_3;
 7. c_0 \leftarrow t_0 - \xi \cdot t_5;
 8. c_1 \leftarrow \xi \cdot t_2 - t_3;
 9. c_2 \leftarrow t_1 \cdot t_4;
10. t_6 \leftarrow a_0 \cdot c_0;
11. t_6 \leftarrow t_6 + \xi \cdot a_2 \cdot c_1;
12. t_6 \leftarrow t_6 + \xi \cdot a_1 \cdot c_2;
13. t_6 \leftarrow t_6^{-1};
14. c_0 \leftarrow c_0 \cdot t_6;
15. c_1 \leftarrow c_1 \cdot t_6;
16. c_2 \leftarrow c_2 \cdot t_6;
17. return C = c_0 + c_1 v + c_2 v^2;
```

### **A.4 Arithmetic over** F*p***<sup>12</sup>**

```
Algorithm 18 Addition in Fp12 = Fp6 [w]/(w
                                              2 − γ).
Require: A = a0 + a1w ∈ Fp12 and B = b0 + b1w ∈ Fp12 .
Ensure: C = c0 + c1w = A + B ∈ Fp12 .
1. c0 ← a0 + b0;
2. c1 ← a1 + b1;
3. return C = c0 + c1w;
```

```
Algorithm 19 Subtraction in Fp12 = Fp6 [w]/(w
                                                 2 − γ).
Require: A = a0 + a1w ∈ Fp12 and B = b0 + b1w ∈ Fp12 .
Ensure: C = c0 + c1w = A − B ∈ Fp12 .
1. c0 ← a0 − b0;
2. c1 ← a1 − b1;
3. return C = c0 + c1w;
```

```
Algorithm 20 Multiplication in Fp12 = Fp6 [w]/(w
                                                      2 − γ).
Require: A = a0 + a1w ∈ Fp12 and B = b0 + b1w ∈ Fp12 .
Ensure: C = c0 + c1w = A · B ∈ Fp12 .
1. t0 ← a0 · b0;
2. t1 ← a1 · b1;
3. c0 ← t0 + t1 · γ;
4. c1 ← (a0 + a1) · (b0 + b1) − t0 − t1;
5. return C = c0 + c1w;
```

The next algorithm will be required during the execution of the optimal ate pairing computation (instead of Algorithm 20), avoiding unnecessary multiplications by zero.

# **Algorithm 21** Multiplication by $B = b_0 + b_1 w$ , where $b_0 \in \mathbb{F}_{p^2}$ and $b_1 = b_1 + b_2 w$

```
b_{10} + b_{11}v + 0v^2
Require: A = a_0 + a_1 w \in \mathbb{F}_{p^{12}} and B = b_0 + b_1 w \in \mathbb{F}_{p^{12}}, with b_0 = b_{00} + 0v + 0v^2
     and b_1 = b_{10} + b_{11}v + 0v^2.
Ensure: C = c_0 + c_1 w = A \cdot B \in \mathbb{F}_{p^{12}}.
1. t_0 \leftarrow a_0 \cdot b_0; {Algorithm 14}
 2. t_1 \leftarrow a_1 \cdot b_1; {Algorithm 15}
 3. c_0 \leftarrow t_0 + t_1 \cdot \gamma;
 4. t_2 \leftarrow (b_0 + b_{10})v + b_{11}v + 0v^2;
 5. c_1 \leftarrow (a_0 + a_1) \cdot t_2; {Algorithm 15}
 6. c_1 \leftarrow c_1 - t_0 - t_1;
 7. return C = c_0 + c_1 w;
```

## **Algorithm 22** Squaring in $\mathbb{F}_{p^{12}} = \mathbb{F}_{p^6}[w]/(w^2 - \gamma)$ .

```
Require: A = a_0 + a_1 w \in \mathbb{F}_{p^{12}}.
Ensure: C = c_0 + c_1 w = A^2 \in \mathbb{F}_{n^{12}}.
1. c_0 \leftarrow a_0 - a_1;
 2. \ c_3 \leftarrow a_0 - \gamma \cdot a_1;
3. c_2 \leftarrow a_0 \cdot a_1;
 4. c_0 \leftarrow c_0 \cdot c_3 + c_2;
 5. c_1 \leftarrow 2c_2;
6. c_2 \leftarrow \gamma \cdot c_2;
 7. c_0 \leftarrow c_0 + c_2;
8. return C = c_0 + c_1 w;
```

### **Algorithm 23** Inverse in $\mathbb{F}_{p^{12}} = \mathbb{F}_{p^6}[w]/(w^2 - \gamma)$ .

```
Require: A = a_0 + a_1 w \in \mathbb{F}_{p^{12}}.
Ensure: C = c_0 + c_1 w = A^{-1} \in \mathbb{F}_{p^{12}}.
 1. t_0 \leftarrow a_0^2;
  2. t_1 \leftarrow a_1^2;
 3. t_0 \leftarrow t_0 - \gamma \cdot t1;
4. t_1 \leftarrow t_0^{-1};
  5. c_0 \leftarrow a_0 \cdot t_1;
  6. c_1 \leftarrow -1 \cdot a_1 \cdot t_1;
  7. return C = c_0 + c_1 w;
```

We stress that Algorithms 24 and 25 for computing field squaring and exponentiation over F*p*<sup>12</sup> , respectively, can be only used when *X ∈* F*p*<sup>12</sup> satisfies *X<sup>p</sup>* <sup>6</sup>+1 = 1. Algorithm 24 is based on the work presented in [17]. Let *f* = *g* + *hw ∈* F*p*<sup>12</sup> be an element in the representation F*p*<sup>12</sup> = F*p*<sup>6</sup> [*w*]*/*(*w* <sup>2</sup> *− γ*). Then, in order to reduce the required number of field multiplications, we can write *f* using the towering F*p*<sup>12</sup> = F*p*<sup>4</sup> [*X*]*/*(*X*<sup>3</sup>*−γ*), where F*p*<sup>4</sup> = F*p*<sup>2</sup> [*V* ]*/*(*V* <sup>2</sup>*−ξ*). In that representation, *f* can be equivalently written as *f* = *g* + *hw* = (*g*<sup>0</sup> + *h*1*V* ) + (*h*<sup>0</sup> + *g*2*V* )*X* + (*g*<sup>1</sup> + *h*2*V* )*X*<sup>2</sup> . We note that the first three squarings of Lines 1, 2 and 3, must be performed using Algorithm 9.

```
Require: f = g + hw ∈ Fp12 , with g = g0 + g1v + g2v
                                                            and h = h0 + h1v + h2v
                                                                                      .
Ensure: C = c0 + c1w = f
                             2 ∈ Fp12 .
 1. t0,0, t1,1 ← (g0 + h1V )
                            2
                             ;
 2. t1,2, t0,1 ← (h0 + g2V )
                            2
 3. t0,2, aux ← (g1 + h2V )
                            2
                             ;
 4. t1,0 ← aux · ξ;
```

<sup>2</sup> *− γ*).

2

2

6. *c*0*,*<sup>1</sup> *← −*2*g*<sup>1</sup> + 3*t*0*,*1; 7. *c*0*,*<sup>2</sup> *← −*2*g*<sup>2</sup> + 3*t*0*,*2; 8. *c*1*,*<sup>0</sup> *←* 2*h*<sup>0</sup> + 3*t*1*,*0; 9. *c*1*,*<sup>1</sup> *←* 2*h*<sup>1</sup> + 3*t*1*,*1;

5. *c*0*,*<sup>0</sup> *← −*2*g*<sup>0</sup> + 3*t*0*,*0;

**Algorithm 24** Squaring in F*p*<sup>12</sup> = F*p*<sup>6</sup> [*w*]*/*(*w*

- 10. *c*1*,*<sup>2</sup> *←* 2*h*<sup>2</sup> + 3*t*1*,*2; 11. *c*0*, c*<sup>1</sup> *∈* F*p*<sup>6</sup> ;
- 12. *c*<sup>0</sup> *← c*0*,*<sup>0</sup> + *c*0*,*1*v* + *c*1*,*2*v* 2 13. *c*<sup>1</sup> *← c*1*,*<sup>0</sup> + *c*1*,*1*v* + *c*1*,*2*v* 2 ;
- 14. **return** *C* = *c*<sup>0</sup> + *c*1*w*;

In the exponentiation Algorithm 25, it is assumed that the exponent *e* is given as, *e* = (*e<sup>L</sup>−*<sup>1</sup>*, . . . , e*1*, e*0), where *e<sup>i</sup> ∈ {−*1*,* 0*,* 1*}* for *i* = 0*, . . . , L −* 1 and where *e<sup>L</sup>−*<sup>1</sup> = 1.

#### **Algorithm 25** Exponentiation in F*p*<sup>12</sup> = F*p*<sup>6</sup> [*w*]*/*(*w* <sup>2</sup> *− γ*).

```
Require: A ∈ Fp12 and e =
                         ∑L−1
                           i=0 ei2
                                 i
                                  .
Ensure: C = A
              e ∈ Fp12 .
1. C ← A;
2. for i ← L − 2 downto 0 do
3. C ← C
           2
            ; {Algorithm 24}
4. if ei ̸= 0 then
5. if ei > 0 then
6. C ← C · A;
7. else
8. C ← C · A¯;
9. end if
10. end if
11. end for
12. return C;
```

#### **A.5 Line Evaluation**

For the line operations, we need to work with the points on the twist as a jacobian points, i.e. (*X, Y, Z*) *∈ E′* (F*p*<sup>2</sup> ). But it is also a good idea to keep some extra values, for instance *Z* 2 *,* which is required several times in Algorithms 26 and 27.

### Algorithm 26 Point doubling and line evaluation

```
Require: Q \in E(\mathbb{F}_{p^2}) and P \in E(\mathbb{F}p), where Q = (X_Q, Y_Q, Z_Q) and P = (x_P, y_P).
Ensure: T=2Q and l_{Q,Q}(P)\in \mathbb{F}_{p^{12}}, where T=(X_T,Y_T,Z_T) and l=l_0+l_1w;
     l_i \in \mathbb{F}_{p^6}.
 1. tmp_0 \leftarrow X_Q^2;
2. tmp_1 \leftarrow Y_Q^2;
 3. tmp_2 \leftarrow tmp_1^2;
 4. tmp_3 \leftarrow (tmp_1 + X_Q)^2 - tmp_0 - tmp_2;
 5. \ tmp_3 \leftarrow 2tmp_3;
 6. \ tmp_4 \leftarrow 3tmp_0;
 7. tmp_6 \leftarrow X_Q + tmp_4;
 8. tmp_5 \leftarrow tmp_4^2;
9. X_T \leftarrow tmp_5 - 2tmp_3;

10. Z_T \leftarrow (Y_Q + Z_Q)^2 - tmp_1 - Z_Q^2;

11. Y_T \leftarrow (tmp_3 - X_T) \cdot tmp_4 - 8tmp_2;
12. tmp_3 \leftarrow -2(tmp_4 \cdot Z_Q^2);
13. tmp_3 \leftarrow tmp_3 \cdot x_P; {Algorithm 7}
14. tmp_6 \leftarrow tmp_6^2 - tmp_0 - tmp_5 - 4tmp1;
15. tmp_0 \leftarrow 2(Z_T \cdot Z_Q^2);
16. tmp_0 \leftarrow tmp_0 \cdot y_P; {Algorithm 7}
17. a_0, a_1 \in \mathbb{F}_{p^6};
18. a_0 \leftarrow tmp_0 + 0v + 0v^2;
19. a_1 \leftarrow tmp_3 + tmp_6v + 0v^2;
20. T \leftarrow (X_T, Y_T, Z_T);
21. l \leftarrow a_0 + a_1 w;
22. return l, T;
```

#### Algorithm 27 Point addition and line evaluation

```
Require: Q, R \in E(\mathbb{F}p^2) and P \in E(\mathbb{F}p), where Q = (X_Q, Y_Q, Z_Q), R = (X_R, Y_R, Z_R)
      and P = (x_P, y_P).
Ensure: T = Q + R and l_{R,Q}(P) \in \mathbb{F}_{p^{12}}, where T = (X_T, Y_T, Z_T) and l = l_0 + l_1 w;
     l_i \in \mathbb{F}_{p^6}.
1. t_0 \leftarrow X_Q \cdot Z_R^2;
2. t_1 \leftarrow (Y_Q + Z_R)^2 - Y_Q^2 - Z_R^2;
 3. t_1 \leftarrow t_1 \cdot Z_R^2;
 4. t_2 \leftarrow t_0 - X_R;
 5. t_3 \leftarrow t_2^2;
 6. t_4 \leftarrow 4t_3;
 7. t_5 \leftarrow t_4 \cdot t_2;
 8. t_6 \leftarrow t_1 - 2Y_R;
9. t_9 \leftarrow t_6 \cdot X_Q;
10. t_7 \leftarrow X_R \cdot t_4;
11. X_T \leftarrow t_6^2 - t_5 - 2t_7;
12. Z_T \leftarrow (Z_R + t_2)^2 - Z_R^2 - t_3;
13. t_{10} \leftarrow \dot{Y}_Q + Z_T;
14. t_8 \leftarrow (t_7 - X_T) \cdot t_6;
15. t_0 \leftarrow 2(Y_R \cdot t_5);
16. Y_T \leftarrow t_8 - t_0;
17. t_{10} \leftarrow t_{10}^2 - Y_Q^2 - Z_T^2;
18. t_9 \leftarrow 2t_9 - t_{10};
19. t_{10} \leftarrow 2(Z_T \cdot y_P); {Algorithm 7}
20. t_6 \leftarrow -t_6;
21. t_1 \leftarrow 2(t_6 \cdot x_P); {Algorithm 7}
22. l_0, l_1 \in \mathbb{F}_{p^6};
23. l_0 \leftarrow t_{10} + 0v + 0v^2;
24. l_1 \leftarrow t_1 + t_9 v + 0 v^2;
25. T \leftarrow (X_T, Y_T, Z_T);
26. l \leftarrow l_0 + l_1 w;
27. return l, T;
```

Some multiplications between elements from different field extensions are required, we need to consider those operations as particular cases instead of performing unnecessary products by zero.

#### A.6 Final Exponentiation

To perform the final exponentiation, we need to raise  $f \in \mathbb{F}_{p^{12}}$  to the *p*-power, as described in Section 3.2. Algorithms 28-30, compute  $f^p$ ,  $f^{p^2}$  and  $f^{p^3}$ , respectively, where f is a field element in  $\mathbb{F}_{p^{12}} = \mathbb{F}_{p^2}[W]/(W^6 - \xi)$ .

#### **Algorithm 28** Frobenius raised to *p* of *f ∈* F*p*<sup>12</sup> = F*p*<sup>6</sup> [*w*]*/*(*w* <sup>2</sup> *− γ*).

```
Require: f ∈ Fp12 , where f = g + hw; fi ∈ Fp6 . And g = g0 + g1v + g2v
                                                                                   2
                                                                                    ; h =
    h0 + h1v + h2v
                   2
Ensure: f
           p ∈ Fp12 .
 1. t1 ← g¯0; {First we need to rearrange the elements and conjugate them}
 2. t2 ← h¯0;
 3. t3 ← g¯1;
 4. t4 ← h¯1;
 5. t5 ← g¯2;
 6. t6 ← h¯2;
 7. for i = 1 to 5 do
 8. γ1,i = ξ
              i·(p−1)/6
                       ;
 9. end for
10. t2 ← t2 · γ1,1;
11. t3 ← t3 · γ1,2;
12. t4 ← t4 · γ1,3;
13. t5 ← t5 · γ1,4;
14. t6 ← t6 · γ1,5;
15. c0 ← t1 + t3v + t5v
                        2
                         ;
16. c1 ← t2 + t4v + t6v
                        2
                         ;
17. return C ← c0 + c1w;
```

#### **Algorithm 29** Frobenius raised to *p* <sup>2</sup> of *f ∈* F*p*<sup>12</sup> = F*p*<sup>6</sup> [*w*]*/*(*w* <sup>2</sup> *− γ*).

```
Require: f ∈ Fp12 , where f = g + hw; fi ∈ Fp6 . And g = g0 + g1v + g2v
                                                                                   2
                                                                                    ; h =
    h0 + h1v + h2v
                   2
Ensure: f
           p
            2
              ∈ Fp12 .
 1. for i = 1 to 5 do
 2. γ2,i = γ1,i · γ
                    p
                    i
                     ;
 3. end for
 4. t1 ← g0;
 5. t2 ← h0 · γ2,1;
 6. t3 ← g1 · γ2,2;
 7. t4 ← h1 · γ2,3;
 8. t5 ← g2 · γ2,4;
 9. t6 ← h2 · γ2,5;
10. c0 ← t1 + t3v + t5v
                        2
                         ;
11. c1 ← t2 + t4v + t6v
                        2
12. return C ← c0 + c1w;
```

#### **Algorithm 30** Frobenius raised to *p* <sup>3</sup> of *f ∈* F*p*<sup>12</sup> = F*p*<sup>6</sup> [*w*]*/*(*w* <sup>2</sup> *− γ*). **Require:** *f ∈* F*p*<sup>12</sup> , where *f* = *g* + *hw*; *f<sup>i</sup> ∈* F*p*<sup>6</sup> . And *g* = *g*<sup>0</sup> + *g*1*v* + *g*2*v* 2 ; *h* = *h*<sup>0</sup> + *h*1*v* + *h*2*v* 2 **Ensure:** *f p* 3 *∈* F*p*<sup>12</sup> . 1. *t*<sup>1</sup> *← g*¯0; *{*First we need to rearrange the elements and conjugate them*}* 2. *t*<sup>2</sup> *← h*¯0; 3. *t*<sup>3</sup> *← g*¯1; 4. *t*<sup>4</sup> *← h*¯1; 5. *t*<sup>5</sup> *← g*¯2; 6. *t*<sup>6</sup> *← h*¯2; 7. **for** *i* = 1 to 5 **do** 8. *γ*3*,i* = *γ*1*,i · γ*2*,i*; 9. **end for** 10. *t*<sup>2</sup> *← t*<sup>2</sup> *· γ*3*,*1; 11. *t*<sup>3</sup> *← t*<sup>3</sup> *· γ*3*,*2; 12. *t*<sup>4</sup> *← t*<sup>4</sup> *· γ*3*,*3; 13. *t*<sup>5</sup> *← t*<sup>5</sup> *· γ*3*,*4; 14. *t*<sup>6</sup> *← t*<sup>6</sup> *· γ*3*,*5; 15. *c*<sup>0</sup> *← t*<sup>1</sup> + *t*3*v* + *t*5*v* 2 ; 16. *c*<sup>1</sup> *← t*<sup>2</sup> + *t*4*v* + *t*6*v* 2 ;

17. **return** *C ← c*<sup>0</sup> + *c*1*w*;

### **Algorithm 31** Final Exponentiation

```
Require: f ∈ Fp12 = Fp6 [w]/(w
                                   2 − γ), where f = g + hw.
Ensure: f
            (p
              12−1)/r ∈ Fp12 .
 1. f1 ← ¯f;
 2. f2 ← f
            −1
              ;
 3. f ← f1 · f2;
 4. f ← f
           p
            2
              · f; {Algorithm 29}
 5. ft1 ← f
            t
             ; {Algorithm 25}
 6. ft2 ← f
            t
              ;
 7. ft3 ← f
            t
              ;
 8. fp1 ← f
            p
              ; {Algorithm 28}
 9. fp2 ← f
            p
              2
               ; {Algorithm 29}
10. fp3 ← f
             p
              3
               ; {Algorithm 30}
11. y0 ← fp1
              · fp2
                   · fp3
                        ;
12. y1 ← f1;
13. y2 ← (ft2
              )
               p
                 ; {Algorithm 29}
14. y3 ← (ft1
              )
               p
                ; {Algorithm 28}
15. y3 ← y¯3;
16. y4 ← (ft2
              )
               p
                 · ft1
                     ; {Algorithm 28}
17. y4 ← y¯4;
18. y5 ← ¯ft2
             ;
19. y6 ← (ft3
              )
               p
                 · ft3
                     ; {Algorithm 28}
20. y6 ← y¯6;
21. t0 ← y
           2
           6 · y4 · y5; {Algorithm 24 for squaring}
22. t1 ← y3 · y5 · t0;
23. t0 ← t0 · y2;
24. t1 ← (t
            2
            1 · t0)
                  2
                   ; {Algorithm 24 for squaring}
25. t0 ← t1 · y1;
26. t1 ← t1 · y0;
27. t0 ← t
           2
           0; {Algorithm 24}
28. f ← t1 · t0;
29. return f;
```