---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2008/390';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Elliptic Curve Cryptography: The Serpentine Course of a Paradigm Shift';
const AUTHORS_HTML = 'Ann Hibner Koblitz, Neal Koblitz, Alfred Menezes';

const CONTENT = `    <p class="text-gray-300">Date: August 28, 2008; last revised on October 2, 2008. 1991 Mathematics Subject Classification. 94A60, 11T71, 14G50, 68P25, 01A80. Key words and phrases. Cryptography, Public Key, Elliptic Curve, Social Construction of Science, Social Construction of Technology.</p>

    <p class="text-gray-300">ANN HIBNER KOBLITZ, NEAL KOBLITZ, AND ALFRED MENEZES</p>

    <p class="text-gray-300">ABSTRACT. Over a period of sixteen years elliptic curve cryptography went from being an approach that many people mistrusted or misunderstood to being a public key technology that enjoys almost unquestioned acceptance. We describe the sometimes surprising twists and turns in this paradigm shift, and compare this story with the commonly accepted Ideal Model of how research and development function in cryptography. We also discuss to what extent the ideas in the literature on "social construction of technology" can contribute to a better understanding of this history.</p>

    <p class="text-gray-300">Research into number theoretic questions concerning elliptic curves was originally pursued mainly for aesthetic reasons. But in recent decades such questions have become important in several applied areas, including coding theory, pseudorandom number generation, and especially cryptography.</p>

    <p class="text-gray-300">The first use of elliptic curves in cryptography was H. W. Lenstra's elliptic curve factoring algorithm [69]. Inspired by this unexpected application of elliptic curves, in 1985 N. Koblitz [52] and V. Miller [80] independently proposed using the group of points on an elliptic curve defined over a finite field in discrete log cryptosystems. The primary advantage that elliptic curve systems have over systems based on either integer factorization or the discrete log problem in the multiplicative group of a finite field is the absence of a subexponential-time algorithm (such as those of index calculus type) that could find discrete logs in these groups, provided that the curve and the underlying field are suitably chosen. Consequently, one can use an elliptic curve group that is smaller in size while maintaining the same level of security. In many situations the result is smaller key sizes, bandwidth savings, and faster implementations, features which are especially attractive for security applications in devices where computational power and integrated circuit space are limited, such as smart cards and cell phones.</p>

    <p class="text-gray-300">In 2005 the U.S. National Security Agency posted a paper [86] titled "The Case for Elliptic Curve Cryptography," in which they recommended that industry "take advantage of the past 30 years of public key research and analysis and move from first generation public key algorithms and on to elliptic curves." The NSA commented:</p>

    <p class="text-gray-300">The best assured group of new public key techniques is built on the arithmetic of elliptic curves. This paper will outline a case</p>

    <p class="text-gray-300">for moving to elliptic curves as a foundation for future Internet security. This case will be based on both the relative security offered by elliptic curves… and the relative performance of these algorithms. While at current security levels elliptic curves do not offer significant benefits over existing public key algorithms, as one scales security upwards over time to meet the evolving threat posed by eavesdroppers and hackers with access to greater computing resources, elliptic curves begin to offer dramatic savings over the old, first generation techniques.</p>

    <p class="text-gray-300">In the present paper we give an overview of the history of elliptic curve cryptography (ECC), focusing on the controversies over the security of ECC. This story can be seen as a case study in the history of technology. We start by describing what we call the Ideal Model of research and development in cryptography. The subsequent sections examine to what extent our observations and experiences conform to or contradict that Ideal Model. We then summarize some of the viewpoints found in a subfield of history and sociology of science called Social Construction of Technology, and ask whether those ideas can contribute to a better understanding of the history of ECC.</p>

    <h2 id="sec-3" class="text-2xl font-bold">2. The Ideal Model</h2>

    <p class="text-gray-300">Although not everyone working in cryptography necessarily believes in the validity of what we shall call the Ideal Model of research and development, the general outline given below is a fair representation of the image that cryptographers hope to project to the outside world — especially to laypeople, business customers, and scientists and engineers in related fields.</p>

    <h3 id="sec-4" class="text-xl font-semibold mt-8">1. Security always at center stage</h3>

    <p class="text-gray-300">The most fundamental feature of any type of cryptographic technology is its security — its resistance to being compromised by an adversary. Although functionality and efficiency are also important — and, for example, users may choose to make do with smaller parameters for increased efficiency if they need only short-term security — the desire to speed up encryption and signature and improve user interface is never a valid reason to lose sight of the basic question of security. In addition, there is a broad realization that complacency is the enemy of security. Hence, the security of the protocols and the underlying mathematical problems is constantly reevaluated in light of new research.</p>

    <h3 id="sec-5" class="text-xl font-semibold mt-8">2. From an art to a science</h3>

    <p class="text-gray-300">Cryptographic research and development have largely left behind the days when they depended on the intuition of artisans. Rather than a craft or art, cryptography has truly become a science. The techniques of “provable security” allow marketers of cryptographic protocols to give ironclad guarantees that broad classes of attacks — and these include even attacks that no one has yet imagined — are impossible provided that certain widely believed mathematical assumptions are correct. In addition, the increasing use of automatic software-checkers and theorem-provers gives further reason to expect that human mistakes</p>

    <p class="text-gray-300">and failings will play an ever-diminishing role in the evaluation and selection of cryptographic products.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Tradition of vigorous debate. The cryptographic community expects and welcomes vigorous debate on the merits of competing systems and methods of analysis. Because of the large interests at stake, these discussions might be heated at times, but the participants understand the need for sharp debate, and so do not take disagreements personally.</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Special institutions to ensure careful vetting. Although, as in other branches of science, cryptographers have the usual peer review system for academic journals, the most important guarantors of quality control are the program committees that choose papers for presentation at major conferences and the accredited industrial standards bodies that evaluate specific systems and recommend their deployment with suggested parameters.</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Survival of the fittest. As a result of the checks and balances that are part and parcel of cryptographic research and development, the technology that emerges as the “winner” has passed a stringent series of tests leading to “survival of the fittest.” In that sense it can be regarded as intrinsically the best of the alternatives available at the time.</li>

    </ol>

    <h2 id="sec-6" class="text-2xl font-bold">3. The mid-1980s: Discrete Logs and Factoring</h2>

    <p class="text-gray-300">At the heart of any type of public key cryptography is a “one-way” mathematical process or function for which the inverse cannot feasibly be computed. In the famous RSA system the process is to take two very large randomly-generated prime numbers and multiply them together. In a classical Diffie-Hellman system the operation is exponentiation in a finite field. In the former case the inverse process is integer factorization. In the latter type of system the inverse is called the discrete logarithm in the finite field.</p>

    <p class="text-gray-300">More precisely, let <span class="math">G</span> be a subgroup of prime order <span class="math">n</span> in the multiplicative group of the field of <span class="math">q</span> elements <span class="math">\\mathbb{F}_{q}</span>, where <span class="math">q=p^{f}</span> is a prime power. (For simplicity we shall generally assume that <span class="math">G</span> has prime order; this is usually the case in cryptographic applications.) Given a generator <span class="math">g\\in G</span> (i.e., a non-identity element), the discrete log problem in <span class="math">G</span> is the problem, given <span class="math">y\\in G</span>, of finding an integer <span class="math">x\\pmod{n}</span> such that <span class="math">y=g^{x}</span>.</p>

    <p class="text-gray-300">The simplest example of a Diffie-Hellman system is a basic key agreement scheme that works as follows. Suppose that Alice and Bob wish to agree on a shared key, which will be a random element of <span class="math">G</span>. Alice chooses a secret integer <span class="math">a\\pmod{n}</span> and sends Bob the group element <span class="math">A=g^{a}</span>; Bob chooses a secret integer <span class="math">b\\pmod{n}</span> and sends Alice the group element <span class="math">B=g^{b}</span>. The shared key is then <span class="math">g^{ab}</span>, which Alice can compute as <span class="math">B^{a}</span> and Bob can compute as <span class="math">A^{b}</span>. An eavesdropper who monitors the exchange of information has the task of computing <span class="math">g^{ab}</span> knowing <span class="math">g</span>, <span class="math">g^{a}</span>, and <span class="math">g^{b}</span>. This problem is known as the Diffie-Hellman problem in the group <span class="math">G</span>. The Diffie-Hellman problem can be immediately solved if one knows how to find discrete logs in <span class="math">G</span>, and it is thought to be essentially equivalent to the discrete log problem.</p>

    <h3 id="sec-7" class="text-xl font-semibold mt-8">3.1. Index calculus</h3>

    <p class="text-gray-300">The most efficient algorithms to solve both the problem of factoring the product of two large primes and the problem of finding the discrete log in a finite field were — and still are — of “index calculus” type. We’ll illustrate how index calculus works using a simplified version for the discrete log in a prime field. For ease of exposition we’ll temporarily suppose that <span class="math">G</span> is the entire group <span class="math">\\mathbb{F}_{p}^{<em>}</span> rather than a prime order subgroup, so that <span class="math">n=p-1</span>. Let <span class="math">g</span> be a generator of <span class="math">\\mathbb{F}_{p}^{</em>}</span>. Given <span class="math">y\\in\\mathbb{F}_{p}^{*}</span>, we want to find <span class="math">x</span> such that <span class="math">y\\equiv g^{x}\\pmod{p}</span>.</p>

    <p class="text-gray-300">To do that we first choose a “factor base” consisting of the first <span class="math">s</span> primes, where <span class="math">s</span> is chosen in a certain optimal way so as to minimize running time. The first part of the algorithm, which does not depend on <span class="math">y</span>, consists in finding the discrete logs of the factor base. We choose some random value <span class="math">u_{i}</span> less than <span class="math">n</span> and compute the least positive residue of <span class="math">g^{u_{i}}\\pmod{p}</span>. If that residue has a prime factor greater than the <span class="math">s</span>-th prime, we make another choice of <span class="math">u_{i}</span>. Finally we get a “smooth” residue that has no large prime factor, at which point we can write</p>

    <p class="text-gray-300"><span class="math">g^{u_{i}}\\equiv\\prod_{j=1}^{s}p_{j}^{\\alpha_{ij}}\\quad\\pmod{p},</span></p>

    <p class="text-gray-300">and hence</p>

    <p class="text-gray-300"><span class="math">u_{i}\\equiv\\sum_{j=1}^{s}\\alpha_{ij}x_{j}\\quad\\pmod{n},</span></p>

    <p class="text-gray-300">where <span class="math">x_{j}</span> is the discrete log of <span class="math">p_{j}</span>. When we get more than <span class="math">s</span> such congruences we can find the unknowns <span class="math">x_{j}</span> by linear algebra over <span class="math">\\mathbb{Z}/n\\mathbb{Z}</span>. Once we have the discrete logs of the <span class="math">p_{j}</span>, the rest of the algorithm proceeds quickly. We choose random values of <span class="math">u</span> until we get one for which the least positive residue of <span class="math">g^{u}y</span> has no prime factor greater than <span class="math">p_{s}</span>, so that we can write</p>

    <p class="text-gray-300"><span class="math">g^{u}y\\equiv\\prod_{j=1}^{s}p_{j}^{\\beta_{j}}\\quad\\pmod{p}.</span></p>

    <p class="text-gray-300">We conclude that the desired discrete log is</p>

    <p class="text-gray-300"><span class="math">x\\equiv\\left(\\sum_{j=1}^{s}\\beta_{j}x_{j}\\right)-u\\quad\\pmod{n}.</span></p>

    <p class="text-gray-300">In the early 1980s the best index calculus algorithms for either factorization or discrete log in a finite field had asymptotic running time of the form <span class="math">\\exp(k^{1/2+\\epsilon})</span>, where <span class="math">k</span> is, respectively, the bitlength of the number to be factored or the bitlength of the size of the finite field. An important exception — which turned out to be a harbinger of things to come — was Don Coppersmith’s algorithm <em>[18]</em> for finding discrete logs in the finite fields <span class="math">\\mathbb{F}_{2^{k}}</span>. His algorithm had running time of the form <span class="math">\\exp(k^{1/3+\\epsilon})</span>.</p>

    <p class="text-gray-300">After the demise of the early knapsack cryptosystems (which were proposed in the late 1970s and broken within a few years), most cryptographic protocols were based on either factorization or discrete logs in a finite field. This was a little disconcerting, because it appeared that, despite the superficial dissimilarity between the two problems, the most efficient algorithms were very similar. In such circumstances one might speculate that a major advance in solving one of the two</p>

    <p class="text-gray-300">ELLiptic CURVE CRYPTOGRAPHY</p>

    <p class="text-gray-300">supposedly “hard” problems would soon be followed by a similar improvement in methods to solve the other one. (And in fact a few years later, when the number field sieve was developed for factoring, it was soon followed by a version that finds discrete logs in a prime field <em>[34]</em>.) In that sense the two problems are not really independent, and it might have seemed that cryptographers were putting all their security eggs in one basket.</p>

    <h3 id="sec-8" class="text-xl font-semibold mt-8">3.2. Elliptic Curve Cryptography (ECC)</h3>

    <p class="text-gray-300">In 1984 Hendrik Lenstra circulated a preprint describing a new factorization method. Like the index calculus algorithms available at the time, it also has running time <span class="math">\\exp(k^{1/2+\\epsilon})</span> to factor a <span class="math">k</span>-bit integer, but it has several features that mark a radical departure from the other algorithms with that running time. First, it is not an index calculus algorithm, and it seems that no algorithm similar to Lenstra’s can be developed for the discrete log problem in a finite field. Second, although it is not more efficient than index calculus for factoring an RSA-type integer — that is, a product of two primes of roughly the same size — it has the advantage that its running time depends on the size of the smallest prime factor, not on the size of the number itself. This was later put to use in factoring other types of numbers that arise in cryptography.</p>

    <p class="text-gray-300">But the most striking feature of Lenstra’s factoring algorithm <em>[69]</em> was that it used elliptic curves. This was the first application of elliptic curves in cryptography, and it set in motion a process of finding cryptographic uses for many types of “pure” mathematics — especially arithmetic algebraic geometry — that had never before been studied for this purpose.</p>

    <p class="text-gray-300">In 1985 V. Miller <em>[80]</em> and N. Koblitz <em>[52]</em> proposed a completely different cryptographic use of elliptic curves: constructing Diffie-Hellman type protocols using the group of points of an elliptic curve defined over a finite field rather than the multiplicative group of a finite field. Let <span class="math">E</span> be given by a Weierstrass equation</p>

    <p class="text-gray-300"><span class="math">y^{2}+a_{1}xy+a_{3}y=x^{3}+a_{2}x^{2}+a_{4}x+a_{6},</span></p>

    <p class="text-gray-300">with <span class="math">a_{i}\\in\\mathbb{F}_{q}</span>. The groups used in ECC are the prime order subgroups <span class="math">G</span> of the <span class="math">\\mathbb{F}_{q}</span>-points of <span class="math">E</span>. In the setting of the elliptic curve group law, which is customarily written in additive notation, the discrete log problem asks: given <span class="math">P,Q\\in G</span>, find <span class="math">x</span> (mod <span class="math">n</span>) such that <span class="math">Q=xP</span>.</p>

    <p class="text-gray-300">The most important reason for considering ECC was that it seemed unlikely that index calculus could be adapted for use in an elliptic curve group. The reason is that in order to apply the idea of index calculus, one needs a set of “small” elements (the “factor base”) such that a reasonable proportion of the remaining elements can be efficiently written in terms of the factor base. In <em>[80]</em> Miller made an argument using the Néron-Tate height function (see also <em>[98]</em>, which contains a much more detailed discussion) that if one tries to use the most natural notion of “smallness” one will find that there are very few points of bounded size, not nearly enough to form a factor base for index calculus.</p>

    <p class="text-gray-300">In the early years of ECC a popular choice of curves for expository purposes was the equation <span class="math">y^{2}=x^{3}-x</span> defined over a prime field <span class="math">\\mathbb{F}_{p}</span>. If <span class="math">p\\equiv 3\\pmod{4}</span> — this is known as the supersingular case — it’s an easy exercise to show that the group order is <span class="math">p+1</span>. One can then quickly find a <span class="math">p</span> such that this group has a very large prime-order subgroup. The procedure is similar to the following method for finding a prime field whose multiplicative group has a prime-order subgroup of smallest possible index <span class="math">2</span>. Namely, let <span class="math">n</span> be a Sophie Germain prime, and set <span class="math">p=2n+1</span>.</p>

    <p class="text-gray-300">ANN HIBNER KOBLITZ, NEAL KOBLITZ, AND ALFRED MENEZES</p>

    <p class="text-gray-300">Then <span class="math">\\mathbb{F}_{p}^{*}</span> has a subgroup of prime order <span class="math">n=(p-1)/2</span>. In the elliptic curve case choose a prime <span class="math">n</span> for which <span class="math">p=4n-1</span> is prime; then the group of <span class="math">\\mathbb{F}_{p}</span>-points on <span class="math">y^{2}=x^{3}-x</span> is the product of the group of 4 points of order 2 and a subgroup of prime order <span class="math">n=(p+1)/4</span>.</p>

    <p class="text-gray-300">In characteristics 2 and 3 the supersingular curves had another convenient feature: point doubling on a supersingular curve in characteristic 2 and point tripling on a supersingular curve in characteristic 3 take negligible time.</p>

    <p class="text-gray-300">Convenient as these parameter choices were, the early writers on ECC later regretted having used them, because in 1991 we learned that the discrete log problem on a supersingular curve is much easier to solve than on most curves (see §4). Among all elliptic curves defined over <span class="math">\\mathbb{F}_{p}</span> the supersingular ones are a tiny proportion — a randomly selected curve has probability only <span class="math">O(1/\\sqrt{p})</span> of being supersingular — but the frequent use of supersingular curves for ease of exposition gave some people an exaggerated impression of their importance.</p>

    <p class="text-gray-300">Avoiding supersingular curves does not, however, mean avoiding curves that are very easy to compute with. For example, one can use the very same curve <span class="math">y^{2}=x^{3}-x</span> but choose <span class="math">p\\equiv 1\\pmod{4}</span>. In that case a formula for the group order goes back to Gauss. If <span class="math">p</span> is expressed as a sum of two squares, <span class="math">p=a^{2}+b^{2}</span> with <span class="math">a\\equiv 1\\pmod{4}</span>, then <span class="math">\\#E(\\mathbb{F}_{p})=p+1-2a</span>. (A similar example is given by <span class="math">y^{2}=x^{3}+1</span> with <span class="math">p\\equiv 1\\pmod{3}</span>.)</p>

    <p class="text-gray-300">The two curves in the last paragraph are obtained by reduction mod <span class="math">p</span> of an elliptic curve defined over <span class="math">\\mathbb{Q}</span> that has complex multiplication by, respectively, the fourth roots and the third roots of unity. Namely, on the curve <span class="math">y^{2}=x^{3}-x</span> we have the automorphism <span class="math">(x,y)\\mapsto(-x,iy)</span>, and on the curve <span class="math">y^{2}=x^{3}+1</span> we have <span class="math">(x,y)\\mapsto(\\zeta x,y)</span>, where <span class="math">\\zeta=\\exp(2\\pi i/3)</span>.</p>

    <h3 id="sec-9" class="text-xl font-semibold mt-8">3.3. ECC protocols</h3>

    <p class="text-gray-300">By a protocol we mean a specific sequence of steps that are carried out in a particular application. Most of the protocols using elliptic curves were obtained by simply repeating the ones that had been developed for finite fields with the obvious modification in notation. Until the advent of pairing-based cryptography (see §9), there were no important protocols that exploited any of the rich structure of elliptic curves.</p>

    <p class="text-gray-300">However, it was a little tricky to find a good elliptic curve analogue of the finite field Digital Signature Algorithm that NSA developed in 1991 (see §7). We now describe this construction. In the elliptic curve digital signature algorithm (ECDSA) we suppose that Alice wants to sign a message that she has sent to Bob, and both Alice and Bob are using the same elliptic curve defined over <span class="math">\\mathbb{F}_{q}</span> containing a subgroup <span class="math">G</span> of prime order <span class="math">n</span> with generator <span class="math">P</span>. For simplicity we shall suppose that <span class="math">q</span> is a prime, although the construction can easily be adapted to a prime power <span class="math">q</span> as well.</p>

    <p class="text-gray-300">As usual, we suppose that we have a “hash function” that assigns a value <span class="math">H</span> to a message; <span class="math">H</span> plays the role of the message’s “fingerprint” in the sense that we assume that it is computationally infeasible to find two different messages with the same hash value.</p>

    <h4 id="sec-10" class="text-lg font-semibold mt-6">ECDSA key generation</h4>

    <p class="text-gray-300">Each user Alice constructs her keys by selecting a random integer <span class="math">x</span> in the interval <span class="math">[1,n-1]</span> and computing <span class="math">Q=xP</span>. Alice’s public key is <span class="math">Q</span>; her private key is <span class="math">x</span>.</p>

    <p class="text-gray-300">ELLiptic CURVE CRYPTOGRAPHY</p>

    <p class="text-gray-300">ECDSA signature generation</p>

    <p class="text-gray-300">To sign a message having hash value <span class="math">H</span>, <span class="math">0&amp;lt;H&amp;lt;n</span>, Alice does the following:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>She selects a random integer <span class="math">k</span> in the interval <span class="math">[1,n-1]</span>.</li>

      <li>She computes <span class="math">kP=(x_{1},y_{1})</span> and sets <span class="math">r</span> equal to the least nonnegative residue of <span class="math">x_{1}\\bmod n</span> (where <span class="math">x_{1}</span> is regarded as an integer between <span class="math">0</span> and <span class="math">q-1</span>). (Note: If <span class="math">r=0</span>, then she must go back to step 1 and select another <span class="math">k</span>.)</li>

      <li>She computes <span class="math">k^{-1}\\bmod n</span> and sets <span class="math">s</span> equal to the least nonnegative residue of <span class="math">k^{-1}(H+xr)\\bmod n</span>. (Note: If <span class="math">s=0</span>, then she must go back to step 1.)</li>

    </ol>

    <p class="text-gray-300">The signature for the message is the pair of integers <span class="math">(r,s)</span>.</p>

    <p class="text-gray-300">ECDSA signature verification</p>

    <p class="text-gray-300">To verify Alice’s signature <span class="math">(r,s)</span> on a message, Bob does the following:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Obtain an authenticated copy of Alice’s public key <span class="math">Q</span>.</li>

      <li>Verify that <span class="math">r</span> and <span class="math">s</span> are integers in the interval <span class="math">[1,n-1]</span>, and compute the hash value <span class="math">H</span> of the message.</li>

      <li>Compute <span class="math">u_{1}=s^{-1}H\\bmod n</span> and <span class="math">u_{2}=s^{-1}r\\bmod n</span>.</li>

      <li>Compute <span class="math">u_{1}P+u_{2}Q=(x_{0},y_{0})</span> and, regarding <span class="math">x_{0}</span> as an integer between <span class="math">0</span> and <span class="math">q-1</span>, set <span class="math">v</span> equal to the least nonnegative residue of <span class="math">x_{0}\\bmod n</span>.</li>

      <li>Accept the signature if and only if <span class="math">v=r</span>.</li>

    </ol>

    <p class="text-gray-300">Notice that if Alice generated her signature correctly, then <span class="math">u_{1}P+u_{2}Q=(u_{1}+xu_{2})P=kP</span> because <span class="math">k\\equiv s^{-1}(H+xr)\\pmod{n}</span>, and so <span class="math">v=r</span>.</p>

    <h3 id="sec-11" class="text-xl font-semibold mt-8">3.4. Early algorithms for elliptic curve discrete logs</h3>

    <p class="text-gray-300">At first the only algorithms known to solve the elliptic curve discrete log problems were generic ones, that is, they have nothing to do with the specific structure of the elliptic curve group. The first such algorithm, designed in the setting of finite field discrete logs by Pohlig and Hellman <em>[87]</em>, uses the Chinese remainder theorem to reduce the problem to the discrete log problem in the prime-order subgroups. This is why groups of prime order are usually chosen for Diffie-Hellman type cryptosystems.</p>

    <p class="text-gray-300">In a group <span class="math">G</span> of prime order <span class="math">n</span> the two best generic algorithms — Shanks’ “baby-step/giant-step” and Pollard’s rho <em>[88]</em> — each requires time roughly <span class="math">O(\\sqrt{n})</span>; for this reason they’re known as squareroot attacks on the discrete log problem. Although Shanks’ method has the advantage of being deterministic, it has a very large storage requirement — also of order <span class="math">\\sqrt{n}</span> — and so in practice some randomized version of the Pollard-rho method is preferred.</p>

    <p class="text-gray-300">The general idea of Pollard is to take a pseudo-random walk in <span class="math">G</span> (i.e., it’s deterministic, but heuristically seems to have a high degree of randomness) using certain combinations of the basepoint <span class="math">P</span> and the point <span class="math">Q</span> with the unknown discrete log. As soon as the walk hits the same place twice, one can immediately solve for the discrete log. The <span class="math">\\sqrt{n}</span> estimate comes from the “birthday paradox.”</p>

    <p class="text-gray-300">As we shall soon discuss, subsequently faster-than-squareroot algorithms were found for various classes of elliptic curves. However, it still appears — after a quarter century of ECC — that the types of curves used in most cryptographic applications cannot be attacked by anything faster than the generic algorithms.</p>

    <p class="text-gray-300">The last statement has to be qualified somewhat. One can group together a point and its negative so as to apply Pollard-rho to a set of <span class="math">(n-1)/2</span> pairs of points; this gives a speed-up of generic Pollard-rho by a factor of <span class="math">\\sqrt{2}</span>. Moreover, if the curve <span class="math">E</span> is defined over a much smaller subfield — say, over <span class="math">\\mathbb{F}_{q_{0}}</span>, where <span class="math">q=q_{0}^{\\ell}</span> — then by</p>

    <p class="text-gray-300">grouping together Frobenius conjugacy classes of points (obtained by applying the map <span class="math">(x,y)\\mapsto(x^{q_{0}},y^{q_{0}})</span>) one can speed up the generic algorithm by an additional factor of <span class="math">\\sqrt{\\ell}</span> (see <em>[29, 107]</em>). This is a relatively small effect, but it does have to be taken into account if one wants the efficiency advantage that comes from choosing an elliptic curve defined over a small field.</p>

    <h2 id="sec-12" class="text-2xl font-bold">4. The Weil Pairing Attack</h2>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">If <span class="math">E</span> is an elliptic curve defined over <span class="math">\\mathbb{F}_{q}</span>, <span class="math">q=p^{f}</span>, let <span class="math">E[n]\\subset E(\\overline{\\mathbb{F}}_{q})</span>, where <span class="math">\\overline{\\mathbb{F}}_{q}</span> is the algebraic closure of <span class="math">\\mathbb{F}_{q}</span>, denote the set of all <span class="math">\\overline{\\mathbb{F}}_{q}</span>-points of order <span class="math">n</span>. If <span class="math">n</span> is prime to <span class="math">p</span>, then <span class="math">E[n]\\approx(\\mathbb{Z}/n\\mathbb{Z})\\times(\\mathbb{Z}/n\\mathbb{Z})</span>. Let <span class="math">\\mathbb{F}_{q^{k}}</span> be the smallest field that contains the coordinates of the points in <span class="math">E[n]</span>. In our applications <span class="math">n</span> will be a prime dividing <span class="math">\\#E(\\mathbb{F}_{q})</span> but not dividing <span class="math">q-1</span>. In that case the integer <span class="math">k</span>, which is called the embedding degree, is also equal to the smallest positive integer such that $n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(q^{k}-1)<span class="math">. Let </span>\\mu_{n}\\subset\\mathbb{F}_{q^{k}}^{*}<span class="math"> denote the subgroup of </span>n$-th roots of unity. Then the Weil pairing is a non-degenerate skew-symmetric bilinear map</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">E[n]\\times E[n]\\longrightarrow\\mu_{n}.</span></p>

    <p class="text-gray-300">This pairing can be efficiently computed if <span class="math">k</span> is not too big (see <em>[81, 82]</em>).</p>

    <p class="text-gray-300">The first use of the Weil pairing in cryptography was to solve the discrete log problem in subexponential time on an elliptic curve of low embedding degree. In <em>[75]</em> it was shown how the Weil pairing could be used to transport the elliptic curve discrete log problem to the discrete log problem in the group <span class="math">\\mathbb{F}_{q^{k}}^{<em>}</span>. In the latter group index calculus methods are effective provided that <span class="math">k</span> is very small. (A similar attack using the Tate pairing was given by Frey and Rück </em>[26]*, who introduced that pairing into cryptographic use.)</p>

    <p class="text-gray-300">However, curves for which <span class="math">k</span> is small are very rare. The most important class of such curves are the supersingular curves, i.e., those for which <span class="math">\\#E(\\mathbb{F}_{q})\\equiv 1\\pmod{p}</span>. For those curves <span class="math">k\\leq 6</span>; in contrast, it was shown in <em>[4]</em> that very few ordinary (meaning non-supersingular) curves have small embedding degree. A randomly chosen curve over <span class="math">\\mathbb{F}_{p}</span> has probability <span class="math">O(p^{-1/2})</span> of being supersingular, and a randomly chosen pair consisting of <span class="math">p</span> and an ordinary curve over <span class="math">\\mathbb{F}_{p}</span> has probability only <span class="math">O(p^{-1})</span> of having bounded embedding degree.</p>

    <p class="text-gray-300">Nevertheless, the Weil pairing attack, which was the first subexponential algorithm for the discrete log problem on a prime order subgroup of points on any elliptic curve, had a major impact. As mentioned before, it had an especially chastening effect on those of us who for expository convenience had used supersingular curves with embedding degree <span class="math">k=2</span> in articles and books.</p>

    <p class="text-gray-300">For almost a decade it was widely assumed that supersingular curves should be completely avoided in cryptography, and that even an ordinary curve had to be checked to see that its embedding degree was fairly large. In practice <span class="math">k\\geq 20</span> was usually considered to be sufficient to guarantee intractability of the discrete log problem in <span class="math">\\mathbb{F}_{q^{k}}^{*}</span>. However, some cryptographers have gone to the extreme of insisting that <span class="math">k\\geq(q-1)/100</span> (see §11).</p>

    <p class="text-gray-300">In reality, as long as <span class="math">k\\geq 6</span>, with the state-of-the-art techniques available at the time the discrete log problem in the field <span class="math">\\mathbb{F}_{q^{k}}</span> into which <span class="math">E(\\mathbb{F}_{q})</span> embeds was at least as hard to solve using index calculus as the discrete log problem was to solve directly on <span class="math">E(\\mathbb{F}_{q})</span> using Pollard-rho. And on rare occasions curves with <span class="math">k=6</span> were considered in cryptography papers (for example, <em>[55]</em>). But such curves were</p>

    <p class="text-gray-300">almost universally shunned. Certainly no curves with low embedding degree were permitted in the ECC standards.</p>

    <h2 id="sec-13" class="text-2xl font-bold">5. Hyperelliptic Curve Cryptography</h2>

    <p class="text-gray-300">Just as the group of points on an elliptic curve can be used to construct cryptographic protocols, so can the jacobian group of a genus-<span class="math">g</span> hyperelliptic curve</p>

    <p class="text-gray-300"><span class="math">y^{2}+h(x)y=x^{2g+1}+a_{1}x^{2g}+\\cdots+a_{2g+1}</span></p>

    <p class="text-gray-300">(with <span class="math">\\deg h\\leq g</span>) defined over <span class="math">\\mathbb{F}_{q}</span>. This is a natural generalization of the elliptic curve group, which is the case <span class="math">g=1</span>, and it was first proposed for use in cryptography in 1989 <em>[53]</em>. The group order for a hyperelliptic jacobian is approximately <span class="math">q^{g}</span>, that is, the same size as one gets in elliptic curve cryptography working over the extension field <span class="math">\\mathbb{F}_{q^{g}}</span>. In other words, if <span class="math">g</span> is large, one can work over a small field. On the other hand, the group operation is much more cumbersome than in the elliptic curve case: it uses a process of reduction of divisors that is closely analogous to Gauss’ method for composition of binary quadratic forms. But in any case it turns out that the discrete log problem is actually much easier on the jacobian of a high-genus curve than on a comparably sized group of points of an elliptic curve, as shown by Adleman, DeMarrais, and Huang <em>[1]</em> in 1994.</p>

    <h3 id="sec-14" class="text-xl font-semibold mt-8">5.1. Two meanings of “complexity”</h3>

    <p class="text-gray-300">The subexponential-time algorithm in <em>[1]</em> for the discrete log problem on the jacobian of a high-genus curve came as a big surprise to people who were starting to think about implementing hyperelliptic curve cryptography. When N. Koblitz proposed such systems in <em>[53]</em>, he thought that the difficulty of the discrete log problem for a genus <span class="math">g</span> curve would probably be at least as great as that of the corresponding problem on an elliptic curve. Isn’t it reasonable to assume that a problem would be at least as hard to solve on a more complicated object (a <span class="math">g</span>-dimensional jacobian) as on a relatively simple object?</p>

    <p class="text-gray-300">That way of thinking was a “rookie mistake” for a cryptographer to make, because he was confusing two meanings of “complexity”: conceptual complexity and computational complexity. True, standard treatments of algebraic curves often describe the genus <span class="math">g</span> as a measure of the complexity of the curve. And over a fixed field it’s reasonable to regard high-genus curves as more complicated to compute with than elliptic curves.</p>

    <p class="text-gray-300">However, in practical applications what’s fixed is not the field <span class="math">\\mathbb{F}_{q}</span>, but rather the bitlength of the group size <span class="math">q^{g}</span>. And the algorithm in <em>[1]</em>, while not subexponential in <span class="math">\\log q</span>, is subexponential in <span class="math">g\\log q</span> as <span class="math">g</span> grows. Thus, from a computational standpoint the discrete log problem on a suitably chosen elliptic curve over <span class="math">\\mathbb{F}_{2^{163}}</span> has much higher complexity than the discrete log problem on the jacobian of a genus-163 hyperelliptic curve over <span class="math">\\mathbb{F}_{2}</span>. Such an elliptic curve at present would provide adequate security for cryptographic applications, whereas the genus-163 curve definitely would not.</p>

    <p class="text-gray-300">What made high-genus hyperelliptic curves computationally simpler than low-genus curves was that there was a natural choice of “small” divisors that could be used in index calculus. Namely, elements of the jacobian can be uniquely represented by certain pairs of polynomials of the form <span class="math">(a(x),b(x))</span>, where <span class="math">\\deg a\\leq g</span> and <span class="math">\\deg b&lt;\\deg a</span>. The elements represented by <span class="math">(a(x),b(x))</span> with <span class="math">a(x)</span> of small degree can be used as the “factor base” (see §3.1) for index calculus, and this was what Adleman, DeMarrais, and Huang did.</p>

    <h3 id="sec-15" class="text-xl font-semibold mt-8">5.2. Further developments in genus <span class="math">\\geq 3</span></h3>

    <p class="text-gray-300">A few years after the subexponential index calculus algorithm was found for high-genus jacobians, Gaudry and others saw that for much smaller genus one could get similar algorithms that, while not subexponential, were significantly faster than Pollard-rho. The best and most recent of them <em>[21]</em> can find discrete logs in the jacobian group of a hyperelliptic curve over <span class="math">\\mathbb{F}_{q}</span> of fixed genus <span class="math">g</span> in <span class="math">O(q^{2-2/g})</span> operations. Since a squareroot attack takes <span class="math">O(q^{g/2})</span> operations, this is a big improvement for <span class="math">g\\geq 3</span>; for example, we get <span class="math">O(q^{4/3})</span> rather than <span class="math">O(q^{3/2})</span> for genus <span class="math">3</span>. Somewhat surprisingly, for non-hyperelliptic curves of fixed genus <span class="math">g</span>, Diem <em>[20]</em> found an algorithm with significantly faster running time than in the hyperelliptic case, namely <span class="math">O(q^{2-2/(g-1)})</span>. However, for genus <span class="math">2</span> thus far we have nothing faster than Pollard-rho in the general case.</p>

    <h2 id="sec-16" class="text-2xl font-bold">6. RSA vs. ECC</h2>

    <h3 id="sec-17" class="text-xl font-semibold mt-8">6.1. Early attitudes toward ECC</h3>

    <p class="text-gray-300">For several years after elliptic curve cryptography was proposed, the most common response from cryptographers was curiosity and approval. Although most researchers had never studied elliptic curves and at first had little understanding of the technical issues in ECC, they tended to react positively to the general idea of a type of cryptography based on algebraic curves. In the late 1980s a broad range of mathematicians were starting to work in the field, and the growing interest in cryptography by mathematicians and the increasing sophistication of the mathematics that was being introduced perhaps were taken as an indication that public key cryptography was coming into its own and would soon be “ready for prime time.”</p>

    <p class="text-gray-300">Moreover, ECC was not perceived as a commercial threat to anyone. Commercial rivalries were still in the future, and even RSA had not yet become a major force in commerce. In fact, to most people in the 1980s the term “information security” meant that you bought a lock for your file cabinet. In many ways the atmosphere during the first decade of academic work on cryptography was relaxed, open-minded and curious — a contrast with what came later.</p>

    <h3 id="sec-18" class="text-xl font-semibold mt-8">6.2. ECC becomes a commercial threat</h3>

    <p class="text-gray-300">In the late 1980s three professors at the University of Waterloo formed a company, now called Certicom, that developed and promoted ECC. Researchers affiliated with Certicom started attending meetings of industrial standards bodies, where they lobbied for the inclusion of ECC protocols in the recommendations. For example, the Elliptic Curve Digital Signature Algorithm (see §3.3) was making headway as an efficient alternative both to RSA signatures and to NSA’s original finite field Digital Signature Algorithm (see §7), although its final approval and inclusion in the standards didn’t occur until 1999 and 2000 <em>[3, 85]</em>.</p>

    <p class="text-gray-300">Meanwhile, RSA Data Security was finally enjoying commercial success. RSA cryptography was becoming well known among the general public, and it had a virtual monopoly on the market for public key cryptography. On the other hand, there were clouds on the horizon. The recently developed number field sieve factoring method had lowered the running time for factoring a <span class="math">k</span>-bit RSA modulus from <span class="math">\\exp(k^{1/2+\\epsilon})</span> to <span class="math">\\exp(k^{1/3+\\epsilon})</span>. This was a dramatic improvement, and it meant that the size of the numbers recommended for safe use of RSA would soon grow to over a thousand bits. As small devices such as cell phones, pagers, and smart cards entered the mass market, promoters of ECC were cautioning that RSA would</p>

    <p class="text-gray-300">have significant disadvantages in “constrained environments” that had low storage capacity and bandwidth.</p>

    <h3 id="sec-19" class="text-xl font-semibold mt-8">6.3. “ECC Central”: RSA strikes back</h3>

    <p class="text-gray-300">In 1997 RSA Data Security put on its website a section called “ECC Central,” running to nine printed pages, in order to respond to what they termed “significant coverage in the media” and “the current excitement around elliptic curve cryptosystems.” The website announced that</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>The recommendation of RSA, supported by the world’s top cryptographers and cryptanalysts, is that the use of ECC puts customer data at far too great a risk and that further study and testing is required.</p>
    </blockquote>

    <p class="text-gray-300">The company’s main argument to justify its recommendation was that</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>…the integer factorization problem (on which the security of RSA depends) has been studied intensively by number theorists and mathematicians around the world for literally hundreds of years and there is no doubt that the RSA cryptosystem has stood the test of time very well. By contrast, research into the elliptic curve discrete logarithm problem (on which the security of elliptic curve cryptosystems depends) and on elliptic curve cryptosystems in general represents a fraction of that spent on both RSA and the integer factorization.</p>
    </blockquote>

    <p class="text-gray-300">The last section of the RSA policy statement rhetorically asked “Elliptic curve cryptosystems ready for prime time?” and answered the question in the negative.</p>

    <p class="text-gray-300">RSA buttressed its position by appending a section called “The Experts Comment on ECC” in which eight cryptographers offered their skeptical commentary. Most interesting were the statements by two of the three founders of RSA, Leonard Adleman and Ron Rivest. Adleman started by saying, “I am suspicious of elliptic curve cryptosystems,” and then explained his suspicion by citing his work <em>[1]</em> with DeMarrais and Huang giving a subexponential algorithm for the analogous problem for high-genus hyperelliptic curves. He correctly pointed out that those curves had been thought to be at least as secure as elliptic curves (see §5.1).</p>

    <p class="text-gray-300">Rivest’s comments were the most erudite:</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>But the security of cryptosystems based on elliptic curves is not well understood, due in large part to the abstruse nature of elliptic curves. Few cryptographers understand elliptic curves, so there is not the same widespread understanding and consensus concerning the security of elliptic curves that RSA enjoys. Over time, this may change, but for now trying to get an evaluation of the security of an elliptic-curve cryptosystem is a bit like trying to get an evaluation of some recently discovered Chaldean poetry.</p>
    </blockquote>

    <p class="text-gray-300">Supporters of ECC countered these statements by pointing out that the claim that the security of RSA rested on sturdier ground was a little misleading. Although Gauss himself spoke of his interest in the integer factorization problem almost two hundred years ago, it is a gross exaggeration to say that mathematicians have been studying the problem intensively since that time. In fact, it was the invention of RSA cryptography in 1977 that stimulated stepped-up efforts to improve algorithms, and most of the research on integer factorization is relatively recent.</p>

    <p class="text-gray-300">In addition, the elliptic curve discrete log problem is analogous to the corresponding problem in a finite field, and most of the approaches to the elliptic curve problem are closely related to approaches that were studied earlier in the finite field context. The discrete log problem in a finite field played an important role in cryptography long before the invention of RSA and public key: in the 1950s it arose in work on shift-register sequences. Index calculus was actually first developed in the 1920s by Kraitchik <em>[64, 65]</em> for the discrete log problem in a prime field, and it was not applied to integer factorization until many years later.</p>

    <p class="text-gray-300">Moreover, it is not quite right that more sophisticated mathematical knowledge is needed to study possible attacks on elliptic curves than to study approaches to the integer factorization problem. Although it takes a little more mathematical background to understand the group law on an elliptic curve than to understand the modular exponentiation in RSA, it is illogical to conclude from this that research on breaking RSA through factoring is easier to understand than research on finding discrete logs on elliptic curves. At the time that “ECC Central” appeared, by far the most complicated mathematics that had ever been applied to solve either problem was the number field sieve, which had had such a dramatic impact on factoring. Contrary to what Rivest implied in the remark quoted above, in 1997 the number of cryptographers with sufficient mathematical background to analyze and improve upon the best attacks on integer factorization was less than the number who were capable of evaluating the best attacks on the elliptic curve discrete log problem. As number theorists know well, there is no correlation between ease of understanding the statement of a problem and the level of difficulty involved in making progress in solving it.</p>

    <h3 id="sec-20" class="text-xl font-semibold mt-8">6.4. Xedni calculus and liftings</h3>

    <p class="text-gray-300">In September 1998 J. Silverman circulated an outline of an attack <em>[96]</em> on the elliptic curve discrete log problem. He called it “xedni” calculus (xedni = index spelled backwards) because in some sense it reversed the steps in index calculus. Suppose we have two points <span class="math">P,Q</span> in a prime order subgroup <span class="math">G\\subset E(\\mathbb{F}_{p})</span>, and we want to find <span class="math">x</span> such that <span class="math">Q=xP</span>. Silverman’s general idea was to start by randomly generating a few (no more than 9) integer linear combinations <span class="math">P_{i}=a_{i}P+b_{i}Q</span> and then lifting them to points <span class="math">\\widetilde{P}_{i}</span> with <span class="math">\\mathbb{Z}</span>-coordinates. He then finds a lifting <span class="math">\\widetilde{E}</span> over <span class="math">\\mathbb{Q}</span> that reduces to <span class="math">E</span> mod <span class="math">p</span>, passes through the <span class="math">\\widetilde{P}_{i}</span>, and satisfies some other conditions that, if one believes the heuristics of the Birch and Swinnerton-Dyer conjecture (and uses an analytic formula of J. F. Mestre for the Mordell rank of <span class="math">\\widetilde{E}</span>), increase the likelihood that the points <span class="math">\\widetilde{P}_{i}\\in\\widetilde{E}</span> will be dependent over <span class="math">\\mathbb{Z}</span>. If they are dependent, then it’s easy to find <span class="math">x</span>.</p>

    <p class="text-gray-300">Although the outline of xedni calculus was fairly simple, its running time would depend on some subtle considerations that were hard to pin down in computational terms. At first it was completely unclear whether or not xedni calculus would be more efficient than other algorithms for finding elliptic curve discrete logs. This was still a time when RSA and ECC were in fierce competition, and the promoters of ECC feared that RSA people would seize upon the opportunity provided by xedni calculus and proclaim to the world that ECC had been broken.</p>

    <p class="text-gray-300">Fortunately, however, it turned out that slight modifications of Silverman’s algorithm could be used to solve not only the discrete log problem in the multiplicative group of <span class="math">\\mathbb{F}_{p}</span> (by applying it to a degenerate elliptic curve, i.e., a rational curve over <span class="math">\\mathbb{F}_{p}</span>), but also the problem of factoring an RSA modulus <span class="math">N</span> (by applying it to</p>

    <p class="text-gray-300">a degenerate elliptic curve over <span class="math">\\mathbb{Z}/N\\mathbb{Z}</span>). In other words, if Silverman’s algorithm destroyed ECC, then it would destroy RSA as well. This feature of the algorithm was very opportune, because it gave us time to analyze it without having to worry about RSA people making premature announcements about the threat from xedni calculus.</p>

    <p class="text-gray-300">The xedni algorithm was found to be extremely inefficient; in fact, it seemed to take super-exponential time to find discrete logs <em>[43]</em>. The reason was basically the same one that Miller <em>[80]</em> had used back in 1985 to argue that index calculus wouldn’t work on elliptic curves. Namely, the Néron-Tate height function guaranteed that <span class="math">\\widetilde{E}(\\mathbb{Q})</span> couldn’t have a large number of “small” points.</p>

    <p class="text-gray-300">Once again the height function played a crucial role in explaining why lifting techniques couldn’t be efficiently used to find discrete logs. In 2000 N. Koblitz gave a talk on this at the ECC conference in Essen titled “Miracles of the Height Function — A Golden Shield Protecting ECC.” Subsequent developments would show that Koblitz’s celebration of the “golden shield” was premature, as researchers found faster-than-squareroot and even subexponential index calculus attacks on some elliptic curves defined over certain classes of finite fields (see §10). However, in none of these partial successes of index calculus have liftings to global fields played any role.</p>

    <p class="text-gray-300">At the ECC conference in 2007 Silverman <em>[97]</em> gave a much more systematic analysis of the failure of four possible plans of attack on the discrete log problem based on lifting to a global field. But despite the repeated failure of lifting-based approaches, one cannot be absolutely certain that no lifting will ever work. For this reason some people recommend staying away from elliptic curves over <span class="math">\\mathbb{F}_{q}</span> for which it is easy to construct a lifting to a number field that has special properties that might some day prove useful to an attacker. In particular, in §11 we’ll discuss the recommendation of the Brainpool consortium that all curves used in ECC have complex multiplication by quadratic imaginary fields of very high class number so that they cannot efficiently be lifted to a CM-curve over a number field.</p>

    <h2 id="sec-21" class="text-2xl font-bold">7. The Role of NSA</h2>

    <p class="text-gray-300">In the 1970s and early 1980s the U.S. National Security Agency was an extremely secretive organization. The standing joke at the time was that NSA stood for “No Such Agency.” People from NSA would attend the crypto conferences that were starting to be held, but they would never identify where they worked.</p>

    <p class="text-gray-300">NSA was unhappy with the sudden growth of open research on cryptography that had been stimulated by the invention of public key systems and especially RSA. In 1980 they made a heavy-handed and ultimately unsuccessful attempt to impose a system of prior restraint on publication of mathematical articles that they judged to have cryptographic relevance (see <em>[67]</em>).</p>

    <p class="text-gray-300">But by the time the debates between RSA and ECC heated up in the 1990s, NSA had changed in a fundamental way — it had “come in from the cold.” There were two main reasons for the transformation of NSA into an organization that started to participate openly in the cryptographic research community.</p>

    <p class="text-gray-300">The first reason was a broadening of NSA’s mandate after the passage of the Computer Security Act of 1987. Originally NSA had been given responsibility only for communication security for the U.S. military and government agencies. But with the emergence of the Internet and other technologies, communications were</p>

    <p class="text-gray-300">ANN HIBNER KOBLITZ, NEAL KOBLITZ, AND ALFRED MENEZES</p>

    <p class="text-gray-300">increasingly mixed up with computers, and it was becoming clear that issues of computer security and communication security could not be separated. In addition, most government communications were integrated with the public network and faced the same threats as everyone else. So government security could not be kept separate from similar issues in the private sector. Thus, in 1987 the U.S. government agency NIST (National Institute for Standards and Technology, the new name of the National Bureau of Standards) was given a mandate to investigate and help establish standards for security of all sorts of computer and communication networks. According to some accounts <em>[24, 70]</em> the intent of the Computer Security Act of 1987 in explicitly assigning this task to NIST was to have non-military cryptography under civilian control and prevent NSA from venturing into the private sector. However, in practice NSA has had the resources and expertise to dominate NIST, and NIST has rarely played a significant independent role. In any case, whatever the intent of the Act was, in the aftermath NSA took on an increasing role in the civilian world.</p>

    <p class="text-gray-300">The second basic reason for the emergence of a “kinder, friendlier NSA” (in the words of a top NSA official <em>[108]</em>) was the end of the Cold War. During the decade between the collapse of the Soviet Union and the 9/11/2001 attacks, the U.S. did not have any obvious external enemy. As a result the companies, government agencies, and even academic disciplines (such as Russian area studies) that had come to prominence during the Cold War had to re-tool or else risk losing their relevance and their funding. Thus, it was strongly in NSA’s interest to show that it had a role to play in developing technology that could protect the commercial world and the public at large from all sorts of threats to their communications.</p>

    <p class="text-gray-300">Whatever the reasons for NSA’s new focus, the timing could not have been better for elliptic curve cryptography, which by the mid-1990s was locked in an increasingly nasty competition with RSA. From a commercial standpoint RSA had a tremendous advantage over the Canadian company Certicom, which was the main promoter of ECC. RSA was well established, had name recognition and had the lion’s share of the public key cryptography market. On the other hand, the advent of the number field sieve forced RSA to use longer and longer keys. People who understood the math behind the two systems could see that over time RSA would be inferior to ECC in constrained environments where memory and bandwidth are very limited.</p>

    <p class="text-gray-300">In the early 1990s there was a controversy over a proposed Digital Signature Standard that to some extent presaged the role that NSA would later play in the debate over ECC. NIST proposed a protocol for digital signatures that had been developed by NSA and closely resembled an earlier method invented by C. Schnorr. In these systems the security of signatures was based on the discrete log problem in a finite field. This choice was a direct challenge to the predominance of factorization-based cryptography, and it was bitterly opposed by RSA. Although the Digital Signature Standard — which was approved for commercial use in 1994 — was not based on elliptic curves, it signaled a dissatisfaction with RSA technology within NSA.</p>

    <p class="text-gray-300">The technical people in NSA had been attracted to elliptic curve cryptography since the 1980s. But the first time these views became known to the outside world occurred at a meeting of the American National Standards Institute (ANSI) in</p>

    <p class="text-gray-300">December 1995. Meetings of standards bodies typically include industry representatives who have little mathematical background and so are easily manipulated by scare tactics. At the meeting in question, the RSA people were casting doubt on the safety of ECC-based protocols. As the heated debate continued, one of the NSA representatives left to make a phone call. He then returned to the meeting and announced that NSA believed that ECC had sufficient security to be used for communications among all U.S. government agencies, including the Federal Reserve. People were stunned. Normally the NSA representatives at standards meetings would sit quietly and hardly say a word. No one had expected such a direct and unambiguous statement from NSA — a statement that tipped the scales at ANSI in favor of ECC.</p>

    <p class="text-gray-300">At Crypto ’97 J. Solinas gave the first paper ever presented publicly at a cryptography meeting by an NSA member. It contained a procedure he had developed (see <em>[102]</em>) for greatly improved efficiency of ECC using anomalous binary curves (see §11.1). NSA’s support for ECC became more and more obvious over the years. In 2003 it licensed 26 ECC-related patents from Certicom for US$25 million, and in 2005 it posted the paper “The Case for Elliptic Curve Cryptography” on its website (see §1).</p>

    <p class="text-gray-300">The influence of NSA, which is part of the U.S. Department of Defense, on the RSA versus ECC debate is an example of a general phenomenon that has been documented by sociologists and historians of technology. For example, Braun and MacDonald (see <em>[13]</em> and <em>[72]</em>, p. 16) have shown that military support played an essential role in the history of the microchip, especially in the early years of semiconductor electronics when the commercial world viewed solid-state devices as inferior to the earlier valve technology. According to MacKenzie and Wajcman (<em>[72]</em>, p. 15), “Military interest in new technology has often been crucial in overcoming what might otherwise have been insuperable economic barriers to its development and adoption.” In a sense, NSA served as a counterweight to RSA’s market advantage, and in this way helped level the playing field between RSA and ECC.</p>

    <h2 id="sec-22" class="text-2xl font-bold">8. XTR vs. ECC</h2>

    <p class="text-gray-300">At Crypto 2000 A. Lenstra and Verheul <em>[68]</em> proposed a new type of cryptosystem called XTR. They choose a prime <span class="math">p</span> such that <span class="math">p^{2}-p+1</span> has a large prime factor <span class="math">n</span>, and they let <span class="math">G</span> be the subgroup <span class="math">\\mu_{n}\\subset\\mathbb{F}_{p^{6}}^{*}</span> of order <span class="math">n</span> in the multiplicative group of the degree-6 extension of <span class="math">\\mathbb{F}_{p}</span>. They have a way (which they call the “trace representation”) of writing elements of <span class="math">G</span> as efficiently as if they lived in the subfield <span class="math">\\mathbb{F}_{p^{2}}</span> (which, of course, they don’t). But to find discrete logs in <span class="math">G</span> by index calculus methods one would have to work in the field of <span class="math">p^{6}</span> elements, not <span class="math">p^{2}</span> elements. Lenstra and Verheul explained the advantages of their system:</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>XTR achieves security similar to RSA for much smaller key sizes than RSA. Although ECC key sizes can be somewhat further reduced than XTR key sizes, in many circumstances… key sizes of ECC and XTR will be comparable… XTR may be regarded as the best of two worlds, RSA and ECC.</p>
    </blockquote>

    <p class="text-gray-300">They also claimed a security advantage over ECC:</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>However, XTR is not affected by the uncertainty still marring ECC security…. Also, compared to ECC, the mathematics underlying</p>
    </blockquote>

    <p class="text-gray-300">XTR is straightforward, thus avoiding two common ECC-pitfalls: ascertaining that unfortunate parameter choices are avoided that happen to render the system less secure, and keeping abreast of… newly obtained results.</p>

    <p class="text-gray-300">At the Crypto 2000 Rump Session, Menezes and Vanstone responded to the claims for XTR by pointing out that the XTR group is precisely the group to which a certain supersingular curve <span class="math">E</span> defined over <span class="math">\\mathbb{F}_{p^{2}}</span> is isomorphic using the Weil pairing. Since the appearance of the Weil pairing attack <em>[75]</em>, such curves were generally avoided in ECC. Isn’t it risky to start using a group that is so intimately related to a weak case of ECC? Of course, the Weil embedding transports the discrete log problem on <span class="math">E</span> to the XTR group, not vice-versa. This means that the problem on <span class="math">E</span> reduces to the problem on the XTR group, not that the two problems are equivalent. However, Menezes and Vanstone asked whether there might be an efficiently computable map in the other direction that inverted the map coming from the Weil pairing. If so, then that would show that the discrete log problems on the two groups are exactly equivalent.</p>

    <h3 id="sec-23" class="text-xl font-semibold mt-8">8.1. Verheul’s theorem</h3>

    <p class="text-gray-300">Lenstra and Verheul were bothered by the suggestion that their system was equivalent in security to that of supersingular ECC. In 2000 supersingular elliptic curves were still viewed as too weak for cryptography. Verheul took up the challenge of Menezes-Vanstone, and was able to prove a striking theorem <em>[104, 105]</em>: If an efficiently computable isomorphism existed from the XTR group to the curve, then the Diffie-Hellman problem would be easy in both groups. Since that was unlikely, he concluded that the map goes only one way.</p>

    <p class="text-gray-300">Verheul’s own interpretation of his theorem — stated boldly in the title to <em>[104, 105]</em> — was that it provided evidence that XTR has strictly greater security (in the sense of hardness of the discrete log problem) than the corresponding supersingular ECC. However, in the first place, that conclusion does not follow logically from the theorem. There is in fact no evidence that there’s any method of solving the discrete log problem on the supersingular curve that’s faster than embedding it in the XTR group and then solving the discrete log problem in that group. Just because a possible avenue to proving equivalence of two problems — namely, constructing an efficient isomorphism in both directions — has been shown to be unlikely, that doesn’t mean that in practice the problems are not equivalent. For example, on curves of high embedding degree the so-called decision Diffie-Hellman problem (the problem, given <span class="math">g,g^{x},g^{y}</span>, of determining whether or not a fourth group element is equal to <span class="math">g^{xy}</span>) is believed to be solvable only if one can find the discrete log of <span class="math">g^{x}</span> or <span class="math">g^{y}</span>. However, it is highly unlikely that anyone will be able to prove by a reduction that the decision Diffie-Hellman problem is equivalent to the discrete log problem in such a group.</p>

    <p class="text-gray-300">If someone really believes, along with Verheul, that the supersingular curve <span class="math">E</span> over <span class="math">\\mathbb{F}_{p^{2}}</span> might be even less secure than the subgroup of <span class="math">\\mathbb{F}_{p^{0}}^{<em>}</span> into which it embeds, then presumably the same would apply to all supersingular curves. That would have dire implications for much of pairing-based cryptography. However, Verheul’s theorem was presented just a few months before the first major pairing-based protocols were announced. So at the time no one was worried about this implication of Verheul’s claim in the title of his papers </em>[104, 105]*.</p>

    <p class="text-gray-300">And what if a map in the reverse direction could be constructed? It turns out that Verheul’s theorem can be generalized (see <em>[28, 83]</em>) to all supersingular curves</p>

    <p class="text-gray-300">and all finite fields. Thus, the construction of such a map would imply that the Diffie-Hellman problem is easy in all finite fields and all supersingular elliptic curves. We do not mean to suggest that this is likely — we only want to illustrate the point that Verheul’s theorem lends itself to multiple interpretations.</p>

    <h3 id="sec-24" class="text-xl font-semibold mt-8">8.2. Skepticism’s last gasp</h3>

    <p class="text-gray-300">Despite the disparaging comments about ECC by the promoters of XTR, skepticism about elliptic curves was very much on the decline by the start of the new millenium. Industrial standards bodies had endorsed certain forms of ECC (see, e.g., <em>[3, 85]</em>), and “ECC Central” had been removed from the RSA website.</p>

    <p class="text-gray-300">This is not to say that no one in recent years has expressed doubts about ECC. Occasionally a writer on cryptography might object to the increasing acceptance of elliptic curve technology. For example, Bruce Schneier, the author of a best-selling guide to cryptography, has a popular blog that in 2005 took comments on the NSA paper “The Case for Elliptic Curve Cryptography” (see §1). In response to a blogger who wrote, “But ECC was less researched than the others [sic] algorithms!” Schneier posted the comment: “I agree with you, not the NSA.”</p>

    <h2 id="sec-25" class="text-2xl font-bold">9. The Dramatic Entry of Pairing-Based Cryptography</h2>

    <p class="text-gray-300">Starting in 2001, pairing-based cryptosystems were proposed by Dan Boneh, Matt Franklin, and others. Although some of the ideas had been around for a couple of years (see, for example, <em>[45, 89]</em>), their tremendous potential had not been realized before.</p>

    <p class="text-gray-300">The basic idea is that the Weil or Tate pairing on elliptic curves allows certain cryptographic functions to be performed more efficiently than ever before, provided that one works with elliptic curves where the pairing can be efficiently computed, i.e., curves of low embedding degree. Such curves have the “Diffie-Hellman gap” property, which means that the Diffie-Hellman problem is thought to be difficult, whereas the decision Diffie-Hellman problem (see §8.1) can be easily solved using the pairing.</p>

    <p class="text-gray-300">One of the first uses of pairing-based cryptography was the elegant solution by Boneh and Franklin <em>[10]</em> to an old question of Shamir <em>[93]</em>, who had asked whether an efficient encryption scheme could be devised in which a user’s public key would be just her identity (e.g., e-mail address). Such a system is called identity-based encryption. Another early application (see below) was to obtain short signatures.</p>

    <h3 id="sec-26" class="text-xl font-semibold mt-8">9.1. Boneh-Lynn-Shacham signatures</h3>

    <p class="text-gray-300">We shall describe the pairing-based signature scheme of Boneh-Lynn-Shacham <em>[11]</em> in the setting of the supersingular elliptic curve</p>

    <p class="text-gray-300">(1) <span class="math">y^{2}=x^{3}-x</span></p>

    <p class="text-gray-300">defined over <span class="math">\\mathbb{F}_{p}</span>, <span class="math">p\\equiv 3\\pmod{4}</span>. This curve <span class="math">E</span> has group order <span class="math">p+1</span> and embedding degree <span class="math">2</span>; suppose that <span class="math">p</span> is chosen so that <span class="math">n=(p+1)/4</span> is prime. Let <span class="math">P</span> be a fixed and publicly known generator of the subgroup <span class="math">G\\subset E(\\mathbb{F}_{p})</span> of prime order <span class="math">n</span>. We define what’s called a distortion map on the <span class="math">\\mathbb{F}_{p^{2}}</span>-points of <span class="math">E</span> as follows:</p>

    <p class="text-gray-300"><span class="math">Q=(u,v)\\mapsto\\widetilde{Q}=(-u,iv),\\text{ where }i^{2}=-1,\\ i\\in\\mathbb{F}_{p^{2}}.</span></p>

    <p class="text-gray-300">This is the reduction mod <span class="math">p</span> of the usual complex multiplication on the <span class="math">\\mathbb{Q}</span>-curve with equation (1). It gives an isomorphism from <span class="math">G\\subset E(\\mathbb{F}_{p})</span> to a “distorted group”</p>

    <p class="text-gray-300"><span class="math">\\widetilde{G}\\subset E(\\mathbb{F}_{p^{2}})</span> that, together with <span class="math">G</span>, generates all of <span class="math">E[n]</span>. Note that non-degeneracy of the Weil pairing implies that the pairing of a nontrivial element of <span class="math">G</span> with a nontrivial element of <span class="math">\\widetilde{G}</span> gives a nontrivial <span class="math">n</span>-th root of unity.</p>

    <p class="text-gray-300">Each user Alice chooses a random integer <span class="math">x</span> mod <span class="math">n</span>, which is her secret key, and computes the point <span class="math">Q=xP</span>, which is her public key. Suppose that Alice wants to sign a message to Bob that has hash value <span class="math">H</span>, which we suppose is an <span class="math">\\mathbb{F}_{p}</span>-point of <span class="math">E</span>. All she does is compute <span class="math">S=xH</span>, which is her signature for the message. When Bob receives the message and the signature he computes the hash value <span class="math">H</span> and then the two pairing values</p>

    <p class="text-gray-300"><span class="math">(H,\\widetilde{Q})\\qquad\\text{and}\\qquad(S,\\widetilde{P}).</span></p>

    <p class="text-gray-300">If Alice created the signature correctly, then the two values must be equal, because they are both equal to</p>

    <p class="text-gray-300"><span class="math">(H,\\widetilde{P})^{x}.</span></p>

    <p class="text-gray-300">Bob has confidence that only Alice could have signed the message, because only she would have been able to generate the point <span class="math">S</span> whose discrete log to the base <span class="math">H</span> is the same as the discrete log of <span class="math">Q</span> to the base <span class="math">P</span>.</p>

    <p class="text-gray-300">Not only is the Boneh-Lynn-Shacham signature shorter in bitlength and easier to describe than the Elliptic Curve Digital Signature Algorithm (see §3.3), but, unlike ECDSA, it uses properties of elliptic curves in an essential way and does not have any analogue in the simpler group <span class="math">\\mathbb{F}_{q}^{*}</span>.</p>

    <h3 id="sec-27" class="text-xl font-semibold mt-8">9.2. Selection of curves</h3>

    <p class="text-gray-300">There are two ways to select a curve of low embedding degree <span class="math">k</span>. One can choose a supersingular curve, for which <span class="math">k\\leq 6</span>. Supersingular curves have the advantage that there is a computable distortion map that can be used to construct protocols (see §9.1).</p>

    <p class="text-gray-300">However, one often wants <span class="math">k\\geq 6</span> to be large enough so that the time required to find discrete logs using index calculus in <span class="math">\\mathbb{F}_{q^{k}}</span> is comparable to the time required to find discrete logs directly in the group <span class="math">G</span> using a squareroot attack. At present <span class="math">k=6</span> is a reasonable choice, but with increased computing power the optimal choice of <span class="math">k</span> will soon be larger. A supersingular curve with <span class="math">k=6</span> exists only in characteristic 3, and there is no supersingular curve with <span class="math">k&gt;6</span>. Thus, implementers might want to use ordinary curves of low embedding degree. Such curves are rare, and the only way known to construct them is to use the so-called CM-method.</p>

    <p class="text-gray-300">Let <span class="math">E</span> be an ordinary elliptic curve defined over <span class="math">\\mathbb{F}_{p}</span> with trace <span class="math">t</span>, which means that <span class="math">\\#E(\\mathbb{F}_{p})=p+1-t</span>. We want <span class="math">p+1-t</span> to be a prime (or a prime times a very small cofactor); we want <span class="math">p^{k}\\equiv 1\\pmod{p+1-t}</span> (note that this is equivalent to <span class="math">(t-1)^{k}\\equiv 1\\pmod{p+1-t}</span>); and we want the discriminant <span class="math">t^{2}-4p</span> to have small squarefree part <span class="math">d</span>, in which case a curve over a number field can be found with complex multiplication by <span class="math">\\mathbb{Q}(\\sqrt{d})</span> that reduces modulo a prime lying over <span class="math">p</span> to a curve with the desired properties. The idea of the construction of ordinary curves with low <span class="math">k</span> by the CM-method is to find a family of integers <span class="math">(p,t)</span> parameterized by an integer <span class="math">z</span> such that the second and third of these conditions hold (and there’s a reasonable probability that <span class="math">p</span> is prime and <span class="math">p+1-t</span> has a large prime factor). The first results of this type were found for <span class="math">k=3,4,6</span> in <em>[79]</em>; in the case <span class="math">k=6</span> they set <span class="math">p=4z^{2}+1</span> and <span class="math">t=1\\pm 2z</span>. Subsequently other authors showed how to construct ordinary curves for certain embedding degrees <span class="math">k&gt;6</span>.</p>

    <p class="text-gray-300">ELLiptic CURVE CRYPTOGRAPHY</p>

    <h3 id="sec-28" class="text-xl font-semibold mt-8">9.3. Like a knife through butter</h3>

    <p class="text-gray-300">Pairing-based cryptography received near-universal acceptance and acclaim from the beginning. Unlike traditional ECC, it did not pass through a period of several years of skepticism and resistance. We find this especially striking because the curves used in this type of cryptography are precisely the ones that were shunned in ECC for many years after the discovery of the Weil pairing attack <em>[75]</em> and were still being disparaged as late as Eurocrypt 2001 by Verheul <em>[104]</em>.</p>

    <p class="text-gray-300">This paradoxical turn of events has several possible explanations. In the first place, it is hard not to be attracted by the sheer elegance of some of the constructions in pairing-based cryptography. Note, for example, how much simpler the Boneh-Lynn-Shacham signature is to describe (see §9.1) than the ECDSA was (see §3.3).</p>

    <p class="text-gray-300">In the second place, the timing was propitious. The first major pairing-based protocols were being promoted in the years right after traditional ECC had won acceptance and the once-bitter rivalry between RSA and ECC had subsided. Basically, most of the earlier critics of ECC had thrown in the towel — starting in the late 1990s the RSA software toolkit even included a version of ECC.</p>

    <p class="text-gray-300">In the history of technology it often happens that after a period of intense debate (what the sociologists Kline and Pinch <em>[48]</em> call <em>interpretative flexibility</em>) a consensus emerges to admit the “new kid on the block” into full membership in the club. At that point most people see no benefit in standing in the way of adopting the newer technology; rather, it seems to be in everyone’s interest to incorporate it into their theories and products. This process is known as <em>closure</em>. As Kline and Pinch explain,</p>

    <p class="text-gray-300">&gt; Interpretative flexibility, however, does not continue forever. ‘Closure’ and stabilization occur, such that some artifacts [i.e., inventions] appear to have fewer problems and become increasingly the dominant form of the technology. This, it should be noted, may not result in all rivals vanishing, and often two very different technologies can exist side by side (for example, jet planes and propeller planes). Also this process of closure and stabilization need not be final. New problems can emerge and interpretative flexibility may reappear. (<em>[48]</em>, pp. 113-114)</p>

    <p class="text-gray-300">A third explanation for the immediate acceptance of pairing-based cryptography is that by 2001 the viewpoint that papers proposing new protocols must always include a “proof of security” had become pervasive, especially on cryptography conference program committees. Almost all papers proposing pairing-based protocols included such “proofs,” and they served to reassure people about the security of the systems.</p>

    <p class="text-gray-300">This isn’t the place to repeat the critique of “provable security” in the series of papers <em>[57, 58, 59]</em>. Suffice it to say that the guarantees given by such proofs, even when the proofs are mathematically correct, are very conditional and contingent. In recent years what has often happened is that, whether or not readers fully understand the proof, they are mesmerized by it and are willing to put aside any doubts they might have had. Most likely this effect was at work in causing virtually universal and unquestioning acceptance of pairing-based cryptography in the research community.</p>

    <p class="text-gray-300">What a “security proof” — or, as we prefer to say, a reductionist security argument <em>[57]</em> — actually does is show that an adversary cannot succeed in mounting a certain category of attack unless a certain underlying mathematical problem is tractable. What is peculiar in the case of pairing-based cryptography is that the underlying mathematical problem is often a very contrived one, of the sort that hardly any mathematician would recognize as natural, let alone want to study. Nevertheless, it has become customary to regard a conditional result related to such a problem as a type of guarantee of security.</p>

    <p class="text-gray-300">For example, the underlying problem in <em>[8]</em> is called the <span class="math">m</span>-strong Diffie-Hellman problem in a group <span class="math">G</span> of prime order <span class="math">n</span>. Let <span class="math">g</span> be a generator of <span class="math">G</span>, and let <span class="math">x</span> denote an unknown integer mod <span class="math">n</span>. Given the <span class="math">m+1</span> group elements <span class="math">g,g^{x},g^{x^{2}},\\ldots,g^{x^{m}}</span>, the <span class="math">m</span>-strong Diffie-Hellman problem asks one to find a pair <span class="math">(c,h)</span> (where <span class="math">c</span> is a nonzero integer mod <span class="math">n</span> and <span class="math">h</span> is a group element) such that <span class="math">h^{x+c}=g</span>. At first it seemed that in practice this problem would prove to be as hard as finding discrete logs — in other words, in a generic group <span class="math">G</span> no algorithm would be faster than <span class="math">\\sqrt{n}</span>. However, at Eurocrypt 2006 Cheon <em>[17]</em>, using the same method that had been described earlier in a different context by Brown and Gallant <em>[16]</em>, showed that if <span class="math">n-1</span> has a factor <span class="math">m_{0}\\leq m</span> of size a little less than <span class="math">n^{1/3}</span>, then the <span class="math">m</span>-strong problem can be solved in roughly <span class="math">n^{1/3}</span> operations. So the underlying problem used in the security proof turned out to be weaker than expected.</p>

    <p class="text-gray-300">Some of the other underlying problems that occur in reductionist security arguments for pairing-based systems are even more ornate and contrived than the <span class="math">m</span>-strong Diffie-Hellman problem (see <em>[60]</em> for some examples). Nevertheless, few people have expressed skepticism regarding the true security of the “provably secure” pairing-based protocols.</p>

    <p class="text-gray-300">We wish to stress that we have no reason to believe that any pairing-based protocol is actually insecure. Our purpose in discussing this issue is not to urge people to avoid such cryptosystems, but rather to raise the intriguing question of why there have been hardly any skeptics in the research community.</p>

    <p class="text-gray-300">A final reason for the rapid acceptance of pairing-based cryptography is that it was not perceived as a threat either to important commercial interests or to established traditions of cryptographic research. On the contrary, the idea had an immediate appeal both for practical reasons — it provided the opportunity to improve functionality — and for intellectual reasons as well — it used some clever ideas in both mathematics and protocol design.</p>

    <p class="text-gray-300">Moreover, the timing could not have been better for the cryptography profession, which was having some difficulty coming up with a lot of nice problems for research projects. A large number of people with math or computer science backgrounds had entered the field and were faced with the challenge — especially, but not exclusively, in academia — to “publish or perish.” In addition, there had been a proliferation of cryptography conferences, all of which hoped to attract cutting-edge research papers. An increasing concern of program committees was that it was unrealistic to expect the amount of high-quality research to have increased at the same rate as the number of conferences. Against this backdrop the entrance onto the stage of pairing-based cryptography was like a godsend.</p>

    <p class="text-gray-300">As mentioned before, pairing-based cryptography started at the height of influence of the notion of “provable security,” and almost all papers in the area included reductionist arguments for the security of the proposed protocol. Interestingly, this</p>

    <p class="text-gray-300">tradition of always including a security proof led to even more possibilities for research projects, thanks to the controversy surrounding the so-called “random oracle model.” (The random oracle model basically allows one to make arguments for the security of a protocol under the plausible assumption that hash function values are indistinguishable from random bitstrings.) Leading theoreticians — apparently inspired in part by the Biblical story of the Bronze Serpent (see <em>[33]</em>, pp. 10-11) — had decided that the random oracle assumption that is used in many security proofs is suspect, and cryptographers should try to design protocols that have security proofs that avoid the use of this assumption. As a result it became common first to develop a protocol with nice properties that has a proof of security in the random oracle model, and then to publish a modified version, usually with slightly less desirable properties but with a security proof in a “standard” model. This was an important advance for the profession, since in one fell swoop it increased the number of papers that could be published on provably secure protocols from <span class="math">N</span> to <span class="math">2N</span>.</p>

    <h2 id="sec-29" class="text-2xl font-bold">10. A Chink in the Golden Shield: Index Calculus Again Rears Its Head</h2>

    <h3 id="sec-30" class="text-xl font-semibold mt-8">10.1. Weil descent</h3>

    <p class="text-gray-300">In the late 1990s Gerhard Frey had the idea of attacking the discrete log problem on an elliptic curve defined over <span class="math">\\mathbb{F}_{q^{m}}</span> by transporting it to the jacobian group of a curve over the smaller field <span class="math">\\mathbb{F}_{q}</span>, where it could be solved using index calculus in a way similar to <em>[1]</em>. This program was first carried out in certain cases by Gaudry, Hess, and Smart <em>[31]</em>, and their method has been generalized by Hess <em>[37]</em>.</p>

    <p class="text-gray-300">In some very special situations it has been possible to transport the discrete log problem on the elliptic curve defined over <span class="math">\\mathbb{F}_{q^{m}}</span> to the corresponding problem on the jacobian group of a genus-<span class="math">m</span> curve defined over <span class="math">\\mathbb{F}_{q}</span> (in that case both groups have the same order <span class="math">\\approx q^{m}</span>). In other special cases the genus of the curve is considerably larger than <span class="math">m</span>, but the resulting algorithm is still faster-than-squareroot as a function of <span class="math">q^{m}</span>.</p>

    <p class="text-gray-300">Weil descent doesn’t apply over prime fields, and in the range of interest in cryptography it seems not to apply to curves considered over prime degree extensions of <span class="math">\\mathbb{F}_{2}</span> (see <em>[76]</em>). Its main successes so far have been for curves defined over the fields <span class="math">\\mathbb{F}_{2^{f}}</span> when <span class="math">f</span> is divisible by <span class="math">3</span>, <span class="math">5</span>, <span class="math">6</span>, <span class="math">7</span>, or <span class="math">8</span>. For example, in <em>[78]</em> one of the classes of curves to which the Weil descent methods in <em>[31]</em> were shown to be applicable is the set of all elliptic curves <span class="math">E</span> defined over <span class="math">\\mathbb{F}_{2^{5\\ell}}</span> (with <span class="math">\\ell</span> prime) and not over a proper subfield. In theory it might be possible to transport the discrete log problem on <span class="math">E</span> to the jacobian of a genus-<span class="math">5</span> curve over <span class="math">\\mathbb{F}_{2^{\\ell}}</span>, for which there would be an index calculus algorithm requiring <span class="math">O(2^{1.6\\ell})</span> operations. In practice, though, the curves that came out of the Weil descent had genus <span class="math">15</span> or <span class="math">16</span>, resulting in an algorithm with running time roughly <span class="math">2^{2\\ell}</span>. This was still significantly better than Pollard-rho, which takes time <span class="math">2^{2.5\\ell+\\epsilon}</span>.</p>

    <h3 id="sec-31" class="text-xl font-semibold mt-8">10.2. Other potentially weak fields for ECC</h3>

    <p class="text-gray-300">In <em>[30]</em> Gaudry used index calculus methods directly on elliptic curves defined over <span class="math">\\mathbb{F}_{q^{m}}</span> with <span class="math">m&gt;1</span>. For a factor base he used the set of points whose <span class="math">x</span>-coordinate lies in <span class="math">\\mathbb{F}_{q}</span>. He performed the crucial step of expressing a randomly generated point in terms of the factor base by means of summation polynomials, a concept introduced by Semaev <em>[92]</em>. For fixed</p>

    <p class="text-gray-300"><span class="math">m</span> the running time of Gaudry’s algorithm was <span class="math">O(q^{2-2/m})</span>, so for <span class="math">m\\geq 3</span> this gave a faster-than-squareroot attack.</p>

    <p class="text-gray-300">In addition, Diem <em>[19]</em> proved that Gaudry’s algorithm yields a subexponential algorithm when the size of the field <span class="math">\\mathbb{F}_{q^{m}}</span> increases in such a way that <span class="math">m^{2}</span> is of order <span class="math">\\log q</span>.</p>

    <p class="text-gray-300">Fortunately for ECC, by the late 1990s implementers had largely restricted themselves to either prime fields or prime-degree extensions of <span class="math">\\mathbb{F}_{2}</span>. Prime fields and binary fields have traditionally been the easiest finite fields to use in most applications. The choice of prime degree <span class="math">m</span> of <span class="math">\\mathbb{F}_{2^{m}}</span> was partly dictated by the desire to allow the use of anomalous binary curves (see §11.1), which must be taken over such an extension if one wants the group order to be divisible by a prime of roughly <span class="math">m</span> bits. Thus, when NIST decided to recommend one random curve and one anomalous binary curve for each recommended binary field, it was natural to choose <span class="math">m</span> to be prime values for which the order of one of the curves (2) or (3) (see below) is equal to twice a prime or four times a prime <em>[85]</em>. In any case, because of this preference for prime fields and prime-degree binary fields, the faster-than-squareroot attacks described in this section, none of which applied to curves over such fields, had no impact on real-world implementations.</p>

    <h2 id="sec-32" class="text-2xl font-bold">11. A Tale of Two Standards: Brainpool vs. Voltage</h2>

    <p class="text-gray-300">In this section we compare two recent recommendations concerning which elliptic curves to use in ECC. One comes from Brainpool, a European consortium of companies and government agencies led by Bundesamt für Sicherheit in der Informationstechnik (BSI, the German equivalent of NSA). The other one <em>[12]</em> comes from an American company called Voltage, which presented it at a NIST workshop on pairing-based protocols (see <em>[73]</em>). What is interesting to us is the extent to which these recommendations contradict one another.</p>

    <p class="text-gray-300">The Brainpool draft <em>[71]</em> explicitly excludes all elliptic curves of low embedding degree (hence all supersingular curves) and all ordinary elliptic curves whose CM-field has low class number (hence all curves constructed by the CM-method). In particular, Brainpool rules out all curves (supersingular or ordinary) used in pairing-based cryptography.</p>

    <p class="text-gray-300">Both of these Brainpool requirements are given in a rather extreme form. The embedding degree must be greater than <span class="math">(q-1)/100</span>. If, for example, <span class="math">q</span> has 160 bits (the smallest size they allow), then they are saying that it’s a bad idea to use an elliptic curve group that embeds in a finite field of the form <span class="math">\\mathbb{F}_{q^{k}}</span> with <span class="math">k</span> a 150-bit integer (i.e., <span class="math">k\\approx(q-1)/1000</span>). Note that in such a humongous field the fastest algorithms known for the finite field discrete log would take time greater than <span class="math">\\exp(10^{15})</span> — roughly 1 followed by four hundred trillion zeros. Brainpool certainly seems to want to err on the side of caution! They also require that when the elliptic curve lifts to an elliptic curve over a number field that has complex multiplication, that number field must have degree greater than ten million.</p>

    <p class="text-gray-300">In contrast, the Voltage recommendation <em>[73]</em> states under “security considerations” that</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>The conservative choice for implementing a pairing-based algorithm is to use a supersingular curve.</p>
    </blockquote>

    <p class="text-gray-300">The elliptic curve they recommend using is the curve</p>

    <p class="text-gray-300"><span class="math">y^{2}=x^{3}+b</span></p>

    <p class="text-gray-300">over a prime field <span class="math">\\mathbb{F}_{p}</span> with <span class="math">p\\equiv-1\\pmod{12}</span>. This curve has <span class="math">p+1</span> points, embedding degree 2, and complex multiplication by the ring <span class="math">\\mathbb{Z}[\\zeta]</span>, <span class="math">\\zeta=\\exp(2\\pi i/3)</span>.</p>

    <p class="text-gray-300">Moreover, the Voltage curve has far more structure than most curves because it is supersingular. Namely, supersingular curves have a gigantic endomorphism ring — a quaternion algebra that includes imaginary quadratic rings as a small part. For the Voltage curve <span class="math">E</span> the endomorphism ring of <span class="math">E(\\overline{\\mathbb{F}}_{p})</span> is the following quaternion algebra:</p>

    <p class="text-gray-300"><span class="math">\\mathbb{Z}+\\mathbb{Z}\\zeta+\\mathbb{Z}\\phi+\\mathbb{Z}\\phi\\zeta,</span></p>

    <p class="text-gray-300">where <span class="math">\\phi</span> is the Frobenius endomorphism <span class="math">(x,y)\\mapsto(x^{p},y^{p})</span>, which satisfies the relation <span class="math">\\phi^{2}=-p</span>. Since <span class="math">\\zeta^{p}=\\zeta^{-1}</span>, the commutation relation here is: <span class="math">\\zeta\\phi=\\phi\\zeta^{-1}=-\\phi-\\phi\\zeta</span>.</p>

    <p class="text-gray-300">No one has ever been able to use this vast stable of endomorphisms to mount an attack on the discrete log problem on a supersingular curve. So there is no real evidence that the Voltage curve is weak. But its extensive special properties would certainly give heartburn to the Brainpool cryptographers.</p>

    <p class="text-gray-300">What is Voltage’s rationale for referring to its curve as the “conservative choice”? In the context of pairing-based cryptography, if you want to use an ordinary curve rather than a supersingular curve, you must use a very special version of the CM-method to construct your curve (see §9.2). As explained in <em>[73]</em>, “With ordinary curves, additional structure is needed to get a low embedding degree.” As mentioned in <em>[56]</em>, the type of special values of <span class="math">p</span> that are used might cause the discrete log problem in <span class="math">\\mathbb{F}_{p^{k}}</span> (where <span class="math">k</span> is the embedding degree) to be vulnerable to a version of the special number field sieve rather than the general number field sieve. Indeed, Schirokauer <em>[90]</em> has shown that this is true in a few cases. However, in most cases it is far from clear that the “additional structure” in the choice of the prime <span class="math">p</span> or the group order <span class="math">n</span> could ever be utilized by an attacker. So whether the “conservative choice” is to use supersingular curves or to generate ordinary curves of low embedding degree — or perhaps (if one is a follower of Brainpool) to avoid pairing-based cryptography altogether — is anyone’s guess.</p>

    <h3 id="sec-33" class="text-xl font-semibold mt-8">11.1. Special or random selection of parameters?</h3>

    <p class="text-gray-300">A general philosophy one often encounters in cryptography is that whenever possible parameters should be chosen by some random process. If a special choice is made to increase efficiency, there is always the risk that the same property that made the choice so attractive will also lead to vulnerability to an unanticipated attack.</p>

    <p class="text-gray-300">In the case of elliptic curve cryptography one of the arguments for its superiority over RSA was the tremendous variety of curves to choose from. This means that there are several opportunities to introduce randomness into parameter selection. One can make a random choice of prime field <span class="math">\\mathbb{F}_{p}</span>, for instance, followed by random choices of the coefficients in the Weierstrass equation of the curve. This is, in fact, essentially what Brainpool recommends.</p>

    <p class="text-gray-300">In 1985 R. Schoof <em>[91]</em> devised the first polynomial-time algorithm to determine the group order for an arbitrary elliptic curve. His method was greatly improved upon by Atkin, Morain, Elkies, and others. Much of this work was based on isogenies of elliptic curves; this was the first — but not the last (see §11.2) — cryptographic application of isogenies.</p>

    <p class="text-gray-300">The availability of efficient point-counting algorithms for random elliptic curves means that there is no practical reason not to use them. On the other hand, certain special curves have significant efficiency advantages. For example, over characteristic-2 fields one can save a lot of time computing point multiples by using the so-called anomalous binary curves defined over <span class="math">\\mathbb{F}_{2}</span></p>

    <p class="text-gray-300">(2) <span class="math">y^{2}+xy=x^{3}+x^{2}+1</span></p>

    <p class="text-gray-300">and</p>

    <p class="text-gray-300">(3) <span class="math">y^{2}+xy=x^{3}+1</span></p>

    <p class="text-gray-300">(see <em>[54, 102]</em>). In elliptic curve cryptography one would use a prime order subgroup of the group of points defined over an extension of <span class="math">\\mathbb{F}_{2}</span>.</p>

    <p class="text-gray-300">The conventional wisdom is that there’s a trade-off. If you want long-term security, you must be willing to sacrifice a little bit of efficiency and generate your parameters in a random way. On the other hand, if a special choice of parameters allows for greater efficiency and if there are no known attacks that utilize their special properties, and if you’re willing to risk the possibility that such attacks will be found some day, then by all means use, for example, anomalous binary curves.</p>

    <p class="text-gray-300">This point of view seems logical, and it is uncontroversial among cryptographers. However, under certain circumstances it may be wrong. In particular, it is conceivable that Brainpool’s super-cautious recommendations might cause one to choose curves that are less secure than some CM-type curves might be. In other words, random curves might be riskier than special curves.</p>

    <p class="text-gray-300">Before explaining how this is possible, we’d like to make a remark about the notion of special versus generic curves. As we saw in §5.1, a word such as “complexity” might have a different meaning in cryptography than in traditional mathematics; conceptual complexity and computational complexity are two quite different things. The same goes for the term “special curve.”</p>

    <h6 id="sec-34" class="text-base font-medium mt-4">Example 1.</h6>

    <p class="text-gray-300">In the study of algebraic curves one normally regards hyperelliptic curves as a very special subclass. For <span class="math">g\\geq 3</span> there are far fewer hyperelliptic than non-hyperelliptic curves in the sense that the hyperelliptic curves correspond to a submanifold of codimension <span class="math">g-2</span> in the moduli space of all genus-<span class="math">g</span> curves. That is, for <span class="math">g\\geq 3</span> there are roughly <span class="math">1/q^{g-2}</span> times as many hyperelliptic curves as non-hyperelliptic curves over <span class="math">\\mathbb{F}_{q}</span>.</p>

    <p class="text-gray-300">Yet Diem and Thomé <em>[22]</em> found an index calculus attack on the discrete log problem in the jacobian group of a genus-3 non-hyperelliptic curve over <span class="math">\\mathbb{F}_{q}</span> that has running time of order only <span class="math">q^{1+\\epsilon}</span>. In <em>[20]</em> Diem generalized this algorithm to all “sufficiently general” non-hyperelliptic curves of arbitrary genus <span class="math">g\\geq 3</span> with running time <span class="math">q^{2-2/(g-1)+\\epsilon}</span>. This algorithm is substantially faster than the fastest known algorithm for discrete logs in the jacobian group of a hyperelliptic curve (see <em>[21]</em>), which takes time <span class="math">q^{2-(2/g)+\\epsilon}</span>. To put it another way, over a fixed field <span class="math">\\mathbb{F}_{q}</span> the discrete log problem on the jacobian of a genus-<span class="math">g</span> hyperelliptic curve has the same computational complexity (in the sense of the best available algorithms) as the discrete log problem on the (much larger) jacobian of a genus-<span class="math">(g+1)</span> non-hyperelliptic curve. It turned out that a certain way in which a generic non-hyperelliptic curve can be represented as a plane curve allows for a particularly efficient generation of relations among divisor classes. Thus, to the best of our current knowledge, it</p>

    <p class="text-gray-300">is the non-hyperelliptic curves and not the hyperelliptic curves whose discrete log problems have a special vulnerability to index calculus.</p>

    <p class="text-gray-300">There are various scenarios in which someone (say, Alice) who chose to use ECC with a special curve might end up better off than someone else (say, Bob) who chose a random curve. Our first example is a little removed from practice because we use extension fields of composite degree, whereas real-world implementations of ECC generally are over either a prime field <span class="math">\\mathbb{F}_{p}</span> or an extension of <span class="math">\\mathbb{F}_{2}</span> of prime degree.</p>

    <h6 id="sec-35" class="text-base font-medium mt-4">Example 2.</h6>

    <p class="text-gray-300">Suppose that Alice wants to use an anomalous <span class="math">\\mathbb{F}_{2}</span>-curve (2) or (3) over a field extension of degree <span class="math">5\\ell</span> with <span class="math">\\ell</span> prime. She knows, of course, that, because of the large subgroup of order <span class="math">\\approx 2^{\\ell}</span> consisting of the <span class="math">\\mathbb{F}_{2^{\\ell}}</span>-points of the curve, the largest prime order subgroup she can hope to get has order roughly <span class="math">2^{4\\ell}</span>. (It’ll actually be a little smaller because there’s also a subgroup of <span class="math">\\mathbb{F}_{2^{5}}</span>-points.) This means that the Pollard-rho algorithm will take time approximately <span class="math">2^{2\\ell}</span>. (There will also be a slight speed-up from grouping together conjugate points as explained in <em>[29, 107]</em>, but this is only by <span class="math">\\sqrt{\\ell}</span>, and we are using rough asymptotic running times here.) So if Alice wants <span class="math">k</span> bits of security she’ll have to use <span class="math">\\ell</span> of order <span class="math">k/2</span>. Nevertheless, she still wants to use an anomalous curve because she feels that its efficiency advantage is great enough to compensate for the need to choose <span class="math">\\ell</span> a little larger.</p>

    <p class="text-gray-300">Meanwhile, Bob thinks that Alice is being unwise, because if he uses a random curve over the same type of field <span class="math">\\mathbb{F}_{2^{5\\ell}}</span> with <span class="math">\\ell</span> prime, he can find a curve whose group order is twice a prime, in which case Pollard-rho will take time roughly <span class="math">2^{2.5\\ell}</span>. That means that he can get the same <span class="math">k</span> bits of security as Alice with <span class="math">\\ell</span> equal only to <span class="math">0.4k</span>.</p>

    <p class="text-gray-300">Bob’s reasoning made perfect sense throughout the 1990s. However, the study of Weil descent in <em>[78]</em> showed that the discrete log problem on a random curve over <span class="math">\\mathbb{F}_{2^{5\\ell}}</span> can be reduced to the corresponding problem in the jacobian of a genus-15 or genus-16 curve over <span class="math">\\mathbb{F}_{2^{\\ell}}</span>, which, in turn, can be solved in time roughly <span class="math">2^{2\\ell}</span>. This is asymptotically the same as the time for Pollard-rho on Alice’s special curve. Thus, Bob took a bad gamble when he decided to use a random curve with a lower value of <span class="math">\\ell</span> than Alice’s. He gets only <span class="math">0.8k</span> bits of security, not the <span class="math">k</span> bits he thought he’d get.</p>

    <p class="text-gray-300">In order to give two more examples of possible security disadvantages of randomness in ECC, we have to talk about isogenies.</p>

    <h3 id="sec-36" class="text-xl font-semibold mt-8">11.2. Isogenies and endomorphism rings</h3>

    <p class="text-gray-300">We shall give a brief overview of isogenies between elliptic curves. For proofs and details see <em>[95, 106]</em>. Let <span class="math">E_{1}</span> and <span class="math">E_{2}</span> be defined over <span class="math">\\mathbb{F}_{q}</span>. An isogeny <span class="math">\\psi:\\ E_{1}\\longrightarrow E_{2}</span> defined over <span class="math">\\mathbb{F}_{q}</span> is a non-constant rational map defined over <span class="math">\\mathbb{F}_{q}</span> that maps <span class="math">\\infty</span> to <span class="math">\\infty</span>; its degree is its degree as a rational map. If <span class="math">\\psi</span> is a separable isogeny, then the kernel of <span class="math">\\psi</span> is a subgroup of <span class="math">E_{1}</span> of order <span class="math">\\deg\\psi</span>.</p>

    <p class="text-gray-300">Any isogeny <span class="math">\\psi:\\ E_{1}\\longrightarrow E_{2}</span> has a dual isogeny <span class="math">\\widehat{\\psi}:\\ E_{2}\\longrightarrow E_{1}</span> such that the composition <span class="math">\\psi\\circ\\widehat{\\psi}</span> is the endomorphism of multiplication by <span class="math">\\deg\\psi</span>. We say that <span class="math">E_{1}</span> and <span class="math">E_{2}</span> are isogenous over <span class="math">\\mathbb{F}_{q}</span> if there exists an isogeny from one to the other that is defined over <span class="math">\\mathbb{F}_{q}</span>. A theorem of Tate states that <span class="math">E_{1}</span> and <span class="math">E_{2}</span> are isogenous over <span class="math">\\mathbb{F}_{q}</span> if and only if <span class="math">\\#E_{1}(\\mathbb{F}_{q})=\\#E_{2}(\\mathbb{F}_{q})</span>.</p>

    <p class="text-gray-300">For example, suppose that <span class="math">\\ell\\neq p</span> is a prime, and <span class="math">C</span> is a subgroup of <span class="math">E_{1}</span> of order <span class="math">\\ell</span> that is defined over <span class="math">\\mathbb{F}_{q}</span>. (Recall that this means that the subgroup <span class="math">C</span> is fixed by the Frobenius map <span class="math">\\phi:\\ (x,y)\\mapsto(x^{q},y^{q})</span>, which can be true even if the individual points of <span class="math">C</span> are not in <span class="math">\\mathbb{F}_{q}</span>.) For every such group <span class="math">C</span> there is a degree-<span class="math">\\ell</span> isogeny from <span class="math">E_{1}</span> to a curve <span class="math">E_{2}</span> defined over <span class="math">\\mathbb{F}_{q}</span> whose kernel is <span class="math">C</span>.</p>

    <p class="text-gray-300">The modular polynomial <span class="math">\\Phi_{\\ell}[X,Y]\\in\\mathbb{Z}[X,Y]</span> has the property that if we let <span class="math">\\overline{\\Phi}_{\\ell}</span> denote the reduction mod <span class="math">p</span> and set <span class="math">Y</span> equal to the <span class="math">j</span>-invariant of <span class="math">E_{1}</span>, then the <span class="math">\\ell+1</span> roots of <span class="math">\\overline{\\Phi}_{\\ell}[X,j]\\in\\mathbb{F}_{q}[X]</span> are the <span class="math">j</span>-invariants of all of the curves <span class="math">E_{2}</span> that are <span class="math">\\ell</span>-isogenous to <span class="math">E_{1}</span> over the algebraic closure <span class="math">\\overline{\\mathbb{F}}_{q}</span>. Each such isogeny corresponds to one of the <span class="math">\\ell+1</span> subgroups of order <span class="math">\\ell</span> in the group of <span class="math">\\ell^{2}</span> points of order <span class="math">\\ell</span> on <span class="math">E_{1}(\\overline{\\mathbb{F}}_{q})</span>. An <span class="math">\\ell</span>-isogeny from a given curve can be quickly constructed if <span class="math">\\ell</span> is small; however, in general the best available algorithm <em>[63]</em> has running time roughly <span class="math">\\ell^{3}</span>, so for large <span class="math">\\ell</span> the construction is not feasible.</p>

    <p class="text-gray-300">Let <span class="math">E</span> be an elliptic curve defined over <span class="math">\\mathbb{F}_{q}</span>, <span class="math">q=p^{f}</span>, and let <span class="math">t=q+1-\\#E(\\mathbb{F}_{q})</span> denote its trace. An endomorphism of <span class="math">E</span> is an isogeny from <span class="math">E</span> to itself that is defined over <span class="math">\\overline{\\mathbb{F}}_{q}</span>. The endomorphisms form a ring denoted <span class="math">\\operatorname{End}(E)</span>. We consider the ordinary case when <span class="math">p</span> does not divide <span class="math">t</span>; in that case the elements of <span class="math">\\operatorname{End}(E)</span> are all defined over <span class="math">\\mathbb{F}_{q}</span>. Let <span class="math">\\Delta=t^{2}-4q</span> denote the discriminant of <span class="math">E</span>. Then the complex multiplication (CM) field of <span class="math">E</span> is <span class="math">K=\\mathbb{Q}(\\sqrt{\\Delta})</span>. We have <span class="math">\\Delta=c_{0}^{2}d</span>, where <span class="math">d&lt;0</span> is the discriminant of the imaginary quadratic number field <span class="math">K</span>. Let <span class="math">\\mathbb{Z}_{K}</span> denote the ring of integers; then <span class="math">\\operatorname{End}(E)\\subset\\mathbb{Z}_{K}</span> is an order in <span class="math">\\mathbb{Z}_{K}</span>. We let <span class="math">c</span> denote the conductor of <span class="math">\\operatorname{End}(E)</span>, i.e., its index in <span class="math">\\mathbb{Z}_{K}</span>.</p>

    <p class="text-gray-300">As before, let <span class="math">\\phi</span> denote the Frobenius endomorphism, given by <span class="math">(x,y)\\mapsto(x^{q},y^{q})</span>. We regard <span class="math">\\phi</span> as an element of <span class="math">\\mathbb{Z}_{K}</span> of norm <span class="math">q</span>, since its characteristic polynomial is <span class="math">T^{2}-tT+q=0</span>. The subring <span class="math">\\mathbb{Z}[\\phi]</span> has index <span class="math">c_{0}=\\sqrt{\\Delta/d}</span> in <span class="math">\\mathbb{Z}_{K}</span>, and <span class="math">\\operatorname{End}(E)</span> is an order of <span class="math">\\mathbb{Z}_{K}</span> that contains <span class="math">\\mathbb{Z}[\\phi]</span>, and so its index in <span class="math">\\mathbb{Z}_{K}</span> is a divisor <span class="math">c</span> of <span class="math">c_{0}</span>, <span class="math">1\\leq c\\leq c_{0}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The curves in the <span class="math">\\mathbb{F}_{q}</span>-isogeny class of a given <span class="math">E</span> can be partitioned according to their endomorphism ring, i.e., into “endomorphism classes” within the isogeny class. The endomorphism rings are the orders in <span class="math">\\mathbb{Z}_{K}</span> that contain <span class="math">\\mathbb{Z}[\\phi]</span>, and they are in one-to-one correspondence with the divisors <span class="math">c</span> of <span class="math">c_{0}</span>. The number of isomorphism classes of curves in a given endomorphism class is equal to the class number <span class="math">h_{c}</span> of the order, and this is approximately equal to <span class="math">ch_{K}</span>, where <span class="math">h_{K}</span> is the class number of the imaginary quadratic CM field <span class="math">K</span> (for a more precise formula, see <em>[27]</em>, p. 123). The class number <span class="math">h_{K}</span> satisfies $h_{K}\\leq\\frac{1}{\\pi}\\sqrt{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">d</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">d</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, where </span>d<span class="math"> is the discriminant of </span>K$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">As mentioned before, the first use of isogenies was to develop improved methods of determining the group order of a random curve. More recently, isogenies have been used to investigate possible attacks on the elliptic curve discrete log problem. The idea is that if an isogeny can be computed between <span class="math">E_{1}</span> and <span class="math">E_{2}</span>, then the discrete log problem on <span class="math">E_{1}</span> can be transported to the same problem on <span class="math">E_{2}</span>. If it’s feasible to construct isogenies between any two curves in a certain subset of the isogeny class, then the discrete log problem is random self-reducible in that subset of curves; this implies that the problem is equally difficult for all of those elliptic curves.</p>

    <p class="text-gray-300">Suppose that starting with a curve <span class="math">E_{1}</span> in an endomorphism class with conductor <span class="math">c</span> one randomly chooses an <span class="math">\\ell</span>-isogeny <span class="math">E_{1}\\longrightarrow E_{2}</span>, where <span class="math">\\ell</span> is a small prime. Then</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">either <span class="math">E_{2}</span> is in the same endomorphism class as <span class="math">E_{1}</span>, or else it has conductor <span class="math">c\\ell</span> or else <span class="math">c/\\ell</span>. The last two possibilities can occur only if $\\ell</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">c_{0}<span class="math">. The main result of <em>[44]</em> (assuming the Generalized Riemann Hypothesis) is that a sequence of isogenies of prime degree </span>\\ell<L=(\\log q)^{2+\\epsilon}<span class="math"> (for fixed </span>\\epsilon<span class="math">), </span>(\\ell,c_{0})=1<span class="math">, can be used to fan out randomly throughout the endomorphism class. (The precise statement is that the graph whose vertices are the isomorphism classes in a given endomorphism class with adjacency determined by these </span>\\ell$-isogenies is an <em>expander graph</em>.)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">It is also possible to use isogenies to go efficiently between two endomorphism classes, but only if they have a small <em>conductor gap</em>, by which we mean the largest prime that divides one conductor and not the other. Thus, if <span class="math">L</span> is a bound on the size of primes <span class="math">\\ell</span> for which it is feasible to construct an <span class="math">\\ell</span>-isogeny, it is natural to divide a given isogeny class into subsets that each consist of endomorphism classes with conductor gap <span class="math">&lt;L</span>. Thus, in each isogeny class we define the <em><span class="math">L</span>-conductor-gap class</em> of a curve <span class="math">E</span> to be the set of all endomorphism classes having conductor gap <span class="math">&lt;L</span> with <span class="math">\\operatorname{End}(E)</span>. The result of <em>[44]</em> extends to these larger classes; that is, the discrete log problem is random self-reducible in each <span class="math">L</span>-conductor-gap class. That means that if an efficient algorithm were found to solve the discrete log problem in time <span class="math">T_{1}</span> in a constant proportion <span class="math">\\epsilon</span> of all elliptic curves defined over <span class="math">\\mathbb{F}_{q}</span> (we shall call them “weak” curves), then the discrete log could be found on any curve in the <span class="math">L</span>-conductor-gap class in time roughly <span class="math">T_{1}+T_{2}/\\epsilon</span>, where <span class="math">T_{2}</span> is the time required to construct an <span class="math">\\ell</span>-isogeny, <span class="math">\\ell&lt;L</span>. Here, of course, we’re assuming that the property of being a weak curve for the discrete log algorithm is independent of isogeny class and endomorphism ring; and we’re also assuming that the <span class="math">L</span>-conductor-gap class contains <span class="math">\\gg 1/\\epsilon</span> curves.</p>

    <p class="text-gray-300">Note that if <span class="math">c_{0}=1</span> (which is often the case) or if <span class="math">c_{0}</span> is <span class="math">L</span>-smooth, then all <span class="math">O(\\sqrt{p})</span> curves in the isogeny class are in the same <span class="math">L</span>-conductor-gap class. If <span class="math">c_{0}</span> is divisible by just a single large prime <span class="math">r</span>, then there are two such classes: a small set of isomorphism classes of curves whose endomorphism ring has conductor not divisible by <span class="math">r</span>, and the “generic” isomorphism classes where the endomorphism ring has conductor a multiple of <span class="math">r</span>.</p>

    <p class="text-gray-300">It is the possibility of random isogeny walks through a conductor-gap class that under certain circumstances might make a generic curve less secure than a special curve. We discuss this in the next subsection.</p>

    <h3 id="sec-37" class="text-xl font-semibold mt-8">11.3. More examples of potential weakness of random curves</h3>

    <p class="text-gray-300">Example 3. In V. Müller’s Table 6.2 of <em>[84]</em> the following is a choice of parameters suggested for ECC. Let <span class="math">q=2^{3\\cdot 59}</span>, and let <span class="math">E</span> be the curve defined over <span class="math">\\mathbb{F}_{8}</span> by the equation</p>

    <p class="text-gray-300"><span class="math">y^{2}+xy=x^{3}+x^{2}+\\gamma,</span></p>

    <p class="text-gray-300">where <span class="math">\\gamma\\in\\mathbb{F}_{8}</span> satisfies <span class="math">\\gamma^{3}=\\gamma^{2}+1</span>. This curve has 6 <span class="math">\\mathbb{F}_{8}</span>-points, and its group of <span class="math">\\mathbb{F}_{2^{177}}</span>-points has order 6 times the 175-bit prime</p>

    <p class="text-gray-300"><span class="math">P_{175}=31926990434706017882465563211521159723534715689440269.</span></p>

    <p class="text-gray-300">Suppose that Alice, following the suggestion of Müller, chooses this curve <span class="math">E</span> and extension field <span class="math">\\mathbb{F}_{2^{177}}</span>. She calculates that Pollard-rho (with the speed-up of <span class="math">\\sqrt{59}</span> in <em>[29, 107]</em>) would take roughly <span class="math">2^{84}</span> operations, i.e., the curve will give her 84 bits of security.</p>

    <p class="text-gray-300">Bob, as usual, thinks that Alice is foolish for having chosen a curve with very special properties that allow the <span class="math">\\sqrt{59}</span> speed-up and may leave her vulnerable to</p>

    <p class="text-gray-300">other attacks. He figures that if he chooses a random curve over the same field with group order twice a 176-bit prime, then he’ll get 88 bits of security rather than 84, and he’ll also be less vulnerable to unanticipated specialized attacks.</p>

    <p class="text-gray-300">At least through the 1990s Bob’s reasoning would have appeared to be correct. But a closer examination using more recent research (see <em>[78, 77]</em>) shows that Bob might not have nearly the security level that he thinks he has.</p>

    <p class="text-gray-300">The complex multiplication field for Alice’s curve is <span class="math">\\mathbb{Q}(\\sqrt{-23})</span>, and the discriminant is <span class="math">-23c_{0}^{2}</span> with <span class="math">c_{0}</span> factoring as the product of two primes:</p>

    <p class="text-gray-300"><span class="math">c_{0}=11681\\cdot 98766024850235972863.</span></p>

    <p class="text-gray-300">In <em>[77]</em> Menezes and Teske found that a certain proportion — roughly <span class="math">\\epsilon=2^{-58}</span> — of all elliptic curves over <span class="math">\\mathbb{F}_{2^{3\\cdot 59}}</span> with group order <span class="math">\\equiv 2\\pmod{8}</span> are “weak” in the sense that Weil descent can be used to transport the discrete log problem to the corresponding problem on the jacobian of a genus-3 hyperelliptic curve over <span class="math">2^{59}</span>. At that point the discrete log problem can be solved in time roughly <span class="math">2^{59\\cdot 4/3}\\approx 2^{79}</span> <em>[21]</em>.</p>

    <p class="text-gray-300">In what follows we shall make the (plausible) assumption that the property of being a “weak” curve is independent of isogeny and endomorphism classes — in other words, that the expected number of weak curves in such a class is roughly equal to <span class="math">\\epsilon=2^{-58}</span> times its cardinality.</p>

    <p class="text-gray-300">In Bob’s case almost certainly the discriminant of his curve <span class="math">E</span> is not divisible by the square of a large prime, and so it is possible to use isogenies to transport the discrete log problem on <span class="math">E</span> along a “random walk” throughout its isogeny class. If his group order is <span class="math">\\equiv 2\\pmod{8}</span> (of which there is a 50% chance), then after approximately <span class="math">2^{58}</span> isogenies we will have transported the discrete log problem to a curve where it can be solved in time roughly <span class="math">2^{79}</span>. Each step in the “walk” takes time approximately <span class="math">2^{17}</span>, so that the reduction to the weak curve will take time <span class="math">\\approx 2^{75}</span>. In other words, Bob’s random curve will have just 79 bits of security, not 88 bits as Bob thought and not even the 84 bits that Alice has.</p>

    <p class="text-gray-300">In contrast, even if the result in <em>[77]</em> applied to curves in Alice’s isogeny class (which it doesn’t, since the number of points on her curve is <span class="math">\\equiv 6\\pmod{8}</span>), she’d still be safe because her curve’s endomorphism ring has conductor 1 and is in a <span class="math">2^{66}</span>-conductor-gap class containing fewer than <span class="math">2^{16}</span> curves (the ones with conductor 1 or 11681). Under our assumption that the “weak” property is independent of isogeny or endomorphism class, it is highly unlikely — a probability of about <span class="math">2^{-42}</span> — that the discrete log problem on Alice’s curve can be moved to a weak curve by a sequence of isogenies. In other words, what saves Alice from Bob’s fate is precisely the very special nature of her curve.</p>

    <p class="text-gray-300">Most practical implementations of ECC in characteristic two use prime extension degrees, in which case Weil descent appears not to be useful (see <em>[76]</em>). However, it is not inconceivable that either a new version of Weil descent or some entirely different approach will some day lead to a faster-than-squareroot attack on a certain small (but non-negligible) proportion of elliptic curves defined over <span class="math">\\mathbb{F}_{q}</span>, where <span class="math">q</span> is a</p>

    <p class="text-gray-300">prime power of 2. If we are using a curve over this field when this happens, we had better hope that our curve cannot be linked to a weak curve by means of isogenies.</p>

    <h6 id="sec-38" class="text-base font-medium mt-4">Example 4.</h6>

    <p class="text-gray-300">In 2000 in its Digital Signature Standard <em>[85]</em>, NIST recommended ten elliptic curves over binary fields <span class="math">\\mathbb{F}_{2^{\\ell}}</span> with <span class="math">\\ell=163</span>, <span class="math">233</span>, <span class="math">283</span>, <span class="math">409</span>, <span class="math">571</span>. For each <span class="math">\\ell</span> they gave one random curve and one anomalous binary curve. The security level in the face of squareroot attacks is roughly <span class="math">2^{\\ell/2}</span>. For instance, both curves over <span class="math">\\mathbb{F}_{2^{571}}</span> should provide more than the 256 bits of security necessary to protect a high-security Advanced Encryption Standard (AES) private key.</p>

    <p class="text-gray-300">This raises the question: Which of the two NIST curves over <span class="math">\\mathbb{F}_{2^{571}}</span> is safer? The conventional wisdom would be that the random curve is the more conservative choice.</p>

    <p class="text-gray-300">However, let’s suppose that a certain very small — but not negligible — fraction <span class="math">\\epsilon</span> of curves over this field could be attacked by some new faster-than-squareroot algorithm. We further suppose that the property of being a “weak” curve is independent of isogeny class or endomorphism class. In such a situation if our curve is in a large <span class="math">L</span>-conductor-gap class, then after a “random walk” consisting of <span class="math">O(1/\\epsilon)</span> isogenies, an attacker can move the discrete log problem to a weak curve. A random curve is virtually certain to be in a large endomorphism class (since the discriminant of a random curve is very unlikely to be divisible by a large square). In particular, this is true of the random NIST curve over <span class="math">\\mathbb{F}_{2^{571}}</span>, whose discriminant is squarefree, i.e., all isogenous curves are in the same endomorphism class <em>[44]</em>. In contrast, the anomalous binary curve K-571 in <em>[85]</em> has discriminant <span class="math">\\Delta=-7c_{0}^{2}</span>, where the conductor <span class="math">c_{0}</span> is the product of a 22-bit prime and a 263-bit prime, and its endomorphism ring has conductor 1. For <span class="math">L=2^{262}</span> the <span class="math">L</span>-conductor-gap class of the curve K-571 has approximately <span class="math">2^{22}</span> curves, so if <span class="math">\\epsilon\\ll 2^{-22}</span>, this curve is likely to be safer than a random curve under our assumptions.</p>

    <p class="text-gray-300">Weil descent methods are not applicable to curves defined over a prime field. But suppose that we’re worried about the possibility that some new approach to the discrete log problem will turn out to give faster-than-squareroot algorithms for a certain proportion of curves defined over <span class="math">\\mathbb{F}_{p}</span>. Suppose also that the condition for a curve to be “weak” is likely to be independent of its isogeny or endomorphism class. In such a case we might want to choose our curve <span class="math">E</span> over <span class="math">\\mathbb{F}_{p}</span> to be in a very small endomorphism class — more precisely, in a small <span class="math">L</span>-conductor-gap class for fairly large <span class="math">L</span> — so that an attacker could not use isogenies to transport the discrete log problem from our curve to a weak curve.</p>

    <h6 id="sec-39" class="text-base font-medium mt-4">Example 5.</h6>

    <p class="text-gray-300">Choose <span class="math">B</span> to be a random <span class="math">k</span>-bit prime, and choose <span class="math">A</span> to be a random even number (perhaps also of <span class="math">k</span> bits, but <span class="math">A</span> may be chosen to have fewer bits) such that (i) <span class="math">p=A^{2}+B^{2}</span> is prime, and (ii) either <span class="math">n=(p+1)/2-A</span> or <span class="math">n=(p+1)/2+A</span> is a prime. Heuristically one expects to have to test <span class="math">O(k^{2})</span> values of <span class="math">A</span> in order to obtain conditions (i) and (ii). Then the curve <span class="math">E</span> over <span class="math">\\mathbb{F}_{p}</span> with equation</p>

    <p class="text-gray-300"><span class="math">y^{2}=x^{3}-\\alpha x</span></p>

    <p class="text-gray-300">has <span class="math">2n</span> points, where <span class="math">\\alpha\\in\\mathbb{F}_{p}</span> is a quadratic non-residue whose quartic residue class depends on the sign in <span class="math">n=(p+1)/2\\mp A</span> (see §9.8 and §18.4 of <em>[42]</em>). The trace of <span class="math">E</span> is <span class="math">\\pm 2A</span>, and its discriminant is <span class="math">4A^{2}-4p=-4B^{2}</span>. Because <span class="math">B</span> is prime, for</p>

    <p class="text-gray-300">ANN HIBNER KOBLITZ, NEAL KOBLITZ, AND ALFRED MENEZES</p>

    <p class="text-gray-300"><span class="math">k\\geq 80</span> it is completely infeasible to transport the discrete log problem on <span class="math">E</span> to that on a generic isogenous curve. Note that <span class="math">E</span> has complex multiplication by the full ring of integers <span class="math">\\mathbb{Z}[i]</span> (since <span class="math">i</span> acts on the curve by <span class="math">(x,y)\\mapsto(-x,iy)</span>, where the latter occurrence of <span class="math">i</span> denotes a square root of <span class="math">-1</span> in the finite field); that is, <span class="math">\\operatorname{End}(E)</span> has conductor <span class="math">1</span>. Up to isomorphism <span class="math">E</span> is the only curve in its conductor-gap class, and the endomorphism ring of any of the other isogenous curves has conductor <span class="math">B</span>.</p>

    <p class="text-gray-300">The method of parameter selection in this example of course directly flouts the advice of Brainpool <em>[71]</em>. But whether it is reckless or wise to do this is at present far from clear.</p>

    <p class="text-gray-300">Our purpose in giving these examples is not to lobby for the use of special curves in preference to random ones. Rather, our point is that conventional wisdom may turn out to be wrong and that, as far as anyone knows, either choice has risks. The decision about what kind of curve to use in ECC is a subjective one based on the user’s best guess about future vulnerabilities.</p>

    <p class="text-gray-300">As frequently happens in cryptography, a close examination of a commonly accepted viewpoint on security issues reveals that opposing opinions or interpretations cannot be ruled out. Much as we might wish to convey to the outside world an impression of self-confidence and mathematical certainty about our recommendations (see §2), there is ample reason to wonder whether this self-confidence is justified.</p>

    <h2 id="sec-40" class="text-2xl font-bold">12. Path Dependence</h2>

    <p class="text-gray-300">In <em>[72]</em> MacKenzie and Wajcman discuss what they call the <em>path-dependence</em> of technical change:</p>

    <p class="text-gray-300">&gt; Technologies often manifest increasing returns to adoption. The processes of learning by doing and by using… and the frequent focus of inventive effort on removing weak points… from existing technologies, mean that the very process of adoption tends to improve the performance of those technologies that are adopted. This gives the history, especially the early history, of a technology considerable significance. Early adoptions, achieved for whatever reason, can be built into what may become irreversible superiority over rivals, because success tends to breed success and rejection can turn into neglect and therefore permanent inferiority. The history of technology is a path-dependent history, one in which past events exercise continuing influences. Which of two or more technologies eventually succeeds is not determined by their intrinsic characteristics alone, but also by their histories of adoption. The technology that triumphs is not necessarily abstractly best…. Path-dependence means that local, short-term contingencies can exercise lasting effects.</p>

    <h3 id="sec-41" class="text-xl font-semibold mt-8">12.1. Historical what-ifs</h3>

    <p class="text-gray-300">One of the best ways to refute the technological determinist view of the history of cryptography that is implicit in the Ideal Model (see the last paragraph of §2) is to ask some hypothetical questions of the form “What if…?”</p>

    <p class="text-gray-300"><span class="math">\\bullet</span> What if in 1977 someone who had just written a Ph.D. thesis on elliptic curves had happened to read the classic article <em>[23]</em> that had appeared the year before? Fortunately for RSA, that appears not to have happened, since it probably would</p>

    <p class="text-gray-300">have occurred to such a person to suggest replacing the multiplicative group of a finite field by the group of points of an elliptic curve, and ECC would have been born eight years before 1985. In 1977 subexponential algorithms were already known for the integer factorization problem. The elliptic curve discrete log problem thus would have struck everyone as a much harder problem, and hence the one-way function in ECC would have appeared to be much safer for the construction of public key protocols. There would have been little reason for anyone to adopt RSA.</p>

    <p class="text-gray-300"><span class="math">\\bullet</span> What if the ideas described in §10 for finding discrete logs on an elliptic curve <span class="math">E</span> over <span class="math">\\mathbb{F}_{q^{m}}</span> — Weil descent followed by index calculus on a jacobian group, or index calculus directly on <span class="math">E</span> using points with <span class="math">x</span>-coordinate in <span class="math">\\mathbb{F}_{q}</span> as the factor base — had been proposed in the late 1980s or early 1990s? At that time it was generally assumed that any finite field could be used in ECC, and the choice should depend only on convenience. In fact, some people proposed using fields of the form <span class="math">\\mathbb{F}_{q^{m}}</span> with <span class="math">q</span> a prime or a power of 2 of intermediate size (say, 8 or 32 bits). The faster-than-squareroot and even subexponential algorithms for some elliptic curves over such “weak” fields would have come as a shock, and opponents of ECC could have easily used the discovery of such algorithms as a reason not to have confidence in elliptic curves. As it happened, however, by the late 1990s implementers were almost exclusively using either prime fields or prime degree extensions of <span class="math">\\mathbb{F}_{2}</span>, to which those algorithms do not apply.</p>

    <p class="text-gray-300"><span class="math">\\bullet</span> What if pairing-based cryptography had been proposed just three or four years earlier, say in 1997 when “ECC Central” on the RSA website was warning of the dangers of ECC? The elliptic curve skeptics would have had a field day! “The ECC promoters are now using the very same low-embedding-degree elliptic curves that five years ago they acknowledged to be insecure and recommended avoiding!” they would have said. Some people would have hoped that by undermining confidence in pairing-based cryptography they might be able to bring down all of ECC with it. However, by 2001 the big rivalry between RSA and ECC was largely over, and hardly anyone wanted to reopen that debate.</p>

    <p class="text-gray-300">These hypothetical questions show that the particular chronology of RSA, ECC, pairing-based cryptography, and new algorithms for factoring and discrete logs has a lot to do with the history of the paradigm shift to ECC.</p>

    <h3 id="sec-42" class="text-xl font-semibold mt-8">12.2. Narrative inversion</h3>

    <p class="text-gray-300">In historical studies one often finds a wide gap between the image that a nation or group has of its past — the historical narrative — and what the record shows. In extreme cases it sometimes seems that the farther this narrative is from reality, the more adamantly people repeat it and insist on its validity. This is narrative inversion.</p>

    <p class="text-gray-300">Take the hypothetical example of a country whose official version of its history is that the guiding principle of its foreign policy has been to “defend freedom.” Even though people in other countries might see an ever-widening chasm between this national myth and the reality, the narrative continues to be a centerpiece of the belief system of millions of people, who proclaim it with increasing fervor.</p>

    <p class="text-gray-300">In the world of scholarship as well, one often encounters narrative inversion. Take, for example, the word science. Often the humanistic and social areas whose practitioners are the most insistent on using this word are those fields that have the worst track record in attempting to use scientific methodology. In the last century</p>

    <p class="text-gray-300">the term “social studies” was replaced by “social sciences,” and departments of government became departments of “political science.” Interestingly, the one profession in social studies that arguably uses a fair amount of scientific methodology and does it competently — history — has never insisted on changing its name to “historical science.”</p>

    <h3 id="sec-43" class="text-xl font-semibold mt-8">12.3. Narrative inversion in cryptography</h3>

    <p class="text-gray-300">Modern cryptography can be viewed as an applied science in the overlap between mathematics and computer science. Nevertheless, the development of various technologies for implementing secure communications continues to be as much a story of chance occurrences, mistaken interpretations, zigzags, blunders, and strokes of good luck as was the cryptography of old. It seems impossible to remove the element of contingency — of intuition and of craft.</p>

    <p class="text-gray-300">Part of the reason why cryptography has such a strong subjective element is that speculation is central to the field. When deciding on the basic type of cryptography to use (RSA or ECC, for example), when choosing the type of protocol for a given application (e.g., whether or not to use identity-based encryption), and when selecting parameters (for instance, random generation versus enhanced efficiency), one has to make a guess about future developments in order to evaluate the fundamental issue of safety of the system. One has to ask: What type of adversaries are we likely to encounter, and what will be their most likely avenues of attack? Will there be any breakthroughs in bringing down the asymptotic running time to solve any of the supposedly intractable mathematical problems? Will quantum computing (see <em>[94]</em>) ever become practical? What new “side-channel” attacks (see <em>[2, 9, 61, 62]</em>) might be devised?</p>

    <p class="text-gray-300">Perhaps it is because of this highly contingent element in the field that researchers increasingly feel the need to go out of their way to assure the public that it is rapidly becoming a science, that ironclad guarantees of security can be given (“provable security”), and that cryptographers faithfully follow the Ideal Model described in §2.</p>

    <p class="text-gray-300">Among the leading researchers in cryptography, Mihir Bellare (coinventor of the subdiscipline of <em>practice-oriented provable security</em>) has a relatively moderate view of the scientific nature of the field. On the one hand, he acknowledges that the search for suitable mathematical one-way functions — what he calls <em>atomic primitives</em> — has a large element of artistry <em>[6]</em>. But on the other hand, he thinks that the part of cryptography concerned with constructing usable cryptosystems based on these primitives is becoming a science:</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>…I’d like to claim that the design of protocols can be made a science. <em>[6]</em></p>
    </blockquote>

    <p class="text-gray-300">Other theoreticians, writing more recently, are categorical in their rejection of any notion that cryptography is not fully a science. In response to comments in <em>[57]</em> questioning the claims of “provable security” and suggesting that cryptography is “more an art than a science,” Oded Goldreich <em>[33]</em> stated that</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>…<em>cryptographic research is indeed part of science</em>. [emphasis in original]</p>
    </blockquote>

    <p class="text-gray-300">And in the preface to their recent book <em>[47]</em> Jonathan Katz and Yehuda Lindell insisted that</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>…cryptographic constructions can be proven secure with respect to a clearly-stated definition of security and relative to a well-defined cryptographic assumption. This is the essence of modern cryptography, and what has transformed cryptography from an art to a science. The importance of this idea cannot be over-emphasized. [emphasis in original]</p>
    </blockquote>

    <p class="text-gray-300">As in other cases of narrative inversion, these belabored claims inevitably bring to mind the famous line from Hamlet</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>The lady doth protest too much, methinks.</p>
    </blockquote>

    <h2 id="sec-44" class="text-2xl font-bold">13. Social Construction of Science and Technology</h2>

    <p class="text-gray-300">Until the work of Thomas Kuhn a half century ago, the term Scientific Revolution, used in the singular, referred to the birth of modern science in the 16th and 17th centuries. Kuhn, whose most famous book <em>[66]</em> appeared in 1962, used the term “scientific revolutions” in the plural to refer to the radical shifts of point of view that have punctuated the history of science. It was Kuhn who coined the term “paradigm shift” for this process — a term that was later used in many areas outside the sciences.</p>

    <p class="text-gray-300">Before Kuhn’s work, the most common view among historians was that science and technology progressed steadily toward a more accurate and complete understanding of the natural world. Mistakes were often made — and one could frequently find social and political explanations for the backward steps — but the overall pattern was to build upon the edifice constructed by earlier generations, “standing on the shoulders of giants” in Newton’s famous formulation.</p>

    <p class="text-gray-300">Kuhn, however, believed that the most important developments in the history of science occur by means of a radical challenge to earlier conceptions. In his view social and professional influences have a great effect on the direction of science as a whole, and should not be invoked simply to explain the “mistakes.” In fact, he believed in what later came to be called the “symmetry principle,” which states that historians should use the same methods to study the emergence of a scientific theory or school of thought independently of whether modern science regards the theory as correct or incorrect.</p>

    <p class="text-gray-300">In the years after Kuhn’s book appeared, this methodological principle was carried much further by other historians and philosophers, who started advocating a type of scientific relativism, according to which science has no more objective validity than anything else. Science, according to this view, is “socially constructed” just as literature, politics, and religion are. The relativist tendency in thinking about science was most pronounced among postmodernists such as Jacques Lacan, Paul Feyerabend, Vandana Shiva, and Bruno Latour.</p>

    <p class="text-gray-300">In the 1980s and 1990s as this tendency grew in strength among academics in the humanities and social studies, some scientists started to take notice. Most reacted with horror and anger at what the postmodern writers were saying. Some, such as Holton <em>[38]</em> and Gross and Levitt <em>[35]</em>, published refutations. Journalists often referred to the debate as the “science wars.”</p>

    <p class="text-gray-300">The culmination of the scientists’ counterattack on postmodern writings on science came in the form of a hoax — perhaps the most successful hoax in the history of academic writing. After two months of studying the relevant literature, physicist Alan Sokal wrote a parody of the postmodern science studies jargon in the form</p>

    <p class="text-gray-300">of an article on the “hermeneutics” of quantum gravity. He submitted it to the journal Social Text for publication. Astoundingly, the caricature was accepted, and his article <em>[100]</em> appeared in the Spring/Summer 1996 issue of the journal.</p>

    <p class="text-gray-300">Sokal’s hoax and subsequent critiques <em>[14, 101]</em> were directed against an extreme form of “science studies.” But even the more moderate sociologists of science sometimes write in a style that reveals an unmistakable undercurrent of resentment and pique toward the sciences and technology. For example, in his introduction to the book “Technology and Social Process,” B. Elliott <em>[25]</em> says:</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>Running through many of the chapters in this book… there is a concern to demystify technology. The social studies of science have shown us that the closer we get to the laboratories, to the day-to-day practice of science, and the more intimately we explore the social processes through which scientific knowledge is constituted, the less in awe of it we stand. We appreciate the looseness of its boundaries, the contested nature of its claims. Scientific research turns out to be much messier than we had perhaps supposed, its development less the product of logical and rational progression than the product of hunches, improbable connections and various struggles for power. In consequence we grow more skeptical of claims that may be made for its special, privileged status and more critical of various forms of scientific determinism. And so it is, and should be, with technology.</p>
    </blockquote>

    <p class="text-gray-300">It is tempting for scientists to revel in Sokal’s spoof of the nonsensical jargon of the postmodernists, react with annoyance to the tone of sociologists of science such as Elliott, and dismiss as ridiculous any attempt to describe a school of scientific thought as a “social construct.” But that would be a mistake.</p>

    <p class="text-gray-300">There have been many studies of the effects of such social factors as race, class, and gender on the content of scientific theories. In some areas of the sciences — especially those connected with human behavior — and in many areas of technology these studies have exposed serious methodological failings.</p>

    <p class="text-gray-300">This work in the history and sociology of science and technology on occasion can be fascinating — and it can be especially entertaining when gender bias is involved. In the sciences the influence of gender has been most pronounced in such fields as primatology, endocrinology, embryology, archaeology, and sociobiology. We’ll give brief (and admittedly superficial) descriptions of three examples.</p>

    <h3 id="sec-45" class="text-xl font-semibold mt-8">13.1. Gorillas</h3>

    <p class="text-gray-300">The field of primatology emerged toward the end of the 19th century in the wake of Darwin’s pathbreaking work on natural selection and evolution, which was popularly known as the theory that “man descended from apes.” For close to a century most primatologists visualized ape family life as conforming to Victorian views of gender roles. A now-classic example of this tendency could be seen in the primate hall of the American Museum of Natural History, which featured a majestic male silverback gorilla towering over and guarding his much smaller mate and their offspring. This memorable tableau directly replicated the stereotypical Victorian nuclear family in the primate world. Unstated anywhere in the exhibit was the fact that several large female gorillas had been shot in the mistaken belief that they were males worthy of being stuffed for the Museum. Unstated also was the fact that such a scene of a nuclear ape family would have been highly</p>

    <p class="text-gray-300">unlikely in nature <em>[36]</em>. It wasn’t until the 1960s and 1970s, with the rise of second-wave feminism and the entrance of a new generation of women into the profession, that primatologists began to systematically question the patriarchal assumptions of their older colleagues and point out that primates exhibit a surprising variety of social organizations, parenting strategies, dominance hierarchies, and male/female relations <em>[39, 103]</em>.</p>

    <h3 id="sec-46" class="text-xl font-semibold mt-8">13.2. The Hohokam</h3>

    <p class="text-gray-300">A more recent and equally amusing example of gender bias can be found in a currently fashionable trend in the study of the prehistoric Southwest of the U.S. A group of archaeologists led by Steven LeBlanc of Harvard and David Wilcox of the Museum of Northern Arizona have developed an elaborate theory of endemic warfare among the ancient Hohokam peoples of central Arizona (see <em>[50, 51]</em>). Wilcox and his coauthors describe how, while talking late at night around a campfire, they arrived at their “exciting” conclusions, which seem to be the result of lively imagination stimulated by male-to-male comradery rather than any scholarly deductions. They recount with awe and describe as “scientific” the “seminal ideas” supplied by a much-decorated veteran of the Vietnam War who visited the sites with Wilcox. Although there is scant evidence for any warfare among the Hohokam, let alone battles of epic proportions, this group of archaeologists has insisted on a version of prehistory that appears to have more to do with a modern American culture of aggressive masculinity than with the actual interactions among peoples in 14th-century Arizona.</p>

    <h3 id="sec-47" class="text-xl font-semibold mt-8">13.3. Smart houses</h3>

    <p class="text-gray-300">Examples of gender bias abound in technology. For example, the much-hyped “smart house” was analyzed in a delightful article by Anne-Jorunn Berg <em>[7]</em>. On the face of it, one would expect that efforts to automate household processes would naturally incorporate input from women, who are the primary users of technology within the home. Berg found, however, that “smart house” designers had been remarkably uninterested in grappling with such labor-intensive activities as cooking, cleaning and childcare. Instead, designers had concentrated on getting peripheral technologies to “talk” to one another through central control stations: getting lights to turn on automatically, arranging voice-activated controls for entertainment systems, etc. The closest any of the projects had come to a basic household task was the “robobutler,” which could supposedly serve drinks. But the drinks must first be made by a human and set precisely on the robobutler’s tray, at which point the robobutler could be remotely guided into the livingroom by controls much like those used for toy boats and planes. In other words, this technology was a “toy for the boys” rather than a true labor-saving advance. The core tasks that make housework so time-consuming remained untouched.</p>

    <h3 id="sec-48" class="text-xl font-semibold mt-8">13.4. The social study of technology</h3>

    <p class="text-gray-300">The social study of technology has become a subfield in its own right relatively recently — a decade or two after the emergence of the social study of science. Sociologists of technology have usually avoided the pitfalls of jargon and over-generalization that have plagued writers on the social construction of science. In part this is a conscious strategy adopted in order to avoid a repetition of the “science wars.” In the preface to the 1999 edition of their book <em>[72]</em> MacKenzie and Wajcman warn their colleagues not to repeat the mistakes of sociologists of science:</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>We fear a rerun in the social studies of technology of what has happened in the social studies of science. There, in the 1970s and 1980s,</p>
    </blockquote>

    <p class="text-gray-300">a variety of empirical studies… offered evidence that the content of scientific knowledge was influenced by the social circumstances of its production….. Those who produced this work knew well that the evidence was partial, tentative and patchy, and that the conceptual issues involved were poorly understood, but a wider audience of scholars in the humanities and social sciences grasped eagerly at the conclusion that scientific knowledge was ‘a social construct’. The notion became something of a premature orthodoxy, and too little was done to clarify what the ambiguous phrase meant…. In consequence, when some natural scientists reacted with hostility to the notion of social construction (in the ‘science wars’ debate…), the field was not as well placed as it might have been.</p>

    <p class="text-gray-300">In addition, it is easier for sociologists of technology to get a sympathetic reception from practitioners, because most leaders of the field are fully conscious of the role that economic, social and political factors play in the adoption of certain technologies and the rejection of others. A famous example was Thomas Edison (see <em>[40, 41]</em>), who was as much an entrepreneur as an inventor. Few technologists would see their work as being entirely removed from the cultural environment. In contrast, researchers in the basic sciences — especially the physical sciences and mathematics — tend to see their work as a process of discovering a set of truths that transcend the exigencies of the moment.</p>

    <p class="text-gray-300">However theoreticians in math and physics might view their work, practitioners in applied fields such as cryptography would have to be very naive in order to believe that their ideas and protocols have some sort of intrinsic value apart from human culture. It is quite a stretch to visualize RSA or ECC inhabiting a realm of Platonic Ideals side-by-side with the perfect circle, the Pythagorean theorem, and the Heisenberg uncertainty principle.</p>

    <h3 id="sec-49" class="text-xl font-semibold mt-8">13.5. Conclusion</h3>

    <p class="text-gray-300">To what extent can ideas from “social construction of technology” help us to understand the paradigm shift from RSA to ECC? Certain broad social categories do not appear to be relevant to this history; to the best of our knowledge questions of gender, race, or class have nothing to do with this story. It is perhaps particularly surprising that gender has played no discernible role, since the popular history of cryptography is intimately tied up with the military and is full of male-dominated stories of intrigue. Certainly David Kahn’s famous history of cryptography <em>[46]</em> has a notably sexist slant:</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>Four officers in GY [the cryptanalysis section of U.S. Navy intelligence in 1941], assisted by chief petty officers, stood round-the-clock watches…. GY had others on its staff, such as girl typists who also did the simple deciphering of some diplomatic messages after the watch officers and other cryptanalysts had found the keys. (<em>[46]</em>, p. 11)</p>
    </blockquote>

    <p class="text-gray-300">Nevertheless, we are aware of no examples of gender, race, or class bias influencing the direction of public key cryptography.</p>

    <p class="text-gray-300">Nor are we aware of evidence that women are especially put off by the disciplinary culture of the field — any more than in other areas of computer science, engineering, and mathematics. In fact, the proportion of prominent women researchers is probably greater than that in most of the allied fields of science. This flies in the</p>

    <p class="text-gray-300">face of some currently popular notions about women in science, according to which women by nature avoid fields where conflict and confrontation are common (see, for example, <em>[5, 32]</em>). In the case of cryptography, adversarial behavior is central to the very definition of the subject, and the “spy vs. spy” mentality of intense rivalry often seems to permeate the research community as well. Heated disputes might involve the relative merits of different types of cryptography or of different approaches to evaluating them, or such mundane matters as which of several contending research groups deserves credit for advancing a particular subfield.</p>

    <p class="text-gray-300">Just as we reject technological determinism, we should also avoid a type of equally simplistic sociological determinism that is sometimes called <em>essentialism</em>. In thinking about disciplines such as cryptography, some feminist theoreticians would reason more or less as follows: “Women by their nature are less confrontational and militaristic than men, and hence are less likely to be attracted to a field whose entire purpose is to combat adversarial behavior.” And postmodern feminist philosophers of science would also see a gender subtext in the debate over whether cryptography is more a science or an art. They would most likely claim that the very term “science” is so tied to masculinity that some cryptographers’ fixation on the word “science” to describe their field (see §12.3) is <em>prima facie</em> evidence of a male bias. (See <em>[49]</em> for a discussion of some of the fallacies in postmodern feminist views of science.)</p>

    <p class="text-gray-300">Similarly, in trying to explain the dramatic contrast between the recommendations of Brainpool and of Voltage (see §11) some might be tempted to resort to popular stereotypes of national character: “Germans are risk-averse by nature, whereas Americans have a penchant for high-stakes gambling, so that’s why German-led Brainpool was extra-cautious, whereas the American security company Voltage happily endorsed a supersingular curve.” In our opinion such attempts at explanation based on gender or national character are far-fetched and untenable.</p>

    <p class="text-gray-300">The social influences on the course of public key cryptography appear to have come not from such broad categories as gender, race, class, or nationality, but rather from certain aspects of the professional culture. This is not unusual in the history of technology. As MacKenzie and Wajcman put it,</p>

    <blockquote class="border-l-4 border-gray-600 pl-4 my-4 text-gray-400 italic">
      <p>…‘social shaping’ does not necessarily involve reference to wider societal relations such as those of class, gender and ethnicity. These <em>are</em> sometimes directly crucial… but often what is more immediately relevant are ‘local’ considerations, such as engineers’ membership of professional communities, the reward structures of those communities, and so on. (<em>[72]</em>, pp. 18-19)</p>
    </blockquote>

    <p class="text-gray-300">Our examination of the history of ECC offers no support to those who would argue that technology follows an inevitable path that is independent of societal constraints. Rather, the evidence points toward ways in which technology is socially constructed:</p>

    <p class="text-gray-300"><span class="math">\\bullet</span> <em>path-dependence</em> — the importance of timing, the role of happenstance;</p>

    <p class="text-gray-300"><span class="math">\\bullet</span> <em>the role of the military</em> in intervening at crucial stages to send the technology in a different direction from that favored by market forces;</p>

    <p class="text-gray-300"><span class="math">\\bullet</span> <em>closure</em> — the need eventually to reach a consensus and stop most debate, even if some basic questions remain unanswered;</p>

    <p class="text-gray-300"><span class="math">\\bullet</span> narrative inversion — a desire to use high-status terms such as “science” and “mathematical proof” that becomes more fervent even as the field is showing itself again and again to be as much an art as a science.</p>

    <h2 id="sec-50" class="text-2xl font-bold">14. Acknowledgments</h2>

    <p class="text-gray-300">We would like to thank Ian Blake, Claus Diem, Andreas Enge, Steven Galbraith, David Jao, Susan Landau, and Arjen Lenstra for their comments on an earlier draft of this paper.</p>

    <h2 id="sec-51" class="text-2xl font-bold">References</h2>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[1] L. Adleman, J. DeMarrais and M. Huang, A subexponential algorithm for discrete logarithms over the rational subgroup of the jacobians of large genus hyperelliptic curves over finite fields, Algorithmic Number Theory: First International Symposium, Lecture Notes in Computer Science, 877 (1994), Springer-Verlag, pp. 28-40.</li>

      <li>[2] D. Agrawal, B. Archambeault, J. Rao and P. Rohatgi, The EM side-channel(s), Cryptographic Hardware and Embedded Systems — CHES 2002, Lecture Notes in Computer Science, 2523 (2002), pp. 29-45.</li>

      <li>[3] American National Standards Institute (ANSI) X9.62, Public Key Cryptography for the Financial Services Industry: The Elliptic Curve Digital Signature Algorithm (ECDSA), 1999.</li>

      <li>[4] R. Balasubramanian and N. Koblitz, The improbability that an elliptic curve has subexponential discrete log problem under the Menezes–Okamoto–Vanstone algorithm, J. Cryptology, 11 (1998), pp. 141-145.</li>

      <li>[5] M. Belenky et al., “Women’s Ways of Knowing: The Development of Self, Voice, and Mind,” Basic Books, 1986.</li>

      <li>[6] M. Bellare, Practice-oriented provable-security, Proc. First International Workshop on Information Security (ISW ’97), Lecture Notes in Computer Science, 1396 (1998), pp. 221-231.</li>

      <li>[7] A.-J. Berg, A gendered socio-technical construction: the smart house, in “The Social Shaping of Technology,” 2nd ed., Open University Press, 1999, pp. 301-313.</li>

      <li>[8] D. Boneh and X. Boyen, Short signatures without random oracles and the SDH assumption on bilinear groups, J. Cryptology, 21 (2008), pp. 149-177.</li>

      <li>[9] D. Boneh, R. DeMillo and R. Lipton, On the importance of checking cryptographic protocols for faults, Advances in Cryptology — EUROCRYPT ’97, Lecture Notes in Computer Science, 1233 (1997), pp. 37-51.</li>

      <li>[10] D. Boneh and M. Franklin, Identity-based encryption from the Weil pairing, SIAM Journal on Computing, 32 (2003), pp. 586-615.</li>

      <li>[11] D. Boneh, B. Lynn and H. Shacham, Short signatures from the Weil pairing, Progress in Cryptology — ASIACRYPT 2001, Lecture Notes in Computer Science, 2248 (2001), pp. 514-532.</li>

      <li>[12] X. Boyen and L. Martin, Identity-Based Cryptography Standard (IBCS) #1: Supersingular curve implementations of the BF and BB1 cryptosystems, IETF RFC, December 2007; available from http://www.ietf.org/rfc/rfc5091.txt</li>

      <li>[13] E. Braun and S. Macdonald, “Revolution in Miniature: The History and Impact of Semiconductor Electronics,” Cambridge University Press, 1978.</li>

      <li>[14] J. Bricmont and A. Sokal, “Fashionable Nonsense: Postmodern Intellectuals’ Abuse of Science,” St. Martin’s Press, 1998.</li>

      <li>[15] R. Bröker, D. Charles and K. Lauter, Evaluating large degree isogenies and applications to pairing based cryptography, Pairing-Based Cryptography — Pairing 2008, Lecture Notes in Computer Science, 5209 (2008), pp. 100-112.</li>

      <li>[16] D. Brown and R. Gallant, The static Diffie-Hellman problem, http://eprint.iacr.org/2004/ 306/</li>

      <li>[17] J. Cheon, Security analysis of the Strong Diffie-Hellman Problem, Advances in Cryptology — EUROCRYPT 2006, Lecture Notes in Computer Science, 4004 (2006), pp. 1-11.</li>

      <li>[18] D. Coppersmith, Fast evaluation of logarithms in fields of characteristic two, IEEE Transactions on Information Theory, 30 (1984), pp. 587-594.</li>

    </ul>

    <p class="text-gray-300">ELLiptIC CURVE CRYPTOGRAPHY</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[19] C. Diem, On arithmetic and the discrete logarithm problem in class groups of curves, Habilitationsschrift, Universität Leipzig; available from http://www.math.uni-leipzig.de/~diem/preprints/habil.pdf</li>

      <li>[20] C. Diem, An index calculus algorithm for plane curves of small degree, Algorithmic Number Theory: Seventh International Conference, Lecture Notes in Computer Science, 4076 (2006), pp. 543-557.</li>

      <li>[21] C. Diem, P. Gaudry, N. Thériault and E. Thomé, A double large prime variation for small genus hyperelliptic index calculus, Mathematics of Computation, 76 (2007), pp. 475-492.</li>

      <li>[22] C. Diem and E. Thomé, Index calculus in class groups of non-hyperelliptic curves of genus three, J. Cryptology, 21 (2008), pp. 593-611.</li>

      <li>[23] W. Diffie and M. Hellman, New directions in cryptography, IEEE Transactions on Information Theory, 22 (1976), pp. 644-654.</li>

      <li>[24] W. Diffie and S. Landau, “Privacy on the Line: The Politics of Wiretapping and Encryption,” 2nd ed., MIT Press, 2007.</li>

      <li>[25] B. Elliott, Introduction, “Technology and Social Process,” Edinburgh University Press, 1988, pp. 1-7.</li>

      <li>[26] G. Frey and H. Rück, A remark concerning <span class="math">m</span>-divisibility and the discrete logarithm in the divisor class group of curves, Mathematics of Computation, 62 (1994), pp. 865-874.</li>

      <li>[27] S. Galbraith, Constructing isogenies between elliptic curves over finite fields, LMS Journal of Computation and Mathematics, 2 (1999), pp. 118-138.</li>

      <li>[28] S. Galbraith and V. Rotger, Easy decision Diffie-Hellman groups, LMS Journal of Computation and Mathematics, 7 (2004), pp. 201-218.</li>

      <li>[29] R. Gallant, R. Lambert and S. Vanstone, Improving the parallelized Pollard lambda search on an anomalous binary curve, Mathematics of Computation, 69 (2000), pp. 1699-1705.</li>

      <li>[30] P. Gaudry, Index calculus for abelian varieties and the elliptic curve discrete logarithm problem, Journal of Symbolic Computation, to appear; available from http://www.loria.fr/~gaudry/papers.en.</li>

      <li>[31] P. Gaudry, F. Hess and N. Smart, Constructive and destructive facets of Weil descent on elliptic curves, J. Cryptology, 15 (2002), pp. 19-34.</li>

      <li>[32] C. Gilligan, “In a Different Voice: Psychological Theory and Women’s Development,” Harvard University Press, 1982.</li>

      <li>[33] O. Goldreich, On post-modern cryptography, available from http://eprint.iacr.org/2006/461/</li>

      <li>[34] D. Gordon, Discrete logarithms in <span class="math">GF(p)</span> using the number field sieve, SIAM Journal on Discrete Mathematics, 6 (1993), pp. 124-138.</li>

      <li>[35] P. Gross and N. Levitt, “Higher Superstition: The Academic Left and Its Quarrels with Science,” Johns Hopkins University Press, 1994.</li>

      <li>[36] D. Haraway, “Primate Visions: Gender, Race, and Nature in the World of Modern Science,” Routledge, 1989.</li>

      <li>[37] F. Hess, Generalizing the GHS attack on the elliptic curve discrete logarithm problem, LMS Journal of Computation and Mathematics, 7 (2004), pp. 167-192.</li>

      <li>[38] G. Holton, “Science and Anti-Science,” Harvard University Press, 1993.</li>

      <li>[39] S. Hrdy, “The Woman That Never Evolved,” Harvard University Press, 1981.</li>

      <li>[40] T. Hughes, The seamless web: technology, science, et cetera, et cetera, in “Technology and Social Processes,” Edinburgh University Press, 1988, pp. 9-19.</li>

      <li>[41] T. Hughes, Edison and electric light, in “The Social Shaping of Technology,” 2nd ed., Open University Press, 1999, pp. 50-63.</li>

      <li>[42] K. Ireland and M. Rosen, “A Classical Introduction to Modern Number Theory,” 2nd ed., Springer-Verlag, 1990.</li>

      <li>[43] M. Jacobson, N. Koblitz, J. Silverman, A. Stein and E. Teske, Analysis of the xedni calculus attack, Designs, Codes and Cryptography, 20 (2000), pp. 41-64.</li>

      <li>[44] D. Jao, S. Miller and R. Venkatesan, Do all elliptic curves of the same order have the same difficulty of discrete log?, Advances in Cryptology — ASIACRYPT 2005, Lecture Notes in Computer Science, 3788 (2005), pp. 21-40.</li>

      <li>[45] A. Joux, A one round protocol for tripartite Diffie-Hellman, Algorithmic Number Theory: Fourth International Symposium, Lecture Notes in Computer Science, 1838 (2000), pp. 385-393.</li>

      <li>[46] D. Kahn, “The Codebreakers: The Story of Secret Writing,” Macmillan, 1967.</li>

    </ul>

    <p class="text-gray-300">ANN HIBNER KOBLITZ, NEAL KOBLITZ, AND ALFRED MENEZES</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[47] J. Katz and Y. Lindell, “Introduction to Modern Cryptography,” CRC Press, 2007.</li>

      <li>[48] R. Kline and T. Pinch, The social construction of technology, in “The Social Shaping of Technology,” 2nd ed., Open University Press, 1999, pp. 113-115.</li>

      <li>[49] A. H. Koblitz, A historian looks at gender and science, International Journal of Science Education, 9 (1987), pp. 399-407.</li>

      <li>[50] A. H. Koblitz, Male bonding around the campfire: Constructing myths of Hohokam militarism, Men and Masculinities, 9 (2006) pp. 95-107.</li>

      <li>[51] A. H. Koblitz, Warriors, campfires, and a big stick: Modern male fantasies of Hohokam militarism, Bulletin of Old Pueblo Archaeology Center, No. 53 (2008), pp. 2-5.</li>

      <li>[52] N. Koblitz, Elliptic curve cryptosystems, Mathematics of Computation, 48 (1987), pp. 203-209.</li>

      <li>[53] N. Koblitz, Hyperelliptic cryptosystems, J. Cryptology, 1 (1989), pp. 139-150.</li>

      <li>[54] N. Koblitz, CM-curves with good cryptographic properties, Advances in Cryptology — CRYPTO ’91, Lecture Notes in Computer Science, 576 (1992), pp. 279-287.</li>

      <li>[55] N. Koblitz, An elliptic curve implementation of the finite field Digital Signature Algorithm, Advances in Cryptology — CRYPTO ’98, Lecture Notes in Computer Science, 1462 (1998), pp. 327-337.</li>

      <li>[56] N. Koblitz and A. Menezes, Pairing-based cryptography at high security levels, Proceedings of the Tenth IMA International Conference on Cryptography and Coding, Lecture Notes in Computer Science 3796 (2005), pp. 13-36.</li>

      <li>[57] N. Koblitz and A. Menezes, Another look at ‘provable security’, J. Cryptology, (2007), pp. 3-37.</li>

      <li>[58] N. Koblitz and A. Menezes, Another look at ‘provable security’. II, Progress in Cryptology — INDOCRYPT 2006, Lecture Notes in Computer Science 4329 (2006), pp. 148-175.</li>

      <li>[59] N. Koblitz and A. Menezes, Another look at generic groups, Advances in Mathematics of Communications, 1 (2007), pp. 13-28.</li>

      <li>[60] N. Koblitz and A. Menezes, Another look at non-standard discrete log and Diffie-Hellman problems, to appear in J. Mathematical Cryptology.</li>

      <li>[61] P. Kocher, Timing attacks on implementations of Diffie-Hellman, RSA, DSS, and other systems, Advances in Cryptology — CRYPTO ’96, Lecture Notes in Computer Science, 1109 (1996), pp. 104-113.</li>

      <li>[62] P. Kocher, J. Jaffe and B. Jun, Differential power analysis, Advances in Cryptology — CRYPTO ’99, Lecture Notes in Computer Science, 1666 (1999), pp. 388-397.</li>

      <li>[63] D. Kohel, Endomorphism rings of elliptic curves over finite fields, Ph.D. thesis, University of California at Berkeley, 1996.</li>

      <li>[64] M. Kraitchik, “Théorie des nombres,” vol. 1, Gauthier-Villars, 1922.</li>

      <li>[65] M. Kraitchik, “Recherches sur la théorie des nombres,” Gauthier-Villars, 1924.</li>

      <li>[66] T. Kuhn, “The Structure of Scientific Revolutions,” University of Chicago Press, 1962.</li>

      <li>[67] S. Landau, Communications security for the twenty-first century: The Advanced Encryption Standard, Notices of the AMS, 47 (2000), pp. 450-459.</li>

      <li>[68] A. K. Lenstra and E. R. Verheul, The XTR public key system, Advances in Cryptology — CRYPTO 2000, Lecture Notes in Computer Science, 1880 (2000), pp. 1-19.</li>

      <li>[69] H. W. Lenstra, Jr., Factoring integers with elliptic curves, Annals of Mathematics, 126 (1987), pp. 649-673.</li>

      <li>[70] S. Levy, “Crypto: How the Code Rebels Beat the Government – Saving Privacy in the Digital Age,” Viking Penguin, 2001.</li>

      <li>[71] M. Lochter and J. Merkle, ECC Brainpool standard curves and curve generation, IETF Internet-Draft, February 18, 2008.</li>

      <li>[72] D. MacKenzie and J. Wajcman, Preface to the second edition, and Introductory essay: The social shaping of technology, in “The Social Shaping of Technology,” 2nd ed., Open University Press, 1999, pp. xiv-xvi and 3-27.</li>

      <li>[73] L. Martin, A closer look at pairings, Presentation at the NIST workshop “Applications of Pairing Based Cryptography: Identity Based Encryption and Beyond,” June 3-4, 2008; available from http://csrc.nist.gov/groups/ST/IBE/documents/June08</li>

      <li>[74] M. Maurer, A. Menezes and E. Teske, Analysis of the GHS Weil descent attack on the ECDLP over characteristic two finite fields of composite degree, LMS Journal of Computation and Mathematics, 5 (2002), pp. 127-174.</li>

    </ul>

    <p class="text-gray-300">ELLiptic CURVE CRYPTOGRAPHY</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[75] A. Menezes, T. Okamoto and S. Vanstone, Reducing elliptic curve logarithms to logarithms in a finite field, IEEE Transactions on Information Theory, 39 (1993), pp. 1639-1646.</li>

      <li>[76] A. Menezes and M. Qu, Analysis of the Weil descent attack of Gaudry, Hess and Smart, Topics in Cryptology — CT-RSA 2001, Lecture Notes in Computer Science, 2020 (2001), pp. 308-318.</li>

      <li>[77] A. Menezes and E. Teske, Cryptographic implications of Hess’ generalized GHS attack, Applicable Algebra in Engineering, Communication and Computing, 16 (2006), pp. 439-460.</li>

      <li>[78] A. Menezes, E. Teske and A. Weng, Weak fields for ECC, Topics in Cryptology — CT-RSA 2004, Lecture Notes in Computer Science, 2964 (2004), pp. 366-386.</li>

      <li>[79] A. Miyaji, M. Nakabayashi and S. Takano, New explicit conditions of elliptic curve traces for FR-reduction, IEICE — Transactions on Fundamentals of Electronics, Communications and Computer Sciences, E84-A (2001), pp. 1234-1243.</li>

      <li>[80] V. Miller, Uses of elliptic curves in cryptography, Advances in Cryptology — CRYPTO ’85, Lecture Notes in Computer Science, 218 (1986), pp. 417-426.</li>

      <li>[81] V. Miller, Short programs for functions on curves, unpublished manuscript, 1986.</li>

      <li>[82] V. Miller, The Weil pairing, and its efficient calculation, J. Cryptology, 17 (2004), pp. 235-261.</li>

      <li>[83] D. Moody, The Diffie-Hellman problem and generalization of Verheul’s theorem, Ph.D. Thesis, University of Washington, 2009.</li>

      <li>[84] V. Müller, Fast multiplication on elliptic curves over small fields of characteristic two, J. Cryptology, 11 (1998), pp. 219-234.</li>

      <li>[85] National Institute of Standards and Technology, “Digital Signature Standard,” Federal Information Processing Standards Publication 186-2, 2000.</li>

      <li>[86] National Security Agency, The case for elliptic curve cryptography, http://www.nsa.gov/ia/industry/crypto_elliptic_curve.cfm.</li>

      <li>[87] S. Pohlig and M. Hellman, An improved algorithm for computing logarithms over <span class="math">GF(p)</span> and its cryptographic significance, IEEE Transactions on Information Theory, 24 (1978), pp. 106-110.</li>

      <li>[88] J. Pollard, Monte Carlo methods for index computation mod <span class="math">p</span>, Mathematics of Computation, 32 (1978), pp. 918-924.</li>

      <li>[89] R. Sakai, K. Ohgishi, and M. Kasahara, Cryptosystems based on pairings, Proceedings of the 2000 Symposium on Cryptography and Information Security, Okinawa, 2000.</li>

      <li>[90] O. Schirokauer, The number field sieve for primes of low hamming weight, in preparation.</li>

      <li>[91] R. Schoof, Elliptic curves over finite fields and the computation of square roots mod <span class="math">p</span>, Mathematics of Computation, 44 (1985), pp. 483-494.</li>

      <li>[92] I. Semaev, Summation polynomial and the discrete logarithm on elliptic curves, http:// eprint.iacr.org/2004/031/</li>

      <li>[93] A. Shamir, Identity-based cryptosystems and signature schemes, Advances in Cryptology — CRYPTO ’84, Lecture Notes in Computer Science, 196 (1985), pp. 277-296.</li>

      <li>[94] P. W. Shor, Polynomial-time algorithms for prime factorization and discrete logarithms on a quantum computer, SIAM Journal on Computing, 26 (1997), pp. 1484-1509.</li>

      <li>[95] J. Silverman, “The Arithmetic of Elliptic Curves,” Springer-Verlag, 1986.</li>

      <li>[96] J. Silverman, The xedni calculus and the elliptic curve discrete logarithm problem, Designs, Codes and Cryptography, 20 (2000), pp. 5-40.</li>

      <li>[97] J. Silverman, The four faces of lifting for the elliptic curve discrete logarithm problem, 11th Workshop on Elliptic Curve Cryptography, University College Dublin, September 5, 2007; available from http://mathsci.ucd.ie/~gmg/ECC2007Talks</li>

      <li>[98] J. Silverman and J. Suzuki, Elliptic curve discrete logarithms and the index calculus, Advances in Cryptology — ASIACRYPT ’98, Lecture Notes in Computer Science, 1514 (1998), pp. 110-125.</li>

      <li>[99] B. Smith, Isogenies and the discrete logarithm problem in jacobians of genus 3 hyperelliptic curves, Advances in Cryptology — EUROCRYPT 2008, Lecture Notes in Computer Science, 4965 (2008), pp. 163-180.</li>

      <li>[100] A. Sokal, Transgressing the boundaries: Toward a transformative hermeneutics of quantum gravity, Social Text, 46/47 (1996), pp. 217-252.</li>

      <li>[101] A. Sokal, “Beyond the Hoax: Science, Philosophy and Culture,” Oxford University Press, 2008.</li>

    </ul>

    <p class="text-gray-300">ANN HIBNER KOBLITZ, NEAL KOBLITZ, AND ALFRED MENEZES</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[102] J. Solinas, Efficient arithmetic on Koblitz curves, Designs, Codes and Cryptography, 19 (2000), pp. 195-249.</li>

      <li>[103] S. Strum and L. Fedigan, eds., “Primate Encounters: Models of Science, Gender, and Society,” The University of Chicago Press, 2000.</li>

      <li>[104] E. Verheul, Evidence that XTR is more secure than supersingular elliptic curve cryptosystems, Advances in Cryptology — EUROCRYPT 2001, Lecture Notes in Computer Science, 2045 (2001), pp. 195-210.</li>

      <li>[105] E. Verheul, Evidence that XTR is more secure than supersingular elliptic curve cryptosystems, J. Cryptology, 17 (2004), pp. 277-296.</li>

      <li>[106] L. Washington, “Elliptic Curves: Number Theory and Cryptography,” 2nd ed., CRC Press, 2008.</li>

      <li>[107] M. Wiener and R. Zuccherato, Faster attacks on elliptic curve cryptosystems, Selected Areas in Cryptography — SAC ’98, Lecture Notes in Computer Science, 1556 (1999), pp. 190-200.</li>

      <li>[108] D. Wolf, Assurance provider: Designing a roadmap for information security, http://www. military-information-technology.com/article.cfm?DocID=1294</li>

    </ul>

    <p class="text-gray-300">Women and Gender Studies Program, Arizona State University, Tempe, AZ 85287 U.S.A.</p>

    <p class="text-gray-300">E-mail address: koblitz@asu.edu</p>

    <p class="text-gray-300">Dept. of Mathematics, Box 354350, Univ. of Washington, Seattle, WA 98195 U.S.A.</p>

    <p class="text-gray-300">E-mail address: koblitz@math.washington.edu</p>

    <p class="text-gray-300">Dept. of Combinatorics &amp; Optimization, Univ. of Waterloo, Waterloo, Ontario N2L 3G1 Canada</p>

    <p class="text-gray-300">E-mail address: ajmeneze@uwaterloo.ca</p>`;
---

<BaseLayout title="Elliptic Curve Cryptography: The Serpentine Course of a Para... (2008/390)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2008 &middot; eprint 2008/390
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
