---
import BaseLayout from '../../layouts/BaseLayout.astro';
import PaperDisclaimer from '../../components/PaperDisclaimer.astro';
import PaperHistory from '../../components/PaperHistory.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2011/444';
const CRAWLER = 'modal-marker';
const CONVERTED_DATE = '2026-02-18';
const TITLE_HTML = 'Generalised Mersenne Numbers Revisited';
const AUTHORS_HTML = 'Robert Granger, Andrew Moss';

const CONTENT = `    <section id="abstract" class="mb-10">
      <h2 class="text-2xl font-bold">Abstract</h2>
      <p class="text-gray-300">Generalised Mersenne Numbers (GMNs) were defined by Solinas in 1999 and feature in the NIST Digital Signature Standard (FIPS 186-2) for use in elliptic curve cryptography. Their form is such that modular reduction is extremely efficient, thus making them an attractive choice for modular multiplication implementation. However, the issue of residue multiplication efficiency seems to have been overlooked. Asymptotically, using a cyclic rather than a linear convolution, residue multiplication modulo a Mersenne number is twice as fast as integer multiplication; this property does not hold for prime GMNs, unless they are of Mersenne&#x27;s form. In this work we exploit an alternative generalisation of Mersenne numbers for which an analogue of the above property --- and hence the same efficiency ratio --- holds, even at bitlengths for which schoolbook multiplication is optimal, while also maintaining very efficient reduction. Moreover, our proposed primes are abundant at any bitlength, whereas GMNs are extremely rare. Our multiplication and reduction algorithms can also be easily parallelised, making our arithmetic particularly suitable for hardware implementation. Furthermore, the field representation we propose also naturally protects against side-channel attacks, including timing attacks, simple power analysis and differential power analysis, which is essential in many cryptographic scenarios, in constrast to GMNs.</p>
      <p class="text-gray-300"><strong>Keywords:</strong> elliptic curve cryptography &middot; high-speed arithmetic &middot; generalised Mersenne numbers &middot; cyclotomic primes &middot; generalised repunit primes</p>
    </section>

    <p class="text-gray-300">The problem of how to efficiently perform arithmetic in Z/NZ is a very natural one, with numerous applications in computational mathematics and number theory, such as primality proving [1], factoring [39], and coding theory [61], for example. It is also of central importance to nearly all public-key cryptographic systems, including the Digital Signature Algorithm [21], RSA [47], and elliptic curve cryptography (ECC) [33,41]. As such, from both a theoretical and a practical perspective it is interesting and essential to have efficient algorithms for working in this ring, for either arbitrary or special moduli, with the application determining whether generality (essential for RSA for instance), or efficiency (desirable for ECC) takes precedence.</p>

    <p class="text-gray-300">Two intimately related factors need consideration when approaching this problem. First, how should one represent residues? And second, how should one perform arithmetic on these representatives? A basic answer to the first question is to use the canonical representation Z/NZ = {0, . . . , N &minus; 1}. With regard to modular multiplication for example, an obvious answer to the second question is to perform integer multiplication of residues, followed by reduction of the result modulo N, in order to obtain a canonical representative once again. Using this approach, the two components needed for efficient modular arithmetic are clearly fast integer arithmetic, and fast modular reduction.</p>

    <p class="text-gray-300"><sup>?</sup> Supported by the Claude Shannon Institute, Science Foundation Ireland Grant No. 06/MI/006.</p>

    <p class="text-gray-300">At bitlengths for which schoolbook multiplication is optimal, research on fast modular multiplication has naturally tended to focus on reducing the cost of the reduction step. For arbitrary moduli, Montgomery's celebrated algorithm [42] enables reduction to be performed for approximately the cost of a residue by residue multiplication. For the Mersenne numbers M<sup>k</sup> = 2<sup>k</sup> &minus; 1, efficient modular multiplication consists of integer residue multiplication to produce a 2k-bit product U &middot; 2 <sup>k</sup> +L, with U, L of at most k-bits, followed by a single modular addition U + L mod M<sup>k</sup> to effect the reduction, as is well known. In 1999 Solinas proposed an extension of this method to a larger class of integers: the Generalised Mersenne Numbers (GMNs) [53]. As they are a superset, GMNs are more numerous than the Mersenne numbers and hence contain more primes, yet incur little additional overhead in terms of performance [11]. In 2000, NIST recommended ten fields for use in the ECDSA: five binary fields and five prime fields, and due to their performance characteristics the latter of these are all GMNs [21], which range from 192 to 521 bits in size.</p>

    <p class="text-gray-300">For the GMNs recommended by NIST, there is no interplay between the residue multiplication and reduction algorithms, each step being treated separately with respect to optimisation. On the other hand, at asymptotic bitlengths the form of the modulus may be effectively exploited to speed up the residue multiplication step. For the Mersenne numbers M<sup>k</sup> in particular, modular multiplication can be performed for any k using a cyclic convolution effected by a discrete weighted transform [16, &sect;3.1]. As such, multiplication modulo Mersenne numbers is approximately twice as fast as multiplication of integers of the same bitlength, for which a linear convolution is required, as each multiplicand must be padded with k zeros before a cyclic convolution of length 2k can be performed. For Montgomery multiplication at asymptotic bitlengths, the reduction step can be made 25% cheaper, again by using a cyclic rather than a linear convolution for one of the required multiplications [46]. However, since the multiplication step is oblivious to the form of the modulus, it seems unlikely to possess the same efficiency benefits that the Mersenne numbers enjoy. These considerations raise the natural question of whether there exists a similar residue multiplication speed up at bitlengths for which schoolbook multiplication is optimal? Certainly for the modulus N = 2<sup>k</sup> , such a speed up can be achieved, since the upper half words of the product can simply be ignored. However, this modulus is unfortunately not at all useful for ECC.</p>

    <p class="text-gray-300">In this work we answer the above question affirmatively, using an alternative generalisation of Mersenne numbers, which has several desirable features:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>&minus; Simple. Our proposed family is arguably a far more natural generalisation of Mersenne numbers than Solinas', and gives rise to beautiful multiplication and reduction algorithms.</li>
      <li>&minus; Abundant. Our primes are significantly more numerous than the set of prime GMNs and are abundant for all tested bitlengths; indeed their number can be estimated using Bateman and Horn's quantitative version [3] of Schinzel and Sierpi&acute;nski's &quot;Hypothesis H&quot; [49].</li>
      <li>&minus; Fast multiplication. Our residue multiplication is nearly twice as fast as multiplication of integer residues.</li>
      <li>&minus; Fast reduction. Our reduction has linear complexity and is particularly efficient for specialised parameters, although such specialisation comes at the cost of reducing the number of primes available.</li>
      <li>&minus; Parallelisable. Both multiplication and reduction can be easily parallelised, making our arithmetic particularly suitable for hardware implementation.</li>
      <li>&minus; Side-channel secure. Our representation naturally protects against well-known sidechannel attacks on ECC (see [10, ch. IV] for an overview), in contrast to the NIST GMNs,</li>
    </ul>

    <p class="text-gray-300">see [48] and [51, &sect;3.2]. This includes timing attacks [35, 57], simple power analysis [48] and differential power analysis [36].</p>

    <p class="text-gray-300">This article provides an introductory (and comprehensive) theoretical framework for the use of our proposed moduli. It thus serves as a foundation for a new approach to the secure and efficient implementation of prime fields for ECC, both in software and in hardware. At a high level, our proposal relies on the combination of a remarkable algebraic identity used by Nogami, Saito, and Morikawa in the context of extension fields [44], together with the residue representation and optimisation of the reduction method proposed by Chung and Hasan [14], which models suitable prime fields as the quotient of an integer lattice by a particular equivalence relation. To verify the validity of our approach, we also provide a proof-of-concept implementation that is already competitive with the current fastest modular multiplication algorithms at contemporary ECC security levels [5, 6, 22, 23, 27, 40].</p>

    <p class="text-gray-300">The sequel is organised as follows. In &sect;2 we present some definitions and recall related work. In &sect;3 we describe the basis of our arithmetic, then in &sect;4-6 we present details of our residue multiplication, reduction and representation respectively. In &sect;7 we show how to ensure I/O stability for modular multiplication, then in &sect;8 we put everything together into a full modular multiplication algorithm. We then address other arithmetic operations and give a brief treatment of side-channel secure ECC in &sect;9, and in &sect;10 show how to generate suitable parameters. In &sect;11 we present our implementation results and finally, in &sect;12 we draw some conclusions.</p>

    <p class="text-gray-300">In this section we introduce the cyclotomic primes and provide a summary of related work. We begin with the following definition.</p>

    <p class="text-gray-300">Definition 1. For n &ge; 1 let &zeta;<sup>n</sup> be a primitive n-th root of unity. The n-th cyclotomic polynomial is defined by</p>

    <p class="text-gray-300"><span class="math">$\\Phi_n(x) = \\prod_{(k,n)=1} (x - \\zeta_n^k) = \\prod_{d|n} (1 - x^{n/d})^{\\mu(d)},</span>$</p>

    <p class="text-gray-300">where &micro; is the M&uml;obius function.</p>

    <p class="text-gray-300">Two basic properties of the cyclotomic polynomials are that they have integer coefficients, and are irreducible over Z. These two properties ensure that the evaluation of a cyclotomic polynomial at an integer argument will also be an integer, and that this integer will not inherit a factorisation from one in Z[x]. One can therefore ask whether or not these polynomials ever assume prime values at integer arguments, which leads to our next definition.</p>

    <p class="text-gray-300">Definition 2. For n &ge; 1 and t &isin; Z, if p = &Phi;n(t) is prime, we call p an n-th cyclotomic prime, or simply a cyclotomic prime.</p>

    <p class="text-gray-300">Note that for all primes p, we have p = &Phi;1(p + 1) = &Phi;2(p &minus; 1), and so trivially all primes are cyclotomic primes. These instances are also trivial in the context of the algorithms we present for performing arithmetic modulo these primes, since in both cases the cyclotomic polynomials are linear and our algorithms reduce to ordinary Montgomery arithmetic. Hence for the remainder of the article we assume n &ge; 3.</p>

    <p class="text-gray-300">In addition to being prime-evaluations of cyclotomic polynomials, note that for a cyclotomic prime  <span class="math">p = \\Phi_n(t)</span> , the field  <span class="math">\\mathbb{F}_p</span>  can be modelled as the quotient of the ring of integers of the n-th cyclotomic field  <span class="math">\\mathbb{Q}(\\zeta_n)</span> , by the prime ideal  <span class="math">\\pi = \\langle p, \\zeta_n - t \\rangle</span> . This is precisely how one would represent  <span class="math">\\mathbb{F}_p</span>  when applying the Special Number Field Sieve to solve discrete logarithms in  <span class="math">\\mathbb{F}_p</span> , for example [38]. Hence our nomenclature for these primes seems apt. This interpretation of  <span class="math">\\mathbb{F}_p</span>  for p a cyclotomic prime is implicit within the arithmetic we develop here, albeit only insofar as it provides a theoretical context for it; this perspective offers no obvious insight into how to perform arithmetic efficiently and the algorithms we develop make no use of it at all. Similarly, the method of Chung and Hasan [14] upon which our residue representation is based can be seen as arising in exactly the same way for the much larger set of primes they consider, with the field modelled as a quotient of the ring of integers of a suitable number field by a degree one prime ideal, just as for the cyclotomic primes.</p>

      <h3 id="sec-2.1" class="text-xl font-semibold mt-8">2.1 Low redundancy cyclotomic primes</h3>

    <p class="text-gray-300">The goal of the present work is to provide efficient algorithms for performing  <span class="math">\\mathbb{F}_p</span>  arithmetic, for  <span class="math">p = \\Phi_n(t)</span>  a cyclotomic prime. As will become clear from our exposition, in order to exploit the available cyclic structure &mdash; for both multiplication and reduction &mdash; we do not use the field  <span class="math">\\mathbb{Z}/\\Phi_n(t)\\mathbb{Z}</span> , but instead embed into the slightly larger ring  <span class="math">\\mathbb{Z}/(t^n-1)\\mathbb{Z}</span>  if n is odd, and  <span class="math">\\mathbb{Z}/(t^{n/2}+1)\\mathbb{Z}</span>  if n is even. In each case, using the larger ring potentially introduces an expansion factor e(n) into the residue representation. One can alternatively view this in terms of a redundancy measure r(n), where r = e - 1. Since using a larger ring for arithmetic will potentially be slower, we now identify three families of cyclotomic polynomials for which the above embeddings have low redundancy.</p>

    <p class="text-gray-300">For n even, there is a family of cases for which the above embedding does not introduce any redundancy, namely for  <span class="math">n=2^k</span> , since  <span class="math">\\Phi_{2^k}(t)=t^{2^{k-1}}+1=t^{2^k/2}+1</span> , and hence e=1 and r=0. When t=2 these are of course the Fermat numbers, and for general t these integers are known as Generalised Fermat Numbers (GFNs). It is expected that for each k there are infinitely many t for which  <span class="math">t^{2^k}+1</span>  is prime [18, &sect;3].</p>

    <p class="text-gray-300">If n=2p for p prime, then  <span class="math">\\Phi_{2p}(t)=t^{p-1}-t^{p-2}+\\cdots+t-1=(t^p+1)/(t+1)</span>  and</p>

    <p class="text-gray-300">If n=2p for p prime, then  <span class="math">\\Phi_{2p}(t)=t^{p-1}-t^{p-2}+\\cdots+t-1=(t^p+1)/(t+1)</span>  and in this case e=p/(p-1) and r=1/(p-1). The primality of these numbers was studied in [19], and while they apparently do not have a designation in the literature, one can see that by substituting t with -t in the third family below produces this one. For general even n we have  <span class="math">e=n/2\\phi(n)</span>  and  <span class="math">r=(n-2\\phi(n))/2\\phi(n)</span> , with  <span class="math">\\phi(\\cdot)</span>  Euler's totient function, which is the degree of  <span class="math">\\Phi_n(x)</span> . Hence amongst those even n which are not a power of 2, this family produces the successive local minima of r.</p>

    <p class="text-gray-300">For odd n, we have  <span class="math">e = n/\\phi(n)</span>  and  <span class="math">r = (n-\\phi(n))/\\phi(n)</span> . The successive local minima of r occur at n=p for p prime, in which case  <span class="math">\\Phi_p(t)=t^{p-1}+t^{p-2}+\\cdots+t+1=(t^p-1)/(t-1)</span> , also with r=1/(p-1). When t=2 these are of course the Mersenne numbers, and in analogy with the case of Fermat numbers, it would be natural to refer to these integers for general t as Generalised Mersenne Numbers, particularly as one can show they share the aforementioned asymptotic efficiency properties of the Mersenne numbers, while Solinas' GMNs do not, unless they are of Mersenne's form. However, this family of numbers is known in the literature as generalised repunits [17,52,58], since their base-t expansion consists entirely of 1's. Therefore for the sake of uniform nomenclature, we use the following definition.</p>

    <p class="text-gray-300"><strong>Definition 3.</strong> For m + 1 an odd prime let</p>

    <p class="text-gray-300"><span class="math">$p = \\Phi_{m+1}(t) = t^m + t^{m-1} + \\dots + t + 1.</span>$</p>

    <p class="text-gray-300">We call such an integer a Generalised Repunit; when p is prime we call it a Generalised Repunit Prime (GRP).</p>

    <p class="text-gray-300">We have developed modular multiplication algorithms for both GRPs and GFNs. In terms of efficiency, for GRPs and GFNs of the same bitlength the respective multiplication algorithms require exactly the same number of word-by-word multiplications. Also, our reduction algorithms for both GRPs and GFNs are virtually identical. However, the multiplication algorithm for GFNs is far less elegant, is not perfectly parallelisable and contains more additions. Furthermore, for a given bitlength there are fewer efficient GFN primes than there are GRPs &mdash; as the bitlength of GFNs doubles as k is incremented &mdash; and the I/O stability analysis for multiplication modulo a GRP is far simpler. Therefore in this exposition we focus on algorithms for performing arithmetic modulo GRPs and their analysis only. Note that the studies of GRPs [17,58] consider only very small t and large m, whereas we will be interested in t approximately the word base of the target architecture, and m the number of words in the prime whose field arithmetic we are to implement. Hence one expects (and finds) there to be very many GRPs for any given relevant bitlength, see &sect;10.</p>

      <h3 id="sec-2.2" class="text-xl font-semibold mt-8">2.2 Related work</h3>

    <p class="text-gray-300">In the context of extension fields, let m + 1 be prime and let p be a primitive root modulo m + 1. Then Fp<sup>m</sup> = Fp[x]/(&Phi;m+1(x)Fp[x]). In the binary case, i.e., p = 2, several authors have proposed the use of this polynomial &mdash; also known as the all-one polynomial (AOP) to obtain efficient multiplication algorithms [9, 29, 50, 59]. All of these rely on the observation that the field F2[x]/(&Phi;m+1(x)F2[x]) embeds into the ring F2[x]/((x <sup>m</sup>+1 + 1)F2[x]) &mdash; referred to by Silverman [50] as the &quot;ghost bit&quot; basis &mdash; which possesses a particularly nice cyclic structure, but introduces some redundancy. Similarly, this idea applies to any cyclotomic polynomial, and several authors have investigated this strategy, embedding suitably defined extension fields into the ring F2[x]/((x <sup>n</sup> + 1)F2[x]) [20, 24, 60].</p>

    <p class="text-gray-300">For odd characteristic extension fields, Silverman noted that the &quot;ghost bit&quot; basis for p = 2 extends easily to larger p [50], while Kwon et al. have explored this idea further [37]. Central to our application is the work of Nogami, Saito and Morikawa [44], who used the AOP to obtain a very fast multiplication algorithm, see &sect;4. The use of cyclotomic polynomials in extension field arithmetic is therefore well studied. In the context of prime fields however, the present work appears to be the first to transfer ideas for cyclotomic polynomials from the domain of extension field arithmetic to prime field arithmetic, at least for the relatively small bitlengths for which schoolbook multiplication is optimal.</p>

    <p class="text-gray-300">With regard to the embedding of a prime field into a larger integer ring, the idea of operand scaling was introduced by Walter in order to obtain a desired representation in the higherorder bits [54], which aids in the estimation of the quotient when using Barrett reduction [2]. Similarly, Ozturk et al. proposed using fields with characteristics dividing integers of the form 2<sup>k</sup> &plusmn; 1, with particular application to ECC [45]. As stated in the introduction, there are numerous very efficient prime field ECC implementations [5, 6, 23, 27, 40]. While the moduli used in these instances permit fast reduction algorithms, and the implementations are highly optimised, it would appear that none of them permit the same residue multiplication speed up that we present here, which is one of the central distinguishing features of the present work.</p>

    <section id="sec-3" class="mb-10">
      <h2 class="text-2xl font-bold">3 GRP Field Representation</h2>

    <p class="text-gray-300">In this section we present a sequence of representations of  <span class="math">\\mathbb{F}_p</span> , with p a GRP, the final one being the target representation which we use for our arithmetic. We recall the mathematical framework of Chung-Hasan arithmetic, in both the general setting and as specialised to GRPs, focusing here on the underlying theory, deferring explicit algorithms for residue multiplication, reduction and representation until &sect;4-6.</p>

      <h3 id="sec-3.1" class="text-xl font-semibold mt-8">3.1 Chung-Hasan arithmetic</h3>

    <p class="text-gray-300">We now describe the ideas behind Chung-Hasan arithmetic [12&ndash;14]. The arithmetic was developed for a class of integers they term low-weight polynomial form integers (LWPFIs), whose definition we now recall.</p>

    <p class="text-gray-300"><strong>Definition 4.</strong> An integer p is a low-weight polynomial form integer (LWPFI), if it can be represented by a monic polynomial  <span class="math">f(t) = t^n + f_{n-1}t^{n-1} + \\cdots + f_1t + f_0</span> , where t is a positive integer and  <span class="math">|f_i| \\leq \\xi</span>  for some small positive integer  <span class="math">\\xi &lt; t</span> .</p>

    <p class="text-gray-300">Note that if for a given LWPFI each  <span class="math">f_i \\in \\{\\pm 1, 0\\}</span>  and  <span class="math">t = 2^k</span> , then it is a GMN, as defined by Solinas [53]. The key idea of Chung and Hasan is to perform arithmetic modulo p using representatives from the polynomial ring  <span class="math">\\mathbb{Z}[T]/(f(T)\\mathbb{Z}[T])</span> . To do so, one uses the natural embedding  <span class="math">\\psi : \\mathbb{F}_p \\hookrightarrow \\mathbb{Z}[T]/(f(T)\\mathbb{Z}[T])</span>  obtained by taking the base t expansion of an element of  <span class="math">\\mathbb{F}_p</span>  in the canonical representation  <span class="math">\\mathbb{F}_p = \\{0, \\ldots, p-1\\}</span> , and substituting T for t. To compute  <span class="math">\\psi^{-1}</span>  one simply makes the inverse substitution and evaluates the expression modulo p.</p>

    <p class="text-gray-300">The reason for using this ring is straightforward: since  <span class="math">\\psi^{-1}</span>  is a homomorphism, when one computes  <span class="math">z(T) = x(T) \\cdot y(T)</span>  in  <span class="math">\\mathbb{Z}[T]</span> , reducing the result modulo f(T) to give w(T) does not change the element of  <span class="math">\\mathbb{F}_p</span>  represented by z(T), i.e., if  <span class="math">z(T) \\equiv w(T) \\pmod{f(T)}</span> , then  <span class="math">z(t) \\equiv w(t) \\pmod{p}</span> , since p = f(t). Furthermore, since f(T) has very small coefficients, w(T) can be computed from z(T) using only additions and subtractions. Hence given the degree 2(n-1) product of two degree n-1 polynomials in  <span class="math">\\mathbb{Z}[T]</span> , its degree n-1 representation in  <span class="math">\\mathbb{Z}[T]/(f(T)\\mathbb{Z}[T])</span>  can be computed very efficiently. Note that for non-low-weight polynomials this would no longer be the case.</p>

    <p class="text-gray-300">The only problem with this approach is that when computing z(T) as above, the coefficients of z(T), and hence w(T), will be approximately twice the size of the inputs' coefficients, and if further operations are performed the representatives will continue to expand. Since for I/O stability one requires that the coefficients be approximately the size of t after each modular multiplication or squaring, one must somehow reduce the coefficients of w(T) to obtain a standard, or reduced representative, while ensuring that  <span class="math">\\psi^{-1}(w(T))</span>  remains unchanged.</p>

    <p class="text-gray-300">Chung and Hasan refer to this issue as the <em>coefficient reduction problem</em> (CRP), and developed three solutions in their series of papers on LWPFI arithmetic [12&ndash;14]. Each of these solutions is based on an underlying lattice, although this was only made explicit in [14]. Since the lattice interpretation is the most elegant and simplifies the exposition, in the sequel we opt to develop the necessary theory for GRP arithmetic in this setting.</p>

      <h3 id="sec-3.2" class="text-xl font-semibold mt-8">3.2 Chung-Hasan representation for GRPs</h3>

    <p class="text-gray-300">Let  <span class="math">p = \\Phi_{m+1}(t)</span>  be a GRP. Our goal is to develop arithmetic for  <span class="math">\\mathbb{F}_p</span> , and we begin with the canonical representation  <span class="math">\\mathbb{F}_p = \\mathbb{Z}/\\Phi_{m+1}(t)\\mathbb{Z}</span> . As stated in &sect;2.1, the first map in our chain</p>

    <p class="text-gray-300">of representations takes the canonical ring and embeds it into  <span class="math">\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span> , for which the identity map suffices. To map back, one reduces a representative modulo p. We then apply the Chung-Hasan transformation of &sect;3.1, which embeds the second ring into  <span class="math">\\mathbb{Z}[T]/(T^{m+1}-1)\\mathbb{Z}[T]</span> , by taking the base t expansion of a canonical residue representative in  <span class="math">\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span> , and substituting T for t. We call this map  <span class="math">\\psi</span> . To compute  <span class="math">\\psi^{-1}</span>  one simply makes the inverse substitution and evaluates the expression modulo  <span class="math">t^{m+1}-1</span> .</p>

    <p class="text-gray-300">Note that the codomain of  <span class="math">\\psi</span>  may be regarded as an (m+1)-dimensional vector space over  <span class="math">\\mathbb{Z}</span> , equipped with the natural basis  <span class="math">\\{T^m, \\ldots, T, 1\\}</span> . In particular, for  <span class="math">x(T) \\in \\mathbb{Z}[T]/(T^{m+1} - 1)\\mathbb{Z}[T]</span> , where</p>

    <p class="text-gray-300"><span class="math">$x(T) = x_m T^m + \\ldots + x_1 T + x_0,</span>$</p>

    <p class="text-gray-300">one can consider x(T) to be a vector  <span class="math">\\overline{\\mathbf{x}} = [x_m, \\dots, x_0] \\in \\mathbb{Z}^{m+1}</span> . Since  <span class="math">\\mathbb{Z}^{m+1}</span>  has elements whose components are naturally unbounded, for each  <span class="math">x \\in \\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span>  there are infinitely many elements of  <span class="math">\\mathbb{Z}^{m+1}</span>  that map via  <span class="math">\\psi^{-1}</span>  to x. Therefore in order to obtain a useful isomorphism directly between  <span class="math">\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span>  and  <span class="math">\\mathbb{Z}^{m+1}</span> , we identify two elements of  <span class="math">\\mathbb{Z}^{m+1}</span>  whenever they map via  <span class="math">\\psi^{-1}</span>  to the same element of  <span class="math">\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span> , i.e.,</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{x}} \\sim \\overline{\\mathbf{y}} \\iff \\psi^{-1}(\\overline{\\mathbf{x}}) \\equiv \\psi^{-1}(\\overline{\\mathbf{y}}) \\pmod{t^{m+1} - 1},</span>$
(3.1)</p>

    <p class="text-gray-300">and take the image of  <span class="math">\\psi</span>  to be the quotient of  <span class="math">\\mathbb{Z}^{m+1}</span>  by this equivalence relation. Pictorially, we thus have:</p>

    <p class="text-gray-300"><span class="math">$\\mathbb{F}_p \\subset \\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z} \\cong \\mathbb{Z}^{m+1}/\\sim</span>$</p>

    <p class="text-gray-300">As mentioned in &sect;3.1, for each coset in  <span class="math">\\mathbb{Z}^{m+1}/\\sim</span> , we should like to use a minimal, or in some sense 'small' representative, in order to facilitate efficient arithmetic after a multiplication or a squaring, for example. Since we know that the base-t expansion of every  <span class="math">x \\in \\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span>  gives one such representative for each coset in  <span class="math">\\mathbb{Z}^{m+1}/\\sim</span> , for a reduction algorithm we just need to be able to find it, or at least one whose components are of approximately the same size. Chung and Hasan related finding such 'nice' or reduced coset representatives to solving a computational problem in an underlying lattice, which we now recall.</p>

      <h3 id="sec-3.3" class="text-xl font-semibold mt-8">3.3 Lattice interpretation</h3>

    <p class="text-gray-300">Given an input vector  <span class="math">\\overline{\\mathbf{z}}</span> , which is the output of a multiplication or a squaring, a coefficient reduction algorithm should output a vector  <span class="math">\\overline{\\mathbf{w}}</span>  such that  <span class="math">\\overline{\\mathbf{w}} \\sim \\overline{\\mathbf{z}}</span> , in the sense of (3.1), whose components are approximately the same size as t. As observed in [14], the equivalence relation (3.1) is captured by an underlying lattice, and finding  <span class="math">\\overline{\\mathbf{w}}</span>  is tantamount to solving an instance of the <em>closest vector problem</em> (CVP) in this lattice. To see why this is, we first fix some notation as in [14].</p>

    <p class="text-gray-300">Let  <span class="math">\\overline{\\mathbf{u}}</span>  and  <span class="math">\\overline{\\mathbf{v}}</span>  be vectors in  <span class="math">\\mathbb{Z}^{m+1}</span>  such that the following condition is satisfied:</p>

    <p class="text-gray-300"><span class="math">$[t^m,\\ldots,t,1]\\cdot\\overline{\\mathbf{u}}^T\\equiv[t^m,\\ldots,t,1]\\cdot\\overline{\\mathbf{v}}^T\\pmod{t^{m+1}-1}</span>$</p>

    <p class="text-gray-300">Then we say that  <span class="math">\\overline{\\mathbf{u}}</span>  is congruent to  <span class="math">\\overline{\\mathbf{v}}</span>  modulo  <span class="math">t^{m+1}-1</span>  and write this as  <span class="math">\\overline{\\mathbf{u}} \\cong_{t^{m+1}-1} \\overline{\\mathbf{v}}</span> . Note that this is exactly the same as saying  <span class="math">\\psi^{-1}(\\overline{\\mathbf{u}}) \\equiv \\psi^{-1}(\\overline{\\mathbf{v}})</span>  (mod  <span class="math">t^{m+1}-1</span> ), and so  <span class="math">\\overline{\\mathbf{u}} \\sim \\overline{\\mathbf{v}} \\iff \\overline{\\mathbf{u}} \\cong_{t^{m+1}-1} \\overline{\\mathbf{v}}</span> .</p>

    <p class="text-gray-300">Similarly, but abusing notation slightly, for any integer  <span class="math">b \\neq t^{m+1} - 1</span>  (where b is typically a power of the word base of the target architecture), we write  <span class="math">\\overline{\\mathbf{u}} \\cong_b v</span>  for some integer</p>

    <p class="text-gray-300">v satisfying  <span class="math">[t^m, \\ldots, t, 1] \\cdot \\overline{\\mathbf{u}}^T \\equiv v \\pmod{b}</span> , and say  <span class="math">\\overline{\\mathbf{u}}</span>  is congruent to v modulo b, in this case. We reserve the use of ' <span class="math">\\equiv</span> ' to express a component-wise congruence relation, i.e.,  <span class="math">\\overline{\\mathbf{u}} \\equiv \\overline{\\mathbf{v}} \\pmod{b}</span> . Finally, we denote by  <span class="math">\\overline{\\mathbf{u}} \\mod b</span>  the component-wise modular reduction of  <span class="math">\\overline{\\mathbf{u}}</span>  by b.</p>

    <p class="text-gray-300">The lattice underlying the equivalence relation (3.1) can now enter the frame. Let  <span class="math">\\mathbf{V} = \\{\\overline{\\mathbf{v}}_0, \\dots, \\overline{\\mathbf{v}}_m\\}</span>  be a set of m+1 linearly independent vectors in  <span class="math">\\mathbb{Z}^{m+1}</span>  such that  <span class="math">\\overline{\\mathbf{v}}_i \\cong_{t^{m+1}-1} \\overline{\\mathbf{0}}</span> , the all zero vector, for  <span class="math">i = 0, \\dots, m</span> . Then the set of all integer combinations of elements of  <span class="math">\\mathbf{V}</span>  forms an integral lattice,  <span class="math">\\mathcal{L}(\\mathbf{V})</span> , with the property that for all  <span class="math">\\overline{\\mathbf{z}} \\in \\mathbb{Z}^{m+1}</span> , and all  <span class="math">\\overline{\\mathbf{u}} \\in \\mathcal{L}</span> , we have</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{z}} + \\overline{\\mathbf{u}} \\cong_{t^{m+1}-1} \\overline{\\mathbf{z}} \\tag{3.2}</span>$</p>

    <p class="text-gray-300">In particular, the equivalence relation (3.1) is captured by the lattice  <span class="math">\\mathcal{L}</span> , in the sense that</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{x}} \\cong_{t^{m+1}-1} \\overline{\\mathbf{y}} \\iff \\overline{\\mathbf{x}} - \\overline{\\mathbf{y}} \\in \\mathcal{L}</span>$</p>

    <p class="text-gray-300">Therefore if one selects basis vectors for  <span class="math">\\mathcal{L}</span>  that have infinity-norm approximately t, then for a given  <span class="math">\\overline{\\mathbf{z}} \\in \\mathbb{Z}^{m+1}</span> , finding the closest vector  <span class="math">\\overline{\\mathbf{u}} \\in \\mathcal{L}</span>  to  <span class="math">\\overline{\\mathbf{z}}</span>  (with respect to the infinity-norm), means the vector  <span class="math">\\overline{\\mathbf{w}} = \\overline{\\mathbf{z}} - \\overline{\\mathbf{u}}</span>  is in the fundamental domain of  <span class="math">\\mathcal{L}</span> , and so has components of the desired size. Furthermore, since  <span class="math">\\overline{\\mathbf{w}} = \\overline{\\mathbf{z}} - \\overline{\\mathbf{u}}</span> , by (3.2) we have</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{w}} \\cong_{t^{m+1}-1} \\overline{\\mathbf{z}},</span>$</p>

    <p class="text-gray-300">and hence solving the CVP in this lattice solves the CRP. In general solving the CVP is NP-hard, but since we can exhibit a good (near-othogonal) lattice basis for LWPFIs, and an excellent lattice basis for GRPs, solving it is straightforward in our case.</p>

      <h3 id="sec-3.4" class="text-xl font-semibold mt-8">3.4 Lattice basis and simple reduction</h3>

    <p class="text-gray-300">For GRPs, we use the following basis for  <span class="math">\\mathcal{L}</span> :</p>

    <p class="text-gray-300"><span class="math">$\\begin{bmatrix} 1 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 &amp; -t \\\\ -t &amp; 1 &amp; \\cdots &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; -t &amp; \\cdots &amp; 0 &amp; 0 &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; -t &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; -t &amp; 1 \\end{bmatrix}</span>$</p>

    <p class="text-gray-300"><span class="math">$(3.3)</span>$</p>

    <p class="text-gray-300">Observe that the infinity-norm of each basis vector is t, so elements in the fundamental domain will have components of the desired size, and that each basis vector is orthogonal to all others except the two adjacent vectors (considered cyclically). In order to perform a simple reduction that reduces the size of components by approximately  <span class="math">\\log_2 t</span>  bits, write each component of  <span class="math">\\overline{\\mathbf{z}}</span>  in base t:  <span class="math">z_i = z_{i,1}t + z_{i,0}</span> . If we define  <span class="math">\\overline{\\mathbf{w}}^T</span>  to be:</p>

    <p class="text-gray-300"><span class="math">$\\begin{bmatrix} z_m \\\\ z_{m-1} \\\\ \\vdots \\\\ z_1 \\\\ z_0 \\end{bmatrix} + \\begin{bmatrix} 1 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 &amp; -t \\\\ -t &amp; 1 &amp; \\cdots &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; -t &amp; \\cdots &amp; 0 &amp; 0 &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; -t &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; -t &amp; 1 \\end{bmatrix} \\begin{bmatrix} z_{m-1,1} \\\\ z_{m-2,1} \\\\ \\vdots \\\\ \\vdots \\\\ z_{0,1} \\\\ z_{m,1} \\end{bmatrix},</span>$</p>

    <p class="text-gray-300">then <sup>w</sup> <sup>&sim;</sup>=tm+1&minus;<sup>1</sup> <sup>z</sup> and each <sup>|</sup>w<sup>i</sup> | &asymp; |z<sup>i</sup> |/t, assuming |z<sup>i</sup> | &gt; t<sup>2</sup> . This was the method of reduction described in [12], which requires integer division. The idea described in [13] was based on an analogue of Barrett reduction [2]. The method we shall use, from [14], is based on Montgomery reduction [42] and for t not a power of 2 is the most efficient of the three Chung-Hasan methods.</p>

    <p class="text-gray-300">In ordinary Montgomery reduction [42], one has an integer 0 &le; Z &lt; pR which is to be reduced modulo p, an odd prime, where here R is the smallest power of the word base b larger than p. The central idea is to add a multiple of p to Z such that the result is divisible by R. Upon dividing by R, which is a simple right shift of words, the result is congruent to ZR&minus;<sup>1</sup> (mod p), and importantly is less than 2p.</p>

    <p class="text-gray-300">In the context of GRPs, let R = b <sup>q</sup> be the smallest power of b greater than t. The input to the reduction algorithm is a vector z &isin; Z <sup>m</sup>+1 for which each component is approximately R<sup>2</sup> . The natural analogue of Montgomery reduction is to add to z a vector u &isin; L whose components are also bounded by R<sup>2</sup> , such that z + u &equiv; [0, . . . , 0] (mod R). Then upon the division of each component by R, the result will be a vector w which satisfies</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{w}} \\cong_{t^{m+1}-1} (\\overline{\\mathbf{z}} + \\overline{\\mathbf{u}}) \\cdot R^{-1} \\cong_{t^{m+1}-1} \\overline{\\mathbf{z}} \\cdot R^{-1},</span>$</p>

    <p class="text-gray-300">and which has components of the desired size. While this introduces an R&minus;<sup>1</sup> term into the congruence, as with Montgomery arithmetic, one circumvents this simply by altering the original coset representation of Z/(t <sup>m</sup>+1 &minus; 1)Z, via the map x 7&rarr; xR (mod t <sup>m</sup>+1 &minus; 1), which is bijective since gcd(t <sup>m</sup>+1 &minus; 1, R) = 1, assuming t is even, see &sect;5. How then does one find a suitable lattice point u? For this one use the lattice basis (3.3), which from here on in we call L. Proposition 3 of [14] proves that det L = 1 &minus; t <sup>m</sup>+1, and so gcd(det L, R) = 1. One can therefore compute</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{u}}^T \\stackrel{\\text{def}}{=} -L^{-1} \\cdot \\overline{\\mathbf{z}}^T \\pmod{R},\\tag{3.4}</span>$</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{w}}^T \\stackrel{\\text{def}}{=} (\\overline{\\mathbf{z}}^T + L \\cdot \\overline{\\mathbf{u}}^T) / R, \\tag{3.5}</span>$</p>

    <p class="text-gray-300">giving w with the required properties. Observe that the form of these two operations is identical to Montgomery reduction, the only difference being that integer multiplication is replaced by matrix by vector multiplication. It is easy to see that this is what one requires, since for any u &isin; Z <sup>m</sup>+1, we have L &middot; u <sup>T</sup> &isin; L, and so</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{z}}^T + L \\cdot \\overline{\\mathbf{u}}^T \\cong_{t^{m+1}-1} \\overline{\\mathbf{z}}^T.</span>$</p>

    <p class="text-gray-300">Furthermore, modulo R we have</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{z}}^T + L \\cdot \\overline{\\mathbf{u}}^T = \\overline{\\mathbf{z}}^T + L \\cdot (-L^{-1} \\cdot \\overline{\\mathbf{z}}^T \\mod R) \\equiv [0, \\dots, 0]^T,</span>$</p>

    <p class="text-gray-300">ensuring the division of each component by <sup>R</sup> is exact. Hence <sup>w</sup> <sup>&sim;</sup>=tm+1&minus;<sup>1</sup> <sup>z</sup> &middot; <sup>R</sup>&minus;<sup>1</sup> , as claimed. In [14], an algorithm was given for computing u and w in (3.4) and (3.5) respectively, for an arbitrary LWPFI f(t). The number of word-by-word multiply instructions in the algorithm &mdash; which is the dominant cost &mdash; is &asymp; nq<sup>2</sup> , where n is the degree of f(t), and R = b q . In comparison, for ordinary Montgomery reduction modulo an integer of equivalent size this number is n 2 q 2 , making the former approach potentially very attractive. For our choice of primes &mdash; the GRPs &mdash; our specialisation of this algorithm is extremely efficient, as we show in &sect;5.</p>

      <h3 id="sec-3.6" class="text-xl font-semibold mt-8">3.6 High level view of Chung-Hasan arithmetic</h3>

    <p class="text-gray-300">For extension fields, there exists a natural separation between the polynomial arithmetic of the extension, and the prime subfield arithmetic, which makes respective optimisation considerations for each almost orthogonal. On the other hand, if for an LWPFI one naively attempts to use efficient techniques that are valid for extension fields, then one encounters an inherent obstruction, namely that there is no such separation between the polynomial arithmetic and the coefficient arithmetic, which leads to coefficient expansion upon performing arithmetic operations. Chung-Hasan arithmetic can be viewed as a tool to overcome this obstruction, since it provides an efficient solution to the coefficent reduction problem. In practice therefore any efficient techniques for extension field arithmetic can be ported to prime fields, whenever the prime is an LWPFI, which is precisely what we do in &sect;4.</p>

    </section>

    <section id="sec-4" class="mb-10">
      <h2 class="text-2xl font-bold">4 GRP Multiplication</h2>

    <p class="text-gray-300">In this section we detail algorithms for performing multiplication of GRP residue representatives. While for the reduction and residue representation we consider elements to be in  <span class="math">\\mathbb{Z}^{m+1}</span> , the multiplication algorithm arises from the arithmetic of the polynomial ring  <span class="math">\\mathbb{Z}[T]/(T^{m+1}-1)\\mathbb{Z}[T]</span> , and so here we use this ring to derive the multiplication formulae.</p>

      <h3 id="sec-4.1" class="text-xl font-semibold mt-8">4.1 Ordinary multiplication formulae</h3>

    <p class="text-gray-300">Let  <span class="math">\\mathcal{R} = \\mathbb{Z}[T]/(T^{m+1}-1)\\mathbb{Z}[T]</span> , and let  <span class="math">\\overline{\\mathbf{x}} = [x_m, \\dots, x_0]</span>  and  <span class="math">\\overline{\\mathbf{y}} = [y_m, \\dots, y_0]</span>  be elements in  <span class="math">\\mathcal{R}</span> . Then in  <span class="math">\\mathcal{R}</span>  the product  <span class="math">\\overline{\\mathbf{x}} \\cdot \\overline{\\mathbf{y}}</span>  is equal to  <span class="math">[z_m, \\dots, z_0]</span> , where</p>

    <p class="text-gray-300"><span class="math">$z_{i} = \\sum_{j=0}^{m} x_{\\langle j \\rangle} y_{\\langle i-j \\rangle}, \\tag{4.1}</span>$</p>

    <p class="text-gray-300">where the subscript  <span class="math">\\langle i \\rangle</span>  denotes  <span class="math">i \\pmod{m+1}</span> . This follows from the trivial property  <span class="math">T^{m+1} \\equiv 1 \\pmod{T^{m+1}-1}</span> , and that for  <span class="math">\\overline{\\mathbf{x}} = \\sum_{i=0}^m x_i T^i</span>  and  <span class="math">\\overline{\\mathbf{y}} = \\sum_{j=0}^m y_j T^j</span> , we have:</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{x}} \\cdot \\overline{\\mathbf{y}} = \\sum_{i=0}^{m} x_i \\cdot (T^i \\cdot \\overline{\\mathbf{y}}) = \\sum_{i=0}^{m} x_i \\cdot \\left(\\sum_{j=0}^{m} y_j T^{i+j}\\right)</span>$
<span class="math">$= \\sum_{i=0}^{m} x_i \\cdot \\left(\\sum_{j=0}^{m} y_{\\langle j-i \\rangle} T^j\\right) = \\sum_{j=0}^{m} \\left(\\sum_{i=0}^{m} x_i \\cdot y_{\\langle j-i \\rangle}\\right) T^j.</span>$</p>

    <p class="text-gray-300">This is of course just the cyclic convolution of  <span class="math">\\overline{\\mathbf{x}}</span>  and  <span class="math">\\overline{\\mathbf{y}}</span> .</p>

      <h3 id="sec-4.2" class="text-xl font-semibold mt-8">4.2 Multiplication formulae of Nogami <em>et al.</em></h3>

    <p class="text-gray-300">Nogami, Saito and Morikawa proposed the use of all-one polynomials (AOPs) to define extensions of prime fields [44]. In this section we will first describe their algorithm in this context, and then show how it fits into the framework developed in &sect;3.</p>

    <p class="text-gray-300">Let  <span class="math">\\mathbb{F}_p</span>  be a prime field and let  <span class="math">f(\\omega) = \\omega^m + \\omega^{m-1} + \\cdots + \\omega + 1</span>  be irreducible over  <span class="math">\\mathbb{F}_p</span> , i.e., m+1 is prime and p is a primitive root modulo m+1. Then  <span class="math">\\mathbb{F}_{p^m} = \\mathbb{F}_p[\\omega]/(f(\\omega)\\mathbb{F}_p[\\omega])</span> . Using</p>

    <p class="text-gray-300">the polynomial basis  <span class="math">\\{\\omega^m, \\omega^{m-1}, \\dots, \\omega\\}</span>  &mdash; rather than the more conventional  <span class="math">\\{\\omega^{m-1}, \\dots, \\omega, 1\\}</span>  &mdash; elements of  <span class="math">\\mathbb{F}_{p^m}</span>  are represented as vectors of length m over  <span class="math">\\mathbb{F}_p</span> :</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{x}} = [x_m, \\dots, x_1] = x_m \\omega^m + x_{m-1} \\omega^{m-1} + \\dots + x_1 \\omega.</span>$</p>

    <p class="text-gray-300">Let  <span class="math">\\overline{\\mathbf{x}} = [x_m, \\dots, x_1]</span>  and  <span class="math">\\overline{\\mathbf{y}} = [y_m, \\dots, y_1]</span>  be two elements to be multiplied. For  <span class="math">0 \\le i \\le m</span> , let</p>

    <p class="text-gray-300"><span class="math">$q_i = \\sum_{j=1}^{m/2} (x_{\\langle \\frac{i}{2} + j \\rangle} - x_{\\langle \\frac{i}{2} - j \\rangle}) (y_{\\langle \\frac{i}{2} + j \\rangle} - y_{\\langle \\frac{i}{2} - j \\rangle}), \\tag{4.2}</span>$</p>

    <p class="text-gray-300">where the subscript  <span class="math">\\langle i \\rangle</span>  here, as in &sect;4.1, denotes  <span class="math">i \\pmod{m+1}</span> . One then has:</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{z}} = \\overline{\\mathbf{x}} \\cdot \\overline{\\mathbf{y}} = \\sum_{i=1}^{m} z_i \\omega^i, \\text{ with } z_i = q_0 - q_i.</span>$
(4.3)</p>

    <p class="text-gray-300">Nogami et al. refer to these coefficient formulae as the cyclic vector multiplication algorithm (CVMA) formulae. The CVMA formulae are remarkable, since the number of  <span class="math">\\mathbb{F}_p</span>  multiplications is reduced relative to the schoolbook method from  <span class="math">m^2</span>  to m(m+1)/2, but at the cost of increasing the number of  <span class="math">\\mathbb{F}_p</span>  additions from  <span class="math">m^2 - 1</span>  to 3m(m-1)/2 - 1. As alluded to in &sect;3.6, a basic insight of the present work is the observation that one may apply the expressions in (4.2) to GRP multiplication, provided that one uses the Chung-Hasan representation and reduction methodology of &sect;3, to give a full modular multiplication algorithm.</p>

    <p class="text-gray-300">Note that Karatsuba-Ofman multiplication [30] offers a similar trade-off for extension field arithmetic. Crucially however, as we show in &sect;4.6, when we apply these formulae to GRPs the number of additions required is in fact reduced. One thus expects the CVMA to be significantly more efficient at contemporary ECC bitlengths. The original proof of (4.3) given in [44] excludes some intermediate steps and so for the sake of clarity we give a full proof in &sect;4.4, beginning with the following motivation.</p>

      <h3 id="sec-4.3" class="text-xl font-semibold mt-8">4.3 Alternative bases</h3>

    <p class="text-gray-300">Observe that in the set of equations (4.2), each of the 2(m+1) coefficients  <span class="math">x_j, y_j</span>  is featured m+1 times, and so there is a nice symmetry and balance to the formulae. However due to the choice of basis, both  <span class="math">x_0</span>  and  <span class="math">y_0</span>  are implicitly assumed to be zero. The output  <span class="math">\\bar{\\mathbf{z}}</span>  naturally has this property also, and indeed if one extends the multiplication algorithm to compute  <span class="math">z_0</span>  we see that it equals  <span class="math">q_0 - q_0 = 0</span> .</p>

    <p class="text-gray-300">At first sight, the expression  <span class="math">z_i = q_0 - q_i</span>  may seem a little unnatural. It is easy to change the basis from  <span class="math">\\{\\omega^m, \\ldots, \\omega\\}</span>  to  <span class="math">\\{\\omega^{m-1}, \\ldots, \\omega, 1\\}</span> : for  <span class="math">\\overline{\\mathbf{x}} = [x_{m-1}, \\ldots, x_0]</span>  and  <span class="math">\\overline{\\mathbf{y}} = [y_{m-1}, \\ldots, y_0]</span> , we have:</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{z}} = \\overline{\\mathbf{x}} \\cdot \\overline{\\mathbf{y}} = \\sum_{i=0}^{m-1} z_i \\omega^i,</span>$</p>

    <p class="text-gray-300">resulting in the expressions  <span class="math">z_i = q_m - q_i</span> , with  <span class="math">q_i</span>  as given before. This change of basis relies on the relation</p>

    <p class="text-gray-300"><span class="math">$\\omega^m \\equiv -1 - \\omega - \\dots - \\omega^{m-1} \\bmod f(\\omega). \\tag{4.4}</span>$</p>

    <p class="text-gray-300">Note that in using this basis we have implicitly ensured that  <span class="math">x_m = y_m = 0</span>  in (4.2), rather than  <span class="math">x_0 = y_0 = 0</span> , and again the above formula is consistent since  <span class="math">z_m = q_m - q_m = 0</span> . More generally if one excludes  <span class="math">\\omega^k</span>  from the basis, then  <span class="math">x_k = y_k = 0</span>  and  <span class="math">z_i = q_k - q_i</span> .</p>

    <p class="text-gray-300">One may infer from these observations that the most natural choice of basis would seem to be  <span class="math">\\{\\omega^m, \\ldots, \\omega, 1\\}</span> , and that the expressions for  <span class="math">q_i</span>  arise from the arithmetic in the quotient ring  <span class="math">\\mathcal{R}&#x27; = \\mathbb{F}_p[\\omega]/((\\omega^{m+1}-1)\\mathbb{F}_p[\\omega])</span> , rather than  <span class="math">\\mathbb{F}_{p^m} = \\mathbb{F}_p[\\omega]/(f(\\omega)\\mathbb{F}_p[\\omega])</span> . In this case multiplication becomes</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{z}} = \\overline{\\mathbf{x}} \\cdot \\overline{\\mathbf{y}} = \\sum_{i=0}^{m-1} z_i \\omega^i = \\sum_{i=0}^{m-1} (q_m - q_i) \\omega^i = \\sum_{i=0}^m -q_i \\omega^i,</span>$</p>

    <p class="text-gray-300">where for the last equality we have again used equation (4.4).</p>

      <h3 id="sec-4.4" class="text-xl font-semibold mt-8">4.4 Derivation of coefficient formulae</h3>

    <p class="text-gray-300">We now derive the CVMA formulae of (4.2). Let  <span class="math">\\overline{\\mathbf{x}} = [x_m, \\dots, x_0] = \\sum_{i=0}^m x_i \\omega^i</span> , and  <span class="math">\\overline{\\mathbf{y}} = [y_m, \\dots, y_0] = \\sum_{i=0}^m y_i \\omega^i</span> . Then in the ring  <span class="math">\\mathcal{R}&#x27;</span> , as in (4.1) the product  <span class="math">\\overline{\\mathbf{x}} \\cdot \\overline{\\mathbf{y}}</span>  is equal to  <span class="math">\\sum_{i=0}^m z_i \\omega^i</span> , where</p>

    <p class="text-gray-300"><span class="math">$z_i = \\sum_{i=0}^m x_{\\langle j \\rangle} y_{\\langle i-j \\rangle}.</span>$</p>

    <p class="text-gray-300">Of crucial importance is the following identity. For  <span class="math">0 \\le i \\le m</span>  we have:</p>

    <p class="text-gray-300"><span class="math">$2\\sum_{j=0}^{m} x_{\\langle j\\rangle} y_{\\langle i-j\\rangle} - 2\\sum_{j=0}^{m} x_{\\langle j\\rangle} y_{\\langle j\\rangle} = -\\sum_{j=0}^{m} (x_{\\langle j\\rangle} - x_{\\langle i-j\\rangle}) (y_{\\langle j\\rangle} - y_{\\langle i-j\\rangle}). \\tag{4.5}</span>$</p>

    <p class="text-gray-300">To verify this identity observe that when one expands the terms in the right-hand side, the two negative sums cancel with the second term on the left-hand side, since both are over a complete set of residues modulo m+1. Similarly the two positive sums are equal and therefore cancel with the convolutions in the first term on the left-hand side. We now observe that there is some redundancy in the right-hand side of (4.5), in the following sense. First, observe that</p>

    <p class="text-gray-300"><span class="math">$\\sum_{j=0}^m x_{\\langle \\frac{i}{2}+j\\rangle} y_{\\langle \\frac{i}{2}-j\\rangle} = \\sum_{j=0}^m x_{\\langle \\frac{i}{2}+(j-\\frac{i}{2})\\rangle} y_{\\langle \\frac{i}{2}-(j-\\frac{i}{2})\\rangle} = \\sum_{j=0}^m x_{\\langle j\\rangle} y_{\\langle i-j\\rangle}.</span>$</p>

    <p class="text-gray-300">One can therefore rewrite the right-hand side of (4.5) as:</p>

    <p class="text-gray-300"><span class="math">$-\\sum_{i=0}^{m} (x_{\\langle \\frac{i}{2}+j \\rangle} - x_{\\langle \\frac{i}{2}-j \\rangle}) (y_{\\langle \\frac{i}{2}+j \\rangle} - y_{\\langle \\frac{i}{2}-j \\rangle}). \\tag{4.6}</span>$</p>

    <p class="text-gray-300">Noting that the j=0 term of expression (4.6) is zero, we rewrite it as:</p>

    <p class="text-gray-300"><span class="math">$-\\sum_{j=1}^{m/2}(x_{\\langle\\frac{i}{2}+j\\rangle}-x_{\\langle\\frac{i}{2}-j\\rangle})(y_{\\langle\\frac{i}{2}+j\\rangle}-y_{\\langle\\frac{i}{2}-j\\rangle})-\\sum_{j=m/2+1}^{m}(x_{\\langle\\frac{i}{2}+j\\rangle}-x_{\\langle\\frac{i}{2}-j\\rangle})(y_{\\langle\\frac{i}{2}+j\\rangle}-y_{\\langle\\frac{i}{2}-j\\rangle}),</span>$</p>

    <p class="text-gray-300">which in turn becomes</p>

    <p class="text-gray-300"><span class="math">$-\\sum_{j=1}^{m/2}(x_{\\langle\\frac{i}{2}+j\\rangle}-x_{\\langle\\frac{i}{2}-j\\rangle})(y_{\\langle\\frac{i}{2}+j\\rangle}-y_{\\langle\\frac{i}{2}-j\\rangle})-\\sum_{j=1}^{m/2}(x_{\\langle\\frac{i}{2}-j\\rangle}-x_{\\langle\\frac{i}{2}+j\\rangle})(y_{\\langle\\frac{i}{2}-j\\rangle}-y_{\\langle\\frac{i}{2}+j\\rangle}),</span>$</p>

    <p class="text-gray-300">and then upon negating the two terms in the second summation, we finally have</p>

    <p class="text-gray-300"><span class="math">$-\\sum_{j=0}^m(x_{\\langle\\frac{i}{2}+j\\rangle}-x_{\\langle\\frac{i}{2}-j\\rangle})(y_{\\langle\\frac{i}{2}+j\\rangle}-y_{\\langle\\frac{i}{2}-j\\rangle})=2\\sum_{j=1}^{m/2}(x_{\\langle\\frac{i}{2}+j\\rangle}-x_{\\langle\\frac{i}{2}-j\\rangle})(y_{\\langle\\frac{i}{2}+j\\rangle}-y_{\\langle\\frac{i}{2}-j\\rangle}).</span>$</p>

    <p class="text-gray-300">Hence (4.5) becomes</p>

    <p class="text-gray-300"><span class="math">$\\sum_{j=0}^{m} x_{\\langle j \\rangle} y_{\\langle i-j \\rangle} = \\sum_{j=0}^{m} x_{\\langle j \\rangle} y_{\\langle j \\rangle} - \\sum_{j=1}^{m/2} (x_{\\langle \\frac{i}{2} + j \\rangle} - x_{\\langle \\frac{i}{2} - j \\rangle}) (y_{\\langle \\frac{i}{2} + j \\rangle} - y_{\\langle \\frac{i}{2} - j \\rangle}). \\tag{4.7}</span>$</p>

    <p class="text-gray-300">Equation (4.7) gives an expression for the coefficients of the product  <span class="math">\\overline{\\mathbf{z}}</span>  of elements  <span class="math">\\overline{\\mathbf{x}}</span>  and  <span class="math">\\overline{\\mathbf{y}}</span> , in the ring  <span class="math">\\mathcal{R}&#x27;</span> . Assuming these are computed using the more efficient right-hand side, in order to restrict back to  <span class="math">\\mathbb{F}_p[\\omega]/(f(\\omega)\\mathbb{F}_p[\\omega])</span> , one can reduce the resulting polynomial  <span class="math">\\overline{\\mathbf{z}}</span>  by  <span class="math">f(\\omega)</span> . Note however that one does not need to use a smaller basis &agrave; la Nogami  <span class="math">et\\ al.</span>  in &sect;4.2 or &sect;4.3, but can reduce by  <span class="math">f(\\omega)</span>  implicitly, without performing any computation. Indeed, letting  <span class="math">\\langle \\overline{\\mathbf{x}}, \\overline{\\mathbf{y}} \\rangle = \\sum_{j=0}^m x_{\\langle j \\rangle} y_{\\langle j \\rangle}</span> , we have:</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{z}} = \\sum_{i=0}^{m} z_i \\omega^i = \\sum_{i=0}^{m} (-q_i + \\langle \\overline{\\mathbf{x}}, \\overline{\\mathbf{y}} \\rangle) \\omega^i = \\sum_{i=0}^{m} -q_i \\omega^i + \\langle \\overline{\\mathbf{x}}, \\overline{\\mathbf{y}} \\rangle \\sum_{i=0}^{m} \\omega^i</span>$</p>

    <p class="text-gray-300"><span class="math">$\\equiv \\sum_{i=0}^{m} -q_i \\omega^i \\pmod{f(\\omega)}.</span>$
(4.8)</p>

    <p class="text-gray-300">Therefore the first term on the right-hand side of (4.7) vanishes, so that one need not even compute it. Thus using the arithmetic in  <span class="math">\\mathcal{R}&#x27;</span>  but implicitly working modulo  <span class="math">f(\\omega)</span>  is more efficient than performing arithmetic in  <span class="math">\\mathcal{R}&#x27;</span>  alone. This is somewhat fortuitous as it means that while the multiply operation in (4.8) is not correct in  <span class="math">\\mathcal{R}&#x27;</span> , nevertheless, when one maps back to  <span class="math">\\mathbb{F}_p[\\omega]/(f(\\omega)\\mathbb{F}_p[\\omega])</span> , it is correct.</p>

      <h3 id="sec-4.5" class="text-xl font-semibold mt-8">4.5 Application to GRPs</h3>

    <p class="text-gray-300">Since equation (4.5) is an algebraic identity, it is easy to see that exactly the same argument applies in the context of GRPs, and we can replace the formulae (4.1) with the CVMA formulae (4.2). Since reduction in the ring  <span class="math">\\mathcal{R} = \\mathbb{Z}[T]/(T^{m+1}-1)\\mathbb{Z}[T]</span>  has a particularly nice form for GRPs, we choose to use the full basis for  <span class="math">\\mathcal{R}</span>  and hence do not reduce explicitly modulo  <span class="math">\\Phi_{m+1}(T)</span>  to obtain a smaller basis. This also has the effect of eliminating the need to perform the addition of  <span class="math">q_0</span>  (or  <span class="math">q_m</span> , or whichever term one wants to eliminate when one reduces modulo  <span class="math">\\Phi_{m+1}(T)</span> ), simplifying the multiplication algorithm further. Absorbing the minus sign into the  <span class="math">q_i</span> , Algorithm 1 details how to multiply residue representatives.</p>

    <p class="text-gray-300">Remark 1. Observe that each component of  <span class="math">\\bar{\\mathbf{z}}</span>  may be computed entirely independently of the others. Hence using m+1 processors rather than 1, it would be possible to speed up the execution time of Algorithm 1 by a factor of m+1, making it particularly suitable for hardware implementation. In &sect;5 we consider the parallelisation of our reduction algorithms as well.</p>

    <h3 id="sec-misc-1" class="text-xl font-semibold mt-8">ALGORITHM 1: GRP MULTIPLICATION</h3>

    <p class="text-gray-300"><span class="math">\\begin{array}{ll} \\text{INPUT:} &amp; \\overline{\\mathbf{x}} = [x_m, \\dots, x_0], \\overline{\\mathbf{y}} = [y_m, \\dots, y_0] \\in \\mathbb{Z}^{m+1} \\\\ \\text{OUTPUT:} &amp; \\overline{\\mathbf{z}} = [z_m, \\dots, z_0] \\in \\mathbb{Z}^{m+1} \\\\ &amp; \\text{where } \\overline{\\mathbf{z}} \\cong_{\\varPhi_{m+1}(t)} \\overline{\\mathbf{x}} \\cdot \\overline{\\mathbf{y}} \\end{array}</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><p class="text-gray-300">For i = m to 0 do:</p></li>
      <li><p class="text-gray-300"><span class="math">$z_i \\leftarrow \\sum_{j=1}^{m/2} (x_{\\langle \\frac{i}{2}-j \\rangle} - x_{\\langle \\frac{i}{2}+j \\rangle}) \\cdot (y_{\\langle \\frac{i}{2}+j \\rangle} - y_{\\langle \\frac{i}{2}-j \\rangle})</span>$</p></li>
      <li><p class="text-gray-300">Return  <span class="math">\\overline{z}</span></p></li>
    </ol>

      <h3 id="sec-4.6" class="text-xl font-semibold mt-8">4.6 Cost comparison</h3>

    <p class="text-gray-300">We here use a simple cost model to provide a measure of the potential performance improvement achieved by using Algorithm 1, rather than schoolbook multiplication of residues. We assume the inputs to the multiplication algorithm have coefficients bounded by  <span class="math">b^q</span> , i.e., they each consist of q words. Let M(q,q) be the cost of a q-word by q-word schoolbook multiplication, and let A(q,q) be the cost of an ition of two q-word values. We assume that A(2q,2q)=2A(q,q) and that there is no overflow beyond 2q words in the resulting vector components, which one can ensure by selecting appropriate GRPs, see &sect;7. The cost of the multiplication using each method is as follows.</p>

    <p class="text-gray-300"><strong>GRP schoolbook multiplication</strong> Working modulo  <span class="math">T^m + \\cdots + T + 1</span>  and using a basis consisting of m terms only, the number of coefficient multiplications is  <span class="math">m^2</span> , while the number of double-length additions is also  <span class="math">m^2</span> . Hence the total cost is simply</p>

    <p class="text-gray-300"><span class="math">$m^2 \\cdot M(q,q) + 2m^2 \\cdot A(q,q).</span>$</p>

    <p class="text-gray-300">Note that computing the convolution (4.1) costs</p>

    <p class="text-gray-300"><span class="math">$(m+1)^2 \\cdot M(q,q) + 2m(m+1) \\cdot A(q,q),</span>$</p>

    <p class="text-gray-300">which is costlier since it requires embedding into  <span class="math">\\mathcal{R}</span> , which introduces some redundancy.</p>

    <p class="text-gray-300"><strong>CVMA formulae</strong> For each  <span class="math">z_i</span>  computing each term in the sum costs M(q,q) + 2A(q,q), and so computing all these terms costs  <span class="math">\\frac{m}{2} \\cdot (M(q,q) + 2A(q,q))</span> . The cost of adding these is  <span class="math">(\\frac{m}{2} - 1)A(2q, 2q) = (m-2) \\cdot A(q,q)</span> . For all the m+1 terms  <span class="math">z_i</span>  the total cost is therefore</p>

    <p class="text-gray-300"><span class="math">$\\frac{m(m+1)}{2} \\cdot M(q,q) + 2(m^2 - 1) \\cdot A(q,q).</span>$</p>

    <p class="text-gray-300">Therefore by using the CVMA formulae, we reduce not only the number of multiplications, but also the number of additions (by 2), contrary to the case of field extensions, for which the CVMA formulae increases the number of additions by nearly 50%. We have thus found an analogue of the asymptotic cyclic versus linear convolution speed up at small bitlengths for which schoolbook multiplication is optimal, for GRPs.</p>

    </section>

    <section id="sec-5" class="mb-10">
      <h2 class="text-2xl font-bold">5 GRP Reduction</h2>

    <p class="text-gray-300">In this section we detail reduction algorithms for two types of GRPs. The first, Algorithm 2, assumes only that t is even, which provides the minimum possible restriction on the form of the resulting GRPs for any given bitlength. All such GRPs can therefore be implemented with code parametrised by the single variable t, which may be beneficial for some applications. Supposing that  <span class="math">R = b^q &gt; t</span> , then as with Montgomery reduction, it is more efficient to reduce components not by R as in (3.4) and (3.5), but by b sequentially q times. In Algorithm 2 each reduction therefore reduces the input's components by approximately  <span class="math">\\log_2 b</span>  bits.</p>

    <p class="text-gray-300">The second reduction method as detailed in Algorithm 3 is a specialisation of Algorithm 2. It assumes that  <span class="math">t \\equiv 0 \\mod 2^l</span>  for some l &gt; 1, and each application of the reduction function reduces the input's components by approximately l bits. Algorithm 3 is potentially far more efficient than Algorithm 2, depending on the form of t. Ideally one should choose a t for which  <span class="math">l &gt; (\\log_2 t)/2</span>  so that two applications of the reduction function are sufficient in order to produce components of the desired size, which is minimal. In general for other values of l a larger number of reductions may be needed, which we consider in &sect;7. In constrast to Algorithm 2, which is designed for generality, Algorithm 3 is geared towards high-speed reduction. The trade-off arising here is that there will naturally be far fewer GRPs of this restricted form. We also present a modification of Algorithm 3, which is slightly more efficient in practice, in Algorithm 4.</p>

      <h3 id="sec-5.1" class="text-xl font-semibold mt-8">5.1 GRP reduction: t even</h3>

    <p class="text-gray-300">Following &sect;3.5, in equation (3.4) we need the matrix  <span class="math">-L^{-1}</span> :</p>

    <p class="text-gray-300"><span class="math">$-L^{-1} = \\frac{1}{t^{m+1} - 1} \\begin{bmatrix} 1 &amp; t^m &amp; \\cdots &amp; t^3 &amp; t^2 &amp; t \\\\ t &amp; 1 &amp; \\cdots &amp; t^4 &amp; t^3 &amp; t^2 \\\\ t^2 &amp; t &amp; \\cdots &amp; t^5 &amp; t^4 &amp; t^3 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ t^{m-1} &amp; t^{m-2} &amp; \\cdots &amp; t &amp; 1 &amp; t^m \\\\ t^m &amp; t^{m-1} &amp; \\cdots &amp; t^2 &amp; t &amp; 1 \\end{bmatrix}.</span>$
(5.1)</p>

    <p class="text-gray-300">The form of L and  <span class="math">-L^{-1}</span>  allows one to compute  <span class="math">\\overline{\\mathbf{u}} = -L^{-1} \\cdot \\overline{\\mathbf{z}} \\mod b</span>  and  <span class="math">L \\cdot \\overline{\\mathbf{u}}</span> , computed in equation (3.5), very efficiently. Since t is even, the following vector may be computed. Let t[0] be the least significant digit of t, written in base b, and let</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{V}} \\stackrel{\\text{def}}{=} \\frac{1}{t[0]^{m+1} - 1} [t[0]^m, t[0]^{m-1}, \\dots, t[0], 1] \\mod b.</span>$</p>

    <p class="text-gray-300">Algorithm 2 details how to reduce a given an input vector  <span class="math">\\overline{\\mathbf{z}}</span>  by b, modulo  <span class="math">t^{m+1}-1</span> , given the precomputed vector  <span class="math">\\overline{\\mathbf{V}}</span> . Observe that Algorithm 2 greatly simplifies the reduction algorithm originally given in [14]. This is possible since for  <span class="math">t^{m+1}-1</span>  one can interleave the computation of the vectors  <span class="math">\\overline{\\mathbf{u}}</span>  and  <span class="math">\\overline{\\mathbf{w}}</span>  defined in (3.4) and (3.5) respectively. This has two benefits. First, as one computes each component of  <span class="math">\\overline{\\mathbf{w}}</span>  sequentially, one need only store a single component of  <span class="math">\\overline{\\mathbf{u}}</span> , rather than m+1. Second, since when one computes  <span class="math">L \\cdot \\overline{\\mathbf{u}}</span>  one needs to compute  <span class="math">t \\cdot u_{\\langle i+1 \\rangle}</span>  for  <span class="math">i=m,\\ldots,0</span>  (in line 3), one obtains  <span class="math">t[0] \\cdot u_i</span>  (the first term on right-hand side of line 4) for free by computing the full product  <span class="math">t \\cdot u_{\\langle i+1 \\rangle}</span>  first. One therefore avoids recomputing the least significant digit of  <span class="math">t \\cdot u_{\\langle i+1 \\rangle}</span>  in each loop iteration. In fact one can do this for any polynomial</p>

    <p class="text-gray-300">t <sup>m</sup>+1 &minus; c, with exactly the same algorithm, the only difference being in the definition of V, where t <sup>m</sup>+1 &minus; c becomes the denominator. For polynomials with other non-zero coefficients, this does not seem possible, and so Algorithm 2 seems likely to be the most efficient Chung-Hasan reduction possible with this minimal restriction on the form of t.</p>

    <pre><code class="language-text">INPUT: z = [zm, . . . , z0] &isin; Z
                           m+1
OUTPUT: redb(z) where redb(z) &sim;=tm+1&minus;1 z &middot; b
                                          &minus;1
1. Set u0 &larr; (
               Pm
                 i=0 Vi
                       &middot; zi
                         [0]) mod b
2. For i = m to 0 do:
3. vi &larr; t &middot; uhi+1i
4. ui &larr; (vi
                [0] &minus; zi
                       [0]) mod b
5. wi &larr; (zi + ui &minus; vi)/b
6. Return w
</code></pre>

    <p class="text-gray-300">It is straightforward to verify that Algorithm 2 correctly produces an output vector in the correct congruency class, via a sequence of simple transformations of [14, Algorithm 3]. However we do not do so here, since we are mainly interested in the more efficient Algorithms 3 and 4.</p>

    <p class="text-gray-300">Remark 2. Note that in the final loop iteration, u<sup>0</sup> from line 1 is recomputed, which is therefore unnecessary. However, we chose to write the algorithm in this form to emphasise its cyclic structure. Indeed, there is no need to compute u<sup>0</sup> first; if one cyclically rotates V by j places to the left, then the vector w to be added to z in (3.5) is rotated j places to the left also. One can therefore compute each coefficient of red1b(z) independently of the others using a rotated definition for V (or equivalently by rotating the input z ). This demonstrates that a parallelised version of the reduction algorithm with m + 1 processors is feasible. However, as each processor requires the least significant word of each component of z, this necessitates a synchronised broadcast before each invocation of the reduction function. In this scenario the reduction time would be proportional to the number of such broadcasts and reductions required, independently of m + 1.</p>

    <p class="text-gray-300">In the ideal case that t = 2<sup>l</sup> , we see that such a GRP would be a GMN. In this case, one can use the reduction method detailed in &sect;3.4 without resorting to using its Montgomery version at all. Multiplication would also be faster thanks to Nogami's formulae. Unfortunately, such GRPs seem to be very rare. It is easy to show that if t = 2<sup>l</sup> with l &gt; 1 and &Phi;m+1(t) is prime, then l = m + 1. Testing the first few cases, we find prime GRPs for l = 2, 3, 7, 59 but no others for prime l &lt; 400. Note that these primes contradict Dubner's assertion that no such GRPs exist [17, &sect;2]. Since for l = 59 the corresponding GRP has 3422 bits, this is already out of our target range for ECC, so we need not worry about such GRPs.</p>

    <p class="text-gray-300">Hoping not to cause confusion, in this subsection we now let b = 2<sup>l</sup> where l is not necessarily and usually not the word size of the target architecture. We denote the cofactor of b in t by c (which by the above discussion we assume is &gt; 1), so that t = b &middot; c. Algorithm 3 details how to reduce a given an input vector z by b, modulo t <sup>m</sup>+1 &minus; 1.</p>

    <p class="text-gray-300">INPUT: z = [zm, . . . , z0] &isin; Z m+1 OUTPUT: redb(z) where redb(z) <sup>&sim;</sup>=tm+1&minus;<sup>1</sup> <sup>z</sup> &middot; <sup>b</sup> &minus;1</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>For i = m to 0 do:</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>w<sup>i</sup> &larr; (z<sup>i</sup> + (&minus;z<sup>i</sup> mod b))/b &minus; c &middot; (&minus;zhi+1<sup>i</sup> mod b)</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Return w</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">A simple proof of correctness of Algorithm 3 comes from the specialisation of Algorithm 2. Since t &equiv; 0 mod b, writing t in base b, the vector V becomes</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{V}} \\stackrel{\\text{def}}{=} [0, \\dots, 0, -1] \\mod b.</span>$</p>

    <p class="text-gray-300">Hence for line 1 of Algorithm 2 we have</p>

    <p class="text-gray-300"><span class="math">$u_0 \\leftarrow -z_0[0] \\bmod b</span>$
.</p>

    <p class="text-gray-300">Since in line 4 of Algorithm 2, we have v<sup>i</sup> &equiv; 0 mod b, we deduce that u<sup>i</sup> = &minus;z<sup>i</sup> mod b, and hence we can eliminate u<sup>i</sup> altogether. Each loop iteration then simplifies to</p>

    <p class="text-gray-300"><span class="math">$v_i \\leftarrow t \\cdot (-z_{\\langle i+1 \\rangle} \\bmod b)</span>$</p>

    <p class="text-gray-300"><span class="math">$w_i \\leftarrow (z_i + (-z_i \\bmod b) - v_i)/b</span>$
(5.2)</p>

    <p class="text-gray-300">Upon expanding (5.2), we obtain</p>

    <p class="text-gray-300"><span class="math">$w_i \\leftarrow (z_i + (-z_i \\bmod b))/b - t \\cdot (-z_{\\langle i+1 \\rangle} \\bmod b)/b</span>$</p>

    <p class="text-gray-300">=  <span class="math">(z_i + (-z_i \\bmod b))/b - c \\cdot (-z_{\\langle i+1 \\rangle} \\bmod b),</span></p>

    <p class="text-gray-300">as required. However since we did not provide a proof of correctness of Algorithm 2, we also give a direct proof as follows. Observe that modulo t <sup>m</sup>+1 &minus; 1, we have</p>

    <p class="text-gray-300"><span class="math">$\\psi^{-1}(\\overline{\\mathbf{w}}) \\equiv \\sum_{i=0}^{m} w_i t^i</span>$</p>

    <p class="text-gray-300"><span class="math">$\\equiv \\sum_{i=0}^{m} [(z_i + (-z_i \\bmod b))/b - c \\cdot (-z_{\\langle i+1 \\rangle} \\bmod b)] t^i</span>$</p>

    <p class="text-gray-300"><span class="math">$\\equiv \\sum_{i=0}^{m} (z_i/b) t^i + \\sum_{i=0}^{m} (-z_i \\bmod b))/b) t^i - \\sum_{i=0}^{m} ((-z_{\\langle i+1 \\rangle} \\bmod b)/b) t^{i+1}</span>$</p>

    <p class="text-gray-300"><span class="math">$\\equiv \\sum_{i=0}^{m} z_i t^i/b \\pmod{t^{m+1} - 1}</span>$</p>

    <p class="text-gray-300">as required. In terms of operations that may be performed very efficiently, we alter Algorithm 3 slightly to give Algorithm 4, which has virtually the same proof of correctness as the one just given.</p>

    <h2 id="sec-misc-2" class="text-2xl font-bold">Algorithm 4: <span class="math">\\operatorname{red}_{b}(\\overline{\\mathbf{z}})</span></h2>

    <pre><code class="language-text">INPUT: \\overline{\\mathbf{z}} = [z_m, \\dots, z_0] \\in \\mathbb{Z}^{m+1}

OUTPUT: \\operatorname{red}_b(\\overline{\\mathbf{z}}) where \\operatorname{red}_b(\\overline{\\mathbf{z}}) \\cong_{t^{m+1}-1} \\overline{\\mathbf{z}} \\cdot b^{-1}

1. For i = m to 0 do:

2. w_i \\leftarrow z_i/b + c \\cdot (z_{\\langle i+1 \\rangle} \\bmod b)

3. Return \\overline{\\mathbf{w}}
</code></pre>

    <p class="text-gray-300">Note that the first term in line 2 of Algorithm 3 has been replaced by a division by b, which can be effected as a simple shift, while now the second term needs the positive residue modulo b, which can be extracted more efficiently. Hence Algorithm 4 is the one we use. By our previous discussion, c necessarily has Hamming weight at least two for GRPs in our desired range. By using c that have very low Hamming weight, one can effect the multiplication by c by shifts and adds, rather than a multiply (or imulq) instruction. Hence for such GRPs, assuming only two invocations of Algorithm 4 are needed, reduction will be extremely efficient.</p>

    <p class="text-gray-300">Remark 3. Regarding parallelisation, observe that for m+1 processors, only the least significant word of  <span class="math">z_{\\langle i+1 \\rangle}</span>  is passed to processor i, thus reducing the broadcast requirement in comparison with Algorithm 2.</p>

    </section>

    <section id="sec-6" class="mb-10">
      <h2 class="text-2xl font-bold">6 GRP Residue Representation</h2>

    <p class="text-gray-300">So far in our treatment of both multiplication and reduction, for the sake of generality we have assumed arbitrary precision when representing GRP residues in  <span class="math">\\mathbb{Z}^{m+1}</span> . In this section we specialise to fixed precision and develop a residue representation that ensures that our chosen algorithms are efficient. Our decisions are informed purely by our chosen multiplication and reduction algorithms &mdash; Algorithms 1 and 4 &mdash; which we believe offer the best performance for GRPs for the relatively small bitlengths which are relevant to ECC. In other scenarios or if considering asymptotic performance, one would need to redesign the residue representation and multiplication algorithm accordingly.</p>

    <p class="text-gray-300">For  <span class="math">x \\in \\{0, ..., t^{m+1} - 1\\}</span>  we write  <span class="math">\\overline{\\mathbf{x}} = [x_m, ..., x_0]</span>  for its base-t expansion, i.e.,  <span class="math">x = \\sum_{i=0}^{m} x_i t^i</span> . The base-t representation has positive coefficients, however Algorithm 1 makes use of negative coefficients, so we prefer to incorporate these. We therefore replace the mod function in the conversion with mods, the least absolute residue function, to obtain a residue in the interval [-t/2, t/2 - 1]:</p>

    <p class="text-gray-300"><span class="math">$mods(x) = \\begin{cases} x \\mod t &amp; \\text{if } (x \\mod t) &lt; t/2, \\\\ x \\mod t - t &amp; \\text{otherwise.} \\end{cases}</span>$</p>

    <p class="text-gray-300">Using this function, Algorithm 5 converts residues modulo  <span class="math">t^{m+1}-1</span>  into the required form [14, Algorithm 1].</p>

    <pre><code class="language-text">INPUT: An integer 0 \\le x &lt; t^{m+1} - 1 OUTPUT: \\overline{\\mathbf{x}} = [x_m, \\dots, x_0] such that |x_i| \\le t/2 and \\sum_{i=0}^m x_i t^i \\equiv x \\pmod{t^{m+1} - 1} 1. For i from 0 to m do: 2. x_i \\leftarrow x \\mod t 3. x \\leftarrow (x - x_i)/t 4. x_0 \\leftarrow x_0 + x 5. Return \\overline{\\mathbf{x}} = [x_m, \\dots, x_0]
</code></pre>

    <p class="text-gray-300">The reason for line 4 in Algorithm 5 is to reduce modulo  <span class="math">t^{m+1}-1</span>  the coefficient of  <span class="math">t^{m+1}</span>  possibly arising in the expansion. Note that in this addition,  <span class="math">x \\in \\{0,1\\}</span> , and hence  <span class="math">|x_i| \\le t/2</span>  for each  <span class="math">0 \\le i \\le m</span> . By construction, we in fact have  <span class="math">-t/2 \\le x_i &lt; t/2</span>  for 1 &lt; i &lt; m while only  <span class="math">x_0</span>  can attain the upper bound of t/2. There are therefore  <span class="math">t^m(t+1)</span>  representatives in this format, thus introducing a very small additional redundancy. Letting  <span class="math">k = \\lceil \\log_2 t \\rceil</span> , if we assume  <span class="math">t \\le 2^k - 2</span> , so that  <span class="math">[-t/2, t/2] \\subset [-2^k/2, 2^k/2 - 1]</span> , then the coefficients as computed above can be represented in two's complement in k bits. In terms of efficiency, Algorithm 5 contains divisions by t, which requires not only time, but also space, which on some platforms may be at a premium. Writing  <span class="math">t = 2^l \\cdot c</span>  as in &sect;5.2, then if the cofactor  <span class="math">c = 2^{k-l} - c&#x27;</span>  with c' very small, then division by t consists of a shift right by t bits and a division by t, which can be performed efficiently using Algorithm 1 of [12].</p>

    <p class="text-gray-300">Following this conversion, it might seem desirable to define vectors whose components are in  <span class="math">[-2^k/2, 2^k/2-1]</span>  to be reduced, or canonical residue representatives. However, for efficiency purposes it is preferable to have a reduction function which, when performed sufficiently many times, outputs an element for which one does not have to perform any modular additions or subtractions to make reduced, as this eliminates data-dependent branching. A control-flow invariant reduction function is also essential to defend against side-channel attacks, see &sect;9. To obtain such a function, observe that the second term in line 2 of Algorithm 4, namely  <span class="math">c \\cdot (z_{(i+1)} \\mod b)</span> , is positive, and in the worst case is k bits long. The first term,  <span class="math">z_i/b</span> , is clearly  <span class="math">l = \\log_2 b</span>  bits shorter than  <span class="math">z_i</span> . Since one adds these the resulting value may be k+1 bits, or larger, depending on the initial length of the inputs' components. Furthermore, since we wish to allow negative components, in two's complement the output requires a further bit, giving a minimal requirement of k+2 bits. We therefore choose not to use minimally reduced elements as coset representatives in  <span class="math">\\mathbb{Z}^{m+1}/\\sim</span> , as output by Algorithm 5, but slightly larger elements, which we now define.</p>

    <p class="text-gray-300"><strong>Definition 5.</strong> We define the following set of elements of  <span class="math">\\mathbb{Z}^{m+1}</span>  to be reduced:</p>

    <p class="text-gray-300"><span class="math">$\\mathbb{I}^{m+1} = \\{ [x_m, \\dots, x_0] \\in \\mathbb{Z}^{m+1} \\mid -2^{k+1} \\le x_i &lt; 2^{k+1} \\}.</span>$
(6.1)</p>

    <p class="text-gray-300">Note that the redundancy inherent in this representation depends on how close t is to  <span class="math">2^{k+2}</span> . For a modular multiplication, we assume that the inputs are reduced. We must therefore ensure that the output is reduced also. This naturally leads one to consider I/O stability, as we do in &sect;7.</p>

    <p class="text-gray-300">Once we have a reduced representative x = &psi;(x) we also need to convert to the Montgomery domain. While one can do this in Z/(t <sup>m</sup>+1 &minus; 1)Z before applying &psi;, it is more convenient to do so in Z <sup>m</sup>+1/ &sim;. Assuming q reductions by b are sufficient to ensure I/O modular multiplication stability, we precompute &psi;(b <sup>2</sup><sup>q</sup> mod &Phi;m+1(t)) and then using Algorithms 1 and 4 compute</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{x}} \\cdot \\psi(b^{2q} \\bmod \\Phi_{m+1}(t))/b^q \\cong_{\\Phi_{m+1}(t)} \\psi(x \\cdot b^q).</span>$</p>

    <p class="text-gray-300">Similarly, to get back from the Montgomery domain, again using Algorithms 1 and 4, we compute</p>

    <p class="text-gray-300"><span class="math">$\\psi(x \\cdot b^q) \\cdot \\psi(1)/b^q \\cong_{\\varPhi_{m+1}(t)} \\psi(x).</span>$</p>

    <p class="text-gray-300">With regard to mapping back from x = [xm, . . . , x0] &isin; I <sup>m</sup>+1 to canonical residues in Z/&Phi;m+1(t)Z, one has</p>

    <p class="text-gray-300"><span class="math">$\\sum_{i=0}^{m} x_i t^i \\equiv \\sum_{i=0}^{m-1} (x_i - x_m) t^i \\pmod{\\Phi_{m+1}(t)},</span>$</p>

    <p class="text-gray-300">which can be computed efficiently by first using Horner's rule and then mapped to {0, . . . , &Phi;m+1(t)&minus; 1} by repeated additions or subtractions. In terms of operations required for ECC, we assume that the conversions are one-time computations only, with all other operations taking place in the (Montgomery) Chung-Hasan representation.</p>

    <p class="text-gray-300">In this section we analyse Algorithms 1 and 4 with a view to ensuring I/O stability for modular multiplication. We assume the following: b = 2<sup>l</sup> , t = c &middot; b where c &lt; 2 k&minus;l (and hence t &lt; 2 <sup>k</sup> &minus; 2), and that reduced elements have the form (6.1). Input elements therefore have components in I = [&minus;2 k+1 , 2 <sup>k</sup>+1 &minus; 1], and these are representable in k + 2 bits in two's complement. For simplicity and in order for our analysis to be as general as possible, we use the term single precision to mean a word base large enough to contain t &mdash; even if this in fact requires multiprecision on a given architecture &mdash; and double precision to mean twice this size. We assume that for this single precision word size w, the components of z output by Algorithm 1 are double precision. In practice one prefers to specialise to actual single precision t on a given architecture, since this obviates the need for multiprecision arithmetic; utilising the native double precision multipliers that most CPUs possess is more efficient, and reduction is also faster for smaller t since fewer iterations need be performed. We note that in constrained environments however, multiprecision may however be unavoidable.</p>

    <p class="text-gray-300">During the multiplication, terms of the form x<sup>i</sup> &minus;x<sup>j</sup> are computed, which are bounded by</p>

    <p class="text-gray-300"><span class="math">$-2^{k+2} + 1 \\le x_i - x_j \\le 2^{k+2} - 1,</span>$</p>

    <p class="text-gray-300">and which therefore fit into k+ 3 bits in two's complement. The product of two such elements is performed, giving a result</p>

    <p class="text-gray-300"><span class="math">$-2^{2k+4} + 2^{k+3} - 1 \\le (x_i - x_j) \\cdot (y_j - y_i) \\le 2^{2k+4} - 2^{k+3} + 1,</span>$</p>

    <p class="text-gray-300">which fits into 2k + 5 bits in two's complement. One then adds m/2 of these terms, giving a possible expansion of up to dlog<sup>2</sup> m/2e bits, which must be double precision. We therefore have a constraint on the size of t (in addition to the constraint t &lt; 2 <sup>k</sup> &minus; 2) in terms of m:</p>

    <p class="text-gray-300"><span class="math">$\\lceil \\log_2\\left(m/2\\right) \\rceil + 2k + 5 \\le 2w \\tag{7.1}</span>$</p>

    <p class="text-gray-300">This inequality determines a constraint on the size of t, given m and w. Assuming (7.1) is satisfied, one then needs to find the minimum value of b = 2<sup>l</sup> such that the result of the multiplication step, when reduced by b a specified number of times, say q, outputs a reduced element. This needs to be done for each (m, k) found in the procedure above. Any power of 2 larger than this minimum will obviously be satisfactory also, however minimising b maximises the set of prime-producing cofactors c, which as stated in &sect;5 may be useful in some scenarios.</p>

    <p class="text-gray-300">In &sect;6, we showed that one application of Algorithm 4 shortened an input's components by l&minus;1 bits, unless the components were already shorter than (k + 2)+ (l&minus;1) bits. Therefore stipulating that q reductions suffice to produce a reduced output, we obtain a bound on l in the following manner. Let</p>

    <p class="text-gray-300"><span class="math">$h = \\lceil \\log_2{(m/2)} \\rceil + 2k + 5</span>$</p>

    <p class="text-gray-300">Then after one reduction, the maximum length of a component is h &minus; l + 1. Similarly after q reductions, the maximum length is max{h &minus; q(l &minus; 1), k + 2}, and we need this to be at most k + 2. Hence our desired condition is</p>

    <p class="text-gray-300"><span class="math">$h - q(l-1) \\le k+2</span>$</p>

    <p class="text-gray-300">Solving for l, we have</p>

    <p class="text-gray-300"><span class="math">$l \\ge 1 + \\frac{\\lceil \\log_2\\left(m/2\\right) \\rceil + k + 3}{q} \\tag{7.2}</span>$</p>

    <p class="text-gray-300">Using these inequalities it is an easy matter to generate triples (m + 1, k, l) which ensure multiplication stability for any w and q. For example, for w = 64, Tables 1 and 2 give sets of stable parameters for q = 2 and q = 3 respectively.</p>

    <p class="text-gray-300">Table 1. Stable parameters for w = 64, q = 2</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">m + 1 k</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">l</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">c &lt; dlog2<br>pe</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">61 33 2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">28</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">122</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">61 34 2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">27</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">244</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60 34 2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">26</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">360</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">11</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60 34 2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">26</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">600</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">13</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60 34 2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">26</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">720</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">17</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60 34 2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">26</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">960</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">Table 2. Stable parameters for w = 64, q = 3</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">m + 1 k</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">l</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">c &lt; dlog2<br>pe</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">61 23 2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">38</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">122</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">61 23 2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">38</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">244</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60 23 2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">37</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">360</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">11</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60 23 2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">37</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">600</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">13</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60 23 2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">37</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">720</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">17</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60 23 2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">37</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">960</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">The final column gives the maximum bitlength of a GRP that can be represented with those parameters, though of course by using smaller c one can opt for smaller primes, and the corresponding minimum value of l reduces according to (7.2). To generate suitable GRPs, a simple linear search over the values of c of the desired size is sufficient, checking whether or not  <span class="math">\\Phi_{m+1}(2^l \\cdot c)</span>  is prime, see &sect;10.</p>

    <p class="text-gray-300">For completeness we now piece together the parts treated thus far into a full modular multiplication algorithm, where in Algorithm 6 we assume q reductions by b are required for I/O stability and in line 4 either Algorithm 2 or Algorithm 4 is used according to the form of b.</p>

    <h3 id="sec-misc-3" class="text-xl font-semibold mt-8">Algorithm 6: GRP MODMUL</h3>

    <pre><code class="language-text">\\begin{split} &amp;\\text{INPUT:} \\quad \\overline{\\mathbf{x}} = [x_m, \\dots, x_0], \\overline{\\mathbf{y}} = [y_m, \\dots, y_0] \\in \\mathbb{I}^{m+1} \\\\ &amp;\\text{OUTPUT:} \\quad \\overline{\\mathbf{z}} = [z_m, \\dots, z_0] \\in \\mathbb{I}^{m+1} \\quad \\text{where} \\quad \\overline{\\mathbf{z}} \\cong_{\\varPhi_{m+1}(t)} \\overline{\\mathbf{x}} \\cdot \\overline{\\mathbf{y}} \\cdot b^{-q} \\\\ &amp;\\text{1.} \\quad \\text{For } i = m \\quad \\text{to } 0 \\quad \\text{do:} \\\\ &amp;\\text{2.} \\quad z_i \\leftarrow \\sum_{j=1}^{m/2} (x_{\\left\\langle \\frac{i}{2} - j \\right\\rangle} - x_{\\left\\langle \\frac{i}{2} + j \\right\\rangle}) \\cdot (y_{\\left\\langle \\frac{i}{2} + j \\right\\rangle} - y_{\\left\\langle \\frac{i}{2} - j \\right\\rangle}) \\\\ &amp;\\text{3.} \\quad \\text{For } k \\quad \\text{from } 0 \\quad \\text{to } q - 1 \\quad \\text{do:} \\\\ &amp;\\text{4.} \\quad \\overline{\\mathbf{z}} \\leftarrow \\operatorname{red}_b(\\overline{\\mathbf{z}}) \\\\ &amp;\\text{5.} \\quad \\text{Return } \\overline{\\mathbf{z}} \\end{split}
</code></pre>

    <p class="text-gray-300">Should t be multiprecision on a particular architecture, then as with Montgomery arithmetic it may be more efficient to use an interleaved multiplication and reduction algorithm, as we detail in Algorithm 7. Here one needs b to be the word base of the underlying architecture and so in line 6, if  <span class="math">t \\equiv 0 \\pmod{b}</span>  we use Algorithm 4, otherwise we use Algorithm 2. For  <span class="math">\\overline{\\mathbf{x}} = [x_m, \\dots, x_0]</span>  we write  <span class="math">x_i = x_i[0] + x_i[1]b + \\dots + x_i[q-1]b^{q-1}</span> .</p>

    <h2 id="sec-misc-4" class="text-2xl font-bold">ALGORITHM 7: GRP MODMUL (interleaved)</h2>

    <pre><code class="language-text">INPUT: \\overline{\\mathbf{x}} = [x_m, \\dots, x_0], \\overline{\\mathbf{y}} = [y_m, \\dots, y_0] \\in \\mathbb{I}^{m+1} OUTPUT: \\overline{\\mathbf{z}} = [z_m, \\dots, z_0] \\in \\mathbb{I}^{m+1} where \\overline{\\mathbf{z}} \\cong_{\\varPhi_{m+1}(t)} \\overline{\\mathbf{x}} \\cdot \\overline{\\mathbf{y}} \\cdot b^{-q}

1. \\overline{\\mathbf{z}} \\leftarrow [0, \\dots, 0]

2. For k = 0 to q - 1 do:
3. For i = m to 0 do:
4. w_i \\leftarrow \\sum_{j=1}^{m/2} (x_{\\langle \\frac{i}{2} - j \\rangle}[k] - x_{\\langle \\frac{i}{2} + j \\rangle}[k]) \\cdot (y_{\\langle \\frac{i}{2} + j \\rangle} - y_{\\langle \\frac{i}{2} - j \\rangle})

5. \\overline{\\mathbf{z}} \\leftarrow \\overline{\\mathbf{z}} + \\overline{\\mathbf{w}}

6. \\overline{\\mathbf{z}} \\leftarrow \\operatorname{red}_b(\\overline{\\mathbf{z}})

7. Return \\overline{\\mathbf{z}}
</code></pre>

    <p class="text-gray-300">To verify the correctness of Algorithm 7, observe that for each of the m + 1 components of z, after the last iteration of the outer loop we have:</p>

    <p class="text-gray-300"><span class="math">$z_{i} = \\sum_{j=1}^{m/2} \\left( \\sum_{k=0}^{q-1} (x_{\\langle \\frac{i}{2} - j \\rangle}[k] - x_{\\langle \\frac{i}{2} + j \\rangle}[k]) / b^{q-k} \\right) \\cdot (y_{\\langle \\frac{i}{2} + j \\rangle} - y_{\\langle \\frac{i}{2} - j \\rangle})</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{j=1}^{m/2} ((x_{\\langle \\frac{i}{2} - j \\rangle} - x_{\\langle \\frac{i}{2} + j \\rangle}) / b^{q}) \\cdot (y_{\\langle \\frac{i}{2} + j \\rangle} - y_{\\langle \\frac{i}{2} - j \\rangle}).</span>$</p>

    <p class="text-gray-300">Hence when taken modulo &Phi;m+1(t), we see that z is congruent to:</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\sum_{i=0}^{m} z_i \\cdot t^i &amp;\\cong_{\\varPhi_{m+1}(t)} \\sum_{i=0}^{m} \\Big( \\sum_{j=1}^{m/2} (x_{\\langle \\frac{i}{2} - j \\rangle} - x_{\\langle \\frac{i}{2} + j \\rangle})/b^q \\big) \\cdot (y_{\\langle \\frac{i}{2} + j \\rangle} - y_{\\langle \\frac{i}{2} - j \\rangle}) \\Big) \\cdot t^i \\\\ &amp;\\cong_{\\varPhi_{m+1}(t)} \\sum_{i=0}^{m} \\Big( \\sum_{j=1}^{m/2} (x_{\\langle \\frac{i}{2} - j \\rangle} - x_{\\langle \\frac{i}{2} + j \\rangle}) \\cdot (y_{\\langle \\frac{i}{2} + j \\rangle} - y_{\\langle \\frac{i}{2} - j \\rangle}) \\cdot t^i \\Big)/b^q \\\\ &amp;\\cong_{\\varPhi_{m+1}(t)} \\overline{\\mathbf{x}} \\cdot \\overline{\\mathbf{y}} \\cdot b^{-q}, \\end{split}</span>$</p>

    <p class="text-gray-300">as required. As with ordinary Montgomery arithmetic, there are many possible ways to perform the interleaving, see [34] for example.</p>

    <p class="text-gray-300">In addition to modular multiplication, one also needs to perform other arithmetic operations when implementing ECC point multiplication. In this section we detail how to perform these using our representation and briefly explain how it enables point multiplication to be made immune to various side-channel attacks.</p>

      <h3 id="sec-9.1" class="text-xl font-semibold mt-8">9.1 Other arithmetic operations</h3>

    <p class="text-gray-300">Addition/subtraction To perform an addition or subtraction of two reduced elements x, y, we compute the following:</p>

    <p class="text-gray-300"><span class="math">$\\overline{\\mathbf{x}} \\pm \\overline{\\mathbf{y}} = [x_m \\pm y_m, \\dots, x_0 \\pm y_0].</span>$</p>

    <p class="text-gray-300">Note that the bounds on each of these components is [&minus;2 k+2 , 2 <sup>k</sup>+2 &minus; 2], which are therefore not necessarily reduced. One could reduce the resulting element using the specialisation to GRPs of [14, Algorithm 5], which shows how to do this for a general LWPFI. Chung and Hasan refer to this process as short coefficient reduction (SCR), as opposed to full modular reduction. However, for ECC operations it is faster (and more secure) to simply ignore this expansion and rely on a later modular multiplication to perform the reduction, as is required when computing a point addition or doubling, see [5, 6] and &sect;9.2.</p>

    <p class="text-gray-300">Squaring When t is single precision, the CVMA formulae do not have any common subexpressions, as arises for ordinary integer residue squaring. In this case GRP squaring is performed using Algorithm 6. If t is multiprecision, then the components of a product x &middot; y are computed as a sum of integer squares. In this case, one can eliminate common subexpressions to improve efficiency by nearly a factor of two (in the multiplication step). On the other hand, when using Algorithm 7 and its variants it may be difficult to eliminate common subexpressions efficiently [34].</p>

    <p class="text-gray-300">Inversion and equality check Inversion seems difficult to perform efficiently in the GRP representation. If t were prime then it would be possible to use an analogue of the inversion/division algorithm of [45], exploiting the cyclicity t <sup>m</sup>+1 &equiv; 1 (mod t <sup>m</sup>+1 &minus; 1). However, for our GRPs t is even and greater than 2. One can therefore opt to map back to Z/&Phi;m+1(t)Z, remaining in the Montgomery domain, and perform inversion using the binary extended Euclidean algorithm (see [32], for example) and modular multplying by the precomputed value &psi;(b <sup>3</sup> mod &Phi;m+1(t)). Alternatively, for data-independent inversion, one can simply power by &Phi;m+1(t) &minus; 2, as do the authors of [6]. Using projective coordinates can obviate the need for inversions altogether, however for many protocols inversion is unavoidable and when it is avoidable, in some scenarios such representations of points should be randomised after a point multiplication [43].</p>

    <p class="text-gray-300">Since our representation possesses redundancy, equality checking is naturally problematic. We therefore opt to map back to Z/&Phi;m+1(t)Z to check equality there &mdash; as for inversion while remaining in the Montgomery domain. For ECC equality checking is usually a onetime computation per coordinate, and so again this operation does not greatly impinge upon efficiency.</p>

    <p class="text-gray-300">As we demonstrated in &sect;7, by choosing t, l and m + 1 carefully, one can avoid the need to compute any final additions or subtractions when performing a modular reduction. This is an analogue to various results for ordinary Montgomery arithmetic [26, 55, 56]. The lack of a conditional addition/subtraction averts threats such as [48, 57], the latter of which applies directly to the NIST GMNs. Our modular multiplication algorithm is thus control-flow invariant with no data-dependent operations, making it immune to timing attacks [35] and simple power analysis (SPA).</p>

    <p class="text-gray-300">In addition to making modular multiplications and squarings immune to timing attacks and SPA, one can also ensure that the computation of an entire elliptic curve point addition or doubling is also immune. To do so, one chooses a GRP with t divisible by a sufficiently high power of 2, so that during the course of an elliptic curve point operation, even if one ignores the coefficient expansion caused by additions/subtractions, these do not overflow and the modular reductions ensure the outputs are fully reduced elements. Note that this requires b = 2<sup>l</sup> | t to be a few bits longer than the minimum l-values listed in Tables 1 and 2: for reasons of space we do not include the analysis here. By doing so, a point addition or doubling becomes an atomic operation, where the sequence of arithmetic operations is entirely dataindependent. In this case one only needs point-multiplication-level defences against timing attacks and SPA, such as the double-and-add-always algorithm due to Coron [15], or the use of Edwards curves, for which the addition formula can also be used for doubling [7]. Hence, ECC over GRPs may be straight-line coded, which is beneficial for both efficiency and security.</p>

    <p class="text-gray-300">Lastly, our representation can also be made immune to differential power analysis (DPA) [36]. Observe that the embedding of Z/&Phi;m+1(t)Z into Z/(t <sup>m</sup>+1 &minus; 1)Z can be randomised by adding to it a random multiple r &middot; &Phi;m+1(t) for r &isin; {0, . . . ,(t &minus; 1) &minus; 1}. While our embedding is an example of 'operand scaling' [45, 54] which is used for faster reduction, the addition of a multiple of the modulus within a redundant scaled representation also acts as a countermeasure to DPA &mdash; such as Goubin's attack [25] on the randomised projective coordinates defence of Coron [15] &mdash; as shown by Smart, Oswald and Page [51]. In particular, the authors show that this countermeasure thwarts DPA whenever the scaling factor is longer than the longest string of ones or zeros in the binary expansion of the initial modulus. For the NIST GMNs, this countermeasure requires a large scaling factor, making the defence inefficient and nullifying the benefits of using these moduli. For GRPs, the scaling factor is t &minus; 1, while the longest string of ones or zeros in the binary expansion of &Phi;m+1(t) is dlog te &minus; 1. Since GRPs already use the larger ring, we acquire this defence for almost negligible cost. In particular the addition of a random multiple r of &Phi;m+1(t) to an element x has the form [x<sup>m</sup> + r, xm&minus;<sup>1</sup> + r, . . . , x<sup>0</sup> + r], which only requires m + 1 additions. Since DPA depends on the ability of an attacker to predict a specific bit in the representation of a given field element, if the representation of field elements is randomised in this way prior to every point multiplication, or even every modular multiplication, then DPA will not be feasible.</p>

    <p class="text-gray-300">In this section we provide empirical data regarding the abundancy of fast-reduction GRPs at various bitlengths relevant to ECC. We also specify parameters that are optimal within this subfamily, which are therefore particularly suitable for efficient implementation.</p>

    <p class="text-gray-300">As we saw from Tables 1 and 2, for a given prime m + 1 and word size w, there is an upper bound on the length of a GRP that may be represented. Table 3 contains estimates (or exact counts) for the number of GRPs which are in accordance with the GRP field and residue representation set out in this work, for word size w = 64 and where q = 2 reductions using Algorithm 4 suffice to ensure I/O modular multiplication stability. Note that this reduction specification entails the greatest possible restriction on the available GRPs; using either larger q or Algorithm 2 means vastly more GRPs are availble. It is a simple matter to generate such GRPs, as follows; GRPs of any more general form can be found similarly.</p>

    <p class="text-gray-300">For a desired GRP p of bitlength dlog pe, Table 1 gives the minimum value of prime m+ 1 which is adequate to represent GRPs of this size. The inequality (7.1) gives kmax which is the maximum bitlength of t that is representable, while (7.2) gives the minimum value l required in order for t = 2<sup>l</sup> &middot; c to be I/O stable. We estimate tmax simply as 2dlog <sup>p</sup>e/m, which implies a maximum value for c of 2dlog <sup>p</sup>e/m&minus;lmin . Similarly for p of this precise bitlength, we estimate the minimum value of c as 2(dlog <sup>p</sup>e&minus;1)/m&minus;lmin . We denote this interval by I(c). To estimate P(prime), which is the probability that a given generalised repunit in our form is a GRP, we performed a linear search over c &isin; I(c), counting the first 1, 000 primes and simply dividing by the length of the search. The estimated total number of GRPs satisfying our requirement that q = 2 is then given by |I(c)| &middot; P(prime).</p>

    <p class="text-gray-300">For each of m + 1 = 5, 7 and 11, Table 3 contains estimated counts for the largest GRPs representable. It also contains estimates (or exact counts) for the number of GRPs at the NIST GMN sizes 224, 256 and 384. We also consider bitlength 512 rather than 521, since this conjecturally gives 256-bit security, with the larger prime 2<sup>521</sup> &minus; 1 being nominated purely for fast reduction. Observe that the number of available GRPs for a given m + 1 decreases as the size of p, and hence c decreases. The number available for bitlengths 383 and 384 is particularly low. However, should this be a concern for a particular application, one can see from Table 2 that by moving to GRPs for which 3 reductions suffices, |I(c)| becomes much larger (3.71&times;10<sup>5</sup> ) and our estimate of the number of GRPs becomes over 5, 000. On the other</p>

    <p class="text-gray-300"><strong>Table 3.</strong> Estimated GRP counts for w = 64, q = 2 and  <span class="math">t \\equiv 0 \\pmod{2^{l_{min}}}</span></p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"><span class="math">\\lceil \\log p \\rceil</span></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">m+1</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"><span class="math">k_{max}</span></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"><span class="math">\\log t_{max}</span></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"><span class="math">l_{min}</span></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">I(c)</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">P(prime)</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"><span class="math">\\approx \\# GRPs</span></th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">600</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">11</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60.0</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">34</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">8.54 \\times 10^{-3}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">599</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">11</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">59.9</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">34</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">4.19 \\times 10^{6}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">9.05 \\times 10^{-3}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">37.9 \\times 10^{3}</span></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">512</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">11</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">51.2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">30</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">-</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">1.05 \\times 10^{-2}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1697</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">511</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">11</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">51.1</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">30</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">1.51 \\times 10^{5}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">1.06 \\times 10^{-2}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">384</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">11</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">38.4</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">24</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1448</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">9.67 \\times 10^{-3}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">383</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">11</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">38.3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">24</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">1.33 \\times 10^{-2}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">360</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60.0</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">34</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">1.82 \\times 10^{-2}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">359</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">59.9</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">34</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">4.19 \\times 10^{6}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">1.77 \\times 10^{-2}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">74.1 \\times 10^{3}</span></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">256</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">42.66</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">25</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">2.47 \\times 10^{-2}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">255</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">42.5</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">25</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">2.02 \\times 10^4</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">2.63 \\times 10^{-2}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">531</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">244</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">61</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">61.0</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">34</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">-</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">1.68 \\times 10^{-2}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">243</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">61</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">60.75</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">34</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">1.80 \\times 10^{7}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">1.72 \\times 10^{-2}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">3.08 \\times 10^{5}</span></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">224</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">56</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">56.0</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">31</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">1.98 \\times 10^{-2}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">223</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">56</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">55.75</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">31</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">4.49 \\times 10^{6}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">1.88 \\times 10^{-2}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">8.42 \\times 10^4</span></td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">hand, since 384 is not too far beyond the upper bound for the size of GRP representable by m+1=7, it may be preferable to trade 12-bits of security for much improved performance, see &sect;11.</p>

    <p class="text-gray-300"><strong>Table 4.</strong> Efficient-reduction GRPs for w = 64, q = 2 and  <span class="math">t \\equiv 0 \\pmod{2^{l_{min}}}</span></p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"><span class="math">\\lceil \\log p \\rceil</span></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">GRP</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">S.C. Secure</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">511</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">\\Phi_{11}(2^{42}\\cdot(2^9+1))</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Yes</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">381</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">\\Phi_{11}(2^{34}\\cdot(2^4-1))</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Yes</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">380</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">\\Phi_{11}(2^{34}\\cdot(2^4+1))</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Yes</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">270</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">\\Phi_7(2^{34}\\cdot(2^{11}-1))</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Yes</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">253</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">\\Phi_7(2^{27}\\cdot(2^{15}+1))</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Yes</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">253</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">\\Phi_7(2^{37}\\cdot(2^5+1))</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Yes</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">243</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">\\Phi_5(2^{59}\\cdot(2^2-1))</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">No</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">228</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">\\Phi_5(2^{54}\\cdot(2^3-1))</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Yes</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">224</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">\\Phi_5(2^{33}\\cdot(2^{23}-1))</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">No</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">220</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">\\Phi_5(2^{52} \\cdot (2^3 - 1))</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Yes</td>
          </tr>
        </tbody>
      </table>
    </div>

      <h3 id="sec-10.2" class="text-xl font-semibold mt-8">10.2 Hamming weight 2 parameters</h3>

    <p class="text-gray-300">As we showed in &sect;5.2, there are no suitable GRPs in the ECC range for which  <span class="math">t=2^l</span> . Hence the next best type of GRP parameter t will have Hamming weight equal to 2, where we allow c to have the form  <span class="math">2^{c&#x27;}+1</span>  as well as  <span class="math">2^{c&#x27;}-1</span>  when there is sufficient slack in the representation, since subtractions cost the same as additions. We list these GRPs in Table 4. The final column indicates whether or not the given GRP allows for atomic side-channel secure point additions and doublings, as per &sect;9.2. Note that for m+1=5 and w=64 we can not represent GRPs any larger than 244-bits, and are thus short of the conjectured 128-bit ECC security level of 256-bits. One can therefore either move up to m+1=7, which can represent GRPs</p>

    <p class="text-gray-300">of up to 360-bits, or one can opt to reduce security by a few bits, for better performance. Indeed, in recent work K&uml;asper argues that the NIST GMN prime P-224 = 2<sup>224</sup> &minus; 2 <sup>96</sup> + 1 offers a satisfactory trade-off between security and efficiency [31], when used as the basis of the elliptic curve Diffie-Hellman (ECDH) key exchange in the Transport Layer Security (TLS) protocol [28]. Bernstein has also implemented arithmetic mod P-224 [4]. Yet another possibilty at this security level are the GFN primes &Phi;8(2<sup>41</sup> &middot; (2<sup>15</sup> &minus; 1)) and &Phi;8(2<sup>50</sup> &middot; (2<sup>6</sup> &minus; 1)), both of which have bitlength 224, but experiments with such GFNs have not yet been carried out. Of course in hardware, one can tailor the word base in order to achieve 256-bit atomic elliptic curve point operations without any residual slack.</p>

    <p class="text-gray-300">In this section we provide details of our proof-of-concept implementation and results. For simplicity we consider field multiplication only, as this tends to be the bottleneck in ECC point multiplication, and hence one can gain an accurate indication of performance in this simple way.</p>

    <p class="text-gray-300">In terms of performance, implementations can be compared using the eBATS benchmarking project [8]. For example, nearly all of the fastest 256-bit ECDH implementations in the literature [5,6,22,23,27,40] feature in eBATS. However, as it is difficult to get a fair comparison between our implementation of multiplication and the above ECDH implementations, we opt to compare our multiplication performance with that featured in the mpF<sup>q</sup> benchmarking system due to Gaudry and Thom&acute;e [23], which allows for such a comparison. This has been ported to OS-X 10.5.8 with minor changes and executed on a platform using an Intel Core 2 Duo at 2.2Ghz. As stated in [6], to date mpF<sup>q</sup> gives only the fourth fastest implementation of ECDH, based on Bernstein's curve25519, which utilises a non-standard representation of residues mod 2<sup>255</sup> &minus; 19 and exploits the floating-point unit of specific instruction-set architectures to great effect. Nevertheless, by comparing the basic multiplication cost on the target architecture, one can obtain a crude estimate of the relative performance of our arithmetic with that of curve25519, and hence in turn with the other implementations featured in eBATS.</p>

    <p class="text-gray-300">Our implementation consists of essentially two inline assembly operations targeted at the Core 2 processor. One accumulates the innermost sum of line 2 of Algorithm 6, while the other performs a single instance of the reduction operation in line 2 of Algorithm 4. There are two versions of the latter which correspond to whether or not the cofactor c is general which hence requires an imulq instruction &mdash; or is specialised, i.e., with Hamming weight 2. These operations use the 64-bit operations available on the Core 2 and the extended register set available in x86-64, each using a mere 4 of the 15 registers available. This allows one to rely on normal C code to arrange these macros, and to handle data-storage. As a result the gcc compiler can generate all of the intermediate memory access instructions and schedule the usage of the other 11 registers available. This means that the same code can be reused for any field supported by Algorithm 6 &mdash; the only changes required are the parameter definitions. To generate a particular instance of the family of algorithms we use a simple wrapper written in Python that arranges the sequence of these operations required for the particular parameter choice of m + 1 and t.</p>

    <p class="text-gray-300">To emphasise the relative simplicity of our implementation, we use only 64-bit scalar operations on the processor, and allow the compiler to schedule most of the output instructions. As a result we reach a throughput of slightly less than one operation per cycle. In comparison the mpF<sup>q</sup> implementation of curve25519 uses SSE2 to reach a throughput of almost two operations per cycle (the theoretical maximum on the architecture). Although our implementation is less efficient (because we have spent less programmer time on the machine-dependent optimisation) the performance achieved is still higher. Scheduling a lower-level implementation on the processor would be an interesting challenge.</p>

    <p class="text-gray-300">As explained in &sect;5 and &sect;10, within the reduction algorithm we have a trade-off between the number of GRPs available and performance. If one opts for a generic value of c then many GRPs are available, but the reduction involves a full imulq instruction with relatively high latency. If we specialise our choice of c to those with Hamming weight 2 then we can replace this instruction with a shift and an add or sub instruction to improve performance. We have measured the performance of both implementations. To ensure a fair comparison we have merged our code into mpF<sup>q</sup> so that all algorithms are being tested with the same timing code. This timer executes 10<sup>6</sup> operations in the field, measuring the elapsed time. The reported figures are the mean execution time for the operation. Table 5 contains cycle counts for Montgomery arithmetic at various bitlengths, as well as the curve25519 modular multiplication cycle count. Table 6 contains our results for GRP modular multiplication.</p>

    <p class="text-gray-300">Table 5. mpF<sup>q</sup> cycle counts for curve25519 and Montgomery arithmetic</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Algorithm</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Size (bits) ModMul (cycles)</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Mont.</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">64</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">30</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Mont.</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">128</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">105</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Mont.</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">192</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">195</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">curve25519</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">255</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">140</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Mont.</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">256</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">280</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Mont.</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">320</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">407</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Mont.</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">384</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">563</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Mont.</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">448</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">757</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Mont.</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">512</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">981</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">Table 6. Cycle counts for GRP arithmetic</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Parameters</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Max size (bits) ModMul (cycles)</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m + 1=5, HW(c)=2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">244</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">96</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m + 1=5, general c</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">244</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">112</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m + 1=7, HW(c) = 2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">360</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">165</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m + 1=7, general c</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">360</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">182</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m + 1=11, general c</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">600</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">340</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">As shown in Table 1 and considered in &sect;10.2, the closest size of field to curve25519 that we can implement using m + 1 = 5 is only 244-bits. This small reduction in field size is compensated by an increase in performance, requiring only 80% of the curve25519 cycles per multiplication. Using the specialised reduction function for the 243-bit GRP &Phi;5(2<sup>59</sup> &middot;(22&minus;1)), this figure improves to 69%. Since the results for the first line of Table 6 apply also to Hamming weight 2 GRPs smaller than 243-bits, we obtain the same modular multiplication performance for the 228-bit GRP &Phi;5(2<sup>54</sup> &middot; (2<sup>3</sup> &minus; 1)), while utilising the acquired slack in the representation to ensure atomic point doublings/additions as per &sect;9.2. At 512-bits with general c, compared to Montgomery multiplication, GRP multiplication costs only 35% as many cycles. For GRPs of 600-bits, this proportion would naturally be even smaller, however at this size Karatsuba-Ofman multiplication may be faster than schoolbook multiplication. We thus expect that point multiplications using 224-bit and 512-bit GRPs to be competitive with the state-of-the-art in the literature, once optimised. In particular, by comparing our arithmetic with the modular multiplication used in [6], which is the benchmark for point multiplication at the 128-bit security level, one gains an idea of the potential performance of arithmetic mod &Phi;5(2<sup>54</sup> &middot; (2<sup>3</sup> &minus; 1)), for example. In [6], residues are also represented by five 64-bit words. Residue multiplication requires 25 mul instructions, as well as 4 imul, 20 add and 20 adc instructions. In comparison, to multiply x and y in our representation, the CVMA formulae are as follows:</p>

    <p class="text-gray-300"><span class="math">$z_0 = (x_4 - x_1)(y_1 - y_4) + (x_3 - x_2)(y_2 - y_3),</span>$</p>

    <p class="text-gray-300"><span class="math">$z_1 = (x_2 - x_4)(y_4 - y_2) + (x_1 - x_0)(y_0 - y_1),</span>$</p>

    <p class="text-gray-300"><span class="math">$z_2 = (x_0 - x_2)(y_2 - y_0) + (x_4 - x_3)(y_3 - y_4),</span>$</p>

    <p class="text-gray-300"><span class="math">$z_3 = (x_3 - x_0)(y_0 - y_3) + (x_2 - x_1)(y_1 - y_2),</span>$</p>

    <p class="text-gray-300"><span class="math">$z_4 = (x_1 - x_3)(y_3 - y_1) + (x_0 - x_4)(y_4 - y_0),</span>$</p>

    <p class="text-gray-300">requiring only 10 mul, 20 sub and 5 add and 5 adc instructions. Since the respective reduction algorithms are quite similar with both requiring two rounds of shifts, masks and additions, one expects the GRP modular multiplication to be considerably faster, when optimised. However, since this paper is predominantly expositional, we leave such optimisations as open research.</p>

    <p class="text-gray-300">We have proposed efficient algorithms for performing arithmetic modulo a large family of primes, namely the generalised repunit primes. The algorithms are simple to implement, are fast, are easily parallelisable, can be made side-channel secure, and all across a wide range of field sizes. The central contribution of this work is the development of the necessary theory, covering field and residue representation, as well as algorithms for performing efficient multiplication and reduction in these fields. We have also presented proof-of-concept implementation results which provide an empirical comparison with results in the literature, which we ensured is fair by using the mpF<sup>q</sup> benchmarking procedure. Against Montgomery arithmetic we show an approximate 3-fold improvement in performance, and expect optimised implementations of point multiplications using our proposed family to be competitive with state-of-the-art implementations. We have thus presented a compelling argument in favour of a new approach to the secure and efficient implementation of ECC.</p>

    <p class="text-gray-300">The authors would like to thank Dan Page for making several very useful comments and suggestions.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>A.O.L. Atkin and F. Morain. Elliptic curves and primality proving. Math. Comp., 61(203):29-68, 1993.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>P. Barrett. Implementing the Rivest Shamir and Adleman public key encryption algorithm on a standard digital signal processor, In Advances in CryptologyCRYPTO 86 Springer-Verlag, LNCS 263, 311323, 1987.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>P.T. Bateman and R.A. Horn. A Heuristic Asymptotic Formula Concerning the Distribution of Prime Numbers. In Math. Comp. 16, pp. 363&ndash;367, 1962.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D.J. Bernstein. A software implementation of NIST P-224. Presentation at the 5th Workshop on Elliptic Curve Cryptography (ECC 2001), University of Waterloo, October 29-31, 2001. Slides available from http://cr.yp.to/talks.html.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D.J. Bernstein. Curve25519: New Diffie-Hellman Speed Records. In Public Key Cryptography PKC 2006, LNCS 3958, 207&ndash;228. Springer-Verlag, 2006.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D.J. Bernstein, N. Duif, T. Lange, P. Schwabe and B. Yang. High-speed high-security signatures. Cryptology ePrint Archive, Report 2011/368, 2011.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D.J. Bernstein and T. Lange. Faster addition and doubling on elliptic curves. In Advances in Cryptology ASIACRYPT 2007, LNCS 4833, pp. 29&ndash;50, Springer-Verlag, 2007.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D.J. Bernstein and T. Lange (editors). eBACS: ECRYPT Benchmarking of Cryptographic Systems. http://bench.cr.yp.to/ebats.html.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>I.F. Blake, R.M. Roth and G. Seroussi. Efficient Arithmetic in GF(2<sup>m</sup>) through Palindromic Representation. Technical Report HPL-98-134, 1998. Available from http://www.hpl.hp.com/techreports/98/ HPL-98-134.html.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>I.F. Blake, G. Seroussi, and N.P. Smart. Advances in Elliptic Curve Cryptography. London Mathemtical Society Lecture Note Series, 317, Cambridge University Press, 2005.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>M. Brown, D. Hankerson, J. L&acute;opez, and A. Menezes Software Implementation of the NIST Elliptic Curves Over Prime Fields In Topics in Cryptology CT-RSA 2001, LNCS 2020, 250&ndash;265, Springer.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>J. Chung A. Hasan. More Generalized Mersenne Numbers. In Selected Areas in Cryptography, volume 3006 of LNCS, 335 &ndash; 347. Springer, 2004.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>J. Chung and A. Hasan. Low-Weight Polynomial Form Integers for Efficient Modular Multiplication. In IEEE Trans. Comput., 56-1, 44&ndash;57, 2007.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>J. Chung and A. Hasan. Montgomery Reduction Algorithm for Modular Multiplication Using Low-Weight Polynomial Form Integers. In ARITH 18, 230&ndash;239, 2007</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>J.S. Coron. Resistance against differential power analysis for elliptic curve cryptosystems. In Cryptographic Hardware and Embedded Systems CHES 99, LNCS 1717, pp. 292&ndash;302, 1999.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>R.E. Crandall, E.W. Mayer and J.S. Papadopoulos. The twenty-fourth fermat number is composite. In Math. Comp., vol. 72, 243, pp. 1555&ndash;1572, 2003.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>H. Dubner. Generalized Repunit Primes. In Math. Comp., vol. 61, 204, pp. 927&ndash;930, 1993.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>H. Dubner and Y. Gallot. Distribution of generalized Fermat prime numbers. In Math. Comp., vol. 71, 238, pp. 825&ndash;832, 2002.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>H. Dubner and T. Granlund. Primes of the Form (b <sup>n</sup> + 1)/(b + 1). In Journal of Integer Sequences, vol. 3, 2, Art. 0.0.2.7, 2000.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>G. Drolet. A new representation of elements of finite fields GF(2<sup>m</sup>) yielding small complexity arithmetic circuits. IEEE Trans. Comput., 47(9): 938&ndash;946, 1998.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>FIPS 186-2. Digital Signature Standard. Federal Information Processing Standards Publication 186-2, US Department of Commerce/N.I.S.T. 2000.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>S.D. Galbraith, X. Lin and M. Scott. Endomorphisms for Faster Elliptic Curve Cryptography on a Large Class of Curves. In J. Cryptology, vol. 24, no. 3, pp. 446&ndash;469, 2011.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>P. Gaudry and E. Thom&acute;e. The mpFq library and implementing curve-based key exchanges. In SPEED: Software Performance Enhancement for Encryption and Decryption, ECRYPT Workshop, 49&ndash;64, 2007.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>W. Geiselmann and D. Grollmann. VLSI design for exponentiation in GF(2<sup>m</sup>). AUSCRYPT'90, 398&ndash;405. Springer-Verlag, 2001.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>L. Goubin. A refined power analysis attack on elliptic curve cryptosystems. In em Public Key Cryptography PKC 03, LNCS 2567, pp. 199&ndash;211, 2003.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>G. Hachez and J.J. Quisquater. Montgomery Exponentiation with No Final Subtractions: Improved Results. In Cryptographic Hardware and Embedded Systems (CHES), Springer-Verlag LNCS 1965, pp. 293&ndash;301, 2000.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>H&uml;useyin Hisil. Elliptic curves, group law, and efficient computation. Ph.D. thesis, Queensland University of Technology, 2010. URL: http://eprints.qut.edu.au/33233.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Internet Engineering Task Force. Elliptic Curve Cryptography (ECC) Cipher Suites for Transport Layer Security (TLS), 2006. http://www.ietf.org/rfc/rfc4492.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>T. Itoh and S. Tsuji. Structure of Parallel Multipliers for a Class of Fields GF(2<sup>m</sup>). In Information and Computers, vol. 8, 21&ndash;40, 1989.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>A. Karatsuba and Y. Ofman. Multiplication of multidigit numbers on automata. In Soviet Physics, Doklady 7, 595&ndash;596, 1963.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>E. K&uml;asper. Fast elliptic curve cryptography in OpenSSL. In 2nd Workshop on Real-Life Cryptographic Protocols and Standardization (RLCPS 2011), to appear, 2011.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D.E. Knuth. The Art of Computer Programming, 2 Semi-numerical Algorithms. Addison-Wesley, 2nd edition, 1981.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>N. Koblitz. Elliptic curve cryptosystems. In Math. Comp., 48, pp. 203&ndash;209, 1987.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>C.K. Ko&cedil;c, T. Acar and B.S. Kaliski Jr. Analyzing and comparing Montgomery multiplication algorithms. In IEEE Micro, vol. 16, 3, pp. 26&ndash;33, 1996.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>P.C. Kocher. Timing attacks on implementations of Diffie-Hellman, RSA, DSS and other systems. In Advances in Cryptology CRYPTO 96, LNCS 1109, pp. 104&ndash;113, 1996.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>P.C. Kocher, J. Jaffe and B. Jun. Differential power analysis. In Advances in Cryptology CRYPTO 99, LNCS 1666, pp. 388&ndash;397, 1999.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>S. Kwon, C.H. Kim and C.P. Hong. Gauss Period, Sparse Polynomial, Redundant Basis, and Efficient Exponentiation for a Class of Finite Fields with Small Characteristic. In ISAAC 2003, LNCS 2906, pp. 736&ndash;745, 2003.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>A.K. Lenstra and H.W. Lenstra. The Development of the Number Field Sieve. LNM 1554, Springer-Verlag, 1993.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>H.W. Lenstra, Jr. Factoring integers with elliptic curves. Ann. of Math. (2), 126(3):649&ndash;673, 1987.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>P. Longa and C.H. Gebotys. Efficient techniques for high-speed elliptic curve cryptography. In Cryptographic hardware and embedded systems, CHES 2010, LNCS 6225, pp. 80&ndash;94, Springer 2010.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>V. Miller. Use of elliptic curves in cryptography. In Advances in Cryptology CRYPTO 85. LNCS 218, Springer-Verlag, pp. 417&ndash;426, 1985.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>P.L. Montgomery. Modular Multiplication without trial division. Math. Comp., 44, 519&ndash;521, 1985.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D. Naccache, N.P. Smart and J. Stern. Projective Coordinates Leak. In Advances in Cryptology EU-ROCRYPT, LNCS 2586, pp. 257&ndash;267, Springer-Verlag, 2004.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Y. Nogami, A. Saito, and Y. Morikawa. Finite Extension Field with Modulus of All-One Polynomial and Representation of Its Elements for Fast Arithmetic Operations. In IEICE TRANSACTIONS on Fundamentals of Electronics, Communications and Computer Sciences Vol.E86-A No.9, 2376&ndash;2387, 2003.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>E. Ozturk, B. Sunar, and E. Savas. Low-Power Elliptic Curve Cryptography Using Scaled Modular Arithmetic. In CHES 2004, Springer Verlag, LNCS 3156, pp 92&ndash;106, 2004.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D.S. Phatak and T. Goff. Fast Modular Reduction for Large Wordlengths via One Linear and One Cyclic Convolution. In 17th IEEE Symposium on Computer Arithmetic (ARITH'05), pp. 179&ndash;186, 2005.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>R.L. Rivest, Shamir A., and L.M. Adleman. A method for obtaining digital signatures and public-key cryptosystems. Comm. ACM, 21, 120 &ndash; 126, 1978.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Y. Sakai and K. Sakurai. Simple Power Analysis on Fast Modular Reduction with Generalized Mersenne Prime for Elliptic Curve Cryptosystems. In Ieice Transactions - IEICE, vol. 89-A, no. 1, pp. 231&ndash;237, 2006.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>A. Schinzel and W. Sierpi&acute;nski. Sur certaines hypoth\`eses concernant les nombres premiers. In Acta Arith. 4 (1958), pp. 185&ndash;208, Erratum 5 (1959), 259.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>J.H. Silverman. Fast Multiplication in Finite Fields GF(2<sup>N</sup> ). In Proc. Workshop Cryptographic Hardware and Embedded Systems (CHES '99), LNCS 1717, 122&ndash;134. Springer 1999.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>N.P. Smart, E. Oswald and D. Page. Randomised representations. In IET Information Security, vol. 2, 2, pp. 19&ndash;27, 2008.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>W.M. Snyder. Factoring repunits. In Amer. Math. Monthly, 89 pp. 462&ndash;466, 1982.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>J.A. Solinas. Generalized Mersenne Numbers. Technical report CORR-39, Dept. of C&amp;O, University of Waterloo, 1999. Available from http://www.cacr.math.uwaterloo.cahttp://citeseer.ist.psu.edu/ solinas99generalized.html</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>C.D. Walter. Faster Modular Multiplication by Operand Scaling. Advances in Cryptology LNCS 576, 313&ndash;323, Springer Verlag, 1992.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>C.D. Walter. Montgomery Exponentiation Needs No Final Subtractions. In Electronics Letters, 35, pp. 1831&ndash;1832, 1999.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>C.D. Walter. Montgomery's Multiplication Technique: How to Make it Smaller and Faster. In Cryptographic Hardware and Embedded Systems (CHES), Springer-Verlag LNCS 1717, pp. 80&ndash;93, 1999.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>C.D. Walter and S. Thompson. Distinguishing Exponent Digits by Observing Modular Subtractions. In CT-RSA 2001, LNCS 2020, pp. 192&ndash;207, 2001.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>H.C. Williams and E. Seah. Some primes of the form (a <sup>n</sup> &minus;1)/(a&minus;1). In Math. Comp. 33, pp. 1337&ndash;1342, 1979.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>J.K. Wolf. Low Complexity Finite Field Multiplication. In Discrete Math., no.s 106/107, 497&ndash;502, 1992.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>H. Wu, A. Hasan, I. Blake and S. Gao. Finite Field Multiplier Using Redundant Representation. IEEE Trans. Comput., Vol 51, Num 11, Nov 2002.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>S. Yekhanin. Towards 3-query locally decodable codes of subexponential length. STOC '07, Proceedings of the thirty-ninth annual ACM symposium on Theory of computing, 266&ndash;274, 2007.</li>
    </ol></li>
    </ul>

    </section>
`;
---

<BaseLayout title="Generalised Mersenne Numbers Revisited (2011/444)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2011 &middot; eprint 2011/444
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <PaperDisclaimer eprintUrl={EPRINT_URL} />
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

    <PaperHistory slug="generalised-mersenne-numbers-revisited-2011" />
  </article>
</BaseLayout>
