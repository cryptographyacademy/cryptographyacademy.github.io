---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2011/444';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Generalised Mersenne Numbers Revisited';
const AUTHORS_HTML = 'Robert Granger, Andrew Moss';

const CONTENT = `    <p class="text-gray-300">Robert Granger¹* and Andrew Moss²</p>

    <p class="text-gray-300">¹ Claude Shannon Institute, University College Dublin, Ireland rgranger@computing.dcu.ie</p>

    <p class="text-gray-300">² Blekinge Institute of Technology, Sweden awm@bth.se</p>

    <p class="text-gray-300">Abstract. Generalised Mersenne Numbers (GMNs) were defined by Solinas in 1999 and feature in the NIST Digital Signature Standard (FIPS 186-2) for use in elliptic curve cryptography. Their form is such that modular reduction is extremely efficient, thus making them an attractive choice for modular multiplication implementation. However, the issue of residue multiplication efficiency seems to have been overlooked. Asymptotically, using a cyclic rather than a linear convolution, residue multiplication modulo a Mersenne number is twice as fast as integer multiplication; this property does not hold for prime GMNs, unless they are of Mersenne's form. In this work we exploit an alternative generalisation of Mersenne numbers for which an analogue of the above property — and hence the same efficiency ratio — holds, even at bitlengths for which schoolbook multiplication is optimal, while also maintaining very efficient reduction. Moreover, our proposed primes are abundant at any bitlength, whereas GMNs are extremely rare. Our multiplication and reduction algorithms can also be easily parallelised, making our arithmetic particularly suitable for hardware implementation. Furthermore, the field representation we propose also naturally protects against side-channel attacks, including timing attacks, simple power analysis and differential power analysis, which is essential in many cryptographic scenarios, in constraint to GMNs.</p>

    <p class="text-gray-300">Keywords: Prime fields, high-speed arithmetic, elliptic curve cryptography, generalised Mersenne numbers, cyclotomic primes, generalised repunit primes</p>

    <p class="text-gray-300">The problem of how to efficiently perform arithmetic in <span class="math">\\mathbb{Z}/N\\mathbb{Z}</span> is a very natural one, with numerous applications in computational mathematics and number theory, such as primality proving [1], factoring [39], and coding theory [61], for example. It is also of central importance to nearly all public-key cryptographic systems, including the Digital Signature Algorithm [21], RSA [47], and elliptic curve cryptography (ECC) [33,41]. As such, from both a theoretical and a practical perspective it is interesting and essential to have efficient algorithms for working in this ring, for either arbitrary or special moduli, with the application determining whether generality (essential for RSA for instance), or efficiency (desirable for ECC) takes precedence.</p>

    <p class="text-gray-300">Two intimately related factors need consideration when approaching this problem. First, how should one represent residues? And second, how should one perform arithmetic on these representatives? A basic answer to the first question is to use the canonical representation <span class="math">\\mathbb{Z}/N\\mathbb{Z} = \\{0,\\dots ,N - 1\\}</span>. With regard to modular multiplication for example, an obvious answer to the second question is to perform integer multiplication of residues, followed by reduction of the result modulo <span class="math">N</span>, in order to obtain a canonical representative once again. Using this approach, the two components needed for efficient modular arithmetic are clearly fast integer arithmetic, and fast modular reduction.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Supported by the Claude Shannon Institute, Science Foundation Ireland Grant No. 06/MI/006.</li>

    </ul>

    <p class="text-gray-300">At bitlengths for which schoolbook multiplication is optimal, research on fast modular multiplication has naturally tended to focus on reducing the cost of the reduction step. For arbitrary moduli, Montgomery’s celebrated algorithm <em>[42]</em> enables reduction to be performed for approximately the cost of a residue by residue multiplication. For the Mersenne numbers <span class="math">M_{k}=2^{k}-1</span>, efficient modular multiplication consists of integer residue multiplication to produce a <span class="math">2k</span>-bit product <span class="math">U\\cdot 2^{k}+L</span>, with <span class="math">U,L</span> of at most <span class="math">k</span>-bits, followed by a single modular addition <span class="math">U+L\\bmod M_{k}</span> to effect the reduction, as is well known. In 1999 Solinas proposed an extension of this method to a larger class of integers: the Generalised Mersenne Numbers (GMNs) <em>[53]</em>. As they are a superset, GMNs are more numerous than the Mersenne numbers and hence contain more primes, yet incur little additional overhead in terms of performance <em>[11]</em>. In 2000, NIST recommended ten fields for use in the ECDSA: five binary fields and five prime fields, and due to their performance characteristics the latter of these are all GMNs <em>[21]</em>, which range from 192 to 521 bits in size.</p>

    <p class="text-gray-300">For the GMNs recommended by NIST, there is no interplay between the residue multiplication and reduction algorithms, each step being treated separately with respect to optimisation. On the other hand, at asymptotic bitlengths the form of the modulus may be effectively exploited to speed up the residue multiplication step. For the Mersenne numbers <span class="math">M_{k}</span> in particular, modular multiplication can be performed for any <span class="math">k</span> using a cyclic convolution effected by a discrete weighted transform <em>[16, §3.1]</em>. As such, multiplication modulo Mersenne numbers is approximately twice as fast as multiplication of integers of the same bitlength, for which a linear convolution is required, as each multiplicand must be padded with <span class="math">k</span> zeros before a cyclic convolution of length <span class="math">2k</span> can be performed. For Montgomery multiplication at asymptotic bitlengths, the reduction step can be made 25% cheaper, again by using a cyclic rather than a linear convolution for one of the required multiplications <em>[46]</em>. However, since the multiplication step is oblivious to the form of the modulus, it seems unlikely to possess the same efficiency benefits that the Mersenne numbers enjoy. These considerations raise the natural question of whether there exists a similar residue multiplication speed up at bitlengths for which schoolbook multiplication is optimal? Certainly for the modulus <span class="math">N=2^{k}</span>, such a speed up can be achieved, since the upper half words of the product can simply be ignored. However, this modulus is unfortunately not at all useful for ECC.</p>

    <p class="text-gray-300">In this work we answer the above question affirmatively, using an alternative generalisation of Mersenne numbers, which has several desirable features:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Simple. Our proposed family is arguably a far more natural generalisation of Mersenne numbers than Solinas’, and gives rise to beautiful multiplication and reduction algorithms.</li>

      <li>Abundant. Our primes are significantly more numerous than the set of prime GMNs and are abundant for all tested bitlengths; indeed their number can be estimated using Bateman and Horn’s quantitative version <em>[3]</em> of Schinzel and Sierpiński’s “Hypothesis H” <em>[49]</em>.</li>

      <li>Fast multiplication. Our residue multiplication is nearly twice as fast as multiplication of integer residues.</li>

      <li>Fast reduction. Our reduction has linear complexity and is particularly efficient for specialised parameters, although such specialisation comes at the cost of reducing the number of primes available.</li>

      <li>Parallelisable. Both multiplication and reduction can be easily parallelised, making our arithmetic particularly suitable for hardware implementation.</li>

      <li>Side-channel secure. Our representation naturally protects against well-known side-channel attacks on ECC (see <em>[10, ch. IV]</em> for an overview), in contrast to the NIST GMNs,</li>

    </ul>

    <p class="text-gray-300">see <em>[48]</em> and <em>[51, §3.2]</em>. This includes timing attacks <em>[35, 57]</em>, simple power analysis <em>[48]</em> and differential power analysis <em>[36]</em>.</p>

    <p class="text-gray-300">This article provides an introductory (and comprehensive) theoretical framework for the use of our proposed moduli. It thus serves as a foundation for a new approach to the secure and efficient implementation of prime fields for ECC, both in software and in hardware. At a high level, our proposal relies on the combination of a remarkable algebraic identity used by Nogami, Saito, and Morikawa in the context of extension fields <em>[44]</em>, together with the residue representation and optimisation of the reduction method proposed by Chung and Hasan <em>[14]</em>, which models suitable prime fields as the quotient of an integer lattice by a particular equivalence relation. To verify the validity of our approach, we also provide a proof-of-concept implementation that is already competitive with the current fastest modular multiplication algorithms at contemporary ECC security levels <em>[5, 6, 22, 23, 27, 40]</em>.</p>

    <p class="text-gray-300">The sequel is organised as follows. In §2 we present some definitions and recall related work. In §3 we describe the basis of our arithmetic, then in §4-6 we present details of our residue multiplication, reduction and representation respectively. In §7 we show how to ensure I/O stability for modular multiplication, then in §8 we put everything together into a full modular multiplication algorithm. We then address other arithmetic operations and give a brief treatment of side-channel secure ECC in §9, and in §10 show how to generate suitable parameters. In §11 we present our implementation results and finally, in §12 we draw some conclusions.</p>

    <h2 id="sec-3" class="text-2xl font-bold">2 Definitions and Related Work</h2>

    <p class="text-gray-300">In this section we introduce the cyclotomic primes and provide a summary of related work. We begin with the following definition.</p>

    <h6 id="sec-4" class="text-base font-medium mt-4">Definition 1</h6>

    <p class="text-gray-300">For <span class="math">n\\geq 1</span> let <span class="math">\\zeta_{n}</span> be a primitive <span class="math">n</span>-th root of unity. The <span class="math">n</span>-th cyclotomic polynomial is defined by</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\Phi_{n}(x)=\\prod_{(k,n)=1}(x-\\zeta_{n}^{k})=\\prod_{d</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">n}(1-x^{n/d})^{\\mu(d)},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where <span class="math">\\mu</span> is the Möbius function.</p>

    <p class="text-gray-300">Two basic properties of the cyclotomic polynomials are that they have integer coefficients, and are irreducible over <span class="math">\\mathbb{Z}</span>. These two properties ensure that the evaluation of a cyclotomic polynomial at an integer argument will also be an integer, and that this integer will not inherit a factorisation from one in <span class="math">\\mathbb{Z}[x]</span>. One can therefore ask whether or not these polynomials ever assume prime values at integer arguments, which leads to our next definition.</p>

    <h6 id="sec-5" class="text-base font-medium mt-4">Definition 2</h6>

    <p class="text-gray-300">For <span class="math">n\\geq 1</span> and <span class="math">t\\in\\mathbb{Z}</span>, if <span class="math">p=\\Phi_{n}(t)</span> is prime, we call <span class="math">p</span> an <span class="math">n</span>-th cyclotomic prime, or simply a cyclotomic prime.</p>

    <p class="text-gray-300">Note that for all primes <span class="math">p</span>, we have <span class="math">p=\\Phi_{1}(p+1)=\\Phi_{2}(p-1)</span>, and so trivially all primes are cyclotomic primes. These instances are also trivial in the context of the algorithms we present for performing arithmetic modulo these primes, since in both cases the cyclotomic polynomials are linear and our algorithms reduce to ordinary Montgomery arithmetic. Hence for the remainder of the article we assume <span class="math">n\\geq 3</span>.</p>

    <p class="text-gray-300">In addition to being prime-evaluations of cyclotomic polynomials, note that for a cyclotomic prime <span class="math">p=\\Phi_{n}(t)</span>, the field <span class="math">\\mathbb{F}_{p}</span> can be modelled as the quotient of the ring of integers of the <span class="math">n</span>-th cyclotomic field <span class="math">\\mathbb{Q}(\\zeta_{n})</span>, by the prime ideal <span class="math">\\pi=\\langle p,\\zeta_{n}-t\\rangle</span>. This is precisely how one would represent <span class="math">\\mathbb{F}_{p}</span> when applying the Special Number Field Sieve to solve discrete logarithms in <span class="math">\\mathbb{F}_{p}</span>, for example <em>[38]</em>. Hence our nomenclature for these primes seems apt. This interpretation of <span class="math">\\mathbb{F}_{p}</span> for <span class="math">p</span> a cyclotomic prime is implicit within the arithmetic we develop here, albeit only insofar as it provides a theoretical context for it; this perspective offers no obvious insight into how to perform arithmetic efficiently and the algorithms we develop make no use of it at all. Similarly, the method of Chung and Hasan <em>[14]</em> upon which our residue representation is based can be seen as arising in exactly the same way for the much larger set of primes they consider, with the field modelled as a quotient of the ring of integers of a suitable number field by a degree one prime ideal, just as for the cyclotomic primes.</p>

    <h3 id="sec-6" class="text-xl font-semibold mt-8">2.1 Low redundancy cyclotomic primes</h3>

    <p class="text-gray-300">The goal of the present work is to provide efficient algorithms for performing <span class="math">\\mathbb{F}_{p}</span> arithmetic, for <span class="math">p=\\Phi_{n}(t)</span> a cyclotomic prime. As will become clear from our exposition, in order to exploit the available cyclic structure — for both multiplication and reduction — we do not use the field <span class="math">\\mathbb{Z}/\\Phi_{n}(t)\\mathbb{Z}</span>, but instead embed into the slightly larger ring <span class="math">\\mathbb{Z}/(t^{n}-1)\\mathbb{Z}</span> if <span class="math">n</span> is odd, and <span class="math">\\mathbb{Z}/(t^{n/2}+1)\\mathbb{Z}</span> if <span class="math">n</span> is even. In each case, using the larger ring potentially introduces an expansion factor <span class="math">e(n)</span> into the residue representation. One can alternatively view this in terms of a redundancy measure <span class="math">r(n)</span>, where <span class="math">r=e-1</span>. Since using a larger ring for arithmetic will potentially be slower, we now identify three families of cyclotomic polynomials for which the above embeddings have low redundancy.</p>

    <p class="text-gray-300">For <span class="math">n</span> even, there is a family of cases for which the above embedding does not introduce any redundancy, namely for <span class="math">n=2^{k}</span>, since <span class="math">\\Phi_{2^{k}}(t)=t^{2^{k-1}}+1=t^{2^{k}/2}+1</span>, and hence <span class="math">e=1</span> and <span class="math">r=0</span>. When <span class="math">t=2</span> these are of course the Fermat numbers, and for general <span class="math">t</span> these integers are known as Generalised Fermat Numbers (GFNs). It is expected that for each <span class="math">k</span> there are infinitely many <span class="math">t</span> for which <span class="math">t^{2^{k}}+1</span> is prime <em>[18, §3]</em>.</p>

    <p class="text-gray-300">If <span class="math">n=2p</span> for <span class="math">p</span> prime, then <span class="math">\\Phi_{2p}(t)=t^{p-1}-t^{p-2}+\\cdots+t-1=(t^{p}+1)/(t+1)</span> and in this case <span class="math">e=p/(p-1)</span> and <span class="math">r=1/(p-1)</span>. The primality of these numbers was studied in <em>[19]</em>, and while they apparently do not have a designation in the literature, one can see that by substituting <span class="math">t</span> with <span class="math">-t</span> in the third family below produces this one. For general even <span class="math">n</span> we have <span class="math">e=n/2\\phi(n)</span> and <span class="math">r=(n-2\\phi(n))/2\\phi(n)</span>, with <span class="math">\\phi(\\cdot)</span> Euler’s totient function, which is the degree of <span class="math">\\Phi_{n}(x)</span>. Hence amongst those even <span class="math">n</span> which are not a power of <span class="math">2</span>, this family produces the successive local minima of <span class="math">r</span>.</p>

    <p class="text-gray-300">For odd <span class="math">n</span>, we have <span class="math">e=n/\\phi(n)</span> and <span class="math">r=(n-\\phi(n))/\\phi(n)</span>. The successive local minima of <span class="math">r</span> occur at <span class="math">n=p</span> for <span class="math">p</span> prime, in which case <span class="math">\\Phi_{p}(t)=t^{p-1}+t^{p-2}+\\cdots+t+1=(t^{p}-1)/(t-1)</span>, also with <span class="math">r=1/(p-1)</span>. When <span class="math">t=2</span> these are of course the Mersenne numbers, and in analogy with the case of Fermat numbers, it would be natural to refer to these integers for general <span class="math">t</span> as Generalised Mersenne Numbers, particularly as one can show they share the aforementioned asymptotic efficiency properties of the Mersenne numbers, while Solinas’ GMNs do not, unless they are of Mersenne’s form. However, this family of numbers is known in the literature as generalised repunits <em>[17, 52, 58]</em>, since their base-<span class="math">t</span> expansion consists entirely of <span class="math">1</span>’s. Therefore for the sake of uniform nomenclature, we use the following definition.</p>

    <h6 id="sec-7" class="text-base font-medium mt-4">Definition 3</h6>

    <p class="text-gray-300">For <span class="math">m+1</span> an odd prime let</p>

    <p class="text-gray-300"><span class="math">p=\\Phi_{m+1}(t)=t^{m}+t^{m-1}+\\cdots+t+1.</span></p>

    <p class="text-gray-300">We call such an integer a Generalised Repunit; when <span class="math">p</span> is prime we call it a Generalised Repunit Prime (GRP).</p>

    <p class="text-gray-300">We have developed modular multiplication algorithms for both GRPs and GFNs. In terms of efficiency, for GRPs and GFNs of the same bitlength the respective multiplication algorithms require exactly the same number of word-by-word multiplications. Also, our reduction algorithms for both GRPs and GFNs are virtually identical. However, the multiplication algorithm for GFNs is far less elegant, is not perfectly parallelisable and contains more additions. Furthermore, for a given bitlength there are fewer efficient GFN primes than there are GRPs — as the bitlength of GFNs doubles as <span class="math">k</span> is incremented — and the I/O stability analysis for multiplication modulo a GRP is far simpler. Therefore in this exposition we focus on algorithms for performing arithmetic modulo GRPs and their analysis only. Note that the studies of GRPs <em>[17, 58]</em> consider only very small <span class="math">t</span> and large <span class="math">m</span>, whereas we will be interested in <span class="math">t</span> approximately the word base of the target architecture, and <span class="math">m</span> the number of words in the prime whose field arithmetic we are to implement. Hence one expects (and finds) there to be very many GRPs for any given relevant bitlength, see §10.</p>

    <h3 id="sec-8" class="text-xl font-semibold mt-8">2.2 Related work</h3>

    <p class="text-gray-300">In the context of extension fields, let <span class="math">m+1</span> be prime and let <span class="math">p</span> be a primitive root modulo <span class="math">m+1</span>. Then <span class="math">\\mathbb{F}_{p^{m}}=\\mathbb{F}_{p}[x]/(\\Phi_{m+1}(x)\\mathbb{F}_{p}[x])</span>. In the binary case, i.e., <span class="math">p=2</span>, several authors have proposed the use of this polynomial — also known as the all-one polynomial (AOP) — to obtain efficient multiplication algorithms <em>[59, 29, 50, 9]</em>. All of these rely on the observation that the field <span class="math">\\mathbb{F}_{2}[x]/(\\Phi_{m+1}(x)\\mathbb{F}_{2}[x])</span> embeds into the ring <span class="math">\\mathbb{F}_{2}[x]/((x^{m+1}+1)\\mathbb{F}_{2}[x])</span> — referred to by Silverman <em>[50]</em> as the “ghost bit” basis — which possesses a particularly nice cyclic structure, but introduces some redundancy. Similarly, this idea applies to any cyclotomic polynomial, and several authors have investigated this strategy, embedding suitably defined extension fields into the ring <span class="math">\\mathbb{F}_{2}[x]/((x^{n}+1)\\mathbb{F}_{2}[x])</span> <em>[24, 20, 60]</em>.</p>

    <p class="text-gray-300">For odd characteristic extension fields, Silverman noted that the “ghost bit” basis for <span class="math">p=2</span> extends easily to larger <span class="math">p</span> <em>[50]</em>, while Kwon et al. have explored this idea further <em>[37]</em>. Central to our application is the work of Nogami, Saito and Morikawa <em>[44]</em>, who used the AOP to obtain a very fast multiplication algorithm, see §4. The use of cyclotomic polynomials in extension field arithmetic is therefore well studied. In the context of prime fields however, the present work appears to be the first to transfer ideas for cyclotomic polynomials from the domain of extension field arithmetic to prime field arithmetic, at least for the relatively small bitlengths for which schoolbook multiplication is optimal.</p>

    <p class="text-gray-300">With regard to the embedding of a prime field into a larger integer ring, the idea of operand scaling was introduced by Walter in order to obtain a desired representation in the higher-order bits <em>[54]</em>, which aids in the estimation of the quotient when using Barrett reduction <em>[2]</em>. Similarly, Ozturk et al. proposed using fields with characteristics dividing integers of the form <span class="math">2^{k}\\pm 1</span>, with particular application to ECC <em>[45]</em>. As stated in the introduction, there are numerous very efficient prime field ECC implementations <em>[5, 6, 23, 27, 40]</em>. While the moduli used in these instances permit fast reduction algorithms, and the implementations are highly optimised, it would appear that none of them permit the same residue multiplication speed up that we present here, which is one of the central distinguishing features of the present work.</p>

    <p class="text-gray-300">3 GRP Field Representation</p>

    <p class="text-gray-300">In this section we present a sequence of representations of <span class="math">\\mathbb{F}_{p}</span>, with <span class="math">p</span> a GRP, the final one being the target representation which we use for our arithmetic. We recall the mathematical framework of Chung-Hasan arithmetic, in both the general setting and as specialised to GRPs, focusing here on the underlying theory, deferring explicit algorithms for residue multiplication, reduction and representation until §4-6.</p>

    <h3 id="sec-9" class="text-xl font-semibold mt-8">3.1 Chung-Hasan arithmetic</h3>

    <p class="text-gray-300">We now describe the ideas behind Chung-Hasan arithmetic <em>[12, 13, 14]</em>. The arithmetic was developed for a class of integers they term low-weight polynomial form integers (LWPFIs), whose definition we now recall.</p>

    <h6 id="sec-10" class="text-base font-medium mt-4">Definition 4</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">An integer <span class="math">p</span> is a low-weight polynomial form integer (LWPFI), if it can be represented by a monic polynomial <span class="math">f(t)=t^{n}+f_{n-1}t^{n-1}+\\cdots+f_{1}t+f_{0}</span>, where <span class="math">t</span> is a positive integer and $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">f_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\xi<span class="math"> for some small positive integer </span>\\xi<t$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Note that if for a given LWPFI each <span class="math">f_{i}\\in\\{\\pm 1,0\\}</span> and <span class="math">t=2^{k}</span>, then it is a GMN, as defined by Solinas <em>[53]</em>. The key idea of Chung and Hasan is to perform arithmetic modulo <span class="math">p</span> using representatives from the polynomial ring <span class="math">\\mathbb{Z}[T]/(f(T)\\mathbb{Z}[T])</span>. To do so, one uses the natural embedding <span class="math">\\psi:\\mathbb{F}_{p}\\hookrightarrow\\mathbb{Z}[T]/(f(T)\\mathbb{Z}[T])</span> obtained by taking the base <span class="math">t</span> expansion of an element of <span class="math">\\mathbb{F}_{p}</span> in the canonical representation <span class="math">\\mathbb{F}_{p}=\\{0,\\ldots,p-1\\}</span>, and substituting <span class="math">T</span> for <span class="math">t</span>. To compute <span class="math">\\psi^{-1}</span> one simply makes the inverse substitution and evaluates the expression modulo <span class="math">p</span>.</p>

    <p class="text-gray-300">The reason for using this ring is straightforward: since <span class="math">\\psi^{-1}</span> is a homomorphism, when one computes <span class="math">z(T)=x(T)\\cdot y(T)</span> in <span class="math">\\mathbb{Z}[T]</span>, reducing the result modulo <span class="math">f(T)</span> to give <span class="math">w(T)</span> does not change the element of <span class="math">\\mathbb{F}_{p}</span> represented by <span class="math">z(T)</span>, i.e., if <span class="math">z(T)\\equiv w(T)\\pmod{f(T)}</span>, then <span class="math">z(t)\\equiv w(t)\\pmod{p}</span>, since <span class="math">p=f(t)</span>. Furthermore, since <span class="math">f(T)</span> has very small coefficients, <span class="math">w(T)</span> can be computed from <span class="math">z(T)</span> using only additions and subtractions. Hence given the degree <span class="math">2(n-1)</span> product of two degree <span class="math">n-1</span> polynomials in <span class="math">\\mathbb{Z}[T]</span>, its degree <span class="math">n-1</span> representation in <span class="math">\\mathbb{Z}[T]/(f(T)\\mathbb{Z}[T])</span> can be computed very efficiently. Note that for non-low-weight polynomials this would no longer be the case.</p>

    <p class="text-gray-300">The only problem with this approach is that when computing <span class="math">z(T)</span> as above, the coefficients of <span class="math">z(T)</span>, and hence <span class="math">w(T)</span>, will be approximately twice the size of the inputs’ coefficients, and if further operations are performed the representatives will continue to expand. Since for I/O stability one requires that the coefficients be approximately the size of <span class="math">t</span> after each modular multiplication or squaring, one must somehow reduce the coefficients of <span class="math">w(T)</span> to obtain a standard, or reduced representative, while ensuring that <span class="math">\\psi^{-1}(w(T))</span> remains unchanged.</p>

    <p class="text-gray-300">Chung and Hasan refer to this issue as the coefficient reduction problem (CRP), and developed three solutions in their series of papers on LWPFI arithmetic <em>[12, 13, 14]</em>. Each of these solutions is based on an underlying lattice, although this was only made explicit in <em>[14]</em>. Since the lattice interpretation is the most elegant and simplifies the exposition, in the sequel we opt to develop the necessary theory for GRP arithmetic in this setting.</p>

    <h3 id="sec-11" class="text-xl font-semibold mt-8">3.2 Chung-Hasan representation for GRPs</h3>

    <p class="text-gray-300">Let <span class="math">p=\\Phi_{m+1}(t)</span> be a GRP. Our goal is to develop arithmetic for <span class="math">\\mathbb{F}_{p}</span>, and we begin with the canonical representation <span class="math">\\mathbb{F}_{p}=\\mathbb{Z}/\\Phi_{m+1}(t)\\mathbb{Z}</span>. As stated in §2.1, the first map in our chain</p>

    <p class="text-gray-300">of representations takes the canonical ring and embeds it into <span class="math">\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span>, for which the identity map suffices. To map back, one reduces a representative modulo <span class="math">p</span>. We then apply the Chung-Hasan transformation of §3.1, which embeds the second ring into <span class="math">\\mathbb{Z}[T]/(T^{m+1}-1)\\mathbb{Z}[T]</span>, by taking the base <span class="math">t</span> expansion of a canonical residue representative in <span class="math">\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span>, and substituting <span class="math">T</span> for <span class="math">t</span>. We call this map <span class="math">\\psi</span>. To compute <span class="math">\\psi^{-1}</span> one simply makes the inverse substitution and evaluates the expression modulo <span class="math">t^{m+1}-1</span>.</p>

    <p class="text-gray-300">Note that the codomain of <span class="math">\\psi</span> may be regarded as an <span class="math">(m+1)</span>-dimensional vector space over <span class="math">\\mathbb{Z}</span>, equipped with the natural basis <span class="math">\\{T^{m},\\ldots,T,1\\}</span>. In particular, for <span class="math">x(T)\\in\\mathbb{Z}[T]/(T^{m+1}-1)\\mathbb{Z}[T]</span>, where</p>

    <p class="text-gray-300"><span class="math">x(T)=x_{m}T^{m}+\\ldots+x_{1}T+x_{0},</span></p>

    <p class="text-gray-300">one can consider <span class="math">x(T)</span> to be a vector <span class="math">\\overline{\\mathbf{x}}=[x_{m},\\ldots,x_{0}]\\in\\mathbb{Z}^{m+1}</span>. Since <span class="math">\\mathbb{Z}^{m+1}</span> has elements whose components are naturally unbounded, for each <span class="math">x\\in\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span> there are infinitely many elements of <span class="math">\\mathbb{Z}^{m+1}</span> that map via <span class="math">\\psi^{-1}</span> to <span class="math">x</span>. Therefore in order to obtain a useful isomorphism directly between <span class="math">\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span> and <span class="math">\\mathbb{Z}^{m+1}</span>, we identify two elements of <span class="math">\\mathbb{Z}^{m+1}</span> whenever they map via <span class="math">\\psi^{-1}</span> to the same element of <span class="math">\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span>, i.e.,</p>

    <p class="text-gray-300"><span class="math">\\overline{\\mathbf{x}}\\sim\\overline{\\mathbf{y}}\\ \\ \\Longleftrightarrow\\ \\ \\psi^{-1}(\\overline{\\mathbf{x}})\\equiv\\psi^{-1}(\\overline{\\mathbf{y}})\\quad(\\text{mod}\\ t^{m+1}-1),</span> (3.1)</p>

    <p class="text-gray-300">and take the image of <span class="math">\\psi</span> to be the quotient of <span class="math">\\mathbb{Z}^{m+1}</span> by this equivalence relation. Pictorially, we thus have:</p>

    <p class="text-gray-300"><span class="math">\\mathbb{F}_{p}\\subset\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}\\cong\\mathbb{Z}^{m+1}/\\sim</span></p>

    <p class="text-gray-300">As mentioned in §3.1, for each coset in <span class="math">\\mathbb{Z}^{m+1}/\\sim</span>, we should like to use a minimal, or in some sense ‘small’ representative, in order to facilitate efficient arithmetic after a multiplication or a squaring, for example. Since we know that the base-<span class="math">t</span> expansion of every <span class="math">x\\in\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span> gives one such representative for each coset in <span class="math">\\mathbb{Z}^{m+1}/\\sim</span>, for a reduction algorithm we just need to be able to find it, or at least one whose components are of approximately the same size. Chung and Hasan related finding such ‘nice’ or reduced coset representatives to solving a computational problem in an underlying lattice, which we now recall.</p>

    <h3 id="sec-12" class="text-xl font-semibold mt-8">3.3 Lattice interpretation</h3>

    <p class="text-gray-300">Given an input vector <span class="math">\\overline{\\mathbf{z}}</span>, which is the output of a multiplication or a squaring, a coefficient reduction algorithm should output a vector <span class="math">\\overline{\\mathbf{w}}</span> such that <span class="math">\\overline{\\mathbf{w}}\\sim\\overline{\\mathbf{z}}</span>, in the sense of (3.1), whose components are approximately the same size as <span class="math">t</span>. As observed in <em>[14]</em>, the equivalence relation (3.1) is captured by an underlying lattice, and finding <span class="math">\\overline{\\mathbf{w}}</span> is tantamount to solving an instance of the closest vector problem (CVP) in this lattice. To see why this is, we first fix some notation as in <em>[14]</em>.</p>

    <p class="text-gray-300">Let <span class="math">\\overline{\\mathbf{u}}</span> and <span class="math">\\overline{\\mathbf{v}}</span> be vectors in <span class="math">\\mathbb{Z}^{m+1}</span> such that the following condition is satisfied:</p>

    <p class="text-gray-300"><span class="math">[t^{m},\\ldots,t,1]\\cdot\\overline{\\mathbf{u}}^{T}\\equiv[t^{m},\\ldots,t,1]\\cdot\\overline{\\mathbf{v}}^{T}\\quad(\\text{mod}\\ t^{m+1}-1)</span></p>

    <p class="text-gray-300">Then we say that <span class="math">\\overline{\\mathbf{u}}</span> is congruent to <span class="math">\\overline{\\mathbf{v}}</span> modulo <span class="math">t^{m+1}-1</span> and write this as <span class="math">\\overline{\\mathbf{u}}\\cong_{t^{m+1}-1}\\overline{\\mathbf{v}}</span>. Note that this is exactly the same as saying <span class="math">\\psi^{-1}(\\overline{\\mathbf{u}})\\equiv\\psi^{-1}(\\overline{\\mathbf{v}})\\ (\\text{mod}\\ t^{m+1}-1)</span>, and so <span class="math">\\overline{\\mathbf{u}}\\sim\\overline{\\mathbf{v}}\\Longleftrightarrow\\overline{\\mathbf{u}}\\cong_{t^{m+1}-1}\\overline{\\mathbf{v}}</span>.</p>

    <p class="text-gray-300">Similarly, but abusing notation slightly, for any integer <span class="math">b\\neq t^{m+1}-1</span> (where <span class="math">b</span> is typically a power of the word base of the target architecture), we write <span class="math">\\overline{\\mathbf{u}}\\cong_{b}v</span> for some integer</p>

    <p class="text-gray-300"><span class="math">v</span> satisfying <span class="math">[t^m, \\ldots, t, 1] \\cdot \\overline{\\mathbf{u}}^T \\equiv v \\pmod{b}</span>, and say <span class="math">\\overline{\\mathbf{u}}</span> is congruent to <span class="math">v</span> modulo <span class="math">b</span>, in this case. We reserve the use of <span class="math">\\equiv</span> to express a component-wise congruence relation, i.e., <span class="math">\\overline{\\mathbf{u}} \\equiv \\overline{\\mathbf{v}} \\pmod{b}</span>. Finally, we denote by <span class="math">\\overline{\\mathbf{u}} \\bmod b</span> the component-wise modular reduction of <span class="math">\\overline{\\mathbf{u}}</span> by <span class="math">b</span>.</p>

    <p class="text-gray-300">The lattice underlying the equivalence relation (3.1) can now enter the frame. Let <span class="math">\\mathbf{V} = \\{\\overline{\\mathbf{v}}_0, \\dots, \\overline{\\mathbf{v}}_m\\}</span> be a set of <span class="math">m + 1</span> linearly independent vectors in <span class="math">\\mathbb{Z}^{m + 1}</span> such that <span class="math">\\overline{\\mathbf{v}}_i \\cong_{t^{m + 1} - 1} \\overline{\\mathbf{0}}</span>, the all zero vector, for <span class="math">i = 0, \\dots, m</span>. Then the set of all integer combinations of elements of <span class="math">\\mathbf{V}</span> forms an integral lattice, <span class="math">\\mathcal{L}(\\mathbf{V})</span>, with the property that for all <span class="math">\\overline{\\mathbf{z}} \\in \\mathbb{Z}^{m + 1}</span>, and all <span class="math">\\overline{\\mathbf{u}} \\in \\mathcal{L}</span>, we have</p>

    <div class="my-4 text-center"><span class="math-block">\\overline {{\\mathbf {z}}} + \\overline {{\\mathbf {u}}} \\cong_ {t ^ {m + 1} - 1} \\overline {{\\mathbf {z}}} \\tag {3.2}</span></div>

    <p class="text-gray-300">In particular, the equivalence relation (3.1) is captured by the lattice <span class="math">\\mathcal{L}</span>, in the sense that</p>

    <div class="my-4 text-center"><span class="math-block">\\overline {{\\mathbf {x}}} \\cong_ {t ^ {m + 1} - 1} \\overline {{\\mathbf {y}}} \\iff \\overline {{\\mathbf {x}}} - \\overline {{\\mathbf {y}}} \\in \\mathcal {L}</span></div>

    <p class="text-gray-300">Therefore if one selects basis vectors for <span class="math">\\mathcal{L}</span> that have infinity-norm approximately <span class="math">t</span>, then for a given <span class="math">\\overline{\\mathbf{z}} \\in \\mathbb{Z}^{m+1}</span>, finding the closest vector <span class="math">\\overline{\\mathbf{u}} \\in \\mathcal{L}</span> to <span class="math">\\overline{\\mathbf{z}}</span> (with respect to the infinity-norm), means the vector <span class="math">\\overline{\\mathbf{w}} = \\overline{\\mathbf{z}} - \\overline{\\mathbf{u}}</span> is in the fundamental domain of <span class="math">\\mathcal{L}</span>, and so has components of the desired size. Furthermore, since <span class="math">\\overline{\\mathbf{w}} = \\overline{\\mathbf{z}} - \\overline{\\mathbf{u}}</span>, by (3.2) we have</p>

    <div class="my-4 text-center"><span class="math-block">\\overline {{\\mathbf {w}}} \\cong_ {t ^ {m + 1} - 1} \\overline {{\\mathbf {z}}},</span></div>

    <p class="text-gray-300">and hence solving the CVP in this lattice solves the CRP. In general solving the CVP is NP-hard, but since we can exhibit a good (near-othogonal) lattice basis for LWPFIs, and an excellent lattice basis for GRPs, solving it is straightforward in our case.</p>

    <h2 id="sec-13" class="text-2xl font-bold">3.4 Lattice basis and simple reduction</h2>

    <p class="text-gray-300">For GRPs, we use the following basis for <span class="math">\\mathcal{L}</span>:</p>

    <div class="my-4 text-center"><span class="math-block">\\left[ \\begin{array}{cccccc} 1 &amp;amp; 0 &amp;amp; \\dots &amp;amp; 0 &amp;amp; 0 &amp;amp; -t \\\\ -t &amp;amp; 1 &amp;amp; \\dots &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\\ 0 &amp;amp; -t &amp;amp; \\dots &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\\ \\vdots &amp;amp; \\vdots &amp;amp; \\ddots &amp;amp; \\vdots &amp;amp; \\vdots &amp;amp; \\vdots \\\\ 0 &amp;amp; 0 &amp;amp; \\dots &amp;amp; -t &amp;amp; 1 &amp;amp; 0 \\\\ 0 &amp;amp; 0 &amp;amp; \\dots &amp;amp; 0 &amp;amp; -t &amp;amp; 1 \\end{array} \\right] \\tag{3.3}</span></div>

    <p class="text-gray-300">Observe that the infinity-norm of each basis vector is <span class="math">t</span>, so elements in the fundamental domain will have components of the desired size, and that each basis vector is orthogonal to all others except the two adjacent vectors (considered cyclically). In order to perform a simple reduction that reduces the size of components by approximately <span class="math">\\log_2 t</span> bits, write each component of <span class="math">\\overline{\\mathbf{z}}</span> in base <span class="math">t</span>: <span class="math">z_i = z_{i,1}t + z_{i,0}</span>. If we define <span class="math">\\overline{\\mathbf{w}}^T</span> to be:</p>

    <div class="my-4 text-center"><span class="math-block">\\left[ \\begin{array}{c} z_m \\\\ z_{m-1} \\\\ \\vdots \\\\ \\vdots \\\\ z_1 \\\\ z_0 \\end{array} \\right] + \\left[ \\begin{array}{cccccc} 1 &amp;amp; 0 &amp;amp; \\dots &amp;amp; 0 &amp;amp; 0 &amp;amp; -t \\\\ -t &amp;amp; 1 &amp;amp; \\dots &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\\ 0 &amp;amp; -t &amp;amp; \\dots &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\\\ \\vdots &amp;amp; \\vdots &amp;amp; \\ddots &amp;amp; \\vdots &amp;amp; \\vdots &amp;amp; \\vdots \\\\ 0 &amp;amp; 0 &amp;amp; \\dots &amp;amp; -t &amp;amp; 1 &amp;amp; 0 \\\\ 0 &amp;amp; 0 &amp;amp; \\dots &amp;amp; 0 &amp;amp; -t &amp;amp; 1 \\end{array} \\right] \\left[ \\begin{array}{c} z_{m-1,1} \\\\ z_{m-2,1} \\\\ \\vdots \\\\ \\vdots \\\\ z_{0,1} \\\\ z_{m,1} \\end{array} \\right],</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">then <span class="math">\\overline{\\mathbf{w}}\\cong_{t^{m+1}-1}\\overline{\\mathbf{z}}</span> and each $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\approx</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">/t<span class="math">, assuming </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">>t^{2}<span class="math">. This was the method of reduction described in <em>[12]</em>, which requires integer division. The idea described in <em>[13]</em> was based on an analogue of Barrett reduction <em>[2]</em>. The method we shall use, from <em>[14]</em>, is based on Montgomery reduction <em>[42]</em> and for </span>t<span class="math"> not a power of </span>2$ is the most efficient of the three Chung-Hasan methods.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-14" class="text-xl font-semibold mt-8">3.5 Montgomery lattice-basis reduction</h3>

    <p class="text-gray-300">In ordinary Montgomery reduction <em>[42]</em>, one has an integer <span class="math">0\\leq Z&lt;pR</span> which is to be reduced modulo <span class="math">p</span>, an odd prime, where here <span class="math">R</span> is the smallest power of the word base <span class="math">b</span> larger than <span class="math">p</span>. The central idea is to add a multiple of <span class="math">p</span> to <span class="math">Z</span> such that the result is divisible by <span class="math">R</span>. Upon dividing by <span class="math">R</span>, which is a simple right shift of words, the result is congruent to <span class="math">ZR^{-1}\\pmod{p}</span>, and importantly is less than <span class="math">2p</span>.</p>

    <p class="text-gray-300">In the context of GRPs, let <span class="math">R=b^{g}</span> be the smallest power of <span class="math">b</span> greater than <span class="math">t</span>. The input to the reduction algorithm is a vector <span class="math">\\overline{\\mathbf{z}}\\in\\mathbb{Z}^{m+1}</span> for which each component is approximately <span class="math">R^{2}</span>. The natural analogue of Montgomery reduction is to add to <span class="math">\\overline{\\mathbf{z}}</span> a vector <span class="math">\\overline{\\mathbf{u}}\\in\\mathcal{L}</span> whose components are also bounded by <span class="math">R^{2}</span>, such that <span class="math">\\overline{\\mathbf{z}}+\\overline{\\mathbf{u}}\\equiv[0,\\ldots,0]\\pmod{R}</span>. Then upon the division of each component by <span class="math">R</span>, the result will be a vector <span class="math">\\overline{\\mathbf{w}}</span> which satisfies</p>

    <p class="text-gray-300"><span class="math">\\overline{\\mathbf{w}}\\cong_{t^{m+1}-1}(\\overline{\\mathbf{z}}+\\overline{\\mathbf{u}})\\cdot R^{-1}\\cong_{t^{m+1}-1}\\overline{\\mathbf{z}}\\cdot R^{-1},</span></p>

    <p class="text-gray-300">and which has components of the desired size. While this introduces an <span class="math">R^{-1}</span> term into the congruence, as with Montgomery arithmetic, one circumvents this simply by altering the original coset representation of <span class="math">\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span>, via the map <span class="math">x\\mapsto xR\\pmod{t^{m+1}-1}</span>, which is bijective since <span class="math">\\gcd(t^{m+1}-1,R)=1</span>, assuming <span class="math">t</span> is even, see §5. How then does one find a suitable lattice point <span class="math">\\overline{\\mathbf{u}}</span>? For this one use the lattice basis (3.3), which from here on in we call <span class="math">L</span>. Proposition 3 of <em>[14]</em> proves that <span class="math">\\det L=1-t^{m+1}</span>, and so <span class="math">\\gcd(\\det L,R)=1</span>. One can therefore compute</p>

    <p class="text-gray-300"><span class="math">\\overline{\\mathbf{u}}^{T}\\stackrel{{\\scriptstyle\\rm def}}{{=}}-L^{-1}\\cdot\\overline{\\mathbf{z}}^{T}\\pmod{R},</span> (3.4) <span class="math">\\overline{\\mathbf{w}}^{T}\\stackrel{{\\scriptstyle\\rm def}}{{=}}(\\overline{\\mathbf{z}}^{T}+L\\cdot\\overline{\\mathbf{u}}^{T})/R,</span> (3.5)</p>

    <p class="text-gray-300">giving <span class="math">\\overline{\\mathbf{w}}</span> with the required properties. Observe that the form of these two operations is identical to Montgomery reduction, the only difference being that integer multiplication is replaced by matrix by vector multiplication. It is easy to see that this is what one requires, since for any <span class="math">\\overline{\\mathbf{u}}\\in\\mathbb{Z}^{m+1}</span>, we have <span class="math">L\\cdot\\overline{\\mathbf{u}}^{T}\\in\\mathcal{L}</span>, and so</p>

    <p class="text-gray-300"><span class="math">\\overline{\\mathbf{z}}^{T}+L\\cdot\\overline{\\mathbf{u}}^{T}\\cong_{t^{m+1}-1}\\overline{\\mathbf{z}}^{T}.</span></p>

    <p class="text-gray-300">Furthermore, modulo <span class="math">R</span> we have</p>

    <p class="text-gray-300"><span class="math">\\overline{\\mathbf{z}}^{T}+L\\cdot\\overline{\\mathbf{u}}^{T}=\\overline{\\mathbf{z}}^{T}+L\\cdot(-L^{-1}\\cdot\\overline{\\mathbf{z}}^{T}\\bmod R)\\equiv[0,\\ldots,0]^{T},</span></p>

    <p class="text-gray-300">ensuring the division of each component by <span class="math">R</span> is exact. Hence <span class="math">\\overline{\\mathbf{w}}\\cong_{t^{m+1}-1}\\overline{\\mathbf{z}}\\cdot R^{-1}</span>, as claimed.</p>

    <p class="text-gray-300">In <em>[14]</em>, an algorithm was given for computing <span class="math">\\overline{\\mathbf{u}}</span> and <span class="math">\\overline{\\mathbf{w}}</span> in (3.4) and (3.5) respectively, for an arbitrary LWPFI <span class="math">f(t)</span>. The number of word-by-word multiply instructions in the algorithm — which is the dominant cost — is <span class="math">\\approx nq^{2}</span>, where <span class="math">n</span> is the degree of <span class="math">f(t)</span>, and <span class="math">R=b^{g}</span>. In comparison, for ordinary Montgomery reduction modulo an integer of equivalent size this number is <span class="math">n^{2}q^{2}</span>, making the former approach potentially very attractive. For our choice of primes — the GRPs — our specialisation of this algorithm is extremely efficient, as we show in §5.</p>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">3.6 High level view of Chung-Hasan arithmetic</p>

    <p class="text-gray-300">For extension fields, there exists a natural separation between the polynomial arithmetic of the extension, and the prime subfield arithmetic, which makes respective optimisation considerations for each almost orthogonal. On the other hand, if for an LWPFI one naively attempts to use efficient techniques that are valid for extension fields, then one encounters an inherent obstruction, namely that there is no such separation between the polynomial arithmetic and the coefficient arithmetic, which leads to coefficient expansion upon performing arithmetic operations. Chung-Hasan arithmetic can be viewed as a tool to overcome this obstruction, since it provides an efficient solution to the coefficent reduction problem. In practice therefore any efficient techniques for extension field arithmetic can be ported to prime fields, whenever the prime is an LWPFI, which is precisely what we do in §4.</p>

    <h2 id="sec-15" class="text-2xl font-bold">4 GRP Multiplication</h2>

    <p class="text-gray-300">In this section we detail algorithms for performing multiplication of GRP residue representatives. While for the reduction and residue representation we consider elements to be in <span class="math">\\mathbb{Z}^{m+1}</span>, the multiplication algorithm arises from the arithmetic of the polynomial ring <span class="math">\\mathbb{Z}[T]/(T^{m+1}-1)\\mathbb{Z}[T]</span>, and so here we use this ring to derive the multiplication formulae.</p>

    <h3 id="sec-16" class="text-xl font-semibold mt-8">4.1 Ordinary multiplication formulae</h3>

    <p class="text-gray-300">Let <span class="math">\\mathcal{R}=\\mathbb{Z}[T]/(T^{m+1}-1)\\mathbb{Z}[T]</span>, and let <span class="math">\\overline{\\mathbf{x}}=[x_{m},\\ldots,x_{0}]</span> and <span class="math">\\overline{\\mathbf{y}}=[y_{m},\\ldots,y_{0}]</span> be elements in <span class="math">\\mathcal{R}</span>. Then in <span class="math">\\mathcal{R}</span> the product <span class="math">\\overline{\\mathbf{x}}\\cdot\\overline{\\mathbf{y}}</span> is equal to <span class="math">[z_{m},\\ldots,z_{0}]</span>, where</p>

    <p class="text-gray-300"><span class="math">z_{i}=\\sum_{j=0}^{m}x_{\\langle j\\rangle}y_{\\langle i-j\\rangle},</span> (4.1)</p>

    <p class="text-gray-300">where the subscript <span class="math">\\langle i\\rangle</span> denotes <span class="math">i\\pmod{m+1}</span>. This follows from the trivial property <span class="math">T^{m+1}\\equiv 1\\pmod{T^{m+1}-1}</span>, and that for <span class="math">\\overline{\\mathbf{x}}=\\sum_{i=0}^{m}x_{i}T^{i}</span> and <span class="math">\\overline{\\mathbf{y}}=\\sum_{j=0}^{m}y_{j}T^{j}</span>, we have:</p>

    <p class="text-gray-300"><span class="math">\\overline{\\mathbf{x}}\\cdot\\overline{\\mathbf{y}}</span> <span class="math">=\\sum_{i=0}^{m}x_{i}\\cdot(T^{i}\\cdot\\overline{\\mathbf{y}})=\\sum_{i=0}^{m}x_{i}\\cdot\\Big{(}\\sum_{j=0}^{m}y_{j}T^{i+j}\\Big{)}</span> <span class="math">=\\sum_{i=0}^{m}x_{i}\\cdot\\Big{(}\\sum_{j=0}^{m}y_{\\langle j-i\\rangle}T^{j}\\Big{)}=\\sum_{j=0}^{m}\\Big{(}\\sum_{i=0}^{m}x_{i}\\cdot y_{\\langle j-i\\rangle}\\Big{)}T^{j}.</span></p>

    <p class="text-gray-300">This is of course just the cyclic convolution of <span class="math">\\overline{\\mathbf{x}}</span> and <span class="math">\\overline{\\mathbf{y}}</span>.</p>

    <h3 id="sec-17" class="text-xl font-semibold mt-8">4.2 Multiplication formulae of Nogami et al.</h3>

    <p class="text-gray-300">Nogami, Saito and Morikawa proposed the use of all-one polynomials (AOPs) to define extensions of prime fields <em>[44]</em>. In this section we will first describe their algorithm in this context, and then show how it fits into the framework developed in §3.</p>

    <p class="text-gray-300">Let <span class="math">\\mathbb{F}_{p}</span> be a prime field and let <span class="math">f(\\omega)=\\omega^{m}+\\omega^{m-1}+\\cdots+\\omega+1</span> be irreducible over <span class="math">\\mathbb{F}_{p}</span>, i.e., <span class="math">m+1</span> is prime and <span class="math">p</span> is a primitive root modulo <span class="math">m+1</span>. Then <span class="math">\\mathbb{F}_{p^{m}}=\\mathbb{F}_{p}[\\omega]/(f(\\omega)\\mathbb{F}_{p}[\\omega])</span>. Using</p>

    <p class="text-gray-300">the polynomial basis <span class="math">\\{\\omega^{m},\\omega^{m-1},\\dots,\\omega\\}</span> — rather than the more conventional <span class="math">\\{\\omega^{m-1},\\dots,\\omega,1\\}</span> — elements of <span class="math">\\mathbb{F}_{p^{m}}</span> are represented as vectors of length <span class="math">m</span> over <span class="math">\\mathbb{F}_{p}</span>:</p>

    <p class="text-gray-300"><span class="math">\\overline{\\mathbf{x}}=[x_{m},\\dots,x_{1}]=x_{m}\\omega^{m}+x_{m-1}\\omega^{m-1}+\\dots+x_{1}\\omega.</span></p>

    <p class="text-gray-300">Let <span class="math">\\overline{\\mathbf{x}}=[x_{m},\\dots,x_{1}]</span> and <span class="math">\\overline{\\mathbf{y}}=[y_{m},\\dots,y_{1}]</span> be two elements to be multiplied. For <span class="math">0\\leq i\\leq m</span>, let</p>

    <p class="text-gray-300"><span class="math">q_{i}=\\sum_{j=1}^{m/2}(x_{\\langle\\frac{i}{2}+j\\rangle}-x_{\\langle\\frac{i}{2}-j\\rangle})(y_{\\langle\\frac{i}{2}+j\\rangle}-y_{\\langle\\frac{i}{2}-j\\rangle}),</span> (4.2)</p>

    <p class="text-gray-300">where the subscript <span class="math">\\langle i\\rangle</span> here, as in §4.1, denotes <span class="math">i\\pmod{m+1}</span>. One then has:</p>

    <p class="text-gray-300"><span class="math">\\overline{\\mathbf{z}}=\\overline{\\mathbf{x}}\\cdot\\overline{\\mathbf{y}}=\\sum_{i=1}^{m}z_{i}\\omega^{i},\\ \\ \\text{with}\\ z_{i}=q_{0}-q_{i}.</span> (4.3)</p>

    <p class="text-gray-300">Nogami et al. refer to these coefficient formulae as the cyclic vector multiplication algorithm (CVMA) formulae. The CVMA formulae are remarkable, since the number of <span class="math">\\mathbb{F}_{p}</span> multiplications is reduced relative to the schoolbook method from <span class="math">m^{2}</span> to <span class="math">m(m+1)/2</span>, but at the cost of increasing the number of <span class="math">\\mathbb{F}_{p}</span> additions from <span class="math">m^{2}-1</span> to <span class="math">3m(m-1)/2-1</span>. As alluded to in §3.6, a basic insight of the present work is the observation that one may apply the expressions in (4.2) to GRP multiplication, provided that one uses the Chung-Hasan representation and reduction methodology of §3, to give a full modular multiplication algorithm.</p>

    <p class="text-gray-300">Note that Karatsuba-Ofman multiplication <em>[30]</em> offers a similar trade-off for extension field arithmetic. Crucially however, as we show in §4.6, when we apply these formulae to GRPs the number of additions required is in fact reduced. One thus expects the CVMA to be significantly more efficient at contemporary ECC bitlengths. The original proof of (4.3) given in <em>[44]</em> excludes some intermediate steps and so for the sake of clarity we give a full proof in §4.4, beginning with the following motivation.</p>

    <h3 id="sec-18" class="text-xl font-semibold mt-8">4.3 Alternative bases</h3>

    <p class="text-gray-300">Observe that in the set of equations (4.2), each of the <span class="math">2(m+1)</span> coefficients <span class="math">x_{j},y_{j}</span> is featured <span class="math">m+1</span> times, and so there is a nice symmetry and balance to the formulae. However due to the choice of basis, both <span class="math">x_{0}</span> and <span class="math">y_{0}</span> are implicitly assumed to be zero. The output <span class="math">\\overline{\\mathbf{z}}</span> naturally has this property also, and indeed if one extends the multiplication algorithm to compute <span class="math">z_{0}</span> we see that it equals <span class="math">q_{0}-q_{0}=0</span>.</p>

    <p class="text-gray-300">At first sight, the expression <span class="math">z_{i}=q_{0}-q_{i}</span> may seem a little unnatural. It is easy to change the basis from <span class="math">\\{\\omega^{m},\\dots,\\omega\\}</span> to <span class="math">\\{\\omega^{m-1},\\dots,\\omega,1\\}</span>: for <span class="math">\\overline{\\mathbf{x}}=[x_{m-1},\\dots,x_{0}]</span> and <span class="math">\\overline{\\mathbf{y}}=[y_{m-1},\\dots,y_{0}]</span>, we have:</p>

    <p class="text-gray-300"><span class="math">\\overline{\\mathbf{z}}=\\overline{\\mathbf{x}}\\cdot\\overline{\\mathbf{y}}=\\sum_{i=0}^{m-1}z_{i}\\omega^{i},</span></p>

    <p class="text-gray-300">resulting in the expressions <span class="math">z_{i}=q_{m}-q_{i}</span>, with <span class="math">q_{i}</span> as given before. This change of basis relies on the relation</p>

    <p class="text-gray-300"><span class="math">\\omega^{m}\\equiv-1-\\omega-\\dots-\\omega^{m-1}\\ \\text{mod}\\ f(\\omega).</span> (4.4)</p>

    <p class="text-gray-300">Note that in using this basis we have implicitly ensured that <span class="math">x_{m}=y_{m}=0</span> in (4.2), rather than <span class="math">x_{0}=y_{0}=0</span>, and again the above formula is consistent since <span class="math">z_{m}=q_{m}-q_{m}=0</span>. More generally if one excludes <span class="math">\\omega^{k}</span> from the basis, then <span class="math">x_{k}=y_{k}=0</span> and <span class="math">z_{i}=q_{k}-q_{i}</span>.</p>

    <p class="text-gray-300">One may infer from these observations that the most natural choice of basis would seem to be <span class="math">\\{\\omega^m,\\ldots ,\\omega ,1\\}</span>, and that the expressions for <span class="math">q_{i}</span> arise from the arithmetic in the quotient ring <span class="math">\\mathcal{R}&#x27; = \\mathbb{F}_p[\\omega ] / ((\\omega^{m + 1} - 1)\\mathbb{F}_p[\\omega ])</span>, rather than <span class="math">\\mathbb{F}_{p^m} = \\mathbb{F}_p[\\omega ] / (f(\\omega)\\mathbb{F}_p[\\omega ])</span>. In this case multiplication becomes</p>

    <div class="my-4 text-center"><span class="math-block">\\overline {{\\mathbf {z}}} = \\overline {{\\mathbf {x}}} \\cdot \\overline {{\\mathbf {y}}} = \\sum_ {i = 0} ^ {m - 1} z _ {i} \\omega^ {i} = \\sum_ {i = 0} ^ {m - 1} (q _ {m} - q _ {i}) \\omega^ {i} = \\sum_ {i = 0} ^ {m} - q _ {i} \\omega^ {i},</span></div>

    <p class="text-gray-300">where for the last equality we have again used equation (4.4).</p>

    <h2 id="sec-19" class="text-2xl font-bold">4.4 Derivation of coefficient formulae</h2>

    <p class="text-gray-300">We now derive the CVMA formulae of (4.2). Let <span class="math">\\overline{\\mathbf{x}} = [x_m, \\ldots, x_0] = \\sum_{i=0}^{m} x_i \\omega^i</span>, and <span class="math">\\overline{\\mathbf{y}} = [y_m, \\ldots, y_0] = \\sum_{i=0}^{m} y_i \\omega^i</span>. Then in the ring <span class="math">\\mathcal{R}&#x27;</span>, as in (4.1) the product <span class="math">\\overline{\\mathbf{x}} \\cdot \\overline{\\mathbf{y}}</span> is equal to <span class="math">\\sum_{i=0}^{m} z_i \\omega^i</span>, where</p>

    <div class="my-4 text-center"><span class="math-block">z _ {i} = \\sum_ {j = 0} ^ {m} x _ {\\langle j \\rangle} y _ {\\langle i - j \\rangle}.</span></div>

    <p class="text-gray-300">Of crucial importance is the following identity. For <span class="math">0 \\leq i \\leq m</span> we have:</p>

    <div class="my-4 text-center"><span class="math-block">2 \\sum_ {j = 0} ^ {m} x _ {\\langle j \\rangle} y _ {\\langle i - j \\rangle} - 2 \\sum_ {j = 0} ^ {m} x _ {\\langle j \\rangle} y _ {\\langle j \\rangle} = - \\sum_ {j = 0} ^ {m} \\left(x _ {\\langle j \\rangle} - x _ {\\langle i - j \\rangle}\\right) \\left(y _ {\\langle j \\rangle} - y _ {\\langle i - j \\rangle}\\right). \\tag {4.5}</span></div>

    <p class="text-gray-300">To verify this identity observe that when one expands the terms in the right-hand side, the two negative sums cancel with the second term on the left-hand side, since both are over a complete set of residues modulo <span class="math">m + 1</span>. Similarly the two positive sums are equal and therefore cancel with the convolutions in the first term on the left-hand side. We now observe that there is some redundancy in the right-hand side of (4.5), in the following sense. First, observe that</p>

    <div class="my-4 text-center"><span class="math-block">\\sum_ {j = 0} ^ {m} x _ {\\langle \\frac {j}{2} + j \\rangle} y _ {\\langle \\frac {j}{2} - j \\rangle} = \\sum_ {j = 0} ^ {m} x _ {\\langle \\frac {j}{2} + (j - \\frac {j}{2}) \\rangle} y _ {\\langle \\frac {j}{2} - (j - \\frac {j}{2}) \\rangle} = \\sum_ {j = 0} ^ {m} x _ {\\langle j \\rangle} y _ {\\langle i - j \\rangle}.</span></div>

    <p class="text-gray-300">One can therefore rewrite the right-hand side of (4.5) as:</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>\\sum_ {j = 0} ^ {m} \\left(x _ {\\langle \\frac {j}{2} + j \\rangle} - x _ {\\langle \\frac {j}{2} - j \\rangle}\\right) \\left(y _ {\\langle \\frac {j}{2} + j \\rangle} - y _ {\\langle \\frac {j}{2} - j \\rangle}\\right). \\tag {4.6}</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">Noting that the <span class="math">j = 0</span> term of expression (4.6) is zero, we rewrite it as:</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>\\sum_ {j = 1} ^ {m / 2} (x _ {\\langle \\frac {j}{2} + j \\rangle} - x _ {\\langle \\frac {j}{2} - j \\rangle}) (y _ {\\langle \\frac {j}{2} + j \\rangle} - y _ {\\langle \\frac {j}{2} - j \\rangle}) - \\sum_ {j = m / 2 + 1} ^ {m} (x _ {\\langle \\frac {j}{2} + j \\rangle} - x _ {\\langle \\frac {j}{2} - j \\rangle}) (y _ {\\langle \\frac {j}{2} + j \\rangle} - y _ {\\langle \\frac {j}{2} - j \\rangle}),</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">which in turn becomes</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>\\sum_ {j = 1} ^ {m / 2} (x _ {\\langle \\frac {j}{2} + j \\rangle} - x _ {\\langle \\frac {j}{2} - j \\rangle}) (y _ {\\langle \\frac {j}{2} + j \\rangle} - y _ {\\langle \\frac {j}{2} - j \\rangle}) - \\sum_ {j = 1} ^ {m / 2} (x _ {\\langle \\frac {j}{2} - j \\rangle} - x _ {\\langle \\frac {j}{2} + j \\rangle}) (y _ {\\langle \\frac {j}{2} - j \\rangle} - y _ {\\langle \\frac {j}{2} + j \\rangle}),</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">and then upon negating the two terms in the second summation, we finally have</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>\\sum_ {j = 0} ^ {m} (x _ {\\langle \\frac {j}{2} + j \\rangle} - x _ {\\langle \\frac {j}{2} - j \\rangle}) (y _ {\\langle \\frac {j}{2} + j \\rangle} - y _ {\\langle \\frac {j}{2} - j \\rangle}) = 2 \\sum_ {j = 1} ^ {m / 2} (x _ {\\langle \\frac {j}{2} + j \\rangle} - x _ {\\langle \\frac {j}{2} - j \\rangle}) (y _ {\\langle \\frac {j}{2} + j \\rangle} - y _ {\\langle \\frac {j}{2} - j \\rangle}).</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">Hence (4.5) becomes</p>

    <div class="my-4 text-center"><span class="math-block">\\sum_ {j = 0} ^ {m} x _ {\\langle j \\rangle} y _ {\\langle i - j \\rangle} = \\sum_ {j = 0} ^ {m} x _ {\\langle j \\rangle} y _ {\\langle j \\rangle} - \\sum_ {j = 1} ^ {m / 2} \\left(x _ {\\langle \\frac {j}{2} + j \\rangle} - x _ {\\langle \\frac {j}{2} - j \\rangle}\\right) \\left(y _ {\\langle \\frac {j}{2} + j \\rangle} - y _ {\\langle \\frac {j}{2} - j \\rangle}\\right). \\tag {4.7}</span></div>

    <p class="text-gray-300">Equation (4.7) gives an expression for the coefficients of the product  <span class="math">\\overline{\\mathbf{z}}</span>  of elements  <span class="math">\\overline{\\mathbf{x}}</span>  and  <span class="math">\\overline{\\mathbf{y}}</span> , in the ring  <span class="math">\\mathcal{R}&#x27;</span> . Assuming these are computed using the more efficient right-hand side, in order to restrict back to  <span class="math">\\mathbb{F}_p[\\omega] / (f(\\omega)\\mathbb{F}_p[\\omega])</span> , one can reduce the resulting polynomial  <span class="math">\\overline{\\mathbf{z}}</span>  by  <span class="math">f(\\omega)</span> . Note however that one does not need to use a smaller basis à la Nogami et al. in §4.2 or §4.3, but can reduce by  <span class="math">f(\\omega)</span>  implicitly, without performing any computation. Indeed, letting  <span class="math">\\langle \\overline{\\mathbf{x}},\\overline{\\mathbf{y}}\\rangle = \\sum_{j = 0}^{m}x_{\\langle j\\rangle}y_{\\langle j\\rangle}</span> , we have:</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\overline {{\\mathbf {z}}} = \\sum_ {i = 0} ^ {m} z _ {i} \\omega^ {i} = \\sum_ {i = 0} ^ {m} (- q _ {i} + \\langle \\overline {{\\mathbf {x}}}, \\overline {{\\mathbf {y}}} \\rangle) \\omega^ {i} = \\sum_ {i = 0} ^ {m} - q _ {i} \\omega^ {i} + \\langle \\overline {{\\mathbf {x}}}, \\overline {{\\mathbf {y}}} \\rangle \\sum_ {i = 0} ^ {m} \\omega^ {i} \\\\ \\equiv \\sum_ {i = 0} ^ {m} - q _ {i} \\omega^ {i} \\quad (\\mathrm {m o d} f (\\omega)). \\tag {4.8} \\\\ \\end{array}</span></div>

    <p class="text-gray-300">Therefore the first term on the right-hand side of (4.7) vanishes, so that one need not even compute it. Thus using the arithmetic in  <span class="math">\\mathcal{R}&#x27;</span>  but implicitly working modulo  <span class="math">f(\\omega)</span>  is more efficient than performing arithmetic in  <span class="math">\\mathcal{R}&#x27;</span>  alone. This is somewhat fortuitous as it means that while the multiply operation in (4.8) is not correct in  <span class="math">\\mathcal{R}&#x27;</span> , nevertheless, when one maps back to  <span class="math">\\mathbb{F}_p[\\omega] / (f(\\omega)\\mathbb{F}_p[\\omega])</span> , it is correct.</p>

    <h2 id="sec-20" class="text-2xl font-bold">4.5 Application to GRPs</h2>

    <p class="text-gray-300">Since equation (4.5) is an algebraic identity, it is easy to see that exactly the same argument applies in the context of GRPs, and we can replace the formulae (4.1) with the CVMA formulae (4.2). Since reduction in the ring  <span class="math">\\mathcal{R} = \\mathbb{Z}[T] / (T^{m + 1} - 1)\\mathbb{Z}[T]</span>  has a particularly nice form for GRPs, we choose to use the full basis for  <span class="math">\\mathcal{R}</span>  and hence do not reduce explicitly modulo  <span class="math">\\varPhi_{m+1}(T)</span>  to obtain a smaller basis. This also has the effect of eliminating the need to perform the addition of  <span class="math">q_0</span>  (or  <span class="math">q_m</span> , or whichever term one wants to eliminate when one reduces modulo  <span class="math">\\varPhi_{m+1}(T)</span> ), simplifying the multiplication algorithm further. Absorbing the minus sign into the  <span class="math">q_i</span> , Algorithm 1 details how to multiply residue representatives.</p>

    <p class="text-gray-300">Remark 1. Observe that each component of  <span class="math">\\overline{\\mathbf{z}}</span>  may be computed entirely independently of the others. Hence using  <span class="math">m + 1</span>  processors rather than 1, it would be possible to speed up the execution time of Algorithm 1 by a factor of  <span class="math">m + 1</span> , making it particularly suitable for hardware implementation. In §5 we consider the parallelisation of our reduction algorithms as well.</p>

    <p class="text-gray-300">Algorithm 1 GRP MULTIPLICATION INPUT: <span class="math">\\overline{\\mathbf{x}}=[x_{m},\\ldots,x_{0}],\\overline{\\mathbf{y}}=[y_{m},\\ldots,y_{0}]\\in\\mathbb{Z}^{m+1}</span> OUTPUT: <span class="math">\\overline{\\mathbf{z}}=[z_{m},\\ldots,z_{0}]\\in\\mathbb{Z}^{m+1}</span> where <span class="math">\\overline{\\mathbf{z}}\\cong_{\\varPhi_{m+1}(t)}\\overline{\\mathbf{x}}\\cdot\\overline{\\mathbf{y}}</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For <span class="math">i=m</span> to 0 do:</li>

      <li><span class="math">z_{i}\\leftarrow\\sum_{j=1}^{m/2}(x_{\\langle\\frac{i}{2}-j\\rangle}-x_{\\langle\\frac{i}{2}+j\\rangle})\\cdot(y_{\\langle\\frac{i}{2}+j\\rangle}-y_{\\langle\\frac{i}{2}-j\\rangle})</span></li>

      <li>Return <span class="math">\\overline{\\mathbf{z}}</span></li>

    </ol>

    <h3 id="sec-21" class="text-xl font-semibold mt-8">4.6 Cost comparison</h3>

    <p class="text-gray-300">We here use a simple cost model to provide a measure of the potential performance improvement achieved by using Algorithm 1, rather than schoolbook multiplication of residues. We assume the inputs to the multiplication algorithm have coefficients bounded by <span class="math">b^{q}</span>, i.e., they each consist of <span class="math">q</span> words. Let <span class="math">M(q,q)</span> be the cost of a <span class="math">q</span>-word by <span class="math">q</span>-word schoolbook multiplication, and let <span class="math">A(q,q)</span> be the cost of an ition of two <span class="math">q</span>-word values. We assume that <span class="math">A(2q,2q)=2A(q,q)</span> and that there is no overflow beyond <span class="math">2q</span> words in the resulting vector components, which one can ensure by selecting appropriate GRPs, see §7. The cost of the multiplication using each method is as follows.</p>

    <h4 id="sec-22" class="text-lg font-semibold mt-6">4.6.1 GRP schoolbook multiplication</h4>

    <p class="text-gray-300">Working modulo <span class="math">T^{m}+\\cdots+T+1</span> and using a basis consisting of <span class="math">m</span> terms only, the number of coefficient multiplications is <span class="math">m^{2}</span>, while the number of double-length additions is also <span class="math">m^{2}</span>. Hence the total cost is simply</p>

    <p class="text-gray-300"><span class="math">m^{2}\\cdot M(q,q)+2m^{2}\\cdot A(q,q).</span></p>

    <p class="text-gray-300">Note that computing the convolution (4.1) costs</p>

    <p class="text-gray-300"><span class="math">(m+1)^{2}\\cdot M(q,q)+2m(m+1)\\cdot A(q,q),</span></p>

    <p class="text-gray-300">which is costlier since it requires embedding into <span class="math">\\mathcal{R}</span>, which introduces some redundancy.</p>

    <h4 id="sec-23" class="text-lg font-semibold mt-6">4.6.2 CVMA formulae</h4>

    <p class="text-gray-300">For each <span class="math">z_{i}</span> computing each term in the sum costs <span class="math">M(q,q)+2A(q,q)</span>, and so computing all these terms costs <span class="math">\\frac{m}{2}\\cdot(M(q,q)+2A(q,q))</span>. The cost of adding these is <span class="math">(\\frac{m}{2}-1)A(2q,2q)=(m-2)\\cdot A(q,q)</span>. For all the <span class="math">m+1</span> terms <span class="math">z_{i}</span> the total cost is therefore</p>

    <p class="text-gray-300"><span class="math">\\frac{m(m+1)}{2}\\cdot M(q,q)+2(m^{2}-1)\\cdot A(q,q).</span></p>

    <p class="text-gray-300">Therefore by using the CVMA formulae, we reduce not only the number of multiplications, but also the number of additions (by 2), contrary to the case of field extensions, for which the CVMA formulae increases the number of additions by nearly 50%. We have thus found an analogue of the asymptotic cyclic versus linear convolution speed up at small bitlengths for which schoolbook multiplication is optimal, for GRPs.</p>

    <p class="text-gray-300">5 GRP Reduction</p>

    <p class="text-gray-300">In this section we detail reduction algorithms for two types of GRPs. The first, Algorithm 2, assumes only that <span class="math">t</span> is even, which provides the minimum possible restriction on the form of the resulting GRPs for any given bitlength. All such GRPs can therefore be implemented with code parametrised by the single variable <span class="math">t</span>, which may be beneficial for some applications. Supposing that <span class="math">R = b^{q} &amp;gt; t</span>, then as with Montgomery reduction, it is more efficient to reduce components not by <span class="math">R</span> as in (3.4) and (3.5), but by <span class="math">b</span> sequentially <span class="math">q</span> times. In Algorithm 2 each reduction therefore reduces the input's components by approximately <span class="math">\\log_2 b</span> bits.</p>

    <p class="text-gray-300">The second reduction method as detailed in Algorithm 3 is a specialisation of Algorithm 2. It assumes that <span class="math">t \\equiv 0 \\mod 2^l</span> for some <span class="math">l &amp;gt; 1</span>, and each application of the reduction function reduces the input's components by approximately <span class="math">l</span> bits. Algorithm 3 is potentially far more efficient than Algorithm 2, depending on the form of <span class="math">t</span>. Ideally one should choose a <span class="math">t</span> for which <span class="math">l &amp;gt; (\\log_2 t) / 2</span> so that two applications of the reduction function are sufficient in order to produce components of the desired size, which is minimal. In general for other values of <span class="math">l</span> a larger number of reductions may be needed, which we consider in §7. In contrast to Algorithm 2, which is designed for generality, Algorithm 3 is geared towards high-speed reduction. The trade-off arising here is that there will naturally be far fewer GRPs of this restricted form. We also present a modification of Algorithm 3, which is slightly more efficient in practice, in Algorithm 4.</p>

    <h2 id="sec-24" class="text-2xl font-bold">5.1 GRP reduction: <span class="math">t</span> even</h2>

    <p class="text-gray-300">Following §3.5, in equation (3.4) we need the matrix <span class="math">-L^{-1}</span>:</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>L ^ {- 1} = \\frac {1}{t ^ {m + 1} - 1} \\left[ \\begin{array}{c c c c c} 1 &amp; t ^ {m} &amp; \\dots &amp; t ^ {3} &amp; t ^ {2} &amp; t \\\\ t &amp; 1 &amp; \\dots &amp; t ^ {4} &amp; t ^ {3} &amp; t ^ {2} \\\\ t ^ {2} &amp; t &amp; \\dots &amp; t ^ {5} &amp; t ^ {4} &amp; t ^ {3} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ t ^ {m - 1} &amp; t ^ {m - 2} &amp; \\dots &amp; t &amp; 1 &amp; t ^ {m} \\\\ t ^ {m} &amp; t ^ {m - 1} &amp; \\dots &amp; t ^ {2} &amp; t &amp; 1 \\end{array} \\right]. \\tag {5.1}</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">The form of <span class="math">L</span> and <span class="math">-L^{-1}</span> allows one to compute <span class="math">\\overline{\\mathbf{u}} = -L^{-1} \\cdot \\overline{\\mathbf{z}} \\mod b</span> and <span class="math">L \\cdot \\overline{\\mathbf{u}}</span>, computed in equation (3.5), very efficiently. Since <span class="math">t</span> is even, the following vector may be computed. Let <span class="math">t[0]</span> be the least significant digit of <span class="math">t</span>, written in base <span class="math">b</span>, and let</p>

    <div class="my-4 text-center"><span class="math-block">\\overline {{\\mathbf {V}}} \\stackrel {\\mathrm {d e f}} {=} \\frac {1}{t [ 0 ] ^ {m + 1} - 1} [ t [ 0 ] ^ {m}, t [ 0 ] ^ {m - 1}, \\ldots , t [ 0 ], 1 ] \\bmod b.</span></div>

    <p class="text-gray-300">Algorithm 2 details how to reduce a given an input vector <span class="math">\\overline{\\mathbf{z}}</span> by <span class="math">b</span>, modulo <span class="math">t^{m + 1} - 1</span>, given the precomputed vector <span class="math">\\overline{\\mathbf{V}}</span>. Observe that Algorithm 2 greatly simplifies the reduction algorithm originally given in [14]. This is possible since for <span class="math">t^{m + 1} - 1</span> one can interleave the computation of the vectors <span class="math">\\overline{\\mathbf{u}}</span> and <span class="math">\\overline{\\mathbf{w}}</span> defined in (3.4) and (3.5) respectively. This has two benefits. First, as one computes each component of <span class="math">\\overline{\\mathbf{w}}</span> sequentially, one need only store a single component of <span class="math">\\overline{\\mathbf{u}}</span>, rather than <span class="math">m + 1</span>. Second, since when one computes <span class="math">L\\cdot \\overline{\\mathbf{u}}</span> one needs to compute <span class="math">t\\cdot u_{\\langle i + 1\\rangle}</span> for <span class="math">i = m,\\ldots ,0</span> (in line 3), one obtains <span class="math">t[0]\\cdot u_{i}</span> (the first term on right-hand side of line 4) for free by computing the full product <span class="math">t\\cdot u_{\\langle i + 1\\rangle}</span> first. One therefore avoids recomputing the least significant digit of <span class="math">t\\cdot u_{\\langle i + 1\\rangle}</span> in each loop iteration. In fact one can do this for any polynomial</p>

    <p class="text-gray-300"><span class="math">t^{m+1}-c</span>, with exactly the same algorithm, the only difference being in the definition of <span class="math">\\overline{\\mathbf{V}}</span>, where <span class="math">t^{m+1}-c</span> becomes the denominator. For polynomials with other non-zero coefficients, this does not seem possible, and so Algorithm 2 seems likely to be the most efficient Chung-Hasan reduction possible with this minimal restriction on the form of <span class="math">t</span>.</p>

    <p class="text-gray-300">Algorithm 2: red<span class="math">1_{b}(\\overline{\\mathbf{z}})</span></p>

    <p class="text-gray-300">INPUT: <span class="math">\\overline{\\mathbf{z}}=[z_{m},\\ldots,z_{0}]\\in\\mathbb{Z}^{m+1}</span> OUTPUT: <span class="math">\\mathrm{red}_{b}(\\overline{\\mathbf{z}})</span> where <span class="math">\\mathrm{red}_{b}(\\overline{\\mathbf{z}})\\cong_{t^{m+1}-1}\\overline{\\mathbf{z}}\\cdot b^{-1}</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Set <span class="math">u_{0}\\leftarrow(\\sum_{i=0}^{m}V_{i}\\cdot z_{i}[0])\\bmod b</span></li>

      <li>For <span class="math">i=m</span> to <span class="math">0</span> do:</li>

      <li><span class="math">v_{i}\\leftarrow t\\cdot u_{\\langle i+1\\rangle}</span></li>

      <li><span class="math">u_{i}\\leftarrow(v_{i}[0]-z_{i}[0])\\bmod b</span></li>

      <li><span class="math">w_{i}\\leftarrow(z_{i}+u_{i}-v_{i})/b</span></li>

      <li>Return <span class="math">\\overline{\\mathbf{w}}</span></li>

    </ol>

    <p class="text-gray-300">It is straightforward to verify that Algorithm 2 correctly produces an output vector in the correct congruency class, via a sequence of simple transformations of <em>[14, Algorithm 3]</em>. However we do not do so here, since we are mainly interested in the more efficient Algorithms 3 and 4.</p>

    <h6 id="sec-25" class="text-base font-medium mt-4">Remark 2</h6>

    <p class="text-gray-300">Note that in the final loop iteration, <span class="math">u_{0}</span> from line 1 is recomputed, which is therefore unnecessary. However, we chose to write the algorithm in this form to emphasise its cyclic structure. Indeed, there is no need to compute <span class="math">u_{0}</span> first; if one cyclically rotates <span class="math">\\overline{\\mathbf{V}}</span> by <span class="math">j</span> places to the left, then the vector <span class="math">\\overline{\\mathbf{w}}</span> to be added to <span class="math">\\overline{\\mathbf{z}}</span> in (3.5) is rotated <span class="math">j</span> places to the left also. One can therefore compute each coefficient of <span class="math">\\mathrm{red}1_{b}(\\overline{\\mathbf{z}})</span> independently of the others using a rotated definition for <span class="math">\\overline{\\mathbf{V}}</span> (or equivalently by rotating the input <span class="math">\\overline{\\mathbf{z}}</span> ). This demonstrates that a parallelised version of the reduction algorithm with <span class="math">m+1</span> processors is feasible. However, as each processor requires the least significant word of each component of <span class="math">\\overline{\\mathbf{z}}</span>, this necessitates a synchronised broadcast before each invocation of the reduction function. In this scenario the reduction time would be proportional to the number of such broadcasts and reductions required, independently of <span class="math">m+1</span>.</p>

    <h3 id="sec-26" class="text-xl font-semibold mt-8">5.2 GRP reduction: <span class="math">t\\equiv 0\\bmod 2^{l}</span></h3>

    <p class="text-gray-300">In the ideal case that <span class="math">t=2^{l}</span>, we see that such a GRP would be a GMN. In this case, one can use the reduction method detailed in §3.4 without resorting to using its Montgomery version at all. Multiplication would also be faster thanks to Nogami’s formulae. Unfortunately, such GRPs seem to be very rare. It is easy to show that if <span class="math">t=2^{l}</span> with <span class="math">l&gt;1</span> and <span class="math">\\Phi_{m+1}(t)</span> is prime, then <span class="math">l=m+1</span>. Testing the first few cases, we find prime GRPs for <span class="math">l=2,3,7,59</span> but no others for prime <span class="math">l&lt;400</span>. Note that these primes contradict Dubner’s assertion that no such GRPs exist <em>[17, §2]</em>. Since for <span class="math">l=59</span> the corresponding GRP has <span class="math">3422</span> bits, this is already out of our target range for ECC, so we need not worry about such GRPs.</p>

    <p class="text-gray-300">Hoping not to cause confusion, in this subsection we now let <span class="math">b=2^{l}</span> where <span class="math">l</span> is not necessarily and usually not the word size of the target architecture. We denote the cofactor of <span class="math">b</span> in <span class="math">t</span> by <span class="math">c</span> (which by the above discussion we assume is <span class="math">&gt;1</span>), so that <span class="math">t=b\\cdot c</span>. Algorithm 3 details how to reduce a given an input vector <span class="math">\\overline{\\mathbf{z}}</span> by <span class="math">b</span>, modulo <span class="math">t^{m+1}-1</span>.</p>

    <p class="text-gray-300">Algorithm 3: red2_b(z)</p>

    <p class="text-gray-300">INPUT: <span class="math">\\overline{\\mathbf{z}} = [z_m,\\dots,z_0]\\in \\mathbb{Z}^{m + 1}</span></p>

    <p class="text-gray-300">OUTPUT: <span class="math">\\operatorname{red}_b(\\overline{\\mathbf{z}})</span> where <span class="math">\\operatorname{red}_b(\\overline{\\mathbf{z}}) \\cong_{t^{m+1}-1} \\overline{\\mathbf{z}} \\cdot b^{-1}</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For <span class="math">i = m</span> to 0 do:</li>

      <li><span class="math">w_{i}\\gets (z_{i} + (-z_{i}\\bmod b)) / b - c\\cdot (-z_{\\langle i + 1\\rangle}\\bmod b)</span></li>

      <li>Return <span class="math">\\overline{\\mathbf{w}}</span></li>

    </ol>

    <p class="text-gray-300">A simple proof of correctness of Algorithm 3 comes from the specialisation of Algorithm 2. Since <span class="math">t \\equiv 0 \\mod b</span>, writing <span class="math">t</span> in base <span class="math">b</span>, the vector <span class="math">\\overline{\\mathbf{V}}</span> becomes</p>

    <div class="my-4 text-center"><span class="math-block">\\overline{\\mathbf{V}} \\stackrel{\\text{def}}{=} [0, \\dots, 0, -1] \\bmod b.</span></div>

    <p class="text-gray-300">Hence for line 1 of Algorithm 2 we have</p>

    <div class="my-4 text-center"><span class="math-block">u _ {0} \\leftarrow - z _ {0} [ 0 ] \\bmod b.</span></div>

    <p class="text-gray-300">Since in line 4 of Algorithm 2, we have <span class="math">v_{i} \\equiv 0 \\mod b</span>, we deduce that <span class="math">u_{i} = -z_{i} \\mod b</span>, and hence we can eliminate <span class="math">u_{i}</span> altogether. Each loop iteration then simplifies to</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} v _ {i} \\leftarrow t \\cdot \\left(- z _ {\\langle i + 1 \\rangle} \\bmod b\\right) \\\\ w _ {i} \\leftarrow \\left(z _ {i} + \\left(- z _ {i} \\bmod b\\right) - v _ {i}\\right) / b \\tag{5.2} \\end{array}</span></div>

    <p class="text-gray-300">Upon expanding (5.2), we obtain</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} w _ {i} \\leftarrow \\left(z _ {i} + \\left(- z _ {i} \\bmod b\\right)\\right) / b - t \\cdot \\left(- z _ {\\langle i + 1 \\rangle} \\bmod b\\right) / b \\\\ = \\left(z _ {i} + \\left(- z _ {i} \\bmod b\\right)\\right) / b - c \\cdot \\left(- z _ {\\langle i + 1 \\rangle} \\bmod b\\right), \\end{array}</span></div>

    <p class="text-gray-300">as required. However since we did not provide a proof of correctness of Algorithm 2, we also give a direct proof as follows. Observe that modulo <span class="math">t^{m + 1} - 1</span>, we have</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\psi^ {- 1} (\\overline {{\\mathbf {w}}}) \\equiv \\sum_ {i = 0} ^ {m} w _ {i} t ^ {i} \\\\ \\equiv \\sum_ {i = 0} ^ {m} [ (z _ {i} + (- z _ {i} \\bmod b)) / b - c \\cdot (- z _ {\\langle i + 1 \\rangle} \\bmod b) ] t ^ {i} \\\\ \\equiv \\sum_ {i = 0} ^ {m} (z _ {i} / b) t ^ {i} + \\sum_ {i = 0} ^ {m} (- z _ {i} \\bmod b)) / b) t ^ {i} - \\sum_ {i = 0} ^ {m} ((- z _ {\\langle i + 1 \\rangle} \\bmod b) / b) t ^ {i + 1} \\\\ \\equiv \\sum_ {i = 0} ^ {m} z _ {i} t ^ {i} / b \\pmod {t ^ {m + 1} - 1} \\end{array}</span></div>

    <p class="text-gray-300">as required. In terms of operations that may be performed very efficiently, we alter Algorithm 3 slightly to give Algorithm 4, which has virtually the same proof of correctness as the one just given.</p>

    <p class="text-gray-300">Algorithm 4 red3_{b}(z)</p>

    <p class="text-gray-300">INPUT: <span class="math">\\overline{\\mathbf{z}}=[z_{m},\\ldots,z_{0}]\\in\\mathbb{Z}^{m+1}</span> OUTPUT: <span class="math">\\text{red}_{b}(\\overline{\\mathbf{z}})</span> where <span class="math">\\text{red}_{b}(\\overline{\\mathbf{z}})\\cong_{t^{m+1}-1}\\overline{\\mathbf{z}}\\cdot b^{-1}</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For <span class="math">i=m</span> to 0 do:</li>

      <li><span class="math">w_{i}\\leftarrow z_{i}/b+c\\cdot(z_{\\langle i+1\\rangle}\\bmod b)</span></li>

      <li>Return <span class="math">\\overline{\\mathbf{w}}</span></li>

    </ol>

    <p class="text-gray-300">Note that the first term in line 2 of Algorithm 3 has been replaced by a division by <span class="math">b</span>, which can be effected as a simple shift, while now the second term needs the positive residue modulo <span class="math">b</span>, which can be extracted more efficiently. Hence Algorithm 4 is the one we use. By our previous discussion, <span class="math">c</span> necessarily has Hamming weight at least two for GRPs in our desired range. By using <span class="math">c</span> that have very low Hamming weight, one can effect the multiplication by <span class="math">c</span> by shifts and adds, rather than a multiply (or imulq) instruction. Hence for such GRPs, assuming only two invocations of Algorithm 4 are needed, reduction will be extremely efficient.</p>

    <h6 id="sec-27" class="text-base font-medium mt-4">Remark 3</h6>

    <p class="text-gray-300">Regarding parallelisation, observe that for <span class="math">m+1</span> processors, only the least significant word of <span class="math">z_{\\langle i+1\\rangle}</span> is passed to processor <span class="math">i</span>, thus reducing the broadcast requirement in comparison with Algorithm 2.</p>

    <h2 id="sec-28" class="text-2xl font-bold">6 GRP Residue Representation</h2>

    <p class="text-gray-300">So far in our treatment of both multiplication and reduction, for the sake of generality we have assumed arbitrary precision when representing GRP residues in <span class="math">\\mathbb{Z}^{m+1}</span>. In this section we specialise to fixed precision and develop a residue representation that ensures that our chosen algorithms are efficient. Our decisions are informed purely by our chosen multiplication and reduction algorithms — Algorithms 1 and 4 — which we believe offer the best performance for GRPs for the relatively small bitlengths which are relevant to ECC. In other scenarios or if considering asymptotic performance, one would need to redesign the residue representation and multiplication algorithm accordingly.</p>

    <p class="text-gray-300">For <span class="math">x\\in\\{0,\\ldots,t^{m+1}-1\\}</span> we write <span class="math">\\overline{\\mathbf{x}}=[x_{m},\\ldots,x_{0}]</span> for its base-<span class="math">t</span> expansion, i.e., <span class="math">x=\\sum_{i=0}^{m}x_{i}t^{i}</span>. The base-<span class="math">t</span> representation has positive coefficients, however Algorithm 1 makes use of negative coefficients, so we prefer to incorporate these. We therefore replace the mod function in the conversion with mods, the least absolute residue function, to obtain a residue in the interval <span class="math">[-t/2,t/2-1]</span>:</p>

    <p class="text-gray-300">\\[ \\text{mods}(x)=\\left\\{\\begin{array}[]{ll}x\\bmod t&\\text{if }{(x\\bmod t)<t/2},\\\\ x\\bmod t-t&\\text{otherwise}.\\end{array}\\right. \\]</p>

    <p class="text-gray-300">Using this function, Algorithm 5 converts residues modulo <span class="math">t^{m+1}-1</span> into the required form *[14, Algorithm 1]</p>

    <p class="text-gray-300">Algorithm 5: BASE-<span class="math">t</span> CONVERSION <span class="math">\\psi</span> 0: An integer <span class="math">0\\leq x&lt;t^{m+1}-1</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0: <span class="math">\\overline{\\mathbf{x}}=[x_{m}.\\ldots,x_{0}]</span> such that $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq t/2$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">and <span class="math">\\sum_{i=0}^{m}x_{i}t^{i}\\equiv x\\pmod{t^{m+1}-1}</span> 1: For <span class="math">i</span> from <span class="math">0</span> to <span class="math">m</span> do: 2: <span class="math">x_{i}\\leftarrow x\\mod s\\</span> 3: <span class="math">x\\leftarrow(x-x_{i})/t</span> 4: <span class="math">x_{0}\\leftarrow x_{0}+x</span> 5: Return <span class="math">\\overline{\\mathbf{x}}=[x_{m},\\ldots,x_{0}]</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The reason for line 4 in Algorithm 5 is to reduce modulo <span class="math">t^{m+1}-1</span> the coefficient of <span class="math">t^{m+1}</span> possibly arising in the expansion. Note that in this addition, <span class="math">x\\in\\{0,1\\}</span>, and hence $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq t/2<span class="math"> for each </span>0\\leq i\\leq m<span class="math">. By construction, we in fact have </span>-t/2\\leq x_{i}<t/2<span class="math"> for </span>1<i<m<span class="math"> while only </span>x_{0}<span class="math"> can attain the upper bound of </span>t/2<span class="math">. There are therefore </span>t^{m}(t+1)<span class="math"> representatives in this format, thus introducing a very small additional redundancy. Letting </span>k=\\lceil\\log_{2}t\\rceil<span class="math">, if we assume </span>t\\leq 2^{k}-2<span class="math">, so that </span>[-t/2,t/2]\\subset[-2^{k}/2,2^{k}/2-1]<span class="math">, then the coefficients as computed above can be represented in two’s complement in </span>k<span class="math"> bits. In terms of efficiency, Algorithm 5 contains divisions by </span>t<span class="math">, which requires not only time, but also space, which on some platforms may be at a premium. Writing </span>t=2^{l}\\cdot c<span class="math"> as in §5.2, then if the cofactor </span>c=2^{k-l}-c^{\\prime}<span class="math"> with </span>c^{\\prime}<span class="math"> very small, then division by </span>t<span class="math"> consists of a shift right by </span>l<span class="math"> bits and a division by </span>c$, which can be performed efficiently using Algorithm 1 of <em>[12]</em>.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Following this conversion, it might seem desirable to define vectors whose components are in <span class="math">[-2^{k}/2,2^{k}/2-1]</span> to be reduced, or canonical residue representatives. However, for efficiency purposes it is preferable to have a reduction function which, when performed sufficiently many times, outputs an element for which one does not have to perform any modular additions or subtractions to make reduced, as this eliminates data-dependent branching. A control-flow invariant reduction function is also essential to defend against side-channel attacks, see §9. To obtain such a function, observe that the second term in line 2 of Algorithm 4, namely <span class="math">c\\cdot(z_{\\langle i+1\\rangle}\\bmod b)</span>, is positive, and in the worst case is <span class="math">k</span> bits long. The first term, <span class="math">z_{i}/b</span>, is clearly <span class="math">l=\\log_{2}b</span> bits shorter than <span class="math">z_{i}</span>. Since one adds these the resulting value may be <span class="math">k+1</span> bits, or larger, depending on the initial length of the inputs’ components. Furthermore, since we wish to allow negative components, in two’s complement the output requires a further bit, giving a minimal requirement of <span class="math">k+2</span> bits. We therefore choose not to use minimally reduced elements as coset representatives in <span class="math">\\mathbb{Z}^{m+1}/\\sim</span>, as output by Algorithm 5, but slightly larger elements, which we now define.</p>

    <h6 id="sec-29" class="text-base font-medium mt-4">Definition 5.</h6>

    <p class="text-gray-300">We define the following set of elements of <span class="math">\\mathbb{Z}^{m+1}</span> to be reduced:</p>

    <p class="text-gray-300"><span class="math">\\mathbb{I}^{m+1}=\\{[x_{m},\\ldots,x_{0}]\\in\\mathbb{Z}^{m+1}\\mid-2^{k+1}\\leq x_{i}&lt;2^{k+1}\\}.</span> (6.1)</p>

    <p class="text-gray-300">Note that the redundancy inherent in this representation depends on how close <span class="math">t</span> is to <span class="math">2^{k+2}</span>. For a modular multiplication, we assume that the inputs are reduced. We must therefore ensure that the output is reduced also. This naturally leads one to consider I/O stability, as we do in §7.</p>

    <p class="text-gray-300">Once we have a reduced representative <span class="math">\\overline{\\mathbf{x}}=\\psi(x)</span> we also need to convert to the Montgomery domain. While one can do this in <span class="math">\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span> before applying <span class="math">\\psi</span>, it is more convenient to do so in <span class="math">\\mathbb{Z}^{m+1}/\\sim</span>. Assuming <span class="math">q</span> reductions by <span class="math">b</span> are sufficient to ensure I/O modular multiplication stability, we precompute <span class="math">\\psi(b^{2q}\\bmod\\Phi_{m+1}(t))</span> and then using Algorithms 1 and 4 compute</p>

    <p class="text-gray-300"><span class="math">\\overline{\\mathbf{x}}\\cdot\\psi(b^{2q}\\bmod\\Phi_{m+1}(t))/b^{q}\\cong_{\\Phi_{m+1}(t)}\\psi(x\\cdot b^{q}).</span></p>

    <p class="text-gray-300">Similarly, to get back from the Montgomery domain, again using Algorithms 1 and 4, we compute</p>

    <p class="text-gray-300"><span class="math">\\psi(x\\cdot b^{q})\\cdot\\psi(1)/b^{q}\\cong_{\\Phi_{m+1}(t)}\\psi(x).</span></p>

    <p class="text-gray-300">With regard to mapping back from <span class="math">\\overline{\\mathbf{x}}=[x_{m},\\ldots,x_{0}]\\in\\mathbb{I}^{m+1}</span> to canonical residues in <span class="math">\\mathbb{Z}/\\Phi_{m+1}(t)\\mathbb{Z}</span>, one has</p>

    <p class="text-gray-300"><span class="math">\\sum_{i=0}^{m}x_{i}t^{i}\\equiv\\sum_{i=0}^{m-1}(x_{i}-x_{m})t^{i}\\pmod{\\Phi_{m+1}(t)},</span></p>

    <p class="text-gray-300">which can be computed efficiently by first using Horner’s rule and then mapped to <span class="math">\\{0,\\ldots,\\Phi_{m+1}(t)-1\\}</span> by repeated additions or subtractions. In terms of operations required for ECC, we assume that the conversions are one-time computations only, with all other operations taking place in the (Montgomery) Chung-Hasan representation.</p>

    <h2 id="sec-30" class="text-2xl font-bold">7 Modular Multiplication Stability</h2>

    <p class="text-gray-300">In this section we analyse Algorithms 1 and 4 with a view to ensuring I/O stability for modular multiplication. We assume the following: <span class="math">b=2^{l}</span>, <span class="math">t=c\\cdot b</span> where <span class="math">c&lt;2^{k-l}</span> (and hence <span class="math">t&lt;2^{k}-2</span>), and that reduced elements have the form (6.1). Input elements therefore have components in <span class="math">\\mathbb{I}=[-2^{k+1},2^{k+1}-1]</span>, and these are representable in <span class="math">k+2</span> bits in two’s complement. For simplicity and in order for our analysis to be as general as possible, we use the term single precision to mean a word base large enough to contain <span class="math">t</span> — even if this in fact requires multiprecision on a given architecture — and double precision to mean twice this size. We assume that for this single precision word size <span class="math">w</span>, the components of <span class="math">\\overline{\\mathbf{z}}</span> output by Algorithm 1 are double precision. In practice one prefers to specialise to actual single precision <span class="math">t</span> on a given architecture, since this obviates the need for multiprecision arithmetic; utilising the native double precision multipliers that most CPUs possess is more efficient, and reduction is also faster for smaller <span class="math">t</span> since fewer iterations need be performed. We note that in constrained environments however, multiprecision may however be unavoidable.</p>

    <p class="text-gray-300">During the multiplication, terms of the form <span class="math">x_{i}-x_{j}</span> are computed, which are bounded by</p>

    <p class="text-gray-300"><span class="math">-2^{k+2}+1\\leq x_{i}-x_{j}\\leq 2^{k+2}-1,</span></p>

    <p class="text-gray-300">and which therefore fit into <span class="math">k+3</span> bits in two’s complement. The product of two such elements is performed, giving a result</p>

    <p class="text-gray-300"><span class="math">-2^{2k+4}+2^{k+3}-1\\leq(x_{i}-x_{j})\\cdot(y_{j}-y_{i})\\leq 2^{2k+4}-2^{k+3}+1,</span></p>

    <p class="text-gray-300">which fits into <span class="math">2k+5</span> bits in two’s complement. One then adds <span class="math">m/2</span> of these terms, giving a possible expansion of up to <span class="math">\\lceil\\log_{2}m/2\\rceil</span> bits, which must be double precision. We therefore have a constraint on the size of <span class="math">t</span> (in addition to the constraint <span class="math">t&lt;2^{k}-2</span>) in terms of <span class="math">m</span>:</p>

    <p class="text-gray-300"><span class="math">\\lceil\\log_{2}(m/2)\\rceil+2k+5\\leq 2w</span> (7.1)</p>

    <p class="text-gray-300">This inequality determines a constraint on the size of <span class="math">t</span>, given <span class="math">m</span> and <span class="math">w</span>. Assuming (7.1) is satisfied, one then needs to find the minimum value of <span class="math">b = 2^l</span> such that the result of the multiplication step, when reduced by <span class="math">b</span> a specified number of times, say <span class="math">q</span>, outputs a reduced element. This needs to be done for each <span class="math">(m,k)</span> found in the procedure above. Any power of 2 larger than this minimum will obviously be satisfactory also, however minimising <span class="math">b</span> maximises the set of prime-producing cofactors <span class="math">c</span>, which as stated in §5 may be useful in some scenarios.</p>

    <p class="text-gray-300">In §6, we showed that one application of Algorithm 4 shortened an input's components by <span class="math">l - 1</span> bits, unless the components were already shorter than <span class="math">(k + 2) + (l - 1)</span> bits. Therefore stipulating that <span class="math">q</span> reductions suffice to produce a reduced output, we obtain a bound on <span class="math">l</span> in the following manner. Let</p>

    <div class="my-4 text-center"><span class="math-block">h = \\lceil \\log_ {2} (m / 2) \\rceil + 2 k + 5</span></div>

    <p class="text-gray-300">Then after one reduction, the maximum length of a component is <span class="math">h - l + 1</span>. Similarly after <span class="math">q</span> reductions, the maximum length is <span class="math">\\max \\{h - q(l - 1), k + 2\\}</span>, and we need this to be at most <span class="math">k + 2</span>. Hence our desired condition is</p>

    <div class="my-4 text-center"><span class="math-block">h - q (l - 1) \\leq k + 2</span></div>

    <p class="text-gray-300">Solving for <span class="math">l</span>, we have</p>

    <div class="my-4 text-center"><span class="math-block">l \\geq 1 + \\frac {\\lceil \\log_ {2} (m / 2) \\rceil + k + 3}{q} \\tag {7.2}</span></div>

    <p class="text-gray-300">Using these inequalities it is an easy matter to generate triples <span class="math">(m + 1, k, l)</span> which ensure multiplication stability for any <span class="math">w</span> and <span class="math">q</span>. For example, for <span class="math">w = 64</span>, Tables 1 and 2 give sets of stable parameters for <span class="math">q = 2</span> and <span class="math">q = 3</span> respectively.</p>

    <p class="text-gray-300">Table 1. Stable parameters for <span class="math">w = 64</span>, <span class="math">q = 2</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">m+1</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">k</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">l</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">c<</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">[log2p]</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">3</td>

            <td class="px-3 py-2 border-b border-gray-700">61</td>

            <td class="px-3 py-2 border-b border-gray-700">33</td>

            <td class="px-3 py-2 border-b border-gray-700">228</td>

            <td class="px-3 py-2 border-b border-gray-700">122</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

            <td class="px-3 py-2 border-b border-gray-700">61</td>

            <td class="px-3 py-2 border-b border-gray-700">34</td>

            <td class="px-3 py-2 border-b border-gray-700">227</td>

            <td class="px-3 py-2 border-b border-gray-700">244</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">7</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">34</td>

            <td class="px-3 py-2 border-b border-gray-700">226</td>

            <td class="px-3 py-2 border-b border-gray-700">360</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">11</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">34</td>

            <td class="px-3 py-2 border-b border-gray-700">226</td>

            <td class="px-3 py-2 border-b border-gray-700">600</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">13</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">34</td>

            <td class="px-3 py-2 border-b border-gray-700">226</td>

            <td class="px-3 py-2 border-b border-gray-700">720</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">17</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">34</td>

            <td class="px-3 py-2 border-b border-gray-700">226</td>

            <td class="px-3 py-2 border-b border-gray-700">960</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 2. Stable parameters for <span class="math">w = 64</span>, <span class="math">q = 3</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">m+1</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">k</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">l</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">c<</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">[log2p]</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">3</td>

            <td class="px-3 py-2 border-b border-gray-700">61</td>

            <td class="px-3 py-2 border-b border-gray-700">23</td>

            <td class="px-3 py-2 border-b border-gray-700">238</td>

            <td class="px-3 py-2 border-b border-gray-700">122</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

            <td class="px-3 py-2 border-b border-gray-700">61</td>

            <td class="px-3 py-2 border-b border-gray-700">23</td>

            <td class="px-3 py-2 border-b border-gray-700">238</td>

            <td class="px-3 py-2 border-b border-gray-700">244</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">7</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">23</td>

            <td class="px-3 py-2 border-b border-gray-700">237</td>

            <td class="px-3 py-2 border-b border-gray-700">360</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">11</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">23</td>

            <td class="px-3 py-2 border-b border-gray-700">237</td>

            <td class="px-3 py-2 border-b border-gray-700">600</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">13</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">23</td>

            <td class="px-3 py-2 border-b border-gray-700">237</td>

            <td class="px-3 py-2 border-b border-gray-700">720</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">17</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">23</td>

            <td class="px-3 py-2 border-b border-gray-700">237</td>

            <td class="px-3 py-2 border-b border-gray-700">960</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The final column gives the maximum bitlength of a GRP that can be represented with those parameters, though of course by using smaller <span class="math">c</span> one can opt for smaller primes, and the corresponding minimum value of <span class="math">l</span> reduces according to (7.2). To generate suitable GRPs, a simple linear search over the values of <span class="math">c</span> of the desired size is sufficient, checking whether or not <span class="math">\\varPhi_{m+1}(2^l \\cdot c)</span> is prime, see §10.</p>

    <h2 id="sec-31" class="text-2xl font-bold">8 Full GRP Modular Multiplication</h2>

    <p class="text-gray-300">For completeness we now piece together the parts treated thus far into a full modular multiplication algorithm, where in Algorithm 6 we assume <span class="math">q</span> reductions by <span class="math">b</span> are required for I/O stability and in line 4 either Algorithm 2 or Algorithm 4 is used according to the form of <span class="math">b</span>.</p>

    <p class="text-gray-300"><strong>ALGORITHM 6: GRP MODMUL</strong></p>

    <pre><code class="language-text">INPUT:  $\\overline{\\mathbf{x}} = [x_m,\\dots ,x_0],\\overline{\\mathbf{y}} = [y_m,\\dots ,y_0]\\in \\mathbb{I}^{m + 1}$
OUTPUT:  $\\overline{\\mathbf{z}} = [z_m,\\ldots ,z_0]\\in \\mathbb{I}^{m + 1}$  where  $\\overline{\\mathbf{z}}\\cong_{\\varPhi_{m + 1}(t)}\\overline{\\mathbf{x}}\\cdot \\overline{\\mathbf{y}}\\cdot b^{-q}$</code></pre>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For <span class="math">i = m</span> to 0 do:</li>

      <li><span class="math">z_{i}\\gets \\sum_{j = 1}^{m / 2}(x_{\\langle \\frac{i}{2} -j\\rangle} - x_{\\langle \\frac{i}{2} +j\\rangle})\\cdot (y_{\\langle \\frac{i}{2} +j\\rangle} - y_{\\langle \\frac{i}{2} -j\\rangle})</span></li>

      <li>For <span class="math">k</span> from 0 to <span class="math">q - 1</span> do:</li>

      <li><span class="math">\\overline{\\mathbf{z}}\\gets \\mathrm{red}_b(\\overline{\\mathbf{z}})</span></li>

      <li>Return <span class="math">\\overline{\\mathbf{z}}</span></li>

    </ol>

    <p class="text-gray-300">Should <span class="math">t</span> be multiprecision on a particular architecture, then as with Montgomery arithmetic it may be more efficient to use an interleaved multiplication and reduction algorithm, as we detail in Algorithm 7. Here one needs <span class="math">b</span> to be the word base of the underlying architecture and so in line 6, if <span class="math">t \\equiv 0 \\pmod{b}</span> we use Algorithm 4, otherwise we use Algorithm 2. For <span class="math">\\overline{\\mathbf{x}} = [x_m, \\ldots, x_0]</span> we write <span class="math">x_i = x_i[0] + x_i[1]b + \\dots + x_i[q - 1]b^{q - 1}</span>.</p>

    <p class="text-gray-300"><strong>ALGORITHM 7: GRP MODMUL (interleaved)</strong></p>

    <pre><code class="language-text">INPUT:  $\\overline{\\mathbf{x}} = [x_m,\\dots ,x_0],\\overline{\\mathbf{y}} = [y_m,\\dots ,y_0]\\in \\mathbb{I}^{m + 1}$
OUTPUT:  $\\overline{\\mathbf{z}} = [z_m,\\dots ,z_0]\\in \\mathbb{I}^{m + 1}$  where  $\\overline{\\mathbf{z}}\\cong_{\\varPhi_{m + 1}(t)}\\overline{\\mathbf{x}}\\cdot \\overline{\\mathbf{y}}\\cdot b^{-q}$</code></pre>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\overline{\\mathbf{z}}\\gets [0,\\dots ,0]</span></li>

      <li>For <span class="math">k = 0</span> to <span class="math">q - 1</span> do:</li>

      <li>For <span class="math">i = m</span> to 0 do:</li>

      <li><span class="math">w_{i}\\gets \\sum_{j = 1}^{m / 2}(x_{\\langle \\frac{i}{2} -j\\rangle}[k] - x_{\\langle \\frac{i}{2} +j\\rangle}[k])\\cdot (y_{\\langle \\frac{i}{2} +j\\rangle} - y_{\\langle \\frac{i}{2} -j\\rangle})</span></li>

      <li><span class="math">\\overline{\\mathbf{z}}\\gets \\overline{\\mathbf{z}} +\\overline{\\mathbf{w}}</span></li>

      <li><span class="math">\\overline{\\mathbf{z}}\\gets \\mathrm{red}_b(\\overline{\\mathbf{z}})</span></li>

      <li>Return <span class="math">\\overline{\\mathbf{z}}</span></li>

    </ol>

    <p class="text-gray-300">To verify the correctness of Algorithm 7, observe that for each of the <span class="math">m+1</span> components of <span class="math">\\overline{\\mathbf{z}}</span>, after the last iteration of the outer loop we have:</p>

    <p class="text-gray-300"><span class="math">z_{i}</span> <span class="math">=\\sum_{j=1}^{m/2}\\Big{(}\\sum_{k=0}^{q-1}(x_{\\langle\\frac{i}{2}-j\\rangle}[k]-x_{\\langle\\frac{i}{2}+j\\rangle}[k])/b^{q-k}\\Big{)}\\cdot(y_{\\langle\\frac{i}{2}+j\\rangle}-y_{\\langle\\frac{i}{2}-j\\rangle})</span> <span class="math">=\\sum_{j=1}^{m/2}((x_{\\langle\\frac{i}{2}-j\\rangle}-x_{\\langle\\frac{i}{2}+j\\rangle})/b^{q})\\cdot(y_{\\langle\\frac{i}{2}+j\\rangle}-y_{\\langle\\frac{i}{2}-j\\rangle}).</span></p>

    <p class="text-gray-300">Hence when taken modulo <span class="math">\\Phi_{m+1}(t)</span>, we see that <span class="math">\\overline{\\mathbf{z}}</span> is congruent to:</p>

    <p class="text-gray-300"><span class="math">\\sum_{i=0}^{m}z_{i}\\cdot t^{i}</span> <span class="math">\\cong_{\\Phi_{m+1}(t)}\\sum_{i=0}^{m}\\Big{(}\\sum_{j=1}^{m/2}(x_{\\langle\\frac{i}{2}-j\\rangle}-x_{\\langle\\frac{i}{2}+j\\rangle})/b^{q})\\cdot(y_{\\langle\\frac{i}{2}+j\\rangle}-y_{\\langle\\frac{i}{2}-j\\rangle})\\Big{)}\\cdot t^{i}</span> <span class="math">\\cong_{\\Phi_{m+1}(t)}\\sum_{i=0}^{m}\\Big{(}\\sum_{j=1}^{m/2}(x_{\\langle\\frac{i}{2}-j\\rangle}-x_{\\langle\\frac{i}{2}+j\\rangle})\\cdot(y_{\\langle\\frac{i}{2}+j\\rangle}-y_{\\langle\\frac{i}{2}-j\\rangle})\\cdot t^{i}\\Big{)}/b^{q}</span> <span class="math">\\cong_{\\Phi_{m+1}(t)}\\overline{\\mathbf{x}}\\cdot\\overline{\\mathbf{y}}\\cdot b^{-q},</span></p>

    <p class="text-gray-300">as required. As with ordinary Montgomery arithmetic, there are many possible ways to perform the interleaving, see <em>[34]</em> for example.</p>

    <h2 id="sec-32" class="text-2xl font-bold">9 Other arithmetic and side-channel secure ECC</h2>

    <p class="text-gray-300">In addition to modular multiplication, one also needs to perform other arithmetic operations when implementing ECC point multiplication. In this section we detail how to perform these using our representation and briefly explain how it enables point multiplication to be made immune to various side-channel attacks.</p>

    <h3 id="sec-33" class="text-xl font-semibold mt-8">9.1 Other arithmetic operations</h3>

    <h4 id="sec-34" class="text-lg font-semibold mt-6">9.1.1 Addition/subtraction</h4>

    <p class="text-gray-300">To perform an addition or subtraction of two reduced elements <span class="math">\\overline{\\mathbf{x}},\\overline{\\mathbf{y}}</span>, we compute the following:</p>

    <p class="text-gray-300"><span class="math">\\overline{\\mathbf{x}}\\pm\\overline{\\mathbf{y}}=[x_{m}\\pm y_{m},\\ldots,x_{0}\\pm y_{0}].</span></p>

    <p class="text-gray-300">Note that the bounds on each of these components is <span class="math">[-2^{k+2},2^{k+2}-2]</span>, which are therefore not necessarily reduced. One could reduce the resulting element using the specialisation to GRPs of <em>[14, Algorithm 5]</em>, which shows how to do this for a general LWPFI. Chung and Hasan refer to this process as short coefficient reduction (SCR), as opposed to full modular reduction. However, for ECC operations it is faster (and more secure) to simply ignore this expansion and rely on a later modular multiplication to perform the reduction, as is required when computing a point addition or doubling, see <em>[5, 6]</em> and §9.2.</p>

    <h4 id="sec-35" class="text-lg font-semibold mt-6">9.1.2 Squaring</h4>

    <p class="text-gray-300">When <span class="math">t</span> is single precision, the CVMA formulae do not have any common subexpressions, as arises for ordinary integer residue squaring. In this case GRP squaring is performed using Algorithm 6. If <span class="math">t</span> is multiprecision, then the components of a product <span class="math">\\overline{\\mathbf{x}}\\cdot\\overline{\\mathbf{y}}</span> are computed as a sum of integer squares. In this case, one can eliminate common subexpressions to improve efficiency by nearly a factor of two (in the multiplication step). On the other hand, when using Algorithm 7 and its variants it may be difficult to eliminate common subexpressions efficiently *[34]</p>

    <h4 id="sec-36" class="text-lg font-semibold mt-6">9.1.1 Inversion and equality check</h4>

    <p class="text-gray-300">Inversion seems difficult to perform efficiently in the GRP representation. If <span class="math">t</span> were prime then it would be possible to use an analogue of the inversion/division algorithm of <em>[45]</em>, exploiting the cyclicity <span class="math">t^{m+1}\\equiv 1\\pmod{t^{m+1}-1}</span>. However, for our GRPs <span class="math">t</span> is even and greater than <span class="math">2</span>. One can therefore opt to map back to <span class="math">\\mathbb{Z}/\\Phi_{m+1}(t)\\mathbb{Z}</span>, remaining in the Montgomery domain, and perform inversion using the binary extended Euclidean algorithm (see <em>[32]</em>, for example) and modular multiplying by the precomputed value <span class="math">\\psi(b^{3}\\bmod\\Phi_{m+1}(t))</span>. Alternatively, for data-independent inversion, one can simply power by <span class="math">\\Phi_{m+1}(t)-2</span>, as do the authors of <em>[6]</em>. Using projective coordinates can obviate the need for inversions altogether, however for many protocols inversion is unavoidable and when it is avoidable, in some scenarios such representations of points should be randomised after a point multiplication <em>[43]</em>.</p>

    <p class="text-gray-300">Since our representation possesses redundancy, equality checking is naturally problematic. We therefore opt to map back to <span class="math">\\mathbb{Z}/\\Phi_{m+1}(t)\\mathbb{Z}</span> to check equality there — as for inversion — while remaining in the Montgomery domain. For ECC equality checking is usually a one-time computation per coordinate, and so again this operation does not greatly impinge upon efficiency.</p>

    <h3 id="sec-37" class="text-xl font-semibold mt-8">9.2 Side-channel secure ECC</h3>

    <p class="text-gray-300">As we demonstrated in §7, by choosing <span class="math">t</span>, <span class="math">l</span> and <span class="math">m+1</span> carefully, one can avoid the need to compute any final additions or subtractions when performing a modular reduction. This is an analogue to various results for ordinary Montgomery arithmetic <em>[55, 26, 56]</em>. The lack of a conditional addition/subtraction averts threats such as <em>[48, 57]</em>, the latter of which applies directly to the NIST GMNs. Our modular multiplication algorithm is thus control-flow invariant with no data-dependent operations, making it immune to timing attacks <em>[35]</em> and simple power analysis (SPA).</p>

    <p class="text-gray-300">In addition to making modular multiplications and squarings immune to timing attacks and SPA, one can also ensure that the computation of an entire elliptic curve point addition or doubling is also immune. To do so, one chooses a GRP with <span class="math">t</span> divisible by a sufficiently high power of <span class="math">2</span>, so that during the course of an elliptic curve point operation, even if one ignores the coefficient expansion caused by additions/subtractions, these do not overflow and the modular reductions ensure the outputs are fully reduced elements. Note that this requires <span class="math">b=2^{l}\\mid t</span> to be a few bits longer than the minimum <span class="math">l</span>-values listed in Tables 1 and 2: for reasons of space we do not include the analysis here. By doing so, a point addition or doubling becomes an atomic operation, where the sequence of arithmetic operations is entirely data-independent. In this case one only needs point-multiplication-level defences against timing attacks and SPA, such as the double-and-add-always algorithm due to Coron <em>[15]</em>, or the use of Edwards curves, for which the addition formula can also be used for doubling <em>[7]</em>. Hence, ECC over GRPs may be straight-line coded, which is beneficial for both efficiency and security.</p>

    <p class="text-gray-300">Lastly, our representation can also be made immune to differential power analysis (DPA) <em>[36]</em>. Observe that the embedding of <span class="math">\\mathbb{Z}/\\Phi_{m+1}(t)\\mathbb{Z}</span> into <span class="math">\\mathbb{Z}/(t^{m+1}-1)\\mathbb{Z}</span> can be randomised by adding to it a random multiple <span class="math">r\\cdot\\Phi_{m+1}(t)</span> for <span class="math">r\\in\\{0,\\ldots,(t-1)-1\\}</span>. While our embedding is an example of ‘operand scaling’ <em>[45, 54]</em> which is used for faster reduction, the addition of a multiple of the modulus within a redundant scaled representation also acts as a countermeasure to DPA — such as Goubin’s attack <em>[25]</em> on the randomised projective coordinates defence of Coron <em>[15]</em> — as shown by Smart, Oswald and Page <em>[51]</em>. In particular, the au</p>

    <p class="text-gray-300">thors show that this countermeasure thwarts DPA whenever the scaling factor is longer than the longest string of ones or zeros in the binary expansion of the initial modulus. For the NIST GMNs, this countermeasure requires a large scaling factor, making the defence inefficient and nullifying the benefits of using these moduli. For GRPs, the scaling factor is <span class="math">t-1</span>, while the longest string of ones or zeros in the binary expansion of <span class="math">\\Phi_{m+1}(t)</span> is <span class="math">\\lceil\\log t\\rceil-1</span>. Since GRPs already use the larger ring, we acquire this defence for almost negligible cost. In particular the addition of a random multiple <span class="math">r</span> of <span class="math">\\Phi_{m+1}(t)</span> to an element <span class="math">\\overline{\\mathbf{x}}</span> has the form <span class="math">[x_{m}+r,x_{m-1}+r,\\ldots,x_{0}+r]</span>, which only requires <span class="math">m+1</span> additions. Since DPA depends on the ability of an attacker to predict a specific bit in the representation of a given field element, if the representation of field elements is randomised in this way prior to every point multiplication, or even every modular multiplication, then DPA will not be feasible.</p>

    <h2 id="sec-38" class="text-2xl font-bold">10 GRP Parameters</h2>

    <p class="text-gray-300">In this section we provide empirical data regarding the abundancy of fast-reduction GRPs at various bitlengths relevant to ECC. We also specify parameters that are optimal within this subfamily, which are therefore particularly suitable for efficient implementation.</p>

    <h3 id="sec-39" class="text-xl font-semibold mt-8">10.1 Estimating the number of GRP parameters</h3>

    <p class="text-gray-300">As we saw from Tables 1 and 2, for a given prime <span class="math">m+1</span> and word size <span class="math">w</span>, there is an upper bound on the length of a GRP that may be represented. Table 3 contains estimates (or exact counts) for the number of GRPs which are in accordance with the GRP field and residue representation set out in this work, for word size <span class="math">w=64</span> and where <span class="math">q=2</span> reductions using Algorithm 4 suffice to ensure I/O modular multiplication stability. Note that this reduction specification entails the greatest possible restriction on the available GRPs; using either larger <span class="math">q</span> or Algorithm 2 means vastly more GRPs are availble. It is a simple matter to generate such GRPs, as follows; GRPs of any more general form can be found similarly.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">For a desired GRP <span class="math">p</span> of bitlength <span class="math">\\lceil\\log p\\rceil</span>, Table 1 gives the minimum value of prime <span class="math">m+1</span> which is adequate to represent GRPs of this size. The inequality (7.1) gives <span class="math">k_{max}</span> which is the maximum bitlength of <span class="math">t</span> that is representable, while (7.2) gives the minimum value <span class="math">l</span> required in order for <span class="math">t=2^{l}\\cdot c</span> to be I/O stable. We estimate <span class="math">t_{max}</span> simply as <span class="math">2^{\\lceil\\log p\\rceil/m}</span>, which implies a maximum value for <span class="math">c</span> of <span class="math">2^{\\lceil\\log p\\rceil/m-l_{min}}</span>. Similarly for <span class="math">p</span> of this precise bitlength, we estimate the minimum value of <span class="math">c</span> as <span class="math">2^{(\\lceil\\log p\\rceil-1)/m-l_{min}}</span>. We denote this interval by <span class="math">I(c)</span>. To estimate <span class="math">P(\\text{prime})</span>, which is the probability that a given generalised repunit in our form is a GRP, we performed a linear search over <span class="math">c\\in I(c)</span>, counting the first <span class="math">1,000</span> primes and simply dividing by the length of the search. The estimated total number of GRPs satisfying our requirement that <span class="math">q=2</span> is then given by $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">I(c)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\cdot P(\\text{prime})$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">For each of <span class="math">m+1=5,7</span> and <span class="math">11</span>, Table 3 contains estimated counts for the largest GRPs representable. It also contains estimates (or exact counts) for the number of GRPs at the NIST GMN sizes <span class="math">224,256</span> and <span class="math">384</span>. We also consider bitlength <span class="math">512</span> rather than <span class="math">521</span>, since this conjecturally gives <span class="math">256</span>-bit security, with the larger prime <span class="math">2^{521}-1</span> being nominated purely for fast reduction. Observe that the number of available GRPs for a given <span class="math">m+1</span> decreases as the size of <span class="math">p</span>, and hence <span class="math">c</span> decreases. The number available for bitlengths <span class="math">383</span> and <span class="math">384</span> is particularly low. However, should this be a concern for a particular application, one can see from Table 2 that by moving to GRPs for which <span class="math">3</span> reductions suffices, $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">I(c)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> becomes much larger (</span>3.71\\times 10^{5}<span class="math">) and our estimate of the number of GRPs becomes over </span>5,000$. On the other</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 3. Estimated GRP counts for  <span class="math">w = {64},q = 2</span>  and  <span class="math">t \\equiv  0\\left( {\\;\\operatorname{mod}\\;{2}^{{l}_{\\min }}}\\right)</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">log p</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">m+1</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">kmax</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">log tmax</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">lmin</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">I(c)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">P(prime)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">≈#GRPs</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">600</td>

            <td class="px-3 py-2 border-b border-gray-700">11</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">60.0</td>

            <td class="px-3 py-2 border-b border-gray-700">34</td>

            <td class="px-3 py-2 border-b border-gray-700">4.49 × 10^6</td>

            <td class="px-3 py-2 border-b border-gray-700">8.54 × 10^-3</td>

            <td class="px-3 py-2 border-b border-gray-700">38.4 × 10^3</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">599</td>

            <td class="px-3 py-2 border-b border-gray-700">11</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">59.9</td>

            <td class="px-3 py-2 border-b border-gray-700">34</td>

            <td class="px-3 py-2 border-b border-gray-700">4.19 × 10^6</td>

            <td class="px-3 py-2 border-b border-gray-700">9.05 × 10^-3</td>

            <td class="px-3 py-2 border-b border-gray-700">37.9 × 10^3</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">512</td>

            <td class="px-3 py-2 border-b border-gray-700">11</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">51.2</td>

            <td class="px-3 py-2 border-b border-gray-700">30</td>

            <td class="px-3 py-2 border-b border-gray-700">1.61 × 10^5</td>

            <td class="px-3 py-2 border-b border-gray-700">1.05 × 10^-2</td>

            <td class="px-3 py-2 border-b border-gray-700">1697</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">511</td>

            <td class="px-3 py-2 border-b border-gray-700">11</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">51.1</td>

            <td class="px-3 py-2 border-b border-gray-700">30</td>

            <td class="px-3 py-2 border-b border-gray-700">1.51 × 10^5</td>

            <td class="px-3 py-2 border-b border-gray-700">1.06 × 10^-2</td>

            <td class="px-3 py-2 border-b border-gray-700">1591</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">384</td>

            <td class="px-3 py-2 border-b border-gray-700">11</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">38.4</td>

            <td class="px-3 py-2 border-b border-gray-700">24</td>

            <td class="px-3 py-2 border-b border-gray-700">1448</td>

            <td class="px-3 py-2 border-b border-gray-700">9.67 × 10^-3</td>

            <td class="px-3 py-2 border-b border-gray-700">14</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">383</td>

            <td class="px-3 py-2 border-b border-gray-700">11</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">38.3</td>

            <td class="px-3 py-2 border-b border-gray-700">24</td>

            <td class="px-3 py-2 border-b border-gray-700">1352</td>

            <td class="px-3 py-2 border-b border-gray-700">1.33 × 10^-2</td>

            <td class="px-3 py-2 border-b border-gray-700">18</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">360</td>

            <td class="px-3 py-2 border-b border-gray-700">7</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">60.0</td>

            <td class="px-3 py-2 border-b border-gray-700">34</td>

            <td class="px-3 py-2 border-b border-gray-700">4.49 × 10^6</td>

            <td class="px-3 py-2 border-b border-gray-700">1.82 × 10^-2</td>

            <td class="px-3 py-2 border-b border-gray-700">81.7 × 10^3</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">359</td>

            <td class="px-3 py-2 border-b border-gray-700">7</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">59.9</td>

            <td class="px-3 py-2 border-b border-gray-700">34</td>

            <td class="px-3 py-2 border-b border-gray-700">4.19 × 10^6</td>

            <td class="px-3 py-2 border-b border-gray-700">1.77 × 10^-2</td>

            <td class="px-3 py-2 border-b border-gray-700">74.1 × 10^3</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">256</td>

            <td class="px-3 py-2 border-b border-gray-700">7</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">42.66</td>

            <td class="px-3 py-2 border-b border-gray-700">25</td>

            <td class="px-3 py-2 border-b border-gray-700">2.27 × 10^4</td>

            <td class="px-3 py-2 border-b border-gray-700">2.47 × 10^-2</td>

            <td class="px-3 py-2 border-b border-gray-700">561</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">255</td>

            <td class="px-3 py-2 border-b border-gray-700">7</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">42.5</td>

            <td class="px-3 py-2 border-b border-gray-700">25</td>

            <td class="px-3 py-2 border-b border-gray-700">2.02 × 10^4</td>

            <td class="px-3 py-2 border-b border-gray-700">2.63 × 10^-2</td>

            <td class="px-3 py-2 border-b border-gray-700">531</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">244</td>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

            <td class="px-3 py-2 border-b border-gray-700">61</td>

            <td class="px-3 py-2 border-b border-gray-700">61.0</td>

            <td class="px-3 py-2 border-b border-gray-700">34</td>

            <td class="px-3 py-2 border-b border-gray-700">2.14 × 10^7</td>

            <td class="px-3 py-2 border-b border-gray-700">1.68 × 10^-2</td>

            <td class="px-3 py-2 border-b border-gray-700">3.58 × 10^5</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">243</td>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

            <td class="px-3 py-2 border-b border-gray-700">61</td>

            <td class="px-3 py-2 border-b border-gray-700">60.75</td>

            <td class="px-3 py-2 border-b border-gray-700">34</td>

            <td class="px-3 py-2 border-b border-gray-700">1.80 × 10^7</td>

            <td class="px-3 py-2 border-b border-gray-700">1.72 × 10^-2</td>

            <td class="px-3 py-2 border-b border-gray-700">3.08 × 10^5</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">224</td>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

            <td class="px-3 py-2 border-b border-gray-700">56</td>

            <td class="px-3 py-2 border-b border-gray-700">56.0</td>

            <td class="px-3 py-2 border-b border-gray-700">31</td>

            <td class="px-3 py-2 border-b border-gray-700">5.34 × 10^6</td>

            <td class="px-3 py-2 border-b border-gray-700">1.98 × 10^-2</td>

            <td class="px-3 py-2 border-b border-gray-700">1.06 × 10^5</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">223</td>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

            <td class="px-3 py-2 border-b border-gray-700">56</td>

            <td class="px-3 py-2 border-b border-gray-700">55.75</td>

            <td class="px-3 py-2 border-b border-gray-700">31</td>

            <td class="px-3 py-2 border-b border-gray-700">4.49 × 10^6</td>

            <td class="px-3 py-2 border-b border-gray-700">1.88 × 10^-2</td>

            <td class="px-3 py-2 border-b border-gray-700">8.42 × 10^4</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">hand, since 384 is not too far beyond the upper bound for the size of GRP representable by  <span class="math">m + 1 = 7</span> , it may be preferable to trade 12-bits of security for much improved performance, see §11.</p>

    <p class="text-gray-300">Table 4. Efficient-reduction GRPs for  <span class="math">w = {64},q = 2</span>  and  <span class="math">t \\equiv  0\\left( {\\;\\operatorname{mod}\\;{2}^{{l}_{\\min }}}\\right)</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">log p</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">GRP</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S.C. Secure</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">511</td>

            <td class="px-3 py-2 border-b border-gray-700">Φ11(242·(29+1))</td>

            <td class="px-3 py-2 border-b border-gray-700">Yes</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">381</td>

            <td class="px-3 py-2 border-b border-gray-700">Φ11(234·(24-1))</td>

            <td class="px-3 py-2 border-b border-gray-700">Yes</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">380</td>

            <td class="px-3 py-2 border-b border-gray-700">Φ11(234·(24+1))</td>

            <td class="px-3 py-2 border-b border-gray-700">Yes</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">270</td>

            <td class="px-3 py-2 border-b border-gray-700">Φ7(234·(211-1))</td>

            <td class="px-3 py-2 border-b border-gray-700">Yes</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">253</td>

            <td class="px-3 py-2 border-b border-gray-700">Φ7(227·(215+1))</td>

            <td class="px-3 py-2 border-b border-gray-700">Yes</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">253</td>

            <td class="px-3 py-2 border-b border-gray-700">Φ7(237·(25+1))</td>

            <td class="px-3 py-2 border-b border-gray-700">Yes</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">243</td>

            <td class="px-3 py-2 border-b border-gray-700">Φ5(259·(22-1))</td>

            <td class="px-3 py-2 border-b border-gray-700">No</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">228</td>

            <td class="px-3 py-2 border-b border-gray-700">Φ5(254·(23-1))</td>

            <td class="px-3 py-2 border-b border-gray-700">Yes</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">224</td>

            <td class="px-3 py-2 border-b border-gray-700">Φ5(233·(223-1))</td>

            <td class="px-3 py-2 border-b border-gray-700">No</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">220</td>

            <td class="px-3 py-2 border-b border-gray-700">Φ5(252·(23-1))</td>

            <td class="px-3 py-2 border-b border-gray-700">Yes</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">As we showed in §5.2, there are no suitable GRPs in the ECC range for which  <span class="math">t = 2^l</span> . Hence the next best type of GRP parameter  <span class="math">t</span>  will have Hamming weight equal to 2, where we allow  <span class="math">c</span>  to have the form  <span class="math">2^{c&#x27;} + 1</span>  as well as  <span class="math">2^{c&#x27;} - 1</span>  when there is sufficient slack in the representation, since subtractions cost the same as additions. We list these GRPs in Table 4. The final column indicates whether or not the given GRP allows for atomic side-channel secure point additions and doublings, as per §9.2. Note that for  <span class="math">m + 1 = 5</span>  and  <span class="math">w = 64</span>  we can not represent GRPs any larger than 244-bits, and are thus short of the conjectured 128-bit ECC security level of 256-bits. One can therefore either move up to  <span class="math">m + 1 = 7</span> , which can represent GRPs</p>

    <p class="text-gray-300">of up to 360-bits, or one can opt to reduce security by a few bits, for better performance. Indeed, in recent work Käsper argues that the NIST GMN prime P-<span class="math">224=2^{224}-2^{96}+1</span> offers a satisfactory trade-off between security and efficiency <em>[31]</em>, when used as the basis of the elliptic curve Diffie-Hellman (ECDH) key exchange in the Transport Layer Security (TLS) protocol <em>[28]</em>. Bernstein has also implemented arithmetic mod P-224 <em>[4]</em>. Yet another possibilty at this security level are the GFN primes <span class="math">\\Phi_{8}(2^{41}\\cdot(2^{15}-1))</span> and <span class="math">\\Phi_{8}(2^{50}\\cdot(2^{6}-1))</span>, both of which have bitlength 224, but experiments with such GFNs have not yet been carried out. Of course in hardware, one can tailor the word base in order to achieve 256-bit atomic elliptic curve point operations without any residual slack.</p>

    <h2 id="sec-41" class="text-2xl font-bold">11 Implementation and Results</h2>

    <p class="text-gray-300">In this section we provide details of our proof-of-concept implementation and results. For simplicity we consider field multiplication only, as this tends to be the bottleneck in ECC point multiplication, and hence one can gain an accurate indication of performance in this simple way.</p>

    <p class="text-gray-300">In terms of performance, implementations can be compared using the eBATS benchmarking project <em>[8]</em>. For example, nearly all of the fastest 256-bit ECDH implementations in the literature <em>[5, 6, 22, 23, 27, 40]</em> feature in eBATS. However, as it is difficult to get a fair comparison between our implementation of multiplication and the above ECDH implementations, we opt to compare our multiplication performance with that featured in the mp<span class="math">\\mathbb{F}_{q}</span> benchmarking system due to Gaudry and Thomé <em>[23]</em>, which allows for such a comparison. This has been ported to OS-X 10.5.8 with minor changes and executed on a platform using an Intel Core 2 Duo at 2.2Ghz. As stated in <em>[6]</em>, to date mp<span class="math">\\mathbb{F}_{q}</span> gives only the fourth fastest implementation of ECDH, based on Bernstein’s curve25519, which utilises a non-standard representation of residues mod <span class="math">2^{255}-19</span> and exploits the floating-point unit of specific instruction-set architectures to great effect. Nevertheless, by comparing the basic multiplication cost on the target architecture, one can obtain a crude estimate of the relative performance of our arithmetic with that of curve25519, and hence in turn with the other implementations featured in eBATS.</p>

    <p class="text-gray-300">Our implementation consists of essentially two inline assembly operations targeted at the Core 2 processor. One accumulates the innermost sum of line 2 of Algorithm 6, while the other performs a single instance of the reduction operation in line 2 of Algorithm 4. There are two versions of the latter which correspond to whether or not the cofactor <span class="math">c</span> is general — which hence requires an imulq instruction — or is specialised, i.e., with Hamming weight 2. These operations use the 64-bit operations available on the Core 2 and the extended register set available in x86-64, each using a mere 4 of the 15 registers available. This allows one to rely on normal C code to arrange these macros, and to handle data-storage. As a result the gcc compiler can generate all of the intermediate memory access instructions and schedule the usage of the other 11 registers available. This means that the same code can be reused for any field supported by Algorithm 6 — the only changes required are the parameter definitions. To generate a particular instance of the family of algorithms we use a simple wrapper written in Python that arranges the sequence of these operations required for the particular parameter choice of <span class="math">m+1</span> and <span class="math">t</span>.</p>

    <p class="text-gray-300">To emphasise the relative simplicity of our implementation, we use only 64-bit scalar operations on the processor, and allow the compiler to schedule most of the output instructions. As a result we reach a throughput of slightly less than one operation per cycle. In comparison</p>

    <p class="text-gray-300">the  <span class="math">\\mathfrak{mpF}_q</span>  implementation of curve25519 uses SSE2 to reach a throughput of almost two operations per cycle (the theoretical maximum on the architecture). Although our implementation is less efficient (because we have spent less programmer time on the machine-dependent optimisation) the performance achieved is still higher. Scheduling a lower-level implementation on the processor would be an interesting challenge.</p>

    <p class="text-gray-300">As explained in §5 and §10, within the reduction algorithm we have a trade-off between the number of GRPs available and performance. If one opts for a generic value of  <span class="math">c</span>  then many GRPs are available, but the reduction involves a full imulq instruction with relatively high latency. If we specialise our choice of  <span class="math">c</span>  to those with Hamming weight 2 then we can replace this instruction with a shift and an add or sub instruction to improve performance. We have measured the performance of both implementations. To ensure a fair comparison we have merged our code into  <span class="math">\\mathfrak{mpF}_q</span>  so that all algorithms are being tested with the same timing code. This timer executes  <span class="math">10^6</span>  operations in the field, measuring the elapsed time. The reported figures are the mean execution time for the operation. Table 5 contains cycle counts for Montgomery arithmetic at various bitlengths, as well as the curve25519 modular multiplication cycle count. Table 6 contains our results for GRP modular multiplication.</p>

    <p class="text-gray-300">Table 5.  <span class="math">\\mathrm{{mp}}{\\mathbb{F}}_{q}</span>  cycle counts for curve25519 and Montgomery arithmetic</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Algorithm</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Size (bits)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">ModMul (cycles)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Mont.</td>

            <td class="px-3 py-2 border-b border-gray-700">64</td>

            <td class="px-3 py-2 border-b border-gray-700">30</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Mont.</td>

            <td class="px-3 py-2 border-b border-gray-700">128</td>

            <td class="px-3 py-2 border-b border-gray-700">105</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Mont.</td>

            <td class="px-3 py-2 border-b border-gray-700">192</td>

            <td class="px-3 py-2 border-b border-gray-700">195</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">curve25519</td>

            <td class="px-3 py-2 border-b border-gray-700">255</td>

            <td class="px-3 py-2 border-b border-gray-700">140</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Mont.</td>

            <td class="px-3 py-2 border-b border-gray-700">256</td>

            <td class="px-3 py-2 border-b border-gray-700">280</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Mont.</td>

            <td class="px-3 py-2 border-b border-gray-700">320</td>

            <td class="px-3 py-2 border-b border-gray-700">407</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Mont.</td>

            <td class="px-3 py-2 border-b border-gray-700">384</td>

            <td class="px-3 py-2 border-b border-gray-700">563</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Mont.</td>

            <td class="px-3 py-2 border-b border-gray-700">448</td>

            <td class="px-3 py-2 border-b border-gray-700">757</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Mont.</td>

            <td class="px-3 py-2 border-b border-gray-700">512</td>

            <td class="px-3 py-2 border-b border-gray-700">981</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 6. Cycle counts for GRP arithmetic</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Parameters</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Max size (bits)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">ModMul (cycles)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">m+1=5, HW(c)=2</td>

            <td class="px-3 py-2 border-b border-gray-700">244</td>

            <td class="px-3 py-2 border-b border-gray-700">96</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">m+1=5, general c</td>

            <td class="px-3 py-2 border-b border-gray-700">244</td>

            <td class="px-3 py-2 border-b border-gray-700">112</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">m+1=7, HW(c)=2</td>

            <td class="px-3 py-2 border-b border-gray-700">360</td>

            <td class="px-3 py-2 border-b border-gray-700">165</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">m+1=7, general c</td>

            <td class="px-3 py-2 border-b border-gray-700">360</td>

            <td class="px-3 py-2 border-b border-gray-700">182</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">m+1=11, general c</td>

            <td class="px-3 py-2 border-b border-gray-700">600</td>

            <td class="px-3 py-2 border-b border-gray-700">340</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">As shown in Table 1 and considered in §10.2, the closest size of field to curve25519 that we can implement using  <span class="math">m + 1 = 5</span>  is only 244-bits. This small reduction in field size is compensated by an increase in performance, requiring only  <span class="math">80\\%</span>  of the curve25519 cycles per multiplication. Using the specialised reduction function for the 243-bit GRP  <span class="math">\\varPhi_{5}(2^{59} \\cdot (2^{2} - 1))</span> , this figure improves to  <span class="math">69\\%</span> . Since the results for the first line of Table 6 apply also to</p>

    <p class="text-gray-300">Hamming weight 2 GRPs smaller than 243-bits, we obtain the same modular multiplication performance for the 228-bit GRP <span class="math">\\Phi_{5}(2^{54}\\cdot(2^{3}-1))</span>, while utilising the acquired slack in the representation to ensure atomic point doublings/additions as per §9.2. At 512-bits with general <span class="math">c</span>, compared to Montgomery multiplication, GRP multiplication costs only 35% as many cycles. For GRPs of 600-bits, this proportion would naturally be even smaller, however at this size Karatsuba-Ofman multiplication may be faster than schoolbook multiplication. We thus expect that point multiplications using 224-bit and 512-bit GRPs to be competitive with the state-of-the-art in the literature, once optimised. In particular, by comparing our arithmetic with the modular multiplication used in <em>[6]</em>, which is the benchmark for point multiplication at the 128-bit security level, one gains an idea of the potential performance of arithmetic mod <span class="math">\\Phi_{5}(2^{54}\\cdot(2^{3}-1))</span>, for example. In <em>[6]</em>, residues are also represented by five 64-bit words. Residue multiplication requires 25 mul instructions, as well as 4 imul, 20 add and 20 adc instructions. In comparison, to multiply <span class="math">\\overline{\\mathbf{x}}</span> and <span class="math">\\overline{\\mathbf{y}}</span> in our representation, the CVMA formulae are as follows:</p>

    <p class="text-gray-300"><span class="math">z_{0}</span> <span class="math">=(x_{4}-x_{1})(y_{1}-y_{4})+(x_{3}-x_{2})(y_{2}-y_{3}),</span> <span class="math">z_{1}</span> <span class="math">=(x_{2}-x_{4})(y_{4}-y_{2})+(x_{1}-x_{0})(y_{0}-y_{1}),</span> <span class="math">z_{2}</span> <span class="math">=(x_{0}-x_{2})(y_{2}-y_{0})+(x_{4}-x_{3})(y_{3}-y_{4}),</span> <span class="math">z_{3}</span> <span class="math">=(x_{3}-x_{0})(y_{0}-y_{3})+(x_{2}-x_{1})(y_{1}-y_{2}),</span> <span class="math">z_{4}</span> <span class="math">=(x_{1}-x_{3})(y_{3}-y_{1})+(x_{0}-x_{4})(y_{4}-y_{0}),</span></p>

    <p class="text-gray-300">requiring only 10 mul, 20 sub and 5 add and 5 adc instructions. Since the respective reduction algorithms are quite similar with both requiring two rounds of shifts, masks and additions, one expects the GRP modular multiplication to be considerably faster, when optimised. However, since this paper is predominantly expositional, we leave such optimisations as open research.</p>

    <h2 id="sec-42" class="text-2xl font-bold">12 Conclusion</h2>

    <p class="text-gray-300">We have proposed efficient algorithms for performing arithmetic modulo a large family of primes, namely the generalised repunit primes. The algorithms are simple to implement, are fast, are easily parallelisable, can be made side-channel secure, and all across a wide range of field sizes. The central contribution of this work is the development of the necessary theory, covering field and residue representation, as well as algorithms for performing efficient multiplication and reduction in these fields. We have also presented proof-of-concept implementation results which provide an empirical comparison with results in the literature, which we ensured is fair by using the mpF_{q} benchmarking procedure. Against Montgomery arithmetic we show an approximate 3-fold improvement in performance, and expect optimised implementations of point multiplications using our proposed family to be competitive with state-of-the-art implementations. We have thus presented a compelling argument in favour of a new approach to the secure and efficient implementation of ECC.</p>

    <h2 id="sec-43" class="text-2xl font-bold">Acknowledgements</h2>

    <p class="text-gray-300">The authors would like to thank Dan Page for making several very useful comments and suggestions.</p>

    <p class="text-gray-300">References</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[1] A.O.L. Atkin and F. Morain. Elliptic curves and primality proving. Math. Comp., 61(203):29-68, 1993.</li>

      <li>[2] P. Barrett. Implementing the Rivest Shamir and Adleman public key encryption algorithm on a standard digital signal processor, In Advances in CryptologyCRYPTO 86 Springer-Verlag, LNCS 263, 311323, 1987.</li>

      <li>[3] P.T. Bateman and R.A. Horn. A Heuristic Asymptotic Formula Concerning the Distribution of Prime Numbers. In Math. Comp. 16, pp. 363–367, 1962.</li>

      <li>[4] D.J. Bernstein. A software implementation of NIST P-224. Presentation at the 5th Workshop on Elliptic Curve Cryptography (ECC 2001), University of Waterloo, October 29-31, 2001. Slides available from http://cr.yp.to/talks.html.</li>

      <li>[5] D.J. Bernstein. Curve25519: New Diffie-Hellman Speed Records. In Public Key Cryptography - PKC 2006, LNCS 3958, 207–228. Springer-Verlag, 2006.</li>

      <li>[6] D.J. Bernstein, N. Duif, T. Lange, P. Schwabe and B. Yang. High-speed high-security signatures. Cryptology ePrint Archive, Report 2011/368, 2011.</li>

      <li>[7] D.J. Bernstein and T. Lange. Faster addition and doubling on elliptic curves. In Advances in Cryptology ASIACRYPT 2007, LNCS 4833, pp. 29–50, Springer-Verlag, 2007.</li>

      <li>[8] D.J. Bernstein and T. Lange (editors). eBACS: ECRYPT Benchmarking of Cryptographic Systems. http://bench.cr.yp.to/ebats.html.</li>

      <li>[9] I.F. Blake, R.M. Roth and G. Seroussi. Efficient Arithmetic in <span class="math">GF(2^{m})</span> through Palindromic Representation. Technical Report HPL-98-134, 1998. Available from http://www.hpl.hp.com/techreports/98/HPL-98-134.html.</li>

      <li>[10] I.F. Blake, G. Seroussi, and N.P. Smart. Advances in Elliptic Curve Cryptography. London Mathematical Society Lecture Note Series, 317, Cambridge University Press, 2005.</li>

      <li>[11] M. Brown, D. Hankerson, J. López, and A. Menezes Software Implementation of the NIST Elliptic Curves Over Prime Fields In Topics in Cryptology CT-RSA 2001, LNCS 2020, 250–265, Springer.</li>

      <li>[12] J. Chung A. Hasan. More Generalized Mersenne Numbers. In Selected Areas in Cryptography, volume 3006 of LNCS, 335 – 347. Springer, 2004.</li>

      <li>[13] J. Chung and A. Hasan. Low-Weight Polynomial Form Integers for Efficient Modular Multiplication. In IEEE Trans. Comput., 56-1, 44–57, 2007.</li>

      <li>[14] J. Chung and A. Hasan. Montgomery Reduction Algorithm for Modular Multiplication Using Low-Weight Polynomial Form Integers. In ARITH 18, 230–239, 2007</li>

      <li>[15] J.S. Coron. Resistance against differential power analysis for elliptic curve cryptosystems. In Cryptographic Hardware and Embedded Systems CHES 99, LNCS 1717, pp. 292–302, 1999.</li>

      <li>[16] R.E. Crandall, E.W. Mayer and J.S. Papadopoulos. The twenty-fourth fermat number is composite. In Math. Comp., vol. 72, 243, pp. 1555–1572, 2003.</li>

      <li>[17] H. Dubner. Generalized Repunit Primes. In Math. Comp., vol. 61, 204, pp. 927–930, 1993.</li>

      <li>[18] H. Dubner and Y. Gallot. Distribution of generalized Fermat prime numbers. In Math. Comp., vol. 71, 238, pp. 825–832, 2002.</li>

      <li>[19] H. Dubner and T. Granlund. Primes of the Form <span class="math">(b^{n}+1)/(b+1)</span>. In Journal of Integer Sequences, vol. 3, 2, Art. 0.0.2.7, 2000.</li>

      <li>[20] G. Drolet. A new representation of elements of finite fields <span class="math">GF(2^{m})</span> yielding small complexity arithmetic circuits. IEEE Trans. Comput., 47(9): 938–946, 1998.</li>

      <li>[21] FIPS 186-2. Digital Signature Standard. Federal Information Processing Standards Publication 186-2, US Department of Commerce/N.I.S.T. 2000.</li>

      <li>[22] S.D. Galbraith, X. Lin and M. Scott. Endomorphisms for Faster Elliptic Curve Cryptography on a Large Class of Curves. In J. Cryptology, vol. 24, no. 3, pp. 446–469, 2011.</li>

      <li>[23] P. Gaudry and E. Thomé. The mpFq library and implementing curve-based key exchanges. In SPEED: Software Performance Enhancement for Encryption and Decryption, ECRYPT Workshop, 49–64, 2007.</li>

      <li>[24] W. Geiselmann and D. Grollmann. VLSI design for exponentiation in <span class="math">GF(2^{m})</span>. AUSCRYPT’90, 398–405. Springer-Verlag, 2001.</li>

      <li>[25] L. Goubin. A refined power analysis attack on elliptic curve cryptosystems. In em Public Key Cryptography PKC 03, LNCS 2567, pp. 199–211, 2003.</li>

      <li>[26] G. Hachez and J.J. Quisquater. Montgomery Exponentiation with No Final Subtractions: Improved Results. In Cryptographic Hardware and Embedded Systems (CHES), Springer-Verlag LNCS 1965, pp. 293–301, 2000.</li>

      <li>[27] Hüseyin Hisil. Elliptic curves, group law, and efficient computation. Ph.D. thesis, Queensland University of Technology, 2010. URL: http://eprints.qut.edu.au/33233.</li>

      <li>[28] Internet Engineering Task Force. Elliptic Curve Cryptography (ECC) Cipher Suites for Transport Layer Security (TLS), 2006. http://www.ietf.org/rfc/rfc4492.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[29] T. Itoh and S. Tsuji. Structure of Parallel Multipliers for a Class of Fields <span class="math">GF(2^{m})</span>. In Information and Computers, vol. 8, 21–40, 1989.</li>

      <li>[30] A. Karatsuba and Y. Ofman. Multiplication of multidigit numbers on automata. In Soviet Physics, Doklady 7, 595–596, 1963.</li>

      <li>[31] E. Käsper. Fast elliptic curve cryptography in OpenSSL. In 2nd Workshop on Real-Life Cryptographic Protocols and Standardization (RLCPS 2011), to appear, 2011.</li>

      <li>[32] D.E. Knuth. The Art of Computer Programming, 2 - Semi-numerical Algorithms. Addison-Wesley, 2nd edition, 1981.</li>

      <li>[33] N. Koblitz. Elliptic curve cryptosystems. In Math. Comp., 48, pp. 203–209, 1987.</li>

      <li>[34] C.K. Koç, T. Acar and B.S. Kaliski Jr. Analyzing and comparing Montgomery multiplication algorithms. In IEEE Micro, vol. 16, 3, pp. 26–33, 1996.</li>

      <li>[35] P.C. Kocher. Timing attacks on implementations of Diffie-Hellman, RSA, DSS and other systems. In Advances in Cryptology CRYPTO 96, LNCS 1109, pp. 104–113, 1996.</li>

      <li>[36] P.C. Kocher, J. Jaffe and B. Jun. Differential power analysis. In Advances in Cryptology CRYPTO 99, LNCS 1666, pp. 388–397, 1999.</li>

      <li>[37] S. Kwon, C.H. Kim and C.P. Hong. Gauss Period, Sparse Polynomial, Redundant Basis, and Efficient Exponentiation for a Class of Finite Fields with Small Characteristic. In ISAAC 2003, LNCS 2906, pp. 736–745, 2003.</li>

      <li>[38] A.K. Lenstra and H.W. Lenstra. The Development of the Number Field Sieve. LNM 1554, Springer-Verlag, 1993.</li>

      <li>[39] H.W. Lenstra, Jr. Factoring integers with elliptic curves. Ann. of Math. (2), 126(3):649–673, 1987.</li>

      <li>[40] P. Longa and C.H. Gebotys. Efficient techniques for high-speed elliptic curve cryptography. In Cryptographic hardware and embedded systems, CHES 2010, LNCS 6225, pp. 80–94, Springer 2010.</li>

      <li>[41] V. Miller. Use of elliptic curves in cryptography. In Advances in Cryptology - CRYPTO 85. LNCS 218, Springer-Verlag, pp. 417–426, 1985.</li>

      <li>[42] P.L. Montgomery. Modular Multiplication without trial division. Math. Comp., 44, 519–521, 1985.</li>

      <li>[43] D. Naccache, N.P. Smart and J. Stern. Projective Coordinates Leak. In Advances in Cryptology - EUROCRYPT, LNCS 2586, pp. 257–267, Springer-Verlag, 2004.</li>

      <li>[44] Y. Nogami, A. Saito, and Y. Morikawa. Finite Extension Field with Modulus of All-One Polynomial and Representation of Its Elements for Fast Arithmetic Operations. In IEICE TRANSACTIONS on Fundamentals of Electronics, Communications and Computer Sciences Vol.E86-A No.9, 2376–2387, 2003.</li>

      <li>[45] E. Ozturk, B. Sunar, and E. Savas. Low-Power Elliptic Curve Cryptography Using Scaled Modular Arithmetic. In CHES 2004, Springer Verlag, LNCS 3156, pp 92–106, 2004.</li>

      <li>[46] D.S. Phatak and T. Goff. Fast Modular Reduction for Large Wordlengths via One Linear and One Cyclic Convolution. In 17th IEEE Symposium on Computer Arithmetic (ARITH’05), pp. 179–186, 2005.</li>

      <li>[47] R.L. Rivest, Shamir A., and L.M. Adleman. A method for obtaining digital signatures and public-key cryptosystems. Comm. ACM, 21, 120 – 126, 1978.</li>

      <li>[48] Y. Sakai and K. Sakurai. Simple Power Analysis on Fast Modular Reduction with Generalized Mersenne Prime for Elliptic Curve Cryptosystems. In Ieice Transactions - IEICE, vol. 89-A, no. 1, pp. 231–237, 2006.</li>

      <li>[49] A. Schinzel and W. Sierpiński. Sur certaines hypothèses concernant les nombres premiers. In Acta Arith. 4 (1958), pp. 185–208, Erratum 5 (1959), 259.</li>

      <li>[50] J.H. Silverman. Fast Multiplication in Finite Fields <span class="math">GF(2^{N})</span>. In Proc. Workshop Cryptographic Hardware and Embedded Systems (CHES ’99), LNCS 1717, 122–134. Springer 1999.</li>

      <li>[51] N.P. Smart, E. Oswald and D. Page. Randomised representations. In IET Information Security, vol. 2, 2, pp. 19–27, 2008.</li>

      <li>[52] W.M. Snyder. Factoring repunits. In Amer. Math. Monthly, 89 pp. 462–466, 1982.</li>

      <li>[53] J.A. Solinas. Generalized Mersenne Numbers. Technical report CORR-39, Dept. of C&amp;O, University of Waterloo, 1999. Available from http://www.cacr.math.uwaterloo.cahttp://citeseer.ist.psu.edu/solinas99generalized.</li>

      <li>[54] C.D. Walter. Faster Modular Multiplication by Operand Scaling. Advances in Cryptology LNCS 576, 313–323, Springer Verlag, 1992.</li>

      <li>[55] C.D. Walter. Montgomery Exponentiation Needs No Final Subtractions. In Electronics Letters, 35, pp. 1831–1832, 1999.</li>

      <li>[56] C.D. Walter. Montgomery’s Multiplication Technique: How to Make it Smaller and Faster. In Cryptographic Hardware and Embedded Systems (CHES), Springer-Verlag LNCS 1717, pp. 80–93, 1999.</li>

      <li>[57] C.D. Walter and S. Thompson. Distinguishing Exponent Digits by Observing Modular Subtractions. In CT-RSA 2001, LNCS 2020, pp. 192–207, 2001.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[58] H.C. Williams and E. Seah. Some primes of the form <span class="math">(a^{n}-1)/(a-1)</span>. In Math. Comp. 33, pp. 1337–1342, 1979.</li>

      <li>[59] J.K. Wolf. Low Complexity Finite Field Multiplication. In Discrete Math., no.s 106/107, 497–502, 1992.</li>

      <li>[60] H. Wu, A. Hasan, I. Blake and S. Gao. Finite Field Multiplier Using Redundant Representation. IEEE Trans. Comput., Vol 51, Num 11, Nov 2002.</li>

      <li>[61] S. Yekhanin. Towards 3-query locally decodable codes of subexponential length. STOC ’07, Proceedings of the thirty-ninth annual ACM symposium on Theory of computing, 266–274, 2007.</li>

    </ul>`;
---

<BaseLayout title="Generalised Mersenne Numbers Revisited (2011/444)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2011 &middot; eprint 2011/444
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
