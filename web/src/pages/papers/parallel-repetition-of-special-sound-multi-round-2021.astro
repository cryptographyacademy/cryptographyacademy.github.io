---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2021/1259';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Parallel Repetition of $(k_1,\\dots,k_{\\mu})$-Special-Sound Multi-Round Interactive Proofs';
const AUTHORS_HTML = 'Thomas Attema, Serge Fehr';

const CONTENT = `    <p class="text-gray-300">Thomas Attema<span class="math">^{1,2,3}</span> and Serge Fehr<span class="math">^{1,2}</span></p>

    <p class="text-gray-300"><span class="math">^{1}</span> CWI, Cryptology Group, Amsterdam, The Netherlands serge.fehr@cwi.nl</p>

    <p class="text-gray-300"><span class="math">^{2}</span> Leiden University, Mathematical Institute, Leiden, The Netherlands <span class="math">^{3}</span> TNO, Cyber Security and Robustness, The Hague, The Netherlands thomas.attema@tno.nl</p>

    <p class="text-gray-300">Version 3 - September 6, 2023<span class="math">^{4}</span></p>

    <p class="text-gray-300">Abstract. In many occasions, the knowledge error <span class="math">\\kappa</span> of an interactive proof is not small enough, and thus needs to be reduced. This can be done generically by repeating the interactive proof in parallel. While there have been many works studying the effect of parallel repetition on the soundness error of interactive proofs and arguments, the effect of parallel repetition on the knowledge error has largely remained unstudied. Only recently it was shown that the <span class="math">t</span>-fold parallel repetition of any interactive protocol reduces the knowledge error from <span class="math">\\kappa</span> down to <span class="math">\\kappa^t + \\nu</span> for any non-negligible term <span class="math">\\nu</span>. This generic result is suboptimal in that it does not give the knowledge error <span class="math">\\kappa^t</span> that one would expect for typical protocols, and, worse, the knowledge error remains non-negligible.</p>

    <p class="text-gray-300">In this work we show that indeed the <span class="math">t</span>-fold parallel repetition of any <span class="math">(k_{1},\\ldots ,k_{\\mu})</span>-special-sound multi-round public-coin interactive proof optimally reduces the knowledge error from <span class="math">\\kappa</span> down to <span class="math">\\kappa^t</span>. At the core of our results is an alternative, in some sense more fine-grained, measure of quality of a dishonest prover than its success probability, for which we show that it characterizes when knowledge extraction is possible. This new measure then turns out to be very convenient when it comes to analyzing the parallel repetition of such interactive proofs.</p>

    <p class="text-gray-300">While parallel repetition reduces the knowledge error, it is easily seen to increase the completeness error. For this reason, we generalize our result to the case of <span class="math">s</span>-out-of-<span class="math">t</span> threshold parallel repetition, where the verifier accepts if <span class="math">s</span> out of <span class="math">t</span> of the parallel instances are accepting. An appropriately chosen threshold <span class="math">s</span> allows both the knowledge error and completeness error to be reduced simultaneously.</p>

    <p class="text-gray-300">Keywords: Proofs of Knowledge, Knowledge Soundness, Special-Soundness, Knowledge Extractor, Parallel Repetition, Threshold Parallel Repetition.</p>

    <h2 id="sec-3" class="text-2xl font-bold">1.1 Background</h2>

    <p class="text-gray-300">Proofs of Knowledge. Proofs of Knowledge (PoKs) are essential building blocks in many cryptographic primitives. They allow a prover <span class="math">\\mathcal{P}</span> to convince a verifier <span class="math">\\mathcal{V}</span> that it knows a (secret) string <span class="math">w \\in \\{0,1\\}^*</span>, called a witness, satisfying some public constraint. Typically a prover wishes to do this either in (honest-verifier) zero-knowledge, i.e., without revealing any information about the witness <span class="math">w</span> beyond the veracity of the claim, or with communication costs smaller than the size of the witness <span class="math">w</span>. Both these requirements prevent the prover from simply revealing the witness <span class="math">w</span>.</p>

    <p class="text-gray-300">A key property of PoKs is knowledge soundness. Informally, a protocol is said to be knowledge sound if a dishonest prover that does not know the secret witness can only succeed in convincing a verifier with some small probability <span class="math">\\kappa</span> called the knowledge error. This is formalized by requiring the existence of an efficient extractor so that for any dishonest prover that succeeds with probability <span class="math">\\epsilon &amp;gt; \\kappa</span>, the extractor</p>

    <p class="text-gray-300"><span class="math">^{4}</span> Change log w.r.t. Version 2 - February 16, 2022: Corrected a technical oversight by slightly redefining the punctured success probability <span class="math">\\delta_{k}</span> and its multi-round variant <span class="math">\\delta_{\\mathbf{k}}</span>. In particular, <span class="math">\\delta_{k}</span> is now defined as a minimum over all subsets of cardinality exactly <span class="math">k - 1</span>, whereas this used to be a minimum over all subsets of cardinality at most <span class="math">k - 1</span>. This subtle difference does not affect the analysis of <span class="math">\\Sigma</span>-protocols (in fact, the actual value of <span class="math">\\delta_{k}</span> remains the same), but it turns out to be crucial in the multi-round analysis.</p>

    <p class="text-gray-300">outputs a witness <span class="math">w</span> with probability at least <span class="math">\\epsilon-\\kappa</span>, up to a multiplicative polynomial loss (in the security parameter), when given black-box access to the prover <em>[16]</em>.</p>

    <p class="text-gray-300">Typical 3-round public-coin protocols satisfy the conceptually simpler notion called <em>special-soundness</em>. A 3-round protocol is said to be special-sound if there exists an efficient algorithm that given two valid prover-verifier conversations (transcripts) <span class="math">(a,c,z)</span> and <span class="math">(a,c^{\\prime},z^{\\prime})</span>, with common first message <span class="math">a</span> and distinct second messages (challenges) <span class="math">c\\neq c^{\\prime}</span>, outputs a witness <span class="math">w</span>. More generally, a 3-round protocol is called <span class="math">k</span>-special-sound if the algorithm requires <span class="math">k</span> transcripts, instead of <span class="math">2</span>, to compute <span class="math">w</span>. If <span class="math">k</span> is polynomial in the size of the input <span class="math">x</span>, the property <span class="math">k</span>-special-soundness tightly implies the standard notion of knowledge soundness by a generic reduction, with <span class="math">\\kappa=(k-1)/N</span>, where <span class="math">N</span> is the number of challenges <em>[20, 3]</em>.</p>

    <p class="text-gray-300">In recent years, <em>multi-round</em> PoKs have gained a lot of attention <em>[8, 10, 22, 11, 1, 9, 2, 3, 4]</em>. The notion of <span class="math">k</span>-special-soundness, which is tailored to 3-round protocols, extends quite naturally to <span class="math">(k_{1},\\ldots,k_{\\mu})</span>-special-soundness for <span class="math">(2\\mu+1)</span>-round protocols (see Definition 7 for the formal definition). Many of the considered multi-round protocols satisfy this multi-round version of the special-soundness property. Surprisingly, only recently it was shown that also this generalization tightly implies knowledge soundness <em>[3]</em>.</p>

    <h4 id="sec-4" class="text-lg font-semibold mt-6">Parallel Repetition.</h4>

    <p class="text-gray-300">In certain occasions, the knowledge error <span class="math">\\kappa</span> of a “basic” PoK (and thereby the cheating probability of a dishonest prover) is not small enough, and thus needs to be reduced. This is particularly the case for lattice-based PoKs, where typically challenge sets are only of polynomial size resulting in non-negligible knowledge errors <em>[21, 5]</em>. Reducing the knowledge error can be done generically by repeating the PoK. Indeed, repeating a PoK <span class="math">t</span> times <em>sequentially</em>, i.e., one after the other, is known to reduce the knowledge error from <span class="math">\\kappa</span> down to <span class="math">\\kappa^{t}</span> <em>[16]</em>. However, this approach also increases the number of communication rounds by a factor <span class="math">t</span>. This is often undesirable, and sometimes even insufficient, e.g., because the security loss of the Fiat-Shamir transformation, transforming interactive into non-interactive protocols, is oftentimes exponential in the number of rounds.</p>

    <p class="text-gray-300">Therefore, it is much more attractive to try to reduce the knowledge error by <em>parallel</em> repetition. In the case of special-sound protocols, i.e., <span class="math">k</span>-special-sound protocols with <span class="math">k=2</span>, such a parallel repetition is easy to analyze: the <span class="math">t</span>-fold parallel repetition of a special-sound protocol with challenge space of cardinality <span class="math">N</span> is again special-sound protocol, but now with a challenge space of size <span class="math">N^{t}</span>, and so knowledge-soundness with <span class="math">\\kappa=1/N^{t}</span> follows immediately from the generic reduction. Unfortunately, this reasoning does not extend to <span class="math">k</span>-special-sound protocols with <span class="math">k&gt;2</span>: even though we still have that the <span class="math">t</span>-fold parallel repetition of a <span class="math">k</span>-special-sound protocol is <span class="math">k^{\\prime}</span>-special-sound, but now with <span class="math">k^{\\prime}=(k-1)^{t}+1</span>, this large increase in the special-soundness parameter renders the extractor, obtained via the generic reduction, inefficient. More precisely, the run-time of a <span class="math">k^{\\prime}</span>-special-sound protocol scales linearly in <span class="math">k^{\\prime}</span>, and therefore exponentially in <span class="math">t</span> for <span class="math">k^{\\prime}=(k-1)^{t}+1</span>, unless <span class="math">k=2</span>. In case of multi-round protocols, it is not even clear that the <span class="math">t</span>-fold parallel repetition of a <span class="math">(k_{1},\\ldots,k_{\\mu})</span>-special-sound <span class="math">(2\\mu+1)</span>-round protocol satisfies any meaningful notion of special-soundness.</p>

    <p class="text-gray-300">Somewhat surprisingly, so far the only way to analyze the knowledge error <span class="math">\\kappa</span> of the parallel repetition of <span class="math">k</span>-special-sound protocols with <span class="math">k&gt;2</span>, or of <span class="math">(k_{1},\\ldots,k_{\\mu})</span>-special-sound multi-round protocols, is by means of suboptimal <em>generic</em> parallel-repetition results — or by considering weaker notions of knowledge soundness (see the discussion below). Concretely, based on a result from <em>[13]</em>, it was recently shown that the <span class="math">t</span>-fold parallel repetition of <em>any</em> public-coin PoK reduces the knowledge error from <span class="math">\\kappa</span> down to <span class="math">\\kappa^{t}+\\nu</span> for any non-negligible term <span class="math">\\nu</span> <em>[3]</em>. This generic result is suboptimal in that, when applied to a <span class="math">k</span>-special-sound protocol for instance, it does not give the knowledge error <span class="math">\\kappa^{t}</span> that one expects (and that one should get when <span class="math">k=2</span>), and, worse, the knowledge error remains non-negligible.</p>

    <p class="text-gray-300">Even though this generic parallel-repetition result was shown to be tight, in that there are protocols for which parallel repetition does not allow the knowledge error to be reduced down to a negligible function, we can well hope for a stronger result for certain classes of protocols. In particular, it is not too absurd to expect <em>strong</em> parallel repetition for <span class="math">k</span>-special-sound protocols, and possibly for <span class="math">(k_{1},\\ldots,k_{\\mu})</span>-special-sound protocols in the multi-round case. Here, as usual in the general context of parallel repetition, the term “strong” means that the figure of merit <span class="math">\\kappa</span>, here the knowledge error, drops from <span class="math">\\kappa</span> to <span class="math">\\kappa^{t}</span> under a <span class="math">t</span>-fold parallel repetition.</p>

    <h4 id="sec-5" class="text-lg font-semibold mt-6">Other Notions of a PoK.</h4>

    <p class="text-gray-300">Due to the difficulty in proving the original definition in certain contexts, it has become quite customary to consider modified and/or relaxed notions of a PoK that make it then</p>

    <p class="text-gray-300">feasible to obtain positive or stronger results; it is then typically argued that the considered notion is still meaningful and useful (in the considered context).</p>

    <p class="text-gray-300">For example, many works on multi-round protocols consider the weaker notion of <em>witness-extended emulation</em> rather than the standard notion of knowledge soundness <em>[8, 10]</em>. In the context of quantum security, the knowledge extractor is typically allowed to have success probability <span class="math">(\\epsilon-\\kappa)^{c}</span> (up to a multiplicative polynomial loss) for an arbitrary constant <span class="math">c</span>, instead of <span class="math">\\epsilon-\\kappa</span> <em>[25]</em>. Moreover, recently, tighter security guarantees for discrete logarithm based <span class="math">\\Sigma</span>-protocols were obtained under a relaxed notion of knowledge soundness in which the knowledge extractor is not only given black-box access to the (possibly dishonest) prover <span class="math">\\mathcal{P}^{<em>}</span>, but is also given the success probability <span class="math">\\epsilon</span> of <span class="math">\\mathcal{P}^{</em>}</span> as input <em>[24]</em>. Finally, some works even allow the the extractor to depend arbitrarily on the prover <span class="math">\\mathcal{P}^{<em>}</span> </em>[14]*.</p>

    <p class="text-gray-300">In our work here, we instead insist on the original standard definition of a PoK, and we aim for strong parallel-repetition results nevertheless.</p>

    <h3 id="sec-6" class="text-xl font-semibold mt-8">1.2 Contributions</h3>

    <p class="text-gray-300">In short, we show a strong parallel repetition theorem for the knowledge error of <span class="math">(k_{1},\\ldots,k_{\\mu})</span>-special-sound <span class="math">(2\\mu+1)</span>-round protocols, for <span class="math">k_{1},\\ldots,k_{\\mu}</span> such that their product <span class="math">K=k_{1}\\cdots k_{\\mu}</span> is polynomial in the size of the input statement. This in particular implies strong parallel repetition for <span class="math">k</span>-special-sound protocols for arbitrary polynomial <span class="math">k</span>. Strong parallel repetition means that if the original protocol has knowledge error <span class="math">\\kappa</span> then the <span class="math">t</span>-fold parallel repetition has knowledge error <span class="math">\\kappa^{t}</span>, which is optimal, matching the success probability of a dishonest prover that attacks each instance in the parallel repetition independently (and thus succeeds with independent probability <span class="math">\\kappa</span> in each instance).</p>

    <p class="text-gray-300">We also consider a threshold parallel repetition, where the verifier accepts as soon as <span class="math">s</span> out of the <span class="math">t</span> parallel repetitions succeed, and we show also here that the knowledge error is what one would expect, matching the attack where the dishonest prover cheats in each of the <span class="math">t</span> instances independently and hopes that he is successful in at least <span class="math">s</span> of them.</p>

    <p class="text-gray-300">Our results directly apply to the typical <em>computational</em> version of special soundness as well, where there exists an efficient algorithm that <em>either</em> computes a witness from sufficiently many transcripts <em>or</em> provides a solution to a computational problem that is assumed to be hard (like producing a commitment along with two distinct openings) from sufficiently many transcripts. Indeed, such a protocol can simply be cast as an ordinary “unconditional” special-sound protocol for proving knowledge of: a witness <span class="math">w</span> <em>or</em> a solution to the considered computational problem, and then our results readily apply.</p>

    <h3 id="sec-7" class="text-xl font-semibold mt-8">1.3 Highlevel Approach</h3>

    <p class="text-gray-300">The starting point of our (threshold) parallel-repetition results is the following observation, considering (a single execution of) a <span class="math">k</span>-special-sound protocol. The default measure of quality of a dishonest prover <span class="math">\\mathcal{P}^{<em>}</span> is its success probability <span class="math">\\epsilon=\\epsilon(\\mathcal{P}^{</em>})</span>. For instance, if <span class="math">\\epsilon</span> is below the knowledge error <span class="math">\\kappa</span> then <em>in general</em> we cannot expect the extraction of a witness <span class="math">w</span> to work. However, the crucial observation is that for a given dishonest prover <span class="math">\\mathcal{P}^{<em>}</span>, its success probability <span class="math">\\epsilon</span> does actually not characterize (very well) whether extraction is possible or not. For instance, fixing <span class="math">\\mathcal{P}^{</em>}</span>’s first message, if <span class="math">\\mathcal{P}^{<em>}</span> then answers correctly with probability <span class="math">\\epsilon</span> (and fails to do so with probability <span class="math">1-\\epsilon</span>) independently </em>for each<em> possible choice of the challenge (where the randomness is over <span class="math">P^{</em>}</span>’s randomness used for computing the response), then extraction is still possible even when <span class="math">\\epsilon&lt;\\kappa</span> (yet noticeable): simply try sufficiently many times for <span class="math">k</span> distinct challenges, and after an expected number of <span class="math">k/\\epsilon</span> trials, we have <span class="math">k</span> correct responses to distinct challenges, from which a witness can then be computed.</p>

    <p class="text-gray-300">At the core of our results is a novel (and somewhat peculiar in its design) knowledge extractor for <span class="math">k</span>-special-sound protocols, whose success probability can be expressed in terms of an alternative, in some sense more fine-grained, measure of quality of <span class="math">\\mathcal{P}^{<em>}</span>. In more detail, in the context of a <span class="math">k</span>-special-sound <span class="math">3</span>-round protocol, we define <span class="math">\\delta_{k}(\\mathcal{P}^{</em>})</span> to be the <em>minimal</em> success probability of <span class="math">\\mathcal{P}^{*}</span> when <span class="math">k-1</span> challenges are</p>

    <p class="text-gray-300">removed from the challenge space (minimized over the choice of the removed challenges). We then show (Lemma 2) existence of an extractor <span class="math">\\mathcal{E}</span> that successfully extracts a witness from any <span class="math">\\mathcal{P}^{<em>}</span> with probability <span class="math">\\delta_{k}(\\mathcal{P}^{</em>})/k</span>. A simple calculation also shows that <span class="math">\\delta_{k}(\\mathcal{P}^{<em>})\\geq\\epsilon(\\mathcal{P}^{</em>})-(k-1)/N</span>, confirming that a <span class="math">k</span>-special-sound <span class="math">3</span>-round protocol has knowledge error <span class="math">\\kappa=(k-1)/N</span>. However, the crucial aspect is that this new measure <span class="math">\\delta_{k}(\\mathcal{P}^{*})</span> turns out to be convenient to work with when it comes to parallel repetition.</p>

    <p class="text-gray-300">Indeed, to obtain our parallel-repetition result for <span class="math">3</span>-round protocols, we first observe that a dishonest prover <span class="math">\\mathcal{P}^{<em>}</span> against a <span class="math">t</span>-fold parallel repetition naturally gives rise to <span class="math">t</span> dishonest provers <span class="math">\\mathcal{P}^{</em>}_{1},\\ldots,\\mathcal{P}^{<em>}_{t}</span> against a single invocation: <span class="math">\\mathcal{P}^{</em>}_{t}</span> simply mimics <span class="math">\\mathcal{P}^{<em>}</span>’s behavior in the <span class="math">i</span>-th invocation in the parallel repetition. Thus, <span class="math">\\epsilon(\\mathcal{P}^{</em>}_{i})</span> is then the probability that the <span class="math">i</span>-th invocation in the parallel repetition is accepted. However, the core observation is that it is more convenient to consider the measure <span class="math">\\delta_{k}(\\mathcal{P}^{<em>}_{i})</span> instead. Indeed, by basic probability theory we can show (Lemma 3) that <span class="math">\\delta_{k}(\\mathcal{P}^{</em>}_{1})+\\cdots+\\delta_{k}(\\mathcal{P}^{<em>}_{t})\\geq\\epsilon(\\mathcal{P}^{</em>})-\\kappa^{t}</span>. This in turn immediately gives us a lower bound of <span class="math">(\\epsilon(\\mathcal{P}^{<em>})-\\kappa^{t})/t</span> on the success probability of the natural way to try to extract a witness from <span class="math">\\mathcal{P}^{</em>}</span>, which is by means of running the above extractor <span class="math">\\mathcal{E}</span> for the single invocation case with each of the <span class="math">\\mathcal{P}^{<em>}_{i}</span>’s separately, each run of <span class="math">\\mathcal{E}</span> succeeding with probability <span class="math">\\delta_{k}(\\mathcal{P}^{</em>}_{i})</span> by the property of <span class="math">\\mathcal{E}</span>. Using a slightly more careful argument than upper bounding the sum of the <span class="math">\\delta_{k}(\\mathcal{P}^{<em>}_{i})</span>’s by <span class="math">t\\cdot\\max_{i}\\delta_{k}(\\mathcal{P}^{</em>}_{i})</span> shows a success probability of actually <span class="math">(\\epsilon(\\mathcal{P}^{*})-\\kappa^{t})/2</span>. Either way, this proves our strong parallel-repetition result for <span class="math">3</span>-round protocols.</p>

    <p class="text-gray-300">In order to prove the corresponding strong parallel-repetition result for general <span class="math">(k_{1},\\ldots,k_{\\mu})</span>-special-sound multi-round protocols, we follow the very same blueprint as above, but use an appropriately adjusted definition of <span class="math">\\delta_{k_{1},\\ldots,k_{\\mu}}(\\mathcal{P}^{<em>})</span> as the minimal success probability of <span class="math">\\mathcal{P}^{</em>}</span> when, in every challenge round <span class="math">i</span>, <span class="math">k_{i}-1</span> challenges are removed from the challenge space. First constructing an extractor <span class="math">\\mathcal{E}</span> for a single invocation by an appropriate recursive application of the extractor for the <span class="math">3</span>-round case, and then following the above line of reasoning to deal with the parallel repetition, we eventually obtain the existence of an extractor for the <span class="math">t</span>-fold parallel repetition of any <span class="math">(k_{1},\\ldots,k_{\\mu})</span>-special-sound protocol. The extractor requires an expected number of at most <span class="math">t\\cdot 2^{\\mu}\\cdot K\\leq t\\cdot K^{2}</span> queries to <span class="math">\\mathcal{P}^{*}</span> and succeeds with probability at least <span class="math">\\left(\\epsilon-\\kappa^{t}\\right)/(2K)</span>, where <span class="math">K=k_{1}\\cdots k_{\\mu}</span> and <span class="math">\\kappa</span> is the knowledge error of a single invocation of the protocol. Therefore, we prove that the <span class="math">t</span>-fold parallel repetition has knowledge error <span class="math">\\kappa^{t}</span>.</p>

    <h3 id="sec-8" class="text-xl font-semibold mt-8">1.4 Related Work</h3>

    <h4 id="sec-9" class="text-lg font-semibold mt-6">Reducing the Soundness Error (and Why Knowledge Soundness is Different).</h4>

    <p class="text-gray-300">A related question is that of reducing the (ordinary) soundness error of an interactive proof (or argument) by parallel repetition. It is well known that the <span class="math">t</span>-fold parallel repetition <span class="math">(\\mathcal{P}^{t},\\mathcal{V}^{t})</span> of an interactive proof (i.e., not argument) <span class="math">(\\mathcal{P},\\mathcal{V})</span> reduces the soundness error from <span class="math">\\sigma</span> down to <span class="math">\\sigma^{t}</span> <em>[15]</em>. Namely, it is relatively easy to reduce an arbitrary prover against the <span class="math">t</span>-fold parallel repetition, and which has success probability <span class="math">\\epsilon</span>, into a computationally unbounded prover that successfully attacks a single instantiation with probability at least <span class="math">\\epsilon^{1/t}</span>.</p>

    <p class="text-gray-300">The situation is trickier for interactive arguments, where the prover is required to be efficient and thus this reduction no longer works. Various parallel repetition theorems for interactive arguments have been established <em>[7, 23, 18, 19, 12, 13]</em>. As before, these results reduce an arbitrary prover <span class="math">\\mathcal{P}^{<em>}_{t}</span> against the <span class="math">t</span>-fold parallel repetition, and which has success probability <span class="math">\\epsilon</span>, into a prover <span class="math">\\mathcal{P}^{</em>}=\\mathcal{R}^{\\mathcal{P}^{<em>}_{t}}</span> attacking a single invocation of the interactive argument <span class="math">(\\mathcal{P},\\mathcal{V})</span>, but now with <span class="math">\\mathcal{P}^{</em>}</span> being efficient — well, a subtle issue is that in these parallel repetition theorems there is an unavoidable trade-off between the success probability and the run-time of <span class="math">\\mathcal{P}^{<em>}</span>. For instance, the reduction in </em>[12]<em> results in a prover <span class="math">\\mathcal{P}^{</em>}</span> with success probability <span class="math">\\epsilon^{1/t}\\cdot(1-\\xi)</span> and run-time polynomial in <span class="math">1/\\xi</span> for arbitrary <span class="math">\\xi&gt;0</span>.</p>

    <p class="text-gray-300">Such a trade off is fine in the context of the soundness error of interactive arguments (or proofs). Indeed, a reduction as above implies that if in a single invocation of the argument (or proof) any dishonest prover has bounded success probability, then a <span class="math">t</span>-fold parallel repetition has exponentially small soundness error. Namely, arguing by contradiction, assuming a prover <span class="math">\\mathcal{P}^{<em>}_{t}</span> against the <span class="math">t</span>-fold parallel repetition with a too good success probability, by suitable choice of parameters the prover <span class="math">\\mathcal{P}^{</em>}_{t}</span> can then be turned into a prover <span class="math">\\mathcal{P}^{<em>}=\\mathcal{R}^{\\mathcal{P}^{</em>}_{t}}</span> that violates the bound on the success probability of a single invocation.</p>

    <p class="text-gray-300">However, this trade-off between success probability and run time is a subtle but serious obstacle when considering the knowledge soundness of interactive proofs or arguments. Recall that, by standard</p>

    <p class="text-gray-300">definition [16], there much exist a single efficient extractor that works for all provers, and that must have a success probability that scales proportional to  <span class="math">\\epsilon -\\kappa</span>  for all provers (see Definition 4). But then, the naive approach of constructing the knowledge extractor  <span class="math">\\mathcal{E}_t</span>  for the parallel repetition, which is by running the knowledge extractor  <span class="math">\\mathcal{E}</span>  for the single invocation on the prover that is obtained by the generic reduction, i.e., setting  <span class="math">\\mathcal{E}_t^{\\mathcal{P}_t^s}\\coloneqq \\mathcal{E}^{(\\mathcal{R}^{\\mathcal{P}_t^s})}</span> , runs into problems since the reduction  <span class="math">\\mathcal{R}</span> , and thus the extractor  <span class="math">\\mathcal{E}_t</span> , depends on certain parameters, like the desired success probability of  <span class="math">\\mathcal{P}^<em> = \\mathcal{R}^{\\mathcal{P}_t^</em>}</span> , violating the definition.</p>

    <p class="text-gray-300">One possible "solution" is to weaken the standard definition of a proof of knowledge and to allow the extractor to depend on certain parameters; for instance, the parallel repetition result for predictable arguments of knowledge presented in [14] follows this approach and allows the extractor to arbitrarily depend on the prover. Another approach, as taken in [3], is to consider  <span class="math">\\mathcal{E}_t</span>  as above but then for a fixed choice of the reduction  <span class="math">\\mathcal{R}</span> , e.g., for a fixed choice of  <span class="math">\\xi</span>  in the context of [12] discussed above. However, since the extractor needs to be efficient,  <span class="math">\\xi</span>  must be chosen to be non-negligible then, resulting in a prover  <span class="math">\\mathcal{P}^*</span>  with success probability bounded away from 1 by a non-negligible amount, which in turn results in a non-negligible knowledge error. Indeed, [3] shows that parallel repetition reduces the knowledge error from  <span class="math">\\kappa</span>  down to  <span class="math">\\kappa^t + \\nu</span>  for an arbitrary but fixed non-negligible term  <span class="math">\\nu</span> .</p>

    <p class="text-gray-300">As a consequence, in this work here where we do not want to weaken the definition of a proof of knowledge, but still wish to obtain strong parallel repetition results, i.e., show that the knowledge error  <span class="math">\\kappa</span>  drops exponentially as  <span class="math">\\kappa^t</span>  under parallel repetition, we cannot use the above generic reduction results but need to prove strong parallel repetition (for the considered class of protocols) from scratch.</p>

    <p class="text-gray-300">The Case  <span class="math">t = 1</span> . The starting point of our parallel-repetition result is a new knowledge extractor for a single invocation of  <span class="math">(k_{1},\\ldots ,k_{\\mu})</span> -special-sound protocols; we briefly compare this extractor with other knowledge extractors proposed for such protocols.</p>

    <p class="text-gray-300">For instance, considering a different notion of knowledge soundness, [1] proposed an extractor for  <span class="math">(k_{1},\\ldots ,k_{\\mu})</span> -special-sound protocols that has a strict polynomial run-time, yet a success probability that degrades exponentially in  <span class="math">K = k_{1}\\dots k_{\\mu}</span> . Thus, this notion is meaningful only when  <span class="math">K</span>  is constant in the input size.</p>

    <p class="text-gray-300">Full fledged and tight knowledge soundness for  <span class="math">(k_{1},\\ldots ,k_{\\mu})</span> -special-sound protocols was only very recently shown in [3]. In that work, in line with the standard definition [16], the proposed extractor runs in expected polynomial time and succeeds with probability proportional to  <span class="math">\\epsilon -\\kappa</span> . As shown in Table 1, our extractor behaves somewhat worse in the (expected) polynomial run time, and also in the success probability when the newly introduced measure  <span class="math">\\delta</span>  is bounded by  <span class="math">\\epsilon -\\kappa</span> ; however, by exploiting the definition of  <span class="math">\\delta</span> , as we show in the technical part, we can obtain an extractor for a parallel repetition of the considered protocol by running the extractor individually on each instance of the parallel repetition. Thus, our extractor is well suited to show the claimed (threshold) parallel-repetition results. Nevertheless, it remains an interesting problem whether our extractor can be improved to match up with the extractor from [3] while still giving rise to our parallel-repetition results.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Extractor</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Number of P*-queries Q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Success probability P</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[1]</td>

            <td class="px-3 py-2 border-b border-gray-700">Q ≤ K</td>

            <td class="px-3 py-2 border-b border-gray-700">P ≥ (ε - κ)K</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[3]</td>

            <td class="px-3 py-2 border-b border-gray-700">E[Q] ≤ K</td>

            <td class="px-3 py-2 border-b border-gray-700">P ≥ ε - κ</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">This work</td>

            <td class="px-3 py-2 border-b border-gray-700">E[Q] ≤ 2μ · K ≤ K2</td>

            <td class="px-3 py-2 border-b border-gray-700">P ≥ 1/K δ ≥ 1/K (ε - κ)</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 1. Different knowledge extractors for  <span class="math">(k_{1},\\ldots ,k_{\\mu})</span>  -special-sound protocols. Here,  <span class="math">\\epsilon = \\epsilon (\\mathcal{P}^{<em>})</span>  denotes the success probability of the prover  <span class="math">\\mathcal{P}^</em></span> <span class="math">N_{i}</span>  is size of the  <span class="math">i</span>  -th challenge set,  <span class="math">\\kappa = 1 - \\prod_{i = 1}^{\\mu}\\frac{N_i - k_i + 1}{N_i}</span>  is the knowledge error, and  <span class="math">K = k_{1}\\dots k_{\\mu}</span> . The refined quality measure  <span class="math">\\delta = \\delta (\\mathcal{P}^{*})</span>  will be defined in Section 3 and Section 4.</p>

    <p class="text-gray-300">In Section 2, we introduce notation and recall standard definitions regarding interactive proofs. In Section 3, we show the parallel-repetition result for  <span class="math">k</span> -special-sound 3-round protocols: we first construct a</p>

    <p class="text-gray-300">new knowledge extractor for (the single execution of) a <span class="math">k</span>-special-sound protocol, and then handle the parallel repetition of these protocols in a second step. In Section 4, we generalize the aforementioned results to multi-round protocols. Finally, in Section 5, we treat the <span class="math">s</span>-out-of-<span class="math">t</span> threshold parallel repetition of <span class="math">(k_{1},\\ldots,k_{\\mu})</span>-special-sound protocols.</p>

    <h2 id="sec-11" class="text-2xl font-bold">2 Preliminaries</h2>

    <h3 id="sec-12" class="text-xl font-semibold mt-8">2.1 Interactive Proofs</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Following standard terminology, given a binary relation <span class="math">R\\subseteq\\{0,1\\}^{<em>}\\times\\{0,1\\}^{</em>}</span>, a string <span class="math">w\\in\\{0,1\\}^{<em>}</span> is called a </em>witness<em> for the </em>statement<em> <span class="math">x\\in\\{0,1\\}^{</em>}</span> if <span class="math">(x;w)\\in R</span>. The set of valid witnesses for a statement <span class="math">x</span> is denoted by <span class="math">R(x)</span>, i.e., <span class="math">R(x)=\\{w:(x;w)\\in R\\}</span>. A statement that admits a witness is said to be a <em>true</em> or <em>valid</em> statement. The set of true statements is denoted by <span class="math">L_{R}</span>, i.e., <span class="math">L_{R}=\\{x:\\exists\\,w\\text{ s.t. }(x;w)\\in R\\}</span>. A binary relation is said to be an NP relation if the validity of a witness <span class="math">w</span> can be verified in time polynomial in the size $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> of the statement </span>x$. From now on we assume all relations to be NP relations.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">An interactive proof for a relation <span class="math">R</span> aims for a prover <span class="math">\\mathcal{P}</span> to convince a verifier <span class="math">\\mathcal{V}</span> that a statement <span class="math">x</span> admits a witness, or even that the prover <em>knows</em> a witness <span class="math">w\\in R(x)</span>. We recall the following standard definitions.</p>

    <h6 id="sec-13" class="text-base font-medium mt-4">Definition 1 (Interactive Proof)</h6>

    <p class="text-gray-300">An <em>interactive proof</em> <span class="math">(\\mathcal{P},\\mathcal{V})</span> for relation <span class="math">R</span> is an interactive protocol between two probabilistic machines, a prover <span class="math">\\mathcal{P}</span> and a polynomial time verifier <span class="math">\\mathcal{V}</span>. Both <span class="math">\\mathcal{P}</span> and <span class="math">\\mathcal{V}</span> take as public input a statement <span class="math">x</span> and, additionally, <span class="math">\\mathcal{P}</span> takes as private input a witness <span class="math">w\\in R(x)</span>, which is denoted as <span class="math">(\\mathcal{P}(w),\\mathcal{V})(x)</span>. As the output of the protocol, <span class="math">\\mathcal{V}</span> either accepts or rejects. Accordingly, we say the corresponding transcript (i.e., the set of all messages exchanged in the protocol execution) is <em>accepting</em> or <em>rejecting</em>.</p>

    <p class="text-gray-300">An interactive proof <span class="math">(\\mathcal{P},\\mathcal{V})</span> is <em>complete</em> if the verifier <span class="math">\\mathcal{V}</span> accepts honest executions with a public-private input pair <span class="math">(x;w)\\in R</span> with large probability. It is <em>sound</em> if the verifier rejects false statements <span class="math">x\\notin L_{R}</span> with large probability. Originally interactive proofs were defined to be complete and sound <em>[17]</em>. By contrast, we do not require interactive protocols to satisfy these properties by definition, but consider them as desirable additional security properties.</p>

    <h6 id="sec-14" class="text-base font-medium mt-4">Definition 2 (Completeness)</h6>

    <p class="text-gray-300">An interactive proof <span class="math">(\\mathcal{P},\\mathcal{V})</span> for relation <span class="math">R</span> is <em>complete</em> with completeness error <span class="math">\\rho\\colon\\{0,1\\}^{*}\\to[0,1]</span> if for every <span class="math">(x;w)\\in R</span>,</p>

    <p class="text-gray-300"><span class="math">\\Pr((\\mathcal{P}(w),\\mathcal{V})(x)=\\textsf{reject})\\leq\\rho(x)\\,.</span></p>

    <p class="text-gray-300">If <span class="math">\\rho(x)=0</span> for all <span class="math">x</span>, <span class="math">(\\mathcal{P},\\mathcal{V})</span> is said to be perfectly complete.</p>

    <h6 id="sec-15" class="text-base font-medium mt-4">Definition 3 (Soundness)</h6>

    <p class="text-gray-300">An interactive proof <span class="math">(\\mathcal{P},\\mathcal{V})</span> for relation <span class="math">R</span> is <em>sound</em> with soundness error <span class="math">\\sigma\\colon\\{0,1\\}^{<em>}\\to[0,1]</span>, if for every <span class="math">x\\notin L_{R}</span> and every prover <span class="math">\\mathcal{P}^{</em>}</span>,</p>

    <p class="text-gray-300"><span class="math">\\Pr((\\mathcal{P}^{*},\\mathcal{V})(x)=\\textsf{accept})\\leq\\sigma(x)\\,.</span></p>

    <p class="text-gray-300">If an interactive proof is complete and sound, it “merely” allows a prover to convince a verifier that a statement <span class="math">x</span> is true, i.e., <span class="math">x\\in L_{R}</span>. It does not necessarily convince a verifier that the prover “knows” a witness <span class="math">w\\in R(x)</span>. This stronger property is captured by the notion <em>knowledge soundness</em>. Informally, an interactive proof <span class="math">(\\mathcal{P},\\mathcal{V})</span> is knowledge sound if any prover <span class="math">\\mathcal{P}^{<em>}</span> with <span class="math">\\Pr((\\mathcal{P}^{</em>},\\mathcal{V})(x)=\\textsf{accept})</span> large enough is able to compute a witness <span class="math">w\\in R(x)</span>.</p>

    <h6 id="sec-16" class="text-base font-medium mt-4">Definition 4 (Knowledge Soundness)</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">An interactive proof <span class="math">(\\mathcal{P},\\mathcal{V})</span> for relation <span class="math">R</span> is knowledge sound with knowledge error <span class="math">\\kappa\\colon\\{0,1\\}^{<em>}\\to[0,1]</span> if there exists a positive polynomial <span class="math">q</span> and an algorithm <span class="math">\\mathcal{E}</span>, called a </em>knowledge extractor<em>, with the following properties: The extractor <span class="math">\\mathcal{E}</span>, given input <span class="math">x</span> and rewindable oracle access to a (potentially dishonest) prover <span class="math">\\mathcal{P}^{</em>}</span>, runs in an expected number of steps that is polynomial in $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> and outputs a witness </span>w\\in R(x)$ with probability</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\Pr\\bigl{(}(x;\\mathcal{E}^{\\mathcal{P}^{<em>}}(x))\\in R\\bigr{)}\\geq\\frac{\\epsilon(x,\\mathcal{P}^{</em>})-\\kappa(x)}{q(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)}\\,,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where <span class="math">\\epsilon(x,\\mathcal{P}^{<em>}):=\\Pr((\\mathcal{P}^{</em>},\\mathcal{V})(x)=\\textsf{accept})</span>.</p>

    <p class="text-gray-300">###</p>

    <h6 id="sec-17" class="text-base font-medium mt-4">Remark 1</h6>

    <p class="text-gray-300">It is straightforward to verify that in order to satisfy Definition 4 it is sufficient to show that the required property holds for deterministic provers <span class="math">\\mathcal{P}^{<em>}</span>. Let <span class="math">\\mathcal{P}^{</em>}</span> be an arbitrary randomized dishonest prover, and let <span class="math">\\mathcal{P}^{<em>}[r]</span> be the deterministic prover obtained by fixing <span class="math">\\mathcal{P}^{</em>}</span>’s randomness to <span class="math">r</span>. Then <span class="math">\\epsilon(x,\\mathcal{P}^{<em>})=\\mathbb{E}[\\epsilon(x,\\mathcal{P}^{</em>}[r])]</span>, where <span class="math">\\mathbb{E}</span> denotes the expectation over the random choice of <span class="math">r</span>. Furthermore, if <span class="math">\\mathcal{E}^{\\mathcal{P}^{<em>}}</span> is declared to run <span class="math">\\mathcal{E}^{\\mathcal{P}^{</em>}[r]}</span> for a random choice of <span class="math">r</span> then the same holds for the success probability of the extractor: <span class="math">\\Pr\\big{(}(x;\\mathcal{E}^{\\mathcal{P}^{<em>}}(x))\\in R\\big{)}=\\mathbb{E}\\big{[}\\Pr\\big{(}(x;\\mathcal{E}^{\\mathcal{P}^{</em>}[r]}(x))\\in R\\big{)}\\big{]}</span>. It follows that in order to satisfy Definition 4 it is sufficient to show that the required property holds for deterministic provers <span class="math">\\mathcal{P}^{*}</span>. For this reason, we may assume provers to be deterministic, in particular, we will consider the prover’s first message to be deterministic. This will significantly simplify our analysis.</p>

    <h6 id="sec-18" class="text-base font-medium mt-4">Remark 2</h6>

    <p class="text-gray-300">Definition 4 is a static knowledge soundness definition, i.e., dishonest provers attack a fixed statement <span class="math">x</span>. However, in some scenarios dishonest provers may choose the statement <span class="math">x</span> adaptively. This would warrant a stronger adaptive knowledge soundness definition. However, it is easily seen that, for interactive proofs, static knowledge soundness implies adaptive knowledge soundness <em>[16]</em>. Hence, also in the aforementioned application scenarios Definition 4 is sufficient.</p>

    <p class="text-gray-300">If <span class="math">\\epsilon(x,\\mathcal{P}^{<em>})=\\Pr((\\mathcal{P}^{</em>},\\mathcal{V})(x)=\\texttt{accept})&gt;\\kappa(x)</span>, then the success probability of the knowledge extractor of Definition 4 is positive. Hence, <span class="math">\\epsilon(x,\\mathcal{P}^{*})&gt;\\kappa(x)</span> implies that <span class="math">x</span> admits a witness, i.e., <span class="math">x\\in L_{R}</span>. It therefore follows that knowledge soundness implies soundness.</p>

    <h6 id="sec-19" class="text-base font-medium mt-4">Remark 3</h6>

    <p class="text-gray-300">Sometimes a slightly weaker definition for knowledge soundness is used <em>[6, 16, 20]</em>. This weaker definition decouples knowledge soundness from soundness by only requiring the extractor to run in expected polynomial time on inputs <span class="math">x\\in L_{R}</span>, i.e., it does not require the protocol to be sound. It can be shown that a sound protocol satisfying this weaker version of knowledge soundness is also knowledge sound in the stronger sense of Definition 4.</p>

    <h6 id="sec-20" class="text-base font-medium mt-4">Definition 5 (Proof of Knowledge)</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">An interactive proof that is both complete with completeness error <span class="math">\\rho(\\cdot)</span> and knowledge sound with knowledge error <span class="math">\\kappa(\\cdot)</span> is a Proof of Knowledge (PoK) if there exists a polynomial <span class="math">q</span> such that $1-\\rho(x)\\geq\\kappa(x)+1/q(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> for all </span>x$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Let us consider some additional (desirable) properties of proofs of knowledge. We assume that the prover <span class="math">\\mathcal{P}</span> sends the first and the last message in any interactive proof <span class="math">(\\mathcal{P},\\mathcal{V})</span>. If this is not the case, the interactive proof can be appended with an empty message. Hence, the number of communication rounds <span class="math">2\\mu+1</span> is always odd. We also say <span class="math">(\\mathcal{P},\\mathcal{V})</span> is a <span class="math">(2\\mu+1)</span>-round protocol. We will refer to multi-round protocols as a way of emphasizing that we are not restricting to <span class="math">3</span>-round protocols.</p>

    <h6 id="sec-21" class="text-base font-medium mt-4">Definition 6 (Public-Coin)</h6>

    <p class="text-gray-300">An interactive proof <span class="math">(\\mathcal{P},\\mathcal{V})</span> is public-coin if all of <span class="math">\\mathcal{V}</span>’s random choices are made public.</p>

    <p class="text-gray-300">If a protocol is public-coin, the verifier only needs to send its random choices to the prover. In this case, <span class="math">\\mathcal{V}</span>’s messages are also referred to as challenges and the set from which <span class="math">\\mathcal{V}</span> samples its messages uniformly at random is called the challenge set.</p>

    <p class="text-gray-300">We recall the notion of (general) special-soundness. It is typically easier to prove that an interactive proof is special-sound than to prove that it is knowledge sound. Note that we require special-sound protocols to be public-coin.</p>

    <h6 id="sec-22" class="text-base font-medium mt-4">Definition 7 (<span class="math">k</span>-out-of-<span class="math">N</span> Special-Soundness)</h6>

    <p class="text-gray-300">Let <span class="math">k,N\\in\\mathbb{N}</span>. A <span class="math">3</span>-round public-coin protocol <span class="math">(\\mathcal{P},\\mathcal{V})</span> for relation <span class="math">R</span>, with challenge set of cardinality <span class="math">N\\geq k</span>, is <span class="math">k</span>-out-of-<span class="math">N</span> special-sound if there exists a polynomial time algorithm that, on input a statement <span class="math">x</span> and <span class="math">k</span> accepting transcripts <span class="math">(a,c_{1},z_{1}),\\ldots(a,c_{k},z_{k})</span> with common first message <span class="math">a</span> and pairwise distinct challenges <span class="math">c_{1},\\ldots,c_{k}</span>, outputs a witness <span class="math">w\\in R(x)</span>. We also say <span class="math">(\\mathcal{P},\\mathcal{V})</span> is <span class="math">k</span>-special-sound and, if <span class="math">k=2</span>, it is simply said to be special-sound.</p>

    <p class="text-gray-300">We refer to a <span class="math">3</span>-round public-coin interactive proof as a <span class="math">\\Sigma</span>-protocol. Note that often a <span class="math">\\Sigma</span>-protocol is required to be (perfectly) complete, special-sound and special honest-verifier zero-knowledge (SHVZK) by definition. However, we do not require a <span class="math">\\Sigma</span>-protocol to have these additional properties.</p>

    <h6 id="sec-23" class="text-base font-medium mt-4">Definition 8 (<span class="math">\\Sigma</span>-Protocol)</h6>

    <p class="text-gray-300">A <span class="math">\\Sigma</span>-protocol is a <span class="math">3</span>-round public-coin interactive proof.</p>

    <p class="text-gray-300">In order to generalize <span class="math">k</span>-special-soundness to multi-round protocols we introduce the notion of a tree of transcripts. We follow the definition of *[3]</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Fig. 1.  <span class="math">(k_{1},\\ldots ,k_{\\mu})</span>  -tree of transcripts of a  <span class="math">(2\\mu +1)</span>  -round public-coin protocol [3].</p>

    <p class="text-gray-300">Definition 9 (Tree of Transcripts). Let  <span class="math">k_{1}, \\ldots, k_{\\mu} \\in \\mathbb{N}</span> . A  <span class="math">(k_{1}, \\ldots, k_{\\mu})</span> -tree of transcripts for a  <span class="math">(2\\mu + 1)</span> -round public-coin protocol  <span class="math">(\\mathcal{P}, \\mathcal{V})</span>  is a set of  <span class="math">K = \\prod_{i=1}^{\\mu} k_{i}</span>  transcripts arranged in the following tree structure. The nodes in this tree correspond to the prover's messages and the edges to the verifier's challenges. Every node at depth  <span class="math">i</span>  has precisely  <span class="math">k_{i}</span>  children corresponding to  <span class="math">k_{i}</span>  pairwise distinct challenges. Every transcript corresponds to exactly one path from the root node to a leaf node. For a graphical representation we refer to Figure 1. We refer to the corresponding tree of challenges as a  <span class="math">(k_{1}, \\ldots, k_{\\mu})</span> -tree of challenges. The set of all  <span class="math">(k_{1}, \\ldots, k_{\\mu})</span> -trees of challenges is denoted by  <span class="math">\\mathrm{TREE}(k_{1}, \\ldots, k_{\\mu})</span> .</p>

    <p class="text-gray-300">We will also write  <span class="math">\\mathbf{k} = (k_{1},\\dots ,k_{\\mu})\\in \\mathbb{N}^{\\mu}</span>  and refer to a  <span class="math">\\mathbf{k}</span> -tree of transcripts.</p>

    <p class="text-gray-300">Definition 10  <span class="math">((k_{1},\\ldots ,k_{\\mu})</span>  -out-of-  <span class="math">(N_{1},\\dots ,N_{\\mu})</span>  Special-Soundness). Let  <span class="math">k_{1},\\ldots ,k_{\\mu},N_{1},\\ldots ,N_{\\mu}\\in</span>  N. A  <span class="math">(2\\mu +1)</span>  -round public-coin protocol  <span class="math">(\\mathcal{P},\\mathcal{V})</span>  for relation  <span class="math">R</span>  , where  <span class="math">\\mathcal{V}</span>  samples the  <span class="math">i</span>  -th challenge from a set of cardinality  <span class="math">N_{i}\\geq k_{i}</span>  for  <span class="math">1\\leq i\\leq \\mu</span>  , is  <span class="math">(k_{1},\\ldots ,k_{\\mu})</span>  -out-of-  <span class="math">(N_{1},\\ldots ,N_{\\mu})</span>  special-sound if there exists a polynomial time algorithm that, on input a statement  <span class="math">x</span>  and a  <span class="math">(k_{1},\\ldots ,k_{\\mu})</span>  -tree of accepting transcripts outputs a witness  <span class="math">w\\in R(x)</span>  . We also say  <span class="math">(\\mathcal{P},\\mathcal{V})</span>  is  <span class="math">(k_{1},\\ldots ,k_{\\mu})</span>  -special-sound.</p>

    <p class="text-gray-300">It is well known that, for 3-round protocols,  <span class="math">k</span> -special-soundness implies knowledge soundness, but only recently it was shown that more generally, for public-coin  <span class="math">(2\\mu + 1)</span> -round protocols,  <span class="math">(k_{1}, \\ldots, k_{\\mu})</span> -special-soundness tightly implies knowledge soundness [3].</p>

    <p class="text-gray-300">A random variable  <span class="math">B</span>  with two possible outcomes, denoted 0 (failure) and 1 (success), is said to follow a Bernoulli distribution with parameter  <span class="math">p = \\operatorname{Pr}(B = 1)</span> . Sampling from a Bernoulli distribution is also referred to as running a Bernoulli trial. The probability distribution of the number  <span class="math">X</span>  of independent and identical Bernoulli trials needed to obtain a success is called the geometric distribution with parameter  <span class="math">p = \\operatorname{Pr}(X = 1)</span> . In this case  <span class="math">\\operatorname{Pr}(X = k) = (1 - p)^{k - 1}p</span>  for all  <span class="math">k \\in \\mathbb{N}</span>  and we write  <span class="math">X \\sim \\operatorname{Geo}(p)</span> . For two independent geometric distributions we have the following lemma.</p>

    <p class="text-gray-300">Lemma 1. Let  <span class="math">X \\sim \\operatorname{Geo}(p)</span>  and  <span class="math">Y \\sim \\operatorname{Geo}(q)</span>  be independently distributed. Then,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr (X \\leq Y) = \\frac {p}{p + q - p q} \\geq \\frac {p}{p + q}.</span></div>

    <h6 id="sec-25" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">It holds that</p>

    <p class="text-gray-300"><span class="math">\\Pr(X\\leq Y)</span> <span class="math">=\\sum_{x=1}^{\\infty}\\Pr(X=x)\\Pr(Y\\geq x)=\\sum_{x=1}^{\\infty}(1-p)^{x-1}p\\cdot(1-q)^{x-1}</span> <span class="math">=\\frac{p}{1-(1-p)(1-q)}\\sum_{x=1}^{\\infty}\\left((1-p)(1-q)\\right)^{x-1}(1-(1-p)(1-q))</span> <span class="math">=\\frac{p}{1-(1-p)(1-q)}\\sum_{x=1}^{\\infty}\\Pr(Z=x)</span> <span class="math">=\\frac{p}{1-(1-p)(1-q)}=\\frac{p}{p+q-pq}\\geq\\frac{p}{p+q}\\,,</span></p>

    <p class="text-gray-300">where <span class="math">Z\\sim\\mathrm{Geo}(p+q-pq)</span>. This completes the proof of the lemma. ∎</p>

    <h2 id="sec-26" class="text-2xl font-bold">3 Parallel Repetition of <span class="math">k</span>-Special-Sound <span class="math">\\Sigma</span>-Protocols</h2>

    <p class="text-gray-300">To simplify the exposition, we start with the simpler case of <span class="math">\\Sigma</span>-protocols; the general case of multi-round protocols will then be treated in the subsequent section. Thus, for the remainder of this section, we consider a <span class="math">k</span>-special-sound public-coin interactive proof <span class="math">(\\mathcal{P},\\mathcal{V})</span> with challenge set <span class="math">\\mathcal{C}</span> of cardinality <span class="math">N\\geq k</span>. It is well known that such an interactive proof is a proof of knowledge with knowledge error <span class="math">\\kappa=(k-1)/N</span>. We write <span class="math">(\\mathcal{P}^{t},\\mathcal{V}^{t})</span> for the <span class="math">t</span>-fold parallel repetition of <span class="math">(\\mathcal{P},\\mathcal{V})</span>, which runs <span class="math">t</span> instances of <span class="math">(\\mathcal{P},\\mathcal{V})</span> in parallel and the verifier <span class="math">\\mathcal{V}^{t}</span> accepts if all the parallel instances are accepted. In this section, we prove that <span class="math">(\\mathcal{P}^{t},\\mathcal{V}^{t})</span> is then again a proof of knowledge, but now with knowledge error <span class="math">\\kappa^{t}</span>, which is optimal. Thus, we show what is sometimes referred to as strong parallel repetition, meaning that the figure of merit decreases with power <span class="math">t</span> under parallel repetition. This is well known to hold for special-sound <span class="math">\\Sigma</span>-protocols, i.e., for <span class="math">k=2</span>, but was open for general <span class="math">k</span>.</p>

    <p class="text-gray-300">The standard way to reason about parallel repetition for the special case <span class="math">k=2</span> uses the fact that <span class="math">(\\mathcal{P}^{t},\\mathcal{V}^{t})</span> is <span class="math">\\ell</span>-special-sound with <span class="math">\\ell=(k-1)^{t}+1</span>. However, this reasoning does not apply in general, because <span class="math">\\ell</span> grows exponentially in <span class="math">t</span> for <span class="math">k&gt;2</span>. Instead, our result crucially depends on the fact that <span class="math">(\\mathcal{P}^{t},\\mathcal{V}^{t})</span> is the <span class="math">t</span>-fold parallel repetition of a <span class="math">k</span>-special-sound protocol <span class="math">(\\mathcal{P},\\mathcal{V})</span>.</p>

    <p class="text-gray-300">In Section 3.1, we first construct a novel (and somewhat peculiar) extraction algorithm for <span class="math">k</span>-special-sound protocols <span class="math">(\\mathcal{P},\\mathcal{V})</span>, thereby reproving that <span class="math">k</span>-special-soundness implies knowledge soundness <em>[3]</em>. In Section 3.2, we show how this extraction algorithm can be used to deduce a strong parallel repetition result for <span class="math">(\\mathcal{P}^{t},\\mathcal{V}^{t})</span>. In Section 4, we then extend our results to multi-round protocols.</p>

    <p class="text-gray-300">On a high level, the crucial ingredient in our analyses is to introduce and work with a more “fine-grained” notion of success probability of a dishonest prover, as we introduce it below.</p>

    <h3 id="sec-27" class="text-xl font-semibold mt-8">3.1 Knowledge Soundness of a Single Invocation</h3>

    <p class="text-gray-300">Consider a dishonest prover <span class="math">\\mathcal{P}^{<em>}</span> against the considered <span class="math">k</span>-special-sound interactive proof <span class="math">(\\mathcal{P},\\mathcal{V})</span>. The goal of the extractor is to run <span class="math">\\mathcal{P}^{</em>}</span> and rewind it sufficiently many times so as to obtain a first message <span class="math">a</span> together with <span class="math">k</span> correct answers <span class="math">z_{1},\\ldots,z_{k}</span> for <span class="math">k</span> pairwise distinct challenges <span class="math">c_{1},\\ldots,c_{k}\\in\\mathcal{C}</span>. The crucial question is how often <span class="math">\\mathcal{P}^{<em>}</span> needs to be rewinded, and thus what is the (expected) running time of the extractor. Alternatively, towards satisfying Definition 4, we would like to have an extractor that runs in a fixed (expected) polynomial time, but may fail with some probability. It is quite clear that in both cases the figure of merit (i.e., the running time in the former and the success probability in the latter) depends on the success probability <span class="math">\\epsilon</span> of <span class="math">\\mathcal{P}^{</em>}</span>; for instance, if <span class="math">\\epsilon</span> is below the knowledge error <span class="math">\\kappa</span> then we cannot expect extraction to work in general. However, a crucial observation is that for a given dishonest prover <span class="math">\\mathcal{P}^{<em>}</span>, its success probability <span class="math">\\epsilon</span> does actually not characterize (very well) whether extraction is possible or not: if in a special-sound <span class="math">\\Sigma</span>-protocol <span class="math">\\mathcal{P}^{</em>}</span> provides the correct response with probability <span class="math">\\epsilon</span> (and fails to do so with probability <span class="math">1-\\epsilon</span>) for every possible choice of the challenge, then extraction is still possible even when <span class="math">\\epsilon&lt;\\kappa</span> (but not negligible), simply by trying sufficiently many times for two distinct challenges. Below, we will identify an alternative, in some sense more fine-grained, “quality measure” of <span class="math">\\mathcal{P}^{*}</span>, and we show that this measure does characterize when extraction is possible. This will be helpful when it comes to</p>

    <p class="text-gray-300">more complicated settings, like a parallel repetition, or a multi-round protocol, or, ultimately, a parallel repetition of a multi-round protocol.</p>

    <p class="text-gray-300">For multiple reasons, we will state and prove our core technical results in a more abstract language. One reason is that this allows us to focus on the important aspects; another reason is that we will actually exploit the considered abstraction, and thus generalization, of the considered problem. In our abstraction, we consider an arbitrary function <span class="math">V\\colon\\mathcal{C}\\times\\{0,1\\}^{*}\\to\\{0,1\\}</span>, <span class="math">(c,y)\\mapsto V(c,y)</span>, and we consider an arbitrary (possibly probabilistic) algorithm <span class="math">\\mathcal{A}</span> that takes as input an element <span class="math">c\\in\\mathcal{C}</span> and outputs a string <span class="math">y\\leftarrow\\mathcal{A}(c)</span>. The success probability of <span class="math">\\mathcal{A}</span> is then naturally defined as</p>

    <p class="text-gray-300"><span class="math">\\epsilon^{V}(\\mathcal{A}):=\\Pr\\big{(}V(C,\\mathcal{A}(C))=1\\big{)}\\,,</span></p>

    <p class="text-gray-300">where, here and below, the probability space is defined by means of the randomness of <span class="math">\\mathcal{A}</span> and the random variable <span class="math">C</span> being uniformly random in <span class="math">\\mathcal{C}</span>. If <span class="math">V</span> is clear from context, we simply write <span class="math">\\epsilon(\\mathcal{A})</span>.</p>

    <p class="text-gray-300">The obvious instantiation of <span class="math">\\mathcal{A}</span> is given by a deterministic dishonest prover <span class="math">\\mathcal{P}^{<em>}</span> attacking the considered <span class="math">k</span>-special-sound interactive proof <span class="math">(\\mathcal{P},\\mathcal{V})</span> on input <span class="math">x</span>. More precisely, on input <span class="math">c</span>, <span class="math">\\mathcal{A}</span> runs <span class="math">\\mathcal{P}^{</em>}</span> sending <span class="math">c</span> as the challenge, and outputs <span class="math">\\mathcal{P}^{*}</span>’s (fixed) first message <span class="math">a</span> and its response <span class="math">z</span>, and the function <span class="math">V</span> is defined as the verification check that <span class="math">\\mathcal{V}</span> performs. We point out that this instantiation gives rise to a deterministic <span class="math">\\mathcal{A}</span>; however, later on it will be crucial that in our abstract treatment, <span class="math">\\mathcal{A}</span> may be an arbitrary randomized algorithm that decides on its output <span class="math">y</span> in a randomized manner given the input <span class="math">c</span>, and that <span class="math">V</span> is arbitrary.</p>

    <p class="text-gray-300">Motivated by the <span class="math">k</span>-special-soundness of the considered protocol, given (oracle access to) <span class="math">\\mathcal{A}</span> the goal will be to find correct responses <span class="math">y_{1},\\ldots,y_{k}</span> for <span class="math">k</span> pairwise distinct challenges <span class="math">c_{1},\\ldots,c_{k}\\in\\mathcal{C}</span>, i.e., such that <span class="math">V(c_{i},y_{i})=1</span> for all <span class="math">i</span>. As we show below, the measure that captures how well this can be done is the worst case success probability of <span class="math">\\mathcal{A}</span> for a random challenge when <span class="math">k-1</span> challenges are removed from the challenge space, formally given by</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\delta_{k}^{V}(\\mathcal{A})=\\min_{S\\subset\\mathcal{C}:</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=k-1}\\Pr\\big{(}V(C,\\mathcal{A}(C))=1\\mid C\\notin S\\big{)}\\,.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">More precisely, we argue existence of an extraction algorithm <span class="math">\\mathcal{E}^{\\mathcal{A}}</span> with oracle access to <span class="math">\\mathcal{A}</span>, that runs in expected polynomial time and succeeds with probability at least <span class="math">\\delta_{k}^{V}(\\mathcal{A})/k</span>. As before, if <span class="math">V</span> is clear from context, we write <span class="math">\\delta_{k}(\\mathcal{A})</span>.</p>

    <h6 id="sec-28" class="text-base font-medium mt-4">Lemma 2 (Extraction Algorithm).</h6>

    <p class="text-gray-300">Let <span class="math">k\\in\\mathbb{N}</span> and <span class="math">\\mathcal{C}</span> a finite set with cardinality <span class="math">N\\geq k</span>, and let <span class="math">V\\colon\\mathcal{C}\\times\\{0,1\\}^{<em>}\\to\\{0,1\\}</span>. Then, there exists an algorithm <span class="math">\\mathcal{E}^{\\mathcal{A}}</span> so that, given oracle access to any (probabilistic) algorithm <span class="math">\\mathcal{A}\\colon\\mathcal{C}\\to\\{0,1\\}^{</em>}</span>, <span class="math">\\mathcal{E}^{\\mathcal{A}}</span> requires an expected number of at most <span class="math">2k-1</span> queries to <span class="math">\\mathcal{A}</span> and, with probability at least <span class="math">\\delta_{k}^{V}(\\mathcal{A})/k</span>, it outputs <span class="math">k</span> pairs <span class="math">(c_{1},y_{1}),(c_{2},y_{2}),\\ldots,(c_{k},y_{k})\\in\\mathcal{C}\\times\\{0,1\\}^{*}</span> with <span class="math">V(c_{i},y_{i})=1</span> for all <span class="math">i</span> and <span class="math">c_{i}\\neq c_{j}</span> for all <span class="math">i\\neq j</span>.</p>

    <h6 id="sec-29" class="text-base font-medium mt-4">Proof.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The extraction algorithm is defined recursively over <span class="math">k</span>. For this reason, we add a subscript <span class="math">k</span> and write <span class="math">\\mathcal{E}_{k}^{\\mathcal{A}}</span> for the extraction algorithm that aims to output <span class="math">k</span> pairs <span class="math">(c_{i},y_{i})</span>. In this proof, we also make the set <span class="math">\\mathcal{D}\\subseteq\\mathcal{C}</span>, from which the extractor samples the challenges <span class="math">c_{i}</span>, explicit by writing <span class="math">\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})</span>. This allows the extractor to be deployed on subsets <span class="math">\\mathcal{D}</span> of the full challenge set <span class="math">\\mathcal{C}</span>, i.e., extractor <span class="math">\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})</span> aims to output <span class="math">k</span> pairs <span class="math">(c_{i},y_{i})</span> with pairwise distinct challenges <span class="math">c_{i}\\in\\mathcal{D}</span> and <span class="math">V(c_{i},y_{i})=1</span> for all <span class="math">i</span>. When writing <span class="math">\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})</span> we will always implicitly assume that $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k$. Accordingly, we also write</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\epsilon(\\mathcal{A},\\mathcal{D})</span> <span class="math">:=\\Pr\\big{(}V(C,\\mathcal{A}(C))=1\\big{)}\\,,</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">\\delta_{k}(\\mathcal{A},\\mathcal{D})</span> $:=\\min_{S\\subseteq\\mathcal{D}:</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=k-1}\\Pr\\big{(}V(C,\\mathcal{A}(C))=1\\mid C\\notin S\\big{)}\\,.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where the probability space is defined by means of the randomness of <span class="math">\\mathcal{A}</span> and the random variable <span class="math">C</span> being uniformly random in <span class="math">\\mathcal{D}\\subseteq\\mathcal{C}</span>. It is not too hard to see that for all <span class="math">k\\geq 1</span>,</p>

    <p class="text-gray-300"><span class="math">\\delta_{k+1}(\\mathcal{A},\\mathcal{D})\\leq\\delta_{k}(\\mathcal{A},\\mathcal{D})\\leq\\delta_{1}(\\mathcal{A},\\mathcal{D})=\\epsilon(\\mathcal{A},\\mathcal{D})\\,.</span></p>

    <p class="text-gray-300">Let us now define the extraction algorithm. Let <span class="math">\\mathcal{D}\\subseteq\\mathcal{C}</span> be an arbitrary subset with cardinality at least <span class="math">k</span>. For <span class="math">k=1</span>, the extractor <span class="math">\\mathcal{E}_{1}^{\\mathcal{A}}(\\mathcal{D})</span> simply samples a challenge <span class="math">c_{1}\\in\\mathcal{D}</span> uniformly at random and</p>

    <p class="text-gray-300">computes <span class="math">y_{1}\\leftarrow\\mathcal{A}(c_{1})</span>. If <span class="math">V(c_{1},y_{1})=0</span>, it outputs <span class="math">\\bot</span> and aborts. Otherwise, if <span class="math">V(c_{1},y_{1})=1</span>, it successfully outputs <span class="math">(c_{1},y_{1})</span>. This extractor queries <span class="math">\\mathcal{A}</span> once and it succeeds with probability <span class="math">\\epsilon(\\mathcal{A},\\mathcal{D})=\\delta_{1}(\\mathcal{A},\\mathcal{D})</span>.</p>

    <p class="text-gray-300">For <span class="math">k&gt;1</span>, the extractor <span class="math">\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})</span> first runs the extractor <span class="math">\\mathcal{E}_{1}^{\\mathcal{A}}(\\mathcal{D})</span>. If <span class="math">\\mathcal{E}_{1}^{\\mathcal{A}}(\\mathcal{D})</span> fails, <span class="math">\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})</span> outputs <span class="math">\\bot</span> and aborts; otherwise, if <span class="math">\\mathcal{E}_{1}^{\\mathcal{A}}(\\mathcal{D})</span> succeeds to output a pair <span class="math">(c_{1},y_{1})</span>, <span class="math">\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})</span> proceeds as follows. It sets <span class="math">\\mathcal{D}^{\\prime}:=\\mathcal{D}\\setminus\\{c_{1}\\}</span> and runs <span class="math">\\mathcal{E}_{k-1}^{\\mathcal{A}}(\\mathcal{D}^{\\prime})</span>. If <span class="math">\\mathcal{E}_{k-1}^{\\mathcal{A}}(\\mathcal{D}^{\\prime})</span> succeeds to output <span class="math">k-1</span> pairs <span class="math">(c_{2},y_{2}),\\ldots(c_{k},y_{k})</span> then <span class="math">\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})</span> successfully outputs the <span class="math">k</span> pairs <span class="math">(c_{1},y_{1}),(c_{2},y_{2}),\\ldots,(c_{k},y_{k})</span>. On the other hand, if <span class="math">\\mathcal{E}_{k-1}^{\\mathcal{A}}(\\mathcal{D}^{\\prime})</span> fails then <span class="math">\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})</span> tosses a coin that returns heads with probability <span class="math">\\epsilon(\\mathcal{A},\\mathcal{D})</span>. This coin can be implemented by running <span class="math">\\mathcal{E}_{1}^{\\mathcal{A}}(\\mathcal{D})</span>, i.e., sampling a random challenge <span class="math">c\\leftarrow\\mathcal{D}</span> and evaluating <span class="math">V\\big{(}c,\\mathcal{A}(c)\\big{)}</span>. If the coin returns heads, <span class="math">\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})</span> outputs <span class="math">\\bot</span> and aborts. If the coin returns tails, <span class="math">\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})</span> runs <span class="math">\\mathcal{E}_{k-1}^{\\mathcal{A}}(\\mathcal{D}^{\\prime})</span> once more and performs the same steps as before. The algorithm proceeds in this manner until either it has successfully found a <span class="math">k</span> pairs <span class="math">(c_{i},y_{i})</span> or until the coin returns heads.</p>

    <p class="text-gray-300">Let us now analyze the success probability and the expected number of <span class="math">\\mathcal{A}</span>-queries of <span class="math">\\mathcal{E}_{k}^{\\mathcal{A}}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Success Probability. We aim to show that, for all <span class="math">k\\in\\mathbb{N}</span> and for all <span class="math">\\mathcal{D}\\subseteq\\mathcal{C}</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k<span class="math">, the success probability </span>\\Delta_{k}(\\mathcal{D})<span class="math"> of the extractor </span>\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})$ satisfies</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\Delta_{k}(\\mathcal{D})\\geq\\delta_{k}(\\mathcal{A},\\mathcal{D})/k\\,.</span></p>

    <p class="text-gray-300">The analysis goes by induction. Since</p>

    <p class="text-gray-300"><span class="math">\\Delta_{1}(\\mathcal{D})=\\epsilon(\\mathcal{A},\\mathcal{D})=\\delta_{1}(\\mathcal{A},\\mathcal{D})/1\\,,</span></p>

    <p class="text-gray-300">the induction hypothesis is satisfied for the base case <span class="math">k=1</span> and all <span class="math">\\mathcal{D}\\neq\\emptyset</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let us now consider <span class="math">k&gt;1</span> and assume that the induction hypothesis holds for <span class="math">k^{\\prime}=k-1</span> and all <span class="math">\\mathcal{D}^{\\prime}</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k-1<span class="math">. We consider arbitrary </span>\\mathcal{D}\\subseteq\\mathcal{C}<span class="math"> with </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k<span class="math">. Then if, in its first step, </span>\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})<span class="math"> successfully runs extractor </span>\\mathcal{E}_{1}^{\\mathcal{A}}(\\mathcal{D})<span class="math"> (outputting a pair </span>(c_{1},y_{1})<span class="math"> with </span>V(c_{1},y_{1})=1<span class="math">), it starts running two geometric experiments until one of them finishes. In the first geometric experiment the extractor aims to find an additional set of </span>k-1<span class="math"> pairs </span>(c_{i},y_{i})<span class="math"> by running </span>\\mathcal{E}_{k-1}^{\\mathcal{A}}(\\mathcal{D}^{\\prime})<span class="math">, where </span>\\mathcal{D}^{\\prime}=\\mathcal{D}\\setminus\\{c_{1}\\}<span class="math">. By the induction hypothesis, the parameter </span>p$ of this geometric distribution satisfies</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">p:=\\Delta_{k-1}(\\mathcal{D}^{\\prime})\\geq\\delta_{k-1}(\\mathcal{A},\\mathcal{D}^{\\prime})/(k-1)\\geq\\delta_{k}(\\mathcal{A},\\mathcal{D})/(k-1)\\,.</span></p>

    <p class="text-gray-300">In the second geometric experiment the extractor tosses a coin that returns heads with probability</p>

    <p class="text-gray-300"><span class="math">q:=\\epsilon(\\mathcal{A},\\mathcal{D})\\,.</span></p>

    <p class="text-gray-300">The second step of the extractor succeeds if the second geometric experiment does not finish before the first, and so by Lemma 1 this probability is lower bounded by</p>

    <p class="text-gray-300"><span class="math">\\Pr\\big{(}\\text{Geo}(p)\\leq\\text{Geo}(q)\\big{)}</span> <span class="math">\\geq\\frac{p}{p+q}=\\frac{\\Delta_{k-1}(\\mathcal{D}^{\\prime})}{\\Delta_{k-1}(\\mathcal{D}^{\\prime})+\\epsilon(\\mathcal{A},\\mathcal{D})}\\geq\\frac{\\delta_{k}(\\mathcal{A},\\mathcal{D})/(k-1)}{\\delta_{k}(\\mathcal{A},\\mathcal{D})/(k-1)+\\epsilon(\\mathcal{A},\\mathcal{D})}</span> <span class="math">\\geq\\frac{\\delta_{k}(\\mathcal{A},\\mathcal{D})/(k-1)}{\\epsilon(\\mathcal{A},\\mathcal{D})/(k-1)+\\epsilon(\\mathcal{A},\\mathcal{D})}=\\frac{\\delta_{k}(\\mathcal{A},\\mathcal{D})}{k\\cdot\\epsilon(\\mathcal{A},\\mathcal{D})}\\,,</span></p>

    <p class="text-gray-300">where the second inequality follows from the monotonicity of the function <span class="math">x\\mapsto\\frac{x}{x+q}</span>. Since the first step of the extractor succeeds with probability <span class="math">\\epsilon(\\mathcal{A},\\mathcal{D})</span>, it follows that <span class="math">\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})</span> succeeds with probability at least <span class="math">\\delta_{k}(\\mathcal{A},\\mathcal{D})/k</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Therefore, by induction it follows that for all <span class="math">k</span> and <span class="math">\\mathcal{D}</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k<span class="math">, the extractor </span>\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})<span class="math"> succeeds with probability at least </span>\\delta_{k}(\\mathcal{A},\\mathcal{D})/k<span class="math">. In particular, the extractor </span>\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{C})<span class="math"> succeeds with probability at least </span>\\delta_{k}(\\mathcal{A})/k$, which proves that this extractor has the desired success probability.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Expected Number of <span class="math">\\mathcal{A}</span>-Queries. For <span class="math">\\mathcal{D}\\subseteq\\mathcal{C}</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k<span class="math">, we let </span>Q_{k}(\\mathcal{D})<span class="math"> be the expected number of </span>\\mathcal{A}<span class="math">-queries made by the extractor </span>\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})<span class="math">. We will prove that </span>Q_{k}(\\mathcal{D})\\leq 2k-1<span class="math"> for all </span>k\\in\\mathbb{N}<span class="math"> and </span>\\mathcal{D}\\subseteq\\mathcal{C}<span class="math"> with </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k<span class="math">. The proof of this claim goes by induction. First note that, since </span>Q_{1}(\\mathcal{D})=1<span class="math"> for all </span>\\mathcal{D}\\neq\\emptyset<span class="math">, this claim is clearly satisfied for the base case </span>k=1$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let us now consider <span class="math">k&gt;1</span> and assume the claim is satisfied for <span class="math">k^{\\prime}=k-1</span>. Let <span class="math">\\mathcal{D}\\subseteq\\mathcal{C}</span> be arbitrary with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k<span class="math">. Then, </span>\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})<span class="math"> first runs </span>\\mathcal{E}_{1}^{\\mathcal{A}}(\\mathcal{D})<span class="math">, which requires exactly </span>Q_{1}(\\mathcal{D})=1<span class="math"> query. Then with probability </span>\\epsilon(\\mathcal{A},\\mathcal{D})<span class="math"> it continues to the second step. In each iteration of the second step </span>\\mathcal{E}_{k}^{\\mathcal{A}}(\\mathcal{D})<span class="math"> runs </span>\\mathcal{E}_{k-1}^{\\mathcal{A}}(\\mathcal{D}^{\\prime})<span class="math">, for some </span>D^{\\prime}\\subseteq\\mathcal{C}<span class="math"> with </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k-1<span class="math">, and it tosses a coin by running </span>\\mathcal{E}_{1}^{\\mathcal{A}}(\\mathcal{D})$. Therefore, each iteration requires</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">an expected number of at most <span class="math">Q_{k-1}(\\mathcal{D}^{\\prime})+1\\leq 2k-2</span> queries. Moreover, the expected number of tosses until the coin returns heads is <span class="math">1/\\epsilon(\\mathcal{A},\\mathcal{D})</span>. Hence, the expected number of iterations in the second step of this extraction algorithm is at most <span class="math">1/\\epsilon(\\mathcal{A},\\mathcal{D})</span>. It follows that</p>

    <p class="text-gray-300"><span class="math">Q_{k}(\\mathcal{D})\\leq 1+\\epsilon(\\mathcal{A},\\mathcal{D})\\frac{1}{\\epsilon(\\mathcal{A},\\mathcal{D})}(2k-2)=2k-1\\,,</span></p>

    <p class="text-gray-300">which proves the claimed upper bound on the expected number of <span class="math">\\mathcal{A}</span>-queries and completes the proof of the lemma. ∎</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In the context of a deterministic dishonest prover <span class="math">\\mathcal{P}^{*}</span> attacking a <span class="math">k</span>-special-sound protocol, we make the following observation. First, by basic probability theory, for any <span class="math">S\\subseteq\\mathcal{C}</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=k-1$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\Pr\\bigl{(}V(C,\\mathcal{A}(C))=1\\mid C\\notin S\\bigr{)}</span> <span class="math">=\\frac{\\Pr\\bigl{(}V(C,\\mathcal{A}(C))=1\\,\\wedge\\,C\\notin S\\bigr{)}}{\\Pr\\bigl{(}C\\notin S\\bigr{)}}</span> (1) <span class="math">\\geq\\frac{\\Pr\\bigl{(}V(C,\\mathcal{A}(C))=1)-\\Pr\\bigl{(}C\\in S\\bigr{)}}{\\Pr\\bigl{(}C\\notin S\\bigr{)}}</span> <span class="math">=\\frac{\\Pr\\bigl{(}V(C,\\mathcal{A}(C))=1)-(k-1)/N}{1-(k-1)/N}\\,.</span></p>

    <p class="text-gray-300">Thus, the extractor <span class="math">\\mathcal{E}^{\\mathcal{A}}</span> succeeds with positive probability as soon as <span class="math">\\epsilon(\\mathcal{A})&gt;\\kappa:=(k-1)/N</span>. More precisely,</p>

    <p class="text-gray-300"><span class="math">\\Pr\\bigl{(}\\mathcal{E}^{\\mathcal{A}}\\text{ succeeds}\\bigr{)}\\geq\\frac{\\delta_{k}(\\mathcal{A})}{k}\\geq\\frac{\\epsilon(\\mathcal{A})-\\kappa}{k(1-\\kappa)}\\,.</span></p>

    <p class="text-gray-300">This observation confirms that <span class="math">k</span>-special-soundness implies knowledge soundness with knowledge error <span class="math">\\kappa</span> (see also <em>[3]</em> for an alternative proof). This result is summarized as follows.</p>

    <h6 id="sec-30" class="text-base font-medium mt-4">Theorem 1.</h6>

    <p class="text-gray-300">Let <span class="math">(\\mathcal{P},\\mathcal{V})</span> be a <span class="math">k</span>-out-of-<span class="math">N</span> special-sound <span class="math">\\Sigma</span>-protocol. Then <span class="math">(\\mathcal{P},\\mathcal{V})</span> is knowledge sound with knowledge error <span class="math">\\kappa=(k-1)/N</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Note that this is the best we can hope for, since it may be — and for typical schemes this is the case — that for any <span class="math">S\\subseteq\\mathcal{C}</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=k-1<span class="math">, </span>\\mathcal{P}^{*}<span class="math"> can prepare a first message </span>a<span class="math"> for which he can correctly answer any challenge </span>c\\in S<span class="math">. Thus, </span>\\kappa=(k-1)/N$ is the trivial cheating probability, confirming the tightness of the theorem.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-31" class="text-xl font-semibold mt-8">3.2 Knowledge-Soundness of the Parallel Repetition</h3>

    <p class="text-gray-300">When moving to the <span class="math">t</span>-fold parallel repetition <span class="math">(\\mathcal{P}^{t},\\mathcal{V}^{t})</span> of the <span class="math">k</span>-special-sound public-coin protocol <span class="math">(\\mathcal{P},\\mathcal{V})</span>, we consider an algorithm <span class="math">\\mathcal{A}</span> that takes as input a row <span class="math">(c_{1},\\ldots,c_{t})\\in\\mathcal{C}^{t}</span> of challenges and outputs a string <span class="math">y</span>, and the <em>success probability</em> of <span class="math">\\mathcal{A}</span> is then defined as</p>

    <p class="text-gray-300"><span class="math">\\epsilon^{V}(\\mathcal{A})=\\Pr\\bigl{(}V(C_{1},\\ldots,C_{t},\\mathcal{A}(C_{1},\\ldots,C_{t}))=1\\bigr{)}\\,,</span></p>

    <p class="text-gray-300">for some given <span class="math">V\\colon\\mathcal{C}^{t}\\times\\{0,1\\}^{*}\\to\\{0,1\\}</span> and where the <span class="math">C_{i}</span> are understood to be independently and uniformly distributed over <span class="math">\\mathcal{C}</span>.</p>

    <p class="text-gray-300">The obvious instantiation of <span class="math">\\mathcal{A}</span> is given by a deterministic prover <span class="math">P^{<em>}</span> attacking the considered <span class="math">t</span>-fold parallel repetition <span class="math">(\\mathcal{P}^{t},\\mathcal{V}^{t})</span> of <span class="math">(\\mathcal{P},\\mathcal{V})</span>. More precisely, on input <span class="math">(c_{1},\\ldots,c_{t})</span>, <span class="math">\\mathcal{A}</span> runs <span class="math">\\mathcal{P}^{</em>}</span> sending <span class="math">(c_{1},\\ldots,c_{t})</span> as the challenges for the <span class="math">t</span> repetitions of <span class="math">(\\mathcal{P},\\mathcal{V})</span>, and outputs <span class="math">\\mathcal{P}^{*}</span>’s (fixed) first messages <span class="math">(a_{1},\\ldots,a_{t})</span> and its responses <span class="math">(z_{1},\\ldots,z_{t})</span>, and the function <span class="math">V</span> is defined as the verification procedure of <span class="math">\\mathcal{V}^{t}</span>, which checks each repetition independently and accepts only if all are correct.</p>

    <p class="text-gray-300">Such an <span class="math">\\mathcal{A}</span> naturally induces <span class="math">t</span> algorithms <span class="math">\\mathcal{A}_{1},\\ldots,\\mathcal{A}_{t}</span> as considered above in the context of a single execution of a <span class="math">k</span>-special-sound protocol, taking <em>one</em> challenge as input: on input <span class="math">c_{i}</span>, the algorithm <span class="math">\\mathcal{A}_{i}</span> runs <span class="math">y\\leftarrow\\mathcal{A}(c_{1},\\ldots,c_{t})</span> with <span class="math">c_{j}</span> chosen uniformly at random from <span class="math">\\mathcal{C}</span> for <span class="math">j\\neq i</span>, and outputs <span class="math">y</span> along with the <span class="math">c_{j}</span>’s for <span class="math">j\\neq i</span>. We can thus run the extractor from above on all of the <span class="math">\\mathcal{A}_{i}</span>’s individually, with the hope</p>

    <p class="text-gray-300">being that at least one of them succeeds. We know that for each <span class="math">\\mathcal{A}_i</span> individually, the extraction succeeds with probability</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\delta_k^V(\\mathcal{A}_i) = \\min_{S_i \\subset \\mathcal{C}:</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= k - 1} \\Pr\\left(V(C_i, \\mathcal{A}_i(C_i)) = 1 \\mid C_i \\notin S_i\\right), \\tag{2}</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">where <span class="math">V</span> is understood to appropriately reorder its inputs. The following lemma allows us to bound the probability that at least one of the extractors <span class="math">\\mathcal{E}^{\\mathcal{A}_i}</span> succeeds to produce <span class="math">k</span> challenge-response pairs <span class="math">((c_1, \\ldots, c_t), y)</span> that all verify <span class="math">V</span> and for which the <span class="math">k</span> choices of <span class="math">c_i</span> are all distinct for the considered <span class="math">i</span>.</p>

    <p class="text-gray-300"><strong>Lemma 3.</strong> Let <span class="math">k, t \\in \\mathbb{N}</span> and <span class="math">\\mathcal{C}</span> a finite set with cardinality <span class="math">N \\geq k</span>. Also, let <span class="math">V: \\mathcal{C}^t \\times \\{0,1\\}^<em> \\to \\{0,1\\}</span>, and let <span class="math">\\mathcal{A}</span> be a (probabilistic) algorithm that takes as input a vector <span class="math">(c_1, \\ldots, c_t) \\in \\mathcal{C}^t</span> and outputs a string <span class="math">y \\in \\{0,1\\}^</em></span>. Then</p>

    <div class="my-4 text-center"><span class="math-block">\\sum_{i = 1}^t \\delta_k^V(\\mathcal{A}_i) \\geq \\frac{\\epsilon^V(\\mathcal{A}) - \\kappa^t}{1 - \\kappa},</span></div>

    <p class="text-gray-300">where <span class="math">\\kappa = (k - 1)/N</span>.</p>

    <p class="text-gray-300"><strong>Proof.</strong> Let <span class="math">\\Lambda</span> denote the event <span class="math">V(C_1, \\ldots, C_t, \\mathcal{A}(C_1, \\ldots, C_t)) = 1</span> and, for <span class="math">1 \\leq i \\leq t</span>, let <span class="math">S_i</span> be such that it minimizes Equation 2. Moreover, let <span class="math">\\Gamma_i</span> denote the event <span class="math">C_i \\notin S_i</span>. Then, for all <span class="math">i</span>,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr(\\Gamma_i) = \\Pr(C_i \\notin S_i) = 1 - \\Pr(C_i \\in S_i) = 1 - \\kappa.</span></div>

    <p class="text-gray-300">Moreover, using elementary probability theory,</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} \\sum_{i = 1}^t \\delta_k^V(\\mathcal{A}_i) &amp;amp;= \\sum_{i = 1}^t \\Pr\\left(V(C_i, \\mathcal{A}_i(C_i)) = 1 \\mid C_i \\notin S_i\\right) = \\sum_{i = 1}^t \\Pr\\left(\\Lambda \\mid \\Gamma_i\\right) = \\sum_{i = 1}^t \\frac{\\Pr\\left(\\Lambda \\wedge \\Gamma_i\\right)}{\\Pr\\left(\\Gamma_i\\right)} \\\\ &amp;amp;= \\sum_{i = 1}^t \\frac{\\Pr(\\Lambda \\wedge \\Gamma_i)}{1 - \\kappa} \\geq \\frac{\\Pr(\\Lambda \\wedge \\exists i : \\Gamma_i)}{1 - \\kappa} \\geq \\frac{\\Pr(\\Lambda) - \\Pr(\\neg \\Gamma_i \\ \\forall i)}{1 - \\kappa} = \\frac{\\epsilon^V(\\mathcal{A}) - \\kappa^t}{1 - \\kappa}, \\end{aligned}</span></div>

    <p class="text-gray-300">which completes the proof.</p>

    <p class="text-gray-300"><strong>Lemma 3</strong> readily provides a lower bound on <span class="math">\\max_i \\delta_k^V(\\mathcal{A}_i) \\geq \\sum_i \\delta_k^V(\\mathcal{A}_i)/t</span>, and thus on the success probability of the extractor. However, we can do slightly better. For this purpose, let <span class="math">\\Delta = \\min\\left(1, \\sum_{i=1}^t \\delta_k^V(\\mathcal{A}_i)/k\\right)</span>. Then, by the inequality of the arithmetic and the geometric mean,</p>

    <div class="my-4 text-center"><span class="math-block">\\left(\\prod_{i = 1}^t \\left(1 - \\frac{\\delta_k^V(\\mathcal{A}_i)}{k}\\right)\\right)^{1/t} \\leq \\frac{1}{t} \\sum_{i = 1}^t \\left(1 - \\frac{\\delta_k^V(\\mathcal{A}_i)}{k}\\right) \\leq 1 - \\frac{\\Delta}{t}.</span></div>

    <p class="text-gray-300">Hence, the probability that at least one extractor <span class="math">\\mathcal{E}^{\\mathcal{A}_i}</span> succeeds equals</p>

    <div class="my-4 text-center"><span class="math-block">1 - \\prod_{i = 1}^t \\left(1 - \\delta_k^V(\\mathcal{A}_i)/k\\right) \\geq 1 - \\left(1 - \\frac{\\Delta}{t}\\right)^t \\geq 1 - e^{-\\Delta} \\geq (1 - e^{-1}) \\Delta \\geq \\frac{1}{2} \\Delta, \\tag{3}</span></div>

    <p class="text-gray-300">where the third inequality uses that <span class="math">(1 - e^{-x}) \\geq (1 - e^{-1})x</span> for all <span class="math">0 \\leq x \\leq 1</span>, which is easily verified. Hence, by Lemma 3, the probability of at least one of the extractors <span class="math">\\mathcal{E}^{\\mathcal{A}_i}</span> being successful is at least</p>

    <div class="my-4 text-center"><span class="math-block">\\frac{\\Delta}{2} \\geq \\frac{\\epsilon^V(\\mathcal{A}) - \\kappa^t}{2k(1 - \\kappa)}.</span></div>

    <p class="text-gray-300">From this it follows that the <span class="math">t</span>-fold parallel repetition <span class="math">(\\mathcal{P}^t, \\mathcal{V}^t)</span> of a <span class="math">k</span>-special-sound protocol <span class="math">(\\mathcal{P}, \\mathcal{V})</span> is knowledge sound with knowledge error <span class="math">\\kappa^t</span>, where <span class="math">\\kappa = (k - 1)/N</span> is the knowledge error of a single execution of <span class="math">(\\mathcal{P}, \\mathcal{V})</span>. This parallel repetition result for <span class="math">k</span>-special-sound <span class="math">\\Sigma</span>-protocols is formalized in Theorem 2.</p>

    <p class="text-gray-300"><strong>Theorem 2 (Parallel Repetition of <span class="math">k</span>-Special-Sound <span class="math">\\Sigma</span>-Protocols).</strong> Let <span class="math">(\\mathcal{P}, \\mathcal{V})</span> be a <span class="math">k</span>-out-of-<span class="math">N</span> special-sound <span class="math">\\Sigma</span>-protocol. Let <span class="math">(\\mathcal{P}^t, \\mathcal{V}^t)</span> be the <span class="math">t</span>-fold parallel repetition of protocol <span class="math">(\\mathcal{P}, \\mathcal{V})</span>. Then <span class="math">(\\mathcal{P}^t, \\mathcal{V}^t)</span> is knowledge sound with knowledge error <span class="math">\\kappa^t</span> for <span class="math">\\kappa = (k - 1)/N</span>.</p>

    <p class="text-gray-300">10 For instance by observing that the two sides are equal for <span class="math">x = 0</span> and <span class="math">x = 1</span>, and that the left hand side is a concave function while the right hand side is linear.</p>

    <p class="text-gray-300">Also here we have that the knowledge error <span class="math">\\kappa^t</span> matches the trivial cheating probability, which succeeds if in each instance of the parallel repetition the challenge falls into a given set of size <span class="math">k - 1</span>.</p>

    <p class="text-gray-300">Remark 4. The above parallel repetition result (and also the generalization of Section 4), directly generalize to the parallel composition of <span class="math">t</span> different protocols, or to the parallel composition of <span class="math">t</span> different instances of the same protocol. In this case, the knowledge error will be the product of the individual knowledge errors.</p>

    <h2 id="sec-32" class="text-2xl font-bold">4 Parallel Repetition of Multi-Round Protocols</h2>

    <p class="text-gray-300">We now consider the general case of multi-round protocols. The line of reasoning is quite similar to that of 3-round protocols, but with an appropriately adjusted definition of <span class="math">\\delta</span>. So, for the remainder of this section, we consider a <span class="math">(k_{1},\\ldots ,k_{\\mu})</span>-special-sound <span class="math">(2\\mu +1)</span>-round public-coin interactive proof <span class="math">(\\mathcal{P},\\mathcal{V})</span>, where the verifier samples its <span class="math">j</span>-th challenge uniformly at random from a finite set <span class="math">\\mathcal{C}^{[j]}</span> for <span class="math">1\\leq j\\leq \\mu</span>. We denote the superscript <span class="math">j</span> with square brackets to distinguish the set <span class="math">\\mathcal{C}^{[j]}</span> from the <span class="math">j</span>-fold Cartesian product <span class="math">\\mathcal{C}^j</span>. Eventually, we want to analyze its <span class="math">t</span>-fold parallel repetition <span class="math">(\\mathcal{P}^t,\\mathcal{V}^t)</span>, but again we first consider a single invocation.</p>

    <h2 id="sec-33" class="text-2xl font-bold">4.1 Knowledge Soundness of a Single Invocation</h2>

    <p class="text-gray-300">Here, we consider a (possibly randomized) algorithm <span class="math">\\mathcal{A}</span> that takes as input a column <span class="math">(c^{1},\\ldots ,c^{\\mu})\\in \\mathcal{C}^{[1]}\\times \\dots \\times \\mathcal{C}^{[\\mu ]}</span> of challenges and outputs a string <span class="math">y</span>, and we consider a function</p>

    <div class="my-4 text-center"><span class="math-block">V \\colon \\mathcal {C} ^ {[ 1 ]} \\times \\dots \\times \\mathcal {C} ^ {[ \\mu ]} \\times \\{0, 1 \\} ^ {*} \\to \\{0, 1 \\}.</span></div>

    <p class="text-gray-300">The obvious instantiation is a deterministic prover <span class="math">\\mathcal{P}^<em></span> attacking the considered protocol. Formally, on input <span class="math">(c^{1},\\ldots ,c^{\\mu})</span>, <span class="math">\\mathcal{A}</span> runs <span class="math">\\mathcal{P}^</em></span>, sending <span class="math">c^1</span> in the first challenge round, <span class="math">c^2</span> in the second, etc., and eventually <span class="math">\\mathcal{A}</span> outputs all of <span class="math">\\mathcal{P}^<em></span>'s messages. Then <span class="math">V\\colon \\mathcal{C}^{[1]}\\times \\dots \\times \\mathcal{C}^{[\\mu ]}\\times \\{0,1\\}^{</em>}\\to \\{0,1\\}</span> captures the verification procedure of <span class="math">\\mathcal{V}</span>, i.e., <span class="math">V(c^{1},\\ldots ,c^{\\mu},y) = 1</span> if and only if the corresponding transcript is accepting. This instantiation results in a deterministic algorithm <span class="math">\\mathcal{A}</span>. However, again, it is crucial that in general <span class="math">\\mathcal{A}</span> may be probabilistic, i.e., its output <span class="math">y</span> is not necessarily uniquely determined by its input <span class="math">(c^{1},\\ldots ,c^{\\mu})</span>.</p>

    <p class="text-gray-300">Syntactically identical to the previous section, the success probability of <span class="math">\\mathcal{A}</span> is defined as</p>

    <div class="my-4 text-center"><span class="math-block">\\epsilon^ {V} (\\mathcal {A}) := \\operatorname * {P r} \\bigl (V (C, \\mathcal {A} (C)) = 1 \\bigr),</span></div>

    <p class="text-gray-300">where here <span class="math">C = (C^1, \\ldots, C^\\mu)</span> is uniformly random in <span class="math">\\mathcal{C}^{[1]} \\times \\dots \\times \\mathcal{C}^{[\\mu]}</span>. However, here the goal of the extractor is slightly different: the goal is to find correct responses for a <span class="math">\\mathbf{k}</span>-tree of challenges, where <span class="math">\\mathbf{k} = (k_1, \\ldots, k_\\mu)</span>. Generalizing the case of ordinary 3-round protocols, the figure of merit here is</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\delta_ {\\mathbf {k}} ^ {V} (\\mathcal {A}) := \\min  _ {S ^ {[ 1 ]}, S ^ {[ 2 ]} (\\cdot), \\dots , S ^ {[ \\mu ]} (\\cdot)} \\Pr \\left(V (C, \\mathcal {A} (C)) = 1 \\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\begin{array}{l} C ^ {1} \\notin S ^ {[ 1 ]} \\wedge C ^ {2} \\notin S ^ {[ 2 ]} (C ^ {1}) \\wedge \\dots \\\\ \\dots \\wedge C ^ {\\mu} \\notin S ^ {[ \\mu ]} (C ^ {1}, \\dots , C ^ {\\mu - 1}) \\end{array} \\right.\\right), \\tag {4}</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where the minimum is over all sets $S^{[1]} \\in \\mathcal{C}^{[1]}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{k_1 - 1}<span class="math">, and over all functions </span>S^{[2]} \\colon \\mathcal{C}^{[1]} \\to \\mathcal{C}^{[2]}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{k_2 - 1}, S^{[3]} \\colon \\mathcal{C}^{[1]} \\times \\mathcal{C}^{[2]} \\to \\mathcal{C}^{[3]}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{k_3 - 1}<span class="math">, etc. Here for any set </span>\\mathcal{C}<span class="math"> and </span>k \\in \\mathbb{N}<span class="math">, </span>\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{k - 1}<span class="math"> denotes the set of subsets of </span>\\mathcal{C}<span class="math"> with cardinality </span>k - 1$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Indeed, the following lemma shows that there exists an expected polynomial time extractor <span class="math">\\mathcal{E}^{\\mathcal{A}}</span> with oracle access to <span class="math">\\mathcal{A}</span> that, with probability <span class="math">\\delta_{\\mathbf{k}}^{V}(\\mathcal{A}) / \\prod_{i = 1}^{\\mu}k_{i}</span>, succeeds to extract correct responses for a <span class="math">\\mathbf{k}</span>-tree of challenges. Exploiting the abstract notation of Lemma 2, the proof of this lemma follows by induction over the number of challenges <span class="math">\\mu</span> sent by the verifier.</p>

    <p class="text-gray-300">Lemma 4 (Multi-Round Extraction Algorithm). Let <span class="math">\\mathbf{k} = (k_1, \\ldots, k_\\mu) \\in \\mathbb{N}^\\mu</span>, <span class="math">K = \\prod_{i=1}^\\mu k_i</span>, <span class="math">\\mathcal{C}^{[1]}, \\ldots, \\mathcal{C}^{[\\mu]}</span> finite sets <span class="math">\\mathcal{C}^{[j]}</span> with cardinality <span class="math">N_j \\geq k_j</span>, and let <span class="math">V \\colon \\mathcal{C}^{[1]} \\times \\dots \\times \\mathcal{C}^{[\\mu]} \\times \\{0,1\\}^* \\to \\{0,1\\}</span>.</p>

    <p class="text-gray-300">Then, there exists an algorithm <span class="math">\\mathcal{E}^{\\mathcal{A}}</span> so that, given oracle access to any (probabilistic) algorithm <span class="math">\\mathcal{A}\\colon \\mathcal{C}^{[1]}\\times \\dots \\times \\mathcal{C}^{[\\mu ]}\\to \\{0,1\\}^<em></span>, <span class="math">\\mathcal{E}^{\\mathcal{A}}</span> requires an expected number of at most <span class="math">2^{\\mu}\\cdot K</span> queries to <span class="math">\\mathcal{A}</span> and, with probability at least <span class="math">\\delta_{\\mathbf{k}}^{V}(\\mathcal{A}) / K</span>, outputs <span class="math">K</span> pairs <span class="math">(\\mathbf{c}_1,y_1),\\ldots ,(\\mathbf{c}_K,y_K)\\in \\mathcal{C}^{[1]}\\times \\dots \\times \\mathcal{C}^{[\\mu ]}\\times \\{0,1\\}^</em></span> with <span class="math">V(\\mathbf{c}_i,y_i) = 1</span> for all <span class="math">i</span> and such that the vectors <span class="math">\\mathbf{c}_i\\in \\mathcal{C}^{[1]}\\times \\dots \\times \\mathcal{C}^{[\\mu ]}</span> form a <span class="math">\\mathbf{k}</span>-tree.</p>

    <p class="text-gray-300">14</p>

    <p class="text-gray-300">Proof. The proof goes by induction on <span class="math">\\mu</span>. For the base case <span class="math">\\mu = 1</span>, the lemma directly follows from Lemma 2. So let us assume the lemma holds for <span class="math">\\mu&#x27; = \\mu - 1</span>.</p>

    <p class="text-gray-300">Then, for any <span class="math">c \\in \\mathcal{C}^{[1]}</span>, let <span class="math">\\mathcal{A}_c</span> be the algorithm that takes as input a vector <span class="math">(c^2, \\ldots, c^\\mu) \\in \\mathcal{C}^{[2]} \\times \\dots \\times \\mathcal{C}^{[\\mu]}</span> and runs <span class="math">\\mathcal{A}(c, c^2, \\ldots, c^\\mu)</span>. The function <span class="math">V_c</span> is defined accordingly, i.e.,</p>

    <div class="my-4 text-center"><span class="math-block">V _ {c} \\colon \\mathcal {C} ^ {[ 2 ]} \\times \\dots \\times \\mathcal {C} ^ {[ \\mu ]} \\times \\{0, 1 \\} ^ {*} \\rightarrow \\{0, 1 \\}, (c ^ {2}, \\dots , c ^ {\\mu}, y) \\mapsto V (c, c ^ {2}, \\dots , c ^ {\\mu}, y).</span></div>

    <p class="text-gray-300">Moreover, let <span class="math">\\mathbf{k}&#x27; = (k_2, \\ldots, k_\\mu) \\in \\mathbb{N}^{\\mu - 1}</span> and <span class="math">K&#x27; = \\prod_{i=2}^{\\mu} k_i</span>.</p>

    <p class="text-gray-300">By the induction hypothesis there exists an algorithm <span class="math">\\mathcal{E}_{\\mu -1}^{\\mathcal{A}_c}</span> that outputs a set <span class="math">\\mathcal{Y} = \\{(c_i^2,\\ldots ,c_i^\\mu ,y_i)\\}_{1\\leq i\\leq K&#x27;}</span> with</p>

    <div class="my-4 text-center"><span class="math-block">V (c, c _ {i} ^ {2}, \\dots , c _ {i} ^ {\\mu}, y _ {i}) = 1 \\forall i \\quad \\text {and} \\quad \\{(c _ {i} ^ {2}, \\dots , c _ {i} ^ {\\mu}) \\} _ {i} \\in \\operatorname {T r e e} (k _ {2}, \\dots , k _ {\\mu}).</span></div>

    <p class="text-gray-300">Moreover, <span class="math">\\mathcal{E}_{\\mu -1}^{\\mathcal{A}_c}</span> requires an expected number of at most <span class="math">2^{\\mu -1}\\cdot K^{\\prime}</span> queries to <span class="math">\\mathcal{A}_c</span> (and thus to <span class="math">\\mathcal{A}</span>) and succeeds with probability at least <span class="math">\\delta_{\\mathbf{k}^{\\prime}}^{V_c}(\\mathcal{A}_c) / K^{\\prime}</span>. We define <span class="math">W\\colon \\mathcal{C}^{[1]}\\times \\{0,1\\}^*\\to \\{0,1\\}</span>, by setting <span class="math">W(c,\\mathcal{V}) = 1</span> if and only if <span class="math">\\mathcal{V}</span> is a set satisfying the above properties.</p>

    <p class="text-gray-300">Now let <span class="math">\\mathcal{B}^{\\mathcal{A}}\\colon \\mathcal{C}^{[1]}\\to \\{0,1\\}^<em></span> be the algorithm, with oracle access to <span class="math">\\mathcal{A}</span>, that takes as input an element <span class="math">c\\in \\mathcal{C}^{[1]}</span> and runs <span class="math">\\mathcal{E}_{\\mu -1}^{\\mathcal{A}_c}</span>. By Lemma 2, there exists an expected polynomial time algorithm <span class="math">\\mathcal{E}_1^{\\mathcal{B}^{\\mathcal{A}}}</span>, with oracle access to <span class="math">\\mathcal{B}^{\\mathcal{A}}</span>, that aims to output <span class="math">k_{1}</span> pairs <span class="math">(c_{1},\\mathcal{V}_{1}),\\ldots ,(c_{k_{1}},\\mathcal{V}_{k_{1}})\\in \\mathcal{C}^{[1]}\\times \\{0,1\\}^{</em>}</span> with <span class="math">W(c_{i},\\mathcal{V}_{i}) = 1</span> for all <span class="math">i</span> and <span class="math">c_{i}\\neq c_{j}</span> for all <span class="math">i\\neq j</span>. The extractor <span class="math">\\mathcal{E}^{\\mathcal{A}}</span> simply runs <span class="math">\\mathcal{E}_1^{\\mathcal{B}^{\\mathcal{A}}}</span>. Note that, by the associativity of the composition of oracle algorithms, <span class="math">\\mathcal{E}^{\\mathcal{A}} = \\mathcal{E}_1^{\\mathcal{B}^{\\mathcal{A}}} = (\\mathcal{E}_1^{\\mathcal{B}})^{\\mathcal{A}}</span> is indeed an algorithm with oracle access to <span class="math">\\mathcal{A}</span>.</p>

    <p class="text-gray-300">Let us now analyze the success probability and the expected number of <span class="math">\\mathcal{A}</span>-queries of the algorithm <span class="math">\\mathcal{E}_1^{\\mathcal{B}^{\\mathcal{A}}}</span> and therefore of <span class="math">\\mathcal{E}^{\\mathcal{A}}</span>.</p>

    <p class="text-gray-300"><strong>Success Probability.</strong> Again by Lemma 2, writing <span class="math">C^1</span> here for the random variable that describes the random choice of the challenge in <span class="math">\\mathcal{C}^{[1]}</span>, it follows that <span class="math">\\mathcal{E}_1^{\\mathcal{B}^{\\mathcal{A}}}</span> succeeds with probability at least</p>

    <p class="text-gray-300">$$ \\begin{array}{l}</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\delta_ {k _ {1}} ^ {W} \\left(\\mathcal {B} ^ {\\mathcal {A}}\\right) / k _ {1} = \\min  _ {S ^ {[ 1 ]} \\subset \\mathcal {C} ^ {[ 1 ]},</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S ^ {[ 1 ]}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= k _ {1} - 1} \\frac {\\Pr \\left(W \\left(C ^ {1} , \\mathcal {B} ^ {\\mathcal {A}} \\left(C ^ {1}\\right)\\right) = 1 \\mid C ^ {1} \\notin S ^ {[ 1 ]}\\right)}{k _ {1}} \\\\</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">= \\min  _ {S ^ {[ 1 ]} \\subset \\mathcal {C} ^ {[ 1 ]},</td>

            <td class="px-3 py-2 border-b border-gray-700">S ^ {[ 1 ]}</td>

            <td class="px-3 py-2 border-b border-gray-700">= k _ {1} - 1} \\frac {\\sum_ {c \\in \\mathcal {C}} \\Pr (C ^ {1} = c \\wedge \\Pr \\left(W (c , \\mathcal {E} _ {\\mu - 1} ^ {\\mathcal {A} _ {c}}) = 1 \\mid C ^ {1} \\notin S ^ {[ 1 ]}\\right)}{k _ {1}} \\\\</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">= \\min  _ {S ^ {[ 1 ]} \\subset \\mathcal {C} ^ {[ 1 ]},</td>

            <td class="px-3 py-2 border-b border-gray-700">S ^ {[ 1 ]}</td>

            <td class="px-3 py-2 border-b border-gray-700">= k _ {1} - 1} \\frac {\\sum_ {c \\in \\mathcal {C}} \\Pr \\left(C ^ {1} = c \\mid C ^ {1} \\notin S ^ {[ 1 ]}\\right) \\cdot \\Pr \\left(W \\left(c , \\mathcal {E} _ {\\mu - 1} ^ {\\mathcal {A} _ {c}}\\right) = 1\\right)}{k _ {1}} \\\\</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">\\geq \\min  _ {S ^ {[ 1 ]} \\subset \\mathcal {C} ^ {[ 1 ]},</td>

            <td class="px-3 py-2 border-b border-gray-700">S ^ {[ 1 ]}</td>

            <td class="px-3 py-2 border-b border-gray-700">= k _ {1} - 1} \\frac {\\sum_ {c \\in \\mathcal {C}} \\Pr \\left(C ^ {1} = c \\mid C ^ {1} \\notin S ^ {[ 1 ]}\\right) \\cdot \\delta_ {\\mathbf {k} ^ {\\prime}} ^ {V _ {c}} \\left(\\mathcal {A} _ {c}\\right)}{k _ {1} \\cdot K ^ {\\prime}} \\\\</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">= \\min  _ {S ^ {[ 1 ]} \\subset \\mathcal {C} ^ {[ 1 ]},</td>

            <td class="px-3 py-2 border-b border-gray-700">S ^ {[ 1 ]}</td>

            <td class="px-3 py-2 border-b border-gray-700">= k _ {1} - 1} \\frac {\\sum_ {c \\in \\mathcal {C}} \\Pr \\left(C ^ {1} = c \\mid C ^ {1} \\notin S ^ {[ 1 ]}\\right) \\cdot \\delta_ {\\mathbf {k} ^ {\\prime}} ^ {V _ {c}} \\left(\\mathcal {A} _ {c}\\right)}{K}. \\tag {5}</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">\\end{array} $$</p>

    <p class="text-gray-300">Now note that</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\delta_{\\mathbf{k}^{\\prime}}^{V_{c}}(\\mathcal{A}_{c}) = \\min_{S^{[2]}(\\cdot),\\ldots ,S^{[\\mu ]}(\\cdot)}\\Pr \\left(\\Lambda \\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\begin{array}{c}C^{1} = c\\wedge C^{2}\\notin S^{[2]}(C^{1})\\wedge \\dots \\\\ \\dots \\wedge C^{\\mu}\\notin S^{[\\mu ]}(C^{1},\\ldots ,C^{\\mu -1}) \\end{array} \\right.\\right),</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">where <span class="math">\\varLambda</span> denotes the event <span class="math">V(C,\\mathcal{A}(C)) = 1</span> with <span class="math">C = (C_1,\\ldots ,C_\\mu)</span> distributed uniformly at random over <span class="math">\\mathcal{C}^{[1]}\\times \\dots \\times \\mathcal{C}^{[\\mu ]}</span>. Additionally, observe that</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\Pr \\left(C ^ {1} = c \\mid C ^ {1} \\notin S ^ {[ 1 ]} \\wedge \\dots \\wedge C ^ {\\mu} \\notin S ^ {[ \\mu ]} \\left(C ^ {1}, \\dots , C ^ {\\mu - 1}\\right)\\right) \\\\ = \\frac {\\Pr \\left(C ^ {1} = c \\wedge C ^ {\\mu} \\notin S ^ {[ \\mu ]} \\left(C ^ {1} , \\dots , C ^ {\\mu - 1}\\right) \\mid C ^ {1} \\notin S ^ {[ 1 ]} \\wedge \\cdots \\wedge C ^ {\\mu - 1} \\notin S ^ {[ \\mu - 1 ]} \\left(C ^ {1} , \\dots , C ^ {\\mu - 2}\\right)\\right)}{\\Pr \\left(C ^ {\\mu} \\notin S ^ {[ \\mu ]} \\left(C ^ {1} , \\dots , C ^ {\\mu - 1}\\right) \\mid C ^ {1} \\notin S ^ {[ 1 ]} \\wedge \\cdots \\wedge C ^ {\\mu - 1} \\notin S ^ {[ \\mu - 1 ]} \\left(C ^ {1} , \\dots , C ^ {\\mu - 2}\\right)\\right)} \\\\ = \\frac {\\Pr \\left(C ^ {1} = c \\mid C ^ {1} \\notin S ^ {[ 1 ]} \\wedge \\cdots\\right) \\Pr \\left(C ^ {\\mu} \\notin S ^ {[ \\mu ]} \\left(C ^ {1} , \\dots , C ^ {\\mu - 1}\\right) \\mid C ^ {1} = c \\wedge C ^ {1} \\notin S ^ {[ 1 ]} \\wedge \\cdots\\right)}{\\Pr \\left(C ^ {\\mu} \\notin S ^ {[ \\mu ]} \\left(C ^ {1} , \\dots , C ^ {\\mu - 1}\\right) \\mid C ^ {1} \\notin S ^ {[ 1 ]} \\wedge \\cdots\\right)} \\\\ = \\Pr \\left(C ^ {1} = c \\mid C ^ {1} \\notin S ^ {[ 1 ]} \\wedge \\dots \\wedge C ^ {\\mu - 1} \\notin S ^ {[ \\mu - 1 ]} \\left(C ^ {1}, \\dots , C ^ {\\mu - 2}\\right)\\right) \\end{array}</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where the final equality follows because $\\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S^{[\\mu]}(c_{1},\\ldots,c_{\\mu-1})\\right</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=k_{\\mu}-1<span class="math"> for all </span>c_{1},\\ldots,c_{\\mu-1}<span class="math">, and since </span>C^{\\mu}<span class="math"> is independent of </span>C^{1},\\ldots,C^{\\mu-1}$. Proceeding recursively, we obtain that</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\Pr\\big{(}C^{1}=c\\mid C^{1}\\notin S^{[1]}\\wedge\\cdots\\wedge C^{\\mu}\\notin S^{[\\mu]}(C^{1},\\ldots,C^{\\mu-1})\\big{)}=\\Pr\\big{(}C^{1}=c\\mid C^{1}\\notin S^{[1]}\\big{)}\\,.</span></p>

    <p class="text-gray-300">Hence,</p>

    <p class="text-gray-300"><span class="math">\\sum_{c\\in\\mathcal{C}}\\Pr\\big{(}C^{1}=c\\mid C^{1}\\notin S^{[1]}\\big{)}\\cdot\\delta^{V_{c}}_{\\mathbf{k}^{\\prime}}(\\mathcal{A}_{c})</span> <span class="math">=\\sum_{c\\in\\mathcal{C}}\\Pr\\big{(}C^{1}=c\\mid C^{1}\\notin S^{[1]}\\wedge\\cdots\\wedge C^{\\mu}\\notin S^{[\\mu]}(C^{1},\\ldots,C^{\\mu-1})\\big{)}\\cdot\\delta^{V_{c}}_{\\mathbf{k}^{\\prime}}(\\mathcal{A}_{c})</span> <span class="math">=\\min_{S^{[2]}(\\cdot),\\ldots,S^{[\\mu]}(\\cdot)}\\Pr\\big{(}\\Lambda\\mid C^{1}\\notin S^{[1]}\\wedge\\cdots\\wedge C^{\\mu}\\notin S^{[\\mu]}(C^{1},\\ldots,C^{\\mu-1})\\big{)}\\,.</span></p>

    <p class="text-gray-300">Plugging this equality into Equation 5, shows that</p>

    <p class="text-gray-300"><span class="math">\\delta^{W}_{k_{1}}(\\mathcal{B}^{\\mathcal{A}})/k_{1}\\geq\\frac{\\delta^{V}_{\\mathbf{k}}(\\mathcal{A})}{K}\\,,</span></p>

    <p class="text-gray-300">which shows that <span class="math">\\mathcal{E}_{1}^{B^{\\mathcal{A}}}</span> has the desired success probability.</p>

    <p class="text-gray-300">Expected Number of <span class="math">\\mathcal{A}</span>-Queries. By Lemma 2, it follows that <span class="math">\\mathcal{E}_{1}^{\\mathcal{B}^{\\mathcal{A}}}</span> requires an expected number of at most <span class="math">2k_{1}</span> queries to <span class="math">\\mathcal{B}^{\\mathcal{A}}</span>. By the induction hypothesis it follows that <span class="math">\\mathcal{B}^{\\mathcal{A}}</span> requires an expected number of at most <span class="math">2^{\\mu-1}\\cdot K^{\\prime}</span> queries to <span class="math">\\mathcal{A}</span>. Hence, <span class="math">\\mathcal{E}^{\\mathcal{A}}=\\mathcal{E}_{1}^{\\mathcal{B}^{\\mathcal{A}}}</span> requires an expected number of at most <span class="math">2^{\\mu}\\cdot K</span> queries to <span class="math">\\mathcal{A}</span>, which completes the proof of the lemma. ∎</p>

    <p class="text-gray-300">Let <span class="math">S^{[1]},S^{[2]}(\\cdot),\\ldots,S^{[\\mu]}(\\cdot)</span> be the arguments minimizing Equation 4. Further, let <span class="math">\\Lambda</span> denote the event <span class="math">V(C,\\mathcal{A}(C))=1</span> and let <span class="math">\\Gamma</span> denote the event</p>

    <p class="text-gray-300"><span class="math">\\Gamma\\,=\\,C^{1}\\notin S^{[1]}\\wedge C^{2}\\notin S^{[2]}(C^{1})\\wedge\\cdots\\wedge C^{\\mu}\\notin S^{[\\mu]}(C^{1},\\ldots,C^{\\mu-1})\\,.</span></p>

    <p class="text-gray-300">Then, using the same kind of reasoning as in Equation 1, we have</p>

    <p class="text-gray-300"><span class="math">\\delta^{V}_{\\mathbf{k}}(\\mathcal{A})=\\Pr(\\Lambda\\mid\\Gamma)=\\frac{\\Pr(\\Lambda\\wedge\\Gamma)}{\\Pr(\\Gamma)}\\geq\\frac{\\Pr(\\Lambda)-\\Pr(\\neg\\Gamma)}{\\Pr(\\Gamma)}=\\frac{\\epsilon^{V}(\\mathcal{A})-\\kappa}{1-\\kappa}\\,,</span></p>

    <p class="text-gray-300">where</p>

    <p class="text-gray-300"><span class="math">\\kappa=\\Pr(\\neg\\Gamma)=1-\\prod_{j=1}^{\\mu}\\frac{N_{j}-k_{j}+1}{N_{j}}.</span></p>

    <p class="text-gray-300">This confirms that a <span class="math">(k_{1},\\ldots,k_{\\mu})</span>-special-sound protocol is knowledge sound with knowledge error <span class="math">\\kappa</span>. See <em>[3]</em> for an alternative and the original proof of this statement. This result is formalized as follows.</p>

    <h6 id="sec-34" class="text-base font-medium mt-4">Theorem 3.</h6>

    <p class="text-gray-300">Let <span class="math">(\\mathcal{P},\\mathcal{V})</span> be a <span class="math">(k_{1},\\ldots,k_{\\mu})</span>-out-of-<span class="math">(N_{1},\\ldots,N_{\\mu})</span> special-sound protocol. Then <span class="math">(\\mathcal{P},\\mathcal{V})</span> is knowledge sound with knowledge error</p>

    <p class="text-gray-300"><span class="math">\\kappa=1-\\prod_{j=1}^{\\mu}\\frac{N_{j}-k_{j}+1}{N_{j}}.</span></p>

    <p class="text-gray-300">Once more, <span class="math">\\kappa</span> matches the trivial cheating probability.</p>

    <h3 id="sec-35" class="text-xl font-semibold mt-8">4.2 Knowledge-Soundness of the Parallel Repetition</h3>

    <p class="text-gray-300">We finally move towards stating and proving our main general parallel repetition result for multi-round protocols. Thus, consider the <span class="math">t</span>-fold parallel repetition <span class="math">(\\mathcal{P}^{t},\\mathcal{V}^{t})</span> of the given <span class="math">(k_{1},\\ldots,k_{\\mu})</span>-special-sound <span class="math">(2\\mu+1)</span>-round public-coin interactive proof <span class="math">(\\mathcal{P},\\mathcal{V})</span>.</p>

    <p class="text-gray-300">We consider an algorithm <span class="math">\\mathcal{A}</span> that takes as input a <em>row</em> <span class="math">(\\mathbf{c}_{1},\\ldots,\\mathbf{c}_{t})</span> of <em>columns</em> <span class="math">\\mathbf{c}_{i}=(c_{i}^{1},\\ldots,c_{i}^{\\mu})\\in\\mathcal{C}^{[1]}\\times\\cdots\\times\\mathcal{C}^{[\\mu]}</span> of challenges and outputs a string <span class="math">y</span>. Furthermore, we consider a verification function <span class="math">V</span>, which then defines the <em>success probability</em> of <span class="math">\\mathcal{A}</span> as</p>

    <p class="text-gray-300"><span class="math">\\epsilon^{V}(\\mathcal{A})=\\Pr\\big{(}V(C,\\mathcal{A}(C))=1\\big{)}\\,,</span></p>

    <p class="text-gray-300">where <span class="math">C = (C_1, \\ldots, C_t)</span> with <span class="math">C_i</span> distributed uniformly and independently over <span class="math">\\mathcal{C}^{[1]} \\times \\dots \\mathcal{C}^{[\\mu]}</span> for all <span class="math">1 \\leq i \\leq t</span>.</p>

    <p class="text-gray-300">Again, the obvious instantiation for <span class="math">\\mathcal{A}</span> is a deterministic dishonest prover <span class="math">\\mathcal{P}^<em></span> attacking <span class="math">(\\mathcal{P}^t, \\mathcal{V}^t)</span>. More precisely, on input a row <span class="math">(\\mathbf{c}_1, \\ldots, \\mathbf{c}_t)</span> of columns, <span class="math">\\mathcal{A}</span> runs <span class="math">\\mathcal{P}^</em></span> sending <span class="math">(\\mathbf{c}_1, \\ldots, \\mathbf{c}_t)</span> as the challenges, and outputs all of <span class="math">\\mathcal{P}^*</span>'s messages, and the function <span class="math">V</span> is defined as the verification check that <span class="math">\\mathcal{V}^t</span> performs.</p>

    <p class="text-gray-300">Such an <span class="math">\\mathcal{A}</span> naturally induces <span class="math">t</span> algorithms <span class="math">\\mathcal{A}_1, \\ldots, \\mathcal{A}_t</span> as considered above in the context of a single execution of a multi-round protocol, taking one challenge-column as input and outputting one string: on input <span class="math">\\mathbf{c}_i</span>, the algorithm <span class="math">\\mathcal{A}_i</span> runs <span class="math">y \\gets \\mathcal{A}(\\mathbf{c}_1, \\ldots, \\mathbf{c}_\\mu)</span> with <span class="math">\\mathbf{c}_j</span> chosen uniformly at random from <span class="math">\\mathcal{C}^{[1]} \\times \\dots \\times \\mathcal{C}^{[\\mu]}</span> for <span class="math">j \\neq i</span>, and outputs <span class="math">y</span> along with the <span class="math">\\mathbf{c}_j</span>'s for <span class="math">j \\neq i</span>. Thus, we can run the extractor from Lemma 4 on all of the <span class="math">\\mathcal{A}_i</span>'s individually, with the goal being that at least one of them succeeds. For each <span class="math">\\mathcal{A}_i</span> individually, the extraction succeeds with probability at least</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\delta_{\\mathbf{k}}^{V}(\\mathcal{A}_i)/K = \\min_{S_i^{[1]}, S_i^{[2]}(\\cdot), \\dots, S_i^{[\\mu]}(\\cdot)} \\Pr\\left(V(C_i, \\mathcal{A}_i(C_i)) = 1 \\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\begin{array}{l} C_i^1 \\notin S_i^{[1]} \\wedge C_i^2 \\notin S_i^{[2]}(C_i^1) \\wedge \\dots \\\\ \\dots \\wedge C_i^\\mu \\notin S_i^{[\\mu]}(C_i^1, \\dots, C_i^{\\mu-1}) \\end{array} \\right.\\right)/K, \\tag{6}</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">where <span class="math">V</span> is understood to appropriately reorder its inputs and <span class="math">K = \\prod_{i=1}^{\\mu} k_i</span>. The following lemma allows us to bound the probability that at least one of the extractors <span class="math">\\mathcal{E}^{\\mathcal{A}_i}</span> succeeds.</p>

    <p class="text-gray-300"><strong>Lemma 5.</strong> Let <span class="math">\\mathbf{k} \\in \\mathbb{N}^{\\mu}</span>, <span class="math">t \\in \\mathbb{N}</span>, <span class="math">\\mathcal{C}^{[1]}, \\ldots, \\mathcal{C}^{[\\mu]}</span> finite sets <span class="math">\\mathcal{C}^{[j]}</span> with cardinality <span class="math">N_j \\geq k_j</span>, <span class="math">V: (\\mathcal{C}^{[1]} \\times \\dots \\times \\mathcal{C}^{[\\mu]})^t \\times \\{0,1\\}^<em> \\to \\{0,1\\}</span>, and <span class="math">\\mathcal{A}</span> a (probabilistic) algorithm that takes as input a row <span class="math">(\\mathbf{c}_1, \\ldots, \\mathbf{c}_t)</span> of columns <span class="math">\\mathbf{c}_i = (c_i^1, \\ldots, c_i^\\mu) \\in \\mathcal{C}^{[1]} \\times \\dots \\times \\mathcal{C}^{[\\mu]}</span> and outputs a string <span class="math">y \\in \\{0,1\\}^</em></span>. Then</p>

    <div class="my-4 text-center"><span class="math-block">\\sum_{i=1}^{t} \\delta_{\\mathbf{k}}^{V}(\\mathcal{A}_i) \\geq \\frac{\\epsilon^V(\\mathcal{A}) - \\kappa^t}{1 - \\kappa},</span></div>

    <p class="text-gray-300">where</p>

    <div class="my-4 text-center"><span class="math-block">\\kappa = 1 - \\prod_{j=1}^{\\mu} \\frac{N_j - k_j + 1}{N_j}.</span></div>

    <p class="text-gray-300"><strong>Proof.</strong> Let <span class="math">\\Lambda</span> denote the event <span class="math">V(C, \\mathcal{A}(C)) = 1</span> and, for <span class="math">1 \\leq i \\leq t</span>, let <span class="math">S_i^{[1]}</span> and <span class="math">S_i^{[2]}(\\cdot), \\ldots, S_i^{[\\mu]}(\\cdot)</span> be such that they minimize Equation 6. Moreover, let <span class="math">\\Gamma_i</span> denote the event</p>

    <div class="my-4 text-center"><span class="math-block">C_i^1 \\notin S_i^{[1]} \\wedge C_i^2 \\notin S_i^{[2]}(C_i^1) \\wedge \\dots \\wedge C_i^\\mu \\notin S_i^{[\\mu]}(C_i^1, \\ldots, C_i^{\\mu-1}).</span></div>

    <p class="text-gray-300">Then, for all <span class="math">1 \\leq i \\leq t</span>,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr(\\Gamma_i) = \\prod_{j=1}^{\\mu} \\frac{N - k_j + 1}{N} = 1 - \\kappa.</span></div>

    <p class="text-gray-300">Moreover, using elementary probability theory,</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} \\sum_{i=1}^{t} \\delta_{\\mathbf{k}}^{V}(\\mathcal{A}_i) &amp;amp;= \\sum_{i=1}^{t} \\Pr(\\Lambda \\mid \\Gamma_i) = \\sum_{i=1}^{t} \\frac{\\Pr(\\Lambda \\wedge \\Gamma_i)}{\\Pr(\\Gamma_i)} = \\sum_{i=1}^{t} \\frac{\\Pr(\\Lambda \\wedge \\Gamma_i)}{1 - \\kappa} \\\\ &amp;amp;\\geq \\frac{\\Pr(\\Lambda \\wedge \\exists i : \\Gamma_i)}{1 - \\kappa} \\geq \\frac{\\Pr(\\Lambda) - \\Pr(\\neg \\Gamma_i \\ \\forall i)}{1 - \\kappa} = \\frac{\\epsilon^V(\\mathcal{A}) - \\kappa^t}{1 - \\kappa}, \\end{aligned}</span></div>

    <p class="text-gray-300">which completes the proof.</p>

    <p class="text-gray-300">As for the parallel repetition of a 3-round protocol, it follows that the probability of at least one of the extractors <span class="math">\\mathcal{E}^{\\mathcal{A}_i}</span> being successful is at least</p>

    <div class="my-4 text-center"><span class="math-block">\\frac{\\Delta}{2} \\geq \\frac{\\epsilon^V(\\mathcal{A}) - \\kappa^t}{2K(1 - \\kappa)},</span></div>

    <p class="text-gray-300">where <span class="math">\\Delta = \\min\\left(1, \\sum_{i=1}^{t} \\delta_{\\mathbf{k}}^{V}(\\mathcal{A}_i)/K\\right)</span> and <span class="math">K = \\prod_{i=1}^{\\mu} k_i</span>. This gives us the following strong parallel repetition result for <span class="math">(k_1, \\ldots, k_\\mu)</span>-special-sound protocols.</p>

    <p class="text-gray-300">Theorem 4 (Parallel Repetition for Multi-Round Protocols). Let <span class="math">(\\mathcal{P},\\mathcal{V})</span> be a <span class="math">(k_{1},\\ldots ,k_{\\mu})</span>-out-of-<span class="math">(N_{1},\\ldots ,N_{\\mu})</span> special-sound protocol. Let <span class="math">(\\mathcal{P}^t,\\mathcal{V}^t)</span> be the <span class="math">t</span>-fold parallel repetition of protocol <span class="math">(\\mathcal{P},\\mathcal{V})</span>. Then <span class="math">(\\mathcal{P}^t,\\mathcal{V}^t)</span> is knowledge sound with knowledge error <span class="math">\\kappa^t</span>, where</p>

    <div class="my-4 text-center"><span class="math-block">\\kappa = 1 - \\prod_ {j = 1} ^ {\\mu} \\frac {N _ {j} - k _ {j} + 1}{N _ {j}},</span></div>

    <p class="text-gray-300">is the knowledge error of <span class="math">(\\mathcal{P},\\mathcal{V})</span>.</p>

    <p class="text-gray-300">Also here, the knowledge error <span class="math">\\kappa^t</span> coincides with the trivial cheating probability <span class="math">\\prod_{i}\\operatorname*{Pr}(\\neg \\Gamma_{i})</span>, which is potentially achievable for <span class="math">(k_{1},\\ldots ,k_{\\mu})</span>-out-of-<span class="math">(N_{1},\\ldots ,N_{\\mu})</span> special-sound protocols.</p>

    <p class="text-gray-300">The knowledge error <span class="math">\\kappa^t</span> of the <span class="math">t</span>-fold parallel repetition <span class="math">(\\mathcal{P}^t,\\mathcal{V}^t)</span> of a <span class="math">\\mathbf{k}</span>-special-sound protocol <span class="math">(\\mathcal{P},\\mathcal{V})</span> decreases exponentially with <span class="math">t</span>. However, the completeness error of <span class="math">(\\mathcal{P}^t,\\mathcal{V}^t)</span> equals <span class="math">\\rho&#x27; = 1 - (1 - \\rho)^t</span>, where <span class="math">\\rho</span> is the completeness error of <span class="math">(\\mathcal{P},\\mathcal{V})</span>. Hence, if <span class="math">\\rho \\notin \\{0,1\\}</span>, the completeness error of <span class="math">(\\mathcal{P}^t,\\mathcal{V}^t)</span> increases quickly with <span class="math">t</span>. In order to decrease both the knowledge and the completeness error simultaneously, we consider a threshold parallel repetition. The <span class="math">s</span>-out-of-<span class="math">t</span> threshold parallel repetition of an interactive protocol <span class="math">(\\mathcal{P},\\mathcal{V})</span>, denoted by <span class="math">(\\mathcal{P}^{s,t},\\mathcal{V}^{s,t})</span>, runs <span class="math">t</span> instances of <span class="math">(\\mathcal{P},\\mathcal{V})</span> in parallel and <span class="math">\\mathcal{V}^{s,t}</span> accepts if at least <span class="math">s</span>-out-of-<span class="math">t</span> instances are accepted. In particular, it holds that <span class="math">(\\mathcal{P}^{t,t},\\mathcal{V}^{t,t}) = (\\mathcal{P}^t,\\mathcal{V}^t)</span>. In this section, we show that if <span class="math">(\\mathcal{P},\\mathcal{V})</span> is <span class="math">\\mathbf{k}</span>-special-sound then <span class="math">(\\mathcal{P}^{s,t},\\mathcal{V}^{s,t})</span> is knowledge sound. We will immediately consider the general case of multi-round protocols.</p>

    <p class="text-gray-300">As in Section 4.2, we consider an algorithm <span class="math">\\mathcal{A}</span> that takes as input a row <span class="math">\\mathbf{c} = (\\mathbf{c}_1,\\dots ,\\mathbf{c}_t)</span> of columns <span class="math">\\mathbf{c}_i = (c_i^1,\\ldots ,c_i^\\mu)\\in \\mathcal{C}^{[1]}\\times \\dots \\times \\mathcal{C}^{[\\mu ]}</span> of challenges and outputs a string <span class="math">y</span>. However, this time we consider <span class="math">t</span> different verification functions</p>

    <div class="my-4 text-center"><span class="math-block">V _ {i} \\colon \\left(\\mathcal {C} ^ {[ 1 ]} \\times \\dots \\times \\mathcal {C} ^ {[ \\mu ]}\\right) ^ {t} \\times \\{0, 1 \\} ^ {*} \\to \\{0, 1 \\},</span></div>

    <p class="text-gray-300">together with one additional threshold verification function defined as follows:</p>

    <div class="my-4 text-center"><span class="math-block">V (\\mathbf {c}, y) = \\left\\{ \\begin{array}{l l} 1 &amp;amp; \\text {if} \\sum_ {i = 1} ^ {t} V _ {i} (\\mathbf {c}, y) \\geq s, \\\\ 0 &amp;amp; \\text {otherwise}. \\end{array} \\right.</span></div>

    <p class="text-gray-300">The obvious instantiation for <span class="math">\\mathcal{A}</span> is a deterministic dishonest prover <span class="math">\\mathcal{P}^*</span> attacking <span class="math">(\\mathcal{P}^{s,t},\\mathcal{V}^{s,t})</span>. This instantiation defines <span class="math">V_{i}</span> as the verification that the <span class="math">i</span>-th instance of <span class="math">\\mathcal{V}</span> performs. The verification function <span class="math">V</span> then captures the verification that <span class="math">\\mathcal{V}^{s,t}</span> performs.</p>

    <p class="text-gray-300">As before, such <span class="math">\\mathcal{A}</span> induces <span class="math">t</span> algorithms <span class="math">\\mathcal{A}_1,\\ldots ,\\mathcal{A}_t</span> as considered in the context of a single execution of <span class="math">(\\mathcal{P},\\mathcal{V})</span>, taking one challenge-column as input and outputting one string: on input <span class="math">\\mathbf{c}_i</span>, the algorithm <span class="math">\\mathcal{A}_i</span> runs <span class="math">y\\gets \\mathcal{A}(\\mathbf{c}_1,\\dots ,\\mathbf{c}_t)</span> with <span class="math">\\mathbf{c}_j</span> chosen uniformly at random from <span class="math">\\mathcal{C}^{[1]}\\times \\dots \\times \\mathcal{C}^{[\\mu ]}</span> for <span class="math">j\\neq i</span>, and outputs <span class="math">y</span> along with the <span class="math">\\mathbf{c}_j</span>'s for <span class="math">j\\neq i</span>. For each <span class="math">\\mathcal{A}_i</span>, we can run the extractor from Lemma 4, which succeeds with probability at least</p>

    <div class="my-4 text-center"><span class="math-block">\\frac {\\delta_ {\\mathbf {k}} ^ {V _ {i}} \\left(\\mathcal {A} _ {i}\\right)}{\\prod_ {i = 1} ^ {\\mu} k _ {i}} = \\min  _ {S _ {i} ^ {[ 1 ]}, S _ {i} ^ {[ 2 ]} (\\cdot), \\dots , S _ {i} ^ {[ \\mu ]} (\\cdot)} \\frac {\\Pr \\left(V _ {i} \\left(C _ {i} , \\mathcal {A} _ {i} \\left(C _ {i}\\right)\\right) = 1 \\mid \\begin{array}{l} C _ {i} ^ {1} \\notin S _ {i} ^ {[ 1 ]} \\wedge C _ {i} ^ {2} \\notin S _ {i} ^ {[ 2 ]} \\left(C _ {i} ^ {1}\\right) \\wedge \\\\ \\dots \\wedge C _ {i} ^ {\\mu} \\notin S _ {i} ^ {[ \\mu ]} \\left(C _ {i} ^ {1}, \\dots , C _ {i} ^ {\\mu - 1}\\right) \\end{array}\\right)}{\\prod_ {i = 1} ^ {\\mu} k _ {i}}, \\tag {7}</span></div>

    <p class="text-gray-300">where <span class="math">V_{i}</span> is understood to appropriately reorder its inputs. The following lemma is a generalization of Lemma 5 and it allows us to bound the probability that at least one of the extractors <span class="math">\\mathcal{E}^{\\mathcal{A}_i}</span> succeeds.</p>

    <p class="text-gray-300">Lemma 6. Let <span class="math">\\mathbf{k} \\in \\mathbb{N}^{\\mu}</span>, <span class="math">t \\in \\mathbb{N}</span>, <span class="math">\\mathcal{C}^{[1]}, \\ldots, \\mathcal{C}^{[\\mu]}</span> finite sets <span class="math">\\mathcal{C}^{[j]}</span> with cardinality <span class="math">N_{j} \\geq k_{j}</span> and <span class="math">\\mathcal{A}</span> a (probabilistic) algorithm that takes as input a row <span class="math">(\\mathbf{c}_{1}, \\ldots, \\mathbf{c}_{t})</span> of columns <span class="math">\\mathbf{c}_{i} = (c_{i}^{1}, \\ldots, c_{i}^{\\mu}) \\in \\mathcal{C}^{[1]} \\times \\dots \\times \\mathcal{C}^{[\\mu]}</span> and outputs a string <span class="math">y \\in \\{0, 1\\}^{*}</span>.</p>

    <p class="text-gray-300">Then</p>

    <p class="text-gray-300"><span class="math">\\sum_{i=1}^{t}\\delta_{\\mathbf{k}}^{V_{i}}(\\mathcal{A}_{i})\\geq\\frac{\\epsilon^{V}(\\mathcal{A})-\\kappa^{s,t}}{1-\\kappa}\\,,</span></p>

    <p class="text-gray-300">where</p>

    <p class="text-gray-300"><span class="math">\\kappa^{s,t}=\\sum_{\\ell=s}^{t}\\binom{t}{\\ell}\\kappa^{\\ell}(1-\\kappa)^{t-\\ell}\\quad\\text{and}\\quad\\kappa=1-\\prod_{j=1}^{\\mu}\\frac{N_{j}-k_{j}+1}{N_{j}}\\,.</span></p>

    <p class="text-gray-300">Note that <span class="math">\\kappa^{s,t}</span> is the probability of being successful at least <span class="math">s</span> times when given <span class="math">t</span> trials, when each trial is successful with independent probability <span class="math">\\kappa</span>.</p>

    <h6 id="sec-37" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">For <span class="math">1\\leq i\\leq t</span>, let <span class="math">\\Lambda_{i}</span> denote the event <span class="math">V_{i}(C,\\mathcal{A}_{i}(C))=1</span> and let <span class="math">S_{i}^{[1]}</span> and <span class="math">S_{i}^{[2]}(\\cdot)\\dots,S_{i}^{[\\mu]}(\\cdot)</span> such that they minimize Equation 7. Moreover, let <span class="math">\\Gamma_{i}</span> denote the event</p>

    <p class="text-gray-300"><span class="math">C_{i}^{1}\\notin S_{i}^{[1]}\\wedge C_{i}^{2}\\notin S_{i}^{[2]}(C_{i}^{1})\\wedge\\dots\\wedge C_{i}^{\\mu}\\notin S_{i}^{[\\mu]}(C_{i}^{1},\\dots,C_{i}^{\\mu-1})\\,.</span></p>

    <p class="text-gray-300">Then, for all <span class="math">1\\leq i\\leq t</span>,</p>

    <p class="text-gray-300"><span class="math">\\Pr(\\Gamma_{i})=\\prod_{j=1}^{\\mu}\\frac{N-k_{j}+1}{N}=1-\\kappa\\,.</span></p>

    <p class="text-gray-300">Moreover, using elementary probability theory,</p>

    <p class="text-gray-300"><span class="math">\\sum_{i=1}^{t}\\delta_{\\mathbf{k}}^{V_{i}}(\\mathcal{A}_{i})</span> <span class="math">=\\sum_{i=1}^{t}\\Pr\\big{(}\\Lambda_{i}\\mid\\Gamma_{i}\\big{)}=\\sum_{i=1}^{t}\\frac{\\Pr\\big{(}\\Lambda_{i}\\wedge\\Gamma_{i}\\big{)}}{\\Pr\\big{(}\\Gamma_{i}\\big{)}}=\\sum_{i=1}^{t}\\frac{\\Pr\\big{(}\\Lambda_{i}\\wedge\\Gamma_{i}\\big{)}}{1-\\kappa}</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\geq\\frac{\\Pr\\big{(}\\exists\\,i:\\Lambda_{i}\\wedge\\Gamma_{i}\\big{)}}{1-\\kappa}\\geq\\frac{\\Pr\\big{(}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\{i:\\Lambda_{i}\\}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq s\\wedge</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\{i:\\Gamma_{i}\\}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq t-s+1\\big{)}}{1-\\kappa}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">which completes the proof. ∎</p>

    <p class="text-gray-300">As before (see Equation 3), it follows that the probability of at least one of the extractors <span class="math">\\mathcal{E}^{\\mathcal{A}_{i}}</span> being successful is at least</p>

    <p class="text-gray-300"><span class="math">\\frac{\\Delta}{2}\\geq\\frac{\\epsilon^{V}(\\mathcal{A})-\\kappa^{s,t}}{2K(1-\\kappa)}\\,,</span></p>

    <p class="text-gray-300">where <span class="math">\\Delta=\\min\\big{(}1,\\sum_{i=1}^{t}\\delta_{\\mathbf{k}}^{V_{i}}(\\mathcal{A}_{i})/K\\big{)}</span> and <span class="math">K=\\prod_{i=1}^{\\mu}k_{i}.</span> This gives us the following threshold parallel repetition result for <span class="math">(k_{1},\\dots,k_{\\mu})</span>-special-sound protocols.</p>

    <h6 id="sec-38" class="text-base font-medium mt-4">Theorem 5 (Threshold Parallel Repetition Theorem).</h6>

    <p class="text-gray-300">Let <span class="math">(\\mathcal{P},\\mathcal{V})</span> be a <span class="math">(k_{1},\\dots,k_{\\mu})</span>-out-of-<span class="math">(N_{1},\\dots,N_{\\mu})</span> special-sound protocol. Let <span class="math">(\\mathcal{P}^{s,t},\\mathcal{V}^{s,t})</span> be the <span class="math">s</span>-out-of-<span class="math">t</span> threshold parallel repetition of protocol <span class="math">(\\mathcal{P},\\mathcal{V})</span>. Then <span class="math">(\\mathcal{P}^{s,t},\\mathcal{V}^{s,t})</span> is knowledge sound with knowledge error</p>

    <p class="text-gray-300"><span class="math">\\kappa^{s,t}=\\sum_{\\ell=s}^{t}\\binom{t}{\\ell}\\kappa^{\\ell}(1-\\kappa)^{t-\\ell}\\,,</span></p>

    <p class="text-gray-300">where</p>

    <p class="text-gray-300"><span class="math">\\kappa=1-\\prod_{j=1}^{\\mu}\\frac{N_{j}-k_{j}+1}{N_{j}}\\,,</span></p>

    <p class="text-gray-300">is the knowledge error of <span class="math">(\\mathcal{P},\\mathcal{V})</span>.</p>

    <p class="text-gray-300">As before, the knowledge error <span class="math">\\kappa^{s,t}</span> coincides with the trivial cheating probability for <span class="math">(\\mathcal{P}^{s,t},\\mathcal{V}^{s,t})</span>, confirming the tightness of Theorem 5.</p>

    <p class="text-gray-300">Note that the completeness error of <span class="math">(\\mathcal{P}^{s,t},\\mathcal{V}^{s,t})</span> equals</p>

    <p class="text-gray-300"><span class="math">\\rho^{s,t}=\\sum_{\\ell=0}^{s-1}\\binom{t}{\\ell}\\rho^{t-\\ell}(1-\\rho)^{\\ell}\\,.</span></p>

    <p class="text-gray-300">Hence, the completeness error <span class="math">\\rho^{s,t}</span> increases and the knowledge error decreases <span class="math">\\kappa^{s,t}</span> in <span class="math">s</span>. Moreover, it is easily seen that for <span class="math">t</span> large enough and <span class="math">\\kappa\\cdot t&lt;s&lt;(1-\\rho)t</span> the threshold parallel repetition <span class="math">(\\mathcal{P}^{s,t},\\mathcal{V}^{s,t})</span> has a smaller knowledge and a smaller completeness error than <span class="math">(\\mathcal{P},\\mathcal{V})</span>, i.e., <span class="math">\\kappa^{s,t}&lt;\\kappa</span> and <span class="math">\\rho^{s,t}&lt;\\rho</span>. In contrast to standard parallel repetition, threshold parallel repetition therefore allows both these errors to be reduced.</p>

    <h2 id="sec-39" class="text-2xl font-bold">6 Acknowledgments</h2>

    <p class="text-gray-300">We would like to thank Michael Klooß for helpful comments and insightful discussions. The first author has been supported by EU H2020 project No. 780701 (PROMETHEUS) and the Vraaggestuurd Programma Cyber Security & Resilience, part of the Dutch Top Sector High Tech Systems and Materials program.</p>

    <h2 id="sec-40" class="text-2xl font-bold">References</h2>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[1] Attema, T., Cramer, R.: Compressed <span class="math">\\Sigma</span>-protocol theory and practical application to plug & play secure algorithmics. In: Micciancio, D., Ristenpart, T. (eds.) CRYPTO 2020, Part III. LNCS, vol. 12172, pp. 513–543. Springer, Heidelberg (Aug 2020)</li>

      <li>[2] Attema, T., Cramer, R., Fehr, S.: Compressing proofs of k-out-of-n partial knowledge. In: Malkin, T., Peikert, C. (eds.) CRYPTO 2021, Part IV. LNCS, vol. 12828, pp. 65–91. Springer, Heidelberg, Virtual Event (Aug 2021)</li>

      <li>[3] Attema, T., Cramer, R., Kohl, L.: A compressed <span class="math">\\Sigma</span>-protocol theory for lattices. In: Malkin, T., Peikert, C. (eds.) CRYPTO 2021, Part II. LNCS, vol. 12826, pp. 549–579. Springer, Heidelberg, Virtual Event (Aug 2021)</li>

      <li>[4] Attema, T., Cramer, R., Rambaud, M.: Compressed <span class="math">\\Sigma</span>-protocols for bilinear group arithmetic circuits and application to logarithmic transparent threshold signatures. In: ASIACRYPT 2021. Lecture Notes in Computer Science, vol. 13093, pp. 526–556. Springer (Dec 2021)</li>

      <li>[5] Attema, T., Cramer, R., Xing, C.: A note on short invertible ring elements and applications to cyclotomic and trinomials number fields. Mathematical Cryptology pp. 45–70 (2021)</li>

      <li>[6] Bellare, M., Goldreich, O.: On defining proofs of knowledge. In: Brickell, E.F. (ed.) CRYPTO’92. LNCS, vol. 740, pp. 390–420. Springer, Heidelberg (Aug 1993)</li>

      <li>[7] Bellare, M., Impagliazzo, R., Naor, M.: Does parallel repetition lower the error in computationally sound protocols? In: 38th FOCS. pp. 374–383. IEEE Computer Society Press (Oct 1997)</li>

      <li>[8] Bootle, J., Cerulli, A., Chaidos, P., Groth, J., Petit, C.: Efficient zero-knowledge arguments for arithmetic circuits in the discrete log setting. In: Fischlin, M., Coron, J.S. (eds.) EUROCRYPT 2016, Part II. LNCS, vol. 9666, pp. 327–357. Springer, Heidelberg (May 2016)</li>

      <li>[9] Bootle, J., Lyubashevsky, V., Nguyen, N.K., Seiler, G.: A non-PCP approach to succinct quantum-safe zero-knowledge. In: Micciancio, D., Ristenpart, T. (eds.) CRYPTO 2020, Part II. LNCS, vol. 12171, pp. 441–469. Springer, Heidelberg (Aug 2020)</li>

      <li>[10] Bünz, B., Bootle, J., Boneh, D., Poelstra, A., Wuille, P., Maxwell, G.: Bulletproofs: Short proofs for confidential transactions and more. In: 2018 IEEE Symposium on Security and Privacy. pp. 315–334. IEEE Computer Society Press (May 2018)</li>

      <li>[11] Bünz, B., Fisch, B., Szepieniec, A.: Transparent SNARKs from DARK compilers. In: Canteaut, A., Ishai, Y. (eds.) EUROCRYPT 2020, Part I. LNCS, vol. 12105, pp. 677–706. Springer, Heidelberg (May 2020)</li>

      <li>[12] Chung, K.M., Liu, F.H.: Parallel repetition theorems for interactive arguments. In: Micciancio, D. (ed.) TCC 2010. LNCS, vol. 5978, pp. 19–36. Springer, Heidelberg (Feb 2010)</li>

      <li>[13] Chung, K.M., Pass, R.: Tight parallel repetition theorems for public-coin arguments using KL-divergence. In: Dodis, Y., Nielsen, J.B. (eds.) TCC 2015, Part II. LNCS, vol. 9015, pp. 229–246. Springer, Heidelberg (Mar 2015)</li>

      <li>[14] Faonio, A., Nielsen, J.B., Venturi, D.: Predictable arguments of knowledge. In: Fehr, S. (ed.) PKC 2017, Part I. LNCS, vol. 10174, pp. 121–150. Springer, Heidelberg (Mar 2017)</li>

      <li>[15] Goldreich, O.: Modern Cryptography, Probabilistic Proofs and Pseudorandomness, Algorithms and Combinatorics, vol. 17. Springer (1998)</li>

      <li>[16] Goldreich, O.: Foundations of Cryptography: Basic Tools, vol. 1. Cambridge University Press, Cambridge, UK (2001)</li>

      <li>[17] Goldwasser, S., Micali, S., Rackoff, C.: The knowledge complexity of interactive proof-systems (extended abstract). In: 17th ACM STOC. pp. 291–304. ACM Press (May 1985)</li>

      <li>[18] Haitner, I.: A parallel repetition theorem for any interactive argument. In: 50th FOCS. pp. 241–250. IEEE Computer Society Press (Oct 2009)</li>

      <li>[</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[19] Håstad, J., Pass, R., Wikström, D., Pietrzak, K.: An efficient parallel repetition theorem. In: Micciancio, D. (ed.) TCC 2010. LNCS, vol. 5978, pp. 1–18. Springer, Heidelberg (Feb 2010)</li>

      <li>[20] Hazay, C., Lindell, Y.: Efficient Secure Two-Party Protocols - Techniques and Constructions. ISC, Springer, Heidelberg (2010)</li>

      <li>[21] Lyubashevsky, V., Seiler, G.: Short, invertible elements in partially splitting cyclotomic rings and applications to lattice-based zero-knowledge proofs. In: Nielsen, J.B., Rijmen, V. (eds.) EUROCRYPT 2018, Part I. LNCS, vol. 10820, pp. 204–224. Springer, Heidelberg (Apr / May 2018)</li>

      <li>[22] Maller, M., Bowe, S., Kohlweiss, M., Meiklejohn, S.: Sonic: Zero-knowledge SNARKs from linear-size universal and updatable structured reference strings. In: Cavallaro, L., Kinder, J., Wang, X., Katz, J. (eds.) ACM CCS 2019. pp. 2111–2128. ACM Press (Nov 2019)</li>

      <li>[23] Pass, R., Venkitasubramaniam, M.: An efficient parallel repetition theorem for Arthur-Merlin games. In: Johnson, D.S., Feige, U. (eds.) 39th ACM STOC. pp. 420–429. ACM Press (Jun 2007)</li>

      <li>[24] Rotem, L., Segev, G.: Tighter security for schnorr identification and signatures: A high-moment forking lemma for <span class="math">\\Sigma</span>-protocols. In: Malkin, T., Peikert, C. (eds.) CRYPTO 2021, Part I. LNCS, vol. 12825, pp. 222–250. Springer, Heidelberg, Virtual Event (Aug 2021)</li>

      <li>[25] Unruh, D.: Quantum proofs of knowledge. In: Pointcheval, D., Johansson, T. (eds.) EUROCRYPT 2012. LNCS, vol. 7237, pp. 135–152. Springer, Heidelberg (Apr 2012)</li>

    </ul>`;
---

<BaseLayout title="Parallel Repetition of $(k_1,\dots,k_{\mu})$-Special-Sound M... (2021/1259)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2021 &middot; eprint 2021/1259
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
