---
import BaseLayout from '../../layouts/BaseLayout.astro';
import PaperDisclaimer from '../../components/PaperDisclaimer.astro';
import PaperHistory from '../../components/PaperHistory.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2004/331';
const CRAWLER = 'modal-marker';
const CONVERTED_DATE = '2026-02-17';
const TITLE_HTML = '**Code-Based Game-Playing Proofs and the Security of Triple Encryption**';
const AUTHORS_HTML = 'Mihir Bellare &lt;sup&gt;∗&lt;/sup&gt; Phillip Rogaway †';

const CONTENT = `    <p class="text-gray-300">The proceedings version of this papers, entitled <em>The Security of Triple Encryption and a Framework for Code-Based Game-Playing Proofs</em>, appears in <em>Advances in Cryptology – Eurocrypt 2006</em>, LNCS vol. 4004, Springer, pp. 409–426, 2006. This is the full version of the paper.</p>

    <p class="text-gray-300">Mihir Bellare &lt;sup&gt;∗&lt;/sup&gt; Phillip Rogaway †</p>

    <p class="text-gray-300">November 27, 2008</p>

    <p class="text-gray-300">(Draft 3.0)</p>

    <h4 id="sec-1" class="text-lg font-semibold mt-6"><strong>Abstract</strong></h4>

    <p class="text-gray-300">The game-playing technique is a powerful tool for analyzing cryptographic constructions. We illustrate this by using games as the central tool for proving security of three-key tripleencryption, a long-standing open problem. Our result, which is in the ideal-cipher model, demonstrates that for DES parameters (56-bit keys and 64-bit plaintexts) an adversary's maximal advantage is small until it asks about 2&lt;sup&gt;78&lt;/sup&gt; queries. Beyond this application, we develop the foundations for game playing, formalizing a general framework for game-playing proofs and discussing techniques used within such proofs. To further exercise the game-playing framework we show how to use games to get simple proofs for the PRP/PRF Switching Lemma, the security of the basic CBC MAC, and the chosen-plaintext-attack security of OAEP.</p>

    <p class="text-gray-300"><strong>Keywords:</strong> Cryptographic analysis techniques, games, provable security, triple encryption.</p>

    <p class="text-gray-300">&lt;sup&gt;∗&lt;/sup&gt;Department of Computer Science &amp; Engineering, University of California at San Diego, 9500 Gilman Drive, La Jolla, California 92093 USA. E-mail: mihir@cs.ucsd.edu WWW: www.cse.ucsd.edu/users/mihir/</p>

    <p class="text-gray-300">&lt;sup&gt;†&lt;/sup&gt;Department of Computer Science, University of California at Davis, Davis, California, 95616, USA; and Department of Computer Science, Faculty of Science, Chiang Mai University, Chiang Mai 50200, Thailand. E-mail: rogaway@cs.ucdavis.edu WWW: www.cs.ucdavis.edu/∼rogaway/</p>

    <h2 id="sec-2" class="text-2xl font-bold"><strong>Contents</strong></h2>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">1</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Introduction</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">3</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">The PRP/PRF Switching Lemma</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">The Game-Playing Framework</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">9</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">The Security of Three-Key Triple-Encryption&lt;br&gt;4.1&lt;br&gt;Definitions&lt;br&gt;4.2&lt;br&gt;Results&lt;br&gt;4.3&lt;br&gt;Reduction to simplified adversary&lt;br&gt;4.4&lt;br&gt;Pseudorandomness of three correlated permutations&lt;br&gt;&lt;br&gt;&lt;br&gt;4.5&lt;br&gt;The improbability of forming a 3-chain&lt;br&gt;&lt;br&gt;4.6&lt;br&gt;Putting together the pieces to conclude Theorem 4&lt;br&gt;&lt;br&gt;4.7&lt;br&gt;Proof of Lemma 6&lt;br&gt;&lt;br&gt;4.8&lt;br&gt;Proof of Lemma 7&lt;br&gt;</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">14&lt;br&gt;14&lt;br&gt;14&lt;br&gt;15&lt;br&gt;17&lt;br&gt;18&lt;br&gt;18&lt;br&gt;19&lt;br&gt;23</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Elementary Proof for the CBC MAC</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">25</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">A Game-Based Proof for OAEP</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">28</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Game-Rewriting Techniques&lt;br&gt;7.1&lt;br&gt;Game chains&lt;br&gt;&lt;br&gt;7.2&lt;br&gt;Basic techniques&lt;br&gt;&lt;br&gt;7.3&lt;br&gt;Coin fixing&lt;br&gt;&lt;br&gt;7.4&lt;br&gt;Lazy sampling&lt;br&gt;&lt;br&gt;</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">32&lt;br&gt;32&lt;br&gt;33&lt;br&gt;34&lt;br&gt;35</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Acknowledgments</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">37</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">References</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">37</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">A</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Fixing the PRP/PRF Switching Lemma Without Games</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">39</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">B</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">An Example Programming Language for Games</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">40</td>
          </tr>
        </tbody>
      </table>
    </div>

    <h3 id="sec-3" class="text-xl font-semibold mt-8">1 Introduction</h3>

    <p class="text-gray-300">FOUNDATIONS AND APPLICATIONS. The game-playing technique has become a popular approach for doing proofs in cryptography. We will explain the method shortly. In this paper we take the initial steps in developing a theory of game-playing proofs. We believe that such a theory will prove beneficial for our field. Then we demonstrate the utility of game-playing by providing examples of the technique, the most striking of which is the first proof that triple-encryption (using three independent keys) is far more secure than single or double encryption. The result, which is in the ideal-cipher model, is the first to prove that the cascade of blockciphers can markedly improve security. Other examples that we work out with games include the PRP/PRF Switching Lemma, the PRF-security of the CBC MAC, and the chosen-plaintext-attack security for OAEP.</p>

    <p class="text-gray-300">Why games? There are several reasons why we take a fresh look at the game-playing technique. First, the method is widely applicable, easily employed, and provides a unifying structure for diverse proofs. Games can be used in the standard model, the random-oracle model, the ideal-blockcipher model, and more; in the symmetric setting, the public-key setting, and further trust models; for simple schemes (eg, justifying the Carter-Wegman MAC) and complex protocols (eg, proving the correctness of a key-distribution protocol).</p>

    <p class="text-gray-300">Second, the game-playing technique can lead to significant new results. We demonstrate this by developing a game-based proof for three-key triple encryption. Proving security for triple encryption is a well-known problem, but technical difficulties have always frustrated attempts at a solution.</p>

    <p class="text-gray-300">Finally, we believe that the game-playing approach can lead to proofs that are less errorprone and more easily verifiable, even mechanically verifiable, than proofs grounded solely in more conventional probabilistic language. In our opinion, many proofs in cryptography have become essentially unverifiable. Our field may be approaching a crisis of rigor. While game-playing is not a panacea to this problem (which has at its core a significant cultural element), game-playing may play a role in the answer.</p>

    <p class="text-gray-300">THE CASCADE CONSTRUCTION. The security of the cascade construction, where two or more independently keyed blockciphers are composed with one another, is a nearly 30-year-old problem [19, 36]. Even and Goldreich refer to it as a &quot;critical question&quot; in cryptography [21, p. 109]. They showed that the cascade of ciphers is at least as strong as the weakest cipher in the chain [21], while Maurer and Massey showed that, in a weaker attack model, it is at least as strong as the first cipher in the chain. We know that double encryption (the two-stage cascade) can't strengthen security much, due to the classic meet-in-the-middle attack [19], although Aiello, Bellare, Di Creczenzo, and Venkatesan show that the &quot;shape&quot; of the security curve is slightly improved [3]. This means that triple encryption (the three-stage cascade) is the shortest potentially &quot;good&quot; cascade. And, indeed, triple DES is the cascade that is widely standardized and used [38].</p>

    <p class="text-gray-300">TRIPLE ENCRYPTION &quot;WORKS.&quot; In this paper we prove that triple-encryption vastly improves security over single or double encryption. Given a blockcipher  <span class="math">E: \\{0,1\\}^k \\times \\{0,1\\}^n \\to \\{0,1\\}^n</span>  with inverse D we consider  <span class="math">\\mathsf{Cascade}_E^{\\mathsf{eee}}(K_0K_1K_2, X) = E_{K_2}(E_{K_1}(E_{K_0}(X)))</span>  and  <span class="math">\\mathsf{Cascade}_E^{\\mathsf{ede}}(K_0K_1K_2, X) = E_{K_2}(D_{K_1}(E_{K_0}(X)))</span> . Our results are the same for both versions of triple encryption. Following [22, 32, 44], we model E as a family of random permutations, one for each key, and we provide the adversary with oracle access to the blockcipher  <span class="math">E(\\cdot, \\cdot)</span>  and its inverse  <span class="math">E^{-1}(\\cdot, \\cdot)</span>  Given such oracles, the adversary is asked to distinguish between (a)  <span class="math">\\mathsf{Cascade}_E^{\\mathsf{eee}}(K_0K_1K_2, \\cdot)</span>  and its inverse, for a random key  <span class="math">K_0K_1K_2</span> , and (b) a random permutation on n bits and its inverse. We show that the adversary's advantage in making this determination,  <span class="math">\\mathsf{Adv}_{k,n}^{\\mathsf{eee}}(q)</span> , remains small until it asks about  <span class="math">q = 2^{k+0.5 \\, \\mathrm{min}\\{k,n\\}}</span>  queries (the actual expression is more complex). The bound we get is</p>

    <p class="text-gray-300">    <img src="_page_3_Figure_0.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Figure 1: Upper bound on adversarial advantage (proven security) verses log&lt;sup&gt;2&lt;/sup&gt; q (where q=number of queries) for the cascade construction, assuming key length k = 56 and block length n = 64. Single encryption is the leftmost curve, double encryption is the middle curve [3], and triple encryption in the rightmost curve, as given by Theorem 4.</p>

    <p class="text-gray-300">plotted as the rightmost curve of Figure 1 for DES parameters k = 56 and n = 64. In this case an adversary must ask more than 277.&lt;sup&gt;79&lt;/sup&gt; queries to get advantage 0.5. Also plotted are the security curves for single and double encryption, where the adversary must ask 2&lt;sup&gt;55&lt;/sup&gt; and 255.&lt;sup&gt;5&lt;/sup&gt; queries to get advantage 0.5. For a blockcipher with k = n = 64, the adversary must about 2&lt;sup&gt;89&lt;/sup&gt; queries to get advantage 0.5. As there are matching attacks and security bounds for single and double encryption, our result proves that, in the ideal-cipher model, triple encryption is more secure than single or double encryption.</p>

    <p class="text-gray-300">Our proof for triple-encryption uses game-playing in an integral way, first to recast the advantage we wish to bound to a simpler game, and later to analyze that game by investigating another one. Ultimately one is left with a game where conventional probabilistic reasoning (a special-purpose occupancy bound) can be applied. Game playing does not replace conventional probabilistic reasoning; it supplements it.</p>

    <p class="text-gray-300">As for the cascade of - ≥ 4 blockciphers, the maximal advantage in our attack model is no worse than it is for triple encryption, so our result proves that cascade &quot;works&quot; (provides improved security over single and double encryption) for all - ≥ 3. It is an open question if security actually increases with increasing -.</p>

    <p class="text-gray-300">What is the game-playing technique? One complication in any discussion about gameplaying proofs is that the term means different things to different people. To some, a game-playing proof in cryptography is any proof where one conceptualizes the adversary's interaction with its environment as a kind of game, the proof proceeding by stepwise refinement to that game. Viewed in this way, game-playing proofs have their origin in the earliest hybrid arguments, which began with Goldwasser and Micali [25] and Yao [50]. Bellare and Goldwasser provide an early example of an intricate proof of this flavor, demonstrating the security of a signature scheme that uses multiple cryptographic primitives [4]. In recent years Shoup has come to use such game-based proofs extensively [1, 16–18, 43, 45, 46, 48], as have other authors.</p>

    <p class="text-gray-300">We believe that game-playing proofs can be most effectively studied and systematized by imposing some discipline on the process and, in particular, regarding games as code. This viewpoint begins in 1994 with Kilian and Rogaway [32]. Code-based game-playing soon became the favored technique of Rogaway, who, along with coauthors, used it in many subsequent papers [6, 10, 12– 14, 27, 28, 40–42]. Code-based game-playing typically works like this. Suppose you wish to upper bound the advantage of an adversary A in attacking some cryptographic construction. This is the difference between the probability that A outputs 1 in each of two different &quot;worlds.&quot; First, write some code—a game—that captures the behavior of world 0. The code initializes variables, interacts with the adversary, and then runs some more. Then write another piece of code—a second game—that captures the behavior of world 1. Arrange that games 0 and 1 are <em>syntactically identical</em> apart from statements that follow the setting of a flag <em>bad</em> to true. Now invoke the &quot;fundamental lemma of game playing&quot; (which we formalize and prove in this paper) to say that, in this setup, the adversary's advantage is upper-bounded by the probability that <em>bad</em> gets set (in either game). Next, choose one of the two games and slowly transform it, modifying it in ways that increase or leave unchanged the probability that <em>bad</em> gets set, or decrease the probability that <em>bad</em> gets set by a bounded amount. In this way you produce a <em>chain</em> of games, ending at some <em>terminal</em> game. Bound the probability that <em>bad</em> gets set in the terminal game using conventional (not game-based) techniques.</p>

    <p class="text-gray-300">Formalizing the foundations. In our treatment games are code and not abstract environments; as we develop it, game-playing centers around making disciplined transformations to code. The code can be written in pseudocode or a formalized programming language L. We will describe a sample programming language for writing games, using it (apart from some &quot;syntactic sugar&quot;) in our examples.</p>

    <p class="text-gray-300">Under our framework, a game G is a program that is <em>run</em> with an adversary A, which is also a program (look ahead to Figure 3). The adversary calls out to procedures, called <em>oracles</em>, specified by the game. We define what it means for two games to be identical-until-<em>bad</em>, where <em>bad</em> is a boolean variable in the game. This is a syntactical condition. We prove that if two games are identical-until-<em>bad</em> then the difference in the probabilities of a given outcome is bounded by the probability that <em>bad</em> gets set (in either game). This result, the <em>fundamental lemma of game-playing</em>, is the central tool justifying the technique.</p>

    <p class="text-gray-300">We go on to give describe some general lemmas and techniques for analyzing the probability that <em>bad</em> gets set. Principle among these is a lemma that lets you change anything you want after the flag <em>bad</em> gets set. Other techniques speak to eliminating adaptivity, de-randomization, making &quot;lazy&quot; probabilistic choices, resampling, using &quot;poisoned&quot; points, and so forth.</p>

    <p class="text-gray-300">Further applications. We illustrate the applicability of games in a wide variety of settings, providing results in the standard model, the random-oracle model [9], and the ideal-cipher model, and in both the symmetric and asymmetric settings.</p>

    <p class="text-gray-300">We begin with a motivating observation, due to Tadayoshi Kohno, that the standard proof of the PRP/PRF Switching Lemma ([30, Theorem 5.1], [5], and [29]) contains an error in reasoning about conditional probabilities. (The lemma says that an adversary that asks q queries can distinguish with advantage at most q2/2n+1 a random permutation on n-bits from a random function of nbits to n-bits.) We regard this as evidence that reasoning about cryptographic constructions via conditional probabilities can be subtle and error-prone even in the simplest of settings. This motivates our use of games as an alternative. We re-prove the Switching Lemma with a simple game-based proof.</p>

    <p class="text-gray-300">Next we look at the CBC MAC. Let <strong>Adv</strong>cbc n,m(q) denote the maximum advantage that an adversary restricted to making at most q oracle queries can obtain in distinguishing between (1) the m-block CBC MAC, keyed by a random permutation on n bits, and (2) a random function from mn-bits to n-bits. A result of Bellare, Kilian, and Rogaway [5] says that <strong>Adv</strong>cbc n,m(q) ≤ 2m2q2/2n. But the proof [5] is very complex and does not directly capture the intuition behind the security of the scheme. Here we use games to give an elementary proof for an m2q2/2&lt;sup&gt;n&lt;/sup&gt; bound, the proof directly capturing, in our view, the underlying intuition.</p>

    <p class="text-gray-300">Finally, we give an example of using games in the public-key, random-oracle setting by proving that OAEP [8] with any trapdoor permutation is an IND-CPA secure encryption scheme. The original proof of this result [8] was hard to follow or verify; the new proof is simpler and clearer, and illustrates the use of games in a computational rather than information-theoretic setting.</p>

    <p class="text-gray-300">FURTHER RELATED WORK. The best-known attack on three-key triple-encryption is due to Lucks [33]. He does not work out an explicit lower bound for  <span class="math">\\mathbf{Adv}_{k,n}^{\\text{eee}}(q)</span>  but in the case of triple-DES the advantage becomes large by  <span class="math">q=2^{90}</span>  queries. We prove security to about  <span class="math">2^{78}</span>  queries, so there is no contradiction</p>

    <p class="text-gray-300">The DESX construction has been proven secure up to about  <span class="math">2^{k+n-\\lg m}</span>  blockcipher queries for key length k, block length n, and m queries to the construction [32]. This is stronger than our bound for triple encryption when the adversary can obtain few points encrypted by the construction, a weaker bound otherwise.</p>

    <p class="text-gray-300">Double encryption and two-key triple encryption were analyzed Aiello, Bellare, Di Crescenzo, and Venkatesan [3], where it is shown that the meet-in-the-middle attack is optimal (in the ideal-cipher model). Their result is the first to show that the cascade construction buys you <em>something</em> (half a bit of security for advantage 0.5), but what it buys is inherently limited, because of the meet-in-the-middle attack. We comment that games provide an avenue to a much simpler proof of their result.</p>

    <p class="text-gray-300">With motivation similar to our own, Maurer develops a framework for the analysis of cryptographic constructions and applies it to the CBC MAC and other examples [34]. Vaudenay has likewise developed a framework for the analysis of blockciphers and blockcipher-based constructions, and has applied it to the encrypted CBC MAC [49]. Neither Maurer's nor Vaudenay's approach is geared towards making stepwise, code-directed refinements for computing a probability.</p>

    <p class="text-gray-300">A more limited and less formal version of the Fundamental Lemma appears in [6, Lemma 7.1]. A lemma by Shoup [45, Lemma 1] functions in a similar way for games that are not necessarily code-based.</p>

    <p class="text-gray-300">Shoup has independently and contemporaneously prepared a manuscript on game playing [47]. It is more pedagogically-oriented than this paper. Shoup does not try to develop a theory for game playing beyond [45, Lemma 1]. As with us, one of Shoup's examples is the PRP/PRF Switching Lemma.</p>

    <p class="text-gray-300">In response to a web distribution of this paper, Bernstein offers his own proof for the CBC MAC [11], re-obtaining the conventional bound. Bernstein sees no reason for games, and offers his own explanation for why cryptographic proofs are often complex and hard to verify: author incompetence with probability.</p>

    <p class="text-gray-300">In work derivative of an earlier version of this paper, Bellare, Pietrzak, and Rogaway [7] improve the bound  <span class="math">\\mathbf{Adv}_{n,m}^{\\text{cbc}}(q) \\leq m^2 q^2/2^n</span>  of [5, 34] to about  <span class="math">mq^2/2^n</span> , and consider generalizations to this claim as well. The proof of [7] springs from games, refining the game used here for the CBC MAC and then analyzing it using techniques derivative of [20].</p>

    <p class="text-gray-300">Following the web distribution of this paper, Halevi argues for the creation of an automated tool to help write and verify game-based proofs [26]. We agree. The possibility for such tools has always been one of our motivations, and one of the reasons why we focused on code-based games.</p>

    <p class="text-gray-300">Gaži and Maurer [24] pointed out a couple of bugs that we corrected in draft 3.0. Game H is now parameterized by a permutation S and a formerly missing factor of 3 now appears in the second terms of (14). A consequence is that the claimed bound for triple DES was reduced from  <span class="math">2^{78.5}</span>  to  <span class="math">2^{77.79}</span> . Gaži and Maurer also provide an alternative proof for the security of triple encryption using Maurer's framework [34] and extend the result to longer cascades.</p>

    <p class="text-gray-300">WHY SHOULD GAME-PLAYING WORK? It is fair to ask if anything is actually &quot;going on&quot; when using games—couldn't you recast everything into more conventional probabilistic language and drop all that ugly code? Our experience is that it does not work to do so. The kind of probabilistic statements and thought encouraged by the game-playing paradigm seems to be a better fit, for</p>

    <p class="text-gray-300">many cryptographic problems, than that which is encouraged by (just) defining random-variables, writing conventional probability expressions, conditioning, and the like. Part of the power of the approach stems from the fact that pseudocode is the most precise and easy-to-understand language we know for describing the sort of probabilistic, reactive environments encountered in cryptography, and by remaining in that domain to do ones reasoning you are better able to see what is happening, manipulate what is happening, and validate the changes.</p>

    <h2 id="sec-4" class="text-2xl font-bold">2 The PRP/PRF Switching Lemma</h2>

    <p class="text-gray-300">THE LEMMA. The natural and conventional assumption to make about a blockcipher is that it behaves as a pseudorandom permutation (PRP). However, it usually turns out to be easier to analyze the security of a blockcipher-based construction assuming the blockcipher is secure as a pseudorandom function (PRF). The gap is then bridged (meaning, a result about the security of the construct assuming the blockcipher is a PRP is obtained) using the following lemma. In what follows, we denote by  <span class="math">A^P \\Rightarrow 1</span>  the event that adversary A, equipped with an oracle P, outputs the bit 1. Let Perm(n) be the set of all permutations on  <span class="math">\\{0,1\\}^n</span>  and let Func(n) be the set of all functions from  <span class="math">\\{0,1\\}^n</span>  to  <span class="math">\\{0,1\\}^n</span> . We assume below that  <span class="math">\\pi</span>  is randomly sampled from Perm(n) and  <span class="math">\\rho</span>  is randomly sampled from Func(n).</p>

    <p class="text-gray-300"><strong>Lemma 1</strong> [PRP/PRF Switching Lemma] Let  <span class="math">n \\ge 1</span>  be an integer. Let A be an adversary that asks at most q oracle queries. Then</p>

    <p class="text-gray-300"><span class="math">$\\left|\\Pr\\left[A^{\\pi} \\Rightarrow 1\\right] - \\Pr\\left[A^{\\rho} \\Rightarrow 1\\right]\\right| \\leq \\frac{q(q-1)}{2^{n+1}}</span>$
.</p>

    <p class="text-gray-300">In this section we point to some subtleties in the &quot;standard&quot; proof of this widely used result, as given for example in [5, 29, 30], showing in particular that one of the claims made in these proofs is incorrect. We then show how to prove the lemma in a simple and correct way using games. This example provides a gentle introduction to the game-playing technique and a warning about perils of following ones intuition when dealing with conditional probability in provable-security cryptography.</p>

    <p class="text-gray-300">THE STANDARD PROOF. The standard analysis proceeds as follows. Let Coll (&quot;collision&quot;) be the event that A, interacting with oracle  <span class="math">\\rho \\stackrel{\\</span>}{\\leftarrow} \\operatorname{Func}(n)$ , asks distinct queries X and X' that return the same answer. Let DIST (&quot;distinct&quot;) be the complementary event. Now</p>

    <p class="text-gray-300"><span class="math">$\\Pr[A^{\\pi} \\Rightarrow 1] = \\Pr[A^{\\rho} \\Rightarrow 1 \\mid \\text{Dist}]</span>$
(1)</p>

    <p class="text-gray-300">since a random permutation is the same as a random function in which everything one obtains from distinct queries is distinct. Letting x be this common value and  <span class="math">y = \\Pr[A^{\\rho} \\Rightarrow 1 \\mid \\text{Coll}]</span>  we have</p>

    <p class="text-gray-300"><span class="math">$\\begin{aligned} |\\Pr[A^{\\pi} \\Rightarrow 1] - \\Pr[A^{\\rho} \\Rightarrow 1]| &amp;= |x - x \\Pr[\\text{Dist}] - y \\Pr[\\text{Coll}]| &amp;= |x(1 - \\Pr[\\text{Dist}]) - y \\Pr[\\text{Coll}]| \\\\ &amp;= |x \\Pr[\\text{Coll}] - y \\Pr[\\text{Coll}]| &amp;= |(x - y) \\Pr[\\text{Coll}]| \\leq \\Pr[\\text{Coll}] \\end{aligned}</span>$</p>

    <p class="text-gray-300">where the final inequality follows because  <span class="math">x, y \\in [0, 1]</span> . One next argues that  <span class="math">\\Pr[\\text{Coll}] \\leq q(q - 1)/2^{n+1}</span>  and so the Switching Lemma follows.</p>

    <p class="text-gray-300">Where is the error in the simple proof above? It's at equation (1): it needn't be the case that  <span class="math">\\Pr[A^{\\pi} \\Rightarrow 1] = \\Pr[A^{\\rho} \\Rightarrow 1 \\mid \\text{DIST}]</span> , and the sentence we gave by way of justification was mathematically meaningless. Here is a simple example to demonstrate that  <span class="math">\\Pr[A^{\\pi} \\Rightarrow 1]</span>  can be different from  <span class="math">\\Pr[A^{\\rho} \\Rightarrow 1 \\mid \\text{DIST}]</span> . Let n = 1 and consider the following adversary A with oracle  <span class="math">P: \\{0, 1\\} \\to \\{0, 1\\}</span> :</p>

    <h4 id="sec-5" class="text-lg font-semibold mt-6">procedure Adversary A</h4>

    <pre><code class="language-text">procedure P(X) Game S0
100 Y $
    ← {0, 1}n Game S1
101 if Y ∈ image(π) then bad ← true, Y $
                      ← image(π)
102 return π[X] ← Y
</code></pre>

    <p class="text-gray-300">Figure 2: Games used in the proof of the Switching Lemma. Game S&lt;sup&gt;1&lt;/sup&gt; includes the boxed statement and S&lt;sup&gt;0&lt;/sup&gt; doesn't.</p>

    <p class="text-gray-300">if
<span class="math">$P(0) = 0</span>$
then return 1
else if  <span class="math">P(1) = 1</span>  then return 1 else return 0</p>

    <p class="text-gray-300">We claim that</p>

    <p class="text-gray-300"><span class="math">$\\Pr[A^{\\pi} \\Rightarrow 1] = 1/2</span>$
and  <span class="math">\\Pr[A^{\\rho} \\Rightarrow 1 \\mid \\text{Dist}] = 2/3</span> .</p>

    <p class="text-gray-300">The first equation is true because there are two possibilities for (π(0), π(1)), namely (0, 1),(1, 0), and A returns 1 for one of them, namely (0, 1). On the other hand, there are four possibilities for (ρ(0), ρ(1)), namely (0, 0),(0, 1),(1, 0),(1, 1). The event A&lt;sup&gt;ρ&lt;/sup&gt; ⇒ 1 ∧ Dist is true for two of them, namely (0, 0),(0, 1), while the event Dist is true for three of them, namely (0, 0),(0, 1),(1, 0). Thus Pr[A&lt;sup&gt;ρ&lt;/sup&gt; ⇒ 1 ∧ Dist]/Pr[Dist]=2/3.</p>

    <p class="text-gray-300">Notice that the number of oracle queries made by the adversary of this counterexample varies, being either one or two, depending on the reply it receives to its first query. This turns out to be crucial in making equation (1) fail, in that if A always makes exactly q oracle queries (regardless of A's coins and the answers returned to its queries) then equation (1) is true. (This was pointed out by Kohno, and his argument is re-produced in Appendix A.) Since one can always first modify A to make exactly q queries without altering Pr[A&lt;sup&gt;ρ&lt;/sup&gt; ⇒ 1] or Pr[A&lt;sup&gt;π&lt;/sup&gt; ⇒ 1], we would be loath to say that the proofs in [5, 29, 30] are incorrect. But the authors make claim (1), and view it as &quot;obvious,&quot; without restricting the adversary to exactly q queries, masking a subtlety that is not apparent at a first (or even second) glance.</p>

    <p class="text-gray-300">The fact that one can write something like (1) and people assume this to be correct, and even obvious, suggests to us that the language of conditional probability may often be unsuitable for thinking about and dealing with the kind of probabilistic scenarios that arise in cryptography. Games may more directly capture the desired intuition. Let us use them to give a correct proof.</p>

    <p class="text-gray-300">Game-based proof. Assume without loss of generality (since A's oracle is deterministic) that A never asks an oracle query twice. We imagine answering A's queries by running one of two games. Instead of thinking of A as interacting with a random permutation oracle π $ ← Perm(n), think of it as interacting with the Game S&lt;sup&gt;1&lt;/sup&gt; shown in Figure 2. Instead of thinking of A as interacting with a random function oracle ρ $ ← Func(n), think of A as interacting with the game S&lt;sup&gt;0&lt;/sup&gt; shown in the same figure. Game S&lt;sup&gt;0&lt;/sup&gt; is game S&lt;sup&gt;1&lt;/sup&gt; without the boxed statement. By convention, the boolean variable <em>bad</em> is initialized to false while the array π begins everywhere undefined. The games make available to A an oracle which has a formal name, in this case P. Adversary A can query this oracle with a string X ∈ {0, 1}n, in which case the code following the procedure P(X) line is executed and the value in the return statement is provided to A as the response to its oracle query. As the game runs, we fill-in values of π[X] with n-bit strings. At any point in time, we let image(π) be the set of all n-bit strings Y such that π[X] = Y for some X. Let image(π) be the complement of this set relative to {0, 1}n. Let A&lt;sup&gt;S&lt;/sup&gt; ⇒ 1 denote the event that A outputs 1 in game S ∈ {S0, S1}.</p>

    <p class="text-gray-300">Notice that the adversary never sees the flag <em>bad</em>. The flag will play a central part in our analysis, but it is not something that the adversary can observe. It's only there for our bookkeeping. What <em>does</em> adversary A see as it plays game S0? Whatever query X it asks, the game returns a random</p>

    <p class="text-gray-300"><em>n</em>-bit string Y. So game  <span class="math">S_0</span>  perfectly simulates a random function  <span class="math">\\rho \\stackrel{\\</span>}{\\leftarrow} \\operatorname{Func}(n)$  (remember that the adversary isn't allowed to repeat a query) and  <span class="math">\\Pr[A^{\\rho} \\Rightarrow 1] = \\Pr[A^{S_0} \\Rightarrow 1]</span> . Similarly, if we're in game  <span class="math">S_1</span> , then what the adversary gets in response to each query X is a random point Y that has not already been returned to A. The behavior of a random permutation oracle is exactly this, too. (This is guaranteed by what we will call the &quot;principle of lazy sampling.&quot;) So  <span class="math">\\Pr[A^{\\pi} \\Rightarrow 1] = \\Pr[A^{S_1} \\Rightarrow 1]</span> . We complete the proof via the following chain of inequalities, the first of which we have just justified:</p>

    <p class="text-gray-300"><span class="math">$|\\Pr[A^{\\pi} \\Rightarrow 1] - \\Pr[A^{\\rho} \\Rightarrow 1]| = |\\Pr[A^{S_1} \\Rightarrow 1] - \\Pr[A^{S_0} \\Rightarrow 1]|</span>$</p>

    <p class="text-gray-300"><span class="math">$\\leq \\Pr[A^{S_0} \\text{ sets } bad]</span>$
(2)</p>

    <p class="text-gray-300"><span class="math">$\\leq q(q-1)/2^{n+1} . (3)</span>$</p>

    <p class="text-gray-300">Above, &quot; <span class="math">A^{S_0}</span>  sets bad&quot; refers to the event that the flag bad is set to true in the execution of A with game  <span class="math">S_0</span> . We justify (2) by appealing to the fundamental lemma of game playing (Lemma 2), which says that whenever two games are written so as to be syntactically identical except for things that immediately follow the setting of bad, the difference in the probabilities that A outputs 1 in the two games is bounded by the probability that bad is set in either game. (It actually says something a bit more general, as we will see.) We justify (3) by observing that, by the union bound, the probability that a Y will ever be in image( <span class="math">\\pi</span> ) at line 101 is at most  <span class="math">(1 + 2 + \\cdots + (q - 1))/2^n = q(q - 1)/2^{n+1}</span> . This completes the proof.</p>

    <p class="text-gray-300">Counter-example above fares in the game-playing proof. A computation shows that</p>

    <p class="text-gray-300"><span class="math">$\\Pr[A^{S_0} \\Rightarrow 1] = 3/4</span>$
,  <span class="math">\\Pr[A^{S_1} \\Rightarrow 1] = 1/2</span> , and  <span class="math">\\Pr[A^{S_0} \\text{ sets } bad] = 1/4</span> .</p>

    <p class="text-gray-300">So none of the equalities or inequalities that arose in the game-playing proof are violated.</p>

    <h2 id="sec-6" class="text-2xl font-bold">3 The Game-Playing Framework</h2>

    <p class="text-gray-300">PROGRAMMING LANGUAGE. A game is a program, viewed as a collection of procedures, and the adversary is likewise a program, but one consisting of a single procedure. We will, for the moment, regard games and adversaries as being written in pseudocode. Below we outline some elements of our pseudocode. We find that a pseudocode-based descriptive language is adequate to make game-playing unambiguous and productive. To make a truly rigorous theory one should, in fact, fully specify the underlying programming language. In Appendix B we provide an example language  <span class="math">\\mathcal L</span>  suitable for describing games and adversaries (we specify the syntax but dispense with the operational semantics, which should be clear). The games of this paper conform to the syntax of  <span class="math">\\mathcal L</span>  apart from some minor matters.</p>

    <p class="text-gray-300">Our programming language is strongly typed, with the type of each variable apparent from its usage (we dispense with explicit declarations). We will have variables of type integer, boolean, string, set, and array. A set is a finite set of strings and an array is an associative array, one taking on values of strings. The semantics of a boolean variable, which we will also call a <em>flag</em>, is that once true it stays true.</p>

    <p class="text-gray-300">We allow conventional statements like if statements, for statements, and assignment statements. There is also a random-assignment statement, which is the only source of randomness in programs. Such a statement has the form  <span class="math">s \\stackrel{\\</span>}{\\leftarrow} S$  where S is a finite set. The result is to uniformly select a random element from the set S and assign it to s. If  <span class="math">S = \\emptyset</span>  or S = undefined (we regard undefined as a possible value for a variable) then the result of the random-assignment statement is to set s to undefined. A comma or newline serves as a statement separator and indentation is used to indicate grouping.</p>

    <p class="text-gray-300">    <img src="_page_9_Figure_0.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Figure 3: Running a game G with an adversary A. The game is the code at the top, the adversary is the code at the bottom. The adversary interacts with the game by calling the oracles provided (two of which are shown).</p>

    <p class="text-gray-300">A game has three kinds of procedures: an initialization procedure (Initialize), a finalization procedure (Finalize), and named oracles (each one a procedures). The adversary can make calls to the oracles, passing in values from some finite domain associated to each oracle. The initialization or finalization procedures may be absent, and often are, and there may be any number of oracles, including none. All variables in a game are global variables and are not visible to the adversary's code. All variables in adversary code are local.</p>

    <p class="text-gray-300">Running a game. We can <em>run</em> a game G with an adversary A. To begin, variables are given initial values. Integer variables are initialized to 0; boolean variables are initialized to false; string variables are initialized to the empty string ε; set variables are initialized to the empty set ∅; and array variables hold the value undefined at every point. These conventions facilitate omitting explicit initialization code in many cases.</p>

    <p class="text-gray-300">The Initialize procedure is the first to execute, possibly producing an output <em>inp</em>. This is provided as input to the procedure Adversary, denoted A, which now runs. The adversary code can make oracle queries via statements of the form y ← P(···) for any oracle P that has been defined in the game. The result is to assign to y the value returned by the procedure call. We assume that the game and adversary match syntactically, meaning that all the oracle calls made by the adversary are to oracles specified in the game, and with arguments that match in type or quantity. The semantics of a call is call-by-value; the only way for an oracle to return a value to the adversary is via a return statement. When adversary A halts, possibly with some output <em>out</em>, we call the Finalize procedure, providing it any output produced by A. The Finalize procedure returns a string that is the outcome of the game. If we omit specifying Initialize or Finalize it means that these procedures do nothing: they compute the identity function.</p>

    <p class="text-gray-300">Termination and finite randomness. We assume that an underlying execution model provides a notion for the number of steps (the running time) of a program. We require that both the adversary and the game always terminate in finite time. By this we mean that, for any adversary A there must exist an integer T such that A always halts within T steps (regardless of the random choices A makes and the answers it receives to its oracle queries). Similarly, for any game G there must exist an integer T such that G always halts within T steps (regardless of the random choices made, Initialize halts within T steps, and, regardless of the inputs they are provided, Finalize and the oracles halt within T steps). The finite-termination requirement is guaranteed automatically by our sample programming language L.</p>

    <p class="text-gray-300">Since the adversary and game terminate in finite time, there must be an integer T such that they each execute at most T random-assignment statements, and there must be an integer B such that the size of the set S in any random-assignment statement s $ ← S executed by the adversary or the game is at most B. Taken together, this means that the execution of G with A uses <em>finite randomness</em>, meaning G and A are underlain by a finite sample space Ω. Thus probabilities are well-defined and henceforth we can talk about the probabilities of various events in the execution.</p>

    <p class="text-gray-300">Adversary and game outputs. We associate two outputs to the process of running a game with an adversary. The first, called the adversary output, is the value <em>out</em> returned by A after it has completed its interaction with the oracles provided by the game. The second, called the game output, is the value <em>outcome</em> returned by the Finalize procedure. Often the two outputs are the same, because the Finalize procedure is not specified (whence we define it to do nothing but pass on its input as its output).</p>

    <p class="text-gray-300">The adversary and game outputs can be regarded as random variables. We write Pr[A&lt;sup&gt;G&lt;/sup&gt; ⇒ 1] for the probability that the adversary output is 1 when we run game G with adversary A, and Pr[G&lt;sup&gt;A&lt;/sup&gt; ⇒ 1] for the probability that the game output is 1 when we run game G with adversary A.</p>

    <p class="text-gray-300">Advantages. If G and H are games and A is an adversary, let</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}(A^G, A^H) = \\Pr[A^G \\Rightarrow 1] - \\Pr[A^H \\Rightarrow 1]</span>$
and  <span class="math">\\mathbf{Adv}(G^A, H^A) = \\Pr[G^A \\Rightarrow 1] - \\Pr[H^A \\Rightarrow 1]</span> .</p>

    <p class="text-gray-300">These represent the advantage of the adversary in distinguishing the games, the first measured via adversary output and the second via game output. We refer to the first as the <em>adversarial advantage</em> and the second as the <em>game advantage</em>. We say that G, H are <em>adversarially indistinguishable</em> if for any adversary A it is the case that <strong>Adv</strong>(AG, AH) = 0, and <em>equivalent</em> if, for any adversary A it is the case that <strong>Adv</strong>(GA, HA) = 0. We will often use the fact that</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}(A^G, A^I) = \\mathbf{Adv}(A^G, A^H) + \\mathbf{Adv}(A^H, A^I)</span>$
(4)</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}(G^A, I^A) = \\mathbf{Adv}(G^A, H^A) + \\mathbf{Adv}(H^A, I^A)</span>$
(5)</p>

    <p class="text-gray-300">for any games G, H, I and any adversary A. These will be referred to as the <em>triangle equalities</em>.</p>

    <p class="text-gray-300">We will usually be interested in adversarial advantage (eg, this is the case in the game-playing proof of the PRP/PRF Switching Lemma). Game advantage is useful when we are interested in how the adversary's output relates to some game variable such as a hidden bit chosen by the game (this happens in our proof of the security of OAEP).</p>

    <p class="text-gray-300">Identical-until-<em>bad</em> games. We are interested in programs that are syntactically identical except for statements that follow the setting of a flag <em>bad</em> to true. Somewhat more precisely, let G and H be programs and let <em>bad</em> be a flag that occurs in both of them. Then we say that G and H are <em>identical-until-bad</em> if their code is the same except that there might be places where G has a statement <em>bad</em> ← true, S while game H has a corresponding statement <em>bad</em> ← true, T for some T that is different from S. As an example, in the games S&lt;sup&gt;0&lt;/sup&gt; and S&lt;sup&gt;1&lt;/sup&gt; from Figure 2, the former has the empty statement following <em>bad</em> ← true while in S&lt;sup&gt;1&lt;/sup&gt; we have Y $ ← image(π) following <em>bad</em> ← true. Since this is the only difference in the programs, the games are identical-until-<em>bad</em>. One could also say that G and H are are identical-until-<em>bad</em> if one has the statement if <em>bad</em> then S where the other has the empty statement, for this can be rewritten in the form above.</p>

    <p class="text-gray-300">A fully formal definition of identical-until-<em>bad</em> requires one to pin down the programming language and talk about the parse trees of programs in the language. We establish the needed language in Appendix B but, in fact, such formality isn't needed in applications: for any two games one writes down, whether or not they are identical-until-<em>bad</em> is obvious. We emphasize that identical-until-<em>bad</em> is a purely &quot;syntactic&quot; requirement.</p>

    <p class="text-gray-300">We write  <span class="math">\\Pr[A^G \\text{ sets } bad]</span>  or  <span class="math">\\Pr[G^A \\text{ sets } bad]</span>  to refer to the probability that the flag bad is true at the end of the execution of the adversary A with game G, namely at the point when the Finalize procedure terminates. It is easy to see that, for any flag bad, identical-until-bad is an equivalence relation on games. When we say that a sequence of games  <span class="math">G_1, G_2, \\ldots</span>  are identical-until-bad, we mean that each pair of games in the sequence are identical-until-bad.</p>

    <p class="text-gray-300">THE FUNDAMENTAL LEMMA. The fundamental lemma says that the advantage that an adversary can obtain in distinguishing a pair of identical-until-bad games is at most the probability that its execution sets bad in one of the games (either game will do).</p>

    <p class="text-gray-300"><strong>Lemma 2</strong> [Fundamental lemma of game-playing] Let G and H be identical-until-bad games and let A be an adversary. Then</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}(A^G, A^H) \\leq \\Pr[A^G \\text{ sets } bad] \\quad and</span>$
(6)</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}(G^A, H^A) \\leq \\Pr[G^A \\text{ sets } bad].</span>$
(7)</p>

    <p class="text-gray-300">More generally, let G, H, I be identical-until-bad games. Then</p>

    <p class="text-gray-300"><span class="math">$\\left| \\mathbf{Adv}(A^G, A^H) \\right| \\le \\Pr[A^I \\text{ sets } bad] \\quad and</span>$
(8)</p>

    <p class="text-gray-300"><span class="math">$|\\mathbf{Adv}(G^A, H^A)| \\leq \\Pr[I^A \\text{ sets } bad].</span>$
(9)</p>

    <p class="text-gray-300"><strong>Proof:</strong> Statement (6) follows from (7) by applying the latter to games G', H' formed by replacing the Finalize procedure of games G, H, respectively, with the trivial one that simply returns the adversary output. Similarly, (8) follows from (9). We will now prove (7) and then derive (9) from it.</p>

    <p class="text-gray-300">We have required that the adversary and game always terminate in finite time, and also that there is an integer that bounds the size of any set S in any random-assignment statement  <span class="math">s \\stackrel{\\</span>}{\\leftarrow} S$  executed by the adversary or game. This means that there exists an integer b such that the execution of G with A and the execution of H with A perform no more than b random-assignment statements, each of these sampling from a set of size at most b. Let  <span class="math">C = \\text{Coins}(A, G, H) = [1 \\dots b!]^b</span>  be the set of b-tuples of numbers, each number between 1 and b!. We call C the coins for (A, G, H). For  <span class="math">c = (c_1, \\dots, c_b) \\in C</span> , the execution of G with A on coins c is defined as follows: on the i&lt;sup&gt;th&lt;/sup&gt; random-assignment statement, call it  <span class="math">X \\stackrel{\\</span>}{\\leftarrow} S$ , if  <span class="math">S = \\{a_0, \\dots, a_{m-1}\\}</span>  is nonempty and  <span class="math">a_0 &lt; a_1 &lt; \\dots &lt; a_{m-1}</span>  in lexicographic order then let X take on the value  <span class="math">a_{c_i \\mod m}</span> . If  <span class="math">S = \\emptyset</span>  then let X take on the value undefined. This way to perform random-assignment statements is done regardless of whether it is A or one of the procedures from G that is is performing the random-assignment statement. Notice that m will divide b! and so if c is chosen at random from C then the mechanism above will return a point X drawn uniformly from S, and also the return values for each random-assignment statement are independent. For  <span class="math">c \\in C</span>  we let  <span class="math">G^A(c)</span>  denote the output of G when G is executed with A on coins c. We define the execution of H with A on coins  <span class="math">c \\in C</span> , and  <span class="math">H^A(c)</span> , similarly.</p>

    <p class="text-gray-300">Let  <span class="math">CG_{\\text{one}} = \\{c \\in C : G^A(c) \\Rightarrow 1\\}</span>  be the set of coins  <span class="math">c \\in C</span>  such that G outputs 1 when executed with A on coins c. Partition  <span class="math">CG_{\\text{one}}</span>  into  <span class="math">CG_{\\text{one}}^{\\text{bad}}</span>  and  <span class="math">CG_{\\text{one}}^{\\text{good}}</span> , where  <span class="math">CG_{\\text{one}}^{\\text{bad}}</span>  is the set of all  <span class="math">c \\in CG_{\\text{one}}</span>  such that the execution of G with A on coins c sets bad and  <span class="math">CG_{\\text{one}}^{\\text{good}} = CG_{\\text{one}} \\setminus CG_{\\text{one}}^{\\text{bad}}</span> . Similarly define  <span class="math">CH_{\\text{one}}</span> ,  <span class="math">CH_{\\text{one}}^{\\text{bad}}</span>  and  <span class="math">CH_{\\text{one}}^{\\text{good}}</span> . Observe that because games G and H are identical-until-bad, an element  <span class="math">c \\in C</span>  is in  <span class="math">CG_{\\text{one}}^{\\text{good}}</span>  iff it is in  <span class="math">CH_{\\text{one}}^{\\text{good}}</span> . Thus these sets are equal and in particular have</p>

    <p class="text-gray-300">the same size. Now we have</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\Pr[G^A \\Rightarrow 1] - \\Pr[A^H \\Rightarrow 1] &amp;= \\frac{|CG_{\\text{one}}|}{|C|} - \\frac{|CH_{\\text{one}}|}{|C|} &amp;= \\frac{|CG_{\\text{one}}^{\\text{bad}}| + |CG_{\\text{one}}^{\\text{good}}| - |CH_{\\text{one}}^{\\text{good}}| - |CH_{\\text{one}}^{\\text{bad}}|}{|C|} \\\\ &amp;= \\frac{|CG_{\\text{one}}^{\\text{bad}}| - |CH_{\\text{one}}^{\\text{bad}}|}{|C|} \\leq \\frac{|CG_{\\text{one}}^{\\text{bad}}|}{|C|} \\leq \\frac{|CG^{\\text{bad}}|}{|C|} &amp;= \\Pr[G^A \\text{ sets } bad] \\;. \\end{split}</span>$</p>

    <p class="text-gray-300">This completes the proof of (7). Now, if G, H are identical-until-bad then (7) tells us that</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}(G^A, H^A) \\leq \\Pr[G^A \\text{ sets } bad]</span>$
and  <span class="math">\\mathbf{Adv}(H^A, G^A) \\leq \\Pr[H^A \\text{ sets } bad]</span> .</p>

    <p class="text-gray-300">However, if G, H, I are all identical-until-bad, then Proposition 3 says that</p>

    <p class="text-gray-300"><span class="math">$\\Pr[G^A \\text{ sets } bad] = \\Pr[H^A \\text{ sets } bad] = \\Pr[I^A \\text{ sets } bad].</span>$</p>

    <p class="text-gray-300">Thus we have established (9).</p>

    <p class="text-gray-300">We have used finite randomness in our proof of the Fundamental Lemma, but we comment that this is more for simplicity than necessity: probabilities over the execution of G with A can be defined quite generally, even when the underlying sample space is infinite, and the Fundamental Lemma can still be proved. But we have never encountered any situation where such an extension is useful.</p>

    <p class="text-gray-300">AFTER BAD IS SET, NOTHING MATTERS. One of the most common manipulations of games along a game chain is to change what happens after <em>bad</em> gets set to true. Often one expunges code that follows the setting of <em>bad</em>, as we did in the PRP/PRF Switching Lemma,but it is also fine to insert alternative code. Any modification following the setting of <em>bad</em> leaves unchanged the probability of setting <em>bad</em>, as the following result shows.</p>

    <p class="text-gray-300"><strong>Proposition 3</strong> [After bad is set, nothing matters] Let G and H be identical-until-bad games. Let A be an adversary. Then  <span class="math">Pr[G^A \\text{ sets bad}] = Pr[H^A \\text{ sets bad}]</span> .</p>

    <p class="text-gray-300"><strong>Proof:</strong> Using the definition from the proof of Lemma 2, fix coins C = Coins(A, G, H) and execute  <span class="math">G^A</span>  and  <span class="math">H^A</span>  in the manner we described using these coins. Let  <span class="math">CG^{\\text{bad}} \\subseteq C</span>  be the coins that result in bad getting set to true when we run  <span class="math">G^A</span> , and let  <span class="math">CH^{\\text{bad}} \\subseteq C</span>  be the coins that result in bad getting set to true when we run  <span class="math">H^A</span> . Since G and H are identical-until-bad, each  <span class="math">c \\in C</span>  causes bad to be set to true in  <span class="math">G^A</span>  iff it causes bad to be set to true in  <span class="math">H^A</span> . Thus  <span class="math">CG^{\\text{bad}} = CH^{\\text{bad}}</span>  and hence  <span class="math">|CG^{\\text{bad}}| = |CH^{\\text{bad}}|</span>  and  <span class="math">|CG^{\\text{bad}}|/|C| = CH^{\\text{bad}}|/|C|</span> , which is to say that  <span class="math">\\Pr[G^A \\text{ sets } bad] = \\Pr[H^A \\text{ sets } bad]</span> .</p>

    <p class="text-gray-300">Besides the lemma above, many other ways to manipulate games are illustrated by our examples and our discussion in Section 7.</p>

    <p class="text-gray-300">Game inputs. The setting discussed above can be extended to allow a game to take an input parameter: the Initialize procedure would take an optional input that is a string parameter input. The adversary and game outputs will now be denoted  <span class="math">\\Pr[A^G(input) \\Rightarrow 1]</span>  and  <span class="math">\\Pr[G^A(input) \\Rightarrow 1]</span>  respectively. Similarly, the advantages become  <span class="math">\\mathbf{Adv}(A^G(input), A^H(input))</span>  and  <span class="math">\\mathbf{Adv}(G^A(input), H^A(input))</span> , these being defined in the obvious ways. The definition of identical-until-bad obviously extends to games with inputs, as does the Fundamental Lemma.</p>

    <p class="text-gray-300">We can imagine that it might be convenient for games to have inputs, for example in the asymptotic setting where <em>input</em> might be the security parameter, but our experience has been that it is not really necessary. Rather than giving a game an input <em>input</em>, we can usually imagine a family of games, one for each value of <em>input</em>, and reason about these; since the games are involved only in the analysis, this usually suffices. Accordingly our treatment of games omits explicit game inputs.</p>

    <h3 id="sec-7" class="text-xl font-semibold mt-8">4 The Security of Three-Key Triple-Encryption</h3>

    <p class="text-gray-300">In this section we show that, in the ideal-cipher model, triple encryption dramatically increases security compared to single (or double) encryption. The result covers both EEE-style triple encryption and EDE-style triple encryption.</p>

    <h4 id="sec-8" class="text-lg font-semibold mt-6">4.1 Definitions</h4>

    <p class="text-gray-300">Let  <span class="math">E: \\{0,1\\}^k \\times \\{0,1\\}^n \\to \\{0,1\\}^n</span>  be a blockcipher with key length k and block length n. For  <span class="math">K \\in \\{0,1\\}^k</span>  and  <span class="math">X \\in \\{0,1\\}^n</span>  let  <span class="math">E_K(X) = E(K,X)</span> . Let  <span class="math">E^{-1}: \\{0,1\\}^k \\times \\{0,1\\}^n \\to \\{0,1\\}^n</span>  be the blockcipher that is the inverse of E. We associate to E two blockciphers formed by composition; denoted  <span class="math">\\mathsf{Cascade}_E^{\\mathsf{eee}}</span> ,  <span class="math">\\mathsf{Cascade}_E^{\\mathsf{eee}}: \\{0,1\\}^{3k} \\times \\{0,1\\}^n \\to \\{0,1\\}^n</span> , these are defined as</p>

    <p class="text-gray-300"><span class="math">$\\mathsf{Cascade}_E^{\\mathrm{eee}}(K_0K_1K_2,\\ X) \\ = \\ E_{K_2}(E_{K_1}(E_{K_0}(X))) \\quad \\text{and} \\quad \\\\ \\mathsf{Cascade}_E^{\\mathrm{ede}}(K_0K_1K_2,\\ X) \\ = \\ E_{K_2}(D_{K_1}(E_{K_0}(X)))</span>$</p>

    <p class="text-gray-300">for all  <span class="math">K_0, K_1, K_2 \\in \\{0, 1\\}^k</span>  and  <span class="math">X \\in \\{0, 1\\}^n</span> . These blockciphers have key length 3k and block length n and are sometimes referred to as the <em>three-key</em> forms of triple encryption. We will call the two methods EEE and EDE, respectively. There is also a <em>two-key</em> variant of triple encryption, obtained by setting  <span class="math">K_0 = K_2</span> , but we do not investigate it since the method admits comparatively efficient attacks [36].</p>

    <p class="text-gray-300">We will be working in the ideal-blockcipher model, as in works like [3,22,32]. Let  <span class="math">\\operatorname{Bloc}(k,n)</span>  be the set of all blockciphers  <span class="math">E \\colon \\{0,1\\}^k \\times \\{0,1\\}^n \\to \\{0,1\\}^n</span> . Thus  <span class="math">E \\stackrel{\\</span>}{\\leftarrow} \\operatorname{Bloc}(k,n)$  means that  <span class="math">E_K \\colon \\{0,1\\}^n \\to \\{0,1\\}^n</span>  is a random permutation on n-bit strings for each  <span class="math">K \\in \\{0,1\\}^k</span> . We consider an adversary A that can make four types of oracle queries: T(X),  <span class="math">T^{-1}(Y)</span> , E(K,X), and  <span class="math">E^{-1}(K,Y)</span> , where  <span class="math">X,Y \\in \\{0,1\\}^n</span>  and  <span class="math">K \\in \\{0,1\\}^k</span> . (As for our syntax,  <span class="math">T,T^{-1}</span> ,  <span class="math">E,E^{-1}</span>  are formal symbols, not specific functions.) The advantage of A against EEE and the maximal advantage against EEE obtainable using q queries are defined as</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}_{k,n}^{\\mathrm{eee}}(A) \\ = \\ \\mathbf{Adv}(A_0^C, A_0^R) \\quad \\text{and} \\quad \\mathbf{Adv}_{k,n}^{\\mathrm{eee}}(q) \\ = \\ \\max_{A} \\left\\{ \\ \\mathbf{Adv}_{k,n}^{\\mathrm{eee}}(A) \\ \\right\\}</span>$</p>

    <p class="text-gray-300">where the games  <span class="math">C_0</span> ,  <span class="math">R_0</span>  are shown in Figure 4 and the maximum is over all adversaries A that make at most q oracle queries (that is, a total of q across all four oracles). The advantage of A measures its ability to tell whether  <span class="math">T(\\cdot)</span>  is a random permutation or is  <span class="math">\\mathsf{Cascade}_E^{\\mathsf{eee}}(K_0K_1K_2, \\cdot)</span>  for  <span class="math">K_0K_1K_2</span>  chosen independently at random from  <span class="math">\\{0,1\\}^{3k}</span>  and where E realizes a random blockcipher and  <span class="math">T^{-1}</span> ,  <span class="math">E^{-1}</span>  realize inverses of T, E, respectively.</p>

    <p class="text-gray-300">Define the query threshold  <span class="math">\\mathbf{QTh}_{1/2}^{\\text{eee}}(k,n)</span>  as the largest integer q for which  <span class="math">\\mathbf{Adv}_{k,n}^{\\text{eee}}(q) \\leq 1/2</span> . We will regard EEE as being secure up to  <span class="math">\\mathbf{QTh}_{1/2}^{\\text{eee}}(k,n)</span>  queries. Let  <span class="math">\\mathbf{Adv}_{k,n}^{\\text{ede}}(A)</span> ,  <span class="math">\\mathbf{Adv}_{k,n}^{\\text{ede}}(q)</span> , and  <span class="math">\\mathbf{QTh}_{1/2}^{\\text{ede}}(k,n)</span>  be defined in the analogous way.</p>

    <h4 id="sec-9" class="text-lg font-semibold mt-6">4.2 Results</h4>

    <p class="text-gray-300">We are now ready to state our result about the security of triple encryption.</p>

    <p class="text-gray-300"><strong>Theorem 4</strong> [Security of triple-encryption] Let  <span class="math">k, n \\ge 2</span> . Let  <span class="math">\\alpha = \\max(2e2^{k-n}, 2n + k)</span> . Then</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}_{k,n}^{\\text{eee}}(q) \\leq 12\\alpha \\frac{q^2}{2^{3k}} + 10.7 \\left(\\frac{q}{2^{k+n/2}}\\right)^{2/3} + \\frac{12}{2^k} \\,. \\quad \\blacksquare</span>$
(10)</p>

    <p class="text-gray-300">We display the result graphically in Figure 1 for DES parameters k = 56 and n = 64. Our bound implies that  <span class="math">\\mathbf{QTh}_{1/2}^{\\text{eee}}(k,n)</span>  is, very roughly, about  <span class="math">2^{k+\\min(k,n)/2}</span> , meaning that EEE is secure up to this many queries.</p>

    <p class="text-gray-300">For EDE the result is the same, meaning that  <span class="math">\\mathbf{Adv}_{k,n}^{\\text{ede}}(q)</span>  is also bounded by the quantity on the right-hand-side of (10). This can be shown by mostly-notational modifications to the proof of Theorem 4.</p>

    <p class="text-gray-300">OVERVIEW OF THE PROOF. The first step in our proof reduces the problem of bounding the advantage of an adversary A against EEE to bounding certain quantities that relate to a different, simplified adversary B. By a simplified adversary we mean one that makes no  <span class="math">T(\\cdot)</span> ,  <span class="math">T^{-1}(\\cdot)</span>  queries, meaning it only has oracles  <span class="math">E(\\cdot,\\cdot)</span>  and  <span class="math">E^{-1}(\\cdot,\\cdot)</span> . We will consider two games, both involving random, distinct keys  <span class="math">K_0, K_1, K_2</span> . In one game  <span class="math">(R_3)</span>   <span class="math">E_{K_2}</span>  is random, while in the other  <span class="math">(D_S)</span> , it is correlated to  <span class="math">E_{K_0}, E_{K_1}</span> . The quantities we will need to bound are the ability of our simplified adversary to either distinguish these games without extending a 2-chain, or to extend a 2-chain in one of the games, where what it means to extend a 2-chain is explained below. We will be able to provide these two bounds via two lemmas. The first considers a simplified game in which an adversary has only three permutation oracles, either all random or one correlated to the rest, and has to distinguish them without extending a 2-chain. The second bounds the probability that the adversary can extend a 2-chain in  <span class="math">R_3</span> .</p>

    <p class="text-gray-300">Conventions. We begin with some conventions. An adversary A against EEE can make oracle queries T(X),  <span class="math">T^{-1}(Y)</span> , E(K,X), or  <span class="math">E^{-1}(K,Y)</span>  for any  <span class="math">X,Y \\in \\{0,1\\}^n</span>  and  <span class="math">K \\in \\{0,1\\}^k</span> . We will assume that any adversary against EEE is deterministic and never makes a redundant query. A query is redundant if it has been made before; a query  <span class="math">T^{-1}(Y)</span>  is redundant if A has previously received Y in answer to a query  <span class="math">T^{-1}(Y)</span> ; a query  <span class="math">T^{-1}(X)</span>  is redundant if A has previously received X in answer to a query  <span class="math">T^{-1}(Y)</span> ; a query  <span class="math">T^{-1}(X)</span>  is redundant if  <span class="math">T^{-1}(X)</span>  has previously received  <span class="math">T^{-1}(X)</span>  in answer to a query  <span class="math">T^{-1}(X)</span> . Assuming  <span class="math">T^{-1}(X)</span>  is redundant if  <span class="math">T^{-1}(X)</span>  has previously received  <span class="math">T^{-1}(X)</span>  in answer to a query  <span class="math">T^{-1}(X)</span> . Assuming  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span>  has a query  <span class="math">T^{-1}(X)</span></p>

    <h4 id="sec-10" class="text-lg font-semibold mt-6">4.3 Reduction to simplified adversary</h4>

    <p class="text-gray-300">Consider the games in Figure 4. The R-games (where R stands for random) omit the boxed assignment statements while the C-games and D-game include them. Distinct <span class="math">_3^k</span>  denotes the set of all triples  <span class="math">(K_0, K_1, K_2) \\in (\\{0,1\\}^k)^3</span>  such that  <span class="math">K_0 \\neq K_1</span>  and  <span class="math">K_1 \\neq K_2</span>  and  <span class="math">K_0 \\neq K_2</span> . Games  <span class="math">R_0</span> ,  <span class="math">R_1</span> ,  <span class="math">C_0</span> ,  <span class="math">C_1</span>  will be run with an adversary against EEE. The rest of the games will be run with a simplified adversary. Game  <span class="math">C_T</span>  is parameterized by a permutation  <span class="math">T \\in \\text{Perm}(n)</span> , meaning we are effectively defining one such game for every T, and similarly  <span class="math">D_S</span>  is parameterized by a permutation  <span class="math">S \\in \\text{Perm}(n)</span> . Game  <span class="math">D_S</span>  grows an (initially without edges) edge-labeled directed graph with vertex set  <span class="math">\\{0,1\\}^n</span> . An arc  <span class="math">X \\xrightarrow{i} Y</span>  is created when a query  <span class="math">\\mathbf{E}_{K_i}(X)</span>  returns the value Y or a query  <span class="math">\\mathbf{E}_{K_i}(Y)</span>  returns the value X. The boolean flag X2ch is set if the adversary extends a 2-chain, meaning that a path  <span class="math">P \\xrightarrow{i+1} Q \\xrightarrow{i+2} R</span>  exists in the graph and the adversary asks either  <span class="math">E_{K_i}(R)</span>  or  <span class="math">E_{K_i}^{-1}(P)</span> , where the indicated addition is modulo 3. Note that  <span class="math">D_S</span>  has an explicit Finalize procedure, indicating we will be interested in the game output rather than the adversary output.</p>

    <p class="text-gray-300"><strong>Lemma 5</strong> Let A be an adversary that makes at most q queries. Then there is a permutation  <span class="math">S \\in \\text{Perm}(n)</span>  and a simplified adversary B making at most q queries such that  <span class="math">\\mathbf{Adv}^{\\text{eee}}_{k,n}(A)</span>  is at most</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}(D_S^B, R_3^B) + \\Pr\\left[D_S^B \\text{ sets x2ch }\\right] + \\Pr\\left[R_3^B \\text{ sets x2ch }\\right] + \\frac{6}{2^k}.</span>$</p>

    <pre><code class="language-text">procedure Initialize
K_0, K_1, K_2 \\stackrel{\\$}{\\leftarrow} \\{0, 1\\}^k, \\quad E \\stackrel{\\$}{\\leftarrow} \\operatorname{Bloc}(k, n), \\quad T \\stackrel{\\$}{\\leftarrow} \\operatorname{Perm}(n), \\quad T \\leftarrow E_{K_2} \\circ E_{K_1} \\circ E_{K_0}
                                                              procedure T^{-1}(S)
                                                              return T^{-1}[S]
return T[P]
                                                              procedure E^{-1}(K,Y)
procedure E(K,X)
                                                                                                                                                                           Game R_0
                                                                                                                                                                           Game C_0
return E_K[X]
                                                              return E_K^{-1}[Y]
procedure Initialize
(K_0,K_1,K_2) \\overset{\\hspace{0.1em}\\mathsf{\\scriptscriptstyle\\$}}{\\leftarrow} \\mathrm{Distinct}_3^k, \\quad E \\overset{\\hspace{0.1em}\\mathsf{\\scriptscriptstyle\\$}}{\\leftarrow} \\mathrm{Bloc}(k,n), \\quad T \\overset{\\hspace{0.1em}\\mathsf{\\scriptscriptstyle\\$}}{\\leftarrow} \\mathrm{Perm}(n), \\quad \\left| E_{K_2} \\leftarrow T \\circ E_{K_0}^{-1} \\circ E_{K_1}^{-1} \\right|
                                                              procedure T^{-1}(S)
procedure T(P)
                                                              return T^{-1}[S]
return T[P]
                                                              procedure E^{-1}(K,Y)
procedure E(K,X)
                                                                                                                                                                           Game R_1
                                                              return E_K^{-1}[Y]
return E_K[X]
                                                                                                                                                                           Game C_1
procedure Initialize
(K_0, K_1, K_2) \\stackrel{\\$}{\\leftarrow} \\text{Distinct}_3^k, \\quad E \\stackrel{\\$}{\\leftarrow} \\text{Bloc}(k, n), \\quad \\Big| E_{K_2} \\leftarrow T \\circ E_{K_0}^{-1} \\circ E_{K_1}^{-1}
                                                              procedure E^{-1}(K,Y)
procedure E(K, X)
                                                                                                                                                                           Game R_2
                                                              return E_K^{-1}[Y]
return E_K[X]
                                                                                                                                                                          Game C_T
procedure Initialize
(K_0, K_1, K_2) \\stackrel{\\$}{\\leftarrow} \\text{Distinct}_3^k, \\quad E \\stackrel{\\$}{\\leftarrow} \\text{Bloc}(k, n), \\quad \\Big| E_{K_2} \\leftarrow S \\circ E_{K_0}^{-1} \\circ E_{K_1}^{-1}
procedure E(K,X)
if \\exists i \\in \\{0,1,2\\} such that K = K_i then
                                                                                                                                                                           Game R_3
      Q \\leftarrow E_{K_{i+1}}^{-1}[X], \\quad P \\leftarrow E_{K_{i+1}}^{-1}[Q]
                                                                                                                                                                          Game D_S
      if P \\xrightarrow{i+1} Q \\xrightarrow{i+2} X then x2ch \\leftarrow \\text{true}
      Add arc X \\xrightarrow{i} E_K[X]
return E_K[X]
procedure E^{-1}(K,Y)
                                                                                   procedure Finalize(out)
if \\exists i \\in \\{0, 1, 2\\} such that K = K_i then
                                                                                   if x2ch then return 1 else return out
     Q \\leftarrow E_{K_{i+1}}[Y], \\quad R \\leftarrow E_{K_{i+2}}[Q] if Y \\stackrel{i+1}{\\longrightarrow} Q \\stackrel{i+2}{\\longrightarrow} R then x2ch \\leftarrow \\mathsf{true}
 \\text{Add arc } E_K^{-1}[Y] \\xrightarrow{i} Y  return E_K^{-1}[Y]
</code></pre>

    <p class="text-gray-300">Figure 4: The  <span class="math">C_X</span>  or  <span class="math">D_X</span>  games include the boxed statements while the  <span class="math">R_i</span>  games do not.</p>

    <p class="text-gray-300"><strong>Proof of Lemma 5:</strong> Game  <span class="math">C_0</span>  defines T as  <span class="math">E_{K_2} \\circ E_{K_1} \\circ E_{K_0}</span>  while game  <span class="math">C_1</span>  defines  <span class="math">E_{K_2}</span>  as  <span class="math">T \\circ E_{K_0}^{-1} \\circ E_{K_1}^{-1}</span> . However, these processes are identical. With this factored out, the difference between  <span class="math">C_1</span>  and  <span class="math">C_0</span>  is that the former draws the keys  <span class="math">K_0, K_1, K_2</span>  from Distinct&lt;sup&gt;k&lt;/sup&gt; while the latter draws them from  <span class="math">(\\{0,1\\}^k)^3</span> . Games  <span class="math">R_1</span>  and  <span class="math">R_0</span>  differ in only the latter way. So using (4) we have</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}_{k,n}^{\\text{eee}}(A) = \\mathbf{Adv}(A_0^C, A_0^R) \\le \\mathbf{Adv}(A_1^C, A_1^R) + \\frac{6}{2^k}</span>$
.</p>

    <p class="text-gray-300">Game  <span class="math">C_T</span>  is parameterized by a permutation  <span class="math">T \\in \\text{Perm}(n)</span> . For any such T we consider an adversary  <span class="math">A_T</span>  that has T hardwired in its code and is simplified, meaning can make queries E(K, X) and  <span class="math">E^{-1}(K, Y)</span>  only. This adversary runs A, answering the latter's E(K, X) and  <span class="math">E^{-1}(K, Y)</span>  queries</p>

    <p class="text-gray-300">via its own oracles, and answering T(X) and  <span class="math">T^{-1}(Y)</span>  queries using T. Note that  <span class="math">A_T</span>  makes at most q oracle queries. Choose  <span class="math">S \\in \\text{Perm}(n)</span>  such that  <span class="math">\\mathbf{Adv}(A_S^{C_S}, A_S^{R_2})</span>  is the maximum over all  <span class="math">T \\in \\text{Perm}(n)</span>  of  <span class="math">\\mathbf{Adv}(A_T^{C_T}, A_T^{R_2})</span>  and let  <span class="math">B = A_S</span> . We now have  <span class="math">\\mathbf{Adv}(A_1^C, A_1^R) \\leq \\mathbf{Adv}(B_S^C, B_2^R)</span> . Now by (5) we have</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}(B_S^C, B_2^R) \\leq \\mathbf{Adv}(C_S^B, D_S^B) + \\mathbf{Adv}(D_S^B, R_3^B) + \\mathbf{Adv}(R_3^B, R_2^B) \\;.</span>$</p>

    <p class="text-gray-300">Game  <span class="math">C_S</span>  (resp. game  <span class="math">R_2</span> ) can be easily transformed into an equivalent game such that this game and game  <span class="math">D_S</span>  (resp.  <span class="math">R_3</span> ) are identical-until-x2ch, so by the Fundamental Lemma we have  <span class="math">\\mathbf{Adv}(C_S^B, D_S^B) \\leq \\Pr[D_S^B \\text{ sets } x2ch]</span>  and  <span class="math">\\mathbf{Adv}(R_3^B, R_2^B) \\leq \\Pr[R_3^B \\text{ sets } x2ch]</span> . Putting all this together completes the lemma's proof.</p>

    <p class="text-gray-300">Letting  <span class="math">p = \\Pr [R_3^B \\text{ sets } x2ch]</span> , we now need to bound</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}(D_S^B, R_3^B) + (\\Pr \\left[ D_S^B \\text{ sets } x2ch \\right] - p) + 2p. \\tag{11}</span>$</p>

    <p class="text-gray-300">We will be able to bound the first two terms by bounding the advantages of a pair  <span class="math">B_1</span> ,  <span class="math">B_2</span>  of adversaries, related to B, in distinguishing between a pair of games that involve only three permutation oracles, the first two random, and the third either random or correlated to the first two. We will bound p separately via a combinatorial argument. We now state the lemmas we need, conclude the proof of Theorem 4 using them in Section 4.6, and then return to provide the proofs of the two lemmas.</p>

    <h4 id="sec-11" class="text-lg font-semibold mt-6">4.4 Pseudorandomness of three correlated permutations</h4>

    <p class="text-gray-300">We posit a new problem. Consider games G and  <span class="math">H_S</span> , for  <span class="math">S \\in \\operatorname{Perm}(n)</span> , defined in Figure 5. Game G grows an edge-labeled graph, which we shall describe shortly. An adversary may make queries  <span class="math">\\Pi(i,X)</span>  or  <span class="math">\\Pi^{-1}(i,Y)</span>  where  <span class="math">i \\in \\{0,1,2\\}</span>  and  <span class="math">X,Y \\in \\{0,1\\}^n</span> . The oracles realize three permutations and their inverses, the function realized by  <span class="math">\\Pi^{-1}(i,\\cdot)</span>  being the inverse of that realized by  <span class="math">\\Pi(i,\\cdot)</span> . In both games permutations  <span class="math">\\pi_0, \\pi_1</span>  underlying  <span class="math">\\Pi(0,\\cdot)</span>  and  <span class="math">\\Pi(1,\\cdot)</span>  are uniform and independent. In game G the permutation  <span class="math">\\pi_2</span>  underlying  <span class="math">\\Pi(2,\\cdot)</span>  is also uniform and independent of  <span class="math">\\pi_0</span>  and  <span class="math">\\pi_1</span> , but in game  <span class="math">H_S</span>  it is equal to  <span class="math">S \\circ \\pi_0^{-1} \\circ \\pi_1^{-1}</span> .</p>

    <p class="text-gray-300">Notice that it is easy for an adversary to distinguish between games G and  <span class="math">H_S</span>  by making queries that form a &quot;chain&quot; of length three: for any  <span class="math">P \\in \\{0,1\\}^n</span> , let the adversary ask and be given  <span class="math">Q \\leftarrow \\pi_0(P)</span> , then  <span class="math">R \\leftarrow \\pi_1(Q)</span> , then  <span class="math">P&#x27; \\leftarrow \\pi_2(R)</span> , and then have the adversary output 1 if P = P' (a &quot;triangle&quot; has been found) or 0 if  <span class="math">P \\neq P&#x27;</span>  (the &quot;three-chain&quot; is not in fact a triangle). What we will establish is that, apart from such behavior—extending a known &quot;2-chain&quot;—the adversary is not able to gain much advantage. To capture this, as the adversary A makes its queries and gets replies, the games grow an (initially without edges) edge-labeled directed graph G with vertex set  <span class="math">\\{0,1\\}^n</span> . An arc  <span class="math">X \\xrightarrow{i} Y</span>  is created when a query  <span class="math">\\Pi(i,X)</span>  returns the value Y or a query  <span class="math">\\Pi^{-1}(i,Y)</span>  returns the value X. The boolean flag x2ch is set in the games if the adversary extends a 2-chain, meaning that a path  <span class="math">P \\xrightarrow{i+1} Q \\xrightarrow{i+2} R</span>  exists in the graph and the adversary asks either  <span class="math">\\Pi(i,R)</span>  or  <span class="math">\\Pi^{-1}(i,P)</span> , where the indicated addition is modulo 3. We will be interested in the game outputs rather than the adversary outputs. Again using a game-based proof, we prove the following in Section 4.7:</p>

    <p class="text-gray-300"><strong>Lemma 6</strong> Fix
<span class="math">$S \\in \\text{Perm}(n)</span>$
. If  <span class="math">\\Pr\\left[B^G \\text{ makes} \\geq h \\text{ oracle queries}\\right] \\leq \\delta \\text{ then } \\mathbf{Adv}(H_S^B, G^B) \\leq 2.5 h^2/2^n + \\delta</span> .</p>

    <p class="text-gray-300">We remark that the lemma makes no (explicit) assumption about the probability that  <span class="math">B^H</span>  makes h or more oracle queries.</p>

    <pre><code class="language-text">procedure Initialize
\\pi_0, \\pi_1, \\pi_2 \\stackrel{\\$}{\\leftarrow} \\operatorname{Perm}(n), \\quad \\pi_2 \\leftarrow S \\circ \\pi_0^{-1} \\circ \\pi_1^{-1}
Game G
\\text{Game } H_S

procedure \\Pi(i, X)\\nif \\exists P \\stackrel{i+1}{\\rightarrow} Q \\stackrel{i+2}{\\rightarrow} X \\in \\mathcal{G} \\text{ then } x2ch \\leftarrow \\text{true}
add X \\stackrel{i}{\\rightarrow} \\pi_i[X] \\text{ to } \\mathcal{G}
return \\pi_i[X]\\nif \\exists P \\stackrel{i+1}{\\rightarrow} Q \\stackrel{i+2}{\\rightarrow} X \\in \\mathcal{G} \\text{ then } x2ch \\leftarrow \\text{true}
\\text{add } \\pi_i^{-1}[Y] \\stackrel{i}{\\rightarrow} Y \\text{ to } \\mathcal{G}
return \\pi_i[X]
procedure Finalize(out)\\nif x2ch then return 1 else return out
</code></pre>

    <p class="text-gray-300">Figure 5: Game H includes the boxed statement, game G does not.</p>

    <pre><code class="language-text">\\begin{array}{|c|c|c|c|}\\hline \\mathbf{procedure}\\ \\boldsymbol{E}(K,X) &amp; \\mathbf{procedure}\\ \\boldsymbol{E}^{-1}(K,Y) &amp; \\mathrm{Game}\\ L \\\\ \\hline \\mathrm{return}\\ E_K[X] \\overset{\\hspace{0.1em}\\raisebox{-0.4em}{$\\scriptscriptstyle{\\bullet}$}}{=} \\overline{\\mathrm{image}}(E_K) &amp; E_K^{-1}[Y] \\overset{\\hspace{0.1em}\\raisebox{-0.4em}{$\\scriptscriptstyle{\\bullet}$}}{=} \\overline{\\mathrm{domain}}(E_K) \\\\ \\hline \\mathbf{procedure}\\ \\mathbf{Finalize} &amp; \\\\ K_0, K_1, K_2 \\overset{\\hspace{0.1em}\\raisebox{-0.4em}{$\\scriptscriptstyle{\\bullet}$}}{=} \\{0,1\\}^k &amp; \\\\ \\mathrm{if}\\ (\\exists P)\\ [E_{K_2}[E_{K_1}[E_{K_0}[P]]]]\\ \\mathrm{then}\\ \\mathit{bad} \\leftarrow \\mathsf{true} \\end{array}
</code></pre>

    <p class="text-gray-300">Figure 6: Game L captures improbability of making three chains.</p>

    <h3 id="sec-12" class="text-xl font-semibold mt-8">4.5 The improbability of forming a 3-chain</h3>

    <p class="text-gray-300">Consider an adversary B that can make E(K,X) or  <span class="math">E^{-1}(K,Y)</span>  queries. Game L of Figure 5 implements the oracles as a random blockcipher and its inverse, respectively, but samples these lazily, defining points as they are needed. Write  <span class="math">X \\xrightarrow{K} Y</span>  to mean that that B has made query E(K,X) and obtained Y as a result, or made query  <span class="math">E^{-1}(K,Y)</span>  and obtained X as a result, for  <span class="math">K \\in \\{0,1\\}^k</span>  and  <span class="math">X,Y \\in \\{0,1\\}^n</span> . The Finalize procedure picks keys  <span class="math">K_0, K_1, K_2</span>  at random, and sets bad if the adversary's queries have formed a three chain, meaning that there exist points  <span class="math">P,Q,R,S \\in \\{0,1\\}^n</span>  such that  <span class="math">P \\xrightarrow{K_0} Q \\xrightarrow{K_1} R \\xrightarrow{K_2} S</span> : the conditional which is the last line of Finalize means that there is a P for which  <span class="math">E_{K_0}[P]</span>  is defined and  <span class="math">E_{K_1}[E_{K_0}[P]]</span>  is defined. Our next lemma bounds the probability of this happening. The proof is in Section 4.8.</p>

    <p class="text-gray-300"><strong>Lemma 7</strong> Let  <span class="math">k, n \\ge 1</span> . Let B be an adversary that asks at most q queries. Let  <span class="math">\\alpha = \\max(2e \\, 2^{k-n}, 2n + k)</span> . Then  <span class="math">\\Pr[B^L \\text{ sets } bad] &lt; 2\\alpha \\, q^2/2^{3k}</span> .</p>

    <h4 id="sec-13" class="text-lg font-semibold mt-6">4.6 Putting together the pieces to conclude Theorem 4</h4>

    <p class="text-gray-300">Let B be a simplified adversary and  <span class="math">S \\in \\operatorname{Perm}(n)</span>  a permutation. We associate to B, S a pair of adversaries  <span class="math">B_{S,1}</span>  and  <span class="math">B_{S,2}</span>  that make  <span class="math">\\Pi(i,X)</span>  or  <span class="math">\\Pi^{-1}(i,Y)</span>  queries, where  <span class="math">i \\in \\{0,1,2\\}</span>  and  <span class="math">X,Y \\in \\{0,1\\}^n</span> , as follows. For  <span class="math">b \\in \\{1,2\\}</span> , adversary  <span class="math">B_{S,b}</span>  picks  <span class="math">(K_0,K_1,K_2)</span>  at random from Distinct <span class="math">_3^k</span>  and picks E at random from Bloc(k,n). It then runs B, replying to its oracle queries as follows. If B makes a query E(K,X), adversary  <span class="math">B_{S,b}</span>  returns  <span class="math">E_K(X)</span>  if  <span class="math">K \\notin \\{K_0,K_1,K_2\\}</span>  and returns  <span class="math">\\Pi(i,X)</span>  if  <span class="math">K = K_i</span>  for  <span class="math">i \\in \\{0,1,2\\}</span> . Similarly, if B makes a query  <span class="math">E^{-1}(K,Y)</span> , adversary  <span class="math">B_{S,b}</span>  returns  <span class="math">E_K^{-1}(Y)</span>  if  <span class="math">K \\notin \\{K_0,K_1,K_2\\}</span>  and returns  <span class="math">\\Pi^{-1}(i,Y)</span>  if  <span class="math">K = K_i</span>  for  <span class="math">i \\in \\{0,1,2\\}</span> . Adversaries  <span class="math">B_{S,1},B_{S,2}</span>  differ only in their output, the first always returning 0 and the second returning the output out of B.</p>

    <p class="text-gray-300"><strong>Lemma 8</strong> Let B be a simplified adversary that makes at most q oracle queries, and let  <span class="math">S \\in \\text{Perm}(n)</span> . Let  <span class="math">B_{S,1}, B_{S,2}</span>  be defined as above. Let  <span class="math">K = 2^k</span> . Then for  <span class="math">b \\in \\{1,2\\}</span>  and any c &gt; 0,  <span class="math">\\text{Pr}[B_{S,b}^G \\text{ makes } \\geq 3cq/K \\text{ oracle queries }] \\leq 1/c</span> .</p>

    <p class="text-gray-300"><strong>Proof of Lemma 8:</strong> The oracles B sees when it is run by  <span class="math">B_{S,b}</span>  are exactly a random block cipher and its inverse. (A random permutation composed with a fixed one is still random so the composition by S does not change anything.) Now let X be the random variable that is the number of queries by B that involve keys  <span class="math">K_0</span> ,  <span class="math">K_1</span> , or  <span class="math">K_2</span>  in the experiment where we first run B with oracles  <span class="math">E, E^{-1}</span>  for  <span class="math">E \\stackrel{\\</span>}{\\leftarrow} \\operatorname{Bloc}(k, n)$  and then pick  <span class="math">(K_0, K_1, K_2) \\stackrel{\\</span>}{\\leftarrow} \\operatorname{Distinct}<em>3^k$ . Then the probability that  $B</em>{S,b}^G$  makes  <span class="math">\\geq 3cq/K</span>  oracle queries is exactly the probability that  <span class="math">X \\geq 3cq/K</span> . Now assume wlog that B always makes exactly q distinct oracle queries rather than at most q. Then</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\mathbf{E}[X] &amp;= q \\cdot \\left[ 1 - \\left( 1 - \\frac{1}{K} \\right) \\left( 1 - \\frac{1}{K - 1} \\right) \\left( 1 - \\frac{1}{K - 2} \\right) \\right] \\\\ &amp;= q \\cdot \\left[ 1 - \\frac{K - 1}{K} \\frac{K - 2}{K - 1} \\frac{K - 3}{K - 2} \\right] = q \\cdot \\left[ 1 - \\frac{K - 3}{K} \\right] = \\frac{3q}{K} \\; . \\end{split}</span>$</p>

    <p class="text-gray-300">We can conclude via Markov's inequality.</p>

    <p class="text-gray-300"><strong>Proof of Theorem 4:</strong> Let A be an adversary against EEE that makes at most q oracle queries. Let B be the simplified adversary, and S the permutation, given by Lemma 5, and let  <span class="math">p = \\Pr\\left[R_3^B \\text{ sets } x2ch\\right]</span> . Let  <span class="math">B_{S,1}, B_{S,2}</span>  be the adversaries associated to B as described above. Note that</p>

    <p class="text-gray-300"><span class="math">$\\begin{array}{llll} \\Pr[D_S^B \\text{ sets } \\mathbf{x} 2ch] &amp;=&amp; \\Pr[H_S^{B_{S,1}} \\Rightarrow 1] &amp; \\text{ and } &amp; \\Pr[R_3^B \\text{ sets } \\mathbf{x} 2ch] &amp;=&amp; \\Pr[G^{B_{S,1}} \\Rightarrow 1] \\\\ &amp; \\Pr[D_S^B \\Rightarrow 1] &amp;=&amp; \\Pr[H_S^{B_{S,2}} \\Rightarrow 1] &amp; \\text{ and } &amp; \\Pr[R_3^B \\Rightarrow 1] &amp;=&amp; \\Pr[G^{B_{S,2}} \\Rightarrow 1] \\end{array} \\tag{12}</span>$</p>

    <p class="text-gray-300">Combining (11) and (12) we have</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}_{k,n}^{\\text{eee}}(A) \\le 2p + \\mathbf{Adv}(H_S^{B_{S,1}}, G^{B_{S,1}}) + \\mathbf{Adv}(H_S^{B_{S,2}}, G^{B_{S,2}}) + \\frac{6}{2^k}.</span>$
(13)</p>

    <p class="text-gray-300">Let  <span class="math">\\alpha = \\max(2e2^{k-n}, 2n+k)</span>  and let c be any positive real number. Since the probability that  <span class="math">R_3^B</span>  extends a 2-chain is at most three times the probability that  <span class="math">L^B</span>  forms a 3-chain we have</p>

    <p class="text-gray-300"><span class="math">$p \\leq 3 \\cdot 2^{-k} + 3 \\cdot \\Pr[B^L \\text{ sets } bad]. \\tag{14}</span>$</p>

    <p class="text-gray-300">The first term is because L picks the keys  <span class="math">K_0, K_1, K_2</span>  independently at random while  <span class="math">R_3</span>  picks them from Distinct <span class="math">_3^k</span> . The factor of three in the second term accounts for the fact that game L fixes the order of the permutations in the chain as  <span class="math">E_{K_2} \\circ E_{K_1} \\circ E_{K_0}</span>  whereas game  <span class="math">R_3</span>  considers all three rotations of these permutations,  <span class="math">E_{K_{i+2}} \\circ E_{K_{i+1}} \\circ E_{K_i}</span> . Applying Lemma 7 we get  <span class="math">p \\leq 3 \\cdot 2^{-k} + 6\\alpha q^2 \\cdot 2^{-3k}</span> . Applying Lemma 6 in conjunction with Lemma 8 we have</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}(H^{B_{S,b}}, G^{B_{S,b}}) \\le \\frac{2.5}{2^n} \\left(\\frac{3cq}{2^k}\\right)^2 + \\frac{1}{c}</span>$</p>

    <p class="text-gray-300">for both b=1 and b=2. Putting everything together we have</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}_{k,n}^{\\text{eee}}(A) \\leq 2\\left(\\frac{3}{2^k} + 6\\alpha \\frac{q^2}{2^{3k}}\\right) + \\frac{5}{2^n} \\left(\\frac{3cq}{2^k}\\right)^2 + \\frac{2}{c} + \\frac{6}{2^k}.</span>$</p>

    <p class="text-gray-300">Now, since the above is true for any c&gt;0, we pick a particular one that minimizes the function  <span class="math">f(c)=45\\,c^2q^2\\,2^{-n-2k}+2c^{-1}</span> . The derivative is  <span class="math">f&#x27;(c)=90\\,cq^2\\,2^{-n-2k}-2c^{-2}</span> , and the only real root of the equation f'(c)=0 is  <span class="math">c=(2^{n+2k}/45q^2)^{1/3}</span> , for which we have  <span class="math">f(c)=3(45q^2/2^{n+2k})^{1/3}</span> . Plugging this into the above yields (10) and concludes the proof of Theorem 4.</p>

    <h4 id="sec-14" class="text-lg font-semibold mt-6">4.7 Proof of Lemma 6</h4>

    <p class="text-gray-300">We prove Lemma 6 as a corollary of:</p>

    <p class="text-gray-300"><strong>Lemma 9</strong> Fix  <span class="math">S \\in \\text{Perm}(n)</span> . If A asks at most q queries then  <span class="math">|\\mathbf{Adv}(G^A, H_S^A)| \\leq 2.5 \\, q^2/2^n</span> .</p>

    <p class="text-gray-300"><strong>Proof of Lemma 6:</strong> We construct an adversary A that has the same oracles as B. Adversary A runs B, answering B's oracle queries via its own oracles. It also keeps track of the number of oracle queries that B makes. If this number hits h, it stops and outputs 1; else it outputs whatever B outputs. Then we note that  <span class="math">\\Pr[H_S^B \\Rightarrow 1] \\leq \\Pr[H_S^A \\Rightarrow 1]</span>  and  <span class="math">\\Pr[G^A \\Rightarrow 1] \\leq \\Pr[G^B \\Rightarrow 1] + \\delta</span> . Thus we have</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}(H_S^B, G^B) = \\Pr[H_S^B \\Rightarrow 1] - \\Pr[G^B \\Rightarrow 1]</span>$</p>

    <p class="text-gray-300"><span class="math">$\\leq \\Pr[H_S^A \\Rightarrow 1] - \\left(\\Pr[G^A \\Rightarrow 1] - \\delta\\right) = \\mathbf{Adv}(H_S^A, G^A) + \\delta.</span>$</p>

    <p class="text-gray-300">As A makes  <span class="math">\\leq h</span>  queries, conclude by applying Lemma 9 to A with q = h.</p>

    <p class="text-gray-300"><strong>Proof of Lemma 9:</strong> We assume that the adversary A never repeats a query, never asks a query  <span class="math">\\Pi^{-1}(i,Y)</span>  having asked some  <span class="math">\\Pi(i,X)</span>  that returned Y, and never asks a query  <span class="math">\\Pi(i,X)</span>  having asked some  <span class="math">\\Pi^{-1}(i,Y)</span>  that returned X. Call an adversary <em>valid</em> if it never extends a two-chain.</p>

    <p class="text-gray-300">We begin by noting that to bound A's advantage in distinguishing games G and H we may assume that A is valid. Why? Because for any adversary  <span class="math">A^*</span>  making at most  <span class="math">q_0</span>  queries there exists a valid A that makes at most  <span class="math">q_0</span>  queries and the advantage of A is at least that of  <span class="math">A^*</span> . Adversary A runs  <span class="math">A^*</span> , answering  <span class="math">A^*</span> 's oracle queries via its own oracles, but at any point that  <span class="math">A^*</span>  would extend a two chain, adversary A simply halts and outputs 1. So now assuming A's validity, our task is to show that  <span class="math">|\\mathbf{Adv}(A_1^G, A_1^H)| \\leq 2.5 q^2/2^n</span>  where the games  <span class="math">G_1, H_1</span>  are shown in Figure 7. We show that games  <span class="math">G_1</span>  and  <span class="math">H_1</span>  are close by showing that both are close to game  <span class="math">G_3</span>  (defined in the same figure). First, we claim that  <span class="math">|\\mathbf{Adv}(A_1^G, A_3^G)| \\leq 0.5 q^2/N</span>  where, here and in the rest of this proof,  <span class="math">N=2^n</span> . Rewrite game  <span class="math">G_1</span>  to game  <span class="math">G_{1.5}</span>  (not shown) by lazily growing  <span class="math">\\pi_0, \\pi_1, \\pi_2</span> , setting the flag bad whenever there is a collision; that is, game  <span class="math">G_{1.5}</span>  is identical to game  <span class="math">G_2</span> except, after setting bad at line 211, set  <span class="math">Y \\stackrel{\\</span>}{\\leftarrow} \\overline{\\text{image}}(\\pi_i)$ , and after setting bad at line 221, set  <span class="math">X \\stackrel{\\</span>}{\\leftarrow} \\overline{\\operatorname{domain}}(\\pi_i)$ . Then modify game  <span class="math">G_{1.5}</span>  to <em>not</em> re-sample after setting bad, obtaining game  <span class="math">G_2</span> . Now  <span class="math">\\left|\\operatorname{\\mathbf{Adv}}(A_1^G,A_3^G)\\right| = \\left|\\operatorname{\\mathbf{Adv}}(A_{1.5}^G,A_3^G)\\right| = \\left|\\operatorname{\\mathbf{Adv}}(A_{1.5}^G,A_2^G)\\right| \\leq \\Pr[A_2^G \\text{ sets } bad]</span> . Then note that on the i&lt;sup&gt;th&lt;/sup&gt; query the probability that bad will be set in game  <span class="math">G_2</span>  is at most (i-1)/N since the size of domain <span class="math">(\\pi_j)</span>  and image <span class="math">(\\pi_j)</span>  will be at most i-1 for each  <span class="math">j \\in \\{0,1,2\\}</span> . So over all q queries, the probability that bad ever gets set in game  <span class="math">G_2</span>  is at most  <span class="math">0.5q(q-1)/N \\leq 0.5q^2/N</span> . To establish Lemma 9 we now claim that</p>

    <p class="text-gray-300"><span class="math">$|\\mathbf{Adv}(A_1^H, A_3^G)| \\le 2q^2/N.</span>$
(15)</p>

    <p class="text-gray-300">First rewrite game  <span class="math">H_1</span>  as game  <span class="math">G_4</span>  (again in Figure 7). In the game we have written  <span class="math">S_0 = S_1 = \\mathrm{id}</span>  and  <span class="math">S_2 = S</span>  where id is the identity function on  <span class="math">\\{0,1\\}^n</span>  and S is the fixed permutation in the lemma statement. Addition (+1 and +2) is again understood to be modulo 3. Game  <span class="math">G_4</span>  uses a form of lazy sampling, but it is not maximally lazy; on each query, not only is its answer chosen, but answers for some related queries are chosen and stored. In particular, the game maintains a set  <span class="math">\\mathcal{C}</span>  of commitments. Initially there are no commitments, but every time a query  <span class="math">\\mathbf{\\Pi}(i,X)</span>  or  <span class="math">\\mathbf{\\Pi}^{-1}(i,Y)</span>  is asked, one of two things happens: if a commitment has already been made specifying how to answer this query, we answer according to that commitment; else we not only answer the query asked, but commit ourselves to all of the queries in a &quot;triangle&quot; containing the queried point. In greater detail,  <span class="math">(i, X, Y) \\in \\mathcal{C}</span>  (for  <span class="math">i \\in \\{0, 1, 2\\}</span>  and  <span class="math">X, Y \\in \\{0, 1\\}^n</span> ) means that it has already been decided that  <span class="math">\\pi_i(X) = Y</span> , so a forward query  <span class="math">\\mathbf{\\Pi}(i, X)</span>  will need to be answered by Y and a backward</p>

    <pre><code class="language-text">procedure Initialize
                                                                                                                                                 Game G_1
100 \\pi_0, \\pi_1, \\pi_2 \\stackrel{\\$}{\\leftarrow} \\text{Perm}(n), \\quad \\pi_2 \\leftarrow S \\circ \\pi_0^{-1} \\circ \\pi_1^{-1}
                                                                                                                                                 Game H_1
procedure \\Pi(i,X)
                                                               procedure \\Pi^{-1}(i,Y)
                                                               120 return \\pi_i^{-1}[Y]
110 return \\pi_i[X]
procedure \\Pi(i, X)
                                                               procedure \\Pi^{-1}(i,Y)
                                                                                                                                                  Game G_2
       Y \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n
                                                                        X \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n
        if Y \\in \\text{image}(\\pi_i) then bad \\leftarrow \\text{true}
                                                               221
                                                                        if X \\in \\text{domain}(\\pi_i) then bad \\leftarrow \\text{true}
213
        \\pi[X] \\leftarrow Y
                                                               223
                                                                        \\pi[X] \\leftarrow Y
        return Y
                                                                        return X
procedure \\Pi(i,X)
                                                               procedure \\Pi^{-1}(i,Y)
                                                                                                                                                  Game G_3
       return Y \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n
                                                               320 return X \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n
</code></pre>

    <pre><code class="language-text">procedure \\Pi(i,X)
                                                                                                                                                                             Game G_4
410 if \\exists (i, X, Y) \\in \\mathcal{C} then return Y
       X_{i+1} \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n, if X_{i+1} \\in D_{i+1} then bad \\leftarrow \\mathsf{true}, X_{i+1} \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n \\setminus S_{i+1}
      X_{i+2} \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n, if X_{i+2} \\in D_{i+2} then bad \\leftarrow \\text{true}, X_{i+2} \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n \\setminus S_{i+2}
        D_i \\leftarrow D_i \\cup \\{X_i\\}, \\ D_{i+1} \\leftarrow D_{i+1} \\cup \\{X_{i+1}\\}, \\ D_{i+2} \\leftarrow D_{i+2} \\cup \\{X_{i+2}\\}
         \\mathcal{C} \\leftarrow \\mathcal{C} \\cup \\{(i, X_i, S_i(X_{i+1})), (i+1, X_{i+1}, S_{i+1}(X_{i+2})), (i+2, X_{i+2}, S_{i+2}(X_i))\\}
416 return S_i(X_{i+1})
procedure \\Pi^{-1}(i,Y)
         if \\exists (i, X, Y) \\in \\mathcal{C} then return X
         X_{i+1} \\leftarrow Y
         X_i \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n, if X_i \\in D_{i+1} then bad \\leftarrow \\mathsf{true}, X_i \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n \\setminus S_{i+1}
       X_{i+2} \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n, if X_{i+2} \\in D_{i+2} then bad \\leftarrow \\mathsf{true}, X_{i+2} \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n \\setminus S_{i+2}
         D_i \\leftarrow D_i \\cup \\{X_i\\}, \\ D_{i+1} \\leftarrow D_{i+1} \\cup \\{X_{i+1}\\}, \\ D_{i+2} \\leftarrow D_{i+2} \\cup \\{X_{i+2}\\}
         \\mathcal{C} \\leftarrow \\mathcal{C} \\cup \\{(i, X_i, S_i(X_{i+1})), (i+1, X_{i+1}, S_{i+1}(X_{i+2})), (i+2, X_{i+2}, S_{i+2}(X_i))\\}
         return S_{i+2}(X_i)
</code></pre>

    <p class="text-gray-300">Figure 7: Games for bounding the probability of distinguishing  <span class="math">(\\pi_0, \\pi_1, \\pi_2)</span>  and  <span class="math">(\\pi_0, \\pi_1, \\pi_1^{-1} \\circ \\pi_0^{-1})</span>  by an adversary that never extends a two-chain.</p>

    <p class="text-gray-300">query  <span class="math">\\Pi^{-1}(i, Y)</span>  will need to be answered by X. In effect, we grow permutations  <span class="math">\\pi_0</span> ,  <span class="math">\\pi_1</span> , and  <span class="math">\\pi_2</span>  but store their values in  <span class="math">\\mathcal{C}</span>  and their domains in  <span class="math">D_0, D_1</span> , and  <span class="math">D_2</span> .</p>

    <p class="text-gray-300">We claim that games  <span class="math">H_1</span>  and  <span class="math">G_4</span>  are adversarially indistinguishable even by an adversary that is not valid and asks all 6N possible queries. From this we know that  <span class="math">\\Pr[A_4^G \\Rightarrow 1] = \\Pr[A^{H_1} \\Rightarrow 1]</span> . To show this equivalence we claim that whether the queries are answered by game  <span class="math">G_4</span>  or by game  <span class="math">H_1</span>  the adversary gets the same view: any of  <span class="math">(N!)^2</span>  possible outcomes, each with probability  <span class="math">1/(N!)^2</span> , the answers correspond to a pair of permutations  <span class="math">\\pi_0</span> ,  <span class="math">\\pi_1</span>  along with  <span class="math">\\pi_2 = \\pi_0^{-1} \\circ \\pi_1^{-1}</span> . This is obviously the case when playing game  <span class="math">H_1</span> ; we must show it is so for game  <span class="math">G_4</span> . Note that sets  <span class="math">D_0, D_1, D_2</span> , and C begin with no points in them, then they grow to 1, 1, 1, and 3 points; then to 2, 2, 2, and 6 points; and so forth, until they have N, N, N, and 3N points. Not every query changes the sizes of these sets; it either leaves the sets unaltered or changes them as indicated. The first query that augments C extends the partial functions  <span class="math">(\\pi_0, \\pi_1, \\pi_2)</span>  in any of  <span class="math">N^2</span>  different ways, each with the same probability; the second query that augments C extends  <span class="math">(\\pi_0, \\pi_1, \\pi_2)</span>  in any of  <span class="math">(N-1)^2</span>  different ways, each with the same probability; and so forth, until we have extended  <span class="math">(\\pi_0, \\pi_1, \\pi_2)</span>  in any of  <span class="math">(N!)^2</span>  different ways, each with the same probability. This establishes the claim.</p>

    <pre><code class="language-text">procedure Π(i, X) Game G5
510 if ∃ (i, X, Y ) ∈ C then
511 if (+1, i, X) ∈ P then bad ← true, Y $
                                       ← {0, 1}
                                               n
512 return Y
513 Xi ← X
514 Xi+1
          $
         ← {0, 1}
                n, if Xi+1 ∈ Di+1 then bad ← true
515 Xi+2
         ← {0, 1}
                n, if Xi+2 ∈ Di+2 then bad ← true
516 Di ← Di ∪ {Xi}, Di+1 ← Di+1 ∪ {Xi+1}, Di+2 ← Di+2 ∪ {Xi+2}
517 C←C∪{(i + 1, Xi+1, Si+1(Xi+2)), (i + 2, Xi+2, Si+2(Xi))}
518 P←P∪{(1, i + 2, Xi+2),(−1, i + 1, Si+1(Xi+2))}
519 return Si(Xi+1)
procedure Π−1(i, Y )
520 if ∃ (i, X, Y ) ∈ C then
521 if ∃ (−1, i, Y ) ∈ P then bad ← true, X $
                                         ← {0, 1}
                                                n
522 return X
523 Xi+1 ← Y
524 Xi
        $
       ← {0, 1}
              n, if Xi ∈ Di+1 then bad ← true
525 Xi+2
         ← {0, 1}
                n, if Xi+2 ∈ Di+2 then bad ← true
526 Di ← Di ∪ {Xi}, Di+1 ← Di+1 ∪ {Xi+1}, Di+2 ← Di+2 ∪ {Xi+2}
527 C←C∪{(i + 1, Xi+1, Si+1(Xi+2)), (i + 2, Xi+2, Si+2(Xi))}
528 P←P∪{(1, i + 2, Xi+2),(−1, i + 1, Si+1(Xi+2))}
529 return Si+2(Xi)
</code></pre>

    <p class="text-gray-300">Figure 8: Game G5.</p>

    <p class="text-gray-300">Now let us go back to assuming that the adversary is valid. We make a change to game G&lt;sup&gt;4&lt;/sup&gt; to arrive at game G5, shown in Figure 8. In the transition, we drop the first commitment from each group of three, since our assumptions about the adversary's behavior mean that these queries cannot be asked. We also drop the sequels to <em>bad</em> getting set at lines 412, 413, 422, and 423. More interestingly, in game G&lt;sup&gt;5&lt;/sup&gt; we maintain a set of &quot;poisoned&quot; queries P. As with game G4, when the adversary asks <strong>Π</strong>(i, Xi) we return a random Xi+1, and when the adversary asks <strong>Π<em><strong>−</strong></em>1</strong>(i, Xi+1) we return a random Xi, and in either case we choose a random Xi+2 and &quot;complete the triangle&quot; using this point. We don't expect the adversary to ask about Xi+2, and, what is more, his asking will cause problems. So we record the unlikely but problematic queries involving Xi+2 in P. If the adversary makes a poisoned query then we set <em>bad</em>. The changes we have made can only increase the probability that <em>bad</em> gets set: Pr[AG&lt;sup&gt;4&lt;/sup&gt; sets <em>bad</em> ] ≤ Pr[AG&lt;sup&gt;5&lt;/sup&gt; sets <em>bad</em> ].</p>

    <p class="text-gray-300">We claim that game G&lt;sup&gt;5&lt;/sup&gt; is adversarially indistinguishable from game G3. Remember that our adversary is valid: it does not ask queries whose answers are trivially known and it does not ask to extend any 2-chain. Suppose first that the adversary asks a query whose answer has not been memoized in a commitment. Then for a forward query, we choose a uniform value Xi+1 at line 514 and return it at line 519. Likewise for a backward query, we choose a uniform value X&lt;sup&gt;i&lt;/sup&gt; at line 524 and return it at line 529. So consider instead a query for which a commitment has been memoized. The code executes at lines 511–512 or lines 521–522. If the memoized query was poisoned—added to set P by an earlier execution of lines 518 or 528—then we return a random string (at line 511 or 521). If the memoized query was not poisoned, then we are extending a 1-chain, providing a value Xi+2 that was selected uniformly from {0, 1}&lt;sup&gt;n&lt;/sup&gt; at an earlier execution of line 515 or 525, with this value not yet having influenced the run. Thus we return a uniform random value, independent of all oracle responses so far, and Pr[AG&lt;sup&gt;5&lt;/sup&gt; ⇒ 1] = Pr[AG&lt;sup&gt;3&lt;/sup&gt; ⇒ 1].</p>

    <p class="text-gray-300">Finally, we must bound the probability that bad gets set in game  <span class="math">G_5</span> . The probability that bad ever gets set at any of lines 514, 515, 524, or 525 is at most  <span class="math">2(1+2+\\cdots+(q-1))/N \\leq q^2/N</span> . The probability that it gets set at lines 511 or 521 is at most  <span class="math">2(1+2+\\cdots+(q-1))/N</span>  because no information about the poisoned query is surfaced to the adversary. Overall we have that  <span class="math">\\Pr[A^{G_5} \\text{ sets } bad] \\leq 2q^2/N</span> . Putting everything together we have (15) and the proof of the lemma is complete.</p>

    <h4 id="sec-15" class="text-lg font-semibold mt-6">4.8 Proof of Lemma 7</h4>

    <p class="text-gray-300">To prove this lemma we can assume without loss of generality that B is deterministic. For any particular blockcipher  <span class="math">E \\in \\operatorname{Bloc}(k,n)</span>  we consider the game in which B is executed with oracles  <span class="math">E, E^{-1}</span> , which it queries, adaptively, until it halts. Note that there is no randomness involved in this game, since E is fixed and B is deterministic. Recall that  <span class="math">X \\xrightarrow{K} Y</span>  means that B has either made query E(K,X) and obtained Y as a result, or it has made query  <span class="math">E^{-1}(K,Y)</span>  and obtained X as a result, for  <span class="math">K \\in \\{0,1\\}^k</span>  and  <span class="math">X,Y \\in \\{0,1\\}^n</span> . Now we let</p>

    <p class="text-gray-300"><span class="math">$\\mathsf{Ch}_3^{E,B} \\ = \\ \\left| \\{ \\, (K_0,K_1,K_2,P) \\, : \\, \\exists \\, Q,R,S \\, [ \\, P \\overset{K_0}{\\to} \\, Q \\overset{K_1}{\\to} \\, R \\overset{K_2}{\\to} \\, S \\, ] \\, \\} \\right| \\, .</span>$</p>

    <p class="text-gray-300">This is the number of 3-chains created by B's queries. Here  <span class="math">K_0, K_1, K_2 \\in \\{0,1\\}^k</span>  are keys, and  <span class="math">P, Q, R, S \\in \\{0,1\\}^n</span> . As the notation indicates,  <span class="math">\\mathsf{Ch}_3^{E,B}</span>  is a number that depends on E and B. Regarding it as a random variable over the choice of E we have the following lemma, from which Lemma 7 will follow.</p>

    <p class="text-gray-300"><strong>Lemma 10</strong> Let  <span class="math">\\alpha = \\max(2e2^{k-n}, 2n+k)</span> . Then  <span class="math">\\mathbf{E}[\\mathsf{Ch}_3^{E,B}] &lt; 2\\alpha \\cdot q^2</span> , the expectation over  <span class="math">E \\overset{\\</span>}{\\leftarrow} \\mathrm{Bloc}(k,n)$ .</p>

    <p class="text-gray-300"><strong>Proof of Lemma 7:</strong> Consider the following game  <span class="math">L^E</span>  parameterized by a blockcipher  <span class="math">E \\in \\operatorname{Bloc}(k,n)</span> : adversary B is executed with oracles  <span class="math">E,E^{-1}</span>  until it halts, then  <span class="math">K_0,K_1,K_2</span>  are chosen at random from  <span class="math">\\{0,1\\}^k</span> , and flag bad is set if there exist P,Q,R,S such that  <span class="math">P \\xrightarrow{K_0} Q \\xrightarrow{K_1} R \\xrightarrow{K_2} S</span> . Let  <span class="math">p^{E,B} = \\Pr[L_B^E \\text{ sets } bad]</span> , the probability being over the random choices of  <span class="math">K_0,K_1,K_2</span> . Then for any  <span class="math">E \\in \\operatorname{Bloc}(k,n)</span>  we have</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} p^{E,B} &amp;= \\Pr\\left[\\exists \\, P, Q, R, S \\, : \\, P \\overset{K_0}{\\to} Q \\overset{K_1}{\\to} R \\overset{K_2}{\\to} S \\,\\right] \\\\ &amp;= \\frac{|\\{\\, (K_0, K_1, K_2) \\, : \\, \\exists \\, P, Q, R, S \\, : \\, P \\overset{K_0}{\\to} Q \\overset{K_1}{\\to} R \\overset{K_2}{\\to} S \\,\\}|}{2^{3k}} \\\\ &amp;\\leq \\frac{\\sum_P |\\{\\, (K_0, K_1, K_2) \\, : \\, \\exists \\, Q, R, S \\, : \\, P \\overset{K_0}{\\to} Q \\overset{K_1}{\\to} R \\overset{K_2}{\\to} S \\,\\}|}{2^{3k}} \\, = \\frac{\\mathsf{Ch}_3^{E,B}}{2^{3k}} \\, . \\end{split}</span>$</p>

    <p class="text-gray-300">By Lemma 10 we have  <span class="math">\\Pr[B^L \\text{ sets } bad] = \\mathbf{E}[p^{E,B}] \\leq \\mathbf{E}[\\mathsf{Ch}_3^{E,B}] \\cdot 2^{-3k} &lt; 2\\alpha q^2 2^{-3k} \\text{ where } \\alpha = \\max(2e2^{k-n}, 2n+k) \\text{ and the expectation is over } E \\overset{\\</span>}{\\leftarrow} \\operatorname{Bloc}(k,n).$</p>

    <p class="text-gray-300">Towards the proof of Lemma 10, for  <span class="math">E \\in \\operatorname{Bloc}(k,n)</span>  and  <span class="math">Q, R \\in \\{0,1\\}^n</span>  we let</p>

    <p class="text-gray-300"><span class="math">$\\mathsf{Keys}^E(Q,R) \\ = \\ |\\{\\ K\\ : \\ E(K,Q) = R\\ \\}| \\quad \\text{and} \\quad \\mathsf{Keys}^E \\ = \\ \\max_{Q,R} \\{\\mathsf{Keys}^E(Q,R)\\}\\ .</span>$</p>

    <p class="text-gray-300">The first is the number of keys for which Q maps to R under E, and the second is the maximum value of  <span class="math">\\mathsf{Keys}^E(Q,R)</span>  over all  <span class="math">Q,R \\in \\{0,1\\}^n</span> . No adversary is involved in this definition;  <span class="math">\\mathsf{Keys}^E</span>  is simply a number associated to a given blockcipher. Viewing it as a random variable over the choice of blockcipher we have the following.</p>

    <p class="text-gray-300"><strong>Lemma 11</strong> Suppose  <span class="math">\\beta \\geq 2e2^{k-n}</span> . Then  <span class="math">\\Pr\\left[\\mathsf{Keys}^E \\geq \\beta\\right] &lt; 2^{2n+1-\\beta}</span> , where the probability is over  <span class="math">E \\overset{\\</span>}{\\leftarrow} \\operatorname{Bloc}(k,n)$ .</p>

    <p class="text-gray-300"><strong>Proof of Lemma 11:</strong> We claim that for any  <span class="math">Q, R \\in \\{0, 1\\}^n</span>  <span class="math">\\Pr\\left[\\mathsf{Keys}^E(Q, R) \\ge \\beta\\right] &lt; 2^{1-\\beta}</span> . (16)</p>

    <p class="text-gray-300">The lemma follows via the union bound. We prove (16) using an occupancy-problem approach. Let  <span class="math">b = \\lceil \\beta \\rceil</span> . Then</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\Pr\\left[ \\, \\mathsf{Keys}^E(Q,R) \\geq \\beta \\, \\right] &amp;= \\sum_{i=b}^{2^k} \\binom{2^k}{i} \\left( \\frac{1}{2^n} \\right)^i \\left( 1 - \\frac{1}{2^n} \\right)^{2^k - i} \\\\ &amp;\\leq \\sum_{i=b}^{2^k} \\left( \\frac{2^k e}{i} \\right)^i \\left( \\frac{1}{2^n} \\right)^i \\, \\leq \\, \\sum_{i=b}^{2^k} \\left( \\frac{2^k e}{2^n b} \\right)^i \\; . \\end{split}</span>$</p>

    <p class="text-gray-300">Let  <span class="math">x = (e/b)2^{k-n}</span> . The assumption  <span class="math">\\beta \\ge 2e2^{k-n}</span>  gives  <span class="math">x \\le 1/2</span> . So the above is</p>

    <p class="text-gray-300"><span class="math">$=\\sum_{i=b}^{2^k} x^i &lt; x^b \\cdot \\sum_{i=0}^{\\infty} x^i = \\frac{x^b}{1-x} \\le \\frac{2^{-b}}{1-1/2} = 2^{1-b} \\le 2^{1-\\beta}</span>$</p>

    <p class="text-gray-300">as desired.</p>

    <p class="text-gray-300"><strong>Proof of Lemma 10:</strong> For any  <span class="math">Q, R \\in \\{0, 1\\}^n</span>  we let</p>

    <p class="text-gray-300"><span class="math">$\\begin{array}{lcl} \\mathsf{Ch}_{2}^{E,B}(R) &amp; = &amp; |\\{\\,(K_{0},K_{1},P)\\,:\\,\\exists\\,Q\\,[P\\overset{K_{0}}{\\to}Q\\overset{K_{1}}{\\to}R\\,]\\,\\}|\\\\ \\mathsf{Ch}_{1}^{E,B}(Q) &amp; = &amp; |\\{\\,(K_{0},P)\\,:\\,P\\overset{K_{0}}{\\to}Q\\,\\}|\\\\ \\mathsf{Ch}_{0}^{E,B}(R) &amp; = &amp; |\\{\\,K_{2}\\,:\\,\\exists\\,S\\,[R\\overset{K_{2}}{\\to}S\\,]\\,\\}|\\,. \\end{array}</span>$</p>

    <p class="text-gray-300">Then for any  <span class="math">E \\in \\operatorname{Bloc}(k, n)</span>  we have</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\mathsf{Ch}_3^{E,B} &amp;= \\sum_R \\mathsf{Ch}_2^{E,B}(R) \\cdot \\mathsf{Ch}_0^{E,B}(R) \\\\ &amp;\\leq \\sum_R \\left( \\sum_Q \\mathsf{Ch}_1^{E,B}(Q) \\cdot \\mathsf{Keys}^E(Q,R) \\right) \\cdot \\mathsf{Ch}_0^{E,B}(R) \\\\ &amp;\\leq \\sum_R \\left( \\sum_Q \\mathsf{Ch}_1^{E,B}(Q) \\cdot \\mathsf{Keys}^E \\right) \\cdot \\mathsf{Ch}_0^{E,B}(R) \\\\ &amp;= \\mathsf{Keys}^E \\cdot \\left( \\sum_Q \\mathsf{Ch}_1^{E,B}(Q) \\right) \\cdot \\left( \\sum_R \\mathsf{Ch}_0^{E,B}(R) \\right) \\\\ &amp;\\leq \\mathsf{Keys}^E \\cdot q \\cdot q = q^2 \\cdot \\mathsf{Keys}^E \\;. \\end{split}</span>$</p>

    <p class="text-gray-300">Using the above and Lemma 11, we have the following, where the probability and expectation are both over  <span class="math">E \\stackrel{\\</span>}{\\leftarrow} \\operatorname{Bloc}(k, n)$ :</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\mathbf{E}[\\mathsf{Ch}_3^{E,B}] &amp;&lt;&amp; \\mathbf{E}\\left[\\mathsf{Ch}_3^{E,B} \\mid \\mathsf{Keys}^E &lt; \\alpha\\right] + \\mathbf{E}\\left[\\mathsf{Ch}_3^{E,B} \\mid \\mathsf{Keys}^E \\ge \\alpha\\right] \\cdot 2^{2n+1-\\alpha} \\\\ &amp;\\leq &amp; q^2 \\cdot \\alpha + q^2 \\cdot 2^k \\cdot 2^{2n+1-\\alpha} \\;. \\end{split}</span>$</p>

    <p class="text-gray-300">The last inequality above used the fact that  <span class="math">\\mathsf{Keys}^E</span>  is always at most  <span class="math">2^k</span> . Since  <span class="math">\\alpha = \\max(2e2^{k-n}, 2n + k) &gt; 2</span>  we get  <span class="math">\\mathbf{E}[\\mathsf{Ch}_3^{E,B}] &lt; q^2\\alpha + q^2 \\cdot 2 &lt; 2\\alpha \\cdot q^2</span>  as desired.</p>

    <h2 id="sec-16" class="text-2xl font-bold">5 Elementary Proof for the CBC MAC</h2>

    <p class="text-gray-300">In this section we give a new proof for the security of the CBC MAC. Our proof is far simpler than the original one [5] or the recently devised one that offers an improved bound [7].</p>

    <p class="text-gray-300">Fix  <span class="math">n \\geq 1</span> . A block is a string of length n, and M is a string of blocks if |M| is divisible by n. If  <span class="math">M \\in (\\{0,1\\}^n)^*</span>  is a string of blocks we let  <span class="math">M_i = M[n(i-1)+1..ni]</span>  denote the  <span class="math">i^{\\text{th}}</span>  block of M. If  <span class="math">\\pi: \\{0,1\\}^n \\to \\{0,1\\}^n</span>  is a function and  <span class="math">M \\in (\\{0,1\\}^n)^m</span>  is a string of n-bit blocks then we define  <span class="math">\\text{CBC}_{\\pi}(M)</span>  as the result of running the following algorithm:  <span class="math">C \\leftarrow 0^n</span> , for  <span class="math">i \\leftarrow 1</span>  to m do  <span class="math">C \\leftarrow \\pi(C \\oplus M_i)</span> ; return C. Let Perm(n) denote the set of all permutations on  <span class="math">\\{0,1\\}^n</span>  and let Func(mn,n) denote the set of all functions from  <span class="math">\\{0,1\\}^{mn}</span>  to  <span class="math">\\{0,1\\}^n</span> . For  <span class="math">m \\geq 1</span>  and  <span class="math">\\pi \\in \\text{Perm}(n)</span>  let  <span class="math">\\text{CBC}_{\\pi}^m</span>  be the restriction of  <span class="math">\\text{CBC}_{\\pi}</span>  to the domain  <span class="math">\\{0,1\\}^{mn}</span> . Given an algorithm A that never repeats a query and asks queries that are strings of n-bit blocks, the adversary having oracle-access to a function  <span class="math">F: \\{0,1\\}^{mn} \\to \\{0,1\\}^n</span> , let</p>

    <p class="text-gray-300"><span class="math">$\\begin{array}{lcl} \\mathbf{Adv}^{\\mathrm{cbc}}_{n,m}(A) &amp; = &amp; \\Pr[\\pi \\xleftarrow{\\</span>} \\mathrm{Perm}(n) : \\ A^{\\mathrm{CBC}^m_{\\pi}(\\cdot)} \\Rightarrow 1] - \\Pr[\\rho \\xleftarrow{$} \\mathrm{Func}(mn,n) : \\ A^{\\rho(\\cdot)} \\Rightarrow 1] &amp; \\text{and} \\ \\mathbf{Adv}^{\\mathrm{cbc}}<em>{n,m}(q) &amp; = &amp; \\max\\left{\\mathbf{Adv}^{\\mathrm{cbc}}</em>{n,m}(A)\\right} \\end{array}$$</p>

    <p class="text-gray-300">where, for the second definition, the maximum is over all adversaries A that ask at most q queries, regardless of oracle responses. To avoid working out uninteresting special cases, we assume throughout that  <span class="math">q, m \\ge 2</span> . We will show the following using games followed by a simple case analysis.</p>

    <p class="text-gray-300">Theorem 12 [CBC MAC, conventional bound]  <span class="math">\\mathbf{Adv}_{n,m}^{\\mathrm{cbc}}(q) \\leq m^2 q^2 / 2^n</span>  for any  <span class="math">m, q \\geq 2, n \\geq 1</span> .</p>

    <p class="text-gray-300"><strong>Proof:</strong> Without loss of generality assume that A is deterministic and asks exactly q queries of m blocks each and that it never repeats a query. Refer to games  <span class="math">C_0</span> — <span class="math">C_9</span>  defined in Figures 9 and 10. Let us begin by explaining the conventions used in these games. When M is string of blocks we write  <span class="math">M_i</span>  for the  <span class="math">i^{th}</span>  block of M, as before, and we write  <span class="math">M_{1...j} = M[1...jn]</span>  for the first j blocks. In writing  <span class="math">\\overline{\\text{domain}}(\\pi)</span>  the complement is with respect to  <span class="math">\\{0,1\\}^n</span> . The value defined is an arbitrary string (it is never used), for concreteness,  <span class="math">0^n</span> . Finally,  <span class="math">\\text{Prefix}(M^1, \\ldots, M^s)</span>  is the longest string of blocks  <span class="math">P = P_1 \\cdots P_p</span>  that is a prefix of  <span class="math">M^s</span>  and is also a prefix of  <span class="math">M^r</span>  for some r &lt; s. If Prefix is applied to a single string the result is the empty string,  <span class="math">\\text{Prefix}(P^1) = \\varepsilon</span> . As an example, letting A, B, and C be distinct blocks,  <span class="math">\\text{Prefix}(ABC) = \\varepsilon</span> , Prefix(ACC, ACB, ABB, ABA) = AB, and  <span class="math">\\text{Prefix}(ACC, ACB, BBB) = \\varepsilon</span> .</p>

    <p class="text-gray-300">We briefly explain the game chain up until the terminal game.  <span class="math">\\triangleright</span>  Game  <span class="math">C_0</span>  is obtained from game  <span class="math">C_1</span>  by dropping the assignment statements that immediately follow the setting of bad.  <span class="math">\\triangleright</span>  Game  <span class="math">C_1</span>  is a realization of  <span class="math">\\mathsf{CBC}^m[\\mathsf{Perm}(n)]</span>  and game  <span class="math">C_0</span>  is a realization of  <span class="math">\\mathsf{Func}(mn,n)</span> . The games use lazy sampling of a random permutation (as described in Section 7.4) and the resampling idiom (as described in Section 7.2). Games  <span class="math">C_1</span>  and  <span class="math">C_0</span>  are designed so that the Fundamental Lemma applies, so the advantage of A in attacking the CBC construction is at most  <span class="math">\\mathsf{Pr}[A^{C_0} \\text{ sets } bad]</span> .  <span class="math">\\triangleright C_0 \\to C_2</span> : This is a lossy transition that takes care of bad getting set at line 105, which clearly happens with probability at most  <span class="math">(0+1+\\cdots+(mq-1))/2^n \\leq 0.5\\,m^2q^2/2^n</span> , so  <span class="math">\\mathsf{Pr}[A^{C_0} \\text{ sets } bad] \\leq \\mathsf{Pr}[A^{C_2} \\text{ sets } bad] + 0.5\\,m^2q^2/2^n</span> .  <span class="math">\\triangleright C_2 \\to C_3</span> : Next notice that in game  <span class="math">C_2</span>  we never actually use the values assigned to  <span class="math">\\pi</span> , all that matters is that we record that a value has been placed in the domain of  <span class="math">\\pi</span> , and so game  <span class="math">C_3</span>  does just that, dropping a fixed value defined into  <span class="math">\\pi[X]</span>  when we want X to join the domain of  <span class="math">\\pi</span> . This is the technique we called &quot;marking instead of recording&quot; in Section 7.2. The change is conservative.  <span class="math">\\triangleright C_3 \\to C_4</span> : Now notice that in game  <span class="math">C_3</span>  the value returned to the adversary, although dropped into  <span class="math">T[M_1^s \\cdots M_m^s]</span> , is never subsequently used in the game so we could</p>

    <pre><code class="language-text">Initialize
                                                                                Game C_0
                                                                                                    Initialize
                                                                                                                                                                                     Game C_2
                                                                               \\overline{\\text{Game}} C_1
100 T[\\varepsilon] \\leftarrow 0^n
                                                                                                    200 T[\\varepsilon] \\leftarrow 0^n
                                                                                                    procedure F(M)
procedure F(M)
                                                                                                    210 s \\leftarrow s + 1, M^s \\leftarrow M
110 s \\leftarrow s + 1, M^s \\leftarrow M
111 P \\leftarrow \\mathsf{Prefix}(M^1, \\dots, M^s), \\ p \\leftarrow |P|/n, \\ C \\leftarrow T[P]
                                                                                                    211 P \\leftarrow \\mathsf{Prefix}(M^1, \\dots, M^s), p \\leftarrow |P|/n, C \\leftarrow T[P]
112 for j \\leftarrow p + 1 to m do
                                                                                                    212 for j \\leftarrow p+1 to m do
            X \\leftarrow C \\oplus M_i
                                                                                                    213
                                                                                                                X \\leftarrow C \\oplus M_j
113
            C \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n
                                                                                                                C \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n
                                                                                                    214
114
                                                                                                    215
                                                                                                                 if X \\in \\text{domain}(\\pi) then bad \\leftarrow \\text{true}
            if C \\in \\text{image}(\\pi) then bad \\leftarrow \\text{true}, C \\leftarrow \\overline{\\text{image}}(\\pi)
                                                                                                    216
                                                                                                                 \\pi[X] \\leftarrow C
             if X \\in \\text{domain}(\\pi) then bad \\leftarrow \\text{true}, |C \\leftarrow \\pi[X]|
116
                                                                                                    217
                                                                                                                 T[M_{1..i}] \\leftarrow C
             \\pi[X] \\leftarrow C
117
                                                                                                    218 return C
            T[M_{1..i}] \\leftarrow C
118
119 return C
Initialize
                                                                                Game C_3 | Initialize
                                                                                                                                                                                     Game C_4
300 T[\\varepsilon] \\leftarrow 0^n, defined \\leftarrow 0^n
                                                                                                    400 \\ T[\\varepsilon] \\leftarrow 0^n, defined \\leftarrow 0^n
procedure F(M)
                                                                                                    procedure F(M)
310 s \\leftarrow s + 1, \\ M^s \\leftarrow M
                                                                                                    410 s \\leftarrow s + 1, \\ M^s \\leftarrow M
311 P \\leftarrow \\mathsf{Prefix}(M^1, \\dots, M^s), p \\leftarrow |P|/n, C \\leftarrow T[P]
                                                                                                    411 P \\leftarrow \\mathsf{Prefix}(M^1, \\dots, M^s), p \\leftarrow |P|/n, C \\leftarrow T[P]
                                                                                                    412 for j \\leftarrow p+1 to m do
312 for j \\leftarrow p+1 to m do
            X \\leftarrow C \\oplus M_i
                                                                                                    413
                                                                                                                 X \\leftarrow C \\oplus M_i
313
            C \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n
                                                                                                    414
                                                                                                                 if X \\in \\operatorname{domain}(\\pi) then bad \\leftarrow \\mathsf{true}
314
                                                                                                                 \\pi[X] \\leftarrow \\mathsf{defined}
                                                                                                    415
            if X \\in \\operatorname{domain}(\\pi) then bad \\leftarrow \\mathsf{true}
                                                                                                                 C \\leftarrow T[M_{1..j}] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n
             \\pi[X] \\leftarrow \\mathsf{defined}
                                                                                                    416
316
                                                                                                    417 Z^s \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n
317
            T[M_{1..j}] \\leftarrow C
                                                                                                    418 return Z^s
318 return C
Finalize
                                                                                Game C_5
                                                                                                    Finalize
                                                                                                                                                                                     Game C_6
500 T[\\varepsilon] \\leftarrow 0^n, defined \\leftarrow 0^n
                                                                                                    600 T[\\varepsilon] \\leftarrow 0^n, defined \\leftarrow 0^n
501 for s \\leftarrow 1 to q do
                                                                                                    601 for s \\leftarrow 1 to q do
            P \\leftarrow \\mathsf{Prefix}(\\mathtt{M}^1, \\dots, \\mathtt{M}^s), \\ p \\leftarrow |P|/n, \\ C \\leftarrow T[P]
                                                                                                    602
                                                                                                                 P \\leftarrow \\mathsf{Prefix}(\\mathsf{M}^1, \\dots, \\mathsf{M}^s), \\ p \\leftarrow |P|/n, \\ C \\leftarrow T[P]
503
            for j \\leftarrow p + 1 to m do
                                                                                                    603
                                                                                                                 X \\leftarrow C \\oplus \\mathsf{M}_{p+1}^s
504
                X \\leftarrow C \\oplus M_i^s
                                                                                                    604
                                                                                                                 if X \\in \\operatorname{domain}(\\pi) then bad \\leftarrow \\mathsf{true}
505
                if X \\in \\operatorname{domain}(\\pi) then bad \\leftarrow \\mathsf{true}
                                                                                                                 \\pi[X] \\leftarrow \\mathsf{defined}
                                                                                                    605
                \\pi[X] \\leftarrow \\mathsf{defined}
506
                                                                                                    606
                                                                                                                 C \\leftarrow T[\\mathbf{M}_{1..p+1}^s] \\stackrel{\\mathfrak{s}}{\\leftarrow} \\{0,1\\}^n
                C \\leftarrow T[\\mathsf{M}_{1...i}^s] \\xleftarrow{\\$} \\{0,1\\}^n
507
                                                                                                    607
                                                                                                                 for j \\leftarrow p + 2 to m do
                                                                                                    608
                                                                                                                     X \\leftarrow C \\oplus M_i^s
                                                                                                    609
                                                                                                                     if X \\in \\operatorname{domain}(\\pi) then bad \\leftarrow \\mathsf{true}
                                                                                                    610
                                                                                                                     \\pi[X] \\leftarrow \\mathsf{defined}
                                                                                                                     C \\leftarrow T[\\mathbf{M}_{1-i}^s] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n
                                                                                                    611
Finalize
                                                                                Game C_7
                                                                                                    Finalize
                                                                                                                                                                                     Game C_8
700 T[\\varepsilon] \\leftarrow 0^n, defined \\leftarrow 0^n
                                                                                                    800 T[\\varepsilon] \\leftarrow 0^n, defined \\leftarrow 0^n
                                                                                                    801 for X \\in (\\{0,1\\}^n)^+ do T[X] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n
701 for X \\in (\\{0,1\\}^n)^+ do T[X] \\stackrel{*}{\\leftarrow} \\{0,1\\}^n
701 for s \\leftarrow 1 to q do
                                                                                                    802 for s \\leftarrow 1 to q do
             P \\leftarrow \\mathsf{Prefix}(\\mathsf{M}^1, \\dots, \\mathsf{M}^s), \\ p \\leftarrow |P|/n
                                                                                                                 P^s \\leftarrow \\mathsf{Prefix}(\\mathsf{M}^1, \\dots, \\mathsf{M}^s), \\ \\ \\mathsf{p}^s \\leftarrow |\\mathsf{P}^s|/n
702
                                                                                                    803
703
            if T[P] \\oplus M_{n+1}^s \\in \\operatorname{domain}(\\pi) then bad \\leftarrow \\mathsf{true}
                                                                                                    804
                                                                                                                 if T[\\mathbf{P}^s] \\oplus \\mathbf{M}^s_{\\mathbf{p}^s+1} \\in \\operatorname{domain}(\\pi) then bad \\leftarrow \\mathsf{true}
             \\pi[T[P] \\oplus \\mathtt{M}_{p+1}^s] \\leftarrow \\mathsf{defined}
                                                                                                    805
                                                                                                                 \\pi[T[\\mathbf{P}^s] \\oplus \\mathbf{M}^s_{\\mathbf{p}^s+1}] \\leftarrow \\mathsf{defined}
704
             for j \\leftarrow p + 2 to m do
                                                                                                    806
                                                                                                                 for j \\leftarrow p^s + 1 to m - 1 do
705
                if T[\\mathbf{M}_{1..i-1}^s] \\oplus \\mathbf{M}_i^s \\in \\operatorname{domain}(\\pi) then bad \\leftarrow \\mathsf{true}
706
                                                                                                    807
                                                                                                                     if T[M_{1..i}^s] \\oplus M_{i+1}^s \\in \\operatorname{domain}(\\pi) then bad \\leftarrow \\mathsf{true}
                \\pi[T[\\mathtt{M}^s_{1..i-1}] \\oplus \\mathtt{M}^s_i] \\leftarrow \\mathsf{defined}
707
                                                                                                    808
                                                                                                                     \\pi[T[\\mathtt{M}_{1...i}^s] \\oplus \\mathtt{M}_{i+1}^s] \\leftarrow \\mathsf{defined}
</code></pre>

    <p class="text-gray-300">Figure 9: Games used for the CBC MAC analysis.  <span class="math">\\mathsf{Prefix}(M^1, \\dots, M^s), M_i</span> , and  <span class="math">M_{1...j}</span>  are defined in the text.</p>

    <pre><code class="language-text">Finalize

900 T[\\varepsilon] \\leftarrow 0^n

901 for X \\in (\\{0,1\\}^n)^+ do T[X] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^n

902 for s \\leftarrow 1 to q do P^s \\leftarrow \\mathsf{Prefix}(\\mathsf{M}^1, \\dots, \\mathsf{M}^s), p^s \\leftarrow |P^s|/n

903 bad \\leftarrow

904 T[P^s] \\oplus \\mathsf{M}^s_{p^s+1} = T[P^r] \\oplus \\mathsf{M}^r_{p^r+1} for some 1 \\le r &lt; s \\le q, or

905 T[P^s] \\oplus \\mathsf{M}^s_{p^s+1} = T[\\mathsf{M}^r_{1...i}] \\oplus \\mathsf{M}^r_{i+1} for some 1 \\le r &lt; s \\le q, p^r + 1 \\le i \\le m - 1, or

906 T[\\mathsf{M}^s_{1...j}] \\oplus \\mathsf{M}^s_{j+1} = T[P^r] \\oplus \\mathsf{M}^r_{p^r+1} for some 1 \\le r \\le s \\le q, p^s + 1 \\le j \\le m - 1, or

907 T[\\mathsf{M}^s_{1...j}] \\oplus \\mathsf{M}^s_{j+1} = T[\\mathsf{M}^r_{1...i}] \\oplus \\mathsf{M}^r_{i+1} for some 1 \\le r \\le s \\le q, p^r + 1 \\le i \\le m - 1, or
</code></pre>

    <p class="text-gray-300">Figure 10: Terminal game used in the analysis of the CBC MAC.</p>

    <p class="text-gray-300">as well choose a random value  <span class="math">Z^s</span>  and return it to the adversary, doing nothing else with  <span class="math">Z^s</span> . This is the change made for game  <span class="math">C_4</span> . The transition is conservative.  <span class="math">\\triangleright C_4 \\rightarrow C_5</span> : Changing game  <span class="math">C_4</span>  to  <span class="math">C_5</span> is by the de-randomization technique. First de-randomize line 417, letting each  <span class="math">Z^s</span>  be a constant  <span class="math">Z^s</span> . Thus we are not returning random values  <span class="math">Z^1, \\ldots, Z^q</span>  to the adversary, we are returning constants  <span class="math">Z^1, \\ldots, Z^q</span>  instead. Since adversary A is deterministic there are corresponding queries  <span class="math">M^1, \\ldots, M^q</span> that it will ask. As these are constants, we need no longer consider the adversary as interacting with its oracle; in game  <span class="math">C_5</span>  we &quot;hardwire in&quot; the sequence of queries  <span class="math">M^1, \\ldots, M^q</span>  (and responses  <span class="math">Z^1, \\ldots, Z^q</span>  except that these have no influence on the game) that the adversary A would have asked. The &quot;virtual-queries&quot;  <span class="math">M^1, \\ldots, M^q</span>  still have to be valid: each  <span class="math">M^s</span>  is an mn-bit string different from all prior ones. We have that  <span class="math">\\Pr[A^{C_4} \\text{ sets } bad] \\leq \\Pr[C_5 \\text{ sets } bad]</span> .  <span class="math">\\triangleright C_5 \\to C_6</span> : Game  <span class="math">C_6</span>  unrolls the first iteration of the loop at lines 503–507. This transformation is conservative.  <span class="math">\\triangleright C_6 \\rightarrow C_7</span> : Game  <span class="math">C_7</span>  is a rewriting of game  <span class="math">C_6</span>  that omits mention of the variables C and X, directly using values from the T-table instead, these values now being chosen at the beginning of the game. The change is conservative.  <span class="math">\\triangleright C_7 \\rightarrow C_8</span> : Game  <span class="math">C_8</span>  re-indexes the for loop at line 705–707. The change is conservative.  <span class="math">\\triangleright C_8 \\rightarrow C_9</span> : Game  <span class="math">C_9</span>  restructures the setting of bad inside the loop at 802–808 to set bad in a single statement. Points were put into the domain of  <span class="math">\\pi</span>  at lines 805 and 808 and we checked if any of these points coincide with specified other points at lines 804 and 807. Running through the four possible types of collisions gives rise to the tests at lines 904–907. The change is conservative.</p>

    <p class="text-gray-300">At this point we have only to bound  <span class="math">\\Pr[C_9 \\text{ sets } bad]</span> . We do this using the sum bound and a case analysis. Fix a line number among 904, 905, 906, and 907, and fix a corresponding r, i, s, j as specified on that line. We will show that the probability that the indicated equation holds is at most  <span class="math">2^{-n}</span>  and so, adding the loss incurred in transitioning from From this we can conclude that  <span class="math">\\Pr[C_9 \\text{ sets } bad] \\leq 0.5m^2q^2</span>  because the total number of equations under consideration is less than  <span class="math">0.5m^2q^2</span> . To see that this is the total number of equations note that we can name a candidate equation by choosing a pair of points  <span class="math">(r,i), (q,j) \\in [1..q] \\times [0..m-1]</span>  and then rejecting this pair if (r,i) does not proceed (s,j) in lexicographic order. Adding in the  <span class="math">0.5m^2q^2</span>  term we lost in going from game  <span class="math">C_0</span>  to game  <span class="math">C_2</span> , we will be done. The case analysis follows.</p>

    <p class="text-gray-300">Line 904. We first bound  <span class="math">\\Pr[T[\\mathsf{P}^r] \\oplus \\mathsf{M}^r_{\\mathsf{p}^r+1} = T[\\mathsf{P}^s] \\oplus \\mathsf{M}^s_{\\mathsf{p}^s+1}]</span> . If  <span class="math">\\mathsf{P}^r = \\mathsf{P}^s = \\varepsilon</span>  then  <span class="math">\\Pr[T[\\mathsf{P}^r] \\oplus \\mathsf{M}^r_{\\mathsf{p}^r+1} = T[\\mathsf{P}^s] \\oplus \\mathsf{M}^s_{\\mathsf{p}^s+1}] = \\Pr[\\mathsf{M}^r_1 = \\mathsf{M}^s_1] = 0</span>  because  <span class="math">\\mathsf{M}^r</span>  and  <span class="math">\\mathsf{M}^s</span> , having only  <span class="math">\\varepsilon</span>  as a common block prefix, must differ in their first blocks. If  <span class="math">\\mathsf{P}^r = \\varepsilon</span>  but  <span class="math">\\mathsf{P}^s \\neq \\varepsilon</span>  then  <span class="math">\\Pr[T[\\mathsf{P}^r] \\oplus \\mathsf{M}^r_{\\mathsf{p}^r+1} = T[\\mathsf{P}^s] \\oplus \\mathsf{M}^s_{\\mathsf{p}^s+1}] = \\Pr[\\mathsf{M}^r_1 = T[\\mathsf{P}^s] \\oplus \\mathsf{M}^s_{\\mathsf{p}^s+1}] = 2^{-n}</span>  since the probability expression involves the single random variable  <span class="math">T[\\mathsf{P}^s]</span>  that is uniformly distributed in  <span class="math">\\{0,1\\}^n</span> . If  <span class="math">\\mathsf{P}^r \\neq \\varepsilon</span>  and  <span class="math">\\mathsf{P}^s = \\varepsilon</span>  the same reasoning applies. If  <span class="math">\\mathsf{P}^r \\neq \\varepsilon</span>  and  <span class="math">\\mathsf{P}^s \\neq \\varepsilon</span>  then  <span class="math">\\Pr[T[\\mathsf{P}^r] \\oplus \\mathsf{M}^r_{\\mathsf{p}^r+1} = T[\\mathsf{P}^s] \\oplus \\mathsf{M}^s_{\\mathsf{p}^s+1}] = 2^{-n}</span>  unless  <span class="math">\\mathsf{P}^r = \\mathsf{P}^s</span> , so assume that to be the case. Then  <span class="math">\\Pr[T[\\mathsf{P}^r] \\oplus \\mathsf{M}^r_{\\mathsf{p}^r+1} = T[\\mathsf{P}^s] \\oplus \\mathsf{M}^s_{\\mathsf{p}^s+1}] = \\Pr[\\mathsf{M}^r_{\\mathsf{p}^r+1} = \\mathsf{M}^s_{\\mathsf{p}^s+1}] = 0</span>  because  <span class="math">\\mathsf{P}^r = \\mathsf{P}^s</span>  is the longest block prefix that coincides in  <span class="math">\\mathsf{M}^r</span>  and  <span class="math">\\mathsf{M}^s</span> .</p>

    <p class="text-gray-300">Line 905. We want to bound  <span class="math">\\Pr[T[\\mathsf{P}^s] \\oplus \\mathsf{M}^s_{\\mathsf{p}^s+1} = T[\\mathsf{M}^r_{1..i}] \\oplus \\mathsf{M}^r_{i+1}]</span> . If  <span class="math">\\mathsf{P}^s = \\varepsilon</span>  then  <span class="math">\\Pr[T[\\mathsf{P}^s] \\oplus \\mathsf{M}^s_{\\mathsf{p}^s+1} = T[\\mathsf{M}^r_{1..i}] \\oplus \\mathsf{M}^r_{i+1}] = \\Pr[\\mathsf{M}^s_{\\mathsf{p}^s+1} = T[\\mathsf{M}^r_{1..i}] \\oplus \\mathsf{M}^r_{i+1}] = 2^{-n}</span>  because it involves a single random value  <span class="math">T[\\mathsf{M}^r_{1..i}]</span> . So assume that  <span class="math">\\mathsf{P}^s \\neq \\varepsilon</span> . Then  <span class="math">\\Pr[T[\\mathsf{P}^s] \\oplus \\mathsf{M}^s_{\\mathsf{p}^s+1} = T[\\mathsf{M}^r_{1..i}] \\oplus \\mathsf{M}^r_{i+1}] = 2^{-n}</span>  unless  <span class="math">\\mathsf{P}^s = \\mathsf{M}^r_{1..i}</span>  in which case we are looking at  <span class="math">\\Pr[\\mathsf{M}^s_{\\mathsf{p}^s+1} = \\mathsf{M}^r_{\\mathsf{p}^s+1}]</span> . But this is 0 because  <span class="math">\\mathsf{P}^s = \\mathsf{M}^r_{1..i}</span>  means that the longest prefix that  <span class="math">\\mathsf{M}^s</span>  shares with  <span class="math">\\mathsf{M}^r</span>  is  <span class="math">\\mathsf{P}^s</span>  and so  <span class="math">\\mathsf{M}^s_{\\mathsf{p}^s+1} \\neq \\mathsf{M}^r_{\\mathsf{p}^s+1}</span> .</p>

    <p class="text-gray-300">Line 906. We must bound  <span class="math">\\Pr[T[\\mathtt{P}^r] \\oplus \\mathtt{M}^r_{\\mathtt{p}^r+1} = T[\\mathtt{M}^s_{1..j}] \\oplus \\mathtt{M}^s_{j+1}]</span> . It is at most by  <span class="math">2^{-n}</span>  as above.</p>

    <p class="text-gray-300">Line 907. What is  <span class="math">\\Pr[T[\\mathtt{M}_{1..j}^s] \\oplus \\mathtt{M}_{j+1}^s = T[\\mathtt{M}_{1..i}^r] \\oplus \\mathtt{M}_{i+1}^r]</span> . It is  <span class="math">2^{-n}</span>  unless i=j and  <span class="math">\\mathtt{M}_{1..j}^s = \\mathtt{M}_{1..i}^r</span> . In that case  <span class="math">\\mathtt{p}^s \\geq j</span>  and  <span class="math">\\mathtt{p}^r \\geq i</span> , contradicting the allowed values for i and j at line 907. This completes the proof.</p>

    <h3 id="sec-17" class="text-xl font-semibold mt-8">6 A Game-Based Proof for OAEP</h3>

    <p class="text-gray-300">BACKGROUND. We recall the needed background for the asymmetric encryption scheme OAEP [8]. A trapdoor-permutation generator with associated security parameter k is a randomized algorithm  <span class="math">\\mathcal{F}</span>  that returns a pair  <span class="math">(f, f^{-1})</span>  where  <span class="math">f: \\{0, 1\\}^k \\to \\{0, 1\\}^k</span>  is (the encoding of) a permutation and  <span class="math">f^{-1}</span>  is (the encoding of) its inverse. Let</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}^{\\mathrm{owf}}_{\\mathcal{F}}(I) = \\Pr[(f, f^{-1}) \\stackrel{\\</span>}{\\leftarrow} \\mathcal{F}; x \\stackrel{$}{\\leftarrow} {0, 1}^k : I(f, f(x)) = x]$$</p>

    <p class="text-gray-300">be the advantage of adversary I in inverting  <span class="math">\\mathcal{F}</span> . Let  <span class="math">\\rho &lt; k</span>  be an integer. The key-generation algorithm of asymmetric encryption scheme  <span class="math">\\mathsf{OAEP}^{\\rho}[\\mathcal{F}]</span>  is simply  <span class="math">\\mathcal{F}</span> , meaning it returns f as the public key and  <span class="math">f^{-1}</span>  as the secret key. The encryption and decryption algorithms have oracles  <span class="math">G \\colon \\{0,1\\}^{\\rho} \\to \\{0,1\\}^{k-\\rho}</span>  and  <span class="math">H \\colon \\{0,1\\}^{k-\\rho} \\to \\{0,1\\}^{\\rho}</span>  and work as follows (for the basic, no-authenticity scheme):</p>

    <p class="text-gray-300">algorithm
<span class="math">$\\mathcal{E}_f^{G,H}(M)</span>$
/*  <span class="math">M \\in \\{0,1\\}^{k-\\rho}</span>  */
<span class="math">$R \\overset{\\</span>}{\\leftarrow} {0,1}^{\\rho}$$
algorithm  <span class="math">\\mathcal{D}_{f^{-1}}^{G,H}(Y)</span>  /*  <span class="math">Y \\in \\{0,1\\}^k</span>  */
<span class="math">$X \\leftarrow f^{-1}(Y)</span>$</p>

    <p class="text-gray-300"><span class="math">$S \\leftarrow G(R) \\oplus M, \\ T \\leftarrow H(S) \\oplus R</span>$</p>

    <p class="text-gray-300"><span class="math">$Y \\leftarrow f(S \\parallel T)</span>$
return  <span class="math">Y</span>
<span class="math">$R \\leftarrow H(S) \\oplus T, \\ M \\leftarrow G(R) \\oplus S</span>$
return  <span class="math">M</span></p>

    <p class="text-gray-300">Security of an asymmetric encryption scheme  <span class="math">AE = (\\mathcal{F}, \\mathcal{E}, \\mathcal{D})</span>  is defined via the following game. Keys  <span class="math">(f, f^{-1})</span>  are chosen by running  <span class="math">\\mathcal{F}</span> , and a bit b is chosen at random. Adversary A is given input f and a left-or-right oracle  <span class="math">LR(\\cdot, \\cdot)</span>  which on input a pair  <span class="math">M_0, M_1</span>  of equal-length messages computes  <span class="math">Y \\stackrel{\\</span>}{\\leftarrow} \\mathcal{E}<em>f(M_b)$  and returns Y. The output of adversary is a bit b' and  $\\mathbf{Adv}</em>{AE}^{\\mathrm{ind-cpa}}(A) = 2\\Pr[b' = b] - 1$ .</p>

    <p class="text-gray-300"><strong>Theorem 13</strong> [IND-CPA security of OAEP] Let  <span class="math">\\mathcal{F}</span>  be a trapdoor permutation generator with associated security parameter k, and let  <span class="math">\\rho &lt; k</span>  be an integer. Let A be an adversary with running time  <span class="math">t_A</span> , making at most  <span class="math">q_G</span>  queries to its G oracle,  <span class="math">q_H</span>  to its H oracle, and exactly one query to its left-or-right oracle. Then there is an adversary I with running time  <span class="math">t_I</span>  such that</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}^{\\mathrm{owf}}_{\\mathcal{F}}(I) \\; \\geq \\; \\frac{1}{2} \\, \\mathbf{Adv}^{\\mathrm{ind-cpa}}_{\\mathsf{OAEP}^{\\rho}[\\mathcal{F}]}(A) - \\frac{2q_G}{2^{\\rho}} - \\frac{q_H}{2^{k-\\rho}} \\quad \\ and \\quad \\ t_I \\; \\leq \\; t_A + c \\, q_G q_H \\, t_{\\mathcal{F}}</span>$</p>

    <p class="text-gray-300">where  <span class="math">t_{\\mathcal{F}}</span>  is the time for one computation of a function output by  <span class="math">\\mathcal{F}</span>  and c is an absolute constant depending only on details of the model of computation.</p>

    <p class="text-gray-300"><strong>Proof:</strong> The proof is based on games shown in Figures 11–13. For these games regard  <span class="math">\\mathcal{F}</span> , k, and  <span class="math">\\rho</span>  as fixed; they are hardwired into the games. We have striven to makes steps between adjacent games small at the cost of a somewhat longer game chain.</p>

    <pre><code class="language-text">procedure LR(M_0, M_1)
                                                                                                                                                    Game P_0
000 \\quad R^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
                                         001 GR^* \\leftarrow \\{0,1\\}^{k-\\rho}
                                                                                  002 if G[R^*] then bad \\leftarrow \\mathsf{true}, \\ GR^* \\leftarrow G[R^*]
003 \\quad S^* \\leftarrow GR^* \\oplus M_h
                                         004 \\quad HS^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
                                                                                  005 if H[S^*] then bad \\leftarrow \\text{true}, HS^* \\leftarrow H[S^*]
006 \\quad T^* \\leftarrow R^* \\oplus HS^*
                                               return Y^* \\leftarrow f(S^* \\parallel T^*)
                                                                                                  procedure H(S)
procedure G(R)
010 if R = R^* then return G[R^*] \\leftarrow GR^*
                                                                                                 020 if S = S^* then return H[S^*] \\leftarrow HS^*
        return G[R] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{k-\\rho}
                                                                                                  021 return H[S] \\leftarrow \\{0,1\\}^{\\rho}
procedure LR(M_0, M_1)
                                                                                                                                                    Game P_1
                                         101 GR^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{k-\\rho} 102 S^* \\leftarrow GR^* \\oplus M_b
100 R^* \\leftarrow \\{0,1\\}^{\\rho}
                                                                                                                           103 HS^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
        T^* \\leftarrow R^* \\oplus HS^*
                                         105 return Y^* \\leftarrow f(S^* \\parallel T^*)
procedure G(R)
                                                                                                 procedure H(S)
                                                                                                 120 if S = S^* then return H[S^*] \\leftarrow HS^*
110 if R = R^* then return G[R^*] \\leftarrow GR^*
111 return G[R] \\leftarrow {\\{0,1\\}}^{k-\\rho}
                                                                                                  121 return H[S] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
procedure LR(M_0, M_1)
                                                                                                                                                    Game P_2
                                        201 GR^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{k-\\rho} 202 S^* \\leftarrow GR^* \\oplus M_b
200 R^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
                                                                                                                           203 HS^* \\leftarrow \\{0,1\\}^{\\rho}
204 \\quad T^* \\leftarrow R^* \\oplus HS^*
                                         205 return Y^* \\leftarrow f(S^* \\parallel T^*)
procedure G(R)
                                                                                                  procedure H(S)
210 if R = R^* then bad \\leftarrow \\text{true}, return G[R^*] \\leftarrow GR^*
                                                                                                 220 if S = S^* then return H[S^*] \\leftarrow HS^*
        return G[R] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{k-\\rho}
                                                                                                 221 return H[S] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
procedure LR(M_0, M_1)
                                                                                                                                                    Game P_3
                                        301 GR^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{k-\\rho} 302 S^* \\leftarrow GR^* \\oplus M_b 303 HS^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
300 R^* \\leftarrow {}^{\\$} \\{0,1\\}^{\\rho}
304 \\quad T^* \\leftarrow R^* \\oplus HS^*
                                                 return Y^* \\leftarrow f(S^* \\parallel T^*)
procedure G(R)
                                                              procedure H(S)
        if R = R^* then bad \\leftarrow \\mathsf{true}
                                                              320 if S = S^* then return H[S^*] \\leftarrow HS^*
                                                              321 return H[S] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
        return G[R] \\xleftarrow{\\$} \\{0,1\\}^{k-\\rho}
Game 400 R^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho} 401 S^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{k-\\rho} 402 HS^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho} 403 T^* \\leftarrow R^* \\oplus HS^* 404 return Y^* \\leftarrow f(S^* \\parallel T^*)
                                                                                                                                                    Game P_4
procedure G(R)
                                                              procedure H(S)
410 if R = R^* then bad \\leftarrow \\mathsf{true}
                                                              420 if S = S^* then return H[S^*] \\leftarrow HS^*
411 return G[R] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{k-\\rho}
                                                              421 return H[S] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
procedure LR(M_0, M_1)
                                                                                                                                                    Game P_5
                                                                           502 HS^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho} 503 T^* \\leftarrow R^* \\oplus HS^*
                                        501 S^* \\leftarrow \\{0,1\\}^{k-\\rho}
500 \\quad R^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
504 return Y^* \\leftarrow f(S^* \\parallel T^*)
procedure G(R)
                                                                                       procedure H(S)
                                                                                       520 if S = S^* then return H[S^*] \\leftarrow HS^*
510 if H[S^*] and R = R^* then bad \\leftarrow \\mathsf{true}
                                                                                       521 return H[S] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
511 if \\neg H[S^*] and R = R^* then bad \\leftarrow \\mathsf{true}
      return G[R] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{k-\\rho}
</code></pre>

    <p class="text-gray-300">Figure 11: Games used in the analysis of OAEP. Procedure <strong>Initialize</strong> is the same in all of these games:  <span class="math">(f, f^{-1}) \\stackrel{\\</span>}{\\leftarrow} \\mathcal{F}(k), b \\stackrel{$}{\\leftarrow} {0, 1}$ , return f. Procedure <strong>Finalize</strong>(out) is also the same: return (out = b).</p>

    <pre><code class="language-text">procedure LR(M0, M1) Game Q0
000 R∗ $
     ← {0, 1}
          ρ 001 S∗ $
                      ← {0, 1}
                           k−ρ 002 HS ∗ $
                                       ← {0, 1}
                                             ρ 003 T ∗ ← R∗ ⊕ HS ∗
004 return Y ∗ ← f(S∗  T ∗)
procedure G(R) procedure H(S)
010 if H[S∗] and R = R∗ then bad ← true 020 if S = S∗ then return H[S∗] ← HS ∗
011 return G[R] $
           ← {0, 1}
                k−ρ 021 return H[S] $
                                            ← {0, 1}
                                                 ρ
procedure LR(M0, M1) Game Q1
100 R∗ $
     ← {0, 1}
          ρ 101 S∗ $
                      ← {0, 1}
                           k−ρ 102 T ∗ $
                                      ← {0, 1}
                                            ρ 103 HS ∗ ← R∗ ⊕ T ∗
104 return Y ∗ ← f(S∗  T ∗)
procedure G(R) procedure H(S)
110 if H[S∗] and R = R∗ then bad ← true 120 if S = S∗ then return H[S∗] ← HS ∗
111 return G[R] $
           ← {0, 1}
                k−ρ 121 return H[S] $
                                            ← {0, 1}
                                                 ρ
procedure LR(M0, M1) Game Q2
200 S∗ $
     ← {0, 1}
          k−ρ 201 T ∗ $
                    ← {0, 1}
                          ρ 202 R∗ $
                                    ← {0, 1}
                                         ρ 203 return Y ∗ ← f(S∗  T ∗)
procedure G(R) procedure H(S)
210 if H[S∗] and R = R∗ then bad ← true 220 if S = S∗ then return H[S∗] ← R∗ ⊕ T ∗
211 return G[R] $
           ← {0, 1}
                k−ρ 221 return H[S] $
                                            ← {0, 1}
                                                 ρ
procedure LR(M0, M1) Game Q3
300 S∗ $
     ← {0, 1}
          k−ρ 301 T ∗ $
                    ← {0, 1}
                          ρ 302 return Y ∗ ← f(S∗  T ∗)
procedure G(R) procedure H(S)
310 if H[S∗] and R = R∗ then bad ← true 320 if S = S∗ then R∗ $
                                           ←{0, 1}
                                                ρ
                                                , return H[S∗]←R∗ ⊕ T ∗
311 return G[R] $
           ← {0, 1}
                k−ρ 321 return H[S] $
                                       ← {0, 1}
                                            ρ
procedure LR(M0, M1) Game Q4
400 S∗ $
     ← {0, 1}
          k−ρ 401 T ∗ $
                     ← {0, 1}
                          ρ 402 return Y ∗ ← f(S∗  T ∗)
procedure G(R) procedure H(S)
410 if H[S∗] and R = R∗ then bad ← true 420 H[S] $
                                      ← {0, 1}
                                            ρ
411 return G[R] $
           ← {0, 1}
                k−ρ 421 if S = S∗ then R∗ ← H[S∗] ⊕ T ∗
                               422 return H[S]
procedure LR(M0, M1) Game Q5
500 S∗ $
     ← {0, 1}
          k−ρ 501 T ∗ $
                     ← {0, 1}
                          ρ 502 return Y ∗ ← f(S∗  T ∗)
procedure G(R) procedure H(S)
510 if R = H[S∗] ⊕ T ∗ then bad ← true 520 return H[S] $
                                           ← {0, 1}
                                                ρ
511 return G[R] $
           ← {0, 1}
                k−ρ
procedure LR(M0, M1) Game Q6
600 S∗ $
     ← {0, 1}
          k−ρ 601 T ∗ $
                     ← {0, 1}
                          ρ 602 return Y ∗ ← f(S∗  T ∗)
procedure G(R) procedure H(S)
610 if ∃ S s.t. f(S  T ∗) = Y ∗ and R = H[S] ⊕ T ∗ then bad ← true 620 return H[S] $
                                                          ← {0, 1}
                                                               ρ
611 return G[R] $
           ← {0, 1}
                k−ρ
procedure LR(M0, M1) Game Q7
700 return Y ∗ $
          ← {0, 1}
               k
procedure G(R) procedure H(S)
710 if ∃ S s.t. f(S  H[S] ⊕ R) = Y ∗ then bad ← true 720 return H[S] $
                                                   ← {0, 1}
                                                        ρ
711 return G[R] $
           ← {0, 1}
                k−ρ
</code></pre>

    <p class="text-gray-300">Figure 12: Games used in the analysis of OAEP, continued. Initialize and Finalize are as before. 30</p>

    <pre><code class="language-text">procedure LR(M_0, M_1)
000 R^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho} 001 S^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{k-\\rho} 004 return Y^* \\leftarrow f(S^* \\parallel T^*)
                                                                                                                                           003 \\quad T^* \\leftarrow R^* \\oplus HS^*
                                                                                         002 \\quad HS^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
procedure G(R)
                                                                                                   procedure H(S)
010 if \\neg H[S^*] and R = R^* then bad \\leftarrow \\mathsf{true}
                                                                                                   020 if S = S^* then return H[S^*] \\leftarrow HS^*
         return G[R] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{k-\\rho}
                                                                                                           return H[S] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
procedure LR(M_0, M_1)
                                                                                                                                                                        Game \\hat{Q}_1
                                     101 \\quad S^* \\xleftarrow{\\$} \\{0,1\\}^{k-\\rho}
100 R^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho} 101
104 return Y^* \\leftarrow f(S^* \\parallel T^*)
                                                                                             102 \\quad HS^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
                                                                                                                                            103 T^* \\leftarrow R^* \\oplus HS^*
procedure G(R)
                                                                                                   procedure H(S)
110 if \\neg H[S^*] and R = R^* then bad \\leftarrow \\mathsf{true}
                                                                                                   120 return H[S] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
         return G[R] \\xleftarrow{\\$} \\{0,1\\}^{k-\\rho}
procedure LR(M_0, M_1)
                                                                                                                                                                        Game \\hat{Q}_2
                                         201 \\quad S^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{k-\\rho} \\quad 202 \\quad T^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^k
200 \\quad R^* \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
                                                                                                                                        return Y^* \\leftarrow f(S^* \\parallel T^*)
procedure G(R)
                                                                                                   procedure H(S)
                                                                                                   220 return H[S] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho}
         if R = R^* then bad \\leftarrow \\mathsf{true}
         return G[R] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{k-\\rho}
</code></pre>

    <pre><code class="language-text">procedure LR(M_0, M_1) Procedures of Inverter I 900 return Y^*

procedure G(R) procedure H(S) 910 if \\exists S \\text{ s.t. } f(S \\parallel H[S] \\oplus R) = Y^* \\text{ then} 920 return H[S] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{\\rho} 911 return G[R] \\stackrel{\\$}{\\leftarrow} \\{0,1\\}^{k-\\rho}
</code></pre>

    <p class="text-gray-300">Figure 13: <strong>Top:</strong> Games used in the analysis of OAEP, continued. Procedures Initialize and Finalize are as before. <strong>Bottom:</strong> The inverting algorithm <em>I</em>, likewise with an identical Initialize procedure.</p>

    <p class="text-gray-300">For the analysis let  <span class="math">p_i = \\Pr \\left[ P_i^A \\Rightarrow \\mathsf{true} \\right]</span>  for  <span class="math">0 \\le i \\le 5</span>  (the Finalize procedure of these games outputs a boolean).  <span class="math">\\triangleright</span>  Game  <span class="math">P_0</span>  perfectly mimics the game defining the security of  <span class="math">\\mathsf{OAEP}^{\\rho}[\\mathcal{F}]</span> . Thus</p>

    <p class="text-gray-300"><span class="math">$0.5 + 0.5 \\,\\mathbf{Adv}_{\\mathsf{OAEP}^{\\rho}[\\mathcal{F}]}^{\\mathsf{ind-cpa}}(A) = p_0 = p_1 + (p_0 - p_1) \\leq p_1 + \\Pr[P_0^A \\text{ sets } bad],</span>$</p>

    <p class="text-gray-300">the last step by the Fundamental Lemma. Since game  <span class="math">P_0</span>  chooses  <span class="math">R^*</span> ,  <span class="math">S^*</span>  at random,  <span class="math">\\Pr[P_0^A \\text{ sets } bad] \\le q_G/2^{\\rho} + q_H/2^{k-\\rho}</span> .  <span class="math">\\triangleright</span>  Game  <span class="math">P_2</span>  differs from game  <span class="math">P_1</span>  only in the setting of bad, so  <span class="math">p_1 = p_2</span> , and using the Fundamental Lemma again we have</p>

    <p class="text-gray-300"><span class="math">$p_1 = p_2 = p_3 + (p_2 - p_3) \\le p_3 + \\Pr[P_3^A \\text{ sets } bad].</span>$</p>

    <p class="text-gray-300"><span class="math">\\triangleright</span>  In game  <span class="math">P_4</span>  the string  <span class="math">GR^*</span>  is chosen but not referred to in responding to any oracle queries of the adversary. Thus  <span class="math">P_4</span>  is a conservative replacement for  <span class="math">P_3</span> ,  <span class="math">p_3 = p_4</span> , and  <span class="math">\\Pr[P_3^A \\text{ sets } bad] = \\Pr[P_4^A \\text{ sets } bad]</span> . However, the bit b is not used in  <span class="math">P_4</span> , and hence  <span class="math">p_4 = 1/2</span> . In summary</p>

    <p class="text-gray-300"><span class="math">$p_3 + \\Pr[P_3^A \\text{ sets } bad] = p_4 + \\Pr[P_4^A \\text{ sets } bad] = 1/2 + \\Pr[P_4^A \\text{ sets } bad].</span>$</p>

    <p class="text-gray-300">Putting all this together we have</p>

    <p class="text-gray-300"><span class="math">$0.5 \\operatorname{\\mathbf{Adv}}_{\\mathsf{OAEP}^{\\rho}[\\mathcal{F}]}^{\\mathsf{ind-cpa}}(A) - \\frac{q_G}{2^{\\rho}} - \\frac{q_H}{2^{k-\\rho}} \\leq \\Pr[P_4^A \\text{ sets } bad]. \\tag{17}</span>$</p>

    <p class="text-gray-300">We proceed to upper bound the right-hand-side of the above. We have</p>

    <p class="text-gray-300"><span class="math">\\Pr[P_4^A \\text{ sets } bad] \\leq \\Pr[P_5^A \\text{ sets } bad] \\leq \\Pr[Q_0^A \\text{ sets } bad] + \\Pr[\\hat{Q}_0^A \\text{ sets } bad] \\leq \\Pr[Q_0^A \\text{ sets } bad] + q_G/2^{\\rho}</span> . Above, we have split the analysis of game  <span class="math">P_5</span>  into the analysis of games  <span class="math">Q_0</span>  and  <span class="math">\\hat{Q}_0</span> , the former being accomplished by the game chain at Figure 12 and the latter by the game chain of Figure 13. The second term is readily shown to be at most  <span class="math">q_G/2^{\\rho}</span>  by way of the game chain at Figure 13. Going back to the analysis of game  <span class="math">Q_0</span>  in Figure 12, we have a series of conservative changes, giving  <span class="math">Q_1</span> ,  <span class="math">Q_2</span> ,  <span class="math">Q_3</span> ,  <span class="math">Q_4</span> ,  <span class="math">Q_5</span>  leading to</p>

    <p class="text-gray-300"><span class="math">$\\Pr[Q_0^A \\text{ sets } bad\\,] \\ = \\ \\Pr[Q_5^A \\text{ sets } bad\\,] \\ \\leq \\ \\Pr[Q_6^A \\text{ sets } bad\\,] \\ = \\ \\Pr[Q_7^A \\text{ sets } bad\\,] \\ .</span>$</p>

    <p class="text-gray-300">To conclude the proof we design I so that</p>

    <p class="text-gray-300"><span class="math">$\\Pr[Q_7^A \\text{ sets } bad] \\leq \\mathbf{Adv}_{\\mathcal{F}}^{\\text{owf}}(I).</span>$
(18)</p>

    <p class="text-gray-300">On input  <span class="math">f, Y^*</span> , inverter I runs A on input public key f, responding to its oracle queries via the procedures specified in the last box in Figure 13. When A halts, inverter I returns  <span class="math">S^* \\parallel T^*</span>  if this has been defined. By comparison with game  <span class="math">Q_7</span>  we see that (18) is true, completing the proof.</p>

    <h2 id="sec-18" class="text-2xl font-bold">7 Game-Rewriting Techniques</h2>

    <p class="text-gray-300">In this section we name, describe, and justify some game-transformation techniques that seem universally useful. Our enumeration is not comprehensive, only aiming to hit some of the most interesting and widely applicable methods. We begin with some useful terminology.</p>

    <h4 id="sec-19" class="text-lg font-semibold mt-6">7.1 Game chains</h4>

    <p class="text-gray-300">The power of the game-playing technique stems, in large part, from our ability to incrementally rewrite games, constructing chains of them. Using the Fundamental Lemma, you first arrange that the analysis you want to carry out amounts to bounding  <span class="math">\\epsilon = \\Pr[G_1^A \\text{ sets } bad]</span>  for some first game  <span class="math">G_1</span>  and some adversary A. (In fact, a game chain may be used also for this first phase, before we apply the Fundamental Lemma; triple encryption and OAEP are such examples.) You want to bound  <span class="math">\\epsilon</span>  as a function of the resources expended by A. To this end, you modify the game  <span class="math">G_1</span> , one step at a time, constructing a chain of games  <span class="math">G_1 \\longrightarrow G_2 \\longrightarrow G_3 \\longrightarrow \\cdots \\longrightarrow G_n</span> . Game  <span class="math">G_1</span>  is the initial game and game  <span class="math">G_n</span>  is the terminal game. Game  <span class="math">G_1</span>  is run using adversary A; other games may run with different adversaries.</p>

    <p class="text-gray-300">Consider a transition  <span class="math">G^A \\to H^B</span> . Let  <span class="math">p_G = \\Pr[G^A \\text{ sets } bad]</span>  and let  <span class="math">p_H = \\Pr[H^B \\text{ sets } bad]</span> . We want to bound  <span class="math">p_G</span>  in terms of  <span class="math">p_H</span> . Sometimes we show that  <span class="math">p_G \\leq p_H</span> . In this case, the transformation is safe. A common case of this is when  <span class="math">p_G = p_H</span> , in which case the transformation is conservative. Sometimes we show that  <span class="math">p_G \\leq p_H + \\epsilon</span>  or  <span class="math">p_G \\leq c \\cdot p_H</span>  for some particular  <span class="math">\\epsilon &gt; 0</span>  or c &gt; 1. Either way, the transformation is lossy. When a chain of safe and lossy transformations is performed, a bound for bad getting set in the initial game is obtained from a bound for bad getting set in the terminal game by adding and/or multiplying the loss terms in the natural way. We use the terms safe, conservative, or lossy to apply to pairs of games even in the absence of a specific adversary: the statement is then understood to apply to all adversaries with understood resource bounds.</p>

    <h4 id="sec-20" class="text-lg font-semibold mt-6">7.2 Basic techniques</h4>

    <p class="text-gray-300">We start off with game-transformation methods that do not require an extensive discussion. The methods can be quite powerful just the same.</p>

    <p class="text-gray-300">RESAMPLING IDIOM. Let T be a finite, nonempty set and let  <span class="math">S \\subseteq T</span> . Then the code fragment  <span class="math">x \\stackrel{\\</span>}{\\leftarrow} S$  can be replaced by the equivalent code fragment  <span class="math">x \\stackrel{\\</span>}{\\leftarrow} T$ , if  <span class="math">x \\not\\in S</span>  then  <span class="math">x \\stackrel{\\</span>}{\\leftarrow} S$ . We call this motif resampling. It is a basic &quot;idiom&quot; employed in games, often with bad getting set when resampling is required, replacing  <span class="math">x \\stackrel{\\</span>}{\\leftarrow} S$  by  <span class="math">x \\stackrel{\\</span>}{\\leftarrow} T$ , if  <span class="math">x \\not\\in S</span>  then  <span class="math">bad \\leftarrow \\text{true}, x \\stackrel{\\</span>}{\\leftarrow} S$ . The code-replacement just specified is clearly safe (but not conservative). Our proof for the PRP/PRF Switching Lemma, our proof for triple-encryption, and our proof for the CBC MAC all employ the resampling idiom.</p>

    <p class="text-gray-300">SWAPPING DEPENDENT AND INDEPENDENT VARIABLES. Instead of choosing a random value  <span class="math">X \\stackrel{\\</span>}{\\leftarrow} {0,1}^n$  and then defining  <span class="math">Y \\leftarrow X \\oplus C</span> , one can choose  <span class="math">Y \\stackrel{\\</span>}{\\leftarrow} {0,1}^n$  and define  <span class="math">X \\leftarrow Y \\oplus C</span> . This can be generalized in natural ways. Swapping dependent and independent variables is invariably a conservative change. This technique is used in our proof of OAEP.</p>

    <p class="text-gray-300">CODE MOTION. It is often convenient to move around statements, as an optimizing compiler might. Permissible code motion is usually trivial to verify because games need not employ those programming-language constructs (aliasing and side-effects) that complicate seeing whether or not code motion is permissible. One particular form of code motion that is often used is to postpone until procedure Finalize making random choices that had been made earlier. Permissible code motion is conservative. Examples of code motion are given in the proof of the CBC MAC.</p>

    <p class="text-gray-300">MARKING-INSTEAD-OF-RECORDING. Suppose that a variable  <span class="math">\\pi</span>  is being used in a game to record a lazily-defined permutation: we start off with  <span class="math">\\pi</span>  everywhere undefined, and then we set some first value  <span class="math">\\pi[X_1]</span>  to  <span class="math">Y_1</span> , and later we set some second value  <span class="math">\\pi[X_2]</span>  to  <span class="math">Y_2</span> , and so forth. Sometimes an inspection of the code will reveal that all we are paying attention to is which points are in the domain of  <span class="math">\\pi</span>  and which points are in the range. In such a case, we didn't need to record the association of  <span class="math">Y_i</span>  to  <span class="math">X_i</span> , we could just as well have &quot;marked&quot;  <span class="math">X_i</span>  as being a now-used domain-point, and marked  <span class="math">Y_i</span>  as being a now-used range-point. Dropping the use of  <span class="math">Y_i</span>  may now permit other changes in the code, like code motion. The method is conservative. Marking-instead-of-recording is used in our proof of the CBC MAC.</p>

    <p class="text-gray-300">DERANDOMIZING A VARIABLE. Suppose a game G chooses a variable  <span class="math">X \\stackrel{\\</span>}{\\leftarrow} \\mathcal{X}$  and never re-defines it. We may eliminate the random-assignment statement  <span class="math">X \\stackrel{\\</span>}{\\leftarrow} \\mathcal{X}$  and replace all uses of X by a fixed constant  <span class="math">c \\in X</span> , obtaining a new game  <span class="math">G_c</span> . Given an adversary A, let H be  <span class="math">G_c</span>  for the lexicographically first  <span class="math">c \\in \\mathcal{X}</span>  that maximizes  <span class="math">\\Pr[G_c^A \\text{ sets } bad]</span> . We say that game H has been obtained by derandomizing the variable X. It is easy to see that  <span class="math">\\Pr[G^A \\text{ sets } bad] \\leq \\Pr[H^A \\text{ sets } bad]</span> ; that is, derandomizing a variable is a safe transformation. One can also de-randomize when elements of an array are chosen at random, replacing code for  <span class="math">i \\stackrel{\\</span>}{\\leftarrow} 1$  to q do  <span class="math">A[i] \\stackrel{\\</span>}{\\leftarrow} \\mathcal{X}$  by references to constants. Our analysis of the triple can be viewed as using this method in passing from game  <span class="math">C_2</span>  to  <span class="math">C_T</span>  (but see Section 7.3 for a fuller discussion).</p>

    <p class="text-gray-300">POISONED POINTS. Sometimes a game will place a value in an array that it probably will not use; that is, A[x] is defined as some value c but it is unlikely that the value of A[x] will actually be needed. In this case, one can think of &quot;poisoning&quot; array position x of A, dropping c into A[x] but setting a flag bad if A[x] is ever accessed. Next one can imagine storing a value b different from c in at A[x], and since any access to A[x] will set bad, it doesn't matter that a &quot;wrong&quot; value was placed in A[x]: it will not increase the probability that bad gets set. We call this the &quot;poisoned-point technique.&quot; It is useful because it allows one to make a change in what is stored</p>

    <p class="text-gray-300">in an array (setting A[x] to b instead of c) and pay for corrupting the game only later, and only if A[x] is actually accessed. We use the poisoned-point technique in our proof of triple encryption when passing from game  <span class="math">G_4</span>  to game  <span class="math">G_5</span> .</p>

    <p class="text-gray-300">UNPLAYABLE GAMES. We point out that the games in a game chain do not normally have to be efficient: a game chain is a thought experiment that, typically, is not performed by any user or adversary. We refer to a game that seems to have no efficient implementation as an <em>unplayable game</em>. In most settings it is perfectly fine to use unplayable games, although none are used within this paper.</p>

    <h4 id="sec-21" class="text-lg font-semibold mt-6">7.3 Coin fixing</h4>

    <p class="text-gray-300">It is often much easier to carry out an analysis if one can assume that adversaries decide on their queries in advance; the fact that adversaries can choose their queries adaptively is one of the major factors complicating many analyses. We now describe the <em>coin-fixing technique</em> to eliminate or reduce adversarial adaptivity. You can't <em>always</em> apply this method to remove adaptivity; our purpose is to given an example of a sufficient condition when you can. The coin-fixing technique stems from a classical method in complexity theory to eliminate coins, hardwiring them in, as in the proof that  <span class="math">BPP \\subseteq P/poly [2]</span> .</p>

    <p class="text-gray-300">Fix a game G and an enumeration of its oracles,  <span class="math">P_1, \\ldots, P_m</span>  for some  <span class="math">m \\geq 0</span> . We would like to eliminate oracle  <span class="math">P_1</span> , constructing a new game H with oracles  <span class="math">P_2, \\ldots, P_m</span> . If G has only one oracle,  <span class="math">P_1</span> , then H will be left with no oracles: it will be a non-interactive game, a game whose execution does not depend on an adversary. A resource vector is a sequence of numbers  <span class="math">R = (q_1, \\ldots, q_m) \\in \\mathbb{N}^m</span> . For such a vector  <span class="math">R = (q_1, \\ldots, q_m)</span>  let  <span class="math">A_R</span>  denote the set of all adversaries that ask exactly  <span class="math">q_i</span>  queries to oracle  <span class="math">P_i</span> . Let  <span class="math">tail(R) = (q_2, \\ldots, q_m)</span>  be R stripped of its first component. When speaking of a game G where each oracle  <span class="math">P_i</span>  has an understood domain  <span class="math">D_i</span> , the adversary class  <span class="math">A_R</span>  is further assumed to include only adversaries that ask queries that are within the domain of each oracle.</p>

    <p class="text-gray-300">Now suppose that oracle  <span class="math">P_1</span>  is of the form:</p>

    <p class="text-gray-300"><strong>procedure</strong>
<span class="math">$P_1(X)</span>$
<span class="math">i \\leftarrow i+1</span> ,  <span class="math">X[i] \\leftarrow X</span> ,  <span class="math">Y[i] \\stackrel{\\</span>}{\\leftarrow} D_{X[1],\\dots,X[i],Y[1],\\dots,Y[i-1]}$ ,  <span class="math">S</span> , return  <span class="math">Y[i]</span></p>

    <p class="text-gray-300">where i is some integer variable and X and Y are distinct array variables and i,  <span class="math">X[\\cdot]</span> , and  <span class="math">Y[\\cdot]</span>  appear in game G as l-values (that is, on the left-hand-side of an assignment operator or random-assignment operator) only in the statements shown. Statement S is empty if m &gt; 1 and an arbitrary compound statement if m = 1. By  <span class="math">D_{X[1],...,X[i],Y[1],...,Y[i-1]}</span>  we mean a finite set that depends only on X[1],...,X[i],Y[1],...,Y[i-1]. To fall within our code-based framework the set  <span class="math">D_{X[1],...,X[i],Y[1],...,Y[i-1]}</span>  must be specified in code; what we are asserting that this code computes the associated set and is without side-effects. A useful special cases is  <span class="math">Y[i] \\stackrel{\\</span>}{\\leftarrow} {0,1}^n$  for some constant n. When  <span class="math">P_1</span>  has the form we have just described we say that it is eliminable and has parameters i, X, Y, S.</p>

    <p class="text-gray-300">With all notation as above, let  <span class="math">X, Y \\in (\\{0,1\\}^*)^{q_1}</span> . We say that (X,Y) is possible for  <span class="math">(G, \\mathcal{A}_R)</span>  if there exists an adversary  <span class="math">A \\in \\mathcal{A}_R</span>  for which there is nonzero probability that, in the interaction between A and G, the former asks queries  <span class="math">X_1, \\ldots, X_{q_1}</span>  and receives in response  <span class="math">Y_1, \\ldots, Y_{q_1}</span> . A query set for  <span class="math">(G, \\mathcal{A}_R)</span>  is a finite set of points  <span class="math">\\mathcal{Q}</span>  that includes all possible (X, Y) for  <span class="math">(G, \\mathcal{A}_R)</span> .</p>

    <p class="text-gray-300">For  <span class="math">X, Y \\in (\\{0,1\\}^*)^{q_1}</span>  define the game  <span class="math">G_{X,Y}</span>  to be identical to G except for the following: (1) Eliminate the procedure for oracle  <span class="math">P_1</span> . (2) Replace every expression of the form X[e] by X[e]. (no X[e] appears as an l-value). (3) Replace every expression of the form Y[e] by Y[e] (no Y[e] appears as</p>

    <p class="text-gray-300">an l-value). (4) At the beginning of procedure Finalize, add the statement: for  <span class="math">i \\leftarrow 1</span>  to  <span class="math">q_1</span>  do S. We eliminate  <span class="math">P_1</span>  by appealing to the following.</p>

    <p class="text-gray-300"><strong>Proposition 14</strong> Let G be a game with oracles  <span class="math">P_1, \\ldots, P_m</span> . Let  <span class="math">R = (q_1, \\ldots, q_m) \\in \\mathbb{N}^m</span>  and R' = tail(R). Let Q be a query set. Then</p>

    <p class="text-gray-300"><span class="math">$\\max_{A \\in \\mathcal{A}_R} \\{ \\Pr \\left[ G^A \\text{ sets } bad \\right] \\} \\leq \\max_{B \\in \\mathcal{A}_{R&#x27;}, (\\mathbf{X}, \\mathbf{Y}) \\in \\mathcal{Q}} \\{ \\Pr \\left[ G^B_{\\mathbf{X}, \\mathbf{Y}} \\text{ sets } bad \\right] \\}</span>$</p>

    <h3 id="sec-22" class="text-xl font-semibold mt-8">7.4 Lazy sampling</h3>

    <p class="text-gray-300">Instead of making random choices up front, it is often convenient rewrite a game so as to delay making random choices until they are actually needed. We call such &quot;just-in-time&quot; flipping of coins lazy sampling. Whether a lazy sampling method works or not is sometimes clear but other times subtle. In this section we look at some examples and then provide a sufficient condition for lazy sampling to work.</p>

    <p class="text-gray-300">EXAMPLE 1. As a simple but frequently used example, consider a game that provides the adversary an oracle  <span class="math">\\Pi(X)</span>  that is a permutation on  <span class="math">\\{0,1\\}^n</span> . One implementation of the game is game  <span class="math">G_1</span>  of Figure 14 which simply chooses  <span class="math">\\pi</span>  at random from  <span class="math">\\operatorname{Perm}(n)</span>  during Initialize and then, when asked a  <span class="math">\\Pi(X)</span>  query, answers  <span class="math">\\pi[X]</span> . The alternative, lazy, method for implementing  <span class="math">\\pi</span>  is shown in game  <span class="math">G_2</span> . This game maintains a partial permutation  <span class="math">\\pi</span>  from n bits to n bits that is initially everywhere undefined. When asked a query X not yet in the domain of  <span class="math">\\pi</span> , the game chooses a value Y randomly from the co-range of  <span class="math">\\pi</span> , defines  <span class="math">\\pi[X] \\leftarrow Y</span> , and returns Y.</p>

    <p class="text-gray-300">You can think of the current partial function  <span class="math">\\pi</span>  as imposing the &quot;constraint&quot; that  <span class="math">\\pi[X] \\not\\in \\operatorname{image}(\\pi)</span>  on our choice of  <span class="math">\\pi[X]</span> . We choose  <span class="math">\\pi[X]</span>  at random from all points respecting the constraint. In this case, it seems obvious that the two ways to simulate a random permutation are equivalent. (Recall we have defined this to mean that  <span class="math">\\operatorname{Adv}(G_1^A, G_2^A) = 0</span>  for any adversary A.) But lazy sampling methods can get more complex and prospective methods for lazy sampling often fail to work. One needs to carefully verify any prospective use of lazy sampling. To see this, consider the following.</p>

    <p class="text-gray-300">EXAMPLE 2. Let  <span class="math">\\operatorname{Perm}_2^{\\neq}(S)</span>  denote the set of all  <span class="math">(\\pi_0, \\pi_1)</span>  such that  <span class="math">\\pi_0, \\pi_1</span>  are permutations on the set S that satisfy  <span class="math">\\pi_0[X] \\neq \\pi_1[X]</span>  for all  <span class="math">X \\in S</span> . Game  <span class="math">H_1</span>  of Figure 14 provides the adversary with oracles for  <span class="math">\\pi_0</span>  and  <span class="math">\\pi_1</span>  chosen at random from this set. Game  <span class="math">H_2</span>  presents a lazy sampling alternative. Here,  <span class="math">\\pi_0, \\pi_1</span>  are (according to our conventions) initially everywhere undefined. When the adversary queries  <span class="math">\\Pi_i(X)</span> , the reply  <span class="math">\\pi_i[X]</span>  is chosen at random from the set of points that are not yet in the range of  <span class="math">\\pi_i</span>  and also different from  <span class="math">\\pi_{1-i}[X]</span> . This, as above, can be thought of as imposing the &quot;constraint&quot; that  <span class="math">\\pi_i[X] \\notin \\operatorname{image}(\\pi_i) \\cup \\{\\pi_{1-i}[X]\\}</span>  on our choice of  <span class="math">\\pi[X]</span> , and is thus quite natural.</p>

    <p class="text-gray-300">We will assume as usual that the adversary does not repeat an oracle query. Now we ask whether games  <span class="math">H_1, H_2</span>  are equivalent, meaning whether our lazy sampling method &quot;works.&quot; Curiously, the answer is no. To see this, let  <span class="math">S = \\{1, 2, 3\\}</span> , and consider the adversary A who queries  <span class="math">\\Pi_0(1)</span> ,  <span class="math">\\Pi_0(2)</span> ,  <span class="math">\\Pi_0(3)</span> ,  <span class="math">\\Pi_1(1)</span> ,  <span class="math">\\Pi_1(2)</span> . It outputs 1 if and only if the answer sequence received back is 1, 2, 3, 2, 1. Then  <span class="math">\\Pr[A_1^H \\Rightarrow 1] = 0</span>  because the probability that A gets back the answer sequence 1, 2, 3, 2, 1 when run with  <span class="math">H_1</span>  is zero. This is the case because there is no pair  <span class="math">(\\pi_0, \\pi_1) \\in \\operatorname{Perm}_2^{\\neq}(S)</span>  satisfying  <span class="math">\\pi_0[1] = 1, \\pi_0[2] = 2, \\pi_0[3] = 3, \\pi_1[1] = 2, \\pi_1[2] = 1</span> . (It leaves no choice for  <span class="math">\\pi_1[3]</span> , since the latter is not allowed to equal any of  <span class="math">\\pi_1[1], \\pi_1[2], \\pi_0[3]</span> .) However,  <span class="math">\\Pr[A_2^H \\Rightarrow 1] = 1/24</span>  because the probability that A gets back the answer sequence 1, 2, 3, 2, 1 when run with  <span class="math">H_2</span>  is 1/24. So  <span class="math">\\operatorname{Adv}(H_2^A, H_1^A) = 1/24 \\neq 0</span> , meaning the games are not equivalent. That is, in this case, at least, the &quot;natural&quot; way of performing lazy sampling did not work.</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"><span class="math">\\begin{array}{ c c c c } \\hline \\textbf{procedure Initialize} &amp; \\text{Game } G_1 \\\\ \\hline 100 &amp; \\pi \\stackrel{\\</span>}{\\leftarrow} \\operatorname{Perm}(n) \\ \\hline \\end{array}$</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">$ \\begin{array}{ c c c c } \\hline \\mathbf{procedure} \\ \\mathbf{\\Pi}(X) &amp; \\text{Game } G_2 \\ \\hline 210 \\ \\ \\text{return } \\pi[X] \\xleftarrow{$} \\overline{\\text{image}}(\\pi) &amp; \\ \\hline \\end{array} $</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">procedure <span class="math">\\Pi(X)</span>&lt;br&gt;110 return <span class="math">\\pi[X]</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">procedure Initialize Game <span class="math">H_1</span> <span class="math">100 (\\pi_0, \\pi_1) \\stackrel{\\</span>}{\\leftarrow} \\operatorname{Perm}_2^{\\neq}(S)$</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">procedure <span class="math">\\Pi_0(X)</span> Game <span class="math">H_2</span> 210 return <span class="math">\\pi_0[X] \\stackrel{\\</span>}{\\leftarrow} \\overline{\\mathrm{image}}(\\pi_0) - {\\pi_1[X]}$</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">procedure <span class="math">\\Pi_0(X)</span> procedure <span class="math">\\Pi_1(X)</span>&lt;br&gt;110 return <span class="math">\\pi_0[X]</span> 120 return <span class="math">\\pi_1[X]</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">procedure <span class="math">\\Pi_1(X)</span> 220 return <span class="math">\\pi_1[X] \\leftarrow \\overline{\\text{image}}(\\pi_1) - \\{\\pi_0[X]\\}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">procedure <span class="math">\\Pi_0(X)</span> Game <span class="math">H_3</span> 310 if <span class="math">X \\in \\overline{\\operatorname{domain}}(\\pi_0)</span> then <span class="math">(\\pi_0[X], \\pi_1[X]) \\stackrel{\\</span>}{\\leftarrow} { (Y_1, Y_2) \\in \\overline{\\operatorname{image}}(\\pi_0) \\times \\overline{\\operatorname{image}}(\\pi_1) : Y_1 \\neq Y_2 }$ 311 return <span class="math">\\pi_0[X]</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">procedure <span class="math">\\Pi_1(X)</span> 320 if <span class="math">X \\in \\overline{\\operatorname{domain}}(\\pi_1)</span> then <span class="math">(\\pi_0[X], \\pi_1[X]) \\stackrel{\\</span>}{\\leftarrow} { (Y_1, Y_2) \\in \\overline{\\operatorname{image}}(\\pi_0) \\times \\overline{\\operatorname{image}}(\\pi_1) : Y_1 \\neq Y_2 }$ 321 return <span class="math">\\pi_1[X]</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">Figure 14: Games referred to in discussion of lazy sampling.</p>

    <p class="text-gray-300">There could, however, be some different lazy sampling method that did work in this case. We present a possibility via game  <span class="math">H_3</span>  of Figure 14. We leave as an exercise for the reader to determine whether or not  <span class="math">H_3</span>  is equivalent to  <span class="math">H_1</span>  and prove the answer correct.</p>

    <p class="text-gray-300">AN AID TO JUSTIFYING LAZY SAMPLING METHODS. We would like some way to &quot;test&quot; a candidate lazy sampling method and determine whether or not it works. At least we would like a sufficient condition which, if met by the method, allows us to conclude it works. Here we put forth a result in this vein. Basically we say that we can restrict our attention to adversaries that make all possible oracle queries. Let us now make this more precise.</p>

    <p class="text-gray-300">Let I be a game with an oracle P. We say that I implements P consistently if for any adversary A, if A has made a query P(X) and got back a value Y, then, if A again makes query P(X), the response will be Y. (This does not mean that there are no random choices involved in implementing P, but rather that the value of this oracle at some point, once defined, is not changed.) When all oracles provided by a game are implemented consistently, we can without loss of generality restrict attention to adversaries that never repeat an oracle query.</p>

    <p class="text-gray-300">We say that games G, H are compatible if they provide access to oracles of the same names, meaning there is some  <span class="math">n \\geq 0</span>  and some  <span class="math">P_1, \\ldots, P_n</span>  such that both games provide these oracles and no others, and also both games implement all oracles consistently. (The oracles might be implemented differently in the two games. Think of G as implementing them via an eager sampling method and H via a lazy sampling one.)</p>

    <p class="text-gray-300">Let G, H be compatible games providing oracles  <span class="math">P_1, \\ldots, P_n</span>  for some  <span class="math">n \\geq 1</span> . We assume there is a finite domain  <span class="math">D_i</span>  associated to  <span class="math">P_i</span>  and that all adversaries considered must pick their queries to  <span class="math">P_i</span>  from  <span class="math">D_i</span>  for  <span class="math">1 \\leq i \\leq n</span> . (Such domains are always implicit in games.) We say that an adversary A is exhaustive if it queries all oracles at all possible points. That is, for any game I compatible with games G, H, for each i and each  <span class="math">X \\in D_i</span> , there is some point in the execution of A with I at which A makes query  <span class="math">P_i(X)</span> . Note there are many possible exhaustive adversaries, for we do not impose requirements on the order in which they make their queries, or even on whether they are adaptive or not.</p>

    <p class="text-gray-300"><strong>Lemma 15</strong> <em>Let</em> G,H <em>be compatible games. Then</em> G <em>and</em> H <em>are equivalent if and only if</em> <strong>Adv</strong>(GA, HA) = 0 <em>for all exhaustive adversaries</em> A<em>.</em></p>

    <p class="text-gray-300"><strong>Proof:</strong> If the games are equivalent then by definition <strong>Adv</strong>(GA, HA) = 0 for any adversary A, so in particular this is true when A is exhaustive. Conversely, let B be any adversary, and associate to it an exhaustive adversary A that works as follows. Adversary A runs B, answering B's oracle queries via its own oracles. When B halts with some output b, adversary A continues, making all oracle queries not made by B. (Since the domains of the oracles are finite, A will terminate.) Finally it outputs b and halts. Then <strong>Adv</strong>(GB, HB) = <strong>Adv</strong>(GA, HA). But the latter is by assumption zero since A is exhaustive, and thus <strong>Adv</strong>(GB, HB) = 0 as well. Since B was arbitrary, this shows the games are equivalent.</p>

    <p class="text-gray-300">We remark that we effectively used the principle of the above lemma in justifying the lazy sampling method of G&lt;sup&gt;4&lt;/sup&gt; in the proof of Lemma 9, when we assumed that A makes all 6N oracle queries.</p>

    <p class="text-gray-300">We thank Tadayoshi Kohno for permission to use his observations about the standard proof of the PRP/PRF Switching Lemma noted in Section 2 and Appendix A. Thanks to the Eurocrypt 2006 PC for their comments. Thanks to Deukjo Hong for pointing out an error in the exposition of Section 2. Finally, thanks to Peter Gaˇzi and Ueli Maurer for identifying bugs in earlier version, as described in Section 1.</p>

    <p class="text-gray-300">Mihir Bellare was supported by NSF 0098123, ANR-0129617, NSF 0208842, and an IBM Faculty Partnership Development Award. Phil Rogaway was supported by NSF 0208842 and a gift from Intel Corp. Much of the work on this paper was carried out while Phil was hosted by Chiang Mai University, Thailand.</p>

    <h2 id="sec-23" class="text-2xl font-bold"><strong>References</strong></h2>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><p class="text-gray-300">[1] M. Abe, R. Gennaro, K. Kurosawa and V. Shoup. Tag-KEM/DEM: A new framework for hybrid encryption and a new analysis of Kurosawa-Desmedt KEM. <em>Eurocrypt '05</em>.</p></li>
      <li><p class="text-gray-300">[2] L. Adleman. Two theorems on random polynomial time. <em>FOCS 78</em>.</p></li>
      <li><p class="text-gray-300">[3] W. Aiello, M. Bellare, G. Di Crescenzo, and R. Venkatesan. Security amplification by composition: the case of doubly-iterated, ideal ciphers. <em>Crypto '98</em>.</p></li>
      <li><p class="text-gray-300">[4] M. Bellare and S. Goldwasser. New paradigms for digital signatures and message authentication based on non-interactive zero knowledge proofs. <em>Crypto 89</em>, pp. 194–211, 1989.</p></li>
      <li><p class="text-gray-300">[5] M. Bellare, J. Kilian, and P. Rogaway. The security of the cipher block chaining message authentication code. <em>Journal of Computer and System Sciences</em> (JCSS), vol. 61, no. 3, pp. 362– 399, 2000. Earlier version in <em>Crypto '94</em>.</p></li>
      <li><p class="text-gray-300">[6] M. Bellare, T. Krovetz, and P. Rogaway. Luby-Rackoff backwards: increasing security by making block ciphers non-invertible. <em>Eurocrypt '98</em>.</p></li>
      <li><p class="text-gray-300">[7] M. Bellare, K. Pietrzak, and P. Rogaway. Improved security analyses for CBC MACs. <em>Crypto 05</em>.</p></li>
      <li><p class="text-gray-300">[8] M. Bellare and P. Rogaway. Optimal asymmetric encryption. <em>Eurocrypt '94</em>.</p></li>
      <li><p class="text-gray-300">[9] M. Bellare and P. Rogaway. Random oracles are practical: a paradigm for designing efficient protocols. <em>ACM CCS '93</em>.</p></li>
      <li><p class="text-gray-300">[10] M. Bellare, P. Rogaway, and D. Wagner. The EAX mode of operation (a two-pass authenticated encryption scheme). <em>FSE '04</em></p></li>
      <li><p class="text-gray-300">[11] D. Bernstein. A short proof of the unpredictability of cipher block chaining. Manuscript, January 2005. Available on Bernstein's web page.</p></li>
      <li><p class="text-gray-300">[12] J. Black and P. Rogaway. CBC MACs for arbitrary-length messages: the three-key constructions. <em>Crypto '00</em>.</p></li>
      <li><p class="text-gray-300">[13] J. Black and P. Rogaway. A block-cipher mode of operation for parallelizable message authentication. <em>Eurocrypt '02</em>.</p></li>
      <li><p class="text-gray-300">[14] J. Black, P. Rogaway, and T. Shrimpton. Encryption-scheme security in the presence of keydependent messages. <em>SAC 2002</em>.</p></li>
      <li><p class="text-gray-300">[15] D. Boneh. Simplified OAEP for the RSA and Rabin functions. <em>Crypto '01</em>.</p></li>
      <li><p class="text-gray-300">[16] J. Camenisch and V. Shoup. Practical verifiable encryption and decryption of discrete logs. <em>Crypto '03</em>.</p></li>
      <li><p class="text-gray-300">[17] R. Cramer and V. Shoup. Design and analysis of practical public-key encryption schemes secure against adaptive chosen ciphertext attack. <em>SIAM J. of Computing</em>, vol. 33, pp. 167– 226, 2003.</p></li>
      <li><p class="text-gray-300">[18] R. Cramer and V. Shoup. Universal hash proofs and a paradigm for adaptive chosen ciphertext secure public key encryption. <em>Eurocrypt '02</em>.</p></li>
      <li><p class="text-gray-300">[19] W. Diffie and M. Hellman. Exhaustive cryptanalysis of the data encryption standard. <em>Computer</em>, vol. 10, pp. 74–84, 1977.</p></li>
      <li><p class="text-gray-300">[20] Y. Dodis, R. Gennaro, J. H˚astad, H. Krawczyk, and T. Rabin. Randomness extraction and key derivation using the CBC, Cascade, and HMAC modes. <em>Crypto '04</em>.</p></li>
      <li><p class="text-gray-300">[21] S. Even and O. Goldreich. On the power of cascade ciphers. <em>ACM Transactions on Computer Systems</em>, vol. 3, no. 2, pp. 108–116, 1985.</p></li>
      <li><p class="text-gray-300">[22] S. Even and Y. Mansour. A construction of a cipher from a single pseudorandom permutation. <em>Asiacrypt '91</em>. LNCS 739, Springer, pp. 210–224, 1992.</p></li>
      <li><p class="text-gray-300">[23] E. Fujisaki, T. Okamoto, D. Pointcheval, and J. Stern. RSA-OAEP is secure under the RSA assumption. <em>J. of Cryptology</em>, vol. 17, no. 2, pp. 81–104, 2004.</p></li>
      <li><p class="text-gray-300">[24] P. Gaˇzi and U. Maurer. Cascade encryption revisited. Manuscript provided by the authors. Received September 2008.</p></li>
      <li><p class="text-gray-300">[25] S. Goldwasser and S. Micali. Probabilistic encryption. <em>J. Comput. Syst. Sci.</em>, vol. 28, no. 2, pp. 270–299, 1984. Earlier version in <em>STOC '82</em>.</p></li>
      <li><p class="text-gray-300">[26] S. Halevi. A plausible approach to computer-aided cryptographic proofs. Cryptology ePrint archive report 2005/181, 2005.</p></li>
      <li><p class="text-gray-300">[27] S. Halevi and P. Rogaway. A parallelizable enciphering mode. <em>CT-RSA '04</em>. LNCS 2964, Springer, pp. 292–304, 2004.</p></li>
      <li><p class="text-gray-300">[28] S. Halevi and P. Rogaway. A tweakable enciphering mode. <em>Crypto '03</em>. LNCS 2729, pp. 482– 499, 2004.</p></li>
      <li><p class="text-gray-300">[29] C. Hall, D. Wagner, J. Kelsey, and B. Schneier. Building PRFs from PRPs. Available on Wagner's web page. Earlier version in <em>Crypto '98</em>.</p></li>
      <li><p class="text-gray-300">[30] R. Impagliazzo and S. Rudich. Limits on the provable consequences of one-way permutations. <em>Crypto '88</em>. LNCS 403, pp. 8–26, 1988.</p></li>
      <li><p class="text-gray-300">[31] E. Jaulmes, A. Joux, and F. Valette. On the security of randomized CBC-MAC beyond the birthday paradox limit: a new construction. <em>FSE '02</em>. LNCS 2365, pp. 237–251, 2002.</p></li>
      <li><p class="text-gray-300">[32] J. Kilian and P. Rogaway. How to protect DES against exhaustive key search (an analysis of DESX). <em>J. of Cryptology</em>, vol. 14, no. 1, pp. 17–35, 2001. Earlier version in <em>Crypto '96</em>.</p></li>
      <li><p class="text-gray-300">[33] S. Lucks. Attacking triple encryption. <em>FSE '98</em>. LNCS 1372, pp. 239–253, 1998.</p></li>
      <li><p class="text-gray-300">[34] U. Maurer. Indistinguishability of random systems. <em>Eurocrypt '02</em>. LNCS 2332, Springer, pp. 110–132, 2002.</p></li>
      <li><p class="text-gray-300">[35] U. Maurer and J. Massey. Cascade ciphers: the importance of being first. <em>J. of Cryptology</em>,</p></li>
      <li><p class="text-gray-300">vol. 6, no. 1, pp. 55–61, 1993.</p></li>
      <li><p class="text-gray-300">[36] R. Merkle and M. Hellman. On the security of multiple encryption. <em>Communications of the ACM</em>, vol. 24, pp. 465–467, 1981.</p></li>
      <li><p class="text-gray-300">[37] R. Motwani and P. Raghavan. <em>Randomized Algorithms.</em> Cambridge University Press, 1995.</p></li>
      <li><p class="text-gray-300">[38] National Institute of Standards and Technology. FIPS PUB 46-3, Data Encryption Standard (DES), 1999. Also ANSI X9.52, Triple Data Encryption Algorithm modes of operation, 1998, and other standards.</p></li>
      <li><p class="text-gray-300">[39] E. Petrank and C. Rackoff. CBC MAC for real-time data sources. <em>J. of Cryptology</em>, vol. 13, no. 3, pp. 315–338, 2000.</p></li>
      <li><p class="text-gray-300">[40] P. Rogaway. Authenticated-encryption with associated-data. <em>ACM CCS '02</em>.</p></li>
      <li><p class="text-gray-300">[41] P. Rogaway. Efficient instantiations of tweakable blockciphers and refinements to modes OCB and PMAC. <em>Asiacrypt '04</em>.</p></li>
      <li><p class="text-gray-300">[42] P. Rogaway, M. Bellare, and J. Black. OCB: A block-cipher mode of operation for efficient authenticated encryption. <em>ACM Transactions on Information and System Security</em>, vol. 6, no. 3, pp. 365–403, 2003. Earlier version in <em>ACM CCS '01</em>.</p></li>
      <li><p class="text-gray-300">[43] T. Schweinberger and V. Shoup. ACE: the advanced cryptographic engine. Cryptology ePrint report 2000/022, 2000.</p></li>
      <li><p class="text-gray-300">[44] C. Shannon. Communication theory of secrecy systems. <em>Bell Systems Technical Journal</em>, vol. 28, no. 4, pp. 656–715, 1949.</p></li>
      <li><p class="text-gray-300">[45] V. Shoup. OAEP reconsidered. <em>J. of Cryptology</em>, vol. 15, no. 4, pp. 223–249, 2002. Earlier version in <em>Crypto '01</em>.</p></li>
      <li><p class="text-gray-300">[46] V. Shoup. A proposal for an ISO standard for public key encryption. Cryptology ePrint report 2001/112, 2001.</p></li>
      <li><p class="text-gray-300">[47] V. Shoup. Sequences of games: a tool for taming complexity in security proofs. Cryptology ePrint report 2004/332, November 30, 2004.</p></li>
      <li><p class="text-gray-300">[48] V. Shoup. Using hash function as a hedge against chosen ciphertext attack. <em>Eurocrypt '00</em>.</p></li>
      <li><p class="text-gray-300">[49] S. Vaudenay. Decorrelation over infinite domains: the encrypted CBC-MAC case. <em>Communications in Information and Systems</em> (CIS), vol. 1, pp. 75–85, 2001.</p></li>
      <li><p class="text-gray-300">[50] A. Yao. Theory and applications of trapdoor functions. <em>FOCS 1982</em>, pp. 80–91, 1982.</p></li>
    </ul>

    <p class="text-gray-300">Let adversary A and other notation be as in Section 2,where we showed by example that if the number of oracle queries made by A depends on the answers it receives in response to previous queries, then (1) may not hold. Here we show that if the number of oracle queries made by A is always <em>exactly</em> q—meaning the number of queries is this value regardless of A's coins and the answers to the oracle queries—then (1) is true.</p>

    <p class="text-gray-300">Note that given any adversary A&lt;sup&gt;1&lt;/sup&gt; making at most q queries, it is easy to modify it to an A&lt;sup&gt;2&lt;/sup&gt; that has the same advantage as A&lt;sup&gt;1&lt;/sup&gt; but makes exactly q oracle queries. (Adversary A&lt;sup&gt;2&lt;/sup&gt; will run A&lt;sup&gt;1&lt;/sup&gt; until it halts, counting the number of oracle queries the latter makes. Calling this number q1, it now makes some q − q&lt;sup&gt;1&lt;/sup&gt; oracle queries, whose answers it ignores, outputting exactly what A&lt;sup&gt;1&lt;/sup&gt; outputs.) In other words, if an adversary is assumed to make at most q queries, one can assume wlog that the number of queries is exactly q. This means that one can in fact obtain a correct proof of the PRP/PRF Switching Lemma based on (1). The bug we highlighted in Section 2thus amounts to having claimed (1) for all A making at most q queries rather than those making exactly q queries.</p>

    <p class="text-gray-300">Let us now show that if the number of oracle queries made by A is always exactly q then (1) is true. Since A is computationally unbounded, we may assume wlog that A is deterministic. We also assume it never repeats an oracle query. Let  <span class="math">V = (\\{0,1\\}^n)^q</span>  and for a q-vector  <span class="math">a \\in V</span>  let  <span class="math">a[i] \\in \\{0,1\\}^n</span>  denote the i-th coordinate of a,  <span class="math">1 \\le i \\le q</span> . We can regard A as a function  <span class="math">f \\colon V \\to \\{0,1\\}</span>  that given a q-vector a of replies to its oracle queries returns a bit f(a). Let a denote the random variable that takes value the q-vector of replies returned by the oracle to the queries made by A. Also let</p>

    <p class="text-gray-300">dist = {
<span class="math">$a \\in V : a[1], \\dots, a[n]</span>$
are distinct }
one = {  <span class="math">a \\in V : f(a) = 1</span>  }.</p>

    <p class="text-gray-300">Let  <span class="math">\\Pr_{\\text{rand}}[\\cdot]</span>  denote the probability in the experiment where  <span class="math">\\rho \\stackrel{\\</span>}{\\leftarrow} \\operatorname{Func}(n)$ . Then</p>

    <p class="text-gray-300">$$\\Pr\\left[A^{\\rho} \\Rightarrow 1 \\mid \\text{Dist}\\right] = \\Pr_{\\text{rand}}\\left[f(\\mathbf{a}) = 1 \\mid \\mathbf{a} \\in \\text{dist}\\right] = \\frac{\\Pr_{\\text{rand}}\\left[f(\\mathbf{a}) = 1 \\land \\mathbf{a} \\in \\text{dist}\\right]}{\\Pr_{\\text{rand}}\\left[\\mathbf{a} \\in \\text{dist}\\right]} \\
= \\frac{\\sum_{a \\in \\text{dist} \\cap \\text{one}} \\Pr_{\\text{rand}}\\left[\\mathbf{a} = a\\right]}{\\sum_{a \\in \\text{dist}} \\Pr_{\\text{rand}}\\left[\\mathbf{a} = a\\right]} = \\frac{\\sum_{a \\in \\text{dist} \\cap \\text{one}} 2^{-nq}}{\\sum_{a \\in \\text{dist}} 2^{-nq}} = \\frac{|\\text{dist} \\cap \\text{one}|}{|\\text{dist}|}.$$</p>

    <p class="text-gray-300">On the other hand let  <span class="math">\\Pr_{\\text{perm}}[\\cdot]</span>  denote the probability in the experiment where  <span class="math">\\pi \\stackrel{\\</span>}{\\leftarrow} \\text{Perm}(n)$ . Then</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[A^{\\pi} \\Rightarrow 1\\right] = \\Pr_{\\text{perm}}\\left[f(\\mathbf{a}) = 1\\right] = \\sum_{a \\in \\text{dist}\\cap \\text{one}} \\Pr_{\\text{perm}}\\left[\\mathbf{a} = a\\right]</span>$
<span class="math">$= \\sum_{a \\in \\text{dist}\\cap \\text{one}} \\prod_{i=0}^{q-1} \\frac{1}{2^n - i} = \\sum_{a \\in \\text{dist}\\cap \\text{one}} \\frac{1}{|\\text{dist}|} = \\frac{|\\text{dist}\\cap \\text{one}|}{|\\text{dist}|}.</span>$</p>

    <h2 id="sec-24" class="text-2xl font-bold">B An Example Programming Language for Games</h2>

    <p class="text-gray-300">FORMALIZING THE UNDERLYING PROGRAMMING LANGUAGE. Games, as well as adversaries, are programs written in some programming language. In this section we describe a suitable programming language for specifying games, denoted  <span class="math">\\mathcal{L}</span> . See Figure 15 for the context-free grammar  <span class="math">\\mathcal{G}</span>  for  <span class="math">\\mathcal{L}</span> . As usual, not every program generated by this grammar is valid (eg, identifiers mustn't be keywords, two procedures can't have the same name, and so forth). The start symbol for a game is game and that for an adversary is adversary. We regard a game (and an adversary) as being specified by its parse tree and therefore ignore the fact that  <span class="math">\\mathcal{G}</span>  is ambiguous. If one wants to regard games as textual strings instead of parse trees then ambiguity can easily be dealt with by bracketing if and for statements, adding parenthesis to expressions, and making extra productions to account for precedence and grouping rules.</p>

    <p class="text-gray-300">STRUCTURE OF  <span class="math">\\mathcal{L}</span> . Our programming language is intentionally simple. Games employ only static, global variables. A game consists of a sequence of procedures (the order of which is irrelevant). There are three kinds of procedures in games: an initialization procedure, a finalization procedure, and oracle procedures. The first two are distinguished by the keyword Initialize or Finalize, which is used as though it were the procedure name. The adversary is a single procedure, one which uses the keyword Adversary as though it were the procedure name.</p>

    <p class="text-gray-300">The language  <span class="math">\\mathcal{L}</span>  is strongly typed. The types of expressions are integer, boolean, string, set, and array.  <span class="math">\\triangleright</span>  integer: A value of this type is a point in the set  <span class="math">Z = \\{\\cdots, -2, -1, 0, 1, 2, \\cdots\\}</span> , or else undefined.  <span class="math">\\triangleright</span>  boolean: A value of this type is either true or false, or else undefined.  <span class="math">\\triangleright</span>  string: A value of this type is a finite string over the binary alphabet  <span class="math">\\Sigma = \\{0, 1\\}</span> , or else undefined.  <span class="math">\\triangleright</span>  set: A value of this type is a finite set of strings, or else undefined.  <span class="math">\\triangleright</span>  array: A value of this type is an associative</p>

    <pre><code class="language-text">qame
                  \\longrightarrow \\varepsilon \\mid procedure \\ qame
procedure
                  → initialization | oracle | finalization
initialization --- procedure Initialize arguments compound
                  --- procedure identifier arguments compound
finalization
                  → procedure Finalize arguments compound
                  → procedure Adversary arguments compound
adversary
arguments
                  \\longrightarrow \\varepsilon \\mid (arglist)
arglist
                  \\longrightarrow identifier | identifier, arglist
compound
                  \\longrightarrow simple | simple, compound
simple
                  \\longrightarrow empty \\mid assign \\mid random \\mid if \\mid for \\mid return
empty
                  \\longrightarrow lvalue \\leftarrow exp
assign
                  \\longrightarrow lvalue \\xleftarrow{\\$} set
random
                  → if exp then compound | if exp then compound else compound
if
for
                  \\longrightarrow for str \\in set do compound | for identifier \\leftarrow int to int do compound
return
                   \\longrightarrow return exp
lvalue
                  \\longrightarrow identifier | identifier[str]
                  \\longrightarrow bool \\mid int \\mid str \\mid set \\mid array \\mid call
exp
                   \\longrightarrow false | true | exp = exp \\mid exp \\neq exp \\mid bool \\text{ and } bool \\mid bool \\text{ or } bool \\mid \\text{ not } bool \\mid
bool
                         int &lt; int \\mid int \\leq int \\mid int &gt; int \\mid int \\geq int \\mid str \\in set \\mid str \\notin set \\mid exp \\mid
                         identifier | undefined
                  \\longrightarrow digits \\mid int + int \\mid int - int \\mid int \\cdot int \\mid int \\mid int \\mid |set| \\mid |str| \\mid
int
                         identifier | undefined
                    \\rightarrow \\; \\varepsilon \\; | \\; bits \\; | \\; str \\; | \\; str \\; | \\; str[int \\rightarrow int] \\; | \\; \\text{encode}(list) \\; | \\; identifier \\; | \\; identifier[str] \\; | \\; \\text{undefined}
str
                    \\rightarrow \\emptyset \\mid \\{ strlist \\} \\mid set \\cup set \\mid set \\cap set \\mid set \\setminus set \\mid set \\circ set \\mid set \\hat{} int \\mid
set
                         domain(identifier) | image(identifier) | identifier | undefined
                   \\longrightarrow identifier
arran
                    \\rightarrow identifier arguments
call
list
                   \\longrightarrow exp \\mid exp \\mid list
strlist
                   \\longrightarrow str \\mid str, strlist
bits
                   \\longrightarrow 0 | 1 | 0 bits | 1 bits
                   \\longrightarrow digit | digit digits
digits
                  \\longrightarrow 0 \\mid 1 \\mid 2 \\mid 3 \\mid 4 \\mid 5 \\mid 6 \\mid 7 \\mid 8 \\mid 9
digit
identifier
                   \\longrightarrow letter characters
                  \\longrightarrow \\varepsilon \\mid letter \\ characters \\mid digit \\ characters
characters
                  \\longrightarrow a | b | \\cdots | z | A | B | \\cdots | Z
letter
</code></pre>

    <p class="text-gray-300">Figure 15: CFG for the sample game-programming-language  <span class="math">\\mathcal{L}</span> . A game G is a program in this language starting from the &quot;game&quot; production. An adversary is also a program in this language, but starting from the &quot;adversary&quot; nonterminal.</p>

    <p class="text-gray-300">array from and to strings; formally, an array A is a map  <span class="math">A: \\{0,1\\}^* \\to \\{0,1\\}^* \\cup \\{\\text{undefined}\\}</span> . At any given time, there will be a finite number of strings X for which  <span class="math">A[X] \\neq \\text{undefined}</span> . An array can alternatively be regarded as a partial function from strings to strings. An array cannot have the value of undefined, but can be everywhere undefined: A[X] = undefined for all  <span class="math">X \\in \\{0,1\\}^*</span> . We assert that A[undefined] = undefined.</p>

    <p class="text-gray-300">We do not bother to declare variables, but each variable and each expression must have a well-defined type, this type inferable from the program. Demanding that each variable has a statically-inferable type rules out programs with statements like  <span class="math">x \\leftarrow x</span>  or  <span class="math">x \\leftarrow</span>  undefined where x occurs in no other context to make manifest its type. The possible types for variables are <em>integer</em>, boolean, string, set, or array. These mean the same as they did for expressions except that a boolean</p>

    <p class="text-gray-300">variable has the semantics of a flag: once true a boolean variable remains true, even if it is assigned false or undefined.</p>

    <p class="text-gray-300">We provide traditional operators like addition on integers, concatenation of strings, and union of sets. Observe that no operator can create an infinite set (eg, we do not provide for Kleene-closure). For an array A we support operators  <span class="math">\\operatorname{domain}(A)</span>  and  <span class="math">\\operatorname{image}(A)</span>  that return  <span class="math">\\{x \\in \\{0,1\\}^*: A[x] \\neq \\operatorname{undefined}]\\}</span>  and  <span class="math">\\{A[x]: x \\in \\{0,1\\}^*\\}</span> , respectively. We provide an operator  <span class="math">\\operatorname{encode}(\\cdots)</span>  that takes a list of values, of any type, and creates a string in such a way that  <span class="math">\\operatorname{encode}(L) \\neq \\operatorname{encode}(L&#x27;)</span>  when  <span class="math">L \\neq L&#x27;</span> . We assume lazy evaluation of  <span class="math">\\operatorname{and}</span>  and  <span class="math">\\operatorname{or}</span> , so false and  <span class="math">\\operatorname{undefined} = \\operatorname{false}</span> , while true or  <span class="math">\\operatorname{undefined} = \\operatorname{true}</span> .</p>

    <p class="text-gray-300">Each procedure is a sequence of statements. The types of statements supported in  <span class="math">\\mathcal{L}</span>  are as follows.  <span class="math">\\triangleright</span>  The empty statement does nothing.  <span class="math">\\triangleright</span>  The assignment statement is of the form  <span class="math">x \\leftarrow e</span> where the left-hand-side must be either a variable or an array reference A[s] for an expression s of type string. In the first case the expression e must have the same type as the variable x, and in the second case it must be a string. The semantics is to evaluate the expression e and then modify the store by assigning this value to x.  <span class="math">\\triangleright</span>  For the random-assignment statement  <span class="math">x \\stackrel{\\</span>}{\\leftarrow} S$ , we require x to be a string variable or an array reference A[s] for an array A and string expression s. The right-hand-side S must be a set. The statement uniformly selects a random element from the set S and assigns that value to x. If  <span class="math">S = \\emptyset</span>  or S =undefined then the result of the randomassignment statement is to set x to undefined. Random-assignment statements are the only source of randomness in programs. An if statement comes in two forms, if e then S, and if e then S else S'. The expression e may have any type. If it is not a boolean then undefined is treated as false and any other value is treated as true (so &quot;if A[B[s]] then S&quot; is legal, and it tests if both B[s] and A[B[s]] are both defined).  <span class="math">\\triangleright</span>  A for statement comes in two forms: for  <span class="math">x \\in A</span>  do S, and for  <span class="math">i \\leftarrow a</span>  to b do S. In the first case x must be a string variable and A must be a set. The expression A is evaluated once and the value remembered. The statement that follows is then executed |A| times, with x taking on the values in A in lexicographic order. If A is empty or undefined then S is not executed. For the form for  <span class="math">i \\leftarrow a</span>  to b do S, the variable i must be an integer variable and expressions a and b are evaluated once, their values being saved. The statement is then evaluated for successive integers between a and b. If a &lt; b or either is undefined then S is not executed.  <span class="math">\\triangleright</span>  The return x statement returns the value x to the caller. All procedures (including Initialize and Finalize) return values in this way. If control flows to the end of a routine without encountering a return statement then undefined is returned. It is understood that identifiers must not be keywords and that oracles must have unique names. The procedure invocation call may not be used in a game; it is provided for the benefit of an adversary, who may call out to named oracles.</p>

    <p class="text-gray-300">An adversary is syntactically identical to an oracle except that the oracle is named &quot;Adversary&quot; and a new expression is allowed, the <em>call</em> expression.</p>

    <p class="text-gray-300">We refer the reader to Section 3 for a discussion of initialization and the subsequent execution of a game with an adversary. The description of an execution there is admittedly informal. A rich theory in computer science exists to formalize the execution of programs, and our programming language is simple enough to present no particular difficulties in pinning down an operational semantics.</p>

    <p class="text-gray-300">We observe that programs in our programming language must terminate. This is because we gave the language no <em>goto</em>, <em>while</em>, or the like; the only way to do repetition is via the <em>for</em> statement, which iterates over a finite set. We have never seen it to be an issue if a game programming language is not Turing-complete. It is, intuitively, more of a concern if adversaries are written in a language that is not Turing-complete (and one might wish to add a statement like a <em>while</em> statement to address that concern). But note that once a game is fixed and a bound is set on the total number</p>

    <p class="text-gray-300">of oracle queries and their lengths, the optimal adversary for this game (optimal in terms of setting a flag <em>bad</em>, maximizing the chance of the game outcome is 1, etc.) will be computable, and it will be computable by a program over L. So at least when adversary computational complexity is not at issue, there is no loss of generality to assume that adversaries are programs over L.</p>

    <p class="text-gray-300">Enhancing the language. The language L is a bit too restrictive to make for a convenient description of some games; it is conveniently supplemented with a bit of &quot;syntactic sugar&quot; (and beyond). (1) We use indentation to indicate grouping for compound statements. (2) We often omit commas as statement separators and use line breaks instead. (3) We allow arrays to be indexed by things other than strings. In such a case the meaning is to apply the encode(·) operator to the argument: A[i, x] is short for A[encode(i, x)]. (4) We allow use subscripts, superscripts, and Greek characters in identifiers. (5) We sometimes use a subscript in place of an array argument, as in EK[X] for E[K, X]. (6) We write domain(A) and image(A) for U − domain(A) and U − image(A) for an understood and specified set U, such as U = {0, 1}n. (7) Sometimes we write a shorthand that actually would be implemented with a fragment of code. For example, when π is an array and one writes π−1[Y ], this would have to be re-coded to fit into the syntax of L. If one knows that domain(π) ⊆ {0, 1}&lt;sup&gt;n&lt;/sup&gt; then π−1[Y ] could be re-coded as a <em>for</em> loop that runs over {0, 1}&lt;sup&gt;n&lt;/sup&gt; looking for the first (and presumably only) point X such that π[X] = Y ; π−1[Y ] is then that value.</p>

    <p class="text-gray-300">In general, we view a game as being written in the language L as long as it is obvious how to transform the program so as to be literally in L. If one were using some sort of automated tool for verifying game-based proofs then it would be necessary to make sure that each game was <em>literally</em> in the target programming language. But when giving a human-readable proof, incorporating whatever constructs or conventions work to simplify the games one is writing is not only permissible, it is nearly essential: a few well-chosen and problem-specific conventions can make for much more readable code, facilitating more easily verified proofs.</p>

`;
---

<BaseLayout title="**Code-Based Game-Playing Proofs and the Security of Triple ... (2004/331)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2004 &middot; eprint 2004/331
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <PaperDisclaimer eprintUrl={EPRINT_URL} />
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

    <PaperHistory slug="code-based-game-playing-proofs-and-the-security-of-triple-2004" />
  </article>
</BaseLayout>
