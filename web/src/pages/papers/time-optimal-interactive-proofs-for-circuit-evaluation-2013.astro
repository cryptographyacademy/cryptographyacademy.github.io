---
import BaseLayout from '../../layouts/BaseLayout.astro';
import PaperDisclaimer from '../../components/PaperDisclaimer.astro';
import PaperHistory from '../../components/PaperHistory.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2013/351';
const CRAWLER = 'marker';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Time-Optimal Interactive Proofs for Circuit Evaluation';
const AUTHORS_HTML = 'Justin Thaler';

const CONTENT = `    <section id="abstract" class="mb-10">
      <h2 class="text-2xl font-bold">Abstract</h2>
      <p class="text-gray-300">Several research teams have recently been working toward the development of practical general-purpose protocols for verifiable computation. These protocols enable a computationally weak verifier to offload computations to a powerful but untrusted prover while providing the verifier with a guarantee that the prover performed the requested computations correctly. Despite substantial progress, existing implementations require further improvements before they become practical for most settings. The main bottleneck is typically the extra effort required by the prover to return an answer with a guarantee of correctness, compared to returning an answer with no guarantee.

We describe a refinement of a powerful interactive proof protocol due to Goldwasser, Kalai, and Rothblum. Cormode, Mitzenmacher, and Thaler show how to implement the prover in this protocol in time $O(S \\log S)$, where $S$ is the size of an arithmetic circuit computing the function of interest. Our refinements apply to circuits with sufficiently \`\`regular&#x27;&#x27; wiring patterns; for these circuits, we bring the runtime of the prover down to $O(S)$. That is, our prover can evaluate the circuit with a guarantee of correctness, with only a constant-factor blowup in work compared to evaluating the circuit with no guarantee.

We argue that our refinements capture a large class of circuits, and we complement our theoretical results with experiments on problems such as matrix multiplication and determining the number of distinct elements in a data stream. Experimentally, our refinements yield a 200x speedup for the prover over the implementation of Cormode et al., and our prover is less than 10x slower than a C++ program that simply evaluates the circuit. Along the way, we describe a special-purpose protocol for matrix multiplication that is of interest in its own right.

Our final contribution is the design of an interactive proof protocol targeted at general data parallel computation. Compared to prior work, this protocol can more efficiently verify complicated computations as long as that computation is applied independently to many different pieces of data.</p>
      <p class="text-gray-300"><strong>Keywords:</strong> interactive proofs &middot; verifiable computation &middot; circuit evaluation</p>
    </section>

      <h3 id="sec-1.1" class="text-xl font-semibold mt-8">1.1 Prior Work</h3>

      <h4 id="sec-1.1.1" class="text-lg font-semibold mt-6">1.1.1 Work on Interactive Proofs.</h4>

    <p class="text-gray-300">Goldwasser, Kalai, and Rothblum described a powerful general-purpose interactive proof protocol in <a href="#page-42-0">[21]</a>. This protocol is framed in the context of <em>circuit evaluation</em>. Given a layered arithmetic circuit <em>C</em> of depth <em>d</em>, size <em>S</em>(<em>n</em>), and fan-in 2, the GKR protocol allows a prover to evaluate <em>C</em> with a guarantee of correctness in time poly(<em>S</em>(<em>n</em>)), while the verifier runs in time <em>O</em>&tilde;(<em>n</em>+<em>d</em> log<em>S</em>(<em>n</em>)), where <em>n</em> is the length of the input and the <em>O</em>&tilde; notation hides polylogarithmic factors in <em>n</em>.</p>

    <p class="text-gray-300">Cormode, Mitzenmacher, and Thaler showed how to bring the runtime of the prover in the GKR protocol down from poly(<em>S</em>(<em>n</em>)) to <em>O</em>(<em>S</em>(<em>n</em>)log<em>S</em>(<em>n</em>)) <a href="#page-42-1">[14]</a>. They also built a full implementation of the protocol and ran it on benchmark problems. These results demonstrated that the protocol does indeed save the verifier significant time in practice (relative to evaluating the circuit locally); they also demonstrated surprising scalability for the prover, although the prover's runtime remained a major bottleneck. With the implementation of <a href="#page-42-1">[14]</a> as a baseline, Thaler et al. <a href="#page-43-2">[38]</a> described a parallel implementation of the GKR protocol that achieved 40x-100x speedups for the prover and 100x speedups for the (already fast) implementation of the verifier.</p>

    <p class="text-gray-300">Vu, Setty, Blumberg, and Walfish <a href="#page-43-1">[40]</a> further refine and extend the implementation of Cormode et al. <a href="#page-42-1">[14]</a>. In particular, they combine the GKR protocol with a compiler from a high-level programming language so that programmers do not have to explicitly express computation in the form of arithmetic circuits as was the case in the implementation of <a href="#page-42-1">[14]</a>. This substantially extends the reach of the implementation, but it should be noted that their approach generates circuits with irregular wiring patterns, and hence only works in a <em>batching</em> model, where the cost of a fairly expensive offline setup phase is amortized by verifying many instances of a single computation in batch. They also build a hybrid system that statically evaluates whether it is better to use the GKR protocol or a different, cryptography-based argument system called Zaatar (see Section <a href="#page-5-0">1.1.2)</a>, and runs the more efficient of the two protocols in an automated fashion.</p>

    <p class="text-gray-300">A growing line of work studies protocols for verifiable computation in the context of <em>data streaming</em>. In this context, the goal is not just to save the verifier time (compared to doing the computation without a prover), but also to save the verifier space. The protocols developed in this line of work allow the client to</p>

    <p class="text-gray-300"><sup>1</sup>http://aws.amazon.com/elasticmapreduce/</p>

    <p class="text-gray-300">make a single streaming pass over the input (which can occur, for example, while the client is uploading data to the cloud), keeping only a very small summary of the data set. The interactive version of this model was introduced by Cormode, Thaler, and Yi <a href="#page-42-2">[15]</a>, who observed that many protocols from the interactive proofs literature, including the GKR protocol, can be made to work in this restrictive setting. The observations of <a href="#page-42-2">[15]</a> imply that all of our protocols also work with streaming verifiers. Non-interactive variants of the streaming interactive proofs model have also been studied in detail <a href="#page-41-0">[12,</a> <a href="#page-42-3">13,</a> <a href="#page-42-4">23,</a> <a href="#page-42-5">27]</a>.</p>

      <h4 id="sec-1.1.2" class="text-lg font-semibold mt-6">1.1.2 Work on Argument Systems.</h4>

    <p class="text-gray-300">There has been a lot of work on the development of efficient interactive arguments, which are essentially interactive proofs that are secure only against dishonest provers that run in polynomial time. A substantial body of work in this area has focused on the development of protocols targeted at specific problems (e.g. <a href="#page-41-1">[2,</a> <a href="#page-41-2">5,</a> <a href="#page-42-6">16]</a>). Other works have focused on the development of general-purpose argument systems. Several papers in this direction (e.g. <a href="#page-41-3">[8,</a> <a href="#page-41-4">10,</a> <a href="#page-41-5">11,</a> <a href="#page-42-7">18]</a>) have used fully homomorphic encryption, which unfortunately remains impractical despite substantial recent progress. Work in this category by Chung et al. <a href="#page-41-4">[10]</a> focuses on streaming settings, and is therefore particularly relevant.</p>

    <p class="text-gray-300">Several research teams have been pursuing the development of general-purpose argument systems that might be suitable for practical use. Theoretical work by Ben-Sasson et al. <a href="#page-41-6">[4]</a> focuses on the development of short PCPs that might be suitable for use in practice &ndash; such PCPs can be compiled into efficient interactive arguments. As short PCPs are often a bottleneck in the development of efficient argument systems, other works have focused on avoiding their use <a href="#page-41-7">[3,</a><a href="#page-41-8">6,</a><a href="#page-41-9">7,</a><a href="#page-42-8">19]</a>. In particular, Gennaro et al. <a href="#page-42-8">[19]</a> and Bitansky et al. <a href="#page-41-10">[9]</a> develop argument systems with a clear focus on implementation potential. Very recent work by Parno et al. <a href="#page-42-9">[30]</a> describes a near-practical general-purpose implementation, called Pinocchio, of an argument system based on <a href="#page-42-8">[19]</a>. Pinocchio is additionally non-interactive and achieves public verifiability.</p>

    <p class="text-gray-300">Another line of implementation work focusing on general-purpose interactive argument systems is due to Setty et al. <a href="#page-43-3">[34</a><a href="#page-43-4">&ndash;36]</a>. This line of work begins with a base argument system due to Ishai et al. <a href="#page-42-10">[25]</a>, and substantially refines the theory to achieve an implementation that approaches practicality. The most recent system in this line of work is called Zaatar <a href="#page-43-4">[36]</a>, and is also based on the work of Gennaro et al. <a href="#page-42-8">[19]</a>. An empirical comparison of the GKR-based approach and Zaatar performed by Vu et al. <a href="#page-43-1">[40]</a> finds the GKR approach to be significantly more efficient for quasi-straight-line computations (e.g. programs with relatively simple control flow), while Zaatar is appropriate for programs with more complicated control flow.</p>

      <h3 id="sec-1.2" class="text-xl font-semibold mt-8">1.2 Our Contributions</h3>

    <p class="text-gray-300">Our primary contributions are three-fold. Our first contribution addresses one of the biggest remaining obstacles to achieving a truly practical implementation of the GKR protocol: the logarithmic factor overhead for the prover. That is, Cormode et al. show how to implement the prover in time <em>O</em>(<em>S</em>(<em>n</em>)log<em>S</em>(<em>n</em>)), where <em>S</em>(<em>n</em>) is the size of the arithmetic circuit to which the GKR protocol is applied, down from the &Omega;(<em>S</em>(<em>n</em>) 3 ) time required for a naive implementation. The hidden constant in the Big-Oh notation is at least 3, and the log<em>S</em>(<em>n</em>) factor translates to well over an order of magnitude, even for circuits with a few million gates.</p>

    <p class="text-gray-300">We remove this logarithmic factor, bringing P's runtime down to <em>O</em>(<em>S</em>(<em>n</em>)) for a large class of circuits. Informally, our results apply to any circuit whose wiring pattern is sufficiently &quot;regular&quot;. We formalize the class of circuits to which our results apply in Theorem <a href="#page-24-1">1.</a></p>

    <p class="text-gray-300">We experimentally demonstrate the generality and effectiveness of Theorem <a href="#page-24-1">1</a> via two case studies. Specifically, we apply an implementation of the protocol of Theorem <a href="#page-24-1">1</a> to a circuit computing matrix multiplication (MATMULT), as well as to a circuit computing the number of distinct items in a data stream (DISTINCT). Experimentally, our refinements yield a 200x-250x speedup for the prover over the state of the art implementation of Cormode et al. <a href="#page-42-1">[14]</a>. A serial implementation of our prover is less than 10x slower than a C++ program that simply evaluates the circuit sequentially, a slowdown that is tolerable in realistic outsourcing scenarios where cycles are plentiful for the prover. Moreover, a parallel implementation of our prover using a graphics processing unit (GPU) is roughly 30x faster than our serial implementation, and therefore takes less time than that required to evaluate the circuit in serial.</p>

    <p class="text-gray-300">Our second contribution is to specify a highly efficient protocol for verifiably outsourcing arbitrary data parallel computation. Compared to prior work, this protocol can more efficiently verify complicated computations, as long as that computation is applied independently to many different pieces of data. We formalize this protocol and its efficiency guarantees in Theorem <a href="#page-33-3">2.</a></p>

    <p class="text-gray-300">Our third contribution is to describe a new protocol specific to matrix multiplication that we believe to be of interest in its own right. This protocol is formalized in Theorem <a href="#page-37-2">3.</a> Given any <em>unverifiable</em> algorithm for <em>n</em>&times;<em>n</em> matrix multiplication that requires time <em>T</em>(<em>n</em>) using space <em>s</em>(<em>n</em>), Theorem <a href="#page-37-2">3</a> allows the prover to run in time <em>T</em>(<em>n</em>)+<em>O</em>(<em>n</em> 2 ) using space <em>s</em>(<em>n</em>)+<em>o</em>(<em>n</em> 2 ). Note that Theorem <a href="#page-37-2">3</a> (which is specific to matrix multiplication) is much less general than Theorem <a href="#page-24-1">1</a> (which applies to any circuit with a sufficiently regular wiring pattern). However, Theorem <a href="#page-37-2">3</a> achieves optimal runtime and space usage for the prover up to leading constants, assuming there is no <em>O</em>(<em>n</em> 2 ) time algorithm for matrix multiplication. While these properties are also satisfied by a classic protocol due to Freivalds <a href="#page-42-11">[17]</a>, the protocol of Theorem <a href="#page-37-2">3</a> is significantly more amenable for use as a primitive when verifying computations that repeatedly invoke matrix multiplication. For example, using the protocol of Theorem <a href="#page-37-2">3</a> as a primitive, we give a natural protocol for computing the diameter of an unweighted directed graph <em>G</em>. V's runtime in this protocol is <em>O</em>(<em>m</em>log<em>n</em>), where <em>m</em> is the number of edges in <em>G</em>, P's runtime matches the best known unverifiable diameter algorithm up to a low-order additive term <a href="#page-43-5">[33,</a> <a href="#page-43-6">42]</a>, and the total communication is just polylog(<em>n</em>). We know of no other protocol achieving this.</p>

    <p class="text-gray-300">We complement Theorem <a href="#page-37-2">3</a> with experimental results demonstrating its efficiency.</p>

      <h3 id="sec-1.3" class="text-xl font-semibold mt-8">1.3 Roadmap</h3>

    <p class="text-gray-300">Section <a href="#page-6-1">2</a> presents preliminaries. We give a high-level overview of the ideas underlying our main results in Section <a href="#page-8-1">3.</a> Section <a href="#page-11-0">4</a> gives a detailed overview of prior work, including the standard sum-check protocol as well as the GKR protocol. Section <a href="#page-16-0">5</a> contains the details of our time-optimal protocol for circuit evaluation as formalized in Theorem <a href="#page-24-1">1.</a> Section <a href="#page-26-0">6</a> describes our experimental cases studies of the protocol described in Theorem <a href="#page-24-1">1.</a> Section <a href="#page-30-0">7</a> describes our protocol for arbitrary data parallel computation. Section <a href="#page-35-0">8</a> describes some additional optimizations that apply to specific important wiring patterns. In particular, this section describes our special-purpose protocol for MATMULT that achieves optimal prover efficiency up to leading constants. Section <a href="#page-40-0">9</a> concludes.</p>

    <section id="sec-2" class="mb-10">
      <h2 class="text-2xl font-bold">2 Preliminaries</h2>

      <h3 id="sec-2.1" class="text-xl font-semibold mt-8">2.1 Definitions</h3>

    <p class="text-gray-300">We begin by defining a valid interactive proof protocol for a function <em>f</em> .</p>

    <p class="text-gray-300">Definition 1 <em>Consider a prover</em> P <em>and verifier</em> V <em>who both observe an input x and wish to compute a function f</em> : {0,1} <em><sup>n</sup></em> &rarr; R <em>for some set</em> R<em>. After the input is observed,</em> P <em>and</em> V <em>exchange a sequence of messages. Denote the output of</em> V <em>on input x, given prover</em> P <em>and</em> V<em>'s random bits R, by out</em>(V, <em>x</em>,<em>R</em>,P)<em>.</em> V <em>can output</em> &perp; <em>if</em> V <em>is not convinced that</em> P<em>'s claim is valid.</em></p>

    <p class="text-gray-300">We say  <span class="math">\\mathcal{P}</span>  is a valid prover with respect to  <span class="math">\\mathcal{V}</span>  if for all inputs x,  <span class="math">Pr_R[out(\\mathcal{V},x,R,\\mathcal{P})=f(x)]=1</span> . The property that there is at least one valid prover  <span class="math">\\mathcal{P}</span>  with respect to  <span class="math">\\mathcal{V}</span>  is called completeness. We say  <span class="math">\\mathcal{V}</span>  is a valid verifier for f with soundness probability  <span class="math">\\delta</span>  if there is at least one valid prover  <span class="math">\\mathcal{P}</span>  with respect to  <span class="math">\\mathcal{V}</span> , and for all provers  <span class="math">\\mathcal{P}&#x27;</span>  and all inputs x,  <span class="math">Pr[out(\\mathcal{V},A,R,\\mathcal{P}&#x27;)\\notin\\{f(x),\\bot\\}]\\leq\\delta</span> . We say a prover-verifier pair  <span class="math">(\\mathcal{P},\\mathcal{V})</span>  is a valid interactive proof protocol for f if  <span class="math">\\mathcal{V}</span>  is a valid verifier for f with soundness probability 1/3, and  <span class="math">\\mathcal{P}</span>  is a valid prover with respect to  <span class="math">\\mathcal{V}</span> . If  <span class="math">\\mathcal{P}</span>  and  <span class="math">\\mathcal{V}</span>  exchange f messages in total, we say the protocol has f rounds.</p>

    <p class="text-gray-300">Informally, the completeness property guarantees that an honest prover will convince the verifier that the claimed answer is correct, while the soundness property ensures that a dishonest prover will be caught with high probability. An <em>interactive argument</em> is an interactive proof where the soundness property holds only against polynomial-time provers  <span class="math">\\mathcal{P}&#x27;</span> . We remark that the constant 1/3 used for the soundness probability in Definition 1 is chosen for consistency with the interactive proofs literature, where 1/3 is used by convention. In our actual implementation, the soundness probability will always be less than  <span class="math">2^{-45}</span> .</p>

      <h4 id="sec-2.1.1" class="text-lg font-semibold mt-6">2.1.1 Cost Model</h4>

    <p class="text-gray-300">Whenever we work over a finite field  <span class="math">\\mathbb{F}</span> , we assume that a single field operation can be computed in a single machine operation. For example, when we say that the prover  <span class="math">\\mathcal{P}</span>  in our interactive protocols requires time O(S(n)), we mean that  <span class="math">\\mathcal{P}</span>  must perform O(S(n)) additions and multiplications within the finite field over which the protocol is defined.</p>

    <p class="text-gray-300"><strong>Input Representation.</strong> Following prior work [12,14,15], all of the protocols we consider can handle inputs specified in a general data stream form. Each element of the stream is a tuple  <span class="math">(i, \\delta)</span> , where  <span class="math">i \\in [n]</span>  and  <span class="math">\\delta</span>  is an integer. The  <span class="math">\\delta</span>  values may be negative, thereby modeling deletions. The data stream implicitly defines a frequency vector a, where  <span class="math">a_i</span>  is the sum of all  <span class="math">\\delta</span>  values associated with i in the stream. For simplicity, we assume throughout the paper that the number of stream updates m is related to n by a constant factor i.e.,  <span class="math">m = \\Theta(n)</span> .</p>

    <p class="text-gray-300">When checking the evaluation of a circuit C, we consider the inputs to C to be the entries of the frequency vector a. We emphasize that in all of our protocols,  <span class="math">\\mathcal{V}</span>  only needs to see the raw stream and not the aggregated frequency vector a (see Lemma 2 for details). Notice that we may interpret the frequency vector a as an object other than a vector, such as a matrix or a string. For example, in MATMULT, the data stream defines two matrices to be multiplied.</p>

    <p class="text-gray-300">When we refer to a <em>streaming verifier</em> with space usage s(n), we mean that the verifier can make a single pass over the stream of tuples defining the input, regardless of their ordering, while storing at most s(n) elements in the finite field over which the protocol is defined.</p>

      <h4 id="sec-2.1.2" class="text-lg font-semibold mt-6">2.1.2 Problem Definitions</h4>

    <p class="text-gray-300">To focus our discussion in this paper, we give special attention to two problems also considered in prior work [14,38].</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>In the MATMULT problem, the input consists of two  <span class="math">n \\times n</span>  matrices  <span class="math">A, B \\in \\mathbb{Z}^{n \\times n}</span> , and the goal is to compute the matrix product  <span class="math">A \\cdot B</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>In the DISTINCT problem, also denoted  <span class="math">F_0</span> , the input is a data steam consisting of m tuples  <span class="math">(i, \\delta)</span>  from a universe of size n. The stream defines a frequency vector a, and the goal is to compute  <span class="math">|\\{i: a_i \\neq 0\\}|</span> , the number of items with non-zero frequency.</li>
    </ol></li>
    </ul>

      <h4 id="sec-2.1.3" class="text-lg font-semibold mt-6">2.1.3 Additional Notation</h4>

    <p class="text-gray-300">Throughout, [<em>n</em>] will denote the set {1,...,<em>n</em>}, while [[<em>n</em>]] will denote the set {0,...,<em>n</em>&minus;1}.</p>

    <p class="text-gray-300">Let F be a field, and F <sup>&lowast;</sup> = F\\ {0} its multiplicative group. For any <em>d</em>-variate polynomial <em>p</em>(<em>x</em>1,..., <em>xd</em>) : F <em><sup>d</sup></em> &rarr; F, we use deg<em><sup>i</sup></em> (<em>p</em>) to denote the degree of <em>p</em> in variable <em>i</em>. A <em>d</em>-variate polynomial <em>p</em> is said to be <em>multilinear</em> if deg<em><sup>i</sup></em> (<em>p</em>) &le; 1 for all <em>i</em> &isin; [<em>d</em>]. Given a function <em>V</em> : {0,1} <em><sup>d</sup></em> &rarr; {0,1} whose domain is the <em>d</em>dimensional Boolean hypercube, the <em>multilinear extension</em> (MLE) of <em>V</em> over F, denoted <em>V</em>&tilde; , is the unique multilinear polynomial F <em><sup>d</sup></em> &rarr; F that agrees with <em>V</em> on all Boolean-valued inputs. That is, <em>V</em>&tilde; is the unique multilinear polynomial over F satisfying <em>V</em>&tilde;(<em>x</em>) = <em>V</em>(<em>x</em>) for all <em>x</em> &isin; {0,1} <em>d</em> .</p>

    </section>

    <section id="sec-3" class="mb-10">
      <h2 class="text-2xl font-bold">3 Overview of the Ideas</h2>

    <p class="text-gray-300">We begin by describing the methodology underlying the GKR protocol before summarizing the ideas underlying our improved protocols.</p>

      <h3 id="sec-3.1" class="text-xl font-semibold mt-8">3.1 The GKR Protocol From 10,000 Feet</h3>

    <p class="text-gray-300">In the GKR protocol, P and V first agree on an arithmetic circuit<em>C</em> of fan-in 2 over a finite field F computing the function of interest (<em>C</em> may have multiple outputs). Each gate of<em>C</em> performs an addition or multiplication over F. <em>C</em> is assumed to be in layered form, meaning that the circuit can be decomposed into layers, and wires only connect gates in adjacent layers. Suppose the circuit has depth <em>d</em>; we will number the layers from 1 to <em>d</em> with layer <em>d</em> referring to the input layer, and layer 1 referring to the output layer.</p>

    <p class="text-gray-300">In the first message, P tells V the (claimed) output of the circuit. The protocol then works its way in iterations towards the input layer, with one iteration devoted to each layer. The purpose of iteration <em>i</em> is to reduce a claim about the values of the gates at layer <em>i</em> to a claim about the values of the gates at layer <em>i</em>+1, in the sense that it is safe for V to assume that the first claim is true as long as the second claim is true. This reduction is accomplished by applying the standard <em>sum-check protocol</em> <a href="#page-42-12">[29]</a> to a certain polynomial.</p>

    <p class="text-gray-300">More concretely, the GKR protocol starts with a claim about the values of the output gates of the circuit, but V cannot check this claim without evaluating the circuit herself, which is precisely what she wants to avoid. So the first iteration uses a sum-check protocol to reduce this claim about the outputs of the circuit to a claim about the gate values at layer 2 (more specifically, to a claim about an evaluation of the multilinear extension (MLE) of the gate values at layer 2). Once again, V cannot check this claim herself, so the second iteration uses another sum-check protocol to reduce the latter claim to a claim about the gate values at layer 3, and so on. Eventually, V is left with a claim about the inputs to the circuit, and V can check this claim on her own.</p>

    <p class="text-gray-300">In summary, the GKR protocol uses a sum-check protocol at each level of the circuit to enable V to go from verifying a randomly chosen evaluation of the MLE of the gate values at layer <em>i</em> to verifying a (different) evaluation of the MLE of the gate values at layer <em>i</em> + 1. Importantly, apart from the input layer and output layer, V does not ever see all of the gate values at a layer (in particular, P does not send these values in full). Instead, V relies on P to do the hard work of actually evaluating the circuit, and uses the power of the sum-check protocol as the main tool to force P to be consistent and truthful over the course of the protocol.</p>

      <h3 id="sec-3.2" class="text-xl font-semibold mt-8">3.2 Achieving Optimal Prover Runtime for Regular Circuits</h3>

    <p class="text-gray-300">In Theorem 1, we describe an interactive proof protocol for circuit evaluation that brings  <span class="math">\\mathcal{P}</span> 's runtime down to O(S(n)) for a large class of circuits, while maintaining the same verifier runtime as in prior implementations of the GKR protocol. Informally, Theorem 1 applies to any circuit whose wiring pattern is sufficiently &quot;regular&quot;.</p>

    <p class="text-gray-300">This protocol follows the same general outline as the GKR protocol, in that we proceed in iterations from the output layer of the circuit to the input layer, using a sum-check protocol at iteration i to reduce a claim about the gate values at layer i to a claim about the gate values at layer i+1. However, at each iteration i we apply the sum-check protocol to a carefully chosen polynomial that differs from the one used by GKR. In each round j of the sum-check protocol, our choice of polynomial allows  <span class="math">\\mathcal{P}</span>  to reuse work from prior rounds in order to compute the prescribed message for round j, allowing us to shave a  <span class="math">\\log S(n)</span>  factor from the runtime of  <span class="math">\\mathcal{P}</span>  relative to the  <span class="math">O(S(n)\\log S(n))</span> -time implementation due to Cormode et al. [14].</p>

    <p class="text-gray-300">Specifically, at iteration i, the GKR protocol uses a polynomial  <span class="math">f_z^{(i)}</span>  defined over  <span class="math">\\log S_i + 2\\log S_{i+1}</span>  variables, where  <span class="math">S_i</span>  is the number of gates at layer i. The &quot;truth table&quot; of  <span class="math">f_z^{(i)}</span>  is sparse on the Boolean hypercube, in the sense that  <span class="math">f_z^{(i)}(x)</span>  is non-zero for at most  <span class="math">S_i</span>  of the  <span class="math">S_i \\cdot S_{i+1}^2</span>  inputs  <span class="math">x \\in \\{0,1\\}^{\\log S_i + 2\\log S_{i+1}}</span> . Cormode et al. leverage this sparsity to bring the runtime of  <span class="math">\\mathcal{P}</span>  in iteration i down to  <span class="math">O(S_i \\log S_i)</span>  from a naive bound of  <span class="math">\\Omega(S_i \\cdot S_{i+1}^2)</span> . However, this same sparsity prevents  <span class="math">\\mathcal{P}</span>  from reusing work from prior iterations as we seek to do.</p>

    <p class="text-gray-300">In contrast, we use a polynomial  <span class="math">g_z^{(i)}</span>  defined over only  <span class="math">\\log S_i</span>  variables rather than  <span class="math">\\log S_i + 2\\log S_{i+1}</span>  variables. Moreover, the truth table of  <span class="math">g_z^{(i)}</span>  is dense on the Boolean hypercube, in the sense that  <span class="math">g_z^{(i)}(x)</span>  may be non-zero for all of the  <span class="math">S_i</span>  Boolean inputs  <span class="math">x \\in \\{0,1\\}^{\\log S_i}</span> . This density allows  <span class="math">\\mathcal{P}</span>  to reuse work from prior iterations in order to speed up her computation in round i of the sum-check protocol.</p>

    <p class="text-gray-300">In more detail, in each round j of the sum-check protocol, the prover's prescribed message is defined via a sum over a large number of terms, where the number of terms falls geometrically fast with the round number j. Moreover, it can be shown that in each round j, each gate at layer i+1 contributes to exactly one term of this sum. Essentially, what we do is group the gates at layer i+1 by the term of the sum to which they contribute. Each such group can be treated as a single unit, ensuring that in any round of the sum-check protocol, the amount of work  <span class="math">\\mathcal{P}</span>  needs to do is proportional to the number of terms in the sum rather than the number of gates  <span class="math">S_i</span>  at layer i.</p>

    <p class="text-gray-300">We remark that a similar &quot;reuse of work&quot; technique was implicit in an analysis by Cormode, Thaler, and Yi [15, Appendix B] of an efficient protocol for a specific streaming problem known as the second frequency moment. This frequency moment protocol was the direct inspiration for our refinements, though we require additional insights to apply the reuse of work technique in the context of evaluating general arithmetic circuits.</p>

    <p class="text-gray-300">It is worth clarifying why our methods do not yield savings when applied to the polynomial  <span class="math">f_z^{(i)}</span>  used in the basic GKR protocol. The reason is that, since  <span class="math">f_z^{(i)}</span>  is defined over  <span class="math">\\log S_i + 2\\log S_{i+1}</span>  variables instead of just  <span class="math">\\log S_i</span>  variables, the sum defining  <span class="math">\\mathcal{P}</span> 's message in round j is over a much larger number of terms when using  <span class="math">f_z^{(i)}</span> . It is still the case that each gate contributes to only one term of the sum, but until the number of terms in the sum falls below  <span class="math">S_i</span>  (which does not happen until round  <span class="math">j = \\log S_i + \\log S_{i+1}</span>  of the sum-check protocol), it is possible for each gate to contribute to a different term. Before this point, grouping gates by the term of the sum to which they contribute is not useful, since each group can have size 1.</p>

      <h3 id="sec-3.3" class="text-xl font-semibold mt-8">3.3 Verifying General Data Parallel Computations</h3>

    <p class="text-gray-300">Theorem <a href="#page-24-1">1</a> only applies to circuits with regular wiring patterns, as do other existing implementations of interactive proof protocols for circuit evaluation <a href="#page-42-1">[14,</a> <a href="#page-43-1">40]</a>. For circuits with irregular wiring patterns, these implementations require the verifier to perform an expensive preprocessing phase (requiring time proportional to the size of the circuit) to pull out information about the wiring of the circuit, and they require a substantial factor blowup (logarithmic in the circuit size) in runtime for the prover relative to evaluating the circuit without a guarantee of correctness.</p>

    <p class="text-gray-300">To address these bottlenecks, we do need to make an assumption about the structure of the circuit we are verifying. Ideally our assumption will be satisfied by many real-world computations. To this end, Theorem <a href="#page-33-3">2</a> will describe a protocol that is highly efficient for any data parallel computation, by which we mean any setting in which one applies the same computation independently to many pieces of data. See Figure <a href="#page-32-1">2</a> in Section <a href="#page-30-0">7</a> for a schematic of a data parallel computation.</p>

    <p class="text-gray-300">The idea behind Theorem <a href="#page-33-3">2</a> is as follows. Let <em>C</em> be a circuit of size <em>S</em> with an arbitrary wiring pattern, and let <em>C</em> <sup>&lowast;</sup> be a &quot;super-circuit&quot; that applies <em>C</em> independently to <em>B</em> different inputs before possibly aggregating the results in some fashion. If one naively applied the basic GKR protocol to the super-circuit <em>C</em> &lowast; , V might have to perform a pre-processing phase that requires time proportional to the size of <em>C</em> &lowast; , which is &Omega;(<em>B</em>&middot; <em>S</em>). Moreover, when applying the basic GKR protocol to <em>C</em> &lowast; , P would require time &Theta;(<em>B</em>&middot; <em>S</em> &middot;log(<em>B</em>&middot; <em>S</em>)).</p>

    <p class="text-gray-300">In order to improve on this, the key observation is that although each sub-computation <em>C</em> can have a very complicated wiring pattern, the circuit is &quot;maximally regular&quot; between sub-computations, as the sub-computations do not interact at all. Therefore, each time the basic GKR protocol would apply the sum-check protocol to a polynomial derived from the wiring predicate of <em>C</em> &lowast; , we instead use a simpler polynomial derived only from the wiring predicate of <em>C</em>. This immediately brings the time required by V in the pre-processing phase down to <em>O</em>(<em>S</em>), which is proportional to the cost of executing a single instance of the sub-computation. By using the reuse of work technique underlying Theorem <a href="#page-24-1">1,</a> we are also able to bring P's runtime down from &Theta;(<em>B</em>&middot; <em>S</em> &middot;log(<em>B</em>&middot; <em>S</em>)) to &Theta;(<em>B</em>&middot; <em>S</em> &middot;log<em>S</em>), i.e., P's requires a factor of <em>O</em>(log<em>S</em>) more time to evaluate the circuit with a guarantee of correctness, compared to evaluating the circuit without such a guarantee. This <em>O</em>(log<em>S</em>) factor overhead does not depend on the batch size <em>B</em>.</p>

    <p class="text-gray-300">Our improvements are most significant when <em>B S</em>, i.e., when a (relatively) small but potentially complicated sub-computation is applied to a very large number of pieces of data. For example, given any very large database, one may ask &quot;How many people in the database satisfy Property <em>P</em>?&quot; Our protocol allows one to verifiably outsource such <em>counting</em> queries with overhead that depends minimally on the size of the database, but that necessarily depends on the complexity of the property <em>P</em>.</p>

      <h3 id="sec-3.4" class="text-xl font-semibold mt-8">3.4 A Special-Purpose Protocol for MATMULT</h3>

    <p class="text-gray-300">We describe a special-purpose protocol for <em>n</em>&times;<em>n</em> MATMULT in Theorem <a href="#page-37-2">3.</a> The idea behind this protocol is as follows. The GKR protocol, as well the protocols of Theorems <a href="#page-24-1">1</a> and <a href="#page-33-3">2,</a> only make use of the multilinear extension <em>V</em>&tilde; <em><sup>i</sup></em> of the function <em>V<sup>i</sup></em> mapping gate labels at layer <em>i</em> of the circuit to their values. In some cases, there is something to be gained by using a higher-degree extension of <em>V<sup>i</sup></em> , and this is precisely what we exploit here.</p>

    <p class="text-gray-300">In more detail, our special-purpose protocol can be viewed as an extension of our circuit-checking techniques applied to a circuit <em>C</em> performing naive matrix multiplication, but using a quadratic extension of the gate values in this circuit. This allows us to verify the computation using a single invocation of the sum-check protocol. More importantly, P can evaluate this higher-degree extension at the necessary points without explicitly materializing all of the gate values of <em>C</em>, which would not be possible if we had used the</p>

    <p class="text-gray-300">multilinear extension of the gate values of C.</p>

    <p class="text-gray-300">In the protocol of Theorem 3,  <span class="math">\\mathcal{P}</span>  just needs to compute the correct output (possibly using an algorithm that is much more sophisticated than naive matrix multiplication), and then perform  <span class="math">O(n^2)</span>  additional work to prove the output is correct. Since  <span class="math">\\mathcal{P}</span>  does not have to evaluate C in full, this protocol is perhaps best viewed outside the lens of circuit evaluation. Still, the idea underlying Theorem 3 can be thought of as a refinement of our circuit evaluation protocols, and we believe that similar ideas may yield further improvements to general-purpose protocols in the future.</p>

    </section>

    <section id="sec-4" class="mb-10">
      <h2 class="text-2xl font-bold">4 Technical Background</h2>

      <h3 id="sec-4.1" class="text-xl font-semibold mt-8">4.1 Schwartz-Zippel Lemma</h3>

    <p class="text-gray-300">We will often make use of the following basic property of polynomials.</p>

    <p class="text-gray-300"><strong>Lemma 1</strong> ([32]) Let  <span class="math">\\mathbb{F}</span>  be any field, and let  <span class="math">f: \\mathbb{F}^m \\to \\mathbb{F}</span>  be a nonzero polynomial of total degree d. Then on any finite set  <span class="math">S \\subseteq \\mathbb{F}</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{x \\leftarrow S^m}[f(x) = 0] \\le d/|S|.</span>$</p>

    <p class="text-gray-300">In words, if x is chosen uniformly at random from  <span class="math">S^m</span> , then the probability that f(x) = 0 is at most d/|S|. In particular, any two distinct polynomials of total degree d can agree on at most d/|S| fraction of points in  <span class="math">S^m</span> .</p>

      <h3 id="sec-4.2" class="text-xl font-semibold mt-8">4.2 Sum-Check Protocol</h3>

    <p class="text-gray-300">Our main technical tool is the sum-check protocol [29], and we present a full description of this protocol for completeness. See also [1, Chapter 8] for a complete exposition and proof of soundness.</p>

    <p class="text-gray-300">Suppose we are given a v-variate polynomial g defined over a finite field  <span class="math">\\mathbb{F}</span> . The purpose of the sumcheck protocol is to compute the sum:</p>

    <p class="text-gray-300"><span class="math">$H := \\sum_{b_1 \\in \\{0,1\\}} \\sum_{b_2 \\in \\{0,1\\}} \\cdots \\sum_{b_{\\nu} \\in \\{0,1\\}} g(b_1, \\dots, b_{\\nu}).</span>$</p>

    <p class="text-gray-300">In order to execute the protocol, the verifier needs to be able to evaluate  <span class="math">g(r_1, ..., r_v)</span>  for a randomly chosen vector  <span class="math">(r_1, ..., r_v) \\in \\mathbb{F}^v</span>  &ndash; see the paragraph preceding Proposition 1 below.</p>

    <p class="text-gray-300">The protocol proceeds in v rounds as follows. In the first round, the prover sends a polynomial  <span class="math">g_1(X_1)</span> , and claims that  <span class="math">g_1(X_1) = \\sum_{x_2,...,x_\\nu \\in \\{0,1\\}^{\\nu-1}} g(X_1,x_2,...,x_\\nu)</span> . Observe that if  <span class="math">g_1</span>  is as claimed, then  <span class="math">H = g_1(0) + g_1(1)</span> . Also observe that the polynomial  <span class="math">g_1(X_1)</span>  has degree  <span class="math">\\deg_1(g)</span> , the degree of variable  <span class="math">x_1</span>  in g. Hence  <span class="math">g_1</span>  can be specified with  <span class="math">\\deg_1(g) + 1</span>  field elements. In our implementation,  <span class="math">\\mathcal{P}</span>  will specify g by sending the evaluation of g at each point in the set  <span class="math">\\{0,1,\\ldots,\\deg_1(g)\\}</span> .</p>

    <p class="text-gray-300">Then, in round j &gt; 1,  <span class="math">\\mathcal{V}</span>  chooses a value  <span class="math">r_{j-1}</span>  uniformly at random from  <span class="math">\\mathbb{F}</span>  and sends  <span class="math">r_{j-1}</span>  to  <span class="math">\\mathcal{P}</span> . We will often refer to this step by saying that variable j-1 gets <em>bound</em> to value  <span class="math">r_{j-1}</span> . In return, the prover sends a polynomial  <span class="math">g_j(X_j)</span> , and claims that</p>

    <p class="text-gray-300"><span class="math">$g_j(X_j) = \\sum_{(x_{j+1},\\dots,x_{\\nu})\\in\\{0,1\\}^{\\nu-j}} g(r_1,\\dots,r_{j-1},X_j,x_{j+1},\\dots,x_{\\nu}).</span>$
(1)</p>

    <p class="text-gray-300">The verifier compares the two most recent polynomials by checking that  <span class="math">g_{j-1}(r_{j-1}) = g_j(0) + g_j(1)</span> , and rejecting otherwise. The verifier also rejects if the degree of  <span class="math">g_j</span>  is too high: each  <span class="math">g_j</span>  should have degree  <span class="math">\\deg_j(g)</span> , the degree of variable  <span class="math">x_j</span>  in g.</p>

    <p class="text-gray-300">In the final round, the prover has sent <em>gv</em>(<em>Xv</em>) which is claimed to be <em>g</em>(<em>r</em>1,...,<em>rv</em>&minus;1,<em>Xv</em>). V now checks that <em>gv</em>(<em>rv</em>) = <em>g</em>(<em>r</em>1,...,<em>rv</em>) (recall that we assumed V can evaluate <em>g</em> at this point). If this test succeeds, and so do all previous tests, then the verifier accepts, and is convinced that <em>H</em> = <em>g</em>1(0) +<em>g</em>1(1).</p>

    <p class="text-gray-300">Proposition 1 <em>Let g be a v-variate polynomial defined over a finite field</em> F<em>, and let</em> (P,V) <em>be the proververifier pair in the above description of the sum-check protocol.</em> (P,V) <em>is a valid interactive proof protocol for the function H</em> = &sum;<em>b</em>1&isin;{0,1} &sum;<em>b</em>2&isin;{0,1} &middot;&middot;&middot;&sum;<em>bv</em>&isin;{0,1} <em>g</em>(<em>b</em>1,...,<em>bv</em>)<em>.</em></p>

      <h4 id="sec-4.2.1" class="text-lg font-semibold mt-6">4.2.1 Discussion of costs.</h4>

    <p class="text-gray-300">Observe that there is one round in the sum-check protocol for each of the <em>v</em> variables of <em>g</em>. The total communication is &sum; <em>v i</em>=1 deg<em><sup>i</sup></em> (<em>g</em>) +1 = <em>v</em>+&sum; <em>v i</em>=1 deg<em><sup>i</sup></em> (<em>g</em>) field elements. In all of our applications, deg<em><sup>i</sup></em> (<em>g</em>) = <em>O</em>(1) for all <em>i</em>, and so the communication cost is <em>O</em>(<em>v</em>) field elements.</p>

    <p class="text-gray-300">The running time of the verifier over the entire execution of the protocol is proportional to the total communication, plus the amount of time required to compute <em>g</em>(<em>r</em>1,...,<em>rv</em>).</p>

    <p class="text-gray-300">Determining the running time of the prover is less straightforward. Recall that P can specify <em>g<sup>j</sup></em> by sending for each <em>i</em> &isin; {0,...,deg<em><sup>j</sup></em> (<em>g</em>)} the value:</p>

    <p class="text-gray-300"><span class="math">$g_j(i) = \\sum_{(x_{j+1}, \\dots, x_v) \\in \\{0, 1\\}^{v-j}} g(r_1, \\dots, r_{j-1}, i, x_{j+1}, \\dots, x_v).</span>$
(2)</p>

    <p class="text-gray-300">An important insight is that the number of terms defining the value <em>gj</em>(<em>i</em>) in Equation <a href="#page-12-4">(2)</a> falls geometrically with <em>j</em>: in the <em>j</em>th sum, there are only 2<em>v</em>&minus;<em><sup>j</sup></em> terms, each corresponding to a Boolean vector in {0,1} <em>v</em>&minus;<em>j</em> . The total number of terms that must be evaluated over the course of the protocol is therefore <em>O</em> &sum; <em>v j</em>=1 2 <em>v</em>&minus;<em>j</em> = <em>O</em>(2 <em>v</em> ). Consequently, if P is given oracle access to the truth table of the polynomial <em>g</em>, then P will require just <em>O</em>(2 <em>v</em> ) time.</p>

    <p class="text-gray-300">Unfortunately, in our applications P will not have oracle access to the truth table of <em>g</em>. The key to our results is to show that in our applications P can nonetheless evaluate <em>g</em> at all of the necessary points in <em>O</em>(2 <em>v</em> ) total time.</p>

      <h3 id="sec-4.3" class="text-xl font-semibold mt-8">4.3 The GKR Protocol</h3>

    <p class="text-gray-300">We describe the details of the GKR protocol for completeness, as well as to simplify the exposition of our refinements.</p>

      <h4 id="sec-4.3.1" class="text-lg font-semibold mt-6">4.3.1 Notation</h4>

    <p class="text-gray-300">Suppose we are given a layered arithmetic circuit <em>C</em> of size <em>S</em>(<em>n</em>), depth <em>d</em>(<em>n</em>), and fan-in two. Let <em>S<sup>i</sup></em> denote the number of gates at layer <em>i</em> of the circuit <em>C</em>. Assume <em>S<sup>i</sup></em> is a power of 2 and let <em>S<sup>i</sup></em> = 2 <em>si</em> . In order to explain how each iteration of the GKR protocol proceeds, we need to introduce several functions, each of which encodes certain information about the circuit.</p>

    <p class="text-gray-300">To this end, number the gates at layer <em>i</em> from 0 to <em>S<sup>i</sup></em> &minus;1, and let <em>V<sup>i</sup></em> : {0,1} <em><sup>s</sup><sup>i</sup></em> &rarr; F denote the function that takes as input a binary gate label, and outputs the corresponding gate's value at layer <em>i</em>. The GKR protocol makes use of the multilinear extension <em>V</em>&tilde; <em><sup>i</sup></em> of the function <em>V<sup>i</sup></em> (see Section <a href="#page-8-0">2.1.3)</a>.</p>

    <p class="text-gray-300">The GKR protocol also makes use of the notion of a &quot;wiring predicate&quot; that encodes which pairs of wires from layer <em>i</em>+1 are connected to a given gate at layer <em>i</em> in <em>C</em>. We define two functions, add<em><sup>i</sup></em> and mult<em><sup>i</sup></em></p>

    <p class="text-gray-300">mapping  <span class="math">\\{0,1\\}^{s_i+2s_{i+1}}</span>  to  <span class="math">\\{0,1\\}</span> , which together constitute the wiring predicate of layer i of C. Specifically, these functions take as input three gate labels  <span class="math">(j_1, j_2, j_3)</span> , and return 1 if gate  <span class="math">j_1</span>  at layer i is the addition (respectively, multiplication) of gates  <span class="math">j_2</span>  and  <span class="math">j_3</span>  at layer i+1, and return 0 otherwise. Let  <span class="math">\\tilde{\\text{add}}_i</span>  and  <span class="math">\\tilde{\\text{mult}}_i</span>  denote the multilinear extensions of  <span class="math">\\text{add}_i</span>  and  <span class="math">\\text{mult}_i</span>  respectively.</p>

    <p class="text-gray-300">Finally, let  <span class="math">\\beta_{s_i}(z, p)</span>  denote the function</p>

    <p class="text-gray-300"><span class="math">$\\beta_{s_i}(z,p) = \\prod_{j=1}^{s_i} ((1-z_j)(1-p_j) + z_j p_j).</span>$</p>

    <p class="text-gray-300">It is straightforward to check that  <span class="math">\\beta_{s_i}</span>  is the multilinear extension of the function  <span class="math">B(x,y): \\{0,1\\}^{s_i} \\times \\{0,1\\}^{s_i} \\to \\{0,1\\}</span>  that evaluates to 1 if x = y, and evaluates to 0 otherwise.</p>

      <h4 id="sec-4.3.2" class="text-lg font-semibold mt-6">4.3.2 Protocol Outline</h4>

    <p class="text-gray-300">The GKR protocol consists of d(n) iterations, one for each layer of the circuit. Each iteration starts with  <span class="math">\\mathcal{P}</span>  claiming a value for  <span class="math">\\tilde{V}_i(z)</span>  for some field element  <span class="math">z \\in \\mathbb{F}^{s_i}</span> . In the first iteration and circuits with a single output gate, z = 0 and  <span class="math">\\tilde{V}_1(0)</span>  corresponds to the output value of the circuit.</p>

    <p class="text-gray-300">For circuits with many output gates, Vu et al. [40] observe that in the first iteration,  <span class="math">\\mathcal{P}</span>  may simply send  <span class="math">\\mathcal{V}</span>  the (claimed) values of all output gates, thereby specifying a function  <span class="math">V_1&#x27;: \\{0,1\\}^{s_1} \\to \\mathbb{F}</span>  claimed to equal  <span class="math">V_1</span> .  <span class="math">\\mathcal{V}</span>  can pick a random point  <span class="math">z \\in \\mathbb{F}^{s_1}</span>  and evaluate  <span class="math">\\tilde{V}_1&#x27;(z)</span>  on her own in  <span class="math">O(S_1)</span>  time (see Remark 1 in Section 4.3.5). The Schwartz-Zippel Lemma (Lemma 1) implies that it is safe for  <span class="math">\\mathcal{V}</span>  to believe that  <span class="math">V_1&#x27;</span>  indeed equals  <span class="math">V_1</span>  as claimed, as long as  <span class="math">\\tilde{V}_1(z) = \\tilde{V}_1&#x27;(z)</span>  (which will be checked in the remainder of the protocol).</p>

    <p class="text-gray-300">The purpose of iteration i is to reduce the claim about the value of  <span class="math">\\tilde{V}_i(z)</span>  to a claim about  <span class="math">\\tilde{V}_{i+1}(\\omega)</span>  for some  <span class="math">\\omega \\in \\mathbb{F}^{s_{i+1}}</span> , in the sense that it is safe for  <span class="math">\\mathcal{V}</span>  to assume that the first claim is true as long as the second claim is true. To accomplish this, the iteration applies the sum-check protocol described in Section 4.2 to a specific polynomial derived from  <span class="math">\\tilde{V}_{i+1}</span> ,  <span class="math">\\tilde{\\text{add}}_i</span> , and  <span class="math">\\tilde{\\text{mult}}_i</span> , and  <span class="math">\\beta_{s_i}</span> .</p>

      <h4 id="sec-4.3.3" class="text-lg font-semibold mt-6">4.3.3 Details for Each Iteration</h4>

    <p class="text-gray-300"><strong>Applying the Sum-Check Protocol.</strong> It can be shown that for any  <span class="math">z \\in \\mathbb{F}^{s_i}</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\tilde{V}_i(z) = \\sum_{(p, \\pmb{\\omega}_1, \\pmb{\\omega}_2) \\in \\{0, 1\\}^{s_i + 2s_{i+1}}} f_z^{(i)}(p, \\pmb{\\omega}_1, \\pmb{\\omega}_2),</span>$</p>

    <p class="text-gray-300">where</p>

    <p class="text-gray-300"><span class="math">$f_z^{(i)}(p, \\omega_1, \\omega_2) = \\beta_{s_i}(z, p) \\cdot \\left( \\tilde{\\text{add}}_i(p, \\omega_1, \\omega_2) (\\tilde{V}_{i+1}(\\omega_1) + \\tilde{V}_{i+1}(\\omega_2)) + \\tilde{\\text{mult}}_i(p, \\omega_1, \\omega_2) \\tilde{V}_{i+1}(\\omega_1) \\cdot \\tilde{V}_{i+1}(\\omega_2) \\right). \\tag{3}</span>$</p>

    <p class="text-gray-300">Iteration i therefore applies the sum-check protocol of Section 4.2 to the polynomial  <span class="math">f_z^{(i)}</span> . There remains the issue that  <span class="math">\\mathcal{V}</span>  can only execute her part of the sum-check protocol if she can evaluate the polynomial  <span class="math">f_z^{(i)}</span>  at a random point  <span class="math">f_z^{(i)}(r_1,\\ldots,r_{s_i+2s_{i+1}})</span> . This is handled as follows.</p>

    <p class="text-gray-300">Let  <span class="math">p^*</span>  denote the first  <span class="math">s_i</span>  entries of the vector  <span class="math">(r_1, \\ldots, r_{s_i+2s_{i+1}})</span> ,  <span class="math">\\omega_1^*</span>  the next  <span class="math">s_{i+1}</span>  entries, and  <span class="math">\\omega_2^*</span>  the last  <span class="math">s_{i+1}</span>  entries. Evaluating  <span class="math">f_z^{(i)}(p^*, \\omega_1^*, \\omega_2^*)</span>  requires evaluating  <span class="math">\\beta(z, p^*)</span> ,  <span class="math">\\tilde{\\mathrm{add}}_i(p^*, \\omega_1^*, \\omega_2^*)</span> ,  <span class="math">\\tilde{\\mathrm{mult}}_i(p^*, \\omega_1^*, \\omega_2^*)</span> ,  <span class="math">\\tilde{V}_{i+1}(\\omega_1^*)</span> , and  <span class="math">\\tilde{V}_{i+1}(\\omega_2^*)</span> .</p>

    <p class="text-gray-300"><span class="math">\\mathcal{V}</span>  can easily evaluate  <span class="math">\\beta(z, p^*)</span>  in  <span class="math">O(s_i)</span>  time. For many circuits, particularly those with &quot;regular&quot; wiring patterns,  <span class="math">\\mathcal{V}</span>  can evaluate  <span class="math">\\tilde{\\text{add}}_i(p^*, \\omega_1^*, \\omega_2^*)</span>  and  <span class="math">\\tilde{\\text{mult}}_i(p^*, \\omega_1^*, \\omega_2^*)</span>  on her own in  <span class="math">\\text{poly}(s_i, s_{i+1})</span>  time as well.<sup>2</sup></p>

    <p class="text-gray-300"><span class="math">\\mathcal{V}</span>  cannot however evaluate  <span class="math">\\tilde{V}_{i+1}(\\omega_2^*)</span> , and  <span class="math">\\tilde{V}_{i+1}(\\omega_1^*)</span>  on her own without evaluating the circuit. Instead,  <span class="math">\\mathcal{V}</span>  asks  <span class="math">\\mathcal{P}</span>  to simply tell her these two values, and uses iteration i+1 to <em>verify</em> that these values are as claimed. However, one complication remains: the precondition for iteration i+1 is that  <span class="math">\\mathcal{P}</span>  claims a value for  <span class="math">\\tilde{V}_i(z)</span>  for a single  <span class="math">z \\in \\mathbb{F}^{s_i}</span> . So  <span class="math">\\mathcal{V}</span>  needs to reduce verifying both  <span class="math">\\tilde{V}_{i+1}(\\omega_2^*)</span>  and  <span class="math">\\tilde{V}_{i+1}(\\omega_1^*)</span>  to verifying  <span class="math">\\tilde{V}_{i+1}(\\omega^*)</span>  at a single point  <span class="math">\\omega^* \\in \\mathbb{F}^{s_{i+1}}</span> , in the sense that it is safe for  <span class="math">\\mathcal{V}</span>  to accept the claimed values of  <span class="math">\\tilde{V}_{i+1}(\\omega_1^*)</span>  and  <span class="math">\\tilde{V}_{i+1}(\\omega_2^*)</span>  as long as the value of  <span class="math">\\tilde{V}_{i+1}(\\omega^*)</span>  is as claimed. This is done as follows.</p>

    <p class="text-gray-300"><strong>Reducing to Verification of a Single Point.</strong> Let  <span class="math">\\ell: \\mathbb{F} \\to \\mathbb{F}^{s_{i+1}}</span>  be some canonical line passing through  <span class="math">\\omega_1^*</span>  and  <span class="math">\\omega_2^*</span> . For example, we can let  <span class="math">\\ell</span>  be the unique line such that  <span class="math">\\ell(0) = \\omega_1^*</span>  and  <span class="math">\\ell(1) = \\omega_2^*</span> .  <span class="math">\\mathcal{P}</span>  sends a degree- <span class="math">s_{i+1}</span>  polynomial h claimed to be  <span class="math">\\tilde{V}_{i+1} \\circ \\ell</span> , the restriction of  <span class="math">\\tilde{V}_{i+1}</span>  to the line  <span class="math">\\ell</span> .  <span class="math">\\mathcal{V}</span>  checks that  <span class="math">h(0) = \\omega_1^*</span>  and  <span class="math">h(1) = \\omega_2^*</span>  (rejecting if this is not the case), picks a random point  <span class="math">r^* \\in \\mathbb{F}</span> , and asks  <span class="math">\\mathcal{P}</span>  to prove that  <span class="math">\\tilde{V}_{i+1}(\\ell(r^*)) = h(r^*)</span> . By the Schwartz-Zippel Lemma (Lemma 1), as long as  <span class="math">\\mathcal{V}</span>  is convinced that  <span class="math">\\tilde{V}_{i+1}(\\ell(r^*)) = h(r^*)</span> , it is safe for  <span class="math">\\mathcal{V}</span>  to believe that the values of  <span class="math">\\tilde{V}_{i+1}(\\omega_1^*)</span>  and  <span class="math">\\tilde{V}_{i+1}(\\omega_2^*)</span>  are as claimed by  <span class="math">\\mathcal{P}</span> . This completes iteration i;  <span class="math">\\mathcal{P}</span>  and  <span class="math">\\mathcal{V}</span>  then move on to the iteration for layer i+1 of the circuit, whose purpose is to verify that  <span class="math">\\tilde{V}_{i+1}(\\ell(r^*))</span>  has the claimed value.</p>

    <p class="text-gray-300">The Final Iteration. Finally, at the final iteration d,  <span class="math">\\mathcal{V}</span>  must evaluate  <span class="math">\\tilde{V}_d(\\omega^*)</span>  on her own. But the vector of gate values at layer d of C is simply the input x to C. It can be shown that  <span class="math">\\mathcal{V}</span>  can compute  <span class="math">\\tilde{V}_d(\\omega^*)</span>  on her own in  <span class="math">O(n\\log n)</span>  time, with a single streaming pass over the input [15]. Moreover, Vu et al. show how to bring  <span class="math">\\mathcal{V}</span> 's time cost down to O(n) [40], but this methodology does not work in a general streaming model. For completeness, we present details of both of these observations in Section 4.3.5.</p>

      <h4 id="sec-4.3.4" class="text-lg font-semibold mt-6">4.3.4 Discussion of Costs.</h4>

    <p class="text-gray-300">Observe that the polynomial  <span class="math">f_z^{(i)}</span>  defined in Equation (3) is an  <span class="math">(s_i + 2s_{i+1})</span> -variate polynomial of degree at most 2 in each variable, and so the invocation of the sum-check protocol at iteration i requires  <span class="math">s_i + 2s_{i+1}</span>  rounds, with three field elements transmitted per round. Thus, the total communication cost is  <span class="math">O(d(n)\\log S(n))</span>  field elements, where d(n) is the depth of the circuit C. The time cost to V is  <span class="math">O(n\\log n + d(n)\\log S(n))</span> , where the  <span class="math">n\\log n</span>  term is due to the time required to evaluate  <span class="math">\\tilde{V}_d(\\omega^*)</span>  (see Lemma 2 below), and the  <span class="math">d(n)\\log S(n)</span>  term is the time required for V to send messages to P and process and check the messages from P.</p>

    <p class="text-gray-300">As for  <span class="math">\\mathcal{P}</span> 's runtime, for any iteration i of the GKR protocol, a naive implementation of the prover in the corresponding instance of the sum-check protocol would require time  <span class="math">\\Omega(2^{s_i+2s_{i+1}})</span> , as the sum defining each of  <span class="math">\\mathcal{P}</span> 's messages is over as many as  <span class="math">2^{s_i+2s_{i+1}}</span>  terms. This cost can be  <span class="math">\\Omega(S(n)^3)</span> , which is prohibitively large in practice. However, Cormode, Mitzenmacher, and Thaler showed in [14] that each gate at layers i and i+1 of C contributes to only a <em>single</em> term of sum, and exploit this to bring the runtime of the  <span class="math">\\mathcal{P}</span>  down to  <span class="math">O(S(n)\\log S(n))</span> .</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;2</sup>Various suggestions have been put forth for what to do if this is not the case. For example, these computations can always be done by  <span class="math">\\mathcal{V}</span>  in  <span class="math">O(\\log S(n))</span>  space as long as the circuit is log-space uniform, which is sufficient in streaming applications where the space usage of the verifier is paramount [14]. Moreover, these computations can be done offline before the input is even observed, because they only depend on the wiring of the circuit, and not on the input [14, 21]. Finally, [40] notes that the cost of this computation can be effectively amortized in a batching model, where many identical computations on different inputs are verified simultaneously. See Section 7 for further discussion, and a protocol that mitigates this issue in the context of data parallel computation.</p>

      <h4 id="sec-4.3.5" class="text-lg font-semibold mt-6">4.3.5 Making V Fast vs. Making V Streaming</h4>

    <p class="text-gray-300">We describe how  <span class="math">\\mathcal{V}</span>  can efficiently evaluate  <span class="math">\\tilde{V}_d(\\omega^*)</span>  on her own, as required in the final iteration of the GKR protocol. Prior work has identified two methods for performing this computation. The first method is due to Cormode, Thaler, and Yi [15]. It requires  <span class="math">O(n\\log n)</span>  time, and allows  <span class="math">\\mathcal{V}</span>  to make a single streaming pass over the input using  <span class="math">O(\\log n)</span>  space.</p>

    <p class="text-gray-300"><strong>Lemma 2</strong> ( [15]) Given an input  <span class="math">x \\in \\mathbb{F}^n</span>  and a vector  <span class="math">\\mathbf{\\omega}^* \\in \\mathbb{F}^{\\log n}</span> ,  <span class="math">\\mathcal{V}</span>  can compute  <span class="math">\\tilde{V}_d(\\mathbf{\\omega}^*)</span>  in  <span class="math">O(n \\log n)</span>  time and  <span class="math">O(\\log n)</span>  space with a single streaming pass over the input, where  <span class="math">\\tilde{V}_d</span>  is the multilinear extension of the function that maps  <span class="math">i \\in \\{0,1\\}^{\\log n}</span>  to the value of the ith entry of x.</p>

    <p class="text-gray-300"><strong>Proof:</strong> We exploit the following explicit expression for  <span class="math">\\tilde{V}_d</span> . For a vector  <span class="math">b \\in \\{0,1\\}^{\\log n}</span>  let  <span class="math">\\chi_b(x_1,\\ldots,x_{\\log n}) = \\prod_{k=1}^{\\log n} \\chi_{b_k}(x_k)</span> , where  <span class="math">\\chi_0(x_k) = 1 - x_k</span>  and  <span class="math">\\chi_1(x_k) = x_k</span> . Notice that  <span class="math">\\chi_b</span>  is the unique multilinear polynomial that takes  <span class="math">b \\in \\{0,1\\}^{\\log n}</span>  to 1 and all other values in  <span class="math">\\{0,1\\}^{\\log n}</span>  to 0, i.e., it is the multilinear extension of the indicator function for boolean vector b. With this definition in hand, we may write:</p>

    <p class="text-gray-300">
<span class="math">$\\tilde{V}_d(p_1, \\dots, p_{\\log n}) = \\sum_{b \\in \\{0,1\\}^{\\log n}} V_d(b) \\chi_b(p_1, \\dots p_{\\log n})</span>$
(4)</p>

    <p class="text-gray-300">Indeed, it is easy to check that the right hand side of Equation (4) is a multilinear polynomial, and that it agrees with  <span class="math">V_d</span>  on all Boolean inputs. Hence, the right hand side must equal the multilinear extension of  <span class="math">V_d</span> . In particular, by letting  <span class="math">(p_1, \\ldots, p_{\\log n}) = \\omega^*</span>  in Equation (4), we see that</p>

    <p class="text-gray-300"><span class="math">$\\tilde{V}_d(\\boldsymbol{\\omega}^*) = \\sum_{b \\in \\{0,1\\}^{\\log n}} V_d(b) \\chi_b(\\boldsymbol{\\omega}^*). \\tag{5}</span>$</p>

    <p class="text-gray-300">Given any stream update  <span class="math">(i, \\delta)</span> , let  <span class="math">(i_1, \\ldots, i_{\\log n})</span>  denote the binary representation of i. Notice that update  <span class="math">(i, \\delta)</span>  has the effect of increasing  <span class="math">V_d(i_1, \\ldots, i_{\\log n})</span>  by  <span class="math">\\delta</span> , and does not affect  <span class="math">V_d(x_1, \\ldots, x_{\\log n})</span>  for any  <span class="math">(x_1, \\ldots, x_{\\log n}) \\neq (i_1, \\ldots, i_{\\log n})</span> . Thus,  <span class="math">\\mathcal{V}</span>  can compute  <span class="math">\\tilde{V}_d(\\omega^*)</span>  incrementally from the raw stream by initializing  <span class="math">\\tilde{V}_d(\\omega^*) \\leftarrow 0</span> , and processing each update  <span class="math">(i, \\delta)</span>  via:</p>

    <p class="text-gray-300">
<span class="math">$\\tilde{V}_d(\\boldsymbol{\\omega}^*) \\leftarrow \\tilde{V}_d(\\boldsymbol{\\omega}^*) + \\boldsymbol{\\delta} \\cdot \\boldsymbol{\\chi}_i(\\boldsymbol{\\omega}^*).</span>$</p>

    <p class="text-gray-300"><span class="math">\\mathcal V</span>  only needs to store  <span class="math">\\tilde V_d(\\omega^*)</span>  and  <span class="math">\\omega^*</span> , which requires  <span class="math">O(\\log n)</span>  words of memory. Moreover, for any i,  <span class="math">\\chi_{(i_1,\\dots,i_{\\log n})}(\\omega^*)</span>  can be computed in  <span class="math">O(\\log n)</span>  field operations, and thus  <span class="math">\\mathcal V</span>  can compute  <span class="math">\\tilde V_d(\\omega^*)</span>  with one pass over the raw stream, using  <span class="math">O(\\log n)</span>  words of space and  <span class="math">O(\\log n)</span>  field operations per update.</p>

    <p class="text-gray-300">The second method is due to Vu et al. [40]. It enables  <span class="math">\\mathcal{V}</span>  to compute  <span class="math">\\tilde{V}_d(\\boldsymbol{\\omega}^*)</span>  in O(n) time, but requires  <span class="math">\\mathcal{V}</span>  to use O(n) space.</p>

    <p class="text-gray-300"><strong>Lemma 3 (Vu et al. [40])</strong> V can compute  <span class="math">\\tilde{V}_d(\\omega^*)</span>  in O(n) time and O(n) space.</p>

    <p class="text-gray-300"><strong>Proof:</strong> We again exploit the expression for  <span class="math">\\tilde{V}_d(\\omega^*)</span>  in Equation (5). Notice the right hand side of Equation (5) expresses  <span class="math">\\tilde{V}_d(\\omega^*)</span>  as the inner product of two <em>n</em>-dimensional vectors, where the <em>b</em>th entry of the first vector is  <span class="math">V_d(b)</span>  and the <em>b</em>th entry of the second vector is  <span class="math">\\chi_b(\\omega^*)</span> . This inner product can be computed in O(n) time given a table of size <em>n</em> whose <em>b</em>th entry contains the quantity  <span class="math">\\chi_b(\\omega^*)</span> . Vu et al. show how to build such a table in time O(n) using memoization.</p>

    <p class="text-gray-300">The memoization procedure consists of  <span class="math">\\log n</span>  stages, where Stage j constructs a table  <span class="math">A^{(j)}</span>  of size  <span class="math">2^j</span> , such that for any  <span class="math">(b_1,\\ldots,b_j)\\in\\{0,1\\}^j</span> ,  <span class="math">A^{(j)}[(b_1,\\ldots,b_j)]=\\prod_{i=1}^j\\chi_{b_i}(\\omega_i^*)</span> . Notice  <span class="math">A^{(j)}[(b_1,\\ldots,b_j)]=A^{(j-1)}[(b_1,\\ldots,b_{j-1})]\\cdot\\chi_{b_j}(\\omega_j^*)</span> , and so the jth stage of the memoization procedure requires time  <span class="math">O(2^j)</span> . The total time across all  <span class="math">\\log n</span>  stages is therefore  <span class="math">O(\\sum_{j=1}^{\\log n}2^j)=O(2^{\\log n})=O(n)</span> . This completes the proof.</p>

    <p class="text-gray-300"><strong>Remark 1</strong> In [41], Vu et al. further observe that if the input is presented in a specific order, then V can evaluate  <span class="math">\\tilde{V}_d(\\omega^*)</span>  using  <span class="math">O(\\log n)</span>  space. Compare this result to Lemma 2, which requires  <span class="math">O(\\log n)</span>  time for V, but allows V to use  <span class="math">O(\\log n)</span>  space regardless of the order in which the input is presented.</p>

    </section>

    <section id="sec-5" class="mb-10">
      <h2 class="text-2xl font-bold">5 Time-Optimal Protocols for Circuit Evaluation</h2>

      <h3 id="sec-5.1" class="text-xl font-semibold mt-8">5.1 Protocol Outline and Section Roadmap</h3>

    <p class="text-gray-300">As with the GKR protocol, our protocol consists of d(n) iterations, one for each layer of the circuit. Each iteration starts with  <span class="math">\\mathcal{P}</span>  claiming a value for  <span class="math">\\tilde{V}_i(z)</span>  for some value  <span class="math">z \\in \\mathbb{F}^{s_i}</span> . The purpose of the iteration is to reduce this claim to a claim about  <span class="math">\\tilde{V}_{i+1}(\\omega)</span>  for some  <span class="math">\\omega \\in \\mathbb{F}^{s_{i+1}}</span> , in the sense that it is safe for  <span class="math">\\mathcal{V}</span>  to assume that the first claim is true as long as the second claim is true. As in the GKR protocol, this is done by invoking the sum-check protocol on a certain polynomial.</p>

    <p class="text-gray-300">In order to improve on the costs of the GKR protocol implementation of Cormode et al. [14], we replace the polynomial  <span class="math">f_z^{(i)}</span>  in Equation (3) with a different polynomial  <span class="math">g_z^{(i)}</span>  defined over a much smaller domain. Specifically,  <span class="math">g_z^{(i)}</span>  is defined over only  <span class="math">s_i</span>  variables rather than  <span class="math">s_i + 2s_{i+1}</span>  variables as is the case of  <span class="math">f_z^{(i)}</span> . Using  <span class="math">g_z^{(i)}</span>  in place of  <span class="math">f_z^{(i)}</span>  allows  <span class="math">\\mathcal{P}</span>  to reuse work across iterations of the sum-check protocol, thereby reducing  <span class="math">\\mathcal{P}</span> 's runtime by a logarithmic factor relative to [14], as formalized in Theorem 1 below.</p>

    <p class="text-gray-300">The remainder of the presentation leading up to Theorem 1 proceeds as follows. After stating a preliminary lemma, we describe the polynomial  <span class="math">g_z^{(i)}</span>  that we use in the context of three specific circuits: a binary tree of addition or multiplication gates, and a circuit computing the number of non-zero entries of an n-dimensional vector a. The purpose of this exposition is to showcase the ideas underling Theorem 1 in concrete scenarios. Second, we explain the algorithmic insights that allow  <span class="math">\\mathcal{P}</span>  to reuse work across iterations of the sum-check protocol applied to  <span class="math">g_z^{(i)}</span> . Finally, we state and prove Theorem 1, which formalizes the class of circuits to which our methods apply.</p>

      <h3 id="sec-5.2" class="text-xl font-semibold mt-8">5.2 A Preliminary Lemma</h3>

    <p class="text-gray-300">We will repeatedly invoke the following lemma, which allows us to express the value  <span class="math">\\tilde{V}_i(z)</span>  in a manner amenable to verification via the sum-check protocol. This is essentially a restatement of [31, Lemma 3.2.1].</p>

    <p class="text-gray-300"><strong>Lemma 4</strong> Let W be any polynomial  <span class="math">\\mathbb{F}^{s_i} \\to \\mathbb{F}</span>  that extends  <span class="math">V_i</span> , in the sense that for all  <span class="math">p \\in \\{0,1\\}^{s_i}</span> ,  <span class="math">W(p) = V_i(p)</span> . Then for any  <span class="math">z \\in \\mathbb{F}^{s_i}</span> ,</p>

    <p class="text-gray-300">
<span class="math">$\\tilde{V}_i(z) = \\sum_{p \\in \\{0,1\\}^{s_i}} \\beta_{s_i}(z, p) W(p). \\tag{6}</span>$</p>

    <p class="text-gray-300"><strong>Proof:</strong> It is easy to check that the right hand side of Equation (6) is a multilinear polynomial in z, and that it agrees with  <span class="math">V_i</span>  on all Boolean inputs. Thus, the right hand side of Equation (6), viewed as a polynomial in z, must be the multilinear extension  <span class="math">\\tilde{V}_i</span>  of  <span class="math">V_i</span> . This completes the proof.</p>

      <h3 id="sec-5.3" class="text-xl font-semibold mt-8">5.3 Polynomials for Specific Circuits</h3>

      <h4 id="sec-5.3.1" class="text-lg font-semibold mt-6">5.3.1 The Polynomial for a Binary Tree</h4>

    <p class="text-gray-300">Consider a circuit C that computes the product of all n of its inputs by multiplying them together via a binary tree. Label the gates at layers i and i+1 in the natural way, so that the first input to the gate labelled  <span class="math">p=(p_1,\\ldots,p_{s_i})\\in\\{0,1\\}^{s_i}</span>  at layer i is the gate with label (p,0) at layer i-1, and the second input to gate p has label (p,1). Here and throughout, (p,0) denotes the  <span class="math">s_i+1</span> -dimensional vector obtained by concatenating the entry 0 to the end of the vector p. Interpreting  <span class="math">p=(p_1,\\ldots,p_{s_i})\\in\\{0,1\\}^{s_i}</span>  as an integer between 0 and  <span class="math">2^{s_i}-1</span>  with  <span class="math">p_1</span>  as the high-order bit and  <span class="math">p_{s_i}</span>  as the low-order bit, this says that the first inneighbor of p is 2p and the second is 2p+1. It follows immediately that for any gate  <span class="math">p\\in\\{0,1\\}^{s_i}</span>  at layer i,  <span class="math">V_i(p)=\\tilde{V}_{i+1}(p,0)\\cdot \\tilde{V}_{i+1}(p,1)</span> . Invoking Lemma 4, we obtain the following proposition.</p>

    <p class="text-gray-300"><strong>Proposition 2</strong> Let C be a circuit consisting of a binary tree of multiplication gates. Then  <span class="math">\\tilde{V}_i(z) = \\sum_{p \\in \\{0,1\\}^{s_i}} g_z^{(i)}(p)</span> , where  <span class="math">g_z^{(i)}(p) = \\beta_{s_i}(z,p) \\cdot \\tilde{V}_{i+1}(p,0) \\cdot \\tilde{V}_{i+1}(p,1)</span> .</p>

    <p class="text-gray-300"><strong>Remark 2</strong> Notice that the polynomial  <span class="math">g_z^{(i)}</span>  in Proposition 2 is a degree three polynomial in each variable of p. When applying the sum-check protocol to  <span class="math">g_z^{(i)}</span> , the prover therefore needs to send 4 field elements per round.</p>

    <p class="text-gray-300">In the case of Proposition 2, the line  <span class="math">\\ell: \\mathbb{F} \\to \\mathbb{F}^{2_{i+1}}</span>  in the &quot;Reducing to Verification of a Single Point&quot; step has an especially simple expression. Let  <span class="math">r \\in \\mathbb{F}^{s_i}</span>  be the vector of random field elements chosen by V over the execution of the sum-check protocol. Notice that  <span class="math">\\ell(0)</span>  must equal the point  <span class="math">(r,0) \\in \\mathbb{F}^{s_i+1}</span>  i.e., the point whose first  <span class="math">s_i</span>  coordinates equal r and whose last coordinate equals 0. Similarly,  <span class="math">\\ell(1)</span>  must equal (r,1). We may therefore express the line  <span class="math">\\ell</span>  via the equation  <span class="math">\\ell(t) = (r,t)</span> . In this case,  <span class="math">\\tilde{V}_{i+1} \\circ \\ell</span>  has degree  <span class="math">\\ell</span>  and is implicitly specified when  <span class="math">\\ell</span>  sends the claimed values of  <span class="math">\\tilde{V}_i(r,0)</span>  and  <span class="math">\\tilde{V}_i(r,1)</span> .</p>

    <p class="text-gray-300">The case of a binary tree of addition gates is similar to the case of multiplication gates.</p>

    <p class="text-gray-300"><strong>Proposition 3</strong> Let C be a circuit consisting of a binary tree of addition gates. Then  <span class="math">\\tilde{V}_i(z) = \\sum_{p \\in \\{0,1\\}^{s_i}} g_z^{(i)}(p)</span> , where  <span class="math">g_z^{(i)}(p) = \\beta_{s_i}(z,p) \\left( \\tilde{V}_{i+1}(p,0) + \\tilde{V}_{i+1}(p,1) \\right)</span> .</p>

    <p class="text-gray-300"><strong>Remark 3</strong> The polynomial  <span class="math">g_z^{(i)}</span>  of Proposition 3 has degree 2 in all variables, rather than degree 3 as in Proposition 2.</p>

      <h4 id="sec-5.3.2" class="text-lg font-semibold mt-6"><strong>5.3.2</strong> The Polynomials for DISTINCT</h4>

    <p class="text-gray-300">We now describe a circuit C for computing the number of non-zero entries of a vector  <span class="math">a \\in \\mathbb{F}^n</span>  (this vector should be interpreted as the <em>frequency vector</em> of a data stream). A similar circuit was used in conjunction with the GKR protocol in [14] to yield an efficient protocol with a streaming verifier for DISTINCT, and we borrow heavily from the presentation there. We remark that our refinements enable us to slightly simplify the circuit used in [14] by avoiding the awkward use of a constant-valued input wire with value set to 1. This causes some gates in our circuit to have fan-in 1 rather than fan-in 2, which is easily supported by our protocol.</p>

    <p class="text-gray-300">The circuit C is tailored for use over the field of cardinality equal to a Mersenne prime  <span class="math">q=2^k-1</span>  for some k. Fields of cardinality equal to a Mersenne prime can support extremely fast arithmetic, and as discussed later in Section 6.2, there are several Mersenne primes of appropriate magnitude for use within our protocols.</p>

    <p class="text-gray-300">    <img src="_page_18_Picture_0.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Figure 1: The first several layers of a circuit for  <span class="math">F_0</span>  on four inputs over the field  <span class="math">\\mathbb{F}</span>  with  <span class="math">q=2^k-1</span>  elements. The first layer from the bottom computes  <span class="math">a_i^2</span>  for each input entry  <span class="math">a_i</span> . The second layer from the bottom computes  <span class="math">a_i^4</span>  and  <span class="math">a_i^2</span>  for all i. The third layer computes  <span class="math">a_i^8</span>  and  <span class="math">a_i^6=a_i^4\\times a_i^2</span> , while the fourth layer computes  <span class="math">a_i^{16}</span>  and  <span class="math">a_i^{14}=a_i^8\\times a_i^6</span> . The remaining layers (not shown) have structure identical to the third and fourth layers until the value  <span class="math">a_i^{q-1}</span>  is computed for all i, and the circuit culminates in a binary tree of addition gates.</p>

    <p class="text-gray-300">The circuit C exploits Fermat's Little Theorem, computing  <span class="math">a_i^{q-1}</span>  for each input entry  <span class="math">a_i</span>  before summing the results. As described in [14], verifying the summation sub-circuit can be handled with a one invocation of the sum-check protocol, or less efficiently by running our protocol for a binary tree of addition gates described in Proposition 3.</p>

    <p class="text-gray-300">We now turn to describing the part of the circuit computing  <span class="math">a_i^{q-1}</span>  for each input entry  <span class="math">a_i</span> . We may write  <span class="math">q-1=2^k-2</span> , whose binary representation is k-1 1s followed by a 0. Thus,  <span class="math">a_i^{q-1}=\\prod_{j=1}^{k-1}a_i^{2^j}</span> . To compute  <span class="math">a_i^{q-1}</span> , the circuit repeatedly squares a, and multiplies together the results &quot;as it goes&quot;. In more detail, for j&gt;2 there are two multiplication gates at each layer d(n)-j of the circuit for computing  <span class="math">a_i^{q-1}</span> ; the first computes  <span class="math">a_i^{q-1}</span>  by squaring the corresponding gate at layer j-1, and the second computes  <span class="math">\\prod_{\\ell=1}^{j-1}a_i^{2^{\\ell-1}}</span> . See Figure 1 for a depiction.</p>

    <p class="text-gray-300">For our purposes there are k+1 relevant circuit layers, all of which consist entirely of multiplication gates. Layers 1 through k-1 all contain 2n gates. Number the gates from 0 to 2n-1 in the natural way. In what follows, we will abuse notation and use p to refer to both a gate number as well as its binary representation.</p>

    <p class="text-gray-300">An even-numbered gate p at layer i has both in-wires connected to gate p at layer i+1, while an odd-numbered gate p has one in-wire connected to gate p and another connected to gate p-1. Thus, the connectivity information of the circuit is a simple function of the binary representation p of each gate at layer i. If the low-order bit  <span class="math">p_{s_i}</span>  of p is 0 (i.e., it is an even-numbered gate), then both in-neighbors at layer i+1 of gate p have binary representation p. If the low-order bit  <span class="math">p_{s_i}</span>  is 1 (i.e., it is an odd-numbered gate), then the first in-neighbor of gate p has binary representation p, and the second has binary representation  <span class="math">(p_{-s_i}, 0)</span> , where  <span class="math">p_{-s_i}</span>  denotes p with the coordinate  <span class="math">p_{s_i}</span>  removed.</p>

    <p class="text-gray-300">Invoking Lemma 4, the following proposition is easily verified.</p>

    <p class="text-gray-300"><strong>Proposition 4</strong> Let C be the circuit described above. For layers  <span class="math">i \\in \\{1, ..., k-1\\}</span> ,  <span class="math">\\tilde{V}_i(z) = \\sum_{p \\in \\{0,1\\}^{s_i}} g_z^{(i)}(p)</span>  where</p>

    <p class="text-gray-300"><span class="math">$g_z^{(i)}(p) = \\beta_{s_i}(z, p) \\left( (1 - p_{s_i}) \\tilde{V}_{i+1}(p_{-s_i}, 0) \\cdot \\tilde{V}_{i+1}(p_{-s_i}, 0) + p_{s_i} \\tilde{V}_{i+1}(p_{-s_i}, 1) \\cdot \\tilde{V}_{i+1}(p_{-s_i}, 0) \\right),</span>$</p>

    <p class="text-gray-300">where  <span class="math">p_{-s_i}</span>  denotes p with the coordinate  <span class="math">p_{s_i}</span>  removed.</p>

    <p class="text-gray-300"><strong>Remark 4</strong> To check  <span class="math">\\mathcal{P}</span> 's claim in the final round of the sum-check protocol applied to  <span class="math">g_z^{(i)}</span> ,  <span class="math">\\mathcal{V}</span>  needs to know  <span class="math">\\tilde{V}_{i+1}(r,0)</span>  and  <span class="math">\\tilde{V}_{i+1}(r,1)</span>  for some random vector  <span class="math">r \\in \\mathbb{F}^{s_i-1}</span> . This is identical to the situation in the case of a binary tree of addition or multiplication gates, where the &quot;Reducing to Verification of a Single Point&quot; step had an especially simple implementation.</p>

    <p class="text-gray-300">At layer k, an even-numbered gate p has both in-wires connected to gate p/2 at layer k+1, while an odd-numbered gate p has its unique in-wire connected to gate (p-1)/2 at layer k+1. Thus, for a gate at layer i=k, if the the low-order bit  <span class="math">p_{s_i}</span>  of the gate's binary representation p is 1 (i.e., it is an odd-numbered gate), then both in-neighbors at layer i+1 of have binary representation  <span class="math">p_{-s_i}</span> . If the low-order bit  <span class="math">p_{s_i}</span>  is 0 (i.e., it is an even numbered gate), then the unique in-neighbor of p at layer  <span class="math">p_{s_i}</span>  that binary representation  <span class="math">p_{-s_i}</span> .</p>

    <p class="text-gray-300">Invoking Lemma 4, the following is easily verified.</p>

    <p class="text-gray-300"><strong>Proposition 5</strong> Let C be the circuit described above. For layer i = k,  <span class="math">\\tilde{V}_i(z) = \\sum_{p \\in \\{0,1\\}^{s_i}} g_z^{(i)}(p)</span>  where</p>

    <p class="text-gray-300"><span class="math">$g_z^{(i)}(p) = \\beta_{s_i}(z, p) \\left( (1 - p_{s_i}) \\tilde{V}_{i+1}(p_{-s_i}) \\cdot \\tilde{V}_{i+1}(p_{-s_i}) + p_{s_i} \\tilde{V}_{i+1}(p_{-s_i}) \\right),</span>$</p>

    <p class="text-gray-300">where  <span class="math">p_{-s_i}</span>  denotes p with coordinate  <span class="math">p_{s_i}</span>  removed.</p>

    <p class="text-gray-300">Finally, at layer k + 1, each gate p has both in-wires connected to gate p at layer k + 2 (which is the input layer). Thus:</p>

    <p class="text-gray-300"><strong>Proposition 6</strong> Let C be the circuit described above. For layer i = k + 1,  <span class="math">\\tilde{V}_i(z) = \\sum_{p \\in \\{0,1\\}^{s_i}} g_z^{(i)}(p)</span>  where</p>

    <p class="text-gray-300"><span class="math">$g_z^{(i)}(p) = \\beta_{s_i}(z, p)\\tilde{V}_{i+1}(p) \\cdot \\tilde{V}_{i+1}(p).</span>$</p>

      <h3 id="sec-5.4" class="text-xl font-semibold mt-8">5.4 Reusing Work</h3>

    <p class="text-gray-300">Recall that our analysis of the costs of the sum-check protocol in Section 4.2.1 revealed that, when applying a sum-check protocol to an  <span class="math">s_i</span> -variate polynomial  <span class="math">g_z^{(i)}</span> ,  <span class="math">\\mathcal{P}</span>  only needs to evaluate  <span class="math">g_z^{(i)}</span>  at  <span class="math">O(2^{s_i})</span>  points across all rounds of the protocol. Our goal in this section is to show how  <span class="math">\\mathcal{P}</span>  can do this in time  <span class="math">O(2^{s_i} + 2^{s_{i+1}}) = O(S_i + S_{i+1})</span>  for all of the polynomials  <span class="math">g_z^{(i)}</span>  described in Section 5.3. This is sufficient to ensure that  <span class="math">\\mathcal{P}</span>  takes  <span class="math">O(\\sum_{i=1}^{d(n)} S_i) = O(S(n))</span>  time across all iterations of our circuit-checking protocol.</p>

    <p class="text-gray-300">To this end, notice that all of the polynomials  <span class="math">g_z</span>  described in Propositions 2-6 have the following property: for any  <span class="math">r \\in \\mathbb{F}^{s_i}</span> , evaluating  <span class="math">g_z^{(i)}(r)</span>  can be done in constant time given  <span class="math">\\beta(z,r)</span>  and the evaluations of  <span class="math">\\tilde{V}_{i+1}</span>  at a constant number of points. For example, consider the polynomial  <span class="math">g_z^{(i)}</span>  described in Proposition 4:  <span class="math">g_z^{(i)}(r)</span>  can be computed in constant time given  <span class="math">\\beta_{s_i}(z,r)</span> ,  <span class="math">\\tilde{V}_{i+1}(r_{-s_i},0)</span> , and  <span class="math">\\tilde{V}_{i+1}(r_{-s_i},1)</span> .</p>

    <p class="text-gray-300">Moreover, the points at which  <span class="math">\\mathcal{P}</span>  must evaluate  <span class="math">g_z^{(i)}</span>  within the sum-check protocol are highly structured: in round j of the sum-check protocol, the points are all of the form  <span class="math">(r_1, \\ldots, r_{j-1}, t, b_{j+1}, \\ldots, b_{s_i})</span>  with  <span class="math">t \\in \\{0, 1, \\ldots, \\deg_j(g_z^{(i)})\\}</span>  and  <span class="math">(b_{j+1}, \\ldots, b_{s_i}) \\in \\{0, 1\\}^{s_i - j}</span> .</p>

      <h4 id="sec-5.4.1" class="text-lg font-semibold mt-6"><strong>5.4.1</strong> Computing the Necessary <span class="math">\\beta(z, p)</span> Values</h4>

    <p class="text-gray-300"><em>Pre-processing</em>. We begin by explaining how  <span class="math">\\mathcal{P}</span>  can, in  <span class="math">O(2^{s_i})</span>  time, compute an array  <span class="math">C^{(0)}</span>  of length  <span class="math">2^{s_i}</span>  of all values  <span class="math">\\beta(z,p) = \\prod_{k=1}^{s_i} (p_k z_k + (1-p_k)(1-z_k))</span>  for  <span class="math">p \\in \\{0,1\\}^{s_i}</span> .  <span class="math">\\mathcal{P}</span>  can do this computation in preprocessing before the sum-check protocol begins, as this computation does not depend on any of  <span class="math">\\mathcal{V}</span> 's messages. Naively,</p>

    <p class="text-gray-300">computing all entries of  <span class="math">C^{(0)}</span>  would require  <span class="math">O(s_i 2^{s_i})</span>  time, as there are  <span class="math">2^{s_i}</span>  values to compute, and each involves  <span class="math">\\Omega(s_i)</span>  multiplications. However, this can be improved using dynamic programming.</p>

    <p class="text-gray-300">The dynamic programming algorithm proceeds in stages. In stage j,  <span class="math">\\mathcal{P}</span>  computes an array  <span class="math">C^{(0,j)}</span>  of length  <span class="math">2^j</span> . Abusing notation, we identify a number p in  <span class="math">[2^j]</span>  with its binary representation in  <span class="math">\\{0,1\\}^j</span> .  <span class="math">\\mathcal{P}</span>  computes</p>

    <p class="text-gray-300"><span class="math">$C^{0,j}[p] = \\prod_{k=1}^{j} (p_k z_k + (1 - p_k)(1 - z_k))</span>$</p>

    <p class="text-gray-300">via the recurrence</p>

    <p class="text-gray-300"><span class="math">$C^{0,j}[(p_1,\\ldots,p_j)] = C^{0,j-1}[(p_1,\\ldots,p_{j-1})] \\cdot (p_j z_j + (1-p_j)(1-z_j)).</span>$</p>

    <p class="text-gray-300">Clearly  <span class="math">C^{(0,s_i)}</span>  equals the desired array  <span class="math">C^{(0)}</span> , and the total number of multiplications required over the entire procedure is  <span class="math">O(\\sum_{j=1}^{s_i} 2^j) = O(2^{s_i})</span> . We remark that our dynamic programming procedure is similar to the method used by Vu et al. to reduce the verifier's runtime in the GKR protocol from  <span class="math">O(n \\log n)</span>  to O(n) in Lemma 3.</p>

    <p class="text-gray-300">Overview of Online Processing. In round j of of the sum-check protocol,  <span class="math">\\mathcal{P}</span>  needs to evaluate the polynomial  <span class="math">\\beta(z,p)</span>  at  <span class="math">O(2^{s_i-j})</span>  points of the form  <span class="math">(r_1,\\ldots,r_{j-1},t,b_{j+1},\\ldots,b_{s_i})</span>  for  <span class="math">t\\in[\\deg_j(g_z^{(i)})]</span>  and  <span class="math">(b_{j+1},\\ldots,b_{s_i})\\in\\{0,1\\}^{s_i-j}</span> .  <span class="math">\\mathcal{P}</span>  will do this using the help of intermediate arrays  <span class="math">C^{(j)}</span>  defined as follows.</p>

    <p class="text-gray-300">Define  <span class="math">C^{(j)}</span>  to be the array of length  <span class="math">2^{s_i-j}</span>  such that for  <span class="math">(p_{j+1},\\ldots,p_{s_i})\\in\\{0,1\\}^{s_i-j}</span> :</p>

    <p class="text-gray-300"><span class="math">$C^{(j)}[(p_{j+1},\\ldots,p_{s_i})] = \\left(\\prod_{k=1}^{j}(r_kz_k + (1-r_k)(1-z_k))\\right) \\cdot \\left(\\prod_{k=j+1}^{s_i}(p_kz_k + (1-p_k)(1-z_k))\\right),</span>$</p>

    <p class="text-gray-300">Efficiently Constructing  <span class="math">C^{(j)}</span>  Arrays. Inductively, assume  <span class="math">\\mathcal{P}</span>  has computed the array  <span class="math">C^{(j-1)}</span>  in the previous round. As the base case, we explained how  <span class="math">\\mathcal{P}</span>  can evaluate  <span class="math">C^{(0)}</span>  in  <span class="math">O(2^{s_i})</span>  time in pre-processing. Now observe that  <span class="math">\\mathcal{P}</span>  can compute  <span class="math">C^{(j)}</span>  given  <span class="math">C^{(j-1)}</span>  in  <span class="math">O(2^{s_i-j})</span>  time using the following recurrence:</p>

    <p class="text-gray-300">
<span class="math">$C^{(j)}[(p_{j+1},\\ldots,p_{s_i})] = z_j^{-1}C^{(j-1)}[(1,p_{j+1},\\ldots,p_{s_i})] \\cdot (r_jz_j + (1-r_j)(1-z_j)).</span>$</p>

    <p class="text-gray-300"><span class="math">$(7)</span>$</p>

    <p class="text-gray-300"><strong>Remark 5</strong> Equation (7) is only valid when  <span class="math">z_j \\neq 0</span> . To avoid this issue, we can have V choose  <span class="math">z_j</span>  at random from  <span class="math">\\mathbb{F}^*</span>  rather than from  <span class="math">\\mathbb{F}</span> , and this will affect the soundness probability by at most an additive  <span class="math">O(d(n) \\cdot \\log S(n)/|\\mathbb{F}|)</span>  term.</p>

    <p class="text-gray-300"><strong>Remark 6</strong> Since computing multiplicative inverses in a finite field is not a constant-time operation, it is important to note that  <span class="math">z_j^{-1}</span>  only needs to be computed once when determining the entries of  <span class="math">C^{(j)}</span> , i.e., it need not be recomputed for each entry of  <span class="math">C^{(j)}</span> . Therefore, across all  <span class="math">s_i</span>  rounds of the sum-check protocol, only  <span class="math">\\tilde{O}(s_i)</span>  time in total is required to compute these multiplicative inverses, which does not affect the asymptotic costs for P. We discount the costs of computing  <span class="math">z_j^{-1}</span>  for the remainder of the discussion.</p>

    <p class="text-gray-300">Thus, at the end of round j of the sum-check protocol, when  <span class="math">\\mathcal{V}</span>  sends  <span class="math">\\mathcal{P}</span>  the value  <span class="math">r_j</span> ,  <span class="math">\\mathcal{P}</span>  can compute  <span class="math">C^{(j)}</span>  from  <span class="math">C^{(j-1)}</span>  using Equation (7) in  <span class="math">O(2^{s_i-j})</span>  time.</p>

    <p class="text-gray-300">Using the  <span class="math">C^{(j)}</span>  Arrays. Observe that given any point of the form  <span class="math">p = (r_1, \\dots, r_{j-1}, t, b_{j+1}, \\dots, b_{s_i})</span>  with  <span class="math">(b_{j+1}, \\dots, b_{s_i}) \\in \\{0, 1\\}^{s_i - j}</span> ,  <span class="math">\\beta(z, p)</span>  can be evaluated in constant time using the array  <span class="math">C^{(j-1)}</span> , using the equality</p>

    <p class="text-gray-300"><span class="math">$\\beta(z,p) = C^{(j-1)}[(1,p_{j+1},\\ldots,p_{s_i})] \\cdot z_i^{-1} \\cdot (tz_j + (1-t)(1-z_j)).</span>$</p>

    <p class="text-gray-300">As above, note that  <span class="math">z_j^{-1}</span>  can be computed just once and used for all points p, and this does not affect the asymptotic costs for  <span class="math">\\mathcal{P}</span> .</p>

    <p class="text-gray-300">Putting Things Together. In round j of the sum-check protocol,  <span class="math">\\mathcal P</span>  uses the array  <span class="math">C^{(j-1)}</span>  to evaluate the  <span class="math">O(2^{s_i-j})</span>  required  <span class="math">\\beta(z,p)</span>  values in  <span class="math">O(2^{s_i-j})</span>  time. At the end of round j,  <span class="math">\\mathcal V</span>  sends  <span class="math">\\mathcal P</span>  the value  <span class="math">r_j</span> , and  <span class="math">\\mathcal P</span>  computes  <span class="math">C^{(j)}</span>  from  <span class="math">C^{(j-1)}</span>  in  <span class="math">O(2^{s_i-j})</span>  time. In total across all rounds of the sum-check protocol,  <span class="math">\\mathcal P</span>  spends  <span class="math">O(\\sum_{j=1}^{s_i} 2^{s_i-j}) = O(2^{s_i})</span>  time to compute the  <span class="math">\\beta(z,p)</span>  values.</p>

      <h4 id="sec-5.4.2" class="text-lg font-semibold mt-6"><strong>5.4.2</strong> Computing the Necessary <span class="math">\\tilde{V}_{i+1}(p)</span> Values</h4>

    <p class="text-gray-300">For concreteness and clarity, we restrict our presentation within this subsection to the polynomial  <span class="math">g_z^{(i)}</span>  described in Proposition 4. Theorem 1 abstracts this analysis into a general result capturing a large class of wiring patterns.</p>

    <p class="text-gray-300">Recall that all of the polynomials  <span class="math">g_z^{(i)}</span>  described in Propositions 2-6 have the following property: for any  <span class="math">p \\in \\mathbb{F}^{s_i}</span> , evaluating  <span class="math">g_z^{(i)}(p)</span>  can be done in constant time given  <span class="math">\\beta(z,p)</span>  and the evaluations of  <span class="math">\\tilde{V}_{i+1}</span>  at a constant number of points. We have already shown how  <span class="math">\\mathcal{P}</span>  can evaluate all of the necessary  <span class="math">\\beta(z,p)</span>  values in  <span class="math">O(2^{s_i})</span>  time. It remains to show how  <span class="math">\\mathcal{P}</span>  can evaluate all of the  <span class="math">\\tilde{V}_{i+1}</span>  values in time  <span class="math">O(2^{s_i} + 2^{s_{i+1}})</span> . We remark that in the context of Proposition 4,  <span class="math">s_i = s_{i+1}</span> ; however, we still distinguish between these two quantities throughout this subsection in order to ensure maximal consistency with the general derivation of Theorem 1.</p>

    <p class="text-gray-300">Recall that the polynomial  <span class="math">g_z^{(i)}</span>  in Proposition 4 was defined as follows:</p>

    <p class="text-gray-300"><span class="math">$g_z^{(i)}(p) = \\beta_{s_i}(z, p) \\left( (1 - p_{s_i}) \\tilde{V}_{i+1}(p_{-s_i}, 0) \\cdot \\tilde{V}_{i+1}(p_{-s_i}, 0) + p_{s_i} \\tilde{V}(p_{-s_i}, 1) \\cdot \\tilde{V}(p_{-s_i}, 0) \\right).</span>$</p>

    <p class="text-gray-300">In round j of the sum-check protocol,  <span class="math">\\mathcal{P}</span>  needs to evaluate  <span class="math">g_z</span>  at all points in the set</p>

    <p class="text-gray-300"><span class="math">$S^{(j)} = \\{(r_1, \\dots, r_{j-1}, t, b_{j+1}, \\dots, b_{s_i}) : t \\in \\{0, \\dots, \\deg_j(g_z^{(i)})\\} \\text{ and } (b_{j+1}, \\dots, b_{s_i}) \\in \\{0, 1\\}^{s_i - j}\\}.</span>$</p>

    <p class="text-gray-300">By inspection of  <span class="math">g_z^{(i)}</span> , it suffices for  <span class="math">\\mathcal{V}</span>  to evaluate  <span class="math">\\tilde{V}_{i+1}</span>  at the same set of points. To show how to accomplish this efficiently, we exploit the following explicit expression for  <span class="math">\\tilde{V}_{i+1}</span> . This expression was derived for the case i+1=d in Equation (4) within Lemma 2; we re-derive it here in the general case.</p>

    <p class="text-gray-300">For a vector  <span class="math">b \\in \\{0,1\\}^{s_{i+1}}</span>  let  <span class="math">\\chi_b(x_1,\\ldots,x_{s_{i+1}}) = \\prod_{k=1}^{s_{i+1}} \\chi_{b_k}(x_k)</span> , where  <span class="math">\\chi_0(x_k) = 1 - x_k</span>  and  <span class="math">\\chi_1(x_k) = x_k</span> . With this definition in hand, we may write:</p>

    <p class="text-gray-300"><span class="math">$\\tilde{V}_{i+1}(p_1,\\ldots,p_{s_{i+1}}) = \\sum_{b \\in \\{0,1\\}^{s_{i+1}}} V_{i+1}(b) \\chi_b(p_1,\\ldots p_{s_{i+1}}), \\tag{8}</span>$</p>

    <p class="text-gray-300">To see that Equation (8) holds, notice that the right hand side of Equation (8) is a multilinear polynomial in the variables  <span class="math">(p_1, \\ldots, b_{p_{i+1}})</span> , and that it agrees with  <span class="math">V_{i+1}</span>  at all points  <span class="math">p \\in \\{0, 1\\}^{s_{i+1}}</span> . Hence, it must be the unique multilinear extension of  <span class="math">V_{i+1}</span> .</p>

    <p class="text-gray-300">The intuition behind our optimizations is the following. In round j of the sum-check protocol, there are  <span class="math">|S^{(j)}|</span>  points at which  <span class="math">\\tilde{V}_{i+1}</span>  must be evaluated. Equation (8) can be exploited to show that each gate at layer i+1 of the circuit contributes to  <span class="math">\\tilde{V}_{i+1}(p)</span>  for at most one point  <span class="math">p \\in S^{(j)}</span> ; namely the point p whose last</p>

    <p class="text-gray-300"><span class="math">s_{i+1} - j</span>  coordinates agrees with those of p. This observation alone is enough to achieve an  <span class="math">O(S_{i+1} \\log S_i)</span>  runtime for  <span class="math">\\mathcal{P}</span>  in total across all iterations of the sum-check protocol, because there are  <span class="math">S_{i+1}</span>  gates at layer i+1, and only  <span class="math">s_i = \\log S_i</span>  rounds of the sum-check protocol. However, we need to go further in order to shave off the last  <span class="math">\\log S_i</span>  factor from  <span class="math">\\mathcal{P}</span> 's runtime. Essentially, what we do is group the gates at layer i+1 by the point  <span class="math">p \\in S^{(j)}</span>  to which they contribute. Each such group can be treated as a single unit, ensuring that the work  <span class="math">\\mathcal{P}</span>  has to do in any round of the sum-check protocol in order to evaluate  <span class="math">\\tilde{V}_{i+1}</span>  at all points in  <span class="math">S^{(j)}</span>  is proportional to  <span class="math">|S^{(j)}|</span>  rather than to  <span class="math">S_{i+1}</span> . Since the size of  <span class="math">S^{(j)}</span>  falls geometrically with j, our desired time bounds follow.</p>

    <p class="text-gray-300"><em>Pre-processing.</em>  <span class="math">\\mathcal{P}</span>  will begin by computing an array  <span class="math">V^{(0)}</span> , which is simply defined to be the vector of gate values at layer i+1, i.e., identifying a number  <span class="math">0 &lt; j &lt; S_{i+1}</span>  with its binary representation in  <span class="math">\\{0,1\\}^{s_{i+1}}</span> ,  <span class="math">\\mathcal{P}</span>  sets  <span class="math">V^{(0)}[(j_1,\\ldots,j_{s_{i+1}})] = V_{i+1}(j_1,\\ldots,j_{s_{i+1}})</span>  for each  <span class="math">(j_1,\\ldots,j_{s_{i+1}}) \\in \\{0,1\\}^{s_{i+1}}</span> . The right hand side of this equation is simply the value of the jth gate at layer i+1 of C. So  <span class="math">\\mathcal{P}</span>  can fill in the array  <span class="math">V^{(0)}</span>  when she evaluates the circuit C, before receiving any messages from  <span class="math">\\mathcal{V}</span> .</p>

    <p class="text-gray-300">Overview of Online Processing. In round j of of the sum-check protocol,  <span class="math">\\mathcal{P}</span>  needs to evaluate the polynomial  <span class="math">\\tilde{V}_{i+1}</span>  at the  <span class="math">O(2^{s_i-j})</span>  points in the set  <span class="math">S^{(j)}</span> .  <span class="math">\\mathcal{P}</span>  will do this using the help of intermediate arrays  <span class="math">V^{(j)}</span>  defined as follows.</p>

    <p class="text-gray-300">Define  <span class="math">V^{(j)}</span>  to be the length  <span class="math">2^{s_{i+1}-j}</span>  array such that for  <span class="math">(p_{j+1},...,p_{s_{i+1}}) \\in \\{0,1\\}^{s_{i+1}-j}</span> ,</p>

    <p class="text-gray-300"><span class="math">$V^{(j)}[(p_{j+1},\\ldots,p_{s_{i+1}})] = \\sum_{(b_1,\\ldots,b_j)\\in\\{0,1\\}^j} V_{i+1}(b_1,\\ldots,b_j,p_{j+1},\\ldots,p_{s_{i+1}}) \\cdot \\prod_{k=1}^j \\chi_{b_k}(r_k),</span>$</p>

    <p class="text-gray-300"><em>Efficiently Constructing</em>  <span class="math">V^{(j)}</span>  <em>Arrays.</em> Inductively, assume  <span class="math">\\mathcal{P}</span>  has computed in the previous round the array  <span class="math">V^{(j-1)}</span>  of length  <span class="math">2^{s_{i+1}-j+1}</span> .</p>

    <p class="text-gray-300">As the base case, we explained how  <span class="math">\\mathcal{P}</span>  can fill in  <span class="math">V^{(0)}</span>  in the process of evaluating the circuit C. Now observe that  <span class="math">\\mathcal{P}</span>  can compute  <span class="math">V^{(j)}</span>  given  <span class="math">V^{(j-1)}</span>  in  <span class="math">O(2^{s_{i+1}-j})</span>  time using the following recurrence:</p>

    <p class="text-gray-300"><span class="math">$V^{(j)}[(p_{j+1},\\ldots,p_{s_{i+1}})] = V^{(j-1)}[(0,p_{j+1},\\ldots,p_{s_i})] \\cdot \\chi_0(r_j) + V^{(j-1)}[(1,p_{j+1},\\ldots,p_{s_i})] \\cdot \\chi_1(r_j).</span>$</p>

    <p class="text-gray-300">Thus, at the end of round j of the sum-check protocol, when  <span class="math">\\mathcal{V}</span>  sends  <span class="math">\\mathcal{P}</span>  the value  <span class="math">r_j</span> ,  <span class="math">\\mathcal{P}</span>  can compute  <span class="math">V^{(j)}</span>  from  <span class="math">V^{(j-1)}</span>  in  <span class="math">O(2^{s_{i+1}-j+1})</span>  time.</p>

    <p class="text-gray-300">Using the  <span class="math">V^{(j)}</span>  Arrays. We now show how to use the array  <span class="math">V^{(j-1)}</span>  to evaluate  <span class="math">\\tilde{V}_{i+1}(p)</span>  in constant time for any point of the form  <span class="math">p = (r_1, \\dots, r_{j-1}, t, b_{j+1}, \\dots, b_{s_{i+1}})</span>  with  <span class="math">(b_{j+1}, \\dots, b_{s_{i+1}}) \\in \\{0, 1\\}^{s_{i+1}-j}</span> . We exploit the following sequence of equalities:</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\tilde{V}_{i+1}(r_1,\\ldots,r_{j-1},t,b_{j+1},\\ldots,b_{s_i}) &amp;= \\sum_{c \\in \\{0,1\\}^{s_{i+1}}} V_{i+1}(c) \\chi_c(r_1,\\ldots,r_{j-1},t,b_{j+1},\\ldots,b_{s_{i+1}}) \\\\ &amp;= \\sum_{(c_1,\\ldots,c_j) \\in \\{0,1\\}^j} \\sum_{(c_{j+1},\\ldots,c_{s_{i+1}}) \\in \\{0,1\\}^{s_{i+1}-j}} V_{i+1}(c) \\chi_c(r_1,\\ldots,r_{j-1},t,b_{j+1},\\ldots,b_{s_{i+1}}) \\\\ &amp;= \\sum_{(c_1,\\ldots,c_j) \\in \\{0,1\\}^j} \\sum_{(c_{j+1},\\ldots,c_{s_{i+1}}) \\in \\{0,1\\}^{s_{i+1}-j}} V_{i+1}(c) \\left(\\prod_{k=1}^{j-1} \\chi_{c_k}(r_k)\\right) \\left(\\chi_{c_j}(t)\\right) \\left(\\prod_{k=j+1}^{s_{i+1}} \\chi_{c_k}(b_k)\\right) \\\\ &amp;= \\sum_{(c_1,\\ldots,c_j) \\in \\{0,1\\}^j} V_{i+1}(c_{j+1},\\ldots,c_j,b_{j+1},\\ldots,b_{s_{i+1}}) \\left(\\prod_{k=1}^{j-1} \\chi_{c_k}(r_k)\\right) \\cdot \\chi_{c_j}(t) \\\\ &amp;= V^{(j-1)}[(0,b_{j+1},\\ldots,b_{s_{i+1}})] \\cdot \\chi_0(t) + V^{(j-1)}[(1,b_{j+1},\\ldots,b_{s_{i+1}})] \\cdot \\chi_1(t). \\end{split}</span>$</p>

    <p class="text-gray-300">Here, the first equality holds by Equation (8). The third holds by definition of the function  <span class="math">\\chi_c</span> . The fourth holds because for Boolean values  <span class="math">b_k, c_k \\in \\{0,1\\}</span> ,  <span class="math">\\chi_{c_k}(b_k) = 1</span>  if  <span class="math">c_k = b_k</span> , and  <span class="math">\\chi_{c_k}(b_k) = 0</span>  otherwise. The final equality holds by definition of the array  <span class="math">V^{(j-1)}</span> .</p>

    <p class="text-gray-300">Putting Things Together. In round j of the sum-check protocol,  <span class="math">\\mathcal{P}</span>  uses the array  <span class="math">V^{(j-1)}</span>  to evaluate  <span class="math">\\tilde{V}_{i+1}(p)</span>  for all  <span class="math">O(2^{s_i-j})</span>  points  <span class="math">p \\in S^{(j)}</span> . This requires constant time per point, and hence  <span class="math">O(2^{s_i-j})</span>  time across all points. At the end of round j,  <span class="math">\\mathcal{V}</span>  sends  <span class="math">\\mathcal{P}</span>  the value  <span class="math">r_j</span> , and  <span class="math">\\mathcal{P}</span>  computes  <span class="math">V^{(j)}</span>  from  <span class="math">V^{(j-1)}</span>  in  <span class="math">O(2^{s_{i+1}-j})</span>  time. In total across all rounds of the sum-check protocol,  <span class="math">\\mathcal{P}</span>  spends  <span class="math">O(\\sum_{j=1}^{s_i} 2^{s_i-j} + 2^{s_{i+1}-j}) = O(2^{s_i} + 2^{s_{i+1}})</span>  time to evaluate  <span class="math">\\tilde{V}_{i+1}</span>  at the relevant points. When combined with our  <span class="math">O(2^{s_i})</span> -time algorithm for computing all the relevant  <span class="math">\\beta(z,p)</span>  values, we see  <span class="math">\\mathcal{P}</span>  takes  <span class="math">O(2^{s_i} + 2^{s_{i+1}}) = O(S_i + S_{i+1})</span>  time to run the entire sum-check protocol for iteration i of our circuit-checking protocol.</p>

      <h3 id="sec-5.5" class="text-xl font-semibold mt-8">5.5 A General Theorem</h3>

    <p class="text-gray-300">In this section we formalize a large class of circuits to which our refinements yield asymptotic savings relative to prior implementations of the GKR protocol. Our protocol makes use of the following functions that capture the wiring structure of an arithmetic circuit C.</p>

    <p class="text-gray-300"><strong>Definition 2</strong> Let C be a layered arithmetic circuit of depth d(n) and size S(n) over finite field  <span class="math">\\mathbb{F}</span> . For every  <span class="math">i \\in \\{1, \\ldots, d-1\\}</span> , let  <span class="math">in_1^{(i)}: \\{0,1\\}^{s_i} \\to \\{0,1\\}^{s_{i+1}}</span>  and  <span class="math">in_2^{(i)}: \\{0,1\\}^{s_i} \\to \\{0,1\\}^{s_{i+1}}</span>  denote the functions that take as input the binary label p of a gate at layer i of C, and output the binary label of the first and second in-neighbor of gate p respectively. Similarly, let  <span class="math">type^{(i)}: \\{0,1\\}^{s_i} \\to \\{0,1\\}</span>  denote the function that takes as input the binary label p of a gate at layer i of C, and outputs 0 if p is an addition gate, and 1 if p is a multiplication gate.</p>

    <p class="text-gray-300">Intuitively, the following definition captures functions whose outputs are simple bit-wise transformations of their inputs.</p>

    <p class="text-gray-300"><strong>Definition 3</strong> Let f be a function mapping  <span class="math">\\{0,1\\}^v</span>  to  <span class="math">\\{0,1\\}^{v&#x27;}</span> . Number the v input bits from 1 to v, and the v' output bits from 1 to v'. Assume that one machine word contains  <span class="math">\\Omega(v+v&#x27;)</span>  bits. We say that f is regular if f can be evaluated on any input in constant time, and there is a subset of input bits  <span class="math">S \\subseteq [v]</span>  with |S| = O(1) such that:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Each input bit in  <span class="math">[v] \\setminus S</span>  affects O(1) of the output bits of f. Moreover, given input  <span class="math">j \\in [v] \\setminus S</span> , the set  <span class="math">S_j</span>  of output bits affected by  <span class="math">x_j</span>  can be enumerated in constant time.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Each output bit of f depends on at most one input bit.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Our protocol applied to C proceeds in d(n) iterations, where iteration i consists an application of the sum-check protocol to an appropriate polynomial derived from  <span class="math">\\operatorname{type}^{(i)}</span> ,  <span class="math">\\operatorname{in}_1^{(i)}</span> , and  <span class="math">\\operatorname{in}_2^{(i)}</span> , followed by a phase for &quot;reducing to verification of a single point&quot;. For any layer i of C such that  <span class="math">\\operatorname{in}_1^{(i)}</span> ,  <span class="math">\\operatorname{in}_2^{(i)}</span>  and  <span class="math">\\operatorname{type}^{(i)}</span>  are all regular, we can show that  <span class="math">\\mathcal P</span>  can execute the sum-check protocol at iteration i in  <span class="math">O(S_i + S_{i+1})</span>  time. To ensure that  <span class="math">\\mathcal P</span>  can execute the &quot;reducing to verification of a single point&quot; phase in  <span class="math">O(S_{i+1})</span>  time, we need to place one additional condition on  <span class="math">\\operatorname{in}_1^{(i)}</span>  and  <span class="math">\\operatorname{in}_2^{(i)}</span> .</p>

    <p class="text-gray-300"><strong>Definition 4</strong> We say that  <span class="math">in_1^{(i)}</span>  and  <span class="math">in_2^{(i)}</span>  are similar if there is a set of output bits  <span class="math">\\mathcal{T} \\subseteq [s_{i+1}]</span>  with  <span class="math">|\\mathcal{T}| = O(1)</span>  such that for all inputs x, the jth output bit of  <span class="math">in_1^{(i)}</span>  equals the jth output bit of  <span class="math">in_2^{(i)}</span>  for all  <span class="math">j \\in [s_{i+1}] \\setminus \\mathcal{T}</span> .</p>

    <p class="text-gray-300">We are finally in a position to state the class of circuits to which our refinements apply.</p>

    <p class="text-gray-300"><strong>Theorem 1</strong> Let C be an arithmetic circuit, and suppose that for all layers i of C,  <span class="math">in_1^{(i)}</span> ,  <span class="math">in_2^{(i)}</span> , and  <span class="math">type^{(i)}</span>  are regular. Suppose moreover that  <span class="math">in_1^{(i)}</span>  is similar to  <span class="math">in_2^{(i)}</span>  for all but O(1) layers i of C. Then there is a valid interactive proof protocol  <span class="math">(\\mathcal{P}, \\mathcal{V})</span>  for the function computed by C, with the following costs. The total communication cost is  <span class="math">|\\mathcal{O}| + O(d(n)\\log S(n))</span>  field elements, where  <span class="math">|\\mathcal{O}|</span>  is the number of outputs of C. The time cost to  <span class="math">\\mathcal{V}</span>  is  <span class="math">O(n\\log n + d(n)\\log S(n))</span> , and  <span class="math">\\mathcal{V}</span>  can make a single streaming pass over the input, storing  <span class="math">O(\\log(S(n)))</span>  field elements. The time cost to  <span class="math">\\mathcal{P}</span>  is O(S(n)).</p>

    <p class="text-gray-300">The asymptotic costs of the protocol whose existence is guaranteed by Theorem 1 are identical to those of the implementation of the GKR protocol due to Cormode et al. in [14], except that in Theorem 1  <span class="math">\\mathcal{P}</span>  runs in time O(S(n)) rather than  <span class="math">O(S(n)\\log S(n))</span>  as achieved by [14]. We defer the proof to Appendix A.</p>

      <h4 id="sec-5.5.1" class="text-lg font-semibold mt-6">5.5.1 Applications</h4>

    <p class="text-gray-300">Theorem 1 applies to circuits computing functions from a wide range of applications, with the following implications.</p>

    <p class="text-gray-300"><strong>MATMULT.</strong> Consider the following circuit C of size  <span class="math">O(n^3)</span>  for multiplying two  <span class="math">n \\times n</span>  matrices A and B. Let the input gate labelled (0, i, j) correspond to  <span class="math">A_{ij}</span> , and the input labelled (1, i, j) correspond to  <span class="math">B_{ij}</span> . The layer of C adjacent to the input consists of  <span class="math">n^3</span>  gates, where the gate labeled  <span class="math">(i, j, k) \\in (\\{0, 1\\}^{\\log n})^3</span>  computes  <span class="math">A_{ik} \\cdot B_{kj}</span> . All subsequent layers constitute a binary tree of addition gates summing up the results and thereby computing  <span class="math">\\sum_k A_{ik} B_{kj}</span>  for all  <span class="math">(i, j) \\in [n] \\times [n]</span> .</p>

    <p class="text-gray-300">For layers  <span class="math">i \\in \\{1, ..., \\log n\\}</span>  of this circuit,  <span class="math">\\operatorname{in}_1^{(i)}</span> ,  <span class="math">\\operatorname{in}_2^{(i)}</span> , and  <span class="math">\\operatorname{type}^{(i)}</span>  are all regular, and moreover  <span class="math">\\operatorname{in}_1^{(i)}</span>  is similar to  <span class="math">\\operatorname{in}_2^{(i)}</span>  (see Section 5.3.1 for a careful treatment of this wiring pattern). The remaining layer of the circuit, layer  <span class="math">i = \\log n + 1</span> , is regular, though  <span class="math">\\operatorname{in}_1^{(\\log n + 1)}</span>  and  <span class="math">\\operatorname{in}_2^{(\\log n + 1)}</span>  are not similar. We obtain the following immediate corollary.</p>

    <p class="text-gray-300"><strong>Corollary 1</strong> There is a valid interactive proof protocol for  <span class="math">n \\times n</span>  MATMULT with the following costs. The total communication cost is  <span class="math">n^2 + O(d(n)\\log n)</span>  field elements, where the  <span class="math">n^2</span>  term is required to specify the answer. The time cost to V is  <span class="math">O(n^2\\log n)</span> , and V can make a single streaming pass over the input in time  <span class="math">O(n^2\\log n)</span>  and storing  <span class="math">O(\\log n)</span>  field elements. The time cost to P is  <span class="math">O(n^3)</span> .</p>

    <p class="text-gray-300">We note that the costs of Corollary 1 are subsumed by our special-purpose matrix multiplication protocol presented later in Theorem 3. We included Corollary 1 to demonstrate the applicability of Theorem 1.</p>

    <p class="text-gray-300"><strong>DISTINCT.</strong> Recall the circuit C over field size  <span class="math">q=2^k-1</span>  described in Section 5.3.2 that takes a vector  <span class="math">a \\in \\mathbb{F}^n</span>  as input and outputs the number of non-zero entries of a. This circuit has k+1 relevant layers and consists entirely of multiplication gates. For any layer  <span class="math">i \\in [k-1]</span> , an even-numbered gate p at layer i has both inwires connected to gate p at layer i+1, while an odd-numbered gate p at layer i has one in-wire connected to gate p at layer i+1 and another connected to gate p-1 (which has binary representation  <span class="math">(p_{-s_i},0)</span> , where  <span class="math">p_{-s_i}</span>  denotes the binary representation of p with the coordinate  <span class="math">p_{s_i}</span>  removed). For these layers,  <span class="math">\\operatorname{in}_1^{(i)}</span> ,  <span class="math">\\operatorname{in}_2^{(i)}</span> , and  <span class="math">\\operatorname{type}_{i}^{(i)}</span>  are all regular, and  <span class="math">\\operatorname{in}_1^{(i)}</span>  is similar to  <span class="math">\\operatorname{in}_2^{(i)}</span> .</p>

    <p class="text-gray-300">At layer k, an even-numbered gate p is has both in-wires connected to gate p/2 at layer k+1, while an odd-numbered gate p at layer k has its unique in-wire connected to gate (p-1)/2 at layer k+1. In the former case, both in-neighbors of gate p have binary representation  <span class="math">p_{-s_i}</span> . In the latter case the unique in-neighbor of gate p has binary representation  <span class="math">p_{-s_i}</span> . It is therefore easily seen that  <span class="math">\\operatorname{in}_1^{(k)}</span> ,  <span class="math">\\operatorname{in}_2^{(k)}</span> , and  <span class="math">\\operatorname{type}^{(k)}</span>  are all regular, and  <span class="math">\\operatorname{in}_1^{(k)}</span>  is similar to  <span class="math">\\operatorname{in}_2^{(k)}</span> . Finally, at layer k+1, both in-wires for gate p are connected to gate p at layer k+2. It is easily seen that  <span class="math">\\operatorname{in}_1^{(k+1)}</span> ,  <span class="math">\\operatorname{in}_2^{(k+1)}</span> , and  <span class="math">\\operatorname{type}^{(k+1)}</span>  are all regular, and  <span class="math">\\operatorname{in}_1^{(k+1)}</span>  is similar to  <span class="math">\\operatorname{in}_2^{(k+1)}</span> . With all layers of C satisfying the requirements of Theorem 1, we obtain the following corollary.</p>

    <p class="text-gray-300"><strong>Corollary 2</strong> Let  <span class="math">q &gt; \\max\\{m,n\\}</span>  be a Mersenne Prime. There is a valid interactive proof protocol over the field  <span class="math">\\mathbb{F}_q</span>  for DISTINCT with the following costs. The total communication cost is  <span class="math">O(\\log n \\log q)</span>  field elements. The time cost to  <span class="math">\\mathcal{V}</span>  is  <span class="math">O(m \\log n)</span> , and  <span class="math">\\mathcal{V}</span>  can make a single streaming pass over the input, storing  <span class="math">O(\\log n)</span>  field elements. The time cost to  <span class="math">\\mathcal{P}</span>  is  <span class="math">O(n \\log q)</span> .</p>

    <p class="text-gray-300">To or knowledge, Corollary 2 yields the fastest known prover of any streaming interactive proof protocol for DISTINCT that also has total communication and space usage for  <span class="math">\\mathcal V</span>  that is sublinear in both m and n. The fastest result previously was the  <span class="math">O(n \\cdot \\log(n) \\cdot \\log(p))</span> -time prover obtained by the implementation of Cormode et al. [14]. We remark however that for a data stream with  <span class="math">F_0</span>  distinct items, the prover in [14] actually can be made to run in time  <span class="math">O(n + F_0 \\cdot \\log(n) \\cdot \\log(p))</span> , where the O(n) term is due to the time required to simply observe the entire input stream. Therefore, for streams where  <span class="math">F_0 = o(n/\\log n)</span> , the implementation of [14] achieves an asymptotically faster prover than implied by Corollary 2.</p>

    <p class="text-gray-300"><strong>Remark 7</strong> Cormode et al. in [14, Section 3.2] describe how to extend the GKR protocol to handle circuits with gates that compute more general operations than just addition and multiplication. At a high level, [14] shows that gates computing any &quot;low-degree&quot; operation can be handled, and they demonstrate analytically and experimentally that these more general gates can achieve cost savings for the DISTINCT problem. These same optimizations are also applicable in conjunction with our refinements. We omit further details for brevity, and did not implement these optimizations in conjunction with our refinements.</p>

    <p class="text-gray-300"><strong>Other Problems.</strong> In order to demonstrate its generality, we describe two other non-trivial applications of Theorem 1.</p>

    <p class="text-gray-300">&bull; Pattern Matching. In the Pattern Matching problem, the input consists of a stream of text  <span class="math">T = (t_0, ..., t_{n-1}) \\in [n]^n</span>  and pattern  <span class="math">P = (p_0, ..., p_{m-1}) \\in [n]^m</span> . The pattern P is said to occur at location i in T if, for every position k in P,  <span class="math">p_k = t_{i+k}</span> . The pattern-matching problem is to determine the number of locations at which P occurs in T. For example, one might want to determine the number of times a given phrase appears in a corpus of emails stored in the cloud.</p>

    <p class="text-gray-300">Cormode et al. describe the following circuit C for Pattern Matching over the finite field  <span class="math">\\mathbb{F}_q</span> . The circuit first computes the quantity  <span class="math">I_i = \\sum_{j=0}^m (t_{i+j} - p_j)^2</span>  for each  <span class="math">i \\in [[n]]</span> , and then exploits Fermat's Little Theorem (FLT) by computing  <span class="math">M = \\sum_{i=1}^{n-m} I_i^{q-1}</span> . The number of occurrences of the pattern equals n-m-M.</p>

    <p class="text-gray-300">Computing  <span class="math">I_i</span>  for each i can be done in  <span class="math">\\log m + 2</span>  layers: the layer closest to the input computes  <span class="math">t_{i+k} - p_k</span>  for each pair  <span class="math">(i,k) \\in [[n]] \\times [[q]]</span> , the next layer squares each of the results, and the circuit then sums the results via a depth  <span class="math">\\log m</span> -binary tree of addition gates. The total size of the circuit C is  <span class="math">O(nm + n \\log q)</span> , where the nm term is due to the computation of the  <span class="math">I_i</span>  values, and the  <span class="math">n \\log q</span>  term is due to the FLT computation. The total depth of the circuit is  <span class="math">O(\\log m + \\log q) = O(\\log q)</span> .</p>

    <p class="text-gray-300">We have already demonstrated that Theorem 1 applies to the squaring layer, the binary tree sub-circuit, and the FLT computation. The only remaining layer of the circuit is the one that computes  <span class="math">t_{i+k} - p_k</span>  for each pair  <span class="math">(i,k) \\in [[n]] \\times [[m]]</span> . Unfortunately, Theorem 1 does <em>not</em> apply to this layer of the circuit. This is because the first in-neighbor of a gate with label  <span class="math">(i_1, \\ldots, i_{\\log n}, k_1, \\ldots, k_{\\log m}) \\in \\{0,1\\}^{\\log n + \\log m}</span>  has label equal to the binary representation of the integer i+k, and a single bit  <span class="math">i_j</span>  can affect many bits in the binary representation of i+k (likewise, each bit in the binary representation of i+k may be affected by many bits in the binary representation of i and k).</p>

    <p class="text-gray-300">However, in Appendix B, we describe how to extend the ideas underlying Theorem 1 to handle this wiring pattern. The extensions in Appendix B may be more broadly useful, as the wiring pattern analyzed there is an instance of a common paradigm, in that it interprets binary gate labels as a pair of integers and performs a simple arithmetic operation (namely addition) on those integers.</p>

    <p class="text-gray-300">We also remark that, instead of going through the analysis of Appendix B, a more straightforward approach is to simply apply the implementation of [14] to this layer; the runtime for  <span class="math">\\mathcal{P}</span>  in the corresponding sum-check protocol is  <span class="math">O(nm\\log n)</span> . This does not affect the asymptotic costs of the protocol if m is constant, since in this case  <span class="math">nm\\log n = O(n\\log q)</span> , and the total runtime of  <span class="math">\\mathcal{P}</span>  over all other layers of the circuit is  <span class="math">\\Theta(n\\log q)</span> .</p>

    <p class="text-gray-300">This analysis highlights the following point: our refinements can be applied to a circuit on a layer-by-layer basis, so they can still yield speedups even if some but not all layers of a circuit are sufficiently &quot;regular&quot; for our refinements to apply.</p>

    <p class="text-gray-300">A similar analysis applies to a closely related circuit that solves a more general problem known as Pattern Matching with Wildcards. We omit these details for brevity.</p>

    <p class="text-gray-300">&bull; Fast Fourier Transform. Cormode et al. [14] also describe a circuit over  <span class="math">\\mathbb C</span>  for computing the standard radix-two decimation-in-time FFT. At a high level, this circuit works as follows. It proceeds in  <span class="math">\\log n</span>  stages, where for  <span class="math">k=(k_1,\\ldots,k_n)\\in\\{0,1\\}^n</span> , the kth output of stage i is recursively defined as  <span class="math">V_i(k_1,\\ldots,k_n)=V_{i-1}(k_1,k_{i-1},0,k_i,\\ldots,k_n)+e^{-2\\pi ki/n}V_{i-1}(k_1,\\ldots,k_{i-1},1,k_{i+1},\\ldots,k_n)</span> . Theorem 1 is easily seen to apply to the natural circuit executing this recurrence, and our refinements would therefore shave a logarithmic factor off the runtime of  <span class="math">\\mathcal P</span>  applied to this circuit, relative to the implementation of [14] (since this circuit is defined over the infinite field  <span class="math">\\mathbb C</span> , the protocol is only defined in a model where complex numbers can be communicated and operated on at unit cost).</p>

    <p class="text-gray-300">We implemented the protocols implied by Theorem 1 as applied to circuits computing MATMULT and DISTINCT. These experiments serve as case studies to demonstrate the feasibility of Theorem 1 in prac-</p>

    <p class="text-gray-300">tice, and to quantify the improvements over prior implementations. While Section <a href="#page-35-0">8</a> describes a specialized protocol for MATMULT that is significantly more efficient than the protocol implied by Theorem <a href="#page-24-1">1,</a> MAT-MULT serves as an important case study for the costs of the more general protocol described in Theorem <a href="#page-24-1">1,</a> and allows for direct comparison with prior implementation work that also evaluated general-purpose protocols via their performance on the MATMULT problem <a href="#page-42-1">[14,</a> <a href="#page-42-9">30,</a> <a href="#page-43-9">35,</a> <a href="#page-43-4">36,</a> <a href="#page-43-2">38,</a> <a href="#page-43-1">40]</a>.</p>

    <p class="text-gray-300">Our comparison point is the implementation of Cormode et al. <a href="#page-42-1">[14]</a>, with some of the refinements of Vu et al. <a href="#page-43-1">[40]</a> included. In particular, our comparison point for matrix multiplication uses the refinement of <a href="#page-43-1">[40]</a> for circuits with multiple outputs described in Section <a href="#page-13-0">4.3.2.</a> We did not include Vu et al.'s optimization from Lemma <a href="#page-15-4">3</a> that reduced the runtime of V from <em>O</em>(<em>n</em>log<em>n</em>) to <em>O</em>(<em>n</em>), because this optimization blows up the space usage of V to &Omega;(<em>n</em>), while we want to use a smaller-space verifier for streaming applications such as DISTINCT.</p>

      <h3 id="sec-6.1" class="text-xl font-semibold mt-8">6.1 Summary of Results</h3>

    <p class="text-gray-300">The main takeaways of our experiments are as follows. When Theorem <a href="#page-24-1">1</a> is applicable, the prover in the resulting protocol is 200x-250x faster than the previous state of the art implementation of the GKR protocol. The communication costs and the number of rounds required by our protocols are also 2x-3x smaller than the previous state of the art. The verifier in our implementation takes essentially the same amount of time as in prior implementations of the GKR protocol; this time is much smaller than the time to perform the computation locally without a prover.</p>

    <p class="text-gray-300">Most of the observed 200x speedup can be attributed directly to our improvements in protocol design over prior work: the circuit for 512x512 matrix multiplication is of size 228, and hence our log<em>S</em> factor improvement the runtime of P likely accounts for at least a 28x speedup. The 3x reduction in the number of rounds accounts for another 3x speedup. The remaining speedup factor of roughly 2x may be due to a more streamlined implementation relative to prior work, rather than improved protocol design per se.</p>

    <p class="text-gray-300">We have both a serial implementation and a parallel implementation that leverages graphics processing units (GPUs). The prover in our parallel implementation runs roughly 30x faster than the prover in our serial implementation. The ability to leverage GPUs to obtain robust speedups in our setting is not unexpected, as Thaler, Roberts, Mitzenmacher, and Pfister demonstrated substantial speedups for an earlier implementation of the GKR protocol using GPUs in <a href="#page-43-2">[38]</a>.</p>

    <p class="text-gray-300">All of our code is available online at <a href="#page-43-10">[39]</a>. All of our serial code was written in C++ and all experiments were compiled with g++ using the &minus;O3 compiler optimization flag and run on a workstation with a 64-bit Intel Xeon architecture and 48 GBs of RAM. We implemented all of our GPU code in CUDA and Thrust <a href="#page-42-14">[24]</a> with all compiler optimizations turned on, and ran our GPU implementation on an NVIDIA Tesla C2070 GPU with 6 GBs of device memory.</p>

      <h3 id="sec-6.2" class="text-xl font-semibold mt-8">6.2 Details</h3>

    <p class="text-gray-300"><em>Choice of Finite Field.</em> All of our circuits work over the finite field of size <em>q</em> = 2 <sup>61</sup> &minus; 1. Several remarks are appropriate regarding our choice of field size. This field was used in our earlier work <a href="#page-42-1">[14]</a> because it supports fast arithmetic, as reducing an integer modulo <em>q</em> can be done with a bit-shift, addition, and a bit-wise AND. (The same observation applies to any field whose size equals a Mersenne Prime, including 2 <sup>89</sup> &minus;1, 2<sup>107</sup> &minus;1, and 2<sup>127</sup> &minus;1). Moreover, the field is large enough that the probability a verifier is fooled by a dishonest prover is smaller than 1/2 <sup>45</sup> for all of the problems we consider (this probability is proportional to <em><sup>d</sup></em>(<em>n</em>)log<em>S</em>(<em>n</em>) <em>q</em> ).</p>

    <p class="text-gray-300">The main potential issue with our choice of field size is that &quot;overflow&quot; can occur for problems such as matrix multiplication if the entries of the input matrices can be very large. For example, with 512&times;512 matrix multiplication, if the entries of the input matrices <em>A</em>,<em>B</em> are larger than 226, an entry in the product matrix <em>AB</em> can be as large as 261, which is larger than our field size. If this is a concern, a larger field size is appropriate. (Notice that for a problem such DISTINCT, there is no danger of overflow issues as long as the length of the stream is smaller than 2<sup>61</sup> &minus;2, which is larger than any stream encountered in practice).</p>

    <p class="text-gray-300">A second reason to use larger field sizes is to handle floating-point or rational arithmetic as proposed by Setty et al. in <a href="#page-43-9">[35]</a>.</p>

    <p class="text-gray-300">All of our protocols can be instantiated over fields with more than <em>q</em> = 2 <sup>61</sup> &minus;1 elements, with an implementation using these fields experiencing a slowdown proportional to the increased cost of arithmetic over these fields.</p>

      <h4 id="sec-6.2.1" class="text-lg font-semibold mt-6">6.2.1 Serial Implementation</h4>

    <p class="text-gray-300">MATMULT. The costs of our serial MATMULT implementation are displayed in Table <a href="#page-29-1">1.</a> The prover in our matrix multiplication implementation is about 250x faster than the previous state of the art. For example, when multiplying two 512 x 512 matrices, our prover takes about 38 seconds, while our comparison implementation takes over 2.5 hours. A C++ program that simply evaluates the circuit without an integrity guarantee takes 6.07 seconds, so our prover experiences less than a 7x slowdown to provide the integrity guarantee relative to simply evaluating the circuit without such a guarantee.</p>

    <p class="text-gray-300">When multiplying two 512 x 512 matrices <em>A</em> and <em>B</em>, the protocol requires 236 rounds, and the total communication cost of our protocol is 5.48 KBs (plus the amount of communication required to specify the answer <em>AB</em>). The previous state of the art required 767 rounds and close to 18 KBs of communication (plus the amount of communication required to specify <em>AB</em>). Notice that specifying a 512x512 matrix using 8 bytes per entry requires 2 MBs, which is more than 500 times larger than the 5.48 KBs of extra communication required to verify the answer.</p>

    <p class="text-gray-300">A serial C++ program performing 512 x 512 matrix multiplication over the integers with floating point arithmetic (without going through the circuit representation of the computation) required 1.53 seconds, so our prover runs approximately 25 times slower than a standard unverifiable matrix multiplication algorithm. A serial C++ program performing the same multiplication over the finite field of size 2<sup>61</sup> &minus;1 required 4.74 seconds, so our serial prover runs about 8 times slower than an unverifiable matrix multiplication algorithm over the corresponding finite field.</p>

    <p class="text-gray-300">Our verifier takes essentially the same amount of time as in prior work, as in both implementations the bulk of the work of the verifier is spent evaluating the low-degree extension of the input at a point. This is more than an order of magnitude faster than the 1.03 seconds required by a serial C++ program performing the multiplication in an unverified manner over the integers, so the verifier is indeed saving time by using a prover (relative to doing the computation locally without a prover). We stress that the savings for the verifier would be larger at larger input sizes, as the time cost to the verifier in our implementation and the prior implementation of <a href="#page-42-1">[14]</a> is quasilinear in the input size, which is polynomially faster than all known matrix multiplication algorithms. Moreover, when streaming considerations are not an issue, we could apply the refinement of Vu et al. from Lemma <a href="#page-15-4">3</a> to reduce V's runtime from <em>O</em>(<em>n</em> 2 log<em>n</em>) to <em>O</em>(<em>n</em> 2 ) and thereby further speed up the verifier.</p>

    <p class="text-gray-300">DISTINCT. The costs of our serial DISTINCT implementation are displayed in Table <a href="#page-29-2">2.</a> The comparison of our implementation with prior work is similar to the case of matrix multiplication. Our prover is roughly 200 times faster than the comparison implementation. For example, when computing the number of non-zero</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Implementation</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Problem Size</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"><span class="math">\\mathcal{P}</span> Time</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">V Time</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Rounds</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Total Communication</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Circuit Eval Time</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Previous state of the art</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">256 x 256</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1054 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.02 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">623</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">14.6 KBs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.73 s</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Theorem 1</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">256 x 256</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4.37 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">.02 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">190</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4.4 KBs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.73 s</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Previous state of the art</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">512 x 512</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">9759 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.10 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">767</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">17.97 KBs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6.07 s</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Theorem 1</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">512 x 512</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">37.85 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.10 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">236</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5.48 KBs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6.07 s</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">Table 1: Experimental results for  <span class="math">n \\times n</span>  MATMULT with our serial implementation. The Total Communication column does not count the communication required to specify the answer, only the &quot;extra&quot; communication required to run the verification protocol.</p>

    <p class="text-gray-300"></p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Implementation</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"><span class="math">\\mathcal{P}</span> Time</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">V Time</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Rounds</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Total Communication</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Circuit Eval Time</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Previous state of the art</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">3400.23 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.20 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">3916</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">91.3 KBs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.88 s</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Theorem 1</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">17.28 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.20 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1361</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">40.76 KBs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.88 s</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">Table 2: Experimental results for computing the number of non-zero entries of a vector of length  <span class="math">2^{20}</span>  with our serial implementation.</p>

    <p class="text-gray-300">entries of a vector of length  <span class="math">2^{20}</span> , our prover takes about 17 seconds, while our comparison implementation takes about 57 minutes. A C++ program that simply evaluates the circuit without an integrity guarantee takes 1.88 seconds, so our prover experiences roughly a 10x slowdown to prove an integrity guarantee relative to simply evaluating the circuit. Our implementation required 1361 rounds and 40.76 KBs of total communication, compared to 3916 rounds and 91.3 KBs for the previous state of the art. This is essentially a 3x reduction in the number of rounds, and a 2.25x reduction in the total amount of communication.</p>

    <p class="text-gray-300">A C++ program that (unverifiably) computes the number of non-zero entries in a vector x with  <span class="math">2^{20}</span>  entries takes less than .01 seconds, and our prover implementation runs more than 1,700 times longer than this. The reason that the slowdown for the prover relative to an unverifiable algorithm is larger for DISTINCT than for MATMULT is that DISTINCT is a &quot;less arithmetic&quot; problem, in the sense that the size of the arithmetic circuit we use for computing DISTINCT is more than 100x larger than the runtime of an unverifiable serial algorithm for the problem. We stress however that, as pointed out in [38], when solving the DISTINCT problem in practice, an unverifiable algorithm would first aggregate a data stream into its frequency-vector representation before determining the number of non-zero frequencies. In reporting a time bound of .01 seconds for unverifiably solving DISTINCT, we are not taking the aggregation time cost into account. For sufficiently long data streams, the slow-down for our prover relative to an unverifiable algorithm would be much smaller than 1,700x if we did take aggregation time into account.</p>

      <h4 id="sec-6.2.2" class="text-lg font-semibold mt-6"><strong>6.2.2</strong> Parallel Implementation</h4>

    <p class="text-gray-300">Our serial implementation demonstrates that  <span class="math">\\mathcal{P}</span>  experiences a 10x slowdown in order to evaluate the circuit with an integrity guarantee relative to simply evaluating the circuit without such a guarantee. The purpose of this section is to demonstrate that parallelization can further mitigate this slowdown. To this end, we implemented a parallel version of our prover in the context of the matrix multiplication protocol of Section 5. Our parallel implementation uses a graphics processing unit (GPU).</p>

    <p class="text-gray-300">The high-level idea behind our parallel implementation is the following. Each time we apply the sumcheck protocol to a polynomial  <span class="math">g_z^{(i)}</span> , it suffices for  <span class="math">\\mathcal{P}</span>  to evaluate  <span class="math">g_z^{(i)}</span>  at a large number of points r of the form  <span class="math">p=(r_1,\\ldots,r_{j-1},t,b_{j+1},\\ldots,b_{s_{i+1}})</span>  with  <span class="math">t\\in\\{0,\\ldots,\\deg_j(g_z^{(i)})\\}</span>  and  <span class="math">(b_{j+1},\\ldots,b_{s_{i+1}})\\in\\{0,1\\}^{s_{i+1}-j}</span> . We can perform each of these evaluations independently. Thus, we devote a single thread on the GPU to each value</p>

    <p class="text-gray-300"></p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Implementation</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Problem Size</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">P Time</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Serial Circuit Eval Time</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Theorem 1, Serial Implementation</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">256 x 256</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4.37 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.73 s</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Theorem 1, Parallel Implementation</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">256 x 256</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.23 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.73 s</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Theorem 1, Serial Implementation</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">512 x 512</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">37.85 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6.07 s</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Theorem 1, Parallel Implementation</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">512 x 512</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.29 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6.07 s</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">Table 3: Experimental results for <em>n</em>&times;<em>n</em> MATMULT with our parallel prover implementation.</p>

    <p class="text-gray-300">of (<em>bj</em>+1,...,<em>bsi</em>+<sup>1</sup> ) &isin; {0,1} <em>si</em>+1&minus;<em>j</em> and have that thread evaluate <em>g</em> (<em>i</em>) <em><sup>z</sup></em> (<em>r</em>) at each of the deg<em><sup>j</sup></em> (<em>g</em> (<em>i</em>) <em><sup>z</sup></em> ) +1 points of the form (<em>r</em>1,...,<em>rj</em>&minus;1,<em>t</em>,<em>bj</em>+1,...,<em>bsi</em>+<sup>1</sup> ) with the help of the <em>C</em> (<em>j</em>&minus;1) and <em>V</em> (<em>j</em>&minus;1) arrays described in Section <a href="#page-16-0">5.</a> The one remaining issue is that after each round <em>j</em> of each invocation of the sum-check protocol, we need to update the arrays, i.e., we need to compute <em>C</em> (<em>j</em>) and <em>V</em> (<em>j</em>) . To accomplish this, we devote a single thread to each entry of <em>C</em> (<em>j</em>) and <em>V</em> (<em>j</em>) .</p>

    <p class="text-gray-300">All steps of our parallel implementation achieve excellent memory coalescing, which likely plays a significant role in the large speedups we were able to achieve. For example, if two threads are updating adjacent entries of the array <em>V</em> (<em>j</em>) , the only memory accesses that the threads need to perform are to adjacent entries of the array <em>V</em> (<em>j</em>&minus;1) .</p>

    <p class="text-gray-300">The results are shown in Table <a href="#page-30-1">3:</a> we obtained about a 30x speedup for the prover relative to our serial implementation. The reported prover runtime does count the time required to copy data between the host (CPU) and the device (GPU), but does not count the time required to evaluate the circuit, which our implementation does in serial for simplicity. While our implementation evaluates the circuit serially, this step can in principle be done in parallel one layer at a time, as these circuits have only logarithmic depth. Notice that when the circuit evaluation runtime is excluded, our parallel prover implementation runs faster in the case of 512x512 matrix multiplication than the time required to evaluate the circuit sequentially.</p>

    <p class="text-gray-300">It is possible that we would observe slightly larger speedups at larger input sizes, but our parallel implementation exhausts the memory of the GPU at inputs larger than 512x512. This memory bottleneck was also experienced by Thaler, Roberts, Mitzenmacher, and Pfister <a href="#page-43-2">[38]</a>, who used the GPU to obtain a parallel implementation of the protocol of Cormode et al. <a href="#page-42-1">[14]</a>, and helps motivate the importance of the improved space usage of the special purpose MATMULT protocol we give later in Theorem <a href="#page-37-2">3.</a> For comparison, the GPU implementation of <a href="#page-43-2">[38]</a> required 39.6 seconds for 256 x 256 matrix multiplication, which is about 175x slower than our parallel implementation.</p>

    <p class="text-gray-300">We also mention that Thaler, Roberts, Mitzenmacher, and Pfister <a href="#page-43-2">[38]</a> demonstrate that equally large speedups via parallelization are achievable for the (already fast) computation of the verifier. These results directly apply to our protocols as well, as the verifier's runtime in both implementations is dominated by the time required to evaluate the MLE of the input at a random point <a href="#page-42-1">[14,</a> <a href="#page-43-2">38]</a>.</p>

    </section>

    <section id="sec-7" class="mb-10">
      <h2 class="text-2xl font-bold">7 Verifying General Data Parallel Computations</h2>

    <p class="text-gray-300">In this section, our goal is to extend the applicability of the GKR protocol. While the GKR protocol applies in principle to any function computed by a small-depth circuit, this is not the case when fine-grained efficiency considerations are taken into account. The implementation of Cormode et al. <a href="#page-42-1">[14]</a> required the programmer to express a program as an arithmetic circuit, and moreover this circuit needed to have a regular wiring pattern, in the sense that the verifier could efficiently evaluate the polynomials &tilde; add<em><sup>i</sup></em> and mult &tilde; <em><sup>i</sup></em> at a point. If this was not the case, the verifier would need to do an expensive (though data-independent) preprocessing phase to perform these evaluations. Moreover, even for circuits with regular wiring patterns, this implementation caused the prover to suffer an  <span class="math">O(\\log(S(n)))</span>  factor blowup in runtime relative to evaluating the circuit without a guarantee of correctness. The results of Sections 5 and 8 asymptotically eliminate the blowup in runtime for the prover, but they also only apply when the circuit has a very regular wiring pattern.</p>

    <p class="text-gray-300">The implementation of Vu et al. [40] allows the programmer to express a program in a high-level language, but compiles these programs into potentially irregular circuits that require the verifier to incur the expensive preprocessing phase mentioned above, in order for the verifier to evaluate the polynomials  <span class="math">\\tilde{\\text{add}}_i</span>  and  <span class="math">\\tilde{\\text{mult}}_i</span>  at a point. They therefore propose to apply their system in a &quot;batching&quot; model, where multiple instances of the same sub-computation are applied independently to different pieces of data. More specifically, their system applies the GKR protocol independently to each application of the computation, and relies on the ability of the verifier to use a single  <span class="math">\\tilde{\\text{add}}_i</span>  and  <span class="math">\\tilde{\\text{mult}}_i</span>  evaluation for all instances of the sub-computation, thereby amortizing the cost of this evaluation across the instances. To clarify, this use of a single  <span class="math">\\tilde{\\text{add}}_i</span>  and  <span class="math">\\tilde{\\text{mult}}_i</span>  evaluation for all instances as in [40] is only sound if all of the instances are checked simultaneously. If the instances are instead verified one after the other, then  <span class="math">\\mathcal{P}</span>  knows  <span class="math">\\mathcal{V}</span> 's randomness in all but the first instance, and can use that knowledge to mislead  <span class="math">\\mathcal{V}</span> .</p>

    <p class="text-gray-300">The batching model of Vu et al. is identical to the data parallel setting we consider here. However, a downside to the solution of Vu et al. is that the verifier's work, as well as the total communication cost of the protocol, grows linearly with the &quot;batch size&quot; &ndash; the number of applications of the sub-computation that are being outsourced. We wish to develop a protocol whose costs to both the prover and verifier grow much more slowly with the batch size.</p>

      <h3 id="sec-7.1" class="text-xl font-semibold mt-8">7.1 Motivation</h3>

    <p class="text-gray-300">As discussed above, existing interactive proof protocols for circuit evaluation either apply only to circuits with highly regular wiring patterns or incur large overheads for the prover and verifier. While we do not have a magic bullet for dealing with irregular wiring patterns, we do wish to mitigate the bottlenecks of existing protocols by leveraging some general structure underlying many real-world computations. Specifically, the structure we focus on exploiting is data-parallelism.</p>

    <p class="text-gray-300">By data parallel computation, we mean any setting in which the same sub-computation is applied independently to many pieces of data, before possibly aggregating the results. Crucially, we do not want to make significant assumptions on the sub-computation that is being applied (in particular, we want to handle sub-computations computed by circuits with highly irregular wiring patterns), but we are willing to assume that the sub-computation is applied independently to many pieces of data. See Figure 2 for a schematic of a data parallel computation.</p>

    <p class="text-gray-300">We have already seen a very simple example of a data parallel computation: the DISTINCT problem. The circuit C from Section 5 used to solve this problem takes as input a vector a and computes  <span class="math">a_i^{q-1} \\mod q</span>  for all i (this is the data parallel phase of the computation), before summing the results (this is the aggregation phase). Notice that if the data stream consists of a sequence of words, then the DISTINCT problem becomes the word-count problem, a classic data parallel application.</p>

    <p class="text-gray-300">By design, the protocol of this section also applies to more complicated data parallel computations. For example, it applies to arbitrary <em>counting queries</em> on a database. In a counting query, one applies some function independently to each row of the database and sums the results. For example, one may ask &quot;How many people in the database satisfy Property P?&quot; Our protocol allows one to verifiably outsource such a counting query with overhead that depends minimally on the size of the database, but that necessarily depends on the complexity of the property P.</p>

    <p class="text-gray-300">    <img src="_page_32_Figure_0.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Figure 2: Schematic of a data parallel computation.</p>

      <h3 id="sec-7.2" class="text-xl font-semibold mt-8">7.2 Overview of the Protocol</h3>

    <p class="text-gray-300">Let <em>C</em> be a circuit of size <em>S</em>(<em>n</em>) with an arbitrary wiring pattern, and let <em>C</em> <sup>&lowast;</sup> be a &quot;super-circuit&quot; that applies <em>C</em> independently to <em>B</em> different inputs before aggregating the results in some fashion. For example, in the case of a counting query, the aggregation phase simply sums the results of the data parallel phase. We assume that the aggregation step is sufficiently simple that the aggregation itself can be verified using existing techniques, and we focus on verifying the data parallel part of the computation.</p>

    <p class="text-gray-300">If we naively apply the GKR protocol to the super-circuit <em>C</em> &lowast; , V might have to perform an expensive preprocessing phase to evaluate the wiring predicate of <em>C</em> &lowast; at the necessary locations &ndash; this would require time &Omega;(<em>B</em>&middot;<em>S</em>). Moreover, when applying the basic GKR protocol to <em>C</em> &lowast; , P would require time &Theta;(<em>B</em>&middot; <em>S</em> &middot;log(<em>B</em>&middot; <em>S</em>)). A different approach was taken by Vu et al <a href="#page-43-1">[40]</a>, who applied the GKR protocol <em>B</em> independent times, once for each copy of <em>C</em>. This causes both the communication cost and V's online check time to grow linearly with <em>B</em>, the number of sub-computations.</p>

    <p class="text-gray-300">In contrast, our protocol achieves the best of both prior approaches. We observe that although each sub-computation <em>C</em> can have a complicated wiring pattern, the circuit is maximally regular between subcomputations, as the sub-computations do not interact at all. Therefore, each time the basic GKR protocol would apply the sum-check protocol to a polynomial derived from the wiring predicate of<em>C</em> &lowast; , we can instead use a simpler polynomial derived only from the wiring predicate of <em>C</em>. By itself, this is enough to ensure that V's pre-processing phase requires time only <em>O</em>(<em>S</em>), rather than <em>O</em>(<em>B</em> &middot; <em>S</em>) as in a naive application of the basic GKR protocol. That is, the cost of V's pre-processing phase is essentially proportional to the cost of applying the GKR protocol only to <em>C</em>, not to the super-circuit <em>C</em> &lowast; .</p>

    <p class="text-gray-300">Furthermore, by combining this observation with the methods of Section <a href="#page-16-0">5,</a> we can bring the runtime of P down to <em>O</em>(<em>B</em> &middot; <em>S</em> &middot; log<em>S</em>). That is, the blowup in runtime suffered by the prover, relative to performing the computation without a guarantee of correctness, is just a factor of log<em>S</em> &ndash; the same as it would be if the prover had run the basic GKR protocol on a single instance of the sub-computation.</p>

      <h3 id="sec-7.3" class="text-xl font-semibold mt-8">7.3 Technical Details</h3>

      <h4 id="sec-7.3.1" class="text-lg font-semibold mt-6">7.3.1 Notation</h4>

    <p class="text-gray-300">Let C be an arithmetic circuit over  <span class="math">\\mathbb{F}</span>  of depth d and size S with an arbitrary wiring pattern, and let  <span class="math">C^*</span>  be the circuit of depth d and size  <span class="math">B \\cdot S</span>  obtained by laying B copies of C side-by-side, where  <span class="math">B = 2^b</span>  is a power of S. We assume that the in-neighbors of all of the  <span class="math">S_i</span>  gates at layer  <span class="math">S_i</span>  can be enumerated in  <span class="math">S_i</span>  time. We will use the same notation as in Section  <span class="math">S_i</span> , using *'s to denote quantities referring to  <span class="math">S_i</span> . For example, layer  <span class="math">S_i</span>  of  <span class="math">S_i</span>  and gate values specified by the function  <span class="math">S_i</span> , while layer  <span class="math">S_i</span>  of  <span class="math">S_i</span>  and gate values specified by the function  <span class="math">S_i</span> . We denote the length of the input to  <span class="math">S_i</span>  by  <span class="math">S_i</span>  and  <span class="math">S_i</span>  and gate values specified by the function  <span class="math">S_i</span> .</p>

      <h4 id="sec-7.3.2" class="text-lg font-semibold mt-6">7.3.2 Main Theorem</h4>

    <p class="text-gray-300">Our main theorem gives a protocol for compute  <span class="math">\\tilde{V}_1^*(z)</span> , for any point  <span class="math">z \\in \\mathbb{F}^{s_1^*}</span> . The idea is that the verifier would first apply simpler techniques (such as the protocol of Theorem 1) to the aggregation phase of the computation to obtain a claim about  <span class="math">\\tilde{V}_1^*(z)</span> , and then use our main theorem to verify this claim. Hence, in principle  <span class="math">\\mathcal V</span>  need not look at the entire output of the data parallel phase, only the output of the aggregation phase, which we anticipate to be much smaller.</p>

    <p class="text-gray-300"><strong>Theorem 2</strong> For any point  <span class="math">z \\in \\mathbb{F}^{s_1^*}</span> , there is a valid interactive proof protocol for computing  <span class="math">\\tilde{V}_1^*(z)</span>  with the following costs. V spends O(S) time in a pre-processing phase, and  <span class="math">O(n^*\\log n^* + d \\cdot \\log(B \\cdot S))</span>  time in an online verification phase, where the  <span class="math">n^*\\log n^*</span>  term is due to the time required to evaluate the multilinear extension of the input to  <span class="math">C^*</span>  at a point.  <span class="math">\\mathcal{P}</span>  runs in total time  <span class="math">O(S \\cdot B \\cdot \\log S)</span> . The total communication is  <span class="math">O(d \\cdot \\log(B \\cdot S))</span>  field elements.</p>

    <p class="text-gray-300"><strong>Proof:</strong> Consider layer i of  <span class="math">C^*</span> . Let  <span class="math">p = (p_1, p_2) \\in \\{0, 1\\}^{s_i} \\times \\{0, 1\\}^b</span>  be the label of a gate at layer i of  <span class="math">C^*</span> , where  <span class="math">p_2</span>  specifies which &quot;copy&quot; of C the gate is in, while  <span class="math">p_1</span>  designates the label of the gate within the copy. Similarly, let  <span class="math">\\omega = (\\omega_1, \\omega_2) \\in \\{0, 1\\}^{s_{i+1}} \\times \\{0, 1\\}^b</span>  and  <span class="math">\\gamma = (\\gamma_1, \\gamma_2) \\in \\{0, 1\\}^{s_{i+1}} \\times \\{0, 1\\}^b</span>  be the labels of two gates at layer i + 1.</p>

    <p class="text-gray-300">It is straightforward to check that for all  <span class="math">(p_1, p_2) \\in \\{0, 1\\}^{s_i} \\times \\{0, 1\\}^b</span> ,</p>

    <p class="text-gray-300"><span class="math">$V_i^*(p_1,p_2) = \\sum_{\\pmb{\\omega}_1 \\in \\{0,1\\}^{s_{i+1}}} \\sum_{\\pmb{\\gamma}_1 \\in \\{0,1\\}^{s_{i+1}}} h^{(i)}(p_1,p_2,\\pmb{\\omega}_1,\\pmb{\\gamma}_1),</span>$</p>

    <p class="text-gray-300">where</p>

    <p class="text-gray-300"><span class="math">$h^{(i)}(p_1, p_2, \\omega_1, \\gamma_1) =</span>$</p>

    <p class="text-gray-300"><span class="math">$\\left(\\tilde{\\mathrm{add}}_i(p_1,\\pmb{\\omega}_1,\\pmb{\\gamma}_1)\\left(\\tilde{V}_{i+1}^*(\\pmb{\\omega}_1,p_2)+\\tilde{V}_{i+1}^*(\\pmb{\\gamma}_1,p_2)\\right)+\\tilde{\\mathrm{mult}}_i(p_1,\\pmb{\\omega}_1,\\pmb{\\gamma}_1)\\left(\\tilde{V}_{i+1}^*(\\pmb{\\omega}_1,p_2)\\cdot\\tilde{V}_{i+1}^*(\\pmb{\\gamma}_1,p_2)\\right)\\right).</span>$</p>

    <p class="text-gray-300">Essentially, this equation says that an addition (respectively, multiplication) gate  <span class="math">p = (p_1, p_2) \\in \\{0, 1\\}^{s_i + b}</span>  is connected to gates  <span class="math">\\omega = (\\omega_1, \\omega_2) \\in \\{0, 1\\}^{s_{i+1} + b}</span>  and  <span class="math">\\gamma = (\\gamma_1, \\gamma_2) \\in \\{0, 1\\}^{s_{i+1} + b}</span>  if and only if  <span class="math">p, \\omega</span> , and  <span class="math">\\gamma</span>  are all in the same copy of C, and p is connected to  <span class="math">\\omega</span>  and  <span class="math">\\gamma</span>  within the copy.</p>

    <p class="text-gray-300">Lemma 4 then implies that for any  <span class="math">z \\in \\mathbb{F}^{s_i^*}</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\tilde{V}_i^*(z) = \\sum_{(p_1,p_2,\\pmb{\\omega}_1,\\pmb{\\gamma}_1) \\in \\{0,1\\}^{s_i} \\times \\{0,1\\}^{b} \\times \\{0,1\\}^{s_{i+1}} \\times \\{0,1\\}^{s_{i+1}}} \\pmb{\\beta}_{s_i^*}(z,(p_1,p_2)) \\cdot h^{(i)}(p_1,p_2,\\pmb{\\omega}_1,\\pmb{\\gamma}_1).</span>$</p>

    <p class="text-gray-300">Thus, in iteration i of our protocol, we apply the sum-check protocol to the polynomial  <span class="math">g_z^{(i)}</span>  given by  <span class="math">g_z^{(i)}(p_1,p_2,\\omega_1,\\gamma_1)=\\beta_{s_i^*}(z,(p_1,p_2))\\cdot h^{(i)}(p_1,p_2,\\omega_1,\\gamma_1)</span> . The communication costs of this protocol are immediate.</p>

    <p class="text-gray-300"><strong>Costs for</strong>  <span class="math">\\mathcal{V}</span> . In order to run her part of the sum-check protocol of iteration i,  <span class="math">\\mathcal{V}</span>  only needs to perform the required checks on each of  <span class="math">\\mathcal{P}</span> 's messages.  <span class="math">\\mathcal{V}</span> 's check requires O(1) time in each round of the sum-check protocol except the last. In the last round of the sum-check protocol,  <span class="math">\\mathcal{V}</span>  must evaluate the polynomial  <span class="math">g_z^{(i)}</span>  at a single point. This requires evaluating  <span class="math">\\beta_{s_i^*}</span> ,  <span class="math">\\tilde{\\text{add}}_i</span> ,  <span class="math">\\tilde{\\text{mult}}_i</span> , and  <span class="math">\\tilde{V}_{i+1}^*</span>  at a constant number of points. The  <span class="math">\\tilde{V}_{i+1}^*</span>  evaluations are provided by  <span class="math">\\mathcal{P}</span>  in all iterations i of the protocol except the last, while the  <span class="math">\\beta_{s_i^*}</span>  evaluation can be done in  <span class="math">O(\\log(B \\cdot S))</span>  time.</p>

    <p class="text-gray-300">The  <span class="math">\\tilde{\\text{add}}_i</span>  and  <span class="math">\\tilde{\\text{mult}}_i</span>  computations can be done in pre-processing in time  <span class="math">O(S_i)</span>  by enumerating the inneighbors of each of the  <span class="math">S_i</span>  gates at layer i [14,40]. Adding up the pre-processing time across all iterations i of our protocol,  <span class="math">\\mathcal{V}</span> 's pre-processing time is  <span class="math">O(\\sum_i S_i) = O(S)</span>  as claimed.</p>

    <p class="text-gray-300">In the final iteration of the protocol,  <span class="math">\\mathcal{P}</span>  no longer provides the  <span class="math">\\tilde{V}_{i+1}^*</span>  evaluation for  <span class="math">\\mathcal{V}</span> ; instead,  <span class="math">\\mathcal{V}</span>  must evaluate the multilinear extension of the input at a point on her own. This can be done in a streaming manner using space  <span class="math">O(\\log n^*)</span>  in time  <span class="math">O(n^* \\log n^*)</span> . The time cost for  <span class="math">\\mathcal{V}</span>  in the online phase follows.</p>

    <p class="text-gray-300">Costs for  <span class="math">\\mathcal{P}</span> . It remains to show that  <span class="math">\\mathcal{P}</span>  can perform the required computations in iteration i of the protocol in time  <span class="math">O((S_i + S_{i+1}) \\cdot B \\cdot \\log(S))</span> . To this end, notice  <span class="math">g_z^{(i)}</span>  is a polynomial in  <span class="math">v := s_i + 2s_{i+1} + b</span>  variables. We order the sum in this sum-check protocol so that the  <span class="math">s_i + 2s_{i+1}</span>  variables in  <span class="math">p_1</span> ,  <span class="math">\\omega_1</span> , and  <span class="math">\\gamma_1</span>  are bound first in arbitrary order, followed by the variables of  <span class="math">p_2</span> .  <span class="math">\\mathcal{P}</span>  can compute the prescribed messages in the first  <span class="math">s_i + 2s_{i+1} = O(\\log S)</span>  rounds exactly as in the implementation of Cormode et al. [14]. They show that each gate at layers i and i+1 of  <span class="math">C^*</span>  contributes to exactly one term in the sum defining  <span class="math">\\mathcal{P}</span> 's message in any given round of the sum-check protocol, and moreover the contribution of a given gate can be determined in O(1) time. Hence the total time devoted required by  <span class="math">\\mathcal{P}</span>  to handle these rounds is  <span class="math">O(B \\cdot (S_i + S_{i+1}) \\cdot \\log S)</span> . It remains to show how  <span class="math">\\mathcal{P}</span>  can compute the prescribed messages in the final b rounds of the sum-check protocol while investing  <span class="math">O((S_i + S_{i+1}) \\cdot B)</span>  across all rounds of the protocol.</p>

    <p class="text-gray-300">Recall that in order to compute  <span class="math">\\mathcal{P}</span> 's message in round j of the sum-check protocol applied to the v-variate polynomial  <span class="math">g_z^{(i)}</span> , it suffices for  <span class="math">\\mathcal{P}</span>  to evaluate  <span class="math">g_z^{(i)}</span>  at  <span class="math">2^{v-j}</span>  points of the form  <span class="math">(r_1,\\ldots,r_{j-1},t,b_{j+1},\\ldots,b_v)</span> , with  <span class="math">t\\in\\{0,\\ldots,\\deg_j(g_z^{(i)})\\}</span>  and  <span class="math">(b_{j+1},\\ldots,b_v)\\in\\{0,1\\}^{v-j}</span> . Each of these evaluations of  <span class="math">g_z^{(i)}</span>  can be computed in O(1) time given the evaluations of  <span class="math">\\beta_{s_i^*}</span> , addi, multi, and i-at the relevant points.</p>

    <p class="text-gray-300">Notice that once the variables in  <span class="math">p_1</span> ,  <span class="math">\\omega_1</span> , and  <span class="math">\\gamma_1</span>  are bound to specific values, say  <span class="math">r_1^{(p)}</span> ,  <span class="math">r_1^{(\\omega)}</span> , and  <span class="math">r_1^{(\\gamma)}</span> , add <span class="math">_i(p_1,\\omega_1,\\gamma_1)</span>  and mult <span class="math">_i(p_1,\\omega_1,\\gamma_1)</span>  are themselves bound to specific values, namely add <span class="math">_i(r_1^{(p)},r_1^{(\\omega)},r_1^{(\\gamma)})</span>  and mult <span class="math">_i(r_1^{(p)},r_1^{(\\omega)},r_1^{(\\gamma)})</span> . So  <span class="math">\\mathcal P</span>  only needs to evaluate these polynomials once, and both of these evaluations can be computed by  <span class="math">\\mathcal P</span>  in  <span class="math">O(S_i)</span>  time. Thus, the add <span class="math">_i</span> , mult <span class="math">_i</span>  evaluations in the last b rounds require just  <span class="math">O(S_i)</span>  time in total.</p>

    <p class="text-gray-300"><span class="math">\\mathcal{P}</span>  can evaluate the function  <span class="math">\\beta_{s_i^*}</span>  at the relevant points exactly as in the proof of Theorem 1 using the  <span class="math">C^{(j)}</span>  arrays to ensure that this computation is done quickly. The array  <span class="math">C^{(0)}</span>  has size  <span class="math">2^{s_i^*} = O(S_i \\cdot B)</span> , and  <span class="math">C^{(j-1)}</span>  gets updated to  <span class="math">C^{(j)}</span>  whenever a variable in  <span class="math">p_1</span>  or  <span class="math">p_2</span>  becomes bound. This ensures that across all rounds of the sum-check protocol, the  <span class="math">\\beta_{s_i^*}</span>  evaluations require  <span class="math">O(S_i \\cdot B)</span>  time in total.</p>

    <p class="text-gray-300">Likewise, the  <span class="math">\\tilde{V}_{i+1}^*</span>  evaluations can be handled exactly as in Theorem 1, using the the  <span class="math">V^{(j)}</span>  arrays to ensure that this computation is done quickly. The array  <span class="math">V^{(0)}</span>  has size  <span class="math">2^{s_{i+1}^*} = O(S_{i+1} \\cdot B)</span> , and  <span class="math">V^{(j-1)}</span>  gets updated to  <span class="math">V^{(j)}</span>  whenever a variable in  <span class="math">\\omega_1</span>  becomes bound (and similarly for the variables in  <span class="math">\\gamma_1</span> ). This ensures that across all rounds of the sum-check protocol, the  <span class="math">\\tilde{V}_{i+1}^*</span>  evaluations take  <span class="math">O((S_i + S_{i+1}) \\cdot B)</span>  in total.</p>

    <p class="text-gray-300"><strong>Reducing to Verification of a Single Point.</strong> After executing the sum-check protocol at layer i as</p>

    <p class="text-gray-300">described above, V is left with a claim about  <span class="math">\\tilde{V}_{i+1}(\\omega_1, p_2)</span>  and  <span class="math">\\tilde{V}_{i+1}(\\gamma_1, p_2)</span> , for  <span class="math">\\omega_1, \\gamma_1 \\in \\mathbb{F}^{s_i}</span> , and  <span class="math">p_2 \\in \\mathbb{F}^b</span> . This requires  <span class="math">\\mathcal{P}</span>  to send  <span class="math">\\tilde{V}_{i+1}(\\ell(t))</span>  for a canonical line  <span class="math">\\ell(t)</span>  that passes through  <span class="math">(\\omega_1, p_2)</span>  and  <span class="math">(\\gamma_1, p_2)</span> . It is easily seen that  <span class="math">\\tilde{V}_{i+1}(\\ell(t))</span>  is a univariate polynomial of degree at most  <span class="math">s_i</span> . Here, we are exploiting the fact that the final b coordinates of  <span class="math">(\\omega_1, p_2)</span>  and  <span class="math">(\\gamma_1, p_2)</span>  are equal.</p>

    <p class="text-gray-300">Hence  <span class="math">\\mathcal{P}</span>  can specify  <span class="math">\\tilde{V}_{i+1}(\\ell(t))</span>  by sending  <span class="math">\\tilde{V}_{i+1}(\\ell(t_j))</span>  for  <span class="math">O(s_i)</span>  many points  <span class="math">t_j \\in \\mathbb{F}</span> . Using the method of Lemma 3,  <span class="math">\\mathcal{P}</span>  can evaluate  <span class="math">\\tilde{V}_{i+1}</span>  at each point  <span class="math">\\ell(t_j)</span>  in  <span class="math">O(S_{i+1})</span>  time, and hence can perform all  <span class="math">\\tilde{V}_{i+1}(\\ell(t_j))</span>  evaluations in  <span class="math">O(S_{i+1} \\cdot s_i) = O(S_{i+1} \\cdot \\log S)</span>  time in total. This ensures that across all iterations of our protocol,  <span class="math">\\mathcal{P}</span>  devotes at most  <span class="math">O(S \\cdot B \\cdot \\log S)</span>  time to the &quot;reducing to verification of a single point&quot; phase of the protocol. This completes the proof.</p>

    <p class="text-gray-300">In practice we would expect the results of the data parallel phase of computation represented by the super-circuit  <span class="math">C^*</span>  to be aggregated in some fashion. We assume this aggregation step is amenable to verification via other techniques. In the case of counting queries, the aggregation step simply sums the outputs of the data parallel step, which can be handled via Theorem 1, or slightly more efficiently via Proposition 7 described below in Section 8. More generally, if this aggregation step is computed by a circuit C' of size  <span class="math">O(S \\cdot B \\cdot \\log S / \\log B)</span>  such that V can efficiently evaluate the multilinear extension of the wiring predicate of C', then we can simply apply the basic GKR protocol to C' with asymptotic costs smaller than those of the protocol described in Theorem 2. This application of the GKR protocol to C' ends with a claim about the value of  <span class="math">\\tilde{V}_1^*(z)</span>  for some  <span class="math">z \\in \\mathbb{F}^{s_1^*}</span> . The verifier can then invoke the protocol of Theorem 2 to verify this claim.</p>

    <p class="text-gray-300">We stress that the protocol of Theorem 2 can be applied if there are multiple data parallel stages interleaved with aggregation stages.</p>

    </section>

    <section id="sec-8" class="mb-10">
      <h2 class="text-2xl font-bold">8 Extensions</h2>

    <p class="text-gray-300">In this section we describe two final optimizations that are much more specialized than Theorems 1 and 2, but have a significant effect in practice when they apply. In particular, Section 8.2 culminates in a protocol for matrix multiplication that is of interest in its own right. It is hundreds of times faster than the protocol implied by Theorem 1 and studied experimentally in Section 6.</p>

      <h3 id="sec-8.1" class="text-xl font-semibold mt-8">8.1 Binary Tree of Addition Gates</h3>

    <p class="text-gray-300">Cormode et al. [21] describe an optimization that applies to any circuit C with a single output that culminates in a binary tree of addition gates; at a high level, they directly apply a single sum-check protocol to the entire binary tree, thereby treating the entire tree as a single addition gate with very large fan-in. In contrast, the optimization described here applies to circuits with multiple outputs and allows the binary tree of addition gates to occur anywhere in the circuit, not just at the layers immediately preceding the output.</p>

    <p class="text-gray-300">At first blush, our optimization might seem quite specialized since it only applies to circuits with a specific wiring pattern. However, this is one of the most commonly occurring wiring patterns, as evidenced by its appearance within the circuits computing MATMULT, DISTINCT, Pattern Matching, and counting queries. Notice that our optimization also applies to verifying multiple independent instances of any problem with a single output whose circuit ends with a binary tree of sum-gates, such as verifying the number of distinct items in multiple distinct data streams, or posing multiple separate counting queries to a database. This is because, similar to Theorem 2, one can lay the circuits for each of the individual problem instances side-by-side and treat the result as a single &quot;super-circuit&quot; culminating in a binary tree of addition gates with multiple outputs.</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Implementation</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Problem Size</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"><span class="math">\\mathcal{P}</span> Time</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">V Time</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Rounds</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Total Communication</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Circuit Eval Time</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Theorem 1</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">256 x 256</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4.37 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.02 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">190</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4.4 KBs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.73 s</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Proposition 7</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">256 x 256</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2.52 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.02 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">35</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.76 KBs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.73 s</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Theorem 1</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">512 x 512</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">37.85 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.10 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">236</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5.48 KBs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6.07 s</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Proposition 7</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">512 x 512</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">22.98 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.10 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">39</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.86 KBs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6.07 s</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">Table 4: Experimental results for  <span class="math">n \\times n</span>  MATMULT, with and without the refinement of Section 8.1. As in Table 1, the Total Communication column does not count the  <span class="math">n^2</span>  field elements required to specify the answer.</p>

    <p class="text-gray-300">The starting point for our optimization is the observation of Vu et al. [40] mentioned in Section 4.3.2: in order to verify that  <span class="math">\\mathcal{P}</span>  has correctly evaluated a circuit with many output gates,  <span class="math">\\mathcal{P}</span>  may simply send  <span class="math">\\mathcal{V}</span>  the (claimed) values of all output gates, thereby specifying a function  <span class="math">V_1&#x27;: \\{0,1\\}^{s_1} \\to \\mathbb{F}</span>  claimed to equal  <span class="math">V_1</span> .  <span class="math">\\mathcal{V}</span>  can pick a random point  <span class="math">z \\in \\mathbb{F}^{s_1}</span>  and evaluate  <span class="math">\\tilde{V}_1&#x27;(z)</span>  on her own in  <span class="math">O(S_1)</span>  time. An application of the Schwartz-Zippel Lemma (Lemma 1) implies that it is safe for  <span class="math">\\mathcal{V}</span>  to believe that  <span class="math">V_1</span>  is as claimed as long as  <span class="math">\\tilde{V}_1(z) = \\tilde{V}_1&#x27;(z)</span> . Our protocol as described in Section 5 would then proceed in iterations, with one iteration per layer of the circuit and one application of the sum-check protocol per iteration. This would ultimately reduce  <span class="math">\\mathcal{P}</span> 's claim about the value of  <span class="math">\\tilde{V}_1(z)</span>  to a claim about  <span class="math">\\tilde{V}_d(z&#x27;)</span>  for some  <span class="math">z&#x27; \\in \\mathbb{F}^{s_d}</span> , where d is the input layer of the circuit.</p>

    <p class="text-gray-300">Instead, our final refinement uses a single sum-check protocol to directly reduce  <span class="math">\\mathcal{P}</span> 's claim about  <span class="math">\\tilde{V}_1(z)</span>  to a claim about  <span class="math">\\tilde{V}_d(z&#x27;)</span>  for some random points  <span class="math">z&#x27; \\in \\mathbb{F}^{s_d}</span> .</p>

    <p class="text-gray-300"><strong>Proposition 7</strong> Let C be a depth-d circuit consisting of a binary tree of addition gates,  <span class="math">2^k</span>  inputs, and  <span class="math">2^{k-d}</span>  outputs. For any points  <span class="math">z \\in \\mathbb{F}^{k-d}</span> ,  <span class="math">\\tilde{V}_1(z) = \\sum_{p \\in \\{0,1\\}^k} g_z(p)</span> , where</p>

    <p class="text-gray-300">
<span class="math">$g_z(p) = \\tilde{V}_d(z, p_{k-d+1}, \\dots, p_k).</span>$</p>

    <p class="text-gray-300"><strong>Proof:</strong> At layer i of C, the gate with label  <span class="math">p \\in \\{0,1\\}^{s_i}</span>  is the sum of the gates with labels (p,0) and (p,1) at layer i+1. It is then straightforward to observe that the for any  <span class="math">p \\in \\{0,1\\}^{k-d}</span> , the pth output gate has value</p>

    <p class="text-gray-300"><span class="math">$V_1(p_1,\\ldots,p_{k-d}) = \\sum_{(p_{k-d+1},\\ldots,p_d)\\in\\{0,1\\}^d} \\tilde{V}_d(p_1,\\ldots,p_{k-d},p_{k-d+1},\\ldots,p_k).</span>$
(9)</p>

    <p class="text-gray-300">Notice that the right hand side of Equation (9) is a multilinear polynomial in the variables  <span class="math">(p_1, \\ldots, p_{k-d})</span>  that agrees with  <span class="math">V_1(p_1, \\ldots, p_{k-d})</span>  at all Boolean inputs. Hence, the right hand side is the (unique) multilinear extension  <span class="math">\\tilde{V}_1</span>  of the function  <span class="math">V_1: \\{0,1\\}^{k-d} \\to \\{0,1\\}</span> . The theorem follows.</p>

    <p class="text-gray-300">In applying the sum-check protocol to the polynomial  <span class="math">g_z</span>  in Proposition 7, it is straightforward to use the methods of Section 5.4.2 to implement the honest prover in time  <span class="math">O(2^k)</span> . We omit the details for brevity.</p>

    <p class="text-gray-300"><strong>Experimental Results.</strong> Let C be the circuit for naive matrix multiplication described in Section 5.5.1. To demonstrate the efficiency gains implied by Proposition 7, we modified our MATMULT implementation of Section 6.2.1 to use the protocol of Proposition 7 to verify the sub-circuit of C consisting of a binary tree of addition gates. The results are shown in Table 4. Our optimizations in this section shave P's runtime by a factor of 1.5x-2x, the total number of rounds by a factor of more than 5, and the total communication (not counting the cost of specifying the output of the circuit) by a factor of more than 5.</p>

      <h3 id="sec-8.2" class="text-xl font-semibold mt-8">8.2 Optimal Space and Time Costs for MATMULT</h3>

    <p class="text-gray-300">We describe a final optimization here on top of Proposition <a href="#page-36-0">7.</a> While this optimization is specific to the MAT-MULT problem, its effects are substantial and the underlying observation may be more broadly applicable.</p>

    <p class="text-gray-300">Suppose we are given an unverifiable algorithm for <em>n</em>&times;<em>n</em> matrix multiplication that requires time <em>T</em>(<em>n</em>) and space <em>s</em>(<em>n</em>). Our refinements reduce the prover's runtime from <em>O</em>(<em>n</em> 3 ) in the case of Sections <a href="#page-16-0">5</a> and <a href="#page-35-1">8.1</a> to <em>T</em>(<em>n</em>) + <em>O</em>(<em>n</em> 2 ), and lowers P's space requirement to <em>s</em>(<em>n</em>) + <em>o</em>(<em>n</em> 2 ). That is, in the protocol the prover sends the correct output and performs just <em>O</em>(<em>n</em> 2 ) more work to provide a guarantee of correctness on top. It is irrelevant what algorithm the prover uses to arrive at the correct output &ndash; in particular, algorithms much more sophisticated than naive matrix multiplication are permitted. This runtime and space usage for P are optimal even up to the leading constant assuming matrix multiplication cannot be computed in <em>O</em>(<em>n</em> 2 ) time.</p>

    <p class="text-gray-300">The final protocol is extremely natural, as it consists of a single invocation of the sum-check protocol. We believe this protocol is of interest in its own right. The proof and technical details are in Section <a href="#page-39-0">8.2.2.</a></p>

    <p class="text-gray-300">Theorem 3 <em>There is a valid interactive proof protocol for n</em>&times;<em>n matrix multiplication over the field</em> F<em><sup>q</sup> with the following costs. The communication cost is n</em><sup>2</sup> + <em>O</em>(log<em>n</em>) <em>field elements. The runtime of the prover is T</em>(<em>n</em>)+<em>O</em>(<em>n</em> 2 ) <em>and the space usage is s</em>(<em>n</em>)+<em>o</em>(<em>n</em> 2 )<em>, where T</em>(<em>n</em>) <em>and s</em>(<em>n</em>) <em>are the time and space requirements of any (unverifiable) algorithm for n</em> &times; <em>n matrix multiplication. The verifier can make a single streaming pass over the input as well as over the claimed output in time O</em>(<em>n</em> 2 log<em>n</em>)<em>, storing O</em>(log<em>n</em>) <em>field elements.</em></p>

    <p class="text-gray-300">Using the observation of Vu et al. described in Lemma <a href="#page-15-4">3,</a> the runtime of the verifier can be brought down to <em>O</em>(<em>n</em> 2 ) at the cost of increasing V's space usage to <em>O</em>(<em>n</em> 2 ). Furthermore, by Remark <a href="#page-16-3">1,</a> the runtime of the verifier can be brought down to <em>O</em>(<em>n</em> 2 ) while maintaining the streaming property if the input matrices are presented in row-major order.</p>

    <p class="text-gray-300">The prover's runtime in Theorem <a href="#page-37-2">3</a> is within an additive low-order term of any unverifiable algorithm for matrix multiplication; this is essential in many practical scenarios where even a 2x slowdown is too steep a price to pay for verifiability. Notice also that the space usage bounds in Theorem <a href="#page-37-2">3</a> are in stark contrast to protocols based on circuit-checking: the prover in a general circuit-checking protocol may have to store the entire circuit, and this can result in space requirements that are much larger than those of an unverifiable algorithm for the problem. For example, naive matrix multiplication requires time <em>O</em>(<em>n</em> 3 ), but only <em>O</em>(<em>n</em> 2 ) space, while the provers in our MATMULT protocols of Sections <a href="#page-16-0">5</a> and <a href="#page-35-1">8.1</a> require both space and time <em>O</em>(<em>n</em> 3 ). As implementations of interactive proofs become faster, the prover is likely to run out of space long before she runs out of time.</p>

      <h4 id="sec-8.2.1" class="text-lg font-semibold mt-6">8.2.1 Comparison to Prior Work</h4>

    <p class="text-gray-300">It is worth comparing Theorem <a href="#page-37-2">3</a> to a well-known protocol due to Freivalds <a href="#page-42-11">[17]</a>. Let <em>D</em> <sup>&lowast;</sup> denote the claimed output matrix. In Freivalds' algorithm, the verifier stores a random vector <em>x</em> &isin; F <em>n</em> , and computes <em>D</em> &lowast; <em>x</em> and <em>ABx</em>, accepting if and only if <em>ABx</em> = <em>D</em> &lowast; <em>x</em>. Freivalds showed that this is a valid protocol. In both Freivalds' protocol and that of Theorem <a href="#page-37-2">3,</a> the prover runs in time <em>T</em>(<em>n</em>) +<em>O</em>(<em>n</em> 2 ) (in the case of Freivalds' algorithm, the <em>O</em>(<em>n</em> 2 ) term is 0), and the verifier runs in linear or quasilinear time.</p>

    <p class="text-gray-300">We now highlight several properties of our protocol that are not achieved by prior work.</p>

    <p class="text-gray-300">Utility as a Primitive. A major advantage of Theorem <a href="#page-37-2">3</a> relative to prior work is its utility as a primitive that can be used to verify more complicated computations. This is important as many algorithms repeatedly invoke matrix multiplication as a subroutine. For concreteness, consider the problem of computing <em>A</em> 2 <em>k</em> via repeated squaring. By iterating the protocol of Theorem <a href="#page-37-2">3</a> <em>k</em> times, we obtain a valid interactive proof protocol for computing <em>A</em> 2 <em>k</em> with communication cost <em>n</em> <sup>2</sup> +<em>O</em>(<em>k</em> log(<em>n</em>)). The <em>n</em> 2 term is due simply to specifying the output <em>A</em> 2 <em>k</em> , and can often be avoided in applications &ndash; see for example the diameter protocol described two paragraphs hence. The <em>i</em>th iteration of the protocol for computing <em>A</em> 2 <em>k</em> reduces a claim about an evaluation of the multilinear extension of <em>A</em> 2 <em>k</em>&minus;<em>i</em>+1 to an analogous claim about <em>A</em> 2 <em>k</em>&minus;<em>i</em> . Crucially, the prover in this protocol never needs to send the verifier the intermediate matrices <em>A</em> 2 <em>k</em> 0 for <em>k</em> <sup>0</sup> &lt; <em>k</em>. In contrast, applying Freivalds' algorithm to this problem would require <em>O</em>(<em>kn</em><sup>2</sup> ) communication, as P must specify each of the intermediate matrices <em>A</em> 2 <em>i</em> .</p>

    <p class="text-gray-300">The ability to avoid having P explicitly send intermediate matrices is especially important in settings where an algorithm repeatedly invokes matrix multiplication, but the desired output of the algorithm is smaller than the size of the matrix. In these cases, it is not necessary for P to send <em>any</em> matrices; P can instead send just the desired output, and <em>V</em> can use Theorem <a href="#page-37-2">3</a> to check the validity of the output with only a polylogarithmic amount of additional communication. This is analogous to how the verifier in the GKR protocol can check the values of the output gates of a circuit without ever seeing the values of the &quot;interior&quot; gates of the circuit.</p>

    <p class="text-gray-300">As a concrete example illustrating the power of our matrix multiplication protocol, consider the fundamental problem of computing the diameter of an unweighted (possibly directed) graph <em>G</em> on <em>n</em> vertices. Let <em>A</em> denote the adjacency matrix of <em>G</em>, and let <em>I</em> denote the <em>n</em>&times;<em>n</em> identity matrix. Then it is easily verified that the diameter of <em>G</em> is the least positive number <em>d</em> such that (<em>A</em> + <em>I</em>) <em>d i j</em> 6= 0 for all (<em>i</em>, <em>j</em>). We therefore obtain the following natural protocol for diameter. P sends the claimed output <em>d</em> to <em>V</em>, as well as an (<em>i</em>, <em>j</em>) such that (<em>A</em> + <em>I</em>) <em>d</em>&minus;1 <em>i j</em> = 0. To confirm that <em>d</em> is the diameter of <em>G</em>, it suffices for V to check two things: first, that all entries of (<em>A</em>+<em>I</em>) <em>d</em> are non-zero, and second that (<em>A</em>+<em>I</em>) <em>d</em>&minus;1 <em>i j</em> is indeed non-zero.</p>

    <p class="text-gray-300">The first task is accomplished by combining our matrix multiplication protocol of Theorem <a href="#page-37-2">3</a> with our DISTINCT protocol from Theorem <a href="#page-24-1">1.</a> Indeed, let <em>d<sup>j</sup></em> denote the <em>j</em>th bit in the binary representation of <em>d</em>. Then (<em>A</em> + <em>I</em>) <em><sup>d</sup></em> = &prod; dlog<em>d</em>e <em>j</em> (<em>A</em> + <em>I</em>) <em>dj</em>2 <em>j</em> , so computing the number of non-zero entries of (<em>A</em> + <em>I</em>) <em>d</em> can be computed via a sequence of <em>O</em>(log<em>d</em>) matrix multiplications, followed by a DISTINCT computation. The second task, of verifying that (<em>A</em> + <em>I</em>) <em>d</em>&minus;1 <em>i j</em> = 0, is similarly accomplished using <em>O</em>(log<em>d</em>) invocations of the matrix multiplication protocol of Theorem <a href="#page-37-2">3</a> &ndash; since V is only interested in one entry of (<em>A</em>+<em>I</em>) <em>d</em>&minus;1 , P need not send the matrix (<em>A</em>+<em>I</em>) <em>d</em>&minus;1 in full, and the total communication here is just polylog(<em>n</em>).</p>

    <p class="text-gray-300">V's runtime in this diameter protocol is <em>O</em>(<em>m</em>log<em>n</em>), where <em>m</em> is the number of edges in <em>G</em>. P's runtime in the above diameter protocol matches the best known unverifiable diameter algorithm up to a low-order additive term <a href="#page-43-5">[33,</a> <a href="#page-43-6">42]</a>, and the communication is just polylog(<em>n</em>). We know of no other protocol achieving this.</p>

    <p class="text-gray-300">As discussed above, the fact that P's slowdown is a low-order additive term is critical in the many settings in which even a 2x slowdown to achieve verifiability is unacceptable. Moreover, for a graph with <em>n</em> = 1 million nodes, the total communication cost of the above protocol is on the order of KBs &ndash; in contrast, if P had to send the matrices (<em>I</em> + <em>A</em>) <em><sup>d</sup></em> or (<em>I</em> + <em>A</em>) <em>d</em>&minus;1 explicitly (as required in prior work e.g. Cormode et al. <a href="#page-42-3">[13]</a>), the communication cost would be at least <em>n</em> <sup>2</sup> = 10<sup>12</sup> words, which translates to terabytes of data.</p>

    <p class="text-gray-300">Small-Space Streaming Verifiers. In Freivalds' algorithm, V has the store the random vector <em>x</em>, which requires &Omega;(<em>n</em>) space. There are methods to reduce V's space usage by generating <em>x</em> with limited randomness: Kimbrel and Sinha <a href="#page-42-15">[26]</a> show how to reduce V's space to <em>O</em>(log<em>n</em>), but their solution does not work if V must make a streaming pass over arbitrarily ordered input. Chakrabarti et al. <a href="#page-41-0">[12]</a> extend the method of Kimbrel and Sinha to work with a streaming verifier, but this requires P to play back the input matrices <em>A</em>,<em>B</em> in a special order, increasing proof length to 3<em>n</em> 2 . Our protocol works with a streaming verifier using <em>O</em>(log<em>n</em>) space, and our proof length is <em>n</em> <sup>2</sup> +<em>O</em>(log<em>n</em>), where the <em>n</em> 2 term is due to specifying <em>AB</em> and can be avoided in applications such as the diameter example considered above.</p>

      <h4 id="sec-8.2.2" class="text-lg font-semibold mt-6">8.2.2 Protocol Details</h4>

    <p class="text-gray-300">The idea behind the optimization is as follows. All of our earlier circuit-checking protocols only make use of the multilinear extension  <span class="math">\\tilde{V}_i</span>  of the function  <span class="math">V_i</span>  mapping gate labels at layer i of the circuit to their values. In some cases, there is something to be gained by using a higher-degree extension of  <span class="math">V_i</span> , and this is precisely what we exploit here. By using a higher-degree extension of the gate values in the circuit, we are able to apply the sum-check protocol to a polynomial that differs from the one used in Section 5. In particular, the polynomial we use here avoids referencing the  <span class="math">\\beta_{s_i}</span>  polynomial used in Section 5. Details follow.</p>

    <p class="text-gray-300">When multiplying matrices A and B such that AB = D, let A(i,j), B(i,j) and D(i,j) denote functions from  <span class="math">\\{0,1\\}^{\\log n} \\times \\{0,1\\}^{\\log n} \\to \\mathbb{F}_q</span>  that map input (i,j) to  <span class="math">A_{ij}</span> ,  <span class="math">B_{ij}</span> , and  <span class="math">D_{ij}</span>  respectively. Let  <span class="math">\\tilde{A}</span> ,  <span class="math">\\tilde{B}</span> , and  <span class="math">\\tilde{D}</span>  denote their multilinear extensions.</p>

    <p class="text-gray-300"><strong>Lemma 5</strong> For all  <span class="math">(p_1, p_2) \\in \\mathbb{F}^{\\log n} \\times \\mathbb{F}^{\\log n}</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\tilde{D}(p_1,p_2) = \\sum_{p_3 \\in \\{0,1\\}^{\\log n}} \\tilde{A}(p_1,p_3) \\cdot \\tilde{B}(p_3,p_2)</span>$</p>

    <p class="text-gray-300"><strong>Proof:</strong> For all  <span class="math">(p_1, p_2) \\in \\{0, 1\\}^{\\log n} \\times \\{0, 1\\}^{\\log n}</span> , the right hand side is easily seen to equal  <span class="math">D(p_1, p_2)</span> , using the fact that  <span class="math">D_{ij} = \\sum_k A_{ik} B_{kj}</span>  and the fact that  <span class="math">\\tilde{A}</span>  and  <span class="math">\\tilde{B}</span>  agree with the functions A(i, j) and B(i, j) at all Boolean inputs. Moreover, the right hand side is a multilinear polynomial in the variables of  <span class="math">(p_1, p_2)</span> . Putting these facts together implies that the right hand side is the unique multilinear extension of the function D(i, j).</p>

    <p class="text-gray-300">Lemma 5 implies the following valid interactive proof protocol for matrix multiplication:  <span class="math">\\mathcal{P}</span>  sends a matrix  <span class="math">D^*</span>  claimed to equal the product D=AB.  <span class="math">\\mathcal{V}</span>  evaluates  <span class="math">\\tilde{D}^*(r_1,r_2)</span>  at a random point  <span class="math">(r_1,r_2)\\in\\mathbb{F}^{\\log n}\\times\\mathbb{F}^{\\log n}</span> . By the Schwartz-Zippel lemma, it is safe for  <span class="math">\\mathcal{V}</span>  to believe  <span class="math">D^*</span>  is as claimed, as long as  <span class="math">\\tilde{D}^*(r_1,r_2)=\\tilde{D}(r_1,r_2)</span>  (formally, if  <span class="math">D^*\\neq D</span> , then  <span class="math">\\tilde{D}^*(r_1,r_2)\\neq\\tilde{D}(r_1,r_2)</span>  with probability  <span class="math">1-2\\log n/q</span> ). In order to check that  <span class="math">\\tilde{D}^*(r_1,r_2)=\\tilde{D}(r_1,r_2)</span> , we invoke a sum-check protocol on the polynomial  <span class="math">g_{r_1,r_2}(p_3)=\\tilde{A}(r_1,p_3)\\cdot\\tilde{B}(p_3,r_2)</span> .  <span class="math">\\mathcal{V}</span> 's final check in this protocol requires her to compute  <span class="math">g_{r_1,r_2}(r_3)</span>  for a random point  <span class="math">r_3\\in\\mathbb{F}^{\\log n}</span> .  <span class="math">\\mathcal{V}</span>  can do this by evaluating both of  <span class="math">\\tilde{A}(r_1,r_3)</span>  and  <span class="math">\\tilde{B}(r_3,r_2)</span>  with a single streaming pass over the input, and then multiplying the results.</p>

    <p class="text-gray-300">The prover can be made to run in time  <span class="math">T(n) + O(n^2)</span>  across all rounds of the sum-check protocol using the  <span class="math">V^{(j)}</span>  arrays described in Section 5 to quickly evaluate  <span class="math">\\tilde{A}</span>  and  <span class="math">\\tilde{B}</span>  at all of the necessary points. The  <span class="math">V^{(j)}</span>  arrays are initialized in round 0 to equal the input matrices themselves, and there is no need for  <span class="math">\\mathcal{P}</span>  to maintain an &quot;uncorrupted&quot; copy of the original input (though in practice this may be desirable). Thus, the  <span class="math">V^{(j)}</span>  arrays can be computed using the storage  <span class="math">\\mathcal{P}</span>  initially devoted to the inputs, and  <span class="math">\\mathcal{P}</span>  needs to store just O(1) additional field elements over the course of the protocol ( <span class="math">\\mathcal{P}</span>  does not even need to store the messages sent by  <span class="math">\\mathcal{V}</span> , as  <span class="math">\\mathcal{P}</span>  need not refer to the jth message once the array  <span class="math">V^{(j)}</span>  is computed). The claimed  <span class="math">s(n) + o(n^2)</span>  space usage bound for  <span class="math">\\mathcal{P}</span>  follows.</p>

    <p class="text-gray-300"><strong>Remark 8</strong> Let C be the circuit for naive matrix multiplication described in Section 5. Notice that the  <span class="math">3 \\log n</span> -variate polynomial  <span class="math">h(p_1, p_2, p_3) = \\tilde{A}(p_1, p_3) \\cdot \\tilde{B}(p_3, p_2)</span>  extends the function  <span class="math">V_i</span>  mapping gate labels at layer  <span class="math">i = \\log n</span>  of C to their values. However, h is not the multilinear extension of  <span class="math">\\tilde{V}_i</span> , as h has degree two in the variables of  <span class="math">p_3</span> .</p>

    <p class="text-gray-300">Informally, Theorem 3 cannot be said to perform &quot;circuit checking&quot; on C, since it is not necessary for  <span class="math">\\mathcal P</span>  to evaluate all of the gates in C; indeed, the prover in Theorem 3 can run in sub-cubic time using fast matrix multiplication algorithms. However, the use of a low-degree extension of the gate values at layer  <span class="math">\\log n</span>  of C allows one to view the protocol of Theorem 3 as a direct extension of the circuit-checking methodology.</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Implementation</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Problem Size</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Naive Matrix Multiplication Time</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Additional Time for <span class="math">\\mathcal{P}</span></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"><span class="math">\\mathcal{V}</span> Time</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Rounds</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Theorem 3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">2^{10} \\times 2^{10}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2.17 s over <span class="math">\\mathbb{Z}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.03 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.67 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">11</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">9.11 s over <span class="math">\\mathbb{F}_q</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Theorem 3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">2^{11} \\times 2^{11}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">18.23 s over &#8484;</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.13 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2.89 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">12</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">73.65 s over <span class="math">\\mathbb{F}_q</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">Table 5: Experimental results for the  <span class="math">n \\times n</span>  MATMULT protocol of Theorem 3.</p>

    <p class="text-gray-300"><strong>Remark 9</strong> Consider the problem of computing a matrix power  <span class="math">M^{2^k}</span>  via repeated squaring. We may apply the protocol of Theorem 3 in k iterations, with the ith iteration applied to inputs  <span class="math">A = B = M^{2^{k-i}}</span> . The ith iteration of this protocol reduces a claim about an evaluation of the multilinear extension of  <span class="math">M^{2^{k-i+1}}</span>  to an analogous claim about the multilinear extension of  <span class="math">M^{2^{k-i}}</span>  at two points of the form  <span class="math">(r_1, r_3)</span> ,  <span class="math">(r_3, r_2) \\in \\mathbb{F}^{\\log n \\times \\log n}</span> . We can further reduce the claims about  <span class="math">(r_1, r_3)</span> ,  <span class="math">(r_3, r_2)</span>  to a claim about a single point exactly as in the &quot;Reducing to Verification of a Single Point&quot; step of the GKR protocol. We then move onto iteration i+1. Notice in particular that the verifier only needs to observe the output matrix  <span class="math">M^{2^k}</span>  and the input matrix M to run this protocol; in particular,  <span class="math">\\mathcal{P}</span>  does not need to explicitly send the intermediate matrices  <span class="math">M^{2^{k-i}}</span>  to  <span class="math">\\mathcal{V}</span> .</p>

    <p class="text-gray-300">We implemented the protocol just described (our implementation is sequential). The results are shown in Table 5, where the column labelled &quot;Additional Time for  <span class="math">\\mathcal{P}</span> &quot; denotes the time required to compute  <span class="math">\\mathcal{P}</span> 's prescribed messages after  <span class="math">\\mathcal{P}</span>  has already computed the correct answer. We report the naive matrix multiplication time both when the computation is done using standard multiplication of 64-bit integers, as well as when the computation is done using finite field arithmetic over the field with  <span class="math">q=2^{61}-1</span>  elements. The reported verifier runtime is for the  <span class="math">O(n^2\\log n)</span>  time reported in Theorem 3. The verifier's runtime could be improved using Lemma 3 at the cost of increasing  <span class="math">\\mathcal{V}</span> 's space usage to O(n), but we did not implement this optimization. Moreover, if the input matrices are presented in row-major order, then the observation of Vu et al. described in Remark 1 improves  <span class="math">\\mathcal{V}</span> 's runtime with no increase in space usage.</p>

    <p class="text-gray-300">The main takeaways from Table 5 are that the verifier does indeed save substantial time relative to performing matrix multiplication locally, and that the runtime of the prover is hugely dominated by the time required simply to compute the answer.</p>

    </section>

    <section id="sec-9" class="mb-10">
      <h2 class="text-2xl font-bold">9 Conclusion</h2>

    <p class="text-gray-300">We believe our results substantially advance the goal of achieving a truly practical general purpose implementation of interactive proofs. The  <span class="math">O(\\log S(n))</span>  factor overhead in the runtime of the prover within prior implementations of the GKR protocol is too steep a price to pay in practice, and our refinements (formalized in Theorem 1) remove this logarithmic factor overhead for circuits with regular wiring patterns. Our experiments demonstrate that this protocols yields a prover that is less than 10x slower than a C++ program that simply evaluates the circuit, and that our protocols are highly amenable to parallelization. Exploiting similar ideas, we have also extended the reach of prior interactive proof protocols by describing an efficient protocol (formalized in Theorem 2) for general data parallel computation, and given a protocol for matrix multiplication in which the prover's overhead (relative to <em>any</em> unverifiable algorithm) is just a low-order additive term. The latter is a powerful primitive for verifying the many algorithms that repeatedly invoke matrix multiplication. A major message of our results is that the more structure that exists in a computation, the more efficiently it can be verified, and that this structure exists in many real-world computations.</p>

    <p class="text-gray-300">We believe two directions in particular are worthy of future work. The first direction is to build a full-fledged system implementing our protocol for data parallel computation. Our vision is to combine our</p>

    <p class="text-gray-300">protocol with a high-level programming language allowing the programmer to easily specify data parallel computations, analogous to frameworks such as MapReduce. Any such program could be automatically compiled in the manner of Vu et al. <a href="#page-43-1">[40]</a> into a circuit, and our protocol could be run automatically on that circuit. The second direction is to further enable such a compiler to automatically take advantage of our other refinements, which are targeted at computations that are not necessarily data parallel. These refinements apply to a circuit on a layer-by-layer basis, so they may yield substantial speedups in practice even if they apply only to a subset of the layers of a circuit.</p>

    <p class="text-gray-300">Acknowledgements. The author is grateful to Frank McSherry for raising the question of outsourcing general data parallel computations, and to Michael Mitzenmacher and Graham Cormode for discussions and feedback that greatly improved the quality of this manuscript.</p>

    </section>

    <section id="references" class="mb-10">
      <h2 class="text-2xl font-bold">References</h2>

    <ul class="space-y-2 text-gray-400 text-sm list-none">
      <li><p class="text-gray-300">[1] S. Arora and B. Barak. <em>Computational Complexity: A Modern Approach</em>. Cambridge University Press, 2009.</p></li>
      <li><p class="text-gray-300">[2] S. Benabbas, R. Gennaro, Y. Vahlis. Verifiable delegation of computation over large datasets. In <em>CRYPTO</em>, pages 111-131, 2011.</p></li>
      <li><p class="text-gray-300">[3] E. Ben-Sasson, A. Chiesa, D. Genkin, and E. Tromer. Fast reductions from RAMs to delegatable succinct constraint satisfaction problems. In <em>ITCS</em>, pages 401-414, 2013.</p></li>
      <li><p class="text-gray-300">[4] E. Ben-Sasson, A. Chiesa, D. Genkin, and E. Tromer. On the concrete-efficiency threshold of probabilistically-checkable proofs. In <em>STOC</em>, 2013.</p></li>
      <li><p class="text-gray-300">[5] D. Boneh and D. Freeman. Homomorphic signatures for polynomial functions. In <em>EUROCRYPT</em>, pages 149-168, 2011.</p></li>
      <li><p class="text-gray-300">[6] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer. From extractable collision resistance to succinct non-interactive arguments of knowledge, and back again. In <em>ITCS</em>, pages 326-349, 2012.</p></li>
      <li><p class="text-gray-300">[7] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer. Recursive composition and bootstrapping for SNARKs and proof-carrying data. In <em>STOC</em>, 2013.</p></li>
      <li><p class="text-gray-300">[8] N. Bitansky, and A. Chiesa. Succinct arguments from multi-prover interactive proofs and their efficiency benefits. In <em>CRYPTO</em>, pages 255-272, 2012.</p></li>
      <li><p class="text-gray-300">[9] N. Bitansky, A. Chiesa, Y. Ishai, R. Ostrovsky, and O. Paneth. Succinct non-interactive arguments via linear interactive proofs. In <em>TCC</em>, pages 315-333, 2013.</p></li>
      <li><p class="text-gray-300">[10] K-M. Chung, Y. Tauman Kalai, F-H. Liu, R. Raz. Memory delegation. In <em>CRYPTO</em>, pages 151-168, 2011.</p></li>
      <li><p class="text-gray-300">[11] K-M. Chung, Y. Tauman Kalai, and S. P. Vadhan. Improved delegation of computation using fully homomorphic encryption. In <em>CRYPTO</em>, pages 483-501, 2010.</p></li>
      <li><p class="text-gray-300">[12] A. Chakrabarti, G. Cormode, A. McGregor, and J. Thaler. Annotations in data streams. <em>Electronic Colloquium on Computational Complexity (ECCC)</em>, 19:22, 2012. A preliminary version of this paper by A. Chakrabarti, G. Cormode, and A. McGregor appeared in <em>ICALP</em> 2009.</p></li>
      <li><p class="text-gray-300">[13] G. Cormode, M. Mitzenmacher, and Justin Thaler. Streaming graph computations with a helpful advisor. <em>Algorithmica</em>, 65(2):409-442, 2013.</p></li>
      <li><p class="text-gray-300">[14] G. Cormode, M. Mitzenmacher, and J. Thaler. Practical verified computation with streaming interactive proofs. In <em>ITCS</em>, pages 90-112, 2012.</p></li>
      <li><p class="text-gray-300">[15] G. Cormode, J. Thaler, and K. Yi. Verifying computations with streaming interactive proofs. <em>PVLDB</em>, 5(1):25&ndash;36, 2011.</p></li>
      <li><p class="text-gray-300">[16] D. Fiore, R. Gennaro. Publicly verifiable delegation of large polynomials and matrix computations, with applications. In <em>CCS</em>, pages 501-512, 2012.</p></li>
      <li><p class="text-gray-300">[17] R. Freivalds. Fast probabilistic algorithms. In <em>MFCS</em>, pages 57&ndash;69, 1979.</p></li>
      <li><p class="text-gray-300">[18] R. Gennaro, C. Gentry, and B. Parno. Non-interactive verifiable computing: outsourcing computation to untrusted workers. In <em>CRYPTO</em>, pages 465-482, 2010.</p></li>
      <li><p class="text-gray-300">[19] R. Gennaro, C. Gentry, B. Parno, and M. Raykova. Quadratic span programs and succint NIZKs without PCPs. In <em>EUROCRYPT</em>, pages 626-645, 2013.</p></li>
      <li><p class="text-gray-300">[20] C. Gentry. A fully homomorphic encryption scheme. PhD thesis, Stanford University, 2009.</p></li>
      <li><p class="text-gray-300">[21] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum. Delegating computation: interactive proofs for muggles. In <em>STOC</em>, pages 113&ndash;122, 2008.</p></li>
      <li><p class="text-gray-300">[22] J. Groth. Short pairing-based non-interactive zero-knowledge arguments. In <em>ASIACRYPT</em>, pages 321- 340, 2010.</p></li>
      <li><p class="text-gray-300">[23] T. Gur and R. Raz Arthur-Merlin Streaming Complexity. In <em>ICALP (1)</em>, 2013.</p></li>
      <li><p class="text-gray-300">[24] J. Hoberock and N. Bell. Thrust: A parallel template library, 2011. Version 1.3.0.</p></li>
      <li><p class="text-gray-300">[25] Y. Ishai, E. Kushilevitz, and R. Ostrovsky. Efficient arguments without short PCPs. In <em>CCC</em>, pages 278&ndash;291, 2007.</p></li>
      <li><p class="text-gray-300">[26] T. Kimbrel and R. K. Sinha. A probabilistic algorithm for verifying matrix products Using O(n<sup>2</sup> ) time and log<sup>2</sup> <em>n</em>+<em>O</em>(1) random bits. <em>Inf. Process. Lett.</em> 45(2):107-110, 1993.</p></li>
      <li><p class="text-gray-300">[27] H. Klauck, and V. Prakash. Streaming computations with a loquacious prover. In <em>ITCS</em>, pages 305-320, 2013.</p></li>
      <li><p class="text-gray-300">[28] H. Lipmaa. Progression-free sets and sublinear pairing-based non-interactive zero- knowledge arguments. In <em>TCC</em>, pages 169-189, 2012.</p></li>
      <li><p class="text-gray-300">[29] C. Lund, L. Fortnow, H. Karloff, and N. Nisan. Algebraic methods for interactive proof systems. <em>J. ACM</em>, 39:859&ndash;868, 1992.</p></li>
      <li><p class="text-gray-300">[30] B. Parno, C. Gentry, J. Howell, and M. Raykova. Pinocchio: nearly practical verifiable computation. In <em>IEEE Symposium on Security and Privacy (Oakland)</em>, 2013.</p></li>
      <li><p class="text-gray-300">[31] G. Rothblum. Delegating computation reliably : paradigms and constructions. Ph.D. Thesis. Available online at http://hdl.handle.net/1721.1/54637, 2009.</p></li>
      <li><p class="text-gray-300">[32] J. Schwartz. Fast probabilistic algorithms for verification of polynomial identities. <em>J. ACM</em>, 27(4):701-717, 1980.</p></li>
      <li><p class="text-gray-300">[33] R. Seidel. On the all-pairs-shortest-path problem in unweighted undirected graphs. <em>JCSS</em>, 51(3):400-403, 1995.</p></li>
      <li><p class="text-gray-300">[34] S. Setty, R. McPherson, A. J. Blumberg, and M. Walfish. Making argument systems for outsourced computation practical (sometimes). In <em>NDSS</em>, 2012.</p></li>
      <li><p class="text-gray-300">[35] S. Setty, V. Vu, N. Panpalia, B. Braun, A. J. Blumberg, and M. Walfish. Taking proof-based verified computation a few steps closer to practicality. In <em>USENIX Security</em>, 2012.</p></li>
      <li><p class="text-gray-300">[36] S. Setty, B. Braun, V. Vu, A. J. Blumberg, B. Parno, and M. Walsh. Resolving the conflict between generality and plausibility in verified computation. In <em>EuroSys</em>, pages 71-84, 2013.</p></li>
      <li><p class="text-gray-300">[37] A. Shamir. IP = PSPACE. J. ACM, 39:869&ndash;877, October 1992.</p></li>
      <li><p class="text-gray-300">[38] J. Thaler, M. Roberts, M. Mitzenmacher, and H. Pfister. Verifiable computation with massively parallel interactive proofs. <em>In USENIX Workshop on Hot Topics in Cloud Computing (HotCloud)</em>, 2012.</p></li>
      <li><p class="text-gray-300">[39] Justin Thaler. Source Code for Time-Optimal interactive proofs for circuit evaluation. Available online at http://http://people.seas.harvard.edu/~jthaler/Tcode.htm</p></li>
      <li><p class="text-gray-300">[40] V. Vu, S. Setty, A. J. Blumberg, and M. Walfish. A hybrid architecture for interactive verifiable computation. Pre-print, November 2012. In <em>IEEE Symposium on Security and Privacy (Oakland)</em>, May 2013.</p></li>
      <li><p class="text-gray-300">[41] V. Vu, S. Setty, A. J. Blumberg, and M. Walfish. Personal Communication, January 2013.</p></li>
      <li><p class="text-gray-300">[42] R. Yuster, Computing the diameter polynomially faster than APSP. CoRR, Vol. abs/1011.6181, 2010.</p></li>
    </ul>

    </section>

    <section id="app-a" class="mb-10">
      <h2 class="text-2xl font-bold">A Proof of Theorem 1</h2>

    <p class="text-gray-300"><strong>Proof:</strong> Consider layer i of the circuit C. Since  <span class="math">\\operatorname{in}_1^{(i)}</span>  and  <span class="math">\\operatorname{in}_2^{(i)}</span>  are regular, there is a subset of input bits  <span class="math">S_i \\subseteq [v]</span>  with  <span class="math">|S_i| = c_i</span>  for some constant  <span class="math">c_i</span>  such that each input bit in  <span class="math">[v] \\setminus S</span>  affects O(1) of the output bits of  <span class="math">\\operatorname{in}_1^{(i)}</span>  and  <span class="math">\\operatorname{in}_2^{(i)}</span> . Number the input variables so that the numbers  <span class="math">\\{1, \\ldots, c_i\\}</span>  correspond to variables in  <span class="math">S_i</span> .</p>

    <p class="text-gray-300">Let  <span class="math">\\rho \\in \\{0,1\\}^{c_i}</span>  be an assignment to the variables in  <span class="math">\\mathcal{S}</span> , and let  <span class="math">I_{\\rho}: \\{0,1\\}^{s_i} \\to \\{0,1\\}</span>  denote the indicator function for  <span class="math">\\rho</span> . For example, if  <span class="math">c_i = 3</span>  and  <span class="math">\\rho = (1,0,1)</span> , then  <span class="math">I_{\\rho}(x) = 1</span>  if  <span class="math">x_1 = 1, x_2 = 0</span> , and  <span class="math">x_3 = 1</span> , and  <span class="math">I_{\\rho}(x) = 0</span>  otherwise. Let  <span class="math">\\tilde{I}_{\\rho}</span>  denote the multilinear extension of  <span class="math">I_{\\rho}</span> . In the previous example,  <span class="math">\\tilde{I}_{\\rho} = x_1(1-x_2)x_3</span> . Finally, let  <span class="math">\\inf_{1,\\rho}^{(i)}</span>  and  <span class="math">\\inf_{2,\\rho}^{(i)}</span>  denote the functions  <span class="math">\\inf_{1}^{(i)}</span>  and  <span class="math">\\inf_{2}^{(i)}</span>  with the variables in  <span class="math">\\mathcal{S}_i</span>  fixed to the assignment  <span class="math">\\rho</span> , and for  <span class="math">k \\in \\{1,2\\}</span> , let  <span class="math">b_{\\rho,k,j}</span>  denote the jth output bit of  <span class="math">\\inf_{k,\\rho}^{(i)}</span> .</p>

    <p class="text-gray-300">By regularity, for each assignment  <span class="math">\\rho \\in \\{0,1\\}^{c_i}</span>  to the variables in  <span class="math">\\mathcal{S}_i</span> , the jth output bit  <span class="math">b_{\\rho,k,j}</span>  of  <span class="math">\\operatorname{in}_{\\rho}^k</span>  depends on only one variable  <span class="math">x_{q(\\rho,k,j)} \\in [s_i] \\setminus \\mathcal{S}_i</span>  for some function  <span class="math">q(\\rho,k,j)</span> . Let  <span class="math">\\tilde{b}_{\\rho,k,j}(x_{q(\\rho,k,j)}) : \\mathbb{F} \\to \\mathbb{F}</span>  denote the multilinear extension of the function  <span class="math">b_{\\rho,k,j}(x_{q(\\rho,k,j)}) : \\{0,1\\} \\to \\{0,1\\}</span> . If  <span class="math">b_{\\rho,k,j}</span>  is not identically 0 or identically 1, then either  <span class="math">\\tilde{b}_{\\rho,k,j}(x_{q(\\rho,k,j)}) = x_{q(\\rho,k,j)}</span>  or  <span class="math">\\tilde{b}_{\\rho,k,j} = 1 - x_{q(\\rho,k,j)}</span> .</p>

    <p class="text-gray-300">For any  <span class="math">\\rho \\in \\{0,1\\}^{s_i}</span> , define  <span class="math">\\tilde{\\operatorname{in}}_{1,\\rho}^{(i)}</span>  to be the concatenation of the  <span class="math">\\tilde{b}_{\\rho,1,j}</span>  functions for all  <span class="math">j \\in [s_{i+1}]</span> . Under this definition,  <span class="math">\\tilde{\\operatorname{in}}_{1,\\rho}^{(i)}</span>  is a collection of  <span class="math">s_{i+1}</span>  linear polynomials, where each of the polynomials depends on a</p>

    <p class="text-gray-300">single variable, and we may view  <span class="math">\\tilde{\\text{in}}_{1,\\rho}^{(i)}</span>  as a single function mapping  <span class="math">\\mathbb{F}^{s_i}</span>  to  <span class="math">\\mathbb{F}^{s_{i+1}}</span> . We define  <span class="math">\\tilde{\\text{in}}_{2,\\rho}^{(i)}</span>  and  <span class="math">\\tilde{\\text{type}}_{\\rho}^{(i)}</span>  analogously to  <span class="math">\\tilde{\\text{in}}_1</span> .</p>

    <p class="text-gray-300">Now let</p>

    <p class="text-gray-300"><span class="math">$W^{(i)}(p) =</span>$</p>

    <p class="text-gray-300"><span class="math">$\\sum_{\\boldsymbol{\\rho} \\in L^{(i)}} \\tilde{I}_{\\boldsymbol{\\rho}}(\\boldsymbol{p}) \\cdot \\left( \\operatorname{ty\\tilde{p}e}_{\\boldsymbol{\\rho}}^{(i)}\\left(\\boldsymbol{p}\\right) \\cdot \\tilde{V}_{i+1}\\left( \\tilde{\\operatorname{in}}_{1,\\boldsymbol{\\rho}}^{(i)}\\left(\\boldsymbol{p}\\right) \\right) \\cdot \\tilde{V}_{i+1}\\left( \\tilde{\\operatorname{in}}_{2,\\boldsymbol{\\rho}}^{(i)}\\left(\\boldsymbol{p}\\right) \\right) + \\left( 1 - \\operatorname{ty\\tilde{p}e}_{\\boldsymbol{\\rho}}^{\\phantom{(i)}\\left(\\boldsymbol{p}\\right)}\\left(\\boldsymbol{p}\\right) \\right) \\left( \\tilde{V}_{i+1}\\left( \\tilde{\\operatorname{in}}_{1,\\boldsymbol{\\rho}}^{\\left(i\\right)}\\left(\\boldsymbol{p}\\right) \\right) + \\tilde{V}_{i+1}\\left( \\tilde{\\operatorname{in}}_{2,\\boldsymbol{\\rho}}^{\\left(i\\right)}\\left(\\boldsymbol{p}\\right) \\right) \\right) \\right).</span>$</p>

    <p class="text-gray-300">It is easily checked that for all  <span class="math">p \\in \\{0,1\\}^{s_i}</span> ,  <span class="math">V_i(p) = W^{(i)}(p)</span> . Lemma 4 then implies that  <span class="math">\\tilde{V}_i(z) = \\sum_{p \\in \\{0,1\\}^{s_i}} g_z^{(i)}(p)</span> , where  <span class="math">g_z^{(i)}(p) = \\beta_{s_i}(z,p) \\cdot W^{(i)}(p)</span> . Our protocol follows precisely the description of Section 5.1, with  <span class="math">\\mathcal{P}</span>  and  <span class="math">\\mathcal{V}</span>  applying the sum-check protocol to the polynomial  <span class="math">g_z^{(i)}</span>  at iteration i.</p>

    <p class="text-gray-300"><strong>Communication Costs and Costs to</strong>  <span class="math">\\mathcal{V}</span> . Notice that our polynomial  <span class="math">g_z^{(i)}(p) = \\beta(z,p) \\cdot W^{(i)}(p)</span>  has degree O(1) in each variable. Indeed,  <span class="math">\\beta(z,p)</span>  has degree 1 in each variable. Moreover,  <span class="math">W^{(i)}(p)</span>  is a sum of polynomials that each have degree O(1) in each variable, and hence  <span class="math">W^{(i)}(p)</span>  itself has degree O(1) in each variable.</p>

    <p class="text-gray-300">This latter fact can be seen by observing that for each assignment  <span class="math">\\rho \\in \\{0,1\\}^{c_i}</span>  to the variables in  <span class="math">\\mathcal{S}_i</span> , it holds that  <span class="math">\\tilde{I}_{\\rho}(p)</span> ,  <span class="math">\\operatorname{type}_{\\rho}^{(i)}(p)</span> ,  <span class="math">\\tilde{V}_{i+1}\\left(\\operatorname{in}_{1,\\rho}^{(i)}(p)\\right)</span>  and  <span class="math">\\tilde{V}_{i+1}\\left(\\operatorname{in}_{2,\\rho}^{(i)}(p)\\right)</span>  all have constant degree in each variable. That  <span class="math">\\tilde{V}_{i+1}\\left(\\operatorname{in}_{1,\\rho}^{(i)}(p)\\right)</span>  and  <span class="math">\\tilde{V}_{i+1}\\left(\\operatorname{in}_{2,\\rho}^{(i)}(p)\\right)</span>  have constant degree in each variable follows from the facts that  <span class="math">\\tilde{V}_{i+1}</span>  is a multilinear polynomial, and that each input variable  <span class="math">j \\in [s_i] \\setminus \\mathcal{S}_i</span>  affects at most a constant number of outputs for  <span class="math">\\operatorname{in}_{1,\\rho}</span>  and  <span class="math">\\operatorname{in}_{2,\\rho}</span>  by Property 1 of Definition 3.</p>

    <p class="text-gray-300">Since  <span class="math">g_z^{(i)}(p)</span>  has degree O(1) in each variable, the claimed communication cost and the costs to the verifier follow immediately by summing the corresponding costs of the sum-check protocols over all iterations  <span class="math">i \\in \\{1, ..., d(n)\\}</span>  (see Section 4.2).</p>

    <p class="text-gray-300"><strong>Time Cost for</strong>  <span class="math">\\mathcal{P}</span> . It remains to demonstrate how  <span class="math">\\mathcal{P}</span>  can compute her prescribed messages when applying the sum-check protocol to the polynomial  <span class="math">g_z^{(i)}</span>  in time  <span class="math">O(S_i + S_{i+1})</span> . It will follow that  <span class="math">\\mathcal{P}</span> 's runtime over all d(n) invocations of the sum-check protocol is  <span class="math">O(\\sum_{i=1}^{d(n)} S_i) = O(S(n))</span> .</p>

    <p class="text-gray-300">As in our analysis of Section 5.4, it suffices to show how  <span class="math">\\mathcal{P}</span>  can quickly evaluate  <span class="math">g_z^{(i)}</span>  at all points in  <span class="math">S^{(j)}</span> , where  <span class="math">S^{(j)}</span>  consists of all points of the form  <span class="math">p=(r_1,\\ldots,r_{j-1},t,p_{j+1},\\ldots,p_{s_i})</span>  with  <span class="math">t\\in\\{0,1,\\ldots,\\deg_j(g_z^{(i)})\\}</span>  and  <span class="math">(p_{j+1},\\ldots,p_{s_i})\\in\\{0,1\\}^{s_i-j}</span> . As  <span class="math">g_z^{(i)}(p)=\\beta_{s_i}(z,p)\\cdot W^{(i)}(p)</span> , it suffices for  <span class="math">\\mathcal{P}</span>  to evaluate  <span class="math">\\beta_{s_i}(z,\\cdot)</span>  and  <span class="math">W(\\cdot)</span>  at all such points p. The  <span class="math">\\beta_{s_i}(z,\\cdot)</span>  computations can be done in  <span class="math">O(S_i)</span>  total time across all iterations of the sum-check protocol, exactly as in Section 5.4.1.</p>

    <p class="text-gray-300">To see how  <span class="math">\\mathcal{P}</span>  can efficiently evaluate all of the  <span class="math">W^{(i)}(p)</span>  values efficiently, notice that for any fixed point  <span class="math">p \\in \\mathbb{F}^{s_i}</span> ,  <span class="math">W^{(i)}(p)</span>  can be computed efficiently given  <span class="math">\\operatorname{type}_{\\rho}^{(i)}(p)</span> ,  <span class="math">\\tilde{V}_{i+1}(\\tilde{\\operatorname{in}}_{1,\\rho}(p))</span> , and  <span class="math">\\tilde{V}_{i+1}(\\tilde{\\operatorname{in}}_{2,\\rho}(p))</span>  for all  <span class="math">\\rho \\in \\{0,1\\}^{c_i}</span> . As  <span class="math">|\\mathcal{S}_i| = c_i = O(1)</span> , modulo a constant-factor blowup in runtime it suffices to explain how to perform these evaluations for a fixed restriction  <span class="math">\\rho \\in \\{0,1\\}^{c_i}</span>  to the variables in  <span class="math">\\mathcal{S}_i</span> .</p>

    <p class="text-gray-300">It is easy to see that  <span class="math">t\\tilde{ype}_{\\rho}^{(i)}(p)</span>  can be evaluated in constant time, since this function depends on only 1 input variable  <span class="math">x_{q(\\rho,3,1)}</span> . All that remains is to show how  <span class="math">\\mathcal{P}</span>  can evaluate  <span class="math">\\tilde{V}_{i+1}(\\tilde{in}_{1,\\rho}(p))</span>  quickly; the case for  <span class="math">\\tilde{V}_{i+1}(\\tilde{in}_{2,\\rho}(p))</span>  is similar.</p>

    <p class="text-gray-300">To this end, we follow the approach of Section 5.4.2.</p>

    <p class="text-gray-300"><em>Pre-processing.</em>  <span class="math">\\mathcal{P}</span>  will begin by computing an array  <span class="math">V^{(0)}</span> , which is simply defined to be the vector of gate values at layer i+1 i.e., identifying a number  <span class="math">0 &lt; j &lt; S_{i+1}</span>  with its binary representation in  <span class="math">\\{0,1\\}^{s_{i+1}}</span> ,  <span class="math">\\mathcal{P}</span>  sets  <span class="math">V^{(0)}[(j_1,\\ldots,j_{s_{i+1}})] = V_{i+1}(j_1,\\ldots,j_{s_{i+1}})</span>  for each  <span class="math">(j_1,\\ldots,j_{s_{i+1}}) \\in \\{0,1\\}^{s_{i+1}}</span> . The right hand side of this equation is simply the value of the jth gate at layer i+1 of C. So  <span class="math">\\mathcal{P}</span>  can fill in the array  <span class="math">V^{(0)}</span>  when she evaluates the circuit C, before receiving any messages from  <span class="math">\\mathcal{V}</span> .</p>

    <p class="text-gray-300">Overview of Online Processing. Assume without loss of generality that the output bits of  <span class="math">\\tilde{\\text{in}}_{1,\\rho}(p)</span>  are labelled in increasing order of the input bits they are affected by. So for example if  <span class="math">p_1</span>  affects 2 output bits of  <span class="math">\\tilde{\\text{in}}_{1,\\rho}</span>  and  <span class="math">p_2</span>  affects 3 output bits, then the bits affected by  <span class="math">p_1</span>  are labelled 1 and 2 respectively, while the bits affected by  <span class="math">p_2</span>  are labelled 3, 4, and 5.</p>

    <p class="text-gray-300">In round j of of the sum-check protocol,  <span class="math">\\mathcal{P}</span>  needs to evaluate the polynomial  <span class="math">\\tilde{V}_{i+1}</span>  at the  <span class="math">O(2^{s_{i+1}-j})</span>  points in the sets  <span class="math">\\tilde{\\text{in}}_{1,\\rho}(S^{(j)})</span>  and  <span class="math">\\tilde{\\text{in}}_{2,\\rho}(S^{(j)})</span> .  <span class="math">\\mathcal{P}</span>  will do this using the help of intermediate arrays as follows.</p>

    <p class="text-gray-300">Efficiently Constructing  <span class="math">V^{(j)}</span>  Arrays. Let  <span class="math">a_{j-1}</span>  denote the total number of output bits affected by the first j-1 input variables. Inductively, assume  <span class="math">\\mathcal{P}</span>  has computed in the previous round an array  <span class="math">V^{(j-1)}</span>  of length  <span class="math">2^{s_{i+1}-a_{j-1}}</span> , such that for each  <span class="math">p=(p_{a_{i-1}+1},\\ldots,p_{s_{i+1}})\\in\\{0,1\\}^{s_{i+1}-a_{j-1}}</span> , the pth entry of  <span class="math">V^{(j-1)}</span>  equals</p>

    <p class="text-gray-300"><span class="math">$V^{(j-1)}[(p_{a_{j-1}+1},\\ldots,p_{s_{i+1}})] = \\sum_{(c_1,\\ldots,c_{a_{j-1}})\\in\\{0,1\\}^{a_{j-1}}} V_{i+1}(c_1,\\ldots,c_{a_{j-1}},p_{a_{j-1}+1},\\ldots,p_{s_{i+1}}) \\cdot \\prod_{k=1}^{j-1} \\chi_{c_k}(\\tilde{b}_{\\rho,1,k}(r_{q(\\rho,1,k)})),</span>$</p>

    <p class="text-gray-300">where recall that  <span class="math">q(\\rho, 1, k)</span>  is the input bit that output bit k of  <span class="math">\\text{in}_{1,\\rho}</span>  depends on. As the base case, we explained how  <span class="math">\\mathcal{P}</span>  can fill in  <span class="math">V^{(0)}</span>  in the process of evaluating the circuit C.</p>

    <p class="text-gray-300">Let  <span class="math">x_1, \\ldots, x_{s_i}</span>  denote the input variables to in<sub>1</sub>, and let  <span class="math">b_1, \\ldots, b_{s_{i+1}}</span>  denote the outputs of in<sub>1</sub>. Intuitively, at the end of round j of the sum-check protocol,  <span class="math">\\mathcal{P}</span>  must &quot;bind&quot; input variable  <span class="math">x_j</span>  to value  <span class="math">r_j \\in \\mathbb{F}</span> . This has the effect of binding the output variables affected by  <span class="math">x_j</span> , since each such output variable depends only on  <span class="math">x_j</span> . For illustration, suppose the variable  <span class="math">x_1</span>  affects output variable  <span class="math">b_1</span> ; specifically, suppose that  <span class="math">b_1 = 1 - x_1</span> . Then binding  <span class="math">x_1</span>  to value  <span class="math">r_1</span>  has the effect of binding  <span class="math">b_1</span>  to value  <span class="math">1 - r_1</span> .  <span class="math">V^{(j)}</span>  is obtained from  <span class="math">V^{(j-1)}</span>  by taking this into account. We formalize this as follows.</p>

    <p class="text-gray-300">Assume that variable  <span class="math">x_j</span>  affects only one output variable  <span class="math">b_{\\rho,1,a_{j-1}+1}</span> , and thus  <span class="math">a_j=a_{j-1}+1</span> ; if this is not the case, we can compute  <span class="math">V^{(j)}</span>  by applying the following update once for each output variable affected by  <span class="math">x_j</span> . Observe that  <span class="math">\\mathcal{P}</span>  can compute  <span class="math">V^{(j)}</span>  given  <span class="math">V^{(j-1)}</span>  in  <span class="math">O(2^{s_{i+1}-a_{j-1}})</span>  time using the following recurrence:</p>

    <p class="text-gray-300"><span class="math">$V^{(j)}[(p_{a_j+1},\\ldots,p_{s_{i+1}})] = V^{(j-1)}[(0,p_{a_j+1},\\ldots,p_{s_{i+1}})] \\cdot \\chi_0(\\tilde{b}_{\\rho,1,a_j}(r_j)) + V^{(j-1)}[(1,p_{a_j+1},\\ldots,p_{s_{i+1}})] \\cdot \\chi_1(\\tilde{b}_{\\rho,1,a_j}(r_j)).</span>$</p>

    <p class="text-gray-300">Thus, at the end of round j of the sum-check protocol, when  <span class="math">\\mathcal{V}</span>  sends  <span class="math">\\mathcal{P}</span>  the value  <span class="math">r_j</span> ,  <span class="math">\\mathcal{P}</span>  can compute  <span class="math">V^{(j)}</span>  from  <span class="math">V^{(j-1)}</span>  in  <span class="math">O(2^{s_{i+1}-a_{j-1}})</span>  time.</p>

    <p class="text-gray-300">Using the  <span class="math">V^{(j)}</span>  Arrays. We now show how to use the array  <span class="math">V^{(j-1)}</span>  to evaluate  <span class="math">\\tilde{V}_{i+1}(\\tilde{\\text{in}}_{1,\\rho}(p))</span>  in constant time for any point p of the form  <span class="math">p=(r_1,\\ldots,r_{j-1},t,p_{j+1},\\ldots,p_{s_i})</span>  with  <span class="math">(p_{j+1},\\ldots,p_{s_i})\\in\\{0,1\\}^{s_i-j}</span> . In order to ease notation in the following derivation, we make the simplifying assumption that  <span class="math">\\tilde{b}_{\\rho,1,k}(x_{q(\\rho,1,k)})=x_{q(\\rho,1,k)}</span>  for all output bits  <span class="math">k\\in[s_{i+1}]</span> . The derivation when this assumption does not hold is similar.</p>

    <p class="text-gray-300">We exploit the following sequence of equalities:</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\tilde{V}_{i+1}(\\tilde{\\mathrm{in}}_{1,\\rho}(p)) &amp;= \\sum_{c \\in \\{0,1\\}^{s_{i+1}}} V_{i+1}(c) \\chi_{c}(\\tilde{\\mathrm{in}}_{1,\\rho}(p)) \\\\ &amp;= \\sum_{(c_{1},\\ldots,c_{a_{j-1}}) \\in \\{0,1\\}^{a_{j-1}}} \\sum_{(c_{a_{j-1}+1},\\ldots,c_{s_{i+1}}) \\in \\{0,1\\}^{s_{i+1}-a_{j-1}}} V_{i+1}(c) \\chi_{c}(\\tilde{\\mathrm{in}}_{1,\\rho}(p)) \\\\ &amp;= \\sum_{(c_{1},\\ldots,c_{a_{j-1}}) \\in \\{0,1\\}^{a_{j-1}}} \\sum_{(c_{a_{j-1}+1},\\ldots,c_{s_{i+1}}) \\in \\{0,1\\}^{s_{i+1}-a_{j-1}}} V_{i+1}(c) \\left(\\prod_{k=1}^{a_{j-1}} \\chi_{c_{k}}(\\tilde{b}_{\\rho,1,k}(r_{q(\\rho,1,k)}))\\right) \\left(\\prod_{k=a_{j-1}+1}^{a_{j}} \\chi_{c_{k}}(\\tilde{b}_{\\rho,1,k}(t))\\right) \\left(\\prod_{k=a_{j-1}+1}^{s_{i+1}} \\chi_{c_{k}}(\\tilde{b}_{\\rho,1,k}(t))\\right) \\\\ &amp;= \\sum_{(c_{1},\\ldots,c_{a_{j}}) \\in \\{0,1\\}^{a_{j}}} V_{i+1}(c_{j+1},\\ldots,c_{a_{j}},p_{q(\\rho,1,a_{j+1})},\\ldots,p_{q(\\rho,1,s_{j+1})}) \\left(\\prod_{k=1}^{a_{j-1}} \\chi_{c_{k}}(r_{k})\\right) \\cdot \\left(\\prod_{k=a_{j-1}+1}^{a_{j}} \\chi_{c_{k}}(t)\\right) \\\\ &amp;= \\sum_{(p_{a_{j-1}+1},\\ldots,p_{a_{j}}) \\in \\{0,1\\}^{a_{j}-a_{j-1}}} V^{(j-1)}[(p_{q(\\rho,1,a_{j-1}+1)},\\ldots,p_{q(\\rho,1,s_{j+1})})] \\cdot \\prod_{k=a_{j-1}+1}^{a_{j}} \\chi_{p_{k}}(t) \\end{split}</span>$</p>

    <p class="text-gray-300">Here, the first equality holds by Equation (8). The third holds by definition of the functions  <span class="math">\\chi_c</span>  and  <span class="math">\\tilde{in}_1</span> , as well as the assumption that  <span class="math">\\tilde{b}_{\\rho,1,k}(x_{q(\\rho,1,k)}) = x_{q(\\rho,1,k)}</span>  for all  <span class="math">k \\in [s_{i+1}]</span> . The fourth holds because for Boolean values  <span class="math">c_k, p_{q(\\rho,1,k)} \\in \\{0,1\\}</span> ,  <span class="math">\\chi_{c_k}(p_{q(\\rho,1,k)}) = 1</span>  if  <span class="math">c_k = p_{q(\\rho,1,k)}</span> , and  <span class="math">\\chi_{c_k}(p_{q(\\rho,1,k)}) = 0</span>  otherwise. The final equality holds by definition of the array  <span class="math">V^{(j-1)}</span> .</p>

    <p class="text-gray-300">The final expression above can be computed with  <span class="math">O(2^{a_j-a_{j-1}})</span>  time given the array  <span class="math">V^{(j-1)}</span> . Since  <span class="math">a_j-a_{j-1}</span>  is constant by Property 1 of Definition 3,  <span class="math">O(2^{a_j-a_{j-1}})=O(1)</span> .</p>

    <p class="text-gray-300">Putting Things Together. In round j of the sum-check protocol,  <span class="math">\\mathcal{P}</span>  uses the array  <span class="math">V^{(j-1)}</span>  to evaluate  <span class="math">\\tilde{V}_{i+1}(\\tilde{\\ln}_1(p))</span>  for all  <span class="math">O(2^{s_i-j})</span>  points  <span class="math">p \\in S^{(j)}</span> , which requires constant time per point and hence  <span class="math">O(2^{s_i-j})</span>  time over all points in  <span class="math">S^{(j)}</span> . At the end of round j,  <span class="math">\\mathcal{V}</span>  sends  <span class="math">\\mathcal{P}</span>  the value  <span class="math">r_j</span> , and  <span class="math">\\mathcal{P}</span>  computes  <span class="math">V^{(j)}</span>  from  <span class="math">V^{(j-1)}</span>  in  <span class="math">O(2^{s_{i+1}-a_{j-1}})</span>  time. By ordering input variables in such a way that  <span class="math">a_j &gt; a_{j-1}</span>  for all j, we ensure that in total across all rounds of the sum-check protocol,  <span class="math">\\mathcal{P}</span>  spends  <span class="math">O(\\sum_{j=1}^{s_i} 2^{s_i-j} + 2^{s_{i+1}-j}) = O(2^{s_i} + 2^{s_{i+1}})</span>  time to evaluate  <span class="math">\\tilde{V}_{i+1}</span>  at the relevant points. When combined with our  <span class="math">O(2^{s_i})</span> -time algorithm for computing all the relevant  <span class="math">\\beta(z,p)</span>  values, we see that  <span class="math">\\mathcal{P}</span>  takes  <span class="math">O(2^{s_i} + 2^{s_{i+1}}) = O(S_i + S_{i+1})</span>  time to run the entire sum-check protocol for iteration i of our circuit-checking protocol.</p>

    <p class="text-gray-300"><strong>Reducing to Verification of a Single Point.</strong> After executing the sum-check protocol at layer i as described above,  <span class="math">\\mathcal{V}</span>  is left with a claim about  <span class="math">\\tilde{V}_{i+1}(\\omega_1)</span>  and  <span class="math">\\tilde{V}_{i+1}(\\omega_2)</span>  from two points  <span class="math">\\omega_1, \\omega_2 \\in \\mathbb{F}^{s_{i+1}}</span> . If i is a layer for which  <span class="math">\\operatorname{in}_1^{(i)}</span>  and  <span class="math">\\operatorname{in}_2^{(i)}</span>  are similar (see Definition 4), we run the reducing to verification of a single point phase exactly as in the basic GKR protocol. This requires  <span class="math">\\mathcal{P}</span>  to send  <span class="math">\\tilde{V}_{i+1}(\\ell(t))</span>  for a canonical line  <span class="math">\\ell(t)</span>  that passes through the points  <span class="math">\\omega_1</span>  and  <span class="math">\\omega_2</span> . Because  <span class="math">\\operatorname{in}_1^{(i)}</span>  and  <span class="math">\\operatorname{in}_2^{(i)}</span>  are similar, it is easily seen that  <span class="math">\\tilde{V}_{i+1}(\\ell(t))</span>  is a univariate polynomial of constant degree. Hence  <span class="math">\\mathcal{P}</span>  can specify  <span class="math">\\tilde{V}_{i+1}(\\ell(t))</span>  by sending  <span class="math">\\tilde{V}_{i+1}(\\ell(t_j))</span>  for O(1) many points  <span class="math">t_j \\in \\mathbb{F}</span> . Using the method of Lemma 3,  <span class="math">\\mathcal{P}</span>  can evaluate  <span class="math">\\tilde{V}_{i+1}</span>  at each point  <span class="math">\\ell(t_i)</span>  in  <span class="math">O(S_{i+1})</span>  time, and hence can perform all  <span class="math">\\tilde{V}_{i+1}(\\ell(t_j))</span>  evaluations in  <span class="math">O(S_{i+1})</span>  time in total.</p>

    <p class="text-gray-300">Let c = O(1) be the number of layers i for which  <span class="math">\\operatorname{in}_1^{(i)}</span>  and  <span class="math">\\operatorname{in}_2^{(i)}</span>  are not similar. At each such layer i, we skip the &quot;reducing to verification at a single point&quot; phase of the protocol. Each time we do this, it doubles the number of points  <span class="math">\\omega \\in \\mathbb{F}^{s_{i+1}}</span>  that must be considered at the next iteration. However, we only skip the &quot;reducing to verification at a single point&quot; phase c times, and thus at all layers i of the circuit,  <span class="math">\\mathcal{V}</span>  needs to check  <span class="math">\\tilde{V}_i(\\omega_j)</span>  for at most  <span class="math">2^c = O(1)</span>  points. This affects  <span class="math">\\mathcal{P}</span> 's and  <span class="math">\\mathcal{V}</span> 's runtime by at most a  <span class="math">2^c = O(1)</span>  factor, and the O(S) time bound for  <span class="math">\\mathcal{P}</span> , and the  <span class="math">O(n \\log n + d(n) \\log S(n))</span>  time bound for  <span class="math">\\mathcal{V}</span>  follow.</p>

    </section>

    <section id="app-b" class="mb-10">
      <h2 class="text-2xl font-bold"><strong>B</strong> Analysis for Pattern Matching</h2>

    <p class="text-gray-300">Let C be the circuit for pattern matching described in Section 5.5.1. Our goal in this appendix is to handle the layer of the circuit adjacent to the input layer. Call this layer  <span class="math">\\ell</span> . Layer  <span class="math">\\ell</span>  computes  <span class="math">t_{i+k} - p_k</span>  for each pair  <span class="math">(i,k) \\in [[n]] \\times [[q]]</span> . We want to show how to use a sum-check protocol to reduce a claim about the value of  <span class="math">\\tilde{V}_{\\ell}(z)</span>  for some  <span class="math">z \\in \\mathbb{F}^{s_{\\ell}}</span>  to a claim about  <span class="math">\\tilde{V}_{\\ell+1}(r)</span>  for some  <span class="math">r \\in \\mathbb{F}^{s_{\\ell+1}}</span> , while ensuring that  <span class="math">\\mathcal{P}</span>  runs in time  <span class="math">O(S_{\\ell}) = O(nm)</span> .</p>

    <p class="text-gray-300">The idea underlying our analysis here is the following. The reason Theorem 1 does not apply to layer  <span class="math">\\ell</span>  is that the first in-neighbor of a gate with label  <span class="math">p=(i_1,\\ldots,i_{\\log n},k_1,\\ldots,k_{\\log m})\\in\\{0,1\\}^{\\log n+\\log m}</span>  has label equal to the binary representation of the integer i+k, and a single bit  <span class="math">i_k</span>  can affect many bits in the binary representation of i+k (likewise, each bit in the binary representation of i+k may be affected by many bits in the binary representation of i and k). In order to ensure that each bit of p affects only a single bit of  <span class="math">p=\\inf_{i=1}^{\\ell}(p)</span> , we introduce  <span class="math">\\log n</span>  dummy variables  <span class="math">(c_1,\\ldots,c_{\\log n})</span>  and force the jth dummy variable  <span class="math">c_j</span>  to have value equal to the jth carry bit when adding numbers i and k in binary. Now each bit of p affects only one output bit, and each output bit  <span class="math">y_j</span>  is only affected by at most three &quot;input bits&quot;:  <span class="math">i_j,k_j</span> , and  <span class="math">c_j</span>  if  <span class="math">j \\leq \\log m</span> , and just  <span class="math">i_j</span>  and  <span class="math">c_j</span>  if  <span class="math">j &gt; \\log m</span> .</p>

    <p class="text-gray-300">To this end, let  <span class="math">\\phi: \\{0,1\\}^4 \\to \\{0,1\\}</span>  be the function that evaluates to 1 on input  <span class="math">(i_1,k_1,c_0,c_1)</span>  if and only if  <span class="math">c_1 = 0</span>  and  <span class="math">i_1 + k_1 + c_0 &lt; 2</span>  or  <span class="math">c_1 = 1</span>  and  <span class="math">i_1 + k_1 + c_0 \\geq 2</span> . That is,  <span class="math">\\phi</span>  outputs 1 if and only if  <span class="math">c_1</span>  is equal to the carry bit when adding  <span class="math">i_1,k_1</span> , and  <span class="math">c_0</span> . Let  <span class="math">\\tilde{\\phi}</span>  be the multilinear extension of  <span class="math">\\phi</span> . Notice  <span class="math">\\tilde{\\phi}</span>  can be evaluated at any point  <span class="math">r \\in \\mathbb{F}^4</span>  in O(1) time.</p>

    <p class="text-gray-300">Now let (i,k,c) denote a vector in  <span class="math">\\mathbb{F}^{\\log n} \\times \\mathbb{F}^{\\log m} \\times \\mathbb{F}^{\\log n}</span> , and define</p>

    <p class="text-gray-300"><span class="math">$\\Phi(i,k,c) := \\prod_{j=1}^{\\log n} \\tilde{\\phi}(i_j,k_j,c_{j-1},c_j),</span>$</p>

    <p class="text-gray-300">where it is understood that  <span class="math">c_{-1} = 0</span>  and  <span class="math">k_j = 0</span>  for  <span class="math">j &gt; \\log m</span> .</p>

    <p class="text-gray-300">For any Boolean vector  <span class="math">(i,k,c) \\in \\{0,1\\}^{\\log n} \\times \\{0,1\\}^{\\log m} \\times \\{0,1\\}^{\\log n}</span> , it is easily verified that  <span class="math">\\Phi(i,k,c) = 1</span>  if and only if for all j,  <span class="math">c_j</span>  equals the jth carry bit when adding numbers i and k in binary.</p>

    <p class="text-gray-300">Finally, let  <span class="math">\\gamma: \\{0,1\\}^3 \\to \\{0,1\\}</span>  be the function that evaluates to 1 on input  <span class="math">(i_1,k_1,c_1)</span>  if and only if  <span class="math">i_1+k_1+c_1=1 \\mod 2</span> . Let  <span class="math">\\tilde{\\gamma}</span>  be the multilinear extension of  <span class="math">\\gamma</span> . Notice  <span class="math">\\tilde{\\gamma}</span>  can be evaluated at any point  <span class="math">r \\in \\mathbb{F}^3</span>  in O(1) time.</p>

    <p class="text-gray-300">Now consider the following  <span class="math">\\log n + \\log m</span> -variate polynomial over the field  <span class="math">\\mathbb{F}</span> :</p>

    <p class="text-gray-300"><span class="math">$W^{(\\ell)}(i,k) = \\sum_{(c_1,\\ldots,c_{\\log n})\\in\\{0,1\\}^{\\log n}} \\Phi(i,k,c) \\cdot \\left(\\tilde{T}(\\tilde{\\gamma}(i_1+k_1+c_0),\\ldots,\\tilde{\\gamma}(i_{\\log n}+k_{\\log n}+c_{\\log n-1})) - \\tilde{P}(k_1,\\ldots,k_{\\log m})\\right),</span>$</p>

    <p class="text-gray-300">where again it is understood that  <span class="math">c_{-1} = 0</span>  and  <span class="math">k_j = 0</span>  for  <span class="math">j &gt; \\log m</span> . Here,  <span class="math">\\tilde{T}</span>  is the multilinear extension of the input T, viewed as a function from  <span class="math">\\{0,1\\}^{\\log n}</span>  to [n], and  <span class="math">\\tilde{P}</span>  is the multilinear extension of the input pattern P, viewed as a function from  <span class="math">\\{0,1\\}^{\\log m}</span>  to [n].</p>

    <p class="text-gray-300">It can be seen that for all Boolean vectors  <span class="math">(i,k) = \\{0,1\\}^{\\log n} \\times \\{0,1\\}^{\\log m}</span> ,  <span class="math">W^{(\\ell)}(i,k) = V_{\\ell}(i,k)</span> . This is because for any  <span class="math">(i,k) \\in \\{0,1\\}^{\\log n} \\times \\{0,1\\}^{\\log m}</span> ,  <span class="math">\\Phi(i,k,c)</span>  will be zero for all c except the c consisting of the correct carry bits for i and k, and for this input c,  <span class="math">\\tilde{T}(\\tilde{\\gamma}(i_1+k_1+c_0),\\ldots,\\tilde{\\gamma}(i_{\\log n}+k_{\\log n}+c_{\\log n-1}))</span>  will equal T(i+k) when interpreting i,k as integers in the natural way.</p>

    <p class="text-gray-300">Lemma 4 then implies that for all  <span class="math">z \\in \\mathbb{F}^{\\log n + \\log m}</span> .</p>

    <p class="text-gray-300"><span class="math">$\\tilde{V}_{\\ell}(z) = \\sum_{(i,k) \\in \\{0,1\\}^{\\log n} \\times \\{0,1\\}^{\\log m}} \\beta_{\\log n + \\log m}(z,(i,k)) \\cdot W^{(\\ell)}(i,k)</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{(i,k,c)\\in\\{0,1\\}^{\\log n}\\times\\{0,1\\}^{\\log n}\\times\\{0,1\\}^{\\log m}\\times\\{0,1\\}^{\\log n}} \\beta_{\\log n+\\log m}(z,(i,k))\\cdot\\Phi(i,k,c)\\cdot\\left(\\tilde{T}(\\tilde{\\gamma}(i_1+k_1+c_0),\\ldots,\\tilde{\\gamma}(i_{\\log n}+k_{\\log n}+c_{\\log n-1}))-\\tilde{P}(j_1,\\ldots,j_{\\log m})\\right).</span>$</p>

    <p class="text-gray-300">Therefore, in order to reduce a claim about  <span class="math">\\tilde{V}_{\\ell}(z)</span>  to a claim about  <span class="math">\\tilde{T}(r_1)</span>  and  <span class="math">\\tilde{P}(r_2)</span>  for random vectors  <span class="math">r_1 \\in \\mathbb{F}^{\\log n}</span>  and  <span class="math">r_2 \\in \\mathbb{F}^{\\log m}</span> , it suffices to apply the sum-check protocol to the  <span class="math">2\\log n + \\log m</span> -variate polynomial</p>

    <p class="text-gray-300"><span class="math">$g_z(i,k,c) = \\beta_{\\log n + \\log m}(z,(i,k)) \\cdot \\Phi(i,k,c) \\cdot \\left( \\tilde{T}(\\tilde{\\gamma}(i_1 + k_1 + c_0), \\dots, \\tilde{\\gamma}(i_{\\log n} + k_{\\log n} + c_{\\log n-1})) - \\tilde{P}(j_1, \\dots, j_{\\log m}) \\right).</span>$</p>

    <p class="text-gray-300">It remains to show how to extend the techniques underlying Theorem 1 to allow  <span class="math">\\mathcal{P}</span>  to compute all of the required messages in this sum-check protocol in O(nm) time. For brevity, we restrict ourselves to a sketch of the techniques.</p>

    <p class="text-gray-300">The first obvious complication is that the sum defining  <span class="math">\\mathcal{P}</span> 's message in a given round of the sum-check protocol has as many as  <span class="math">2^{2\\log n + \\log m} = \\Omega(mn^2) &gt; nm</span>  terms. Fortunately, the  <span class="math">\\Phi</span>  polynomial ensures that almost all of these terms are zero: when considering any Boolean setting of the variables  <span class="math">i_j, k_j</span> , and  <span class="math">c_{j-1}</span> , the only setting of  <span class="math">c_j</span>  that  <span class="math">\\mathcal{P}</span>  must consider is the one corresponding to the carry bit of  <span class="math">i_j + k_j + c_{j-1}</span>  i.e., the unique setting of  <span class="math">c_j</span>  such that  <span class="math">\\phi(i_j, k_j, c_{j-1}, c_j) = 1</span> . This ensures that at round 3j, 3j + 1, and 3j + 2 of the sum-check protocol applied to  <span class="math">g_z</span> ,  <span class="math">\\mathcal{P}</span>  must only evaluate  <span class="math">g_z</span>  at  <span class="math">O(2^{\\log n + \\log m - j})</span>  terms, which is falling geometrically quickly with j.</p>

    <p class="text-gray-300">We now turn to explaining how  <span class="math">\\mathcal{P}</span>  can evaluate  <span class="math">g_z</span>  at all necessary points in round 3j, 3j+1 and 3j+2 in total time  <span class="math">O(2^{\\log n + \\log m - j})</span> . To accomplish this, it is sufficient for  <span class="math">\\mathcal{P}</span>  to evaluate  <span class="math">\\beta_{\\log n + \\log m}</span>  at the necessary points, as well as  <span class="math">\\Phi</span> ,  <span class="math">\\tilde{T}</span> , and  <span class="math">\\tilde{P}</span>  at the necessary points. The  <span class="math">\\beta_{\\log n + \\log m}</span>  evaluations are handled exactly as in Theorem 1 i.e., by using  <span class="math">C^{(j)}</span>  arrays (but these arrays only get updated every time a variable  <span class="math">i_j</span>  or  <span class="math">k_j</span>  gets bound within the sum-check protocol; no update is necessary when a variable  <span class="math">c_j</span>  gets bound). The  <span class="math">\\tilde{P}</span>  evaluations are also handled exactly as in Theorem 1, using  <span class="math">V^{(j)}</span>  arrays that only need to be updated when a variable  <span class="math">k_j</span>  gets bound.</p>

    <p class="text-gray-300">The  <span class="math">\\tilde{T}</span>  evaluations require some additional explanation on top of the analysis of Theorem 1. We want  <span class="math">\\mathcal{P}</span>  to be able to use  <span class="math">V^{(j)}</span>  arrays as in Theorem 1 to evaluate  <span class="math">\\tilde{T}</span>  at the necessary points in constant time per point, but we need to make sure that  <span class="math">\\mathcal{P}</span>  can compute array  <span class="math">V^{(j)}</span>  from  <span class="math">V^{(j-1)}</span>  in time that falls geometrically quickly with j. In order to do this, it is essential to choose a specific ordering for the sum in the sum-check protocol. Specifically, we write the sum as:</p>

    <p class="text-gray-300"><span class="math">$\\sum_{i_1} \\sum_{k_1} \\sum_{c_1} \\sum_{i_2} \\sum_{k_2} \\sum_{c_2} \\cdots \\sum_{i_{\\log n}} \\sum_{c_{\\log n}} g_z(i,k,c).</span>$</p>

    <p class="text-gray-300">This ensures that, e.g.,  <span class="math">(i_1,k_1,c_1)</span>  are the first three variables in the sum-check protocol to become bound to random values in  <span class="math">\\mathbb{F}</span> . The reason we must do this is so that every 3 rounds, another value  <span class="math">\\tilde{\\gamma}(i_j+k_j+c_{j-1})</span>  feeding into  <span class="math">\\tilde{T}</span>  becomes bound to a specific value (and moreover the outputs of  <span class="math">\\tilde{\\gamma}(i_{j&#x27;}+k_{j&#x27;}+c_{j&#x27;-1})</span>  are unaffected by the bound variables for all j'&gt;j). This is precisely the property we exploited in the protocol of Theorem 1 to ensure that the  <span class="math">V^{(j)}</span>  arrays there halved in size every round, and that  <span class="math">V^{(j)}</span>  could be computed from  <span class="math">V^{(j-1)}</span>  in time proportional to its size. So we can use  <span class="math">V^{(j)}</span>  arrays to efficiently perform the  <span class="math">\\tilde{T}</span>  evaluations, updating the arrays every time another value  <span class="math">\\tilde{\\gamma}(i_j+k_j+c_{j-1})</span>  feeding into  <span class="math">\\tilde{T}</span>  becomes bound to a specific value.</p>

    <p class="text-gray-300">Finally, the  <span class="math">\\Phi</span>  evaluations can be handled as follows. Consider for simplicity round 3j of the protocol. Recall that  <span class="math">\\mathcal{P}</span>  only needs to evaluate  <span class="math">\\Phi</span>  at points for which  <span class="math">\\phi_{j&#x27;}(i_{j&#x27;},k_{j&#x27;},c_{j&#x27;-1},c_{j&#x27;})=1</span>  for all j'&gt;j. Thus, for all j'&gt;j,  <span class="math">\\phi_{j&#x27;}</span>  does not affect the product defining  <span class="math">\\Phi</span> . So in order to evaluate  <span class="math">\\Phi</span>  at the relevant points, it suffices for  <span class="math">\\mathcal{P}</span>  to evaluate the  <span class="math">\\phi_{j&#x27;}</span> s for  <span class="math">j&#x27;\\leq j</span> . Now at round 3j of the protocol, all triples  <span class="math">(i_{j&#x27;},k_{j&#x27;},c_{j&#x27;})</span>  for j'&lt; j are already bound, say to the values  <span class="math">(r_{j&#x27;}^{(i)},r_{j&#x27;}^{(k)},r_{j&#x27;}^{(c)})</span> , and hence all the  <span class="math">\\phi_{j&#x27;}</span>  functions for j'&lt; j are themselves</p>

    <p class="text-gray-300">already bound to specific values. So in order to quickly determine the contribution of the  <span class="math">\\phi_{j&#x27;}</span> s for j' &lt; j to the product defining  <span class="math">\\Phi</span> , it suffices for  <span class="math">\\mathcal P</span>  to maintain the quantity  <span class="math">\\prod_{j&#x27; &lt; j} \\phi_{j&#x27;}(r_{j&#x27;}^{(i)}, r_{j&#x27;}^{(k)}, r_{j&#x27;}^{(c)})</span>  over the course of the protocol, which takes just  <span class="math">O(\\log n)</span>  time in total. Finally, the contribution of  <span class="math">\\phi_j</span>  to the product defining  <span class="math">\\Phi</span>  can be computed in constant time per point. This completes the proof that  <span class="math">\\Phi</span>  can be evaluated by  <span class="math">\\mathcal P</span>  at all of the necessary points in O(1) time per point over all rounds of the sum-check protocol, and completes the proof of the theorem.</p>

    </section>
`;
---

<BaseLayout title="Time-Optimal Interactive Proofs for Circuit Evaluation (2013/351)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2013 &middot; eprint 2013/351
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <PaperDisclaimer eprintUrl={EPRINT_URL} />
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <nav id="toc" class="mb-10 p-6 rounded-lg" style="background: rgba(255,255,255,0.03); border: 1px solid rgba(255,255,255,0.06);">
      <h2 class="text-lg font-bold mb-4">Table of Contents</h2>
      <ol class="space-y-1 text-sm text-gray-300
        list-decimal list-inside">
        <li><a href="#abstract" class="hover:text-white">Abstract</a></li>
        <li>
          <a href="#sec-1" class="hover:text-white">Introduction</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-1.1" class="hover:text-white">Prior Work</a></li>
            <li><a href="#sec-1.1.1" class="hover:text-white">Work on Interactive Proofs.</a></li>
            <li><a href="#sec-1.1.2" class="hover:text-white">Work on Argument Systems.</a></li>
            <li><a href="#sec-1.2" class="hover:text-white">Our Contributions</a></li>
            <li><a href="#sec-1.3" class="hover:text-white">Roadmap</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-2" class="hover:text-white">Preliminaries</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-2.1" class="hover:text-white">Definitions</a></li>
            <li><a href="#sec-2.1.1" class="hover:text-white">Cost Model</a></li>
            <li><a href="#sec-2.1.2" class="hover:text-white">Problem Definitions</a></li>
            <li><a href="#sec-2.1.3" class="hover:text-white">Additional Notation</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-3" class="hover:text-white">Overview of the Ideas</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-3.1" class="hover:text-white">The GKR Protocol From 10,000 Feet</a></li>
            <li><a href="#sec-3.2" class="hover:text-white">Achieving Optimal Prover Runtime for Regular Circuits</a></li>
            <li><a href="#sec-3.3" class="hover:text-white">Verifying General Data Parallel Computations</a></li>
            <li><a href="#sec-3.4" class="hover:text-white">A Special-Purpose Protocol for MATMULT</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-4" class="hover:text-white">Technical Background</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-4.1" class="hover:text-white">Schwartz-Zippel Lemma</a></li>
            <li><a href="#sec-4.2" class="hover:text-white">Sum-Check Protocol</a></li>
            <li><a href="#sec-4.2.1" class="hover:text-white">Discussion of costs.</a></li>
            <li><a href="#sec-4.3" class="hover:text-white">The GKR Protocol</a></li>
            <li><a href="#sec-4.3.1" class="hover:text-white">Notation</a></li>
            <li><a href="#sec-4.3.2" class="hover:text-white">Protocol Outline</a></li>
            <li><a href="#sec-4.3.3" class="hover:text-white">Details for Each Iteration</a></li>
            <li><a href="#sec-4.3.4" class="hover:text-white">Discussion of Costs.</a></li>
            <li><a href="#sec-4.3.5" class="hover:text-white">Making V Fast vs. Making V Streaming</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-5" class="hover:text-white">Time-Optimal Protocols for Circuit Evaluation</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-5.1" class="hover:text-white">Protocol Outline and Section Roadmap</a></li>
            <li><a href="#sec-5.2" class="hover:text-white">A Preliminary Lemma</a></li>
            <li><a href="#sec-5.3" class="hover:text-white">Polynomials for Specific Circuits</a></li>
            <li><a href="#sec-5.3.1" class="hover:text-white">The Polynomial for a Binary Tree</a></li>
            <li><a href="#sec-5.3.2" class="hover:text-white">The Polynomials for DISTINCT</a></li>
            <li><a href="#sec-5.4" class="hover:text-white">Reusing Work</a></li>
            <li><a href="#sec-5.4.1" class="hover:text-white">Computing the Necessary \beta(z, p) Values</a></li>
            <li><a href="#sec-5.4.2" class="hover:text-white">Computing the Necessary \tilde&#123;V&#125;_&#123;i+1&#125;(p) Values</a></li>
            <li><a href="#sec-5.5" class="hover:text-white">A General Theorem</a></li>
            <li><a href="#sec-5.5.1" class="hover:text-white">Applications</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-6" class="hover:text-white">Experimental Results</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-6.1" class="hover:text-white">Summary of Results</a></li>
            <li><a href="#sec-6.2" class="hover:text-white">Details</a></li>
            <li><a href="#sec-6.2.1" class="hover:text-white">Serial Implementation</a></li>
            <li><a href="#sec-6.2.2" class="hover:text-white">Parallel Implementation</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-7" class="hover:text-white">Verifying General Data Parallel Computations</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-7.1" class="hover:text-white">Motivation</a></li>
            <li><a href="#sec-7.2" class="hover:text-white">Overview of the Protocol</a></li>
            <li><a href="#sec-7.3" class="hover:text-white">Technical Details</a></li>
            <li><a href="#sec-7.3.1" class="hover:text-white">Notation</a></li>
            <li><a href="#sec-7.3.2" class="hover:text-white">Main Theorem</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-8" class="hover:text-white">Extensions</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-8.1" class="hover:text-white">Binary Tree of Addition Gates</a></li>
            <li><a href="#sec-8.2" class="hover:text-white">Optimal Space and Time Costs for MATMULT</a></li>
            <li><a href="#sec-8.2.1" class="hover:text-white">Comparison to Prior Work</a></li>
            <li><a href="#sec-8.2.2" class="hover:text-white">Protocol Details</a></li>
          </ol>
        </li>
        <li><a href="#sec-9" class="hover:text-white">Conclusion</a></li>
      </ol>
      <p class="text-xs text-gray-500 mt-4 mb-1 font-semibold">
        Appendices
      </p>
      <ol class="space-y-1 text-sm text-gray-400
        list-[upper-alpha] list-inside">
        <li><a href="#app-a" class="hover:text-white">Proof of Theorem 1</a></li>
        <li><a href="#app-b" class="hover:text-white">Analysis for Pattern Matching</a></li>
      </ol>
      <p class="text-xs text-gray-500 mt-4 mb-1 font-semibold">
        Additional
      </p>
      <ul class="space-y-1 text-sm text-gray-400
        list-disc list-inside">
        <li><a href="#references" class="hover:text-white">References</a></li>
      </ul>
    </nav>


    <Fragment set:html={CONTENT} />

    <PaperHistory slug="time-optimal-interactive-proofs-for-circuit-evaluation-2013" />
  </article>
</BaseLayout>
