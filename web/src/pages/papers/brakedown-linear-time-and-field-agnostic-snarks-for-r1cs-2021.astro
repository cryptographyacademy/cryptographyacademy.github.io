---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2021/1043';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Brakedown: Linear-time and field-agnostic SNARKs for R1CS';
const AUTHORS_HTML = 'Alexander Golovnev, Jonathan Lee, Srinath Setty, Justin Thaler, Riad S.  Wahby';

const CONTENT = `    <p class="text-gray-300">Brakedown: Linear-time and field-agnostic SNARKs for R1CS</p>

    <p class="text-gray-300">Alexander Golovnev* Jonathan Lee† Srinath Setty‡ Justin Thaler§ Riad S. Wahby¶</p>

    <h6 id="sec-1" class="text-base font-medium mt-4">Abstract</h6>

    <p class="text-gray-300">This paper introduces a SNARK called <em>Brakedown</em>. Brakedown targets R1CS, a popular NP-complete problem that generalizes circuit-satisfiability. It is the first built system that provides a <em>linear-time</em> prover, meaning the prover incurs <span class="math">O(N)</span> finite field operations to prove the satisfiability of an <span class="math">N</span>-sized R1CS instance. Brakedown’s prover is faster, both concretely and asymptotically, than prior SNARK implementations. It does not require a trusted setup and may be post-quantum secure. Furthermore, it is compatible with <em>arbitrary</em> finite fields of sufficient size; this property is new among built proof systems with sublinear proof sizes.</p>

    <p class="text-gray-300">To design Brakedown, we observe that recent work of Bootle, Chiesa, and Groth (BCG, TCC 2020) provides a polynomial commitment scheme that, when combined with the linear-time interactive proof system of Spartan (CRYPTO 2020), yields linear-time IOPs and SNARKs for R1CS (a similar theoretical result was previously established by BCG, but our approach is conceptually simpler, and crucial for achieving high-speed SNARKs). A core ingredient in the polynomial commitment scheme that we distill from BCG is a linear-time encodable code. Existing constructions of such codes are believed to be impractical. Nonetheless, we design and engineer a new one that is practical in our context.</p>

    <p class="text-gray-300">We also implement a variant of Brakedown that uses Reed-Solomon codes instead of our linear-time encodable codes; we refer to this variant as <em>Shockwave</em>. Shockwave is <em>not</em> a linear-time SNARK, but it provides shorter proofs and lower verification times than Brakedown, and also provides a faster prover than prior plausibly post-quantum SNARKs.</p>

    <h2 id="sec-2" class="text-2xl font-bold">1 Introduction</h2>

    <p class="text-gray-300">A SNARK <em>[57, 66, 45, 18]</em> is a cryptographic primitive that enables a <em>prover</em> to prove to a <em>verifier</em> the knowledge of a satisfying witness to an NP statement by producing a proof <span class="math">\\pi</span> such that the size of <span class="math">\\pi</span> and the cost to verify it are both sub-linear in the size of the witness. Given their many applications, constructing SNARKs with excellent asymptotics and concrete efficiency is a highly active area of research. Still, one of the key bottlenecks preventing application of existing SNARKs to large NP statements is the prover’s asymptotic and concrete cost. This has limited the use of SNARKs to practical applications in which NP statements of interest are relatively small (for example, cryptocurrencies).</p>

    <p class="text-gray-300">As with much of the literature on SNARKs, we focus on rank-1 constraint satisfiability (R1CS) over a finite field <span class="math">\\mathbb{F}</span>, an NP-complete problem that generalizes arithmetic circuit satisfiability. An R1CS instance comprises a set of <span class="math">M</span> constraints, with a vector <span class="math">w</span> over <span class="math">\\mathbb{F}</span> said to <em>satisfy</em> the instance if it satisfies all <span class="math">M</span> constraints. The term “rank-1” means that the constraints should have a specific form. Specifically, each constraint asserts that the product of two specified linear combinations of the entries of <span class="math">w</span> equals a third linear combination of those entries. See Definition 2.1 for details. R1CS is amenable to probabilistic checking and is highly expressive. For example, in theory, any non-deterministic random access machine running in time <span class="math">T</span> can be transformed into an R1CS instance of size “close” to <span class="math">T</span>. In practice, there exist efficient transformations and compiler toolchains to transform applications of interest to R1CS <em>[79, 70, 26, 13, 86, 76, 61, 69]</em>.</p>

    <p class="text-gray-300">*Georgetown University</p>

    <p class="text-gray-300">†Nanotronics Imaging</p>

    <p class="text-gray-300">Microsoft Research</p>

    <p class="text-gray-300">\\S a16z crypto research and Georgetown University</p>

    <p class="text-gray-300">Carnegie Mellon University</p>

    <p class="text-gray-300">Our focus in this work is designing SNARKs for R1CS with the fastest possible prover. We also wish for the SNARK to be transparent (or be without a trusted setup): there should be no need to run a complex multi-party computation to generate a so-called structured reference string that is needed for proof generation.</p>

    <p class="text-gray-300">Furthermore, we desire a verifier that runs in time sub-linear in the size of the R1CS instance. Since the verifier must at least read the statement that is being proven, we allow a one-time public preprocessing phase for general (unstructured) R1CS instances. In this phase, the verifier computes a computation commitment, a cryptographic commitment to the structure of a circuit or R1CS instance <em>[75]</em>. (For “structured” computations, our SNARKs, like several prior works, can avoid this pre-processing phase.) After the pre-processing phase, the verifier must run in time sub-linear in the size of the R1CS instance. Furthermore, the pre-processing phase should be at least as efficient as the SNARK prover. Subsequent works to Spartan <em>[75]</em> refer to such public preprocessing to achieve fast verification as leveraging holography <em>[35, 36, 22]</em>.</p>

    <p class="text-gray-300">A second focus of our work is designing SNARKs that can operate over arbitrary (sufficiently large) finite fields. Prior SNARKs apply over fields that are “discrete-log friendly” or “FFT-friendly”, or otherwise require one or many multiplicative or additive subgroups of specified sizes. Yet many cryptographic applications naturally work over fields that do not satisfy these properties. Examples include proofs regarding encryption or signature schemes that themselves work over fields that do not satisfy the properties needed by the SNARK. Indeed, most practically relevant elliptic curve groups are defined over fields that are not FFT-friendly. Even in applications where SNARK designers do have flexibility in field choice, field size restrictions can still create engineering challenges or inconveniences, as well as performance overheads. For example, they may limit the size of R1CS statements that can be handled over the chosen field, or force instance sizes to be padded to a length corresponding to the size of a subgroup.</p>

    <p class="text-gray-300">In this work we design transparent SNARKs that asymptotically have the fastest possible prover, may be post-quantum secure, and work over arbitrary (sufficiently large) finite fields. We refer to this latter property as being field-agnostic, and to the best of our knowledge, it is new amongst implemented arguments with sublinear proof size and even quasilinear runtime. We optimize and implement our new SNARKs, and demonstrate the fastest prover performance in the SNARK literature (even compared to SNARKs that require FFT-friendly or discrete-log–friendly fields).</p>

    <h4 id="sec-3" class="text-lg font-semibold mt-6">Formalizing “fastest possible” provers.</h4>

    <p class="text-gray-300">How fast can we hope for the prover in a SNARK to be? Letting <span class="math">N</span> denote the size of the R1CS or arithmetic-circuit-satisfiability instance over an arbitrary finite field <span class="math">\\mathbb{F}</span>, a lower bound on the prover’s runtime is <span class="math">N</span> operations in <span class="math">\\mathbb{F}</span>. Here, the size of an arithmetic-circuit-satisfiability instance is the number of gates in the circuit. The size of an R1CS instance of the form <span class="math">Az\\circ Bz=Cz</span> is the number of non-zero entries in <span class="math">A,B,C</span>, where <span class="math">\\circ</span> denotes the Hadamard (entry-wise) product. This is because any prover that knows a witness <span class="math">w</span> for the instance has to at least convince itself (much less the verifier) that <span class="math">w</span> is valid. We refer to this procedure as native evaluation of the instance. So the natural goal, roughly speaking, is to achieve a SNARK prover that is only a constant factor slower than native evaluation. Such a prover is said to run in linear-time.</p>

    <p class="text-gray-300">Achieving a linear-time prover may sound like a simple and well-defined goal, but it is in fact subtle to formalize, because one must be precise about what operations can be performed in one “time-step”, as well as the soundness error achieved and the choice of the finite field.</p>

    <p class="text-gray-300">In known SNARKs, the bottleneck for the prover (both asymptotically and concretely) is typically one or more of the following operations: (1) Performing an FFT over a vector of length <span class="math">O(N)</span>. (2) Building a Merkle-hash tree over a vector consisting of <span class="math">O(N)</span> elements of <span class="math">\\mathbb{F}</span>. (3) Performing a multiexponentiation of size <span class="math">O(N)</span> in a (multiplicative) cryptographic group <span class="math">\\mathbb{G}</span>. In this case, the field <span class="math">\\mathbb{F}</span> is of prime order <span class="math">p</span> and <span class="math">\\mathbb{G}</span> is typically an elliptic curve group (or subgroup) of order <span class="math">p</span>. A multiexponentiation of size <span class="math">N</span> in <span class="math">\\mathbb{G}</span> refers to a product of <span class="math">N</span> exponentiations, i.e., <span class="math">\\prod_{i=1}^{N}g_{i}^{c_{i}}</span>, where each <span class="math">g_{i}\\in\\mathbb{G}</span> and each <span class="math">c_{i}\\in\\{0,\\ldots,p-1\\}</span>.</p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">Should any of these operations count as “linear-time”?</p>

    <p class="text-gray-300">FFTs. An FFT of length <span class="math">\\Theta(N)</span> over <span class="math">\\mathbb{F}</span> should not count as linear-time, because the fastest known algorithms require <span class="math">\\Theta(N\\log N)</span> operations over <span class="math">\\mathbb{F}</span>, which is a <span class="math">\\log N</span> factor, rather than a constant factor, larger than native evaluation.</p>

    <p class="text-gray-300">However, the remaining operations are trickier to render judgment upon, because they do not refer to field operations.</p>

    <p class="text-gray-300">Merkle-hashing. Build a Merkle tree over a vector of <span class="math">O(N)</span> elements of <span class="math">\\mathbb{F}</span>, computing <span class="math">O(N)</span> cryptographic hashes is necessary and sufficient, assuming the hash function takes as input <span class="math">O(1)</span> elements of <span class="math">\\mathbb{F}</span>. However, this is only “linear-time” if hashing <span class="math">O(N)</span> elements of <span class="math">\\mathbb{F}</span> can be done in time comparable to <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span>. It is not clear whether or not applying a standard hash function such as SHA-256 to hash a field element should be considered comparable to performing a single field operation.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Theoretical work of Bootle et al. <em>[21]</em> sidesteps this issue by observing that (assuming the intractability of certain lattice problems over <span class="math">\\mathbf{F}_{2}</span>, specifically finding a low-Hamming vector in the kernel of a sparse matrix), a collision-resistant hash family of Applebaum et al. <em>[5]</em> is capable of hashing strings consisting of <span class="math">k\\gg\\lambda</span> bits in <span class="math">O(k)</span> bit operations, with security parameter <span class="math">\\lambda</span>. This means that a vector of <span class="math">O(N)</span> elements of <span class="math">\\mathbb{F}</span> can be Merkle-hashed in $O(N\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> bit operations, which Bootle et al. <em>[21]</em> consider comparable to the cost of </span>O(N)<span class="math"> operations in </span>\\mathbb{F}$. The aforementioned hash functions appear to be of primarily theoretical interest because they can be orders of magnitude slower than standard hash functions (e.g., SHA-256). Hence, in this paper our implementations make use of standard hash functions, and with this choice, Merkle-hashing is not the concrete bottleneck in our implementations. Accordingly, and to simplify discussion, we consider our implemented Merkle-hashing procedure to be linear-time, even if this may not be strictly justified from a theoretical perspective.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Multiexponentation. Pippenger’s algorithm <em>[71]</em> (see also <em>[16, 54]</em>) can perform an <span class="math">O(N)</span>-sized multiexponentiation in a group <span class="math">\\mathbb{G}</span> of size <span class="math">\\sim 2^{\\lambda}</span> by performing <span class="math">O(N\\cdot\\lambda/\\log{(N\\cdot\\lambda)})</span> group operations (i.e., group multiplications). Typically, one thinks of the security parameter <span class="math">\\lambda</span> as <span class="math">\\omega(\\log N)</span> (so that <span class="math">2^{\\lambda}</span> is superpolynomial in <span class="math">N</span>, ensuring the intractability of problems such as discrete logarithm in <span class="math">\\mathbb{G}</span>), and so <span class="math">O(N\\cdot\\lambda/\\log{(N\\cdot\\lambda)})</span> group operations is considered <span class="math">\\omega(N)</span> group operations. Each group operation is at least as expensive (in fact, several times slower) than a field operation—typically, an operation in the elliptic-curve group <span class="math">\\mathbb{G}</span> requires performing a constant number of field operations within a field that is of similar size to, but different than, then prime-order field <span class="math">\\mathbb{F}</span> over which the circuit or R1CS instance is defined. Hence, we do not consider this to be linear time.</p>

    <p class="text-gray-300">However, note that for a fixed value of the security parameter <span class="math">\\lambda</span>, the cost of a multiexponentiation of size <span class="math">N</span> performed using Pippenger’s algorithm scales only linearly (in fact, sublinearly) with <span class="math">N</span>. That is, Pippenger’s algorithm incurs <span class="math">\\Theta(N\\cdot(\\lambda/\\log(N\\lambda)))=\\Theta_{\\lambda}(N/\\log N)</span> group operations and in turn this cost is comparable up to a constant factor to the same number of operations over a field of size <span class="math">\\exp(\\lambda)</span>. In practice, protocol designers fix a cryptographic group (and hence fix <span class="math">\\lambda</span>), and then apply the resulting protocol to R1CS instances of varying sizes <span class="math">N</span>. For this reason, systems (e.g., Spartan <em>[75]</em>) whose dominant prover cost is a multiexponentiation of size <span class="math">N</span> will scale (sub-)linearly as a function of <span class="math">N</span>. Specifically, in the experimental results <em>[75]</em>, Spartan’s prover exhibits the behavior of a linear-time prover (as the cost of native evaluation of the instance also scales linearly as a function of <span class="math">N</span>). Nonetheless, since <span class="math">\\lambda</span> should be thought of as <span class="math">\\omega(\\log N)</span>, we do not consider a multiexponentation of size <span class="math">N</span> to be a linear-time operation.</p>

    <p class="text-gray-300">In summary, we do not consider FFTs and multiexponentations of size <span class="math">O(N)</span> to be linear-time operations, but do consider Merkle-hashing of vectors of size <span class="math">O(N)</span> to be linear-time.</p>

    <h5 id="sec-4" class="text-base font-semibold mt-4">Closely related work.</h5>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Building on Bootle et al. <em>[21]</em>, Bootle, Chiesa, and Groth <em>[22]</em> give an interactive oracle proof (IOP) <em>[15]</em> with constant soundness error, in which the prover’s work is <span class="math">O(N)</span> finite field operations for an <span class="math">N</span>-sized R1CS instance over any finite field of size <span class="math">\\Omega(N)</span>. Here, an interactive oracle proof (IOP) <em>[15, 72]</em> is a generalization of an interactive proof, where in each round, the prover sends a string as an oracle, and the verifier may read one or more entries in the oracle. To achieve soundness error that is exponentially small in the security parameter <span class="math">\\lambda</span> in the IOP of <em>[22]</em>, one must restrict to R1CS instances over a “sufficiently large” finite field i.e., where $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=2^{\\Theta(\\lambda)}$, or else sacrifice the linear-time prover.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">Applying standard transformations to their IOP, one can obtain a SNARG in the random oracle model with similar prover costs, or an interactive argument assuming linear-time computable cryptographic hash functions <em>[5]</em>. Unlike prior SNARGs (even those with a <em>quasi</em>-linear time prover), the resulting protocol does not require the field to be FFT-friendly nor discrete-log friendly.</p>

    <p class="text-gray-300">Their IOP construction does not achieve zero-knowledge nor polylogarithmic proofs and verification times (the proof sizes and verification times are <span class="math">O_{\\lambda}(N^{1/t})</span>, where <span class="math">t</span> is a constant, and not <span class="math">O_{\\lambda}(\\log N)</span> or <span class="math">O_{\\lambda}(1)</span>). Bootle, Chiesa, and Liu <em>[24]</em> address these issues by achieving zero-knowledge as well as polylogarithmic proof sizes and verification times (a more detailed discussion of the relationship between our results and those of <em>[24]</em> can be found in Appendix C). Both <em>[22]</em> and <em>[24]</em> are theoretical in nature; they do not implement their schemes nor report performance results.</p>

    <p class="text-gray-300">There is also very recent work related to our goal of working over arbitrary finite fields. Ben-Sasson et al. <em>[11, 12]</em> improve the efficiency of FFT-like algorithms that apply over fields with no smooth order root of unity, by a factor of <span class="math">\\exp(\\log^{<em>}N)</span>. An explicit motivation for their work is to improve the efficiency of known SNARKs that perform FFTs (e.g., Fractal </em>[36]<em>) when operating over “non-FFT-friendly” fields. These results do not eliminate the superlinearity of the prover’s runtime in their target SNARKs. The algorithms given in </em>[11, 12]* also perform significant pre-computation that is field-specific and have not to date yielded implemented SNARKs. We seek (and achieve) high-speed SNARKs that require only black-box access to the addition and multiplication operations of the field, with the only additional information required being a lower bound on the field size to ensure soundness.</p>

    <p class="text-gray-300">In summary, prior works leave open the problem of achieving concretely efficient SNARKs that support arbitrary (sufficiently large) finite fields, much less one with a linear-time prover.</p>

    <h3 id="sec-5" class="text-xl font-semibold mt-8">1.1 Results and contributions</h3>

    <p class="text-gray-300">We address the above problems with <em>Brakedown</em>, a new linear-time field-agnostic SNARK that we design, implement, optimize, and experimentally evaluate. Concretely, Brakedown achieves the fastest SNARK prover in the literature, even over fields to which prior SNARKs apply. We also implement and evaluate <em>Shockwave</em>, a variant of Brakedown that reduces proof sizes and verification times at the cost of sacrificing a linear-time prover, but nonetheless provides a faster prover than prior plausibly post-quantum SNARKs. Brakedown and Shockwave are unconditionally secure in the random oracle model.</p>

    <h4 id="sec-6" class="text-lg font-semibold mt-6">SNARK design background.</h4>

    <p class="text-gray-300">Modern SNARKs work by combining a type of interactive protocol called a <em>polynomial IOP</em> <em>[30]</em> with a cryptographic primitive called a <em>polynomial commitment scheme</em> <em>[55]</em>. The combination yields succinct <em>interactive</em> argument, which can then be rendered non-interactive via the Fiat-Shamir transformation <em>[41]</em>, yielding a SNARK.</p>

    <p class="text-gray-300">Roughly, a polynomial IOP is an interactive protocol where, in one or more rounds, the prover “sends” to the verifier a very large polynomial <span class="math">q</span>. Because <span class="math">q</span> is so large, one does not wish for the verifier to read a complete description of <span class="math">q</span>. Instead, the verifier only “queries” <span class="math">q</span> at one point (or a handful of points). This means that the only information the verifier needs about <span class="math">q</span> to check that the prover is behaving honestly is one (or a few) evaluations of <span class="math">q</span>.</p>

    <p class="text-gray-300">In turn, a polynomial commitment scheme enables an untrusted prover to succinctly <em>commit</em> to a polynomial <span class="math">q</span>, and later provide to the verifier any evaluation <span class="math">q(r)</span> for a point <span class="math">r</span> chosen by the verifier, along with a proof that the returned value is indeed consistent with the committed polynomial.</p>

    <p class="text-gray-300">Essentially, a polynomial commitment scheme is exactly the cryptographic primitive that one needs to obtain a succinct argument from a polynomial IOP. Rather than having the prover send a large polynomial <span class="math">q</span> to the verifier as in the polynomial IOP, the argument system prover cryptographically commits to <span class="math">q</span> and later reveals any evaluations of <span class="math">q</span> required by the verifier to perform its checks.</p>

    <h4 id="sec-7" class="text-lg font-semibold mt-6">Design of our linear-time SNARK.</h4>

    <p class="text-gray-300">We first distill from <em>[22]</em> a polynomial commitment scheme with a linear-time commitment procedure, and show that it satisfies extractability, a key property required in the context of SNARKs (the commitment scheme itself is little more than a rephrasing of the results in</p>

    <p class="text-gray-300"><em>[22]</em>, though <em>[22]</em> did not analyze extractability). This improves over the prior state-of-the-art polynomial commitment schemes <em>[55, 92, 87, 91, 30, 78, 60]</em> by offering the first in which the time to commit to a polynomial is linear in the size of the polynomial. We focus on multilinear polynomials over the Lagrange basis, but the scheme generalizes to many other types of polynomials such as univariate polynomials over the standard monomial basis (see e.g., <em>[60]</em>).</p>

    <p class="text-gray-300">To obtain linear-time SNARKs for R1CS, we first make explicit a polynomial IOP for R1CS from Spartan <em>[75]</em> and then use our new linear-time polynomial commitment scheme in conjunction with prior compilers <em>[75, 30]</em> to transform it into a SNARK for R1CS.</p>

    <h4 id="sec-8" class="text-lg font-semibold mt-6">A new and concretely fast linear-time encodable code.</h4>

    <p class="text-gray-300">A major component in the linear-time polynomial commitment scheme that we distill from <em>[22]</em> is a linear-time encodable linear code. Unfortunately, to the best of our knowledge, existing linear-time encodable codes are highly impractical. We therefore design a new linear-time encodable code that is concretely fast in our context. Our code builds on classic results <em>[43, 80, 40]</em>, but designing this code is involved and represents a significant technical contribution. We achieve a fast linear code that works over any (sufficiently large) field by leveraging the following four observations: (1) In our setting, to achieve sublinear sized proofs, it is sufficient for the code to achieve relative Hamming distance only a small constant, rather than very close to 1 (higher minimum distance would improve Brakedown’s proof length by a constant factor, but would not meaningfully reduce the prover time); (2) Efficient decoding is not necessary for reasons elaborated upon below; (3) We can (and indeed want to) work over large fields, say, of size at least <span class="math">2^{127}</span>; and (4) We can use randomized constructions instead of deterministic constructions of pseudorandom objects, so long as the probability that the construction fails to satisfy the necessary distance properties is cryptographically small (e.g., <span class="math">\\leq 2^{-100}</span>).</p>

    <p class="text-gray-300">Observation (2) holds for the following two reasons: (1) the prover and verifier only execute the code’s encoding procedure (this observation also appears in prior work <em>[22]</em>); (2) we describe an efficient extractor for our polynomial commitment scheme that does not invoke the code’s decoding procedure. Hence, efficient decoding is not even needed to establish that our SNARK is knowledge-sound.</p>

    <p class="text-gray-300">Observations (1)–(4) together allow us to strip out much of the complexity of prior constructions. For example, Spielman’s celebrated work <em>[80]</em> is focused on achieving both linear-time encoding and decoding, while Druk and Ishai <em>[40]</em> focus on improving the minimum distance of Spielman’s code. On top of this, we further optimize and simplify the code construction, and provide a detailed, quantitative analysis to show that the probability our code fails to achieve the necessary minimum distance is cryptographically small.</p>

    <h4 id="sec-9" class="text-lg font-semibold mt-6">Implementation, optimization, and experimental results.</h4>

    <p class="text-gray-300">We implement the aforementioned linear-time SNARK, yielding a system we call Brakedown. Because our linear-time code works over any (sufficiently large) field, and the polynomial IOP from Spartan does as well, Brakedown is field-agnostic. This is the first built SNARK to achieve this property. It is also the first built system with a linear-time prover and sub-linear proof sizes and verification times.</p>

    <p class="text-gray-300">We also implement Shockwave, a variant of Brakedown that uses Reed-Solomon codes instead of our fast linear-time code. Since Shockwave uses Reed-Solomon codes, it is not a linear-time SNARK and requires an FFT-friendly finite field, but it provides concretely shorter proofs and lower verification times than Brakedown and is faster than prior plausibly post-quantum secure SNARKs.</p>

    <p class="text-gray-300">Both Shockwave and Brakedown contain simple but crucial concrete optimizations to the polynomial commitment scheme to reduce proof sizes. Neither Shockwave’s nor Brakedown’s implementations are currently zero-knowledge. However, Shockwave can be rendered zero-knowledge using standard techniques with minimal overhead <em>[4, 89, 34]</em>. Brakedown could be rendered zero-knowledge while maintaining linear prover time by using one layer of recursive composition with zkShockwave (or another zkSNARK). Indeed, subsequent work, called Orion <em>[90]</em>, uses Virgo <em>[91]</em> to prove in zero-knowledge the knowledge of valid proofs produced by (a variant of) Brakedown. It is also plausible that Brakedown could be rendered zero-knowledge more directly using techniques from <em>[24]</em>.</p>

    <p class="text-gray-300">In terms of experimental results, Brakedown achieves a faster prover than all prior SNARKs for R1CS. Its primary downside is that its proofs are on the larger side, but they are still far smaller than the size of</p>

    <p class="text-gray-300">the NP-witness for R1CS instance sizes beyond several million constraints. Shockwave reduces Brakedown’s proof sizes and verification times by about a factor of <span class="math">6\\times</span>, at the cost of a slower prover (both asymptotically and concretely). Nonetheless, Shockwave already features a concretely faster prover than prior plausibly post-quantum SNARKs. Furthermore, although Shockwave’s proof sizes are somewhat larger than most prior schemes with sublinear proof size, they are surprisingly competitive with prior post-quantum schemes such as Fractal <em>[36]</em> and Aurora <em>[14]</em> that have lower <em>asymptotic</em> proof size (polylog(<span class="math">N</span>) rather than <span class="math">\\Theta_{\\lambda}(\\sqrt{N})</span>). Its verification times are competitive with discrete-logarithm based schemes, and in fact superior to prior plausibly post-quantum SNARKs.</p>

    <h5 id="sec-10" class="text-base font-semibold mt-4">Public parameter generation.</h5>

    <p class="text-gray-300">The public parameters of Brakedown include a description of the encoding procedure of our error-correcting code. This involves randomly generating certain sparse matrices (we provide details of this in Section 5.1). Our implementation generates the matrices deterministically using a cryptographic PRG with a public, fixed seed, which could be chosen in a “nothing-up-my-sleeve” way (e.g., as in Bulletproofs <em>[28]</em>). Generating the matrices is concretely fast: our implementation takes under 700 milliseconds to sample parameters suitable for encoding inputs of length <span class="math">2^{20}</span>, and 22 seconds for encoding inputs of length <span class="math">2^{25}</span>. The latter setting is suitable for committing to polynomials of degree over <span class="math">2^{40}</span>, and for giving SNARKs for R1CS instances with roughly <span class="math">2^{40}</span> constraints. Note that any party acting as the prover or verifier in Brakedown need only generate these matrices once, no matter how many times the SNARK is used.</p>

    <h3 id="sec-11" class="text-xl font-semibold mt-8">1.2 Subsequent work on linear-time provers</h3>

    <p class="text-gray-300">Xie et al. <em>[90]</em> compose Brakedown with a different SNARK called Virgo <em>[91]</em> that requires an FFT-friendly field but has smaller proofs. This asymptotically reduces the proof size from <span class="math">\\Theta_{\\lambda}(\\sqrt{N})</span> to <span class="math">\\Theta_{\\lambda}(\\log^{2}N)</span>. The resulting implementation, called Orion, requires an FFT-friendly field, but has substantially smaller proofs than Brakedown, and a slightly faster prover due to the improved code parameters. Orion+ <em>[33]</em> improves Brakedown (this work) and the work of Xie et al. <em>[90]</em> by providing proofs of <span class="math">\\approx</span>10 KB at the cost of requiring a (universal) trusted setup and giving up plausible post-quantum security. Vortex <em>[7]</em> builds on Brakedown and uses lattice-based hash functions for improved recursion capabilities. Diamond and Posen <em>[38]</em> reduce the proof size and prover time of Brakedown by a factor of close to 2, by showing that the testing and evaluation phases of Brakedown’s polynomial commitment scheme can be consolidated if the evaluation queries are random, as they are in Brakedown’s SNARKs. Haböck <em>[50]</em> improves the concrete parameters of Brakedown’s linear-time encodable code, including over fields as small as 31 bits.</p>

    <p class="text-gray-300">Recent theoretical works have obtained interactive arguments with constant soundness error and a linear-time prover even over small fields <em>[74, 23, 53]</em>.</p>

    <h3 id="sec-12" class="text-xl font-semibold mt-8">1.3 Roadmap</h3>

    <p class="text-gray-300">Section 3 describes a linear-time polynomial IOP for R1CS implicit in Spartan <em>[75]</em>. Section 4 describes a linear-time polynomial commitment scheme distilled from <em>[22]</em> with proof size <span class="math">N^{\\epsilon}</span> for any desired constant <span class="math">\\epsilon&gt;0</span>. Section 4.1 gives a self-contained description and security analysis (including extractability) of the the polynomial commitment scheme when <span class="math">\\epsilon=1/2</span>, along with important concrete optimizations. (Appendix B provides a concretely improved security analysis of the polynomial commitment scheme when instantiated with the Reed-Solomon code as used in one of our two implemented systems, namely Shockwave.) Section 5 describes the construction and analysis of our concretely efficient linear-time-encodable linear error-correcting code used in our polynomial commitment scheme implementation within Brakedown. Section 6 extends the polynomial commitment scheme to handle sparse polynomials efficiently using techniques from Spartan <em>[75]</em>. Section 7 obtains linear-time SNARKs for R1CS by combining the polynomial IOP from Spartan with the polynomial commitment schemes derived in Sections 4-6.</p>

    <p class="text-gray-300">Performance results for our implemented SNARKs (Brakedown and Shockwave) are detailed in Section 8.</p>

    <p class="text-gray-300">##</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We use  <span class="math">\\mathbb{F}</span>  to denote a finite field,  <span class="math">\\lambda</span>  to denote the security parameter, and  <span class="math">\\operatorname{negl}((\\lambda)</span>  to denote a negligible function in  <span class="math">\\lambda</span> . Unless we specify otherwise,  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= 2^{\\Theta(\\lambda)}$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Polynomials. We recall a few basic facts about polynomials. Detailed treatment of these facts can be found elsewhere [82].</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>A polynomial over  <span class="math">\\mathbb{F}</span>  is an expression consisting of a sum of monomials where each monomial is the product of a constant and powers of one or more variables (which take values from  <span class="math">\\mathbb{F}</span> ); all arithmetic is performed over  <span class="math">\\mathbb{F}</span> .</li>

      <li>The degree of a monomial is the sum of the exponents of variables in the monomial; the (total) degree of a polynomial  <span class="math">g</span>  is the maximum degree of any monomial in  <span class="math">g</span> . Also, the degree of a polynomial  <span class="math">g</span>  in a particular variable  <span class="math">x_{i}</span>  is the maximum exponent that  <span class="math">x_{i}</span>  takes in any of the monomials in  <span class="math">g</span> .</li>

      <li>A multivariate polynomial is a polynomial with more than one variable; otherwise it is called a univariate polynomial. A multivariate polynomial is called a multilinear polynomial if the degree of the polynomial in each variable is at most one.</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Definition 2.1. An R1CS instance is a tuple  <span class="math">(\\mathbb{F}, A, B, C, M, N, \\mathfrak{io})</span> , where  <span class="math">A, B, C \\in \\mathbb{F}^{M \\times M}</span> ,  $M \\geq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathfrak{io}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+ 1<span class="math"> ,  </span>\\mathfrak{io}<span class="math">  denotes the public input and output, and there are at most  </span>N = \\Omega(M)$  non-zero entries in each matrix.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We denote the set of R1CS (instance, witness) pairs as  <span class="math">\\mathcal{R}_{\\mathrm{R1CS}}</span> , defined as:  <span class="math">\\{\\langle (\\mathbb{F}, A, B, C, \\mathfrak{io}, M, N), w \\rangle : A \\cdot (w, 1, \\mathfrak{io}) \\circ B \\cdot (w, 1, \\mathfrak{io}) = C \\cdot (w, 1, \\mathfrak{io})\\}</span> .</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In the rest of the paper, WLOG, we assume that  <span class="math">M</span>  and  <span class="math">N</span>  are powers of 2, and that  $M =</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathfrak{io}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+ 1$ . Throughout this paper, all logarithms are to base 2.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">SNARKs. We adapt the definition provided in [59].</p>

    <p class="text-gray-300">Definition 2.2. Consider a relation  <span class="math">\\mathcal{R}</span>  over public parameters, structure, instance, and witness tuples. A non-interactive argument of knowledge for  <span class="math">\\mathcal{R}</span>  consists of PPT algorithms  <span class="math">(\\mathcal{G},\\mathcal{P},\\mathcal{V})</span>  and deterministic  <span class="math">\\mathcal{K}</span> , denoting the generator, the prover, the verifier and the encoder respectively with the following interface.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{G}(1^{\\lambda})\\to \\mathfrak{pp}</span> : On input security parameter  <span class="math">\\lambda</span> , samples public parameters  <span class="math">\\mathfrak{pp}</span> .</li>

      <li><span class="math">\\mathcal{K}(\\mathsf{pp},\\mathsf{s})\\to (\\mathsf{pk},\\mathsf{vk})</span>  : On input structure s, representing common structure among instances, outputs the prover key pk and verifier key vk.</li>

      <li><span class="math">\\mathcal{P}(\\mathsf{pk}, u, w) \\to \\pi</span> : On input instance  <span class="math">u</span>  and witness  <span class="math">w</span> , outputs a proof  <span class="math">\\pi</span>  proving that  <span class="math">(\\mathsf{pp}, \\mathsf{s}, u, w) \\in \\mathcal{R}</span> .</li>

      <li><span class="math">\\mathcal{V}(\\mathsf{vk}, u, \\pi) \\to \\{0, 1\\}</span> : On input the verifier key  <span class="math">\\mathsf{vk}</span> , instance  <span class="math">u</span> , and a proof  <span class="math">\\pi</span> , outputs 1 if the instance is accepting and 0 otherwise.</li>

    </ul>

    <p class="text-gray-300">A non-interactive argument of knowledge satisfies completeness if for any PPT adversary  <span class="math">\\mathcal{A}</span></p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname * {P r} \\left[ \\begin{array}{l l} &amp;amp; \\mathsf {p p} \\leftarrow \\mathcal {G} (1 ^ {\\lambda}), \\\\ \\mathcal {V} (\\mathsf {v k}, u, \\pi) = 1 &amp;amp; (\\mathsf {s}, (u, w)) \\leftarrow \\mathcal {A} (\\mathsf {p p}), \\\\ &amp;amp; (\\mathsf {p p}, \\mathsf {s}, u, w) \\in \\mathcal {R}, \\\\ &amp;amp; (\\mathsf {p k}, \\mathsf {v k}) \\leftarrow \\mathcal {K} (\\mathsf {p p}, \\mathsf {s}), \\\\ &amp;amp; \\pi \\leftarrow \\mathcal {P} (\\mathsf {p k}, u, w) \\end{array} \\right] = 1.</span></div>

    <p class="text-gray-300">A non-interactive argument of knowledge satisfies knowledge soundness if for all PPT adversaries <span class="math">\\mathcal{A}</span> there exists a PPT extractor <span class="math">\\mathcal{E}</span> such that for all randomness <span class="math">\\rho</span></p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Pr} \\left[ \\begin{array}{l l} \\mathcal{V}(\\mathsf{vk}, u, \\pi) = 1, &amp;amp; \\mathsf{pp} \\leftarrow \\mathcal{G}(1^{\\lambda}), \\\\ (\\mathsf{pp}, \\mathsf{s}, u, w) \\notin \\mathcal{R} &amp;amp; (\\mathsf{s}, u, \\pi) \\leftarrow \\mathcal{A}(\\mathsf{pp}; \\rho), \\\\ &amp;amp; (\\mathsf{pk}, \\mathsf{vk}) \\leftarrow \\mathcal{K}(\\mathsf{pp}, \\mathsf{s}), \\\\ &amp;amp; w \\leftarrow \\mathcal{E}(\\mathsf{pp}, \\rho) \\end{array} \\right] = \\mathsf{negl}(\\lambda).</span></div>

    <p class="text-gray-300">A non-interactive argument of knowledge is succinct if the size of the proof <span class="math">\\pi</span> and the time to verify it are at most polylogarithmic in the size of the statement proven, where a statement includes both the structure and the instance.</p>

    <p class="text-gray-300"><strong>Remark 1.</strong> In this paper, we consider an argument system to be succinct as long as the proof sizes and verification times are sublinear in the size of the statement proven. We accept this weakening as proofs produced by such proof systems can be shortened (both asymptotically and concretely) without substantial overheads using depth-1 recursion (e.g., see a subsequent work called Orion [90]).</p>

    <p class="text-gray-300"><strong>Polynomial commitment scheme.</strong> We adapt the definition from [30]. A polynomial commitment scheme for multilinear polynomials is a tuple of four protocols <span class="math">\\mathsf{PC} = (\\mathsf{Gen}, \\mathsf{Commit}, \\mathsf{Open}, \\mathsf{Eval})</span>:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">pp \\gets \\mathsf{Gen}(1^{\\lambda}, \\mu)</span>: takes as input <span class="math">\\mu</span> (the number of variables in a multilinear polynomial); produces public parameters <span class="math">pp</span>.</li>

      <li><span class="math">\\mathcal{C} \\gets \\mathrm{Commit}(pp, \\mathcal{G})</span>: takes as input a <span class="math">\\mu</span>-variate multilinear polynomial over a finite field <span class="math">\\mathcal{G} \\in \\mathbb{F}[\\mu]</span>; produces a commitment <span class="math">\\mathcal{C}</span>.</li>

      <li><span class="math">b \\gets \\mathrm{Open}(pp, \\mathcal{C}, \\mathcal{G})</span>: verifies the opening of commitment <span class="math">\\mathcal{C}</span> to the <span class="math">\\mu</span>-variate multilinear polynomial <span class="math">\\mathcal{G} \\in \\mathbb{F}[\\mu]</span>; outputs <span class="math">b \\in \\{0,1\\}</span>.</li>

      <li><span class="math">b \\gets \\mathsf{Eval}(pp, \\mathcal{C}, r, v, \\mu, \\mathcal{G})</span> is a protocol between a PPT prover <span class="math">\\mathcal{P}</span> and verifier <span class="math">\\mathcal{V}</span>. Both <span class="math">\\mathcal{V}</span> and <span class="math">\\mathcal{P}</span> hold a commitment <span class="math">\\mathcal{C}</span>, the number of variables <span class="math">\\mu</span>, a scalar <span class="math">v \\in \\mathbb{F}</span>, and <span class="math">r \\in \\mathbb{F}^{\\mu}</span>. <span class="math">\\mathcal{P}</span> additionally knows a <span class="math">\\mu</span>-variate multilinear polynomial <span class="math">\\mathcal{G} \\in \\mathbb{F}[\\mu]</span>. <span class="math">\\mathcal{P}</span> attempts to convince <span class="math">\\mathcal{V}</span> that <span class="math">\\mathcal{G}(r) = v</span>. At the end of the protocol, <span class="math">\\mathcal{V}</span> outputs <span class="math">b \\in \\{0,1\\}</span>.</li>

    </ul>

    <p class="text-gray-300"><strong>Definition 2.3.</strong> A tuple of four protocols <span class="math">(\\mathsf{Gen}, \\mathsf{Commit}, \\mathsf{Open}, \\mathsf{Eval})</span> is an extractable polynomial commitment scheme for multilinear polynomials over a finite field <span class="math">\\mathbb{F}</span> if the following conditions hold.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><strong>Completeness.</strong> For any <span class="math">\\mu</span>-variate multilinear polynomial <span class="math">\\mathcal{G} \\in \\mathbb{F}[\\mu]</span>,</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Pr} \\left\\{ \\begin{array}{c} pp \\leftarrow \\mathsf{Gen}(1^{\\lambda}, \\mu); \\mathcal{C} \\leftarrow \\mathsf{Commit}(pp, \\mathcal{G}); \\\\ \\mathsf{Eval}(pp, \\mathcal{C}, r, v, \\mu, \\mathcal{G}) = 1 \\wedge v = \\mathcal{G}(r) \\end{array} \\right\\} \\geq 1 - \\mathsf{negl}(\\lambda)</span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><strong>Binding.</strong> For any PPT adversary <span class="math">\\mathcal{A}</span>, size parameter <span class="math">\\mu \\geq 1</span>,</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Pr} \\left\\{ \\begin{array}{c} pp \\leftarrow \\mathsf{Gen}(1^{\\lambda}, m); (\\mathcal{C}, \\mathcal{G}_0, \\mathcal{G}_1) = \\mathcal{A}(pp); \\\\ b_0 \\leftarrow \\mathsf{Open}(pp, \\mathcal{C}, \\mathcal{G}_0); b_1 \\leftarrow \\mathsf{Open}(pp, \\mathcal{C}, \\mathcal{G}_1); \\\\ b_0 = b_1 \\neq 0 \\wedge \\mathcal{G}_0 \\neq \\mathcal{G}_1 \\end{array} \\right\\} \\leq \\mathsf{negl}(\\lambda)</span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><strong>Knowledge soundness.</strong> <span class="math">\\mathsf{Eval}</span> is a succinct argument of knowledge for the following NP relation given <span class="math">pp \\gets \\mathsf{Gen}(1^{\\lambda}, \\mu)</span>.</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\mathcal{R}_{\\mathsf{Eval}}(pp) = \\left\\{ \\langle (\\mathcal{C}, r, v), (\\mathcal{G}) \\rangle : \\mathcal{G} \\in \\mathbb{F}[\\mu] \\wedge \\mathcal{G}(r) = v \\wedge \\mathsf{Open}(pp, \\mathcal{C}, \\mathcal{G}) = 1 \\right\\}</span></div>

    <p class="text-gray-300">This section recapitulates the results of Spartan [75] using a subsequent formalism, a polynomial IOP [30]. This is a variant of IOPs [15, 72] where in each round, the prover sends a polynomial as an oracle, and the verifier query may request an evaluation of the polynomial at a point in its domain.</p>

    <p class="text-gray-300">The following theorem formalizes the polynomial IOP at the core of Spartan.</p>

    <p class="text-gray-300">For an R1CS instance, <span class="math">\\mathbb{X}=(\\mathbb{F},A,B,C,M,N,\\mathsf{io})</span>, we interpret the matrices <span class="math">A,B,C</span> as functions mapping domain <span class="math">\\{0,1\\}^{\\log M}\\times\\{0,1\\}^{\\log M}</span> to <span class="math">\\mathbb{F}</span> in the natural way. That is, an input in <span class="math">\\{0,1\\}^{\\log M}\\times\\{0,1\\}^{\\log M}</span> is interpreted as the binary representation of an index <span class="math">(i,j)\\in[M]\\times[M]</span>, where <span class="math">[M]\\coloneqq\\{1,\\ldots,M\\}</span> and the function outputs the <span class="math">(i,j)</span>’th entry of the matrix.</p>

    <h6 id="sec-16" class="text-base font-medium mt-4">Theorem 1 (<em>[75]</em>).</h6>

    <p class="text-gray-300">For any finite field <span class="math">\\mathbb{F}</span>, there exists a polynomial IOP for <span class="math">\\mathcal{R}_{R1CS}</span>, with the following parameters, where <span class="math">M</span> denotes the dimension of the R1CS coefficient matrices, and <span class="math">N</span> denotes the number of non-zero entries in the matrices:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- soundness error is $O(\\log M)/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>round complexity is <span class="math">O(\\log M)</span>;</li>

      <li>at the start of the protocol, the prover sends a single <span class="math">(\\log M-1)</span>-variate multilinear polynomial <span class="math">\\widetilde{W}</span>, and the verifier has a query access to three additional <span class="math">2\\log M</span>-variate multilinear polynomials <span class="math">\\widetilde{A},\\widetilde{B}</span>, and <span class="math">\\widetilde{C}</span>;</li>

      <li>the verifier makes a single evaluation query to each of the four polynomials <span class="math">\\widetilde{W},\\widetilde{A},\\widetilde{B}</span>, and <span class="math">\\widetilde{C}</span>, and otherwise performs <span class="math">O(\\log M)</span> operations over <span class="math">\\mathbb{F}</span>;</li>

      <li>the prescribed prover performs <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span> to compute its messages over the course of the polynomial IOP (and to compute answers to the verifier’s four queries to <span class="math">\\widetilde{W},\\widetilde{A},\\widetilde{B}</span>, and <span class="math">\\widetilde{C}</span>).</li>

    </ul>

    <h6 id="sec-17" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Let <span class="math">s=\\log M</span>. For an R1CS instance, <span class="math">\\mathbb{X}=(\\mathbb{F},A,B,C,M,N,\\mathsf{io})</span> and a purported witness <span class="math">W</span>, let <span class="math">Z=(W,1,\\mathsf{io})</span>. As explained prior to the theorem statement, we can interpret <span class="math">A,B,C</span> as functions mapping <span class="math">\\{0,1\\}^{s}\\times\\{0,1\\}^{s}</span> to <span class="math">\\mathbb{F}</span>, and similarly we interpret <span class="math">Z</span> and <span class="math">(1,\\mathsf{io})</span> as functions with the following respective signatures in the same manner: <span class="math">\\{0,1\\}^{s}\\to\\mathbb{F}</span> and <span class="math">\\{0,1\\}^{s-1}\\to\\mathbb{F}</span>. It is easy to check that the MLE <span class="math">\\widetilde{Z}</span> of <span class="math">Z</span> satisfies</p>

    <p class="text-gray-300"><span class="math">\\widetilde{Z}(X_{1},\\ldots,X_{\\log M})=(1-X_{1})\\cdot\\widetilde{W}(X_{2},\\ldots,X_{\\log M})+X_{1}\\cdot\\widetilde{(1,\\mathsf{io})}(X_{2},\\ldots,X_{\\log M})</span> (1)</p>

    <p class="text-gray-300">Indeed, the right hand side of Equation (1) is a multilinear polynomial, and it is easily checked that <span class="math">\\widetilde{Z}(x_{1},\\ldots,x_{\\log M})=Z(x_{1},\\ldots,x_{\\log M})</span> for all <span class="math">x_{1},\\ldots,x_{\\log M}</span> (since the first half of the evaluations of <span class="math">Z</span> are given by <span class="math">W</span> and the second half are given by the vector <span class="math">(1,\\mathsf{io})</span>). Hence, the right hand side of Equation (1) must be the unique multilinear extension of <span class="math">Z</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">From <em>[75, Theorem 4.1]</em>, checking if <span class="math">(\\mathbb{X},W)\\in\\mathcal{R}_{\\mathrm{R1CS}}</span> is equivalent, except for a soundness error of $\\log M/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> over the choice of </span>\\tau\\in\\mathbb{F}^{s}$, to checking if the following identity holds:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">0\\stackrel{{\\scriptstyle?}}{{=}}\\left(\\sum_{x\\in\\{0,1\\}^{s}}\\widetilde{eq}(\\tau,x)\\cdot\\left(\\left(\\sum_{y\\in\\{0,1\\}^{s}}\\widetilde{A}(x,y)\\cdot\\widetilde{Z}(y)\\right)\\cdot\\left(\\sum_{y\\in\\{0,1\\}^{s}}\\widetilde{B}(x,y)\\cdot\\widetilde{Z}(y)\\right)-\\sum_{y\\in\\{0,1\\}^{s}}\\widetilde{C}(x,y)\\cdot\\widetilde{Z}(y)\\right)\\right),</span> (2)</p>

    <p class="text-gray-300">where <span class="math">\\widetilde{eq}</span> is the MLE of <span class="math">eq:\\{0,1\\}^{s}\\times\\{0,1\\}^{s}\\to\\mathbb{F}</span>:</p>

    <p class="text-gray-300">\\[ eq(x,e)=\\begin{cases}1&\\text{if }x=e\\\\ 0&\\text{otherwise.}\\end{cases} \\]</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">That is, if <span class="math">(\\mathbb{X},W)\\in\\mathcal{R}_{\\mathrm{R1CS}}</span>, then Equation (2) holds with probability <span class="math">1</span> over the choice of <span class="math">\\tau</span>, and if <span class="math">(\\mathbb{X},W)\\not\\in\\mathcal{R}_{\\mathrm{R1CS}}</span>, then Equation (2) holds with probability at most $O(\\log M/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> over the random choice of </span>\\tau$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Consider computing the right hand side of Equation (2) by applying the sum-check protocol to the polynomial</p>

    <p class="text-gray-300"><span class="math">g(x)\\coloneqq\\widetilde{eq}(\\tau,x)\\cdot\\left(\\left(\\sum_{y\\in\\{0,1\\}^{s}}\\widetilde{A}(x,y)\\cdot\\widetilde{Z}(y)\\right)\\cdot\\left(\\sum_{y\\in\\{0,1\\}^{s}}\\widetilde{B}(x,y)\\cdot\\widetilde{Z}(y)\\right)-\\sum_{y\\in\\{0,1\\}^{s}}\\widetilde{C}(x,y)\\cdot\\widetilde{Z}(y)\\right).</span></p>

    <p class="text-gray-300">From the verifier's perspective, this reduces the task of computing the right hand side of Equation (2) to the task of evaluating  <span class="math">g</span>  at a random input  <span class="math">r_x \\in \\mathbb{F}^s</span> . Note that the verifier can evaluate  <span class="math">\\widetilde{eq}(\\tau, r_x)</span>  unassisted in  <span class="math">O(\\log M)</span>  field operations, as it is easily checked that  <span class="math">\\widetilde{eq}(\\tau, r_x) = \\prod_{i=1}^{s} (\\tau_i r_{x,i} + (1 - \\tau_i)(1 - r_{x,i}))</span> . With  <span class="math">\\widetilde{eq}(\\tau, r_x)</span>  in hand,  <span class="math">g(r_x)</span>  can be computed in  <span class="math">O(1)</span>  time given the three quantities</p>

    <div class="my-4 text-center"><span class="math-block">\\sum_ {y \\in \\{0, 1 \\} ^ {s}} \\widetilde {A} (r _ {x}, y) \\cdot \\widetilde {Z} (y),</span></div>

    <div class="my-4 text-center"><span class="math-block">\\sum_ {y \\in \\{0, 1 \\} ^ {s}} \\widetilde {B} (r _ {x}, y) \\cdot \\widetilde {Z} (y),</span></div>

    <p class="text-gray-300">and</p>

    <div class="my-4 text-center"><span class="math-block">\\sum_ {y \\in \\{0, 1 \\} ^ {s}} \\widetilde {C} (r _ {x}, y) \\cdot \\widetilde {Z} (y).</span></div>

    <p class="text-gray-300">These three quantities can be computed by applying the sum-check protocol three more times in parallel, once to each of the following three polynomials (using the same random vector of field elements,  <span class="math">r_y \\in \\mathbb{F}^s</span> , in each of the three invocations):</p>

    <div class="my-4 text-center"><span class="math-block">\\widetilde {A} (r _ {x}, y) \\cdot \\widetilde {Z} (y),</span></div>

    <div class="my-4 text-center"><span class="math-block">\\widetilde {B} (r _ {x}, y) \\cdot \\widetilde {Z} (y),</span></div>

    <div class="my-4 text-center"><span class="math-block">\\widetilde {C} (r _ {x}, y) \\cdot \\widetilde {Z} (y).</span></div>

    <p class="text-gray-300">To perform the verifier's final check in each of these three invocations of the sum-check protocol, it suffices for the verifier to evaluate each of the above 3 polynomials at the random vector  <span class="math">r_y</span> , which means it suffices for the verifier to evaluate  <span class="math">\\widetilde{A}(r_x, r_y)</span> ,  <span class="math">\\widetilde{B}(r_x, r_y)</span> ,  <span class="math">\\widetilde{C}(r_x, r_y)</span> , and  <span class="math">\\widetilde{Z}(r_y)</span> . The first three evaluations can be obtained via the verifier's assumed query access to  <span class="math">\\widetilde{A}</span> ,  <span class="math">\\widetilde{B}</span> , and  <span class="math">\\widetilde{C}</span> .  <span class="math">\\widetilde{Z}(r_y)</span>  can be obtained from one query to  <span class="math">\\widetilde{W}</span>  and one query to  <span class="math">(1, \\widetilde{\\iota} \\omega)</span>  via Equation (1).</p>

    <p class="text-gray-300">In summary, we have the following polynomial IOP:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{P} \\to \\mathcal{V}</span> : a  <span class="math">(\\log M - 1)</span> -variate multilinear polynomial  <span class="math">\\widetilde{W}</span>  as an oracle.</li>

      <li><span class="math">\\mathcal{V}\\to \\mathcal{P}</span>  ..  <span class="math">\\tau \\in_{R}\\mathbb{F}^{s}</span></li>

      <li><span class="math">\\mathcal{V} \\leftrightarrow \\mathcal{P}</span> : run the sum-check reduction to reduce the check in Equation (2) to checking if the following hold, where  <span class="math">r_x, r_y</span>  are vectors in  <span class="math">\\mathbb{F}^s</span>  chosen at random by the verifier over the course of the sum-check protocol:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\widetilde{A}(r_x, r_y) \\stackrel{?}{=} v_A</span> ,  <span class="math">\\widetilde{B}(r_x, r_y) \\stackrel{?}{=} v_B</span> , and  <span class="math">\\widetilde{C}(r_x, r_y) \\stackrel{?}{=} v_C</span> ; and</li>

      <li><span class="math">\\widetilde{Z}(r_y) \\stackrel{?}{=} v_Z</span> .</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}</span> :</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>check if  <span class="math">\\widetilde{A}(r_x, r_y) \\stackrel{?}{=} v_A</span> ,  <span class="math">\\widetilde{B}(r_x, r_y) \\stackrel{?}{=} v_B</span> , and  <span class="math">\\widetilde{C}(r_x, r_y) \\stackrel{?}{=} v_C</span> , with one query to each of  <span class="math">\\widetilde{A}, \\widetilde{B}, \\widetilde{C}</span> ;</li>

      <li>check if  <span class="math">\\widetilde{Z}(r_y) \\stackrel{?}{=} v_Z</span>  by checking if:  <span class="math">v_Z = (1 - r_y[1]) \\cdot v_W + r_y[1] \\cdot (\\widetilde{io,1})(r_y[2..])</span> , where  <span class="math">r_y[2..]</span>  refers to a slice of  <span class="math">r_y</span>  without the first element of  <span class="math">r_y</span> , and  <span class="math">v_W \\gets \\widetilde{W}(r_y[2..])</span>  via an oracle query (see Equation (1)).</li>

    </ul>

    <p class="text-gray-300">ompleteness.</p>

    <p class="text-gray-300">Perfect completeness follows from perfect completeness of the sum-check protocol and the fact that Equation (2) holds with probability <span class="math">1</span> over the choice of <span class="math">\\tau</span> if <span class="math">(\\mathbb{X},W)\\in\\mathcal{R}_{\\mathrm{R1CS}}</span>.</p>

    <h4 id="sec-18" class="text-lg font-semibold mt-6">Soundness.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Applying a standard union bound to the soundness error introduced by probabilistic check in Equation (2) with the soundness error of the sum-check protocol <em>[65]</em>, we conclude that the soundness error for the depicted polynomial IOP as at most $O(\\log M)/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-19" class="text-lg font-semibold mt-6">Round and communication complexity.</h4>

    <p class="text-gray-300">The sum-check protocol is applied <span class="math">4</span> times (although <span class="math">3</span> of the invocations occur in parallel and in practice combined into one <em>[75]</em>). In each invocation, the polynomial to which the sum-check protocol is applied has degree at most <span class="math">3</span> in each variable, and the number of variables is <span class="math">s=\\log M</span>. Hence, the round complexity of the polynomial IOP is <span class="math">O(\\log M)</span>. Since each polynomial has degree at most <span class="math">3</span> in each variable, the total communication cost is <span class="math">O(\\log M)</span> field elements.</p>

    <h4 id="sec-20" class="text-lg font-semibold mt-6">Verifier time.</h4>

    <p class="text-gray-300">The asserted bounds on the verifier’s runtime are immediate from the verifier’s runtime in the sum-check protocol, and the fact that <span class="math">\\widetilde{eq}</span> can be evaluated at any input <span class="math">(\\tau,r_{x})\\in\\mathbb{F}^{2s}</span> in <span class="math">O(\\log M)</span> field operations.</p>

    <h4 id="sec-21" class="text-lg font-semibold mt-6">Prover Time.</h4>

    <p class="text-gray-300"><em>[75]</em> shows how to implement the prover’s computation in the polynomial IOP in <span class="math">O(N)</span> <span class="math">\\mathbb{F}</span>-ops using prior techniques for linear-time sum-checks <em>[81, 89]</em> (see also <em>[82, Section 7.5.2]</em> for an exposition). This includes the time required to compute <span class="math">\\widetilde{A}(r_{x},r_{y})</span>, <span class="math">\\widetilde{B}(r_{x},r_{y})</span>, <span class="math">\\widetilde{C}(r_{x},r_{y})</span>, and <span class="math">\\widetilde{Z}(r_{y})</span> (i.e., to compute answers to the verifier’s queries to the polynomials <span class="math">\\widetilde{A}</span>, <span class="math">\\widetilde{B}</span>, <span class="math">\\widetilde{C}</span>, and <span class="math">\\widetilde{Z}</span>). ∎</p>

    <h2 id="sec-22" class="text-2xl font-bold">4 Linear-time polynomial commitments</h2>

    <p class="text-gray-300">We distill from Bootle et al. <em>[22]</em> a result establishing the existence of a linear-time commitment scheme for multilinear polynomials over the Lagrange basis with proofs of size <span class="math">O(N^{1/t})</span> for any desired integer constant <span class="math">t&gt;0</span>. Note that this result is implicit in their work.</p>

    <p class="text-gray-300">We then explicitly describe the linear-time polynomial commitment scheme for the case when the parameter <span class="math">t=2</span>. We additionally describe optimizations and prove that the scheme satisfies knowledge soundness.</p>

    <h6 id="sec-23" class="text-base font-medium mt-4">A general result distilled from Bootle et al. <em>[22]</em>.</h6>

    <h6 id="sec-24" class="text-base font-medium mt-4">Theorem 2.</h6>

    <p class="text-gray-300">For security parameter <span class="math">\\lambda</span> and a positive integer <span class="math">t</span>, given a hash function that can compute a Merkle-hash of <span class="math">N</span> elements of <span class="math">\\mathbb{F}</span> with the same time complexity as <span class="math">O(N)</span> <span class="math">\\mathbb{F}</span>-ops, there exists a linear-time polynomial commitment scheme for multilinear polynomials. Specifically, there exists an algorithm that, given as input the coefficient vector of an <span class="math">\\ell</span>-variate multilinear polynomial over <span class="math">\\mathbb{F}</span> over the Lagrange basis, with <span class="math">N=2^{\\ell}</span>, commits to the polynomial, where:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>the size of the commitment is <span class="math">O_{\\lambda}(1)</span>; and</li>

      <li>the running time of the commit algorithm is <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span>.</li>

    </ul>

    <p class="text-gray-300">Furthermore, there exists a non-interactive argument of knowledge in the random oracle model to prove the correct evaluation of a committed polynomial with the following parameters:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>the prover’s running time is <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span>;</li>

      <li>the verifier’s running time is <span class="math">O_{\\lambda}(N^{1/t})</span> operations over <span class="math">\\mathbb{F}</span>; and</li>

      <li>the proof size is <span class="math">O_{\\lambda}(N^{1/t})</span>.</li>

    </ul>

    <p class="text-gray-300">A proof of this theorem is in Appendix A.</p>

    <h3 id="sec-25" class="text-xl font-semibold mt-8">4.1 Polynomial commitments for <span class="math">t=2</span></h3>

    <h4 id="sec-26" class="text-lg font-semibold mt-6">Notation.</h4>

    <p class="text-gray-300"><span class="math">g</span> is a multilinear polynomial with <span class="math">n</span> coefficients. We assume for simplicity that <span class="math">n=m^{2}</span> for some integer <span class="math">m</span>. Let <span class="math">u</span> denote the coefficient vector of <span class="math">g</span> in the Lagrange basis (equivalently, <span class="math">u</span> is the vector of all evaluations of <span class="math">g</span> over inputs in <span class="math">\\{0,1\\}^{\\log n}</span>). Recalling that <span class="math">[m]=\\{1,\\ldots,m\\}</span>, we can naturally index entries of <span class="math">u</span> by elements of the set <span class="math">[m]^{2}</span>. It is well known that for any input <span class="math">r</span> to <span class="math">g</span> there exist vectors <span class="math">q_{1},q_{2}\\in\\mathbb{F}^{m}</span> such that <span class="math">g(r)=\\langle(q_{1}\\otimes q_{2}),u\\rangle</span>.</p>

    <p class="text-gray-300">For each <span class="math">i\\in[m]</span>, let us view <span class="math">u</span> as an <span class="math">m\\times m</span> matrix, and let <span class="math">u_{i}</span> denote the <span class="math">i</span>th row of this matrix, i.e., <span class="math">u_{i}=\\{u_{i,j}\\}_{j\\in[m]}</span>.</p>

    <p class="text-gray-300">Let <span class="math">N=\\rho^{-1}\\cdot m</span>, and let <span class="math">\\mathsf{Enc}\\colon\\mathbb{F}^{m}\\to\\mathbb{F}^{N}</span> denote the encoding function of a linear code with constant rate <span class="math">\\rho&gt;0</span> and constant relative distance <span class="math">\\gamma&gt;0</span>. We assume that <span class="math">\\mathsf{Enc}</span> runs in time proportional to that required to perform <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span>. We assume for simplicity that <span class="math">\\mathsf{Enc}</span> is systematic, since explicit systematic codes with the properties we require are known <em>[80]</em>.</p>

    <h4 id="sec-27" class="text-lg font-semibold mt-6">Commitment phase.</h4>

    <p class="text-gray-300">Let <span class="math">\\hat{u}=\\{\\mathsf{Enc}(u_{i})\\}_{i\\in[m]}\\in\\left(\\mathbb{F}^{N}\\right)^{m}</span> denote the vector obtained by encoding each row of <span class="math">u</span>. In the IOP setting, the commitment to <span class="math">u</span> is just the vector <span class="math">\\hat{u}</span>, i.e., the prover sends <span class="math">\\hat{u}</span> to the verifier, and the verifier is given point query access to <span class="math">\\hat{u}</span>. In the derived polynomial commitment scheme in the plain or random oracle model, the commitment to <span class="math">u</span> will be the Merkle-hash of the vector <span class="math">\\hat{u}</span>. As with <span class="math">u</span>, we may view <span class="math">\\hat{u}</span> as a matrix, with <span class="math">\\hat{u}_{i}\\in\\mathbb{F}^{N}</span> denoting the <span class="math">i</span>th row of <span class="math">\\hat{u}</span> for <span class="math">i\\in[m]</span>.</p>

    <h4 id="sec-28" class="text-lg font-semibold mt-6">Testing phase.</h4>

    <p class="text-gray-300">Upon receiving the commitment message, the IOP verifier will interactively test it to confirm that each “row” of <span class="math">u</span> is indeed (close to) a codeword of <span class="math">\\mathsf{Enc}</span>. We describe this process as occurring in a separate “testing phase” so as to keep the commitment size constant in the plain or random oracle models. In practice, the testing phase can occur during the commit phase, during the evaluation phase, or sometime in between the two.</p>

    <p class="text-gray-300">The verifier sends the prover a random vector <span class="math">r\\in\\mathbb{F}^{m}</span>, and the prover sends a vector <span class="math">u^{\\prime}\\in\\mathbb{F}^{m}</span> claimed to equal the random linear combination of the <span class="math">m</span> rows of <span class="math">u</span>, in which the coefficients of the linear combination are given by <span class="math">r</span>. The verifier reads <span class="math">u^{\\prime}</span> in its entirety.</p>

    <p class="text-gray-300">Next, the verifier tests <span class="math">u^{\\prime}</span> for consistency with <span class="math">\\hat{u}</span>. That is, the verifier will pick <span class="math">\\ell=\\Theta(\\lambda)</span> random entries of the codeword <span class="math">\\mathsf{Enc}(u^{\\prime})\\in\\mathbb{F}^{N}</span> and confirm that <span class="math">\\mathsf{Enc}(u^{\\prime})</span> is consistent with <span class="math">v\\in\\mathbb{F}^{N}</span> at those entries, where <span class="math">v</span> is:</p>

    <p class="text-gray-300"><span class="math">\\sum_{i=1}^{m}r_{i}\\hat{u}_{i}\\in\\mathbb{F}^{N}.</span> (3)</p>

    <p class="text-gray-300">Observe that, by definition of <span class="math">v</span> (Equation (3)), any individual entry <span class="math">v_{j}</span> of <span class="math">v</span> can be learned by querying <span class="math">m</span> entries of <span class="math">\\hat{u}</span> (we refer to these <span class="math">m</span> entries as the “<span class="math">j</span>’th column” of <span class="math">\\hat{u}</span>). Meanwhile, since the verifier reads <span class="math">u^{\\prime}</span> in its entirety; <span class="math">\\mathcal{V}</span> can compute <span class="math">\\mathsf{Enc}(u^{\\prime})_{j}</span> for all desired <span class="math">j\\in[N]</span> in <span class="math">O(m)</span> time.</p>

    <h4 id="sec-29" class="text-lg font-semibold mt-6">Evaluation phase.</h4>

    <p class="text-gray-300">Let <span class="math">q_{1},q_{2}\\in\\mathbb{F}^{m}</span> be such that <span class="math">g(r)=\\langle(q_{1}\\otimes q_{2}),u\\rangle.</span> The evaluation phase is identical to the testing phase, except that <span class="math">r</span> is replaced with <span class="math">q_{1}</span> (and the verifier uses fresh randomness to choose the sets of coordinates used for consistency testing). Let <span class="math">u^{\\prime\\prime}\\in\\mathbb{F}^{m}</span> denote the vector that the prover sends in this phase, which is claimed to equal <span class="math">\\sum_{i=1}^{m}q_{1,i}\\cdot u_{i}</span>. If the prover is honest, then <span class="math">u^{\\prime\\prime}</span> satisfies <span class="math">\\langle u^{\\prime\\prime},q_{2}\\rangle=\\langle(q_{1}\\otimes q_{2}),u\\rangle</span>. Hence, if the verifier’s consistency tests all pass in the testing and evaluation phases, the verifier outputs <span class="math">\\langle u^{\\prime\\prime},q_{2}\\rangle</span> as <span class="math">g(r)</span>.</p>

    <h4 id="sec-30" class="text-lg font-semibold mt-6">Concrete optimizations to the commitment scheme.</h4>

    <p class="text-gray-300">We discuss optimizations to reduce proof sizes in the testing and evaluation phases by large constant factors without affecting the correctness guarantees of the commitment scheme.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In settings where the evaluation phase will only be run once, the testing phase and evaluation phase can be run in parallel and the same query set <span class="math">Q</span> can be used for both testing and evaluation. This saves <span class="math">\\approx 2\\times</span> in proof sizes.</li>

    </ul>

    <p class="text-gray-300">Description of polynomial commitment in the language of IOPs. Following standard transformations <em>[57, 66, 83, 15]</em>, in the actual polynomial commitment scheme, vectors sent by the prover in the IOP may be replaced with a Merkle-commitment to that vector, and each query the verifier makes to a vector is answered by the prover along with Merkle-tree authentication path for the answer. Each phase of the scheme can be rendered non-interactive using the Fiat-Shamir transformation <em>[41]</em>.</p>

    <p class="text-gray-300">Commit phase.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{P}\\to\\mathcal{V}</span>: a vector <span class="math">\\hat{u}=(\\hat{u}_{1},\\dots,\\hat{u}_{m})\\in\\left(\\mathbb{F}^{N}\\right)^{m}</span>. If <span class="math">\\mathcal{P}</span> is honest, each “row” <span class="math">\\hat{u}_{i}</span> of <span class="math">\\hat{u}</span> contains a codeword in Enc.</li>

    </ul>

    <p class="text-gray-300">Testing phase.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}\\to\\mathcal{P}:</span> a random vector <span class="math">r\\in\\mathbb{F}^{m}</span>.</li>

      <li><span class="math">\\mathcal{P}\\to\\mathcal{V}</span> sends a vector <span class="math">u^{\\prime}\\in\\mathbb{F}^{m}</span> claimed to equal <span class="math">v=\\sum_{i=1}^{m}r_{i}\\cdot u_{i}\\in\\mathbb{F}^{m}</span>.</li>

      <li>//Now <span class="math">\\mathcal{V}</span> probabilistically checks consistency between <span class="math">\\hat{u}</span> and <span class="math">u^{\\prime}</span> (<span class="math">\\mathcal{V}</span> reads <span class="math">u^{\\prime}</span> in entirety).</li>

      <li><span class="math">\\mathcal{V}:</span> chooses <span class="math">Q</span> to be a random set of size <span class="math">\\ell=\\Theta(\\lambda)</span> with <span class="math">Q\\subseteq[N]</span>. For each <span class="math">j\\in Q</span>:</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}</span> queries all <span class="math">m</span> entries of the corresponding “column” of <span class="math">\\hat{u}</span>, namely <span class="math">\\hat{u}_{1,j},\\dots,\\hat{u}_{m,j}</span>.</li>

      <li><span class="math">\\mathcal{V}</span> confirms that <span class="math">\\mathsf{Enc}(u^{\\prime})_{j}=\\sum_{i=1}^{m}r_{i}\\cdot\\hat{u}_{i,j}</span>, halting and rejecting if not.</li>

    </ul>

    <p class="text-gray-300">Evaluation phase.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let <span class="math">q_{1},q_{2}\\in\\mathbb{F}^{m}</span> be such that <span class="math">g(r)=\\langle(q_{1}\\otimes q_{2}),z\\rangle</span>.</li>

      <li>The evaluation phase is identical to the testing phase, except that <span class="math">r</span> is replaced with <span class="math">q_{1}</span> (and fresh randomness is used to choose a set <span class="math">Q^{\\prime}</span> of columns for use in consistency checking).</li>

      <li>If all consistency tests pass, then <span class="math">\\mathcal{V}</span> outputs <span class="math">\\langle u^{\\prime},q_{2}\\rangle</span> as <span class="math">g(r)</span>.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For simplicity, we describe the commitment scheme in the setting where <span class="math">u</span> is indexed by <span class="math">[m]^{2}</span>, i.e., <span class="math">u</span> was viewed as a square matrix, this is not a requirement, and the proof size in the testing and evaluation phases can be substantially reduced by exploiting this flexibility. Specifically, if <span class="math">r</span> and <span class="math">c</span> denote the number of rows and columns of <span class="math">u</span>, so that the number of entries in <span class="math">u</span> is <span class="math">c\\cdot r=N</span>, then the proof length of the commitment scheme is roughly <span class="math">2c+r\\cdot\\ell</span> field elements where <span class="math">\\ell</span> is the number of columns of the encoded matrix opened by the verifier. Here, the <span class="math">2c</span> term comes from the prover sending two different linear combination of the rows of <span class="math">u</span>, one in the commitment phase and one in the evaluation phase, while the <span class="math">r\\cdot\\ell</span> term comes from the verifier querying <span class="math">\\ell</span> different columns of <span class="math">u</span> in the testing and evaluation phases. (This optimization appeared in Ligero <em>[4]</em> in the context of the Reed-Solomon code.) To minimize proof length, one should set <span class="math">c\\approx r\\ell/2</span>, or equivalently, one should set <span class="math">r\\approx\\sqrt{2/\\ell}\\cdot\\sqrt{N}</span> and <span class="math">c\\approx\\sqrt{\\ell/2}\\cdot\\sqrt{N}</span>. This reduces the proof length from roughly <span class="math">\\ell\\cdot\\sqrt{N}</span> if a square matrix is used, to roughly <span class="math">\\sqrt{2\\ell}\\cdot\\sqrt{N}</span>, a savings of a factor of <span class="math">\\sqrt{\\ell/2}</span>. Asymptotically, this means the proof length falls from <span class="math">\\Theta(\\lambda\\sqrt{N})</span> if a square matrix is used, down to <span class="math">\\Theta(\\sqrt{\\lambda N})</span>, a quadratic improvement in the dependence on <span class="math">\\lambda</span>. To achieve soundness error, say, <span class="math">2^{-100}</span>, <span class="math">\\ell</span> will be on the order of hundreds or thousands depending on the relative Hamming distance of the code used, and hence this optimization will lead to a reduction in proof length relative to the use of square matrices by one or more orders of magnitude.</li>

      <li>In settings where the commitment is trusted (e.g., applying the polynomial commitment to achieve holography), the testing phase can be omitted. An additional concrete optimization that applies when working over fields of size smaller than <span class="math">\\exp(\\lambda)</span> is in Appendix B.</li>

      <li>If <span class="math">\\mathcal{P}</span> commits to the vector <span class="math">\\hat{u}\\in(\\mathbb{F}^{N})^{m}</span> with a Merkle tree, then revealing <span class="math">\\ell</span> columns of <span class="math">\\hat{u}</span> in the Testing and Evaluation phases would require providing <span class="math">m\\cdot\\ell</span> Merkle-authentication paths. Naively, this may require <span class="math">\\mathcal{P}</span> to send up to <span class="math">\\Theta(m\\cdot\\ell\\cdot\\log m)</span> hash values. However, by arranging the vector <span class="math">\\hat{u}</span> in column-major order before Merkle-hashing it, the communication cost of revealing <span class="math">\\ell</span> columns of <span class="math">\\hat{u}</span> can be reduced to just the</li>

    </ul>

    <p class="text-gray-300"><span class="math">m\\cdot\\ell</span> requested field elements plus <span class="math">O(\\log m)</span> hash values (a similar optimization appears in prior work <em>[9]</em>).</p>

    <h5 id="sec-31" class="text-base font-semibold mt-4">Soundness analysis for the testing phase.</h5>

    <p class="text-gray-300">The following claim roughly states that if <span class="math">\\hat{u}=(\\hat{u}_{1},\\dots,\\hat{u}_{m})\\in\\left(\\mathbb{F}^{N}\\right)^{m}</span>, then if even a single <span class="math">\\hat{u}_{i}</span> is far from all codewords in Enc, then a random linear combination of the <span class="math">\\hat{u}_{i}</span>’s is also far from all codewords with high probability.</p>

    <h6 id="sec-32" class="text-base font-medium mt-4">Claim 1.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(Ames, Hazay, Ishai, and Venkitasubramaniam <em>[4]</em>, Roth and Zémor) Let <span class="math">\\hat{u}=(\\hat{u}_{1},\\dots,\\hat{u}_{m})\\in\\left(\\mathbb{F}^{N}\\right)^{m}</span> and for each <span class="math">i\\in[m]</span> let <span class="math">c_{i}</span> be the closest codeword in Enc to <span class="math">\\hat{u}_{i}</span>. Let <span class="math">E</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq(\\gamma/3)N<span class="math"> be a subset of the columns </span>j\\in[N]<span class="math"> of </span>\\hat{u}<span class="math"> on which there is even one row </span>i\\in[m]<span class="math"> such that </span>\\hat{u}_{i,j}\\neq c_{i,j}<span class="math">. With probability at least </span>1-(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+1)/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">>1-N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> over the choice of </span>r\\in\\mathbb{F}^{m}<span class="math">, </span>\\sum_{i=1}^{m}r_{i}\\cdot\\hat{u}_{i}<span class="math"> has distance at least </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ from any codeword in Enc.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-33" class="text-base font-medium mt-4">Lemma 1.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">If the prover passes all of the checks in the testing phase with probability at least $N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+(1-\\gamma/3)^{\\ell}<span class="math">, then there is a sequence of </span>m<span class="math"> codewords </span>c_{1},\\dots,c_{m}$ in Enc such that</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$E\\coloneqq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\{j\\in[N]\\colon\\exists i\\in[m]\\text{ such that }c_{i,j}\\neq\\hat{u}_{i,j}\\}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq(\\gamma/3)N.$ (4)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-34" class="text-base font-medium mt-4">Proof.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">d(b,c)</span> denote the relative Hamming distance between two vectors <span class="math">b,c\\in\\mathbb{F}^{N}</span>. Assume by way of contradiction that Equation (4) does not hold. We explain that the prover passes the consistency tests during the testing phase with probability less than $N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+(1-\\gamma/3)^{\\ell}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Recall that <span class="math">v</span> denotes <span class="math">\\sum_{i=1}^{m}r_{i}\\hat{u}_{i}</span>. By Claim 1, the probability over the verifier’s choice of <span class="math">r</span> that there exists a codeword <span class="math">a</span> satisfying <span class="math">d(a,v)&gt;\\gamma/3</span> is less than $N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. If no such </span>a<span class="math"> exists, then </span>d(\\textsf{Enc}(u^{\\prime}),v)\\geq\\gamma/3<span class="math">. In this event, all of the verifier’s consistency tests pass with probability at most </span>(1-\\gamma/3)^{\\ell}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">∎</p>

    <h5 id="sec-35" class="text-base font-semibold mt-4">Completeness and binding.</h5>

    <p class="text-gray-300">Completeness holds by design.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">To argue binding, recall from the analysis of the testing phase that <span class="math">c_{i}</span> denotes the codeword in Enc that is closest to row <span class="math">i</span> of <span class="math">\\hat{u}</span>, and let <span class="math">w\\coloneqq\\sum_{i=1}^{m}q_{1,i}\\cdot c_{i}</span>. We show that, if the prover passes the verifier’s checks in the testing phase with probability more than $N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+(1-\\gamma/3)^{\\ell}<span class="math"> and passes the verifier’s checks in the evaluation phase with probability more than </span>(1-(2/3)\\gamma)^{\\ell}<span class="math">, then </span>w=\\textsf{Enc}(u^{\\prime\\prime})$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">If <span class="math">w\\neq\\textsf{Enc}(u^{\\prime\\prime})</span>, then <span class="math">w</span> and <span class="math">\\textsf{Enc}(u^{\\prime\\prime})</span> are two distinct codewords in Enc and hence they can agree on at most <span class="math">(1-\\gamma)\\cdot N</span> coordinates. Denote this agreement set by <span class="math">A</span>. The verifier rejects in the evaluation phase if there is any <span class="math">j\\in Q^{\\prime}</span> such that <span class="math">j\\not\\in A\\cup E</span>, where <span class="math">E</span> is as in Equation (4). $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A\\cup E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq(1-\\gamma)\\cdot N+(\\gamma/3)N=(1-(2/3)\\gamma)N<span class="math">, and hence a randomly chosen column </span>j\\in[N]<span class="math"> is in </span>A\\cup E<span class="math"> with probability at most </span>1-(2/3)\\gamma<span class="math">. It follows that </span>u^{\\prime\\prime}<span class="math"> will pass the verifier’s consistency checks in the evaluation phase with probability at most </span>\\left(1-(2/3)\\gamma\\right)^{\\ell}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In summary, if the prover passes the verifier’s checks in the commitment phase with probability at least</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+(1-\\gamma/3)^{\\ell},$ (5)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">then, in the following sense, the prover is <em>bound</em> to the polynomial <span class="math">g^{<em>}</span> whose coefficients in the Lagrange basis are given by <span class="math">c_{1,1},\\dots,c_{m,m}</span>, where <span class="math">c_{i}\\in\\mathbb{F}^{N}</span> denotes the closest codeword to row <span class="math">i</span> of the vector <span class="math">\\hat{u}</span> sent in the commitment phase: on evaluation query <span class="math">r</span>, the verifier either outputs <span class="math">g^{</em>}(r)</span>, or else rejects in the evaluation phase with probability at least</p>

    <p class="text-gray-300"><span class="math">1-\\left(1-(2/3)\\gamma\\right)^{\\ell}.</span> (6)</p>

    <p class="text-gray-300">The polynomial commitment scheme provides standard extractability properties. We show this by giving two different extractors.</p>

    <h4 id="sec-36" class="text-lg font-semibold mt-6">Extractability via efficient decoding.</h4>

    <p class="text-gray-300">The first is a simple straight-line extractor that is efficient if the error-correcting code Enc has a polynomial-time decoding procedure that can correct up to a <span class="math">\\gamma/4</span> fraction of errors. This is because with the IOP-to-succinct-argument transformation of <em>[57, 66, 83, 15]</em>, it is known that, given a prover <span class="math">\\mathcal{P}</span> that convinces the argument-system verifier to accept with non-negligible probability, there is an efficient straight-line extractor capable of outputting IOP proof string <span class="math">\\pi</span> that “opens” the Merkle commitment sent by the argument system prover in the commitment phase. Moreover, there is an IOP prover strategy <span class="math">\\mathcal{P}^{\\prime}</span> for the testing and evaluation phases by which <span class="math">\\mathcal{P}^{\\prime}</span> can convince the IOP verifier in those phases to accept with non-negligible probability when the first IOP message is <span class="math">\\pi</span> (<span class="math">\\mathcal{P}^{\\prime}</span> merely simulates <span class="math">\\mathcal{P}</span> in those phases).</p>

    <p class="text-gray-300">Our analysis of the testing phase of the polynomial commitment scheme (Lemma 1) then guarantees that each row of the extracted string <span class="math">\\pi</span> has relative Hamming distance at most <span class="math">\\gamma/3</span> from some codeword. Hence, row-by-row decoding provides the coefficients of the multilinear polynomial that the prover is bound to. If the decoding procedure runs in polynomial time, the extractor is efficient.</p>

    <h4 id="sec-37" class="text-lg font-semibold mt-6">Extractability without decoding.</h4>

    <p class="text-gray-300">If the error-correcting code does not support efficient decoding, then even though one can efficiently extract the IOP proof string <span class="math">\\pi</span> underlying the Merkle-comittment sent in the commitment phase of the commitment scheme, one can not necessarily decode (each row of) the string to efficiently extract from <span class="math">\\pi</span> the polynomial that the commiter is bound to.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Instead, the extractor can proceed as follows. We assume throughout the below that Expressions (5) and (6) are negligible (say, exponentially small in the security parameter <span class="math">\\lambda</span>), which holds so long as $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq\\exp(\\lambda)<span class="math"> and the number of column openings is </span>\\ell=\\Theta(\\lambda)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The testing phase of the commitment scheme can be viewed as a 3-move public-coin argument in which the verifier moves first. First, the verifier sends a challenge vector <span class="math">r\\in\\mathbb{F}^{m}</span>. Second, the prover responds with a vector claimed to equal <span class="math">\\sum_{i=1}^{m}r_{i}u_{i}</span>. Third, the verifier chooses a set <span class="math">Q</span> of random columns to use in the consistency test, and performs the consistency test by querying the committed proof string <span class="math">\\pi</span> at all entries of the columns in <span class="math">Q</span>.</p>

    <p class="text-gray-300">Given any efficient prover strategy that passes the verifier’s checks in the testing phase with non-negligible probability, we show in the following lemma that there is a polynomial-time extraction procedure capable of outputting <span class="math">m</span> linearly independent challenge vectors <span class="math">r_{1},\\ldots,r_{m}\\in\\mathbb{F}^{m}</span> from the testing phase of the protocol, and <span class="math">m</span> response vectors <span class="math">u_{1}^{\\prime},\\ldots,u_{m}^{\\prime}\\in\\mathbb{F}^{m}</span> of the prover, each of which pass the verifier’s consistency checks in the testing phase with non-negligible probability.</p>

    <h6 id="sec-38" class="text-base font-medium mt-4">Lemma 2.</h6>

    <p class="text-gray-300">Suppose there is a deterministic prover strategy <span class="math">\\mathcal{P}</span> that, following the commitment phase of the polynomial commitment scheme, passes the verifier’s checks in the testing phase of the polynomial commitment scheme with probability <span class="math">\\epsilon</span>. Then there is a randomized extraction procedure <span class="math">\\mathcal{E}</span> that runs in expected time <span class="math">\\text{poly}(m,\\lambda,1/\\epsilon)</span> and such that the following holds. Given the ability to repeatedly rewind <span class="math">\\mathcal{P}</span> to the start of the testing phase, with probability at least <span class="math">1-2^{-\\Omega(\\lambda)}</span>, <span class="math">\\mathcal{E}</span> outputs <span class="math">m</span> linearly independent challenge vectors <span class="math">r_{1},\\ldots,r_{m}\\in\\mathbb{F}^{m}</span> from the testing phase, and <span class="math">m</span> corresponding response vectors <span class="math">u_{1}^{\\prime},\\ldots,u_{m}^{\\prime}\\in\\mathbb{F}^{m}</span> of the prover, each of which pass the verifier’s checks in the testing phase with probability at least <span class="math">\\epsilon</span>.</p>

    <p class="text-gray-300">Before proving Lemma 2, we explain how to extract the desired polynomial given the extracted challenge vectors <span class="math">r_{1},\\ldots,r_{m}\\in\\mathbb{F}^{m}</span> and <span class="math">m</span> response vectors <span class="math">u_{1}^{\\prime},\\ldots,u_{m}^{\\prime}\\in\\mathbb{F}^{m}</span>. Observe that the testing phase and the evaluation phase of the polynomial commitment scheme are identical up to how the challenge vector is selected. In addition, for each challenge <span class="math">r_{i}</span> the prover’s response <span class="math">u_{i}^{\\prime}</span> passes the verifier’s consistency checks with non-negligible probability. Hence, the binding analysis for the commitment scheme implies that <span class="math">u_{1}^{\\prime},\\ldots,u_{m}^{\\prime}</span> are all consistent with the evaluations of a fixed multilinear polynomial <span class="math">g^{<em>}</span>, i.e., for <span class="math">i=1,\\ldots,m</span>, <span class="math">u_{i}^{\\prime}=r_{i}^{T}\\cdot C</span> where <span class="math">C</span> is the coefficient matrix of <span class="math">g^{</em>}</span> in the Lagrange basis. Since the <span class="math">r_{i}</span> vectors are linearly independent, these <span class="math">m</span> linear equations uniquely specify <span class="math">C</span>, and in fact <span class="math">C</span> can be found in polynomial time using Gaussian elimination.</p>

    <h6 id="sec-39" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">We begin the proof by assuming that the extractor knows <span class="math">\\epsilon</span>. We later explain how to remove this assumption. We refer to the extraction procedure that depends on <span class="math">\\epsilon</span> as the “base extraction procedure”.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">If $\\epsilon<1/\\sqrt{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">, then the base extractor can simply abort, by assumption that the field size is at least </span>\\exp(\\lambda)<span class="math">. Below, we assume that </span>\\epsilon>1/\\sqrt{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Fix the extracted proof string <span class="math">\\pi=(\\pi_{1},\\ldots,\\pi_{m})\\in(\\mathbb{F}^{N})^{m}</span> that “opens” the Merkle-commitment sent by the committer during the commitment phase.</p>

    <p class="text-gray-300">Observe that for any verifier challenge <span class="math">r^{\\prime}\\in\\mathbb{F}^{m}</span> and prover response <span class="math">u^{\\prime}</span>, one can efficiently compute the probability (over the random choice of column set <span class="math">Q</span>) that <span class="math">u^{\\prime}</span> will pass the verifier’s consistency checks. Specifically, if <span class="math">\\eta</span> is the the number of columns <span class="math">i</span> such that <span class="math">\\left(\\sum_{j=1}^{m}r^{\\prime}_{j}\\pi_{j}\\right)_{i}=u^{\\prime}_{i}</span>, and <span class="math">\\ell</span> is the number of columns selected by the verifier, then this probability is <span class="math">(\\eta/N)^{\\ell}</span> (here, for simplicity let us assume columns are selected with replacement, but an exact expression can also be given when columns are selected without replacement).</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">T</span> denote the set of all challenges <span class="math">r</span> such that <span class="math">\\mathcal{P}</span>’s response <span class="math">u</span> to <span class="math">r</span> passes the consistency checks with probability at least <span class="math">\\epsilon/2</span>. By averaging, since <span class="math">\\mathcal{P}</span> passes all checks in the testing phase with probability at least <span class="math">\\epsilon</span>, $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq(\\epsilon/2)\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{m}<span class="math">. The extractor’s goal is to efficiently identify a subset </span>S=\\{r_{1},\\ldots,r_{m}\\}<span class="math"> of </span>T<span class="math"> that spans </span>\\mathbb{F}^{m}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The extractor <span class="math">\\mathcal{E}</span> works by repeatedly picking challenge vectors <span class="math">r</span> uniformly at random from <span class="math">\\mathbb{F}^{m}</span>, and running <span class="math">\\mathcal{P}</span> on challenge <span class="math">r</span> to get a response <span class="math">u</span>; this enables <span class="math">\\mathcal{E}</span> to determine whether <span class="math">r\\in T</span>, and if so, <span class="math">\\mathcal{E}</span> adds <span class="math">r</span> to <span class="math">S</span>. The extractor tries <span class="math">\\ell=18(m+\\lambda)/\\epsilon</span> vectors <span class="math">r</span>, aborting if it fails to identify at least <span class="math">m</span> vectors in <span class="math">T</span>. We claim that the probability the extractor fails to identify <span class="math">m</span> vectors to add to <span class="math">S</span> is at most <span class="math">1-2^{-(m+\\lambda)}</span>. To see this, model each choice of challenge vector <span class="math">r</span> as a Poisson trial with success probability at least <span class="math">\\epsilon/2</span>. Let <span class="math">\\mu</span> be the expected number of successes after <span class="math">\\ell</span> Poisson trials each with success probability at least <span class="math">\\epsilon/2</span>. Then <span class="math">\\mu</span> is at least <span class="math">\\ell\\cdot\\epsilon/2\\geq 9(m+\\lambda)</span>. Let <span class="math">\\delta=1/2</span>. Since <span class="math">m\\leq\\mu/9\\leq(1-\\delta)\\cdot\\mu</span>, standard Chernoff bounds (e.g., <em>[67, Theorem 4.5]</em>) upper bound the probability that the number of successes is less than <span class="math">m</span> by <span class="math">e^{-\\mu\\delta^{2}/2}\\leq e^{-9(m+\\lambda)/8}\\leq 2^{-(m+\\lambda)}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We now argue that with probability at least $1-(m-1)\\cdot(2/\\epsilon)\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{-1}<span class="math">, the first </span>m<span class="math"> vectors that </span>\\mathcal{E}<span class="math"> adds to </span>S<span class="math"> are linearly independent (in the event that this is not the case, the extractor aborts). Denote these </span>m<span class="math"> vectors by </span>r_{1},\\ldots,r_{m}\\in\\mathbb{F}^{m}<span class="math">. Observe that each vector </span>r_{i}<span class="math"> is a random element of </span>T<span class="math">. We now explain that for each </span>i=2,\\ldots,m<span class="math">, the probability that </span>r_{i}\\in\\mathrm{span}(r_{1},\\ldots,r_{i-1})<span class="math"> is at most </span>(m-1)\\cdot(2/\\epsilon)\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{-1}<span class="math">. To see this, observe that since the dimension of </span>\\mathrm{span}(r_{1},\\ldots,r_{i-1})<span class="math"> is at most </span>i-1<span class="math">, the span contains at most </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{i-1}<span class="math"> vectors. Since </span>r_{i}<span class="math"> is a uniform random vector from </span>T<span class="math"> and </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq(\\epsilon/2)\\cdot\\mathbb{F}^{m}<span class="math">, the probability that </span>r_{i}\\in\\mathrm{span}(r_{1},\\ldots,r_{i-1})<span class="math"> is at most </span>(2/\\epsilon)\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{i-1}/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{m}\\leq(2/\\epsilon)\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{-1}<span class="math">. The claim then follows by a union bound over all </span>m-1<span class="math"> vectors </span>r_{2},\\ldots,r_{m}<span class="math">. That is, the probability that </span>r_{1},\\ldots,r_{m}<span class="math"> are not linearly independent is at most </span>(m-1)\\cdot(2/\\epsilon)\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{-1}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Since $\\epsilon>1/\\sqrt{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">, we conclude that the extractor aborts with probability at most </span>2^{-(m+\\lambda)}+(m-1)/\\sqrt{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">. This is a negligible function, by the assumption that </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> is at least </span>\\exp(\\lambda)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The above base extraction procedure depends on <span class="math">\\epsilon</span>, because the extractor tries out <span class="math">\\ell=18(m+\\lambda)/\\epsilon</span> vectors <span class="math">r</span> (aborting if it fails to identify <span class="math">m</span> vectors in <span class="math">T</span> within that many tries). The following modification eliminates this dependence. Iteratively run the base extraction procedure with <span class="math">\\epsilon</span> set to the geometrically decreasing sequence of values <span class="math">\\epsilon^{\\prime}=2^{-1},2^{-2},\\ldots,2^{-\\lambda/8}</span> halting when the extraction procedure succeeds, and aborting if the extractor reaches <span class="math">\\epsilon^{\\prime}&lt;2^{-\\lambda/8}</span> without a witness being identified. The above analysis guarantees that when the extraction procedure is run with <span class="math">\\epsilon^{\\prime}</span> less than or equal to <span class="math">\\epsilon</span>, it successfully outputs a witness with probability at least $1-2^{-(m+\\lambda)}-(m-1)/\\sqrt{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\geq 1-2^{-\\lambda/3}<span class="math">. The expected runtime of this modified extraction procedure is at most </span>36(m+\\lambda)/\\epsilon+2^{-\\lambda/3}\\cdot 18(m+\\lambda)\\cdot 2^{\\lambda/8}\\leq\\mathrm{poly}(m,\\lambda,1/\\epsilon)$. ∎∎</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The extraction procedure given in Lemma 2 succeeds with overwhelming probability and runs in expected time <span class="math">\\mathrm{poly}(m,\\lambda,1/\\epsilon)</span> given access to a prover that produces an accepting proof with probability at least <span class="math">\\epsilon</span>. However, if <span class="math">\\epsilon</span> is not inverse-polynomial in <span class="math">m</span> and <span class="math">\\lambda</span>, this expected runtime is not polynomial in <span class="math">m</span> and <span class="math">\\lambda</span>. The definition of knowledge soundness (Definition 2.2) and extractable polynomial commitments (Definition 2.3) requires that the extractor run in expected polynomial time <em>regardless of <span class="math">\\epsilon</span></em>, and that whenever the prover succeeds in outputting a convincing proof <span class="math">\\pi</span>, the extractor outputs a witness with all but negligible probability. The lemma below achieves this.</p>

    <h6 id="sec-40" class="text-base font-medium mt-4">Lemma 3.</h6>

    <p class="text-gray-300">There is a randomized extraction procedure <span class="math">\\mathcal{E}</span> that runs in expected time <span class="math">\\mathrm{poly}(m,\\lambda)</span> and such that the following holds. <span class="math">\\mathcal{E}</span> first runs <span class="math">\\mathcal{P}</span> once during the testing phase of the above polynomial commitment scheme.</p>

    <p class="text-gray-300">If <span class="math">\\mathcal{P}</span> fails to pass the verifier’s checks on the first run, the extractor aborts. Otherwise, with probability at least <span class="math">1-2^{-\\Omega(\\lambda)}</span>, <span class="math">\\mathcal{E}</span> outputs <span class="math">m</span> linearly independent challenge vectors <span class="math">r_{1},\\ldots,r_{m}\\in\\mathbb{F}^{m}</span> from the testing phase, and <span class="math">m</span> corresponding response vectors <span class="math">u_{1}^{\\prime},\\ldots,u_{m}^{\\prime}\\in\\mathbb{F}^{m}</span> of the prover, each of which pass the verifier’s checks in the testing phase with probability at least <span class="math">\\epsilon</span>.</p>

    <h6 id="sec-41" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">We follow the presentation of Hazay and Lindell <em>[52, Theorem 6.5.6]</em> of an extraction strategy originally due to Goldreich <em>[47]</em>.</p>

    <p class="text-gray-300">As described in the statement of the lemma, <span class="math">\\mathcal{E}</span> first runs <span class="math">\\mathcal{P}</span> once during the testing phase, and if <span class="math">\\mathcal{P}</span> does not pass the verifier’s checks, then <span class="math">\\mathcal{E}</span> aborts. If <span class="math">\\mathcal{P}</span> does pass the verifier’s checks in the testing phase, then <span class="math">\\mathcal{E}</span> proceeds to estimate the value <span class="math">\\epsilon</span> (i.e., the probability that <span class="math">\\mathcal{P}</span> indeed passes the verifier’s checks in the testing phase). It does this by rewinding <span class="math">\\mathcal{P}</span> to the start of the testing phase until <span class="math">12\\cdot(m+\\lambda)</span> successful verifications occur. If <span class="math">T</span> runs of <span class="math">\\mathcal{P}</span> are required before <span class="math">12\\cdot(m+\\lambda)</span> successful verifications occur, then the extractor uses <span class="math">\\epsilon^{\\prime}=12\\cdot(m+\\lambda)/T</span> as an estimate of <span class="math">\\epsilon</span>. The extractor then runs the base extraction procedure from the proof of Lemma 2 with <span class="math">\\epsilon</span> set to <span class="math">\\epsilon^{\\prime}/2</span>. Throughout its entire execution, the extractor also keeps a counter of how many times it has run the prover through the testing phase of the polynomial commitment scheme, and if this number ever exceeds <span class="math">2^{m}</span>, it aborts. In this event, we say that the extractor has “timed out”.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let us analyze the success probability of the extractor under the assumption that <span class="math">\\epsilon&gt;2^{-m/2}</span> (if <span class="math">\\epsilon\\leq 2^{-m/2}</span>, then <span class="math">\\epsilon</span> is negligible, and hence it is acceptable for the extractor to succeed with probability 0). <em>[52, Proof of Theorem 6.5.6]</em> shows that with probability at least <span class="math">1-2^{-m+\\lambda}</span>, <span class="math">\\epsilon^{\\prime}</span> is between <span class="math">2\\epsilon/3</span> and <span class="math">2\\epsilon</span>. We call this the “good event”. Since <span class="math">\\epsilon&gt;2^{-m/2}</span>, if the good event occurs, the extractor runs in fewer than <span class="math">2^{m}</span> steps and hence does not time out. And the proof of Lemma 2 shows that, conditioned on the good event occurring, the extractor succeeds with probability at least $1-2^{-(m+\\lambda)}-(m-1)/\\sqrt{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">. Hence, by a union bound, the extractor succeeds with probability at least </span>1-2^{-(m+\\lambda)}-(m-1)/\\sqrt{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}-2^{-m+\\lambda}\\geq 1-2^{-\\Omega(\\lambda)}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We now explain that the above extractor runs in expected polynomial time, regardless of the value of <span class="math">\\epsilon</span>. Let us first consider the case that <span class="math">\\epsilon\\leq 2^{-m}</span>. The probability that the prover passes the verifier’s checks in the first prover execution is <span class="math">\\epsilon</span>, and the extractor never runs for more than <span class="math">2^{m}</span> steps. So in this case the expected runtime of the extractor is at most <span class="math">\\epsilon\\cdot 2^{m}\\leq 1</span>, plus the time required to run the verification procedure of the testing phase, which is polynomial in <span class="math">m</span> and <span class="math">\\lambda</span>.</p>

    <p class="text-gray-300">Now consider the case that <span class="math">\\epsilon&gt;2^{-m}</span>. The first run of the prover passes the verifier’s tests with probability <span class="math">\\epsilon</span>. If this does not happen, the extractor aborts. Otherwise, the extractor proceeds. If the extractor proceeds and the good event occurs, the extractor runs in time at most <span class="math">O((m+\\lambda)/\\epsilon)</span>. The good event fails to occur with probability only at most <span class="math">2^{-(m+\\lambda)}</span>, and in this case the extractor still does not run for more than <span class="math">2^{m}</span> steps.</p>

    <p class="text-gray-300">Hence, the expected runtime of the extractor is at most</p>

    <p class="text-gray-300"><span class="math">O(\\epsilon\\cdot(m+\\lambda)/\\epsilon+2^{m}\\cdot 2^{-(m+\\lambda)})=O(m+\\lambda).</span></p>

    <p class="text-gray-300">∎∎</p>

    <p class="text-gray-300">The runtime of our knowledge extractor that does not perform decoding may imply reduced concrete security, but the effect is small. Compared to the extractor that uses efficient decoding, the rewinding extractor requires <span class="math">m</span> “successful” executions of the prover rather than just one, where <span class="math">m=\\sqrt{n}</span>, for <span class="math">n</span> equal to the degree of the committed polynomial. So, roughly speaking, the runtime of the rewinding extractor is worse by a factor of <span class="math">m</span>, plus an additive term that accounts for the cost of Gaussian elimination.</p>

    <p class="text-gray-300">In the context of Brakedown (our SNARK for R1CS that utilizes this polynomial commitment scheme, see §7), <span class="math">n</span> is roughly equal to the number of R1CS constraints. As an example, when Brakedown is used to prove a statement about a cryptographic primitive, e.g., knowledge of pre-image of a hash function that is implemented in (say) <span class="math">1000\\cdot\\lambda</span> R1CS constraints, then a factor-of-<span class="math">m</span> increase in extractor time corresponds to a loss of roughly <span class="math">(1/2)\\cdot\\log(1000\\lambda)</span> bits of security, which in practice is less than 10 bits.</p>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">5 Fast linear codes with linear-time encoding</p>

    <p class="text-gray-300">This section describes our construction of practical linear codes with linear-time encoding that we use in Brakedown’s implementation of the polynomial commitment scheme from Section 4.1. We begin with a sketch of our encoding procedure and of the analysis of its minimum distance.</p>

    <h4 id="sec-42" class="text-lg font-semibold mt-6">Overview of encoding.</h4>

    <p class="text-gray-300">In this overview we restrict our attention to a construction of a code with distance <span class="math">\\delta=1/20</span> and rate <span class="math">\\rho=3/5</span>. The encoding procedure is recursive. For a message <span class="math">x\\in\\mathbb{F}^{n}</span> of length <span class="math">n</span>, the codeword consists of three parts <span class="math">\\mathsf{Enc}(x)=(x,z,v)</span>. The first is the “systematic part” that just copies the message <span class="math">x</span> of length <span class="math">n</span>. The other parts <span class="math">(z,v)</span> are obtained via the following three-step process. First, multiply <span class="math">x</span> by a random sparse <span class="math">n\\times n/5</span> matrix to “compress” <span class="math">x</span> to a vector <span class="math">y</span> of length <span class="math">n/5</span>. Then obtain <span class="math">z</span> of length <span class="math">n/3</span> by recursively encoding <span class="math">y</span>, and finally obtain <span class="math">v</span> of length <span class="math">n/3</span> by multiplying <span class="math">z</span> by a random sparse <span class="math">n/3\\times n/3</span> matrix <span class="math">B</span>.</p>

    <h4 id="sec-43" class="text-lg font-semibold mt-6">Overview of distance analysis.</h4>

    <p class="text-gray-300">The distance analysis proceeds in three cases. Since the code is linear, we merely need to show that the encoding of any non-zero message <span class="math">x</span> has Hamming weight at least <span class="math">\\delta n/\\rho=n/12</span>. We sketch the analysis for a fixed <span class="math">x</span>, but the formal analysis in Section 5.1 below holds with overwhelming probability for all <span class="math">x</span> simultaneously.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>If the Hamming weight of <span class="math">x</span> is <span class="math">&gt;n/12</span>, then the systematic part <span class="math">x</span> of <span class="math">\\mathsf{Enc}(x)</span> already ensures that <span class="math">\\mathsf{Enc}(x)</span> has a sufficiently large Hamming weight.</li>

      <li>Otherwise, we show that with overwhelming probability over the random choice of <span class="math">A</span>, <span class="math">y</span> will be non-zero. This, in turn, ensures by induction that <span class="math">z=\\mathsf{Enc}(y)</span> has “reasonably large” Hamming weight, at least <span class="math">n/60</span>. If the Hamming weight of <span class="math">z</span> is in fact larger than <span class="math">n/12</span> then we are done because <span class="math">z</span> is part of <span class="math">\\mathsf{Enc}(x)</span>.</li>

      <li>Otherwise, the Hamming weight of <span class="math">z</span> is between <span class="math">n/60</span> and <span class="math">n/12</span>. In this case, we show that, with overwhelming probability, <span class="math">B</span> “mixes” the non-zero coordinates of <span class="math">z</span>, and results in a <span class="math">v=zB</span> of Hamming weight at least <span class="math">n/12</span>, completing the analysis.</li>

    </ul>

    <p class="text-gray-300">Section 5.1 provides full details of our linear-time codes.</p>

    <h3 id="sec-44" class="text-xl font-semibold mt-8">5.1 Details of fast linear-time codes</h3>

    <h4 id="sec-45" class="text-lg font-semibold mt-6">The construction in detail.</h4>

    <p class="text-gray-300">Let <span class="math">q</span> be a prime power, and <span class="math">\\mathbb{F}=\\mathbb{F}_{q}</span> be the field of size <span class="math">q</span>. For <span class="math">p\\in[0,1]</span>, by <span class="math">H(p)=-p\\log_{2}(p)-(1-p)\\log_{2}(1-p)</span> we denote the binary entropy function, where we adopt the convention that <span class="math">0\\log 0=0</span>. For <span class="math">k\\leq n/2</span>, we’ll use the bound <span class="math">\\sum_{0\\leq i\\leq k}\\binom{n}{i}\\leq 2^{nH(k/n)}</span>. We’ll also use <span class="math">\\binom{n}{k}\\leq 2^{nH(k/n)}</span> and <span class="math">\\binom{n}{k}\\leq\\left(\\frac{cn}{k}\\right)^{k}</span> for <span class="math">0\\leq k\\leq n</span>.</p>

    <p class="text-gray-300">Let <span class="math">\\mathcal{G}_{n,m,d}</span> be a distribution of bipartite graphs with <span class="math">n</span> vertices in the left part and <span class="math">m</span> vertices in the right part, where each vertex on the left has <span class="math">d</span> distinct uniform random neighbors on the right. Let <span class="math">\\mathcal{M}_{n,m,d}</span> be a distribution of matrices <span class="math">M\\in\\mathbb{F}^{n\\times m}</span>, where in each row <span class="math">d</span> distinct uniform random elements are assigned uniform random non-zero elements of <span class="math">\\mathbb{F}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We construct a systematic linear code with efficient encoding procedure. The code uses the parameters <span class="math">0&lt;\\alpha&lt;1,0&lt;\\beta&lt;\\alpha/1.28,r&gt;(1+2\\beta)/(1-\\alpha)&gt;1,c_{n},d_{n}\\geq 3</span> that will be specified later. For a constant <span class="math">r&gt;1</span>, in Algorithm 1 (see also Figure 1 for a visual depiction of the encoding procedure) we give a construction of a linear map <span class="math">\\mathsf{Enc}_{n}\\colon\\mathbb{F}^{n}\\to\\mathbb{F}^{rn}</span> such that every non-zero vector <span class="math">x\\in\\mathbb{F}^{n}</span> is mapped to a vector <span class="math">w\\in\\mathbb{F}^{rn}</span> of Hamming weight at least $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\geq\\beta n<span class="math">. Moreover, the linear map </span>\\mathsf{Enc}_{n}<span class="math"> is systematic, that is, the first </span>n<span class="math"> coordinates of </span>w<span class="math"> equal </span>x<span class="math">. This guarantees that the constructed map has full rank, and, that it defines a linear code of rank </span>n<span class="math">, rate </span>1/r<span class="math">, and distance </span>\\delta=\\beta n/(rn)=\\beta/r$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The map <span class="math">\\mathsf{Enc}_{n}</span> operates recursively, invoking <span class="math">\\mathsf{Enc}_{\\alpha n}</span>, where recall that <span class="math">\\alpha</span> is a parameter that is less than <span class="math">1</span>. <span class="math">\\mathsf{Enc}_{n}</span> makes use of two sparse matrices, which we denote by <span class="math">A^{(n)}</span> and <span class="math">B^{(n)}</span>. In practice, these matrices will be generated in pre-processing for all relevant message lengths, i.e., <span class="math">n,\\alpha n,\\alpha^{2}n,\\alpha^{3}n,\\dots</span>. The generation</p>

    <p class="text-gray-300">procedure is randomized. Specifically, <span class="math">A^{(n)} \\gets \\mathcal{M}_{n,\\alpha n,c_n} B^{(n)} \\gets \\mathcal{M}_{\\alpha rn,(r-1-r\\alpha)n,d_n}</span>, for</p>

    <p class="text-gray-300">$$ \\begin{aligned} c_n = \\left\\lceil \\min \\left(\\max(1.28\\beta n, \\beta n + 4), \\right. \\right. \\\\</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\left. \\frac{1}{\\beta \\log_2 \\frac{\\alpha}{1.28\\beta}} \\left(\\frac{110}{n} + H(\\beta) + \\alpha H\\left(\\frac{1.28\\beta}{\\alpha}\\right)\\right)\\right) \\Bigg</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, \\tag{7} \\\\</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">d_n = \\left\\lceil \\min \\left(\\left(2\\beta + \\frac{(r-1) + 110/n}{\\log_2 q}\\right)n, D\\right) \\right\\rceil, \\tag{8} \\\\ D = \\max \\left( \\frac{r\\alpha H(\\beta/r) + \\mu H(\\nu/\\mu) + 110/n}{\\alpha\\beta \\log_2 \\frac{\\mu}{\\nu}}, \\right. \\\\ \\left. \\frac{r\\alpha H(\\beta/(r\\alpha)) + \\mu H((2\\beta + 0.03)/\\mu) + 110/n}{\\beta \\log_2 \\frac{\\mu}{2\\beta + 0.03}}, \\right. \\\\ (2\\beta + 0.03) \\left( \\frac{1}{\\alpha r - \\beta} + \\frac{1}{\\alpha\\beta} + \\frac{1}{\\mu - 2\\beta - 0.03} \\right) + 1, \\end{aligned} $$</p>

    <p class="text-gray-300">where <span class="math">\\mu = r - 1 - r\\alpha, \\nu = \\beta + \\alpha\\beta + 0.03</span>.</p>

    <p class="text-gray-300">Given the above matrices, <span class="math">\\mathsf{Enc}_n</span> operates as follows. First, compute <span class="math">y = x \\cdot A^{(n)} \\in \\mathbb{F}^{\\alpha n}</span>. Recall that the parameter <span class="math">\\alpha &amp;lt; 1</span>, and, thus, we can recursively apply the encoding procedure <span class="math">\\mathsf{Enc}</span> to <span class="math">y</span>, computing <span class="math">z = \\mathsf{Enc}_{\\alpha n}(y) \\in \\mathbb{F}^{\\alpha r n}</span>. Finally, compute <span class="math">v = z \\cdot B^{(n)} \\in \\mathbb{F}^{(r-1-r\\alpha)n}</span>. The resulting codeword is the concatenation of <span class="math">x, z</span>, and <span class="math">v</span>: <span class="math">w = \\mathsf{Enc}(x) := \\begin{pmatrix} x \\\\ z \\\\ v \\end{pmatrix} \\in \\mathbb{F}^{rn}</span>.</p>

    <p class="text-gray-300">It is easy to see that the constructed code is linear and systematic, and has rate <span class="math">1/r</span>. Therefore, it remains to show that this code has distance <span class="math">\\delta = \\beta/r</span>, and to estimate the running time of its encoding procedure. While our analysis of the running time of the encoding procedure is asymptotic (in that it holds for large enough values of <span class="math">n</span>), our analysis of the code distance is concrete and holds for all values of <span class="math">n</span>.</p>

    <p class="text-gray-300"><strong>Algorithm 1 Encoding Algorithm <span class="math">\\mathsf{Enc}_n</span>: <span class="math">\\mathbb{F}^n \\to \\mathbb{F}^{rn}</span></strong></p>

    <p class="text-gray-300">Input: <span class="math">x \\in \\mathbb{F}^n</span></p>

    <p class="text-gray-300">Parameters: <span class="math">\\alpha, \\beta, r, c_n, d_n</span></p>

    <p class="text-gray-300">Output: <span class="math">w \\in \\mathbb{F}^{rn}</span></p>

    <p class="text-gray-300">1: Matrices <span class="math">A^{(n)} \\gets \\mathcal{M}_{n,\\alpha n,c_n}</span> and <span class="math">B^{(n)} \\gets \\mathcal{M}_{\\alpha rn,(r-1-r\\alpha)n,d_n}</span> are chosen in pre-processing, where <span class="math">c_n</span> and <span class="math">d_n</span> are defined in Equations (7) and (8).</p>

    <p class="text-gray-300">2: <span class="math">y = x \\cdot A^{(n)} \\in \\mathbb{F}^{\\alpha n}</span></p>

    <p class="text-gray-300">3: <span class="math">z = \\mathsf{Enc}_{\\alpha n}(y) \\in \\mathbb{F}^{\\alpha r n}</span></p>

    <p class="text-gray-300">4: <span class="math">v = z \\cdot B^{(n)} \\in \\mathbb{F}^{(r-1-r\\alpha)n}</span></p>

    <p class="text-gray-300">5: <span class="math">w = \\begin{pmatrix} x \\\\ z \\\\ v \\end{pmatrix} \\in \\mathbb{F}^{rn}</span></p>

    <p class="text-gray-300">6: return <span class="math">w</span></p>

    <p class="text-gray-300"><strong>Running time.</strong> We note that since the encoding procedure consists of a series of multiplications of vectors by sparse matrices, the number of field additions is strictly less than the number of field multiplications. Here we only estimate the number of field multiplications because it's a more resource-intensive operation, and it also gives an essentially tight estimate on the number of field additions. The encoding procedure for a message of length <span class="math">n</span> performs a multiplication of a vector of length <span class="math">n</span> by a matrix of row-sparsity <span class="math">c_n</span>, a multiplication of a vector of length <span class="math">\\alpha rn</span> by a matrix of row-sparsity <span class="math">d_n</span>, and a recursive call for a vector of</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Figure 1: The encoding procedure  <span class="math">\\mathsf{Enc}_n</span>  (with all but negligible probability) maps a non-zero vector  <span class="math">x\\in \\mathbb{F}^n</span>  to a vector  <span class="math">w = \\mathsf{Enc}(x)\\coloneqq \\left( \\begin{array}{c}x\\\\ z\\\\ v \\end{array} \\right)\\in \\mathbb{F}^{rn}</span>  of Hamming weight at least  $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_0\\geq \\beta n<span class="math"> , resulting in a linear code of rate  </span>1 / r<span class="math">  and distance  </span>\\delta = \\beta /r$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">length  <span class="math">\\alpha n</span> . Letting  <span class="math">T(n)</span>  denote the running time of  <span class="math">\\mathsf{Enc}_n</span> , we have that</p>

    <div class="my-4 text-center"><span class="math-block">T (n) \\leq n c _ {n} + \\alpha r n d _ {n} + T (\\alpha n) = n \\left(c _ {n} + \\alpha r d _ {n}\\right) + T (\\alpha n).</span></div>

    <p class="text-gray-300">By setting</p>

    <div class="my-4 text-center"><span class="math-block">c = \\lim  _ {n \\rightarrow \\infty} c _ {n} = \\left[ \\frac {H (\\beta) + \\alpha H \\left(\\frac {1 . 2 8 \\beta}{\\alpha}\\right)}{\\beta \\log_ {2} \\frac {\\alpha}{1 . 2 8 \\beta}} \\right],</span></div>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} d = \\lim  _ {n \\rightarrow \\infty} d _ {n} = \\left[ \\max  \\left(\\frac {r \\alpha H (\\beta / r) + \\mu H (\\nu / \\mu)}{\\alpha \\beta \\log_ {2} \\frac {\\mu}{\\nu}}, \\right. \\right. \\\\ \\frac {r \\alpha H (\\beta / (r \\alpha)) + \\mu H ((2 \\beta + 0 . 0 3) / \\mu)}{\\beta \\log_ {2} \\frac {\\mu}{2 \\beta + 0 . 0 3}}, \\\\ \\left. (2 \\beta + 0. 0 3) \\left(\\frac {1}{\\alpha r - \\beta} + \\frac {1}{\\alpha \\beta} + \\frac {1}{\\mu - 2 \\beta - 0 . 0 3}\\right) + 1\\right) \\Bigg ], \\\\ \\end{array}</span></div>

    <p class="text-gray-300">we have for all large enough  <span class="math">n</span></p>

    <div class="my-4 text-center"><span class="math-block">T (n) \\lesssim n (c + \\alpha r d) + T (\\alpha n) &amp;lt;   n \\cdot \\frac {c + \\alpha r d}{1 - \\alpha},</span></div>

    <p class="text-gray-300">where the last inequality uses the infinite geometric series formula.</p>

    <p class="text-gray-300">Code distance. We show that for certain choices of the parameters  <span class="math">\\alpha, \\beta, r, c_n</span> , and  <span class="math">d_n</span> , the following holds with all but negligible probability over the choices of random matrices  <span class="math">A, B</span> :</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(i) for every  $0 &lt; \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_0 &lt; \\beta n<span class="math"> </span>y = x\\cdot A\\neq \\mathbf{0}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- for every $\\alpha\\beta n\\leq\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}<\\beta n<span class="math">, </span>v=z\\cdot B<span class="math"> has </span>\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">v\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\geq\\beta n$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Assuming that these two properties hold, we can show that <span class="math">\\mathsf{Enc}_{n}</span> has distance <span class="math">\\delta=\\beta/r</span>, that is, for every <span class="math">x\\neq\\mathbf{0}</span>, <span class="math">w=\\mathsf{Enc}_{n}(x)</span> satisfies $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\geq\\beta n$. To this end, we consider the following three cases.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">1. $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\geq\\beta n$. In this case, \\[ w=\\begin{pmatrix}x\\\\</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">z\\\\</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">v\\end{pmatrix} \\] trivially satisfies $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\geq\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\geq\\beta n$.</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">3. $0<\\</td>

            <td class="px-3 py-2 border-b border-gray-700">x\\</td>

            <td class="px-3 py-2 border-b border-gray-700">_{0}<\\beta n<span class="math"> and </span>\\</td>

            <td class="px-3 py-2 border-b border-gray-700">z\\</td>

            <td class="px-3 py-2 border-b border-gray-700">_{0}<\\beta n<span class="math">. In this case, by the Property (i) above, we have that </span>y=x\\cdot A\\neq\\mathbf{0}<span class="math">. By the code property of </span>\\mathsf{Enc}_{\\alpha n}<span class="math">, we have that every non-zero vector </span>y<span class="math"> is mapped to </span>z=\\mathsf{Enc}_{\\alpha n}(y)<span class="math"> of Hamming weight </span>\\</td>

            <td class="px-3 py-2 border-b border-gray-700">z\\</td>

            <td class="px-3 py-2 border-b border-gray-700">\\geq\\delta\\cdot(\\alpha rn)=\\alpha\\beta n<span class="math">. Now we have that </span>\\alpha\\beta n\\leq\\</td>

            <td class="px-3 py-2 border-b border-gray-700">z\\</td>

            <td class="px-3 py-2 border-b border-gray-700">_{0}<\\beta n<span class="math">, and by the Property (ii) above, </span>\\</td>

            <td class="px-3 py-2 border-b border-gray-700">v\\</td>

            <td class="px-3 py-2 border-b border-gray-700">_{0}\\geq\\beta n$, which finishes the proof.</td>

          </tr>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">It remains to choose the values of the parameters <span class="math">\\alpha,\\beta,r,c_{n},d_{n}</span> such that the Property (i) and (ii) are satisfied with, say, probability at least <span class="math">1-2^{-100}</span> over the choice of matrices <span class="math">A</span> and <span class="math">B</span>. We remark that once the code is generated (that is, once we have generated matrices <span class="math">A</span> and <span class="math">B</span> for all relevant values of <span class="math">n</span>), we have the guarantee that with probability <span class="math">1-2^{-100}</span>, <em>all</em> non-zero messages <span class="math">x</span> are mapped to vectors <span class="math">w</span> of Hamming weight $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq\\beta n$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We bound the probability of not satisfying the Property (i) in two steps. First, for <span class="math">0&lt;k&lt;\\beta n</span>, let <span class="math">E^{(1)}_{n,k}</span> be the event that there exists a set of <span class="math">k</span> coordinates of <span class="math">x\\in\\mathbb{F}^{n}</span> that doesn’t “expand” into <span class="math">b(k)=\\max(k+4,\\ 1.28k)</span> coordinates of <span class="math">y=x\\cdot A</span>. Formally, let <span class="math">E^{(1)}_{n,k}</span> be the event that there exists a set of <span class="math">k</span> rows of <span class="math">A</span> that have fewer than <span class="math">b(k)</span> non-zero columns. Second, let <span class="math">E^{(2)}_{n,k}</span> denote the event that, given that every set of size <span class="math">k</span> expands into a set of size at least <span class="math">b(k)</span> (that is, conditioned on the complement of <span class="math">E^{(1)}_{n,k}</span>), there exists an <span class="math">x</span> of Hamming weight $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=k<span class="math"> such that </span>y=x\\cdot A=\\mathbf{0}<span class="math">. We will choose the parameters </span>\\alpha,\\beta,<span class="math"> and </span>c_{n}<span class="math"> such that </span>\\sum_{0<k<\\beta n}\\Pr[E^{(1)}_{n,k}]+\\Pr[E^{(2)}_{n,k}]\\ll 2^{-100}.<span class="math"> This will guarantee that with probability at least </span>1-2^{-100}<span class="math">, the Property (i) is satisfied: every </span>x<span class="math"> with </span>0<\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><\\beta n<span class="math"> is mapped to a </span>y\\neq\\mathbf{0}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We use a similar strategy to bound the probability that the constructed code doesn’t satisfy the Property (ii). Let <span class="math">E^{(3)}_{n,k}</span> be the event that there exists a set of <span class="math">k</span> coordinates of <span class="math">z\\in\\mathbb{F}^{\\alpha rn}</span> that doesn’t expand into <span class="math">b^{\\prime}(k)=\\left(\\beta+k/n+\\frac{(r-1)+110/n}{\\log_{2}q}\\right)n</span> coordinates of <span class="math">v=z\\cdot B</span>: there exists a set of <span class="math">k</span> rows of <span class="math">B</span> that have fewer than <span class="math">b^{\\prime}(k)</span> non-zero columns. Then we define <span class="math">E^{(4)}_{n,k}</span> as the event that, given that all sets of size <span class="math">k</span> expand into at least <span class="math">b^{\\prime}(k)</span> coordinates, there exists a <span class="math">z\\in\\mathbb{F}^{\\alpha rn}</span> of Hamming weight $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=k<span class="math"> which is mapped to </span>v=B\\cdot z<span class="math"> of Hamming weight </span>\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}<\\beta n<span class="math">. We will choose the parameters to guarantee that </span>\\sum_{\\alpha\\beta n\\leq k<\\beta n}\\Pr[E^{(3)}_{n,k}]+\\Pr[E^{(4)}_{n,k}]\\ll 2^{-100}.<span class="math"> This will imply that with probability at least </span>1-2^{-100}$, the constructed code satisfies the Property (ii).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In Figure 2 we provide several settings of the parameters and specify the corresponding provable guarantees. These are the parameter settings we use in our implementation, Brakedown. We have chosen parameters in this table to ensure that all guarantees hold for messages of length up to <span class="math">2^{30}</span>. Recall that in the polynomial commitment scheme of Section 4.1, the messages to be encoded have length <span class="math">\\Theta(\\lambda\\cdot N^{1/2})</span> where <span class="math">N</span> is the size of the polynomial to be committed. Concretely, messages of length <span class="math">2^{30}</span> are sufficient for our SNARK to support R1CS instances of size in excess of <span class="math">2^{40}</span> with the stated failure probability of <span class="math">2^{-100}</span> of the code failing to satisfy the asserted minimum distance property. Somewhat faster encoding times than those listed in Figure 2 can be achieved if one is satisfied with larger failure probability, smaller messages, larger field size, etc.</p>

    <p class="text-gray-300">Below, we also describe several conditions on the parameters sufficient for satisfying the Properties (i) and (ii) with high probability. Namely, in Claims 1, 2, 3, and 4, we give conditions sufficient for bounding the probabilities of the events <span class="math">E^{(1)}_{n,k},E^{(2)}_{n,k},E^{(3)}_{n,k}</span>, and <span class="math">E^{(4)}_{n,k}</span>, respectively. These claims may be useful for readers who wish to optimize code parameters with less stringent requirements than ours (e.g., readers who are satisfied with larger probability, or who need not support messages as large as we do, etc.).</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Pr[failure]</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">run-time</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">distance</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">rate</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">α</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">β</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">r</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">cn</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">dn</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">≤ 230</td>

            <td class="px-3 py-2 border-b border-gray-700">≥ 2127</td>

            <td class="px-3 py-2 border-b border-gray-700">≪ 2-100</td>

            <td class="px-3 py-2 border-b border-gray-700">13.2n</td>

            <td class="px-3 py-2 border-b border-gray-700">0.02</td>

            <td class="px-3 py-2 border-b border-gray-700">0.704</td>

            <td class="px-3 py-2 border-b border-gray-700">0.1195</td>

            <td class="px-3 py-2 border-b border-gray-700">0.0284</td>

            <td class="px-3 py-2 border-b border-gray-700">1.42</td>

            <td class="px-3 py-2 border-b border-gray-700">6</td>

            <td class="px-3 py-2 border-b border-gray-700">33</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">≤ 230</td>

            <td class="px-3 py-2 border-b border-gray-700">≥ 2127</td>

            <td class="px-3 py-2 border-b border-gray-700">≪ 2-100</td>

            <td class="px-3 py-2 border-b border-gray-700">14.3n</td>

            <td class="px-3 py-2 border-b border-gray-700">0.03</td>

            <td class="px-3 py-2 border-b border-gray-700">0.68</td>

            <td class="px-3 py-2 border-b border-gray-700">0.138</td>

            <td class="px-3 py-2 border-b border-gray-700">0.0444</td>

            <td class="px-3 py-2 border-b border-gray-700">1.47</td>

            <td class="px-3 py-2 border-b border-gray-700">7</td>

            <td class="px-3 py-2 border-b border-gray-700">26</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">≤ 230</td>

            <td class="px-3 py-2 border-b border-gray-700">≥ 2127</td>

            <td class="px-3 py-2 border-b border-gray-700">≪ 2-100</td>

            <td class="px-3 py-2 border-b border-gray-700">15.8n</td>

            <td class="px-3 py-2 border-b border-gray-700">0.04</td>

            <td class="px-3 py-2 border-b border-gray-700">0.65</td>

            <td class="px-3 py-2 border-b border-gray-700">0.178</td>

            <td class="px-3 py-2 border-b border-gray-700">0.061</td>

            <td class="px-3 py-2 border-b border-gray-700">1.521</td>

            <td class="px-3 py-2 border-b border-gray-700">7</td>

            <td class="px-3 py-2 border-b border-gray-700">22</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">≤ 230</td>

            <td class="px-3 py-2 border-b border-gray-700">≥ 2127</td>

            <td class="px-3 py-2 border-b border-gray-700">≪ 2-100</td>

            <td class="px-3 py-2 border-b border-gray-700">17.8n</td>

            <td class="px-3 py-2 border-b border-gray-700">0.05</td>

            <td class="px-3 py-2 border-b border-gray-700">0.60</td>

            <td class="px-3 py-2 border-b border-gray-700">0.2</td>

            <td class="px-3 py-2 border-b border-gray-700">0.082</td>

            <td class="px-3 py-2 border-b border-gray-700">1.64</td>

            <td class="px-3 py-2 border-b border-gray-700">8</td>

            <td class="px-3 py-2 border-b border-gray-700">19</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">≤ 230</td>

            <td class="px-3 py-2 border-b border-gray-700">≥ 2127</td>

            <td class="px-3 py-2 border-b border-gray-700">≪ 2-100</td>

            <td class="px-3 py-2 border-b border-gray-700">20.5n</td>

            <td class="px-3 py-2 border-b border-gray-700">0.06</td>

            <td class="px-3 py-2 border-b border-gray-700">0.61</td>

            <td class="px-3 py-2 border-b border-gray-700">0.211</td>

            <td class="px-3 py-2 border-b border-gray-700">0.097</td>

            <td class="px-3 py-2 border-b border-gray-700">1.616</td>

            <td class="px-3 py-2 border-b border-gray-700">9</td>

            <td class="px-3 py-2 border-b border-gray-700">21</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">≤ 230</td>

            <td class="px-3 py-2 border-b border-gray-700">≥ 2127</td>

            <td class="px-3 py-2 border-b border-gray-700">≪ 2-100</td>

            <td class="px-3 py-2 border-b border-gray-700">25.5n</td>

            <td class="px-3 py-2 border-b border-gray-700">0.07</td>

            <td class="px-3 py-2 border-b border-gray-700">0.58</td>

            <td class="px-3 py-2 border-b border-gray-700">0.238</td>

            <td class="px-3 py-2 border-b border-gray-700">0.1205</td>

            <td class="px-3 py-2 border-b border-gray-700">1.72</td>

            <td class="px-3 py-2 border-b border-gray-700">10</td>

            <td class="px-3 py-2 border-b border-gray-700">23</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Figure 2: Settings of the parameters leading to codes with small probabilities of error.  <span class="math">n</span>  denotes the length of the message to be encoded. The specified values of  <span class="math">c_{n}, d_{n}</span> , and running time hold for all large enough  <span class="math">n</span> .</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} c _ {n} = \\left\\lceil \\min  \\left(\\max  (1. 2 8 \\beta n, \\beta n + 4), \\right. \\right. \\\\ \\left. \\frac {1}{\\beta \\log_ {2} \\frac {\\alpha}{1 . 2 8 \\beta}} \\left(\\frac {1 1 0}{n} + H (\\beta) + \\alpha H \\left(\\frac {1 . 2 8 \\beta}{\\alpha}\\right)\\right)\\right)\\left. \\right). \\\\ \\end{array}</span></div>

    <p class="text-gray-300">If  <span class="math">\\beta &amp;lt;  \\alpha /1.28</span>  , then for every  <span class="math">n</span>  and  <span class="math">0 &amp;lt;   k &amp;lt;   \\beta n</span></p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\Pr \\left[ E _ {n, k} ^ {(1)} \\right] \\leq \\max  \\left(2 ^ {- 1 1 0}, \\right. \\\\ 2 ^ {n H (1 5 / n) + \\alpha n H (\\frac {1 9 . 2}{\\alpha n}) - 1 5 c _ {n} \\log_ {2} (\\frac {\\alpha n}{1 9 . 2})}, \\\\ \\max  _ {c _ {n} - 3 \\leq k \\leq \\min  (1 4, \\beta n)} \\frac {\\binom {n} {k} \\binom {\\alpha n} {k + 3} \\binom {k + 3} {c _ {n}} ^ {k}}{\\binom {\\alpha n} {c _ {n}} ^ {k}} \\\\ \\end{array}</span></div>

    <p class="text-gray-300">Proof. First we note that</p>

    <p class="text-gray-300"><span class="math">\\operatorname<em>{Pr}[E_{n,k}^{(1)}] = \\operatorname</em>{Pr}_{G\\in \\mathcal{G}n,\\alpha n,c_n}\\left[G\\text{contains a set of } k\\text{ left vertices with fewer than } b(k)\\text{ neighbors}\\right].</span></p>

    <p class="text-gray-300">We will show that with all but negligible probability every set of size  <span class="math">k &amp;lt; \\beta n</span>  will expand into a set of size at least  <span class="math">b(k) = \\max (k + 4,1.28k)</span> . If  <span class="math">c_{n} \\geq \\max (1.28\\beta n,\\beta n + 4)</span> , then every vertex has  <span class="math">c_{n} \\geq b(\\beta n)</span>  neighbors, and, thus, every set of  <span class="math">k &amp;lt; \\beta n</span>  vertices has at least  <span class="math">b(k)</span>  neighbors.</p>

    <p class="text-gray-300">Now we assume that  <span class="math">c_{n} \\geq \\frac{1}{\\beta \\log_{2} \\frac{\\alpha}{1.28\\beta}} \\left( \\frac{110}{n} + H(\\beta) + \\alpha H \\left( \\frac{1.28\\beta}{\\alpha} \\right) \\right)</span> . In order to show that every set of size  <span class="math">k</span>  expands into a set of size at least  <span class="math">b(k) = \\max (k + 4, 1.28k)</span>  with high probability, we'll first bound from above the probability that there exists a set of  <span class="math">k \\geq 15</span>  vertices with at most  <span class="math">1.28k</span>  neighbors, and then we will bound the probability that there exists a set of  <span class="math">k \\leq 14</span>  that has fewer than  <span class="math">k + 4</span>  neighbors.</p>

    <p class="text-gray-300">The probability that a fixed set of size  <span class="math">15 \\leq k &amp;lt; \\beta n</span>  has fewer than  <span class="math">1.28k</span>  neighbors is upper-bounded by</p>

    <div class="my-4 text-center"><span class="math-block">\\frac {\\binom {\\alpha n} {1 . 2 8 k} \\binom {1 . 2 8 k} {c _ {n}} ^ {k}}{\\binom {\\alpha n} {c _ {n}} ^ {k}}.</span></div>

    <p class="text-gray-300">By the union bound over all sets of  <span class="math">k</span>  left vertices,</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\Pr \\left[ E _ {n, k} ^ {(1)} \\right] \\leq \\frac {\\binom {n} {k} \\binom {\\alpha n} {1 . 2 8 k} \\binom {1 . 2 8 k} {c _ {n}} ^ {k}}{\\binom {\\alpha n} {c _ {n}} ^ {k}} \\leq \\binom {n} {k} \\binom {\\alpha n} {1. 2 8 k} \\left(\\frac {1 . 2 8 k}{\\alpha n}\\right) ^ {k c _ {n}} \\leq 2 ^ {n H (k / n)} \\cdot 2 ^ {\\alpha n H \\left(\\frac {1 . 2 8 k}{\\alpha n}\\right)} \\cdot 2 ^ {- k c _ {n} \\log_ {2} \\left(\\frac {\\alpha n}{1 . 2 8 k}\\right)} \\\\ = 2 ^ {n \\left(H (k / n) + \\alpha H \\left(\\frac {1 . 2 8 k}{\\alpha n}\\right) - \\frac {c _ {n} k}{n} \\log_ {2} \\left(\\frac {\\alpha n}{1 . 2 8 k}\\right)\\right)}. \\tag {9} \\\\ \\end{array}</span></div>

    <p class="text-gray-300">Let <span class="math">f(x) = H(x) + \\alpha H(1.28x / \\alpha) - c_n x \\log_2\\left(\\frac{\\alpha}{1.28x}\\right)</span> for <span class="math">x \\in [15 / n, \\beta]</span>. We'll show that for our choice of <span class="math">c_n</span>, <span class="math">f(x)</span> is convex, and therefore it achieves its maximum at one of the end points of the interval <span class="math">x \\in [15 / n, \\beta]</span>. Indeed, <span class="math">f&#x27;&#x27;(x) = \\frac{\\log_2 e}{x} \\left(c_n - \\frac{1}{1 - x} - \\frac{1.28\\alpha}{\\alpha - 1.28x}\\right)</span>. In order to show that <span class="math">f(x)</span> is convex, it's sufficient to show that for every <span class="math">x \\leq \\beta</span>, <span class="math">c_n \\geq \\frac{1}{1 - x} + \\frac{1.28\\alpha}{\\alpha - 1.28x}</span>. Letting <span class="math">g(x) = \\frac{1}{1 - x} + \\frac{1.28\\alpha}{\\alpha - 1.28x}</span>, we have that <span class="math">g&#x27;(x) = \\frac{1.28^2\\alpha}{(\\alpha - 1.28x)^2} + \\frac{1}{(x - 1)^2} &amp;gt; 0</span>. Thus, <span class="math">g(x)</span> is monotone, and it remains to verify that <span class="math">c_n \\geq \\frac{1}{1 - x} + \\frac{1.28\\alpha}{\\alpha - 1.28x}</span> for <span class="math">x = \\beta</span>. For our choice of <span class="math">c_n</span>, for every <span class="math">\\beta &amp;lt; \\alpha / 1.28</span> it can be verified that</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} c_n \\geq \\frac{1}{\\beta \\log_2 \\frac{\\alpha}{1.28\\beta}} \\left(\\frac{110}{n} + H(\\beta) + \\alpha H \\left(\\frac{1.28\\beta}{\\alpha}\\right)\\right) \\\\ &amp;gt; \\frac{1}{\\beta \\log_2 \\frac{\\alpha}{1.28\\beta}} \\left(H(\\beta) + \\alpha H \\left(\\frac{1.28\\beta}{\\alpha}\\right)\\right) \\\\ \\geq \\frac{1}{1 - \\beta} + \\frac{1.28\\alpha}{\\alpha - 1.28\\beta}. \\end{array}</span></div>

    <p class="text-gray-300">Now that we established that <span class="math">f(x)</span> is convex, we upper bound the probability from (9) for <span class="math">k = 15</span> and <span class="math">k = \\beta n</span> as follows. When <span class="math">k = \\beta n</span>,</p>

    <div class="my-4 text-center"><span class="math-block">2^{n \\left(H(\\beta) + \\alpha H \\left(\\frac{1.28\\beta}{\\alpha}\\right) - \\beta c_n \\log_2 \\left(\\frac{\\alpha}{1.28\\beta}\\right)\\right)} \\leq 2^{n (-110 / n)} \\leq 2^{-110}</span></div>

    <p class="text-gray-300">by the choice of <span class="math">c_n \\geq \\frac{1}{\\beta \\log_2 \\frac{\\alpha}{1.28\\beta}} \\left( \\frac{110}{n} + H(\\beta) + \\alpha H \\left( \\frac{1.28\\beta}{\\alpha} \\right) \\right)</span>. For the case of <span class="math">k = 15</span> (assuming that <span class="math">k = 15 &amp;lt; \\beta n</span>), (9) gives us the following upper bound on the probability of failure</p>

    <div class="my-4 text-center"><span class="math-block">2^{n H (15 / n) + \\alpha n H \\left(\\frac{19.2}{\\alpha n}\\right) - 15 c_n \\log_2 \\left(\\frac{\\alpha n}{19.2}\\right)}.</span></div>

    <p class="text-gray-300">Finally, we show that with high probability every set of size <span class="math">k \\leq 14</span> has at least <span class="math">k + 4</span> neighbors. For <span class="math">k \\leq c_n - 4</span>, this happens with certainty as every vertex has <span class="math">c_n \\geq k + 4</span> neighbors. For a set of size <span class="math">c_n - 3 \\leq k \\leq \\min(14, \\beta n)</span>, the probability of having at most <span class="math">k + 3</span> neighbors is bounded from above by <span class="math">\\frac{\\binom{\\alpha n}{k+3} \\binom{k+3}{c_n}^k}{\\binom{\\alpha n}{c_n}^k}</span>. By the union bound over all sets of size <span class="math">k</span>, we obtain the following upper bound on the probability of failure:</p>

    <div class="my-4 text-center"><span class="math-block">\\frac{\\binom{n}{k} \\binom{\\alpha n}{k+3} \\binom{k+3}{c_n}^k}{\\binom{\\alpha n}{c_n}^k},</span></div>

    <p class="text-gray-300">which finishes the proof.</p>

    <p class="text-gray-300">Claim 2. For every <span class="math">n \\leq 2^{30}</span> and every <span class="math">q \\geq 2^{127}</span>, for every <span class="math">n</span> and <span class="math">k \\leq n</span>, <span class="math">\\operatorname{Pr}[E_{n,k}^{(2)}] \\ll 2^{-100}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Proof. Let <span class="math">x \\in \\mathbb{F}^n</span> and $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_0 = k<span class="math">. Let </span>K \\subseteq [n]<span class="math"> be the set of indices of non-zero elements of </span>x<span class="math">. Let </span>T_K<span class="math"> be a random variable denoting the number of columns of </span>A \\gets \\mathcal{M}_{n,\\alpha n,c_n}<span class="math"> with at least one non-zero element in the rows with indices from </span>K$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Note that since the event <span class="math">E_{n,k}^{(2)}</span> is conditioned on the complement of <span class="math">E_{n,k}^{(1)}</span>, we have that <span class="math">T_k \\geq b(k) = \\max(k + 4, 1.28k)</span>. We have that at least <span class="math">T_k</span> coordinates of <span class="math">Ax</span> are non-zero linear combinations of the non-zero coordinates of <span class="math">x</span> with indices from <span class="math">K_x</span>. Since all the coordinates of the linear combinations are uniform random non-zero elements of <span class="math">\\mathbb{F}</span>, each such linear combination equals zero with probability at most <span class="math">1/q</span>, and all linear combinations equal zero with probability at most <span class="math">1/q^{b(k)}</span>. Now taking the union bound over all <span class="math">&amp;lt; \\binom{n}{k}q^k</span> vectors <span class="math">x</span> of Hamming weight <span class="math">k</span>, we have that <span class="math">\\operatorname{Pr}[E_{n,k}^{(2)}] &amp;lt; \\binom{n}{k}q^{k - b(k)}</span>.</p>

    <p class="text-gray-300">For <span class="math">k \\geq 15</span>, this implies that</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Pr}[E_{n,k}^{(2)}] \\leq \\binom{n}{k} q^{-0.28k} \\leq \\left(\\frac{en}{k}\\right)^k \\cdot q^{-0.28k} = \\left(\\frac{en}{k q^{0.28}}\\right)^k \\leq 2^{-120}</span></div>

    <p class="text-gray-300">for every <span class="math">n \\leq 2^{30}</span> and <span class="math">q \\geq 2^{127}</span>.</p>

    <p class="text-gray-300">For <span class="math">k \\leq 14</span>, this gives us that</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Pr}[E_{n,k}^{(2)}] \\leq \\binom{n}{k} q^{-4} \\leq \\left(\\frac{en}{k}\\right)^k \\cdot q^{-4} \\leq \\left(\\frac{e2^{30}}{14}\\right)^{14} \\cdot 2^{-127 \\cdot 4} \\leq 2^{-120}</span></div>

    <p class="text-gray-300">for every <span class="math">n \\leq 2^{30}</span> and <span class="math">q \\geq 2^{127}</span>.</p>

    <p class="text-gray-300"><strong>Claim 3.</strong> Let <span class="math">\\mu = r - 1 - r\\alpha</span>, <span class="math">\\nu = \\beta + \\alpha\\beta + 0.03</span>, and</p>

    <div class="my-4 text-center"><span class="math-block">d_n = \\left\\lceil \\min \\left(\\left(2\\beta + \\frac{(r - 1) + 110/n}{\\log_2 q}\\right)n, D\\right) \\right\\rceil,</span></div>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} D &amp;amp;= \\max \\left( \\frac{r\\alpha H(\\beta/r) + \\mu H(\\nu/\\mu) + 110/n}{\\alpha\\beta \\log_2 \\frac{\\mu}{\\nu}}, \\right. \\\\ &amp;amp;\\quad \\frac{r\\alpha H(\\beta/(r\\alpha)) + \\mu H((2\\beta + 0.03)/\\mu) + 110/n}{\\beta \\log_2 \\frac{\\mu}{2\\beta + 0.03}}, \\\\ &amp;amp;\\quad (2\\beta + 0.03) \\left( \\frac{1}{\\alpha r - \\beta} + \\frac{1}{\\alpha\\beta} + \\frac{1}{\\mu - 2\\beta - 0.03} \\right) + 1. \\end{aligned}</span></div>

    <p class="text-gray-300">Then for every <span class="math">n</span> and <span class="math">\\alpha\\beta n \\leq k &amp;lt; \\beta n</span>, if <span class="math">\\frac{(r-1)+110/n}{\\log_2 q} \\leq 0.03</span>, <span class="math">2\\beta + 0.03 \\leq r - 1 - r\\alpha</span>, and <span class="math">\\beta \\leq \\alpha r</span>, then <span class="math">\\operatorname{Pr}[E_{n,k}^{(3)}] \\ll 2^{-100}</span>.</p>

    <p class="text-gray-300"><strong>Proof.</strong> We need to show that with overwhelming probability every set of <span class="math">k</span> coordinates of <span class="math">z \\in \\mathbb{F}^{\\alpha rn}</span> expands into at least <span class="math">b&#x27;(k) = \\left( \\beta + k/n + \\frac{(r-1)+110/n}{\\log_2 q} \\right)n</span> coordinates of <span class="math">v \\in \\mathbb{F}^{(1-r-r\\alpha)n}</span>. Note that</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Pr}[E_{n,k}^{(3)}] = \\operatorname{Pr}_{G \\in \\mathcal{G}\\alpha r n, n(r-1-r\\alpha), d_n} \\left[ G \\text{ contains a set of } k \\text{ left vertices with fewer than } b&#x27;(k) \\text{ neighbors} \\right].</span></div>

    <p class="text-gray-300">First, if <span class="math">d_n \\geq \\left( 2\\beta + \\frac{(r-1)+110/n}{\\log_2 q} \\right)n</span>, then every left vertex has at least <span class="math">d_n \\geq b&#x27;(\\beta n)</span> neighbors. Then trivially every set of <span class="math">k &amp;lt; \\beta n</span> left vertices has at least <span class="math">b&#x27;(k)</span> neighbors.</p>

    <p class="text-gray-300">Now we assume that <span class="math">d_n \\geq D</span>. Let <span class="math">k = \\gamma n</span> for <span class="math">\\alpha\\beta \\leq \\gamma &amp;lt; \\beta</span>, and let <span class="math">\\nu&#x27; = \\beta + \\gamma + 0.03</span>. A fixed set of size <span class="math">\\gamma n</span> expands into a set of size less than <span class="math">b&#x27;(k) = \\left( \\beta + k/n + \\frac{(r-1)+110/n}{\\log_2 q} \\right)n \\leq (\\beta + \\gamma + 0.03)n</span> with probability at most</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} \\binom{(r-1-r\\alpha)n}{b&#x27;(k)} \\frac{\\binom{b&#x27;(k)}{d_n}^{\\gamma n}}{\\binom{(r-1-r\\alpha)n}{d_n}^{\\gamma n}} &amp;amp;\\leq \\binom{(r-1-r\\alpha)n}{b&#x27;(k)} \\left(\\frac{b&#x27;(k)}{(r-1-r\\alpha)n}\\right)^{d_n \\gamma n} \\\\ &amp;amp;\\leq 2^{(r-1-r\\alpha)n H\\left(\\frac{\\beta + \\gamma + 0.03}{r-1-r\\alpha}\\right)} \\cdot \\left(\\frac{\\beta + \\gamma + 0.03}{r-1-r\\alpha}\\right)^{d_n \\gamma n} \\\\ &amp;amp;= 2^{\\mu n H\\left(\\frac{\\nu&#x27;}{\\mu}\\right) - d_n \\gamma n \\log_2 \\frac{\\mu}{\\nu&#x27;}}, \\end{aligned}</span></div>

    <p class="text-gray-300">where in the second inequality we used <span class="math">\\beta + \\gamma + 0.03 \\leq 2\\beta + 0.03 \\leq r - 1 - r\\alpha</span>.</p>

    <p class="text-gray-300">Taking the union bound over all sets of size <span class="math">\\gamma n</span> we have that</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} \\operatorname{Pr}[E_{n,k}^{(3)}] &amp;amp;\\leq \\binom{\\alpha r n}{\\gamma n} 2^{\\mu n H\\left(\\frac{\\nu&#x27;}{\\mu}\\right) - d_n \\gamma n \\log_2 \\frac{\\mu}{\\nu&#x27;}} \\\\ &amp;amp;\\leq 2^{\\alpha r n H\\left(\\frac{\\gamma}{r\\alpha}\\right) + \\mu n H\\left(\\frac{\\nu&#x27;}{\\mu}\\right) - d_n \\gamma n \\log_2 \\frac{\\mu}{\\nu&#x27;}}, \\end{aligned}</span></div>

    <p class="text-gray-300">where in the second inequality we used <span class="math">\\gamma &amp;lt; \\beta \\leq \\alpha r</span>. Let <span class="math">f(\\gamma) = \\alpha r n H\\left(\\frac{\\gamma}{r\\alpha}\\right) + \\mu n H\\left(\\frac{\\nu&#x27;}{\\mu}\\right) - d_n \\gamma n \\log_2 \\frac{\\mu}{\\nu&#x27;}</span> be the exponent in the above bound. We will show that <span class="math">f(\\gamma)</span> is convex, thus, obtains its maximum value at one of the end points <span class="math">\\gamma = \\alpha \\beta</span> or <span class="math">\\gamma = \\beta</span>. Then we will show that <span class="math">f(\\alpha \\beta), f(\\beta) &amp;lt; -100</span>. The second derivative of <span class="math">f(\\gamma)</span> is</p>

    <div class="my-4 text-center"><span class="math-block">f&#x27;&#x27;(\\gamma) = -n \\ln 2 \\left( \\frac{1}{\\alpha r - \\gamma} + \\frac{1}{\\mu - \\nu&#x27;} + \\frac{1}{\\gamma} + \\frac{d_n \\gamma}{(\\nu&#x27;)^2} + \\frac{1}{\\nu&#x27;} - \\frac{2 d_n}{v&#x27;} \\right).</span></div>

    <p class="text-gray-300">The following series of inequalities proves that <span class="math">f&#x27;&#x27;(\\gamma) \\geq 0</span> for all <span class="math">\\alpha \\beta \\leq \\gamma \\leq \\beta</span>.</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\frac{2 d_n}{\\nu&#x27;} - \\frac{d_n \\gamma}{(\\nu&#x27;)^2} - \\frac{1}{\\nu&#x27;} = \\frac{1}{\\nu&#x27;} \\left( 2 d_n - \\frac{d_n \\gamma}{\\nu&#x27;} - 1 \\right) \\\\ \\geq \\frac{d_n - 1}{\\nu&#x27;} \\\\ \\geq \\frac{d_n - 1}{2 \\beta + 0.03} \\\\ \\geq \\frac{1}{\\alpha r - \\beta} + \\frac{1}{\\alpha \\beta} + \\frac{1}{\\mu - 2 \\beta - 0.03} \\\\ \\geq \\frac{1}{\\alpha r - \\gamma} + \\frac{1}{\\gamma} + \\frac{1}{\\mu - \\nu&#x27;} \\,, \\end{array}</span></div>

    <p class="text-gray-300">where the first inequality uses <span class="math">\\nu&#x27; = \\beta + \\gamma + 0.03 \\geq \\gamma</span>, the second inequality uses <span class="math">\\nu&#x27; = \\beta + \\gamma + 0.03 \\leq 2\\beta + 0.03</span>, the third inequality uses <span class="math">d_n \\geq (2\\beta + 0.03)\\left(\\frac{1}{\\alpha r - \\beta} + \\frac{1}{\\alpha \\beta} + \\frac{1}{\\mu - 2\\beta - 0.03}\\right) + 1</span>, and the last inequality uses <span class="math">\\alpha \\beta \\leq \\gamma \\leq \\beta</span> and <span class="math">\\nu&#x27; \\leq 2\\beta + 0.03</span>.</p>

    <p class="text-gray-300">Finally, <span class="math">f(\\alpha \\beta) = \\alpha r n H\\left(\\frac{\\beta}{r}\\right) + \\mu n H\\left(\\frac{\\nu}{\\mu}\\right) - d_n \\alpha \\beta n \\log_2 \\frac{\\mu}{\\nu} \\leq -110</span> by the choice of <span class="math">d_n \\geq \\frac{r \\alpha H(\\beta / r) + \\mu H(\\nu / \\mu) + 110 / n}{\\alpha \\beta \\log_2 \\frac{\\nu}{\\nu}}</span>, and <span class="math">f(\\beta n) = \\alpha r n H\\left(\\frac{\\beta}{r \\alpha}\\right) + \\mu H\\left(\\frac{2\\beta + 0.03}{\\mu}\\right) - d_n \\beta n \\log_2 \\frac{\\mu}{2\\beta + 0.03} \\leq -110</span> from <span class="math">d_n \\geq \\frac{r \\alpha H(\\beta / (r \\alpha)) + \\mu n H(2\\beta + 0.03) / \\mu) + 110 / n}{\\beta \\log_2 \\frac{\\nu}{2\\beta + 0.03}}</span>.</p>

    <p class="text-gray-300">Claim 4. For every <span class="math">n</span> and <span class="math">\\alpha \\beta n \\leq k \\leq \\beta n</span>, if <span class="math">2\\beta + \\frac{(r - 1) + 110 / n}{\\log_2 q} \\leq r - 1 - r\\alpha</span>, then <span class="math">\\operatorname{Pr}[E_{n,k}^{(4)}] \\ll 2^{-100}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Proof. Assuming that every set of size <span class="math">k</span> expands into a set of size at least <span class="math">b&#x27;(k) = \\left( \\beta + k / n + \\frac{(r - 1) + 110 / n}{\\log_2 q} \\right)n</span>, we need to show that with overwhelming probability every <span class="math">z \\in \\mathbb{F}^{\\alpha rn}</span> of Hamming weight $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_0 = k<span class="math"> is mapped to </span>v = B \\cdot z \\in \\mathbb{F}^{(r - 1 - r\\alpha)n}<span class="math"> of Hamming weight </span>\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">v \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_0 \\geq \\beta n$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Fix a <span class="math">z \\in \\mathbb{F}^{\\alpha rn}</span> of Hamming weight $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_0 = k<span class="math">. Similarly to Claim 2, since the set of its non-zero coordinates expands into at least </span>b'(k)<span class="math"> coordinates, we have that at least </span>b'(k)<span class="math"> coordinates of </span>v<span class="math"> are non-zero linear combinations of the non-zero coordinates of </span>z<span class="math">. Each such linear combination equals zero with probability </span>\\leq 1/q<span class="math">, therefore, for a fixed </span>z<span class="math">, the probability that </span>\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">v \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_0 &lt; \\beta n$ is bounded from above by</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\frac{\\binom{b&#x27;(k)}{\\geq b&#x27;(k) - \\beta n}}{q^{b&#x27;(k) - \\beta n}} \\leq \\frac{\\binom{(r - 1 - r\\alpha)n}{\\geq (r - 1 - r\\alpha)n - \\beta n}}{q^{b&#x27;(k) - \\beta n}} \\leq \\frac{2^{(r - 1 - r\\alpha)n}}{q^{b&#x27;(k) - \\beta n}},</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where we used <span class="math">b&#x27;(k) \\leq \\left( 2\\beta + \\frac{(r - 1) + 110 / n}{\\log_2 q} \\right)n \\leq (r - 1 - r\\alpha)n</span>. Taking the union bound over all <span class="math">z \\in \\mathbb{F}^{\\alpha rn}</span> of Hamming weight $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_0 = k$, we have that</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Pr}[E_{n,k}^{(4)}] \\leq \\binom{r\\alpha n}{k} q^k \\cdot \\frac{2^{(r - 1 - r\\alpha)n}}{q^{b&#x27;(k) - \\beta n}} \\leq \\frac{2^{r\\alpha n + (r - 1 - r\\alpha)n}}{q^{b&#x27;(k) - \\beta n - k}} \\leq \\frac{2^{(r - 1)n}}{q^{\\left(\\frac{(r - 1) + 110 / n}{\\log_2 q}\\right)n}} \\ll 2^{-100}.</span></div>

    <p class="text-gray-300">□</p>

    <h5 id="sec-47" class="text-base font-semibold mt-4">A practical consideration: when to stop recursing.</h5>

    <p class="text-gray-300">One can modify Algorithm 1 such that for all message sizes less than some parameter <span class="math">n_{0}</span>, it simply performs naive (quadratic-time) Reed-Solomon encoding with an appropriate rate parameter (we use naive quadratic-time Reed-Solomon encoding to avoid the need to perform FFTs, and thereby achieve field-agnosticism). For messages of length <span class="math">n\\gg n_{0}^{2}</span>, the use of quadratic-time encoding applied just once to a message of size <span class="math">n_{0}</span> represents a low-order cost in the total encoding time. In our implementation, we set <span class="math">n_{0}</span> to roughly <span class="math">30</span>.</p>

    <h2 id="sec-48" class="text-2xl font-bold">6 Linear-time commitments for sparse multilinear polynomials</h2>

    <p class="text-gray-300">To construct SNARKs from polynomial IOPs (§1), we need a commitment scheme for multilinear polynomials <span class="math">\\widetilde{A}</span>, <span class="math">\\widetilde{B}</span>, and <span class="math">\\widetilde{C}</span> capturing the R1CS instance. Specifically, we desire a polynomial commitment scheme that when applied to these polynomials, the time to commit and prove an evaluation are both <span class="math">O(N)</span>.</p>

    <p class="text-gray-300">The previous section gave a commitment scheme for <span class="math">\\ell</span>-variate multilinear polynomials where the prover runs in time <span class="math">O(2^{\\ell})</span>. However, <span class="math">\\widetilde{A}</span>, <span class="math">\\widetilde{B}</span>, and <span class="math">\\widetilde{C}</span> are each defined over <span class="math">\\ell=2\\log M</span> variables. So if the commitment scheme is applied naively to these polynomials, the runtime of the committer is <span class="math">O(M^{2})</span>, which is superlinear in the size of the R1CS instance (unless a constant fraction of the entries of the matrices <span class="math">A,B,C</span> are non-zero). We call this an efficient commitment scheme for “dense” polynomials, since the prover’s runtime is linear in the number of coefficients of the polynomial, irrespective of how many of those coefficients are non-zero.</p>

    <p class="text-gray-300">Fortunately, for each of these three polynomials, only <span class="math">O(N)</span> of coefficients over the Lagrange basis are non-zero. If <span class="math">N\\ll M^{2}</span>, we call such polynomials <em>sparse</em>. What we require is a commitment scheme for sparse polynomials in which the committer runs in time proportional to the number of non-zero coefficients in both the commitment phase and the evaluation phase. Spartan <em>[75]</em> gave a technique that transforms any efficient polynomial commitment scheme for dense polynomials into an efficient polynomial commitment scheme for sparse polynomials. By applying Spartan’s construction to the polynomial commitment scheme of the previous section, we obtain our desired sparse polynomial commitment scheme.</p>

    <h5 id="sec-49" class="text-base font-semibold mt-4">A straw-man approach and a conceptual outline.</h5>

    <p class="text-gray-300">The following is a natural approach to turning a commitment scheme for dense polynomials into one for sparse polynomials. To commit to a sparse <span class="math">\\ell</span>-variate multilinear polynomial <span class="math">q</span> with <span class="math">k\\ll 2^{\\ell}</span> non-zero coefficients, the committer commits to a representation of the non-zero coefficients <span class="math">q</span> using a polynomial commitment for dense polynomials.</p>

    <p class="text-gray-300">In more detail, associate each Lagrange basis polynomial with a bit-vector <span class="math">S</span> in <span class="math">\\{0,1\\}^{\\ell}</span>, and let <span class="math">c_{S}</span> be the coefficient of monomial <span class="math">S</span> in <span class="math">q</span>. Consider the vector <span class="math">v\\in\\mathbb{P}^{k(1+\\ell)}</span> that simply lists all non-zero (coefficient, monomial) pairs, i.e., <span class="math">v=\\{(c_{S},S):c_{S}\\neq 0\\}</span>. The committer commits to the multilinear extension of the vector <span class="math">v</span> using the dense polynomial commitment scheme, which takes <span class="math">O(k\\ell)</span> time. Then when the verifier asks to evaluate the sparse polynomial <span class="math">q</span> at an input <span class="math">r</span>, one applies an interactive proof for the function that takes as input the vector <span class="math">v</span> that describes <span class="math">q</span> and outputs <span class="math">q(r)</span> (for example, one can apply the GKR protocol <em>[48]</em> to the circuit that takes as input <span class="math">v</span> and outputs <span class="math">q(r)=\\sum_{S}c_{S}\\cdot\\chi_{S}(r)</span>, where <span class="math">\\chi_{S}</span> is the Lagrange basis polynomial corresponding to <span class="math">S</span>). At the end of the interactive proof the verifier needs to evaluate the multilinear extension of <span class="math">v</span> at a random point and can obtain this evaluation from the dense polynomial commitment scheme used to commit to this extension of <span class="math">v</span>.</p>

    <p class="text-gray-300">The problem with this polynomial commitment scheme is that the description of <span class="math">v</span> that is used consists of <span class="math">\\Theta(k\\ell)</span> field elements, which is superlinear in the number <span class="math">k</span> of non-zero coefficients of <span class="math">q</span>, and hence the committer in this scheme runs in superlinear time. Spartan <em>[75]</em> identified a way to use memory-checking techniques allowing to use a description of <span class="math">q</span> consisting of only <span class="math">\\Theta(k)</span> field elements, thereby obtaining a linear-time committer. Details follow.</p>

    <p class="text-gray-300">We first state the result from Spartan <em>[75, Lemma 7.6]</em> in a more general form; below, provide a detailed proof of this result for completeness. An alternate perspective on this result is in <em>[82, §13]</em>.</p>

    <h6 id="sec-50" class="text-base font-medium mt-4">Theorem 3 (<em>[75]</em>).</h6>

    <p class="text-gray-300">Given a polynomial commitment scheme for <span class="math">\\log M</span>-variate multilinear polynomials with the following parameters (where <span class="math">M</span> is a positive integer and WLOG a power of 2):</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>the size of the commitment is <span class="math">\\mathsf{c}(M)</span></li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>the running time of the commit algorithm is <span class="math">\\mathsf{tc}(M)</span>;</li>

      <li>the running time of the prover to prove a polynomial evaluation is <span class="math">\\mathsf{tp}(M)</span>;</li>

      <li>the running time of the verifier to verify a polynomial evaluation is <span class="math">\\mathsf{tv}(M)</span>; and</li>

      <li>the proof size is <span class="math">\\mathsf{p}(M)</span>,</li>

    </ul>

    <p class="text-gray-300">there exists a polynomial commitment scheme for <span class="math">2\\log M</span>-variate multilinear polynomials that evaluate to a non-zero value at at most <span class="math">N=\\Omega(M)</span> locations over the Boolean hypercube <span class="math">\\{0,1\\}^{2\\log M}</span>, with the following parameters, assuming that the commit algorithm is run by an honest entity:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>the size of the commitment is <span class="math">O(\\mathsf{c}(N))</span>;</li>

      <li>the running time of the commit algorithm is <span class="math">O(\\mathsf{tc}(N))</span>;</li>

      <li>the running time of the prover to prove a polynomial evaluation is <span class="math">O(\\mathsf{tp}(N))</span>;</li>

      <li>the running time of the verifier to verify a polynomial evaluation is <span class="math">O(\\mathsf{tv}(N))</span>; and</li>

      <li>the proof size is <span class="math">O(\\mathsf{p}(N))</span>.</li>

    </ul>

    <p class="text-gray-300">The following corollary follows from applying the above theorem to the polynomial commitment scheme for <span class="math">\\log M</span>-variate multilinear polynomials (Theorem 2).</p>

    <h6 id="sec-51" class="text-base font-medium mt-4">Corollary 1.</h6>

    <p class="text-gray-300">Given a polynomial commitment scheme for <span class="math">\\log M</span>-variate multilinear polynomials with the following parameters (where <span class="math">M</span> is a positive integer and WLOG a power of 2, <span class="math">t</span> is a constant, and <span class="math">\\lambda</span> is the security parameter):</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>the size of the commitment is <span class="math">O_{\\lambda}(1)</span>;</li>

      <li>the running time of the commit algorithm is <span class="math">O(M)</span> operations over <span class="math">\\mathbb{F}</span>;</li>

      <li>the running time of the prover to prove a polynomial evaluation is <span class="math">O(M)</span> operations over <span class="math">\\mathbb{F}</span>;</li>

      <li>the running time of the verifier to verify a polynomial evaluation is <span class="math">O_{\\lambda}(M^{1/t})</span> operations over <span class="math">\\mathbb{F}</span>; and</li>

      <li>the proof size is <span class="math">O_{\\lambda}(M^{1/t})</span>,</li>

    </ul>

    <p class="text-gray-300">there exists a polynomial commitment scheme for <span class="math">2\\log M</span>-variate multilinear polynomials that evaluate to a non-zero value at at most <span class="math">N=\\Omega(M)</span> locations over the Boolean hypercube <span class="math">\\{0,1\\}^{2\\log M}</span>, with the following parameters, assuming that the commit algorithm is run by an honest entity:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>the size of the commitment is <span class="math">O_{\\lambda}(1)</span>;</li>

      <li>the running time of the commit algorithm is <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span>;</li>

      <li>the running time of the prover to prove a polynomial evaluation is <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span>;</li>

      <li>the running time of the verifier to verify a polynomial evaluation is <span class="math">O_{\\lambda}(N^{1/t})</span> operations over <span class="math">\\mathbb{F}</span>; and</li>

      <li>the proof size is <span class="math">O_{\\lambda}(N^{1/t})</span>.</li>

    </ul>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">.</p>

    <h4 id="sec-52" class="text-lg font-semibold mt-6">Representing sparse polynomials with dense polynomials.</h4>

    <p class="text-gray-300">Let <span class="math">D</span> denote a <span class="math">2\\log M</span>-variate multilinear polynomial that evaluates to a non-zero value at at most <span class="math">N=\\Omega(M)</span> locations over <span class="math">\\{0,1\\}^{2\\log M}</span>. For any <span class="math">r\\in\\mathbb{F}^{2\\log M}</span>, we can express the evaluation of <span class="math">D(r)</span> as follows. Interpret <span class="math">r\\in\\mathbb{F}^{2\\log M}</span> as a tuple <span class="math">(r_{x},r_{y})</span> in a natural manner, where <span class="math">r_{x},r_{y}\\in\\mathbb{F}^{\\log M}</span>.</p>

    <p class="text-gray-300"><span class="math">D(r_{x},r_{y})=\\sum_{(i,j)\\in\\{0,1\\}^{\\log M}\\times\\{0,1\\}^{\\log M}\\,:\\,D(i,j)\\neq 0}D(i,j)\\cdot\\widetilde{eq}(i,r_{x})\\cdot\\widetilde{eq}(j,r_{y}).</span> (10)</p>

    <h6 id="sec-53" class="text-base font-medium mt-4">Claim 2.</h6>

    <p class="text-gray-300">Let <span class="math">\\mathsf{b}</span> be the canonical injection from <span class="math">\\{0,1\\}^{\\log M}</span> to <span class="math">\\mathbb{F}</span> and <span class="math">\\mathsf{b}^{-1}</span> be its inverse. Given a <span class="math">2\\log M</span>-variate multilinear polynomial <span class="math">D</span> that evaluates to a non-zero value at at most <span class="math">N</span> locations over <span class="math">\\{0,1\\}^{2\\log M}</span>, there exist three <span class="math">\\log N</span>-variate multilinear polynomials <span class="math">\\mathsf{row},\\mathsf{col},\\mathsf{val}</span> such that the following holds for all <span class="math">r_{x},r_{y}\\in\\mathbb{F}^{*}</span>.</p>

    <p class="text-gray-300"><span class="math">D(r_{x},r_{y})=\\sum_{k\\in\\{0,1\\}^{\\log N}}\\mathsf{val}(k)\\cdot\\widetilde{eq}(\\mathsf{b}^{-1}(\\mathsf{row}(k)),r_{x})\\cdot\\widetilde{eq}(\\mathsf{b}^{-1}(\\mathsf{col}(k)),r_{y}).</span> (11)</p>

    <p class="text-gray-300">Moreover, the polynomials’ coefficients in the Lagrange basis can be computed in <span class="math">O(N)</span> time.</p>

    <h6 id="sec-54" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Since <span class="math">D</span> evaluates to a non-zero value at at most <span class="math">N</span> locations over <span class="math">\\{0,1\\}^{2\\log M}</span>, <span class="math">D</span> can be represented uniquely with <span class="math">N</span> tuples of the form <span class="math">(i,j,D(i,j))\\in(\\{0,1\\}^{\\log M},\\{0,1\\}^{\\log M},\\mathbb{F})</span>. By using a natural injection (call it <span class="math">\\mathsf{b}</span>) from <span class="math">\\{0,1\\}^{\\log M}</span> to <span class="math">\\mathbb{F}</span>, we can view the first two entries in each of these tuples as elements of <span class="math">\\mathbb{F}</span> (let <span class="math">\\mathsf{b}^{-1}</span> denote its inverse). Furthermore, these tuples can be represented with three <span class="math">N</span>-sized vectors <span class="math">R,C,V\\in\\mathbb{F}^{N}</span>, where tuple <span class="math">k</span> (for all <span class="math">k\\in[N]</span>) is stored across the three vectors at the <span class="math">k</span>th location in the vector, i.e., the first entry in the tuple is stored in <span class="math">R</span>, the second entry in <span class="math">C</span>, and the third entry in <span class="math">V</span>. Take <span class="math">\\mathsf{row}</span> as the unique MLE of <span class="math">R</span> viewed as a function <span class="math">\\{0,1\\}^{\\log N}\\to\\mathbb{F}</span>. Similarly, <span class="math">\\mathsf{col}</span> is the unique MLE of <span class="math">C</span>, and <span class="math">\\mathsf{val}</span> is the unique MLE of <span class="math">V</span>. The claim holds by inspection since Equations (10) and (11) are both multilinear polynomials in <span class="math">r_{x}</span> and <span class="math">r_{y}</span> and agree with each other at every pair <span class="math">r_{x},r_{y}\\in\\{0,1\\}^{\\log M}</span>. ∎</p>

    <h4 id="sec-55" class="text-lg font-semibold mt-6">A first attempt at the commit phase.</h4>

    <p class="text-gray-300">Here is a first attempt at designing the commit phase. To commit to <span class="math">D</span>, the committer can send commitments to the three <span class="math">\\log N</span>-variate multilinear polynomials <span class="math">\\mathsf{row},\\mathsf{col},\\mathsf{val}</span> from Claim 2. Using the provided polynomial commitment scheme, this costs <span class="math">O(N)</span> finite field operations, and the size of the commitment to <span class="math">D</span> is <span class="math">O_{\\lambda}(1)</span>. As we will see, to aid in the evaluation phase, we will ultimately have to extend the commit phase to include commitments to several additional polynomials.</p>

    <h4 id="sec-56" class="text-lg font-semibold mt-6">A first attempt at the evaluation phase.</h4>

    <p class="text-gray-300">Given <span class="math">r_{x},r_{y}\\in\\mathbb{F}^{\\log M}</span>, to prove an evaluation of a committed polynomial, i.e., to prove that <span class="math">D(r_{x},r_{y})=v</span> for a purported evaluation <span class="math">v\\in\\mathbb{F}</span>, consider the following polynomial IOP, where assume that the verifier has oracle access to the three <span class="math">\\log N</span>-variate multilinear polynomial oracles that encode <span class="math">D</span> (<span class="math">\\mathsf{row},\\mathsf{col},\\mathsf{val}</span>):</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{P}\\to\\mathcal{V}</span>: two <span class="math">\\log N</span>-variate multilinear polynomials <span class="math">E_{\\mathsf{rs}}</span> and <span class="math">E_{\\mathsf{ry}}</span> as oracles. These polynomials are purported to respectively equal the multilinear extensions of the functions mapping <span class="math">k\\in\\{0,1\\}^{\\log N}</span> to <span class="math">\\widetilde{eq}(\\mathsf{b}^{-1}(\\mathsf{row}(k)),r_{x})</span> and <span class="math">\\widetilde{eq}(\\mathsf{b}^{-1}(\\mathsf{col}(k)),r_{y})</span>.</li>

      <li><span class="math">\\mathcal{V}\\leftrightarrow\\mathcal{P}</span>: run the sum-check reduction to reduce the check that</li>

    </ol>

    <p class="text-gray-300"><span class="math">v=\\sum_{k\\in\\{0,1\\}^{\\log N}}\\mathsf{val}(k)\\cdot E_{\\mathsf{rs}}(k)\\cdot E_{\\mathsf{ry}}(k)</span></p>

    <p class="text-gray-300">to checking if the following hold, where <span class="math">r_{z}\\in\\mathbb{F}^{\\log N}</span> is chosen at random by the verifier over the course of the sum-check protocol:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{val}(r_z) \\stackrel{?}{=} v_{\\mathsf{val}}</span>;</li>

      <li><span class="math">E_{\\mathsf{rx}}(r_z) \\stackrel{?}{=} v_{E_{\\mathsf{rx}}}</span> and <span class="math">E_{\\mathsf{ry}}(r_z) \\stackrel{?}{=} v_{E_{\\mathsf{ry}}}</span>. Here, <span class="math">v_{\\mathsf{val}}</span>, <span class="math">v_{E_{\\mathsf{rx}}}</span>, and <span class="math">v_{E_{\\mathsf{ry}}}</span> are values provided by the prover at the end of the sum-check protocol.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}</span>: check if the three equalities hold with an oracle query to each of <span class="math">\\mathsf{val}, E_{\\mathsf{rx}}, E_{\\mathsf{ry}}</span>.</li>

    </ol>

    <p class="text-gray-300">If the prover is honest, it is easy to see that it can convince the verifier about the correct of evaluations of <span class="math">D</span>. Unfortunately, the two oracles that the prover sends in the first step of the depicted polynomial IOP can be completely arbitrary. To fix, this, <span class="math">\\mathcal{V}</span> must <em>additionally</em> check that the following two conditions hold.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\forall k\\in \\{0,1\\}^{\\log N}</span>, <span class="math">E_{\\mathsf{rx}}(k)=\\widetilde{eq}(\\mathsf{b}^{-1}(\\mathsf{row}(k)),r_{x})</span>; and</li>

      <li><span class="math">\\forall k\\in \\{0,1\\}^{\\log N}</span>, <span class="math">E_{\\mathsf{ry}}(k)=\\widetilde{eq}(\\mathsf{b}^{-1}(\\mathsf{col}(k)),r_{y})</span>.</li>

    </ul>

    <p class="text-gray-300">A core insight of Spartan <em>[75]</em> is to check these two conditions using memory-checking techniques <em>[20]</em>. In particular, the RHS in each of the above conditions can be viewed as <span class="math">N</span> memory lookups over an <span class="math">M</span>-sized memory, initialized to contain the values <span class="math">\\{\\widetilde{eq}(i,r_{x})\\colon i\\in\\{0,1\\}^{\\log M}\\}</span> and <span class="math">\\{\\widetilde{eq}(j,r_{y})\\colon j\\in\\{0,1\\}^{\\log M}\\}</span> (note that all of these values can be computed in <span class="math">O(M)</span> total time using standard techniques).</p>

    <p class="text-gray-300">Specifically, focusing on the RHS of the first condition, the <span class="math">M</span>-sized memory <span class="math">\\mathsf{mem}_{\\mathsf{rx}}</span> is initialized to satisfy <span class="math">\\mathsf{mem}_{\\mathsf{rx}}[i]=\\widetilde{eq}(i,r_{x})</span> for all <span class="math">i\\in\\{0,1\\}^{\\log M}</span>, and for memory lookup <span class="math">k\\in[N]</span>, the memory address that is read is <span class="math">\\mathsf{row}(k)</span>. Similarly, in the second condition, the <span class="math">M</span>-sized memory <span class="math">\\mathsf{mem}_{\\mathsf{ry}}</span> is the evaluations of <span class="math">\\widetilde{eq}(j,r_{y})</span> for all <span class="math">j\\in\\{0,1\\}^{\\log M}</span>, and for memory lookup <span class="math">k\\in[N]</span>, the memory address read is <span class="math">\\mathsf{col}(k)</span>.</p>

    <p class="text-gray-300">We take a detour to introduce prior results that we rely on here.</p>

    <h4 id="sec-57" class="text-lg font-semibold mt-6">Detour: offline memory checking.</h4>

    <p class="text-gray-300">Recall that in the offline memory checking algorithm of <em>[20]</em>, a <em>trusted checker</em> issues operations to an untrusted memory. For our purposes, it suffices to consider only operation sequences in which each memory address is initialized to a certain value, and all subsequent operations are read operations. To enable efficient checking using set-fingerprinting techniques, the memory is modified so that in addition to storing a value at each address, the memory also stores a timestamp with each address. Moreover, each read operation is followed by a write operation that updates the timestamp associated with that address (but not the value stored there). This is captured in the codebox below.</p>

    <p class="text-gray-300"><em>Local state of the checker:</em></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>a timestamp counter <span class="math">ts</span> initialized to 0;</li>

      <li>Two sets: <span class="math">RS</span> and <span class="math">WS</span>, which are initialized as follows. <span class="math">RS=\\{\\}</span>, and for an <span class="math">M</span>-sized memory, <span class="math">WS</span> is initialized to the following set of tuples: for all <span class="math">i\\in[M]</span>, the tuple <span class="math">(i,v_{i},0)</span> is included in <span class="math">WS</span>, where <span class="math">v_{i}</span> is the value stored at address <span class="math">i</span>, and the third entry in the tuple, 0, is an “initial timestamp” associated with the value (intuitively capturing the notion that <span class="math">v_{i}</span> was written to address <span class="math">i</span> at time step 0, i.e., at initialization).</li>

    </ul>

    <p class="text-gray-300"><em>Read operations and an invariant.</em> For a read operation at address <span class="math">a</span>, suppose that the untrusted memory responds with a value-timestamp pair <span class="math">(v,t)</span>. Then the checker updates its local state as follows:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">RS\\leftarrow RS\\cup\\{(a,v,t)\\}</span>;</li>

      <li><span class="math">ts\\leftarrow\\max(ts,t)+1</span>;</li>

    </ol>

    <p class="text-gray-300">3.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>store <span class="math">(v, ts)</span> at address <span class="math">a</span> in the untrusted memory; and</li>

      <li><span class="math">WS \\gets WS \\cup \\{(a, v, ts)\\}</span>.</li>

    </ol>

    <p class="text-gray-300">The following claim captures the invariant maintained on the sets of the checker:</p>

    <p class="text-gray-300"><strong>Claim 3.</strong> There exists a set <span class="math">S</span> with cardinality <span class="math">M</span> consisting of tuples of the form <span class="math">(k, v_k, t_k)</span> for all <span class="math">k \\in [M]</span> such that <span class="math">WS = RS \\cup S</span> if and only if for every read operation the untrusted memory returns the tuple last written to that location.</p>

    <p class="text-gray-300"><em>Proof.</em> A proof of a more general claim is at [77, Lemma C.1]. <span class="math">\\square</span></p>

    <p class="text-gray-300">Observe that if the untrusted memory is honest, <span class="math">S</span> can be constructed trivially from the current state of the memory. It is simply the current state of the memory viewed as a set of address-value-timestamp tuples.</p>

    <p class="text-gray-300"><strong>Timestamp polynomials.</strong> To aid the polynomial evaluation proof of the sparse polynomial commitment scheme, the commit algorithm of the sparse polynomial commitment commits to additional multilinear polynomials, beyond val, row, and col. We now describe these additional polynomials and how they are constructed.</p>

    <p class="text-gray-300">Observe that given the size of memory <span class="math">M</span> and a list of <span class="math">N</span> addresses involved in read operations, one can locally compute three vectors <span class="math">T_r \\in \\mathbb{F}^N</span>, <span class="math">T_w \\in \\mathbb{F}^N</span>, <span class="math">T_f \\in \\mathbb{F}^M</span> defined as follows. For <span class="math">k \\in [N]</span>, <span class="math">T_r[k]</span> stores the timestamp that would have been returned by the untrusted memory if it were honest during the <span class="math">k</span>th read operation. Let <span class="math">T_w[k]</span> store the timestamp that the checker stores in step (3) of its specification when processing the <span class="math">k</span>th read operation. Similarly, for <span class="math">k \\in [M]</span>, let <span class="math">T_f[k]</span> store the final timestamp stored at memory location <span class="math">k</span> of the untrusted memory (if the untrusted memory were honest) at the termination of the <span class="math">N</span> read operations. Computing these three vectors requires computation comparable to <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span>.</p>

    <p class="text-gray-300">Let <span class="math">\\mathsf{read} = \\widetilde{T}_r, \\mathsf{write} = \\widetilde{T}_w, \\mathsf{final} = \\widetilde{T}_f</span>. We refer these polynomials as timestamp polynomials, which are unique for a given memory size <span class="math">M</span> and a list of <span class="math">N</span> addresses involved in read operations.</p>

    <p class="text-gray-300"><strong>The actual commit algorithm.</strong> Given a <span class="math">2\\log M</span>-variate multilinear polynomial <span class="math">D</span> that evaluates to a non-zero value at most <span class="math">N</span> locations over <span class="math">\\{0,1\\}^{2\\log M}</span>, the commitment algorithm commits to <span class="math">D</span> by committing to seven <span class="math">\\log N</span>-variate multilinear polynomials (row, col, val, read_row, write_row, read_col, write_col), two <span class="math">\\log M</span>-variate multilinear polynomials (final_row, final_col), where row, col, val are described in Claim 2, and (read_row, write_row, final_row) and (read_col, write_col, final_col) are respectively the timestamp polynomials for the <span class="math">N</span> addresses specified by row and col over a memory of size <span class="math">M</span>.</p>

    <p class="text-gray-300">There are two crucial subtleties unique to the setting of holography that we are exploiting in the above commitment procedure. First, that the timestamp polynomials (read_row, write_row, final_row, read_col, write_col, final_col) depend only on the sparse polynomial being committed, and in particular not on the evaluation point <span class="math">(r_x, r_y)</span>. Second, in the holography context, the commit algorithm is run by an honest entity. This means that the commit phase does not need to include any proof that the committed timestamp polynomials actually equal the polynomials <span class="math">\\widetilde{T}_r</span>, <span class="math">\\widetilde{T}_w</span>, and <span class="math">\\widetilde{T}_f</span> described above. This appears to be essential for avoiding superlinear operations such as sorting.⁴</p>

    <p class="text-gray-300">In total, using the provided polynomial commitment, the commit algorithm incurs <span class="math">O(N)</span> finite field operations, and the commitment size is <span class="math">O_{\\lambda}(1)</span>.</p>

    <p class="text-gray-300">⁴If desired in other contexts, such a proof can be produced with <span class="math">O(N \\log N)</span> operations over <span class="math">\\mathbb{F}</span>. We are unaware of a mechanism to produce a proof faster than this. Straightforward approaches either require breaking field elements into their binary representations (which introduces <span class="math">\\log N</span> factor to the number of coefficients of the polynomials being committed) or require the prover to sort a vector of timestamps, which is a superlinear-time operation. The challenging issue is to ensure after every read operation, the timestamp associated with the memory location gets updated to the maximum of the returned timestamp <span class="math">ts</span> and the current timestamp <span class="math">t</span>.</p>

    <p class="text-gray-300">30</p>

    <p class="text-gray-300">The actual evaluation procedure. To prove the correct evaluation of a <span class="math">2\\log M</span>-variate multilinear polynomial <span class="math">D</span>, in addition to performing the polynomial IOP depicted earlier in the proof, the core idea is to check if the two oracles sent by the prover satisfy the conditions identified earlier using Claim 3.</p>

    <h6 id="sec-58" class="text-base font-medium mt-4">Claim 4.</h6>

    <p class="text-gray-300">Given a <span class="math">2\\log M</span>-variate multilinear polynomial, suppose that <span class="math">(\\mathsf{row},\\mathsf{col},\\mathsf{val},\\mathsf{read}_{\\mathsf{row}},\\mathsf{write}_{\\mathsf{row}},\\mathsf{final}_{\\mathsf{row}},\\mathsf{read}_{\\mathsf{col}}</span>, <span class="math">\\mathsf{write}_{\\mathsf{col}},\\mathsf{final}_{\\mathsf{col}})</span> denote multilinear polynomials committed by the commit algorithm. Then, for any <span class="math">r_{x}\\in\\mathbb{F}^{\\log M}</span>, checking that <span class="math">\\forall k\\in\\{0,1\\}^{\\log N}</span>, <span class="math">E_{\\mathsf{rx}}(k)=\\widetilde{eq}(\\mathsf{b}^{-1}(\\mathsf{row}(k)),r_{x})</span> is equivalent to checking <span class="math">WS=RS\\cup S</span>, where</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">WS=\\{(i,\\widetilde{eq}(i,r_{x}),0)\\colon i\\in[M]\\}\\cup\\{(\\mathsf{row}(k),E_{\\mathsf{rx}}(k),\\mathsf{write}_{\\mathsf{row}}(k))\\colon k\\in[N]\\}</span>;</li>

      <li><span class="math">RS=\\{(\\mathsf{row}(k),E_{\\mathsf{rx}}(k),\\mathsf{read}_{\\mathsf{row}}(k))\\colon k\\in[N]\\}</span>; and</li>

      <li><span class="math">S=\\{(i,\\widetilde{eq}(i,r_{x}),\\mathsf{final}_{\\mathsf{row}}(i))\\colon i\\in[M]\\}</span>.</li>

    </ul>

    <p class="text-gray-300">Similarly, for any <span class="math">r_{y}\\in\\mathbb{F}^{\\log M}</span>, checking that <span class="math">\\forall k\\in\\{0,1\\}^{\\log N}</span>, <span class="math">E_{\\mathsf{ry}}(k)=\\widetilde{eq}(\\mathsf{b}^{-1}(\\mathsf{col}(k)),r_{y})</span> is equivalent to checking <span class="math">WS^{\\prime}=RS^{\\prime}\\cup S^{\\prime}</span>, where</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">WS^{\\prime}=\\{(j,\\widetilde{eq}(j,r_{y}),0)\\colon j\\in[M]\\}\\cup\\{(\\mathsf{col}(k),E_{\\mathsf{ry}}(k),\\mathsf{write}_{\\mathsf{col}}(k))\\colon k\\in[N]\\}</span>;</li>

      <li><span class="math">RS^{\\prime}=\\{(\\mathsf{col}(k),E_{\\mathsf{ry}}(k),\\mathsf{read}_{\\mathsf{col}}(k))\\colon k\\in[N]\\}</span>; and</li>

      <li><span class="math">S^{\\prime}=\\{(j,\\widetilde{eq}(j,r_{y}),\\mathsf{final}_{\\mathsf{col}}(i))\\colon j\\in[M]\\}</span>.</li>

    </ul>

    <h6 id="sec-59" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">The desired result follows from a straightforward application of the invariant in Claim 3. ∎</p>

    <p class="text-gray-300">There is no direct way to prove that the checks on sets in Claim 4 hold. Instead, we rely on public-coin, multiset hash functions to compress <span class="math">RS</span>, <span class="math">WS</span>, and <span class="math">S</span> into a single element of <span class="math">\\mathbb{F}</span> each. Specifically:</p>

    <h6 id="sec-60" class="text-base font-medium mt-4">Claim 5 (<em>[75]</em>).</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Given two multisets <span class="math">A,B</span> where each element is from <span class="math">\\mathbb{F}^{3}</span>, checking that <span class="math">A=B</span> is equivalent to checking the following, except for a soundness error of $O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">B</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> over the choice of </span>\\gamma,\\tau<span class="math">: </span>\\mathcal{H}_{\\tau,\\gamma}(A)=\\mathcal{H}_{\\tau,\\gamma}(B)<span class="math">, where </span>\\mathcal{H}_{\\tau,\\gamma}(A)=\\prod_{(a,v,t)\\in A}(h_{\\gamma}(a,v,t)-\\tau)<span class="math">, and </span>h_{\\gamma}(a,v,t)=a\\cdot\\gamma^{2}+v\\cdot\\gamma+t<span class="math">. That is, if </span>A=B<span class="math">, </span>\\mathcal{H}_{\\tau,\\gamma}(A)=\\mathcal{H}_{\\tau,\\gamma}(B)<span class="math"> with probability </span>1<span class="math"> over randomly chosen values </span>\\tau<span class="math"> and </span>\\gamma<span class="math"> in </span>\\mathbb{F}<span class="math">, while if </span>A\\neq B<span class="math">, then </span>\\mathcal{H}_{\\tau,\\gamma}(A)=\\mathcal{H}_{\\tau,\\gamma}(B)<span class="math"> with probability at most </span>O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">B</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We are now ready to depict a polynomial IOP for proving evaluations of a committed sparse multilinear polynomial. Given <span class="math">r_{x},r_{y}\\in\\mathbb{F}^{\\log M}</span>, to prove that <span class="math">D(r_{x},r_{y})=v</span> for a purported evaluation <span class="math">v\\in\\mathbb{F}</span>, consider the following polynomial IOP, where assume that the verifier has an oracle access to multilinear polynomial oracles that encode <span class="math">D</span> (namely, <span class="math">\\mathsf{row},\\mathsf{col},\\mathsf{val},\\mathsf{read}_{\\mathsf{row}},\\mathsf{write}_{\\mathsf{row}},\\mathsf{final}_{\\mathsf{row}},\\mathsf{read}_{\\mathsf{col}}</span>, <span class="math">\\mathsf{write}_{\\mathsf{col}},\\mathsf{final}_{\\mathsf{col}}</span>).</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{P}\\to\\mathcal{V}</span>: two <span class="math">\\log N</span>-variate multilinear polynomials <span class="math">E_{\\mathsf{rx}}</span> and <span class="math">E_{\\mathsf{ry}}</span> as oracles.</li>

      <li><span class="math">\\mathcal{V}\\leftrightarrow\\mathcal{P}</span>: run the sum-check reduction to reduce the check that</li>

    </ol>

    <p class="text-gray-300"><span class="math">v=\\sum_{k\\in\\{0,1\\}^{\\log N}}\\mathsf{val}(k)\\cdot E_{\\mathsf{rx}}(k)\\cdot E_{\\mathsf{ry}}(k)</span></p>

    <p class="text-gray-300">to checking that the following equations hold, where <span class="math">r_{z}\\in\\mathbb{F}^{\\log N}</span> chosen at random by the verifier over the course of the sum-check protocol:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{val}(r_{z})\\stackrel{{\\scriptstyle?}}{{=}}v_{\\mathsf{val}}</span>; and</li>

      <li><span class="math">E_{\\mathsf{rx}}(r_{z})\\stackrel{{\\scriptstyle?}}{{=}}v_{E_{\\mathsf{rx}}}</span> and <span class="math">E_{\\mathsf{ry}}(r_{z})\\stackrel{{\\scriptstyle?}}{{=}}v_{E_{\\mathsf{ry}}}</span>. Here, <span class="math">v_{\\mathsf{val}}</span>, <span class="math">v_{E_{\\mathsf{rx}}}</span> and <span class="math">v_{E_{\\mathsf{ry}}}</span> are values provided by the prover at the end of the sum-check protocol.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}</span>: check if the three obligations hold with an oracle query each to <span class="math">\\mathsf{val},E_{\\mathsf{rx}},E_{\\mathsf{ry}}</span>.</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>// The following steps check if  <span class="math">E_{\\mathrm{rx}}</span>  is well-formed</li>

      <li><span class="math">\\mathcal{V}\\to \\mathcal{P}</span>  ..  <span class="math">\\tau ,\\gamma \\in_{R}\\mathbb{F}</span></li>

      <li><span class="math">\\mathcal{V} \\leftrightarrow \\mathcal{P}</span> : run the layered sum-check reduction for "grand products" [81, §5.3.1] to reduce the check that  <span class="math">\\mathcal{H}_{\\tau,\\gamma}(WS) = \\mathcal{H}_{\\tau,\\gamma}(RS) \\cdot \\mathcal{H}_{\\tau,\\gamma}(S)</span> , where  <span class="math">RS, WS, S</span>  are as defined in Claim 4 and  <span class="math">\\mathcal{H}</span>  is defined in Claim 5 to checking if the following hold, where  <span class="math">r_M \\in \\mathbb{F}^{\\log M}, r_N \\in \\mathbb{F}^{\\log N}</span>  chosen at random by the verifier over the course of the sum-check protocol:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\widetilde{eq}(r_M, r_x) \\stackrel{?}{=} v_{eq}</span></li>

      <li><span class="math">E_{\\mathrm{rx}}(r_N) \\stackrel{?}{=} v_{E_{\\mathrm{rx}}}</span></li>

      <li><span class="math">\\operatorname{row}(r_N) \\stackrel{?}{=} v_{\\operatorname{row}}</span> ;  <span class="math">\\operatorname{write}_{\\operatorname{row}}(r_N) \\stackrel{?}{=} v_{\\operatorname{write}_{\\operatorname{row}}}</span> ;  <span class="math">\\operatorname{read}_{\\operatorname{row}}(r_N) \\stackrel{?}{=} v_{\\operatorname{read}_{\\operatorname{row}}}</span> ; and  <span class="math">\\operatorname{final}_{\\operatorname{row}}(r_M) \\stackrel{?}{=} v_{\\operatorname{final}_{\\operatorname{row}}}</span></li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}</span> : directly check if the first equality holds, which can be done with  <span class="math">O(\\log M)</span>  field operations; check the remaining equations hold with an oracle query to each of  <span class="math">E_{\\mathrm{rx}}, \\mathrm{row}, \\mathrm{write}_{\\mathrm{row}}, \\mathrm{read}_{\\mathrm{row}}, \\mathrm{final}_{\\mathrm{row}}</span> .</li>

      <li>// The following steps check if  <span class="math">E_{\\mathrm{ry}}</span>  is well-formed</li>

      <li><span class="math">\\mathcal{V}\\to \\mathcal{P}</span>  ..  <span class="math">\\tau^{\\prime},\\gamma^{\\prime}\\in_{R}\\mathbb{F}</span></li>

      <li><span class="math">\\mathcal{V} \\leftrightarrow \\mathcal{P}</span> : run the sum-check reduction for "grand products" [81, 78] to reduce the check that  <span class="math">\\mathcal{H}_{\\tau&#x27;, \\gamma&#x27;}(WS&#x27;) = \\mathcal{H}_{\\tau&#x27;, \\gamma&#x27;}(RS&#x27;) \\cdot \\mathcal{H}_{\\tau&#x27;, \\gamma&#x27;}(S&#x27;)</span> , where  <span class="math">RS&#x27;, WS&#x27;, S&#x27;</span>  are as defined in Claim 4 and  <span class="math">\\mathcal{H}</span>  is defined in Claim 5 to checking if the following hold, where  <span class="math">r_M&#x27; \\in \\mathbb{F}^{\\log M}, r_N&#x27; \\in \\mathbb{F}^{\\log N}</span>  chosen at random by the verifier over the course of the sum-check protocol:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\widetilde{eq}(r_M&#x27;, r_y) \\stackrel{?}{=} v_{eq}&#x27;</span></li>

      <li><span class="math">E_{\\mathrm{ry}}(r_N^{\\prime}) \\stackrel{?}{=} v_{E_{\\mathrm{ry}}}</span></li>

      <li><span class="math">\\operatorname{col}(r_N&#x27;) \\stackrel{?}{=} v_{\\operatorname{col}}</span> ;  <span class="math">\\operatorname{write}_{\\operatorname{col}}(r_N&#x27;) \\stackrel{?}{=} v_{\\operatorname{write}_{\\operatorname{col}}}</span> ;  <span class="math">\\operatorname{read}_{\\operatorname{col}}(r_N&#x27;) \\stackrel{?}{=} v_{\\operatorname{read}_{\\operatorname{col}}}</span> ; and  <span class="math">\\operatorname{final}_{\\operatorname{col}}(r_M&#x27;) \\stackrel{?}{=} v_{\\operatorname{final}_{\\operatorname{col}}}</span></li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}</span> : directly check if the first equality holds, which can be done with  <span class="math">O(\\log M)</span>  field operations; check the remaining equations hold with an oracle query to each of  <span class="math">E_{\\mathrm{ry}}, \\mathrm{col}, \\mathrm{write}_{\\mathrm{col}}, \\mathrm{read}_{\\mathrm{col}}, \\mathrm{final}_{\\mathrm{col}}</span> .</li>

    </ol>

    <p class="text-gray-300">Completeness. Perfect completeness follows from perfect completeness of the sum-check protocol and the fact that the multiset equality checks using their fingerprints hold with probability 1 over the choice of  <span class="math">\\tau, \\gamma</span>  if the prover is honest.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Soundness. Applying a standard union bound to the soundness error introduced by probabilistic multiset equality checks with the soundness error of the sum-check protocol [65], we conclude that the soundness error for the depicted polynomial IOP as at most  $O(N) /</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Round and communication complexity. There are three sum-check reductions. First, it is applied on a polynomial with  <span class="math">\\log N</span>  variables where the degree is at most 3 in each variable, so the round complexity is  <span class="math">O(\\log N)</span>  and the communication cost is  <span class="math">O(\\log N)</span>  field elements.</p>

    <p class="text-gray-300">Second, it is applied to compute four "grand products" in parallel. Two of the grand products are over vectors of size  <span class="math">M</span>  and the remaining two are over vectors of size  <span class="math">N</span> . We use the interactive proof for grand products of [81], for which the round complexity is  <span class="math">O(\\log^2 N)</span>  with a communication cost of  <span class="math">O(\\log^2 N)</span>  field elements.</p>

    <p class="text-gray-300">Third, the depicted IOP runs four additional "grand products", which incurs the same costs as above.</p>

    <p class="text-gray-300">In total, the round complexity of the depicted IOP is <span class="math">O(\\log^2 N)</span> and the communication cost is <span class="math">O(\\log^2 N)</span> field elements.5</p>

    <p class="text-gray-300">Verifier time. The verifier's runtime is dominated by its runtime in the grand product sum-check reductions, which is <span class="math">O(\\log^2 N)</span>.</p>

    <p class="text-gray-300">Prover Time. Using linear-time sum-checks [81, 89] in all three sum-check reductions (and exploiting the linear-time prover in the grand product interactive proof [81]), the prover's time is <span class="math">O(N)</span> finite field operations.</p>

    <p class="text-gray-300">Finally, to prove Theorem 3, applying the compiler of [30] to the depicted polynomial IOP with the given polynomial commitment primitive, followed by the Fiat-Shamir transformation [41], provides the desired non-interactive argument of knowledge for proving evaluations of committed sparse multilinear polynomials, with efficiency claimed in the theorem statement.</p>

    <p class="text-gray-300">The following theorem captures our main result.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Theorem 4. Assuming that $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= 2^{\\Theta(\\lambda)}<span class="math"> there exists a preprocessing SNARK for </span>\\mathcal{R}_{R1CS}<span class="math"> in the random oracle model, with the following efficiency characteristics, where </span>M<span class="math"> denotes the dimensions of the R1CS matrices, </span>N<span class="math"> denotes the number of non-zero entries, and a fixed positive integer </span>t$:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>the preprocessing cost to the verifier is <span class="math">O(N)</span> <span class="math">\\mathbb{F}</span>-ops;</li>

      <li>the running time of the prover is <span class="math">O(N)</span> <span class="math">\\mathbb{F}</span>-ops;</li>

      <li>the running time of the verifier is <span class="math">O_{\\lambda}(N^{1 / t})</span> <span class="math">\\mathbb{F}</span>-ops; and</li>

      <li>the proof size is <span class="math">O_{\\lambda}(N^{1 / t})</span>.</li>

    </ul>

    <p class="text-gray-300">A proof of Theorem 4 is in Appendix D. In a nutshell, we obtain a SNARK with the claimed performance profile as follows. We first make explicit Spartan's polynomial IOP for R1CS. We then combine our polynomial commitment schemes with Spartan's polynomial IOP to obtain a succinct argument per prior compilers [30]. Finally, to achieve linear-time computation commitments (also called holography) we invoke prior techniques [75] to transform our polynomial commitment scheme from Theorem 2 into one that handles so-called sparse multilinear polynomials. This step is necessary because the polynomials used in Spartan's IOP to "capture" the R1CS matrices are sparse.</p>

    <p class="text-gray-300">For an R1CS instance, <span class="math">\\mathbb{X} = (\\mathbb{F}, A, B, C, M, N, \\mathrm{i}\\omega)</span> and a purported witness <span class="math">W</span>, let <span class="math">Z = (W, 1, \\mathrm{i}\\omega)</span>. For ease of notation, we assume that the vector <span class="math">W</span> and the vector <span class="math">(1, \\mathrm{i}\\omega)</span> have the same length. We interpret the matrices <span class="math">A, B, C</span> as functions mapping domain <span class="math">\\{0, 1\\}^{\\log M} \\times \\{0, 1\\}^{\\log M}</span> to <span class="math">\\mathbb{F}</span> in the natural way. That is, an input in <span class="math">\\{0, 1\\}^{\\log M} \\times \\{0, 1\\}^{\\log M}</span> is interpreted as the binary representation of an index <span class="math">(i, j) \\in [M] \\times [M]</span>, where <span class="math">[M] := \\{1, \\dots, M\\}</span> and the function outputs the <span class="math">(i, j)</span>'th entry of the matrix. Similarly we interpret <span class="math">Z</span> and <span class="math">(1, \\mathrm{i}\\omega)</span> as functions with the following respective signatures in the same manner: <span class="math">\\{0, 1\\}^s \\to \\mathbb{F}</span> and <span class="math">\\{0, 1\\}^{s-1} \\to \\mathbb{F}</span>.</p>

    <p class="text-gray-300">5Employing the sum-check reduction for grand products in [78] results in a complexity of <span class="math">O(\\log N)</span> with a communication cost of <span class="math">O(\\log N)</span> field elements and a verifier runtime of <span class="math">O(\\log N)</span>, though it requires the prover to send an additional polynomial of size <span class="math">O(N)</span>.</p>

    <p class="text-gray-300">33</p>

    <p class="text-gray-300">Note that the multilinear extension (MLE) polynomial <span class="math">\\widetilde{Z}</span> of <span class="math">Z</span> satisfies</p>

    <div class="my-4 text-center"><span class="math-block">\\widetilde{Z}(X_1, \\dots, X_{\\log M}) = (1 - X_1) \\cdot \\widetilde{W}(X_2, \\dots, X_{\\log M}) + \\\\ X_1 \\cdot \\widetilde{(1, \\mathrm{io})}(X_2, \\dots, X_{\\log M}). \\tag{12}</span></div>

    <p class="text-gray-300">Here, the MLE refers to the unique multilinear polynomial <span class="math">\\widetilde{Z}</span> satisfying <span class="math">\\widetilde{Z}(x_1, \\ldots, x_{\\log M}) = Z(x_1, \\ldots, x_{\\log M})</span> for all <span class="math">(x_1, \\ldots, x_{\\log M}) \\in \\{0, 1\\}^{\\log M}</span>. Indeed, the RHS of Equation (12) is a multilinear polynomial, and it is easily checked that <span class="math">\\widetilde{Z}(x_1, \\ldots, x_{\\log M}) = Z(x_1, \\ldots, x_{\\log M})</span> for all <span class="math">x_1, \\ldots, x_{\\log M}</span> (since the first half of the evaluations of <span class="math">Z</span> are given by <span class="math">W</span> and the second half are given by the vector <span class="math">(1, \\mathrm{io})</span>).</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">From [75, Theorem 4.1], checking if <span class="math">(\\mathbb{X}, W) \\in \\mathcal{R}_{\\mathrm{R1CS}}</span> is equivalent, except for a soundness error of $\\log M /</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> over the choice of </span>\\tau \\in \\mathbb{F}^s$, to checking if the following identity holds:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} 0 \\stackrel{?}{=} \\sum_{x \\in \\{0, 1\\}^s} \\widetilde{eq}(\\tau, x) \\cdot \\\\ \\left[ \\left(\\sum_{y \\in \\{0, 1\\}^s} \\widetilde{A}(x, y) \\cdot \\widetilde{Z}(y)\\right) \\cdot \\left(\\sum_{y \\in \\{0, 1\\}^s} \\widetilde{B}(x, y) \\cdot \\widetilde{Z}(y)\\right) \\right. \\\\ \\left. - \\sum_{y \\in \\{0, 1\\}^s} \\widetilde{C}(x, y) \\cdot \\widetilde{Z}(y) \\right] \\tag{13} \\end{aligned}</span></div>

    <p class="text-gray-300">where <span class="math">\\widetilde{eq}</span> is the MLE of <span class="math">eq: \\{0,1\\}^s \\times \\{0,1\\}^s \\to \\mathbb{F}</span>:</p>

    <div class="my-4 text-center"><span class="math-block">eq(x, e) = \\begin{cases} 1 &amp;amp; \\text{if } x = e \\\\ 0 &amp;amp; \\text{otherwise.} \\end{cases}</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">That is, if <span class="math">(\\mathbb{X}, W) \\in \\mathcal{R}_{\\mathrm{R1CS}}</span>, then Equation (13) holds with probability 1 over the choice of <span class="math">\\tau</span>, and if <span class="math">(\\mathbb{X}, W) \\notin \\mathcal{R}_{\\mathrm{R1CS}}</span>, then Equation (13) holds with probability at most $O(\\log M /</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> over the random choice of </span>\\tau$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Consider computing the right hand side of Equation (13) by applying the well-known sum-check protocol [65] to the polynomial</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} g(x) := \\widetilde{eq}(\\tau, x) \\cdot \\\\ \\left[ \\left(\\sum_{y \\in \\{0, 1\\}^s} \\widetilde{A}(x, y) \\cdot \\widetilde{Z}(y)\\right) \\cdot \\left(\\sum_{y \\in \\{0, 1\\}^s} \\widetilde{B}(x, y) \\cdot \\widetilde{Z}(y)\\right) \\right. \\\\ \\left. - \\sum_{y \\in \\{0, 1\\}^s} \\widetilde{C}(x, y) \\cdot \\widetilde{Z}(y) \\right] \\end{aligned}</span></div>

    <p class="text-gray-300">From the verifier's perspective, this reduces the task of computing the right hand side of Equation (13) to the task of evaluating <span class="math">g</span> at a random input <span class="math">r_x \\in \\mathbb{F}^s</span>. Note that the verifier can evaluate <span class="math">\\widetilde{eq}(\\tau, r_x)</span> unassisted in <span class="math">O(\\log M)</span> field operations, as it is easily checked that <span class="math">\\widetilde{eq}(\\tau, r_x) = \\prod_{i=1}^{s} (\\tau_i r_{x,i} + (1 - \\tau_i)(1 - r_{x,i}))</span>. With <span class="math">\\widetilde{eq}(\\tau, r_x)</span> in hand, <span class="math">g(r_x)</span> can be computed in <span class="math">O(1)</span> time given the three quantities <span class="math">\\sum_{y \\in \\{0,1\\}^s} \\widetilde{A}(r_x, y) \\cdot \\widetilde{Z}(y)</span>, <span class="math">\\sum_{y \\in \\{0,1\\}^s} \\widetilde{B}(r_x, y) \\cdot \\widetilde{Z}(y)</span>, and <span class="math">\\sum_{y \\in \\{0,1\\}^s} \\widetilde{C}(r_x, y) \\cdot \\widetilde{Z}(y)</span>.</p>

    <p class="text-gray-300">These three quantities can be computed by applying the sum-check protocol three more times in parallel, once to each of the following three polynomials (using the same random vector of field elements, <span class="math">r_y \\in \\mathbb{F}^s</span>, in each of the three invocations): <span class="math">\\widetilde{A}(r_x, y) \\cdot \\widetilde{Z}(y)</span>, <span class="math">\\widetilde{B}(r_x, y) \\cdot \\widetilde{Z}(y)</span>, <span class="math">\\widetilde{C}(r_x, y) \\cdot \\widetilde{Z}(y)</span>.</p>

    <p class="text-gray-300">To perform the verifier's final check in each of these three invocations of the sum-check protocol, it suffices for the verifier to evaluate each of the above 3 polynomials at the random vector <span class="math">r_y</span>, which means it suffices</p>

    <p class="text-gray-300">34</p>

    <p class="text-gray-300">for the verifier to evaluate <span class="math">\\widetilde{A}(r_x, r_y)</span>, <span class="math">\\widetilde{B}(r_x, r_y)</span>, <span class="math">\\widetilde{C}(r_x, r_y)</span>, and <span class="math">\\widetilde{Z}(r_y)</span>. We present the protocol in this section assuming that the verifier can evaluate <span class="math">\\widetilde{A}</span>, <span class="math">\\widetilde{B}</span>, and <span class="math">\\widetilde{C}</span> at the point <span class="math">(r_x, r_y)</span> in time <span class="math">O(\\sqrt{N})</span>—if this is not the case, then as discussed in Section 7.1 and detailed in Section 6, these polynomials can each be committed in pre-processing and the necessary evaluations revealed by the prover, thereby achieving holography. <span class="math">\\widetilde{Z}(r_y)</span> can be obtained from one query to <span class="math">\\widetilde{W}</span> and one query to <span class="math">\\widetilde{(1, \\mathrm{i}o)}</span> via Equation (12).</p>

    <p class="text-gray-300">In summary, we have the following succinct interactive argument. It is public coin, and can be rendered non-interactive via the Fiat-Shamir transformation.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{P} \\to \\mathcal{V}</span>: a commitment to the <span class="math">(\\log M - 1)</span>-variate multilinear polynomial <span class="math">\\widetilde{W}</span> using the polynomial commitment scheme of §4.1.</li>

      <li><span class="math">\\mathcal{V} \\to \\mathcal{P}</span>: <span class="math">\\tau \\in_{R} \\mathbb{F}^s</span></li>

      <li><span class="math">\\mathcal{V} \\leftrightarrow \\mathcal{P}</span>: run the sum-check reduction to reduce the check in Equation (13) to checking if the following hold, where <span class="math">r_x, r_y</span> are vectors in <span class="math">\\mathbb{F}^s</span> chosen at random by the verifier over the course of the sum-check protocol:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\widetilde{A}(r_x, r_y) \\stackrel{?}{=} v_A</span>, <span class="math">\\widetilde{B}(r_x, r_y) \\stackrel{?}{=} v_B</span>, and <span class="math">\\widetilde{C}(r_x, r_y) \\stackrel{?}{=} v_C</span>; and</li>

      <li><span class="math">\\widetilde{Z}(r_y) \\stackrel{?}{=} v_Z</span>.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}</span>:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>check if <span class="math">\\widetilde{A}(r_x, r_y) \\stackrel{?}{=} v_A</span>, <span class="math">\\widetilde{B}(r_x, r_y) \\stackrel{?}{=} v_B</span>, and <span class="math">\\widetilde{C}(r_x, r_y) \\stackrel{?}{=} v_C</span>, (recall that we have assumed that each of <span class="math">\\widetilde{A}, \\widetilde{B}, \\widetilde{C}</span> can be evaluated in <span class="math">O(\\sqrt{N})</span> time).</li>

      <li>check if <span class="math">\\widetilde{Z}(r_y) \\stackrel{?}{=} v_Z</span> by checking if: <span class="math">v_Z = (1 - r_y[1]) \\cdot v_W + r_y[1] \\cdot (\\widetilde{i o, 1})(r_y[2..])</span>, where <span class="math">r_y[2..]</span> refers to a slice of <span class="math">r_y</span> without the first element of <span class="math">r_y</span> (Equation (12)), and <span class="math">v_W \\gets \\widetilde{W}(r_y[2..])</span> is obtained via the evaluation procedure of the polynomial commitment scheme (§4.1).</li>

    </ul>

    <p class="text-gray-300">By composing the SNARK of Theorem 4 with known zkSNARKs [75, 78, 49], we obtain zkSNARKs with shorter proofs (Figure 9 in Appendix E provides detailed cost profiles of the resulting zkSNARKs). Specifically, the prover in the composed SNARKs proves that it knows a proof <span class="math">\\pi</span> that would convince the SNARK verifier in Theorem 4 to accept. Perfect zero-knowledge of the resulting composed SNARK is immediate from the zero-knowledge property of the SNARKs from these prior works [75, 78, 49]. Perfect completeness follows from the perfect completeness properties of these prior works and of Theorem 4. Knowledge soundness follows from a standard argument [83, 19]: one composes the knowledge extractors of the two constituent SNARKs to get a knowledge extractor for the composed SNARK.</p>

    <p class="text-gray-300">We evaluate the performance of two polynomial commitment schemes and two SNARKs based on these schemes. Specifically, we evaluate two instantiations of the polynomial commitment scheme of Section 4.1: Ligero-PC, which uses the Reed-Solomon code (this scheme is implicit in Ligero [4]), and Brakedown-PC, which uses the new linear-time error-correcting code described in Section 5.</p>

    <p class="text-gray-300">Implementation. We implement Ligero-PC and Brakedown-PC in <span class="math">\\approx 3500</span> lines of Rust. This includes an implementation of the polynomial commitment of Section 4.1 that is generic over fields, error-correcting codes, and hash functions; implementations of the Reed-Solomon code and our new linear-time code; and a fast parallelized FFT. We also integrate our implementation with Spartan [3], yielding a SNARK library; this took less than 100 lines of glue Rust code.</p>

    <p class="text-gray-300">All reported measurements of our implementation use the BLAKE3 hash function [68]. Because Ligero-PC needs to perform FFTs, our measurements use fields of characteristic <span class="math">p</span> such that <span class="math">p - 1</span> is divisible by <span class="math">2^{40}</span>, which ensures that reasonably large FFTs are possible in the field; we choose <span class="math">p</span> at random.</p>

    <p class="text-gray-300">35</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Figure 3: Microbenchmark results (§8.1); lower is better. Brakedown-PC uses the parameters in the third line of Figure 2; Ligero-PC <span class="math">^{38/39}</span> , Ligero-PC <span class="math">^{1/2}</span> , Ligero-PC <span class="math">^{1/4}</span> , and FRI-PC are instantiated with Reed-Solomon rates of  <span class="math">^{38/39}</span> ,  <span class="math">^{1/2}</span> ,  <span class="math">^{1/4}</span> , and  <span class="math">^{1/4}</span> , respectively. FRI-PC results are incomplete as the prover ran out of memory for larger instances.</p>

    <p class="text-gray-300">This section evaluates the concrete costs of our polynomial commitment schemes and a prior baseline, for univariate polynomials, over the standard monomial basis, of degree  <span class="math">2^{13}</span>  to  <span class="math">2^{29}</span>  (for our schemes, the costs for such univariate polynomials is identical to the costs for multilinear polynomials having 13 to 29 variables).</p>

    <p class="text-gray-300">Baseline. The FRI protocol [8] underlies all prior IOP-based polynomial commitment schemes and all built post-quantum schemes. (Lattice-based Bulletproofs [25] could also be used to construct post-quantum schemes, but to our knowledge these have not been implemented.) Like Ligero-PC, FRI requires an FFT-friendly field for efficiency. Vlasov and Panarin [84] use FRI to construct a univariate polynomial commitment, which we call FRI-PC; Virgo [91] effectively extends FRI-PC to multilinear polynomials by invoking an interactive proof, increasing costs. We evaluate the  <span class="math">\\mathrm{C + + }</span>  FRI implementation in libiop [63]. Following the best known soundness analysis [10, 84], we set the Reed-Solomon rate to  <span class="math">1 / 4</span>  and number of queries to 189.</p>

    <p class="text-gray-300">Parameters of the error-correcting codes. We instantiate Brakedown-PC with the parameters given on the third line of Figure 2. For Ligero-PC, the rate of the Reed-Solomon code trades between proving and verification costs: roughly, a lower rate gives a slower prover but smaller proofs and faster verification. To explore this tradeoff, we test Ligero-PC with three different code rates:  <span class="math">38/39</span>  gives proof sizes roughly matching Brakedown-PC,  <span class="math">1/2</span>  gives smaller proofs than Brakedown-PC at roughly comparable prover cost, and  <span class="math">1/4</span>  gives even smaller proofs at the cost of greater prover computation. <span class="math">^7</span></p>

    <p class="text-gray-300">Other parameters. We evaluate all schemes over 255-bit prime fields. We set parameters of the commitment schemes to obtain 128 bits of security (the exception is that the randomized code generation procedure in Brakedown-PC is designed to have at most a  <span class="math">2^{-100}</span>  probability of failing to satisfy the requisite distance properties according to the analysis of Section 5; this is acceptable because code generation is done in public). To achieve this, we set the number of columns opened in Brakedown-PC to 6593, in Ligero-PC- <span class="math">^{38/39}</span>  to 7054, in Ligero-PC- <span class="math">^{1/2}</span>  to 309, and in Ligero-PC- <span class="math">^{1/4}</span>  to 189.</p>

    <p class="text-gray-300">Setup and method. Our testbed for this section is an Azure Standard F64s_v2 virtual machine (64 Intel Xeon Platinum 8272CL vCPUs, 128 GiB memory) with Ubuntu 18.04. We measure single-threaded speed for committing, opening, and verifying; and we report communication cost. For each experiment, we run the operation 10 times and report the average; in all cases, variation is negligible.</p>

    <p class="text-gray-300">Results.</p>

    <p class="text-gray-300">Figure 3 reports the results. The FRI-PC prover ran out of memory for polynomials of degree greater than <span class="math">2^{25}</span>.</p>

    <p class="text-gray-300">For Brakedown-PC and Ligero-PC, the dominant cost for the prover is committing to the polynomial. For large enough polynomials, Brakedown-PC’s commitment computation is as fast or faster than Ligero-PC-<span class="math">\\nicefrac{{1}}{{2}}</span>’s, and roughly 2–3<span class="math">\\times</span> faster than Ligero-PC-<span class="math">\\nicefrac{{1}}{{4}}</span>’s. Computing commitments in Ligero-PC-<span class="math">\\nicefrac{{38}}{{39}}</span> is faster than in Brakedown-PC, but Ligero-PC-<span class="math">\\nicefrac{{38}}{{39}}</span> does not support multilinear polynomials (see Footnote 7).</p>

    <p class="text-gray-300">For FRI-PC, committing and opening have similar (high) costs: on the sizes where the FRI prover succeeded (<span class="math">\\leq 2^{25}</span>), committing and opening with FRI-PC is <span class="math">\\approx</span>2–9<span class="math">\\times</span> slower than Brakedown-PC and <span class="math">\\approx</span>3–7<span class="math">\\times</span> slower than the slowest Ligero-PC; for Brakedown-PC, the gap widens with increasing size.</p>

    <p class="text-gray-300">Ligero-PC-<span class="math">\\nicefrac{{1}}{{2}}</span> and Ligero-PC-<span class="math">\\nicefrac{{1}}{{4}}</span> have lower verification cost than Ligero-PC-<span class="math">\\nicefrac{{38}}{{39}}</span> and Brakedown-PC, though this advantage shrinks as instances grow. FRI-PC’s verification cost is up to 17<span class="math">\\times</span> lower than the other schemes.</p>

    <p class="text-gray-300">Brakedown-PC and Ligero-PC-<span class="math">\\nicefrac{{38}}{{39}}</span> have nearly the same communication cost, by design. Ligero-PC-<span class="math">\\nicefrac{{1}}{{2}}</span> has <span class="math">\\approx</span>5–15<span class="math">\\times</span> less communication than Brakedown-PC, and Ligero-PC-<span class="math">\\nicefrac{{1}}{{4}}</span> has <span class="math">\\approx</span>6–21<span class="math">\\times</span> less than Brakedown-PC; like verification time, their proof size advantage shrinks as instance size grows. FRI-PC’s communication is significantly lower: <span class="math">\\approx</span>22–66<span class="math">\\times</span> less than Brakedown-PC or Ligero-PC-<span class="math">\\nicefrac{{38}}{{39}}</span>, <span class="math">\\approx</span>2–13<span class="math">\\times</span> less than Ligero-PC-<span class="math">\\nicefrac{{1}}{{2}}</span>, and <span class="math">\\approx</span>1.3–10<span class="math">\\times</span> less than Ligero-PC-<span class="math">\\nicefrac{{1}}{{4}}</span>.</p>

    <p class="text-gray-300">In sum, Brakedown-PC has a concretely and asymptotically fast prover (especially for multilinear polynomials) but gives large proofs and slower verification than the other schemes. Brakedown-PC’s proofs are larger because higher <span class="math">\\rho</span> implies more column openings; for large polynomials, the overhead is <span class="math">\\approx\\sqrt{\\ell^{\\prime}}</span>, where <span class="math">\\ell^{\\prime}</span> is the ratio of the number of column openings. For these instance sizes, Ligero-PC’s prover is competitive with Brakedown-PC’s and its proof size and verification cost are lower. FRI-PC gives much smaller proofs and lower verification cost but has a much slower prover. Of course, neither Ligero-PC nor FRI-PC is field-agnostic; Brakedown-PC is.</p>

    <p class="text-gray-300">In Section 8.3 we report on Brakedown-PC and Ligero-PC experiments with 64 threads. For large polynomials, proving times improve by <span class="math">\\approx</span>16–34<span class="math">\\times</span>.</p>

    <h3 id="sec-65" class="text-xl font-semibold mt-8">8.2 Evaluation of Brakedown and Shockwave SNARKs</h3>

    <h4 id="sec-66" class="text-lg font-semibold mt-6">Metrics, method, and baselines.</h4>

    <p class="text-gray-300">As is standard in the SNARKs literature, our metrics are: (1) the prover time to produce a proof; (2) the verifier time to verify a proof; (3) proof sizes; and (4) the verifier’s preprocessing costs. As baselines, we consider two types of SNARKs: (1) schemes that achieve verification costs sub-linear in the size of the statement (which implies sub-linear proof sizes); and (2) schemes that only achieve proof sizes that are sub-linear in the size of the statement. We refer to the latter type of schemes as <span class="math">\\frac{1}{2}</span>-SNARKs. Additionally, we focus on schemes that do not require a trusted setup (we refer the reader to Spartan <em>[75]</em> for a comparison between our baselines with state-of-the-art SNARKs with trusted setup).</p>

    <p class="text-gray-300">The reader may wonder why we include results for our <span class="math">\\frac{1}{2}</span>-SNARK given that our implementation is not yet zero-knowledge; after all, the verifier runtime in any non-zero-knowledge <span class="math">\\frac{1}{2}</span>-SNARK is commensurate with that of the trivial proof system in which the prover explicitly sends the NP-witness to the verifier. The answer is three-fold. First, the proof length in our <span class="math">\\frac{1}{2}</span>-SNARK is smaller than the witness size for sufficiently large instances (<span class="math">N\\geq 2^{13}</span> for Shockwave and <span class="math">N\\geq 2^{18}</span> for Brakedown). Second, our <span class="math">\\frac{1}{2}</span>-SNARK actually can save the verifier time relative to the trivial proof system for structured R1CS instances. In particular, if the R1CS is data parallel, then the verifier can run in time proportional to the size of a single sub-computation, independent of the number of times the sub-computation is performed (this is entirely analogous to how prior proof systems save the verifier work for structured computations <em>[81, 9]</em>). Third, we expect that the reported performance results are indicative of the performance of future zero-knowledge implementations.</p>

    <p class="text-gray-300">Unless we specify otherwise, we run our experiments in this section on an Azure Standard F16s_v2 virtual machine (16 vCPUs, 32 GB memory) with Ubuntu 20.10. We report results from a single-threaded configuration since not all our baselines leverage multiple cores. As with prior work <em>[14, 75, 36, 78]</em>, we vary the size of the R1CS instance by varying the number of constraints and variables <span class="math">m</span> and maintain the ratio <span class="math">n/m</span> to approximately 1.</p>

    <p class="text-gray-300">####</p>

    <p class="text-gray-300">(a) Prover time !<a href="img-2.jpeg">img-2.jpeg</a></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Brakedown  <span class="math">\\left(\\frac{1}{2}\\right.</span>  -SNARK)</li>

    </ul>

    <p class="text-gray-300">(b) Verifier time !<a href="img-3.jpeg">img-3.jpeg</a> Ligero Aurora SpartanNIZK</p>

    <p class="text-gray-300">(c) Proof size Figure 4:  <span class="math">\\frac{1}{2}</span> -SNARK results (§8.2); lower is better. Brakedown, Shockwave, Ligero, and Aurora are plausibly post-quantum secure. !<a href="img-4.jpeg">img-4.jpeg</a> Lakonia</p>

    <p class="text-gray-300">(a) Prover time !<a href="img-5.jpeg">img-5.jpeg</a></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Brakedown  <span class="math">\\left(\\frac{1}{2}\\right.</span>  -SNARK), 256-bit field</li>

      <li>Shockwave  <span class="math">\\left(\\frac{1}{2}\\right.</span>  -SNARK), 256-bit field</li>

    </ul>

    <p class="text-gray-300">(b) Verifier time !<a href="img-6.jpeg">img-6.jpeg</a></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Brakedown  <span class="math">\\left(\\frac{1}{2}\\right.</span>  -SNARK), 128-bit field</li>

      <li>Shockwave  <span class="math">\\left(\\frac{1}{2}\\right.</span>  -SNARK), 128-bit field</li>

    </ul>

    <p class="text-gray-300">(c) Proof size !<a href="img-7.jpeg">img-7.jpeg</a></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Brakedown  <span class="math">\\left(\\frac{1}{2}\\right.</span>  -SNARK), 256-bit field</li>

      <li>Shockwave  <span class="math">\\left(\\frac{1}{2}\\right.</span>  -SNARK), 128-bit field</li>

    </ul>

    <p class="text-gray-300">Figure 5:  <span class="math">\\frac{1}{2}</span> -SNARK results for varying field sizes (§8.2); lower is better. Brakedown and Shockwave are plausibly post-quantum secure.</p>

    <p class="text-gray-300">Prior state-of-the-art  <span class="math">\\frac{1}{2}</span> -SNARK schemes include: Ligero [4], Bulletproofs [28], Aurora [14], SpartanNIZK [75], and Lakonia [78]. Note that for uniform computations (e.g., data-parallel circuits), Hyrax [87] and STARK [9] are SNARKs, but for computations without any structure, they are  <span class="math">\\frac{1}{2}</span> -SNARKs. We do not compare with Ligero++ [17] since its source code is not public. Broadly speaking, Ligero++ has shorter proofs than Ligero at the cost of a slower prover, so its prover will be significantly slower than both Brakedown and Shockwave. We do not report results from Bulletproofs or STARK as they feature a more expensive prover than other baselines considered here [28, 14]. Hyrax [87] supports only layered arithmetic circuits, so as used in prior work [75] for comparison purposes, we translate R1CS to depth-1 arithmetic circuits (without any structure). None of the  <span class="math">\\frac{1}{2}</span> -SNARKs we consider require a preprocessing step for the verifier.</p>

    <p class="text-gray-300">In Section 8.3, we provide a rough comparison with Wolverine [88] and Mac'n'Cheese [6], which unlike schemes considered here do not support proof sizes sub-linear in the instance size. Another potential baseline is Virgo [91], which like Hyrax [87] applies only to low-depth circuits as they both share the same information-theoretic component [48, 37, 85, 89].</p>

    <p class="text-gray-300">For Aurora and Ligero, we use their open-source implementations from libiop [63], configured to provide provable security. For Hyrax, we use its reference (i.e., unoptimized) implementation [62]. For SpartanNIZK,</p>

    <p class="text-gray-300">(a) Prover time !<a href="img-8.jpeg">img-8.jpeg</a></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Brakedown</li>

      <li>Shockwave</li>

    </ul>

    <p class="text-gray-300">(b) Verifier time !<a href="img-9.jpeg">img-9.jpeg</a></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Spartan</li>

    </ul>

    <p class="text-gray-300">SuperSonic</p>

    <p class="text-gray-300">(c) Encoder time !<a href="img-10.jpeg">img-10.jpeg</a></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Fractal</li>

      <li>Kopis</li>

    </ul>

    <p class="text-gray-300">Figure 6: SNARK results (§8.2); lower is better. Brakedown, Shockwave, and Fractal are plausibly post-quantum secure. Fractal results are incomplete because the prover and encoder ran out of memory for larger instances.</p>

    <p class="text-gray-300">(d) Proof size !<a href="img-11.jpeg">img-11.jpeg</a> Xiphos Groth16</p>

    <p class="text-gray-300">we use its open-source implementation [3]. Unless we specify otherwise, we use 256-bit prime fields. Hyrax uses curve25519 and SpartanNIZK uses ristretto255 [2, 51] for a group where the discrete-log problem is hard, so R1CS instances are defined over the scalar field of these curves. For Aurora and Ligero, we use the 256-bit prime field option in libiop. Finally, our schemes use the scalar field of BLS12-381, which supports FFTs (Brakedown does not need FFTs but Shockwave does). However, we note that none of these implementations leverages the specifics of the prime field to speed up scalar arithmetic.</p>

    <p class="text-gray-300">We first experiment with Brakedown and Shockwave and their baselines with varying R1CS instance sizes up to  <span class="math">2^{20}</span>  constraints defined over a 256-bit prime field. Figures 4a, 4b, and 4c depict respectively the prover time, the verifier time, and the proof size from these experiments. We find the following.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Brakedown's and Shockwave's provers are faster than prior work at all instance sizes we measure. Compared to baseslines that are plausibly post-quantum secure (Ligero and Aurora), Brakedown's and Shockwave's provers are over an order of magnitude faster.</li>

      <li>Brakedown's proof size is larger than other depicted systems except for Ligero. Still, its proofs are substantially smaller than the size of the NP-witness for instance sizes  <span class="math">N \\geq 2^{18}</span> . Shockwave provides shorter proofs than Brakedown as well as prior post-quantum secure baselines (Ligero and Aurora). Note that Aurora has asymptotically shorter proofs than Shockwave, and hence the proof size comparison would "cross over" at larger instance sizes). Shockwave's proof sizes are smaller than that of the NP-witness for instance sizes  <span class="math">N \\geq 2^{13}</span> .</li>

      <li>Despite their larger proofs, Brakedown's and Shockwave's verifiers are competitive with those of Spartan-NIZK and Lakonia, and is well over an order of magnitude faster than the plausibly post-quantum secure baselines.</li>

    </ul>

    <p class="text-gray-300">Performance for larger instance sizes. To demonstrate Brakedown's and Shockwave's scalability to larger instance sizes, we experiment with them and SpartanNIZK for instance sizes beyond  <span class="math">2^{20}</span>  constraints.</p>

    <p class="text-gray-300">For these larger-scale experiments, we use an Azure Standard F32s_v2 VM which has 32 vCPUs and 64 GB memory. Figures 5a, 5b, and 5c depict results from these larger-scale experiments. Our findings from these experiments are similar to results from the smaller-scale results.</p>

    <p class="text-gray-300">Performance over small fields. To demonstrate flexibility with different field sizes, we also run Brakedown and Shockwave with a prime field where the prime modulus is 128 bits. For the latter case, our choice of parameters achieve at least 100 bits security. We depict these results together with results from our larger-scale experiments (Figures 5a, 5c, and 5b).</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Recall that our asymptotic results require  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">&gt; \\exp(\\Omega(\\lambda))<span class="math">  to achieve a linear-time prover, because if the field is smaller than this, certain parts of the protocol need to be repeated  </span>\\omega(1)<span class="math">  times to drive the soundness error below  </span>\\exp(-\\lambda)$ . However, Brakedown and Shockwave are quite efficient over small fields. The reason is</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">(a) Prover time !<a href="img-12.jpeg">img-12.jpeg</a> <span class="math">\\spadesuit</span>  Brakedown</p>

    <p class="text-gray-300">(b) Verifier time !<a href="img-13.jpeg">img-13.jpeg</a> Shockwave</p>

    <p class="text-gray-300">(c) Proof size Figure 7: SNARK results (§8.2); lower is better. Brakedown and Shockwave are plausibly post-quantum secure. !<a href="img-14.jpeg">img-14.jpeg</a> Spartan</p>

    <p class="text-gray-300">that only some parts of the protocol need to be repeated to drive the soundness error below  <span class="math">\\exp(-\\lambda)</span>  and those repetitions produce only low-order effects on the prover's runtime and the proof length. This means that for a fixed security level, our prover is faster over small fields than large fields, because the effect of faster field arithmetic dominates the overhead due to the need to repeat parts of the protocol to drive down soundness error. Similar observations appear in prior work [9].</p>

    <p class="text-gray-300">Prior state-of-the-art schemes SNARKs include: Spartan [75], SuperSonic [30], Fractal [36], Kopis [78], and Xiphos [78]. We also give results for Groth16 [49], a SNARK whose preprocessing phase involves secret randomness and is therefore not transparent, but which gives very short proofs, fast verification, and fast proving times compared to other systems with similar properties.</p>

    <p class="text-gray-300">For Fractal, we use its open-source implementations from libiop [63], configured to provide provable security. For SuperSonic, there is no prior implementation, so we use prior estimates of their costs based on microbenchmarks (See [78] for a detailed discussion of how they estimate these costs). For Spartan, we use its open-source implementation [3]. For Groth16, we benchmark the libsnark implementation using the BN254 elliptic curve [64]. For preprocessing costs, we ignore the use of "untrusted assistant" technique [78], which applies to all schemes considered here except Groth16.</p>

    <p class="text-gray-300">Figures 6a, 6b, 6c, 6d depict respectively the prover time, the verifier time, the verifier's preprocessing time, and the proof size for varying R1CS instance sizes for our schemes and their baselines. We find the following from these results.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Brakedown achieves the fastest prover at instance sizes we measure. Shockwave's prover is slower than Brakedown's, both asymptotically and concretely, but Shockwave's prover is still over an order of magnitude faster than prior plausibly post-quantum secure SNARKs (namely Fractal [36]).</li>

      <li>Brakedown and Shockwave have the largest proof sizes amongst the displayed proof systems, but for large enough R1CS instances their proof sizes are sublinear in the size of the NP-witness ( <span class="math">N &amp;gt; 2^{16}</span>  for Shockwave and  <span class="math">N \\geq 2^{22}</span>  for Brakedown).</li>

      <li>Brakedown's verifier is slower than Shockwave and most other schemes, particularly Xiphos [78] which is specifically designed for achieving a fast verifier. However, Shockwave's verifier is competitive with prior plausibly post-quantum secure SNARKs.</li>

      <li>Brakedown's and Shockwave's preprocessing costs for the verifier are competitive with those of prior high-speed SNARKs such as Spartan [75] and Xiphos [78], and an order of magnitude faster than the prior post-quantum secure SNARK (Fractal).</li>

    </ul>

    <p class="text-gray-300">Performance for larger instance sizes.</p>

    <p class="text-gray-300">To demonstrate Brakedown’s and Shockwave’s scalability to larger instance sizes, we experiment with them and Spartan for instance sizes beyond <span class="math">2^{20}</span> constraints.</p>

    <p class="text-gray-300">For these larger-scale experiments, we use an Azure Standard F64s_v2 VM which has 64 vCPUs and 128 GB memory. Figures 7(a), 7(c), and 7(b) depict results from these larger-scale experiments. Our findings from these experiments are similar to results from the smaller-scale results.</p>

    <h3 id="sec-69" class="text-xl font-semibold mt-8">8.3 Additional experimental results</h3>

    <h4 id="sec-70" class="text-lg font-semibold mt-6">8.3.1 Multi-threaded benchmarks.</h4>

    <p class="text-gray-300">Figure 8 lists results for Brakedown-PC and Ligero-PC experiments with 64 threads. The most significant result is that, for large polynomials, proving times improve by <span class="math">\\approx</span>16–34<span class="math">\\times</span>. Our sparse matrix library does not parallelize as well as our FFT library; optimizing this should improve multi-threaded Brakedown-PC performance relative to Ligero-PC.</p>

    <h4 id="sec-71" class="text-lg font-semibold mt-6">8.3.2 Comparison with Wolverine and Mac’n’Cheese.</h4>

    <p class="text-gray-300">There does not appear to be open-source implementations of these baselines, so we rely on prior performance reports. Since we do not measure the performance of all schemes on the same hardware platform, one must treat this as a rough comparison, distinct from the more rigorous comparison to other systems earlier in this section. Note, moreover, that Wolverine and Mac’n’Cheese are targeted at circuits rather than R1CS (R1CS can simulate circuits with addition and multiplication gates of fan-in two, with one R1CS constraint per multiplication gate).</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Both baselines require interaction between the verifier and the prover, so unlike Brakedown and Shockwave, they do not produce proofs that any verifier can verify. In other words, both baselines do not produce publicly-verifiable proofs. The verifier’s runtime is asymptotically the same as Brakedown’s and Shockwave’s verifiers (<span class="math">\\frac{1}{2}</span>-SNARK variants), but Brakedown’s and Shockwave’s verifier appear to be concretely far cheaper.</li>

      <li>Proof sizes are <span class="math">O_{\\lambda}(N)</span> for an <span class="math">N</span>-sized instance for both baselines, whereas Brakedown’s and Shockwave’s proofs are <span class="math">O_{\\lambda}(\\sqrt{N})</span>. Concretely, Brakedown’s and Shockwave’s proofs are orders of magnitude shorter than both baselines.</li>

      <li>Asymptotically, the prover in both baselines uses memory proportional to that needed to produce the witness and evaluate the circuit non-cryptographically. Brakedown and Shockwave do not have this property, though for worst-case circuits, Brakedown, Shockwave, and the baselines have the same asymptotic memory consumption (this includes, for example, circuit-satisfiability instances whose witness size is linear in the circuit size). Concretely, both baselines report better memory usage than Brakedown and Shockwave.</li>

    </ul>

    <h2 id="sec-72" class="text-2xl font-bold">Acknowledgments</h2>

    <p class="text-gray-300">We are grateful to Benjamin E. Diamond and Jim Posen for identifying issues with our original extractability analysis for the Brakedown polynomial commitment scheme when using codes without efficient decoding procedures, and suggesting corrections, which we have implemented here. These issues and suggested corrections are described in <em>[38]</em>. We thank Jonathan Bootle, Alessandro Chiesa, and Jens Groth for answering our questions on <em>[22]</em>, and Eran Tromer for helpful discussions on recursive composition. Justin Thaler was supported in part by NSF CAREER award CCF-1845125. Both Justin Thaler and Riad Wahby were supported in part by DARPA under Agreement No. HR00112020022. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author and do not necessarily reflect the views of the United States Government or DARPA.</p>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">References</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[1] ethSTARK. https://github.com/starkware-libs/ethSTARK.</li>

      <li>[2] The Ristretto group. https://ristretto.group/.</li>

      <li>[3] Spartan: High-speed zkSNARKs without trusted setup. https://github.com/Microsoft/Spartan.</li>

      <li>[4] S. Ames, C. Hazay, Y. Ishai, and M. Venkitasubramaniam. Ligero: Lightweight sublinear arguments without a trusted setup. In CCS, 2017.</li>

      <li>[5] B. Applebaum, N. Haramaty, Y. Ishai, E. Kushilevitz, and V. Vaikuntanathan. Low-complexity cryptographic hash functions. In ITCS, 2017.</li>

      <li>[6] C. Baum, A. J. Malozemoff, M. Rosen, and P. Scholl. Mac’n’cheese: Zero-knowledge proofs for arithmetic circuits with nested disjunctions. Cryptology ePrint Archive, Report 2020/1410, 2020.</li>

      <li>[7] A. Belling and A. Soleimanian. Vortex : Building a lattice-based snark scheme with transparent setup. Cryptology ePrint Archive, Paper 2022/1633, 2022.</li>

      <li>[8] E. Ben-Sasson, I. Bentov, Y. Horesh, and M. Riabzev. Fast Reed-Solomon interactive oracle proofs of proximity. In ICALP, 2018.</li>

      <li>[9] E. Ben-Sasson, I. Bentov, Y. Horesh, and M. Riabzev. Scalable zero knowledge with no trusted setup. In CRYPTO, 2019.</li>

      <li>[10] E. Ben-Sasson, D. Carmon, Y. Ishai, S. Kopparty, and S. Saraf. Proximity gaps for Reed-Solomon codes. In FOCS, 2020.</li>

      <li>[11] E. Ben-Sasson, D. Carmon, S. Kopparty, and D. Levit. Elliptic Curve Fast Fourier Transform (ECFFT) part I: Fast polynomial algorithms over all finite fields. Electronic Colloquium on Computational Complexity, Report 2021/103, 2021.</li>

      <li>[12] E. Ben-Sasson, D. Carmon, S. Kopparty, and D. Levit. Scalable and transparent proofs over all large fields, via elliptic curves. Electronic Colloquium on Computational Complexity, Report 2022/110, 2022.</li>

      <li>[13] E. Ben-Sasson, A. Chiesa, D. Genkin, and E. Tromer. Fast reductions from RAMs to delegatable succinct constraint satisfaction problems: Extended abstract. In ITCS, 2013.</li>

      <li>[14] E. Ben-Sasson, A. Chiesa, M. Riabzev, N. Spooner, M. Virza, and N. P. Ward. Aurora: Transparent succinct arguments for R1CS. In EUROCRYPT, 2019.</li>

      <li>[15] E. Ben-Sasson, A. Chiesa, and N. Spooner. Interactive Oracle Proofs. In TCC, 2016.</li>

      <li>[16] D. J. Bernstein, J. Doumen, T. Lange, and J.-J. Oosterwijk. Faster batch forgery identification. Cryptology ePrint Archive, Paper 2012/549, 2012.</li>

      <li>[17] R. Bhadauria, Z. Fang, C. Hazay, M. Venkitasubramaniam, T. Xie, and Y. Zhang. Ligero++: a new optimized sublinear iop. In CCS, pages 2025–2038, 2020.</li>

      <li>[18] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer. From extractable collision resistance to succinct non-interactive arguments of knowledge, and back again. In ITCS, 2012.</li>

      <li>[19] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer. Recursive composition and bootstrapping for SNARKs and proof-carrying data. In STOC, 2013.</li>

      <li>[20] M. Blum, W. Evans, P. Gemmell, S. Kannan, and M. Naor. Checking the correctness of memories. In FOCS, 1991.</li>

      <li>[21] J. Bootle, A. Cerulli, E. Ghadafi, J. Groth, M. Hajiabadi, and S. K. Jakobsen. Linear-time zero-knowledge proofs for arithmetic circuit satisfiability. In ASIACRYPT, 2017.</li>

      <li>[22] J. Bootle, A. Chiesa, and J. Groth. Linear-time arguments with sub-linear verification from tensor codes. In TCC, 2020.</li>

      <li>[23] J. Bootle, A. Chiesa, Z. Guan, and S. Liu. Linear-time probabilistic proofs with sublinear verification for algebraic automata over every field. Cryptology ePrint Archive, 2022.</li>

      <li>[24] J. Bootle, A. Chiesa, and S. Liu. Zero-knowledge succinct arguments with a linear-time prover. ePrint Report 2020/1527, 2020.</li>

      <li>[25] J. Bootle, V. Lyubashevsky, N. K. Nguyen, and G. Seiler. A non-PCP approach to succinct quantum-safe zero knowledge. In CRYPTO, 2020.</li>

    </ul>

    <p class="text-gray-300">-</p>

    <p class="text-gray-300">[26] B. Braun, A. J. Feldman, Z. Ren, S. Setty, A. J. Blumberg, and M. Walfish. Verifying computations with state. In SOSP, 2013.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[27] R. Bröker and P. Stevenhagen. Efficient CM-constructions of elliptic curves over finite fields. Math. Comp., 76(260):2161–2179, Oct. 2007.</li>

      <li>[28] B. Bünz, J. Bootle, D. Boneh, A. Poelstra, P. Wuille, and G. Maxwell. Bulletproofs: Short proofs for confidential transactions and more. In S&P, 2018.</li>

      <li>[29] B. Bünz, A. Chiesa, P. Mishra, and N. Spooner. Proof-carrying data from accumulation schemes. In TCC, 2020.</li>

      <li>[30] B. Bünz, B. Fisch, and A. Szepieniec. Transparent SNARKs from DARK compilers. In EUROCRYPT, 2020.</li>

      <li>[31] R. Canetti, Y. Chen, J. Holmgren, A. Lombardi, G. N. Rothblum, R. D. Rothblum, and D. Wichs. Fiat-Shamir: from practice to theory. In STOC, 2019.</li>

      <li>[32] M. Chase, D. Derler, S. Goldfeder, C. Orlandi, S. Ramacher, C. Rechberger, D. Slamanig, and G. Zaverucha. Post-quantum zero-knowledge and signatures from symmetric-key primitives. In CCS, 2017.</li>

      <li>[33] B. Chen, B. Bünz, D. Boneh, and Z. Zhang. Hyperplonk: Plonk with linear-time prover and high-degree custom gates. In EUROCRYPT, 2023.</li>

      <li>[34] A. Chiesa, M. A. Forbes, and N. Spooner. A zero knowledge sumcheck and its applications. CoRR, abs/1704.02086, 2017.</li>

      <li>[35] A. Chiesa, Y. Hu, M. Maller, P. Mishra, N. Vesely, and N. Ward. Marlin: Preprocessing zkSNARKs with universal and updatable SRS. In EUROCRYPT, 2020.</li>

      <li>[36] A. Chiesa, D. Ojha, and N. Spooner. Fractal: Post-quantum and transparent recursive proofs from holography. In EUROCRYPT, 2020.</li>

      <li>[37] G. Cormode, M. Mitzenmacher, and J. Thaler. Practical verified computation with streaming interactive proofs. In ITCS, 2012.</li>

      <li>[38] B. E. Diamond and J. Posen. Proximity testing with logarithmic randomness. Cryptology ePrint Archive, 2023.</li>

      <li>[39] S. Dittmer, Y. Ishai, and R. Ostrovsky. Line-point zero knowledge and its applications. Cryptology ePrint Archive, Report 2020/1446, 2020.</li>

      <li>[40] E. Druk and Y. Ishai. Linear-time encodable codes meeting the Gilbert-Varshamov bound and their cryptographic applications. In ITCS, pages 169–182, 2014.</li>

      <li>[41] A. Fiat and A. Shamir. How to prove yourself: Practical solutions to identification and signature problems. In CRYPTO, pages 186–194, 1986.</li>

      <li>[42] A. Gabizon, Z. J. Williamson, and O. Ciobotaru. PLONK: Permutations over Lagrange-bases for oecumenical noninteractive arguments of knowledge. ePrint Report 2019/953, 2019.</li>

      <li>[43] S. I. Gelfand, R. L. Dobrushin, and M. S. Pinsker. On the complexity of coding. pages 177–184, 1973.</li>

      <li>[44] R. Gennaro, C. Gentry, B. Parno, and M. Raykova. Quadratic span programs and succinct NIZKs without PCPs. In EUROCRYPT, 2013.</li>

      <li>[45] C. Gentry and D. Wichs. Separating succinct non-interactive arguments from all falsifiable assumptions. In STOC, pages 99–108, 2011.</li>

      <li>[46] I. Giacomelli, J. Madsen, and C. Orlandi. ZKBoo: Faster zero-knowledge for Boolean circuits. In USENIX Security, 2016.</li>

      <li>[47] O. Goldreich and A. Kahan. How to construct constant-round zero-knowledge proof systems for np. Journal of Cryptology, 9(3):167–189, 1996.</li>

      <li>[48] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum. Delegating computation: Interactive proofs for muggles. In STOC, 2008.</li>

      <li>[49] J. Groth. On the size of pairing-based non-interactive arguments. In EUROCRYPT, 2016.</li>

      <li>[50] U. Haböck. Brakedown’s expander code. Cryptology ePrint Archive, Paper 2023/769, 2023.</li>

      <li>[51] M. Hamburg. Decaf: Eliminating cofactors through point compression. In CRYPTO, 2015.</li>

      <li>[52] C. Hazay and Y. Lindell. Efficient secure two-party protocols: Techniques and constructions. Springer Science & Business Media, 2010.</li>

    </ul>

    <p class="text-gray-300">[53] J. Holmgren and R. D. Rothblum. Faster sounder succinct arguments and iop s. In CRYPTO, pages 474–503, 2022.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[54] Y. E. Housni and G. Botrel. EdMSM: Multi-Scalar-Multiplication for SNARKs and faster Montgomery multiplication. Cryptology ePrint Archive, Paper 2022/1400, 2022.</li>

      <li>[55] A. Kate, G. M. Zaverucha, and I. Goldberg. Constant-size commitments to polynomials and their applications. In ASIACRYPT, pages 177–194, 2010.</li>

      <li>[56] A. Kattis, K. Panarin, and A. Vlasov. RedShift: Transparent SNARKs from list polynomial commitment IOPs. Cryptology ePrint Archive, Report 2019/1400, 2019.</li>

      <li>[57] J. Kilian. A note on efficient zero-knowledge proofs and arguments (extended abstract). In STOC, 1992.</li>

      <li>[58] A. Kothapalli, E. Masserova, and B. Parno. A direct construction for asymptotically optimal zkSNARKs. Cryptology ePrint Archive, Report 2020/1318, 2020.</li>

      <li>[59] A. Kothapalli, S. Setty, and I. Tzialla. Nova: Recursive Zero-Knowledge Arguments from Folding Schemes. In CRYPTO, 2022.</li>

      <li>[60] J. Lee. Dory: Efficient, transparent arguments for generalised inner products and polynomial commitments. Cryptology ePrint Archive, Report 2020/1274, 2020.</li>

      <li>[61] J. Lee, K. Nikitin, and S. Setty. Replicated state machines without replicated execution. In S&P, 2020.</li>

      <li>[62] libfennel. Hyrax reference implementation. https://github.com/hyraxZK/fennel.</li>

      <li>[63] libiop. A C++ library for IOP-based zkSNARK. https://github.com/scipr-lab/libiop.</li>

      <li>[64] libsnark. A C++ library for zkSNARK proofs. https://github.com/scipr-lab/libsnark.</li>

      <li>[65] C. Lund, L. Fortnow, H. Karloff, and N. Nisan. Algebraic methods for interactive proof systems. In FOCS, Oct. 1990.</li>

      <li>[66] S. Micali. CS proofs. In FOCS, 1994.</li>

      <li>[67] M. Mitzenmacher and E. Upfal. Probability and computing: Randomization and probabilistic techniques in algorithms and data analysis. Cambridge university press, 2017.</li>

      <li>[68] J. O’Connor, J.-P. Aumasson, S. Neves, and Z. Wilcox-O’Hearn. BLAKE3: One function, fast everywhere. https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf, Feb. 2020.</li>

      <li>[69] A. Ozdemir, F. Brown, and R. S. Wahby. Unifying compilers for SNARKs, SMT, and more. Cryptology ePrint Archive, Report 2020/1586, 2020.</li>

      <li>[70] B. Parno, C. Gentry, J. Howell, and M. Raykova. Pinocchio: Nearly practical verifiable computation. In S&P, May 2013.</li>

      <li>[71] N. Pippenger. On the evaluation of powers and related problems. In SFCS, 1976.</li>

      <li>[72] O. Reingold, G. N. Rothblum, and R. D. Rothblum. Constant-round interactive proofs for delegating computation. In STOC, pages 49–62, 2016.</li>

      <li>[73] N. Ron-Zewi and R. Rothblum. Local proofs approaching the witness length. In Foundations of Computer Science (FOCS), 2020.</li>

      <li>[74] N. Ron-Zewi and R. D. Rothblum. Proving as fast as computing: succinct arguments with constant prover overhead. In STOC, 2022.</li>

      <li>[75] S. Setty. Spartan: Efficient and general-purpose zkSNARKs without trusted setup. In CRYPTO, 2020.</li>

      <li>[76] S. Setty, S. Angel, T. Gupta, and J. Lee. Proving the correct execution of concurrent services in zero-knowledge. In OSDI, Oct. 2018.</li>

      <li>[77] S. Setty, S. Angel, T. Gupta, and J. Lee. Proving the correct execution of concurrent services in zero-knowledge (extended version). ePrint Report 2018/907, Sept. 2018.</li>

      <li>[78] S. Setty and J. Lee. Quarks: Quadruple-efficient transparent zkSNARKs. Cryptology ePrint Archive, Report 2020/1275, 2020.</li>

      <li>[79] S. Setty, V. Vu, N. Panpalia, B. Braun, A. J. Blumberg, and M. Walfish. Taking proof-based verified computation a few steps closer to practicality. In USENIX Security, Aug. 2012.</li>

    </ul>

    <p class="text-gray-300">[80] D. A. Spielman. Linear-time encodable and decodable error-correcting codes. IEEE Transactions on Information Theory, 42(6):1723–1731, 1996.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[81] J. Thaler. Time-optimal interactive proofs for circuit evaluation. In CRYPTO, 2013.</li>

      <li>[82] J. Thaler. Proofs, arguments, and zero-knowledge.</li>

    </ul>

    <p class="text-gray-300">http://people.cs.georgetown.edu/jthaler/ProofsArgsAndZK.html, 2020.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[83] P. Valiant. Incrementally verifiable computation or proofs of knowledge imply time/space efficiency. In TCC, pages 1–18, 2008.</li>

      <li>[84] A. Vlasov and K. Panarin. Transparent polynomial commitment scheme with polylogarithmic communication complexity. Cryptology ePrint Archive, Report 2019/1020, 2019.</li>

      <li>[85] R. S. Wahby, Y. Ji, A. J. Blumberg, A. Shelat, J. Thaler, M. Walfish, and T. Wies. Full accounting for verifiable outsourcing. In CCS, 2017.</li>

      <li>[86] R. S. Wahby, S. Setty, Z. Ren, A. J. Blumberg, and M. Walfish. Efficient RAM and control flow in verifiable outsourced computation. In NDSS, 2015.</li>

      <li>[87] R. S. Wahby, I. Tzialla, A. Shelat, J. Thaler, and M. Walfish. Doubly-efficient zkSNARKs without trusted setup. In S&P, 2018.</li>

      <li>[88] C. Weng, K. Yang, J. Katz, and X. Wang. Wolverine: Fast, scalable, and communication-efficient zero-knowledge proofs for Boolean and arithmetic circuits. Cryptology ePrint Archive, Report 2020/925, 2020.</li>

      <li>[89] T. Xie, J. Zhang, Y. Zhang, C. Papamanthou, and D. Song. Libra: Succinct zero-knowledge proofs with optimal prover computation. In CRYPTO, 2019.</li>

      <li>[90] T. Xie, Y. Zhang, and D. Song. Orion: Zero knowledge proof with linear prover time. In CRYPTO, 2022.</li>

      <li>[91] J. Zhang, T. Xie, Y. Zhang, and D. Song. Transparent polynomial delegation and its applications to zero knowledge proof. In S&P, 2020.</li>

      <li>[92] Y. Zhang, D. Genkin, J. Katz, D. Papadopoulos, and C. Papamanthou. vSQL: Verifying arbitrary SQL queries over dynamic outsourced databases. In S&P, 2017.</li>

    </ul>

    <p class="text-gray-300">A Linear-time commitments for multilinear polynomials</p>

    <h4 id="sec-73" class="text-lg font-semibold mt-6">Overview.</h4>

    <p class="text-gray-300">In this appendix, we prove Theorem 2 by observing that a core technique in the work of Bootle, Chiesa, and Groth <em>[22]</em> can be used, in a straightforward manner, to build a non-interactive argument of knowledge for a specific type of inner product relations between two vectors over <span class="math">\\mathbb{F}</span>, where one of the vectors is committed with a binding commitment and the other is the tensor product of a constant number of smaller vectors. Specifically, an untrusted prover commits to a vector <span class="math">z\\in\\mathbb{F}^{N}</span> by producing an <span class="math">O_{\\lambda}(1)</span>-sized commitment, and then later proves that <span class="math">v=\\langle q,z\\rangle</span>, where <span class="math">q\\in\\mathbb{F}^{N}</span> is any vector that is a tensor product of <span class="math">t</span> vectors of length <span class="math">N^{1/t}</span> (for a constant <span class="math">t</span>) and <span class="math">v\\in\\mathbb{F}</span>. For <span class="math">N</span>-sized vectors, the cost to commit and to later prove an inner product relation are both <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span>; the size of an evaluation proof and the time to verify are both <span class="math">O_{\\lambda}(N^{1/t})</span> where <span class="math">\\lambda</span> is the security parameter (the verification time is sub-linear because it exploits the tensor structure in <span class="math">q</span>).</p>

    <p class="text-gray-300">We further observe that the above non-interactive proof system implies a polynomial commitment scheme for multilinear polynomials with efficiency characteristics stated earlier. In a nutshell, one can express the evaluations of a multilinear polynomial using the special inner product operation (§4).</p>

    <p class="text-gray-300">Our focus here is on multilinear polynomials over the Lagrange basis, but the scheme described here generalizes to other polynomials such as univariate polynomials over the standard monomial basis (see e.g., <em>[60]</em>).</p>

    <h4 id="sec-74" class="text-lg font-semibold mt-6">Background on tensor IOPs.</h4>

    <p class="text-gray-300">Recall that an interactive oracle proof (IOP) <em>[15, 72]</em> is a generalization of an interactive proof (IP), in which in each round the <span class="math">i</span> prover sends a (possibly long) message string <span class="math">\\Pi_{i}</span>, and the verifier is given query access to <span class="math">\\Pi_{i}</span>. <em>[22]</em> define a generalization of IOPs called <em>tensor</em> IOPs. To distinguish tensor IOPs from the standard notion of IOPs that they generalize, <em>[22]</em> refers to standard IOPs as <em>point-query</em> IOPs.</p>

    <h6 id="sec-75" class="text-base font-medium mt-4">Definition A.1 (<em>[22]</em>).</h6>

    <p class="text-gray-300">A <span class="math">(\\mathbb{F},k,t)</span>-tensor IOP is an IOP except for the following modifications: (1) the prover’s message in each round <span class="math">i</span> consists of a message <span class="math">m_{i}</span> that the verifier reads in full, followed optionally by a vector <span class="math">\\Pi_{i}\\in\\mathbb{F}^{k^{i}}</span>; and (2) a verifier query to <span class="math">\\Pi_{i}</span> may request the value <span class="math">\\langle q_{1}\\otimes q_{2}\\otimes\\ldots\\otimes q_{t},\\Pi_{i}\\rangle</span> for a chosen round <span class="math">i</span> and chosen vectors <span class="math">q_{1},\\ldots,q_{t}\\in\\mathbb{F}^{k}</span>.</p>

    <h4 id="sec-76" class="text-lg font-semibold mt-6">Polynomial evaluation as a tensor query to the coefficient vector.</h4>

    <p class="text-gray-300">For an <span class="math">\\ell</span>-variate multilinear polynomial <span class="math">g</span> represented in the Lagrange basis via a vector <span class="math">z\\in\\mathbb{F}^{n}</span> (where <span class="math">n=2^{\\ell}</span>), given an evaluation point <span class="math">r\\in\\mathbb{F}^{\\ell}</span>, <span class="math">g(r)</span> can be evaluated using the following tensor product identity:</p>

    <p class="text-gray-300"><span class="math">g(r)=\\langle((r_{1},1-r_{1})\\otimes(r_{2},1-r_{2})\\otimes\\ldots\\otimes(r_{\\ell},1-r_{\\ell})),z\\rangle.</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The above equality expresses <span class="math">g(r)</span> as the inner product of the coefficient vector <span class="math">z</span> of the polynomial with another vector described as a tensor product of dimensionality <span class="math">\\ell</span>. However, the identity generalizes to any dimensionality <span class="math">t\\leq\\ell</span> (for simplicity of presentation, we assume henceforth that $t</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\ell<span class="math">). Specifically, given </span>r\\in\\mathbb{F}^{\\ell}<span class="math"> and </span>t\\in(1,\\ell)<span class="math">, there always exist vectors </span>q_{1},\\ldots,q_{t}\\in\\mathbb{F}^{n^{1/t}}<span class="math"> (which can be computed from </span>r<span class="math"> using </span>O(n^{1/t})<span class="math"> operations over </span>\\mathbb{F}$) such that the following holds:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">(r_{1},1-r_{1})\\otimes(r_{2},1-r_{2})\\otimes\\ldots\\otimes(r_{\\ell},1-r_{\\ell})=(q_{1}\\otimes q_{2}\\otimes\\ldots\\otimes q_{t}).</span> (14)</p>

    <p class="text-gray-300">Equation (14) implies:</p>

    <p class="text-gray-300"><span class="math">g(r)=\\langle(q_{1}\\otimes q_{2}\\otimes\\ldots\\otimes q_{t}),z\\rangle.</span></p>

    <h4 id="sec-77" class="text-lg font-semibold mt-6">Indexed relations.</h4>

    <p class="text-gray-300">The completeness and soundness requirements of IPs and IOPs are typically defined with respect to a language <span class="math">\\mathcal{L}</span>. For languages, completeness requires that for every input <span class="math">x\\in\\mathcal{L}</span>, there exists a</p>

    <p class="text-gray-300">prover strategy that causes the verifier to output <span class="math">1</span> with high probability. Soundness requires that for every input <span class="math">x\\not\\in\\mathcal{L}</span> and for every prover strategy, the verifier outputs <span class="math">0</span> with high probability.</p>

    <p class="text-gray-300">Recall that a relation <span class="math">\\mathcal{R}</span> is a set of tuples <span class="math">(\\mathbb{X},W)</span>, where <span class="math">\\mathbb{X}</span> is the instance and <span class="math">W</span> is the witness. Moreover, for any relation <span class="math">\\mathcal{R}</span>, there is a corresponding language <span class="math">\\mathcal{L}_{\\mathcal{R}}</span>, which is the set of <span class="math">\\mathbb{X}</span> for which there exists a witness <span class="math">W</span> such that <span class="math">(\\mathbb{X},W)\\in\\mathcal{R}</span>. In this section, we consider a generalized notion of relations called <em>indexed relations</em>, which are implicit in <em>[75]</em> but formalized in <em>[36]</em>. An indexed relation <span class="math">\\mathcal{R}</span> is a set of triples <span class="math">(\\mathbb{I},\\mathbb{X},W)</span>, where <span class="math">\\mathbb{I}</span> is the index, <span class="math">\\mathbb{X}</span> is the instance, and <span class="math">W</span> is the witness. Naturally, there is an <em>indexed language</em> <span class="math">\\mathcal{L}_{\\mathcal{R}}</span> associated with an indexed relation, namely the set of tuples <span class="math">(\\mathbb{I},\\mathbb{X})</span> for which there exists a witness <span class="math">W</span> such that <span class="math">(\\mathbb{I},\\mathbb{X},W)\\in\\mathcal{R}</span>.</p>

    <h5 id="sec-78" class="text-base font-semibold mt-4">Tensor IOPs for multilinear polynomial evaluation.</h5>

    <p class="text-gray-300">Consider the following indexed relation.</p>

    <h6 id="sec-79" class="text-base font-medium mt-4">Definition A.2 (Multilinear evaluation indexed relation).</h6>

    <p class="text-gray-300">The indexed relation <span class="math">\\mathcal{R}_{MLE}</span> is the set of all triples</p>

    <p class="text-gray-300"><span class="math">(\\mathbb{I},\\mathbb{X},W)=((\\mathbb{F},Z),(\\ell,r,e),\\bot),</span></p>

    <p class="text-gray-300">where <span class="math">\\mathbb{F}</span> is a finite field, <span class="math">Z\\in\\mathbb{F}^{N}</span> for <span class="math">n=2^{\\ell}</span>, <span class="math">r\\in\\mathbb{F}^{\\ell}</span>, <span class="math">v\\in\\mathbb{F}</span>, such that</p>

    <p class="text-gray-300"><span class="math">e=\\langle Z,(r_{1},1-r_{1})\\otimes(r_{2},1-r_{2})\\otimes\\ldots\\otimes(r_{\\ell},1-r_{\\ell})\\rangle.</span></p>

    <h6 id="sec-80" class="text-base font-medium mt-4">Theorem 5.</h6>

    <p class="text-gray-300">For a finite field <span class="math">\\mathbb{F}</span> and positive integers <span class="math">k,t</span>, there exists a <span class="math">(\\mathbb{F},k,t)</span>-tensor IOP for <span class="math">\\mathcal{R}_{MLE}</span> with the following parameters, where <span class="math">N=2^{\\ell}=k^{t}</span> and <span class="math">\\ell</span> is a parameter in an instance:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>soundness error is 0;</li>

      <li>round complexity is <span class="math">O(1)</span>;</li>

      <li>index length is <span class="math">O(N)</span> elements in <span class="math">\\mathbb{F}</span>;</li>

      <li>query complexity is <span class="math">O(1)</span>;</li>

      <li>the prover performs <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span>; and</li>

      <li>the verifier performs <span class="math">O(N^{1/t})</span> operations over <span class="math">\\mathbb{F}</span>, given a tensor-query access to the index.</li>

    </ul>

    <h6 id="sec-81" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Suppose that the evaluation point is <span class="math">r\\in\\mathbb{F}^{\\ell}</span>. Consider the following tensor IOP.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathbb{I}</span>: a vector <span class="math">\\Pi</span> specifying the coefficients of the <span class="math">\\ell</span>-variate multilinear polynomial in the Lagrange basis.</li>

      <li><span class="math">\\mathcal{V}\\to\\mathcal{P}</span>: a tensor query <span class="math">(q_{1},\\ldots,q_{t})</span> to <span class="math">\\mathcal{P}</span>, where <span class="math">(r_{1},1-r_{1})\\otimes(r_{2},1-r_{2})\\otimes\\ldots\\otimes(r_{\\ell},1-r_{\\ell})=(q_{1}\\otimes q_{2}\\otimes\\ldots\\otimes q_{t})</span>. This query is answered with an evaluation <span class="math">e\\in\\mathbb{F}</span> equal to <span class="math">\\langle(q_{1},\\ldots,q_{t}),\\Pi\\rangle</span>.</li>

    </ol>

    <p class="text-gray-300">The index consists of <span class="math">O(N)</span> elements in <span class="math">\\mathbb{F}</span>. The round complexity and the query complexity of the depicted tensor IOP is <span class="math">O(1)</span>; soundness error is <span class="math">0</span>. In terms of time complexity, the verifier starts with an evaluation point <span class="math">r\\in\\mathbb{F}^{\\ell}</span>, which it transforms to a set of vectors <span class="math">(q_{1},\\ldots q_{t})</span>, where each <span class="math">q_{i}\\in\\mathbb{F}^{N^{1/t}}</span>; this costs <span class="math">O(N^{1/t})</span> operations over <span class="math">\\mathbb{F}</span> to the verifier. The prover performs <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span> to compute a response to the tensor query. ∎</p>

    <p class="text-gray-300">The theorem below requires a linear code, and to achieve the stated asymptotics, the linear code must support linear-time encoding.</p>

    <h6 id="sec-82" class="text-base font-medium mt-4">Theorem 6.</h6>

    <p class="text-gray-300">For security parameter <span class="math">\\lambda</span>, given an <span class="math">(\\mathbb{F},k,t)</span>-tensor IOP for <span class="math">\\mathcal{R}_{MLE}</span> with <span class="math">N=2^{\\ell}=k^{t}</span> (where <span class="math">\\ell</span> is the size parameter) and fixed value of <span class="math">t</span>, and a linear code over <span class="math">\\mathbb{F}</span> with rate <span class="math">\\rho=k/n</span>, relative distance <span class="math">\\delta=d/n</span>, and encoding time <span class="math">k</span>, there exists a point-query IOP for <span class="math">\\mathcal{R}_{MLE}</span> with the following parameters:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- soundness error is $O(d^{t}/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+(1-\\frac{\\delta^{t}}{2})^{\\lambda})$;</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>round complexity is <span class="math">O(1)</span>;</li>

      <li>index length is <span class="math">O(N)</span> elements in <span class="math">\\mathbb{F}</span>;</li>

      <li>query complexity is <span class="math">O(N^{1/t})</span>;</li>

      <li>the indexer performs <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span>;</li>

      <li>the prover performs <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span>; and</li>

      <li>the verifier performs <span class="math">O(N^{1/t})</span> operations over <span class="math">\\mathbb{F}</span>.</li>

    </ul>

    <h6 id="sec-83" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Applying <em>[22, Theorem 3]</em> to the tensor IOP from Theorem 5 provides the desired result. ∎</p>

    <h4 id="sec-84" class="text-lg font-semibold mt-6">Proof of Theorem 2.</h4>

    <h6 id="sec-85" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">The desired commit algorithm and its claimed efficiency follows from from applying the BCS transform <em>[15]</em> (with a linear-time hash function <em>[5, 21]</em>) to the indexer in the point-query IOP from Theorem 6 (obtained by using any linear-time encodable linear error-correcting code of constant rate and relative distance). Similarly, the non-interactive argument of knowledge along with its claimed efficiency follows from applying the BCS transform <em>[15]</em> (with a linear-time hash function <em>[5, 21]</em>) to the point-query IOP from Theorem 6. ∎</p>

    <h2 id="sec-86" class="text-2xl font-bold">Appendix B Tighter Analysis for the Reed-Solomon Code</h2>

    <p class="text-gray-300">By invoking a state of the art analysis in place of Claim 1, one can concretely improve the number of columns that must be opened by the verifier in the polynomial commitment when the error-correcting code used is the Reed-Solomon code. The following claim is a rephrasing of <em>[10, Theorem 3.1]</em>.</p>

    <h6 id="sec-87" class="text-base font-medium mt-4">Claim 6.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(Ben-Sasson, Carmon, Ishai, Kopparty, and Saraf <em>[10]</em>) Let <span class="math">\\mathsf{Enc}</span> be the encoding function of a Reed-Solomon code over <span class="math">\\mathbb{F}</span> with message length <span class="math">k</span>, blocklength <span class="math">N</span>, and rate <span class="math">\\rho=(k+1)/N</span>. Let <span class="math">\\hat{u}=(\\hat{u}_{1},\\ldots,\\hat{u}_{m})\\in\\left(\\mathbb{F}^{N}\\right)^{m}</span> and for each <span class="math">i\\in[m]</span> let <span class="math">c_{i}</span> be the closest codeword in <span class="math">\\mathsf{Enc}</span> to <span class="math">\\hat{u}_{i}</span>. Let <span class="math">\\delta\\in(0,\\frac{1-\\rho}{2}]</span>. Let <span class="math">E</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><\\delta N<span class="math"> be a subset of the columns </span>j\\in[N]<span class="math"> of </span>\\hat{u}<span class="math"> on which there is even one row </span>i\\in[m]<span class="math"> such that </span>\\hat{u}_{i,j}\\neq c_{i,j}<span class="math">. Let </span>\\epsilon=N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. With probability at least </span>1-\\epsilon<span class="math"> over the choice of </span>r\\in\\mathbb{F}^{m}<span class="math">, </span>\\sum_{i=1}^{m}r_{i}\\cdot\\hat{u}_{i}<span class="math"> has distance at least </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> from any codeword in </span>\\mathsf{Enc}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-88" class="text-base font-medium mt-4">Lemma 4.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">\\rho</span> and $\\epsilon=N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> be as in Claim 6 and let </span>\\delta\\in(0,\\frac{1-\\rho}{2}]$. If the prover passes all of the checks in the testing phase with probability at least</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\epsilon+(1-\\delta)^{\\ell},</span></p>

    <p class="text-gray-300">then there is a sequence of <span class="math">m</span> codewords <span class="math">c_{1},\\ldots,c_{m}</span> in <span class="math">\\mathsf{Enc}</span> such that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$E\\coloneqq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\{j\\in[N]\\colon\\exists i\\in[m]\\text{ such that }c_{i,j}\\neq\\hat{u}_{i,j}\\}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\delta N.$ (15)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-89" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Let <span class="math">d(b,c)</span> denote the relative Hamming distance between two vectors <span class="math">b,c\\in\\mathbb{F}^{N}</span>. Assume by way of contradiction that Equation (15) does not hold. We explain that the prover passes the consistency tests during the testing phase with probability less than <span class="math">\\epsilon+(1-\\delta)^{\\ell}</span>.</p>

    <p class="text-gray-300">Recall that <span class="math">v</span> denotes <span class="math">\\sum_{i=1}^{m}r_{i}\\hat{u}_{i}</span>. By Claim 6, the probability over the verifier’s choice of <span class="math">r</span> that there exists a codeword <span class="math">a</span> satisfying <span class="math">d(a,v)\\leq\\delta</span> is less than <span class="math">\\epsilon</span>. If no such <span class="math">a</span> exists, then <span class="math">d(\\mathsf{Enc}(u^{\\prime}),v)&gt;\\delta</span>. In this event, all of the verifier’s consistency tests pass with probability at most <span class="math">(1-\\delta)^{\\ell}</span>.</p>

    <p class="text-gray-300">∎</p>

    <p class="text-gray-300">####</p>

    <p class="text-gray-300">Completeness and binding of the polynomial commitment scheme. Completeness holds by design.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">To argue binding, recall from the analysis of the testing phase that <span class="math">c_{i}</span> denotes the codeword in <span class="math">\\mathsf{Enc}</span> that is closest to row <span class="math">i</span> of <span class="math">\\hat{u}</span>, and let <span class="math">w\\coloneqq\\sum_{i=1}^{m}q_{1,i}\\cdot c_{i}</span>. Let <span class="math">\\rho,\\delta</span> and $\\epsilon=N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> be as in Lemma 4. We show that, if the prover passes the verifier’s checks in the testing phase with probability more than </span>\\epsilon+(1-\\delta)^{\\ell}<span class="math"> and passes the verifier’s checks in the evaluation phase with probability more than </span>\\left(\\rho+\\delta\\right)^{\\ell}<span class="math">, then </span>w=\\mathsf{Enc}(u^{\\prime\\prime})$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">If <span class="math">w\\neq\\mathsf{Enc}(u^{\\prime\\prime})</span>, then <span class="math">w</span> and <span class="math">\\mathsf{Enc}(u^{\\prime\\prime})</span> are two distinct codewords in <span class="math">\\mathsf{Enc}</span> and hence they can agree on at most <span class="math">\\rho\\cdot N</span> coordinates. Denote this agreement set by <span class="math">A</span>. The verifier rejects in the evaluation phase if there is any <span class="math">j\\in Q^{\\prime}</span> such that <span class="math">j\\not\\in A\\cup E</span>, where <span class="math">E</span> is as in Equation (15). $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A\\cup E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\rho\\cdot N+\\delta N=(\\rho+\\delta)N<span class="math">, and hence a randomly chosen column </span>j\\in[N]<span class="math"> is in </span>A\\cup E<span class="math"> with probability at most </span>\\rho+\\delta<span class="math">. It follows that </span>u^{\\prime\\prime}<span class="math"> will pass the verifier’s consistency checks in the evaluation phase with probability at most </span>\\left(\\rho+\\delta\\right)^{\\ell}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In summary, we have shown that if the prover passes the verifier’s checks in the testing phase with probability at least <span class="math">\\epsilon+(1-\\delta)^{\\ell}</span>, then, in the following sense, the prover is <em>bound</em> to the polynomial <span class="math">g^{<em>}</span> whose coefficients in the Lagrange basis are given by <span class="math">c_{1,1},\\ldots,c_{m,m}</span>, where <span class="math">c_{i}\\in\\mathbb{F}^{N}</span> denotes the closest codeword to row <span class="math">i</span> of the vector <span class="math">\\hat{u}</span> sent in the commitment phase: on evaluation query <span class="math">r</span>, the verifier either outputs <span class="math">g^{</em>}(r)</span>, or else rejects in the evaluation phase with probability at least <span class="math">1-\\left(\\frac{1+\\rho}{2}\\right)^{\\ell}</span>. Setting <span class="math">\\delta=\\frac{1-\\rho}{2}</span>, we obtain the following theorem.</p>

    <h6 id="sec-90" class="text-base font-medium mt-4">Theorem 7.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Consider the polynomial commitment scheme described in Section 4.1 using the Reed-Solomon code. If the prover passes the verifier’s checks in the testing phase with probability at least $N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+(\\frac{1+\\rho}{2})^{\\ell}<span class="math">, then, in the following sense, the prover is <em>bound</em> to the polynomial </span>g^{<em>}<span class="math"> whose coefficients in the Lagrange basis are given by </span>c_{1,1},\\ldots,c_{m,m}<span class="math">, where </span>c_{i}\\in\\mathbb{F}^{N}<span class="math"> denotes the closest codeword to row </span>i<span class="math"> of the vector </span>\\hat{u}<span class="math"> sent in the commitment phase: on evaluation query </span>r<span class="math">, the verifier either outputs </span>g^{</em>}(r)<span class="math">, or else rejects in the evaluation phase with probability at least </span>1-\\left(\\frac{1+\\rho}{2}\\right)^{\\ell}$. The polynomial commitment is extractable.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Furthermore, the polynomial commitment scheme provides standard extractability properties. This is because with the transformation of <em>[57, 66, 83, 15]</em>, informally speaking, given a prover in the random oracle model that convinces a verifier, one can efficiently extract the IOP proof strings from the prover. Our analysis of the testing phase of the polynomial commitment scheme (Lemma 4) guarantees that each row of the prover’s proof string in the commitment phase has relative Hamming distance at most <span class="math">\\delta=\\frac{1-\\rho}{2}</span> from some codeword. Hence, row-by-row decoding provides the coefficients of the multilinear polynomial that the prover is bound to (decoding of the Reed-Solomon code can be done in polynomial time via, e.g., the Berlekamp-Welch algorithm).</p>

    <h4 id="sec-91" class="text-lg font-semibold mt-6">An optimization over small fields.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The probability $N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+(\\frac{1+\\rho}{2})^{\\ell}<span class="math"> appearing in Theorem 7 can be driven arbitrarily close to </span>N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> by increasing </span>\\ell<span class="math">. However, for small fields, </span>N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> may be larger than the desired soundness error </span>\\epsilon=\\exp(-\\lambda)<span class="math">. In this event, one can modify the polynomial commitment scheme as follows so as to replace </span>N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+(\\frac{1+\\rho}{2})^{\\ell}<span class="math"> with </span>(N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)^{\\eta}+\\eta\\cdot(\\frac{1+\\rho}{2})^{\\ell}<span class="math"> for any constant </span>\\eta>1<span class="math">. The Testing Phase is repeated </span>\\eta<span class="math"> times in parallel, but with the same random subset </span>Q\\subseteq[N]<span class="math"> of columns (with </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\ell=\\Theta(\\lambda)<span class="math">) used in all </span>\\eta<span class="math"> repetitions. The proof of Theorem 7 is easily extended to show that Theorem 7 applies to this modification of the polynomial commitment, with </span>N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+(\\frac{1+\\rho}{2})^{\\ell}<span class="math"> replaced with </span>(N/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)^{\\eta}+\\eta\\cdot(\\frac{1+\\rho}{2})^{\\ell}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">By using the same set <span class="math">Q</span> in all <span class="math">\\eta</span> invocations of the testing phase, one avoids a factor-<span class="math">\\eta</span> blowup in the proof length (as revealing all “columns” in <span class="math">Q</span> of <span class="math">\\hat{u}</span> is the bottleneck in the proof length). When using the Reed-Solomon code, the repetitions of the Testing Phase also do not substantially increase the prover time, because the bottleneck in the prover time is computing <span class="math">\\hat{u}</span> in the Commit Phase, not the Test Phase (this holds both asymptotically when using Reed-Solomon codes, and concretely for large enough instance sizes <span class="math">N</span>).</p>

    <h2 id="sec-92" class="text-2xl font-bold">Appendix C Additional discussion of related work</h2>

    <h4 id="sec-93" class="text-lg font-semibold mt-6">On cryptographic assumptions and detailed comparison to <em>[24]</em>.</h4>

    <p class="text-gray-300">Recall from Section 1 that Bootle, Chiesa, and Liu <em>[24]</em> give a zero-knowledge IOP for R1CS with linear-time prover and polylogarithmic</p>

    <p class="text-gray-300">time verifier. Standard transformations can then translate this IOP into a zero-knowledge SNARG that is unconditionally secure in the random oracle model.</p>

    <p class="text-gray-300">Our implemented SNARKs, Shockwave and Brakedown, satisfy the same type of security property as <em>[24, 22]</em>, in the sense that we give an IOP (of knowledge), and this can be transformed into a SNARK that is unconditionally secure in the random oracle model. However, our other theoretical SNARKs do not, owing to their use of (one layer of) recursive composition. Rather, they are knowledge-sound assuming our first SNARK remains knowledge sound in the plain model when the random oracle is instantiated by the appropriate concrete hash function. This is a well-known issue that arises whenever one recursively composes two SNARKs, where the “inner” SNARK makes use of random oracles <em>[83, 19, 36, 29]</em>. The random oracle used by the inner SNARK must be instantiated before recursive composition can occur, and knowledge soundness of the composed SNARK requires knowledge soundness of the inner SNARK.</p>

    <p class="text-gray-300">On a technical level, Bootle et al. <em>[24]</em> obtain a zero-knowledge IOP with polylogarithmic proof length by applying proof composition to interactive oracle proofs (IOPs) that one can later transform into zkSNARKs via Merkle hashing and the Fiat-Shamir transformation <em>[66, 83, 15]</em>. In contrast, we obtain our theoretical zkSNARKs with analogous costs by transforming our first (non-zero-knowledge) IOP into a SNARK <em>before</em> performing recursive proof composition with a suitable existing zkSNARK.</p>

    <h5 id="sec-94" class="text-base font-semibold mt-4">Additional related work.</h5>

    <p class="text-gray-300">Other than <em>[22, 24]</em>, the following works have come closest to the goals set forth in this paper: (1) Hyrax <em>[87]</em> and Libra <em>[89]</em> for low-depth, uniform circuits; (2) Spartan <em>[75]</em> and Xiphos <em>[78]</em> for arbitrary, non-uniform statements represented with R1CS; (3) the recent work of Kothapalli et al. <em>[58]</em> for a variant of R1CS. All these schemes combine variants of the sum-check protocol <em>[65, 14]</em> with cryptographic commitments (e.g., polynomial commitments).</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In Hyrax and Libra, beyond performing <span class="math">O(N)</span> finite field operations where <span class="math">N</span> is the size of the circuit, the prover performs <span class="math">O(d\\log N+W)</span> exponentiations in a group, where <span class="math">W</span> is the size of the witness to the circuit. (Hyrax employs Giraffe <em>[85]</em> that shows how to implement the prover via <span class="math">O(N)</span> finite field operations for <em>data-parallel</em> circuits. Libra showed how to achieve this runtime bound for arbitrary circuits.) As a result, these schemes achieve a linear-time prover so long as <span class="math">d\\log N+W\\leq(N\\cdot\\log W)/\\lambda</span> (i.e., for circuits of sub-linear depth and with sub-linear sized witnesses, and when $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=2^{\\Theta(\\lambda)}<span class="math">). Two downsides remain. First, their underlying interactive proof <em>[48, 37, 85]</em> has communication cost </span>\\Theta(d\\log N)$, which places a lower bound on the proof length (regardless of the polynomial commitment scheme used). Second, they require uniform circuits (e.g., data-parallel circuits) to achieve verifier’s costs that are sub-linear in the circuit size.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In contrast, Spartan and Xiphos apply to arbitrary R1CS (over discrete-logarithm-friendly fields) and when using appropriate polynomial commitment schemes (such as Dory <em>[60]</em>), their proof length is <span class="math">O(\\log N)</span> group elements. Furthermore, they achieve <span class="math">O_{\\lambda}(\\log N)</span> verification times, after a one-time preprocessing step to create a commitment to R1CS matrices.However, after performing <span class="math">O(N)</span> operations over <span class="math">\\mathbb{F}</span>, Spartan’s and Xiphos’s provers perform an <span class="math">O(N)</span>-sized multiexponentiation, which stems from their use of a polynomial commitment schemes applied to a multilinear polynomial with <span class="math">O(N)</span> coefficients. As a result, according to our accounting (§1), they do not achieve a linear-time prover even though concretely these zkSNARKs have a prover time that is in fact the state of the art in most cases for large enough instance sizes.</p>

    <p class="text-gray-300">In a recent theoretical work, Kothapalli et al <em>[58]</em> propose a zkSNARK that achieves <span class="math">O_{\\lambda}(1)</span> proof sizes and verification times for a variant of R1CS, but their prover performs an <span class="math">O(N)</span>-sized multiexponentiation for an <span class="math">N</span>-sized R1CS instance, so it too does not achieve a linear-time prover. Additionally, their scheme requires a one-time trusted setup.</p>

    <p class="text-gray-300">Beyond the above works, GGPR-based zkSNARKs <em>[44, 70, 49]</em> offer the best proof sizes and verification times in practice, but they require the prover to perform an FFT of length <span class="math">\\Theta(N)</span> and also require a trusted setup (a trusted authority, or a set of authorities of which at least one is honest, that creates public parameters using a secret trapdoor that they later forget). Other approaches to zero-knowledge arguments not discussed above either require the prover to devote <span class="math">\\Theta(N\\log N)</span> field operations to FFTs <em>[4, 14, 42, 35]</em>, or they require</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">213</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">215</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">217</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">219</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">221</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">223</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">225</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">227</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">229</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  1 thread  |   |   |   |   |   |   |   |   |   |</p>

    <p class="text-gray-300">|  Commit (seconds)  |   |   |   |   |   |   |   |   |   |</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Brakedown-PC</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.013</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.038</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.123</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.491</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">2.14</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">8.91</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">36.0</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">150</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">605</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/2</td>

            <td class="px-3 py-2 border-b border-gray-700">0.007</td>

            <td class="px-3 py-2 border-b border-gray-700">0.028</td>

            <td class="px-3 py-2 border-b border-gray-700">0.115</td>

            <td class="px-3 py-2 border-b border-gray-700">0.492</td>

            <td class="px-3 py-2 border-b border-gray-700">2.08</td>

            <td class="px-3 py-2 border-b border-gray-700">8.75</td>

            <td class="px-3 py-2 border-b border-gray-700">39.9</td>

            <td class="px-3 py-2 border-b border-gray-700">169</td>

            <td class="px-3 py-2 border-b border-gray-700">717</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/4</td>

            <td class="px-3 py-2 border-b border-gray-700">0.015</td>

            <td class="px-3 py-2 border-b border-gray-700">0.058</td>

            <td class="px-3 py-2 border-b border-gray-700">0.244</td>

            <td class="px-3 py-2 border-b border-gray-700">1.04</td>

            <td class="px-3 py-2 border-b border-gray-700">4.46</td>

            <td class="px-3 py-2 border-b border-gray-700">19.7</td>

            <td class="px-3 py-2 border-b border-gray-700">83.9</td>

            <td class="px-3 py-2 border-b border-gray-700">356</td>

            <td class="px-3 py-2 border-b border-gray-700">1590</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">FRI-PC</td>

            <td class="px-3 py-2 border-b border-gray-700">0.028</td>

            <td class="px-3 py-2 border-b border-gray-700">0.118</td>

            <td class="px-3 py-2 border-b border-gray-700">0.503</td>

            <td class="px-3 py-2 border-b border-gray-700">2.21</td>

            <td class="px-3 py-2 border-b border-gray-700">9.44</td>

            <td class="px-3 py-2 border-b border-gray-700">39.9</td>

            <td class="px-3 py-2 border-b border-gray-700">168</td>

            <td class="px-3 py-2 border-b border-gray-700">—</td>

            <td class="px-3 py-2 border-b border-gray-700">—</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  Open (seconds)  |   |   |   |   |   |   |   |   |   |</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Brakedown-PC</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.022</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.028</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.048</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.113</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.271</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.935</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">3.21</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">13.0</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">48.6</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/2</td>

            <td class="px-3 py-2 border-b border-gray-700">0.002</td>

            <td class="px-3 py-2 border-b border-gray-700">0.005</td>

            <td class="px-3 py-2 border-b border-gray-700">0.014</td>

            <td class="px-3 py-2 border-b border-gray-700">0.051</td>

            <td class="px-3 py-2 border-b border-gray-700">0.214</td>

            <td class="px-3 py-2 border-b border-gray-700">0.799</td>

            <td class="px-3 py-2 border-b border-gray-700">3.11</td>

            <td class="px-3 py-2 border-b border-gray-700">12.4</td>

            <td class="px-3 py-2 border-b border-gray-700">50.0</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/4</td>

            <td class="px-3 py-2 border-b border-gray-700">0.002</td>

            <td class="px-3 py-2 border-b border-gray-700">0.004</td>

            <td class="px-3 py-2 border-b border-gray-700">0.014</td>

            <td class="px-3 py-2 border-b border-gray-700">0.052</td>

            <td class="px-3 py-2 border-b border-gray-700">0.209</td>

            <td class="px-3 py-2 border-b border-gray-700">0.793</td>

            <td class="px-3 py-2 border-b border-gray-700">3.13</td>

            <td class="px-3 py-2 border-b border-gray-700">12.5</td>

            <td class="px-3 py-2 border-b border-gray-700">51.6</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">FRI-PC</td>

            <td class="px-3 py-2 border-b border-gray-700">0.039</td>

            <td class="px-3 py-2 border-b border-gray-700">0.108</td>

            <td class="px-3 py-2 border-b border-gray-700">0.527</td>

            <td class="px-3 py-2 border-b border-gray-700">4.21</td>

            <td class="px-3 py-2 border-b border-gray-700">22.5</td>

            <td class="px-3 py-2 border-b border-gray-700">20.9</td>

            <td class="px-3 py-2 border-b border-gray-700">185</td>

            <td class="px-3 py-2 border-b border-gray-700">—</td>

            <td class="px-3 py-2 border-b border-gray-700">—</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  Verify (seconds)  |   |   |   |   |   |   |   |   |   |</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Brakedown-PC</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.025</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.035</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.056</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.148</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.298</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.613</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.703</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">2.56</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">2.96</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/2</td>

            <td class="px-3 py-2 border-b border-gray-700">0.003</td>

            <td class="px-3 py-2 border-b border-gray-700">0.006</td>

            <td class="px-3 py-2 border-b border-gray-700">0.011</td>

            <td class="px-3 py-2 border-b border-gray-700">0.021</td>

            <td class="px-3 py-2 border-b border-gray-700">0.044</td>

            <td class="px-3 py-2 border-b border-gray-700">0.093</td>

            <td class="px-3 py-2 border-b border-gray-700">0.196</td>

            <td class="px-3 py-2 border-b border-gray-700">0.402</td>

            <td class="px-3 py-2 border-b border-gray-700">0.846</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/4</td>

            <td class="px-3 py-2 border-b border-gray-700">0.004</td>

            <td class="px-3 py-2 border-b border-gray-700">0.008</td>

            <td class="px-3 py-2 border-b border-gray-700">0.017</td>

            <td class="px-3 py-2 border-b border-gray-700">0.036</td>

            <td class="px-3 py-2 border-b border-gray-700">0.077</td>

            <td class="px-3 py-2 border-b border-gray-700">0.160</td>

            <td class="px-3 py-2 border-b border-gray-700">0.338</td>

            <td class="px-3 py-2 border-b border-gray-700">0.714</td>

            <td class="px-3 py-2 border-b border-gray-700">1.57</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">FRI-PC</td>

            <td class="px-3 py-2 border-b border-gray-700">0.018</td>

            <td class="px-3 py-2 border-b border-gray-700">0.022</td>

            <td class="px-3 py-2 border-b border-gray-700">0.025</td>

            <td class="px-3 py-2 border-b border-gray-700">0.029</td>

            <td class="px-3 py-2 border-b border-gray-700">0.032</td>

            <td class="px-3 py-2 border-b border-gray-700">0.038</td>

            <td class="px-3 py-2 border-b border-gray-700">0.041</td>

            <td class="px-3 py-2 border-b border-gray-700">—</td>

            <td class="px-3 py-2 border-b border-gray-700">—</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  64 threads  |   |   |   |   |   |   |   |   |   |</p>

    <p class="text-gray-300">|  Commit (seconds)  |   |   |   |   |   |   |   |   |   |</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Brakedown-PC</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.012</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.018</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.024</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.074</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.234</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.682</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">2.24</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">10.7</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">38.8</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/2</td>

            <td class="px-3 py-2 border-b border-gray-700">0.009</td>

            <td class="px-3 py-2 border-b border-gray-700">0.022</td>

            <td class="px-3 py-2 border-b border-gray-700">0.062</td>

            <td class="px-3 py-2 border-b border-gray-700">0.174</td>

            <td class="px-3 py-2 border-b border-gray-700">0.367</td>

            <td class="px-3 py-2 border-b border-gray-700">1.04</td>

            <td class="px-3 py-2 border-b border-gray-700">3.21</td>

            <td class="px-3 py-2 border-b border-gray-700">11.5</td>

            <td class="px-3 py-2 border-b border-gray-700">45.5</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/4</td>

            <td class="px-3 py-2 border-b border-gray-700">0.015</td>

            <td class="px-3 py-2 border-b border-gray-700">0.034</td>

            <td class="px-3 py-2 border-b border-gray-700">0.095</td>

            <td class="px-3 py-2 border-b border-gray-700">0.280</td>

            <td class="px-3 py-2 border-b border-gray-700">0.646</td>

            <td class="px-3 py-2 border-b border-gray-700">1.74</td>

            <td class="px-3 py-2 border-b border-gray-700">5.73</td>

            <td class="px-3 py-2 border-b border-gray-700">21.6</td>

            <td class="px-3 py-2 border-b border-gray-700">94.6</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  Open (seconds)  |   |   |   |   |   |   |   |   |   |</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Brakedown-PC</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.025</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.028</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.039</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.067</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.105</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.189</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.281</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.931</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">2.05</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/2</td>

            <td class="px-3 py-2 border-b border-gray-700">0.005</td>

            <td class="px-3 py-2 border-b border-gray-700">0.005</td>

            <td class="px-3 py-2 border-b border-gray-700">0.006</td>

            <td class="px-3 py-2 border-b border-gray-700">0.010</td>

            <td class="px-3 py-2 border-b border-gray-700">0.022</td>

            <td class="px-3 py-2 border-b border-gray-700">0.048</td>

            <td class="px-3 py-2 border-b border-gray-700">0.146</td>

            <td class="px-3 py-2 border-b border-gray-700">0.449</td>

            <td class="px-3 py-2 border-b border-gray-700">1.54</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/4</td>

            <td class="px-3 py-2 border-b border-gray-700">0.004</td>

            <td class="px-3 py-2 border-b border-gray-700">0.004</td>

            <td class="px-3 py-2 border-b border-gray-700">0.006</td>

            <td class="px-3 py-2 border-b border-gray-700">0.009</td>

            <td class="px-3 py-2 border-b border-gray-700">0.019</td>

            <td class="px-3 py-2 border-b border-gray-700">0.049</td>

            <td class="px-3 py-2 border-b border-gray-700">0.140</td>

            <td class="px-3 py-2 border-b border-gray-700">0.421</td>

            <td class="px-3 py-2 border-b border-gray-700">1.51</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  Verify (seconds)  |   |   |   |   |   |   |   |   |   |</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Brakedown-PC</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.010</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.017</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.031</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.120</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.270</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.558</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0.551</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">2.37</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">2.40</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/2</td>

            <td class="px-3 py-2 border-b border-gray-700">0.012</td>

            <td class="px-3 py-2 border-b border-gray-700">0.006</td>

            <td class="px-3 py-2 border-b border-gray-700">0.010</td>

            <td class="px-3 py-2 border-b border-gray-700">0.014</td>

            <td class="px-3 py-2 border-b border-gray-700">0.022</td>

            <td class="px-3 py-2 border-b border-gray-700">0.035</td>

            <td class="px-3 py-2 border-b border-gray-700">0.058</td>

            <td class="px-3 py-2 border-b border-gray-700">0.106</td>

            <td class="px-3 py-2 border-b border-gray-700">0.201</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/4</td>

            <td class="px-3 py-2 border-b border-gray-700">0.006</td>

            <td class="px-3 py-2 border-b border-gray-700">0.009</td>

            <td class="px-3 py-2 border-b border-gray-700">0.013</td>

            <td class="px-3 py-2 border-b border-gray-700">0.018</td>

            <td class="px-3 py-2 border-b border-gray-700">0.027</td>

            <td class="px-3 py-2 border-b border-gray-700">0.043</td>

            <td class="px-3 py-2 border-b border-gray-700">0.075</td>

            <td class="px-3 py-2 border-b border-gray-700">0.136</td>

            <td class="px-3 py-2 border-b border-gray-700">0.278</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  Communication (kiB)  |   |   |   |   |   |   |   |   |   |</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Brakedown-PC</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">4299</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">5198</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">6739</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">10010</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">15797</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">27112</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">49157</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">93767</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">181948</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/2</td>

            <td class="px-3 py-2 border-b border-gray-700">279</td>

            <td class="px-3 py-2 border-b border-gray-700">432</td>

            <td class="px-3 py-2 border-b border-gray-700">727</td>

            <td class="px-3 py-2 border-b border-gray-700">1304</td>

            <td class="px-3 py-2 border-b border-gray-700">2446</td>

            <td class="px-3 py-2 border-b border-gray-700">4718</td>

            <td class="px-3 py-2 border-b border-gray-700">9250</td>

            <td class="px-3 py-2 border-b border-gray-700">18302</td>

            <td class="px-3 py-2 border-b border-gray-700">36394</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ligero-PC-1/4</td>

            <td class="px-3 py-2 border-b border-gray-700">203</td>

            <td class="px-3 py-2 border-b border-gray-700">321</td>

            <td class="px-3 py-2 border-b border-gray-700">551</td>

            <td class="px-3 py-2 border-b border-gray-700">1004</td>

            <td class="px-3 py-2 border-b border-gray-700">1901</td>

            <td class="px-3 py-2 border-b border-gray-700">3689</td>

            <td class="px-3 py-2 border-b border-gray-700">7256</td>

            <td class="px-3 py-2 border-b border-gray-700">14383</td>

            <td class="px-3 py-2 border-b border-gray-700">28631</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">FRI-PC</td>

            <td class="px-3 py-2 border-b border-gray-700">153</td>

            <td class="px-3 py-2 border-b border-gray-700">221</td>

            <td class="px-3 py-2 border-b border-gray-700">302</td>

            <td class="px-3 py-2 border-b border-gray-700">388</td>

            <td class="px-3 py-2 border-b border-gray-700">492</td>

            <td class="px-3 py-2 border-b border-gray-700">613</td>

            <td class="px-3 py-2 border-b border-gray-700">740</td>

            <td class="px-3 py-2 border-b border-gray-700">—</td>

            <td class="px-3 py-2 border-b border-gray-700">—</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Figure 8: Microbenchmark results (§8.1). Brakedown-PC uses the parameters given on the third line of Figure 2; Ligero-PC-38/39, Ligero-PC-1/2, Ligero-PC-1/4, and FRI-PC are instantiated with Reed-Solomon rates of  <span class="math">^{38/39}</span> ,  <span class="math">^{1/2}</span> ,  <span class="math">^{1/4}</span> , and  <span class="math">^{1/4}</span> , respectively. For FRI-PC, ‘—’ means that the prover ran out of memory.</p>

    <p class="text-gray-300">a trusted setup [42, 35], or they do not achieve sub-linear verification costs [28, 21]. Moreover, as mentioned in Section 1, all prior succinct argument implementations have placed restrictions on the field used, e.g., discrete-logarithm friendliness, FFT-friendliness, or the need for one or more additive or multiplicative subgroups of a specified size.</p>

    <p class="text-gray-300">Finally, several recent works [46, 32, 88, 6, 39] do achieve a linear-time prover, but they do not achieve sub-linear verification costs nor proof sizes; many of these works also do not achieve non-interactivity nor publicly-verifiable proofs.</p>

    <p class="text-gray-300">D Proof of Theorem 4</p>

    <p class="text-gray-300">Proof. From applying [30, Theorem 8] to the polynomial IOP in Theorem 1 using polynomial commitment schemes from Theorem 2 and Corollary 1, there exists a public-coin interactive argument for <span class="math">\\mathcal{R}_{\\mathrm{R1CS}}</span> with witness-extended emulation. Applying the Fiat-Shamir transform [41] to the public-coin interactive argument results in the claimed SNARK for <span class="math">\\mathcal{R}_{\\mathrm{R1CS}}</span>.</p>

    <p class="text-gray-300">The verifier, in a preprocessing step, commits to three <span class="math">2\\log M</span>-variate polynomials that evaluate to a non-zero value at at most <span class="math">N</span> locations over the Boolean hypercube <span class="math">\\{0,1\\}^{2\\log M}</span>; this costs <span class="math">O(N)</span> <span class="math">\\mathbb{F}</span>-ops.</p>

    <p class="text-gray-300">The prover: (1) commits to a <span class="math">O(\\log M)</span>-variate polynomial (which costs <span class="math">O(M)</span> <span class="math">\\mathbb{F}</span>-ops); (2) participates in the sum-check protocol in the polynomial IOP in Theorem 1 (which costs <span class="math">O(N)</span> <span class="math">\\mathbb{F}</span>-ops); and (3) proves evaluations of one <span class="math">(\\log M-1)</span>-variate multilinear polynomial and three <span class="math">2\\log M</span>-variate multilinear polynomials from the preprocessing step (which costs <span class="math">O(N)</span> <span class="math">\\mathbb{F}</span>-ops). Together, the prover incurs <span class="math">O(N)</span> <span class="math">\\mathbb{F}</span>-ops.</p>

    <p class="text-gray-300">The verifier to verify a proof: (1) participates in the sum-check protocol in the polynomial IOP in Theorem 1 (which costs <span class="math">O(\\log M)</span> <span class="math">\\mathbb{F}</span>-ops); and (2) verifies the proofs of evaluations of one <span class="math">(\\log M-1)</span>-variate multilinear polynomial and three <span class="math">2\\log M</span>-variate multilinear polynomials from the preprocessing step (which costs <span class="math">O_{\\lambda}(N^{1/t})</span> <span class="math">\\mathbb{F}</span>-ops). Together, the verifier incurs <span class="math">O_{\\lambda}(N^{1/t})</span> <span class="math">\\mathbb{F}</span>-ops.</p>

    <p class="text-gray-300">Finally, the proof size is the sum of the proof sizes from the sum-check protocol in the polynomial IOP from Theorem 1 and the proof sizes from polynomial commitment schemes. In total, the proof size is <span class="math">O(\\log M)+O_{\\lambda}(N^{1/t})=O_{\\lambda}(N^{1/t})</span>. <span class="math">\\square</span></p>

    <h2 id="sec-95" class="text-2xl font-bold">Appendix E Asymptotic Efficiency of Prior SNARKs</h2>

    <p class="text-gray-300">Figure 9 depicts the efficiency of SNARKs from this work and prior works.</p>

    <p class="text-gray-300">##</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">prover time</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">encoder time</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">proof size/verifier time</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">ZK?</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">assumptions</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">computational model</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Hyrax [87]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(W+d log N) G-exp O(N) F-ops</td>

            <td class="px-3 py-2 border-b border-gray-700">N/A</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(√W+d log N)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

            <td class="px-3 py-2 border-b border-gray-700">DLOG, RO</td>

            <td class="px-3 py-2 border-b border-gray-700">data-parallel circuits with low-depth d</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Libra [89]†</td>

            <td class="px-3 py-2 border-b border-gray-700">O(W+d log N) G-exp O(N) F-ops</td>

            <td class="px-3 py-2 border-b border-gray-700">N/A</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(d log N)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

            <td class="px-3 py-2 border-b border-gray-700">q-type, RO</td>

            <td class="px-3 py-2 border-b border-gray-700">uniform circuits with low-depth d</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Virgo [91]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N+W log W) F-ops O(W) hashes</td>

            <td class="px-3 py-2 border-b border-gray-700">N/A</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(d log N + log2W)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

            <td class="px-3 py-2 border-b border-gray-700">RO</td>

            <td class="px-3 py-2 border-b border-gray-700">uniform circuits with low-depth d</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Spartan [75]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) G-exp</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) G-exp</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(√N)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

            <td class="px-3 py-2 border-b border-gray-700">DLOG, RO</td>

            <td class="px-3 py-2 border-b border-gray-700">R1CS</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Spartan++ [78]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) G-exp</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(√N)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

            <td class="px-3 py-2 border-b border-gray-700">DLOG, RO</td>

            <td class="px-3 py-2 border-b border-gray-700">R1CS</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Xiphos [78]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) G-exp</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(log N)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

            <td class="px-3 py-2 border-b border-gray-700">SXDH, RO</td>

            <td class="px-3 py-2 border-b border-gray-700">R1CS</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[58]†</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) G-exp</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) G-exp</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(1)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

            <td class="px-3 py-2 border-b border-gray-700">q-type, RO*</td>

            <td class="px-3 py-2 border-b border-gray-700">ACS</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Hyrax*</td>

            <td class="px-3 py-2 border-b border-gray-700">O(W+d log N) G-exp O(N) F-ops</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(d log N)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

            <td class="px-3 py-2 border-b border-gray-700">SXDH, RO</td>

            <td class="px-3 py-2 border-b border-gray-700">non-uniform circuits with low-depth d</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[22]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops O(N) hashes</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops O(N) hashes</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(Nε)</td>

            <td class="px-3 py-2 border-b border-gray-700">X</td>

            <td class="px-3 py-2 border-b border-gray-700">RO</td>

            <td class="px-3 py-2 border-b border-gray-700">R1CS</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[24]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops O(N) hashes</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops O(N) hashes</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(logc(N))</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

            <td class="px-3 py-2 border-b border-gray-700">RO</td>

            <td class="px-3 py-2 border-b border-gray-700">R1CS</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">This work</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops O(N) hashes</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(Nε)</td>

            <td class="px-3 py-2 border-b border-gray-700">X</td>

            <td class="px-3 py-2 border-b border-gray-700">RO</td>

            <td class="px-3 py-2 border-b border-gray-700">R1CS</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">This work</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops O(N) hashes</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(log2N)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

            <td class="px-3 py-2 border-b border-gray-700">RO*</td>

            <td class="px-3 py-2 border-b border-gray-700">R1CS</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">This work</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops O(N) hashes</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(log N)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

            <td class="px-3 py-2 border-b border-gray-700">RO*, SXDH</td>

            <td class="px-3 py-2 border-b border-gray-700">R1CS</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">This work†</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops O(N) hashes</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) F-ops</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(1)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

            <td class="px-3 py-2 border-b border-gray-700">RO*, q-type</td>

            <td class="px-3 py-2 border-b border-gray-700">R1CS</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\dagger</span>  Requires universal trusted setup</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Figure 9: Asymptotic efficiency of zkSNARKs from this work and prior works (we borrow style from [75, 78, 22]). The depicted costs are for an NP statement of size  <span class="math">N</span>  over a finite field  <span class="math">\\mathbb{F}</span> , where  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\exp(\\Theta(\\lambda))<span class="math">  and  </span>\\lambda \\geq \\omega(\\log N)<span class="math">  is the security parameter.  </span>\\mathbb{F}<span class="math"> -ops refers to field multiplications or additions;  </span>\\mathbb{G}<span class="math"> -exp refers to an exponentiation in a group  </span>\\mathbb{G}<span class="math">  whose scalar field is  </span>\\mathbb{F}<span class="math"> . We focus on zkSNARKs with a linear number of operations of a certain type. We do not depict schemes that do not achieve sub-linear verification costs [28, 21, 88, 6, 39]. For Hyrax [87] and Libra [89], we assume a layered arithmetic circuit, with  </span>N<span class="math">  gates, depth  </span>d<span class="math"> , and a non-deterministic witness of size  </span>W<span class="math"> . The parameters  </span>\\epsilon \\in (0,1)<span class="math">  and  </span>c &gt; 0<span class="math">  are constants. ACS refers to a specialization of R1CS [58]. Spartan++ and Xiphos use an untrusted assistant (e.g., the prover) to accelerate the encoder, thereby avoiding  </span>O(N)<span class="math"> </span>\\mathbb{G}<span class="math"> -exp operations [78]. Hyrax<em> refers to Hyrax with the following modifications from subsequent works: (1) linear-time sum-checks for non-uniform circuits from Libra [89]; (2) computation commitments from Spartan [75] to preprocess the structure of a non-uniform circuit; and (3) polynomial commitment scheme from Dory [60], which is also used in Xiphos [78]. Bootle et al. [22, 24] and our first scheme give IOPs, and the table refers to SNARKs that can be obtained thereof via standard transformations. Our first scheme is Theorem 4. The latter three schemes are obtained by applying one-level of proof composition to our first scheme using one of three existing zkSNARKs as the &quot;outer&quot; proof system: Spartan </span>_{80}<span class="math">  [75], Xiphos [78], and Groth16 [49]. RO in the &quot;assumptions&quot; column refers to the random oracle model (rows for which RO is the only assumption yield an unconditionally knowledge sound protocol in the random oracle model, and interactive protocols in the plain model that are knowledge sound assuming CRHFs. Rows for which  </span>\\mathrm{RO}^</em><span class="math">  appears in the assumption column require assuming plain-model security when the random oracle is instantiated with a concrete hash function). To achieve a linear-time prover by using a linear-time hash function for Merkle hashes, our schemes and the schemes of Bootle et al. [22, 24] require assuming the hardness of certain lattice problems, which are not listed in the &quot;assumptions&quot; column for brevity ( </span>\\S 1$ ).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>`;
---

<BaseLayout title="Brakedown: Linear-time and field-agnostic SNARKs for R1CS (2021/1043)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2021 &middot; eprint 2021/1043
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
