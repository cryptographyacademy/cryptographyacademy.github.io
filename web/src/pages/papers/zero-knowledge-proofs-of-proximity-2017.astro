---
import BaseLayout from '../../layouts/BaseLayout.astro';
import PaperDisclaimer from '../../components/PaperDisclaimer.astro';
import PaperHistory from '../../components/PaperHistory.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2017/114';
const CRAWLER = 'modal-marker';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Zero-Knowledge Proofs of Proximity';
const AUTHORS_HTML = 'Itay Berman, Ron D.  Rothblum, Vinod Vaikuntanathan';

const CONTENT = `    <section id="abstract" class="mb-10">
      <h2 class="text-2xl font-bold">Abstract</h2>
      <p class="text-gray-300">Interactive proofs of proximity (Ergun, Kumar and Rubinfeld, Information &amp; Computation, 2004 and Rothblum, Vadhan and Wigderson, STOC 2013), or IPPs, are interactive proofs in which the verifier runs in time sub-linear in the input&#x27;s length. Since the verifier cannot even read the entire input, following the property testing literature, the requirement is that she accepts inputs that are in the language and rejects ones that are far from the language. However, these proofs could (and in many cases, do) betray considerable global information about the input to the verifier.

In this work, we initiate the study of zero-knowledge proofs of proximity (ZKPP). A ZKPP convinces a sub-linear time verifier while ensuring that she learns nothing more than a few locations of the input (and the fact that the input is \`\`close&#x27;&#x27; to the language).

Our main focus is the setting of statistical zero-knowledge where we show that the following hold unconditionally (where $N$ denotes the input size):

* Statistical ZKPPs can be sub-exponentially more efficient than property testers (or even non-interactive IPPs): We show a natural property which has a statistical ZKPP with a polylog(N) time verifier, but requires $\\Omega(\\sqrt{N})$ queries (and hence also runtime) for every property tester.

* Statistical ZKPPs can be sub-exponentially less efficient than IPPs: We show a property which has an IPP with a polylog(N) time verifier, but cannot have a statistical ZKPP with even an $N^{o(1)}$ time verifier.

* Statistical ZKPPs for some graph-based properties such as promise versions of expansion and bipartiteness.

Lastly, we also consider the computational setting where we show that:
1. Assuming the existence of one-way functions, every language computable either in (logspace uniform) NC or in SC, has a computational ZKPP with a (roughly) $\\sqrt{N}$ time verifier.

2. Assuming the existence of collision-resistant hash functions, every language in NP has a statistical zero-knowledge argument of proximity with a polylog(N) verifier.</p>
      <p class="text-gray-300"><strong>Keywords:</strong> Zero Knowledge &middot; Proofs of Proximity</p>
    </section>

    <p class="text-gray-300">Itay Berman MIT</p>

    <p class="text-gray-300">Ron D. Rothblum MIT</p>

    <p class="text-gray-300">Vinod Vaikuntanathan MIT</p>

    <p class="text-gray-300">February 11, 2017</p>

    <h4 id="sec-misc-1" class="text-lg font-semibold mt-6"><strong>Abstract</strong></h4>

    <p class="text-gray-300">Interactive proofs of proximity (Ergun, Kumar and Rubinfeld, Information &amp; Computa- &uml; tion, 2004 and Rothblum, Vadhan and Wigderson, STOC 2013), or IPPs, are interactive proofs in which the verifier runs in time <em>sub-linear</em> in the input's length. Since the verifier cannot even read the entire input, following the property testing literature, the requirement is that she accepts inputs that are <em>in</em> the language and rejects ones that are <em>far</em> from the language. However, these proofs could (and in many cases, do) betray considerable <em>global</em> information about the input to the verifier.</p>

    <p class="text-gray-300">In this work, we initiate the study of <em>zero-knowledge proofs of proximity</em> (ZKPP). A ZKPP convinces a sub-linear time verifier while ensuring that she learns nothing more than a few locations of the input (and the fact that the input is &quot;close&quot; to the language).</p>

    <p class="text-gray-300">Our main focus is the setting of <em>statistical</em> zero-knowledge where we show that the following hold <em>unconditionally</em> (where N denotes the input size):</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Statistical ZKPPs can be sub-exponentially more efficient than property testers (or even non-interactive IPPs): We show a natural property which has a statistical ZKPP with a polylog(N) time verifier, but requires &Omega;(<sup>&radic;</sup> N) queries (and hence also runtime) for every property tester.</li>
      <li>Statistical ZKPPs can be sub-exponentially less efficient than IPPs: We show a property which has an IPP with a polylog(N) time verifier, but cannot have a statistical ZKPP with even an No(1) time verifier.</li>
      <li>Statistical ZKPPs for some graph-based properties such as promise versions of expansion and bipartiteness.</li>
    </ul>

    <p class="text-gray-300">Lastly, we also consider the computational setting where we show that:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Assuming the existence of one-way functions, every language computable either in (logspace uniform) NC or in SC, has a <em>computational</em> ZKPP with a (roughly) <sup>&radic;</sup> N time verifier.</li>
      <li>Assuming the existence of collision-resistant hash functions, every language in NP has a <em>statistical</em> zero-knowledge <em>argument</em> of proximity with a polylog(N) verifier.</li>
    </ul>

    <p class="text-gray-300"><sup>&lowast;</sup>Email: {itayberm,ronr,vinodv}@mit.edu</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">1</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Introduction</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">1</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.1 Our Results</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.2 Additional Related Works</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Preliminaries</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2.1 Hashing and Entropy</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2.2 Statistical Zero-Knowledge</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">ZKPP &mdash; Model and Definitions</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">9</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">12</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4.1 ZKPP for Permutations</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">12</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4.2 Promise Expansion is in HV-SZKPP</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">21</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4.3 Promise Bipartiteness is in HV-SZKPP</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Limitations of SZKPP</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">25</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5.1 IPP &#8840; ESZKPP</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">26</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5.2 MAP &#8840; ESZKPP, assuming Circuit Lower Bounds</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">28</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Computational ZK Proofs and Statistical ZK Arguments of Proximity</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">32</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">A</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Reducing HV-SZKPP to Entropy Difference</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">41</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">&#1042;</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Missing Proofs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">43</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">B.1 Proving Lemma 5.3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">43</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">B.2 Proving Claim 5.16</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">B.3 Proof Sketch of Lemma 5.11</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">B.4 Proof Sketch of Lemma 6.4</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">44</td>
          </tr>
        </tbody>
      </table>
    </div>

    <section id="sec-1" class="mb-10">
      <h2 class="text-2xl font-bold">1 Introduction</h2>

    <p class="text-gray-300">Interactive proofs, introduced by Goldwasser, Micali and Rackoff [GMR89] are protocols that allow for a polynomial-time verifier to check the correctness of a computational statement, typically formulated as membership of an input x in a language  <span class="math">\\mathcal{L}</span> , using an interactive protocol.</p>

    <p class="text-gray-300">Interactive proofs have had an incredible impact on theoretical computer science in general, and especially on cryptography and complexity theory. However, given the vast amounts of data that are available nowadays, in some applications even polynomial running time may be too much.</p>

    <p class="text-gray-300">Erg&uuml;n, Kumar and Rubinfeld [EKR04] asked whether we can obtain proof-systems in which the verifier runs in <em>sub-linear</em> time. In particular, this means that the verifier does not even have time to read the entire input. Since it is impossible to obtain sub-linear verification in general, to obtain a meaningful notion we settle for a suitable notion of approximation. Inspired by the property testing literature [RS96, GGR98] (see also [Gol16]) a recent line of works, initiated by Rothblum, Vadhan and Wigderson [RVW13], focuses on interactive proofs in which soundness is relaxed and the verifier is only required to reject inputs that are <em>far</em> (say, in Hamming distance) from being in the language. Thus, the verifier is only assured that the input x is <em>close</em> to the language  <span class="math">\\mathcal L</span>  and so these proof-systems are called <em>interactive proofs of proximity</em>, or IPPs for short. Recent results ([RVW13, GR16, FGL14, KR15, GGR15, RRR16, GG16, GR17]) have demonstrated that many languages admit very efficient IPPs.</p>

    <p class="text-gray-300">One of the main advantages of classical interactive proofs is that they allow for proving statements in <em>zero-knowledge</em> [GMR89, GMW91]: amazingly, it is possible to prove that  <span class="math">x \\in \\mathcal{L}</span>  without revealing anything other than that. Beyond being of intrinsic interest, zero-knowledge proofs have a multitude of applications.</p>

    <p class="text-gray-300">In this work we initiate the study of <em>zero-knowledge</em> proofs of proximity, or ZKPP for short. Specifically we ask:</p>

    <p class="text-gray-300">Is it possible to prove correctness of a computation to a sub-linear time verifier, so that the verifier does not learn more than it could have learned by reading a few bits from the input?</p>

    <p class="text-gray-300">Loosely speaking, we say that an IPP with prover P and verifier V is a ZKPP, if for any possible cheating verifier  <span class="math">\\hat{V}</span>  that runs in time t = o(N), where here and below N denotes the input length, there exists a simulator  <span class="math">S_{\\hat{V}}</span>  that runs in time roughly t and outputs a view that is indistinguishable from the view of  <span class="math">\\hat{V}</span>  when interacting with P. Note that the bound on the running times for the verifier and the simulator also bounds their query complexity (i.e., the number of bits read from the input).</p>

    <p class="text-gray-300">Interestingly, the notion of ZKPP has already implicitly appeared in the cryptographic literature 20 years ago. Bellare and Yung [BY96] noticed that the soundness of the [FLS99] construction of non-interactive zero-knowledge proof-system (NIZK) from trapdoor permutations breaks, if the cheating prover sends a description of a function that is not a permutation. [BY96] observed that to regain soundness in the [FLS99] protocol, it suffices to verify that the given function is <em>close</em> to being a permutation.</p>

    <p class="text-gray-300">Focusing on the case that the domain of the permutation is  <span class="math">\\{0,1\\}^n</span> , [BY96] suggested the</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;1</sup>We remark that the general case (i.e., when the domain is not  <span class="math">\\{0,1\\}^n</span> ) introduces significant difficulties. See [GR13] and [CL17] for details.</p>

    <p class="text-gray-300">following natural non-interactive zero-knowledge proof for certifying that a function is <em>close</em> to a permutation: the many random elements y1, . . . , y<sup>k</sup> in {0, 1} <sup>n</sup> are specified as part of a common random string<a href="#page-3-1">2</a> (CRS), and the prover is required to provide inverses x1, . . . , x<sup>k</sup> to all of these elements. Soundness follows from the fact that if the function is far from a permutation then, with high probability, one of these elements will simply not have an inverse. Zero-knowledge is demonstrated by having the simulator sample the x's at random and obtain the y's by evaluating the permutation.</p>

    <p class="text-gray-300">Since the verifier in the <a href="#page-39-2">[BY96]</a> protocol is only assured that the function is close to a permutation, in our terminology, the <a href="#page-39-2">[BY96]</a> protocol is a non-interactive ZKPP. Notice that the verifier runs in time poly(n), which is <em>poly-logarithmic</em> in the input (i.e., the truth table of f).</p>

    <p class="text-gray-300"><strong>Knowledge Tightness.</strong> When we consider ZKPP with a poly-logarithmic verifier (as in the foregoing example), it will suffice for us to allow the simulator to run in time that is polynomial in that of the verifier (i.e., also poly-logarithmic time). However, when considering protocols were the verifier runs in time, say <sup>&radic;</sup> N, we cannot afford such a polynomial simulation overhead.<a href="#page-3-2">3</a> Thus, following Goldreich <a href="#page-40-7">[Gol01,</a> Section 4.4.4.2], we will sometimes want to more precisely quantify the simulator's overhead.</p>

    <p class="text-gray-300">As is the case for standard zero-knowledge, the results that we can obtain depend heavily on the specific notion of zero-knowledge. These notions depend on what exactly it means that the output of the simulator is indistinguishable from a real interaction.</p>

    <p class="text-gray-300">The main notion that we consider in this work is that of <em>statistical zero knowledge proofs of proximity</em>. Here, the requirement is that the distribution of the output of the simulator is <em>statistically close</em> to that of the real interaction.</p>

    <p class="text-gray-300">Clearly not every IPP must necessarily be zero-knowledge.<a href="#page-3-3">4</a> Thus, the first natural question to ask is whether this notion is meaningful - do there exist languages with non-trivial statistical ZKPPs? We answer this question affirmatively. Moreover, we show that same natural problem considered by <a href="#page-39-2">[BY96]</a> (i.e., verifying that a function is a permutation) has a very efficient zero-knowledge proof of proximity.<a href="#page-3-4">5</a></p>

    <p class="text-gray-300"><strong>Theorem 1.1</strong> (ZKPP for permutations, Informally Stated)<strong>.</strong> <em>Let</em> PERMUTATION = {f : {0, 1} <sup>n</sup> &rarr; {0, 1} n <em>such that</em> f <em>is a permutation</em>}<em>. Then:</em></p>

    <p class="text-gray-300"><sup>2</sup>Recall that NIZKs inherently require the use of a CRS.</p>

    <p class="text-gray-300"><sup>3</sup>Note that in such a case, if the simulator has a quadratic overhead, than in particular the simulator can read the entire input whereas the verifier cannot.</p>

    <p class="text-gray-300"><sup>4</sup>Consider the following example, due to Fischer <em>et-al.</em> <a href="#page-39-1">[FGL14]</a>. Suppose that we want to check whether a given input consists of two consecutive palindromes (of possibly different lengths) or is far from such. Alon <em>et-al.</em> <a href="#page-38-0">[AKNS00]</a> showed that every property tester must make &Omega;(<sup>&radic;</sup> N) queries. However, if a prover provides the index that separates the two palindromes, the property becomes extremely easy to verify. Needless to say, this proof-system is blatantly not zero-knowledge.</p>

    <p class="text-gray-300"><sup>5</sup>Note that protocol of <a href="#page-39-2">[BY96]</a> immediately yields an <em>honest-verifier</em> zero-knowledge proof of proximity. In contrast, our protocol is zero-knowledge against arbitrary cheating verifiers.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><strong>Property Testing Lower Bound:</strong> Every tester for PERMUTATION must make at least  <span class="math">\\Omega(2^{n/2})</span>  queries to the input (and in particular must run in time  <span class="math">\\Omega(2^{n/2})</span> ).</li>
      <li>ZKPP <strong>Upper Bound:</strong> PERMUTATION has a 4-round statistical ZKPP in which the verifier runs in poly(n) time.</li>
    </ul>

    <p class="text-gray-300">We remark that in this result, and similarly to other results in the literature on (constant-round) statistical zero-knowledge (SZK), we can only bound the expected running time of our simulator. We also remark that Gur and Rothblum [GR15] give a lower bound on the complexity of <em>non-interactive</em> IPPs (i.e., IPP in which the entire interaction consists of a single message from the prover to the verifier, also known as MAPs) for PERMUTATION, and using that result we obtain a sub-exponential separation between the power of statistical ZKPP vs. MAPs.</p>

    <p class="text-gray-300">Beyond the property of permutation we also consider two additional problems, both of which are graph problems and show that they admit efficient <em>honest-verifier</em> ZKPP protocols.<sup>6</sup> Both problems that we consider are in the bounded degree graph model, which has been widely studied in the property testing literature [GGR98, GR02].</p>

    <p class="text-gray-300"><strong>Theorem 1.2</strong> (Honest Verifier ZKPP for Expansion and Bipartiteness, Informally Stated). <em>There exist</em> honest-verifier <em>statistical</em> ZKPP <em>in which the verifier's running time is</em> polylog(N), <em>for input graphs of size</em> N, <em>for the following two promise problems:</em></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><strong>Promise Expansion:</strong> Distinguish graphs with (vertex) expansion  <span class="math">\\alpha</span>  from graphs that are far from even having expansion roughly  <span class="math">\\beta = \\alpha^2/\\log(N)</span> .</li>
    </ol></li>
      <li>2. <strong>Promise Bipartiteness:</strong> Distinguish bipartite graphs from graphs that are rapidly mixing and far from being bipartite.</li>
    </ul>

    <p class="text-gray-300">A few remarks are in order. We first note that the property testing complexity of both promise problems is  <span class="math">\\tilde{\\Theta}(\\sqrt{N})</span>  [GR02, GR11, CS10, NS10, KS11]. Second, the IPP for promise-biparititeness that we use to prove Theorem 1.2 is due to [RVW13] and we merely point out that it is honest-verifier ZKPP. In contrast, the promise-expansion property above was not previously known to admit an (efficient) IPP (let alone an honest-verifier zero-knowledge one). We also remark that both of the problems in Theorem 1.2 refer to <em>promise problems</em>. In particular, we leave open the possibility of a ZKPP for bipartiteness that also handles graphs that are not rapidly mixing, and a ZKPP for expansion that accepts graphs that are  <span class="math">\\alpha</span> -expanding and rejects graphs that are far from  <span class="math">\\alpha</span> -expanding (rather than just those that are far from being  <span class="math">\\alpha^2/\\log(N)</span> -expanding as in Theorem 1.2). Lastly, we also leave open the possibility of extending these protocols to be statistical ZKPP against arbitrary cheating verifiers (rather than just honest verifiers).<sup>7</sup></p>

    <p class="text-gray-300"><strong>Limitations of Statistical</strong> ZKPP. Given these feasibility results, one may wonder whether statistical ZKPP are as powerful as IPPs. That is, can every IPP be converted to be statistically zero-knowledge with small overhead? We show that this is not the case:</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;6</sup>In such protocols, the simulator needs only to output an interaction that is indistinguishable from the interaction of the honest (original) verifier and the prover.</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;7</sup>Since honest-verifier SZK protocols can be converted to be zero-knowledge against arbitrary malicious verifiers ([GSV98], see also [Vad99]), it is reasonable to wonder whether the same holds for statistical ZKPP. We conjecture that this is the case but leave the question of verifying this conjecture to future work.</p>

    <p class="text-gray-300"><strong>Theorem 1.3</strong> (IPP * SZKPP, Informally Stated)<strong>.</strong> <em>There exists a property</em> &Pi; <em>that has an</em> IPP <em>in which the verifier runs in</em> polylog(N) <em>time, where</em> N <em>is the input length, but</em> &Pi; <em>does not have a statistical</em> ZKPP <em>in which the verifier runs even in time</em> No(1) <em>.</em></p>

    <p class="text-gray-300">We note that <a href="#page-5-0">Theorem 1.3</a> is unconditional. Interestingly, if we do allow for assumptions, then we can even separate MAP from SZKPP:</p>

    <p class="text-gray-300"><strong>Theorem 1.4</strong> (MAP * SZKPP, Informally Stated)<strong>.</strong> <em>Assuming certain circuit lower bounds, there exists a property</em> &Pi; <em>that has an</em> MAP <em>in which the verifier runs in</em> polylog(N) <em>time, where</em> N <em>is the input length, but</em> &Pi; <em>does not have a statistical</em> ZPP <em>in which the verifier runs even in time</em> No(1) <em>.</em></p>

    <p class="text-gray-300">The circuit lower bound that we use follows from the (highly plausible) assumption that the Arthur-Merlin communication complexity of disjointness is n &epsilon; , where n is the input length and &epsilon; &gt; 0 is some constant.</p>

      <h4 id="sec-1.1.2" class="text-lg font-semibold mt-6"><strong>1.1.2 The Computational Setting</strong></h4>

    <p class="text-gray-300">As is the case in the classical setting, we can obtain much stronger results if we either (1) only require that the simulated view be <em>computationally</em> indistinguishable from the real interaction (i.e., computational zero-knowledge), or (2) only require soundness against <em>efficient</em> cheating provers (i.e., computational soundness or argument).</p>

    <p class="text-gray-300">The following results show that under these relaxations, and assuming reasonable cryptographic assumptions, we can transform many of the known results from the literature of IPPs to be zero-knowledge. Focusing on computational zero-knowledge, we can derive such protocols for any language computable in bounded-depth or in bounded-space, where the verifier runs in roughly <sup>&radic;</sup> N time.</p>

    <p class="text-gray-300"><strong>Theorem 1.5</strong> (Computational ZKPP for Bounded Depth, Informally Stated)<strong>.</strong> <em>Assume that there exist one-way functions. Then, every language in logspace-uniform</em> NC<em>, has a computational</em> ZKPP<em>, where the verifier (and the simulator) run in time</em> N <sup>2</sup> <sup>+</sup>o(1) <em>and the number of rounds is</em> polylog(N)<em>.</em></p>

    <p class="text-gray-300"><strong>Theorem 1.6</strong> (Computational ZKPP for Bounded Space, Informally Stated)<strong>.</strong> <em>Assume that there exist one-way functions. Then, every language computable in</em> poly(N)<em>-time and</em> O(N<sup>&sigma;</sup> )<em>-space, for some sufficiently small constant</em> &sigma; &gt; 0<em>, has a computational</em> ZKPP<em>, where the verifier (and the simulator) run in time</em> N 1 <sup>2</sup> +O(&sigma;) <em>.</em></p>

    <p class="text-gray-300">Interestingly, if we only require <em>computational soundness</em>, we can do even better. The following result gives <em>statistical</em> zero-knowledge arguments of proximity for every language in NP, and with a verifier that runs in <em>poly-logarithmic</em> time.</p>

    <p class="text-gray-300"><strong>Theorem 1.7</strong> (Statistical Zero-Knowledge Arguments for NP, Informally Stated)<strong>.</strong> <em>Assume that there exist collision-resistant hash functions. Then, every language in</em> NP<em>, has a constant-round</em> statistical <em>zeroknowledge argument of proximity, where the verifier runs in time</em> polylog(N)<em>.</em></p>

    <p class="text-gray-300">We note that <a href="#page-5-1">Theorems 1.5</a> to <a href="#page-5-2">1.7</a> strongly rely on (1) results from the literature on IPPs <a href="#page-42-2">[RVW13,</a> <a href="#page-42-3">RRR16]</a> and interactive arguments of proximity <a href="#page-41-5">[Kil92,</a> <a href="#page-39-6">BGH</a>+06, <a href="#page-39-7">DR06]</a>, (2) a method introduced by <a href="#page-39-8">[BGG</a>+88] for transforming interactive proofs (and arguments) into zero-knowledge ones (while taking some additional care that is not required in the classical setting), and (3) the observation that the verifiers in many of the underlying protocols all make queries that do not depend on messages sent by the prover. See <a href="#page-33-0">Section 6</a> for details.</p>

      <h3 id="sec-1.2" class="text-xl font-semibold mt-8">1.2 Additional Related Works</h3>

    <p class="text-gray-300">A related notion of <em>zero-knowledge</em> PCPs of proximity was recently considered by Ishai and Weiss [IW14]. These are PCP systems in which, the verifier gets oracle access to both the input and to an alleged proof. Similarly to our notion of ZKPP, the verifier runs in sublinear and is assured (with high probability) that the input is close to the language. Here, zero-knowledge means that the verifier learns nothing more than what it could simulate by making few queries to the input. We emphasize that the difference between our model and that of [IW14] is that we consider <em>interactice</em> proofs, whereas [IW14] focus on PCP-style proofs: namely soundness is guaranteed only if the PCP proof string is written in advance.</p>

    <p class="text-gray-300">A recent work by Ben-Sasson <em>et-al</em>. [BCF<sup>+</sup>16] studies zero-knowledge interactive oracle proofs - in a model in which the verifier receives <em>oracle</em> access to the communication tape, but full access to the input.<sup>8</sup> Our model of ZKPP is reversed - the verifier has oracle access to the input but full access to the communication tape.</p>

    <p class="text-gray-300"><strong>Organization.</strong> General notations and definitions used throughout the paper are given in Section 2. The model of zero-knowledge proofs of proximity (ZKPP) is defined in Section 3. Our statistical ZKPP protocols for Permutations, Expansion and Bipartiteness, are presented and analyzed in Section 4, while our lower bounds for statistical ZKPP are in Section 5. Finally, in Section 6 we present our results on computational ZK proofs of proximity and the statistical ZK arguments of proximity.</p>

    </section>

    <section id="sec-2" class="mb-10">
      <h2 class="text-2xl font-bold">2 Preliminaries</h2>

    <p class="text-gray-300">We use calligraphic letters to denote sets, uppercase for random variables, lowercase for values and functions, boldface for vectors, and uppercase sans-serif (e.g., A) for algorithms (i.e., Turing Machines). All logarithms considered here are in base two. Given a random variable X, we write  <span class="math">x \\leftarrow X</span>  to indicate that x is selected according to X. Similarly, given a finite set S, we let S denote that S is selected according to the uniform distribution on S. For an interactive protocol (A, B), let S output in a random execution of (A, B) (usually, A will be some prover and B will be an honest verifier).</p>

    <p class="text-gray-300">The relative distance, over alphabet  <span class="math">\\Sigma</span> , between two strings  <span class="math">x \\in \\Sigma^n</span>  and  <span class="math">y \\in \\Sigma^n</span>  is defined by  <span class="math">\\Delta(x,y) := \\frac{|\\{x_i \\neq y_i : i \\in [n]\\}|}{n}</span> . If  <span class="math">\\Delta(x,y) \\leq \\varepsilon</span> , we say that x is  <span class="math">\\varepsilon</span> -close to y, and otherwise we say that x is  <span class="math">\\varepsilon</span> -far from y. Similarly, we define the relative distance of x from a non-empty set  <span class="math">S \\subseteq \\Sigma^n</span>  by  <span class="math">\\Delta(x,S) := \\min_{y \\in S} \\Delta(x,y)</span> . If  <span class="math">\\Delta(x,y) \\leq \\varepsilon</span> , we say that x is  <span class="math">\\varepsilon</span> -close to S, and otherwise we say that x is  <span class="math">\\varepsilon</span> -far from S. The bitwise exclusive-or between two binary strings  <span class="math">x,y \\in \\{0,1\\}^n</span>  is denoted by  <span class="math">x \\oplus y</span> . The statistical distance between two distributions P and Q over a finite set  <span class="math">\\mathcal{U}</span> , is defined as  <span class="math">\\mathrm{SD}(P,Q) := \\max_{S \\subseteq \\mathcal{U}} |P(S) - Q(S)| = \\frac{1}{2} \\sum_{u \\in \\mathcal{U}} |P(u) - Q(u)|</span>  and their product distribution is denoted by  <span class="math">P \\otimes B</span> .</p>

    <p class="text-gray-300">The image of a function  <span class="math">f\\colon \\mathcal{X} \\to \\mathcal{Y}</span>  is defined as  <span class="math">\\mathrm{Im}(f) = \\{y \\in \\mathcal{Y}\\colon \\exists x \\in \\mathcal{X}\\,, f(x) = y\\}</span> . An additional notation that we will use is that if  <span class="math">S = (S_k)_{k \\in \\mathbb{N}}</span>  and  <span class="math">T = (T_k)_{k \\in \\mathbb{N}}</span>  are ensembles of sets, we denote by  <span class="math">S \\subseteq T</span>  the fact that  <span class="math">S_k \\subseteq T_k</span>  for every  <span class="math">k \\in \\mathbb{N}</span> .</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;8</sup>Interactive proofs in which the verifier is not charged for reading the entire communication tape are called either <em>probabilistically checkable interactive proofs</em> [RRR16] or <em>interactive oracle proofs</em> [BCS16] in the literature.</p>

      <h3 id="sec-2.1" class="text-xl font-semibold mt-8">2.1 Hashing and Entropy</h3>

      <h4 id="sec-2.1.1" class="text-lg font-semibold mt-6">2.1.1 Entropy</h4>

    <p class="text-gray-300"><strong>Definition 2.1</strong> (Entropy). The entropy of a discrete random variable X is defined as</p>

    <p class="text-gray-300"><span class="math">$H(X) := E_{x \\leftarrow X} \\left[ \\log \\left( \\frac{1}{\\Pr[X = x]} \\right) \\right].</span>$</p>

    <p class="text-gray-300">The binary entropy function  <span class="math">h: [0,1] \\to [0,1]</span>  is defined to be the entropy of  <span class="math">X \\sim \\text{Bernoulli}(p)</span> , that is,  <span class="math">h(p) = -p \\log(p) - (1-p) \\log(1-p)</span> , where we use the convention that h(0) = h(1) = 0.</p>

    <p class="text-gray-300">Another notion of entropy that we shall use is that that of (conditional) average min-entropy.</p>

    <p class="text-gray-300"><strong>Definition 2.2</strong> (average min-entropy [DORS08]). Let X, Y be jointly distributed random variables. The average min-entropy of X given Y is defined by</p>

    <p class="text-gray-300"><span class="math">$\\widetilde{H}_{\\infty}(X|Y) := -\\log\\left(\\mathbb{E}_{y \\leftarrow Y}\\left[\\max_{x} \\Pr[X = x \\mid Y = y]\\right]\\right).</span>$</p>

    <p class="text-gray-300">The following fact follows immediately from the above definition.</p>

    <p class="text-gray-300"><strong>Fact 2.3.</strong> Let  <span class="math">X^n, Y^n</span>  be n-tuples of independent copies of the random variables X and Y respectively. Then  <span class="math">\\tilde{H}_{\\infty}(X^n|Y^n) = n \\cdot \\tilde{H}_{\\infty}(X|Y)</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> We prove for the case that n=2. The general case follows by induction.</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\tilde{\\mathbf{H}}_{\\infty}(X^{2}|Y^{2}) &amp;= -\\log \\left( \\mathbf{E}_{(y_{1},y_{2})\\leftarrow Y^{2}} \\left[ \\max_{x_{1},x_{2}} \\Pr[X^{2} = (x_{1},x_{2}) \\mid Y^{2} = (y_{1},y_{2})] \\right] \\right) \\\\ &amp;= -\\log \\left( \\mathbf{E}_{(y_{1},y_{2})\\leftarrow Y^{2}} \\left[ \\max_{x_{1},x_{2}} \\Pr[X = x_{1} \\mid Y = y_{1}] \\cdot \\Pr[X = x_{2} \\mid Y = y_{2}] \\right] \\right) \\\\ &amp;= -\\log \\left( \\mathbf{E}_{(y_{1},y_{2})\\leftarrow Y^{2}} \\left[ \\max_{x_{1}} \\Pr[X = x_{1} \\mid Y = y_{1}] \\cdot \\max_{x_{2}} \\Pr[X = x_{2} \\mid Y = y_{2}] \\right] \\right), \\end{split}</span>$</p>

    <p class="text-gray-300">where the second inequality follows since the first sample from (X,Y) is independent from the second one, and thre third inequality follows since for non-negative functions f,g, it holds that  <span class="math">\\max_{x_1,x_2} f(x_1) \\cdot g(x_2) = \\max_{x_1} f(x_1) \\cdot \\max_{x_2} g(x_2)</span> . Letting  <span class="math">h(y) = \\max_x \\Pr[X = x \\mid Y = y]</span> , we write</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\tilde{\\mathbf{H}}_{\\infty}(X^{2}|Y^{2}) &amp;= -\\log \\left( \\mathbf{E}_{(y_{1},y_{2})\\leftarrow Y^{2}}[h(y_{1})\\cdot h(y_{2})] \\right) \\\\ &amp;= -\\log (\\mathbf{E}_{y_{1}\\leftarrow Y}[h(y_{1})]\\cdot \\mathbf{E}_{y_{2}\\leftarrow Y}[h(y_{2})]) \\\\ &amp;= -\\log (\\mathbf{E}_{y_{1}\\leftarrow Y}[h(y_{1})]) - \\log (\\mathbf{E}_{y_{2}\\leftarrow Y}[h(y_{2})]) \\\\ &amp;= \\tilde{\\mathbf{H}}_{\\infty}(X|Y) + \\tilde{\\mathbf{H}}_{\\infty}(X|Y), \\end{split}</span>$</p>

    <p class="text-gray-300">where the second inequality follows since the first sample of <em>Y</em> is independent of the second one.</p>

      <h4 id="sec-2.1.2" class="text-lg font-semibold mt-6">2.1.2 Hashing</h4>

    <p class="text-gray-300"><strong>Definition 2.4</strong> (pairwise independent hash functions). A family of functions  <span class="math">\\mathcal{H} = \\{h : [N] \\to [M]\\}</span>  is pairwise independent if for every  <span class="math">x_1 \\neq x_2 \\in [N]</span>  and every  <span class="math">y_1, y_2 \\in [M]</span> , it holds that</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{h \\leftarrow \\mathcal{H}}[h(x_1) = y_1 \\land h(x_2) = y_2] = \\frac{1}{M^2}.</span>$</p>

    <p class="text-gray-300">The existence of efficient pairwise independent hash functions is well known.</p>

    <p class="text-gray-300"><strong>Fact 2.5</strong> (c.f. [Vad12, Theorem 3.26]). For every  <span class="math">n, m \\in \\mathbb{N}</span> , there exists a family of pairwise independent hash functions  <span class="math">\\mathcal{H}_{n,m} = \\{h : \\{0,1\\}^n \\to \\{0,1\\}^m\\}</span>  where a random function from  <span class="math">\\mathcal{H}_{n,m}</span>  can be selected using  <span class="math">\\max(m,n) + m</span>  bits, and given a description of  <span class="math">h \\in \\mathcal{H}_{n,m}</span>  and  <span class="math">x \\in \\{0,1\\}^n</span> , the value h(x) can be evaluated in time  <span class="math">\\operatorname{poly}(n,m)</span> .</p>

    <p class="text-gray-300">Dodis <em>et-al.</em> [DORS08], showed the following generalization of the leftover hash lemma, for sources having high <em>conditional</em> min-entropy.</p>

    <p class="text-gray-300"><strong>Lemma 2.6</strong> (generalized leftover hash lemma [DORS08, Lemma 2.4]). Let  <span class="math">\\mathcal{H} = \\{h : \\{0,1\\}^n \\to \\{0,1\\}^m\\}</span>  be a family of pairwise independent hash functions. Then, for any random variables X and Y and the random variable  <span class="math">H \\leftarrow \\mathcal{H}</span> , it holds that</p>

    <p class="text-gray-300"><span class="math">$\\operatorname{SD}((H(X), H, Y), (U_m, H, Y)) \\leq \\frac{1}{2} \\cdot \\sqrt{2^{-\\tilde{H}_{\\infty}(X|Y)} \\cdot 2^m},</span>$</p>

    <p class="text-gray-300">where  <span class="math">U_m</span>  is distributed uniformly over  <span class="math">\\{0,1\\}^m</span> .</p>

    <p class="text-gray-300">We use standard definitions and results from the literature of statistical zero-knowledge proofs, based mainly on [Vad99].</p>

      <h4 id="sec-2.2.1" class="text-lg font-semibold mt-6">2.2.1 Statistical Zero-Knowledge Interactive Proofs</h4>

    <p class="text-gray-300">In this section we give the (almost) standard definitions for interactive proofs and honest-verifier zero-knowledge proofs.</p>

    <p class="text-gray-300"><strong>Definition 2.7</strong> (interactive proofs). Let  <span class="math">\\Pi = (\\Pi_{YES}, \\Pi_{NO})</span>  be a promise problem. An interactive proof system for  <span class="math">\\Pi</span>  is an interactive protocol (P, V) with completness error  <span class="math">c \\colon \\mathbb{N} \\to [0, 1]</span>  and soundness error  <span class="math">s \\colon \\mathbb{N} \\to [0, 1]</span>  if the following holds for every security parameter  <span class="math">k \\in \\mathbb{N}</span> :</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Completeness: If  <span class="math">x \\in \\Pi_{YES}</span> , then, when V(x, k) interacts with P(x, k), with probability 1 c(k) it accepts.</li>
      <li>Soundness: If  <span class="math">x \\in \\Pi_{NO}</span> , then for every prover strategy  <span class="math">\\widehat{P}</span> , when V(x,k) interacts with  <span class="math">\\widehat{P}</span> , with probability 1 s(k) it rejects.</li>
    </ul>

    <p class="text-gray-300">If  <span class="math">c(\\cdot)</span>  and  <span class="math">s(\\cdot)</span>  are negligible functions, we say that (P,V) is an interactive proof system.</p>

    <p class="text-gray-300">The above definition does not deal with the efficiency of the verifier or the prover, unlike the standard definition that requires the verifier to run in time poly(|x|,k). Jumping ahead, this is because in our settings the verifier (and also the simulator) will have only oracle-access to their inputs. We will refer to the efficiency of those algorithms within theorem statements.</p>

    <p class="text-gray-300"><strong>Definition 2.8</strong> (view of interactive protocol). Let (P, V) be an r-message interactive protocol. The view of V on a common input x (given as standard input or by oracle access to either of the parties) is defined by  <span class="math">\\text{view}_{P,V}(x) := (m_1, m_2, \\ldots, m_r; \\rho)</span> , where  <span class="math">m_1, m_2, \\ldots, m_r</span>  are the messages sent by the parties in a random execution of the protocol, and  <span class="math">\\rho</span>  contains of all the random coins V used during this execution.</p>

    <p class="text-gray-300">We allow probabilistic algorithms to fail by outputting  <span class="math">\\bot</span> . An algorithm A is useful if  <span class="math">\\Pr[A(x) = \\bot] \\le 1/2</span>  for every x, and let  <span class="math">\\widetilde{A}(x)</span>  denote the output distribution of A(x), conditioning on  <span class="math">A(x) \\ne \\bot</span> .</p>

    <p class="text-gray-300"><strong>Definition 2.9</strong> (honest-verifier zero-knowledge proofs). Let  <span class="math">\\Pi = (\\Pi_{YES}, \\Pi_{NO})</span>  be a promise problem. An interactive proof (P, V) for  <span class="math">\\Pi</span>  is said to be honest-verifier statistical zero-knowledge, if there exists an algorithm S, and a negligible function  <span class="math">\\mu \\colon \\mathbb{N} \\to [0, 1]</span>  such that for every  <span class="math">k \\in \\mathbb{N}</span>  and  <span class="math">x \\in \\Pi_{YES}</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\mathrm{SD}\\left(\\widetilde{\\mathsf{S}}(x,k),\\mathrm{view}_{\\mathsf{P},\\mathsf{V}}(x,k)\\right) \\leq \\mu(k).</span>$</p>

      <h4 id="sec-2.2.2" class="text-lg font-semibold mt-6">2.2.2 Statistical Distance, Entropy Difference and Sample-Access Proofs</h4>

    <p class="text-gray-300">Central in the study of statistical zero-knowledge are problems dealing with properties of distributions encoded by circuits.</p>

    <p class="text-gray-300"><strong>Definition 2.10</strong> (distributions encoded by circuits). Let X be a Boolean circuit with m input gates and n output gates. The distribution encoded by X is the distribution induced on  <span class="math">\\{0,1\\}^n</span>  by evaluating X on a uniformly selected string from  <span class="math">\\{0,1\\}^m</span> . By abuse of notation, we also write X for the distribution defined by the circuit X.</p>

    <p class="text-gray-300">Two particularly interesting problems are <em>statistical distance</em> and <em>entropy difference</em>.</p>

    <p class="text-gray-300"><strong>Definition 2.11</strong> (Statistical Distance). For any constants  <span class="math">0 \\le \\beta \\le \\alpha \\le 1</span> , the promise problem  <span class="math">SD^{\\alpha,\\beta} = (SD^{\\alpha,\\beta}_{YES}, SD^{\\alpha,\\beta}_{NO})</span>  is given by</p>

    <p class="text-gray-300"><span class="math">$SD_{\\mathsf{YES}}^{\\alpha,\\beta} = \\{(X,Y) \\colon SD(X,Y) \\ge \\alpha\\}</span>$</p>

    <p class="text-gray-300"><span class="math">$SD_{\\mathsf{NO}}^{\\alpha,\\beta} = \\{(X,Y) \\colon SD(X,Y) \\le \\beta\\}.</span>$</p>

    <p class="text-gray-300">Above, X, Y are distributions encoded by circuits according to Definition 2.10.</p>

    <p class="text-gray-300"><strong>Definition 2.12</strong> (Entropy Difference). Entropy Difference is the promise problem  <span class="math">ED = (ED_{YES}, ED_{NO})</span> , where</p>

    <p class="text-gray-300"><span class="math">$\\begin{aligned} \\mathsf{ED}_{\\mathsf{YES}} &amp;= \\{ (X,Y) \\colon \\, \\mathsf{H}(X) \\geq \\mathsf{H}(Y) + 1 \\}, \\\\ \\mathsf{ED}_{\\mathsf{NO}} &amp;= \\{ (X,Y) \\colon \\, \\mathsf{H}(Y) \\geq \\mathsf{H}(X) + 1 \\}. \\end{aligned}</span>$</p>

    <p class="text-gray-300">Above, X, Y are distributions encoded by circuits according to Definition 2.10.</p>

    <p class="text-gray-300">Both SD and ED are known to be complete for the class of problems that have statistical zero-knowledge proofs (see [Vad99, Theorem 3.5.1]). A fact that we will rely on heavily, is that the zero-knowledge proof-systems for SD and ED only require <em>sample</em> access to the distributions induced by the input circuits. That is, neither the verifier not the simulator in these proof-systems need to actually look at the circuits themselves. Rather, all that they need is the ability to generate random samples from the circuits.</p>

    <p class="text-gray-300"><strong>Definition 2.13</strong> (sample-access honest-verifier zero-knowledge proof). Let  <span class="math">\\Pi</span>  be a promise problem whose instances are pairs of distributions encoded by circuits. An honest-verifier zero-knowledge proof system for  <span class="math">\\Pi</span>  is sample-access if both the verifier and the simulator only require oracle access to random samples from the distributions encoded by the input circuits (in addition to explicitly getting the security parameter k).</p>

    <p class="text-gray-300">We can now state the results regarding the zero-knowledge proof systems of SD and ED. In fact, we will not care about SD but rather about <em>statistical closeness</em>, the complement of SD in which the YES and NO instances are switched, namely  <span class="math">\\overline{\\mathsf{SD}^{\\alpha,\\beta}} := \\left(\\mathsf{SD}^{\\alpha,\\beta}_{\\mathsf{NO}}, \\mathsf{SD}^{\\alpha,\\beta}_{\\mathsf{YES}}\\right)</span> .</p>

    <p class="text-gray-300"><strong>Lemma 2.14.</strong> Let  <span class="math">0 \\le \\beta \\le \\alpha \\le 1</span>  be constants such that  <span class="math">h((1+\\alpha)/2) &lt; 1-\\beta</span> . Then, there exists a 2-message sample-access honest-verifier statistical zero-knowledge proof for  <span class="math">\\overline{\\mathsf{SD}^{\\alpha,\\beta}}</span> . Moreover, the running times of the verifier and the simulator in the above protocol given sample access to (X,Y) and security parameter k are  <span class="math">\\mathsf{poly}(m,n,k)</span> , where m is the number of random coins needed to sample from X or Y (i.e., their input size) and n is the output size of X and Y.</p>

    <p class="text-gray-300">The protocol establishing Lemma 2.14 reduces, in a black-box way, an instance of  <span class="math">\\overline{\\mathsf{SD}^{\\alpha,\\beta}}</span>  to ED (see [Vad99, Section 4.4]) and then uses the next lemma.</p>

    <p class="text-gray-300"><strong>Lemma 2.15.</strong> There exists 2-message sample-access honest-verifier statistical zero-knowledge proof for ED. Moreover, the running times of the verifier and the simulator in the above protocol given sample access to (X,Y) and security parameter k are  <span class="math">\\mathsf{poly}(m,n,k)</span> , where m is the number of random coins needed to sample from X or Y (i.e., their input size) and n is the output size of X and Y.</p>

    <p class="text-gray-300">In this section we formally define the model of <em>statistical</em> zero-knowledge proofs of proximity. We follow definition choices from the literature of classical statistical zero-knowledge proofs, mainly based on [Vad99] (see Section 2.2.2). For a discussion about the computational setting, see Remark 3.7 below.</p>

    <p class="text-gray-300">Properties will be identified as sets of functions. A propery is an ensemble  <span class="math">\\Pi = (\\Pi_n, \\mathcal{D}_n, \\mathcal{R}_n)_{n \\in \\mathbb{N}}</span> , where  <span class="math">\\Pi_n \\subseteq \\mathcal{F}_{\\mathcal{D}_n \\to \\mathcal{R}_n}</span>  for every  <span class="math">n \\in \\mathbb{N}</span> , letting  <span class="math">\\mathcal{F}_{\\mathcal{D} \\to \\mathcal{R}}</span>  denote the set of all functions from domain  <span class="math">\\mathcal{D}</span>  to range  <span class="math">\\mathcal{R}</span> . Equivalently, we sometimes view  <span class="math">\\Pi_n</span>  as a string of length  <span class="math">|\\mathcal{D}_n|</span>  over the alphabet  <span class="math">\\mathcal{R}_n</span>  and write  <span class="math">\\Pi_n \\subseteq \\mathcal{R}_n^{|\\mathcal{D}_n|}</span> . For a property  <span class="math">\\Pi</span>  and  <span class="math">n \\in \\mathbb{N}</span> , let  <span class="math">N_{\\Pi}(n) := |\\mathcal{D}_n| \\cdot \\log(|\\mathcal{R}_n|)</span>  denote the inputsize of  <span class="math">\\Pi_n</span> . Throughout this paper we remove  <span class="math">\\Pi</span>  and n from the above notation, and simply let N denote the input-size of the relevant property (this will be convenient when defining complexity classes; see ahead). We note that, depending on the context, we will sometimes refer to properties as languages. Lastly, similar to [Vad99], we use a security parameter to control our soundness and zero-knowledge guarantees (see Remark 3.6 for additional details).</p>

    <p class="text-gray-300"><strong>Definition 3.1</strong> (interactive proofs of proximity (IPP)). An r-message interactive proof of proximity (IPP), with respect to proximity parameter  <span class="math">\\varepsilon &gt; 0</span> , (in short,  <span class="math">\\varepsilon</span> -IPP) for the property  <span class="math">\\Pi = (\\Pi_n, \\mathcal{D}_n, \\mathcal{R}_n)_{n \\in \\mathbb{N}}</span>  is an interactive protocol (P, V) between a prover P, which gets free access to an input  <span class="math">f: \\mathcal{D}_n \\to \\mathcal{R}_n</span>  as well as to  <span class="math">\\varepsilon</span> ,  <span class="math">|\\mathcal{D}_n|</span> ,  <span class="math">|\\mathcal{R}_n|</span>  and k, and a verifier V, which gets oracle access to f as well as free access to  <span class="math">\\varepsilon</span> , n,  <span class="math">|\\mathcal{D}_n|</span> ,  <span class="math">|\\mathcal{R}_n|</span>  and k. The following conditions are satisfied at the end of the protocol for every  <span class="math">k \\in \\mathbb{N}</span>  and large enough  <span class="math">n \\in \\mathbb{N}</span> :</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;9</sup>Recall that we use h to denote the binary entropy function  <span class="math">h(p) = -p \\log(p) - (1-p) \\log(1-p)</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Completeness: If  <span class="math">f \\in \\Pi_n</span> , then, when V interacts with P, with probability 1 negl(k) it accepts.</li>
      <li><strong>Soundness</strong>: If f is  <span class="math">\\varepsilon</span> -far from  <span class="math">\\Pi_n</span> , then for every prover strategy  <span class="math">\\widehat{P}</span> , when V interacts with  <span class="math">\\widehat{P}</span> , with probability 1 negl(k) it rejects.</li>
    </ul>

    <p class="text-gray-300">For  <span class="math">t = t(n, |\\mathcal{D}_n|, |\\mathcal{R}_n|, k, \\varepsilon)</span> , IPP[t] denotes the class of properties possessing  <span class="math">\\varepsilon</span> -IPP in which the verifier's running time is at most O(t). Finally, for a class of functions  <span class="math">\\mathcal{C}</span> , we denote by IPP[ <span class="math">\\mathcal{C}(n, |\\mathcal{D}_n|, |\\mathcal{R}_n|, k, \\varepsilon)</span> ] the class of properties  <span class="math">\\Pi</span>  for which there exists  <span class="math">t \\in \\mathcal{C}</span>  such that  <span class="math">\\Pi \\in \\mathsf{IPP}[t]</span> .</p>

    <p class="text-gray-300">The probabilities that the verifier rejects in the completeness condition and accepts in the soundness condition are called the completeness error and soundness error, respectively. If the completeness condition holds with probability 1, then we say that the IPP has perfect completeness. A public-coin IPP is an IPP in which every message from the verifier to the prover consists only of fresh random coin tosses.</p>

    <p class="text-gray-300">An IPP is said to have query complexity  <span class="math">q\\colon \\mathbb{N}\\times\\mathbb{N}\\times\\mathbb{N}\\times\\mathbb{N}\\times(0,1]\\to\\mathbb{N}</span>  if for every  <span class="math">n,k\\in\\mathbb{N}</span> ,  <span class="math">\\varepsilon&gt;0</span> ,  <span class="math">x\\in\\mathcal{F}_{\\mathcal{D}_n\\to\\mathcal{R}_n}</span> , and any prover strategy  <span class="math">\\widehat{\\mathsf{P}}</span> , the verifier  <span class="math">\\mathsf{V}</span>  makes at most  <span class="math">q(n,|\\mathcal{D}_n|,|\\mathcal{R}_n|,k,\\varepsilon)</span>  queries to x when interacting with  <span class="math">\\widehat{\\mathsf{P}}</span> . The IPP is said to have communication complexity  <span class="math">c\\colon\\mathbb{N}\\times\\mathbb{N}\\times\\mathbb{N}\\times(0,1]\\to\\mathbb{N}</span>  if for every  <span class="math">n,k\\in\\mathbb{N},\\varepsilon&gt;0</span> , and  <span class="math">x\\in\\mathcal{F}_{\\mathcal{D}_n\\to\\mathcal{R}_n}</span>  the communication between  <span class="math">\\mathsf{V}</span>  and  <span class="math">\\mathsf{P}</span>  consists of at most  <span class="math">c(n,|\\mathcal{D}_n|,|\\mathcal{R}_n|,k,\\varepsilon)</span>  bits.</p>

    <p class="text-gray-300">Our main (but not exclusive) focus in this work is on properties that have IPPs in which the verifier's running time (and thus also the communication and query complexities) is poly-logarithmic in the input size and polynomial in the security parameter k and in the reciprocal of the proximity parameter  <span class="math">1/\\varepsilon</span> , that is, the class IPP[poly(log(N), k,  <span class="math">1/\\varepsilon</span> )].</p>

    <p class="text-gray-300">An IPP that consists of a single message sent from the prover (Merlin) to the verifier (Arthur) is called Merlin-Arthur proof of proximity (MAP). We extend all the above notations to Merlin-Arthur proofs of proximity in the natural way.</p>

    <p class="text-gray-300">Before defining general ZKPPs, we first consider zero-knowledge with respect to <em>honest verifiers</em>.</p>

    <p class="text-gray-300"><strong>Definition 3.2</strong> (honest-verifier zero-knowledge proof of proximity (HV-SZKPP, HV-PZKPP)). <em>Let</em> (P, V) <em>be an interactive proof of proximity for a property</em>  <span class="math">\\Pi = (\\Pi_n, \\mathcal{D}_n, \\mathcal{R}_n)_{n \\in \\mathbb{N}}</span> . <em>The protocol</em> (P, V) <em>is said to be</em> honest-verifier statistical zero-knowledge with simulation overhead s, for some function  <span class="math">s \\colon \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N}</span></p>

    <p class="text-gray-300"><span class="math">$\\mathrm{SD}\\Big(\\widetilde{\\mathsf{S}}^f(\\varepsilon,n,|\\mathcal{D}_n|,|\\mathcal{R}_n|,k),\\mathrm{view}_{\\mathsf{P},\\mathsf{V}}(\\varepsilon,n,|\\mathcal{D}_n|,|\\mathcal{R}_n|,k,f)\\Big) \\leq \\mathsf{negl}(k).</span>$</p>

    <p class="text-gray-300">If the negl(k) can be replaced with 0 in the above equation, (P, V) is said to be honest-verifier perfect zero-knowledge with simulation overhead s.</p>

    <p class="text-gray-300">For  <span class="math">t = t(n, |\\mathcal{D}_n|, |\\mathcal{R}_n|, k, \\varepsilon)</span> , HV-SZKPP[t, s] (resp., HV-PZKPP[t, s]) denotes the class of properties possessing honest-verifier statistical (resp., perfect) zero-knowledge proof of proximity with simulation overhead s in which the verifier's running time is at most O(t).</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;10</sup>Recall that an algorithm A is useful if  <span class="math">\\Pr[A(x) = \\bot] \\le 1/2</span>  for every x, and that  <span class="math">\\widetilde{A}(x)</span>  denote the output distribution of A(x), conditioning on  <span class="math">A(x) \\ne \\bot</span> .</p>

    <p class="text-gray-300">We say that the query complexity of a simulator S is  <span class="math">q&#x27; : \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times (0,1] \\to \\mathbb{N}</span>  if for every  <span class="math">n, k \\in \\mathbb{N}</span> ,  <span class="math">\\varepsilon &gt; 0</span> ,  <span class="math">f \\in \\mathcal{F}_{\\mathcal{D}_n \\to \\mathcal{R}_n}</span> ,  <span class="math">S_n^f</span>  makes at most  <span class="math">q&#x27;(n, |\\mathcal{D}_n|, |\\mathcal{R}_n|, k, \\varepsilon)</span>  queries to f.</p>

    <p class="text-gray-300">A typical setting (that we will focus on) is when the verifier's running time is  <span class="math">\\operatorname{poly}(\\log(N), k, 1/\\varepsilon)</span> , namely poly-logarithmic in the input length N and polynomial in the security parameter k and in the proximity parameter  <span class="math">1/\\varepsilon</span> . In this setting we often allow for  <span class="math">\\operatorname{polynomial}</span>  simulation overhead, that is the simulator's running time is also  <span class="math">\\operatorname{poly}(\\log(N), k, 1/\\varepsilon)</span> . Specifically, we denote by  <span class="math">\\operatorname{HV-SZKPP}[\\operatorname{poly}(\\log(N), k, 1/\\varepsilon)]</span>  the class of properties  <span class="math">\\Pi \\in \\operatorname{HV-SZKPP}[t, s]</span>  for  <span class="math">t = \\operatorname{poly}(\\log(N), k, 1/\\varepsilon)</span>  and  <span class="math">s = \\operatorname{poly}(t, \\log(N), k, 1/\\varepsilon)</span> . The class  <span class="math">\\operatorname{HV-PZKPP}[\\operatorname{poly}(\\log(N), k, 1/\\varepsilon)]</span>  is similarly defined.</p>

    <p class="text-gray-300">Another setting of interest is when the verifier's running time is  <span class="math">N^{\\delta}</span>  poly <span class="math">(k, 1/\\varepsilon)</span> , for some constant  <span class="math">\\delta \\in (0,1)</span> . In this setting, unlike the previous one, allowing the simulation overhead to be polynomial will give the simulator much greater computational power than the verifier (e.g., if  <span class="math">\\delta = 1/2</span>  and s is quadratic in the verifier's running time, then the simulator can run in time O(N) and in particular may read the entire input). In this setting we aim for the simulation overhead to be <em>linear</em> in the verifier's running time (but it can be polynomial in k and  <span class="math">1/\\varepsilon</span> ). <sup>11</sup></p>

    <p class="text-gray-300">When the simulation overhead is clear from context (as it will almost always be the case) we omit it from the notation.</p>

    <p class="text-gray-300">Cheating Verifier ZKPP. We will allow cheating verifiers to be non-uniform by giving them an auxiliary input. For an algorithm A and a string  <span class="math">z \\in \\{0,1\\}^*</span>  (all auxiliary inputs will be binary strings, regardless of the properties' alphabet), let  <span class="math">A_{[z]}</span>  be A when z was given as auxiliary input. Since we care about algorithms whose running time is insufficient to read the entire input, we would not want to allow the running time to depend on the auxiliary input (otherwise, we could artificially inflate z so that A would be able to read the entire input). Thus, following [Vad99], we adopt the convention that the running time of A is independent of z, so if z is too long, A will not be able to access it in its entirety.</p>

    <p class="text-gray-300"><strong>Definition 3.3</strong> (cheating-verifier zero-knowledge proof of proximity (SZKPP, PZKPP)). <em>Let</em> (P, V) be an interactive proof of proximity for a property  <span class="math">\\Pi = (\\Pi_n, \\mathcal{D}_n, \\mathcal{R}_n)_{n \\in \\mathbb{N}}</span> . (P, V) is said to be cheating-verifier statistical zero-knowledge with simulation overhead s, for some function  <span class="math">s : \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N} \\times \\mathbb{N}</span></p>

    <p class="text-gray-300"><span class="math">$\\mathrm{SD}\\Big(\\widetilde{\\mathsf{S}}_{[z]}^f(\\varepsilon,n,|\\mathcal{D}_n|,|\\mathcal{R}_n|,k),\\mathrm{view}_{\\mathsf{P},\\widehat{\\mathsf{V}}_{[z]}}(\\varepsilon,n,|\\mathcal{D}_n|,|\\mathcal{R}_n|,k,f)\\Big) \\leq \\mathsf{negl}(k).</span>$</p>

    <p class="text-gray-300">If the negl(k) can be replaced with 0 in the above equation, (P, V) is said to be resp., cheating-verifier perfect zero-knowledge with simulation overhead s.</p>

    <p class="text-gray-300">For  <span class="math">t = t(n, |\\mathcal{D}_n|, |\\mathcal{R}_n|, k, \\varepsilon)</span> , SZKPP[t, s] (resp., PZKPP[t, s]) denotes the class of properties possessing cheating-verifier statistical (resp., perfect) zero-knowledge proof of proximity with simulation overhead s in which the verifier's running time is at most O(t).</p>

    <p class="text-gray-300"><strong>Expected Simulation Overhead.</strong> Definition 3.3 requires that the running time of the simulator always be bounded. Similarly to many results in the ZK literature, in some cases we can only bound the simulator's <em>expected</em> running time.</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;11</sup>This requirement is in the spirit of <em>constant</em> knowledge tightness, see [Gol01, Section 4.4.4.2].</p>

    <p class="text-gray-300"><strong>Definition 3.4</strong> (cheating-verifier ZKPP with expected simulation (ESZKPP, EPZKPP))<strong>.</strong> <em>Let</em> (P, V) <em>be an interactive proof of proximity for a property</em> &Pi; = (&Pi;n, Dn, Rn)n&isin;N<em>. The protocol</em> (P, V) <em>is said to be</em> cheating-verifier statistical zero-knowledge with expected simulation overhead s <em>if it satisfies the same requirement as in <a href="#page-12-1">Definition 3.3</a> except that we only bound the</em> expected <em>running time of the simulator.</em></p>

    <p class="text-gray-300"><em>The classes</em> ESZKPP[t, s] <em>and</em> EPZKPP[t, s] <em>are defined analogous to</em> SZKPP[t, s] <em>and</em> PZKPP[t, s] <em>from <a href="#page-12-1">Definition 3.3.</a></em></p>

    <p class="text-gray-300">Unless explicitly saying otherwise, all zero-knowledge protocols we discuss are cheatingverifier ones.</p>

    <p class="text-gray-300">As in the honest-verifier case, a typical setting is that in which the verifier's running time is poly-logarithmic in the input size N and polynomial in the security parameter k and in 1/&epsilon;, and the simulator's (possibly only expected and not strict) running time is polynomial in the running time of the cheating-verifier that it simulates, poly-logarithmic in N and polynomial in k and 1/&epsilon;. Specifically, if we allow the cheating-verifier the same computational powers as the honestverifier, then both the honest-verifier and every simulator run in time poly(log(N), k, 1/&epsilon;). We let ESZKPPpoly(log(N), k, 1/&epsilon;) be the class of properties &Pi; &isin; ESZKPP[t, s] fort = poly(log(N), k, 1/&epsilon;) and s = poly(t <sup>V</sup>b, log(N), k, <sup>1</sup>/&epsilon;). The class PZKPPpoly(log(N), k, 1/&epsilon;), poly is similarly defined.</p>

    <p class="text-gray-300">We conclude this section with a few remarks on the model and the above definitions.</p>

    <p class="text-gray-300"><strong>Remark 3.5</strong> (Promise Problems)<strong>.</strong> <em>Some of the protocols that we construct do not refer to a property but rather to a</em> promise problem<em>. More specifically, rather than distinguishing between inputs that are in the property</em> &Pi; <em>for those that are</em> &epsilon;<em>-far from</em> &Pi;<em>, we will consider a promise problem</em> (&Pi;YES, &Pi;NO) <em>and the requirement is that the verifier accepts inputs that are in</em> &Pi;YES <em>and rejects inputs that are both in</em> &Pi;NO and <em>are</em> &epsilon;<em>-far from</em> &Pi;YES<em>. We extend the definitions above to handle such promise problems in the natural way.</em></p>

    <p class="text-gray-300"><strong>Remark 3.6</strong> (The Security Parameter)<strong>.</strong> <em>One of the original motivations to include security parameter in the classical definitions of statistical zero-knowledge proofs was to control the error parameters (completeness, soundness and simulation deviation) independently from the input's length. Specifically, one may want to provide a high-quality proof (i.e., very small errors) for short inputs (see <a href="#page-42-6">[Vad99,</a> Section 2.4]). In our setting, the situation is somehow reversed. We think of very large inputs that the verifier and simulators cannot even entirely read. Hence, it is infeasible to ask them for errors that are negligible in the input's length. Instead, we control the quality of the proof with the security parameter, independent of the input's length.</em></p>

    <p class="text-gray-300"><strong>Remark 3.7</strong> (Computational ZKPP)<strong>.</strong> <em>Since our focus is on the statistical case, we do not provide explicit definitions of computational zero-knowledge proofs of proximity. Indeed, these definitions can be easily interpolated from the statistical ones in a standard way (see for example Vadhan's <a href="#page-42-6">[Vad99,</a> Section 2] definition of computational zero-knowledge). Specifically, in the computational definitions one simply replaces the requirement that the simulator's output and the protocol's view are statistically-close with one in which they are computationally indistinguishable.</em></p>

    <p class="text-gray-300">In this section, we look at functions f : {0, 1} <sup>n</sup> &rarr; {0, 1} <sup>n</sup> and consider the property of being a permutation. That is, we would like to distinguish between functions that are a permutation from those that are far from being a permutation.</p>

    <p class="text-gray-300"><strong>Definition 4.1</strong> (The permutation property). <em>For every</em>  <span class="math">n \\in \\mathbb{N}</span>  <em>let</em></p>

    <p class="text-gray-300"><span class="math">$\\mathsf{PERMUTATION}_n = \\Big\\{ f \\colon \\{0,1\\}^n \\to \\{0,1\\}^n \\ \\Big| \\ f \\text{ is a permutation} \\Big\\}.</span>$</p>

    <p class="text-gray-300">We define the permutation property as  <span class="math">\\mathsf{PERMUTATION} = \\left(\\mathsf{PERMUTATION}_n, \\{0,1\\}^n, \\{0,1\\}^n\\right)_{n \\in \\mathbb{N}}</span> .</p>

    <p class="text-gray-300">It is not difficult to see that any <em>property tester</em> for PERMUTATION must make at least  <span class="math">\\Omega(\\sqrt{N})</span>  queries, where  <span class="math">N=2^n</span> . To see this, consider the following two distributions: (1) a random permutation over  <span class="math">\\{0,1\\}^n</span> ; and (2) a random function from  <span class="math">\\{0,1\\}^n</span>  to  <span class="math">\\{0,1\\}^n</span> . The first distribution is supported exclusively on YES instances whereas it can be shown that the second is, with high probability, far from a permutation. However, if a tester makes  <span class="math">q \\ll \\sqrt{N}</span>  queries, then in both cases, with high probability, its view will be the same: q distinct random elements. The property testing lower bound follows.</p>

    <p class="text-gray-300">As a matter of fact, Gur and Rothblum [GR15] have shown that the verifier in every MAP (i.e., non-interactive proof of proximity, see [GR16]) for PERMUTATION must make either  <span class="math">\\Omega(N^{1/4})</span>  queries or use a proof of length  <span class="math">\\Omega(N^{1/4})</span> .</p>

    <p class="text-gray-300">In this section, we show that the PERMUTATION property has a 4-message (statistical) zero-knowledge proof of proximity with respect to <em>cheating</em> verifiers. We note that we only bound the <em>expected</em> number of queries and running time of the simulator of our protocol. We leave it as an open problem to obtain a protocol (possibly with more rounds of interaction) in which one can show a <em>high probability bound</em> on the query complexity and running times of the simulator.</p>

    <p class="text-gray-300">Before stating the theorem a word on notation. In Section 3 we gave the prover and the verifier, as explicit inputs, the domain and range sizes &mdash; both, in the case of the permutation property, are  <span class="math">2^n</span> . In this section, for convenience, instead of giving  <span class="math">2^n</span>  as an explicit input, we will simply give n. Relevant complexity measures (e.g., running time, query and communication complexity) will similarly be functions of n.</p>

    <p class="text-gray-300"><strong>Theorem 4.2</strong> (EPZKPP for Permutation). PERMUTATION  <span class="math">\\in</span>  EPZKPP [poly(log( <span class="math">N, k, 1/\\varepsilon</span> ))]. Specifically, PERMUTATION has a cheating-verifier perfect zero-knowledge proof of proximity ( <span class="math">P_{perm}, V_{perm}</span> ) with expected simulator  <span class="math">S_{perm}</span>  with respect to proximity parameter  <span class="math">\\varepsilon &gt; 0</span>  such that the following properties hold for every  <span class="math">n \\in \\mathbb{N}</span> , every input  <span class="math">f: \\{0,1\\}^n \\to \\{0,1\\}^n</span>  and security parameter  <span class="math">k \\in \\mathbb{N}</span> :</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The interaction consists of four messages and the total communication is  <span class="math">O(n^2k/\\varepsilon^2)</span>  bits.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">V_{perm}</span> 's running time is  <span class="math">poly(n, k, 1/\\varepsilon)</span>  and  <span class="math">V_{perm}</span> 's query complexity is  <span class="math">O(nk/\\varepsilon^2)</span> .</li>
    </ol></li>
      <li>3. If  <span class="math">f \\in \\mathsf{PERMUTATION}_n</span> , then for every auxiliary input z,  <span class="math">\\mathsf{S}_{\\mathsf{perm}_{[z]}}</span> 's expected running time and query complexity, given access to a (possibly cheating) verifier  <span class="math">\\widehat{\\mathsf{V}}</span> , are  <span class="math">O(t_{\\widehat{\\mathsf{V}}}(\\varepsilon,n,k,z)) + \\mathsf{poly}(n,k,1/\\varepsilon)</span>  and  <span class="math">O(q_{\\widehat{\\mathsf{V}}}(\\varepsilon,n,k,z) + nk/\\varepsilon^2)</span>  respectively, where  <span class="math">t_{\\widehat{\\mathsf{V}}}(\\varepsilon,n,k,z)</span>  and  <span class="math">q_{\\widehat{\\mathsf{V}}}(\\varepsilon,n,k,z)</span>  are the running time and query complexity of  <span class="math">\\widehat{\\mathsf{V}}_{[z]}^f(\\varepsilon,n,k)</span> .</li>
    </ul>

    <p class="text-gray-300">(Note that the input of PERMUTATION<sub>n</sub> has size  <span class="math">n \\cdot 2^n</span> , so a polynomial dependence on n translates into a poly-logarithmic dependence on the input-size.)</p>

    <p class="text-gray-300">Combined with the aforementioned MAP lower bound for PERMUTATION, we obtain that the complexity of ZKPP (with expected simulation bounds) can be sub-exponentially smaller than those of MAPs (and therefore also of property testers).</p>

    <p class="text-gray-300"><strong>Remark 4.3.</strong> <em>We mention that in <a href="#page-14-0">Item 3</a> in the theorem statement, when the simulator simulates the view of an interaction with the</em> honest <em>verifier</em> Vperm<em>, its</em> strict <em>(rather than expected) query complexity is exactly equal to the query complexity of the verifier.</em></p>

    <p class="text-gray-300">The rest of this section is dedicated to proving <a href="#page-14-1">Theorem 4.2.</a></p>

    <p class="text-gray-300">Consider the following simple IPP for PERMUTATION (based on the <a href="#page-39-2">[BY96]</a> protocol). Given oracle access to a function f : {0, 1} <sup>n</sup> &rarr; {0, 1} n , the verifier chooses a random r &isin; {0, 1} <sup>n</sup> and sends r to the prover. The prover computes z = f &minus;1 (r) and sends it to the verifier. The verifier checks that indeed f(z) = r and if so accepts.</p>

    <p class="text-gray-300">Clearly if f is a permutation then the verifier in this protocol accepts with probability 1, whereas if f is <em>far</em> from a permutation, then with some non-negligible probability the verifier chooses r which does not have a pre-image under f. In such a case the prover cannot make the verifier accept and so the protocol is sound.</p>

    <p class="text-gray-300">It is also not hard to see that this protocol is <em>honest-verifier</em> zero-knowledge.<a href="#page-15-0">12</a> However, it is not <em>cheating-verifier</em> zero-knowledge: a cheating verifier could learn the inverse of some arbitrary r of its choice.</p>

    <p class="text-gray-300">In order to make the protocol zero-knowledge, intuitively, we would like to have a way for the prover and verifier to jointly sample the element r such that both are assured that it is uniform. For simplicity let us focus on the task of just sampling a single bit &sigma;. The specific properties that we need are</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>If f is a permutation then the prover is assured that the &sigma; is random.</li>
    </ol></li>
      <li>2. If f is far from being a permutation then the verifier is assured that &sigma; is random.</li>
    </ul>

    <p class="text-gray-300">In fact, the transformation of general honest-verifier statistical zero-knowledge proofs to cheatingverifier ones (see <a href="#page-42-6">[Vad99,</a> Chapter 6]) implements a sub-routine achieving a generalization of the above task, assuming <em>full</em> access to the input. We give a simple solution for our specific case. That is, using only oracle access to a function that is either a permutation or far from any permutation.</p>

    <p class="text-gray-300">We proceed to describe a simple procedure for sampling such a random bit &sigma;. First, the verifier chooses at random x &isin; {0, 1} <sup>n</sup> and a pairwise independent hash function h : {0, 1} <sup>n</sup> &rarr; {0, 1} and sends y = f(x) and h to the prover. The prover now chooses a random bit r &isin; {0, 1} and sends r to the verifier. The verifier now sends x to the prover who checks that indeed f(x) = y. The random bit that they agree on is &sigma; = r &oplus; h(x).</p>

    <p class="text-gray-300">From the prover's perspective, if f is a permutation then y fully determines x and so r (which is chosen uniformly at random after y is specified) is independent of h(x). Hence, &sigma; = r &oplus; h(x) is uniformly random bit. On the other hand, from the verifier's perspective, if f is far from being a permutation, then, intuitively, even conditioned on the value y there still remains some entropy in x (indeed, x is essentially uniform among all the pre-images of y).<a href="#page-15-1">13</a> Now, using a variant of the leftover hash lemma, we can argue that h(x) is close to random. Actually, since the leftover</p>

    <p class="text-gray-300"><sup>12</sup>As a matter of fact, this protocol can be viewed as a non-interactive statistical zero-knowledge protocol for PERMUTATION (and is used as such in <a href="#page-39-2">[BY96]</a>).</p>

    <p class="text-gray-300"><sup>13</sup>Actually, the amount of entropy is fairly small (and depends on how far f is from being a permutation). To obtain a sufficient amount of entropy, in our actual protocol we generate many such y's.</p>

    <p class="text-gray-300">Pperm's Input: A function f : {0, 1} <sup>n</sup> &rarr; {0, 1} <sup>n</sup>, proximity parameter &epsilon; &gt; 0 and security parameter k. Vperm's Input: &epsilon;, n, k and oracle access to f.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Both parties set t = d(n + 1)/&epsilon;e and s = dk/&epsilon;e.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Vperm samples x = (x1, x2, . . . , xt&middot;s) &larr; {0, 1} n <sup>t</sup>&middot;<sup>s</sup> and h &larr; Hn&middot;t&middot;s,n&middot;s. <em><a href="#page-16-0">a</a></em> Vperm computes y<sup>i</sup> = f(xi) for every i &isin; [t &middot; s] (by querying f), and sends y = (y1, y2, . . . , yt&middot;s) and h to Pperm.</li>
    </ol></li>
      <li>3. Pperm samples r = (r1, r2, . . . , rs) &larr; {0, 1} n s and send them to Vperm.</li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Vperm sends x to Pperm.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Pperm checks that f(xi) = y<sup>i</sup> , for every i &isin; [t &middot; s]. If any check fails then Pperm sends &perp; and aborts.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Pperm sends z = (z1, z2, . . . , zs) to Vperm, where z<sup>i</sup> = f &minus;1 r<sup>i</sup> &oplus; h(x)<sup>i</sup> , for every i &isin; [s]. <em><a href="#page-16-1">b</a></em></li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Vperm accepts if f(zi) = r<sup>i</sup> &oplus; h(x)<sup>i</sup> for every i &isin; [s], and otherwise it rejects.</li>
    </ol></li>
    </ul>

    <pre><code class="language-text">aRecall that Hn,m = {h: {0, 1}
                                n &rarr; {0, 1}
                                           m} is a family of pairwise independent hash functions. See Fact 2.5.
   bRecall that &oplus; stands for the bitwise exclusive-or. Also, we view h(x) &isin; {0, 1}
                                                                                                n&middot;s
                                                                                                     as h(x) =
(h(x)1, h(x)2, . . . , h(x)s) such that h(x)i &isin; {0, 1}
                                               n
                                                 .
</code></pre>

    <p class="text-gray-300">Figure 1: The Permutation Protocol</p>

    <p class="text-gray-300">hash lemma implies that pairwise independent hash functions are <em>strong</em> extractors, we have that h(x) is close to random even conditioned on h and therefore also conditioned on r (which is a randomized function of h). Thus, we obtain that &sigma; = r&oplus;h(x) is close to uniformly random bit and so our procedure satisfies the desired properties.</p>

    <p class="text-gray-300">We proceed to the description of our actual protocol, which is based on the foregoing ideas. The protocol Pperm, Vperm is given in <a href="#page-16-2">Fig. 1.</a></p>

    <p class="text-gray-300">It is easy to verify that Pperm, Vperm has the desired round complexity, query complexity and verifier's running time, where we use the fact that O(n <sup>2</sup>k/&epsilon;) bits suffice for describing the pairwise independent hash function in the protocol (see <a href="#page-8-1">Fact 2.5)</a>.</p>

    <p class="text-gray-300">To see that completeness holds observe that if f : {0, 1} <sup>n</sup> &rarr; {0, 1} n is a permutation, and the two parties follow the protocol, then indeed f(xi) = y<sup>i</sup> and f(zi) = f(f &minus;1 (r<sup>i</sup> &oplus;h(x)i)) = r<sup>i</sup> &oplus;h(x)<sup>i</sup> for every i &isin; [t &middot; s], and therefore the parties complete the interaction and the verifier accepts.</p>

    <p class="text-gray-300">It remains to show that the soundness and zero-knowledge conditions hold. Soundness follows from the following lemma, which is proved in <a href="#page-17-0">Section 4.1.2.</a></p>

    <p class="text-gray-300"><strong>Lemma 4.4.</strong> <em>Let</em> n, k &isin; N<em>, let</em> &epsilon; &gt; 0 <em>and suppose that</em> f : {0, 1} <sup>n</sup> &rarr; {0, 1} n <em>is</em> &epsilon;<em>-far from</em> PERMUTATIONn<em>. Then, for every prover strategy</em> Pb<em>, when</em> Vperm f (&epsilon;, n, k) <em>interacts with</em> <sup>P</sup><sup>b</sup> <em>it rejects with probability</em> <sup>1</sup> <sup>&minus;</sup> negl(k)<em>.</em></p>

    <p class="text-gray-300">Finally, to show that this protocol is perfect zero-knowledge, consider the simulator Sperm given in <a href="#page-17-1">Fig. 2.</a> The following lemma, which we prove in <a href="#page-19-0">Section 4.1.3,</a> shows that this simulator perfectly samples from the view of any (possible cheating) verifier.</p>

    <p class="text-gray-300">Simulator's Input:  <span class="math">\\varepsilon</span> , n, k, auxiliary input z, oracle access to  <span class="math">f: \\{0,1\\}^n \\to \\{0,1\\}^n</span>  and access to (possibly cheating) verifier  <span class="math">\\hat{V}</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Run  <span class="math">\\widehat{\\mathsf{V}}_{[z]}^f(\\varepsilon,n,k)</span>  using random coins  <span class="math">\\rho</span>  to get  <span class="math">\\overline{\\mathbf{y}}=(y_1,y_2,\\ldots,y_{ts})</span>  and h.</li>
    </ol></li>
      <li>2. Sample  <span class="math">\\overline{\\mathbf{r}} = (r_1, r_2, \\dots, r_s) \\leftarrow (\\{0, 1\\}^n)^s</span>  and give them to  <span class="math">\\widehat{\\mathbf{V}}_{[z]}</span>  as the answers from  <span class="math">\\mathsf{P}_{\\mathsf{perm}}</span> .</li>
      <li>3. Continue to run  <span class="math">\\widehat{\\mathsf{V}}_{[z]}^f(\\varepsilon,n,k)</span>  to get  <span class="math">\\overline{\\mathbf{x}}=(x_1,x_2,\\ldots,x_{ts})</span> , the values  <span class="math">\\widehat{\\mathsf{V}}_{[z]}^f(\\varepsilon,n,k)</span>  sends to  <span class="math">\\mathsf{P}_{\\mathsf{perm}}</span>  in the third message of the protocol.</li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>If there exists  <span class="math">i \\in [t \\cdot s]</span>  such that  <span class="math">f(x_i) \\neq y_i</span> , output  <span class="math">(\\overline{\\mathbf{y}}, h, \\overline{\\mathbf{r}}, \\overline{\\mathbf{x}}, \\perp, \\rho)</span> .</li>
    </ol></li>
      <li>5. Otherwise, repeat the following:    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(a) Sample  <span class="math">\\overline{\\mathbf{r}&#x27;} = (r&#x27;_1, r&#x27;_2, \\dots, r&#x27;_s) \\leftarrow (\\{0, 1\\}^n)^s</span>  and for every  <span class="math">i \\in [s]</span> , set  <span class="math">r&#x27;&#x27;_i = f(r&#x27;_i) \\oplus h(\\overline{\\mathbf{x}})_i</span> .</li>
      <li>(b) Rewind  <span class="math">\\widehat{\\mathsf{V}}_{[z]}^f(\\varepsilon,n,k)</span>  to the point it is waiting for the second message of the protocol using  <span class="math">\\rho</span>  again as the random coins (i.e., step 3 of the protocol). Give  <span class="math">\\overline{\\mathbf{r}&#x27;&#x27;}=(r_1&#x27;&#x27;,r_2&#x27;&#x27;,\\ldots,r_{ts}&#x27;&#x27;)</span>  as the answers from  <span class="math">\\mathsf{P}_{\\mathrm{perm}}</span> .</li>
      <li>(c) Continue to run  <span class="math">\\widehat{\\mathsf{V}}_{[z]}^f(\\varepsilon,n,k)</span>  to get  <span class="math">\\overline{\\mathbf{x}&#x27;}=(x_1&#x27;,x_2&#x27;,\\ldots,x_{ts}&#x27;)</span> , the values  <span class="math">\\widehat{\\mathsf{V}}_{[z]}^f(\\varepsilon,n,k)</span>  sends to  <span class="math">\\mathsf{P}_{\\mathsf{perm}}</span>  in the third message of the protocol.</li>
      <li>(d) If  <span class="math">f(x_i) = y_i</span>  for every  <span class="math">i \\in [ts]</span> , output  <span class="math">(\\overline{\\mathbf{y}}, h, \\overline{\\mathbf{r&#x27;&#x27;}}, \\overline{\\mathbf{x&#x27;}}, \\overline{\\mathbf{r&#x27;}}, \\rho)</span>  and halt. Otherwise, go back to 5a.</li>
    </ul></li>
    </ul>

    <p class="text-gray-300">Figure 2: The Simulator for The Permutation Protocol</p>

    <p class="text-gray-300"><strong>Lemma 4.5.</strong> Let  <span class="math">n, k \\in \\mathbb{N}</span> , let  <span class="math">z \\in \\{0, 1\\}^*</span> , let  <span class="math">f \\in \\mathsf{PERMUTATION}_n</span> , let  <span class="math">\\widehat{\\mathsf{V}}</span>  be some verifier strategy and let  <span class="math">\\mathsf{S}^f_{[z]}(\\varepsilon, n, k, \\widehat{\\mathsf{V}})</span>  be the output of  <span class="math">\\mathsf{S}_{\\mathsf{perm}}</span>  when running on input  <span class="math">\\varepsilon, n, k</span> , auxiliary input z, with oracle access to  <span class="math">\\widehat{\\mathsf{V}}</span>  and access to  <span class="math">\\widehat{\\mathsf{V}}</span> . Then:</p>

    <p class="text-gray-300"><span class="math">$\\mathrm{SD}\\Big(\\mathsf{S}^f_{[z]}(\\varepsilon,n,k,\\widehat{\\mathsf{V}}),\\mathrm{view}_{\\mathsf{P}_{\\mathrm{perm}},\\widehat{\\mathsf{V}}_{[z]}}(\\varepsilon,n,k,f)\\Big)=0.</span>$</p>

    <p class="text-gray-300">Moreover, the expected running time and query complexity of  <span class="math">S_{[z]}^f(\\varepsilon, n, k, \\widehat{V})</span>  are as in Item 3 of the theorem statement.</p>

    <p class="text-gray-300">This concludes the proof of Theorem 4.2 (modulo the proofs of Lemma 4.4 and Lemma 4.5 which are proved next).</p>

      <h4 id="sec-4.1.2" class="text-lg font-semibold mt-6">4.1.2 Analyzing Soundness &mdash; Proof of Lemma 4.4</h4>

    <p class="text-gray-300">Before proving Lemma 4.4 we show two basic, but useful, properties of functions that are  <span class="math">\\varepsilon</span> -far from permutations. The first property is that the image size of such functions cannot be too large.</p>

    <p class="text-gray-300"><strong>Fact 4.6.</strong> If f is  <span class="math">\\varepsilon</span> -far from PERMUTATION<sub>n</sub>, then  <span class="math">|\\operatorname{Im}(f)| \\leq (1 - \\varepsilon) \\cdot 2^n</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> We prove the contrapositive. Let  <span class="math">f: \\{0,1\\}^n \\to \\{0,1\\}^n</span>  and suppose that  <span class="math">|\\text{Im}(f)| &gt; (1-\\varepsilon) \\cdot 2^n</span> . We show that f is  <span class="math">\\varepsilon</span> -close to a permutation  <span class="math">f&#x27;: \\{0,1\\}^n \\to \\{0,1\\}^n</span> .</p>

    <p class="text-gray-300">Start by setting f'(x) = f(x) for every x. Repeat the following process until  <span class="math">\\text{Im}(f&#x27;) = \\{0,1\\}^n</span> : take  <span class="math">y \\notin \\text{Im}(f)</span> ; find  <span class="math">x \\neq x&#x27;</span>  such that f'(x) = f'(x') (such x, x' must exist since at this point f' is not a permutation); set f'(x) = y.</p>

    <p class="text-gray-300">In every iteration  <span class="math">|\\operatorname{Im}(f)|</span>  increases by one. The above process started with  <span class="math">|\\operatorname{Im}(f&#x27;)| &gt; (1-\\varepsilon) \\cdot 2^n</span> , and thus takes less than  <span class="math">\\varepsilon \\cdot 2^n</span>  iterations. It follows that f' and f disagree on at most  <span class="math">\\varepsilon \\cdot 2^n</span>  inputs, or in other words f' is  <span class="math">\\varepsilon</span> -close to f. Moreover, f' is a permutation, since  <span class="math">\\operatorname{Im}(f&#x27;) = \\{0,1\\}^n</span> .</p>

    <p class="text-gray-300">Next we show that even after seeing a random element in the image of a function that is  <span class="math">\\varepsilon</span> -far from permutation, its preimage still has some entropy. The specific notion of entropy we use is average min-entropy.<sup>14</sup></p>

    <p class="text-gray-300"><strong>Claim 4.7.</strong> Suppose that  <span class="math">f: \\{0,1\\}^n \\to \\{0,1\\}^n</span>  is  <span class="math">\\varepsilon</span> -far from PERMUTATION<sub>n</sub>. Let X be a random variable uniformly distributed over  <span class="math">\\{0,1\\}^n</span> , and let Y = f(X). Then,  <span class="math">\\tilde{\\mathrm{H}}_{\\infty}(X|Y) \\geq \\log(1/(1-\\varepsilon))</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> For  <span class="math">y \\in \\{0,1\\}^n</span> , let  <span class="math">f^{-1}(y) = \\{x \\in \\{0,1\\}^n : f(x) = y\\}</span> . Fix  <span class="math">y \\in \\text{Im}(f)</span> . For  <span class="math">x \\in f^{-1}(y)</span> , it holds that  <span class="math">\\Pr[X = x | Y = y] = 1/|f^{-1}(y)|</span> , while for  <span class="math">x \\notin f^{-1}(y)</span> , it holds that  <span class="math">\\Pr[X = x | Y = y] = 0</span> . Thus,  <span class="math">\\max_x \\Pr[X = x | Y = y] = 1/|f^{-1}(y)|</span> . Moreover, it holds that  <span class="math">\\Pr[Y = y] = |f^{-1}(y)|/2^n</span> . Finally, for every  <span class="math">y \\notin \\text{Im}(f)</span> , it holds that  <span class="math">\\Pr[Y = y] = 0</span> . Hence,</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\tilde{\\mathbf{H}}_{\\infty}(X|Y) &amp;= -\\log \\Big( \\mathbf{E}_{y \\leftarrow Y} \\Big[ \\max_{x} \\Pr[X = x | Y = y] \\Big] \\Big) \\\\ &amp;= -\\log \\left( \\sum_{y \\in \\mathrm{Im}(f)} \\frac{\\left| f^{-1}(y) \\right|}{2^n} \\cdot \\frac{1}{\\left| f^{-1}(y) \\right|} \\right) \\\\ &amp;= \\log \\left( \\frac{2^n}{\\left| \\mathrm{Im}(f) \\right|} \\right) \\\\ &amp;\\geq \\log \\left( \\frac{1}{1 - \\varepsilon} \\right), \\end{split}</span>$</p>

    <p class="text-gray-300">where the inequality follows from Fact 4.6.</p>

    <p class="text-gray-300">We are now ready to prove Lemma 4.4.</p>

    <p class="text-gray-300"><em>Proof of Lemma 4.4.</em> Let  <span class="math">\\widehat{P}</span>  be a (cheating) prover strategy. We assume without loss of generality that  <span class="math">\\widehat{P}</span>  is deterministic (by fixing the best choice of random coin tosses).</p>

    <p class="text-gray-300">Let  <span class="math">\\overline{\\mathbf{X}}</span> , H,  <span class="math">\\overline{\\mathbf{Y}}</span> ,  <span class="math">\\overline{\\mathbf{R}}</span>  and  <span class="math">\\overline{\\mathbf{Z}}</span>  be the (jointly distributed) random variables induced by the values of  <span class="math">\\overline{\\mathbf{x}}</span> , h,  <span class="math">\\overline{\\mathbf{y}}</span> ,  <span class="math">\\overline{\\mathbf{r}}</span>  and  <span class="math">\\overline{\\mathbf{z}}</span>  respectively, in a random execution of  <span class="math">(\\widehat{\\mathsf{P}},\\mathsf{V}_{perm})</span>  and let  <span class="math">\\mathrm{out}(\\widehat{\\mathsf{P}},\\mathsf{V}_{perm})</span>  be the random variable induced by  <span class="math">\\mathsf{V}_{perm}</span> 's output in the same random execution (i.e.,  <span class="math">\\mathrm{out}(\\widehat{\\mathsf{P}},\\mathsf{V}_{perm}) \\in \\{accept, reject\\}</span> ).</p>

    <p class="text-gray-300">By the definition of the permutation protocol, it holds that</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[\\operatorname{out}(\\widehat{\\mathsf{P}},\\mathsf{V}_{\\operatorname{perm}}) = accept\\right] \\leq \\Pr\\left[\\forall i \\in [s] \\colon f(X_i&#x27;) = R_i \\oplus H(\\overline{\\mathbf{X}})_i\\right]</span>$</p>

    <p class="text-gray-300"><span class="math">$\\leq \\Pr\\left[\\forall i \\in [s] \\colon R_i \\oplus H(\\overline{\\mathbf{X}})_i \\in \\operatorname{Im}(f)\\right].</span>$</p>

    <p class="text-gray-300"><span class="math">$(1)</span>$</p>

    <p class="text-gray-300"></p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;14</sup>Recall that average min-entropy of X given Y is defined as  <span class="math">\\tilde{H}_{\\infty}(X|Y) := -\\log(\\mathbb{E}_{y \\leftarrow Y}[\\max_x \\Pr[X = x \\mid Y = y]])</span>  (see Definition 2.2).</p>

    <p class="text-gray-300">Note that R = (R1, . . . , Rs) is a function of Y and H, determined by Pb. It follows that</p>

    <p class="text-gray-300"><span class="math">$\\Pr[\\forall i \\in [s] : R_i(\\overline{\\mathbf{Y}}, H) \\oplus H(\\overline{\\mathbf{X}})_i \\in \\operatorname{Im}(f)] \\leq \\Pr[\\forall i \\in [s] : R_i(\\overline{\\mathbf{Y}}, H) \\oplus U_i \\in \\operatorname{Im}(f)] + \\operatorname{SD}((H(\\overline{\\mathbf{X}}), H, \\overline{\\mathbf{Y}}), (\\overline{\\mathbf{U}}, H, \\overline{\\mathbf{Y}})),</span>$
(2)</p>

    <p class="text-gray-300">where U = (U1, U2, . . . , Us) is uniform over ({0, 1} n ) s . We bound both terms in the right-hand side of <a href="#page-19-1">Equation (2).</a> For the first term, note that U<sup>i</sup> is independent of U<sup>j</sup> for i 6= j, and thus</p>

    <p class="text-gray-300">
<span class="math">$\\Pr[\\forall i \\in [s] : R_i(\\overline{\\mathbf{Y}}, H) \\oplus U_i \\in \\operatorname{Im}(f)] = \\prod_{i=1}^s \\Pr[R_i(\\overline{\\mathbf{Y}}, H) \\oplus U_i \\in \\operatorname{Im}(f)]</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\prod_{i=1}^s \\Pr[U_i \\in \\operatorname{Im}(f)]</span>$</p>

    <p class="text-gray-300"><span class="math">$\\leq (1 - \\varepsilon)^s,</span>$
(3)</p>

    <p class="text-gray-300">where the second equality follows from the fact that for every r &isin; {0, 1} n , r &oplus; U<sup>i</sup> is uniform over {0, 1} <sup>n</sup> and the last inequality follows from <a href="#page-17-3">Fact 4.6.</a></p>

    <p class="text-gray-300">As for the second term of <a href="#page-19-1">Equation (2),</a> by <a href="#page-7-2">Fact 2.3</a> it holds that</p>

    <p class="text-gray-300">
<span class="math">$\\widetilde{H}_{\\infty}(\\overline{\\mathbf{X}}|\\overline{\\mathbf{Y}}) = t \\cdot s \\cdot \\widetilde{H}_{\\infty}(X_1|Y_1) \\ge t \\cdot s \\cdot \\log(1/(1-\\varepsilon)),</span>$
(4)</p>

    <p class="text-gray-300">where the inequality follows from <a href="#page-18-1">Claim 4.7.</a> Applying the generalized leftover hash lemma <a href="#page-8-2">(Lemma 2.6)</a> we now obtain that:</p>

    <p class="text-gray-300"><span class="math">$SD((H(\\overline{\\mathbf{X}}), H, \\overline{\\mathbf{Y}}), (U, H, \\overline{\\mathbf{Y}})) \\le \\frac{1}{2} \\cdot \\sqrt{2^{ts \\log(1-\\varepsilon)} \\cdot 2^{ns}} = \\frac{1}{2} \\cdot (2^n \\cdot (1-\\varepsilon)^t)^{s/2}.</span>$
(5)</p>

    <p class="text-gray-300">Plugging <a href="#page-19-1">Equations (2),</a> <a href="#page-19-2">(3)</a> and <a href="#page-19-3">(5)</a> into <a href="#page-18-2">Equation (1),</a> we have</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[\\operatorname{out}(\\widehat{\\mathsf{P}}, \\mathsf{V}_{\\mathsf{perm}}) = accept\\right] \\leq (1 - \\varepsilon)^s + \\frac{1}{2} \\cdot \\left(2^n \\cdot (1 - \\varepsilon)^t\\right)^{s/2}</span>$</p>

    <p class="text-gray-300"><span class="math">$\\leq (1 - \\varepsilon)^{k/\\varepsilon} + \\frac{1}{2} \\cdot \\left(2^n \\cdot (1 - \\varepsilon)^{(n+1)/\\varepsilon}\\right)^{k/(2\\varepsilon)}</span>$</p>

    <p class="text-gray-300"><span class="math">$\\leq 2^{-k} + \\frac{1}{2} \\cdot \\left(2^n \\cdot 2^{-(n+1)}\\right)^{k/(2\\varepsilon)}</span>$</p>

    <p class="text-gray-300"><span class="math">$= 2^{-k} + 2^{-k/(2\\varepsilon)-1},</span>$</p>

    <p class="text-gray-300"><span class="math">$(6)</span>$</p>

    <p class="text-gray-300"></p>

    <p class="text-gray-300">where the second inequality follows from our setting of t = d(n + 1)/&epsilon;e and s = dk/&epsilon;e and the third inequality follows from the fact that 1 &minus; x &le; 2 &minus;x for any x &ge; 0. Thus, the verifier accepts with probability that is exponentially vanishing in k, and in particular negligible.</p>

      <h4 id="sec-4.1.3" class="text-lg font-semibold mt-6"><strong>4.1.3 Analyzing Zero-Knowledge &mdash; Proof of <a href="#page-16-5">Lemma 4.5</a></strong></h4>

    <p class="text-gray-300">Let <sup>V</sup><sup>b</sup> be a cheating verifier strategy and fix an input <sup>f</sup> <sup>&isin;</sup> PERMUTATION. For simplicity, and without loss of generality, we assume that <sup>V</sup><sup>b</sup> is deterministic.<a href="#page-19-4">15</a></p>

    <p class="text-gray-300"><sup>15</sup>Recall that if the cheating verifier is randomized, we can fix its random coins as part of the auxiliary input to both parties.</p>

    <p class="text-gray-300">Throughout this proof we fix an auxiliary input z to  <span class="math">S_{perm}</span>  and remove it from the notation of both the simulator and the (possibly cheating) verifier (since all  <span class="math">S_{perm}</span>  does with its auxiliary input is to provide it to  <span class="math">\\widehat{V}</span> , both algorithms get the same auxiliary inputs).</p>

    <p class="text-gray-300">Recall that we let  <span class="math">S^f(\\varepsilon, n, k, \\widehat{V})</span>  denote the algorithm defined by running  <span class="math">S_{perm}</span>  on input  <span class="math">\\varepsilon, n, k</span> , with oracle access to  <span class="math">\\widehat{V}</span> . Note that  <span class="math">S^f(\\varepsilon, n, k, \\widehat{V})</span>  halts <em>almost surely</em>, namely the probability that it never halts is zero.</p>

    <p class="text-gray-300">The following claim shows show that the output distribution of  <span class="math">S_{perm}</span>  is identical to the view of  <span class="math">\\widehat{V}</span> . Later, in Claim 4.9, we will bound the (expected) running time and query complexity of  <span class="math">S_{perm}</span> .</p>

    <p class="text-gray-300"><strong>Claim 4.8.</strong> The output distribution of  <span class="math">S_{perm}</span>  is identical to the view of  <span class="math">\\widehat{V}</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> Let  <span class="math">\\overline{\\mathbf{X}}</span> , H,  <span class="math">\\overline{\\mathbf{Y}}</span> ,  <span class="math">\\overline{\\mathbf{R}}</span>  and  <span class="math">\\overline{\\mathbf{Z}}</span>  be the (jointly distributed) random variables induced by the values of  <span class="math">\\overline{\\mathbf{x}}</span> , h,  <span class="math">\\overline{\\mathbf{y}}</span> ,  <span class="math">\\overline{\\mathbf{r}}</span>  and  <span class="math">\\overline{\\mathbf{z}}</span>  respectively, in a random execution of  <span class="math">(\\mathsf{P}_{\\mathsf{perm}}, \\widehat{\\mathsf{V}})</span> .</p>

    <p class="text-gray-300">First observe that since  <span class="math">\\widehat{\\mathbf{V}}</span>  is deterministic, its first message  <span class="math">(\\overline{\\mathbf{y}},h)</span>  is fixed and so  <span class="math">\\overline{\\mathbf{Y}}=\\overline{\\mathbf{y}}</span>  and H=h. Also, since the verifier is deterministic, there exists a function v such that  <span class="math">\\overline{\\mathbf{X}}=v(\\overline{\\mathbf{R}})</span> . Lastly, observe that there also exists a function u such that  <span class="math">\\overline{\\mathbf{Z}}=u(\\overline{\\mathbf{R}})</span> .</p>

    <p class="text-gray-300">The view of the verifier is therefore:</p>

    <p class="text-gray-300"><span class="math">$\\operatorname{view}_{\\mathbf{P}|\\widehat{\\mathbf{V}}}(\\varepsilon, n, k, f) = (\\overline{\\mathbf{Y}}, H, \\overline{\\mathbf{R}}, \\overline{\\mathbf{X}}, \\overline{\\mathbf{Z}}) = (\\overline{\\mathbf{y}}, h, \\overline{\\mathbf{R}}, v(\\overline{\\mathbf{R}}), u(\\overline{\\mathbf{R}}))</span>$
(7)</p>

    <p class="text-gray-300">Similarly, let  <span class="math">\\overline{\\mathbf{X}}_{S}</span> ,  <span class="math">H_{S}</span> ,  <span class="math">\\overline{\\mathbf{Y}}_{S}</span> ,  <span class="math">\\overline{\\mathbf{Z}}_{S}</span>  be the (jointly distributed) random variables induced by the output of a random execution of  <span class="math">S^{f}(\\varepsilon, n, k, \\widehat{V})</span> . We need to show that:</p>

    <p class="text-gray-300">
<span class="math">$(\\overline{\\mathbf{Y}}, H, \\overline{\\mathbf{R}}, \\overline{\\mathbf{X}}, \\overline{\\mathbf{Z}}) \\equiv (\\overline{\\mathbf{Y}_{S}}, H_{S}, \\overline{\\mathbf{R}_{S}}, \\overline{\\mathbf{X}_{S}}, \\overline{\\mathbf{Z}_{S}}).</span>$
(8)</p>

    <p class="text-gray-300">First observe that by construction  <span class="math">\\overline{\\mathbf{Y}_{S}} = \\overline{\\mathbf{y}}</span>  and  <span class="math">H_{S} = h</span> . Also observe that no matter what value  <span class="math">\\overline{\\mathbf{R}_{S}}</span>  obtains, in all steps in which the simulator might generate an output, it holds that  <span class="math">\\overline{\\mathbf{X}_{S}} = v(R_{S})</span> , where the function v is as defined above. Similarly it holds that  <span class="math">\\overline{\\mathbf{Z}_{S}} = u(R_{S})</span> , where u was defined above.</p>

    <p class="text-gray-300">Thus, Equation (8) reduces to showing that  <span class="math">\\overline{\\mathbf{R}}</span>  and  <span class="math">\\overline{\\mathbf{R}_S}</span>  are identically distributed. Since  <span class="math">\\overline{\\mathbf{R}}</span>  is uniform all we need to show is that  <span class="math">\\overline{\\mathbf{R}_S}</span>  is also uniformly distributed.</p>

    <p class="text-gray-300">Let</p>

    <p class="text-gray-300"><span class="math">$\\mathcal{A} = \\left\\{ \\overline{\\mathbf{r}} \\in (\\{0,1\\}^n)^s : \\exists i \\in [t \\cdot s] \\text{ s.t. } y_i \\neq f(x_i) \\text{ where } \\overline{\\mathbf{x}} = v(\\overline{\\mathbf{r}}) \\right\\}, \\tag{9}</span>$</p>

    <p class="text-gray-300">where  <span class="math">\\overline{\\mathbf{y}}=(y_1,\\ldots,y_{ts})</span>  (and recall that  <span class="math">\\overline{\\mathbf{y}}</span>  was fixed). Namely,  <span class="math">\\mathcal{A}</span>  contains those elements in  <span class="math">(\\{0,1\\}^n)^s</span> , that had they been sent by  <span class="math">\\mathsf{P}_{\\mathsf{perm}}</span>  as its second message, the verifier  <span class="math">\\widehat{\\mathsf{V}}</span>  would have sent  <span class="math">\\overline{\\mathbf{x}}</span>  that are not the preimages of  <span class="math">\\overline{\\mathbf{y}}</span> . Finally, let  <span class="math">p=\\Pr_{r\\leftarrow(\\{0,1\\}^n)^s}[r\\notin\\mathcal{A}]</span>  and fix  <span class="math">r^*\\in(\\{0,1\\}^n)^s</span> . We show that  <span class="math">\\Pr[R_{\\mathsf{S}}=r^*]=1/(2^n)^s</span> . The proof now splits according to  <span class="math">r^*</span> .</p>

    <p class="text-gray-300"><span class="math">r^* \\in \\mathcal{A}</span> : The only way  <span class="math">\\mathsf{S}^f(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span>  would output  <span class="math">r^*</span>  is by choosing it in Step 2. Since  <span class="math">\\mathsf{S}^f(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span>  chooses the values in this step uniformly at random from  <span class="math">(\\{0,1\\}^n)^s</span> , it follows that  <span class="math">\\Pr[R_{\\mathsf{S}} = r^*] = 1/(2^n)^s</span> .</p>

    <p class="text-gray-300"><span class="math">r^* \\notin \\mathcal{A}</span> : The only way  <span class="math">\\mathsf{S}^f(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span>  would output  <span class="math">r^*</span>  is by choosing  <span class="math">r&#x27;&#x27;=r^*</span>  in Step 5a. The probability that  <span class="math">\\mathsf{S}^f(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span>  reaches Step 5 at all is p. Having reached Step 5, and since f is a permutation, every time that  <span class="math">\\mathsf{S}^f(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span>  runs Step 5a, it samples r'' uniformly at random from  <span class="math">(\\{0,1\\}^n)^s</span> , independent of all previous messages it received from  <span class="math">\\widehat{\\mathsf{V}}</span> . In Step 5  <span class="math">\\mathsf{S}^f(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span>  is performing rejection sampling until it gets  <span class="math">r&#x27;&#x27; \\notin \\mathcal{A}</span>  and then sets  <span class="math">\\overline{\\mathbf{R}}_{\\mathsf{S}} = r&#x27;&#x27;</span> . All in all, it holds that</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\Pr[\\overline{\\mathbf{R}}_{\\mathbb{S}} = r^*] &amp;= p \\cdot \\Pr_{r&#x27;&#x27; \\leftarrow (\\{0,1\\}^n)^s} \\big[ r&#x27;&#x27; = r^* \\mid r&#x27;&#x27; \\notin \\mathcal{A} \\big] \\\\ &amp;= \\Pr_{r \\leftarrow (\\{0,1\\}^n)^s} [r \\notin \\mathcal{A}] \\cdot \\frac{\\Pr_{r&#x27;&#x27; \\leftarrow (\\{0,1\\}^n)^s} [r&#x27;&#x27; = r^*]}{\\Pr_{r&#x27;&#x27; \\leftarrow (\\{0,1\\}^n)^s} [r&#x27;&#x27; \\notin \\mathcal{A}]} \\\\ &amp;= \\Pr_{r \\leftarrow (\\{0,1\\}^n)^s} [r = r^*] = \\frac{1}{(2^n)^s}. \\end{split}</span>$</p>

    <p class="text-gray-300">(Note that we can condition on the event  <span class="math">r&#x27;&#x27; \\notin A</span>  since  <span class="math">r^* \\notin A</span>  and so  <span class="math">\\Pr[r&#x27;&#x27; \\notin A] &gt; 0</span> .)</p>

    <p class="text-gray-300">Hence,  <span class="math">\\overline{\\mathbf{R}}_{S}</span>  is uniform over  <span class="math">(\\{0,1\\}^n)^s</span> . This completes the proof of Claim 4.8.</p>

    <p class="text-gray-300"><strong>Claim 4.9.</strong> If the cheating verifier  <span class="math">\\widehat{V}</span>  runs in time  <span class="math">t_{\\widehat{V}}</span>  and makes  <span class="math">q_{\\widehat{V}}</span>  queries, then the expected running time of the simulator  <span class="math">S_{perm}</span>  is  <span class="math">O(t_{\\widehat{V}}) + poly(n, k, 1/\\varepsilon)</span>  and its query complexity is  <span class="math">O(q_{\\widehat{V}} + nk/\\varepsilon^2)</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> We prove this part by first showing the expected number of calls it makes to  <span class="math">\\hat{V}</span>  is constant.</p>

    <p class="text-gray-300">Let T be the number of times  <span class="math">S^f(\\varepsilon,n,k,\\widehat{V})</span>  executes Steps 3 and 5c when  <span class="math">\\widehat{V}</span>  uses the coins  <span class="math">\\rho</span> . Note that T is equal to the number of times the simulator invokes  <span class="math">\\widehat{V}</span> . Let  <span class="math">\\mathcal{A}</span>  be as defined in Equation (9) (recall that  <span class="math">\\mathcal{A}</span>  was defined as the set of vectors  <span class="math">\\overline{\\mathbf{r}}</span>  for which the verifier  <span class="math">\\widehat{V}</span>  responds with  <span class="math">\\overline{\\mathbf{x}}</span>  that do not all correspond to the respective preimages of  <span class="math">\\overline{\\mathbf{y}}</span> ). Let  <span class="math">p = \\Pr_{r \\leftarrow (\\{0,1\\}^n)^s}[r \\notin \\mathcal{A}]</span> .</p>

    <p class="text-gray-300">Let E denote the event that  <span class="math">S^f(\\varepsilon, n, k, \\widehat{V})</span>  reaches Step 5. By construction,  <span class="math">\\Pr[T = 1] = \\Pr[\\neg E] = 1-p</span> . Moreover, it holds that the random variable T|E is drawn from a geometric distribution with parameter p. Since the latter has expectation 1/p we have that:</p>

    <p class="text-gray-300"><span class="math">$E[T] = \\Pr[\\neg E] \\cdot E[T \\mid \\neg E] + \\Pr[E] \\cdot E[T \\mid E]</span>$</p>

    <p class="text-gray-300"><span class="math">$= (1 - p) \\cdot 1 + p \\cdot \\frac{1}{p}</span>$</p>

    <p class="text-gray-300"><span class="math">$= 2 - p,</span>$
(10)</p>

    <p class="text-gray-300">Thus, in expectation, the simulator invokes  <span class="math">\\hat{V}</span>  at most twice.</p>

    <p class="text-gray-300">Every time  <span class="math">S^f(\\varepsilon,n,k,\\widehat{V})</span>  calls  <span class="math">\\widehat{V}</span> , it samples a random string in  <span class="math">\\{0,1\\}^{n\\cdot s}</span> , evaluates some  <span class="math">h\\in\\mathcal{H}_{n\\cdot t\\cdot s,n\\cdot s}</span> , and makes  <span class="math">O(t\\cdot s)</span>  calls to f. Recall that  <span class="math">t_{\\widehat{V}}</span>  and  <span class="math">q_{\\widehat{V}}</span>  denote the running time and query complexity of  <span class="math">\\widehat{V}</span> , respectively. The expected running time of  <span class="math">S^f(\\varepsilon,n,k,\\widehat{V})</span>  is thus at most  <span class="math">O(t_{\\widehat{V}})+\\operatorname{poly}(t,s,n)=O(t_{\\widehat{V}})+\\operatorname{poly}(n,k,1/\\varepsilon)</span>  (note that by Fact 2.5, evaluation of h can be done in time  <span class="math">\\operatorname{poly}(t,s,n)</span> ). The expected query complexity of  <span class="math">S^f(\\varepsilon,n,k,\\widehat{V})</span>  is thus at most  <span class="math">O(q_{\\widehat{V}}+t\\cdot s)=O(q_{\\widehat{V}}+nk/\\varepsilon^2)</span> .</p>

      <h3 id="sec-4.2" class="text-xl font-semibold mt-8">4.2 Promise Expansion is in HV-SZKPP</h3>

    <p class="text-gray-300">In this section we consider the property of a graph being a &quot;good&quot; expander, in the bounded degree graph model (see [GGR98, GR02]). Recall that in bounded degree graph model, the input graph is represented by an adjacency list and so, using a single query, the verifier can find the  <span class="math">i^{\\rm th}</span>  neighbor of a vertex v.</p>

    <p class="text-gray-300">The property of being a good expander was first considered by Goldreich and Ron [GR11]. They showed that any tester for the (spectral) expansion of a graph on n vertices must make at least  <span class="math">\\Omega(\\sqrt{n})</span>  queries. [GR11] also suggested a testing algorithm that matches this bound and conjectured its correctness. Czumaj and Sohler [CS10] focused on vertex expansion and proved that the [GR11] tester accepts graphs that are good expanders and rejects graphs that are far from having even much worst expansion. More specifically, [CS10] showed that the [GR11] tester accepts graphs with (vertex) expansion  <span class="math">\\alpha</span>  and rejects graphs that are far from having even (vertex) expansion  <span class="math">\\Theta\\left(\\frac{\\alpha^2}{\\log(n)}\\right)</span> . Lastly, Nachmias and Shapira [NS10] and Kale and Seshadhri[KS11] improved [CS10]'s result and showed that the tester in fact rejects graphs that are far from having expansion  <span class="math">\\Theta\\left(\\alpha^2\\right)</span> . We show how to apply [CS10]'s approach to get an honest-verifier statistical zero-knowledge proof of proximity with only a poly-logarithmic dependence on n, as long as we have a similar type of gap between YES and NO instances as in [CS10].</p>

    <p class="text-gray-300">Formally, a vertex expander is defined as follows.</p>

    <p class="text-gray-300"><strong>Definition 4.10</strong> (Vertex expander). Let  <span class="math">\\alpha &gt; 0</span> . A graph  <span class="math">G = (\\mathcal{V}, \\mathcal{E})</span>  is an  <span class="math">\\alpha</span> -expander if for every subset  <span class="math">\\mathcal{U} \\subseteq \\mathcal{V}</span>  of size  <span class="math">|\\mathcal{U}| \\leq |\\mathcal{V}|/2</span> , it holds that  <span class="math">|N(\\mathcal{U})| \\geq \\alpha \\cdot |\\mathcal{U}|</span> , where  <span class="math">N(\\mathcal{U}) := \\{v \\in \\mathcal{V} \\setminus \\mathcal{U} : \\exists u \\in \\mathcal{U} \\text{ such that } (v, u) \\in \\mathcal{E}\\}</span> .</p>

    <p class="text-gray-300">Throughout this section we fix a bound d on the degree of all graphs (which we think of as constant). We identify graphs on n vertices as functions  <span class="math">G \\colon [n] \\times [d] \\to [n] \\cup \\{\\bot\\}</span>  such that G(u,i) = v if v is the i'th neighbor of a vertex u and  <span class="math">G(u,i) = \\bot</span>  if u has less than i neighbors.</p>

    <p class="text-gray-300"><strong>Definition 4.11.</strong> <em>Let</em>  <span class="math">d \\in \\mathbb{N}</span> . For  <span class="math">n \\in \\mathbb{N}</span>  and  <span class="math">\\alpha = \\alpha(n) &gt; 0</span> , let</p>

    <p class="text-gray-300"><span class="math">$\\mathsf{EXPANDER}_n^{d,\\alpha} = \\Big\\{G \\colon [n] \\times [d] \\to [n] \\ \\Big| \\ G \\text{ is a } \\alpha(n)\\text{-expander}\\Big\\}.</span>$</p>

    <p class="text-gray-300">Let  <span class="math">\\beta = \\beta(n) \\in (0, \\alpha(n)]</span> . We define the expander promise problem (see Remark 3.5) as</p>

    <p class="text-gray-300"><span class="math">$\\mathsf{EXPANDER}^{d,\\alpha,\\beta} = \\Big(\\mathsf{EXPANDER}^{d,\\alpha,\\beta}_{\\mathsf{YES},n}, \\mathsf{EXPANDER}^{d,\\alpha,\\beta}_{\\mathsf{NO},n}, [n] \\times [d], [n]\\Big),</span>$</p>

    <p class="text-gray-300">where  <span class="math">\\mathsf{EXPANDER}_{\\mathsf{YFS}\\,n}^{d,\\alpha,\\beta} = \\mathsf{EXPANDER}_n^{d,\\alpha}</span>  and  <span class="math">\\mathsf{EXPANDER}_{\\mathsf{NO}\\,n}^{d,\\alpha,\\beta} = \\mathsf{EXPANDER}_n^{d,\\beta}</span> .</p>

    <p class="text-gray-300">That is, YES instances of the promise problem are graphs that are  <span class="math">\\alpha</span> -expanders and NO instances are graphs that are far from even being  <span class="math">\\beta</span> -expanders, for  <span class="math">\\beta \\leq \\alpha</span> .</p>

    <p class="text-gray-300"><strong>Theorem 4.12</strong> (SZKPP for Expansion). Let  <span class="math">d \\in \\mathbb{N}</span>  and  <span class="math">\\alpha \\in (0,1/3]</span>  be constants. Then, EXPANDER <span class="math">^{d,\\alpha,\\beta} \\in \\mathsf{HV-SZKPP}[\\mathsf{poly}(\\log(n),k,1/\\varepsilon)]</span>  for  <span class="math">\\beta = \\Theta\\Big(\\frac{\\alpha^2}{d^2\\log(n)}\\Big)</span> , where n is the number of vertices in the graph, k is the security parameter and  <span class="math">\\varepsilon</span>  is the proximity parameter.</p>

    <p class="text-gray-300"><em>Proof of Theorem 4.12.</em> We prove Theorem 4.12 by reducing graph expansion to the problem of testing whether two distributions are statistically close. The reduction is such that we can sample from each distribution using few queries to our original input graph. Given this reduction, we</p>

    <p class="text-gray-300">can now use Lemma 2.14 which gives an honest-verifier statistical zero-knowledge proof for verifying whether the distribution induced by two circuits on a random input is statistically close. A crucial observation is that neither the verifier nor the simulator in the latter protocol need to actually look at their input circuits. Rather, they only need to be able to draw relatively few random samples from the distribution induced by the circuit on a random input. Intuitively, by applying our reduction we therefore obtain an honest-verifier statistical zero-knowledge proof for EXPANDER <span class="math">^{d,\\alpha,\\beta}</span> .</p>

    <p class="text-gray-300">We proceed to give an overview of our reduction from EXPANDER <span class="math">^{d,\\alpha,\\beta}</span>  to statistical closeness. The reduction, which is randomized, chooses uniformly at random a vertex u and considers two distributions: the first, denoted by  <span class="math">P_u^\\ell</span> , outputs the last vertex in a random walk of length  <span class="math">\\ell = \\Theta\\left(\\frac{d^2\\log(n)}{\\alpha^2}\\right)</span>  starting at u; the second, denoted by  <span class="math">U_{[n]}</span> , is uniform over all vertices. Observe that both distributions can be sampled using relatively few queries to the input graph.</p>

    <p class="text-gray-300">We observe that if the graph is an  <span class="math">\\alpha</span> -expander (i.e., a YES instance) then for <em>any</em> choice of u, it holds that  <span class="math">\\mathrm{SD}\\big(P_u^\\ell,U_{[n]}\\big)\\approx 0</span>  (and so the two distributions are close). On the other hand, [CS10] showed that if the graph is far from being a  <span class="math">\\Theta\\big(\\frac{\\alpha^2}{d^2\\log(n)}\\big)</span> -expander (i.e., a NO instance), then there exists a set of vertices  <span class="math">\\mathcal U</span>  with  <span class="math">|\\mathcal U|=\\Omega(n)</span>  such that for every  <span class="math">u\\in\\mathcal U</span> , it holds that  <span class="math">\\mathrm{SD}\\big(P_u^\\ell,U_{[n]}\\big)\\gg 0</span> . Thus, in the NO case, with constant probability (over the choice of u), our reduction generates distributions that are statistically far. We proceed to the actual proof.</p>

    <p class="text-gray-300">Our protocol uses the following lazy random walk on the graph G.</p>

    <p class="text-gray-300"><strong>Definition 4.13</strong> (Random walk). Let  <span class="math">G = (\\mathcal{V}, \\mathcal{E})</span>  be a (simple) bounded degree d graph. For  <span class="math">u \\in \\mathcal{V}</span> , define  <span class="math">p_u(v) = 1/2d</span>  if  <span class="math">(u, v) \\in \\mathcal{E}</span>  (i.e., (u, v) is an edge), and  <span class="math">p_u(u) = 1 - \\deg(u)/2d</span> . For  <span class="math">\\ell \\in \\mathbb{N}</span> , a random walk of length  <span class="math">\\ell</span>  starting at u is a random process that chooses  <span class="math">\\ell</span>  vertices  <span class="math">u_1, \\ldots, u_\\ell</span>  such that  <span class="math">u_1 := u</span>  and every vertex  <span class="math">u_{i+1}</span>  is sampled from the distribution  <span class="math">p_{u_i}</span> . The distribution  <span class="math">P_u^\\ell(v)</span>  is the probability that  <span class="math">u_\\ell = v</span> .</p>

    <p class="text-gray-300">Assume without loss of generality that  <span class="math">\\varepsilon \\leq 0.1</span> , where  <span class="math">\\varepsilon</span>  is the proximity parameter.<sup>16</sup> Let  <span class="math">h:[0,1] \\to [0,1]</span>  be the binary entropy function (recall that  <span class="math">h(p) := -p \\log(p) - (1-p) \\log(1-p)</span> ). By a routine calculation, it holds that</p>

    <p class="text-gray-300">
<span class="math">$h\\left(\\frac{1}{2}\\cdot(1+0.2)\\right) \\le h(0.6) &lt; 0.98 &lt; 1-0.01.</span>$
(11)</p>

    <p class="text-gray-300">Thus, we can apply Lemma 2.14, with respect to the constants  <span class="math">\\alpha=0.2</span>  and  <span class="math">\\beta=0.01</span>  to obtain an honest verifier statistical zero knowledge protocol  <span class="math">\\left(\\mathsf{P}^{(\\cdot,\\cdot)}(k),\\mathsf{V}^{(\\cdot,\\cdot)}(k)\\right)</span>  for  <span class="math">\\overline{\\mathsf{SD}^{0.2,0.01}}</span> . Thus,  <span class="math">\\left(\\mathsf{P}^{(\\cdot,\\cdot)}(k),\\mathsf{V}^{(\\cdot,\\cdot)}(k)\\right)</span>  is a statistical zero-knowledge protocol for distinguishing between YES instances, which are pairs of circuits that have statistical distance at most 0.01, from NO instances, which are pairs of circuits whose statistical distance is at least 0.2.<sup>17</sup> Using the latter, we construct a protocol  <span class="math">\\left(\\mathsf{P}_{\\text{expan}},\\mathsf{V}_{\\text{expan}}\\right)</span>  for verifying expansion, which is given in Fig. 3.</p>

    <p class="text-gray-300">The next two lemmas show the completeness and soundness of the expander protocol.</p>

    <p class="text-gray-300"><strong>Lemma 4.14.</strong> Let  <span class="math">n, k \\in \\mathbb{N}</span> , let  <span class="math">\\varepsilon &gt; 0</span>  and let  <span class="math">G: [n] \\times [d] \\to [n]</span> . Assume that G is in  <span class="math">\\mathsf{EXPANDER}_n^{d,\\alpha}</span>  (i.e., G is an  <span class="math">\\alpha</span> -expander), then  <span class="math">\\mathsf{V}_{\\mathsf{expan}}_{\\alpha,d}^G(\\varepsilon,n,k)</span> , when interacting with  <span class="math">\\mathsf{P}_{\\mathsf{expan}}_{\\alpha,d}(\\varepsilon,G,k)</span>  according to the expander protocol (Fig. 3), accepts with probability  <span class="math">1 - \\mathsf{negl}(k)</span> .</p>

    <p class="text-gray-300"> <span class="math">&lt;sup&gt;^{16}&lt;/sup&gt;</span> Otherwise, we can just &quot;reset&quot;  <span class="math">\\varepsilon</span>  to 0.1.</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;17</sup>The constant 0.2 that we use here stems from the analysis of [CS10]. On the other hand, the constant 0.01 is arbitrary (but was chosen so that Equation (11) holds).</p>

    <p class="text-gray-300">Prover's Input: A graph  <span class="math">G: [n] \\times [d] \\to [n]</span> , expansion parameter  <span class="math">\\alpha &gt; 0</span> , proximity parameter  <span class="math">\\varepsilon &gt; 0</span>  and security parameter k.</p>

    <p class="text-gray-300">Verifier's Input:  <span class="math">\\alpha</span> ,  <span class="math">\\varepsilon</span> , n, d, k and oracle access to G.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">V_{\\text{expan}}</span>  samples  <span class="math">u \\leftarrow [n]</span>  and sends u to  <span class="math">P_{\\text{expan}}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The parties construct two oracle circuits: one encodes the distribution  <span class="math">P_u^{\\ell}</span>  for  <span class="math">\\ell = \\left\\lceil \\frac{8d^2}{\\alpha^2} \\ln(\\sqrt{n}/0.01) \\right\\rceil</span> ; the other encodes  <span class="math">U_{[n]}</span> , the uniform distribution on the graph's vertices.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The parties run the protocol  <span class="math">\\left(\\mathsf{P}^{P_u^\\ell,U_{[n]}}(k),\\mathsf{V}^{P_u^\\ell,U_{[n]}}(k)\\right)</span> , where  <span class="math">\\left(\\mathsf{P}^{(\\cdot,\\cdot)},\\mathsf{V}^{(\\cdot,\\cdot)}\\right)</span>  is the protocol for  <span class="math">\\overline{\\mathsf{SD}^{0.2,0.01}}</span>  from Lemma 2.14.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Figure 3: The Expander Protocol</p>

    <p class="text-gray-300">Lemma 4.14 is proven in Section 4.2.1 via a standard analysis of random walks on expanders.</p>

    <p class="text-gray-300"><strong>Lemma 4.15.</strong> Let  <span class="math">n, k \\in \\mathbb{N}</span> , let  <span class="math">0 &lt; \\varepsilon \\le 0.1</span>  and let  <span class="math">G: [n] \\times [d] \\to [n]</span> . Assume that G is  <span class="math">\\varepsilon</span> -far from EXPANDER <span class="math">_n^{d,\\beta}</span>  for  <span class="math">\\beta = \\Theta\\left(\\frac{\\alpha^2}{d^2\\log(n)}\\right)</span> , then for every prover strategy  <span class="math">\\widehat{\\mathsf{P}}</span> , when  <span class="math">\\mathsf{V}_{\\mathrm{expan}}_{\\alpha,d}^G(\\varepsilon,n,k)</span>  interacts with  <span class="math">\\widehat{\\mathsf{P}}</span>  according to the expander protocol (Fig. 3), with probability at least  <span class="math">\\varepsilon/24 - \\mathsf{negl}(k)</span>  it rejects.</p>

    <p class="text-gray-300">Lemma 4.15 is proven in Section 4.2.2 via a combinatorial property of graphs that are  <span class="math">\\varepsilon</span> -far from <em>&beta;</em>-expanders, shown by [CS10].</p>

    <p class="text-gray-300">As for honest-verifier zero-knowledge, let  <span class="math">S^{(\\cdot,\\cdot)}</span>  denote the simulator of the protocol for  <span class="math">\\overline{SD^{0.2,0.01}}</span>  from Lemma 2.14. Note that if G is an  <span class="math">\\alpha</span> -expander, the same mixing argument used to establish completeness implies that  <span class="math">SD(P_u^\\ell,U_{[n]}) \\leq 0.01</span> , for every vertex u (see Section 4.2.1). Hence, for every vertex u it holds that  <span class="math">S^{P_u^\\ell,U_{[n]}}(k)</span>  simulates  <span class="math">\\left(\\mathsf{P}^{P_u^\\ell,U_{[n]}}(k),\\mathsf{V}^{P_u^\\ell,U_{[n]}}(k)\\right)</span>  with simulation deviation at most  <span class="math">\\mu(k)</span> , for some negligible function  <span class="math">\\mu</span> . Our simulator for the expansion protocol, denoted by  <span class="math">S_{\\text{expan}}</span>  will choose a vertex u uniformly at random, and output  <span class="math">\\left(u,\\mathsf{S}^{P_u^\\ell,U_{[n]}}(k)\\right)</span> . Now observe that  <span class="math">S_{\\text{expan}}</span> 's deviation from  <span class="math">V_{\\text{expan}}</span> 's view in  <span class="math">(\\mathsf{P}_{\\text{expan}},\\mathsf{V}_{\\text{expan}})</span>  is precisely equal to the expected deviation, over the choice of a random vertex u, of  <span class="math">\\mathsf{S}^{P_u^\\ell,U_{[n]}}(k)</span>  from the view of  <span class="math">\\mathsf{V}^{P_u^\\ell,U_{[n]}}</span>  in the protocol  <span class="math">\\left(\\mathsf{P}^{P_u^\\ell,U_{[n]}}(k),\\mathsf{V}^{P_u^\\ell,U_{[n]}}(k)\\right)</span> . Since the latter is bounded by  <span class="math">\\mu</span>  for <em>every</em> choice of u, the expected deviation is bounded by  <span class="math">\\mu(k)</span>  as well.</p>

    <p class="text-gray-300">So far we have shown that the expander protocol (Fig. 3) has  <span class="math">\\operatorname{negl}(k)</span>  completeness error,  <span class="math">1-(\\varepsilon/24-\\operatorname{negl}(k))</span>  soundness error and is honest-verifier statistical zero-knowledge. To reduce the soundness error the parties will repeat the above protocol in parallel for  <span class="math">\\operatorname{poly}(k)/\\varepsilon</span>  times. Since honest-verifier statistical zero-knowledge is preserved under parallel repetition, and parallel repetition reduces the soundness errors of IPPs at an exponential rate (see, e.g., [GGR15, Appendix A]), the resulting protocol is an honest-verifier statistical zero-knowledge proof of proximity.</p>

    <p class="text-gray-300">Finally, we argue about the efficiency of  <span class="math">V_{\\text{expan}}</span>  (the analysis of the simulator's efficiency is similar). The verifier  <span class="math">V_{\\text{expan}}</span>  needs to provide  <span class="math">V^{P_u^\\ell,U_{[n]}}(k)</span>  samples from  <span class="math">P_u^\\ell</span>  and  <span class="math">U_{[n]}</span> . Generating a random sample from  <span class="math">U_{[n]}</span>  is easy and requires  <span class="math">O(\\log n)</span>  random coins. Generating a random sample from  <span class="math">P_u^\\ell</span>  is standard as well, requires  <span class="math">\\operatorname{poly}(\\ell,d) = \\operatorname{poly}(\\log n)</span>  random coins and oracle calls</p>

    <p class="text-gray-300">to the input graph. By Lemma 2.14, it follows the  <span class="math">V_{\\text{expan}}</span> 's running time (accounting for the parallel repetition as well) is at most  <span class="math">\\text{poly}(\\log(n), 1/\\varepsilon, k)</span> .</p>

      <h4 id="sec-4.2.1" class="text-lg font-semibold mt-6">4.2.1 Analyzing Completeness &mdash; Proving Lemma 4.14</h4>

    <p class="text-gray-300">Lemma 4.14 is an easy implication of the following standard result regarding random walks on expanders.</p>

    <p class="text-gray-300"><strong>Lemma 4.16</strong> (Expanders are Rapidly Mixing (c.f. [NS10, proof of Theorem 2.1])). Suppose that G is an  <span class="math">\\alpha</span> -expander graph on n vertices with bounded degree d. Then for every vertex u and  <span class="math">\\ell \\in \\mathbb{N}</span>  it holds that  <span class="math">SD(P_u^{\\ell}, U_{[n]}) \\leq \\sqrt{n} \\cdot e^{-\\frac{\\alpha^2}{8d^2} \\cdot \\ell}</span> .</p>

    <p class="text-gray-300"><em>Proof of Lemma 4.14.</em> From the choice of  <span class="math">\\ell</span>  and Lemma 4.16, it holds that</p>

    <p class="text-gray-300"><span class="math">$SD(P_u^{\\ell}, U_{[n]}) \\le 0.01,</span>$</p>

    <p class="text-gray-300">for every vertex u. Let W be the random variable induced by the values of u chosen in step 1 of a random execution of the protocol It follows that</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\Big[\\mathsf{V}_{\\mathsf{expan}}_{\\alpha,d}^G(\\varepsilon,n,k)\\ \\mathsf{accepts}\\Big] = \\Pr\\Big[\\mathsf{V}^{P_W^\\ell,U_{[n]}}(k)\\ \\mathsf{accepts}\\Big] \\geq 1 - \\mathsf{negl}(k),</span>$</p>

    <p class="text-gray-300">where the last inequality follows from the completeness property of (P, V) (Lemma 2.14).</p>

      <h4 id="sec-4.2.2" class="text-lg font-semibold mt-6">4.2.2 Analyzing Soundness &mdash; Proving Lemma 4.15</h4>

    <p class="text-gray-300">The soundness of the expander protocol follows from the following combinatoral property of graphs that are far from expanders.</p>

    <p class="text-gray-300"><strong>Lemma 4.17</strong> ([CS10, Corollary 4.6 and Lemma 4.7]). Let G be a graph on n vertices with bounded degree d. There exists a constant c = c(d) &gt; 0 such that the following holds. If G is  <span class="math">\\varepsilon</span> -far from any  <span class="math">\\beta</span> -expander with  <span class="math">\\beta \\leq 1/10</span> , then there exists  <span class="math">\\mathcal{U} \\subset [n]</span>  with  <span class="math">|\\mathcal{U}| \\geq \\varepsilon \\cdot n/24</span>  such that for every  <span class="math">u \\in \\mathcal{U}</span> , it holds that  <span class="math">SD(P_u^{\\ell}, U_{[n]}) \\geq \\frac{1-2\\varepsilon}{4}</span> , where  <span class="math">\\ell \\leq 1/(10c\\beta)</span> .</p>

    <p class="text-gray-300">Recall that  <span class="math">V_{\\text{expan}}</span> 's first steps is to choose uniformly at random a vertex u. This u will belong to the set  <span class="math">\\mathcal{U}</span>  from the Lemma 4.17 with probability at least  <span class="math">\\varepsilon/24</span> . Conditioned on the latter, we claim that the input to  <span class="math">\\left(\\mathsf{P}^{P_u^\\ell,U_{[n]}}(k),\\mathsf{V}^{P_u^\\ell,U_{[n]}}(k)\\right)</span>  is a NO input and so soundness follows immediately from the soundness of the protocol for  <span class="math">\\overline{\\mathsf{SD}}</span>  (Lemma 2.14).</p>

    <p class="text-gray-300">from the soundness of the protocol for  <span class="math">\\overline{\\mathsf{SD}}</span>  (Lemma 2.14). We argue soundness with respect to  <span class="math">\\beta = \\left\\lfloor \\frac{\\alpha^2}{20 \\cdot c \\cdot d^2 \\cdot \\log(\\sqrt{n}/0.01)} \\right\\rfloor</span> , where c = c(d) &gt; 0 is the constant guaranteed to exist by Lemma 4.17.</p>

    <p class="text-gray-300"><em>Proof of Lemma 4.15.</em> Let  <span class="math">\\widehat{\\mathsf{P}}</span>  be any prover strategy. Let W be the random variable induced by the values of u chosen in step 1 of a random execution of the protocol and let  <span class="math">\\mathcal{U}</span>  be the set guaranteed to exist by Lemma 4.17. It holds that</p>

    <p class="text-gray-300">
<span class="math">$\\Pr\\Big[\\mathsf{V}_{\\mathsf{expan}}_{\\alpha,d}^G(\\varepsilon,n,k)\\ \\mathsf{accepts}\\Big] \\leq \\Pr[W \\notin \\mathcal{U}] + \\Pr\\Big[\\mathsf{V}_{\\mathsf{expan}}_{\\alpha,d}^G(\\varepsilon,n,k)\\ \\mathsf{accepts}\\ \\Big|\\ W \\in \\mathcal{U}\\Big]. \\tag{12}</span>$</p>

    <p class="text-gray-300">We bound both terms in the right-hand side of Equation (12). Lemma 4.17 yields that  <span class="math">\\Pr[W \\notin \\mathcal{U}] \\leq 1-\\varepsilon/24</span> . As for the second term, Lemma 4.17 yields that  <span class="math">\\operatorname{SD}(P_w^\\ell, U_{[n]}) \\geq \\frac{1-2\\varepsilon}{4} \\geq 0.2</span>  for every  <span class="math">w \\in \\mathcal{U}</span>  (note that  <span class="math">\\beta</span>  was chosen so that  <span class="math">\\ell \\leq 1/(10c\\beta)</span>  and that we assumed above that  <span class="math">\\varepsilon &lt; 0.1</span> ). It follows that</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\Big[\\mathsf{V}_{\\mathsf{expan}}{}_{\\alpha,d}^G(\\varepsilon,n,k) \\text{ accepts } \\Big| \\ W \\in \\mathcal{U}\\Big] \\leq \\mathsf{E}_{u \\leftarrow \\mathcal{U}}\\Big[\\Pr\\Big[\\mathsf{V}^{P_u^\\ell,U_{[n]}}(k) \\text{ accepts}\\Big]\\Big] \\leq \\mathsf{negl}(k), \\tag{13}</span>$</p>

    <p class="text-gray-300">where the last inequality follows from the soundness properties of V (Lemma 2.14).</p>

    <p class="text-gray-300">In this section we consider the property of a graph being bipartite in the bounded degree model (we introduced this model in Section 4.2). The property of being a bipartite graph was first considered by Goldrich and Ron [GR02, GR99]. They showed a tester for bipartiteness of graphs with n vertices which makes at most  <span class="math">\\tilde{O}(\\sqrt{n})</span>  queries. They also showed a matching lower bound, namely that any such tester must make at least  <span class="math">\\Omega(\\sqrt{n})</span>  queries.</p>

    <p class="text-gray-300">Rothblum et al. [RVW13] gave an interactive proof of proximity for the following promise version of this property in which the verifier's running time is  <span class="math">\\Theta(\\log n)</span> . In this version, YES instances are bipartite graphs. NO instances, in addition to being far from bipartite, are also well-mixing, namely that a random walk of  <span class="math">\\Theta(\\log n)</span>  steps ends at each vertex with probability at least 1/2n (e.g., expanders). We denote this property by BIPARTITE. In [RVW13]'s protocol, the verifier takes a random walk of length  <span class="math">\\Theta(\\log n)</span>  starting at a randomly chosen vertex (in each step it performs a self-loop with probability at least 1/2; see Definition 4.13). The verifier then sends the prover the start and end vertices of the walk and asks the prover to tell him the parity of the number of non-self-loop steps it took during the walk.</p>

    <p class="text-gray-300">If the graph is bipartite, then the parity of the number of non-self-loops is equal to the parity of the shortest simple path from the start vertex to the end vertex. [RVW13] showed that if the graph is far from being bipartite and well-mixing, then the chance of taking a path of even non-self-loop steps is close to that of taking a path of odd non-self-loop steps. Hence, any cheating prover will fail to convince the verifier.</p>

    <p class="text-gray-300">In fact, it is easy to see that the above protocol is also an honest-verifier perfect zero-knowledge proof of proximity. The simulator will simply act as the verifier: take a random walk and output the parity of the non-self-loop steps in this walk (which the simulator knows since it performs the walk). Since this result follows immediately from [RVW13]'s protocol, we only state an informal version of the it here, and refer the reader to [RVW13] for formal definitions and description of the protocol.</p>

    <p class="text-gray-300"><strong>Theorem 4.18</strong> ([RVW13, Section 5.1], informal). BIPARTITE  <span class="math">\\in</span>  HV-PZKPP[poly(log(N), k,  <span class="math">1/\\varepsilon</span> )].</p>

    <p class="text-gray-300">It is an interesting open question to show a <em>cheating-verifier</em> zero-knowledge proof of proximity for BIPARTITE.</p>

    </section>

    <section id="sec-5" class="mb-10">
      <h2 class="text-2xl font-bold">5 Limitations of SZKPP</h2>

    <p class="text-gray-300">In light of the positive results in Section 4 an important questions rises:</p>

    <p class="text-gray-300">Does every property that has a sub-linear IPP also have a sub-linear statistical zero-knowledge IPP?</p>

    <p class="text-gray-300">We give a negative answer to the above question.<a href="#page-27-2">18</a> Actually we show two incomparable lower bounds:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>There exists a property &Pi; that has an IPP in which the verifier runs in poly-logarithmic time, but the verifier in any zero-knowledge proof of proximity for &Pi; cannot run in polylogarithmic time. (Actually we can even show that such a verifier cannot run in time No(1) , see <a href="#page-28-0">Remark 5.6)</a>.Thus, this lower bound can be viewed as a separation between the class IPPpoly(log(N), k, 1/&epsilon;) and HV-ESZKPPpoly(log(N), k, 1/&epsilon;) .</li>
    </ol></li>
      <li>2. We show an additional lower bound which separates HV-ESZKPPpoly(log(N), k, 1/&epsilon;) even from a weaker class - namely the class of languages admitting <em>non-interactive</em> proofs of proximity, also known as Merlin-Arthur proofs of proximity or MAPs <a href="#page-41-0">[GR16]</a>. However, in contrast to the previous separation from IPPs, this result is conditional: we can only prove it assuming a (very plausible) circuit lower bound. Specifically, we assume that (randomized) DNF&oplus;, namely DNF formulas composed with one layer of parity gates (see <a href="#page-39-10">[CS16,</a> <a href="#page-38-3">ABG</a>+14] and references therein), cannot compute the disjointness function. This circuit lower bound is implied by the assumption that the Arthur-Merlin communication complexity of disjointness is n &epsilon; , for inputs of length n and some constant &epsilon; &gt; 0.</li>
    </ul>

    <p class="text-gray-300">We show that there exists a property &Pi; &isin; IPP[poly(log(N), k, 1/&epsilon;)] but &Pi; &isin;/ HV-ESZKPP[poly(log(N), k, 1/&epsilon;)]. Namely, &Pi; that has an efficient IPP, which <em>unconditionally</em> cannot have such a statistical zeroknowledge IPP. <a href="#page-27-3">19</a></p>

    <p class="text-gray-300"><strong>Theorem 5.1.</strong> IPPpoly(log(N), k, 1/&epsilon;) * HV<em>-</em>ESZKPPpoly(log(N), k, 1/&epsilon;) <em>.</em></p>

    <p class="text-gray-300">The proof of <a href="#page-27-4">Theorem 5.1</a> is done in two steps. The first step is to argue the existence of a property &Pi; which has an interactive proof of proximity with a large number of rounds and polylog(N)-time verifier , but such that in every 2<em>-message</em> interactive proof of proximity for &Pi;, the verifier's running time must be N<sup>&delta;</sup> , for some constant &delta; &gt; 0. Actually, such a result was recently established by Gur and Rothblum <a href="#page-41-2">[GR17]</a>:</p>

    <p class="text-gray-300"><strong>Lemma 5.2</strong> (<a href="#page-41-2">[GR17,</a> Theorem 1])<strong>.</strong> <em>The exists</em> &Pi; &isin; IPP[poly(log(N), k, 1/&epsilon;)] <em>such that the verifier in every</em> 2<em>-message</em> IPP <em>for</em> &Pi;<em>, with respect to proximity parameter</em> &epsilon; = 1/10 <em>and completeness and soundness error</em> 1/3<em>, must run in time</em> &Omega; N<sup>&delta;</sup> <em>, for some universal constant</em> &delta; &gt; 0<em>.</em></p>

    <p class="text-gray-300">The second step in proving <a href="#page-27-4">Theorem 5.1</a> is a general round reduction transformation for any honest-verifier statistical zero-knowledge proof of proximity. Namely, we would like a procedure that takes any <em>many-messages</em> honest-verifier zero-knowledge proof of proximity and turns it into a 2<em>-message</em> honest-verifier zero-knowledge proof of proximity while only slightly deteriorating the verifier's and simulator's running times. Specifically, we show the following lemma.</p>

    <p class="text-gray-300"><strong>Lemma 5.3</strong> (Efficient Round Reduction for SZKPP)<strong>.</strong> <em>Suppose that the property</em> &Pi; <em>has an honest-verifier statistical zero-knowledge</em> &epsilon;<em>-</em>IPP <em>such that for every input length</em> N &isin; N <em>and security parameter</em> k &isin; N <em>the</em></p>

    <p class="text-gray-300"><sup>18</sup>We emphasize that here we refer to <em>statistical</em> zero-knowledge. Indeed, in <a href="#page-33-0">Section 6</a> below we show that for <em>computational</em> zero-knowledge such a transformation is possible, for a large class of IPPs (see <a href="#page-34-0">Theorem 6.2)</a>.</p>

    <p class="text-gray-300"><sup>19</sup>Our actualy result refers to statistical zero-knowledge with <em>expected</em> simulation bounds, but this only makes our result stronger.</p>

    <p class="text-gray-300">simulator's expected running time is bounded by  <span class="math">t_{S}(\\varepsilon, N, k) = t&#x27;_{S}(\\varepsilon, N) \\cdot \\mathsf{poly}(k)</span>  and for every value of  <span class="math">\\varepsilon</span> , the function  <span class="math">t&#x27;_{S}(\\varepsilon, \\cdot)</span>  is monotone non-decreasing.</p>

    <p class="text-gray-300">Then,  <span class="math">\\Pi</span>  has a 2-message honest verifier statistical zero-knowledge  <span class="math">\\varepsilon</span> -IPP such that for every input length N and security parameter k the running time of the verifier is  <span class="math">\\mathsf{poly}(t_{\\mathsf{S}}(\\varepsilon, N, k&#x27;), k)</span> , for  <span class="math">k&#x27; = \\mathsf{poly}(t&#x27;_{\\mathsf{S}}(\\varepsilon, N))</span> .</p>

    <p class="text-gray-300">For the setting of poly-logarithmic zero-knowledge proof of proximity, Lemma 5.3 can be stated as follows.</p>

    <p class="text-gray-300"><strong>Corollary 5.4.</strong> Every  <span class="math">\\Pi \\in \\mathsf{HV}\\text{-}\\mathsf{ESZKPP}[\\mathsf{poly}(\\log(N), k, 1/\\varepsilon)]</span>  has a 2-message honest-verifier statistical zero-knowledge  <span class="math">\\varepsilon\\text{-}\\mathsf{IPP}</span>  with expected simulation, such that the verifier's running time is  <span class="math">\\mathsf{poly}(\\log(N), k, 1/\\varepsilon)</span> .</p>

    <p class="text-gray-300"><strong>Remark 5.5</strong> (Comparison with the Babai-Moran [BM88] Round). <em>Lemma 5.3</em> and <em>Corollary 5.4</em> should be contrasted with the classical round reduction of interactive proofs, due to Babai and Moran [BM88] (and shown in [RVW13] to hold also for IPPs). In contrast to Lemma 5.3, the Babai-Moran round reduction increases the complexity of the verifier exponentially in the round complexity of the original protocol. In contrast, the overhead in Lemma 5.3 is only polynomial, which is crucial for our lower bound.</p>

    <p class="text-gray-300">The proof of Lemma 5.3 is a direct application of the proof that the promise problem Entropy Difference (ED, see Definition 2.12) is complete for the class SZK (see [Vad99]). That proof takes an instance x of any promise problem  <span class="math">\\Pi = (\\Pi_{YES}, \\Pi_{NO}) \\in SZK</span>  and efficiently constructs two distributions X and Y such that if  <span class="math">x \\in \\Pi_{YES}</span>  then  <span class="math">H(X) \\ge H(Y) + 1</span> , and if  <span class="math">x \\in \\Pi_{NO}</span>  then  <span class="math">H(Y) \\ge H(X) + 1</span> . That proof goes on to show a zero-knowledge protocol to distinguish between the case that  <span class="math">H(X) \\ge H(Y) + 1</span>  and the case that  <span class="math">H(Y) \\ge H(X) + 1</span> . Two important points regarding that proof: (1) sampling from X and Y can be done by running (many times) the simulator for the original problem  <span class="math">\\Pi</span> ; (2) the protocol for ED consists of only two messages and requires only sample access to X and Y (we stated this fact in Lemma 2.15).</p>

    <p class="text-gray-300">In our settings, we can view a property  <span class="math">\\Pi</span>  as a promise problem where functions possessing the property are in  <span class="math">\\Pi_{NO}</span> . Then, we can have the verifier &quot;run&quot; the reduction to ED and apply the sample-access protocol for ED. The unbounded prover will behave as in the protocol for ED. Recall that the original simulator (i.e., the one for the property's IPP) required only oracle access to the input function. Since sampling from the distributions only requires running the original simulator, the new verifier can implement this step with only oracle access to the input function and with only polynomial overhead to the running time of the original simulator. We defer the actual proof of Lemma 5.3 to Appendix B.1.</p>

    <p class="text-gray-300">Using Lemmas 5.2 and 5.3 we can now prove Theorem 5.1.</p>

    <p class="text-gray-300"><em>Proof of Theorem 5.1.</em> Let &Pi; be the property guaranteed to exist by Lemma 5.2. Assume towards a contradiction that  <span class="math">\\Pi \\in \\mathsf{HV-ESZKPP}[\\mathsf{poly}(\\log(N), k, 1/\\varepsilon)]</span> . Namely, &Pi; has an honest-verifier statistical zero-knowledge interactive proof of proximity with the simulator's expected running time being  <span class="math">(\\log(N))^{\\alpha} \\cdot k^{\\beta} \\cdot (1/\\varepsilon)^{\\gamma}</span>  for constants  <span class="math">\\alpha, \\beta, \\gamma &gt; 0</span> . Applying Lemma 5.3 with respect to &Pi; yields that &Pi; has a 2-message  <span class="math">\\varepsilon</span> -IPP (P, V), with V's running time being  <span class="math">(\\log(N))^{\\delta_1} \\cdot k^{\\delta_2} \\cdot (1/\\varepsilon)^{\\delta_3}</span>  for constants  <span class="math">\\delta_1 = \\delta_1(\\alpha, \\beta), \\delta_2, \\delta_3 = \\delta_3(\\beta, \\gamma) &gt; 0</span> .</p>

    <p class="text-gray-300">Set  <span class="math">\\varepsilon = 1/10</span>  and k such that the soundness error of (P, V) is at most 1/3. Note that in this setting, V's running time is  <span class="math">O(\\log(N)^{\\delta_1}) = \\text{poly}(\\log(N))</span> . This is a contradiction to Lemma 5.2.  <span class="math">\\square</span></p>

    <p class="text-gray-300"><strong>Remark 5.6.</strong> We remark that the proof of Theorem 5.1 actually establishes the stronger result that  <span class="math">\\Pi</span>  cannot even have an HV-ESZKPP protocol in which the verifier runs in time  <span class="math">N^{o(1)} \\cdot \\mathsf{poly}(k, 1/\\varepsilon)</span> . Indeed, assuming</p>

    <p class="text-gray-300"><em>a simulator with expected running time</em> No(1) &middot; <sup>&alpha;</sup> &middot;k &beta; &middot; (1/&epsilon;) &gamma; <em>, <a href="#page-27-1">Lemma 5.3</a> yields that</em> &Pi; <em>has a</em> 2 &epsilon;<em>-</em>IPP <em>in which the verifier runs in</em> No(1) <em>time, in contradiction to <a href="#page-27-5">Lemma 5.2.</a></em></p>

    <p class="text-gray-300">We show that there exists a property &Pi; &isin; MAPpoly(log(N), k, 1/&epsilon;) but, assuming certain circuit lower bounds, it holds that &Pi; 6&isin; HV-ESZKPPpoly(log(N), k, 1/&epsilon;)</p>

    <p class="text-gray-300">Let t-DNF<sup>&oplus;</sup> refer to depth 3 circuits, whose output gate is an bounded fan-in OR gate, intermediate level are composed of fan-in t AND gates and third layer is composed of (unbounded fan-in) parity gates. The size of a t-DNF<sup>&oplus;</sup> gate is the fan-in of its top gate. A randomized t-DNF<sup>&oplus;</sup> simply refers to a distribution over t-DNF<sup>&oplus;</sup> circuits. We say that a randomized t-DNF<sup>&oplus;</sup> circuit C : {0, 1} <sup>k</sup> &rarr; {0, 1} computes a function f if for every x &isin; {0, 1} k it holds that Pr[C(x) = f(x)] &ge; 2/3.</p>

    <p class="text-gray-300">For any k &isin; N and strings x, y &isin; {0, 1} k , we define DISJk(x, y) = 1 if for every i &isin; [k] it holds that either x<sup>i</sup> = 0 or y<sup>i</sup> = 0 and DISJk(x, y) = 0 otherwise. The following conjecture states that small randomized DNF<sup>&oplus;</sup> circuits cannot compute DISJ. <a href="#page-29-1">20</a></p>

    <p class="text-gray-300"><strong>Conjecture 5.7.</strong> <em>There exists a constant</em> &delta; &gt; 0 <em>such that every randomized</em> t<em>-</em>DNF<sup>&oplus;</sup> <em>of size</em> S <em>that computes</em> DISJ<sup>k</sup> <em>it holds that</em> min(t, log(S)) = &Omega;(k &delta; )<em>.</em></p>

    <p class="text-gray-300">We remark that a randomized t-DNF<sup>&oplus;</sup> circuit of size S yields an Arthur-Merlin communication complexity with complexity log(S) + t. <a href="#page-29-2">21</a> To the best of our knowledge, it is believed that the Arthur-Merlin communication complexity of disjointness is believed to be &Omega;(k) (which would imply <a href="#page-29-3">Conjecture 5.7</a> with &delta; = 1). We mention that proving any non-trivial Arthur-Merlin communication complexity lower bound is a notorious open problem.</p>

    <p class="text-gray-300"><strong>Theorem 5.8.</strong> <em>If <a href="#page-29-3">Conjecture 5.7</a> holds, then</em> MAPpoly(log(N), k, 1/&epsilon;) * HV<em>-</em>ESZKPPpoly(log(N), k, 1/&epsilon;) <em>.</em></p>

    <p class="text-gray-300">We begin by an outline of the proof. Our main tool will be a binary linear error-correcting C : {0, 1} <sup>k</sup> &rarr; {0, 1} n , with constant relative distance and almost-linear<a href="#page-29-4">22</a> blocklength, which is also <em>locally testable</em> and <em>locally decodable</em>. A code C : {0, 1} <sup>k</sup> &rarr; {0, 1} n is locally testable if there exists a procedure that makes only few queries to a word w &isin; {0, 1} n , and determines with high probability if it is a codeword (i.e., if w = C(x) for some message x &isin; {0, 1} k ) or far from the code (see <a href="#page-30-0">Definition 5.9</a> for the formal definition). A code is locally decodable if there exists a procedure that takes as input an index i &isin; [k] and a word w &isin; {0, 1} n close to some codeword C(x), makes only few queries to w, and outputs x<sup>i</sup> with high probability (see <a href="#page-30-1">Definition 5.10</a> for the formal definition).</p>

    <p class="text-gray-300">The property that we consider is the <em>Code Intersection</em> (CI) property. This property consists of pairs of codewords (C(x), C(y)), coded under the foregoing code, such that DISJ(x, y) = 0 (i.e., x and y intersect). This problem was previously considered by Gur and Rothblum <a href="#page-41-0">[GR16]</a> who showed that it has a very efficient MAP (we re-prove this fact since we use a slightly different code).</p>

    <p class="text-gray-300"><sup>20</sup>In contrast, note that there is a very simple CNF formula for computing DISJ.</p>

    <p class="text-gray-300"><sup>21</sup>First, Alice and Bob choose a DNF<sup>&oplus;</sup> circuit from the distribution and specify it to Merlin. Merlin then sends an index of which term in the circuit is satisfied. A single term is an fan-in t AND gate composed with parity gates. Alice and Bob can compute this term's value using 2t communication, by having them send to each other their respective contributions to each of the t parities.</p>

    <p class="text-gray-300"><sup>22</sup>Note that we are using the term &quot;linear&quot; in two different ways. First, the code is a linear function of the message. Second, the length of the codeword is almost linear in the length of messages.</p>

    <p class="text-gray-300">Indeed, it is easy to see that CI has a very efficient MAP. Merlin simply sends to Arthur the index i on which x and y intersect. Arthur, using the local testability, will verify that the input is close to a pair of codewords, and then locally decodes x<sup>i</sup> and y<sup>i</sup> . Arthur accepts iff x<sup>i</sup> = y<sup>i</sup> = 1. This proof of proximity, however, reveals a lot to Arthur (and in particular is not zero-knowledge). Specifically, Arthur learns the index of the intersection. As a matter of fact, this is not a coincidence. We show that, assuming that <a href="#page-29-3">Conjecture 5.7</a> holds, the property CI does not have any honestverifier zero-knowledge IPP with poly-logarithmic complexity.</p>

    <p class="text-gray-300">To see how we prove the lower bound, consider the promise problem <em>Code Disjointness</em> (CD), in which the YES instances are pairs of codewords (C(x), C(y)) such that DISJ(x, y) = 1, and NO instances are pairs of codewords (C(x), C(y)) such that DISJ(x, y) = 0. Note that NO instances of CD are in the property CI. Moreover, YES instances of CD are &delta;(C)/2-far from CI, where &delta;(C) is the relative distance of the code C.</p>

    <p class="text-gray-300">Assume, toward a contradiction, that CI has an honest-verifier statistical zero-knowledge IPP with poly-logarithmic complexity. We argue that this implies that the complement promise problem of CD has a <em>constant-round</em> IPP. The latter fact basically follows from the fact that entropy difference (ED) is complete for the class of promise problems having a statistical zero-knowledge proof, and is itself closed under complement.</p>

    <p class="text-gray-300">Thus, we have constructed an IPP which accepts inputs from CD and rejects inputs from CI. Using a result of Rothblum <em>et-al.</em> <a href="#page-42-2">[RVW13]</a>, we can derive from this IPP a quasi-polynomial size randomized DNF for the same promise problem. We further observe that since the code C is a <em>linear</em> code, we have obtained a circuit that computes the disjointness function on input (x, y) by first applying a linear transformation and then the aforementioned randomized DNF. Or in other words, a quasi-polynomial sized DNF<sup>&oplus;</sup> circuit. This contradicts <a href="#page-29-3">Conjecture 5.7.</a></p>

    <p class="text-gray-300">We proceed to the formal proof of <a href="#page-29-5">Theorem 5.8.</a> We begin with definitions and notations. An error-correcting code is an injective function C : {0, 1} <sup>k</sup> &rarr; {0, 1} n . The code C is said to have relative distance &delta;(C) if for any x 6= x <sup>0</sup> &isin; {0, 1} k it holds that &#8710;(C(x), C(x 0 )) &ge; &delta;(C). <a href="#page-30-2">23</a> Throughout this work we deal with (uniform) algorithms, and so we will need (families of) error-correcting codes. Formally, for a parameters k = k(<code>) &ge; 1 and = n(</code>) &ge; k(<code>) we define an ensemble of error correcting code as an ensemble C = C</code> : {0, 1} <sup>k</sup>(<code>) &rarr; {0, 1} n(</code>) <code>&isin;N of error-correcting codes. An ensemble of error correcting codes C = (C</code>)<code>&isin;&lt;sup&gt;N&lt;/sup&gt; is said to have relative distance &delta;(C) if for all sufficiently large </code>, each code C\` in the ensemble has relative distance &delta;(C).</p>

    <p class="text-gray-300">We next formally define locally testable and decodable codes.</p>

    <p class="text-gray-300"><strong>Definition 5.9</strong> ((strong) locally testable codes (c.f. <a href="#page-41-7">[GS06]</a>))<strong>.</strong> <em>Let</em> t: N &rarr; N<em>. A ensemble of errorcorrecting code</em> C = C<code> : {0, 1} &lt;sup&gt;k&lt;/sup&gt;(</code>) &rarr; {0, 1} n(<code>) </code>&isin;N <em>is</em> t-locally-testable <em>if there exists a probabilistic algorithm (tester)</em> T <em>that, given explicit input</em> <code> *and oracle access to* w &isin; {0, 1} n(</code>) <em>, runs in time</em> t(\`)<em>, and satisfies the following.</em></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><strong>Completeness:</strong> <em>For every</em> x &isin; {0, 1} k(<code>) *it holds that* Pr-T C</code>(x) (\`) = 1 = 1<em>.</em></li>
      <li><strong>Soundness:</strong> <em>For every</em> w &isin; {0, 1} n(<code>) *it holds that* Pr[T &lt;sup&gt;w&lt;/sup&gt;(</code>) = 0] &ge; &Omega;(&#8710;(w,Im(C<code>)))*, where* &#8710;(w,Im(C</code>)) <em>is the relative distance of</em> w <em>from the code.</em><a href="#page-30-3">24</a></li>
    </ul>

    <p class="text-gray-300"><sup>23</sup>Recall that the relative distance between y &isin; {0, 1} n and y <sup>0</sup> &isin; {0, 1} n is defined as &#8710;(y, y<sup>0</sup> ) = |{<sup>y</sup>i6=<sup>y</sup> 0 i : <sup>i</sup>&isin;[n]}| .</p>

    <p class="text-gray-300">n <sup>24</sup>Recall that the relative distance of x &isin; {0, 1} n from a non-empty set S &sube; {0, 1} is defined as &#8710;(x, S) = miny&isin;S &#8710;(x, y).</p>

    <p class="text-gray-300"><strong>Definition 5.10</strong> (locally decodable codes (c.f. [KT00])). Let  <span class="math">t: \\mathbb{N} \\to \\mathbb{N}</span> . A ensemble of error-correcting code  <span class="math">C = (C_{\\ell}: \\{0,1\\}^{k(\\ell)} \\to \\{0,1\\}^{n(\\ell)})_{\\ell \\in \\mathbb{N}}</span>  is t-locally-decodable if there exists a constant  <span class="math">\\delta_{\\mathsf{radius}} \\in (0, \\delta(C)/2)</span>  and a probabilistic algorithm (decoder) D that, given oracle access to  <span class="math">w \\in \\{0,1\\}^n</span>  and explicit inputs  <span class="math">i \\in [k]</span>  and  <span class="math">\\ell \\in \\mathbb{N}</span> , runs in time  <span class="math">t(\\ell)</span>  and satisfies the following.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Completeness: For every  <span class="math">i \\in [k(\\ell)]</span>  and  <span class="math">x \\in \\{0,1\\}^{k(\\ell)}</span> , it holds that  <span class="math">\\Pr[D^{C(x)}(i) = x_i] = 1</span> .</li>
      <li>Soundness: For every  <span class="math">i \\in [k(\\ell)]</span>  and every  <span class="math">w \\in \\{0,1\\}^{n(\\ell)}</span>  with  <span class="math">\\Delta(w,C(x)) \\leq \\delta_{\\mathsf{radius}}</span> , it holds that  <span class="math">\\Pr[D^w(i) = x_i] \\geq 2/3</span> .</li>
    </ul>

    <p class="text-gray-300">We use the following well-known fact.</p>

    <p class="text-gray-300"><strong>Lemma 5.11.</strong> There exists an ensemble of binary linear codes  <span class="math">C = (C_{\\ell} : \\{0,1\\}^{k(\\ell)} \\to \\{0,1\\}^{n(\\ell)})_{\\ell \\in \\mathbb{N}&#x27;}</span>  for  <span class="math">k(\\ell) = \\tilde{O}(\\ell)</span>  and  <span class="math">n(\\ell) \\leq k(\\ell)^{1.01}</span> , whose relative distance is some constant  <span class="math">\\delta &gt; 0</span>  and that is  <span class="math">\\operatorname{polylog}(\\ell)</span> -locally-testable and  <span class="math">\\operatorname{polylog}(\\ell)</span> -locally-decodable.</p>

    <p class="text-gray-300">See Appendix B.3 for a sketch of the construction (which is basically the concatenation of the low degree extension code, over a field of poly-logarithmic size, with a good binary code).</p>

    <p class="text-gray-300">Using Lemma 5.11, we can now define the property <em>Code Intersection</em>.</p>

    <p class="text-gray-300"><strong>Definition 5.12</strong> (Code Intersection). <em>Let</em>  <span class="math">C = (C_{\\ell})_{\\ell \\in \\mathbb{N}}</span>  <em>be the code guaranteed to exist by Lemma 5.11. For</em>  <span class="math">\\ell \\in \\mathbb{N}</span> <em>, let</em></p>

    <p class="text-gray-300"><span class="math">$\\mathsf{CI}_{\\ell} = \\Big\\{ \\big( C_{\\ell}(x), C_{\\ell}(y) \\big) \\colon x, y \\in \\{0, 1\\}^{k(\\ell)} \\text{ such that } \\mathsf{DISJ}_{k(\\ell)}(x, y) = 0 \\Big\\}.</span>$</p>

    <p class="text-gray-300">We define the Code Intersection property as  <span class="math">CI = (CI_{\\ell}, [2n(\\ell)], \\{0, 1\\})_{\\ell \\in \\mathbb{N}}</span> .</p>

    <p class="text-gray-300">The proof of Theorem 5.8 follows immediately from the next two lemmas, proven in Sections 5.2.1 and 5.2.2.</p>

    <p class="text-gray-300">Lemma 5.13.  <span class="math">\\mathsf{CI} \\in \\mathsf{MAP} \\big[ \\mathsf{poly}(\\log(N), k, 1/\\varepsilon) \\big].</span></p>

    <p class="text-gray-300"><strong>Lemma 5.14.</strong> <em>If Conjecture</em> 5.7 <em>holds, then</em>  <span class="math">\\mathsf{CI} \\notin \\mathsf{HV-ESZKPP}[\\mathsf{poly}(\\log(N), k, 1/\\varepsilon)].</span></p>

      <h4 id="sec-5.2.1" class="text-lg font-semibold mt-6"><strong>5.2.1 Proving Lemma 5.13</strong></h4>

    <p class="text-gray-300">Consider the protocol  <span class="math">(P_{CI}, V_{CI})</span>  from Fig. 4. Perfect completeness follows from the perfect completeness in the local testing and decoding procedures. We proceed to argue that soundness holds.</p>

    <p class="text-gray-300">Fix  <span class="math">\\varepsilon &gt; 0</span> , sufficiently large  <span class="math">\\ell \\in \\mathbb{N}</span>  and  <span class="math">w = (w_1, w_2) \\in \\{0, 1\\}^{2 \\cdot n(\\ell)}</span>  such that w is  <span class="math">\\varepsilon</span> -far from  <span class="math">\\text{Cl}_{\\ell}</span> . We assume without loss of generality that  <span class="math">\\varepsilon &lt; \\delta_{\\text{radius}}</span>  (otherwise &quot;reset&quot;  <span class="math">\\varepsilon</span>  to  <span class="math">\\delta_{\\text{radius}}</span> ). We consider two cases:</p>

    <p class="text-gray-300"><span class="math">\\Delta(w_1, \\operatorname{Im}(C_\\ell)) \\ge \\varepsilon/2</span>  or  <span class="math">\\Delta(w_2, \\operatorname{Im}(C_\\ell)) \\ge \\varepsilon/2</span> : Let  <span class="math">j \\in \\{1, 2\\}</span>  such that  <span class="math">\\Delta(w_j, \\operatorname{Im}(C_\\ell)) \\ge \\epsilon/2</span> . By the soundness condition of the tester T, it holds that</p>

    <p class="text-gray-300"><span class="math">$\\Pr[\\mathsf{V_{CI}}^w(\\varepsilon,n(\\ell)) \\text{ rejects}] \\geq \\Pr[\\mathsf{T}^{w_j}(\\ell)=0] \\geq \\Omega(\\Delta(w_j,\\operatorname{Im}(C_\\ell))) \\geq \\Omega(\\varepsilon/2).</span>$</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;25</sup>Since  <span class="math">\\delta_{\\text{radius}} \\leq \\delta_C/2</span>  the message x is unique.</p>

    <h4 id="sec-misc-2" class="text-lg font-semibold mt-6">The Code Intersection Protocol (P<sub>CI</sub>, V<sub>CI</sub>)</h4>

    <p class="text-gray-300">Prover's Input: A pair of strings  <span class="math">(w_1, w_2) \\in \\{0, 1\\}^{2 \\cdot n(\\ell)}</span>  and proximity parameter  <span class="math">\\varepsilon &gt; 0</span> . Verifier's Input:  <span class="math">\\ell</span> ,  <span class="math">n(\\ell)</span> ,  <span class="math">\\varepsilon</span>  and oracle access to  <span class="math">(w_1, w_2)</span> .</p>

    <p class="text-gray-300">Let <em>C</em> be the code ensemble from Lemma 5.11.</p>

    <p class="text-gray-300">Let T be the tester from Definition 5.9 with respect to C.</p>

    <p class="text-gray-300">Let  <span class="math">\\delta_{\\text{radius}}(C)</span>  and D be the decoding radius and decoder, respectively, from Definition 5.10 with respect to C.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>1.  <span class="math">P_{CI}</span>  finds  <span class="math">i \\in [k(\\ell)]</span>  such that  <span class="math">w = (C_{\\ell}(x), C_{\\ell}(y))</span>  for some  <span class="math">x, y \\in \\{0, 1\\}^{k(\\ell)}</span>  and  <span class="math">x_i = y_i</span> . Sends i to  <span class="math">V_{CI}</span> .</li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">V_{CI}</span>  acts as follows:</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(a) Set  <span class="math">\\varepsilon = \\min\\{\\varepsilon, 2\\delta_{\\mathsf{radius}}(C)\\}.</span></li>
      <li>(b) Run  <span class="math">\\mathsf{T}^{w_1}(\\ell)</span>  and  <span class="math">\\mathsf{T}^{w_2}(\\ell)</span>  and reject if any of them rejects.</li>
      <li>(c) Accept if  <span class="math">\\mathsf{D}^{w_1}(i,\\ell) = \\mathsf{D}^{w_2}(i,\\ell) = 1</span> , and otherwise reject.</li>
    </ul></li>
    </ul>

    <p class="text-gray-300">Figure 4: The Code Intersection Protocol</p>

    <p class="text-gray-300"><span class="math">\\Delta(w_1,\\operatorname{Im}(C_\\ell)) \\leq \\varepsilon/2</span>  and  <span class="math">\\Delta(w_2,\\operatorname{Im}(C_\\ell)) \\leq \\varepsilon/2</span> : Fix a cheating prover  <span class="math">\\widehat{\\mathsf{P}}</span> . Assume without loss of generality that  <span class="math">\\widehat{\\mathsf{P}}</span>  is deterministic and let  <span class="math">i^*</span>  be the index it sends to  <span class="math">\\mathsf{V}_{\\mathsf{Cl}}</span>  in step 1. Let  <span class="math">x,y \\in \\{0,1\\}^{k(\\ell)}</span>  such that  <span class="math">\\Delta(w_1,C_\\ell(x)) \\leq \\varepsilon/2</span>  and  <span class="math">\\Delta(w_2,C_\\ell(y)) \\leq \\varepsilon/2</span>  (such x and y are unique since  <span class="math">\\varepsilon \\leq \\delta_{\\mathsf{radius}}(C)</span> ). Moreover, as w is  <span class="math">\\varepsilon</span> -far from  <span class="math">\\mathsf{Cl}_\\ell</span> , it must be that either  <span class="math">x_{i^*}=0</span>  or  <span class="math">y_{i^*}=0</span> . Observe that if  <span class="math">x_{i^*}=0</span> , then by the soundness of the decoding procedure, with probability 2/3, the decoder will output 0 in which case our verifier rejects. The case that  <span class="math">y_{i^*}=0</span>  is analyzed similarly.</p>

    <p class="text-gray-300">Combining both conditions, it holds that  <span class="math">\\Pr[V_{Cl}^{w}(\\varepsilon, n(\\ell)) \\text{ rejects}] \\ge \\min\\{\\Omega(\\varepsilon/2), 1/3\\} = \\Omega(\\varepsilon)</span> .</p>

    <p class="text-gray-300">So far we have shown that the code intersection protocol (Fig. 4) has prefect completeness and soundness error  <span class="math">1 - O(\\varepsilon)</span> . To reduce the soundness error it suffices to have the verifier repeat its check  <span class="math">\\operatorname{poly}(k)/\\varepsilon</span>  times.<sup>26</sup> As shown in [GR16] this reduces the soundness error to  <span class="math">2^{-k}</span>  and so the resulting protocol is an  <span class="math">\\varepsilon</span> -MAP.</p>

    <p class="text-gray-300">Finally, it is easy to verify that the ultimate verifier run in time  <span class="math">\\mathsf{poly}(\\log(\\ell), k, 1/\\varepsilon)</span>  which, since the input length (i.e.,  <span class="math">2 \\cdot n(\\ell)</span> ) is  <span class="math">\\mathsf{poly}(\\ell)</span> , is  <span class="math">\\mathsf{poly}(\\log(N), k, 1/\\varepsilon)</span> .</p>

      <h4 id="sec-5.2.2" class="text-lg font-semibold mt-6"><strong>5.2.2</strong> Proof of Lemma <strong>5.14</strong></h4>

    <p class="text-gray-300">We prove the contrapositive. Assume that  <span class="math">\\mathsf{CI} \\in \\mathsf{HV}\\text{-}\\mathsf{ESZKPP}\\big[\\mathsf{poly}(\\log(N), k, 1/\\varepsilon)\\big]</span>  and consider the promise problem of <em>Code Disjointness</em>.</p>

    <p class="text-gray-300"><strong>Definition 5.15</strong> (Code Disjointness). <em>For</em>  <span class="math">\\ell \\in \\mathbb{N}</span> , <em>let</em></p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\mathsf{CD}_{\\mathsf{YES},\\ell} &amp;= \\Big\\{ \\big( C_\\ell(x), C_\\ell(y) \\big) \\colon x,y \\in \\{0,1\\}^{k(\\ell)} \\text{ such that } \\mathsf{DISJ}_{k(\\ell)}(x,y) = 1 \\Big\\} \\\\ \\mathsf{CD}_{\\mathsf{NO},\\ell} &amp;= \\Big\\{ \\big( C_\\ell(x), C_\\ell(y) \\big) \\colon x,y \\in \\{0,1\\}^{k(\\ell)} \\text{ such that } \\mathsf{DISJ}_{k(\\ell)}(x,y) = 0 \\Big\\}. \\end{split}</span>$</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;26</sup>Note that here k refers to the security parameter and not the message length  <span class="math">k(\\ell)</span> .</p>

    <p class="text-gray-300">Let
<span class="math">$CD = (CD_{YES,\\ell}, CD_{NO,\\ell})_{\\ell \\in \\mathbb{N}}</span>$
.</p>

    <p class="text-gray-300">Note that the input length here is N = 2 &middot; n(<code>) = O&tilde;(</code> <sup>1</sup>.01). Hence, the query complexity and communication complexity of the IPP are poly(log(\`), k, 1/&epsilon;).</p>

    <p class="text-gray-300">We will use the zero-knowledge proof of proximity for CI to design a randomized DNF<sup>&oplus;</sup> circuit that solves disjointness. Note that by definition CDNO,<code> = CI</code> .</p>

    <p class="text-gray-300">Observe that every string w &isin; CDYES,<code> is &delta;(C)/2-far from CI</code> . Thus, an (honest-verifier) statistical zero-knowledge IPP for CI immediately yields an (honest-verifier) statistical zero-knowledge proof for the complement of CD. Recall that in <a href="#page-27-0">Section 5.1</a> we used that entropy difference (ED) is complete for the class SZK. Here, we will use this fact again, plus that there is an easy reduction from ED to its complement, to show the following claim, proven in <a href="#page-44-2">Appendix B.2.</a></p>

    <p class="text-gray-300"><strong>Claim 5.16.</strong> <em>The promise problem</em> CD <em>has an interactive proof system with the following properties.</em></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><em>1. The verifier gets</em> <code> *as explicit input and oracle access to* w &isin; CDYES,</code> &cup; CDNO,\`<em>.</em></li>
      <li><em>2. The completeness and soundness errors are both</em> 1/3<em>.</em></li>
      <li><em>3. The verifier's running time is</em> poly(log(\`))<em>.</em></li>
      <li><em>4. The parties exchange a constant number of messages.</em></li>
    </ul>

    <p class="text-gray-300">Using the Goldwasser-Sipser <a href="#page-41-8">[GS89]</a> transformation from private-coin to public-coin interactive proofs and the Babai-Moran <a href="#page-39-11">[BM88]</a> round reduction (see <a href="#page-42-2">[RVW13,</a> Section 4] for more details). We obtain a 2-message Arthur Merlin interactive proof, where the verifier runs in time polylog(\`). Applying an additional transformation from such proof-systems to randomized DNFs due to <a href="#page-42-2">[RVW13]</a> (see also <a href="#page-41-2">[GR17]</a>), we can obtain the following:</p>

    <p class="text-gray-300"><strong>Claim 5.17</strong> (Based on <a href="#page-42-2">[RVW13,</a> Section 4])<strong>.</strong> <em>There exists a randomized</em> polylog(<code>)*-*DNF *of size* 2 polylog(</code>) <em>that computes (the promise problem)</em> CD <em>for inputs of size</em> 2 &middot; n(\`)<em>.</em></p>

    <p class="text-gray-300">By observing that all w &isin; CDY ES,<code> &cup; CDNO,</code> are composed of two codewords, and the the code is a binary <em>linear</em> error correcting code, <a href="#page-33-2">Claim 5.17</a> implies that there exists a randomized polylog(<code>)-DNF&lt;sup&gt;&oplus;&lt;/sup&gt; circuit of size 2 polylog(</code>) that computes DISJk(\`) . This contradicts <a href="#page-29-3">Conjecture 5.7.</a> This concludes the proof of <a href="#page-31-2">Section 5.2.1.</a></p>

    <p class="text-gray-300"><strong>Remark 5.18</strong> (Relaxed Local Decoders and the <a href="#page-40-11">[GGK15]</a> Code)<strong>.</strong> <em>We remark that for our result, as in <a href="#page-41-0">[GR16]</a> it suffices for us to use</em> relaxed <em>local decoders (as put forth in <a href="#page-39-6">[BGH</a></em>+<em>06]). Loosely speaking, relaxed local decoding allows the decoder to refuse to decode if it notices that the word is corrupt.</em></p>

    <p class="text-gray-300"><em>Given that, it is tempting to ask why we did not use the locally testable and (relaxed) decodable codes of Golderich et-al. <a href="#page-40-11">[GGK15]</a>. Indeed, their codes have</em> constant-query <em>whereas the code that we used requires poly-logarithmic query complexity. The only reason that we do not use the <a href="#page-40-11">[GGK15]</a> code is that the</em> computational <em>complexity of this code was not analyzed in <a href="#page-40-11">[GGK15]</a>.</em></p>

    <p class="text-gray-300">In this section we show that, assuming reasonable cryptographic assumptions (specifically, the existence of one-way or collision-resistant hash functions), a large class of IPPs and arguments of proximity<sup>27</sup> can be transformed to be zero-knowledge. As a consequence, using the results of [RVW13, RRR16, Kil92, BGH+06, DR06] we obtain computational ZK proofs of proximity for small-depth and for small-space computations, and statistical ZK arguments of proximity for all of NP.</p>

    <p class="text-gray-300">Our transformation should be contrasted with an analogous transformation of Ben-Or <em>etal</em>. [BGG<sup>+</sup>88] for classical public-coin interactive proofs (and arguments). Indeed, our transformation is based on the main idea of [BGG<sup>+</sup>88]. However, in contrast to their result, our transformation does not apply to <em>arbitrary</em> public-coin IPPs. Rather, it only applies to such IPPs in which the queries that the verifier makes do not depend on messages sent by the prover. We say that such IPPs make <em>prover-oblivious queries</em>.</p>

    <p class="text-gray-300"><strong>Definition 6.1.</strong> We say that an IPP makes prover-oblivious queries if the input locations that the verifier queries are fully determined by its random coin tosses and the answers to previous queries that it made. That is, the queries do not depend on messages sent by the prover.</p>

    <p class="text-gray-300">Thus, an IPP with prover-oblivious queries can be thought of as a two steps process. In the first step the verifier can make queries to its input but it is not allowed to interact with the prover. In the second step, the parties are allowed to interact but the verifier is no longer allowed to query the input.<sup>28</sup></p>

    <p class="text-gray-300">Interestingly (and crucially for our purpose), the <em>general purpose</em> IPPs and arguments of proximity in the literature are indeed public-coin and make only prover-oblivious queries. Using this fact, together with our transformation, we obtain general purpose ZK proofs of proximity.</p>

    <p class="text-gray-300">Our main transformation is summarized in the following two theorems.</p>

    <p class="text-gray-300"><strong>Theorem 6.2</strong> (IPPs  <span class="math">\\rightarrow</span>  Computational ZK). Assume that one-way functions exist. Suppose that the language  <span class="math">\\mathcal{L}</span>  has an  <span class="math">\\ell</span> -message public-coin IPP with prover oblivious queries where the verifier runs in time  <span class="math">t_{\\mathsf{V}} = t_{\\mathsf{V}}(N,k,\\varepsilon)</span>  and the (honest) prover runs in time  <span class="math">t_{\\mathsf{P}} = t_{\\mathsf{P}}(N,k,\\varepsilon)</span> . Then,  <span class="math">\\mathcal{L}</span>  has an  <span class="math">(\\ell + \\mathsf{poly}(k))</span> -message computational ZKPP in which the prover runs in time  <span class="math">t&#x27;_{\\mathsf{P}}(N,k,\\varepsilon) := (t_{\\mathsf{P}}(N,k,\\varepsilon) + \\mathsf{poly}(t_{\\mathsf{V}}(n,k,\\varepsilon)))</span> &middot; poly(k) and the verifier runs in time  <span class="math">t&#x27;_{\\mathsf{V}}(N,k,\\varepsilon) := t_{\\mathsf{V}}(N,k,\\varepsilon) \\cdot \\mathsf{poly}(k)</span> . The simulation overhead (see discussion in Section 3) is  <span class="math">s(t_{\\widehat{\\mathsf{V}}},N,k,\\varepsilon) = t_{\\widehat{\\mathsf{V}}} \\cdot \\mathsf{poly}(k)</span> , for cheating verifiers that run in time  <span class="math">t_{\\widehat{\\mathsf{V}}} = t_{\\widehat{\\mathsf{V}}}(N,k,\\varepsilon)</span> .</p>

    <p class="text-gray-300"><strong>Theorem 6.3</strong> (Arguments of Proximity  <span class="math">\\rightarrow</span>  Statistical ZK Arguments). Assume that one-way functions exist. Suppose that the language  <span class="math">\\mathcal{L}</span>  has an  <span class="math">\\ell</span> -message public-coin interactive argument of proximity with prover oblivious queries where the verifier runs in time  <span class="math">t_V = t_V(N, k, \\varepsilon)</span>  and the (honest) prover runs in time  <span class="math">t_P = (N, k, \\varepsilon)</span> . Then,  <span class="math">\\mathcal{L}</span>  has an  <span class="math">(\\ell \\cdot \\mathsf{poly}(k))</span> -message statistical zero-knowledge argument of proximity in which the prover runs in time  <span class="math">t_P&#x27;(N, k, \\varepsilon) := (t_P(N, k, \\varepsilon) + \\mathsf{poly}(t_V(N, k, \\varepsilon))) \\cdot \\mathsf{poly}(k)</span>  and the verifier runs in time  <span class="math">t_V&#x27;(N, k, \\varepsilon) := t_V(N, k, \\varepsilon) \\cdot \\mathsf{poly}(k)</span> .</p>

    <p class="text-gray-300">Furthermore, if there exist collision-resistant hash functions, then the round complexity of the foregoing argument-system can be reduced to  <span class="math">(\\ell + O(1))</span> .</p>

    <p class="text-gray-300">Our proof of Theorems 6.2 and 6.3 is based on the idea, which originates in the work of Ben-Or <em>et-al</em>. [BGG<sup>+</sup>88], of having the prover commit to its messages rather than sending them in the clear. Since the protocol is <em>public-coin</em> the verifier can continue the interaction even though it does</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;27</sup>An argument of proximity is similar to an IPP except that the soundness condition is further relaxed and required to hold only for polynomial-time cheating provers. See [KR15] for details and a formal definition.</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;28</sup>Our notion of <em>prover-oblivious queries</em> extends the notion of <em>proof-oblivious queries</em> studied by Gur and Rothblum [GR16] in the context of MAPs (i.e., non-interactive proofs of proximity).</p>

    <p class="text-gray-300">not see the actual contents of the prover's messages. After all commitments have been sent, the verifier only needs to check that there exist suitable decommitments that would have made the underlying IPP verifier accept. Since the commitment hides the contents of the messages, it cannot do so by itself and we would like to use the prover. At this point, one could try to naively argue that the residual statement is an NP statement, and so we can invoke a general purpose zero-knowledge protocol for NP (e.g., the classical [GMW91] protocol or the more efficient [IKOS09] protocol).<sup>29</sup></p>

    <p class="text-gray-300">Herein arises the main difficulty with this approach. While the statement that the verifier needs to check at the end of the interaction does consist of an existential quantifier applied to a polynomial-time computable predicate, the latter predicate makes oracle access to the input x and so we do not know how to express it as an NP statement. To resolve this difficulty, we restrict our attention to verifiers that make <em>prover-oblivious queries</em>. Thus, our verifier can actually make its queries before and we can construct a NP statement that refers to the actual values that it reads from the input. At this point we can indeed invoke a general purpose zero-knowledge protocol for NP and conclude the proof.</p>

    <p class="text-gray-300">Lastly, we remark that the specific flavor of soundness and zero-knowledge that we obtain depends on the commitment scheme we use. Specifically, instantiating the above approach with a computationally hiding and statistically binding commitment scheme yields a <em>computational</em> zero-knowledge proof of proximity, whereas a statistically hiding and computationally binding one yields a statistical zero-knowledge <em>argument</em> of proximity.</p>

    <p class="text-gray-300">As noted above, we need the following result from [IKOS09]:</p>

    <p class="text-gray-300"><strong>Lemma 6.4</strong> ([IKOS09]). Let  <span class="math">\\mathcal{L} \\in NP</span>  with witness relation  <span class="math">R(\\cdot, \\cdot)</span>  that is computable in time t. If there exist one-way functions, then  <span class="math">\\mathcal{L}</span>  has a computational zero-knowledge proof in which the verifier runs in time  <span class="math">\\tilde{O}(t) \\cdot \\text{poly}(k)</span>  and the prover runs in time poly(N, k). For every (malicious) verifier running in time T, the simulator runs in time  <span class="math">(T + \\tilde{O}(t)) \\cdot \\text{poly}(k)</span> . The number of rounds is poly(k).</p>

    <p class="text-gray-300">Actually, since the running times are not specified in [IKOS09], we give an overview of the construction in Appendix B.4.</p>

    <p class="text-gray-300">We proceed to give a proof sketch of Theorem 6.2 and note that Theorem 6.3 is proved similarly (using statistically hiding commitments).<sup>30</sup></p>

    <p class="text-gray-300"><em>Proof Sketch of Theorem 6.2.</em> The existence of one-way functions implies the existence of the following cryptographic protocols that we will use:</p>

    <p class="text-gray-300">&bull; A computationally hiding and statistically binding commitment scheme [Nao91, HILL99]. Moreover, after one initial set-up message from the receiver to the sender (where this setup can be re-used for a polynomial number of commitments), the commitment scheme is non-interactive: the sender only needs to send a single message to the receiver. (This commitment scheme will be used to derive the first part of Theorem 6.2.)</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;29</sup>The verifier in the [IKOS09] protocol runs in time that is <em>linear</em> in the complexity t of the NP verification process. In contrast, the [GMW91] verifier runs in time poly(t). The distinction is important for us since in Corollaries 6.8 and 6.9 below, we will apply Theorem 6.2 on a statement that can be verified in roughly  <span class="math">\\sqrt{n}</span>  time, and so we cannot afford a polynomial overhead.</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;30</sup>Note that statistically hiding commitments can be based on any one-way function [HNO<sup>+</sup>09]. For the furthermore part, we need to use <em>constant-round</em> statistically hiding commitments and <em>constant-round</em> statistical zero-knowledge arguments for NP. Both are known to exist assuming collision resistant hash functions [NY89, BCY91].</p>

    <p class="text-gray-300">&bull; Computational zero-knowledge proofs for any language in NP in which the verifier runs in time that is almost linear in the complexity of the witness relation (see Lemma 6.4).</p>

    <p class="text-gray-300">Let (P,V) be an  <span class="math">\\ell</span> -round public-coin IPP for  <span class="math">\\mathcal L</span>  with prover oblivious queries. We describe the construction of a computational zero-knowledge proof of proximity for  <span class="math">\\mathcal L</span> . As alluded to above, the construction of a statistical zero-knowledge argument of proximity is similar, except that we replace the computationally hiding and statistically binding commitment with one that is statistically hiding and computationally binding, and replace the computational zero-knowledge proof for NP with a statistical zero-knowledge argument.</p>

    <p class="text-gray-300">We proceed to describe the computational ZKPP (P', V') for  <span class="math">\\mathcal{L}</span> , on input x of length N, security parameter k and proximity parameter  <span class="math">\\epsilon</span> . First, (P', V') run the setup for the commitment scheme. After this initial step, the interaction consists of two main parts. In the first part, P' and V' emulate the interaction between P and V, where P' only <em>commits</em> to the messages that P would have sent. Since the protocol (P, V) is a <em>public-coin</em> protocol, the verifier V' can continue the interaction without actually knowing the contents of the messages that it receives (since V' only needs to sample and send random coin tosses).</p>

    <p class="text-gray-300">Then, in the second part, V' has already obtained commitments  <span class="math">c_1, \\ldots, c_\\ell</span>  to some messages  <span class="math">\\alpha_1, \\ldots, \\alpha_\\ell</span>  that P would have sent. At this point we would like P' to prove the statement:</p>

    <p class="text-gray-300"><span class="math">d_i \\text{ is a decommitment of } c_i \\text{ with respect to message } \\alpha_i \\text{, for every } i \\in [r]</span>   <span class="math">\\exists d_1, \\dots, d_\\ell, \\alpha_1, \\dots, \\alpha_\\ell \\text{ such that} \\qquad \\text{and}</span>   <span class="math">\\mathsf{V}^x(N, \\varepsilon, k, (\\alpha_1, \\beta_1, \\dots, \\alpha_\\ell, \\beta_\\ell)) = 1.</span>  (14)</p>

    <p class="text-gray-300">The statement in Equation (14) is almost, but not quite, an NP statement. The reason that we would like to phrase it as an NP statement is that by Lemma 6.4 (and using our assumption that there exist one-way functions), there exist very efficient (computational) zero knowledge proofs for any language in NP. Thus, we would like for P' to prove Equation (14) to V' using such a general purpose zero-knowledge proof-system.</p>

    <p class="text-gray-300">The problem that we encounter is that Equation (14) is not precisely an NP statement since it refers to oracle access to a given string x.<sup>31</sup> To overcome this problem, we use our assumption that V makes <em>prover oblivious queries</em>. Hence, the queries that V makes depend only on its own random coin tosses (and answers to previous queries that it has made), but not on the messages sent by P. Denote by  <span class="math">Q(x; \\rho)</span>  the sequence of (possibly adaptive) queries that V makes on input x and random string  <span class="math">\\rho</span> . Since  <span class="math">Q(x, \\rho)</span>  depends only on the randomness (and, possibly, on answers to previous queries to x), the verifier V' can sample  <span class="math">\\rho</span>  at random and generate this set. We can now re-state Equation (14) as:</p>

    <p class="text-gray-300"><span class="math">$d_i \\text{ is a decommitment of } c_i \\text{ with respect to message } \\alpha_i \\text{, for every } i \\in [r]</span>$</p>

    <p class="text-gray-300"><span class="math">$\\exists d_1, \\dots, d_\\ell, \\alpha_1, \\dots, \\alpha_\\ell \\text{ such that} \\qquad \\text{and} \\qquad \\qquad \\mathsf{V}(x_{Q(x;\\rho)}, (N,\\varepsilon,k), (\\alpha_1,\\beta_1,\\dots,\\alpha_\\ell,\\beta_\\ell)) = 1, \\tag{15}</span>$</p>

    <p class="text-gray-300">which is in fact an NP relation, for which P' has a witness. Therefore, using our assumption that one-way functions exist, there exists a computational zero-knowledge proof for Equation (15). P'</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;31</sup>As a matter of fact Equation (14) can be expressed as an &quot;non-interactive proof of proximity&quot; or MAP [GR16].</p>

    <p class="text-gray-300">and V' engage in this proof-system and V' accepts or rejects accordingly. (To actually run this proof-system V' first shares  <span class="math">\\rho</span>  with P' - but it does so only after they have completed the emulation of (P, V).)</p>

    <p class="text-gray-300">Completeness of (P', V') follows from the completeness of (P, V) and the (perfect) completeness of the [IKOS09] zero-knowledge proof. The analysis of soundness and zero-knowledge is standard and we omit them from this preliminary version.</p>

    <p class="text-gray-300">We proceed to analyze the efficiency of the proof-system. We consider the three phases of interactions separately:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><strong>Setup Phase:</strong> First, the two parties set up the commitment scheme this step is done using a single round of communication and with complexity poly(k) for both parties.</li>
      <li>Commitment Phase: Each bit that P sends to V in the original protocol is emulated by a (non-interactive) commitment (with a poly(k) overhead). Messages sent from V to P are unchanged (recall that these refer to random coin tosses). Thus, the round complexity of this part is  <span class="math">\\ell</span>  and there is a poly(k) overhead to the running time of both parties.</li>
      <li>Final Phase: V' first sends the random string used by the underlying V. This introduces a  <span class="math">t_{\\mathsf{V}}(N,k,\\varepsilon)</span>  overhead to both parties. Then, both parties run the [IKOS09] protocol on an NP statement that can be verified in time  <span class="math">t=t_{\\mathsf{V}}(N,\\varepsilon,k)\\cdot\\mathsf{poly}(k)</span> . The [IKOS09] verifier runs in time that is  <span class="math">O(t)=t_{\\mathsf{V}}(N,\\varepsilon,k)\\cdot\\mathsf{poly}(k)</span>  whereas the [IKOS09] prover runs in time  <span class="math">\\mathsf{poly}(t)=\\mathsf{poly}(t_{\\mathsf{V}}(N,\\varepsilon,k),k)</span> . The number of rounds is  <span class="math">\\mathsf{poly}(k)</span> .</li>
    </ul>

    <p class="text-gray-300">To obtain our ZKPP results, we will combine Theorem 6.2 with known results from the literature. Specifically, we will use the following results: (where throughout N denotes the input length, k the security parameter, and  <span class="math">\\varepsilon</span>  the security parameter).</p>

    <p class="text-gray-300"><strong>Theorem 6.5</strong> ([RVW13]). Every language in logspace-uniform NC, has a polylog(N)-round public-coin  <span class="math">\\varepsilon</span> -IPP, for  <span class="math">\\varepsilon = N^{-1/2}</span> , with perfect completeness and 1/2 soundness error. The verifier runs in time  <span class="math">N^{\\frac{1}{2}+o(1)}</span>  and the (honest) prover runs in time poly(N). Furthermore, the verifier makes prover oblivious queries.</p>

    <p class="text-gray-300"><strong>Theorem 6.6</strong> ([RRR16]). Let  <span class="math">\\mathcal{L}</span>  be a language that is computable in poly(N)-time and  <span class="math">O(N^{\\sigma})</span> -space, for some sufficiently small constant  <span class="math">\\sigma &gt; 0</span> . Then  <span class="math">\\mathcal{L}</span>  has a constant-round public-coin  <span class="math">\\varepsilon</span> -IPP for  <span class="math">\\varepsilon = N^{-1/2}</span> , with perfect completeness and 1/2 soundness error. The verifier runs in time  <span class="math">N^{1/2+O(\\sigma)}</span>  and the (honest) prover runs in time poly(N). Furthermore, the verifier makes prover oblivious queries.</p>

    <p class="text-gray-300"><strong>Theorem 6.7</strong> ([Kil92, BGH<sup>+</sup>06, DR06]). Assume that there exist collision-resistant hash functions. Then, every language in NP has a 4-message public-coin argument of  <span class="math">\\varepsilon</span> -proximity with perfect completeness and 1/2 soundness error (for any value of  <span class="math">\\varepsilon &gt; 0</span> ). The verifier runs in time  <span class="math">\\operatorname{poly}(\\log(N), k, 1/\\varepsilon)</span>  and the prover runs in time  <span class="math">\\operatorname{poly}(N, k)</span> . Furthermore, the verifier makes prover oblivious queries.</p>

    <p class="text-gray-300">We remark that the fact that the verifier makes prover oblivious queries is not stated explicitly in the above works but can be verified by inspection.<sup>32</sup> Combining Theorems 6.5 and 6.6 with Theorem 6.2, and Theorem 6.7 with Theorem 6.3 we derive the following corollaries:</p>

    <p class="text-gray-300"> <span class="math">&lt;sup&gt;^{32}&lt;/sup&gt;</span> Theorem 6.7 is obtained by applying Kilian's [Kil92] protocol to a PCP of proximity (c.f., [BGH <span class="math">^+</span> 06, DR06]). See further discussions in [RVW13, KR15]. We remark that for the resulting argument of proximity to have proof oblivious queries, we need to use a PCP of proximity whose queries are non-adaptive in the proof. Such general purpose PCPs of proximity were constructed in [BGH <span class="math">^+</span> 06, DR06].</p>

    <p class="text-gray-300"><strong>Corollary 6.8</strong> (Computational ZKPP for Bounded Depth)<strong>.</strong> <em>Assume that there exist one-way functions. Then, every language in logspace-uniform</em> NC<em>, has a</em> (polylog(N) + poly(k))<em>-round computational zeroknowledge proof of</em> &epsilon;<em>-proximity, for</em> &epsilon; = n &minus;1/2 <em>. The verifier runs in time</em> N <sup>2</sup> +o(1) &middot; poly(k) <em>and the (honest) prover runs in time</em> poly(N, k)<em>. The simulation overhead is</em> s(t <sup>V</sup>b, N, k, &epsilon;) = <sup>t</sup> <sup>V</sup><sup>b</sup> &middot; poly(k)<em>, for (malicious) verifiers running in time</em> t <sup>V</sup><sup>b</sup> <sup>=</sup> <sup>t</sup> <sup>V</sup>b(N, k, &epsilon;)<em>.</em></p>

    <p class="text-gray-300"><strong>Corollary 6.9</strong> (Computational ZKPP for Bounded Space)<strong>.</strong> <em>Assume that there exist one-way functions. Let</em> L <em>be a language that is computable in</em> poly(N)<em>-time and</em> O(N<sup>&sigma;</sup> )<em>-space, for some sufficiently small constant</em> &sigma; &gt; 0<em>. Then,</em> L <em>has a</em> poly(k)<em>-message computational zero-knowledge proof of</em> &epsilon;<em>-proximity, for</em> &epsilon; = N <sup>&minus;</sup>1/<sup>2</sup> <em>. The verifier runs in time</em> N1/2+O(&sigma;) &middot; poly(k) <em>and the (honest) prover runs in time</em> poly(N, k)<em>. The simulation overhead is</em> s(t <sup>V</sup>b, N, k, &epsilon;) = <sup>t</sup> <sup>V</sup><sup>b</sup> &middot; poly(k)<em>, for (malicious) verifiers running in time</em> <sup>t</sup> <sup>V</sup><sup>b</sup> <sup>=</sup> t <sup>V</sup>b(N, k, &epsilon;)<em>.</em></p>

    <p class="text-gray-300"><strong>Corollary 6.10</strong> (Statistical Zero-Knowledge Arguments)<strong>.</strong> <em>Assume that there exist collision resistant hash functions. Then, every language in</em> NP<em>, has a constant-round statistical zero-knowledge argument of</em> &epsilon;<em>-proximity, for every value of</em> &epsilon; &gt; 0<em>. The verifier runs in time</em> poly(log(N), k, 1/&epsilon;) <em>and the (honest) prover runs in time</em> poly(N, k)<em>.</em></p>

    <p class="text-gray-300">We thank Oded Goldreich and Omer Paneth for useful discussions.</p>

    <p class="text-gray-300">The first and third author were supported in part by NSF Grants CNS-1350619 and CNS-1414119, Alfred P. Sloan Research Fellowship, Microsoft Faculty Fellowship, the NEC Corporation, a Steven and Renee Finn Career Development Chair from MIT. This work was also sponsored in part by the Defense Advanced Research Projects Agency (DARPA) and the U.S. Army Research Office under contracts W911NF-15-C-0226.</p>

    <p class="text-gray-300">The second author was partially supported by NSF MACS - CNS-1413920, DARPA IBM - W911NF-15-C-0236 and SIMONS Investigator award Agreement Dated 6-5-12.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><p class="text-gray-300">[ABG+14] Adi Akavia, Andrej Bogdanov, Siyao Guo, Akshay Kamath, and Alon Rosen. Candidate weak pseudorandom functions in AC<sup>0</sup> &#9702; MOD2 . In <em>Innovations in Theoretical Computer Science, ITCS'14, Princeton, NJ, USA, January 12-14, 2014</em>, pages 251&ndash;260, 2014. <a href="#page-27-6">2</a></p></li>
      <li><p class="text-gray-300">[AKNS00] Noga Alon, Michael Krivelevich, Ilan Newman, and Mario Szegedy. Regular languages are testable with a constant number of queries. <em>SIAM J. Comput.</em>, 30(6):1842&ndash; 1862, 2000. <a href="#page-3-3">4</a></p></li>
      <li><p class="text-gray-300">[BCF+16] Eli Ben-Sasson, Alessandro Chiesa, Michael A. Forbes, Ariel Gabizon, Michael Riabzev, and Nicholas Spooner. On probabilistic checking in perfect zero knowledge. <em>IACR Cryptology ePrint Archive</em>, 2016:988, 2016. <a href="#page-6-0">1.2</a></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>[BCS16] Eli Ben-Sasson, Alessandro Chiesa, and Nicholas Spooner. Interactive oracle proofs. In <em>Theory of Cryptography - 14th International Conference, TCC 2016-B, Beijing, China, October 31 - November 3, 2016, Proceedings, Part II</em>, pages 31&ndash;60, 2016. <a href="#page-6-2">8</a></li>
    </ul></li>
      <li><p class="text-gray-300">[BCY91] Gilles Brassard, Claude Crepeau, and Moti Yung. Constant-round perfect zero- &acute; knowledge computationally convincing protocols. <em>Theor. Comput. Sci.</em>, 84(1):23&ndash;52, 1991. <a href="#page-35-2">30</a></p></li>
      <li><p class="text-gray-300">[BGG+88] Michael Ben-Or, Oded Goldreich, Shafi Goldwasser, Johan Hastad, Joe Kilian, Silvio &#730; Micali, and Phillip Rogaway. Everything provable is provable in zero-knowledge. In <em>Advances in Cryptology - CRYPTO '88, 8th Annual International Cryptology Conference, Santa Barbara, California, USA, August 21-25, 1988, Proceedings</em>, pages 37&ndash;56, 1988. <a href="#page-5-2">1.1.2,</a> <a href="#page-33-0">6,</a> <a href="#page-34-3">6</a></p></li>
      <li><p class="text-gray-300">[BGH+06] Eli Ben-Sasson, Oded Goldreich, Prahladh Harsha, Madhu Sudan, and Salil P. Vadhan. Robust PCPs of proximity, shorter PCPs, and applications to coding. <em>SIAM J. Comput.</em>, 36(4):889&ndash;974, 2006. <a href="#page-5-2">1.1.2,</a> <a href="#page-33-3">5.18,</a> <a href="#page-33-0">6,</a> <a href="#page-37-4">6.7,</a> <a href="#page-37-1">32</a></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>[BM88] Laszl &acute; o Babai and Shlomo Moran. Arthur-Merlin games: A randomized proof system &acute; and a hierarchy of complexity classes. <em>Journal of Computer and System Sciences</em>, pages 254&ndash;276, 1988. <a href="#page-28-2">5.5,</a> <a href="#page-33-4">5.2.2</a></li>
      <li>[BY96] Mihir Bellare and Moti Yung. Certifying permutations: Noninteractive zeroknowledge based on any trapdoor permutation. <em>J. Cryptology</em>, 9(3):149&ndash;166, 1996. <a href="#page-2-0">1,</a> <a href="#page-3-5">1.1.1,</a> <a href="#page-3-4">5,</a> <a href="#page-15-2">4.1.1,</a> <a href="#page-15-0">12</a></li>
      <li>[CL17] Ran Canetti and Amit Lichtenberg, 2017. Unpublished manuscript. <a href="#page-2-1">1</a></li>
      <li>[CS10] Artur Czumaj and Christian Sohler. Testing expansion in bounded-degree graphs. <em>Combinatorics, Probability &amp; Computing</em>, 19(5-6):693&ndash;709, 2010. <a href="#page-4-3">1.1.1,</a> <a href="#page-22-0">4.2,</a> <a href="#page-22-1">4.2,</a> <a href="#page-23-1">17,</a> <a href="#page-24-1">4.2,</a> <a href="#page-25-3">4.17</a></li>
      <li>[CS16] Gil Cohen and Igor Shinkar. The complexity of DNF of parities. In <em>Proceedings of the 2016 ACM Conference on Innovations in Theoretical Computer Science, Cambridge, MA, USA, January 14-16, 2016</em>, pages 47&ndash;58, 2016. <a href="#page-27-6">2</a></li>
    </ul></li>
      <li><p class="text-gray-300">[DORS08] Yevgeniy Dodis, Rafail Ostrovsky, Leonid Reyzin, and Adam D. Smith. Fuzzy extractors: How to generate strong keys from biometrics and other noisy data. <em>SIAM J. Comput.</em>, 38(1):97&ndash;139, 2008. <a href="#page-7-1">2.2,</a> <a href="#page-8-1">2.1.2,</a> <a href="#page-8-2">2.6</a></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>[DR06] Irit Dinur and Omer Reingold. Assignment testers: Towards a combinatorial proof of the PCP theorem. <em>SIAM J. Comput.</em>, 36(4):975&ndash;1024, 2006. <a href="#page-5-2">1.1.2,</a> <a href="#page-33-0">6,</a> <a href="#page-37-4">6.7,</a> <a href="#page-37-1">32</a></li>
      <li>[EKR04] Funda Ergun, Ravi Kumar, and Ronitt Rubinfeld. Fast approximate probabilistically &uml; checkable proofs. <em>Inf. Comput.</em>, 189(2):135&ndash;159, 2004. <a href="#page-2-0">1</a></li>
      <li>[FGL14] Eldar Fischer, Yonatan Goldhirsh, and Oded Lachish. Partial tests, universal tests and decomposability. In <em>Innovations in Theoretical Computer Science, ITCS'14, Princeton, NJ, USA, January 12-14, 2014</em>, pages 483&ndash;500, 2014. <a href="#page-2-0">1,</a> <a href="#page-3-3">4</a></li>
      <li>[FLS99] Uriel Feige, Dror Lapidot, and Adi Shamir. Multiple non-interactive zero knowledge proofs under general assumptions. <em>SIAM Journal on Computing</em>, 1999. Preliminary version in <em>FOCS'90</em>. <a href="#page-2-0">1</a></li>
    </ul></li>
      <li><p class="text-gray-300">[GG16] Oded Goldreich and Tom Gur. Universal locally testable codes. <em>Electronic Colloquium on Computational Complexity (ECCC)</em>, 23:42, 2016. <a href="#page-2-0">1</a></p></li>
      <li><p class="text-gray-300">[GGK15] Oded Goldreich, Tom Gur, and Ilan Komargodski. Strong locally testable codes with relaxed local decoders. In <em>30th Conference on Computational Complexity, CCC 2015, June 17-19, 2015, Portland, Oregon, USA</em>, pages 1&ndash;41, 2015. <a href="#page-33-3">5.18</a></p></li>
      <li><p class="text-gray-300">[GGR98] Oded Goldreich, Shafi Goldwasser, and Dana Ron. Property testing and its connection to learning and approximation. <em>J. ACM</em>, 45(4):653&ndash;750, 1998. <a href="#page-2-0">1,</a> <a href="#page-3-6">1.1.1,</a> <a href="#page-22-0">4.2</a></p></li>
      <li><p class="text-gray-300">[GGR15] Oded Goldreich, Tom Gur, and Ron D. Rothblum. Proofs of proximity for contextfree languages and read-once branching programs - (extended abstract). In <em>Automata, Languages, and Programming - 42nd International Colloquium, ICALP 2015, Kyoto, Japan, July 6-10, 2015, Proceedings, Part I</em>, pages 666&ndash;677, 2015. <a href="#page-2-0">1,</a> <a href="#page-24-1">4.2</a></p></li>
      <li><p class="text-gray-300">[GMR89] Shafi Goldwasser, Silvio Micali, and Charles Rackoff. The knowledge complexity of interactive proof systems. <em>SIAM Journal on Computing</em>, pages 186&ndash;208, 1989. Preliminary version in <em>STOC'85</em>. <a href="#page-2-0">1</a></p></li>
      <li><p class="text-gray-300">[GMW87] Oded Goldreich, Silvio Micali, and Avi Wigderson. How to play any mental game or a completeness theorem for protocols with honest majority. In <em>Proceedings of the 19th Annual ACM Symposium on Theory of Computing (STOC)</em>, pages 218&ndash;229, 1987. <a href="#page-45-0">B.4,</a> <a href="#page-45-1">1</a></p></li>
      <li><p class="text-gray-300">[GMW91] Oded Goldreich, Silvio Micali, and Avi Wigderson. Proofs that yield nothing but their validity or all languages in NP have zero-knowledge proof systems. <em>Journal of the ACM</em>, pages 691&ndash;729, 1991. Preliminary version in <em>FOCS'86</em>. <a href="#page-2-0">1,</a> <a href="#page-34-3">6,</a> <a href="#page-35-1">29</a></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>[Gol01] Oded Goldreich. <em>Foundations of Cryptography: Basic Tools</em>. Cambridge University Press, 2001. <a href="#page-3-7">1,</a> <a href="#page-12-0">11</a></li>
      <li>[Gol16] Oded Goldreich. <em>Introduction to Property Testing</em>. forthcoming (<a href="http://www.wisdom.weizmann.ac.il/~oded/pt-intro.html" target="_blank" rel="noopener noreferrer">http://www.</a> <a href="http://www.wisdom.weizmann.ac.il/~oded/pt-intro.html" target="_blank" rel="noopener noreferrer">wisdom.weizmann.ac.il/&tilde;oded/pt-intro.html</a>), 2016. <a href="#page-2-0">1</a></li>
      <li>[GR99] Oded Goldreich and Dana Ron. A sublinear bipartiteness tester for bounded degree graphs. <em>Combinatorica</em>, 19(3):335&ndash;373, 1999. <a href="#page-26-0">4.3</a></li>
      <li>[GR02] Oded Goldreich and Dana Ron. Property testing in bounded degree graphs. <em>Algorithmica</em>, 32(2):302&ndash;343, 2002. <a href="#page-3-6">1.1.1,</a> <a href="#page-4-3">1.1.1,</a> <a href="#page-22-0">4.2,</a> <a href="#page-26-0">4.3</a></li>
      <li>[GR11] Oded Goldreich and Dana Ron. On testing expansion in bounded-degree graphs. In Oded Goldreich, editor, <em>Studies in Complexity and Cryptography. Miscellanea on the Interplay between Randomness and Computation - In Collaboration with Lidor Avigad, Mihir Bellare, Zvika Brakerski, Shafi Goldwasser, Shai Halevi, Tali Kaufman, Leonid Levin, Noam Nisan, Dana Ron, Madhu Sudan, Luca Trevisan, Salil Vadhan, Avi Wigderson, David Zuckerman</em>, volume 6650 of <em>Lecture Notes in Computer Science</em>, pages 68&ndash;75. Springer, 2011. <a href="#page-4-3">1.1.1,</a> <a href="#page-22-0">4.2</a></li>
      <li>[GR13] Oded Goldreich and Ron D. Rothblum. Enhancements of trapdoor permutations. <em>J. Cryptology</em>, 26(3):484&ndash;512, 2013. <a href="#page-2-1">1</a></li>
    </ul></li>
      <li><p class="text-gray-300">[GR15] Tom Gur and Ron D. Rothblum, 2015. Unpublished observation. <a href="#page-3-6">1.1.1,</a> <a href="#page-14-2">4.1</a></p></li>
      <li><p class="text-gray-300">[GR16] Tom Gur and Ron D. Rothblum. Non-interactive proofs of proximity. <em>Computational Complexity</em>, pages 1&ndash;109, 2016. <a href="#page-2-0">1,</a> <a href="#page-14-2">4.1,</a> <a href="#page-27-6">2,</a> <a href="#page-29-5">5.2,</a> <a href="#page-32-1">5.2.1,</a> <a href="#page-33-3">5.18,</a> <a href="#page-34-2">28,</a> <a href="#page-36-1">31</a></p></li>
      <li><p class="text-gray-300">[GR17] Tom Gur and Ron D. Rothblum. A hierarchy theorem for interactive proofs of proximity. In <em>Proceedings of the 2017 ACM Conference on Innovations in Theoretical Computer Science, Berkeley, CA, USA, January 9-11, 2016</em>, 2017. <a href="#page-2-0">1,</a> <a href="#page-27-4">5.1,</a> <a href="#page-27-5">5.2,</a> <a href="#page-33-4">5.2.2</a></p></li>
      <li><p class="text-gray-300">[GS89] Shafi Goldwasser and Michael Sipser. Private coins versus public coins in interactive proof systems. <em>Advances in Computing Research: Randomness and Computation</em>, pages 73&ndash;90, 1989. <a href="#page-33-4">5.2.2</a></p></li>
      <li><p class="text-gray-300">[GS92] Peter Gemmell and Madhu Sudan. Highly resilient correctors for polynomials. <em>Inf. Process. Lett.</em>, 43(4):169&ndash;174, 1992. <a href="#page-44-3">B.3</a></p></li>
      <li><p class="text-gray-300">[GS06] Oded Goldreich and Madhu Sudan. Locally testable codes and pcps of almost-linear length. <em>J. ACM</em>, 53(4):558&ndash;655, 2006. <a href="#page-30-0">5.9</a></p></li>
      <li><p class="text-gray-300">[GSV98] Oded Goldreich, Amit Sahai, and Salil P. Vadhan. Honest-verifier statistical zeroknowledge equals general statistical zero-knowledge. In <em>Proceedings of the Thirtieth Annual ACM Symposium on the Theory of Computing, Dallas, Texas, USA, May 23-26, 1998</em>, pages 399&ndash;408, 1998. <a href="#page-4-2">7</a></p></li>
      <li><p class="text-gray-300">[HILL99] Johan Hastad, Russell Impagliazzo, Leonid A. Levin, and Michael Luby. A pseudoran- &#730; dom generator from any one-way function. <em>SIAM J. Comput.</em>, 28(4):1364&ndash;1396, 1999. <a href="#page-35-0">6,</a> <a href="#page-45-2">36</a></p></li>
      <li><p class="text-gray-300">[HNO+09] Iftach Haitner, Minh Nguyen, Shien Jin Ong, Omer Reingold, and Salil Vadhan. Statistically hiding commitments and statistical zero-knowledge arguments from any oneway function. <em>SIAM Journal on Computing</em>, pages 1153&ndash;1218, 2009. Preliminary versions in <em>FOCS '06</em> and <em>STOC '07</em>. <a href="#page-35-2">30</a></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>[IKOS09] Yuval Ishai, Eyal Kushilevitz, Rafail Ostrovsky, and Amit Sahai. Zero-knowledge proofs from secure multiparty computation. <em>SIAM J. Comput.</em>, 39(3):1121&ndash;1152, 2009. <a href="#page-34-3">6,</a> <a href="#page-35-0">6.4,</a> <a href="#page-35-0">6,</a> <a href="#page-35-1">29,</a> <a href="#page-36-2">6,</a> <a href="#page-45-0">B.4,</a> <a href="#page-45-3">35,</a> <a href="#page-46-0">B.4</a>    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>[IW14] Yuval Ishai and Mor Weiss. Probabilistically checkable proofs of proximity with zeroknowledge. In <em>Theory of Cryptography - 11th Theory of Cryptography Conference, TCC 2014, San Diego, CA, USA, February 24-26, 2014. Proceedings</em>, pages 121&ndash;145, 2014. <a href="#page-6-0">1.2</a></li>
      <li>[Kil92] Joe Kilian. A note on efficient zero-knowledge proofs and arguments (extended abstract). In <em>Proceedings of the 24th Annual ACM Symposium on Theory of Computing (STOC)</em>, pages 723&ndash;732, 1992. <a href="#page-5-2">1.1.2,</a> <a href="#page-33-0">6,</a> <a href="#page-37-4">6.7,</a> <a href="#page-37-1">32</a></li>
      <li>[KR15] Yael Tauman Kalai and Ron D. Rothblum. Arguments of proximity [extended abstract]. In <em>Advances in Cryptology - CRYPTO 2015 - 35th Annual Cryptology Conference, Santa Barbara, CA, USA, August 16-20, 2015, Proceedings, Part II</em>, pages 422&ndash;442, 2015. <a href="#page-2-0">1,</a> <a href="#page-34-1">27,</a> <a href="#page-37-1">32</a></li>
    </ul></li>
    </ul></li>
      <li><p class="text-gray-300">[KS11] Satyen Kale and C. Seshadhri. An expansion tester for bounded degree graphs. <em>SIAM J. Comput.</em>, 40(3):709&ndash;720, 2011. 1.1.1, 4.2</p></li>
      <li><p class="text-gray-300">[KT00] Jonathan Katz and Luca Trevisan. On the efficiency of local decoding procedures for error-correcting codes. In <em>Proceedings of the Thirty-Second Annual ACM Symposium on Theory of Computing, May 21-23, 2000, Portland, OR, USA</em>, pages 80&ndash;86, 2000. 5.10</p></li>
      <li><p class="text-gray-300">[Nao91] Moni Naor. Bit commitment using pseudorandomness. <em>J. Cryptology</em>, 4(2):151&ndash;158, 1991. 6, 36</p></li>
      <li><p class="text-gray-300">[NS10] Asaf Nachmias and Asaf Shapira. Testing the expansion of a graph. <em>Inf. Comput.</em>, 208(4):309&ndash;314, 2010. 1.1.1, 4.2, 4.16</p></li>
      <li><p class="text-gray-300">[NY89] Moni Naor and Moti Yung. Universal one-way hash functions and their cryptographic applications. In <em>Proceedings of the 21st Annual ACM Symposium on Theory of Computing (STOC)</em>, pages 33&ndash;43, 1989. 30</p></li>
      <li><p class="text-gray-300">[RRR16] Omer Reingold, Guy N. Rothblum, and Ron D. Rothblum. Constant-round interactive proofs for delegating computation. In <em>Proceedings of the 48th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2016, Cambridge, MA, USA, June 18-21, 2016</em>, pages 49&ndash;62, 2016. 1, 1.1.2, 8, 6, 6.6</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>[RS96] Ronitt Rubinfeld and Madhu Sudan. Robust characterizations of polynomials with applications to program testing. <em>SIAM J. Comput.</em>, 25(2):252&ndash;271, 1996. 1, B.3</li>
    </ul></li>
      <li><p class="text-gray-300">[RVW13] Guy N. Rothblum, Salil P. Vadhan, and Avi Wigderson. Interactive proofs of proximity: delegating computation in sublinear time. In <em>Symposium on Theory of Computing Conference</em>, STOC'13, Palo Alto, CA, USA, June 1-4, 2013, pages 793&ndash;802, 2013. 1, 1.1.1, 1.1.2, 4.3, 4.18, 5.5, 5.2, 5.2.2, 5.17, 6, 6.5, 32</p></li>
      <li><p class="text-gray-300">[Sud95] Madhu Sudan. Efficient Checking of Polynomials and Proofs and the Hardness of Approximation Problems, volume 1001 of Lecture Notes in Computer Science. Springer, 1995. B.3</p></li>
      <li><p class="text-gray-300">[Vad99] Salil P. Vadhan. A Study of Statistical Zero-Knowledge Proofs. PhD thesis, Massachusetts Institute of Technology, Cambridge, MA, USA, 1999. 7, 2.2, 2.2.2, 2.2.2, 3, 3, 3.6, 3.7, 4.1.1, 5.1, A, A</p></li>
      <li><p class="text-gray-300">[Vad12] Salil P. Vadhan. Pseudorandomness. Now Publishers Inc., Hanover, MA, USA, 2012. 2.5</p></li>
    </ul>

    <p class="text-gray-300">In this section we show how to reduce any property with honest-verifier zero-knowledge to an instance of <em>Entropy Difference</em>.</p>

    <p class="text-gray-300"><strong>Lemma A.1.</strong> Suppose that a property  <span class="math">\\Pi</span>  has a honest-verifier statistical zero-knowledge  <span class="math">\\varepsilon</span> -IPP such that for every input length N and security parameter  <span class="math">k \\in \\mathbb{N}</span>  the simulator's expected running time is bounded by  <span class="math">t_{\\mathbf{S}}(\\varepsilon, N, k) = t&#x27;_{\\mathbf{S}}(\\varepsilon, N) \\cdot \\operatorname{poly}(k)</span>  and for every  <span class="math">\\varepsilon</span>  the function  <span class="math">t&#x27;_{\\mathbf{S}}(\\varepsilon, \\cdot)</span>  is monotone non-decreasing.</p>

    <p class="text-gray-300">Then, there is a reduction from  <span class="math">\\Pi</span>  to ED. Specifically, the reduction is given  <span class="math">\\varepsilon</span>  and an input length N and outputs two oracle aided circuits  <span class="math">C_0, C_1 \\colon \\{0,1\\}^m \\to \\{0,1\\}^n</span>  such that the following holds.</p>

    <p class="text-gray-300">1.  <span class="math">(C_0, C_1)</span>  is an instance of ED:</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} f \\in \\Pi &amp;\\implies \\mathrm{H}(C_0^f) \\geq \\mathrm{H}(C_1^f) + 1, \\\\ f \\text{ is } \\varepsilon\\text{-far from } \\Pi &amp;\\implies \\mathrm{H}(C_1^f) \\geq \\mathrm{H}(C_0^f) + 1. \\end{split}</span>$</p>

    <p class="text-gray-300">2. The reduction's running time is  <span class="math">poly(t_S(\\varepsilon, N, poly(t_S&#x27;(\\varepsilon, N))))</span> .</p>

    <p class="text-gray-300">Note that the last item implies that for every  <span class="math">x \\in \\{0,1\\}^m</span>  and  <span class="math">b \\in \\{0,1\\}</span> , computing  <span class="math">C_b(x)</span>  requires only  <span class="math">\\operatorname{poly}(t_{\\mathsf{S}}(\\varepsilon,N,\\operatorname{poly}(t&#x27;_{\\mathsf{S}}(\\varepsilon,N))))</span>  many oracle calls. The proof of the above lemma follows from the proof that entropy difference is SZK-hard [Vad99]. We only give sufficient details to demonstrate how to apply that proof to our setting.</p>

    <p class="text-gray-300"><em>Proof sketch.</em> Assume that (P,V) is the  <span class="math">\\varepsilon</span> -IPP for  <span class="math">\\Pi</span>  and let S be the honest-verifier simulator for (P,V) whose simulation deviation is  <span class="math">\\mu(k)=\\operatorname{negl}(k)</span> . We assume for simplicity that  <span class="math">t_S(N,k,\\varepsilon)</span>  is a strict bound (and not only expected) on the running of S. The proof can be extended to handle expected bounds as well (in fact, the proof in  <span class="math">[\\operatorname{Vad99}]</span>  handles even weaker simulators). Assume without loss of generality that P and V send their messages in turns, P sends the odd messages and V the even ones. Let  <span class="math">v(\\varepsilon,N,k)</span>  be a bound on the number of messages sent by V to P for every f. In addition, let  <span class="math">c(\\varepsilon,N,k)</span>  and  <span class="math">c(\\varepsilon,N,k)</span>  be bounds on the total communication (measures in bits) between P and V and the number of random bits accessed by the verifier, respectively. We now modify the proof system so that V sends its random coins to P in an additional message just before the end of the protocol. The total communication and number of messages sent from V to P now increases to  <span class="math">c&#x27;(\\varepsilon,N,k)=c(\\varepsilon,N,k)+r(\\varepsilon,N,k)</span>  and  <span class="math">c&#x27;(\\varepsilon,N,k)=c(\\varepsilon,N,k)+1</span> , respectively. S is modified to simulate the additional last message as well, without increasing its simulation deviation (this is possible since S was supposed to simulate V random coins anyway).</p>

    <p class="text-gray-300">Fix  <span class="math">\\varepsilon</span>  and N and let  <span class="math">k&#x27; \\in \\mathbb{N}</span>  such that  <span class="math">\\mu(k&#x27;) \\leq \\min \\left\\{ 1/v&#x27;(\\varepsilon,N,k&#x27;) \\cdot c&#x27;(\\varepsilon,N,k&#x27;), 1/4 - 2^{-40} \\right\\}</span>  and the completeness and soundness errors of  <span class="math">(\\mathsf{P},\\mathsf{V})</span>  are at most  <span class="math">2^{-40}</span> . Note that it suffices to take  <span class="math">k&#x27; = \\mathsf{poly}(t&#x27;_{\\mathsf{S}}(\\varepsilon,N))</span>  (i.e., a fixed polynomial for all  <span class="math">\\varepsilon</span>  and N): It holds that  <span class="math">v&#x27;(\\varepsilon,N,k&#x27;) \\cdot c&#x27;(\\varepsilon,N,k&#x27;) \\leq t_{\\mathsf{S}}^2(\\varepsilon,N,k&#x27;) = t_{\\mathsf{S}}&#x27;^2(\\varepsilon,N) \\cdot \\mathsf{poly}(k&#x27;)</span> . Thus, we can take k' such that  <span class="math">\\mu&#x27;(k&#x27;) \\leq 1/t_{\\mathsf{S}}&#x27;^2(\\varepsilon,N)</span> , for some negligible function  <span class="math">\\mu&#x27;(k&#x27;) = \\mu(k&#x27;) \\cdot \\mathsf{poly}(k&#x27;)</span> . Since  <span class="math">t_{\\mathsf{S}}&#x27;(\\varepsilon,N)</span>  is monotone non-decreasing in N, taking  <span class="math">k&#x27; = \\mathsf{poly}(t&#x27;_{\\mathsf{S}}(\\varepsilon,N))</span>  guarantee the required condition for large enough (depending on  <span class="math">\\mu</span> ) N (for simplicity, we ignore shorter inputs that can be solved via brute-force by the verifier).</p>

    <p class="text-gray-300">Finally, let  <span class="math">S_i^f</span>  be the random variable distributed according to the first i messages in the output of a random execution of  <span class="math">S^f(\\varepsilon, N, k&#x27;)</span> . In the following we remove  <span class="math">\\varepsilon</span> , N and k' from the notation.</p>

    <p class="text-gray-300"><strong>Constructing</strong>  <span class="math">C_0</span>  and  <span class="math">C_1</span> . Define  <span class="math">X = S_2^f \\otimes S_4^f \\otimes \\cdots \\otimes S_{2v&#x27;}^f</span> . Similarly, define  <span class="math">Y_1</span>  to be  <span class="math">Y_1 = S_1^f \\otimes S_3^f \\otimes \\cdots \\otimes S_{2v&#x27;-1}^f</span>  and define  <span class="math">Y_2</span>  to be the uniform distribution on r-7 bits. Furthermore, define  <span class="math">Y_3</span>  as follows: run  <span class="math">S^f 8 \\ln(c&#x27;v&#x27;+2)</span>  times independently; if the verifier rejects in the majority of the transcripts obtained, output c'v'+2 random bits; otherwise, output the empty string. Define  <span class="math">Y = Y_1 \\otimes Y_2 \\otimes Y_3</span> . Finally, the circuits  <span class="math">C_0</span>  and  <span class="math">C_1</span>  take as input random coins to sample and output  <span class="math">x \\leftarrow X</span>  and  <span class="math">y \\leftarrow Y</span> , respectively. Since we require that the input (resp., output) lengths of  <span class="math">C_0</span>  and  <span class="math">C_1</span>  will be equal, we pad the shorter input (resp., output) with redundant random coins (resp., zeros).</p>

    <p class="text-gray-300"> <span class="math">&lt;sup&gt;^{33}\\&lt;/sup&gt;mbox{Recall}</span>  that  <span class="math">P\\otimes Q</span>  stands for the product distribution of P and Q.</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;34</sup>Let  <span class="math">m_X</span>  and  <span class="math">n_Y</span>  denote the input and output lengths of X, respectively. Let  <span class="math">m_Y, n_Y</span>  be similarly defined. For example, if  <span class="math">m_X &lt; m_Y</span>  and  <span class="math">n_X &lt; n_Y</span>  we can modify X as follows: sample  <span class="math">x \\leftarrow X</span>  using part of the given  <span class="math">m_Y</span>  random</p>

    <p class="text-gray-300"><strong>Analysis.</strong> That  <span class="math">(C_0, C_1)</span>  is an instance of Entropy Difference (Item 1) follows from [Vad99, Claims 3.3.14 and 3.3.15]. The reduction's running time (Item 2) follows from the constructions of  <span class="math">C_0</span>  and  <span class="math">C_1</span> .</p>

      <h3 id="app-b.1" class="text-xl font-semibold mt-8">B.1 Proving Lemma 5.3</h3>

    <p class="text-gray-300">The proof of Lemma 5.3, sketch of which is given below, immediately follows from Lemmas 2.15 and A.1.</p>

    <p class="text-gray-300"><em>Proof sketch of Lemma 5.3.</em> Both the verifier and the prover will run the reduction form Lemma A.1 to get two distributions encoded by oracle-aided circuits  <span class="math">(C_0, C_1)</span> . They will then run the protocol from Lemma 2.15 with respect to these distributions. Since the latter is a sample-access protocol the verifier can indeed run it using only oracle access to its input f.</p>

    <p class="text-gray-300">The running time of the reduction implies that the input and outputs sizes of  <span class="math">C_0</span>  and  <span class="math">C_1</span>  are  <span class="math">\\mathsf{poly}(t_{\\mathsf{S}}(\\varepsilon,N,\\mathsf{poly}(t_{\\mathsf{S}}&#x27;(\\varepsilon,N))))</span> . By Lemma 2.15 the running time of the verifier is thus  <span class="math">\\mathsf{poly}(t_{\\mathsf{S}}(\\varepsilon,N,\\mathsf{poly}(t_{\\mathsf{S}}&#x27;(\\varepsilon,N))),k)</span> , as required.</p>

    <p class="text-gray-300">Zero-knowledge follows from similar arguments to the ones made above.  <span class="math">\\Box</span></p>

      <h3 id="app-b.2" class="text-xl font-semibold mt-8"><strong>B.2</strong> Proving Claim 5.16</h3>

    <p class="text-gray-300">The proof of Claim 5.16 follows similar lines to that of Lemma 5.3.</p>

    <p class="text-gray-300">Proof sketch of Claim 5.16. Both the verifier and the prover will run the reduction form Lemma A.1 with respect to the property Cl and proximity parameter  <span class="math">\\delta(C)/2</span>  to get two distributions encoded by oracle-aided circuits  <span class="math">(C_0,C_1)</span> . If  <span class="math">w\\in \\mathsf{CD}_{\\mathsf{YES},\\ell}</span>  then w is  <span class="math">\\delta(C)/2</span> -far from Cl and thus  <span class="math">\\mathsf{H}(C_1^w)\\geq \\mathsf{H}(C_0^w)+1</span> . However, if  <span class="math">w\\in \\mathsf{CD}_{\\mathsf{NO},\\ell}</span>  then  <span class="math">w\\in \\mathsf{Cl}</span>  and thus  <span class="math">\\mathsf{H}(C_0^w)\\geq \\mathsf{H}(C_1^w)+1</span> .</p>

    <p class="text-gray-300">The verifier and the prover will then run the protocol from Lemma 2.15 with respect to the instance  <span class="math">(C_1^w, C_0^w)</span>  (note that the order of the circuits has changed) and security parameter k chosen such that the completeness and soundness errors are both 1/3 for large enough  <span class="math">\\ell</span> . Since the latter is a sample-access protocol the verifier can indeed run it using only oracle access to its input w.</p>

    <p class="text-gray-300">Recall that we assumed that  <span class="math">\\mathsf{CI} \\in \\mathsf{HV}\\text{-}\\mathsf{ESZKPP}\\big[\\mathsf{poly}(\\log(N), k, 1/\\varepsilon)\\big]</span> . Hence, the simulator for  <span class="math">\\mathsf{CI}</span>  runs in time  <span class="math">\\mathsf{poly}(\\log(\\ell), k, 1/\\varepsilon)</span> , which by the choice of parameters is simply  <span class="math">\\mathsf{poly}(\\log \\ell)</span>  (recall the the proximity parameter  <span class="math">\\delta(C)</span>  and the security parameter k are constant). The running time of the reduction implies that the input (i.e., the number of bits need to sample from the distribution) and outputs sizes of  <span class="math">C_0</span>  and  <span class="math">C_1</span>  are  <span class="math">\\mathsf{poly}(\\log \\ell)</span>  as well, and by Lemma 2.15 the running time of the verifier is thus  <span class="math">\\mathsf{poly}(\\log(\\ell))</span> , as required.</p>

      <h3 id="app-b.3" class="text-xl font-semibold mt-8">B.3 Proof Sketch of Lemma 5.11</h3>

    <p class="text-gray-300">We start with a low degree extension code, over a finite field  <span class="math">\\mathbb{F}</span> , which view messages  <span class="math">x \\in \\mathbb{F}^{\\ell}</span>  as functions  <span class="math">x: H^m \\to \\mathbb{F}</span> , where  <span class="math">H \\subseteq \\mathbb{F}</span>  is a subset and m is a dimension, such that  <span class="math">|H^m| = \\ell</span> . The code maps x to its low degree extension: namely, the unique individual degree |H|-1 polynomial that agrees with x on  <span class="math">H^m</span> . By the Shwartz-Zippel lemma this code has relative distance  <span class="math">1 - \\frac{(|H|-1) \\cdot m}{|\\mathbb{F}|}</span> .</p>

    <p class="text-gray-300">bits and output  <span class="math">x0^{n_y-n_x}</span> .</p>

    <p class="text-gray-300">Furthermore, this code is known to be locally testable [RS96] and decodable [GS92, Sud95] using  <span class="math">O(|H| \\cdot m)</span>  queries. We set  <span class="math">|H| = (\\log(\\ell))^c</span> ,  <span class="math">m = \\frac{\\log(\\ell)}{c \\cdot \\log\\log(\\ell)}</span>  and  <span class="math">|\\mathbb{F}| = O(m \\cdot |H|)</span>  for a sufficiently large constant  <span class="math">c \\geq 1</span> . Furthermore, we use a field  <span class="math">\\mathbb{F}</span>  which is an extension field of the binary field  <span class="math">\\mathbb{F}_2</span> .</p>

    <p class="text-gray-300">We then concatenate the above low degree extension code with a good binary linear code. The overall resulting code has message length  <span class="math">k(\\ell) = |H|^m \\cdot \\log(F) = \\tilde{O}(\\ell)</span> , blocklength  <span class="math">n(\\ell) = O(\\mathbb{F}^m \\cdot \\mathbb{F}) = \\tilde{O}(\\ell^{1+1/c})</span> , constant relative distance and locally testable and decodable with  <span class="math">O(|H| \\cdot m) = \\operatorname{polylog}(\\ell)</span>  queries, which meets our desired parameters by setting c to be sufficiently large. Furthermore, since the low degree extension is <em>linear</em> over the large field  <span class="math">\\mathbb{F}</span> , which is an extension field of  <span class="math">\\mathbb{F}_2</span> , it is also linear over  <span class="math">\\mathbb{F}_2</span>  and therefore the resulting code is also  <span class="math">\\mathbb{F}_2</span> -linear.</p>

      <h3 id="app-b.4" class="text-xl font-semibold mt-8">B.4 Proof Sketch of Lemma 6.4</h3>

    <p class="text-gray-300">We use the [IKOS09] &quot;MPC in the head&quot; construction. More specifically, we will use their simplest variant, which is based on the [GMW87] 3-party protocol, in the OT-hybrid, with <em>semi-honest</em> security against 2 (semi-honest) players.<sup>35</sup> Below we refer to this as the IKOS protocol.</p>

    <p class="text-gray-300">We first recall that the [GMW87] protocol, with 2-out-of-3 semi-honest can be implemented so that the parties, and the (semi-honest) simulator, run in time O(t') (where we count OT calls at unit cost), where t' is the circuit complexity of the function.</p>

    <p class="text-gray-300">The IKOS protocol works in k sequential phases (in order to obtain  <span class="math">2^{-k}</span>  soundness), where each phase works as follows. The prover first runs the [GMW87] protocol with respect to to the function  <span class="math">f(x, w_1, w_2, w_3) = R(x, w_1 \\oplus w_2 \\oplus w_3)</span> , where  <span class="math">w_1, w_2, w_3</span>  are an additive secret sharing of the witness W. Observe that f is computable by a size t' = tildeO(t) circuit, where t is the complexity of R of the NP relation (an extra log factor comes from emulating Turing machines by circuits). Thus, the parties and the MPC simulator run in time  <span class="math">\\tilde{O}(t)</span> .</p>

    <p class="text-gray-300">After running the MPC protocol (in its &quot;head&quot;), the IKOS prover commits to the view of all the players.<sup>36</sup> Then, the verifier chooses two (distinct) players  <span class="math">i, j \\in \\{1, 2, 3\\}</span>  at random, and sends i and j to the prover. The prover decommits to these players views. The verifier rejects if the decommitments are invalid, the views are inconsistent, or if the result of the computation is not 1. Otherwise it accepts.</p>

    <p class="text-gray-300">For the analysis of soundness and zero-knowledge of the IKOS protocol see [IKOS09]. Here we focus on the running times of the verifier and the simulator.</p>

    <p class="text-gray-300">Observe that all that the verifier's running time in each phase is  <span class="math">\\tilde{O}(t) * \\text{poly}(secp)</span>  as required.</p>

    <p class="text-gray-300">We proceed to describe the IKOS simulator. Fix a malicious verifier  <span class="math">\\hat{V}</span> . The simulator also runs for k phases. In each phase it repeats the following procedure at most poly(secp) times (and aborts if all fail):</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>1. Select at random a pair of (distinct) players  <span class="math">i, j \\in \\{1, 2, 3\\}</span> , and runs the [GMW87] simulation on them (with respect to random strings  <span class="math">w_i</span>  and  <span class="math">w_j</span> ).</li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The simulator generates commitments to the simulated views for these players as well as a fake simulation (e.g., all zero) for the third player. The simulator &quot;sends&quot; these commitments to the verifier  <span class="math">\\hat{V}</span> .</li>
    </ol></li>
    </ul>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;35</sup>Indeed, note that the [IKOS09] approach transforms <em>semi-honest</em> secure MPC protocols into proof-systems that are zero-knowledge with respect to <em>malicious</em> verifiers.</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;36</sup>Here we use a satistically binding commitment scheme, which follows from the existence of one-way functions [HILL99, Nao91].</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Vb responds with a pair of distinct indices i 0 , j<sup>0</sup> &isin; {1, 2, 3} (otherwise, since the IKOS prover would abort, the simulator can output its generated view so far followed by a &perp; symbol).</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>If i 0 , j<sup>0</sup> are not the same as i, j, then continue the loop.</li>
    </ol></li>
      <li>5. Otherwise, the simulator can send decommitments to Vb and they continue to the next phase.</li>
    </ul>

    <p class="text-gray-300">Overall the simulation of a single phase takes (O&tilde;(t) + T)&middot; poly(k) time, where T is the running time of Vb. See <a href="#page-41-9">[IKOS09]</a> for additional details.</p>

    </section>
`;
---

<BaseLayout title="Zero-Knowledge Proofs of Proximity (2017/114)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2017 &middot; eprint 2017/114
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <PaperDisclaimer eprintUrl={EPRINT_URL} />
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

    <PaperHistory slug="zero-knowledge-proofs-of-proximity-2017" />
  </article>
</BaseLayout>
