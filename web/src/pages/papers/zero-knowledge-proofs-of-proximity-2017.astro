---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2017/114';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Zero-Knowledge Proofs of Proximity';
const AUTHORS_HTML = 'Itay Berman, Ron D.  Rothblum, Vinod Vaikuntanathan';

const CONTENT = `    <p class="text-gray-300">Itay Berman MIT Ron D. Rothblum MIT Vinod Vaikuntanathan MIT</p>

    <h6 id="sec-2" class="text-base font-medium mt-4">Abstract</h6>

    <p class="text-gray-300">Interactive proofs of proximity (Ergün, Kumar and Rubinfeld, Information &amp; Computation, 2004 and Rothblum, Vadhan and Wigderson, STOC 2013), or IPPs, are interactive proofs in which the verifier runs in time <em>sub-linear</em> in the input’s length. Since the verifier cannot even read the entire input, following the property testing literature, the requirement is that she accepts inputs that are <em>in</em> the language and rejects ones that are <em>far</em> from the language. However, these proofs could (and in many cases, do) betray considerable <em>global</em> information about the input to the verifier.</p>

    <p class="text-gray-300">In this work, we initiate the study of <em>zero-knowledge proofs of proximity</em> (ZKPP). A ZKPP convinces a sub-linear time verifier while ensuring that she learns nothing more than a few locations of the input (and the fact that the input is “close” to the language).</p>

    <p class="text-gray-300">Our main focus is the setting of <em>statistical</em> zero-knowledge where we show that the following hold <em>unconditionally</em> (where <span class="math">N</span> denotes the input size):</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Statistical ZKPPs can be sub-exponentially more efficient than property testers (or even non-interactive IPPs): We show a natural property which has a statistical ZKPP with a <span class="math">\\mathsf{polylog}(N)</span> time verifier, but requires <span class="math">\\Omega(\\sqrt{N})</span> queries (and hence also runtime) for every property tester.</li>

      <li>Statistical ZKPPs can be sub-exponentially less efficient than IPPs: We show a property which has an IPP with a <span class="math">\\mathsf{polylog}(N)</span> time verifier, but cannot have a statistical ZKPP with even an <span class="math">N^{o(1)}</span> time verifier.</li>

      <li>Statistical ZKPPs for some graph-based properties such as promise versions of expansion and bipartiteness.</li>

    </ul>

    <p class="text-gray-300">Lastly, we also consider the computational setting where we show that:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Assuming the existence of one-way functions, every language computable either in (logspace uniform) NC or in SC, has a <em>computational</em> ZKPP with a (roughly) <span class="math">\\sqrt{N}</span> time verifier.</li>

      <li>Assuming the existence of collision-resistant hash functions, every language in NP has a <em>statistical</em> zero-knowledge <em>argument</em> of proximity with a <span class="math">\\mathsf{polylog}(N)</span> verifier.</li>

    </ul>

    <p class="text-gray-300">*Email: {itayberm,ronr,vinodv}@mit.edu</p>

    <p class="text-gray-300">1 Introduction 1 1.1 Our Results 2 1.2 Additional Related Works 5</p>

    <p class="text-gray-300">2 Preliminaries 5 2.1 Hashing and Entropy 6 2.2 Statistical Zero-Knowledge 7</p>

    <p class="text-gray-300">3 ZKPP — Model and Definitions 9</p>

    <p class="text-gray-300">4 The Power of ZKPP: The Statistical Case 12 4.1 ZKPP for Permutations 12 4.2 Promise Expansion is in HV-SZKPP 21 4.3 Promise Bipartiteness is in HV-SZKPP 25</p>

    <p class="text-gray-300">5 Limitations of SZKPP 25 5.1 IPP <span class="math">\\not\\subseteq</span> ESZKPP 26 5.2 MAP <span class="math">\\not\\subseteq</span> ESZKPP, assuming Circuit Lower Bounds 28</p>

    <p class="text-gray-300">6 Computational ZK Proofs and Statistical ZK Arguments of Proximity 32</p>

    <p class="text-gray-300">A Reducing HV-SZKPP to Entropy Difference 41 B Missing Proofs 43 B.1 Proving Lemma 5.3 43 B.2 Proving Claim 5.16 43 B.3 Proof Sketch of Lemma 5.11 43 B.4 Proof Sketch of Lemma 6.4 44</p>

    <p class="text-gray-300">1 Introduction</p>

    <p class="text-gray-300">Interactive proofs, introduced by Goldwasser, Micali and Rackoff <em>[x10]</em> are protocols that allow for a polynomial-time verifier to check the correctness of a computational statement, typically formulated as membership of an input <span class="math">x</span> in a language <span class="math">\\mathcal{L}</span>, using an interactive protocol.</p>

    <p class="text-gray-300">Interactive proofs have had an incredible impact on theoretical computer science in general, and especially on cryptography and complexity theory. However, given the vast amounts of data that are available nowadays, in some applications even polynomial running time may be too much.</p>

    <p class="text-gray-300">Ergün, Kumar and Rubinfeld <em>[x12]</em> asked whether we can obtain proof-systems in which the verifier runs in <em>sub-linear</em> time. In particular, this means that the verifier does not even have time to read the entire input. Since it is impossible to obtain sub-linear verification in general, to obtain a meaningful notion we settle for a suitable notion of approximation. Inspired by the property testing literature <em>[x21, x11]</em> (see also <em>[x13]</em>) a recent line of works, initiated by Rothblum, Vadhan and Wigderson <em>[x22]</em>, focuses on interactive proofs in which soundness is relaxed and the verifier is only required to reject inputs that are <em>far</em> (say, in Hamming distance) from being in the language. Thus, the verifier is only assured that the input <span class="math">x</span> is <em>close</em> to the language <span class="math">\\mathcal{L}</span> and so these proof-systems are called <em>interactive proofs of proximity</em>, or IPPs for short. Recent results (<em>[x22, x14, x15, x16, x17, x23]</em>) have demonstrated that many languages admit very efficient IPPs.</p>

    <p class="text-gray-300">One of the main advantages of classical interactive proofs is that they allow for proving statements in <em>zero-knowledge</em> <em>[x10, x11]</em>: amazingly, it is possible to prove that <span class="math">x\\in\\mathcal{L}</span> without revealing anything other than that. Beyond being of intrinsic interest, zero-knowledge proofs have a multitude of applications.</p>

    <p class="text-gray-300">In this work we initiate the study of <em>zero-knowledge</em> proofs of proximity, or ZKPP for short. Specifically we ask:</p>

    <p class="text-gray-300"><em>Is it possible to prove correctness of a computation to a </em>sub-linear<em> time verifier, so that the verifier does not learn more than it could have learned by reading a few bits from the input?</em></p>

    <p class="text-gray-300">Loosely speaking, we say that an IPP with prover <span class="math">\\mathsf{P}</span> and verifier <span class="math">\\mathsf{V}</span> is a ZKPP, if for any possible cheating verifier <span class="math">\\widehat{\\mathsf{V}}</span> that runs in time <span class="math">t=o(N)</span>, where here and below <span class="math">N</span> denotes the input length, there exists a simulator <span class="math">\\mathsf{S}_{\\widehat{\\mathsf{V}}}</span> that runs in time roughly <span class="math">t</span> and outputs a view that is indistinguishable from the view of <span class="math">\\widehat{\\mathsf{V}}</span> when interacting with <span class="math">\\mathsf{P}</span>. Note that the bound on the running times for the verifier and the simulator also bounds their query complexity (i.e., the number of bits read from the input).</p>

    <p class="text-gray-300">Interestingly, the notion of ZKPP has already implicitly appeared in the cryptographic literature 20 years ago. Bellare and Yung <em>[x4]</em> noticed that the soundness of the <em>[x14]</em> construction of non-interactive zero-knowledge proof-system (NIZK) from trapdoor permutations breaks, if the cheating prover sends a description of a function that is not a permutation. <em>[x4]</em> observed that to regain soundness in the <em>[x14]</em> protocol, it suffices to verify that the given function is <em>close</em> to being a permutation.</p>

    <p class="text-gray-300">Focusing on the case that the domain of the permutation is <span class="math">\\{0,1\\}^{n}</span>, <em>[x4]</em> suggested the</p>

    <p class="text-gray-300">following natural non-interactive zero-knowledge proof for certifying that a function is close to a permutation: the many random elements <span class="math">y_{1},\\ldots,y_{k}</span> in <span class="math">\\{0,1\\}^{n}</span> are specified as part of a common random string (CRS), and the prover is required to provide inverses <span class="math">x_{1},\\ldots,x_{k}</span> to all of these elements. Soundness follows from the fact that if the function is far from a permutation then, with high probability, one of these elements will simply not have an inverse. Zero-knowledge is demonstrated by having the simulator sample the <span class="math">x</span>’s at random and obtain the <span class="math">y</span>’s by evaluating the permutation.</p>

    <p class="text-gray-300">Since the verifier in the <em>[x10]</em> protocol is only assured that the function is close to a permutation, in our terminology, the <em>[x10]</em> protocol is a non-interactive ZKPP. Notice that the verifier runs in time <span class="math">\\operatorname{poly}(n)</span>, which is poly-logarithmic in the input (i.e., the truth table of <span class="math">f</span>).</p>

    <h4 id="sec-4" class="text-lg font-semibold mt-6">Knowledge Tightness.</h4>

    <p class="text-gray-300">When we consider ZKPP with a poly-logarithmic verifier (as in the foregoing example), it will suffice for us to allow the simulator to run in time that is polynomial in that of the verifier (i.e., also poly-logarithmic time). However, when considering protocols were the verifier runs in time, say <span class="math">\\sqrt{N}</span>, we cannot afford such a polynomial simulation overhead. Thus, following Goldreich <em>[x14, Section 4.4.2]</em>, we will sometimes want to more precisely quantify the simulator’s overhead.</p>

    <h3 id="sec-5" class="text-xl font-semibold mt-8">1.1 Our Results</h3>

    <p class="text-gray-300">As is the case for standard zero-knowledge, the results that we can obtain depend heavily on the specific notion of zero-knowledge. These notions depend on what exactly it means that the output of the simulator is indistinguishable from a real interaction.</p>

    <p class="text-gray-300">The main notion that we consider in this work is that of statistical zero knowledge proofs of proximity. Here, the requirement is that the distribution of the output of the simulator is statistically close to that of the real interaction.</p>

    <h4 id="sec-6" class="text-lg font-semibold mt-6">1.1.1 Statistical ZKPP</h4>

    <p class="text-gray-300">Clearly not every IPP must necessarily be zero-knowledge. Thus, the first natural question to ask is whether this notion is meaningful - do there exist languages with non-trivial statistical ZKPPs? We answer this question affirmatively. Moreover, we show that same natural problem considered by <em>[x10]</em> (i.e., verifying that a function is a permutation) has a very efficient zero-knowledge proof of proximity.</p>

    <h6 id="sec-7" class="text-base font-medium mt-4">Theorem 1.1 (ZKPP for permutations, Informally Stated).</h6>

    <p class="text-gray-300">Let <span class="math">\\operatorname{PERMUTATION}=\\{f:\\{0,1\\}^{n}\\rightarrow\\{0,1\\}^{n}\\text{ such that }f\\text{ is a permutation}\\}.</span> Then:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Property Testing Lower Bound: Every tester for PERMUTATION must make at least <span class="math">\\Omega(2^{n/2})</span> queries to the input (and in particular must run in time <span class="math">\\Omega(2^{n/2})</span>).</li>

      <li>ZKPP Upper Bound: PERMUTATION has a <span class="math">4</span>-round statistical ZKPP in which the verifier runs in <span class="math">\\operatorname{poly}(n)</span> time.</li>

    </ul>

    <p class="text-gray-300">We remark that in this result, and similarly to other results in the literature on (constant-round) statistical zero-knowledge (SZK), we can only bound the expected running time of our simulator. We also remark that Gur and Rothblum <em>[x12]</em> give a lower bound on the complexity of non-interactive IPPs (i.e., IPP in which the entire interaction consists of a single message from the prover to the verifier, also known as MAPs) for PERMUTATION, and using that result we obtain a sub-exponential separation between the power of statistical ZKPP vs. MAPs.</p>

    <p class="text-gray-300">Beyond the property of permutation we also consider two additional problems, both of which are graph problems and show that they admit efficient honest-verifier ZKPP protocols. Both problems that we consider are in the bounded degree graph model, which has been widely studied in the property testing literature <em>[x11, x12]</em>.</p>

    <h6 id="sec-8" class="text-base font-medium mt-4">Theorem 1.2 (Honest Verifier ZKPP for Expansion and Bipartiteness, Informally Stated).</h6>

    <p class="text-gray-300">There exist <em>honest-verifier</em> statistical ZKPP in which the verifier’s running time is <span class="math">\\operatorname{polylog}(N)</span>, for input graphs of size <span class="math">N</span>, for the following two promise problems:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Promise Expansion: Distinguish graphs with (vertex) expansion <span class="math">\\alpha</span> from graphs that are far from even having expansion roughly <span class="math">\\beta=\\alpha^{2}/\\log(N)</span>.</li>

      <li>Promise Bipartiteness: Distinguish bipartite graphs from graphs that are rapidly mixing and far from being bipartite.</li>

    </ol>

    <p class="text-gray-300">A few remarks are in order. We first note that the property testing complexity of both promise problems is <span class="math">\\hat{\\Theta}(\\sqrt{N})</span> <em>[x11, x12, x16, x20, x21]</em>. Second, the IPP for promise-biparititeness that we use to prove Theorem 1.2 is due to <em>[x24]</em> and we merely point out that it is honest-verifier ZKPP. In contrast, the promise-expansion property above was not previously known to admit an (efficient) IPP (let alone an honest-verifier zero-knowledge one). We also remark that both of the problems in Theorem 1.2 refer to promise problems. In particular, we leave open the possibility of a ZKPP for bipartiteness that also handles graphs that are not rapidly mixing, and a ZKPP for expansion that accepts graphs that are <span class="math">\\alpha</span>-expanding and rejects graphs that are far from <span class="math">\\alpha</span>-expanding (rather than just those that are far from being <span class="math">\\alpha^{2}/\\log(N)</span>-expanding as in Theorem 1.2). Lastly, we also leave open the possibility of extending these protocols to be statistical ZKPP against arbitrary cheating verifiers (rather than just honest verifiers).</p>

    <h4 id="sec-9" class="text-lg font-semibold mt-6">Limitations of Statistical ZKPP.</h4>

    <p class="text-gray-300">Given these feasibility results, one may wonder whether statistical ZKPP are as powerful as IPPs. That is, can every IPP be converted to be statistically zero-knowledge with small overhead? We show that this is not the case:</p>

    <h6 id="sec-10" class="text-base font-medium mt-4">Theorem 1.3 (<span class="math">\\mathsf{IPP}\\nsubseteq\\mathsf{SZKPP}</span>, Informally Stated).</h6>

    <p class="text-gray-300">There exists a property <span class="math">\\Pi</span> that has an <span class="math">\\mathsf{IPP}</span> in which the verifier runs in <span class="math">\\mathsf{polylog}(N)</span> time, where <span class="math">N</span> is the input length, but <span class="math">\\Pi</span> does not have a statistical <span class="math">\\mathsf{ZKPP}</span> in which the verifier runs even in time <span class="math">N^{o(1)}</span>.</p>

    <p class="text-gray-300">We note that Theorem 1.3 is unconditional. Interestingly, if we do allow for assumptions, then we can even separate <span class="math">\\mathsf{MAP}</span> from <span class="math">\\mathsf{SZKPP}</span>:</p>

    <h6 id="sec-11" class="text-base font-medium mt-4">Theorem 1.4 (<span class="math">\\mathsf{MAP}\\nsubseteq\\mathsf{SZKPP}</span>, Informally Stated).</h6>

    <p class="text-gray-300">Assuming certain circuit lower bounds, there exists a property <span class="math">\\Pi</span> that has an <span class="math">\\mathsf{MAP}</span> in which the verifier runs in <span class="math">\\mathsf{polylog}(N)</span> time, where <span class="math">N</span> is the input length, but <span class="math">\\Pi</span> does not have a statistical <span class="math">\\mathsf{ZPP}</span> in which the verifier runs even in time <span class="math">N^{o(1)}</span>.</p>

    <p class="text-gray-300">The circuit lower bound that we use follows from the (highly plausible) assumption that the Arthur-Merlin communication complexity of disjointness is <span class="math">n^{\\varepsilon}</span>, where <span class="math">n</span> is the input length and <span class="math">\\varepsilon&gt;0</span> is some constant.</p>

    <h4 id="sec-12" class="text-lg font-semibold mt-6">1.1.2 The Computational Setting</h4>

    <p class="text-gray-300">As is the case in the classical setting, we can obtain much stronger results if we either (1) only require that the simulated view be <em>computationally</em> indistinguishable from the real interaction (i.e., computational zero-knowledge), or (2) only require soundness against <em>efficient</em> cheating provers (i.e., computational soundness or argument).</p>

    <p class="text-gray-300">The following results show that under these relaxations, and assuming reasonable cryptographic assumptions, we can transform many of the known results from the literature of <span class="math">\\mathsf{IPPs}</span> to be zero-knowledge. Focusing on computational zero-knowledge, we can derive such protocols for any language computable in bounded-depth or in bounded-space, where the verifier runs in roughly <span class="math">\\sqrt{N}</span> time.</p>

    <h6 id="sec-13" class="text-base font-medium mt-4">Theorem 1.5 (Computational <span class="math">\\mathsf{ZKPP}</span> for Bounded Depth, Informally Stated).</h6>

    <p class="text-gray-300">Assume that there exist one-way functions. Then, every language in logspace-uniform <span class="math">\\mathsf{NC}</span>, has a computational <span class="math">\\mathsf{ZKPP}</span>, where the verifier (and the simulator) run in time <span class="math">N^{\\frac{1}{2}+o(1)}</span> and the number of rounds is <span class="math">\\mathsf{polylog}(N)</span>.</p>

    <h6 id="sec-14" class="text-base font-medium mt-4">Theorem 1.6 (Computational <span class="math">\\mathsf{ZKPP}</span> for Bounded Space, Informally Stated).</h6>

    <p class="text-gray-300">Assume that there exist one-way functions. Then, every language computable in <span class="math">\\mathsf{poly}(N)</span>-time and <span class="math">O(N^{\\sigma})</span>-space, for some sufficiently small constant <span class="math">\\sigma&gt;0</span>, has a computational <span class="math">\\mathsf{ZKPP}</span>, where the verifier (and the simulator) run in time <span class="math">N^{\\frac{1}{2}+O(\\sigma)}</span>.</p>

    <p class="text-gray-300">Interestingly, if we only require <em>computational soundness</em>, we can do even better. The following result gives <em>statistical</em> zero-knowledge arguments of proximity for every language in <span class="math">\\mathsf{NP}</span>, and with a verifier that runs in <em>poly-logarithmic</em> time.</p>

    <h6 id="sec-15" class="text-base font-medium mt-4">Theorem 1.7 (Statistical Zero-Knowledge Arguments for <span class="math">\\mathsf{NP}</span>, Informally Stated).</h6>

    <p class="text-gray-300">Assume that there exist collision-resistant hash functions. Then, every language in <span class="math">\\mathsf{NP}</span>, has a constant-round <em>statistical</em> zero-knowledge argument of proximity, where the verifier runs in time <span class="math">\\mathsf{polylog}(N)</span>.</p>

    <p class="text-gray-300">We note that Theorems 1.5 to 1.7 strongly rely on (1) results from the literature on <span class="math">\\mathsf{IPPs}</span> <em>[x21, x22]</em> and interactive arguments of proximity <em>[x13, BGH^{+}06, x10]</em>, (2) a method introduced by <em>[BGG^{+}88]</em> for transforming interactive proofs (and arguments) into zero-knowledge ones (while taking some additional care that is not required in the classical setting), and (3) the observation that the verifiers in many of the underlying protocols all make queries that do not depend on messages sent by the prover. See Section 6 for details.</p>

    <p class="text-gray-300">1.2 Additional Related Works</p>

    <p class="text-gray-300">A related notion of <em>zero-knowledge</em> PCPs <em>of</em> proximity was recently considered by Ishai and Weiss <em>[x10]</em>. These are PCP systems in which, the verifier gets oracle access to both the input and to an alleged proof. Similarly to our notion of ZKPP, the verifier runs in sublinear and is assured (with high probability) that the input is close to the language. Here, zero-knowledge means that the verifier learns nothing more than what it could simulate by making few queries to the input. We emphasize that the difference between our model and that of <em>[x10]</em> is that we consider <em>interactice</em> proofs, whereas <em>[x10]</em> focus on PCP-style proofs: namely soundness is guaranteed only if the PCP proof string is written in advance.</p>

    <p class="text-gray-300">A recent work by Ben-Sasson <em>et-al.</em> <em>[BCF^{+}16]</em> studies zero-knowledge interactive oracle proofs - in a model in which the verifier receives <em>oracle</em> access to the communication tape, but full access to the input. Our model of ZKPP is reversed - the verifier has oracle access to the input but full access to the communication tape.</p>

    <h4 id="sec-16" class="text-lg font-semibold mt-6">Organization.</h4>

    <p class="text-gray-300">General notations and definitions used throughout the paper are given in Section 2. The model of zero-knowledge proofs of proximity (ZKPP) is defined in Section 3. Our statistical ZKPP protocols for Permutations, Expansion and Bipartiteness, are presented and analyzed in Section 4, while our lower bounds for statistical ZKPP are in Section 5. Finally, in Section 6 we present our results on computational ZK proofs of proximity and the statistical ZK arguments of proximity.</p>

    <h2 id="sec-17" class="text-2xl font-bold">2 Preliminaries</h2>

    <p class="text-gray-300">We use calligraphic letters to denote sets, uppercase for random variables, lowercase for values and functions, boldface for vectors, and uppercase sans-serif (e.g., A) for algorithms (i.e., Turing Machines). All logarithms considered here are in base two. Given a random variable <span class="math">X</span>, we write <span class="math">x\\leftarrow X</span> to indicate that <span class="math">x</span> is selected according to <span class="math">X</span>. Similarly, given a finite set <span class="math">\\mathcal{S}</span>, we let <span class="math">s\\leftarrow\\mathcal{S}</span> denote that <span class="math">s</span> is selected according to the uniform distribution on <span class="math">\\mathcal{S}</span>. For an interactive protocol <span class="math">(\\mathsf{A},\\mathsf{B})</span>, let <span class="math">\\mathrm{out}(\\mathsf{A},\\mathsf{B})</span> denote a random variable induced by <span class="math">\\mathsf{B}</span>’s output in a random execution of <span class="math">(\\mathsf{A},\\mathsf{B})</span> (usually, <span class="math">\\mathsf{A}</span> will be some prover and <span class="math">\\mathsf{B}</span> will be an honest verifier).</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The relative distance, over alphabet <span class="math">\\Sigma</span>, between two strings <span class="math">x\\in\\Sigma^{n}</span> and <span class="math">y\\in\\Sigma^{n}</span> is defined by $\\Delta(x,y):=\\frac{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\{x_{i}\\neq y_{i}:\\,i\\in[n]\\}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{n}<span class="math">. If </span>\\Delta(x,y)\\leq\\varepsilon<span class="math">, we say that </span>x<span class="math"> is </span>\\varepsilon<span class="math">-close to </span>y<span class="math">, and otherwise we say that </span>x<span class="math"> is </span>\\varepsilon<span class="math">-far from </span>y<span class="math">. Similarly, we define the relative distance of </span>x<span class="math"> from a non-empty set </span>S\\subseteq\\Sigma^{n}<span class="math"> by </span>\\Delta(x,S):=\\min_{y\\in S}\\Delta(x,y)<span class="math">. If </span>\\Delta(x,y)\\leq\\varepsilon<span class="math">, we say that </span>x<span class="math"> is </span>\\varepsilon<span class="math">-close to </span>S<span class="math">, and otherwise we say that </span>x<span class="math"> is </span>\\varepsilon<span class="math">-far from </span>S<span class="math">. The bitwise exclusive-or between two binary strings </span>x,y\\in\\{0,1\\}^{n}<span class="math"> is denoted by </span>x\\oplus y<span class="math">. The statistical distance between two distributions </span>P<span class="math"> and </span>Q<span class="math"> over a finite set </span>\\mathcal{U}<span class="math">, is defined as </span>\\mathrm{SD}(P,Q):=\\max_{\\mathcal{S}\\subseteq\\mathcal{U}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">P(\\mathcal{S})-Q(\\mathcal{S})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\frac{1}{2}\\sum_{u\\in\\mathcal{U}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">P(u)-Q(u)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> and their product distribution is denoted by </span>P\\otimes B$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The image of a function <span class="math">f\\colon\\mathcal{X}\\to\\mathcal{Y}</span> is defined as <span class="math">\\mathrm{Im}(f)=\\{y\\in\\mathcal{Y}\\colon\\exists x\\in\\mathcal{X}\\,,f(x)=y\\}</span>. An additional notation that we will use is that if <span class="math">S=\\left(S_{k}\\right)_{k\\in\\mathbb{N}}</span> and <span class="math">T=\\left(T_{k}\\right)_{k\\in\\mathbb{N}}</span> are ensembles of sets, we denote by <span class="math">S\\subseteq T</span> the fact that <span class="math">S_{k}\\subseteq T_{k}</span> for every <span class="math">k\\in\\mathbb{N}</span>.</p>

    <p class="text-gray-300">2.1 Hashing and Entropy</p>

    <h4 id="sec-18" class="text-lg font-semibold mt-6">2.1.1 Entropy</h4>

    <h6 id="sec-19" class="text-base font-medium mt-4">Definition 2.1 (Entropy).</h6>

    <p class="text-gray-300">The entropy of a discrete random variable <span class="math">X</span> is defined as</p>

    <p class="text-gray-300"><span class="math">\\mathrm{H}(X):=\\mathrm{E}_{x\\leftarrow X}\\bigg{[}\\log\\bigg{(}\\frac{1}{\\Pr[X=x]}\\bigg{)}\\bigg{]}.</span></p>

    <p class="text-gray-300">The binary entropy function <span class="math">h\\colon[0,1]\\to[0,1]</span> is defined to be the entropy of <span class="math">X\\sim\\text{Bernoulli}(p)</span>, that is, <span class="math">h(p)=-p\\log(p)-(1-p)\\log(1-p)</span>, where we use the convention that <span class="math">h(0)=h(1)=0</span>.</p>

    <p class="text-gray-300">Another notion of entropy that we shall use is that that of (conditional) average min-entropy.</p>

    <h6 id="sec-20" class="text-base font-medium mt-4">Definition 2.2 (average min-entropy <em>[x10]</em>).</h6>

    <p class="text-gray-300">Let <span class="math">X,Y</span> be jointly distributed random variables. The average min-entropy of <span class="math">X</span> given <span class="math">Y</span> is defined by</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\tilde{\\mathrm{H}}_{\\infty}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y):=-\\log\\Big{(}\\mathrm{E}_{y\\leftarrow Y}\\Big{[}\\max_{x}\\Pr[X=x\\mid Y=y]\\Big{]}\\Big{)}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The following fact follows immediately from the above definition.</p>

    <h6 id="sec-21" class="text-base font-medium mt-4">Fact 2.3.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">X^{n},Y^{n}</span> be <span class="math">n</span>-tuples of independent copies of the random variables <span class="math">X</span> and <span class="math">Y</span> respectively. Then $\\tilde{\\mathrm{H}}_{\\infty}(X^{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y^{n})=n\\cdot\\tilde{\\mathrm{H}}_{\\infty}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-22" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">We prove for the case that <span class="math">n=2</span>. The general case follows by induction.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\tilde{\\mathrm{H}}_{\\infty}(X^{2}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y^{2})<span class="math"> </span>=-\\log\\bigg{(}\\mathrm{E}_{(y_{1},y_{2})\\leftarrow Y^{2}}\\bigg{[}\\max_{x_{1},x_{2}}\\Pr\\big{[}X^{2}=(x_{1},x_{2})\\mid Y^{2}=(y_{1},y_{2})\\big{]}\\bigg{]}\\bigg{)}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">=-\\log\\bigg{(}\\mathrm{E}_{(y_{1},y_{2})\\leftarrow Y^{2}}\\bigg{[}\\max_{x_{1},x_{2}}\\Pr[X=x_{1}\\mid Y=y_{1}]\\cdot\\Pr[X=x_{2}\\mid Y=y_{2}]\\bigg{]}\\bigg{)}</span> <span class="math">=-\\log\\bigg{(}\\mathrm{E}_{(y_{1},y_{2})\\leftarrow Y^{2}}\\bigg{[}\\max_{x_{1}}\\Pr[X=x_{1}\\mid Y=y_{1}]\\cdot\\max_{x_{2}}\\Pr[X=x_{2}\\mid Y=y_{2}]\\bigg{]}\\bigg{)},</span></p>

    <p class="text-gray-300">where the second inequality follows since the first sample from <span class="math">(X,Y)</span> is independent from the second one, and thre third inequality follows since for non-negative functions <span class="math">f,g</span>, it holds that <span class="math">\\max_{x_{1},x_{2}}f(x_{1})\\cdot g(x_{2})=\\max_{x_{1}}f(x_{1})\\cdot\\max_{x_{2}}g(x_{2})</span>. Letting <span class="math">h(y)=\\max_{x}\\Pr[X=x\\mid Y=y]</span>, we write</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\tilde{\\mathrm{H}}_{\\infty}(X^{2}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y^{2})<span class="math"> </span>=-\\log\\big{(}\\mathrm{E}_{(y_{1},y_{2})\\leftarrow Y^{2}}[h(y_{1})\\cdot h(y_{2})]\\big{)}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">=-\\log(\\mathrm{E}_{y_{1}\\leftarrow Y}[h(y_{1})]\\cdot\\mathrm{E}_{y_{2}\\leftarrow Y}[h(y_{2})])</span> <span class="math">=-\\log(\\mathrm{E}_{y_{1}\\leftarrow Y}[h(y_{1})])-\\log(\\mathrm{E}_{y_{2}\\leftarrow Y}[h(y_{2})])</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$=\\tilde{\\mathrm{H}}_{\\infty}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y)+\\tilde{\\mathrm{H}}_{\\infty}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y),$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where the second inequality follows since the first sample of <span class="math">Y</span> is independent of the second one. ∎</p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">2.1.2 Hashing</p>

    <h6 id="sec-23" class="text-base font-medium mt-4">Definition 2.4 (pairwise independent hash functions).</h6>

    <p class="text-gray-300">A family of functions <span class="math">\\mathcal{H}=\\{h:[N]\\to[M]\\}</span> is pairwise independent if for every <span class="math">x_{1}\\neq x_{2}\\in[N]</span> and every <span class="math">y_{1},y_{2}\\in[M]</span>, it holds that</p>

    <p class="text-gray-300"><span class="math">\\Pr_{h\\leftarrow\\mathcal{H}}[h(x_{1})=y_{1}\\wedge h(x_{2})=y_{2}]=\\frac{1}{M^{2}}.</span></p>

    <p class="text-gray-300">The existence of efficient pairwise independent hash functions is well known.</p>

    <h6 id="sec-24" class="text-base font-medium mt-4">Fact 2.5 (c.f. <em>[x19, Theorem 3.26]</em>).</h6>

    <p class="text-gray-300">For every <span class="math">n,m\\in\\mathbb{N}</span>, there exists a family of pairwise independent hash functions <span class="math">\\mathcal{H}_{n,m}=\\{h\\colon\\{0,1\\}^{n}\\to\\{0,1\\}^{m}\\}</span> where a random function from <span class="math">\\mathcal{H}_{n,m}</span> can be selected using <span class="math">\\max(m,n)+m</span> bits, and given a description of <span class="math">h\\in\\mathcal{H}_{n.m}</span> and <span class="math">x\\in\\{0,1\\}^{n}</span>, the value <span class="math">h(x)</span> can be evaluated in time <span class="math">\\poly(n,m)</span>.</p>

    <p class="text-gray-300">Dodis <em>et-al.</em> <em>[x10]</em>, showed the following generalization of the leftover hash lemma, for sources having high <em>conditional</em> min-entropy.</p>

    <h6 id="sec-25" class="text-base font-medium mt-4">Lemma 2.6 (generalized leftover hash lemma <em>[x10, Lemma 2.4]</em>).</h6>

    <p class="text-gray-300">Let <span class="math">\\mathcal{H}=\\{h\\colon\\{0,1\\}^{n}\\to\\{0,1\\}^{m}\\}</span> be a family of pairwise independent hash functions. Then, for any random variables <span class="math">X</span> and <span class="math">Y</span> and the random variable <span class="math">H\\leftarrow\\mathcal{H}</span>, it holds that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\mathrm{SD}\\Big{(}\\big{(}H(X),H,Y\\big{)},\\big{(}U_{m},H,Y\\big{)}\\Big{)}\\leq\\frac{1}{2}\\cdot\\sqrt{2^{-\\tilde{\\mathsf{H}}_{\\infty}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y)}\\cdot 2^{m}}\\ ,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where <span class="math">U_{m}</span> is distributed uniformly over <span class="math">\\{0,1\\}^{m}</span>.</p>

    <h3 id="sec-26" class="text-xl font-semibold mt-8">2.2 Statistical Zero-Knowledge</h3>

    <p class="text-gray-300">We use standard definitions and results from the literature of statistical zero-knowledge proofs, based mainly on <em>[x18]</em>.</p>

    <h4 id="sec-27" class="text-lg font-semibold mt-6">2.2.1 Statistical Zero-Knowledge Interactive Proofs</h4>

    <p class="text-gray-300">In this section we give the (almost) standard definitions for interactive proofs and honest-verifier zero-knowledge proofs.</p>

    <h6 id="sec-28" class="text-base font-medium mt-4">Definition 2.7 (interactive proofs).</h6>

    <p class="text-gray-300">Let <span class="math">\\Pi=(\\Pi_{\\mathsf{YES}},\\Pi_{\\mathsf{NO}})</span> be a promise problem. An <em>interactive proof system</em> for <span class="math">\\Pi</span> is an interactive protocol <span class="math">(\\mathsf{P},\\mathsf{V})</span> with <em>completeness error</em> <span class="math">c\\colon\\mathbb{N}\\to[0,1]</span> and <em>soundness error</em> <span class="math">s\\colon\\mathbb{N}\\to[0,1]</span> if the following holds for every security parameter <span class="math">k\\in\\mathbb{N}</span>:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Completeness: If <span class="math">x\\in\\Pi_{\\mathsf{YES}}</span>, then, when <span class="math">\\mathsf{V}(x,k)</span> interacts with <span class="math">\\mathsf{P}(x,k)</span>, with probability <span class="math">1-c(k)</span> it accepts.</li>

      <li>Soundness: If <span class="math">x\\in\\Pi_{\\mathsf{NO}}</span>, then for every prover strategy <span class="math">\\widehat{\\mathsf{P}}</span>, when <span class="math">\\mathsf{V}(x,k)</span> interacts with <span class="math">\\widehat{\\mathsf{P}}</span>, with probability <span class="math">1-s(k)</span> it rejects.</li>

    </ul>

    <p class="text-gray-300">If <span class="math">c(\\cdot)</span> and <span class="math">s(\\cdot)</span> are negligible functions, we say that <span class="math">(\\mathsf{P},\\mathsf{V})</span> is an <em>interactive proof system</em>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The above definition does not deal with the efficiency of the verifier or the prover, unlike the standard definition that requires the verifier to run in time $\\poly(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,k)$. Jumping ahead, this is because in our settings the verifier (and also the simulator) will have only oracle-access to their inputs. We will refer to the efficiency of those algorithms within theorem statements.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-29" class="text-base font-medium mt-4">Definition 2.8 (view of interactive protocol).</h6>

    <p class="text-gray-300">Let <span class="math">(\\mathsf{P},\\mathsf{V})</span> be an <span class="math">r</span>-message interactive protocol. The view of <span class="math">\\mathsf{V}</span> on a common input <span class="math">x</span> (given as standard input or by oracle access to either of the parties) is defined by <span class="math">\\operatorname{view}_{\\mathsf{P},\\mathsf{V}}(x):=(m_{1},m_{2},\\ldots,m_{r};\\rho)</span>, where <span class="math">m_{1},m_{2},\\ldots,m_{r}</span> are the messages sent by the parties in a random execution of the protocol, and <span class="math">\\rho</span> contains of all the random coins <span class="math">\\mathsf{V}</span> used during this execution.</p>

    <p class="text-gray-300">We allow probabilistic algorithms to fail by outputting <span class="math">\\bot</span>. An algorithm <span class="math">\\mathsf{A}</span> is useful if <span class="math">\\Pr[\\mathsf{A}(x)=\\bot]\\leq 1/2</span> for every <span class="math">x</span>, and let <span class="math">\\widetilde{\\mathsf{A}}(x)</span> denote the output distribution of <span class="math">\\mathsf{A}(x)</span>, conditioning on <span class="math">\\mathsf{A}(x)\\neq\\bot</span>.</p>

    <h6 id="sec-30" class="text-base font-medium mt-4">Definition 2.9 (honest-verifier zero-knowledge proofs).</h6>

    <p class="text-gray-300">Let <span class="math">\\Pi=(\\Pi_{\\mathsf{YES}},\\Pi_{\\mathsf{NO}})</span> be a promise problem. An interactive proof <span class="math">(\\mathsf{P},\\mathsf{V})</span> for <span class="math">\\Pi</span> is said to be honest-verifier statistical zero-knowledge, if there exists an algorithm <span class="math">\\mathsf{S}</span>, and a negligible function <span class="math">\\mu\\colon\\mathbb{N}\\to[0,1]</span> such that for every <span class="math">k\\in\\mathbb{N}</span> and <span class="math">x\\in\\Pi_{\\mathsf{YES}}</span>,</p>

    <p class="text-gray-300"><span class="math">\\operatorname{SD}\\Big{(}\\widetilde{\\mathsf{S}}(x,k),\\operatorname{view}_{\\mathsf{P},\\mathsf{V}}(x,k)\\Big{)}\\leq\\mu(k).</span></p>

    <h4 id="sec-31" class="text-lg font-semibold mt-6">2.2.2 Statistical Distance, Entropy Difference and Sample-Access Proofs</h4>

    <p class="text-gray-300">Central in the study of statistical zero-knowledge are problems dealing with properties of distributions encoded by circuits.</p>

    <h6 id="sec-32" class="text-base font-medium mt-4">Definition 2.10 (distributions encoded by circuits).</h6>

    <p class="text-gray-300">Let <span class="math">X</span> be a Boolean circuit with <span class="math">m</span> input gates and <span class="math">n</span> output gates. The distribution encoded by <span class="math">X</span> is the distribution induced on <span class="math">\\{0,1\\}^{n}</span> by evaluating <span class="math">X</span> on a uniformly selected string from <span class="math">\\{0,1\\}^{m}</span>. By abuse of notation, we also write <span class="math">X</span> for the distribution defined by the circuit <span class="math">X</span>.</p>

    <p class="text-gray-300">Two particularly interesting problems are statistical distance and entropy difference.</p>

    <h6 id="sec-33" class="text-base font-medium mt-4">Definition 2.11 (Statistical Distance).</h6>

    <p class="text-gray-300">For any constants <span class="math">0\\leq\\beta\\leq\\alpha\\leq 1</span>, the promise problem <span class="math">\\mathsf{SD}^{\\alpha,\\beta}=(\\mathsf{SD}^{\\alpha,\\beta}_{\\mathsf{YES}},\\mathsf{SD}^{\\alpha,\\beta}_{\\mathsf{NO}})</span> is given by</p>

    <p class="text-gray-300"><span class="math">\\mathsf{SD}^{\\alpha,\\beta}_{\\mathsf{YES}}</span> <span class="math">=\\{(X,Y)\\colon\\operatorname{SD}(X,Y)\\geq\\alpha\\}</span> <span class="math">\\mathsf{SD}^{\\alpha,\\beta}_{\\mathsf{NO}}</span> <span class="math">=\\{(X,Y)\\colon\\operatorname{SD}(X,Y)\\leq\\beta\\}.</span></p>

    <p class="text-gray-300">Above, <span class="math">X,Y</span> are distributions encoded by circuits according to Definition 2.10.</p>

    <h6 id="sec-34" class="text-base font-medium mt-4">Definition 2.12 (Entropy Difference).</h6>

    <p class="text-gray-300">Entropy Difference is the promise problem <span class="math">\\mathsf{ED}=(\\mathsf{ED}_{\\mathsf{YES}},\\mathsf{ED}_{\\mathsf{NO}})</span>, where</p>

    <p class="text-gray-300"><span class="math">\\mathsf{ED}_{\\mathsf{YES}}</span> <span class="math">=\\{(X,Y)\\colon\\operatorname{H}(X)\\geq\\operatorname{H}(Y)+1\\},</span> <span class="math">\\mathsf{ED}_{\\mathsf{NO}}</span> <span class="math">=\\{(X,Y)\\colon\\operatorname{H}(Y)\\geq\\operatorname{H}(X)+1\\}.</span></p>

    <p class="text-gray-300">Above, <span class="math">X,Y</span> are distributions encoded by circuits according to Definition 2.10.</p>

    <p class="text-gray-300">Both <span class="math">\\mathsf{SD}</span> and <span class="math">\\mathsf{ED}</span> are known to be complete for the class of problems that have statistical zero-knowledge proofs (see <em>[x20, Theorem 3.5.1]</em>). A fact that we will rely on heavily, is that the zero-knowledge proof-systems for <span class="math">\\mathsf{SD}</span> and <span class="math">\\mathsf{ED}</span> only require sample access to the distributions induced by the input circuits. That is, neither the verifier not the simulator in these proof-systems need to actually look at the circuits themselves. Rather, all that they need is the ability to generate random samples from the circuits.</p>

    <h6 id="sec-35" class="text-base font-medium mt-4">Definition 2.13 (sample-access honest-verifier zero-knowledge proof).</h6>

    <p class="text-gray-300">Let <span class="math">\\Pi</span> be a promise problem whose instances are pairs of distributions encoded by circuits. An honest-verifier zero-knowledge proof system for <span class="math">\\Pi</span> is sample-access if both the verifier and the simulator only require oracle access to random samples from the distributions encoded by the input circuits (in addition to explicitly getting the security parameter <span class="math">k</span>).</p>

    <p class="text-gray-300">We can now state the results regarding the zero-knowledge proof systems of <span class="math">\\mathsf{SD}</span> and <span class="math">\\mathsf{ED}</span>. In fact, we will not care about <span class="math">\\mathsf{SD}</span> but rather about <em>statistical closeness</em>, the complement of <span class="math">\\mathsf{SD}</span> in which the <span class="math">\\mathsf{YES}</span> and <span class="math">\\mathsf{NO}</span> instances are switched, namely <span class="math">\\widetilde{\\mathsf{SD}^{\\alpha,\\beta}}:=\\left(\\mathsf{SD}^{\\alpha,\\beta}_{\\mathsf{NO}},\\mathsf{SD}^{\\alpha,\\beta}_{\\mathsf{YES}}\\right)</span>.</p>

    <h6 id="sec-36" class="text-base font-medium mt-4">Lemma 2.14.</h6>

    <p class="text-gray-300">Let <span class="math">0\\leq\\beta\\leq\\alpha\\leq 1</span> be constants such that <span class="math">h((1+\\alpha)/2)&lt;\\underline{1}-\\beta</span>. Then, there exists a <span class="math">2</span>-message sample-access honest-verifier statistical zero-knowledge proof for <span class="math">\\widetilde{\\mathsf{SD}^{\\alpha,\\beta}}</span>. Moreover, the running times of the verifier and the simulator in the above protocol given sample access to <span class="math">(X,Y)</span> and security parameter <span class="math">k</span> are <span class="math">\\mathsf{poly}(m,n,k)</span>, where <span class="math">m</span> is the number of random coins needed to sample from <span class="math">X</span> or <span class="math">Y</span> (i.e., their input size) and <span class="math">n</span> is the output size of <span class="math">X</span> and <span class="math">Y</span>.</p>

    <p class="text-gray-300">The protocol establishing Lemma 2.14 reduces, in a black-box way, an instance of <span class="math">\\widetilde{\\mathsf{SD}^{\\alpha,\\beta}}</span> to <span class="math">\\mathsf{ED}</span> (see <em>[x20, Section 4.4]</em>) and then uses the next lemma.</p>

    <h6 id="sec-37" class="text-base font-medium mt-4">Lemma 2.15.</h6>

    <p class="text-gray-300">There exists <span class="math">2</span>-message sample-access honest-verifier statistical zero-knowledge proof for <span class="math">\\mathsf{ED}</span>. Moreover, the running times of the verifier and the simulator in the above protocol given sample access to <span class="math">(X,Y)</span> and security parameter <span class="math">k</span> are <span class="math">\\mathsf{poly}(m,n,k)</span>, where <span class="math">m</span> is the number of random coins needed to sample from <span class="math">X</span> or <span class="math">Y</span> (i.e., their input size) and <span class="math">n</span> is the output size of <span class="math">X</span> and <span class="math">Y</span>.</p>

    <h2 id="sec-38" class="text-2xl font-bold">3 ZKPP — Model and Definitions</h2>

    <p class="text-gray-300">In this section we formally define the model of <em>statistical</em> zero-knowledge proofs of proximity. We follow definition choices from the literature of classical statistical zero-knowledge proofs, mainly based on <em>[x20]</em> (see Section 2.2.2). For a discussion about the computational setting, see Remark 3.7 below.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Properties will be identified as sets of functions. A property is an ensemble <span class="math">\\Pi=(\\Pi_{n},\\mathcal{D}_{n},\\mathcal{R}_{n})_{n\\in\\mathbb{N}}</span>, where <span class="math">\\Pi_{n}\\subseteq\\mathcal{F}_{\\mathcal{D}_{n}\\to\\mathcal{R}_{n}}</span> for every <span class="math">n\\in\\mathbb{N}</span>, letting <span class="math">\\mathcal{F}_{\\mathcal{D}\\to\\mathcal{R}}</span> denote the set of all functions from domain <span class="math">\\mathcal{D}</span> to range <span class="math">\\mathcal{R}</span>. Equivalently, we sometimes view <span class="math">\\Pi_{n}</span> as a string of length $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> over the alphabet </span>\\mathcal{R}_{n}<span class="math"> and write </span>\\Pi_{n}\\subseteq\\mathcal{R}_{n}^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">. For a property </span>\\Pi<span class="math"> and </span>n\\in\\mathbb{N}<span class="math">, let </span>N_{\\Pi}(n):=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\cdot\\log(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> denote the input-size of </span>\\Pi_{n}<span class="math">. Throughout this paper we remove </span>\\Pi<span class="math"> and </span>n<span class="math"> from the above notation, and simply let </span>N$ denote the input-size of the relevant property (this will be convenient when defining complexity classes; see ahead). We note that, depending on the context, we will sometimes refer to properties as languages. Lastly, similar to <em>[x20]</em>, we use a security parameter to control our soundness and zero-knowledge guarantees ( see Remark 3.6 for additional details).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-39" class="text-base font-medium mt-4">Definition 3.1 (interactive proofs of proximity (<span class="math">\\mathsf{IPP}</span>)).</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">An <span class="math">r</span>-message interactive proof of proximity (<span class="math">\\mathsf{IPP}</span>), with respect to proximity parameter <span class="math">\\varepsilon&gt;0</span>, (in short, <span class="math">\\varepsilon</span>-<span class="math">\\mathsf{IPP}</span>) for the property <span class="math">\\Pi=(\\Pi_{n},\\mathcal{D}_{n},\\mathcal{R}_{n})_{n\\in\\mathbb{N}}</span> is an interactive protocol <span class="math">(\\mathsf{P},\\mathsf{V})</span> between a prover <span class="math">\\mathsf{P}</span>, which gets <em>free</em> access to an input <span class="math">f\\colon\\mathcal{D}_{n}\\to\\mathcal{R}_{n}</span> as well as to <span class="math">\\varepsilon</span>, $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> and </span>k<span class="math">, and a verifier </span>\\mathsf{V}<span class="math">, which gets <em>oracle</em> access to </span>f<span class="math"> as well as free access to </span>\\varepsilon<span class="math">, </span>n<span class="math">, </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> and </span>k<span class="math">. The following conditions are satisfied at the end of the protocol for every </span>k\\in\\mathbb{N}<span class="math"> and large enough </span>n\\in\\mathbb{N}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Completeness: If <span class="math">f \\in \\Pi_n</span>, then, when <span class="math">\\mathsf{V}</span> interacts with <span class="math">\\mathsf{P}</span>, with probability <span class="math">1 - \\mathrm{negl}(k)</span> it accepts.</li>

      <li>Soundness: If <span class="math">f</span> is <span class="math">\\varepsilon</span>-far from <span class="math">\\Pi_n</span>, then for every prover strategy <span class="math">\\widehat{\\mathsf{P}}</span>, when <span class="math">\\mathsf{V}</span> interacts with <span class="math">\\widehat{\\mathsf{P}}</span>, with probability <span class="math">1 - \\mathrm{negl}(k)</span> it rejects.</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">For $t = t(n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, k, \\varepsilon)<span class="math">, </span>\\mathsf{IPP}[t]<span class="math"> denotes the class of properties possessing </span>\\varepsilon<span class="math">-IPP in which the verifier&#x27;s running time is at most </span>O(t)<span class="math">. Finally, for a class of functions </span>\\mathcal{C}<span class="math">, we denote by </span>\\mathsf{IPP}[\\mathcal{C}(n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, k, \\varepsilon)]<span class="math"> the class of properties </span>\\Pi<span class="math"> for which there exists </span>t \\in \\mathcal{C}<span class="math"> such that </span>\\Pi \\in \\mathsf{IPP}[t]$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The probabilities that the verifier rejects in the completeness condition and accepts in the soundness condition are called the completeness error and soundness error, respectively. If the completeness condition holds with probability 1, then we say that the IPP has perfect completeness. A public-coin IPP is an IPP in which every message from the verifier to the prover consists only of fresh random coin tosses.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">An IPP is said to have query complexity <span class="math">q\\colon \\mathbb{N}\\times \\mathbb{N}\\times \\mathbb{N}\\times \\mathbb{N}\\times (0,1]\\to \\mathbb{N}</span> if for every <span class="math">n,k\\in \\mathbb{N}</span>, <span class="math">\\varepsilon &amp;gt;0</span>, <span class="math">x\\in \\mathcal{F}_{\\mathcal{D}_n\\to \\mathcal{R}_n}</span>, and any prover strategy <span class="math">\\widehat{\\mathsf{P}}</span>, the verifier <span class="math">\\mathsf{V}</span> makes at most $q(n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,k,\\varepsilon)<span class="math"> queries to </span>x<span class="math"> when interacting with </span>\\widehat{\\mathsf{P}}<span class="math">. The IPP is said to have communication complexity </span>c\\colon \\mathbb{N}\\times \\mathbb{N}\\times \\mathbb{N}\\times \\mathbb{N}\\times (0,1]\\to \\mathbb{N}<span class="math"> if for every </span>n,k\\in \\mathbb{N}<span class="math">, </span>\\varepsilon &gt;0<span class="math">, and </span>x\\in \\mathcal{F}_{\\mathcal{D}_n\\to \\mathcal{R}_n}<span class="math"> the communication between </span>\\mathsf{V}<span class="math"> and </span>\\mathsf{P}<span class="math"> consists of at most </span>c(n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,k,\\varepsilon)$ bits.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Our main (but not exclusive) focus in this work is on properties that have IPPs in which the verifier's running time (and thus also the communication and query complexities) is poly-logarithmic in the input size and polynomial in the security parameter <span class="math">k</span> and in the reciprocal of the proximity parameter <span class="math">1 / \\varepsilon</span>, that is, the class <span class="math">\\mathsf{IPP}[\\mathsf{poly}(\\log (N),k,1 / \\varepsilon)]</span>.</p>

    <p class="text-gray-300">An IPP that consists of a single message sent from the prover (Merlin) to the verifier (Arthur) is called Merlin-Arthur proof of proximity (MAP). We extend all the above notations to Merlin-Arthur proofs of proximity in the natural way.</p>

    <p class="text-gray-300">Before defining general ZKPPs, we first consider zero-knowledge with respect to honest verifiers.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Definition 3.2 (honest-verifier zero-knowledge proof of proximity (HV-SZKPP, HV-PZKPP)). Let <span class="math">(\\mathsf{P},\\mathsf{V})</span> be an interactive proof of proximity for a property <span class="math">\\Pi = (\\Pi_n,\\mathcal{D}_n,\\mathcal{R}_n)_{n\\in \\mathbb{N}}</span>. The protocol <span class="math">(\\mathsf{P},\\mathsf{V})</span> is said to be honest-verifier statistical zero-knowledge with simulation overhead <span class="math">s</span>, for some function <span class="math">s\\colon \\mathbb{N}\\times \\mathbb{N}\\times \\mathbb{N}\\times \\mathbb{N}\\times \\mathbb{N}\\times (0,1]\\to \\mathbb{N}</span> if there exists a useful probabilistic algorithm <span class="math">\\mathsf{S}</span>, which (like <span class="math">\\mathsf{V}</span>) gets oracle access to <span class="math">f\\colon \\mathcal{D}_n\\to \\mathcal{R}_n</span> as well as free access to <span class="math">\\varepsilon</span>, <span class="math">n</span>, $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> and </span>k<span class="math">, and whose running time is at most </span>O(s(t_{\\mathsf{V}},n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,k,\\varepsilon))<span class="math">, where </span>t_{\\mathsf{V}}(n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,k,\\varepsilon)<span class="math"> is </span>\\mathsf{V}<span class="math">&#x27;s running time, such that for every </span>k\\in \\mathbb{N}<span class="math">, every large enough </span>n\\in \\mathbb{N}<span class="math"> and </span>f\\colon \\mathcal{D}_n\\to \\mathcal{R}_n<span class="math">, if </span>f\\in \\Pi_n$, then</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathrm {S D} \\left(\\widetilde {\\mathbf {S}} ^ {f} (\\varepsilon , n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal {D} _ {n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal {R} _ {n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, k), \\operatorname {v i e w} _ {\\mathrm {P}, \\mathrm {V}} (\\varepsilon , n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal {D} _ {n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal {R} _ {n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, k, f)\\right) \\leq \\operatorname {n e g l} (k).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">If the <span class="math">\\mathrm{negl}(k)</span> can be replaced with 0 in the above equation, <span class="math">(\\mathsf{P},\\mathsf{V})</span> is said to be honest-verifier perfect zero-knowledge with simulation overhead <span class="math">s</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">For $t = t(n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,k,\\varepsilon)<span class="math">, HV-SZKPP[t,s] (resp., HV-PZKPP[t,s]) denotes the class of properties possessing honest-verifier statistical (resp., perfect) zero-knowledge proof of proximity with simulation overhead </span>s<span class="math"> in which the verifier&#x27;s running time is at most </span>O(t)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">10Recall that an algorithm A is useful if <span class="math">\\operatorname{Pr}[\\mathsf{A}(x) = \\bot] \\leq 1/2</span> for every <span class="math">x</span>, and that <span class="math">\\widetilde{\\mathsf{A}}(x)</span> denote the output distribution of <span class="math">\\mathsf{A}(x)</span>, conditioning on <span class="math">\\mathsf{A}(x) \\neq \\bot</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We say that the query complexity of a simulator <span class="math">\\mathsf{S}</span> is <span class="math">q^{\\prime}\\colon\\mathbb{N}\\times\\mathbb{N}\\times\\mathbb{N}\\times(0,1]\\to\\mathbb{N}</span> if for every <span class="math">n,k\\in\\mathbb{N}</span>, <span class="math">\\varepsilon&gt;0</span>, <span class="math">f\\in\\mathcal{F}_{\\mathcal{D}_{n}\\to\\mathcal{R}_{n}}</span>, <span class="math">\\mathsf{S}_{n}^{f}</span> makes at most $q^{\\prime}(n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,k,\\varepsilon)<span class="math"> queries to </span>f$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">A typical setting (that we will focus on) is when the verifier’s running time is <span class="math">\\poly(\\log(N),k,1/\\varepsilon)</span>, namely poly-logarithmic in the input length <span class="math">N</span> and polynomial in the security parameter <span class="math">k</span> and in the proximity parameter <span class="math">1/\\varepsilon</span>. In this setting we often allow for <em>polynomial</em> simulation overhead, that is the simulator’s running time is also <span class="math">\\poly(\\log(N),k,1/\\varepsilon)</span>. Specifically, we denote by <span class="math">\\textsf{HV-SZKPP}\\big{[}\\poly(\\log(N),k,1/\\varepsilon)\\big{]}</span> the class of properties <span class="math">\\Pi\\in\\textsf{HV-SZKPP}[t,s]</span> for <span class="math">t=\\poly(\\log(N),k,1/\\varepsilon)</span> and <span class="math">s=\\poly(t,\\log(N),k,1/\\varepsilon)</span>. The class HV-PZKPP<span class="math">\\big{[}\\poly(\\log(N),k,1/\\varepsilon)\\big{]}</span> is similarly defined.</p>

    <p class="text-gray-300">Another setting of interest is when the verifier’s running time is <span class="math">N^{\\delta}\\cdotpoly(k,1/\\varepsilon)</span>, for some constant <span class="math">\\delta\\in(0,1)</span>. In this setting, unlike the previous one, allowing the simulation overhead to be polynomial will give the simulator much greater computational power than the verifier (e.g., if <span class="math">\\delta=1/2</span> and <span class="math">s</span> is quadratic in the verifier’s running time, then the simulator can run in time <span class="math">O(N)</span> and in particular may read the entire input). In this setting we aim for the simulation overhead to be <em>linear</em> in the verifier’s running time (but it can be polynomial in <span class="math">k</span> and <span class="math">1/\\varepsilon</span>).</p>

    <p class="text-gray-300">When the simulation overhead is clear from context (as it will almost always be the case) we omit it from the notation.</p>

    <h4 id="sec-40" class="text-lg font-semibold mt-6">Cheating Verifier ZKPP.</h4>

    <p class="text-gray-300">We will allow cheating verifiers to be non-uniform by giving them an auxiliary input. For an algorithm <span class="math">\\mathsf{A}</span> and a string <span class="math">z\\in\\{0,1\\}^{<em>}</span> (all auxiliary inputs will be binary strings, regardless of the properties’ alphabet), let <span class="math">\\mathsf{A}_{[z]}</span> be <span class="math">\\mathsf{A}</span> when <span class="math">z</span> was given as auxiliary input. Since we care about algorithms whose running time is insufficient to read the entire input, we would not want to allow the running time to depend on the auxiliary input (otherwise, we could artificially inflate <span class="math">z</span> so that <span class="math">\\mathsf{A}</span> would be able to read the entire input). Thus, following </em>[x20]*, we adopt the convention that the running time of <span class="math">\\mathsf{A}</span> is independent of <span class="math">z</span>, so if <span class="math">z</span> is too long, <span class="math">\\mathsf{A}</span> will not be able to access it in its entirety.</p>

    <h6 id="sec-41" class="text-base font-medium mt-4">Definition 3.3 (cheating-verifier zero-knowledge proof of proximity (SZKPP, PZKPP)).</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">(\\mathsf{P},\\mathsf{V})</span> be an interactive proof of proximity for a property <span class="math">\\Pi=(\\Pi_{n},\\mathcal{D}_{n},\\mathcal{R}_{n})_{n\\in\\mathbb{N}}</span>. <span class="math">(\\mathsf{P},\\mathsf{V})</span> is said to be cheating-verifier statistical zero-knowledge with simulation overhead <span class="math">s</span>, for some function <span class="math">s\\colon\\mathbb{N}\\times\\mathbb{N}\\times\\mathbb{N}\\times\\mathbb{N}\\times\\mathbb{N}\\times(0,1]\\to\\mathbb{N}</span>, if for every algorithm <span class="math">\\widehat{\\mathsf{V}}</span> whose running time is $O(t_{\\widehat{\\mathsf{V}}}(n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,k,\\varepsilon))<span class="math">, there exists a useful probabilistic algorithm </span>\\mathsf{S}<span class="math">, which (like </span>\\widehat{\\mathsf{V}}<span class="math">) gets oracle access to </span>f\\colon\\mathcal{D}_{n}\\to\\mathcal{R}_{n}<span class="math"> as well as free access to </span>\\varepsilon<span class="math">, </span>n<span class="math">, </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> and </span>k<span class="math">, and whose running time is at most </span>O(s(t_{\\widehat{\\mathsf{V}}},n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,k,\\varepsilon))<span class="math">, such that for every </span>k\\in\\mathbb{N}<span class="math">, large enough </span>n\\in\\mathbb{N}<span class="math">, </span>z\\in\\{0,1\\}^{*}<span class="math"> and </span>f\\colon\\mathcal{D}_{n}\\to\\mathcal{R}_{n}<span class="math">, if </span>f\\in\\Pi_{n}$, then</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\mathrm{SD}\\Big{(}\\widetilde{\\mathsf{S}}_{[z]}^{f}(\\varepsilon,n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,k),\\mathrm{view}_{\\mathsf{P},\\widehat{\\mathsf{V}}_{[z]}}(\\varepsilon,n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,k,f)\\Big{)}\\leq\\negl(k).$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">If the <span class="math">\\negl(k)</span> can be replaced with <span class="math">0</span> in the above equation, <span class="math">(\\mathsf{P},\\mathsf{V})</span> is said to be resp., cheating-verifier perfect zero-knowledge with simulation overhead <span class="math">s</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">For $t=t(n,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{D}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{R}_{n}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,k,\\varepsilon)<span class="math">, </span>\\mathsf{SZKPP}[t,s]<span class="math"> (resp., </span>\\mathsf{PZKPP}[t,s]<span class="math">) denotes the class of properties possessing cheating-verifier statistical (resp., perfect) zero-knowledge proof of proximity with simulation overhead </span>s<span class="math"> in which the verifier’s running time is at most </span>O(t)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-42" class="text-lg font-semibold mt-6">Expected Simulation Overhead.</h4>

    <p class="text-gray-300">Definition 3.3 requires that the running time of the simulator always be bounded. Similarly to many results in the ZK literature, in some cases we can only bound the simulator’s <em>expected</em> running time.</p>

    <p class="text-gray-300">##</p>

    <h6 id="sec-43" class="text-base font-medium mt-4">Definition 3.4 (cheating-verifier ZKPP with expected simulation (ESZKPP, EPZKPP)).</h6>

    <p class="text-gray-300">Let <span class="math">(\\mathsf{P},\\mathsf{V})</span> be an interactive proof of proximity for a property <span class="math">\\Pi=(\\Pi_{n},\\mathcal{D}_{n},\\mathcal{R}_{n})_{n\\in\\mathbb{N}}</span>. The protocol <span class="math">(\\mathsf{P},\\mathsf{V})</span> is said to be <em>cheating-verifier statistical zero-knowledge with expected simulation overhead</em> <span class="math">s</span> if it satisfies the same requirement as in Definition 3.3 except that we only bound the <em>expected</em> running time of the simulator.</p>

    <p class="text-gray-300">The classes <span class="math">\\mathsf{ESZKPP}[t,s]</span> and <span class="math">\\mathsf{EPZKPP}[t,s]</span> are defined analogous to <span class="math">\\mathsf{SZKPP}[t,s]</span> and <span class="math">\\mathsf{PZKPP}[t,s]</span> from Definition 3.3.</p>

    <p class="text-gray-300">Unless explicitly saying otherwise, all zero-knowledge protocols we discuss are cheating-verifier ones.</p>

    <p class="text-gray-300">As in the honest-verifier case, a typical setting is that in which the verifier’s running time is poly-logarithmic in the input size <span class="math">N</span> and polynomial in the security parameter <span class="math">k</span> and in <span class="math">1/\\varepsilon</span>, and the simulator’s (possibly only expected and not strict) running time is polynomial in the running time of the cheating-verifier that it simulates, poly-logarithmic in <span class="math">N</span> and polynomial in <span class="math">k</span> and <span class="math">1/\\varepsilon</span>. Specifically, if we allow the cheating-verifier the same computational powers as the honest-verifier, then both the honest-verifier and every simulator run in time <span class="math">\\mathsf{poly}(\\log(N),k,1/\\varepsilon)</span>. We let <span class="math">\\mathsf{ESZKPP}\\big{[}\\mathsf{poly}(\\log(N),k,1/\\varepsilon)\\big{]}</span> be the class of properties <span class="math">\\Pi\\in\\mathsf{ESZKPP}[t,s]</span> for <span class="math">t=\\mathsf{poly}(\\log(N),k,1/\\varepsilon)</span> and <span class="math">s=\\mathsf{poly}(t_{\\widetilde{\\mathsf{V}}},\\log(N),k,1/\\varepsilon)</span>. The class <span class="math">\\mathsf{PZKPP}\\big{[}\\mathsf{poly}(\\log(N),k,1/\\varepsilon),\\mathsf{poly}\\big{]}</span> is similarly defined.</p>

    <p class="text-gray-300">We conclude this section with a few remarks on the model and the above definitions.</p>

    <h6 id="sec-44" class="text-base font-medium mt-4">Remark 3.5 (Promise Problems).</h6>

    <p class="text-gray-300">Some of the protocols that we construct do not refer to a property but rather to a <em>promise problem</em>. More specifically, rather than distinguishing between inputs that are in the property <span class="math">\\Pi</span> for those that are <span class="math">\\varepsilon</span>-far from <span class="math">\\Pi</span>, we will consider a promise problem <span class="math">(\\Pi_{\\mathsf{YES}},\\Pi_{\\mathsf{NO}})</span> and the requirement is that the verifier accepts inputs that are in <span class="math">\\Pi_{\\mathsf{YES}}</span> and rejects inputs that are both in <span class="math">\\Pi_{\\mathsf{NO}}</span> and are <span class="math">\\varepsilon</span>-far from <span class="math">\\Pi_{\\mathsf{YES}}</span>. We extend the definitions above to handle such promise problems in the natural way.</p>

    <h6 id="sec-45" class="text-base font-medium mt-4">Remark 3.6 (The Security Parameter).</h6>

    <p class="text-gray-300">One of the original motivations to include security parameter in the classical definitions of statistical zero-knowledge proofs was to control the error parameters (completeness, soundness and simulation deviation) independently from the input’s length. Specifically, one may want to provide a high-quality proof (i.e., very small errors) for short inputs (see <em>[x20, Section 2.4]</em>). In our setting, the situation is somehow reversed. We think of very large inputs that the verifier and simulators cannot even entirely read. Hence, it is infeasible to ask them for errors that are negligible in the input’s length. Instead, we control the quality of the proof with the security parameter, independent of the input’s length.</p>

    <h6 id="sec-46" class="text-base font-medium mt-4">Remark 3.7 (Computational ZKPP).</h6>

    <p class="text-gray-300">Since our focus is on the statistical case, we do not provide explicit definitions of computational zero-knowledge proofs of proximity. Indeed, these definitions can be easily interpolated from the statistical ones in a standard way (see for example Vadhan’s <em>[x20, Section 2]</em> definition of computational zero-knowledge). Specifically, in the computational definitions one simply replaces the requirement that the simulator’s output and the protocol’s view are statistically-close with one in which they are computationally indistinguishable.</p>

    <h2 id="sec-47" class="text-2xl font-bold">4 The Power of ZKPP: The Statistical Case</h2>

    <h3 id="sec-48" class="text-xl font-semibold mt-8">4.1 ZKPP for Permutations</h3>

    <p class="text-gray-300">In this section, we look at functions <span class="math">f:\\{0,1\\}^{n}\\to\\{0,1\\}^{n}</span> and consider the property of being a permutation. That is, we would like to distinguish between functions that are a permutation from</p>

    <p class="text-gray-300">those that are far from being a permutation.</p>

    <h6 id="sec-49" class="text-base font-medium mt-4">Definition 4.1 (The permutation property).</h6>

    <p class="text-gray-300">For every <span class="math">n\\in\\mathbb{N}</span> let</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\mathsf{PERMUTATION}_{n}=\\Big{\\{}f\\colon\\{0,1\\}^{n}\\to\\{0,1\\}^{n}\\ \\Big{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\ f\\text{ is a permutation}\\Big{\\}}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We define the permutation property as <span class="math">\\mathsf{PERMUTATION}=\\Big{(}\\mathsf{PERMUTATION}_{n},\\{0,1\\}^{n},\\{0,1\\}^{n}\\Big{)}_{n\\in\\mathbb{N}}</span>.</p>

    <p class="text-gray-300">It is not difficult to see that any <em>property tester</em> for <span class="math">\\mathsf{PERMUTATION}</span> must make at least <span class="math">\\Omega(\\sqrt{N})</span> queries, where <span class="math">N=2^{n}</span>. To see this, consider the following two distributions: (1) a random permutation over <span class="math">\\{0,1\\}^{n}</span>; and (2) a random function from <span class="math">\\{0,1\\}^{n}</span> to <span class="math">\\{0,1\\}^{n}</span>. The first distribution is supported exclusively on YES instances whereas it can be shown that the second is, with high probability, far from a permutation. However, if a tester makes <span class="math">q\\ll\\sqrt{N}</span> queries, then in both cases, with high probability, its view will be the same: <span class="math">q</span> distinct random elements. The property testing lower bound follows.</p>

    <p class="text-gray-300">As a matter of fact, Gur and Rothblum <em>[x12]</em> have shown that the verifier in every MAP (i.e., non-interactive proof of proximity, see <em>[x13]</em>) for <span class="math">\\mathsf{PERMUTATION}</span> must make either <span class="math">\\Omega(N^{1/4})</span> queries or use a proof of length <span class="math">\\Omega(N^{1/4})</span>.</p>

    <p class="text-gray-300">In this section, we show that the <span class="math">\\mathsf{PERMUTATION}</span> property has a 4-message (statistical) zero-knowledge proof of proximity with respect to <em>cheating</em> verifiers. We note that we only bound the <em>expected</em> number of queries and running time of the simulator of our protocol. We leave it as an open problem to obtain a protocol (possibly with more rounds of interaction) in which one can show a <em>high probability bound</em> on the query complexity and running times of the simulator.</p>

    <p class="text-gray-300">Before stating the theorem a word on notation. In Section 3 we gave the prover and the verifier, as explicit inputs, the domain and range sizes — both, in the case of the permutation property, are <span class="math">2^{n}</span>. In this section, for convenience, instead of giving <span class="math">2^{n}</span> as an explicit input, we will simply give <span class="math">n</span>. Relevant complexity measures (e.g., running time, query and communication complexity) will similarly be functions of <span class="math">n</span>.</p>

    <h6 id="sec-50" class="text-base font-medium mt-4">Theorem 4.2 (EPZKPP for Permutation).</h6>

    <p class="text-gray-300"><span class="math">\\mathsf{PERMUTATION}\\in\\mathsf{EPZKPP}\\big{[}\\mathsf{poly}(\\log(N,k,1/\\varepsilon))\\big{]}</span>. Specifically, <span class="math">\\mathsf{PERMUTATION}</span> has a cheating-verifier perfect zero-knowledge proof of proximity <span class="math">\\big{(}\\mathsf{P}_{\\text{perm}},\\mathsf{V}_{\\text{perm}}\\big{)}</span> with expected simulator <span class="math">\\mathsf{S}_{\\text{perm}}</span> with respect to proximity parameter <span class="math">\\varepsilon&gt;0</span> such that the following properties hold for every <span class="math">n\\in\\mathbb{N}</span>, every input <span class="math">f\\colon\\{0,1\\}^{n}\\to\\{0,1\\}^{n}</span> and security parameter <span class="math">k\\in\\mathbb{N}</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The interaction consists of four messages and the total communication is <span class="math">O\\big{(}n^{2}k/\\varepsilon^{2}\\big{)}</span> bits.</li>

      <li><span class="math">\\mathsf{V}_{\\text{perm}}</span>’s running time is <span class="math">\\mathsf{poly}(n,k,1/\\varepsilon)</span> and <span class="math">\\mathsf{V}_{\\text{perm}}</span>’s query complexity is <span class="math">O(nk/\\varepsilon^{2})</span>.</li>

      <li>If <span class="math">f\\in\\mathsf{PERMUTATION}_{n}</span>, then for every auxiliary input <span class="math">z</span>, <span class="math">\\mathsf{S}_{\\text{perm}_{[z]}}</span>’s expected running time and query complexity, given access to a (possibly cheating) verifier <span class="math">\\widehat{\\mathsf{V}}</span>, are <span class="math">O\\big{(}t_{\\widehat{\\mathsf{V}}}(\\varepsilon,n,k,z)\\big{)}+\\mathsf{poly}(n,k,1/\\varepsilon)</span> and <span class="math">O\\big{(}q_{\\widehat{\\mathsf{V}}}(\\varepsilon,n,k,z)+nk/\\varepsilon^{2}\\big{)}</span> respectively, where <span class="math">t_{\\widehat{\\mathsf{V}}}(\\varepsilon,n,k,z)</span> and <span class="math">q_{\\widehat{\\mathsf{V}}}(\\varepsilon,n,k,z)</span> are the running time and query complexity of <span class="math">\\widehat{\\mathsf{V}}_{[z]}^{f}(\\varepsilon,n,k)</span>.</li>

    </ol>

    <p class="text-gray-300">(Note that the input of <span class="math">\\mathsf{PERMUTATION}_{n}</span> has size <span class="math">n\\cdot 2^{n}</span>, so a polynomial dependence on <span class="math">n</span> translates into a poly-logarithmic dependence on the input-size.)</p>

    <p class="text-gray-300">Combined with the aforementioned MAP lower bound for <span class="math">\\mathsf{PERMUTATION}</span>, we obtain that the complexity of ZKPP (with expected simulation bounds) can be sub-exponentially smaller than those of MAPs (and therefore also of property testers).</p>

    <p class="text-gray-300">Remark 4.3.</p>

    <p class="text-gray-300">We mention that in Item 3 in the theorem statement, when the simulator simulates the view of an interaction with the honest verifier <span class="math">\\mathsf{V}_{\\text{perm}}</span>, its strict (rather than expected) query complexity is exactly equal to the query complexity of the verifier.</p>

    <p class="text-gray-300">The rest of this section is dedicated to proving Theorem 4.2.</p>

    <h4 id="sec-51" class="text-lg font-semibold mt-6">4.1.1 Proof of Theorem 4.2</h4>

    <p class="text-gray-300">Consider the following simple IPP for PERMUTATION (based on the <em>[x10]</em> protocol). Given oracle access to a function <span class="math">f:\\{0,1\\}^{n}\\to\\{0,1\\}^{n}</span>, the verifier chooses a random <span class="math">r\\in\\{0,1\\}^{n}</span> and sends <span class="math">r</span> to the prover. The prover computes <span class="math">z=f^{-1}(r)</span> and sends it to the verifier. The verifier checks that indeed <span class="math">f(z)=r</span> and if so accepts.</p>

    <p class="text-gray-300">Clearly if <span class="math">f</span> is a permutation then the verifier in this protocol accepts with probability <span class="math">1</span>, whereas if <span class="math">f</span> is far from a permutation, then with some non-negligible probability the verifier chooses <span class="math">r</span> which does not have a pre-image under <span class="math">f</span>. In such a case the prover cannot make the verifier accept and so the protocol is sound.</p>

    <p class="text-gray-300">It is also not hard to see that this protocol is honest-verifier zero-knowledge. However, it is not cheating-verifier zero-knowledge: a cheating verifier could learn the inverse of some arbitrary <span class="math">r</span> of its choice.</p>

    <p class="text-gray-300">In order to make the protocol zero-knowledge, intuitively, we would like to have a way for the prover and verifier to jointly sample the element <span class="math">r</span> such that both are assured that it is uniform. For simplicity let us focus on the task of just sampling a single bit <span class="math">\\sigma</span>. The specific properties that we need are</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>If <span class="math">f</span> is a permutation then the prover is assured that the <span class="math">\\sigma</span> is random.</li>

      <li>If <span class="math">f</span> is far from being a permutation then the verifier is assured that <span class="math">\\sigma</span> is random.</li>

    </ol>

    <p class="text-gray-300">In fact, the transformation of general honest-verifier statistical zero-knowledge proofs to cheating-verifier ones (see <em>[x23, Chapter 6]</em>) implements a sub-routine achieving a generalization of the above task, assuming full access to the input. We give a simple solution for our specific case. That is, using only oracle access to a function that is either a permutation or far from any permutation.</p>

    <p class="text-gray-300">We proceed to describe a simple procedure for sampling such a random bit <span class="math">\\sigma</span>. First, the verifier chooses at random <span class="math">x\\in\\{0,1\\}^{n}</span> and a pairwise independent hash function <span class="math">h:\\{0,1\\}^{n}\\to\\{0,1\\}</span> and sends <span class="math">y=f(x)</span> and <span class="math">h</span> to the prover. The prover now chooses a random bit <span class="math">r\\in\\{0,1\\}</span> and sends <span class="math">r</span> to the verifier. The verifier now sends <span class="math">x</span> to the prover who checks that indeed <span class="math">f(x)=y</span>. The random bit that they agree on is <span class="math">\\sigma=r\\oplus h(x)</span>.</p>

    <p class="text-gray-300">From the prover’s perspective, if <span class="math">f</span> is a permutation then <span class="math">y</span> fully determines <span class="math">x</span> and so <span class="math">r</span> (which is chosen uniformly at random after <span class="math">y</span> is specified) is independent of <span class="math">h(x)</span>. Hence, <span class="math">\\sigma=r\\oplus h(x)</span> is uniformly random bit. On the other hand, from the verifier’s perspective, if <span class="math">f</span> is far from being a permutation, then, intuitively, even conditioned on the value <span class="math">y</span> there still remains some entropy in <span class="math">x</span> (indeed, <span class="math">x</span> is essentially uniform among all the pre-images of <span class="math">y</span>). Now, using a variant of the leftover hash lemma, we can argue that <span class="math">h(x)</span> is close to random. Actually, since the leftover</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Figure 1: The Permutation Protocol</p>

    <p class="text-gray-300">hash lemma implies that pairwise independent hash functions are strong extractors, we have that  <span class="math">h(x)</span>  is close to random even conditioned on  <span class="math">h</span>  and therefore also conditioned on  <span class="math">r</span>  (which is a randomized function of  <span class="math">h</span> ). Thus, we obtain that  <span class="math">\\sigma = r \\oplus h(x)</span>  is close to uniformly random bit and so our procedure satisfies the desired properties.</p>

    <p class="text-gray-300">We proceed to the description of our actual protocol, which is based on the foregoing ideas. The protocol  <span class="math">\\left(\\mathsf{P}_{\\mathrm{perm}},\\mathsf{V}_{\\mathrm{perm}}\\right)</span>  is given in Fig. 1.</p>

    <p class="text-gray-300">It is easy to verify that  <span class="math">\\left(\\mathsf{P}_{\\mathrm{perm}},\\mathsf{V}_{\\mathrm{perm}}\\right)</span>  has the desired round complexity, query complexity and verifier's running time, where we use the fact that  <span class="math">O(n^{2}k / \\varepsilon)</span>  bits suffice for describing the pairwise independent hash function in the protocol (see Fact 2.5).</p>

    <p class="text-gray-300">To see that completeness holds observe that if  <span class="math">f: \\{0,1\\}^n \\to \\{0,1\\}^n</span>  is a permutation, and the two parties follow the protocol, then indeed  <span class="math">f(x_i) = y_i</span>  and  <span class="math">f(z_i) = f(f^{-1}(r_i \\oplus h(\\overline{\\mathbf{x}})_i)) = r_i \\oplus h(\\overline{\\mathbf{x}})_i</span>  for every  <span class="math">i \\in [t \\cdot s]</span> , and therefore the parties complete the interaction and the verifier accepts.</p>

    <p class="text-gray-300">It remains to show that the soundness and zero-knowledge conditions hold. Soundness follows from the following lemma, which is proved in Section 4.1.2.</p>

    <p class="text-gray-300">Lemma 4.4. Let  <span class="math">n, k \\in \\mathbb{N}</span> , let  <span class="math">\\varepsilon &amp;gt; 0</span>  and suppose that  <span class="math">f \\colon \\{0,1\\}^n \\to \\{0,1\\}^n</span>  is  <span class="math">\\varepsilon</span> -far from PERMUTATION <span class="math">_n</span> . Then, for every prover strategy  <span class="math">\\widetilde{\\mathsf{P}}</span> , when  <span class="math">\\mathsf{V}_{\\mathrm{perm}}^f(\\varepsilon, n, k)</span>  interacts with  <span class="math">\\widetilde{\\mathsf{P}}</span>  it rejects with probability  <span class="math">1 - \\mathrm{negl}(k)</span> .</p>

    <p class="text-gray-300">Finally, to show that this protocol is perfect zero-knowledge, consider the simulator  <span class="math">\\mathsf{S}_{\\mathrm{perm}}</span>  given in Fig. 2. The following lemma, which we prove in Section 4.1.3, shows that this simulator perfectly samples from the view of any (possible cheating) verifier.</p>

    <p class="text-gray-300">Simulator's Input:  <span class="math">\\varepsilon, n, k</span> , auxiliary input  <span class="math">z</span> , oracle access to  <span class="math">f \\colon \\{0,1\\}^n \\to \\{0,1\\}^n</span>  and access to (possibly cheating) verifier  <span class="math">\\widehat{\\mathbf{V}}</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run  <span class="math">\\widehat{\\mathbf{V}}_{[z]}^{f}(\\varepsilon, n, k)</span>  using random coins  <span class="math">\\rho</span>  to get  <span class="math">\\overline{\\mathbf{y}} = (y_1, y_2, \\ldots, y_{ts})</span>  and  <span class="math">h</span> .</li>

      <li>Sample  <span class="math">\\overline{\\mathbf{r}} = (r_1, r_2, \\ldots, r_s) \\gets (\\{0, 1\\}^n)^s</span>  and give them to  <span class="math">\\widehat{\\mathbf{V}}_{[z]}</span>  as the answers from  <span class="math">\\mathsf{P}_{\\mathrm{perm}}</span> .</li>

      <li>Continue to run  <span class="math">\\widehat{\\mathbf{V}}_{[z]}^{f}(\\varepsilon, n, k)</span>  to get  <span class="math">\\overline{\\mathbf{x}} = (x_1, x_2, \\ldots, x_{ts})</span> , the values  <span class="math">\\widehat{\\mathbf{V}}_{[z]}^{f}(\\varepsilon, n, k)</span>  sends to  <span class="math">\\mathsf{P}_{\\mathrm{perm}}</span>  in the third message of the protocol.</li>

      <li>If there exists  <span class="math">i \\in [t \\cdot s]</span>  such that  <span class="math">f(x_{i}) \\neq y_{i}</span> , output  <span class="math">(\\overline{\\mathbf{y}}, h, \\overline{\\mathbf{r}}, \\overline{\\mathbf{x}}, \\bot, \\rho)</span> .</li>

      <li>Otherwise, repeat the following:</li>

    </ol>

    <p class="text-gray-300">(a) Sample  <span class="math">\\overline{\\mathbf{r}&#x27;} = (r_1&#x27;, r_2&#x27;, \\ldots, r_s&#x27;) \\gets (\\{0, 1\\}^n)^s</span>  and for every  <span class="math">i \\in [s]</span> , set  <span class="math">r_i&#x27;&#x27; = f(r_i&#x27;) \\oplus h(\\overline{\\mathbf{x}})_i</span> . (b) Rewind  <span class="math">\\widehat{\\mathbf{V}}_{[z]}^{f}(\\varepsilon, n, k)</span>  to the point it is waiting for the second message of the protocol using  <span class="math">\\rho</span>  again as the random coins (i.e., step 3 of the protocol). Give  <span class="math">\\overline{\\mathbf{r}&#x27;&#x27;} = (r_1&#x27;&#x27;, r_2&#x27;&#x27;, \\ldots, r_{ts}&#x27;)</span>  as the answers from  <span class="math">\\mathsf{P}_{\\mathrm{perm}}</span> . (c) Continue to run  <span class="math">\\widehat{\\mathbf{V}}_{[z]}^{f}(\\varepsilon, n, k)</span>  to get  <span class="math">\\overline{\\mathbf{x}&#x27;} = (x_1&#x27;, x_2&#x27;, \\ldots, x_{ts}&#x27;)</span> , the values  <span class="math">\\widehat{\\mathbf{V}}_{[z]}^{f}(\\varepsilon, n, k)</span>  sends to  <span class="math">\\mathsf{P}_{\\mathrm{perm}}</span>  in the third message of the protocol. (d) If  <span class="math">f(x_{i}) = y_{i}</span>  for every  <span class="math">i \\in [ts]</span> , output  <span class="math">(\\overline{\\mathbf{y}}, h, \\overline{\\mathbf{r}^{\\prime\\prime}}, \\overline{\\mathbf{x}^{\\prime}}, \\overline{\\mathbf{r}^{\\prime}}, \\rho)</span>  and halt. Otherwise, go back to 5a.</p>

    <p class="text-gray-300">Figure 2: The Simulator for The Permutation Protocol</p>

    <p class="text-gray-300">Lemma 4.5. Let  <span class="math">n, k \\in \\mathbb{N}</span> , let  <span class="math">z \\in \\{0,1\\}^*</span> , let  <span class="math">f \\in \\mathrm{PERMUTATION}_n</span> , let  <span class="math">\\widehat{\\mathbf{V}}</span>  be some verifier strategy and let  <span class="math">\\mathsf{S}_{[z]}^f(\\varepsilon, n, k, \\widehat{\\mathbf{V}})</span>  be the output of  <span class="math">\\mathsf{S}_{\\mathrm{perm}}</span>  when running on input  <span class="math">\\varepsilon, n, k</span> , auxiliary input  <span class="math">z</span> , with oracle access to  <span class="math">f</span>  and access to  <span class="math">\\widehat{\\mathbf{V}}</span> . Then:</p>

    <div class="my-4 text-center"><span class="math-block">\\mathrm {S D} \\left(\\mathsf {S} _ {[ z ]} ^ {f} (\\varepsilon , n, k, \\widehat {\\mathbf {V}}), \\operatorname {v i e w} _ {\\mathsf {P} _ {\\text {p e r m}}, \\widehat {\\mathbf {V}} _ {[ z ]}} (\\varepsilon , n, k, f)\\right) = 0.</span></div>

    <p class="text-gray-300">Moreover, the expected running time and query complexity of  <span class="math">\\mathsf{S}_{[z]}^f (\\varepsilon ,n,k,\\widehat{\\mathbf{V}})</span>  are as in Item 3 of the theorem statement.</p>

    <p class="text-gray-300">This concludes the proof of Theorem 4.2 (modulo the proofs of Lemma 4.4 and Lemma 4.5 which are proved next).</p>

    <p class="text-gray-300">Before proving Lemma 4.4 we show two basic, but useful, properties of functions that are  <span class="math">\\varepsilon</span> -far from permutations. The first property is that the image size of such functions cannot be too large.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Fact 4.6. If  <span class="math">f</span>  is  <span class="math">\\varepsilon</span> -far from PERMUTATION <span class="math">_n</span> , then  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\operatorname{Im}(f)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq (1 - \\varepsilon) \\cdot 2^n$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Proof. We prove the contrapositive. Let  <span class="math">f: \\{0,1\\}^n \\to \\{0,1\\}^n</span>  and suppose that  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\operatorname{Im}(f)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">&gt; (1 - \\varepsilon) \\cdot 2^n<span class="math"> . We show that  </span>f<span class="math">  is  </span>\\varepsilon<span class="math"> -close to a permutation  </span>f': \\{0,1\\}^n \\to \\{0,1\\}^n$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Start by setting <span class="math">f&#x27;(x) = f(x)</span> for every <span class="math">x</span>. Repeat the following process until <span class="math">\\operatorname{Im}(f&#x27;) = \\{0,1\\}^n</span>: take <span class="math">y \\notin \\operatorname{Im}(f)</span>; find <span class="math">x \\neq x&#x27;</span> such that <span class="math">f&#x27;(x) = f&#x27;(x&#x27;)</span> (such <span class="math">x, x&#x27;</span> must exist since at this point <span class="math">f&#x27;</span> is not a permutation); set <span class="math">f&#x27;(x) = y</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In every iteration $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\operatorname{Im}(f)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> increases by one. The above process started with </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\operatorname{Im}(f')</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">&gt; (1 - \\varepsilon)\\cdot 2^n<span class="math">, and thus takes less than </span>\\varepsilon \\cdot 2^n<span class="math"> iterations. It follows that </span>f'<span class="math"> and </span>f<span class="math"> disagree on at most </span>\\varepsilon \\cdot 2^n<span class="math"> inputs, or in other words </span>f'<span class="math"> is </span>\\varepsilon<span class="math">-close to </span>f<span class="math">. Moreover, </span>f'<span class="math"> is a permutation, since </span>\\operatorname{Im}(f') = \\{0,1\\}^n$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Next we show that even after seeing a random element in the image of a function that is <span class="math">\\varepsilon</span>-far from permutation, its preimage still has some entropy. The specific notion of entropy we use is average min-entropy.[14]</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><strong>Claim 4.7.</strong> Suppose that <span class="math">f\\colon \\{0,1\\}^n \\to \\{0,1\\}^n</span> is <span class="math">\\varepsilon</span>-far from PERMUTATION<span class="math">_n</span>. Let <span class="math">X</span> be a random variable uniformly distributed over <span class="math">\\{0,1\\}^n</span>, and let <span class="math">Y = f(X)</span>. Then, $\\tilde{\\mathrm{H}}_{\\infty}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y) \\geq \\log(1/(1 - \\varepsilon))$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><strong>Proof.</strong> For <span class="math">y \\in \\{0,1\\}^n</span>, let <span class="math">f^{-1}(y) = \\{x \\in \\{0,1\\}^n \\colon f(x) = y\\}</span>. Fix <span class="math">y \\in \\operatorname{Im}(f)</span>. For <span class="math">x \\in f^{-1}(y)</span>, it holds that $\\operatorname{Pr}[X = x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y = y] = 1 /</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">f^{-1}(y)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, while for </span>x \\notin f^{-1}(y)<span class="math">, it holds that </span>\\operatorname{Pr}[X = x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y = y] = 0<span class="math">. Thus, </span>\\max_x \\operatorname{Pr}[X = x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y = y] = 1 /</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">f^{-1}(y)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. Moreover, it holds that </span>\\operatorname{Pr}[Y = y] =</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">f^{-1}(y)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">/ 2^n<span class="math">. Finally, for every </span>y \\notin \\operatorname{Im}(f)<span class="math">, it holds that </span>\\operatorname{Pr}[Y = y] = 0$. Hence,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">$$ \\begin{array}{l}</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\tilde{\\mathrm{H}}_{\\infty}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y) = - \\log \\left(\\mathrm{E}_{y \\leftarrow Y} \\left[ \\max_{x} \\Pr [ X = x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y = y ] \\right]\\right) \\\\</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">= \\log \\left(\\frac {2^{n}}{</td>

            <td class="px-3 py-2 border-b border-gray-700">\\operatorname{Im} (f)</td>

            <td class="px-3 py-2 border-b border-gray-700">}\\right) \\\\</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">\\geq \\log \\left(\\frac {1}{1 - \\varepsilon}\\right), \\end{array} $$</p>

    <p class="text-gray-300">where the inequality follows from Fact 4.6.</p>

    <p class="text-gray-300">We are now ready to prove Lemma 4.4.</p>

    <p class="text-gray-300"><strong>Proof of Lemma 4.4.</strong> Let <span class="math">\\widehat{\\mathbf{P}}</span> be a (cheating) prover strategy. We assume without loss of generality that <span class="math">\\widehat{\\mathbf{P}}</span> is deterministic (by fixing the best choice of random coin tosses).</p>

    <p class="text-gray-300">Let <span class="math">\\overline{\\mathbf{X}}</span>, <span class="math">H</span>, <span class="math">\\overline{\\mathbf{Y}}</span>, <span class="math">\\overline{\\mathbf{R}}</span> and <span class="math">\\overline{\\mathbf{Z}}</span> be the (jointly distributed) random variables induced by the values of <span class="math">\\overline{\\mathbf{x}}</span>, <span class="math">h</span>, <span class="math">\\overline{\\mathbf{y}}</span>, <span class="math">\\overline{\\mathbf{r}}</span> and <span class="math">\\overline{\\mathbf{z}}</span> respectively, in a random execution of <span class="math">(\\widehat{\\mathbf{P}}, \\mathsf{V}_{\\mathrm{perm}})</span> and let <span class="math">\\mathrm{out}(\\widehat{\\mathbf{P}}, \\mathsf{V}_{\\mathrm{perm}})</span> be the random variable induced by <span class="math">\\mathsf{V}_{\\mathrm{perm}}</span>'s output in the same random execution (i.e., <span class="math">\\mathrm{out}(\\widehat{\\mathbf{P}}, \\mathsf{V}_{\\mathrm{perm}}) \\in \\{accept, reject\\}</span>).</p>

    <p class="text-gray-300">By the definition of the permutation protocol, it holds that</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\Pr \\left[ \\operatorname{out} (\\widehat {\\mathbf {P}}, \\mathsf {V} _ {\\text {perm}}) = \\text{accept} \\right] \\leq \\Pr \\left[ \\forall i \\in [s ]: f \\left(X _ {i} ^ {\\prime}\\right) = R _ {i} \\oplus H (\\overline {{\\mathbf {X}}}) _ {i} \\right] \\tag {1} \\\\ \\leq \\Pr \\left[ \\forall i \\in [s ]: R _ {i} \\oplus H (\\overline {{\\mathbf {X}}}) _ {i} \\in \\operatorname {Im} (f) \\right]. \\end{array}</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">[14]Recall that average min-entropy of <span class="math">X</span> given <span class="math">Y</span> is defined as $\\tilde{\\mathrm{H}}_{\\infty}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y) := -\\log (\\mathrm{E}_{y\\leftarrow Y}[\\max_x\\Pr [X = x\\mid Y = y]])$ (see Definition 2.2).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Note that <span class="math">\\overline{\\mathbf{R}} = (R_1, \\ldots, R_s)</span> is a function of <span class="math">\\overline{\\mathbf{Y}}</span> and <span class="math">H</span>, determined by <span class="math">\\widehat{\\mathbf{P}}</span>. It follows that</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} \\operatorname{Pr}\\left[ \\forall i \\in [s]: R_i(\\overline{\\mathbf{Y}}, H) \\oplus H(\\overline{\\mathbf{X}})_i \\in \\operatorname{Im}(f) \\right] &amp;amp;\\leq \\operatorname{Pr}\\left[ \\forall i \\in [s]: R_i(\\overline{\\mathbf{Y}}, H) \\oplus U_i \\in \\operatorname{Im}(f) \\right] \\\\ &amp;amp;\\quad + \\operatorname{SD}\\left( (H(\\overline{\\mathbf{X}}), H, \\overline{\\mathbf{Y}}), (\\overline{\\mathbf{U}}, H, \\overline{\\mathbf{Y}}) \\right), \\end{aligned} \\tag{2}</span></div>

    <p class="text-gray-300">where <span class="math">\\overline{\\mathbf{U}} = (U_1, U_2, \\ldots, U_s)</span> is uniform over <span class="math">(\\{0, 1\\}^n)^s</span>. We bound both terms in the right-hand side of Equation (2). For the first term, note that <span class="math">U_i</span> is independent of <span class="math">U_j</span> for <span class="math">i \\neq j</span>, and thus</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} \\operatorname{Pr}\\left[ \\forall i \\in [s]: R_i(\\overline{\\mathbf{Y}}, H) \\oplus U_i \\in \\operatorname{Im}(f) \\right] &amp;amp;= \\prod_{i=1}^{s} \\operatorname{Pr}\\left[ R_i(\\overline{\\mathbf{Y}}, H) \\oplus U_i \\in \\operatorname{Im}(f) \\right] \\\\ &amp;amp;= \\prod_{i=1}^{s} \\operatorname{Pr}[U_i \\in \\operatorname{Im}(f)] \\\\ &amp;amp;\\leq (1 - \\varepsilon)^s, \\end{aligned} \\tag{3}</span></div>

    <p class="text-gray-300">where the second equality follows from the fact that for every <span class="math">r \\in \\{0, 1\\}^n</span>, <span class="math">r \\oplus U_i</span> is uniform over <span class="math">\\{0, 1\\}^n</span> and the last inequality follows from Fact 4.6.</p>

    <p class="text-gray-300">As for the second term of Equation (2), by Fact 2.3 it holds that</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\hat{\\mathrm{H}}_{\\infty}(\\overline{\\mathbf{X}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\overline{\\mathbf{Y}}) = t \\cdot s \\cdot \\hat{\\mathrm{H}}_{\\infty}(X_1</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y_1) \\geq t \\cdot s \\cdot \\log\\left(1/(1 - \\varepsilon)\\right),</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">\\tag{4} $$</p>

    <p class="text-gray-300">where the inequality follows from Claim 4.7. Applying the generalized leftover hash lemma (Lemma 2.6) we now obtain that:</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{SD}\\left( (H(\\overline{\\mathbf{X}}), H, \\overline{\\mathbf{Y}}), (U, H, \\overline{\\mathbf{Y}}) \\right) \\leq \\frac{1}{2} \\cdot \\sqrt{2^{ts \\log(1 - \\varepsilon)} \\cdot 2^{ns}} = \\frac{1}{2} \\cdot \\left(2^n \\cdot (1 - \\varepsilon)^t\\right)^{s/2}. \\tag{5}</span></div>

    <p class="text-gray-300">Plugging Equations (2), (3) and (5) into Equation (1), we have</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} \\operatorname{Pr}\\left[ \\operatorname{out}(\\widehat{\\mathbf{P}}, \\mathsf{V}_{\\text{perm}}) = \\text{accept} \\right] &amp;amp;\\leq (1 - \\varepsilon)^s + \\frac{1}{2} \\cdot \\left(2^n \\cdot (1 - \\varepsilon)^t\\right)^{s/2} \\\\ &amp;amp;\\leq (1 - \\varepsilon)^{k/\\varepsilon} + \\frac{1}{2} \\cdot \\left(2^n \\cdot (1 - \\varepsilon)^{(n+1)/\\varepsilon}\\right)^{k/(2\\varepsilon)} \\\\ &amp;amp;\\leq 2^{-k} + \\frac{1}{2} \\cdot \\left(2^n \\cdot 2^{-(n+1)}\\right)^{k/(2\\varepsilon)} \\\\ &amp;amp;= 2^{-k} + 2^{-k/(2\\varepsilon)-1}, \\end{aligned} \\tag{6}</span></div>

    <p class="text-gray-300">where the second inequality follows from our setting of <span class="math">t = \\lceil (n+1)/\\varepsilon \\rceil</span> and <span class="math">s = \\lceil k/\\varepsilon \\rceil</span> and the third inequality follows from the fact that <span class="math">1 - x \\leq 2^{-x}</span> for any <span class="math">x \\geq 0</span>. Thus, the verifier accepts with probability that is exponentially vanishing in <span class="math">k</span>, and in particular negligible.</p>

    <p class="text-gray-300">□</p>

    <h2 id="sec-54" class="text-2xl font-bold">4.1.3 Analyzing Zero-Knowledge — Proof of Lemma 4.5</h2>

    <p class="text-gray-300">Let <span class="math">\\widehat{\\mathbf{V}}</span> be a cheating verifier strategy and fix an input <span class="math">f \\in \\mathrm{PERMUTATION}</span>. For simplicity, and without loss of generality, we assume that <span class="math">\\widehat{\\mathbf{V}}</span> is deterministic.¹⁵</p>

    <p class="text-gray-300">¹⁵Recall that if the cheating verifier is randomized, we can fix its random coins as part of the auxiliary input to both parties.</p>

    <p class="text-gray-300">Throughout this proof we fix an auxiliary input <span class="math">z</span> to <span class="math">\\mathsf{S}_{\\text{perm}}</span> and remove it from the notation of both the simulator and the (possibly cheating) verifier (since all <span class="math">\\mathsf{S}_{\\text{perm}}</span> does with its auxiliary input is to provide it to <span class="math">\\widehat{\\mathsf{V}}</span>, both algorithms get the same auxiliary inputs).</p>

    <p class="text-gray-300">Recall that we let <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span> denote the algorithm defined by running <span class="math">\\mathsf{S}_{\\text{perm}}</span> on input <span class="math">\\varepsilon,n,k</span>, with oracle access to <span class="math">f</span> and access to <span class="math">\\widehat{\\mathsf{V}}</span>. Note that <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span> halts <em>almost surely</em>, namely the probability that it never halts is zero.</p>

    <p class="text-gray-300">The following claim shows show that the output distribution of <span class="math">\\mathsf{S}_{\\text{perm}}</span> is identical to the view of <span class="math">\\widehat{\\mathsf{V}}</span>. Later, in Claim 4.9, we will bound the (expected) running time and query complexity of <span class="math">\\mathsf{S}_{\\text{perm}}</span>.</p>

    <h6 id="sec-55" class="text-base font-medium mt-4">Claim 4.8.</h6>

    <p class="text-gray-300">The output distribution of <span class="math">\\mathsf{S}_{\\text{perm}}</span> is identical to the view of <span class="math">\\widehat{\\mathsf{V}}</span>.</p>

    <h6 id="sec-56" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Let <span class="math">\\overline{\\mathbf{X}}</span>, <span class="math">H</span>, <span class="math">\\overline{\\mathbf{Y}}</span>, <span class="math">\\overline{\\mathbf{R}}</span> and <span class="math">\\overline{\\mathbf{Z}}</span> be the (jointly distributed) random variables induced by the values of <span class="math">\\overline{\\mathbf{x}}</span>, <span class="math">h</span>, <span class="math">\\overline{\\mathbf{y}}</span>, <span class="math">\\overline{\\mathbf{r}}</span> and <span class="math">\\overline{\\mathbf{z}}</span> respectively, in a random execution of <span class="math">(\\mathsf{P}_{\\text{perm}},\\widehat{\\mathsf{V}})</span>.</p>

    <p class="text-gray-300">First observe that since <span class="math">\\widehat{\\mathsf{V}}</span> is deterministic, its first message <span class="math">(\\overline{\\mathbf{y}},h)</span> is fixed and so <span class="math">\\overline{\\mathbf{Y}}=\\overline{\\mathbf{y}}</span> and <span class="math">H=h</span>. Also, since the verifier is deterministic, there exists a function <span class="math">v</span> such that <span class="math">\\overline{\\mathbf{X}}=v(\\overline{\\mathbf{R}})</span>. Lastly, observe that there also exists a function <span class="math">u</span> such that <span class="math">\\overline{\\mathbf{Z}}=u(\\overline{\\mathbf{R}})</span>.</p>

    <p class="text-gray-300">The view of the verifier is therefore:</p>

    <p class="text-gray-300"><span class="math">\\operatorname{view}_{\\mathsf{P},\\widehat{\\mathsf{V}}}(\\varepsilon,n,k,f)=\\big{(}\\overline{\\mathbf{Y}},H,\\overline{\\mathbf{R}},\\overline{\\mathbf{X}},\\overline{\\mathbf{Z}}\\big{)}=\\big{(}\\overline{\\mathbf{y}},h,\\overline{\\mathbf{R}},v(\\overline{\\mathbf{R}}),u(\\overline{\\mathbf{R}})\\big{)}</span> (7)</p>

    <p class="text-gray-300">Similarly, let <span class="math">\\overline{\\mathbf{X}_{\\mathsf{S}}}</span>, <span class="math">H_{\\mathsf{S}}</span>, <span class="math">\\overline{\\mathbf{Y}_{\\mathsf{S}}}</span>, <span class="math">\\overline{\\mathbf{R}_{\\mathsf{S}}}</span>, <span class="math">\\overline{\\mathbf{Z}_{\\mathsf{S}}}</span> be the (jointly distributed) random variables induced by the output of a random execution of <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span>. We need to show that:</p>

    <p class="text-gray-300"><span class="math">(\\overline{\\mathbf{Y}},H,\\overline{\\mathbf{R}},\\overline{\\mathbf{X}},\\overline{\\mathbf{Z}})\\equiv(\\overline{\\mathbf{Y}_{\\mathsf{S}}},H_{\\mathsf{S}},\\overline{\\mathbf{R}_{\\mathsf{S}}},\\overline{\\mathbf{X}_{\\mathsf{S}}},\\overline{\\mathbf{Z}_{\\mathsf{S}}}).</span> (8)</p>

    <p class="text-gray-300">First observe that by construction <span class="math">\\overline{\\mathbf{Y}_{\\mathsf{S}}}=\\overline{\\mathbf{y}}</span> and <span class="math">H_{\\mathsf{S}}=h</span>. Also observe that no matter what value <span class="math">\\overline{\\mathbf{R}_{\\mathsf{S}}}</span> obtains, in all steps in which the simulator might generate an output, it holds that <span class="math">\\overline{\\mathbf{X}_{\\mathsf{S}}}=v(R_{\\mathsf{S}})</span>, where the function <span class="math">v</span> is as defined above. Similarly it holds that <span class="math">\\overline{\\mathbf{Z}_{\\mathsf{S}}}=u(R_{\\mathsf{S}})</span>, where <span class="math">u</span> was defined above.</p>

    <p class="text-gray-300">Thus, Equation (8) reduces to showing that <span class="math">\\overline{\\mathbf{R}}</span> and <span class="math">\\overline{\\mathbf{R}_{\\mathsf{S}}}</span> are identically distributed. Since <span class="math">\\overline{\\mathbf{R}}</span> is uniform all we need to show is that <span class="math">\\overline{\\mathbf{R}_{\\mathsf{S}}}</span> is also uniformly distributed.</p>

    <p class="text-gray-300">Let</p>

    <p class="text-gray-300"><span class="math">\\mathcal{A}=\\Big{\\{}\\overline{\\mathbf{r}}\\in(\\{0,1\\}^{n})^{s}:\\ \\exists i\\in[t\\cdot s]\\text{ s.t. }y_{i}\\neq f(x_{i})\\text{ where }\\overline{\\mathbf{x}}=v(\\overline{\\mathbf{r}})\\Big{\\}},</span> (9)</p>

    <p class="text-gray-300">where <span class="math">\\overline{\\mathbf{y}}=(y_{1},\\ldots,y_{ts})</span> (and recall that <span class="math">\\overline{\\mathbf{y}}</span> was fixed). Namely, <span class="math">\\mathcal{A}</span> contains those elements in <span class="math">(\\{0,1\\}^{n})^{s}</span>, that had they been sent by <span class="math">\\mathsf{P}_{\\text{perm}}</span> as its second message, the verifier <span class="math">\\widehat{\\mathsf{V}}</span> would have sent <span class="math">\\overline{\\mathbf{x}}</span> that are not the preimages of <span class="math">\\overline{\\mathbf{y}}</span>. Finally, let <span class="math">p=\\Pr_{r\\leftarrow(\\{0,1\\}^{n})^{s}}[r\\notin\\mathcal{A}]</span> and fix <span class="math">r^{<em>}\\in(\\{0,1\\}^{n})^{s}</span>. We show that <span class="math">\\Pr[R_{\\mathsf{S}}=r^{</em>}]=1/(2^{n})^{s}</span>. The proof now splits according to <span class="math">r^{*}</span>.</p>

    <p class="text-gray-300"><span class="math">r^{<em>}\\in\\mathcal{A}</span>: The only way <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span> would output <span class="math">r^{</em>}</span> is by choosing it in Step 2. Since <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span> chooses the values in this step uniformly at random from <span class="math">(\\{0,1\\}^{n})^{s}</span>, it follows that <span class="math">\\Pr[R_{\\mathsf{S}}=r^{*}]=1/(2^{n})^{s}</span>.</p>

    <p class="text-gray-300"><span class="math">r^{<em>}\\notin\\mathcal{A}</span>: The only way <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span> would output <span class="math">r^{</em>}</span> is by choosing <span class="math">r^{\\prime\\prime}=r^{*}</span> in Step 5a. The probability that <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span> reaches Step 5 at all is <span class="math">p</span>. Having reached Step 5, and since <span class="math">f</span> is a permutation, every time that <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span> runs Step 5a, it samples <span class="math">r^{\\prime\\prime}</span> uniformly at random from <span class="math">(\\{0,1\\}^{n})^{s}</span>, independent of all previous messages it received from <span class="math">\\widehat{\\mathsf{V}}</span>. In Step 5 <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span> is performing rejection sampling until it gets <span class="math">r^{\\prime\\prime}\\notin\\mathcal{A}</span> and then sets <span class="math">\\overline{\\mathbf{R}}_{\\mathsf{S}}=r^{\\prime\\prime}</span>. All in all, it holds that</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\overline{\\mathbf{R}}_{\\mathsf{S}}=r^{<em>}]</span> <span class="math">=p\\cdot\\Pr_{r^{\\prime\\prime}\\leftarrow(\\{0,1\\}^{n})^{s}}\\bigl{[}r^{\\prime\\prime}=r^{</em>}\\mid r^{\\prime\\prime}\\notin\\mathcal{A}\\bigr{]}</span> <span class="math">=\\Pr_{r\\leftarrow(\\{0,1\\}^{n})^{s}}[r\\notin\\mathcal{A}]\\cdot\\frac{\\Pr_{r^{\\prime\\prime}\\leftarrow(\\{0,1\\}^{n})^{s}}[r^{\\prime\\prime}=r^{<em>}]}{\\Pr_{r^{\\prime\\prime}\\leftarrow(\\{0,1\\}^{n})^{s}}[r^{\\prime\\prime}\\notin\\mathcal{A}]}</span> <span class="math">=\\Pr_{r\\leftarrow(\\{0,1\\}^{n})^{s}}[r=r^{</em>}]=\\frac{1}{(2^{n})^{s}}.</span></p>

    <p class="text-gray-300">(Note that we can condition on the event <span class="math">r^{\\prime\\prime}\\not\\in\\mathcal{A}</span> since <span class="math">r^{*}\\not\\in\\mathcal{A}</span> and so <span class="math">\\Pr[r^{\\prime\\prime}\\not\\in\\mathcal{A}]&gt;0</span>.)</p>

    <p class="text-gray-300">Hence, <span class="math">\\overline{\\mathbf{R}}_{\\mathsf{S}}</span> is uniform over <span class="math">(\\{0,1\\}^{n})^{s}</span>. This completes the proof of Claim 4.8. ∎</p>

    <h6 id="sec-57" class="text-base font-medium mt-4">Claim 4.9.</h6>

    <p class="text-gray-300">If the cheating verifier <span class="math">\\widehat{\\mathsf{V}}</span> runs in time <span class="math">t_{\\widehat{\\mathsf{V}}}</span> and makes <span class="math">q_{\\widehat{\\mathsf{V}}}</span> queries, then the expected running time of the simulator <span class="math">\\mathsf{S}_{\\textup{perm}}</span> is <span class="math">O(t_{\\widehat{\\mathsf{V}}})+\\mathsf{poly}(n,k,1/\\varepsilon)</span> and its query complexity is <span class="math">O(q_{\\widehat{\\mathsf{V}}}+nk/\\varepsilon^{2})</span>.</p>

    <h6 id="sec-58" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">We prove this part by first showing the expected number of calls it makes to <span class="math">\\widehat{\\mathsf{V}}</span> is constant.</p>

    <p class="text-gray-300">Let <span class="math">T</span> be the number of times <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span> executes Steps 3 and 5c when <span class="math">\\widehat{\\mathsf{V}}</span> uses the coins <span class="math">\\rho</span>. Note that <span class="math">T</span> is equal to the number of times the simulator invokes <span class="math">\\widehat{\\mathsf{V}}</span>. Let <span class="math">\\mathcal{A}</span> be as defined in Equation (9) (recall that <span class="math">\\mathcal{A}</span> was defined as the set of vectors <span class="math">\\overline{\\mathbf{r}}</span> for which the verifier <span class="math">\\widehat{\\mathsf{V}}</span> responds with <span class="math">\\overline{\\mathbf{x}}</span> that do not all correspond to the respective preimages of <span class="math">\\overline{\\mathbf{y}}</span>). Let <span class="math">p=\\Pr_{r\\leftarrow(\\{0,1\\}^{n})^{s}}[r\\notin\\mathcal{A}]</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">E</span> denote the event that <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span> reaches Step 5. By construction, <span class="math">\\Pr[T=1]=\\Pr[\\neg E]=1-p</span>. Moreover, it holds that the random variable $T</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E<span class="math"> is drawn from a geometric distribution with parameter </span>p<span class="math">. Since the latter has expectation </span>1/p$ we have that:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\operatorname{E}[T]</span> <span class="math">=\\Pr[\\neg E]\\cdot\\operatorname{E}[T\\mid\\neg E]+\\Pr[E]\\cdot\\operatorname{E}[T\\mid E]</span> (10) <span class="math">=(1-p)\\cdot 1+p\\cdot\\frac{1}{p}</span> <span class="math">=2-p,</span></p>

    <p class="text-gray-300">Thus, in expectation, the simulator invokes <span class="math">\\widehat{\\mathsf{V}}</span> at most twice.</p>

    <p class="text-gray-300">Every time <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span> calls <span class="math">\\widehat{\\mathsf{V}}</span>, it samples a random string in <span class="math">\\{0,1\\}^{n\\cdot s}</span>, evaluates some <span class="math">h\\in\\mathcal{H}_{n\\cdot t\\cdot s,n\\cdot s}</span>, and makes <span class="math">O(t\\cdot s)</span> calls to <span class="math">f</span>. Recall that <span class="math">t_{\\widehat{\\mathsf{V}}}</span> and <span class="math">q_{\\widehat{\\mathsf{V}}}</span> denote the running time and query complexity of <span class="math">\\widehat{\\mathsf{V}}</span>, respectively. The expected running time of <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span> is thus at most <span class="math">O(t_{\\widehat{\\mathsf{V}}})+\\mathsf{poly}(t,s,n)=O(t_{\\widehat{\\mathsf{V}}})+\\mathsf{poly}(n,k,1/\\varepsilon)</span> (note that by Fact 2.5, evaluation of <span class="math">h</span> can be done in time <span class="math">\\mathsf{poly}(t,s,n)</span>). The expected query complexity of <span class="math">\\mathsf{S}^{f}(\\varepsilon,n,k,\\widehat{\\mathsf{V}})</span> is thus at most <span class="math">O(q_{\\widehat{\\mathsf{V}}}+t\\cdot s)=O(q_{\\widehat{\\mathsf{V}}}+nk/\\varepsilon^{2})</span>. ∎</p>

    <p class="text-gray-300">4.2 Promise Expansion is in HV-SZKPP</p>

    <p class="text-gray-300">In this section we consider the property of a graph being a “good” expander, in the bounded degree graph model (see <em>[x10, x11]</em>). Recall that in bounded degree graph model, the input graph is represented by an adjacency list and so, using a single query, the verifier can find the <span class="math">i^{\\text{th}}</span> neighbor of a vertex <span class="math">v</span>.</p>

    <p class="text-gray-300">The property of being a good expander was first considered by Goldreich and Ron <em>[x11]</em>. They showed that any tester for the (spectral) expansion of a graph on <span class="math">n</span> vertices must make at least <span class="math">\\Omega(\\sqrt{n})</span> queries. <em>[x11]</em> also suggested a testing algorithm that matches this bound and conjectured its correctness. Czumaj and Sohler <em>[x7]</em> focused on vertex expansion and proved that the <em>[x11]</em> tester accepts graphs that are good expanders and rejects graphs that are far from having even much worst expansion. More specifically, <em>[x7]</em> showed that the <em>[x11]</em> tester accepts graphs with (vertex) expansion <span class="math">\\alpha</span> and rejects graphs that are <em>far</em> from having even (vertex) expansion <span class="math">\\Theta\\Big{(}\\frac{\\alpha^{2}}{\\log(n)}\\Big{)}</span>. Lastly, Nachmias and Shapira <em>[x15]</em> and Kale and Seshadhri<em>[x14]</em> improved <em>[x7]</em>’s result and showed that the tester in fact rejects graphs that are far from having expansion <span class="math">\\Theta\\big{(}\\alpha^{2}\\big{)}</span>. We show how to apply <em>[x7]</em>’s approach to get an honest-verifier statistical zero-knowledge proof of proximity with only a <em>poly-logarithmic</em> dependence on <span class="math">n</span>, as long as we have a similar type of gap between YES and NO instances as in <em>[x7]</em>.</p>

    <p class="text-gray-300">Formally, a vertex expander is defined as follows.</p>

    <h6 id="sec-59" class="text-base font-medium mt-4">Definition 4.10 (Vertex expander).</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">\\alpha&gt;0</span>. A graph <span class="math">G=(\\mathcal{V},\\mathcal{E})</span> is an <span class="math">\\alpha</span>-expander if for every subset <span class="math">\\mathcal{U}\\subseteq\\mathcal{V}</span> of size $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{U}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{V}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">/2<span class="math">, it holds that </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">N(\\mathcal{U})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq\\alpha\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{U}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, where </span>N(\\mathcal{U}):=\\{v\\in\\mathcal{V}\\setminus\\mathcal{U}\\colon\\exists u\\in\\mathcal{U}\\text{ such that }(v,u)\\in\\mathcal{E}\\}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Throughout this section we fix a bound <span class="math">d</span> on the degree of all graphs (which we think of as constant). We identify graphs on <span class="math">n</span> vertices as functions <span class="math">G\\colon[n]\\times[d]\\to[n]\\cup\\{\\bot\\}</span> such that <span class="math">G(u,i)=v</span> if <span class="math">v</span> is the <span class="math">i</span>’th neighbor of a vertex <span class="math">u</span> and <span class="math">G(u,i)=\\bot</span> if <span class="math">u</span> has less than <span class="math">i</span> neighbors.</p>

    <h6 id="sec-60" class="text-base font-medium mt-4">Definition 4.11.</h6>

    <p class="text-gray-300">Let <span class="math">d\\in\\mathbb{N}</span>. For <span class="math">n\\in\\mathbb{N}</span> and <span class="math">\\alpha=\\alpha(n)&gt;0</span>, let</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\text{\\tt EXPANDER}_{n}^{d,\\alpha}=\\Big{\\{}G\\colon[n]\\times[d]\\to[n]\\ \\Big{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\ \\ G\\text{ is a }\\alpha(n)\\text{-expander}\\Big{\\}}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Let <span class="math">\\beta=\\beta(n)\\in(0,\\alpha(n)]</span>. We define the expander promise problem (see Remark 3.5) as</p>

    <p class="text-gray-300"><span class="math">\\text{\\tt EXPANDER}^{d,\\alpha,\\beta}=\\Big{(}\\text{\\tt EXPANDER}^{d,\\alpha,\\beta}_{\\text{\\tt YES},n},\\text{\\tt EXPANDER}^{d,\\alpha,\\beta}_{\\text{\\tt NO},n},[n]\\times[d],[n]\\Big{)},</span></p>

    <p class="text-gray-300">where <span class="math">\\text{\\tt EXPANDER}^{d,\\alpha,\\beta}_{\\text{\\tt YES},n}=\\text{\\tt EXPANDER}^{d,\\alpha}_{n}</span> and <span class="math">\\text{\\tt EXPANDER}^{d,\\alpha,\\beta}_{\\text{\\tt NO},n}=\\text{\\tt EXPANDER}^{d,\\beta}_{n}</span>.</p>

    <p class="text-gray-300">That is, YES instances of the promise problem are graphs that are <span class="math">\\alpha</span>-expanders and NO instances are graphs that are far from even being <span class="math">\\beta</span>-expanders, for <span class="math">\\beta\\leq\\alpha</span>.</p>

    <h6 id="sec-61" class="text-base font-medium mt-4">Theorem 4.12 (SZKPP for Expansion).</h6>

    <p class="text-gray-300">Let <span class="math">d\\in\\mathbb{N}</span> and <span class="math">\\alpha\\in(0,1/3]</span> be constants. Then, <span class="math">\\text{\\tt EXPANDER}^{d,\\alpha,\\beta}\\in\\texttt{HV-SZKPP}[\\text{\\tt poly}(\\log(n),k,1/\\varepsilon)]</span> for <span class="math">\\beta=\\Theta\\Big{(}\\frac{\\alpha^{2}}{d^{2}\\log(n)}\\Big{)}</span>, where <span class="math">n</span> is the number of vertices in the graph, <span class="math">k</span> is the security parameter and <span class="math">\\varepsilon</span> is the proximity parameter.</p>

    <h6 id="sec-62" class="text-base font-medium mt-4">Proof of Theorem 4.12.</h6>

    <p class="text-gray-300">We prove Theorem 4.12 by reducing graph expansion to the problem of testing whether two distributions are statistically close. The reduction is such that we can sample from each distribution using few queries to our original input graph. Given this reduction, we</p>

    <p class="text-gray-300">can now use Lemma 2.14 which gives an honest-verifier statistical zero-knowledge proof for verifying whether the distribution induced by two circuits on a random input is statistically close. A crucial observation is that neither the verifier nor the simulator in the latter protocol need to actually look at their input circuits. Rather, they only need to be able to draw relatively few random samples from the distribution induced by the circuit on a random input. Intuitively, by applying our reduction we therefore obtain an honest-verifier statistical zero-knowledge proof for <span class="math">\\textsc{EXPANDER}^{d,\\alpha,\\beta}</span>.</p>

    <p class="text-gray-300">We proceed to give an overview of our reduction from <span class="math">\\textsc{EXPANDER}^{d,\\alpha,\\beta}</span> to statistical closeness. The reduction, which is randomized, chooses uniformly at random a vertex <span class="math">u</span> and considers two distributions: the first, denoted by <span class="math">P^{\\ell}_{u}</span>, outputs the last vertex in a random walk of length <span class="math">\\ell=\\Theta\\left(\\frac{d^{2}\\log(n)}{\\alpha^{2}}\\right)</span> starting at <span class="math">u</span>; the second, denoted by <span class="math">U_{[n]}</span>, is uniform over all vertices. Observe that both distributions can be sampled using relatively few queries to the input graph.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We observe that if the graph is an <span class="math">\\alpha</span>-expander (i.e., a YES instance) then for <em>any</em> choice of <span class="math">u</span>, it holds that <span class="math">\\mathrm{SD}\\big{(}P^{\\ell}_{u},U_{[n]}\\big{)}\\approx 0</span> (and so the two distributions are close). On the other hand, <em>[x10]</em> showed that if the graph is far from being a <span class="math">\\Theta\\left(\\frac{\\alpha^{2}}{d^{2}\\log(n)}\\right)</span>-expander (i.e., a NO instance), then there exists a set of vertices <span class="math">\\mathcal{U}</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{U}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\Omega(n)<span class="math"> such that for every </span>u\\in\\mathcal{U}<span class="math">, it holds that </span>\\mathrm{SD}\\big{(}P^{\\ell}_{u},U_{[n]}\\big{)}\\gg 0<span class="math">. Thus, in the NO case, with constant probability (over the choice of </span>u$), our reduction generates distributions that are statistically far. We proceed to the actual proof.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Our protocol uses the following lazy random walk on the graph <span class="math">G</span>.</p>

    <h6 id="sec-63" class="text-base font-medium mt-4">Definition 4.13 (Random walk).</h6>

    <p class="text-gray-300">Let <span class="math">G=(\\mathcal{V},\\mathcal{E})</span> be a (simple) bounded degree <span class="math">d</span> graph. For <span class="math">u\\in\\mathcal{V}</span>, define <span class="math">p_{u}(v)=1/2d</span> if <span class="math">(u,v)\\in\\mathcal{E}</span> (i.e., <span class="math">(u,v)</span> is an edge), and <span class="math">p_{u}(u)=1-\\deg(u)/2d</span>. For <span class="math">\\ell\\in\\mathbb{N}</span>, a random walk of length <span class="math">\\ell</span> starting at <span class="math">u</span> is a random process that chooses <span class="math">\\ell</span> vertices <span class="math">u_{1},\\ldots,u_{\\ell}</span> such that <span class="math">u_{1}:=u</span> and every vertex <span class="math">u_{i+1}</span> is sampled from the distribution <span class="math">p_{u_{i}}</span>. The distribution <span class="math">P^{\\ell}_{u}(v)</span> is the probability that <span class="math">u_{\\ell}=v</span>.</p>

    <p class="text-gray-300">Assume without loss of generality that <span class="math">\\varepsilon\\leq 0.1</span>, where <span class="math">\\varepsilon</span> is the proximity parameter. Let <span class="math">h:[0,1]\\to[0,1]</span> be the binary entropy function (recall that <span class="math">h(p):=-p\\log(p)-(1-p)\\log(1-p)</span>). By a routine calculation, it holds that</p>

    <p class="text-gray-300"><span class="math">h\\bigg{(}\\frac{1}{2}\\cdot(1+0.2)\\bigg{)}\\leq h(0.6)&lt;0.98&lt;1-0.01.</span> (11)</p>

    <p class="text-gray-300">Thus, we can apply Lemma 2.14, with respect to the constants <span class="math">\\alpha=0.2</span> and <span class="math">\\beta=0.01</span> to obtain an honest verifier statistical zero knowledge protocol <span class="math">\\left(\\mathsf{P}^{(\\cdot,\\cdot)}(k),\\mathsf{V}^{(\\cdot,\\cdot)}(k)\\right)</span> for <span class="math">\\overline{\\mathsf{SD}^{0.2,0.01}}</span>. Thus, <span class="math">\\left(\\mathsf{P}^{(\\cdot,\\cdot)}(k),\\mathsf{V}^{(\\cdot,\\cdot)}(k)\\right)</span> is a statistical zero-knowledge protocol for distinguishing between YES instances, which are pairs of circuits that have statistical distance at most <span class="math">0.01</span>, from NO instances, which are pairs of circuits whose statistical distance is at least <span class="math">0.2</span>. Using the latter, we construct a protocol <span class="math">(\\mathsf{P}_{\\text{expan}},\\mathsf{V}_{\\text{expan}})</span> for verifying expansion, which is given in Fig. 3.</p>

    <p class="text-gray-300">The next two lemmas show the completeness and soundness of the expander protocol.</p>

    <h6 id="sec-64" class="text-base font-medium mt-4">Lemma 4.14.</h6>

    <p class="text-gray-300">Let <span class="math">n,k\\in\\mathbb{N}</span>, let <span class="math">\\varepsilon&gt;0</span> and let <span class="math">G\\colon[n]\\times[d]\\to[n]</span>. Assume that <span class="math">G</span> is in <span class="math">\\textsc{EXPANDER}^{d,\\alpha}_{n}</span> (i.e., <span class="math">G</span> is an <span class="math">\\alpha</span>-expander), then <span class="math">\\mathsf{V}_{\\textsc{expan}^{G}_{\\alpha,d}}(\\varepsilon,n,k)</span>, when interacting with <span class="math">\\mathsf{P}_{\\text{expan}_{\\alpha,d}}(\\varepsilon,G,k)</span> according to the expander protocol (Fig. 3), accepts with probability <span class="math">1-\\textsf{negl}(k)</span>.</p>

    <p class="text-gray-300">######</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Figure 3: The Expander Protocol</p>

    <p class="text-gray-300">Lemma 4.14 is proven in Section 4.2.1 via a standard analysis of random walks on expanders.</p>

    <p class="text-gray-300">Lemma 4.15. Let  <span class="math">n, k \\in \\mathbb{N}</span> , let  <span class="math">0 &amp;lt; \\varepsilon \\leq 0.1</span>  and let  <span class="math">G \\colon [n] \\times [d] \\to [n]</span> . Assume that  <span class="math">G</span>  is  <span class="math">\\varepsilon</span> -far from  <span class="math">\\text{EXPANDER}_n^{d,\\beta}</span>  for  <span class="math">\\beta = \\Theta\\left(\\frac{\\alpha^2}{d^2 \\log(n)}\\right)</span> , then for every prover strategy  <span class="math">\\widehat{\\mathsf{P}}</span> , when  <span class="math">\\mathsf{V}_{\\text{expan}}^G(\\varepsilon, n, k)</span>  interacts with  <span class="math">\\widehat{\\mathsf{P}}</span>  according to the expander protocol (Fig. 3), with probability at least  <span class="math">\\varepsilon / 24 - \\text{negl}(k)</span>  it rejects.</p>

    <p class="text-gray-300">Lemma 4.15 is proven in Section 4.2.2 via a combinatorial property of graphs that are  <span class="math">\\varepsilon</span> -far from  <span class="math">\\beta</span> -expanders, shown by [CS10].</p>

    <p class="text-gray-300">As for honest-verifier zero-knowledge, let  <span class="math">\\mathsf{S}^{(\\cdot ,\\cdot)}</span>  denote the simulator of the protocol for  <span class="math">\\overline{\\mathsf{SD}^{0.2,0.01}}</span>  from Lemma 2.14. Note that if  <span class="math">G</span>  is an  <span class="math">\\alpha</span> -expander, the same mixing argument used to establish completeness implies that  <span class="math">\\mathrm{SD}\\big(P_u^\\ell ,U_{[n]}\\big)\\leq 0.01</span> , for every vertex  <span class="math">u</span>  (see Section 4.2.1). Hence, for every vertex  <span class="math">u</span>  it holds that  <span class="math">\\mathsf{S}^{P_u^\\ell ,U_{[n]}}(k)</span>  simulates  <span class="math">\\left(\\mathsf{P}^{P_u^\\ell ,U_{[n]}}(k),\\mathsf{V}^{P_u^\\ell ,U_{[n]}}(k)\\right)</span>  with simulation deviation at most  <span class="math">\\mu (k)</span> , for some negligible function  <span class="math">\\mu</span> . Our simulator for the expansion protocol, denoted by  <span class="math">\\mathsf{S}_{\\mathrm{expan}}</span>  will choose a vertex  <span class="math">u</span>  uniformly at random, and output  <span class="math">\\left(u,\\mathsf{S}^{P_u^\\ell ,U_{[n]}}(k)\\right)</span> . Now observe that  <span class="math">\\mathsf{S}_{\\mathrm{expan}}</span> ’s deviation from  <span class="math">\\mathsf{V}_{\\mathrm{expan}}</span> ’s view in  <span class="math">(\\mathsf{P}_{\\mathrm{expan}},\\mathsf{V}_{\\mathrm{expan}})</span>  is precisely equal to the expected deviation, over the choice of a random vertex  <span class="math">u</span> , of  <span class="math">\\mathsf{S}^{P_u^\\ell ,U_{[n]}}(k)</span>  from the view of  <span class="math">\\mathsf{V}^{P_u^\\ell ,U_{[n]}}</span>  in the protocol  <span class="math">\\left(\\mathsf{P}^{P_u^\\ell ,U_{[n]}}(k),\\mathsf{V}^{P_u^\\ell ,U_{[n]}}(k)\\right)</span> . Since the latter is bounded by  <span class="math">\\mu</span>  for every choice of  <span class="math">u</span> , the expected deviation is bounded by  <span class="math">\\mu (k)</span>  as well.</p>

    <p class="text-gray-300">So far we have shown that the expander protocol (Fig. 3) has  <span class="math">\\mathrm{negl}(k)</span>  completeness error,  <span class="math">1 - (\\varepsilon /24 - \\mathrm{negl}(k))</span>  soundness error and is honest-verifier statistical zero-knowledge. To reduce the soundness error the parties will repeat the above protocol in parallel for  <span class="math">\\mathrm{poly}(k) / \\varepsilon</span>  times. Since honest-verifier statistical zero-knowledge is preserved under parallel repetition, and parallel repetition reduces the soundness errors of IPPs at an exponential rate (see, e.g., [GGR15, Appendix A]), the resulting protocol is an honest-verifier statistical zero-knowledge proof of proximity.</p>

    <p class="text-gray-300">Finally, we argue about the efficiency of  <span class="math">\\mathsf{V}_{\\mathrm{expan}}</span>  (the analysis of the simulator's efficiency is similar). The verifier  <span class="math">\\mathsf{V}_{\\mathrm{expan}}</span>  needs to provide  <span class="math">\\mathsf{V}^{P_u^\\ell ,U_{[n]}}(k)</span>  samples from  <span class="math">P_{u}^{\\ell}</span>  and  <span class="math">U_{[n]}</span> . Generating a random sample from  <span class="math">U_{[n]}</span>  is easy and requires  <span class="math">O(\\log n)</span>  random coins. Generating a random sample from  <span class="math">P_{u}^{\\ell}</span>  is standard as well, requires  <span class="math">\\mathsf{poly}(\\ell ,d) = \\mathsf{poly}(\\log n)</span>  random coins and oracle calls</p>

    <p class="text-gray-300">to the input graph. By Lemma 2.14, it follows the <span class="math">\\mathsf{V}_{\\text{expan}}</span>’s running time (accounting for the parallel repetition as well) is at most <span class="math">\\poly(\\log(n),1/\\varepsilon,k)</span>. ∎</p>

    <h4 id="sec-65" class="text-lg font-semibold mt-6">4.2.1 Analyzing Completeness — Proving Lemma 4.14</h4>

    <p class="text-gray-300">Lemma 4.14 is an easy implication of the following standard result regarding random walks on expanders.</p>

    <h6 id="sec-66" class="text-base font-medium mt-4">Lemma 4.16 (Expanders are Rapidly Mixing (c.f. <em>[x23, proof of Theorem 2.1]</em>)).</h6>

    <p class="text-gray-300">Suppose that <span class="math">G</span> is an <span class="math">\\alpha</span>-expander graph on <span class="math">n</span> vertices with bounded degree <span class="math">d</span>. Then for every vertex <span class="math">u</span> and <span class="math">\\ell\\in\\mathbb{N}</span> it holds that <span class="math">\\mathrm{SD}\\big{(}P_{u}^{\\ell},U_{[n]}\\big{)}\\leq\\sqrt{n}\\cdot e^{-\\frac{\\alpha^{2}}{8d^{2}}\\cdot\\ell}</span>.</p>

    <h6 id="sec-67" class="text-base font-medium mt-4">Proof of Lemma 4.14.</h6>

    <p class="text-gray-300">From the choice of <span class="math">\\ell</span> and Lemma 4.16, it holds that</p>

    <p class="text-gray-300"><span class="math">\\mathrm{SD}\\Big{(}P_{u}^{\\ell},U_{[n]}\\Big{)}\\leq 0.01,</span></p>

    <p class="text-gray-300">for every vertex <span class="math">u</span>. Let <span class="math">W</span> be the random variable induced by the values of <span class="math">u</span> chosen in step 1 of a random execution of the protocol It follows that</p>

    <p class="text-gray-300"><span class="math">\\Pr\\Big{[}\\mathsf{V}_{\\text{expan}^{G}_{\\alpha,d}}(\\varepsilon,n,k)\\text{ accepts}\\Big{]}=\\Pr\\Big{[}\\mathsf{V}^{P_{W}^{\\ell},U_{[n]}}(k)\\text{ accepts}\\Big{]}\\geq 1-\\text{negl}(k),</span></p>

    <p class="text-gray-300">where the last inequlity follows from the completeness property of <span class="math">(\\mathsf{P},\\mathsf{V})</span>(Lemma 2.14). ∎</p>

    <h4 id="sec-68" class="text-lg font-semibold mt-6">4.2.2 Analyzing Soundness — Proving Lemma 4.15</h4>

    <p class="text-gray-300">The soundness of the expander protocol follows from the following combinatoral property of graphs that are far from expanders.</p>

    <h6 id="sec-69" class="text-base font-medium mt-4">Lemma 4.17 (<em>[x10, Corollary 4.6 and Lemma 4.7]</em>).</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">G</span> be a graph on <span class="math">n</span> vertices with bounded degree <span class="math">d</span>. There exists a constant <span class="math">c=c(d)&gt;0</span> such that the following holds. If <span class="math">G</span> is <span class="math">\\varepsilon</span>-far from any <span class="math">\\beta</span>-expander with <span class="math">\\beta\\leq 1/10</span>, then there exists <span class="math">\\mathcal{U}\\subset[n]</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{U}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq\\varepsilon\\cdot n/24<span class="math"> such that for every </span>u\\in\\mathcal{U}<span class="math">, it holds that </span>\\mathrm{SD}\\big{(}P_{u}^{\\ell},U_{[n]}\\big{)}\\geq\\frac{1-2\\varepsilon}{4}<span class="math">, where </span>\\ell\\leq 1/(10c\\beta)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Recall that <span class="math">\\mathsf{V}_{\\text{expan}}</span>’s first steps is to choose uniformly at random a vertex <span class="math">u</span>. This <span class="math">u</span> will belong to the set <span class="math">\\mathcal{U}</span> from the Lemma 4.17 with probability at least <span class="math">\\varepsilon/24</span>. Conditioned on the latter, we claim that the input to <span class="math">\\Big{(}\\mathsf{P}^{P_{u}^{\\ell},U_{[n]}}(k),\\mathsf{V}^{P_{u}^{\\ell},U_{[n]}}(k)\\Big{)}</span> is a NO input and so soundness follows immediately from the soundness of the protocol for <span class="math">\\overline{\\mathrm{SD}}</span> (Lemma 2.14).</p>

    <p class="text-gray-300">We argue soundness with respect to <span class="math">\\beta=\\Big{\\lfloor}\\frac{\\alpha^{2}}{20\\cdot c\\cdot d^{2}\\cdot\\log(\\sqrt{n}/0.01)}\\Big{\\rfloor}</span>, where <span class="math">c=c(d)&gt;0</span> is the constant guaranteed to exist by Lemma 4.17.</p>

    <h6 id="sec-70" class="text-base font-medium mt-4">Proof of Lemma 4.15.</h6>

    <p class="text-gray-300">Let <span class="math">\\widehat{\\mathsf{P}}</span> be any prover strategy. Let <span class="math">W</span> be the random variable induced by the values of <span class="math">u</span> chosen in step 1 of a random execution of the protocol and let <span class="math">\\mathcal{U}</span> be the set guaranteed to exist by Lemma 4.17. It holds that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\Pr\\Big{[}\\mathsf{V}_{\\text{expan}^{G}_{\\alpha,d}}(\\varepsilon,n,k)\\text{ accepts}\\Big{]}\\leq\\Pr[W\\notin\\mathcal{U}]+\\Pr\\Big{[}\\mathsf{V}_{\\text{expan}^{G}_{\\alpha,d}}(\\varepsilon,n,k)\\text{ accepts }\\Big{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\ W\\in\\mathcal{U}\\Big{]}.$ (12)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We bound both terms in the right-hand side of Equation 12. Lemma 4.17 yields that <span class="math">\\Pr[W\\notin\\mathcal{U}]\\leq 1-\\varepsilon/24</span>. As for the second term, Lemma 4.17 yields that <span class="math">\\mathrm{SD}\\big{(}P_{w}^{\\ell},U_{[n]}\\big{)}\\geq\\frac{1-2\\varepsilon}{4}\\geq 0.2</span> for every <span class="math">w\\in\\mathcal{U}</span> (note that <span class="math">\\beta</span> was chosen so that <span class="math">\\ell\\leq 1/(10c\\beta)</span> and that we assumed above that <span class="math">\\varepsilon&lt;0.1</span>). It follows that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\Pr\\Big{[}\\mathsf{V}_{\\text{expan}^{G}_{\\alpha,d}}(\\varepsilon,n,k)\\text{ accepts }\\Big{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}W\\in\\mathcal{U}\\Big{]}\\leq\\mathrm{E}_{u\\leftarrow\\mathcal{U}}\\Big{[}\\Pr\\Big{[}\\mathsf{V}^{P_{n}^{\\ell},U_{[n]}}(k)\\text{ accepts}\\Big{]}\\Big{]}\\leq\\mathsf{negl}(k),$ (13)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where the last inequality follows from the soundness properties of <span class="math">\\mathsf{V}</span> (Lemma 2.14). ∎</p>

    <h3 id="sec-71" class="text-xl font-semibold mt-8">4.3 Promise Bipartiteness is in HV-SZKPP</h3>

    <p class="text-gray-300">In this section we consider the property of a graph being bipartite in the bounded degree model (we introduced this model in Section 4.2). The property of being a bipartite graph was first considered by Goldrich and Ron <em>[x11, x12]</em>. They showed a tester for bipartiteness of graphs with <span class="math">n</span> vertices which makes at most <span class="math">\\tilde{O}(\\sqrt{n})</span> queries. They also showed a matching lower bound, namely that any such tester must make at least <span class="math">\\Omega(\\sqrt{n})</span> queries.</p>

    <p class="text-gray-300">Rothblum et al. <em>[x20]</em> gave an interactive proof of proximity for the following promise version of this property in which the verifier’s running time is <span class="math">\\Theta(\\log n)</span>. In this version, YES instances are bipartite graphs. NO instances, in addition to being far from bipartite, are also well-mixing, namely that a random walk of <span class="math">\\Theta(\\log n)</span> steps ends at each vertex with probability at least <span class="math">1/2n</span> (e.g., expanders). We denote this property by BIPARTITE. In <em>[x20]</em>’s protocol, the verifier takes a random walk of length <span class="math">\\Theta(\\log n)</span> starting at a randomly chosen vertex (in each step it performs a self-loop with probability at least <span class="math">1/2</span>; see Definition 4.13). The verifier then sends the prover the start and end vertices of the walk and asks the prover to tell him the parity of the number of non-self-loop steps it took during the walk.</p>

    <p class="text-gray-300">If the graph is bipartite, then the parity of the number of non-self-loops is equal to the parity of the shortest simple path from the start vertex to the end vertex. <em>[x20]</em> showed that if the graph is far from being bipartite and well-mixing, then the chance of taking a path of even non-self-loop steps is close to that of taking a path of odd non-self-loop steps. Hence, any cheating prover will fail to convince the verifier.</p>

    <p class="text-gray-300">In fact, it is easy to see that the above protocol is also an honest-verifier perfect zero-knowledge proof of proximity. The simulator will simply act as the verifier: take a random walk and output the parity of the non-self-loop steps in this walk (which the simulator knows since it performs the walk). Since this result follows immediately from <em>[x20]</em>’s protocol, we only state an informal version of the it here, and refer the reader to <em>[x20]</em> for formal definitions and description of the protocol.</p>

    <h6 id="sec-72" class="text-base font-medium mt-4">Theorem 4.18 (<em>[x20, Section 5.1]</em>, informal).</h6>

    <p class="text-gray-300">BIPARTITE <span class="math">\\in</span> HV-PZKPP<span class="math">[\\mathsf{poly}(\\log(N),k,1/\\varepsilon)]</span>.</p>

    <p class="text-gray-300">It is an interesting open question to show a <em>cheating-verifier</em> zero-knowledge proof of proximity for BIPARTITE.</p>

    <h2 id="sec-73" class="text-2xl font-bold">5 Limitations of SZKPP</h2>

    <p class="text-gray-300">In light of the positive results in Section 4 an important questions rises:</p>

    <p class="text-gray-300"><em>Does every property that has a sub-linear <span class="math">\\mathsf{IPP}</span> also have a sub-linear </em>statistical zero-knowledge <span class="math">\\mathsf{IPP}</span></p>

    <p class="text-gray-300">We give a negative answer to the above question.18 Actually we show two incomparable lower bounds:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>There exists a property <span class="math">\\Pi</span> that has an IPP in which the verifier runs in poly-logarithmic time, but the verifier in any zero-knowledge proof of proximity for <span class="math">\\Pi</span> cannot run in poly-logarithmic time. (Actually we can even show that such a verifier cannot run in time <span class="math">N^{o(1)}</span>, see Remark 5.6). Thus, this lower bound can be viewed as a separation between the class <span class="math">\\mathsf{IPP}\\big{[}\\mathsf{poly}(\\log(N),k,1/\\varepsilon)\\big{]}</span> and <span class="math">\\mathsf{HV\\text{-}ESZKPP}\\big{[}\\mathsf{poly}(\\log(N),k,1/\\varepsilon)\\big{]}</span>.</li>

      <li>We show an additional lower bound which separates <span class="math">\\mathsf{HV\\text{-}ESZKPP}\\big{[}\\mathsf{poly}(\\log(N),k,1/\\varepsilon)</span> even from a weaker class - namely the class of languages admitting <em>non-interactive</em> proofs of proximity, also known as Merlin-Arthur proofs of proximity or MAPs <em>[x12]</em>. However, in contrast to the previous separation from IPPs, this result is conditional: we can only prove it assuming a (very plausible) circuit lower bound. Specifically, we assume that (randomized) <span class="math">\\mathsf{DNF}_{\\oplus}</span>, namely <span class="math">\\mathsf{DNF}</span> formulas composed with one layer of parity gates (see <em>[x10, ABG^{+}14]</em> and references therein), cannot compute the disjointness function. This circuit lower bound is implied by the assumption that the Arthur-Merlin communication complexity of disjointness is <span class="math">n^{\\varepsilon}</span>, for inputs of length <span class="math">n</span> and some constant <span class="math">\\varepsilon&gt;0</span>.</li>

    </ol>

    <h3 id="sec-74" class="text-xl font-semibold mt-8">5.1 <span class="math">\\mathsf{IPP}\\nsubseteq\\mathsf{ESZKPP}</span></h3>

    <p class="text-gray-300">We show that there exists a property <span class="math">\\Pi\\in\\mathsf{IPP}[\\mathsf{poly}(\\log(N),k,1/\\varepsilon)]</span> but <span class="math">\\Pi\\notin\\mathsf{HV\\text{-}ESZKPP}[\\mathsf{poly}(\\log(N),k,1/\\varepsilon)]</span>. Namely, <span class="math">\\Pi</span> that has an efficient IPP, which <em>unconditionally</em> cannot have such a statistical zero-knowledge IPP.</p>

    <h6 id="sec-75" class="text-base font-medium mt-4">Theorem 5.1.</h6>

    <p class="text-gray-300"><span class="math">\\mathsf{IPP}\\big{[}\\mathsf{poly}(\\log(N),k,1/\\varepsilon)\\big{]}\\nsubseteq\\mathsf{HV\\text{-}ESZKPP}\\big{[}\\mathsf{poly}(\\log(N),k,1/\\varepsilon)\\big{]}</span>.</p>

    <p class="text-gray-300">The proof of Theorem 5.1 is done in two steps. The first step is to argue the existence of a property <span class="math">\\Pi</span> which has an interactive proof of proximity with a large number of rounds and <span class="math">\\mathsf{polylog}(N)</span>-time verifier , but such that in every <em><span class="math">2</span>-message</em> interactive proof of proximity for <span class="math">\\Pi</span>, the verifier’s running time must be <span class="math">N^{\\delta}</span>, for some constant <span class="math">\\delta&gt;0</span>. Actually, such a result was recently established by Gur and Rothblum <em>[x12]</em>:</p>

    <h6 id="sec-76" class="text-base font-medium mt-4">Lemma 5.2 (<em>[x12, Theorem 1]</em>).</h6>

    <p class="text-gray-300">The exists <span class="math">\\Pi\\in\\mathsf{IPP}[\\mathsf{poly}(\\log(N),k,1/\\varepsilon)]</span> such that the verifier in every <span class="math">2</span>-message <span class="math">\\mathsf{IPP}</span> for <span class="math">\\Pi</span>, with respect to proximity parameter <span class="math">\\varepsilon=1/10</span> and completeness and soundness error <span class="math">1/3</span>, must run in time <span class="math">\\Omega\\big{(}N^{\\delta}\\big{)}</span>, for some universal constant <span class="math">\\delta&gt;0</span>.</p>

    <p class="text-gray-300">The second step in proving Theorem 5.1 is a general round reduction transformation for any honest-verifier statistical zero-knowledge proof of proximity. Namely, we would like a procedure that takes any <em>many-messages</em> honest-verifier zero-knowledge proof of proximity and turns it into a <em><span class="math">2</span>-message</em> honest-verifier zero-knowledge proof of proximity while only slightly deteriorating the verifier’s and simulator’s running times. Specifically, we show the following lemma.</p>

    <h6 id="sec-77" class="text-base font-medium mt-4">Lemma 5.3 (Efficient Round Reduction for <span class="math">\\mathsf{SZKPP}</span>).</h6>

    <p class="text-gray-300">Suppose that the property <span class="math">\\Pi</span> has an honest-verifier statistical zero-knowledge <span class="math">\\varepsilon</span>-<span class="math">\\mathsf{IPP}</span> such that for every input length <span class="math">N\\in\\mathbb{N}</span> and security parameter <span class="math">k\\in\\mathbb{N}</span> the</p>

    <p class="text-gray-300">simulator’s expected running time is bounded by <span class="math">t_{\\mathsf{S}}(\\varepsilon,N,k)=t^{\\prime}_{\\mathsf{S}}(\\varepsilon,N)\\cdot\\mathsf{poly}(k)</span> and for every value of <span class="math">\\varepsilon</span>, the function <span class="math">t^{\\prime}_{\\mathsf{S}}(\\varepsilon,\\cdot)</span> is monotone non-decreasing.</p>

    <p class="text-gray-300">Then, <span class="math">\\Pi</span> has a <span class="math">2</span>-message honest verifier statistical zero-knowledge <span class="math">\\varepsilon</span>-<span class="math">\\mathsf{IPP}</span> such that for every input length <span class="math">N</span> and security parameter <span class="math">k</span> the running time of the verifier is <span class="math">\\mathsf{poly}(t_{\\mathsf{S}}(\\varepsilon,N,k^{\\prime}),k)</span>, for <span class="math">k^{\\prime}=\\mathsf{poly}(t^{\\prime}_{\\mathsf{S}}(\\varepsilon,N))</span>.</p>

    <p class="text-gray-300">For the setting of poly-logarithmic zero-knowledge proof of proximity, Lemma 5.3 can be stated as follows.</p>

    <h6 id="sec-78" class="text-base font-medium mt-4">Corollary 5.4.</h6>

    <p class="text-gray-300">Every <span class="math">\\Pi\\in\\mathsf{HV\\text{-}ESZKPP}[\\mathsf{poly}(\\log(N),k,1/\\varepsilon)]</span> has a <span class="math">2</span>-message honest-verifier statistical zero-knowledge <span class="math">\\varepsilon</span>-<span class="math">\\mathsf{IPP}</span> with expected simulation, such that the verifier’s running time is <span class="math">\\mathsf{poly}(\\log(N),k,1/\\varepsilon)</span>.</p>

    <h6 id="sec-79" class="text-base font-medium mt-4">Remark 5.5 (Comparison with the Babai-Moran <em>[x1]</em> Round).</h6>

    <p class="text-gray-300">Lemma 5.3 and Corollary 5.4 should be contrasted with the classical round reduction of interactive proofs, due to Babai and Moran <em>[x1]</em> (and shown in <em>[x21]</em> to hold also for <span class="math">\\mathsf{IPP}</span>s). In contrast to Lemma 5.3, the Babai-Moran round reduction increases the complexity of the verifier exponentially in the round complexity of the original protocol. In contrast, the overhead in Lemma 5.3 is only polynomial, which is crucial for our lower bound.</p>

    <p class="text-gray-300">The proof of Lemma 5.3 is a direct application of the proof that the promise problem Entropy Difference (ED, see Definition 2.12) is complete for the class <span class="math">\\mathsf{SZK}</span> (see <em>[x27]</em>). That proof takes an instance <span class="math">x</span> of any promise problem <span class="math">\\Pi=(\\Pi_{\\mathsf{YES}},\\Pi_{\\mathsf{NO}})\\in\\mathsf{SZK}</span> and efficiently constructs two distributions <span class="math">X</span> and <span class="math">Y</span> such that if <span class="math">x\\in\\Pi_{\\mathsf{YES}}</span> then <span class="math">\\mathrm{H}(X)\\geq\\mathrm{H}(Y)+1</span>, and if <span class="math">x\\in\\Pi_{\\mathsf{NO}}</span> then <span class="math">\\mathrm{H}(Y)\\geq\\mathrm{H}(X)+1</span>. That proof goes on to show a zero-knowledge protocol to distinguish between the case that <span class="math">\\mathrm{H}(X)\\geq\\mathrm{H}(Y)+1</span> and the case that <span class="math">\\mathrm{H}(Y)\\geq\\mathrm{H}(X)+1</span>. Two important points regarding that proof: (1) sampling from <span class="math">X</span> and <span class="math">Y</span> can be done by running (many times) the simulator for the original problem <span class="math">\\Pi</span>; (2) the protocol for ED consists of only two messages and requires only sample access to <span class="math">X</span> and <span class="math">Y</span> (we stated this fact in Lemma 2.15).</p>

    <p class="text-gray-300">In our settings, we can view a property <span class="math">\\Pi</span> as a promise problem where functions possessing the property are in <span class="math">\\Pi_{\\mathsf{YES}}</span> and functions that are <span class="math">\\varepsilon</span>-far from possessing the property are in <span class="math">\\Pi_{\\mathsf{NO}}</span>. Then, we can have the verifier “run” the reduction to ED and apply the sample-access protocol for ED. The unbounded prover will behave as in the protocol for ED. Recall that the original simulator (i.e., the one for the property’s <span class="math">\\mathsf{IPP}</span>) required only oracle access to the input function. Since sampling from the distributions only requires running the original simulator, the new verifier can implement this step with only oracle access to the input function and with only polynomial overhead to the running time of the original simulator. We defer the actual proof of Lemma 5.3 to Appendix B.1.</p>

    <p class="text-gray-300">Using Lemmas 5.2 and 5.3 we can now prove Theorem 5.1.</p>

    <h6 id="sec-80" class="text-base font-medium mt-4">Proof of Theorem 5.1.</h6>

    <p class="text-gray-300">Let <span class="math">\\Pi</span> be the property guaranteed to exist by Lemma 5.2. Assume towards a contradiction that <span class="math">\\Pi\\in\\mathsf{HV\\text{-}ESZKPP}[\\mathsf{poly}(\\log(N),k,1/\\varepsilon)]</span>. Namely, <span class="math">\\Pi</span> has an honest-verifier statistical zero-knowledge interactive proof of proximity with the simulator’s expected running time being <span class="math">(\\log(N))^{\\alpha}\\cdot k^{\\beta}\\cdot(1/\\varepsilon)^{\\gamma}</span> for constants <span class="math">\\alpha,\\beta,\\gamma&gt;0</span>. Applying Lemma 5.3 with respect to <span class="math">\\Pi</span> yields that <span class="math">\\Pi</span> has a <span class="math">2</span>-message <span class="math">\\varepsilon</span>-<span class="math">\\mathsf{IPP}</span> <span class="math">(\\mathsf{P},\\mathsf{V})</span>, with <span class="math">\\mathsf{V}</span>’s running time being <span class="math">(\\log(N))^{\\delta_{1}}\\cdot k^{\\delta_{2}}\\cdot(1/\\varepsilon)^{\\delta_{3}}</span> for constants <span class="math">\\delta_{1}=\\delta_{1}(\\alpha,\\beta),\\delta_{2},\\delta_{3}=\\delta_{3}(\\beta,\\gamma)&gt;0</span>.</p>

    <p class="text-gray-300">Set <span class="math">\\varepsilon=1/10</span> and <span class="math">k</span> such that the soundness error of <span class="math">(\\mathsf{P},\\mathsf{V})</span> is at most <span class="math">1/3</span>. Note that in this setting, <span class="math">\\mathsf{V}</span>’s running time is <span class="math">O(\\log(N)^{\\delta_{1}})=\\mathsf{poly}(\\log(N))</span>. This is a contradiction to Lemma 5.2. ∎</p>

    <h6 id="sec-81" class="text-base font-medium mt-4">Remark 5.6.</h6>

    <p class="text-gray-300">We remark that the proof of Theorem 5.1 actually establishes the stronger result that <span class="math">\\Pi</span> cannot even have an <span class="math">\\mathsf{HV\\text{-}ESZKPP}</span> protocol in which the verifier runs in time <span class="math">N^{o(1)}\\cdot\\mathsf{poly}(k,1/\\varepsilon)</span>. Indeed, assuming</p>

    <p class="text-gray-300">a simulator with expected running time <span class="math">N^{o(1)} \\cdot^{\\alpha} \\cdot k^{\\beta} \\cdot (1 / \\varepsilon)^{\\gamma}</span>, Lemma 5.3 yields that <span class="math">\\Pi</span> has a <span class="math">2 \\varepsilon</span>-IPP in which the verifier runs in <span class="math">N^{o(1)}</span> time, in contradiction to Lemma 5.2.</p>

    <h2 id="sec-82" class="text-2xl font-bold">5.2 MAP <span class="math">\\nsubseteq</span> ESZKPP, assuming Circuit Lower Bounds</h2>

    <p class="text-gray-300">We show that there exists a property <span class="math">\\Pi \\in \\mathsf{MAP}\\big[\\mathsf{poly}(\\log (N),k,1 / \\varepsilon)\\big]</span> but, assuming certain circuit lower bounds, it holds that <span class="math">\\Pi \\notin \\mathsf{HV - ESZKPP}\\big[\\mathsf{poly}(\\log (N),k,1 / \\varepsilon)\\big]</span></p>

    <p class="text-gray-300">Let <span class="math">t\\text{-}\\mathsf{DNF}_{\\oplus}</span> refer to depth 3 circuits, whose output gate is an bounded fan-in OR gate, intermediate level are composed of fan-in <span class="math">t</span> AND gates and third layer is composed of (unbounded fan-in) parity gates. The size of a <span class="math">t\\text{-}\\mathsf{DNF}_{\\oplus}</span> gate is the fan-in of its top gate. A randomized <span class="math">t\\text{-}\\mathsf{DNF}_{\\oplus}</span> simply refers to a distribution over <span class="math">t\\text{-}\\mathsf{DNF}_{\\oplus}</span> circuits. We say that a randomized <span class="math">t\\text{-}\\mathsf{DNF}_{\\oplus}</span> circuit <span class="math">C: \\{0,1\\}^k \\to \\{0,1\\}</span> computes a function <span class="math">f</span> if for every <span class="math">x \\in \\{0,1\\}^k</span> it holds that <span class="math">\\operatorname*{Pr}[C(x) = f(x)] \\geq 2/3</span>.</p>

    <p class="text-gray-300">For any <span class="math">k \\in \\mathbb{N}</span> and strings <span class="math">x, y \\in \\{0,1\\}^k</span>, we define <span class="math">\\mathsf{DISJ}_k(x,y) = 1</span> if for every <span class="math">i \\in [k]</span> it holds that either <span class="math">x_i = 0</span> or <span class="math">y_i = 0</span> and <span class="math">\\mathsf{DISJ}_k(x,y) = 0</span> otherwise. The following conjecture states that small randomized <span class="math">\\mathsf{DNF}_{\\oplus}</span> circuits cannot compute <span class="math">\\mathsf{DISJ}</span>.</p>

    <p class="text-gray-300"><strong>Conjecture 5.7.</strong> There exists a constant <span class="math">\\delta &amp;gt; 0</span> such that every randomized <span class="math">t</span>-<span class="math">\\mathsf{DNF}_{\\oplus}</span> of size <span class="math">S</span> that computes <span class="math">\\mathsf{DISJ}_k</span> it holds that <span class="math">\\min(t, \\log(S)) = \\Omega(k^{\\delta})</span>.</p>

    <p class="text-gray-300">We remark that a randomized <span class="math">t</span>-<span class="math">\\mathsf{DNF}_{\\oplus}</span> circuit of size <span class="math">S</span> yields an Arthur-Merlin communication complexity with complexity <span class="math">\\log(S) + t</span>.²¹ To the best of our knowledge, it is believed that the Arthur-Merlin communication complexity of disjointness is believed to be <span class="math">\\Omega(k)</span> (which would imply Conjecture 5.7 with <span class="math">\\delta = 1</span>). We mention that proving any non-trivial Arthur-Merlin communication complexity lower bound is a notorious open problem.</p>

    <p class="text-gray-300"><strong>Theorem 5.8.</strong> If Conjecture 5.7 holds, then <span class="math">\\mathsf{MAP}\\big[\\mathsf{poly}(\\log (N),k,1 / \\varepsilon)\\big] \\not\\subseteq \\mathsf{HV - ESZKPP}\\big[\\mathsf{poly}(\\log (N),k,1 / \\varepsilon)\\big]</span>.</p>

    <p class="text-gray-300">We begin by an outline of the proof. Our main tool will be a binary linear error-correcting <span class="math">C: \\{0,1\\}^k \\to \\{0,1\\}^n</span>, with constant relative distance and almost-linear²² blocklength, which is also locally testable and locally decodable. A code <span class="math">C: \\{0,1\\}^k \\to \\{0,1\\}^n</span> is locally testable if there exists a procedure that makes only few queries to a word <span class="math">w \\in \\{0,1\\}^n</span>, and determines with high probability if it is a codeword (i.e., if <span class="math">w = C(x)</span> for some message <span class="math">x \\in \\{0,1\\}^k</span>) or far from the code (see Definition 5.9 for the formal definition). A code is locally decodable if there exists a procedure that takes as input an index <span class="math">i \\in [k]</span> and a word <span class="math">w \\in \\{0,1\\}^n</span> close to some codeword <span class="math">C(x)</span>, makes only few queries to <span class="math">w</span>, and outputs <span class="math">x_i</span> with high probability (see Definition 5.10 for the formal definition).</p>

    <p class="text-gray-300">The property that we consider is the Code Intersection (CI) property. This property consists of pairs of codewords <span class="math">(C(x), C(y))</span>, coded under the foregoing code, such that <span class="math">\\mathsf{DISJ}(x, y) = 0</span> (i.e., <span class="math">x</span> and <span class="math">y</span> intersect). This problem was previously considered by Gur and Rothblum [GR16] who showed that it has a very efficient MAP (we re-prove this fact since we use a slightly different code).</p>

    <p class="text-gray-300">²¹In contrast, note that there is a very simple CNF formula for computing DISJ.</p>

    <p class="text-gray-300">²²Note that we are using the term “linear” in two different ways. First, the code is a linear function of the message. Second, the length of the codeword is almost linear in the length of messages.</p>

    <p class="text-gray-300">28</p>

    <p class="text-gray-300">Indeed, it is easy to see that CI has a very efficient MAP. Merlin simply sends to Arthur the index <span class="math">i</span> on which <span class="math">x</span> and <span class="math">y</span> intersect. Arthur, using the local testability, will verify that the input is close to a pair of codewords, and then locally decodes <span class="math">x_{i}</span> and <span class="math">y_{i}</span>. Arthur accepts iff <span class="math">x_{i}=y_{i}=1</span>. This proof of proximity, however, reveals a lot to Arthur (and in particular is not zero-knowledge). Specifically, Arthur learns the index of the intersection. As a matter of fact, this is not a coincidence. We show that, assuming that Conjecture 5.7 holds, the property CI does not have any honest-verifier zero-knowledge IPP with poly-logarithmic complexity.</p>

    <p class="text-gray-300">To see how we prove the lower bound, consider the promise problem Code Disjointness (CD), in which the YES instances are pairs of codewords <span class="math">(C(x),C(y))</span> such that <span class="math">\\textsf{DISJ}(x,y)=1</span>, and NO instances are pairs of codewords <span class="math">(C(x),C(y))</span> such that <span class="math">\\textsf{DISJ}(x,y)=0</span>. Note that NO instances of CD are in the property CI. Moreover, YES instances of CD are <span class="math">\\delta(C)/2</span>-far from CI, where <span class="math">\\delta(C)</span> is the relative distance of the code <span class="math">C</span>.</p>

    <p class="text-gray-300">Assume, toward a contradiction, that CI has an honest-verifier statistical zero-knowledge IPP with poly-logarithmic complexity. We argue that this implies that the complement promise problem of CD has a constant-round IPP. The latter fact basically follows from the fact that entropy difference (ED) is complete for the class of promise problems having a statistical zero-knowledge proof, and is itself closed under complement.</p>

    <p class="text-gray-300">Thus, we have constructed an IPP which accepts inputs from CD and rejects inputs from CI. Using a result of Rothblum et-al. <em>[x20]</em>, we can derive from this IPP a quasi-polynomial size randomized DNF for the same promise problem. We further observe that since the code <span class="math">C</span> is a linear code, we have obtained a circuit that computes the disjointness function on input <span class="math">(x,y)</span> by first applying a linear transformation and then the aforementioned randomized DNF. Or in other words, a quasi-polynomial sized <span class="math">\\textsf{DNF}_{\\oplus}</span> circuit. This contradicts Conjecture 5.7.</p>

    <p class="text-gray-300">We proceed to the formal proof of Theorem 5.8. We begin with definitions and notations. An error-correcting code is an injective function <span class="math">C:\\{0,1\\}^{k}\\to\\{0,1\\}^{n}</span>. The code <span class="math">C</span> is said to have relative distance <span class="math">\\delta(C)</span> if for any <span class="math">x\\neq x^{\\prime}\\in\\{0,1\\}^{k}</span> it holds that <span class="math">\\Delta(C(x),C(x^{\\prime}))\\geq\\delta(C)</span>. Throughout this work we deal with (uniform) algorithms, and so we will need (families of) error-correcting codes. Formally, for a parameters <span class="math">k=k(\\ell)\\geq 1</span> and <span class="math">=n(\\ell)\\geq k(\\ell)</span> we define an ensemble of error correcting code as an ensemble <span class="math">C=\\left(C_{\\ell}:\\{0,1\\}^{k(\\ell)}\\to\\{0,1\\}^{n(\\ell)}\\right)_{\\ell\\in\\mathbb{N}}</span> of error-correcting codes. An ensemble of error correcting codes <span class="math">C=(C_{\\ell})_{\\ell\\in\\mathbb{N}}</span> is said to have relative distance <span class="math">\\delta(C)</span> if for all sufficiently large <span class="math">\\ell</span>, each code <span class="math">C_{\\ell}</span> in the ensemble has relative distance <span class="math">\\delta(C)</span>.</p>

    <p class="text-gray-300">We next formally define locally testable and decodable codes.</p>

    <h6 id="sec-83" class="text-base font-medium mt-4">Definition 5.9 ((strong) locally testable codes (c.f. <em>[x11]</em>)).</h6>

    <p class="text-gray-300">Let <span class="math">t\\colon\\mathbb{N}\\to\\mathbb{N}</span>. A ensemble of error-correcting code <span class="math">C=\\left(C_{\\ell}:\\{0,1\\}^{k(\\ell)}\\to\\{0,1\\}^{n(\\ell)}\\right)_{\\ell\\in\\mathbb{N}}</span> is <span class="math">t</span>-locally-testable if there exists a probabilistic algorithm (tester) <span class="math">\\mathsf{T}</span> that, given explicit input <span class="math">\\ell</span> and oracle access to <span class="math">w\\in\\{0,1\\}^{n(\\ell)}</span> , runs in time <span class="math">t(\\ell)</span>, and satisfies the following.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Completeness: For every <span class="math">x\\in\\{0,1\\}^{k(\\ell)}</span> it holds that <span class="math">\\Pr[T^{C_{\\ell}(x)}(\\ell)=1]=1</span>.</li>

      <li>Soundness: For every <span class="math">w\\in\\{0,1\\}^{n(\\ell)}</span> it holds that <span class="math">\\Pr[T^{w}(\\ell)=0]\\geq\\Omega(\\Delta(w,\\operatorname{Im}(C_{\\ell})))</span>, where <span class="math">\\Delta(w,\\operatorname{Im}(C_{\\ell}))</span> is the relative distance of <span class="math">w</span> from the code.</li>

    </ul>

    <p class="text-gray-300">29</p>

    <h6 id="sec-84" class="text-base font-medium mt-4">Definition 5.10 (locally decodable codes (c.f. <em>[x13]</em>)).</h6>

    <p class="text-gray-300">Let <span class="math">t\\colon\\mathbb{N}\\to\\mathbb{N}</span>. A ensemble of error-correcting code <span class="math">C=\\big{(}C_{\\ell}:\\{0,1\\}^{k(\\ell)}\\to\\{0,1\\}^{n(\\ell)}\\big{)}_{\\ell\\in\\mathbb{N}}</span> is <span class="math">t</span>-locally-decodable if there exists a constant <span class="math">\\delta_{\\mathsf{radius}}\\in(0,\\delta(C)/2)</span> and a probabilistic algorithm (decoder) <span class="math">\\mathsf{D}</span> that, given oracle access to <span class="math">w\\in\\{0,1\\}^{n}</span> and explicit inputs <span class="math">i\\in[k]</span> and <span class="math">\\ell\\in\\mathbb{N}</span>, runs in time <span class="math">t(\\ell)</span> and satisfies the following.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Completeness: For every <span class="math">i\\in[k(\\ell)]</span> and <span class="math">x\\in\\{0,1\\}^{k(\\ell)}</span>, it holds that <span class="math">\\Pr\\big{[}D^{C(x)}(i)=x_{i}\\big{]}=1</span>.</li>

      <li>Soundness: For every <span class="math">i\\in[k(\\ell)]</span> and every <span class="math">w\\in\\{0,1\\}^{n(\\ell)}</span> with <span class="math">\\Delta(w,C(x))\\leq\\delta_{\\mathsf{radius}}</span>, it holds that <span class="math">\\Pr[D^{w}(i)=x_{i}]\\geq 2/3</span>.</li>

    </ul>

    <p class="text-gray-300">We use the following well-known fact.</p>

    <h6 id="sec-85" class="text-base font-medium mt-4">Lemma 5.11.</h6>

    <p class="text-gray-300">There exists an ensemble of binary linear codes <span class="math">C=\\big{(}C_{\\ell}:\\{0,1\\}^{k(\\ell)}\\to\\{0,1\\}^{n(\\ell)}\\big{)}_{\\ell\\in\\mathbb{N}}</span>, for <span class="math">k(\\ell)=\\tilde{O}(\\ell)</span> and <span class="math">n(\\ell)\\leq k(\\ell)^{1.01}</span>, whose relative distance is some constant <span class="math">\\delta&gt;0</span> and that is <span class="math">\\mathsf{polylog}(\\ell)</span>-locally-testable and <span class="math">\\mathsf{polylog}(\\ell)</span>-locally-decodable.</p>

    <p class="text-gray-300">See Appendix B.3 for a sketch of the construction (which is basically the concatenation of the low degree extension code, over a field of poly-logarithmic size, with a good binary code).</p>

    <p class="text-gray-300">Using Lemma 5.11, we can now define the property Code Intersection.</p>

    <h6 id="sec-86" class="text-base font-medium mt-4">Definition 5.12 (Code Intersection).</h6>

    <p class="text-gray-300">Let <span class="math">C=(C_{\\ell})_{\\ell\\in\\mathbb{N}}</span> be the code guaranteed to exist by Lemma 5.11. For <span class="math">\\ell\\in\\mathbb{N}</span>, let</p>

    <p class="text-gray-300"><span class="math">\\mathsf{Cl}_{\\ell}=\\Big{\\{}\\big{(}C_{\\ell}(x),C_{\\ell}(y)\\big{)}\\colon x,y\\in\\{0,1\\}^{k(\\ell)}\\text{ such that }\\mathsf{DISJ}_{k(\\ell)}(x,y)=0\\Big{\\}}.</span></p>

    <p class="text-gray-300">We define the <span class="math">\\mathsf{Code}</span> <span class="math">\\mathsf{Intersection}</span> property as <span class="math">\\mathsf{Cl}=(\\mathsf{Cl}_{\\ell},[2n(\\ell)],\\{0,1\\})_{\\ell\\in\\mathbb{N}}</span>.</p>

    <p class="text-gray-300">The proof of Theorem 5.8 follows immediately from the next two lemmas, proven in Sections 5.2.1 and 5.2.2.</p>

    <h6 id="sec-87" class="text-base font-medium mt-4">Lemma 5.13.</h6>

    <p class="text-gray-300"><span class="math">\\mathsf{Cl}\\in\\mathsf{MAP}\\big{[}\\mathsf{poly}(\\log(N),k,1/\\varepsilon)\\big{]}.</span></p>

    <h6 id="sec-88" class="text-base font-medium mt-4">Lemma 5.14.</h6>

    <p class="text-gray-300">If Conjecture 5.7 holds, then <span class="math">\\mathsf{Cl}\\notin\\mathsf{HV\\text{-}ESZKPP}\\big{[}\\mathsf{poly}(\\log(N),k,1/\\varepsilon)\\big{]}.</span></p>

    <h4 id="sec-89" class="text-lg font-semibold mt-6">5.2.1 Proving Lemma 5.13</h4>

    <p class="text-gray-300">Consider the protocol <span class="math">(\\mathsf{P}_{\\mathsf{Cl}},\\mathsf{V}_{\\mathsf{Cl}})</span> from Fig. 4. Perfect completeness follows from the perfect completeness in the local testing and decoding procedures. We proceed to argue that soundness holds.</p>

    <p class="text-gray-300">Fix <span class="math">\\varepsilon&gt;0</span>, sufficiently large <span class="math">\\ell\\in\\mathbb{N}</span> and <span class="math">w=(w_{1},w_{2})\\in\\{0,1\\}^{2\\cdot n(\\ell)}</span> such that <span class="math">w</span> is <span class="math">\\varepsilon</span>-far from <span class="math">\\mathsf{Cl}_{\\ell}</span>. We assume without loss of generality that <span class="math">\\varepsilon&lt;\\delta_{\\mathsf{radius}}</span> (otherwise “reset” <span class="math">\\varepsilon</span> to <span class="math">\\delta_{\\mathsf{radius}}</span>). We consider two cases:</p>

    <p class="text-gray-300"><span class="math">\\Delta(w_{1},\\mathrm{Im}(C_{\\ell}))\\geq\\varepsilon/2</span> or <span class="math">\\Delta(w_{2},\\mathrm{Im}(C_{\\ell}))\\geq\\varepsilon/2</span>: Let <span class="math">j\\in\\{1,2\\}</span> such that <span class="math">\\Delta(w_{j},\\mathrm{Im}(C_{\\ell}))\\geq\\epsilon/2</span>. By the soundness condition of the tester <span class="math">\\mathsf{T}</span>, it holds that</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mathsf{V}_{\\mathsf{Cl}}{}^{w}(\\varepsilon,n(\\ell))\\text{ rejects}]\\geq\\Pr[\\mathsf{T}^{w_{j}}(\\ell)=0]\\geq\\Omega(\\Delta(w_{j},\\mathrm{Im}(C_{\\ell})))\\geq\\Omega(\\varepsilon/2).</span></p>

    <p class="text-gray-300">Prover's Input: A pair of strings  <span class="math">(w_{1},w_{2})\\in \\{0,1\\}^{2\\cdot n(\\ell)}</span>  and proximity parameter  <span class="math">\\varepsilon &amp;gt;0</span></p>

    <p class="text-gray-300">Verifier's Input:  <span class="math">\\ell, n(\\ell), \\varepsilon</span>  and oracle access to  <span class="math">(w_1, w_2)</span> .</p>

    <p class="text-gray-300">Let  <span class="math">C</span>  be the code ensemble from Lemma 5.11.</p>

    <p class="text-gray-300">Let  <span class="math">\\mathsf{T}</span>  be the tester from Definition 5.9 with respect to  <span class="math">C</span> .</p>

    <p class="text-gray-300">Let  <span class="math">\\delta_{\\mathrm{radius}}(C)</span>  and  <span class="math">\\mathsf{D}</span>  be the decoding radius and decoder, respectively, from Definition 5.10 with respect to  <span class="math">C</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{P}_{\\mathsf{CI}}</span>  finds  <span class="math">i\\in [k(\\ell)]</span>  such that  <span class="math">w = (C_{\\ell}(x),C_{\\ell}(y))</span>  for some  <span class="math">x,y\\in \\{0,1\\}^{k(\\ell)}</span>  and  <span class="math">x_{i} = y_{i}</span></li>

    </ol>

    <p class="text-gray-300">Sends  <span class="math">i</span>  to  <span class="math">\\mathsf{V}_{\\mathsf{CI}}</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{V}_{\\mathsf{CI}}</span>  acts as follows:</li>

    </ol>

    <p class="text-gray-300">(a) Set  <span class="math">\\varepsilon = \\min \\{\\varepsilon, 2\\delta_{\\mathrm{radius}}(C)\\}</span> . (b) Run  <span class="math">\\mathsf{T}^{w_1}(\\ell)</span>  and  <span class="math">\\mathsf{T}^{w_2}(\\ell)</span>  and reject if any of them rejects. (c) Accept if  <span class="math">\\mathsf{D}^{w_1}(i,\\ell) = \\mathsf{D}^{w_2}(i,\\ell) = 1</span> , and otherwise reject.</p>

    <p class="text-gray-300">Figure 4: The Code Intersection Protocol</p>

    <p class="text-gray-300"><span class="math">\\Delta (w_{1},\\mathrm{Im}(C_{\\ell}))\\leq \\varepsilon /2</span>  and  <span class="math">\\Delta (w_{2},\\mathrm{Im}(C_{\\ell}))\\leq \\varepsilon /2</span>  : Fix a cheating prover  <span class="math">\\widehat{\\mathsf{P}}</span>  . Assume without loss of generality that  <span class="math">\\widehat{\\mathsf{P}}</span>  is deterministic and let  <span class="math">i^{<em>}</span>  be the index it sends to  <span class="math">\\mathsf{V}_{\\mathsf{CI}}</span>  in step 1. Let  <span class="math">x,y\\in</span> <span class="math">\\{0,1\\}^{k(\\ell)}</span>  such that  <span class="math">\\Delta (w_1,C_\\ell (x))\\leq \\varepsilon /2</span>  and  <span class="math">\\Delta (w_{2},C_{\\ell}(y))\\leq \\varepsilon /2</span>  (such  <span class="math">x</span>  and  <span class="math">y</span>  are unique since  <span class="math">\\varepsilon \\leq \\delta_{\\mathrm{radius}}(C)</span>  ). Moreover, as  <span class="math">w</span>  is  <span class="math">\\varepsilon</span>  -far from  <span class="math">\\mathsf{Cl}_{\\ell}</span>  , it must be that either  <span class="math">x_{i^</em>} = 0</span>  or  <span class="math">y_{i^<em>} = 0</span>  . Observe that if  <span class="math">x_{i^</em>} = 0</span>  , then by the soundness of the decoding procedure, with probability  <span class="math">2 / 3</span>  , the decoder will output O in which case our verifier rejects. The case that  <span class="math">y_{i^*} = 0</span>  is analyzed similarly.</p>

    <p class="text-gray-300">Combining both conditions, it holds that  <span class="math">\\operatorname*{Pr}[\\mathsf{V}_{\\mathsf{CI}}^w (\\varepsilon ,n(\\ell))</span>  rejects]  <span class="math">\\geq \\min \\{\\Omega (\\varepsilon /2),1 / 3\\} = \\Omega (\\varepsilon)</span></p>

    <p class="text-gray-300">So far we have shown that the code intersection protocol (Fig. 4) has prefect completeness and soundness error  <span class="math">1 - O(\\varepsilon)</span> . To reduce the soundness error it suffices to have the verifier repeat its check  <span class="math">\\mathrm{poly}(k) / \\varepsilon</span>  times.[26] As shown in [GR16] this reduces the soundness error to  <span class="math">2^{-k}</span>  and so the resulting protocol is an  <span class="math">\\varepsilon</span> -MAP.</p>

    <p class="text-gray-300">Finally, it is easy to verify that the ultimate verifier run in time  <span class="math">\\mathrm{poly}(\\log (\\ell),k,1 / \\varepsilon)</span>  which, since the input length (i.e.,  <span class="math">2\\cdot n(\\ell)</span> ) is  <span class="math">\\mathrm{poly}(\\ell)</span> , is  <span class="math">\\mathrm{poly}(\\log (N),k,1 / \\varepsilon)</span> .</p>

    <p class="text-gray-300">We prove the contrapositive. Assume that  <span class="math">\\mathsf{CI} \\in \\mathsf{HV-ESZKPP}\\big[\\mathsf{poly}(\\log (N), k, 1 / \\varepsilon)\\big]</span>  and consider the promise problem of Code Disjointness.</p>

    <p class="text-gray-300">Definition 5.15 (Code Disjointness). For  <span class="math">\\ell \\in \\mathbb{N}</span> , let</p>

    <p class="text-gray-300"><span class="math">\\mathsf{CD}_{\\mathsf{YES},\\ell} = \\Big\\{\\big(C_{\\ell}(x),C_{\\ell}(y)\\big):x,y\\in \\{0,1\\}^{k(\\ell)}</span>  such that  <span class="math">\\mathsf{DISJ}_{k(\\ell)}(x,y) = 1\\Big\\}</span></p>

    <p class="text-gray-300"><span class="math">\\mathsf{CD}_{\\mathsf{NO},\\ell} = \\Big\\{\\big(C_{\\ell}(x),C_{\\ell}(y)\\big):x,y\\in \\{0,1\\}^{k(\\ell)}</span>  such that  <span class="math">\\mathsf{DISJ}_{k(\\ell)}(x,y) = 0\\Big\\} .</span></p>

    <p class="text-gray-300"><span class="math">CD=\\big{(}\\mathsf{CD}_{\\mathsf{YES},\\ell},\\mathsf{CD}_{\\mathsf{NO},\\ell}\\big{)}_{\\ell\\in\\mathbb{N}}.</span></p>

    <p class="text-gray-300">Note that the input length here is <span class="math">N=2\\cdot n(\\ell)=\\tilde{O}(\\ell^{1.01})</span>. Hence, the query complexity and communication complexity of the <span class="math">\\mathsf{IPP}</span> are <span class="math">\\mathsf{poly}(\\log(\\ell),k,1/\\varepsilon)</span>.</p>

    <p class="text-gray-300">We will use the zero-knowledge proof of proximity for <span class="math">\\mathsf{CI}</span> to design a randomized <span class="math">\\mathsf{DNF}_{\\oplus}</span> circuit that solves disjointness. Note that by definition <span class="math">\\mathsf{CD}_{\\mathsf{NO},\\ell}=\\mathsf{CI}_{\\ell}</span>.</p>

    <p class="text-gray-300">Observe that every string <span class="math">w\\in\\mathsf{CD}_{\\mathsf{YES},\\ell}</span> is <span class="math">\\delta(C)/2</span>-far from <span class="math">\\mathsf{CI}_{\\ell}</span>. Thus, an (honest-verifier) statistical zero-knowledge <span class="math">\\mathsf{IPP}</span> for <span class="math">\\mathsf{CI}</span> immediately yields an (honest-verifier) statistical zero-knowledge proof for the complement of <span class="math">\\mathsf{CD}</span>. Recall that in Section 5.1 we used that entropy difference (<span class="math">\\mathsf{ED}</span>) is complete for the class <span class="math">\\mathsf{SZK}</span>. Here, we will use this fact again, plus that there is an easy reduction from <span class="math">\\mathsf{ED}</span> to its complement, to show the following claim, proven in Appendix B.2.</p>

    <h6 id="sec-92" class="text-base font-medium mt-4">Claim 5.16.</h6>

    <p class="text-gray-300">The promise problem <span class="math">\\mathsf{CD}</span> has an interactive proof system with the following properties.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The verifier gets <span class="math">\\ell</span> as explicit input and oracle access to <span class="math">w\\in\\mathsf{CD}_{\\mathsf{YES},\\ell}\\cup\\mathsf{CD}_{\\mathsf{NO},\\ell}</span>.</li>

      <li>The completeness and soundness errors are both <span class="math">1/3</span>.</li>

      <li>The verifier’s running time is <span class="math">\\mathsf{poly}(\\log(\\ell))</span>.</li>

      <li>The parties exchange a constant number of messages.</li>

    </ol>

    <p class="text-gray-300">Using the Goldwasser-Sipser <em>[x10]</em> transformation from private-coin to public-coin interactive proofs and the Babai-Moran <em>[x3]</em> round reduction (see <em>[x21, Section 4]</em> for more details). We obtain a 2-message Arthur Merlin interactive proof, where the verifier runs in time <span class="math">\\mathsf{polylog}(\\ell)</span>. Applying an additional transformation from such proof-systems to randomized <span class="math">\\mathsf{DNF}</span>s due to <em>[x21]</em> (see also <em>[x16]</em>), we can obtain the following:</p>

    <h6 id="sec-93" class="text-base font-medium mt-4">Claim 5.17 (Based on <em>[x21, Section 4]</em>).</h6>

    <p class="text-gray-300">There exists a randomized <span class="math">\\mathsf{polylog}(\\ell)</span>-<span class="math">\\mathsf{DNF}</span> of size <span class="math">2^{\\mathsf{polylog}(\\ell)}</span> that computes (the promise problem) <span class="math">\\mathsf{CD}</span> for inputs of size <span class="math">2\\cdot n(\\ell)</span>.</p>

    <p class="text-gray-300">By observing that all <span class="math">w\\in\\mathsf{CD}_{YES,\\ell}\\cup\\mathsf{CD}_{\\mathsf{NO},\\ell}</span> are composed of two codewords, and the the code is a binary <em>linear</em> error correcting code, Claim 5.17 implies that there exists a randomized <span class="math">\\mathsf{polylog}(\\ell)</span>-<span class="math">\\mathsf{DNF}_{\\oplus}</span> circuit of size <span class="math">2^{\\mathsf{polylog}(\\ell)}</span> that computes <span class="math">\\mathsf{DISJ}_{k(\\ell)}</span>. This contradicts Conjecture 5.7. This concludes the proof of Section 5.2.1.</p>

    <h6 id="sec-94" class="text-base font-medium mt-4">Remark 5.18 (Relaxed Local Decoders and the <em>[x14]</em> Code).</h6>

    <p class="text-gray-300">We remark that for our result, as in <em>[x14]</em> it suffices for us to use <em>relaxed</em> local decoders (as put forth in <em>[BGH^{+}06]</em>). Loosely speaking, relaxed local decoding allows the decoder to refuse to decode if it notices that the word is corrupt.</p>

    <p class="text-gray-300">Given that, it is tempting to ask why we did not use the locally testable and (relaxed) decodable codes of Golderich et-al. <em>[x14]</em>. Indeed, their codes have <em>constant-query</em> whereas the code that we used requires poly-logarithmic query complexity. The only reason that we do not use the <em>[x14]</em> code is that the <em>computational</em> complexity of this code was not analyzed in <em>[x14]</em>.</p>

    <h2 id="sec-95" class="text-2xl font-bold">6 Computational ZK Proofs and Statistical ZK Arguments of Proximity</h2>

    <p class="text-gray-300">In this section we show that, assuming reasonable cryptographic assumptions (specifically, the existence of one-way or collision-resistant hash functions), a large class of IPPs and arguments</p>

    <p class="text-gray-300">of proximity <span class="math">^{27}</span> can be transformed to be zero-knowledge. As a consequence, using the results of [RVW13, RRR16, Kil92, BGH <span class="math">^{+}</span> 06, DR06] we obtain computational ZK proofs of proximity for small-depth and for small-space computations, and statistical ZK arguments of proximity for all of NP.</p>

    <p class="text-gray-300">Our transformation should be contrasted with an analogous transformation of Ben-Or et-al.  <span class="math">\\mathrm{[BGG^{+}88]}</span>  for classical public-coin interactive proofs (and arguments). Indeed, our transformation is based on the main idea of  <span class="math">\\mathrm{[BGG^{+}88]}</span> . However, in contrast to their result, our transformation does not apply to arbitrary public-coin IPPs. Rather, it only applies to such IPPs in which the queries that the verifier makes do not depend on messages sent by the prover. We say that such IPPs make prover-oblivious queries.</p>

    <p class="text-gray-300">Definition 6.1. We say that an IPP makes prover-oblivious queries if the input locations that the verifier queries are fully determined by its random coin tosses and the answers to previous queries that it made. That is, the queries do not depend on messages sent by the prover.</p>

    <p class="text-gray-300">Thus, an IPP with prover-oblivious queries can be thought of as a two steps process. In the first step the verifier can make queries to its input but it is not allowed to interact with the prover. In the second step, the parties are allowed to interact but the verifier is no longer allowed to query the input.[28]</p>

    <p class="text-gray-300">Interestingly (and crucially for our purpose), the general purpose IPPs and arguments of proximity in the literature are indeed public-coin and make only prover-oblivious queries. Using this fact, together with our transformation, we obtain general purpose ZK proofs of proximity.</p>

    <p class="text-gray-300">Our main transformation is summarized in the following two theorems.</p>

    <p class="text-gray-300">Theorem 6.2 (IPPs  <span class="math">\\rightarrow</span>  Computational ZK). Assume that one-way functions exist. Suppose that the language  <span class="math">\\mathcal{L}</span>  has an  <span class="math">\\ell</span> -message public-coin IPP with prover oblivious queries where the verifier runs in time  <span class="math">t_{\\mathsf{V}} = t_{\\mathsf{V}}(N,k,\\varepsilon)</span>  and the (honest) prover runs in time  <span class="math">t_{\\mathsf{P}} = t_{\\mathsf{P}}(N,k,\\varepsilon)</span> . Then,  <span class="math">\\mathcal{L}</span>  has an  <span class="math">(\\ell + \\mathrm{poly}(k))</span> -message computational ZKPP in which the prover runs in time  <span class="math">t_{\\mathsf{P}}&#x27;(N,k,\\varepsilon) := (t_{\\mathsf{P}}(N,k,\\varepsilon) + \\mathrm{poly}(t_{\\mathsf{V}}(n,k,\\varepsilon))) \\cdot \\mathrm{poly}(k)</span>  and the verifier runs in time  <span class="math">t_{\\mathsf{V}}&#x27;(N,k,\\varepsilon) := t_{\\mathsf{V}}(N,k,\\varepsilon) \\cdot \\mathrm{poly}(k)</span> . The simulation overhead (see discussion in Section 3) is  <span class="math">s(t_{\\widehat{\\mathsf{V}}}, N, k, \\varepsilon) = t_{\\widehat{\\mathsf{V}}} \\cdot \\mathrm{poly}(k)</span> , for cheating verifiers that run in time  <span class="math">t_{\\widehat{\\mathsf{V}}} = t_{\\widehat{\\mathsf{V}}}(N, k, \\varepsilon)</span> .</p>

    <p class="text-gray-300">Theorem 6.3 (Arguments of Proximity  <span class="math">\\rightarrow</span>  Statistical ZK Arguments). Assume that one-way functions exist. Suppose that the language  <span class="math">\\mathcal{L}</span>  has an  <span class="math">\\ell</span> -message public-coin interactive argument of proximity with prover oblivious queries where the verifier runs in time  <span class="math">t_{\\mathsf{V}} = t_{\\mathsf{V}}(N,k,\\varepsilon)</span>  and the (honest) prover runs in time  <span class="math">t_{\\mathsf{P}} = (N,k,\\varepsilon)</span> . Then,  <span class="math">\\mathcal{L}</span>  has an  <span class="math">(\\ell \\cdot \\mathrm{poly}(k))</span> -message statistical zero-knowledge argument of proximity in which the prover runs in time  <span class="math">t_{\\mathsf{P}}&#x27;(N,k,\\varepsilon) := (t_{\\mathsf{P}}(N,k,\\varepsilon) + \\mathrm{poly}(t_{\\mathsf{V}}(N,k,\\varepsilon))) \\cdot \\mathrm{poly}(k)</span>  and the verifier runs in time  <span class="math">t_{\\mathsf{V}}&#x27;(N,k,\\varepsilon) := t_{\\mathsf{V}}(N,k,\\varepsilon) \\cdot \\mathrm{poly}(k)</span> .</p>

    <p class="text-gray-300">Furthermore, if there exist collision-resistant hash functions, then the round complexity of the foregoing argument-system can be reduced to  <span class="math">(\\ell + O(1))</span> .</p>

    <p class="text-gray-300">Our proof of Theorems 6.2 and 6.3 is based on the idea, which originates in the work of Ben-Or et-al.  <span class="math">\\mathrm{[BGG^{+}88]}</span> , of having the prover commit to its messages rather than sending them in the clear. Since the protocol is public-coin the verifier can continue the interaction even though it does</p>

    <p class="text-gray-300">not see the actual contents of the prover's messages. After all commitments have been sent, the verifier only needs to check that there exist suitable decommitments that would have made the underlying IPP verifier accept. Since the commitment hides the contents of the messages, it cannot do so by itself and we would like to use the prover. At this point, one could try to naively argue that the residual statement is an NP statement, and so we can invoke a general purpose zero-knowledge protocol for NP (e.g., the classical [GMW91] protocol or the more efficient [IKOS09] protocol).[29]</p>

    <p class="text-gray-300">Herein arises the main difficulty with this approach. While the statement that the verifier needs to check at the end of the interaction does consist of an existential quantifier applied to a polynomial-time computable predicate, the latter predicate makes oracle access to the input  <span class="math">x</span>  and so we do not know how to express it as an NP statement. To resolve this difficulty, we restrict our attention to verifiers that make prover-oblivious queries. Thus, our verifier can actually make its queries before and we can construct a NP statement that refers to the actual values that it reads from the input. At this point we can indeed invoke a general purpose zero-knowledge protocol for NP and conclude the proof.</p>

    <p class="text-gray-300">Lastly, we remark that the specific flavor of soundness and zero-knowledge that we obtain depends on the commitment scheme we use. Specifically, instantiating the above approach with a computationally hiding and statistically binding commitment scheme yields a computational zero-knowledge proof of proximity, whereas a statistically hiding and computationally binding one yields a statistical zero-knowledge argument of proximity.</p>

    <p class="text-gray-300">As noted above, we need the following result from [IKOS09]:</p>

    <p class="text-gray-300">Lemma 6.4 ([IKOS09]). Let  <span class="math">\\mathcal{L} \\in \\mathsf{NP}</span>  with witness relation  <span class="math">R(\\cdot, \\cdot)</span>  that is computable in time  <span class="math">t</span> . If there exist one-way functions, then  <span class="math">\\mathcal{L}</span>  has a computational zero-knowledge proof in which the verifier runs in time  <span class="math">\\tilde{O}(t) \\cdot \\mathsf{poly}(k)</span>  and the prover runs in time  <span class="math">\\mathsf{poly}(N, k)</span> . For every (malicious) verifier running in time  <span class="math">T</span> , the simulator runs in time  <span class="math">(T + \\tilde{O}(t)) \\cdot \\mathsf{poly}(k)</span> . The number of rounds is  <span class="math">\\mathsf{poly}(k)</span> .</p>

    <p class="text-gray-300">Actually, since the running times are not specified in [IKOS09], we give an overview of the construction in Appendix B.4.</p>

    <p class="text-gray-300">We proceed to give a proof sketch of Theorem 6.2 and note that Theorem 6.3 is proved similarly (using statistically hiding commitments).[30]</p>

    <p class="text-gray-300">Proof Sketch of Theorem 6.2. The existence of one-way functions implies the existence of the following cryptographic protocols that we will use:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>A computationally hiding and statistically binding commitment scheme [Nao91, HILL99]. Moreover, after one initial set-up message from the receiver to the sender (where this setup can be re-used for a polynomial number of commitments), the commitment scheme is non-interactive: the sender only needs to send a single message to the receiver. (This commitment scheme will be used to derive the first part of Theorem 6.2.)</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Computational zero-knowledge proofs for any language in NP in which the verifier runs in time that is almost linear in the complexity of the witness relation (see Lemma 6.4).</li>

    </ul>

    <p class="text-gray-300">Let <span class="math">(\\mathsf{P},\\mathsf{V})</span> be an <span class="math">\\ell</span>-round public-coin IPP for <span class="math">\\mathcal{L}</span> with prover oblivious queries. We describe the construction of a computational zero-knowledge proof of proximity for <span class="math">\\mathcal{L}</span>. As alluded to above, the construction of a statistical zero-knowledge argument of proximity is similar, except that we replace the computationally hiding and statistically binding commitment with one that is statistically hiding and computationally binding, and replace the computatational zero-knowledge proof for NP with a statistical zero-knowledge argument.</p>

    <p class="text-gray-300">We proceed to describe the computational ZKPP <span class="math">(\\mathsf{P}^{\\prime},\\mathsf{V}^{\\prime})</span> for <span class="math">\\mathcal{L}</span>, on input <span class="math">x</span> of length <span class="math">N</span>, security parameter <span class="math">k</span> and proximity parameter <span class="math">\\varepsilon</span>. First, <span class="math">(\\mathsf{P}^{\\prime},\\mathsf{V}^{\\prime})</span> run the setup for the commitment scheme. After this initial step, the interaction consists of two main parts. In the first part, <span class="math">\\mathsf{P}^{\\prime}</span> and <span class="math">\\mathsf{V}^{\\prime}</span> emulate the interaction between <span class="math">\\mathsf{P}</span> and <span class="math">\\mathsf{V}</span>, where <span class="math">\\mathsf{P}^{\\prime}</span> only commits to the messages that <span class="math">\\mathsf{P}</span> would have sent. Since the protocol <span class="math">(\\mathsf{P},\\mathsf{V})</span> is a public-coin protocol, the verifier <span class="math">\\mathsf{V}^{\\prime}</span> can continue the interaction without actually knowing the contents of the messages that it receives (since <span class="math">\\mathsf{V}^{\\prime}</span> only needs to sample and send random coin tosses).</p>

    <p class="text-gray-300">Then, in the second part, <span class="math">\\mathsf{V}^{\\prime}</span> has already obtained commitments <span class="math">c_{1},\\ldots,c_{\\ell}</span> to some messages <span class="math">\\alpha_{1},\\ldots,\\alpha_{\\ell}</span> that <span class="math">\\mathsf{P}</span> would have sent. At this point we would like <span class="math">\\mathsf{P}^{\\prime}</span> to prove the statement:</p>

    <p class="text-gray-300"><span class="math">d_{i}</span> is a decommitment of <span class="math">c_{i}</span> with respect to message <span class="math">\\alpha_{i}</span>, for every <span class="math">i\\in[r]</span> and <span class="math">\\exists d_{1},\\ldots,d_{\\ell},\\alpha_{1},\\ldots,\\alpha_{\\ell}</span> such that <span class="math">\\mathsf{V}^{x}(N,\\varepsilon,k,(\\alpha_{1},\\beta_{1},\\ldots,\\alpha_{\\ell},\\beta_{\\ell}))=1.</span> (14)</p>

    <p class="text-gray-300">The statement in Equation 14 is almost, but not quite, an NP statement. The reason that we would like to phrase it as an NP statement is that by Lemma 6.4 (and using our assumption that there exist one-way functions), there exist very efficient (computational) zero knowledge proofs for any language in NP. Thus, we would like for <span class="math">\\mathsf{P}^{\\prime}</span> to prove Equation 14 to <span class="math">\\mathsf{V}^{\\prime}</span> using such a general purpose zero-knowledge proof-system.</p>

    <p class="text-gray-300">The problem that we encounter is that Equation 14 is not precisely an NP statement since it refers to oracle access to a given string <span class="math">x</span>. To overcome this problem, we use our assumption that <span class="math">\\mathsf{V}</span> makes prover oblivious queries. Hence, the queries that <span class="math">\\mathsf{V}</span> makes depend only on its own random coin tosses (and answers to previous queries that it has made), but not on the messages sent by <span class="math">\\mathsf{P}</span>. Denote by <span class="math">Q(x;\\rho)</span> the sequence of (possibly adaptive) queries that <span class="math">\\mathsf{V}</span> makes on input <span class="math">x</span> and random string <span class="math">\\rho</span>. Since <span class="math">Q(x,\\rho)</span> depends only on the randomness (and, possibly, on answers to previous queries to <span class="math">x</span>), the verifier <span class="math">\\mathsf{V}^{\\prime}</span> can sample <span class="math">\\rho</span> at random and generate this set. We can now re-state Equation 14 as:</p>

    <p class="text-gray-300"><span class="math">d_{i}</span> is a decommitment of <span class="math">c_{i}</span> with respect to message <span class="math">\\alpha_{i}</span>, for every <span class="math">i\\in[r]</span> and <span class="math">\\exists d_{1},\\ldots,d_{\\ell},\\alpha_{1},\\ldots,\\alpha_{\\ell}</span> such that <span class="math">\\mathsf{V}(x_{Q(x;\\rho)},(N,\\varepsilon,k),(\\alpha_{1},\\beta_{1},\\ldots,\\alpha_{\\ell},\\beta_{\\ell}))=1,</span> (15)</p>

    <p class="text-gray-300">which is in fact an NP relation, for which <span class="math">\\mathsf{P}^{\\prime}</span> has a witness. Therefore, using our assumption that one-way functions exist, there exists a computational zero-knowledge proof for Equation 15. <span class="math">\\mathsf{P}^{\\prime}</span></p>

    <p class="text-gray-300">and  <span class="math">\\mathsf{V}&#x27;</span>  engage in this proof-system and  <span class="math">\\mathsf{V}&#x27;</span>  accepts or rejects accordingly. (To actually run this proof-system  <span class="math">\\mathsf{V}&#x27;</span>  first shares  <span class="math">\\rho</span>  with  <span class="math">\\mathsf{P}&#x27;</span>  - but it does so only after they have completed the emulation of  <span class="math">(\\mathsf{P},\\mathsf{V})</span> .)</p>

    <p class="text-gray-300">Completeness of  <span class="math">(\\mathsf{P}&#x27;,\\mathsf{V}&#x27;)</span>  follows from the completeness of  <span class="math">(\\mathsf{P},\\mathsf{V})</span>  and the (perfect) completeness of the [IKOS09] zero-knowledge proof. The analysis of soundness and zero-knowledge is standard and we omit them from this preliminary version.</p>

    <p class="text-gray-300">We proceed to analyze the efficiency of the proof-system. We consider the three phases of interactions separately:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Setup Phase: First, the two parties set up the commitment scheme this step is done using a single round of communication and with complexity  <span class="math">\\mathsf{poly}(k)</span>  for both parties.</li>

      <li>Commitment Phase: Each bit that  <span class="math">\\mathsf{P}</span>  sends to  <span class="math">\\mathsf{V}</span>  in the original protocol is emulated by a (non-interactive) commitment (with a  <span class="math">\\mathsf{poly}(k)</span>  overhead). Messages sent from  <span class="math">\\mathsf{V}</span>  to  <span class="math">\\mathsf{P}</span>  are unchanged (recall that these refer to random coin tosses). Thus, the round complexity of this part is  <span class="math">\\ell</span>  and there is a  <span class="math">\\mathsf{poly}(k)</span>  overhead to the running time of both parties.</li>

      <li>Final Phase:  <span class="math">\\mathsf{V}&#x27;</span>  first sends the random string used by the underlying  <span class="math">\\mathsf{V}</span> . This introduces a  <span class="math">t_{\\mathsf{V}}(N, k, \\varepsilon)</span>  overhead to both parties. Then, both parties run the [IKOS09] protocol on an NP statement that can be verified in time  <span class="math">t = t_{\\mathsf{V}}(N, \\varepsilon, k) \\cdot \\mathsf{poly}(k)</span> . The [IKOS09] verifier runs in time that is  <span class="math">O(t) = t_{\\mathsf{V}}(N, \\varepsilon, k) \\cdot \\mathsf{poly}(k)</span>  whereas the [IKOS09] prover runs in time  <span class="math">\\mathsf{poly}(t) = \\mathsf{poly}(t_{\\mathsf{V}}(N, \\varepsilon, k), k)</span> . The number of rounds is  <span class="math">\\mathsf{poly}(k)</span> .</li>

    </ul>

    <p class="text-gray-300">□</p>

    <p class="text-gray-300">To obtain our ZKPP results, we will combine Theorem 6.2 with known results from the literature. Specifically, we will use the following results: (where throughout  <span class="math">N</span>  denotes the input length,  <span class="math">k</span>  the security parameter, and  <span class="math">\\varepsilon</span>  the security parameter).</p>

    <p class="text-gray-300">Theorem 6.5 ([RVW13]). Every language in logspace-uniform NC, has a polylog(N)-round public-coin  <span class="math">\\varepsilon</span> -IPP, for  <span class="math">\\varepsilon = N^{-1/2}</span> , with perfect completeness and  <span class="math">1/2</span>  soundness error. The verifier runs in time  <span class="math">N^{\\frac{1}{2} + o(1)}</span>  and the (honest) prover runs in time  <span class="math">\\mathsf{poly}(N)</span> . Furthermore, the verifier makes prover oblivious queries.</p>

    <p class="text-gray-300">Theorem 6.6 ([RRR16]). Let  <span class="math">\\mathcal{L}</span>  be a language that is computable in  <span class="math">\\mathsf{poly}(N)</span> -time and  <span class="math">O(N^{\\sigma})</span> -space, for some sufficiently small constant  <span class="math">\\sigma &amp;gt; 0</span> . Then  <span class="math">\\mathcal{L}</span>  has a constant-round public-coin  <span class="math">\\varepsilon</span> -IPP for  <span class="math">\\varepsilon = N^{-1/2}</span> , with perfect completeness and  <span class="math">1/2</span>  soundness error. The verifier runs in time  <span class="math">N^{1/2 + O(\\sigma)}</span>  and the (honest) prover runs in time  <span class="math">\\mathsf{poly}(N)</span> . Furthermore, the verifier makes prover oblivious queries.</p>

    <p class="text-gray-300">Theorem 6.7 ([Kil92, BGH <span class="math">^{+}</span> 06, DR06]). Assume that there exist collision-resistant hash functions. Then, every language in NP has a 4-message public-coin argument of  <span class="math">\\varepsilon</span> -proximity with perfect completeness and  <span class="math">1/2</span>  soundness error (for any value of  <span class="math">\\varepsilon &amp;gt; 0</span> ). The verifier runs in time  <span class="math">\\mathsf{poly}(\\log(N), k, 1/\\varepsilon)</span>  and the prover runs in time  <span class="math">\\mathsf{poly}(N, k)</span> . Furthermore, the verifier makes prover oblivious queries.</p>

    <p class="text-gray-300">We remark that the fact that the verifier makes prover oblivious queries is not stated explicitly in the above works but can be verified by inspection. Combining Theorems 6.5 and 6.6 with Theorem 6.2, and Theorem 6.7 with Theorem 6.3 we derive the following corollaries:</p>

    <p class="text-gray-300">Corollary 6.8 (Computational ZKPP for Bounded Depth).</p>

    <p class="text-gray-300">Assume that there exist one-way functions. Then, every language in logspace-uniform <span class="math">\\mathsf{NC}</span>, has a <span class="math">(\\mathsf{polylog}(N)+\\mathsf{poly}(k))</span>-round computational zero-knowledge proof of <span class="math">\\varepsilon</span>-proximity, for <span class="math">\\varepsilon=n^{-1/2}</span>. The verifier runs in time <span class="math">N^{\\frac{1}{2}+o(1)}\\cdot\\mathsf{poly}(k)</span> and the (honest) prover runs in time <span class="math">\\mathsf{poly}(N,k)</span>. The simulation overhead is <span class="math">s(t_{\\widehat{\\mathsf{Y}}},N,k,\\varepsilon)=t_{\\widehat{\\mathsf{Y}}}\\cdot\\mathsf{poly}(k)</span>, for (malicious) verifiers running in time <span class="math">t_{\\widehat{\\mathsf{Y}}}=t_{\\widehat{\\mathsf{Y}}}(N,k,\\varepsilon)</span>.</p>

    <h6 id="sec-96" class="text-base font-medium mt-4">Corollary 6.9 (Computational ZKPP for Bounded Space).</h6>

    <p class="text-gray-300">Assume that there exist one-way functions. Let <span class="math">\\mathcal{L}</span> be a language that is computable in <span class="math">\\mathsf{poly}(N)</span>-time and <span class="math">O(N^{\\sigma})</span>-space, for some sufficiently small constant <span class="math">\\sigma&gt;0</span>. Then, <span class="math">\\mathcal{L}</span> has a <span class="math">\\mathsf{poly}(k)</span>-message computational zero-knowledge proof of <span class="math">\\varepsilon</span>-proximity, for <span class="math">\\varepsilon=N^{-1/2}</span>. The verifier runs in time <span class="math">N^{1/2+O(\\sigma)}\\cdot\\mathsf{poly}(k)</span> and the (honest) prover runs in time <span class="math">\\mathsf{poly}(N,k)</span>. The simulation overhead is <span class="math">s(t_{\\widehat{\\mathsf{Y}}},N,k,\\varepsilon)=t_{\\widehat{\\mathsf{Y}}}\\cdot\\mathsf{poly}(k)</span>, for (malicious) verifiers running in time <span class="math">t_{\\widehat{\\mathsf{Y}}}=t_{\\widehat{\\mathsf{Y}}}(N,k,\\varepsilon)</span>.</p>

    <h6 id="sec-97" class="text-base font-medium mt-4">Corollary 6.10 (Statistical Zero-Knowledge Arguments).</h6>

    <p class="text-gray-300">Assume that there exist collision resistant hash functions. Then, every language in <span class="math">\\mathsf{NP}</span>, has a constant-round statistical zero-knowledge argument of <span class="math">\\varepsilon</span>-proximity, for every value of <span class="math">\\varepsilon&gt;0</span>. The verifier runs in time <span class="math">\\mathsf{poly}(\\log(N),k,1/\\varepsilon)</span> and the (honest) prover runs in time <span class="math">\\mathsf{poly}(N,k)</span>.</p>

    <h2 id="sec-98" class="text-2xl font-bold">Acknowledgments</h2>

    <p class="text-gray-300">We thank Oded Goldreich and Omer Paneth for useful discussions.</p>

    <p class="text-gray-300">The first and third author were supported in part by NSF Grants CNS-1350619 and CNS-1414119, Alfred P. Sloan Research Fellowship, Microsoft Faculty Fellowship, the NEC Corporation, a Steven and Renee Finn Career Development Chair from MIT. This work was also sponsored in part by the Defense Advanced Research Projects Agency (DARPA) and the U.S. Army Research Office under contracts W911NF-15-C-0226.</p>

    <p class="text-gray-300">The second author was partially supported by NSF MACS - CNS-1413920, DARPA IBM - W911NF-15-C-0236 and SIMONS Investigator award Agreement Dated 6-5-12.</p>

    <h2 id="sec-99" class="text-2xl font-bold">References</h2>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[ABG^{+}14] Adi Akavia, Andrej Bogdanov, Siyao Guo, Akshay Kamath, and Alon Rosen. Candidate weak pseudorandom functions in <span class="math">\\mathrm{AC}^{0}\\circ\\mathrm{MOD}_{2}</span>. In Innovations in Theoretical Computer Science, ITCS’14, Princeton, NJ, USA, January 12-14, 2014, pages 251–260, 2014.</li>

      <li>[AKNS00] Noga Alon, Michael Krivelevich, Ilan Newman, and Mario Szegedy. Regular languages are testable with a constant number of queries. SIAM J. Comput., 30(6):1842–1862, 2000.</li>

      <li>[BCF^{+}16] Eli Ben-Sasson, Alessandro Chiesa, Michael A. Forbes, Ariel Gabizon, Michael Riabzev, and Nicholas Spooner. On probabilistic checking in perfect zero knowledge. IACR Cryptology ePrint Archive, 2016:988, 2016.</li>

      <li>[BCS16] Eli Ben-Sasson, Alessandro Chiesa, and Nicholas Spooner. Interactive oracle proofs. In Theory of Cryptography - 14th International Conference, TCC 2016-B, Beijing, China, October 31 - November 3, 2016, Proceedings, Part II, pages 31–60, 2016.</li>

    </ul>

    <p class="text-gray-300">-</p>

    <p class="text-gray-300">[BCY91] Gilles Brassard, Claude Crépeau, and Moti Yung. Constant-round perfect zero-knowledge computationally convincing protocols. Theor. Comput. Sci., 84(1):23–52, 1991.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[BGG^{+}88] Michael Ben-Or, Oded Goldreich, Shafi Goldwasser, Johan Håstad, Joe Kilian, Silvio Micali, and Phillip Rogaway. Everything provable is provable in zero-knowledge. In Advances in Cryptology - CRYPTO ’88, 8th Annual International Cryptology Conference, Santa Barbara, California, USA, August 21-25, 1988, Proceedings, pages 37–56, 1988.</li>

      <li>[BGH^{+}06] Eli Ben-Sasson, Oded Goldreich, Prahladh Harsha, Madhu Sudan, and Salil P. Vadhan. Robust PCPs of proximity, shorter PCPs, and applications to coding. SIAM J. Comput., 36(4):889–974, 2006.</li>

      <li>[BM88] László Babai and Shlomo Moran. Arthur-Merlin games: A randomized proof system and a hierarchy of complexity classes. Journal of Computer and System Sciences, pages 254–276, 1988.</li>

      <li>[BY96] Mihir Bellare and Moti Yung. Certifying permutations: Noninteractive zero-knowledge based on any trapdoor permutation. J. Cryptology, 9(3):149–166, 1996.</li>

      <li>[CL17] Ran Canetti and Amit Lichtenberg, 2017. Unpublished manuscript.</li>

      <li>[CS10] Artur Czumaj and Christian Sohler. Testing expansion in bounded-degree graphs. Combinatorics, Probability & Computing, 19(5-6):693–709, 2010.</li>

      <li>[CS16] Gil Cohen and Igor Shinkar. The complexity of DNF of parities. In Proceedings of the 2016 ACM Conference on Innovations in Theoretical Computer Science, Cambridge, MA, USA, January 14-16, 2016, pages 47–58, 2016.</li>

      <li>[DORS08] Yevgeniy Dodis, Rafail Ostrovsky, Leonid Reyzin, and Adam D. Smith. Fuzzy extractors: How to generate strong keys from biometrics and other noisy data. SIAM J. Comput., 38(1):97–139, 2008.</li>

      <li>[DR06] Irit Dinur and Omer Reingold. Assignment testers: Towards a combinatorial proof of the PCP theorem. SIAM J. Comput., 36(4):975–1024, 2006.</li>

      <li>[EKR04] Funda Ergün, Ravi Kumar, and Ronitt Rubinfeld. Fast approximate probabilistically checkable proofs. Inf. Comput., 189(2):135–159, 2004.</li>

      <li>[FGL14] Eldar Fischer, Yonatan Goldhirsh, and Oded Lachish. Partial tests, universal tests and decomposability. In Innovations in Theoretical Computer Science, ITCS’14, Princeton, NJ, USA, January 12-14, 2014, pages 483–500, 2014.</li>

      <li>[FLS99] Uriel Feige, Dror Lapidot, and Adi Shamir. Multiple non-interactive zero knowledge proofs under general assumptions. SIAM Journal on Computing, 1999. Preliminary version in FOCS’90.</li>

    </ul>

    <p class="text-gray-300">[GG16] Oded Goldreich and Tom Gur. Universal locally testable codes. Electronic Colloquium on Computational Complexity (ECCC), 23:42, 2016.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[GGK15] Oded Goldreich, Tom Gur, and Ilan Komargodski. Strong locally testable codes with relaxed local decoders. In 30th Conference on Computational Complexity, CCC 2015, June 17-19, 2015, Portland, Oregon, USA, pages 1–41, 2015.</li>

      <li>[GGR98] Oded Goldreich, Shafi Goldwasser, and Dana Ron. Property testing and its connection to learning and approximation. J. ACM, 45(4):653–750, 1998.</li>

      <li>[GGR15] Oded Goldreich, Tom Gur, and Ron D. Rothblum. Proofs of proximity for context-free languages and read-once branching programs - (extended abstract). In Automata, Languages, and Programming - 42nd International Colloquium, ICALP 2015, Kyoto, Japan, July 6-10, 2015, Proceedings, Part I, pages 666–677, 2015.</li>

      <li>[GMR89] Shafi Goldwasser, Silvio Micali, and Charles Rackoff. The knowledge complexity of interactive proof systems. SIAM Journal on Computing, pages 186–208, 1989. Preliminary version in STOC’85.</li>

      <li>[GMW87] Oded Goldreich, Silvio Micali, and Avi Wigderson. How to play any mental game or a completeness theorem for protocols with honest majority. In Proceedings of the 19th Annual ACM Symposium on Theory of Computing (STOC), pages 218–229, 1987.</li>

      <li>[GMW91] Oded Goldreich, Silvio Micali, and Avi Wigderson. Proofs that yield nothing but their validity or all languages in NP have zero-knowledge proof systems. Journal of the ACM, pages 691–729, 1991. Preliminary version in FOCS’86.</li>

      <li>[Gol01] Oded Goldreich. Foundations of Cryptography: Basic Tools. Cambridge University Press, 2001.</li>

      <li>[Gol16] Oded Goldreich. Introduction to Property Testing. forthcoming (http://www.wisdom.weizmann.ac.il/~oded/pt-intro.html), 2016.</li>

      <li>[GR99] Oded Goldreich and Dana Ron. A sublinear bipartiteness tester for bounded degree graphs. Combinatorica, 19(3):335–373, 1999.</li>

      <li>[GR02] Oded Goldreich and Dana Ron. Property testing in bounded degree graphs. Algorithmica, 32(2):302–343, 2002.</li>

      <li>[GR11] Oded Goldreich and Dana Ron. On testing expansion in bounded-degree graphs. In Oded Goldreich, editor, Studies in Complexity and Cryptography. Miscellanea on the Interplay between Randomness and Computation - In Collaboration with Lidor Avigad, Mihir Bellare, Zvika Brakerski, Shafi Goldwasser, Shai Halevi, Tali Kaufman, Leonid Levin, Noam Nisan, Dana Ron, Madhu Sudan, Luca Trevisan, Salil Vadhan, Avi Wigderson, David Zuckerman, volume 6650 of Lecture Notes in Computer Science, pages 68–75. Springer, 2011.</li>

      <li>[GR13] Oded Goldreich and Ron D. Rothblum. Enhancements of trapdoor permutations. J. Cryptology, 26(3):484–512, 2013.</li>

    </ul>

    <p class="text-gray-300">[GR15] Tom Gur and Ron D. Rothblum, 2015. Unpublished observation. 1.1.1, 4.1</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[GR16] Tom Gur and Ron D. Rothblum. Non-interactive proofs of proximity. Computational Complexity, pages 1–109, 2016. 1, 4.1, 2, 5.2, 5.2.1, 5.18, 28, 31</li>

      <li>[GR17] Tom Gur and Ron D. Rothblum. A hierarchy theorem for interactive proofs of proximity. In Proceedings of the 2017 ACM Conference on Innovations in Theoretical Computer Science, Berkeley, CA, USA, January 9-11, 2016, 2017. 1, 5.1, 5.2, 5.2.2</li>

      <li>[GS89] Shafi Goldwasser and Michael Sipser. Private coins versus public coins in interactive proof systems. Advances in Computing Research: Randomness and Computation, pages 73–90, 1989. 5.2.2</li>

      <li>[GS92] Peter Gemmell and Madhu Sudan. Highly resilient correctors for polynomials. Inf. Process. Lett., 43(4):169–174, 1992. B.3</li>

      <li>[GS06] Oded Goldreich and Madhu Sudan. Locally testable codes and pcps of almost-linear length. J. ACM, 53(4):558–655, 2006. 5.9</li>

      <li>[GSV98] Oded Goldreich, Amit Sahai, and Salil P. Vadhan. Honest-verifier statistical zero-knowledge equals general statistical zero-knowledge. In Proceedings of the Thirtieth Annual ACM Symposium on the Theory of Computing, Dallas, Texas, USA, May 23-26, 1998, pages 399–408, 1998.</li>

      <li>[HILL99] Johan Håstad, Russell Impagliazzo, Leonid A. Levin, and Michael Luby. A pseudorandom generator from any one-way function. SIAM J. Comput., 28(4):1364–1396, 1999.</li>

      <li>[HNO^{+}09] Iftach Haitner, Minh Nguyen, Shien Jin Ong, Omer Reingold, and Salil Vadhan. Statistically hiding commitments and statistical zero-knowledge arguments from any one-way function. SIAM Journal on Computing, pages 1153–1218, 2009. Preliminary versions in FOCS ’06 and STOC ’07.</li>

      <li>[IKOS09] Yuval Ishai, Eyal Kushilevitz, Rafail Ostrovsky, and Amit Sahai. Zero-knowledge proofs from secure multiparty computation. SIAM J. Comput., 39(3):1121–1152, 2009. 6, 6.4, 6, 29, 6, B.4, 35, B.4</li>

      <li>[IW14] Yuval Ishai and Mor Weiss. Probabilistically checkable proofs of proximity with zero-knowledge. In Theory of Cryptography - 11th Theory of Cryptography Conference, TCC 2014, San Diego, CA, USA, February 24-26, 2014. Proceedings, pages 121–145, 2014.</li>

      <li>[Kil92] Joe Kilian. A note on efficient zero-knowledge proofs and arguments (extended abstract). In Proceedings of the 24th Annual ACM Symposium on Theory of Computing (STOC), pages 723–732, 1992. 1.1.2, 6, 6.7, 32</li>

      <li>[KR15] Yael Tauman Kalai and Ron D. Rothblum. Arguments of proximity - [extended abstract]. In Advances in Cryptology - CRYPTO 2015 - 35th Annual Cryptology Conference, Santa Barbara, CA, USA, August 16-20, 2015, Proceedings, Part II, pages 422–442, 2015. 1, 27, 32</li>

    </ul>

    <p class="text-gray-300">[KS11] Satyen Kale and C. Seshadhri. An expansion tester for bounded degree graphs. SIAM J. Comput., 40(3):709–720, 2011.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[KT00] Jonathan Katz and Luca Trevisan. On the efficiency of local decoding procedures for error-correcting codes. In Proceedings of the Thirty-Second Annual ACM Symposium on Theory of Computing, May 21-23, 2000, Portland, OR, USA, pages 80–86, 2000.</li>

      <li>[Nao91] Moni Naor. Bit commitment using pseudorandomness. J. Cryptology, 4(2):151–158, 1991.</li>

      <li>[NS10] Asaf Nachmias and Asaf Shapira. Testing the expansion of a graph. Inf. Comput., 208(4):309–314, 2010.</li>

      <li>[NY89] Moni Naor and Moti Yung. Universal one-way hash functions and their cryptographic applications. In Proceedings of the 21st Annual ACM Symposium on Theory of Computing (STOC), pages 33–43, 1989.</li>

      <li>[RRR16] Omer Reingold, Guy N. Rothblum, and Ron D. Rothblum. Constant-round interactive proofs for delegating computation. In Proceedings of the 48th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2016, Cambridge, MA, USA, June 18-21, 2016, pages 49–62, 2016.</li>

      <li>[RS96] Ronitt Rubinfeld and Madhu Sudan. Robust characterizations of polynomials with applications to program testing. SIAM J. Comput., 25(2):252–271, 1996.</li>

      <li>[RVW13] Guy N. Rothblum, Salil P. Vadhan, and Avi Wigderson. Interactive proofs of proximity: delegating computation in sublinear time. In Symposium on Theory of Computing Conference, STOC’13, Palo Alto, CA, USA, June 1-4, 2013, pages 793–802, 2013.</li>

      <li>[Sud95] Madhu Sudan. Efficient Checking of Polynomials and Proofs anf the Hardness of Approximation Problems, volume 1001 of Lecture Notes in Computer Science. Springer, 1995.</li>

      <li>[Vad99] Salil P. Vadhan. A Study of Statistical Zero-Knowledge Proofs. PhD thesis, Massachusetts Institute of Technology, Cambridge, MA, USA, 1999.</li>

      <li>[Vad12] Salil P. Vadhan. Pseudorandomness. Now Publishers Inc., Hanover, MA, USA, 2012.</li>

    </ul>

    <h2 id="sec-100" class="text-2xl font-bold">Appendix A Reducing HV-SZKPP to Entropy Difference</h2>

    <p class="text-gray-300">In this section we show how to reduce any property with honest-verifier zero-knowledge to an instance of Entropy Difference.</p>

    <h6 id="sec-101" class="text-base font-medium mt-4">Lemma A.1.</h6>

    <p class="text-gray-300">Suppose that a property <span class="math">\\Pi</span> has a honest-verifier statistical zero-knowledge <span class="math">\\varepsilon</span>-<span class="math">\\mathsf{IPP}</span> such that for every input length <span class="math">N</span> and security parameter <span class="math">k\\in\\mathbb{N}</span> the simulator’s expected running time is bounded by <span class="math">t_{\\mathsf{S}}(\\varepsilon,N,k)=t_{\\mathsf{S}}^{\\prime}(\\varepsilon,N)\\cdot\\mathsf{poly}(k)</span> and for every <span class="math">\\varepsilon</span> the function <span class="math">t_{\\mathsf{S}}^{\\prime}(\\varepsilon,\\cdot)</span> is monotone non-decreasing.</p>

    <p class="text-gray-300">Then, there is a reduction from <span class="math">\\Pi</span> to <span class="math">\\mathsf{ED}</span>. Specifically, the reduction is given <span class="math">\\varepsilon</span> and an input length <span class="math">N</span> and outputs two oracle aided circuits <span class="math">C_{0},C_{1}\\colon\\{0,1\\}^{m}\\to\\{0,1\\}^{n}</span> such that the following holds.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">(C_0, C_1)</span> is an instance of ED:</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">f \\in \\Pi \\implies \\mathrm{H}(C_0^f) \\geq \\mathrm{H}(C_1^f) + 1,</span></div>

    <div class="my-4 text-center"><span class="math-block">f \\text{ is } \\varepsilon\\text{-far from } \\Pi \\implies \\mathrm{H}(C_1^f) \\geq \\mathrm{H}(C_0^f) + 1.</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The reduction's running time is <span class="math">\\mathsf{poly}(t_{\\mathsf{S}}(\\varepsilon, N, \\mathsf{poly}(t_{\\mathsf{S}}&#x27;(\\varepsilon, N))))</span>.</li>

    </ol>

    <p class="text-gray-300">Note that the last item implies that for every <span class="math">x \\in \\{0,1\\}^m</span> and <span class="math">b \\in \\{0,1\\}</span>, computing <span class="math">C_b(x)</span> requires only <span class="math">\\mathsf{poly}(t_{\\mathsf{S}}(\\varepsilon, N, \\mathsf{poly}(t_{\\mathsf{S}}&#x27;(\\varepsilon, N))))</span> many oracle calls. The proof of the above lemma follows from the proof that entropy difference is SZK-hard [Vad99]. We only give sufficient details to demonstrate how to apply that proof to our setting.</p>

    <p class="text-gray-300">Proof sketch. Assume that <span class="math">(\\mathsf{P},\\mathsf{V})</span> is the <span class="math">\\varepsilon</span>-IPP for <span class="math">\\Pi</span> and let <span class="math">\\mathsf{S}</span> be the honest-verifier simulator for <span class="math">(\\mathsf{P},\\mathsf{V})</span> whose simulation deviation is <span class="math">\\mu(k) = \\mathrm{negl}(k)</span>. We assume for simplicity that <span class="math">t_{\\mathsf{S}}(N,k,\\varepsilon)</span> is a strict bound (and not only expected) on the running of <span class="math">\\mathsf{S}</span>. The proof can be extended to handle expected bounds as well (in fact, the proof in [Vad99] handles even weaker simulators). Assume without loss of generality that <span class="math">\\mathsf{P}</span> and <span class="math">\\mathsf{V}</span> send their messages in turns, <span class="math">\\mathsf{P}</span> sends the odd messages and <span class="math">\\mathsf{V}</span> the even ones. Let <span class="math">v(\\varepsilon,N,k)</span> be a bound on the number of messages sent by <span class="math">\\mathsf{V}</span> to <span class="math">\\mathsf{P}</span> for every <span class="math">f</span>. In addition, let <span class="math">c(\\varepsilon,N,k)</span> and <span class="math">r(\\varepsilon,N,k)</span> be bounds on the total communication (measures in bits) between <span class="math">\\mathsf{P}</span> and <span class="math">\\mathsf{V}</span> and the number of random bits accessed by the verifier, respectively. We now modify the proof system so that <span class="math">\\mathsf{V}</span> sends its random coins to <span class="math">\\mathsf{P}</span> in an additional message just before the end of the protocol. The total communication and number of messages sent from <span class="math">\\mathsf{V}</span> to <span class="math">\\mathsf{P}</span> now increases to <span class="math">c&#x27;(\\varepsilon,N,k) = c(\\varepsilon,N,k) + r(\\varepsilon,N,k)</span> and <span class="math">v&#x27;(\\varepsilon,N,k) = v(\\varepsilon,N,k) + 1</span>, respectively. <span class="math">\\mathsf{S}</span> is modified to simulate the additional last message as well, without increasing its simulation deviation (this is possible since <span class="math">\\mathsf{S}</span> was supposed to simulate <span class="math">\\mathsf{V}</span>'s random coins anyway).</p>

    <p class="text-gray-300">Fix <span class="math">\\varepsilon</span> and <span class="math">N</span> and let <span class="math">k&#x27; \\in \\mathbb{N}</span> such that <span class="math">\\mu(k&#x27;) \\leq \\min\\left\\{1 / v&#x27;(\\varepsilon, N, k&#x27;) \\cdot c&#x27;(\\varepsilon, N, k&#x27;), 1 / 4 - 2^{-40}\\right\\}</span> and the completeness and soundness errors of <span class="math">(\\mathsf{P}, \\mathsf{V})</span> are at most <span class="math">2^{-40}</span>. Note that it suffices to take <span class="math">k&#x27; = \\mathsf{poly}(t_{\\mathsf{S}}&#x27;(\\varepsilon, N))</span> (i.e., a fixed polynomial for all <span class="math">\\varepsilon</span> and <span class="math">N</span>): It holds that <span class="math">v&#x27;(\\varepsilon, N, k&#x27;) \\cdot c&#x27;(\\varepsilon, N, k&#x27;) \\leq t_{\\mathsf{S}}^2(\\varepsilon, N, k&#x27;) = t_{\\mathsf{S}}&#x27;^2(\\varepsilon, N) \\cdot \\mathsf{poly}(k&#x27;)</span>. Thus, we can take <span class="math">k&#x27;</span> such that <span class="math">\\mu&#x27;(k&#x27;) \\leq 1 / t_{\\mathsf{S}}&#x27;^2(\\varepsilon, N)</span>, for some negligible function <span class="math">\\mu&#x27;(k&#x27;) = \\mu(k&#x27;) \\cdot \\mathsf{poly}(k&#x27;)</span>. Since <span class="math">t_{\\mathsf{S}}&#x27;(\\varepsilon, N)</span> is monotone non-decreasing in <span class="math">N</span>, taking <span class="math">k&#x27; = \\mathsf{poly}(t_{\\mathsf{S}}&#x27;(\\varepsilon, N))</span> guarantee the required condition for large enough (depending on <span class="math">\\mu</span>) <span class="math">N</span> (for simplicity, we ignore shorter inputs that can be solved via brute-force by the verifier).</p>

    <p class="text-gray-300">Finally, let <span class="math">S_i^f</span> be the random variable distributed according to the first <span class="math">i</span> messages in the output of a random execution of <span class="math">\\mathsf{S}^f(\\varepsilon, N, k&#x27;)</span>. In the following we remove <span class="math">\\varepsilon</span>, <span class="math">N</span> and <span class="math">k&#x27;</span> from the notation.</p>

    <p class="text-gray-300">Constructing <span class="math">C_0</span> and <span class="math">C_1</span>. Define <span class="math">X = S_2^f \\otimes S_4^f \\otimes \\dots \\otimes S_{2v&#x27;}^f</span>. Similarly, define <span class="math">Y_1</span> to be <span class="math">Y_1 = S_1^f \\otimes S_3^f \\otimes \\dots \\otimes S_{2v&#x27; - 1}^f</span> and define <span class="math">Y_2</span> to be the uniform distribution on <span class="math">r - 7</span> bits. Furthermore, define <span class="math">Y_3</span> as follows: run <span class="math">\\mathsf{S}^f 8 \\ln (c&#x27;v&#x27; + 2)</span> times independently; if the verifier rejects in the majority of the transcripts obtained, output <span class="math">c&#x27;v&#x27; + 2</span> random bits; otherwise, output the empty string. Define <span class="math">Y = Y_1 \\otimes Y_2 \\otimes Y_3</span>. Finally, the circuits <span class="math">C_0</span> and <span class="math">C_1</span> take as input random coins to sample and output <span class="math">x \\gets X</span> and <span class="math">y \\gets Y</span>, respectively. Since we require that the input (resp., output) lengths of <span class="math">C_0</span> and <span class="math">C_1</span> will be equal, we pad the shorter input (resp., output) with redundant random coins (resp., zeros).</p>

    <p class="text-gray-300">33Recall that <span class="math">P\\otimes Q</span> stands for the product distribution of <span class="math">P</span> and <span class="math">Q</span></p>

    <p class="text-gray-300">34Let <span class="math">m_X</span> and <span class="math">n_Y</span> denote the input and output lengths of <span class="math">X</span>, respectively. Let <span class="math">m_Y, n_Y</span> be similarly defined. For example, if <span class="math">m_X &amp;lt; m_Y</span> and <span class="math">n_X &amp;lt; n_Y</span> we can modify <span class="math">X</span> as follows: sample <span class="math">x \\gets X</span> using part of the given <span class="math">m_Y</span> random</p>

    <p class="text-gray-300">Analysis.</p>

    <p class="text-gray-300">That <span class="math">(C_{0},C_{1})</span> is an instance of Entropy Difference (Item 1) follows from <em>[x23, Claims 3.3.14 and 3.3.15]</em>. The reduction’s running time (Item 2) follows from the constructions of <span class="math">C_{0}</span> and <span class="math">C_{1}</span>. ∎</p>

    <h2 id="sec-102" class="text-2xl font-bold">Appendix B Missing Proofs</h2>

    <h3 id="sec-103" class="text-xl font-semibold mt-8">B.1 Proving Lemma 5.3</h3>

    <p class="text-gray-300">The proof of Lemma 5.3, sketch of which is given below, immediately follows from Lemmas 2.15 and A.1.</p>

    <h6 id="sec-104" class="text-base font-medium mt-4">Proof sketch of Lemma 5.3.</h6>

    <p class="text-gray-300">Both the verifier and the prover will run the reduction form Lemma A.1 to get two distributions encoded by oracle-aided circuits <span class="math">(C_{0},C_{1})</span>. They will then run the protocol from Lemma 2.15 with respect to these distributions. Since the latter is a sample-access protocol the verifier can indeed run it using only oracle access to its input <span class="math">f</span>.</p>

    <p class="text-gray-300">The running time of the reduction implies that the input and outputs sizes of <span class="math">C_{0}</span> and <span class="math">C_{1}</span> are <span class="math">\\poly(t_{\\mathsf{S}}(\\varepsilon,N,\\poly(t_{\\mathsf{S}}^{\\prime}(\\varepsilon,N))))</span>. By Lemma 2.15 the running time of the verifier is thus <span class="math">\\poly(t_{\\mathsf{S}}(\\varepsilon,N,\\poly(t_{\\mathsf{S}}^{\\prime}(\\varepsilon,N))),k)</span>, as required.</p>

    <p class="text-gray-300">Zero-knowledge follows from similar arguments to the ones made above. ∎</p>

    <h3 id="sec-105" class="text-xl font-semibold mt-8">B.2 Proving Claim 5.16</h3>

    <p class="text-gray-300">The proof of Claim 5.16 follows similar lines to that of Lemma 5.3.</p>

    <h6 id="sec-106" class="text-base font-medium mt-4">Proof sketch of Claim 5.16.</h6>

    <p class="text-gray-300">Both the verifier and the prover will run the reduction form Lemma A.1 with respect to the property <span class="math">\\mathsf{Cl}</span> and proximity parameter <span class="math">\\delta(C)/2</span> to get two distributions encoded by oracle-aided circuits <span class="math">(C_{0},C_{1})</span>. If <span class="math">w\\in\\mathsf{CD}_{\\mathsf{YES},\\ell}</span> then <span class="math">w</span> is <span class="math">\\delta(C)/2</span>-far from <span class="math">\\mathsf{Cl}</span> and thus <span class="math">\\mathrm{H}(C_{1}^{w})\\geq\\mathrm{H}(C_{0}^{w})+1</span>. However, if <span class="math">w\\in\\mathsf{CD}_{\\mathsf{NO},\\ell}</span> then <span class="math">w\\in\\mathsf{Cl}</span> and thus <span class="math">\\mathrm{H}(C_{0}^{w})\\geq\\mathrm{H}(C_{1}^{w})+1</span>.</p>

    <p class="text-gray-300">The verifier and the prover will then run the protocol from Lemma 2.15 with respect to the instance <span class="math">(C_{1}^{w},C_{0}^{w})</span> (note that the order of the circuits has changed) and security parameter <span class="math">k</span> chosen such that the completeness and soundness errors are both <span class="math">1/3</span> for large enough <span class="math">\\ell</span>. Since the latter is a sample-access protocol the verifier can indeed run it using only oracle access to its input <span class="math">w</span>.</p>

    <p class="text-gray-300">Recall that we assumed that <span class="math">\\mathsf{Cl}\\in\\mathsf{HV\\text{-}ESZKPP}\\big{[}\\poly(\\log(N),k,1/\\varepsilon)\\big{]}</span>. Hence, the simulator for <span class="math">\\mathsf{Cl}</span> runs in time <span class="math">\\poly(\\log(\\ell),k,1/\\varepsilon)</span>, which by the choice of parameters is simply <span class="math">\\poly(\\log\\ell)</span> (recall the the proximity parameter <span class="math">\\delta(C)</span> and the security parameter <span class="math">k</span> are constant). The running time of the reduction implies that the input (i.e., the number of bits need to sample from the distribution) and outputs sizes of <span class="math">C_{0}</span> and <span class="math">C_{1}</span> are <span class="math">\\poly(\\log\\ell)</span> as well, and by Lemma 2.15 the running time of the verifier is thus <span class="math">\\poly(\\log(\\ell))</span>, as required. ∎</p>

    <h3 id="sec-107" class="text-xl font-semibold mt-8">B.3 Proof Sketch of Lemma 5.11</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We start with a low degree extension code, over a finite field <span class="math">\\mathbb{F}</span>, which view messages <span class="math">x\\in\\mathbb{F}^{\\ell}</span> as functions <span class="math">x:H^{m}\\to\\mathbb{F}</span>, where <span class="math">H\\subseteq\\mathbb{F}</span> is a subset and <span class="math">m</span> is a dimension, such that $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">H^{m}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\ell<span class="math">. The code maps </span>x<span class="math"> to its low degree extension: namely, the unique individual degree </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">H</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-1<span class="math"> polynomial that agrees with </span>x<span class="math"> on </span>H^{m}<span class="math">. By the Shwartz-Zippel lemma this code has relative distance </span>1-\\frac{(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">H</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-1)\\cdot m}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Furthermore, this code is known to be locally testable [RS96] and decodable [GS92, Sud95] using $O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">H</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\cdot m)<span class="math"> queries. We set </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">H</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= (\\log(\\ell))^c<span class="math">, </span>m = \\frac{\\log(\\ell)}{c \\cdot \\log \\log(\\ell)}<span class="math"> and </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= O(m \\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">H</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> for a sufficiently large constant </span>c \\geq 1<span class="math">. Furthermore, we use a field </span>\\mathbb{F}<span class="math"> which is an extension field of the binary field </span>\\mathbb{F}_2$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We then concatenate the above low degree extension code with a good binary linear code. The overall resulting code has message length $k(\\ell) =</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">H</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^m \\cdot \\log(F) = \\tilde{O}(\\ell)<span class="math">, blocklength </span>n(\\ell) = O(\\mathbb{F}^m \\cdot \\mathbb{F}) = \\tilde{O}(\\ell^{1 + 1/c})<span class="math">, constant relative distance and locally testable and decodable with </span>O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">H</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\cdot m) = \\text{polylog}(\\ell)<span class="math"> queries, which meets our desired parameters by setting </span>c<span class="math"> to be sufficiently large. Furthermore, since the low degree extension is linear over the large field </span>\\mathbb{F}<span class="math">, which is an extension field of </span>\\mathbb{F}_2<span class="math">, it is also linear over </span>\\mathbb{F}_2<span class="math"> and therefore the resulting code is also </span>\\mathbb{F}_2$-linear.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h2 id="sec-108" class="text-2xl font-bold">B.4 Proof Sketch of Lemma 6.4</h2>

    <p class="text-gray-300">We use the [IKOS09] "MPC in the head" construction. More specifically, we will use their simplest variant, which is based on the [GMW87] 3-party protocol, in the OT-hybrid, with semi-honest security against 2 (semi-honest) players.[35] Below we refer to this as the IKOS protocol.</p>

    <p class="text-gray-300">We first recall that the [GMW87] protocol, with 2-out-of-3 semi-honest can be implemented so that the parties, and the (semi-honest) simulator, run in time <span class="math">O(t&#x27;)</span> (where we count OT calls at unit cost), where <span class="math">t&#x27;</span> is the circuit complexity of the function.</p>

    <p class="text-gray-300">The IKOS protocol works in <span class="math">k</span> sequential phases (in order to obtain <span class="math">2^{-k}</span> soundness), where each phase works as follows. The prover first runs the [GMW87] protocol with respect to the function <span class="math">f(x, w_1, w_2, w_3) = R(x, w_1 \\oplus w_2 \\oplus w_3)</span>, where <span class="math">w_1, w_2, w_3</span> are an additive secret sharing of the witness <span class="math">W</span>. Observe that <span class="math">f</span> is computable by a size <span class="math">t&#x27; = tildeO(t)</span> circuit, where <span class="math">t</span> is the complexity of <span class="math">R</span> of the NP relation (an extra log factor comes from emulating Turing machines by circuits). Thus, the parties and the MPC simulator run in time <span class="math">\\tilde{O}(t)</span>.</p>

    <p class="text-gray-300">After running the MPC protocol (in its "head"), the IKOS prover commits to the view of all the players.[36] Then, the verifier chooses two (distinct) players <span class="math">i,j\\in \\{1,2,3\\}</span> at random, and sends <span class="math">i</span> and <span class="math">j</span> to the prover. The prover decommits to these players views. The verifier rejects if the decommitments are invalid, the views are inconsistent, or if the result of the computation is not 1. Otherwise it accepts.</p>

    <p class="text-gray-300">For the analysis of soundness and zero-knowledge of the IKOS protocol see [IKOS09]. Here we focus on the running times of the verifier and the simulator.</p>

    <p class="text-gray-300">Observe that all that the verifier's running time in each phase is <span class="math">\\tilde{O}(t) * \\text{poly}(secp)</span> as required.</p>

    <p class="text-gray-300">We proceed to describe the IKOS simulator. Fix a malicious verifier <span class="math">\\tilde{\\mathsf{V}}</span>. The simulator also runs for <span class="math">k</span> phases. In each phase it repeats the following procedure at most <span class="math">\\text{poly}(secp)</span> times (and aborts if all fail):</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Select at random a pair of (distinct) players <span class="math">i, j \\in \\{1, 2, 3\\}</span>, and runs the [GMW87] simulation on them (with respect to random strings <span class="math">w_i</span> and <span class="math">w_j</span>).</li>

      <li>The simulator generates commitments to the simulated views for these players as well as a fake simulation (e.g., all zero) for the third player. The simulator "sends" these commitments to the verifier <span class="math">\\tilde{\\mathsf{V}}</span>.</li>

    </ol>

    <p class="text-gray-300">[35]Indeed, note that the [IKOS09] approach transforms semi-honest secure MPC protocols into proof-systems that are zero-knowledge with respect to malicious verifiers.</p>

    <p class="text-gray-300">[36]Here we use a statistically binding commitment scheme, which follows from the existence of one-way functions [HILL99, Nao91].</p>

    <p class="text-gray-300">44</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\widehat{\\mathsf{V}}</span> responds with a pair of distinct indices <span class="math">i^{\\prime},j^{\\prime}\\in\\{1,2,3\\}</span> (otherwise, since the IKOS prover would abort, the simulator can output its generated view so far followed by a <span class="math">\\bot</span> symbol).</li>

      <li>If <span class="math">i^{\\prime},j^{\\prime}</span> are not the same as <span class="math">i,j</span>, then continue the loop.</li>

      <li>Otherwise, the simulator can send decommitments to <span class="math">\\widehat{\\mathsf{V}}</span> and they continue to the next phase.</li>

    </ol>

    <p class="text-gray-300">Overall the simulation of a single phase takes <span class="math">(\\tilde{O}(t)+T)\\cdot\\mathsf{poly}(k)</span> time, where <span class="math">T</span> is the running time of <span class="math">\\widehat{\\mathsf{V}}</span>. See <em>[x14]</em> for additional details.</p>`;
---

<BaseLayout title="Zero-Knowledge Proofs of Proximity (2017/114)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2017 &middot; eprint 2017/114
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
