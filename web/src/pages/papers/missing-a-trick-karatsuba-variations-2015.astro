---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2015/1247';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Missing a trick: Karatsuba variations';
const AUTHORS_HTML = 'Mike Scott';

const CONTENT = `    <p class="text-gray-300">Michael Scott</p>

    <h6 id="sec-2" class="text-base font-medium mt-4">Abstract</h6>

    <p class="text-gray-300">There are a variety of ways of applying the Karatsuba idea to multi-digit multiplication. These apply particularly well in the context where digits do not use the full word-length of the computer, so that partial products can be safely accumulated without fear of overflow. Here we re-visit the “arbitrary degree” version of Karatsuba and show that the cost of this little-known variant has been over-estimated in the past. We also attempt to definitively answer the question as to the cross-over point where Karatsuba performs better than the classic method.</p>

    <h2 id="sec-3" class="text-2xl font-bold">1 Introduction</h2>

    <p class="text-gray-300">As is well known the Karatsuba idea for calculating the product of two polynomials can be used recursively to significantly reduce the number of partial products required in a long multiplication calculation, at the cost of increasing the number of additions. A one-level application can save <span class="math">1/4</span> of the partial products, and a two-level application can save <span class="math">7/16</span>ths etc. However application of Karatsuba in this way is quite awkward, it attracts a large overhead of extra additions, and the ideal recursion is only available if the number of digits is an exact power of two.</p>

    <p class="text-gray-300">One way to make Karatsuba more competitive is to use a number base radix that is somewhat less than the full register size, so that additions can be accumulated without overflow, and without requiring immediate carry propagation. Here we refer to this as a “reduced-radix” representation.</p>

    <p class="text-gray-300">Multi-precision numbers are represented as an array of computer words, or “limbs”, each limb representing a digit of the number. Each computer word is typically the same size as the processor’s registers, that are manipulated by its instruction set. Using a full computer word for each digit, or a “packed-radix” representation <em>[7]</em>, intuitively seems to be optimal, and was the method originally adopted by most multi-precision libraries. However to be efficient this virtually mandates an assembly language implementation to handle the flags that catch the overflows that can arise, for example, from the simple act of adding two digits.</p>

    <p class="text-gray-300">The idea of using a reduced-radix representation of multi-precision numbers (independent of its suitability for Karatsuba) has long been championed by Bernstein and his co-workers. See for example <em>[2]</em> for a discussion of the relative merits of packed-radix and reduced-radix representation. This approach is supported by the recent experience of Hamburg in his implementation of the Goldilocks</p>

    <p class="text-gray-300">elliptic curve <em>[7]</em>. A reduced-radix representation is sometimes considered to be more efficient <em>[7]</em> – and this is despite the fact that in many cases it will require an increased number of limbs.</p>

    <p class="text-gray-300">In <em>[1]</em> is described an elliptic curve implementation that uses this technique to demonstrate the superiority of using the Karatsuba idea in a context where each curve coordinate is represented in just 16 32-bit limbs. In fact there is much confusion in the literature as to the break-even point where Karatsuba becomes superior. One confounding factor is that whereas Karatsuba trades multiplications for additions, in modern processors multiplications may be almost as fast as additions.</p>

    <p class="text-gray-300">Elliptic curve sizes have traditionally been chosen to be multiples of 128-bits, to provide a nice match to standard levels of security. On the face of it, this is fortuitous, as for example a 256-bit curve might have its <span class="math">x</span> and <span class="math">y</span> coordinates fit snugly inside of 4 64-bit or 8 32-bit computer words using a packed-radix representation. Again, as these are exact powers of 2, they might be thought of as being particularly suitable for the application of the Karatsuba idea. However somewhat counter-intuitively this is not the case – if Karatsuba is to be competitive the actual number base must be a few bits less than the word size in order to facilitate addition of elements without carry processing (and to support the ability to distinguish positive and negative numbers). So in fact a competitive implementation would typically require 5 64-bit or 9 32-bit words, where 5 and 9 are not ideal polynomial degrees for the application of traditional Karatsuba.</p>

    <p class="text-gray-300">What is less well known is that there is an easy to use “arbitrary degree” variant of Karatsuba (ADK), as it is called by Weimerskirch and Paar <em>[12]</em>, which can save nearly 1/2 of the partial products and where the polynomial degree is of no concern to the implementor. In fact this idea has an interesting history. An earlier draft of the Weimerskirch and Paar paper from 2003 is referenced in <em>[10]</em>. But it appears to have been discovered even earlier by Khachatrian et al. <em>[8]</em> , and independently by David Harvey, as reported in Exercise 1.4 in the textbook <em>[3]</em>. Essentially the same idea was used by Granger and Scott <em>[4]</em>, building on earlier work from Granger and Moss <em>[5]</em> and Nogami et al. <em>[11]</em>, in the context of a particular form of modular arithmetic.</p>

    <p class="text-gray-300">Here we consider the application of this variant to the problem of long integer multiplication. Since the number of partial products required is the same as the well known squaring algorithm, squaring is not improved, and so is not considered further here. We restrict our attention to the multiplication of two equal sized numbers, as arises when implementing modular arithmetic as required by common cryptographic implementations.</p>

    <h2 id="sec-4" class="text-2xl font-bold">2 The ADK algorithm</h2>

    <p class="text-gray-300">This algorithm is described in mathematical terms in <em>[3]</em>, <em>[8]</em> and <em>[12]</em>. However here we have used the subtractive variant of Karatsuba to some advantage to get a simpler formula, as pointed out to us by <em>[13]</em>.</p>

    <p class="text-gray-300">###</p>

    <div class="my-4 text-center"><span class="math-block">\\boldsymbol {x} \\boldsymbol {y} = \\sum_ {i = 1} ^ {n - 1} \\sum_ {j = 0} ^ {i - 1} \\left(x _ {i} - x _ {j}\\right) \\left(y _ {j} - y _ {i}\\right) b ^ {i + j} + \\sum_ {i = 0} ^ {n - 1} b ^ {i} \\sum_ {j = 0} ^ {n - 1} x _ {j} y _ {j} b ^ {j} \\tag {1}</span></div>

    <p class="text-gray-300">Observe that in additive form the formula is more complex:-</p>

    <div class="my-4 text-center"><span class="math-block">\\boldsymbol {x} \\boldsymbol {y} = \\sum_ {i = 1} ^ {n - 1} \\sum_ {j = 0} ^ {i - 1} \\left(x _ {i} + x _ {j}\\right) \\left(y _ {i} + y _ {j}\\right) b ^ {i + j} + 2 \\sum_ {i = 0} ^ {n - 1} x _ {i} y _ {i} b ^ {2 i} - \\sum_ {j = 0} ^ {n - 1} b ^ {j} \\sum_ {i = 0} ^ {n - 1} x _ {i} y _ {i} b ^ {i} \\tag {2}</span></div>

    <p class="text-gray-300">This clearly involves more additions and subtractions than equation (1). In fact we find the mathematical description unhelpful in that it makes the method look more complex than it is. It also makes it difficult to determine its exact complexity. To that end an algorithmic description is more helpful.</p>

    <p class="text-gray-300">Algorithm 1 The ADK algorithm for long multiplication INPUT: Degree <span class="math">n</span>, and radix <span class="math">b = 2^t</span> INPUT: <span class="math">\\pmb{x} = [x_0, \\dots, x_{n-1}], \\pmb{y} = [y_0, \\dots, y_{n-1}]</span> where <span class="math">x_i, y_i \\in [0, b-1]</span> OUTPUT: <span class="math">\\pmb{z} = [z_0, \\dots, z_{2n-2}, 0]</span>, where <span class="math">z_i \\in [0, b^2-1]</span> and <span class="math">\\pmb{z} = \\pmb{x}\\pmb{y}</span> 1: function ADKMUL(x,y) 2: for <span class="math">i \\gets 0</span> to <span class="math">n-1</span> do 3: <span class="math">d_i \\gets x_i y_i</span> 4: end for 5: <span class="math">s \\gets d_0</span> 6: <span class="math">z_0 \\gets s</span> 7: for <span class="math">k \\gets 1</span> to <span class="math">n-1</span> do 8: <span class="math">s \\gets s + d_k</span> 9: <span class="math">t \\gets s</span> 10: for <span class="math">i \\gets 1 + \\lfloor k/2 \\rfloor</span> to <span class="math">k</span> do 11: <span class="math">t \\gets t + (x_i - x_{k-i})(y_{k-i} - y_i)</span> 12: end for 13: <span class="math">z_k \\gets t</span> 14: end for 15: for <span class="math">k \\gets n</span> to <span class="math">2n-2</span> do 16: <span class="math">s \\gets s - d_{k-n}</span> 17: <span class="math">t \\gets s</span> 18: for <span class="math">i \\gets 1 + \\lfloor k/2 \\rfloor</span> to <span class="math">n-1</span> do 19: <span class="math">t \\gets t + (x_i - x_{k-i})(y_{k-i} - y_i)</span> 20: end for 21: <span class="math">z_k \\gets t</span> 22: end for 23: return <span class="math">z</span> 24: end function</p>

    <p class="text-gray-300">The number of multiplications and additions required can be confirmed by a simple counting exercise. For clarity we have not included the final carry propa</p>

    <p class="text-gray-300">ation, which reduces the product <span class="math">z</span> to a radix <span class="math">b</span> representation. A fully unrolled example of the algorithm in action for the case <span class="math">n=4</span> is given in the next section.</p>

    <h2 id="sec-5" class="text-2xl font-bold">3 Comparing Karatsuba variants</h2>

    <p class="text-gray-300">As an easy introduction consider the product of two 4 digit numbers, <span class="math">z=xy</span>. The School-boy method (SB) requires 16 multiplications (muls) and 9 double precision adds, which is equivalent to 18 single precision adds. In the sequel when comparing calculation costs a “mul” M is a register-sized signed multiplication resulting in a double register product. An “add” A is the addition (or subtraction) of two registers. We also make the reasonable assumption that while add, shift or masking instructions cost the same on the target processor, an integer multiply instruction may cost more. So the cost of the SB method here is 16M+18A.</p>

    <p class="text-gray-300"><span class="math">z_{0}</span> <span class="math">=x_{0}y_{0}</span> <span class="math">z_{1}</span> <span class="math">=x_{1}y_{0}+x_{0}y_{1}</span> <span class="math">z_{2}</span> <span class="math">=x_{2}y_{0}+x_{1}y_{1}+x_{0}y_{2}</span> <span class="math">z_{3}</span> <span class="math">=x_{3}y_{0}+x_{2}y_{1}+x_{1}y_{2}+x_{0}y_{3}</span> (3) <span class="math">z_{4}</span> <span class="math">=x_{3}y_{1}+x_{2}y_{2}+x_{1}y_{3}</span> <span class="math">z_{5}</span> <span class="math">=x_{3}y_{2}+x_{2}y_{3}</span> <span class="math">z_{6}</span> <span class="math">=x_{3}y_{3}</span></p>

    <p class="text-gray-300">A final “propagation” of carries is also required. Assuming that the number base is a simple power of 2, this involves a single precision masking followed by a double precision shift applied to each digit of the result. The carry must then be added to the next digit. If multiplying two <span class="math">n</span> digit numbers the extra cost is equivalent to <span class="math">(10n-7)A</span> adds. Here we will neglect this extra contribution, as it applies independent of the method used for long multiplication.</p>

    <p class="text-gray-300">Using arbitrary-degree Karatsuba (or ADK), the same calculation takes 10 muls and 11 double precision adds and 12 single precision subs. The total cost is 10M+34A. So overall 6 muls are saved at the cost of 16 adds</p>

    <p class="text-gray-300"><span class="math">z_{0}</span> <span class="math">=x_{0}y_{0}</span> <span class="math">z_{1}</span> <span class="math">=(x_{1}-x_{0})(y_{0}-y_{1})+(x_{0}y_{0}+x_{1}y_{1})</span> <span class="math">z_{2}</span> <span class="math">=(x_{2}-x_{0})(y_{0}-y_{2})+[x_{0}y_{0}+x_{1}y_{1}]+x_{2}y_{2}</span> <span class="math">z_{3}</span> <span class="math">=(x_{3}-x_{0})(y_{0}-y_{3})+(x_{2}-x_{1})(y_{1}-y_{2})+[x_{0}y_{0}+x_{1}y_{1}]+[x_{2}y_{2}+x_{3}y_{3}]</span> <span class="math">z_{4}</span> <span class="math">=(x_{3}-x_{1})(y_{1}-y_{3})+x_{1}y_{1}+[x_{2}y_{2}+x_{3}y_{3}]</span> <span class="math">z_{5}</span> <span class="math">=(x_{3}-x_{2})(y_{2}-y_{3})+(x_{2}y_{2}+x_{3}y_{3})</span> <span class="math">z_{6}</span> <span class="math">=x_{3}y_{3}</span> (4)</p>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">Here square brackets indicate values already available from the calculation. Hopefully the reader can see the pattern in this example in order to easily extrapolate to higher degree multiplications.</p>

    <p class="text-gray-300">It is an interesting exercise to repeat this calculation using one level of “regular” Karatsuba, and simplifying the result. As can be seen in equation 5 the same calculation requires 12 muls, 10 double precision adds and 4 single precision subs, or equivalently 12M+24A, so 4 muls are saved at the cost of 6 adds.</p>

    <p class="text-gray-300"><span class="math">z_{0}</span> <span class="math">=x_{0}y_{0}</span> <span class="math">z_{1}</span> <span class="math">=(x_{1}y_{0}+x_{0}y_{1})</span> <span class="math">z_{2}</span> <span class="math">=(x_{2}-x_{0})(y_{0}-y_{2})+x_{0}y_{0}+(x_{1}y_{1}+x_{2}y_{2})</span> <span class="math">z_{3}</span> <span class="math">=<a href="y_{1}-y_{3}">(x_{2}-x_{0})</a>+(x_{3}-x_{1})[(y_{0}-y_{2})]+[x_{1}y_{0}+x_{0}y_{1}]+[x_{3}y_{2}+x_{2}y_{3}]</span> <span class="math">z_{4}</span> <span class="math">=[(x_{3}-x_{1})][(y_{1}-y_{3})]+[x_{1}y_{1}+x_{2}y_{2}]+x_{3}y_{3}</span> <span class="math">z_{5}</span> <span class="math">=(x_{3}y_{2}+x_{2}y_{3})</span> <span class="math">z_{6}</span> <span class="math">=x_{3}y_{3}</span></p>

    <p class="text-gray-300">Observe that only <span class="math">z_{1}</span>, <span class="math">z_{3}</span> and <span class="math">z_{5}</span> are calculated differently. Using two levels of Karatsuba (equation 6), requires 9M+38A, so 7 muls are saved at the cost of 20 adds.</p>

    <p class="text-gray-300"><span class="math">z_{0}</span> <span class="math">=x_{0}y_{0}</span> <span class="math">z_{1}</span> <span class="math">=(x_{1}-x_{0})(y_{0}-y_{1})+(x_{0}y_{0}+x_{1}y_{1})</span> <span class="math">z_{2}</span> <span class="math">=(x_{2}-x_{0})(y_{0}-y_{2})+[x_{0}y_{0}+x_{1}y_{1}]+x_{2}y_{2}</span> <span class="math">z_{3}</span> <span class="math">=([x_{3}-x_{1}]-[x_{2}-x_{0}])([y_{0}-y_{2}]-[y_{1}-y_{3}])+[(x_{2}-x_{0})(y_{0}-y_{2})]+[(x_{3}-x_{1})(y_{1}-y_{3})]</span> <span class="math">+[(x_{1}-x_{0})(y_{0}-y_{1})]+[(x_{3}-x_{2})(y_{2}-y_{3})]+[x_{0}y_{0}+x_{1}y_{1}]+[x_{2}y_{2}+x_{3}y_{3}]</span> <span class="math">z_{4}</span> <span class="math">=(x_{3}-x_{1})(y_{1}-y_{3})+x_{1}y_{1}+[x_{2}y_{2}+x_{3}y_{3}]</span> <span class="math">z_{5}</span> <span class="math">=(x_{3}-x_{2})(y_{2}-y_{3})+(x_{2}y_{2}+x_{3}y_{3})</span> <span class="math">z_{6}</span> <span class="math">=x_{3}y_{3}</span></p>

    <p class="text-gray-300">Now only <span class="math">z_{3}</span> is calculated differently from the ADK approach. It is noteworthy that in <em>[1]</em> the authors deployed two levels of standard Karatsuba, and apparently did not consider the ADK method. However since the ADK approach works on a digit-by-digit basis, and thus applies seemlessly independent of the number of digits, it would appear to offer a nice easily applied compromise solution that extracts a big part of the Karatsuba advantage, without causing an explosion in the number of additions.</p>

    <p class="text-gray-300">In terms of the number of partial products required, its performance is always at least as good as that obtained by applying one level of regular Karatsuba. This may represent an easily achieved “sweet spot” of relevance to applications</p>

    <p class="text-gray-300">involving medium sized numbers, as may for example apply in the context of Elliptic Curve Cryptography.</p>

    <p class="text-gray-300">In passing we observe, as also noted in <em>[3]</em>, that the ADK method can be used as an amusing alternative algorithm for pencil-and-paper long multiplication. We would not be surprised to learn of its use in the recreational mathematics literature.</p>

    <h2 id="sec-6" class="text-2xl font-bold">4 Numerical stability</h2>

    <p class="text-gray-300">Before proceeding we need to address the problem of numerical stability. We start by assuming that both numbers to be multiplied are fully normalized, that is each digit of <span class="math">x</span> is in the range <span class="math">0\\leq x_{i}&lt;b</span>. If they are not, they can be quickly normalized using a fast mask and shift operation (which works even if some of the digits are temporarily negative). For numerical stability of the long multiplication it is important that the sum of double-precision products that form each row of equation 3, do not cause a signed integer overflow. Assume that <span class="math">b=2^{t}</span> where <span class="math">t&lt;w</span> on a <span class="math">w</span>-bit wordlength computer. Then the product of two such numbers could be as big as <span class="math">2^{2t}-2^{t+1}+1</span>. The longest row consists of <span class="math">n</span> such numbers, plus a carry from the previous row. So each row could not be larger than <span class="math">(n+1)(2^{2t}-2^{t+1}+1)</span>. Since it must be possible to distinguish the sign of each partial product this must be strictly less than <span class="math">2^{2w-1}</span>.</p>

    <p class="text-gray-300">For the common wordlengths of <span class="math">w=32</span> and <span class="math">w=64</span>-bits, and for numbers of the sizes relevant to elliptic curve cryptography, we would expect <span class="math">t</span> to be 28 or 29 on a 32-bit computer, and 61 or 62 for a 64-bit computer. Too large and the stability criteria will not be met. Too small and too many words will be required to represent our numbers, with a loss of efficiency.</p>

    <p class="text-gray-300">We would assume that normally the largest radix possible would be used that is compatible with this stability condition. However there may be other factors at play which might dictate a slightly smaller choice for <span class="math">t</span> – for example if reduction were merged with multiplication <em>[4]</em>, or if it were regarded as desirable that field elements could be added without normalization prior to multiplication <em>[7]</em>.</p>

    <h2 id="sec-7" class="text-2xl font-bold">5 The true cost of ADK multiplication</h2>

    <p class="text-gray-300">In <em>[12]</em> the number of multiplications and additions required for the application of the ADK method is calculated, in the context of polynomial arithmetic. There it is worked out that its performance compared to the school-boy method, given a multiplication to addition cost ratio of <span class="math">r</span>, is such that they are equivalent for <span class="math">r=3</span> irrespective of the degree of the polynomials. The rather neat conclusion might be that unless multiplication takes more than 3 times as long as an addition, the method brings no advantage. And for many real-world processors with hardware support for integer multiplication, this may not be the case.</p>

    <p class="text-gray-300">However here we are interested in multi-precision arithmetic, which is a little different. While all of the additions in the SB method are double precision, the subtractions required by the ADK method are only single precision. Furthermore</p>

    <p class="text-gray-300">the cost function used for ADK in [12] appears to be incorrect. The true cost in terms of single precision additions is actually only  <span class="math">2n^{2} + 2n - 6</span>  for the ADK method, compared to the  <span class="math">2n^{2} - 4n + 2</span>  required by SB. In [12] the number of additions is calculated as being of the order of  <span class="math">2.5n^{2}</span> . This dramatically changes the balance between the two contenders. Recall that for SB the number of muls is  <span class="math">n^{2}</span> , while for the ADK method it is  <span class="math">n(n + 1)/2</span> . An immediate and striking conclusion is that for  <span class="math">n \\geq 12</span>  the total number of muls and adds for ADK becomes less than the total required for SB.</p>

    <p class="text-gray-300">Interestingly Khachatrian et al. [8] appear to have got it wrong as well, overestimating the number of additions required to an even greater extent, as always requiring  <span class="math">50\\%</span>  more additions than the SB method. However these previous over-estimates may be explained by the authors considering only a packed-radix representation.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">muls</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">adds</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">SB</td>

            <td class="px-3 py-2 border-b border-gray-700">n2</td>

            <td class="px-3 py-2 border-b border-gray-700">2n2-4n+2</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">ADK</td>

            <td class="px-3 py-2 border-b border-gray-700">n(n+1)/2</td>

            <td class="px-3 py-2 border-b border-gray-700">2n2+2n-6</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Processor designers go to great lengths to cut the cost in cycles of a mul instruction, even getting it down to 1 clock cycle, the same as that required for an add. However a mul will always require more processor resources, and thus a hidden extra cost will probably show up in actual working code. For example in a multi-scalar architecture only one processor pipeline might support hardware multiplication, whereas all available pipelines will allow simultaneous execution of adds, so whereas one mul can execute in 1 cycle, two or more adds might execute simultaneously. The actual break-even point between ADK and SB can only be determined on a case-by-case basis via an actual implementation. In this next table we calculate the ratio  <span class="math">r</span>  between the costs of muls and adds that mark the expected break-even between SB and ADK.</p>

    <p class="text-gray-300">Table 1. Complexity</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">SB muls</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">SB adds</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">ADK muls</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">ADK adds</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">r</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

            <td class="px-3 py-2 border-b border-gray-700">25</td>

            <td class="px-3 py-2 border-b border-gray-700">32</td>

            <td class="px-3 py-2 border-b border-gray-700">15</td>

            <td class="px-3 py-2 border-b border-gray-700">54</td>

            <td class="px-3 py-2 border-b border-gray-700">2.2</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">9</td>

            <td class="px-3 py-2 border-b border-gray-700">81</td>

            <td class="px-3 py-2 border-b border-gray-700">128</td>

            <td class="px-3 py-2 border-b border-gray-700">45</td>

            <td class="px-3 py-2 border-b border-gray-700">174</td>

            <td class="px-3 py-2 border-b border-gray-700">1.28</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">12</td>

            <td class="px-3 py-2 border-b border-gray-700">144</td>

            <td class="px-3 py-2 border-b border-gray-700">242</td>

            <td class="px-3 py-2 border-b border-gray-700">78</td>

            <td class="px-3 py-2 border-b border-gray-700">306</td>

            <td class="px-3 py-2 border-b border-gray-700">0.97</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">16</td>

            <td class="px-3 py-2 border-b border-gray-700">256</td>

            <td class="px-3 py-2 border-b border-gray-700">450</td>

            <td class="px-3 py-2 border-b border-gray-700">136</td>

            <td class="px-3 py-2 border-b border-gray-700">538</td>

            <td class="px-3 py-2 border-b border-gray-700">0.69</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 2. Operation Counts</p>

    <p class="text-gray-300">This would appear to settle the matter: A variant of Karatsuba should be used for all multi-precision multiplications that involve numbers with 12 or more limbs. A caveat might be that the simplicity of the SB method might favour a</p>

    <p class="text-gray-300">compiler in terms of the number of memory accesses and register move instructions (not considered here) which it might require. However we suspect that any such advantage would be outweighed by the hidden resource consumption of even the fastest integer multiply.</p>

    <p class="text-gray-300">On the other hand it remains a real possibility that a packed-radix implementation of the School-Boy method written in carefully hand-crafted assembly language might prove superior on particular processors, even beyond the 12 limb limit (bearing in mind that a packed-radix representation may actually require less limbs). This could only be established experimentally. A useful resource for comparison purposes would be the well known GMP multi-precision library [6].</p>

    <p class="text-gray-300">We tested our results on an industry standard Intel i3-4025U 1.9GHz 64-bit processor running in Windows. This is a simple head-to-head comparison of the reduced-radix SB and ADK methods. The test code was written in C, and compiled using the GCC compiler (version 5.1.0) with maximum optimization. It includes the carry propagation code. The multiplication code was fully unrolled, as a compiler cannot always be trusted to do this automatically. Our experience would be that optimized compiler output like this for Intel processors is very hard to improve upon, even using hand-crafted assembly language.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">SB cycles</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">ADK cycles</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

            <td class="px-3 py-2 border-b border-gray-700">75</td>

            <td class="px-3 py-2 border-b border-gray-700">78</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">9</td>

            <td class="px-3 py-2 border-b border-gray-700">234</td>

            <td class="px-3 py-2 border-b border-gray-700">185</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">12</td>

            <td class="px-3 py-2 border-b border-gray-700">397</td>

            <td class="px-3 py-2 border-b border-gray-700">324</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">16</td>

            <td class="px-3 py-2 border-b border-gray-700">687</td>

            <td class="px-3 py-2 border-b border-gray-700">577</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 3. Intel i3-4025U Cycle Counts</p>

    <p class="text-gray-300">These results more than support the conclusion to be drawn from table 2: In fact on this processor the cross-over point occurs already with just 9 limbs. On examining the generated code, it was observed that the number of mul and add-equivalent instructions were as predicted in the analysis above. However an inspection of the generated code also confirmed our suspicion that the ADK code generated more register-register move instructions and memory accesses. On some processors this could offset the ADK advantage.</p>

    <p class="text-gray-300">In this note we have dusted off an old oft-rediscovered trick that we would suggest has not received sufficient attention from those interested in efficient cryptographic implementations. We have demonstrated that it is much more efficient than previously thought. We have established a concrete break-even</p>

    <p class="text-gray-300">point where Karatsuba variants should be considered ahead of the classic schoolboy method for long multiplication.</p>

    <p class="text-gray-300">An obvious extension of the idea applies to Montgomery’s method for modular reduction without division <em>[9]</em> – details are given in an appendix.</p>

    <p class="text-gray-300">Of course we are not claiming that the ADK method is necessarily the best choice in all circumstances. A classic recursive Karatsuba may well be superior in particular cases. For example Hamburg <em>[7]</em> uses a modulus that chimes particularly well with 1-level of classic Karatsuba. And Bernstein et al. <em>[1]</em> may well be correct in applying 2-level Karatsuba in their particular context.</p>

    <p class="text-gray-300">The fact that a multiplication now requires the calculation of the same number of partial products as a squaring, might encourage implementors to use this multiplication algorithm for both squaring and multiplication, so that multiplications and squarings cannot be easily distinguished by some simple kinds of side-channel attack, like for example a timing attack.</p>

    <h2 id="sec-10" class="text-2xl font-bold">8 Acknowledgements</h2>

    <p class="text-gray-300">The author would like to thank Rob Granger, Billy Bob Brumley, Paul Zimmermann and Dan Bernstein for helpful comments on an earlier draft of this paper.</p>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">References</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[1] Daniel J. Bernstein, Chitchanok Chuengsatiansup, and Tanja Lange. Curve41417: Karatsuba revisited. Cryptology ePrint Archive, Report 2014/526, 2014. http://eprint.iacr.org/2014/526.</li>

      <li>[2] Daniel J. Bernstein, Niels Duif, Tanja Lange, Peter Schwabe, and Bo-Yin Yang. High-speed high-security signatures. Cryptology ePrint Archive, Report 2011/368, 2011. http://eprint.iacr.org/2011/368.</li>

      <li>[3] R. Brent and P. Zimmermann. Modern Computer Arithmetic. Cambridge University Press, 2010.</li>

      <li>[4] R. Granger and M. Scott. Faster ECC over <span class="math">\\mathbb{F}_{2^{521}-1}</span>. In Public-Key Cryptography – PKC 2015, volume 9020 of Lecture Notes in Computer Science, pages 539–553. Springer Berlin Heidelberg, 2015.</li>

      <li>[5] Robert Granger and Andrew Moss. Generalised Mersenne numbers revisited. Mathematics of Computation, 82:2389–2420, 2013. http://arxiv.org/abs/1108.3054.</li>

      <li>[6] Torbjorn Granlund and the GMP development team. GNU MP: The GNU Multiple Precision Arithmetic Library, 6.1.0 edition, 2015. http://gmplib.org/.</li>

      <li>[7] Mike Hamburg. Ed448-Goldilocks, a new elliptic curve. Cryptology ePrint Archive, Report 2015/625, 2015. http://eprint.iacr.org/2015/625.</li>

      <li>[8] G. Khachatrian, M. Kuregian, K. Ispiryan, and J. Massey. Faster multiplication of integers for public-key applications. In Selected Areas in Cryptography, volume 2259 of Lecture Notes in Computer Science, pages 245–254. Springer Berlin Heidelberg, 2001.</li>

      <li>[9] P. Montgomery. Modular multiplication without trial division. Mathematics of Computation, 44(170):519–521, 1985.</li>

      <li>[10] P. Montgomery. Five, six and seven term karatsuba-like formulae. IEEE Transactions on Computers, 54(3):362–369, 2005.</li>

      <li>[11] Y. Nogami, A. Saito, and Y. Morikawa. Finite extension field with modulus of all-one polynomial and representation of its elements for fast arithmetic operations. IEICE Transactions on Fundementals of Electronics, Communications and Computer Sciences, E86-A(9):2376–2387, 2003.</li>

      <li>[12] Andre Weimerskirch and Christof Paar. Generalization of the Karatsuba algorithm for efficient implementations. Cryptology ePrint Archive, Report 2006/224, 2006. http://eprint.iacr.org/2006/224.</li>

      <li>[13] P. Zimmermann. Personal communication, January 2015.</li>

    </ul>

    <p class="text-gray-300">We carried out further tests on a variety of platforms. In all cases we used the GCC compiler tools. Where the well known GMP library could be installed, we provide a comparison with its assembly language mpn.mul_basecase() packed-radix SB implementation. However it should be noted that whereas the GMP code is only partially unrolled, ours is fully unrolled.</p>

    <p class="text-gray-300">First up is a rather old Intel Core i5 chip running under the Ubuntu OS, and using GCC version 5.2.1.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">SB cycles</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">ADK cycles</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">GMP cycles</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

            <td class="px-3 py-2 border-b border-gray-700">87</td>

            <td class="px-3 py-2 border-b border-gray-700">106</td>

            <td class="px-3 py-2 border-b border-gray-700">99</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">9</td>

            <td class="px-3 py-2 border-b border-gray-700">234</td>

            <td class="px-3 py-2 border-b border-gray-700">248</td>

            <td class="px-3 py-2 border-b border-gray-700">289</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">12</td>

            <td class="px-3 py-2 border-b border-gray-700">400</td>

            <td class="px-3 py-2 border-b border-gray-700">380</td>

            <td class="px-3 py-2 border-b border-gray-700">506</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">16</td>

            <td class="px-3 py-2 border-b border-gray-700">691</td>

            <td class="px-3 py-2 border-b border-gray-700">626</td>

            <td class="px-3 py-2 border-b border-gray-700">921</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Next a more modern i5 variant, running on an Apple Mac Mini.</p>

    <p class="text-gray-300">Table 4. 64-bit Intel i5-M520 Cycle Counts</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">SB cycles</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">ADK cycles</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">GMP cycles</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

            <td class="px-3 py-2 border-b border-gray-700">66</td>

            <td class="px-3 py-2 border-b border-gray-700">60</td>

            <td class="px-3 py-2 border-b border-gray-700">64</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">9</td>

            <td class="px-3 py-2 border-b border-gray-700">195</td>

            <td class="px-3 py-2 border-b border-gray-700">154</td>

            <td class="px-3 py-2 border-b border-gray-700">172</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">12</td>

            <td class="px-3 py-2 border-b border-gray-700">368</td>

            <td class="px-3 py-2 border-b border-gray-700">250</td>

            <td class="px-3 py-2 border-b border-gray-700">286</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">16</td>

            <td class="px-3 py-2 border-b border-gray-700">658</td>

            <td class="px-3 py-2 border-b border-gray-700">491</td>

            <td class="px-3 py-2 border-b border-gray-700">495</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Finally results for an old 32-bit Intel Atom processor, using GCC version 4.8.4</p>

    <p class="text-gray-300">Table 5. 64-bit Intel i5-4278U Cycle Counts</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">SB cycles</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">ADK cycles</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

            <td class="px-3 py-2 border-b border-gray-700">373</td>

            <td class="px-3 py-2 border-b border-gray-700">313</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">9</td>

            <td class="px-3 py-2 border-b border-gray-700">1068</td>

            <td class="px-3 py-2 border-b border-gray-700">888</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">12</td>

            <td class="px-3 py-2 border-b border-gray-700">1824</td>

            <td class="px-3 py-2 border-b border-gray-700">1441</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">16</td>

            <td class="px-3 py-2 border-b border-gray-700">3193</td>

            <td class="px-3 py-2 border-b border-gray-700">2459</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 6. 32-bit Intel Atom N270 Cycle Counts</p>

    <p class="text-gray-300">Example Code</p>

    <p class="text-gray-300">Here we present an example of the loop unrolled C code for the SB and ADK methods that we used in our tests. In this small example the number of limbs <span class="math">n</span> in <span class="math">x</span> and <span class="math">y</span> is 5. Code for carry propagation is included. In practise this code can be automatically generated by a small utility program for any value of <span class="math">n</span>.</p>

    <pre><code>typedef int64_t small;
typedef __int128 large;
#define B 61 // bits in radix
#define M (((small)1&lt;&lt;B)-1) //Mask

void sbmul5(small *x,small *y,small *z)
{
large t,c;
t=(large)x[0]*y[0]; z[0]=(small)t&amp;M; c=t&gt;&gt;B;
t=c+(large)x[1]*y[0]+(large)x[0]*y[1]; z[1]=(small)t&amp;M; c=t&gt;&gt;B;
t=c+(large)x[2]*y[0]+(large)x[1]*y[1]+(large)x[0]*y[2]; z[2]=(small)t&amp;M; c=t&gt;&gt;B;
t=c+(large)x[3]*y[0]+(large)x[2]*y[1]+(large)x[1]*y[2]+(large)x[0]*y[3];
z[3]=(small)t&amp;M; c=t&gt;&gt;B;
t=c+(large)x[4]*y[0]+(large)x[3]*y[1]+(large)x[2]*y[2]+(large)x[1]*y[3]
+(large)x[0]*y[4]; z[4]=(small)t&amp;M; c=t&gt;&gt;B;

t=c+(large)x[4]*y[1]+(large)x[3]*y[2]+(large)x[2]*y[3]+(large)x[1]*y[4];
z[5]=(small)t&amp;M; c=t&gt;&gt;B;
t=c+(large)x[4]*y[2]+(large)x[3]*y[3]+(large)x[2]*y[4]; z[6]=(small)t&amp;M; c=t&gt;&gt;B;
t=c+(large)x[4]*y[3]+(large)x[3]*y[4]; z[7]=(small)t&amp;M; c=t&gt;&gt;B;
t=c+(large)x[4]*y[4]; z[8]=(small)t&amp;M; c=t&gt;&gt;B;
z[9]=(small)c;
}

void adkmul5(small *x,small *y,small *z)
{
large t,s,c,d[5];
d[0]=(large)x[0]*y[0];
d[1]=(large)x[1]*y[1];
d[2]=(large)x[2]*y[2];
d[3]=(large)x[3]*y[3];
d[4]=(large)x[4]*y[4];

s=d[0]; t=s; z[0]=(small)t&amp;M; c=t&gt;&gt;B;
s+=d[1]; t=c+s+(large)(x[1]-x[0])*(y[0]-y[1]); z[1]=(small)t&amp;M; c=t&gt;&gt;B;
s+=d[2]; t=c+s+(large)(x[2]-x[0])*(y[0]-y[2]); z[2]=(small)t&amp;M; c=t&gt;&gt;B;
s+=d[3]; t=c+s+(large)(x[3]-x[0])*(y[0]-y[3])+(large)(x[2]-x[1])*(y[1]-y[2]);
z[3]=(small)t&amp;M; c=t&gt;&gt;B;
s+=d[4]; t=c+s+(large)(x[4]-x[0])*(y[0]-y[4])+(large)(x[3]-x[1])*(y[1]-y[3]);
z[4]=(small)t&amp;M; c=t&gt;&gt;B;

s-=d[0]; t=c+s+(large)(x[4]-x[1])*(y[1]-y[4])+(large)(x[3]-x[2])*(y[2]-y[3]);
z[5]=(small)t&amp;M; c=t&gt;&gt;B;
s-=d[1]; t=c+s+(large)(x[4]-x[2])*(y[2]-y[4]); z[6]=(small)t&amp;M; c=t&gt;&gt;B;
s-=d[2]; t=c+s+(large)(x[4]-x[3])*(y[3]-y[4]); z[7]=(small)t&amp;M; c=t&gt;&gt;B;
/* s-=d[3]; */ s=d[4]; t=c+s ; z[8]=(small)t&amp;M; c=t&gt;&gt;B;
z[9]=(small)c;
}

# Application to Montgomery&#x27;s REDC function

This well known method carries out reduction modulo  $m$  where field elements are first converted to  $n$ -residue form by multiplying them by  $b^{-n} \\mod m$ , where  $b^n$  is larger than, and co-prime to,  $m$ . Assume that a product of a pair of  $n$ -residues is to be reduced modulo  $m$ , and that the value of  $w = -1 / m \\mod b$  is precalculated. The following ADK-based method carries out the reduction. This function may be tightly combined with that of algorithm (1) to provide an integrated modular multiplication/squaring function  $z = xy \\mod m$  for  $n$ -residues, where each  $z_i$  is processed as soon as it is calculated.

Algorithm 2 ADK algorithm for the REDC function
INPUT: Modulus  $m$  of degree  $n$ , radix  $b = 2^t$ , precalculated  $w = -1/m \\mod b$
INPUT:  $z = [z_0, \\ldots, z_{2n-2}, 0]$ , where  $z_i \\in [0, b^2 - 1]$
OUTPUT:  $r = [r_0, \\ldots, z_{n-1}]$ , where  $r_i \\in [0, b-1]$  and  $r = zb^{-n} \\bmod m$
1: function ADKREDC(z)
2:  $t \\gets z_0$
3:  $v_0 \\gets tw \\bmod b$
4:  $t \\gets t + v_0m_0$
5:  $c \\gets z_1 + t/b$
6:  $s \\gets 0$
7: for  $k \\gets 1$  to  $n-1$  do
8:  $t \\gets c + s + v_0m_k$
9: for  $i \\gets 1 + \\lfloor k/2 \\rfloor$  to  $k-1$  do
10:  $t \\gets t + (v_i - v_{k-i})(m_{k-i} - m_i)$
11: end for
12:  $v_k \\gets tw \\bmod b$
13:  $t \\gets t + v_km_0$
14:  $c \\gets z_{k+1} + t/b$
15:  $d_k \\gets v_km_k$
16:  $s \\gets s + d_k$
17: end for
18: for  $k \\gets n$  to  $2n-2$  do
19:  $t \\gets c + s$
20: for  $i \\gets 1 + \\lfloor k/2 \\rfloor$  to  $n-1$  do
21:  $t \\gets t + (v_i - v_{k-i})(m_{k-i} - m_i)$
22: end for
23:  $r_{k-n} \\gets t \\bmod b$
24:  $c \\gets z_{k+1} + t/b$
25:  $s \\gets s - d_{k-n+1}$
26: end for
27:  $r_{n-1} \\gets c \\bmod b$
28: return  $r$
29: end function

This implementation includes full carry propagation. Observe that divisions and remainders modulo  $b$  are carried out using simple shift and masking operations as  $b$  is a power of 2. As is well known the output of this algorithm may require one extra subtraction of the modulus  $m$  to get a fully reduced result. However in many contexts field elements will not need to be immediately fully reduced. The number of muls and adds compared with a straight-forward SB-based implementation is given in Table (7) In some cases the constant  $w$  may be equal to 1, which allows some extra saving. Working code in a variety of languages can be found in the big module here  $^2$ .

|   | muls | adds  |
| --- | --- | --- |
|  SB | n(n+1) | 2n2+4n-2  |
|  ADK | (n2+5n-2)/2 | 2n2+10n-8  |

Table 7. REDC Complexity</code></pre>`;
---

<BaseLayout title="Missing a trick: Karatsuba variations (2015/1247)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2015 &middot; eprint 2015/1247
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
