---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2021/1063';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Cairo – a Turing-complete STARK-friendly CPU architecture';
const AUTHORS_HTML = 'Lior Goldberg, Shahar Papini, Michael Riabzev';

const CONTENT = `    <p class="text-gray-300">Cairo – a Turing-complete STARK-friendly CPU architecture</p>

    <p class="text-gray-300">Lior Goldberg Shahar Papini Michael Riabzev</p>

    <p class="text-gray-300">February 2025*</p>

    <p class="text-gray-300">Abstract</p>

    <p class="text-gray-300">Proof systems allow one party to prove to another party that a certain statement is true. Most existing practical proof systems require that the statement will be represented in terms of polynomial equations over a finite field. This makes the process of representing a statement that one wishes to prove or verify rather complicated, as this process requires a new set of equations for each statement.</p>

    <p class="text-gray-300">Various approaches to deal with this problem have been proposed, see for example [1].</p>

    <p class="text-gray-300">We present Cairo, a practically-efficient Turing-complete STARK-friendly CPU architecture. We describe a single set of polynomial equations for the statement that the execution of a program on this architecture is valid. Given a statement one wishes to prove, Cairo allows writing a program that describes that statement, instead of writing a set of polynomial equations.</p>

    <p class="text-gray-300">Contents</p>

    <p class="text-gray-300">1 Introduction 3 1.1 Background 3 1.2 Our contribution 5 1.3 Overview 7 1.4 Notation 7 1.5 Acknowledgements 8</p>

    <p class="text-gray-300">2 Design principles 8 2.1 Algebraic Intermediate Representation (AIR) and Randomized AIR with Preprocessing (RAP) 8 2.2 von Neumann architecture 9 2.2.1 Bootloading: Loading programs from their hash 11</p>

    <p class="text-gray-300">*First version: August 2021.</p>

    <p class="text-gray-300">2</p>

    <p class="text-gray-300">2.2.2 Running several different programs in the same proof . . 11 2.2.3 Advanced optimizations (just in time compilation and bytecode generation) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 2.2.4 Incrementally verifiable computation (recursive proofs) . 12</p>

    <p class="text-gray-300">2.3 The instruction set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2.3.1 Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2.3.2 Algebraic RISC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14</p>

    <p class="text-gray-300">2.4 Registers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.5 Nondeterminism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 2.5.1 Hints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17</p>

    <p class="text-gray-300">2.6 Memory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 2.6.1 Public memory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 2.6.2 Handling on-chain-data in blockchain applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19</p>

    <p class="text-gray-300">2.7 Program input and program output . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 2.7.1 Program input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 2.7.2 Program output . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21</p>

    <p class="text-gray-300">2.8 Builtins . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21</p>

    <p class="text-gray-300">3 The Cairo framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.1 The deterministic Cairo machine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.2 The nondeterministic Cairo machine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 3.3 The Cairo program bytecode . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 3.4 Cairo programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 3.5 The Cairo Runner . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 3.6 Generating proofs of computational integrity using Cairo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29</p>

    <p class="text-gray-300">4 The CPU architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 4.1 The registers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 4.2 The memory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 4.3 Execution of a program . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 4.4 Instruction structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 4.5 The state transition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32</p>

    <p class="text-gray-300">5 The Cairo Assembly . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 5.1 Common syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 5.2 Assert equal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 5.3 Conditional and Unconditional Jumps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 5.4 call and ret . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 5.5 Advancing ap . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37</p>

    <p class="text-gray-300">6 Recommended memory layout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 6.1 Function call stack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 6.2 Memory segments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39</p>

    <p class="text-gray-300">7 Builtins 7.1 Memory communication 42</p>

    <p class="text-gray-300">8 Cairo Constructs 8.1 Loops and recursion 43 8.2 Integer arithmetic 44 8.3 Fixed and floating-point arithmetic 45 8.4 Obtaining the values of the registers 46 8.5 Read-write memory 46 8.5.1 Append-only array 46 8.5.2 Read-write dictionary 47 8.5.3 Sorting with permutation checking 47</p>

    <p class="text-gray-300">9 An Algebraic Intermediate Representation (AIR) for Cairo 9.1 Notation 49 9.2 The proven integrity statement 50 9.3 Quadratic AIR 50 9.4 Instruction flags 50 9.5 Updating pc 52 9.6 Permutations and interaction step 54 9.7 Nondeterministic continuous read-only memory 55 9.7.1 Definition 55 9.7.2 Constraints 55 9.8 Public memory 56 9.9 Permutation range-checks 57 9.10 List of constraints 58</p>

    <p class="text-gray-300">A Running untrusted code 60</p>

    <p class="text-gray-300">1 Introduction</p>

    <p class="text-gray-300">1.1 Background</p>

    <p class="text-gray-300">The seminal work of Babai, Fortnow and Lund [8] was the first to show the applications of interactive proof systems to scalability. Informally speaking, such systems allow two parties, named the prover and the verifier, to engage in a protocol where the prover convinces the verifier that a certain statement is correct. The statement has the general form: "I know an input of a certain computation that results in a certain output", where both the computation and the output are known to the prover and the verifier. The naive approach is for the prover to send the input to the verifier and let the verifier repeat the computation. This approach has two potentially undesirable features: (1) the verifier learns the input (lack of privacy), and</p>

    <p class="text-gray-300">(2) the verifier needs to re-execute the computation (inefficient). Cryptographic proof systems for computational integrity are protocols that can address these issues by: (1) introducing zero-knowledge <em>[17]</em> for privacy and (2) enabling succinct verification, which is exponentially more efficient than re-execution.</p>

    <p class="text-gray-300">This paper addresses the challenge of representing the proven computation by introducing Cairo, an architecture that allows describing the computation in the form of a computer program and then generating a proof of integrity for that computation. The Cairo architecture is designed for: (1) ease of writing and reading programs to be used as provable statements, and (2) efficient proving, for example, based on the STARK <em>[10]</em> proof system.</p>

    <p class="text-gray-300">In most of the existing practical proof systems, one has to represent the computation being proven in terms of polynomial equations over a finite field. This process is called "arithmetization", and was first used in the context of interactive proofs in <em>[19]</em>. Examples of such representations are arithmetic circuits, Quadratic Span Programs <em>[15]</em> (aka R1CS) and Algebraic Intermediate Representations <em>[10, p. 14]</em> (AIRs).</p>

    <p class="text-gray-300">This requirement, of representing the computation in terms of a system of polynomial equations, makes it very complicated to use these proof systems for practical applications. In addition, some of the approaches for doing the arithmetization process result in unnecessary computation (see the example of branches and loops below).</p>

    <p class="text-gray-300">Consider some examples of how such an arithmetization process may look. Start with the simple task of asserting that <span class="math">x\\neq y</span>. Note that polynomial equations must usually be of the form <span class="math">p=0</span> (rather than <span class="math">p\\neq 0</span>) where <span class="math">p</span> is some polynomial in the variables. The assertion <span class="math">x\\neq y</span> may be translated to <span class="math">\\exists a\\colon(x-y)\\cdot a=1</span> (by adding an auxiliary variable <span class="math">a</span>). The slightly more complicated task of addition modulo <span class="math">2^{64}</span> can be translated to polynomial equations by adding 64 auxiliary variables that capture the binary representation of the sum.</p>

    <p class="text-gray-300">The task gets even more complicated when one has to deal with branches in the computation (for example, do one thing if <span class="math">x=y</span> and another otherwise) and loops (for example, repeat doing something until <span class="math">x=y</span>). One approach for dealing with branches is to translate both of the branches to polynomial equations and add one equation that "selects" the result according to the value of the condition (for example, the equation <span class="math">z=(1-b)\\cdot x+b\\cdot y</span> enforces that <span class="math">z=x</span> if <span class="math">b=0</span> and <span class="math">z=y</span> if <span class="math">b=1</span>). Loops can be dealt with by bounding the number of iterations by some constant <span class="math">B</span> and executing the body of the loop exactly <span class="math">B</span> times, where if the condition was met at some point, the next iterations would simply pass the result until the end of the loop. Note that the last two cases require additional "unnecessary" compu</p>

    <p class="text-gray-300">ation: execute the two branches in the first case and execute <span class="math">B</span> iterations even if the loop ended early in the second case.</p>

    <p class="text-gray-300">One approach to deal with the challenges of the computation’s representation is to write a compiler – a computer program that takes code as its input and outputs the list of polynomial equations that represent the execution of the code. Examples of systems that follow this approach include ZKPDL <em>[20]</em>, Pinocchio <em>[22]</em>, TinyRAM for SNARKs <em>[11]</em> and STARKs <em>[10]</em> and xJsnark <em>[18]</em>. This may make the process simpler, but the result still suffers from several drawbacks, such as the aforementioned inefficiencies of executing unnecessary code, and the necessity of bounding the number of iterations in loops.</p>

    <p class="text-gray-300">Another approach takes its motivation from the invention of CPUs and the von Neumann architecture: One can design a single universal system of polynomial equations representing the execution of an arbitrary computer program written for some fixed instruction set. In the context of preprocessing SNARKs, this approach was used in the vnTinyRAM system <em>[13]</em>.</p>

    <h3 id="sec-1" class="text-xl font-semibold mt-8">1.2 Our contribution</h3>

    <p class="text-gray-300">We present Cairo, an efficient and practical von Neumann architecture that can be used with the STARK proof system to generate proofs of computational integrity. As such, it is the first STARK von Neumann architecture. The main advantages of Cairo are:</p>

    <p class="text-gray-300">The Cairo instruction set was chosen so that the corresponding AIR will be as efficient as possible. For example, the construction of <em>[13]</em> requires around 1000 variables per cycle. Compare this to the 51 variables required by Cairo’s AIR (see Section 9). Moreover, we present the idea of builtins (Sections 2.8 and 7), which make the overhead of executing predefined operations negligible (for example, applying a cryptographic hash function). Cairo supports conditional branches, memory, function calls, and recursion. Cairo is the backbone of multiple cryptocurrency systems that run over the Ethereum blockchain. Proofs for Cairo programs are generated frequently and verified by an on-chain contract. For more information, see <em>[2]</em>.</p>

    <p class="text-gray-300">The following concepts, as presented in this paper, were crucial to achieve the performance of Cairo:</p>

    <p class="text-gray-300">Cairo uses a small and simple, yet relatively expressive,</p>

    <p class="text-gray-300">instruction set; where all of the instructions can be encoded using 15 flags and three integers. See Sections 2.3.2 and 4.5. Instead of using the conventional read-write memory model, Cairo uses a unique memory model (Section 2.6), which is much more restricted – for example, the values of all the memory cells are chosen by the prover and do not change when the code is executed. The additional restrictions allow a very efficient AIR implementation, with only 5 trace cells per memory access (Section 9.7). This is especially important, as each instruction uses 4 memory accesses (one for fetching the instruction and 3 for the 3 operands). In fact, most programming tasks that are usually done using a read-write memory can also be done using this new memory model (see Sections 6 and 8). Permutation range-checks, presented in Section 9.9, allow one to check (in an AIR) that a value is in the range <span class="math">[0,2^{16})</span> using only 3 trace cells (compared to the 16 trace cells required by the naive approach of using the binary representation). Each instruction uses 3 such range-checked values, so such efficiency is crucial. The Cairo architecture supports the implementation of predefined operations directly, as a set of equations, instead of implementing them with Cairo code. We call such predefined operations <em>builtins</em> (Sections 2.8 and 7). The advantage of using builtins is that they significantly reduce the overhead which was added due to the transition from hand-written AIR to Cairo code. This allows the programmer to benefit from writing code while not suffering from significant performance overheads. Cairo’s memory implementation has another important feature – each memory cell that should be shared with the verifier (for example, the program’s code and output), adds a verification cost of only 4 arithmetic operations (excluding the Fiat-Shamir hash). See Sections 2.6.1 and 9.8. For example, (1) proving programs where only the hash (rather than the code) is known to the verifier and (2) proving multiple <em>different</em> programs in one proof to reduce the amortized verification costs. See Section 2.2.</p>

    <p class="text-gray-300">The name Cairo comes from the term “CPU AIR” – an AIR implementing the concept of a CPU (Section 9).</p>

    <p class="text-gray-300">1.3 Overview</p>

    <p class="text-gray-300">Section 2 presents the main features of Cairo and explains many of the decisions that were taken in the design of the architecture.</p>

    <p class="text-gray-300">Section 3 gives the formal definition of the Cairo machine and explains how it fits into a proof system.</p>

    <p class="text-gray-300">Section 4 describes the state transition function of the Cairo machine. This section is very technical as it explains how each of the 15 flags that form an instruction affects the state transition. In practice, very few of the <span class="math">2^{15}</span> possible combinations are used. Its counterpart, Section 5, presents a set of useful instructions that can be implemented using specific flag configurations. Those instructions form the Cairo assembly language (although the exact syntax is out of the scope of this paper).</p>

    <p class="text-gray-300">Section 6 suggests how to arrange the read-only memory to allow handling function calls (including recursion). In other words, how one may implement the function call stack in Cairo.</p>

    <p class="text-gray-300">Section 7 explains the concept of builtins, which are optimized execution units for selected functions.</p>

    <p class="text-gray-300">Section 8 gives a high-level overview of how one can handle common programming tasks (e.g., integer division and simulating read-write memory) given the unique features of Cairo (for example, its unique memory model and the fact that the basic arithmetic operations are evaluated over a finite field, rather than the more common 64-bit integer arithmetic).</p>

    <p class="text-gray-300">As the main purpose of Cairo is to enable the generation of proofs of computational integrity, one must be able to use a proof system in order to prove that the execution of a Cairo program completed successfully. A natural candidate for a proof system is STARK <em>[10]</em> due to its ability to handle uniform computations efficiently.</p>

    <p class="text-gray-300">Section 9 explains how the Cairo machine can be implemented as an Algebraic Intermediate Representation (AIR) <em>[10, p. 14]</em>, which is the way the computation is described in the STARK protocol. It includes a detailed description of the polynomial constraints that enforce the behavior of the Cairo machine.</p>

    <h3 id="sec-2" class="text-xl font-semibold mt-8">1.4 Notation</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Throughout the paper, <span class="math">\\mathbb{F}</span> is a fixed finite field of size $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> and characteristic </span>P<span class="math">. For two integers </span>a,b\\in\\mathbb{Z}<span class="math">, we use the notation </span>[a,b):=\\{x\\in\\mathbb{Z}:a\\leq x<b\\}<span class="math"> and </span>[a,b]:=\\{x\\in\\mathbb{Z}:a\\leq x\\leq b\\}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">1.5 Acknowledgements</p>

    <p class="text-gray-300">We thank Eli Ben-Sasson for the helpful comments and discussions during the development of Cairo and writing this paper, StarkWare’s engineers who gave useful advice during the design and helped to implement the system, and Jeremy Avigad and Yoav Seginer for giving helpful comments on this paper.</p>

    <h2 id="sec-3" class="text-2xl font-bold">2 Design principles</h2>

    <p class="text-gray-300">The Cairo framework enables one to prove the integrity of an arbitrary computation. That is, to convince the verifier that a certain program ran successfully with some given output.</p>

    <p class="text-gray-300">Cairo is designed to provide an intuitive programming framework for efficient proving of valid program executions using the STARK protocol <em>[10]</em>. Even though the STARK protocol can be used by itself (i.e., without Cairo) to prove the integrity of arbitrary computations, Cairo provides a layer of abstraction around STARKs that simplifies the way the computation is described.</p>

    <p class="text-gray-300">In order to use the STARK proof system directly, the computation has to be framed as an AIR (Algebraic Intermediate Representation) <em>[10, p. 14]</em>, see Section 2.1, which requires a rather complicated design process. The Cairo framework introduces an assembly language (and on top of which, a full programming language – which is outside the scope of this paper) in which the computation can be described. This is much easier than designing an AIR.</p>

    <p class="text-gray-300">Note that while Cairo was designed to be used with the STARK protocol, it can also be used with many other finite field-based proof systems, such as SNARKs <em>[11]</em>.</p>

    <p class="text-gray-300">This section deals with the principles behind Cairo and explains some of the choices that were made during its design.</p>

    <h3 id="sec-4" class="text-xl font-semibold mt-8">2.1 Algebraic Intermediate Representation (AIR) and Randomized AIR with Preprocessing (RAP)</h3>

    <p class="text-gray-300">Many finite-field-based proof systems <em>[16, 11, 12, 14]</em> work with arithmetic circuits or quadratic span programs <em>[15]</em> (aka R1CS). Consider an arithmetic circuit – a circuit with addition and multiplication gates, where all the values are from some fixed finite field. The prover gets such an arithmetic circuit, together with inputs (the <em>witness</em>), that make it return 0 where 0 is the algebraic representation of “true” or “success”. Then, it generates a proof attesting to the fact that some inputs of this particular arithmetic circuit exist that make it return 0.</p>

    <p class="text-gray-300">The STARK proof system is based on AIRs (Algebraic Intermediate Representation, see [10, p. 14]), rather than arithmetic circuits or R1CSs. An AIR can be thought of as a list of polynomial constraints (equations) operating on a (two-dimensional) table of field elements (of some finite field,  <span class="math">\\mathbb{F}</span> ) called the "trace" (the witness). A STARK proof proves that there exists a trace satisfying the constraints.</p>

    <p class="text-gray-300">Usually, the number of columns in the table is small (around 20) and the number of rows is a power of 2. Each constraint is assigned a domain, which is a periodic <span class="math">^4</span>  set of the rows to which the constraint applies. For example, a constraint may apply to all the rows, every fourth row, or to a single row.</p>

    <p class="text-gray-300">As we will see in Section 9.6, the Cairo AIR is, in fact, not really an AIR (as per the formal definition in [10, p. 14]), it is a Randomized AIR with Preprocessing (RAP, see [3]). A RAP is a broader definition of the term AIR, that allows an additional step of interaction between the prover and the verifier. This means that:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The constraints may involve variables  <span class="math">c_0, \\ldots, c_m \\in \\mathbb{F}</span>  that are not part of the trace cells. We refer to them as the interaction variables.</li>

      <li>The trace columns are split into two sets: before and after the interaction step.</li>

      <li>Instead of requiring one satisfying assignment, we require the existence of a satisfying assignment for most values of  <span class="math">(c_0,\\ldots ,c_m)</span>  where the first set of columns are independent of the values  <span class="math">(c_{0},\\dots ,c_{m})</span></li>

    </ol>

    <p class="text-gray-300">The STARK protocol can be modified to prove statements described as RAPs (see Section 9.6).</p>

    <p class="text-gray-300">Since this concept was used in Cairo before the term RAP was coined <span class="math">^6</span> , we will continue to use the term "Cairo AIR", rather than "Cairo RAP", in this paper.</p>

    <p class="text-gray-300">The Cairo framework deals with moving from a computation described as a computer program to a computation described as an AIR. The two main approaches that handle this translation are:</p>

    <p class="text-gray-300">The ASIC approach: compiling a program to an AIR. In this approach one writes a computer program (the compiler) that takes as an input a</p>

    <p class="text-gray-300">program written in some language and outputs an AIR (a set of constraints) that represents an equivalent computation. This is similar to a compiler, which takes a program and outputs an ASIC or an FPGA based on the input code.</p>

    <p class="text-gray-300">The CPU approach: designing a single AIR (independent of the computation being proven) that behaves like a CPU. This AIR represents a single computation – the loop of fetching an instruction from memory, executing that instruction, and continuing to the next instruction. This is similar to using a single general-purpose CPU chip rather than an application-specific chip.</p>

    <p class="text-gray-300">The main advantage of the ASIC approach is efficiency. Building an AIR based on the computation does not have the overhead of decoding the instructions and using memory. However, as using builtins (see Section 2.8 and Section 7) reduces this overhead, this enables the CPU approach to present similar performance to that of a hand-written AIR for many computations. If a certain computation cannot take advantage of existing builtins, one has a trade-off: you may choose between (1) accepting the performance loss and (2) designing a new builtin that will improve the computation's performance⁷.</p>

    <p class="text-gray-300">The CPU approach has many advantages, including:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>A small constraint set: as the set of constraints is independent of the computation being proven, it has a fixed size. The AIR of the Cairo CPU consists of 30-40 constraints⁸. This improves the verification costs.</li>

      <li>A single AIR: while the ASIC approach requires a computer program that outputs AIR constraints, the CPU approach has a single set of constraints that can run any program. Therefore, the verifier for this AIR has to be implemented only once (rather than per application). In particular, this simplifies the process of auditing the proof system. Once the constraints are checked, the only thing that requires auditing, when considering a new application, is its code (which is much simpler to audit than polynomial equations). Another advantage of the fact the AIR is independent of the application, is that it simplifies the process of building recursive STARK proofs (see Section 2.2.4).</li>

    </ul>

    <p class="text-gray-300">The rest of Section 2.2 describes the advantages of the CPU approach that are an outcome of following the von Neumann architecture. In the von Neumann architecture, the program's bytecode and data are located within the same memory. A register, called the "program counter" (PC), points to</p>

    <p class="text-gray-300">⁷Note that adding a builtin is not free: designing a builtin is usually a complicated task. In addition, it means that the number of AIR constraints increases, which impacts the verification time.</p>

    <p class="text-gray-300">⁸The CPU does not include the builtins.</p>

    <p class="text-gray-300">10</p>

    <p class="text-gray-300">a memory address. The CPU (1) fetches the value of that memory cell, (2) performs the instruction expressed by that value (which may affect memory cells or change the flow of the program by assigning a different value to PC), (3) moves PC to the next instruction and (4) repeats this process.</p>

    <h2 id="sec-6" class="text-2xl font-bold">2.2.1 Bootloading: Loading programs from their hash</h2>

    <p class="text-gray-300">A program may write the bytecode of another program to memory and then set the PC to point to that memory segment, thus starting the execution of the other program.</p>

    <p class="text-gray-300">One specific use of this idea is "Bootloading from hash": A program, called "the bootloader" computes and outputs the hash of the bytecode of another program and then starts executing it as above. This way, the verifier only needs to know the hash of the program being executed and not its full bytecode.</p>

    <p class="text-gray-300">This improves both privacy and scalability:</p>

    <p class="text-gray-300"><strong>Privacy:</strong> the verifier can verify the execution of a program without knowing what the computation does⁹.</p>

    <p class="text-gray-300"><strong>Scalability:</strong> assuming the program hash is known to the verifier, the verification time does not depend linearly on the program size, as would be the case if the program – rather than its hash – were given as input to the verifier.</p>

    <h2 id="sec-7" class="text-2xl font-bold">2.2.2 Running several different programs in the same proof</h2>

    <p class="text-gray-300">The bootloader described above can be extended to execute several programs one after the other, outputting the bytecode hash of each of the programs, together with the programs' outputs. Note that the programs can describe entirely different computations. As the size of a proof and the cost of verifying it are both sublinear in the size of the computation, one may use such a bootloader to take several programs and generate a single proof attesting to the validity of all of the programs. The verification costs will be shared among these programs.</p>

    <p class="text-gray-300">Let's take a numerical example: In the theoretical construction STARK is based on, STIK¹⁰, proof-verification scales logarithmically with the trace length, <span class="math">O(\\log T)</span>, see [10, p. 21]. The STARK construction (using a Merkle tree commitment) adds another multiplicative factor of <span class="math">O(\\log T)</span>, resulting</p>

    <p class="text-gray-300">⁹Note that to achieve zero-knowledge: (1) the underlying proof system (for example, STARK) has to have the zero-knowledge property, (2) the program hash must use a cryptographic salt, and (3) one must make sure that the values that are shared with the verifier (such as the number of steps) do not reveal information on the program.</p>

    <p class="text-gray-300">¹⁰The acronym STIK stands for scalable, transparent IOP of knowledge, and IOP is interactive oracle proof.</p>

    <p class="text-gray-300">11</p>

    <p class="text-gray-300">in verification time complexity of <span class="math">O(\\log^{2}T)</span>. For simplicity, let’s assume the verification of an integrity proof for an execution trace of length <span class="math">T</span> is exactly <span class="math">\\log^{2}(T)</span>. Verifying the proofs of two programs of 1 million steps each separately will cost <span class="math">2\\log^{2}(T)\\approx 794</span>, whereas verifying one proof for both programs will cost <span class="math">\\log^{2}(2T)\\approx 438</span>. One can see that the amortized verification cost of a program in a batch of many programs approaches zero as more programs are added to the batch.</p>

    <h4 id="sec-8" class="text-lg font-semibold mt-6">2.2.3 Advanced optimizations (just in time compilation and bytecode generation)</h4>

    <p class="text-gray-300">Some advanced optimizations may be implemented via automatic generation of bytecode during the execution of a program. For example, instead of fetching values from the memory in a function, a program may clone the function’s bytecode and place some values directly inside the instructions that require them. Consider the instruction “read <span class="math">c</span> and <span class="math">x</span> from memory and compute <span class="math">x+c</span>”. Once the value of <span class="math">c</span> is known (let’s denote it by <span class="math">C</span>), we may replace the instruction with the, possibly more efficient instruction, “read <span class="math">x</span> from memory and compute <span class="math">x+C</span>”, where <span class="math">C</span> is the immediate value of the instruction.</p>

    <p class="text-gray-300">All other forms of bytecode generation are also possible: A program can generate Cairo bytecode according to some rules and then execute it. For example, let’s say that we need to compute <span class="math">x_{i}^{c}</span> for multiple <span class="math">x_{i}</span>s, we may write a function that gets <span class="math">c</span> and returns the bytecode of a function computing <span class="math">x^{c}</span> using a long sequence of multiplications (rather than the naive implementation which uses recursion and conditional jumps and is, therefore, much less efficient).</p>

    <h4 id="sec-9" class="text-lg font-semibold mt-6">2.2.4 Incrementally verifiable computation (recursive proofs)</h4>

    <p class="text-gray-300">A <em>recursive proof</em> is a proof attesting to the validity of another proof. For example, let <span class="math">A_{0}</span> denote some statement. The simplest use of a proof system is the prover convincing the verifier that <span class="math">A_{0}</span> is true. Now, let’s define <span class="math">A_{1}</span> to be the statement “I verified a proof attesting to the fact that <span class="math">A_{0}</span> is true”. One can try generating a proof for <span class="math">A_{1}</span>. We can then continue with statements <span class="math">A_{2}</span>, <span class="math">A_{3}</span>, and so on. This idea, called “incrementally verifiable computation”, was first defined and analyzed in <em>[23]</em>.</p>

    <p class="text-gray-300">In order to generate a recursive proof, one has to encode the verification process (the algorithm the verifier is running) as the statement being proven. For many proof systems, and in particular, for the ASIC approach, this creates a circular dependency: The verifier depends on the program being proven, which depends on the verifier’s code. However, with the CPU</p>

    <p class="text-gray-300">approach, the verifier <em>does not</em> depend on the program, which simplifies recursive proving – as the circular dependency breaks. Moreover, using the idea of bootloading from the hash (Section 2.2.1), the entire verification program can be encoded as one hash (say, 256 bits), which allows passing the program as an argument to itself (which is one of the steps for generating recursive proofs).</p>

    <h3 id="sec-10" class="text-xl font-semibold mt-8">2.3 The instruction set</h3>

    <p class="text-gray-300">The instruction set is the set of operations the Cairo CPU can perform in a single step. This section describes the high-level properties of Cairo’s instruction set.</p>

    <h4 id="sec-11" class="text-lg font-semibold mt-6">2.3.1 Metrics</h4>

    <p class="text-gray-300">In order to design a good instruction set for Cairo, one first needs to understand what metrics should be optimized. Unlike ordinary instruction sets, which are executed on a physical chip built of transistors, Cairo is executed in an AIR (see Section 2.1). Ordinary instruction sets should minimize the latency of the execution of an instruction and the number of required transistors; while maximizing the throughput of the computation. The metrics for an efficient AIR are different: Roughly speaking, the most important constraint when designing an AIR (and, therefore, when designing an instruction set that will be executed by an AIR) is to minimize the number of trace cells used. This is more or less equivalent to the number of variables in a system of polynomial equations.</p>

    <p class="text-gray-300">In order to design an efficient instruction set, one has to understand what property should be optimized. A reasonable measure is the expectation of the number of trace cells an average program (written optimally in the said instruction set) uses. This is an informal measure because, to be accurate, it would require knowledge of the distribution of the programs, and require that each of those programs is written in the most efficient way in all of the compared instruction sets. Nevertheless, one can still use this definition as a <em>guideline</em> for many decisions throughout the design.</p>

    <p class="text-gray-300">As an example, take two instruction sets, <span class="math">A</span> and <span class="math">B</span>. The instruction set <span class="math">A</span> has an instruction “as_bool” that computes the expression “1 if <span class="math">x\\neq 0</span>, otherwise 0”. The instruction set <span class="math">B</span> is an identical instruction set, except that “as_bool” is missing. Say that the cost, in trace cells, of executing a single step in a CPU based on instruction set <span class="math">A</span> is <span class="math">a</span> (for simplicity we assume all instructions cost the same number of trace cells), and that the cost of a single step when using instruction set <span class="math">B</span> is <span class="math">b</span> (where <span class="math">a&gt;b</span> due to the complexity of adding the additional instruction). On the other hand, a</p>

    <p class="text-gray-300">certain program may require <span class="math">k_{A}</span> steps if written using instruction set <span class="math">A</span> and <span class="math">k_{B}</span> steps if written using instruction set <span class="math">B</span> (here <span class="math">k_{B} \\geq k_{A}</span> since every time the program needs to use “as_bool” it might require more than a single instruction from instruction set <span class="math">B</span>). If <span class="math">a \\cdot k_{A} &amp;lt; b \\cdot k_{B}</span>, instruction set <span class="math">A</span> is better for that program, and if <span class="math">a \\cdot k_{A} &amp;gt; b \\cdot k_{B}</span>, instruction set <span class="math">B</span> is better. When one decides whether to include an instruction or not, they should consider the additional cost per step <span class="math">(a / b)</span> against the additional steps <span class="math">(k_{B} / k_{A})</span>, and do so for “typical” programs, with some understanding of what “typical” programs look like.</p>

    <h2 id="sec-12" class="text-2xl font-bold">2.3.2 Algebraic RISC</h2>

    <p class="text-gray-300">In accordance with the guideline described in Section 2.3.1, the Cairo instruction set tries to create a balance between (1) a minimal set of simple instructions that require a very small number of trace cells and (2) powerful enough instructions that will reduce the number of required steps. As such,</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Addition and multiplication are supported over the base field (for example, modulo a fixed prime number) rather than for 64-bit integers.</li>

      <li>Checking whether two values are equal is supported, but there is no instruction for checking whether a certain value is less than another value (such an instruction would have required many more trace cells – since a finite field does not support an algebraic-friendly linear ordering of its elements).</li>

    </ol>

    <p class="text-gray-300">We say that an instruction set with those properties is an Algebraic RISC (Reduced Instruction Set Computer): “RISC” refers to the minimality of the instruction set, and “Algebraic” refers to the fact that the supported operations are field operations. Using an Algebraic RISC allows us to construct an AIR for Cairo with only 51 trace cells per step. The AIR for the Cairo CPU is described in Section 9.</p>

    <p class="text-gray-300">The Cairo instruction set can simulate any Turing Machine and hence is Turing-complete <span class="math">^{14}</span>. As such, it supports any feasible computation. However, implementing some basic operations, such as comparison of elements, using only Cairo instructions would result in a lot of steps. To mitigate this without increasing the number of trace cells per instruction, Cairo introduces the notion of builtins, through which the cost of operations that are not part of the instruction set is not multiplied by the total number of steps, but rather by the number of times the operation was invoked. See Sections 2.8 and 7.</p>

    <p class="text-gray-300"><span class="math">^{14}</span> We mean this in an informal way, as one would say the x64 instruction set is Turing-complete. The Cairo instruction set instantiated over a fixed prime field can decide the bounded halting problem for instances smaller than the field size.</p>

    <p class="text-gray-300">14</p>

    <p class="text-gray-300">2.4 Registers</p>

    <p class="text-gray-300">An important question that assists to distinguish between instruction sets is: what values do the instructions operate on? Usually, the instruction operands are either general-purpose registers (e.g., <span class="math">\\mathsf{rax}</span> in the x64 architecture) or memory cells. Many instructions have more than one operand, and they force some constraints on what those operands are (an example of a possible constraint is: a maximum of one operand may be a memory cell, and the rest must be general purpose registers).</p>

    <p class="text-gray-300">A few examples for different approaches are:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>No general-purpose registers – all of the instructions are performed directly on memory cells.</li>

      <li>Some general-purpose registers – instructions are performed on those registers and usually, at most, one memory cell.</li>

      <li>Bounded stack machines – those can be thought of as machines with many general purpose registers, where the different instructions shift the values between the registers. In many cases, at most one memory cell is involved, and usually, the only instructions that access the memory are simple read/write instructions that do not perform computation.</li>

    </ol>

    <p class="text-gray-300">In physical systems, memory access is usually very expensive, which makes option 1 above inefficient (consider, for example, a summation loop that has to read and write the partial sum to the memory in each iteration). This is not necessarily the case for AIRs: In Cairo, the cost of one memory access is 5 trace cells (See Section 2.6). Compare this to the cost of decoding an instruction, which is 16 trace cells.</p>

    <p class="text-gray-300">Therefore, Cairo implements option 1 above – there are no general-purpose registers, and all the operands of an instruction are memory cells. Thus, one Cairo instruction may deal with up to 3 values from the memory and perform one arithmetic operation (either addition or multiplication) on two of them, and store the result in the third.</p>

    <p class="text-gray-300">Cairo has 2 address registers, called <span class="math">\\mathsf{ap}</span> and <span class="math">\\mathsf{fp}</span>, which are used for specifying which memory cells the instruction operates on. For each of the 3 values in an instruction, you can choose either an address of the form <span class="math">\\mathsf{ap}</span> + off or <span class="math">\\mathsf{fp}</span> + off where off is a constant offset in the range <span class="math">[-2^{15},2^{15})</span>. Thus, an instruction may involve any 3 memory cells out of <span class="math">2\\cdot 2^{16}=131072</span>. In many aspects, this is similar to having this many registers (implemented in a much cheaper way).</p>

    <p class="text-gray-300">Accessing memory cells that cannot be described in the form above is possible using an instruction (see Section 5.2) that takes the <em>value</em> of a</p>

    <p class="text-gray-300">memory cell and treats it as the <em>address</em> of another memory cell. Note that the address space can be as large as the number of steps being executed.</p>

    <h3 id="sec-13" class="text-xl font-semibold mt-8">2.5 Nondeterminism</h3>

    <p class="text-gray-300">Consider an NP-complete problem, such as SAT, and consider the following two algorithms:</p>

    <p class="text-gray-300">gets a SAT instance and an assignment and returns True if the assignment satisfies the formula. gets a SAT instance and enumerates over all possible assignments. If it finds a satisfying assignment, it stops and returns “True”. Otherwise, if no such assignment is found, it returns “False”.</p>

    <p class="text-gray-300">If the prover wants to convince the verifier that a certain SAT formula is satisfiable, it can use both algorithms. Knowing that either of the algorithms returned “True” for the required SAT-formula means that it’s satisfiable. Of course, Algorithm A is much more efficient, so the prover and the verifier will prefer to use it for such a proof. Even if the prover doesn’t have a satisfying assignment yet, it can run Algorithm B locally, find a satisfying assignment and then prove that <em>Algorithm A</em> returns “True” (this is usually much more efficient than proving that Algorithm B returns “True”, since proving a computation is much more expensive than running the same computation without generating a proof).</p>

    <p class="text-gray-300">We refer to this approach as nondeterministic programming – the prover may do additional work that is not part of the <em>proven computation</em>.</p>

    <p class="text-gray-300">We mentioned before that a Cairo instruction may either add or multiply field elements. What if we want to compute a square root of a certain number <span class="math">x</span> as part of a larger function? The deterministic approach is to use some square-root algorithm to compute <span class="math">y=\\sqrt{x}</span>, which means we need to include its execution trace in our proof. But the nondeterministic approach is much more efficient: the prover computes the square-root <span class="math">y</span> using the same algorithm, but doesn’t include this computation in the <em>proved</em> execution trace. Instead, the only thing proved is that <span class="math">y^{2}=x</span>, which can be done using a single Cairo (multiplication) instruction. Notice that from the point of view of the verifier, the value <span class="math">y</span> is “guessed”, and all the program does is check that the guess is indeed correct (in particular, in certain cases several different guesses are legitimate and valid from the verifier’s point of view; in the example above, notice that <span class="math">-y</span> is valid, even though the deterministic square-root algorithm returns <span class="math">y</span>).</p>

    <p class="text-gray-300">An important aspect in the design of Cairo was to allow the programmer to take advantage of nondeterministic programming.</p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">2.5.1 Hints</p>

    <p class="text-gray-300">To allow taking advantage of nondeterministic programming, Cairo introduces the notion of <em>prover hints</em> or just “hints”. Hints are pieces of code that are inserted between Cairo instructions where additional work is required by the prover. Since hints are only used by the prover, and we don’t have to prove the execution of the hints to the verifier, hints can be written in any programming language. When the Cairo Runner (see Section 3.5) needs to simulate a Cairo instruction that is preceded by a hint, it first runs the hint, which may initialize some memory cells and, only then, continue with the execution of the Cairo instruction.</p>

    <h3 id="sec-14" class="text-xl font-semibold mt-8">2.6 Memory</h3>

    <p class="text-gray-300">Most computer architectures use random-access read-write memory. This means that an instruction may choose an arbitrary memory address and either read the existing value at that address or write a new value to that address, replacing the existing one. However, this is not the only possible memory model. For example, in purely functional programming, once a variable is set, its value cannot change, so a write-once memory model may be enough to efficiently run a program written in a purely functional language.</p>

    <p class="text-gray-300">Below are some memory models which were considered for the Cairo architecture:</p>

    <p class="text-gray-300">This is the most familiar memory model, described above. In this memory model, if you try to write to a memory cell that was already assigned a value, the write operation will fail. Similarly, if you try to read before writing, the operation will fail. In this memory model, the prover chooses all the values of the memory, and the memory is immutable. The Cairo program may only <em>read</em> from it.</p>

    <p class="text-gray-300">The three pieces of pseudo-code in Fig. 1 demonstrate how one can use each memory model to pass information between two points in the program. In all of the examples, the value 7 is written to address 20 and fetched later in the code.</p>

    <p class="text-gray-300">Although Fig. 1a, Fig. 1b share the same code, in fact, Fig. 1b and Fig. 1c have more in common: The first two instructions of Fig. 1c force the prover to initialize address 20 with the value 7, so they function as a write instruction. While in Fig. 1a, we cannot be certain that the value of x will be</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Figure 1: Using various memory models.</p>

    <p class="text-gray-300">7 without reading the code between the two instructions, this property is guaranteed in the other two models. Due to this similarity, we will sometimes refer to an instruction of the form assert read(address=20) == 7 as an assignment instruction.</p>

    <p class="text-gray-300">The main trade-off in choosing a memory model is between allowing efficient implementation of various algorithms and efficient representation of each memory access in the AIR. As we move from Read-Write Memory to Nondeterministic Read-Only Memory, implementation of algorithms becomes more restricted, but the representation of each memory access in the AIR becomes more efficient.</p>

    <p class="text-gray-300">It turns out that, for most of the memory accesses in programs, a Nondeterministic Read-Only Memory is sufficient (for example, Section 6 explains how a function stack may be implemented in the read-only model), and in places where it does not suffice, it's possible to simulate a full read-write memory using it (see Section 8.5). Therefore, Cairo uses a nondeterministic read-only memory as its memory model.</p>

    <p class="text-gray-300">In fact, one more restriction is applied to gain efficiency. The memory address space is continuous, which means that if there is a memory access to address  <span class="math">x</span>  and another memory access to address  <span class="math">y</span> , then for every address  <span class="math">x &amp;lt; a &amp;lt; y</span> , there must be a memory access to this address. This additional restriction on the prover allows a very efficient AIR implementation of memory accesses with only 5 trace cells per access (see Section 9.7).</p>

    <p class="text-gray-300">Another interesting aspect is freeing or reusing memory cells. In all of the memory models mentioned above (assuming similar approaches of AIR implementation to the one described in Section 9.7), one has to pay (in terms of trace-cell) per memory access, rather than per used memory address. This means that rewriting over a single cell in the read-write model, or writing to a new cell each time, will have a similar cost. So, the programmer does not have to worry about freeing memory or reusing memory cells to save "space". They need only try to minimize memory accesses.</p>

    <p class="text-gray-300">19</p>

    <h2 id="sec-15" class="text-2xl font-bold">2.6.1 Public memory</h2>

    <p class="text-gray-300">An important advantage of the way Cairo implements the nondeterministic read-only memory as an AIR is that it allows the prover to efficiently convince the verifier that some memory addresses contain certain values. More formally, given a list of pairs of address <span class="math">a_i</span> and value <span class="math">v_i</span>, shared by the prover and the verifier, the verifier can confirm that the memory at address <span class="math">a_i</span> has the value <span class="math">v_i</span>. Since this information is shared with the verifier, we refer to it as the public memory. One can think of this list as "boundary constraints" on the memory, which are externalized to the world.</p>

    <p class="text-gray-300">This mechanism is extremely efficient: during the proof generation, two "random"¹⁷ numbers are generated: <span class="math">z</span>, <span class="math">\\alpha</span>. Then, the only thing the verifier has to do with the list <span class="math">(a_i, v_i)</span> is to compute the expression</p>

    <div class="my-4 text-center"><span class="math-block">\\prod_{i} (z - (a_i + \\alpha \\cdot v_i)), \\tag{1}</span></div>

    <p class="text-gray-300">and substitute the result in one of the AIR's constraints. This means that the verification cost per entry is one addition, one subtraction, and two multiplications in the field; in addition to the computation of the hash of the list which is required as part of the Fiat-Shamir transformation.</p>

    <p class="text-gray-300">Compare our approach to the naive approach of adding boundary constraints to an AIR: In the naive approach, one adds a constraint per trace cell that should be fixed. This means one should add two constraints per memory cell (for the address and the value). Since the location of the two trace cells that contain the memory cell for a specific address is usually not known before generating the trace¹⁸, the prover will have to send this information to the verifier.</p>

    <p class="text-gray-300">This mechanism can be used for:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Loading the bytecode (see Section 3.3) of the program into memory (the prover and the verifier should agree on the program being executed).</li>

      <li>Passing the arguments and return values of the program (between the prover and the verifier).</li>

    </ol>

    <p class="text-gray-300">For more information about the way this mechanism is implemented as an AIR, see Section 9.8.</p>

    <h2 id="sec-16" class="text-2xl font-bold">2.6.2 Handling on-chain-data in blockchain applications</h2>

    <p class="text-gray-300">Let's now consider one concrete application of the mechanism described in Section 2.6.1, in which its efficiency is crucial. In some blockchain appli</p>

    <p class="text-gray-300">¹⁷ as part of the Fiat-Shamir heuristic in the non-interactive case or sent by the verifier in the interactive case.</p>

    <p class="text-gray-300">¹⁸ Recall that the trace cells are ordered chronologically according to the execution of the program.</p>

    <p class="text-gray-300">cations, one of the outputs of a Cairo program that should be accessible to the verifier is a log of all the changes to the state of the application. Its purpose is not to be processed by the verifier, but rather to only be written on-chain so that users will be able to inspect it if needed (this is sometimes referred to as "data availability" or "on-chain data" and used for common constructions such as a "ZK-Rollup"). Usually, this log is very large, and it is extremely important to reduce the linear verification cost (for example, in the Ethereum blockchain, this cost is measured in "gas") that is involved during its processing as much as possible. This can be done using the public memory mechanism: one may put the data in a contiguous segment of memory cells and include those cells in the public memory. Then, the verification cost is the sum of the cost of transmitting the data to the blockchain and the computation cost of only 4 arithmetic operations per data element and the hash of the data.</p>

    <p class="text-gray-300">Note that this is not the only possible solution. An alternative way for handling such data, which has even cheaper verification costs, is to compute the hash of the data by the verifier, using a blockchain-friendly hash function, and make the same hash computation as part of the statement being proven. The problem with this approach, is that typically blockchain-friendly hash functions are not STARK-friendly<span class="math">^{19}</span> which means that using this method significantly increases the proving costs.</p>

    <h2 id="sec-17" class="text-2xl font-bold">2.7 Program input and program output</h2>

    <p class="text-gray-300">A Cairo program may have:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><strong>Program input</strong> – the input of the program. This data is not shared with the verifier. In terms of proof systems, this is the witness<span class="math">^{20}</span>.</li>

      <li><strong>Program output</strong> – the data that is generated during the execution of the program, that is shared with the verifier. It will become part of the data externalized using the public memory mechanism (Section 2.6.1).</li>

    </ul>

    <p class="text-gray-300">It is possible that some data will be both program input and program output? Consider, for example, a Cairo program given (as an input) a number <span class="math">n</span> and computes the <span class="math">n</span>-th Fibonacci number, <span class="math">y</span>. In this case, the program input is <span class="math">n</span>. Let's consider a few options for the program output and the statement each of them induces:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>If the program output contains both <span class="math">n</span> and <span class="math">y</span>, the statement being proven is "the <span class="math">n</span>-th Fibonacci number is <span class="math">y</span>".</li>

    </ul>

    <p class="text-gray-300"><span class="math">^{19}</span>This means that computing such a hash function as part of the statement being proven costs a large number of trace cells.</p>

    <p class="text-gray-300"><span class="math">^{20}</span>Note that when one proof system is based on another system, each of them has its own witness, and, usually, the outer proof system has to translate its witness to a witness of the inner proof system. Thus, the witness of the Cairo proof system is the program input, and the witness of the STARK proof system is the AIR's trace.</p>

    <p class="text-gray-300">20</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>If the program output contains only <span class="math">y</span>, the statement being proven is “I know <span class="math">n</span> such that the <span class="math">n</span>-th Fibonacci number is <span class="math">y</span>” (but <span class="math">n</span> is not explicitly shared with the verifier).</li>

      <li>If the program output contains only <span class="math">n</span>, the statement being proven is “I have computed the <span class="math">n</span>-th Fibonacci number” (but the result is not explicitly shared with the verifier).</li>

    </ul>

    <h4 id="sec-18" class="text-lg font-semibold mt-6">2.7.1 Program input</h4>

    <p class="text-gray-300">Handling the program input is easy – one may use the hint mechanism to parse the input, which may be given in any desired format (recall that hints can be theoretically written in any programming language) and update uninitialized memory cells accordingly. For example, in the current implementation of the Cairo Runner <em>[4]</em>, the program input is a JSON file which is read by the program-specific hints.</p>

    <p class="text-gray-300">Consider the Fibonacci example above. The program input may be a JSON file of the form <span class="math">\\{\\verb&quot;n&quot;:\\verb&quot;5&quot;}\\}</span>. A hint at the beginning of the program may read this file, fetch the value of <span class="math">n</span>, and place it in a certain memory cell. The Cairo code will then pass the value of that cell to the Fibonacci function.</p>

    <h4 id="sec-19" class="text-lg font-semibold mt-6">2.7.2 Program output</h4>

    <p class="text-gray-300">The program output is handled as follows: the Cairo program writes the values of the output data to a contiguous segment of memory cells. The start and end addresses of this segment are stored in the memory in addresses that can be computed by the verifier (for example, relative to the initial and final value of the ap register, which are part of the information available to the verifier. See Section 3.2). The values of all the memory cells involved (the memory cells containing the output data, as well as the two cells containing the start and end addresses of the segment) are externalized to the verifier using the public memory mechanism (Section 2.6.1). In other words, the prover sends the start and end addresses of the segment, as well as all of the values in the segment, and the verifier incorporates them in Eq. (1) to validate their consistency with the proof.</p>

    <h3 id="sec-20" class="text-xl font-semibold mt-8">2.8 Builtins</h3>

    <p class="text-gray-300">As we have seen in the previous sections, adding a new instruction to the instruction set has a cost even if this instruction is not used. On the other hand, trying to implement some primitives using only Cairo instructions may be inefficient, as a lot of instructions may be required – even for relatively simple tasks such as integer division.</p>

    <p class="text-gray-300">To overcome this conflict, while also supporting predefined tasks without the need to add new instructions, Cairo introduces the concept of <em>builtins</em>.</p>

    <p class="text-gray-300">A builtin enforces some constraints (which depend on the builtin) on the Cairo memory. For example, a builtin may enforce that all the values for the memory cells in some fixed address range are within the range  <span class="math">[0, 2^{128})</span> . In fact, this is a very useful builtin, as we will see in Section 8. We call it the range-check builtin and the memory cells constrained by the builtin range-checked cells.</p>

    <p class="text-gray-300">Cairo doesn't have a special instruction to invoke a builtin. Instead, one should simply read or write values in the memory cells affected by the builtin. This kind of communication is also known as memory-mapped I/O [21]. Take the range-check builtin, for example, if you want to verify that a value  <span class="math">x</span>  is within the range  <span class="math">[0, 2^{128})</span> , just copy it (using a Cairo instruction) to a range-checked cell. If you want to verify that  <span class="math">x</span>  is within the range  <span class="math">[0, B]</span>  where  <span class="math">B &amp;lt; 2^{128}</span> , you can write  <span class="math">x</span>  to one range-checked cell and  <span class="math">B - x</span>  to another.</p>

    <p class="text-gray-300">In terms of building the AIR, it means that adding builtins does not affect the CPU constraints. It just means that the same memory is shared between the CPU and the builtins. Figure 2 shows the relationship between the CPU, the memory, and the builtins: in order to "invoke" a builtin, the Cairo program "communicates" with certain memory cells, and the builtin enforces some constraints on those memory cells.</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Figure 2: The relationship between the Cairo components.</p>

    <p class="text-gray-300">It is important to note that builtins are an optional part of the Cairo architecture: one may replace using a builtin with a piece of pure Cairo code that does the same <span class="math">^{21}</span>  (taking advantage of nondeterministic programming). For example, to implement the range-check builtin, one could "guess" the 128 field elements  <span class="math">b_{i}</span>  that form the binary representation of  <span class="math">x_{i}</span>  assert that  <span class="math">b_{i}^{2} = b_{i}</span>  for all  <span class="math">i \\in [0,128)</span>  and that  <span class="math">x = \\sum_{i} 2^{i} \\cdot b_{i}</span> . This enforces that  <span class="math">x</span>  is within the expected range. However, compare the costs of the two approaches: the above computation takes at least  <span class="math">3 \\cdot 128</span>  Cairo instructions. Using a builtin (implemented with the range-check techniques presented in Section 9.9), it takes the number of trace cells equivalent to about 1.5 instructions.</p>

    <p class="text-gray-300">The Cairo architecture does not specify a specific set of builtins. One may add or remove builtins from the AIR according to one’s needs. For example, if a program needs to invoke the Pedersen hash numerous times, it makes sense to run it on an architecture with a builtin that computes the Pedersen hash. On the other hand, a program that uses this builtin will not be able to run on an architecture where this builtin is missing. Note that adding builtins implies adding constraints, which increases the verification time.</p>

    <h2 id="sec-21" class="text-2xl font-bold">3 The Cairo framework</h2>

    <p class="text-gray-300">We now give a formal definition to the term “the Cairo machine”. In fact, we define two versions: a deterministic and nondeterministic, where the latter is based on the former.</p>

    <p class="text-gray-300">The deterministic Cairo machine by itself does not perform a computation. Instead, it verifies that a given computation trace is valid. One can imagine a machine that is given a sequence of states and a memory function, and checks whether the transition between two consecutive states is valid (according to the rules presented in Section 4.5). It returns “accept” if all the state transitions are valid with respect to the memory; and “reject” otherwise. The term “deterministic” is pertinent due to the fact that the decision problem, whether it accepts or rejects, can be solved efficiently using a deterministic Turing Machine.</p>

    <p class="text-gray-300">The nondeterministic version gets a partial memory function (which can be thought of as boundary constraints on the full memory function) and only the initial and final states (rather than the full list of states). It accepts, if there exist a list of states and a full memory function that are consistent with the inputs that the deterministic version accepts.</p>

    <p class="text-gray-300">We close this section with a description of the Cairo Runner, a concrete realization of those theoretical models, and show how one can use the Cairo Runner to transform a statement, such as “the <span class="math">j</span>-th Fibonacci number is <span class="math">y</span>”, into inputs for the deterministic machine (which is used by the prover) and the nondeterministic machine (which is used by the verifier), in such a way that if the machine accepts, this implies that the statement is true. The Cairo AIR, presented in Section 9, allows one to use the STARK protocol in order to prove that the nondeterministic Cairo machine accepts those inputs, thus proving that the original statement is true.</p>

    <h3 id="sec-22" class="text-xl font-semibold mt-8">3.1 The deterministic Cairo machine</h3>

    <p class="text-gray-300">Fix a prime field <span class="math">\\mathbb{F}_{P}=\\mathbb{Z}/P</span> and a finite extension field <span class="math">\\mathbb{F}</span> of it.</p>

    <h6 id="sec-23" class="text-base font-medium mt-4">Definition 1.</h6>

    <p class="text-gray-300">The Cairo machine is a function that receives the following inputs</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>a number of steps <span class="math">T \\in \\mathbb{N}</span>,</li>

      <li>a memory function <span class="math">\\mathfrak{m} \\colon \\mathbb{F} \\to \\mathbb{F}</span>,</li>

      <li>a sequence <span class="math">S</span> of <span class="math">T + 1</span> states <span class="math">S_{i} = (\\mathsf{pc}_{i},\\mathsf{ap}_{i},\\mathsf{fp}_{i}) \\in \\mathbb{F}^{3}</span> for <span class="math">i \\in [0,T]</span>.</li>

    </ol>

    <p class="text-gray-300">and outputs either "accept" or "reject".</p>

    <p class="text-gray-300">It accepts if, and only if, for every <span class="math">i</span>, the state transition from state <span class="math">i</span> to state <span class="math">i + 1</span> is valid. Section 4.5 describes what constitutes a valid state transition of the machine.</p>

    <p class="text-gray-300">Note that the decision as to whether a single transition is valid depends only on the two states involved (that is <span class="math">S_{i}</span> and <span class="math">S_{i+1}</span>) and the memory function <span class="math">\\mathfrak{m}</span>. In particular, the memory function used for the state transition logic is the same for all <span class="math">i</span>. In other words, the Cairo memory is immutable (read-only) rather than read-write.</p>

    <p class="text-gray-300">We call the sequence of states <span class="math">S</span> the Cairo execution trace. We refer to the state <span class="math">S_0</span> as the initial state and to <span class="math">S_T</span> as the final state.</p>

    <p class="text-gray-300">The memory function is defined formally as a function <span class="math">\\mathfrak{m} \\colon \\mathbb{F} \\to \\mathbb{F}</span>, but, since in practical applications <span class="math">\\mathbb{F}</span> is usually huge and at most <span class="math">O(T)</span> values of <span class="math">\\mathfrak{m}</span> are accessed during the computation, we can treat <span class="math">\\mathfrak{m}</span> as a sparse function where almost all the values are zeros.</p>

    <p class="text-gray-300">Example 1 (The Fibonacci Sequence). Let <span class="math">S_0 = (0,5,5)</span> and let <span class="math">\\mathfrak{m}</span> satisfy</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\mathfrak{m}(0) = 0 \\times 48307 \\text{ffe7fff8000}, \\\\ \\mathfrak{m}(1) = 0 \\times 010780017 \\text{fff7fff}, \\\\ \\mathfrak{m}(2) = -1, \\\\ \\mathfrak{m}(3) = 1, \\\\ \\mathfrak{m}(4) = 1, \\end{array} \\tag{2}</span></div>

    <p class="text-gray-300">In Section 4.5, you will see that the first two constants represent Cairo instructions. The exact way the encoding works is not important for this example.</p>

    <p class="text-gray-300">Note that,</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For the state transition <span class="math">S_0 \\to S_1</span>, we have</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\mathfrak{m}(\\mathsf{pc}_0) = \\mathfrak{m}(0) = 0 \\times 48307 \\text{ffe7fff8000}.</span></div>

    <p class="text-gray-300">Careful review of Section 4.5 reveals that this implies that the state transition from <span class="math">S_0</span> to <span class="math">S_1</span> is valid if, and only if,</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\mathsf{pc}_1 = \\mathsf{pc}_0 + 1, \\quad \\mathsf{ap}_1 = \\mathsf{ap}_0 + 1, \\quad \\mathsf{fp}_1 = \\mathsf{fp}_0, \\quad \\text{and} \\\\ \\mathfrak{m}(\\mathsf{ap}_0) = \\mathfrak{m}(\\mathsf{ap}_0 - 1) + \\mathfrak{m}(\\mathsf{ap}_0 - 2). \\end{array}</span></div>

    <p class="text-gray-300">24</p>

    <p class="text-gray-300">Therefore, if we want the Cairo machine to accept, we must set <span class="math">S_{1} = (1,6,5)</span> and <span class="math">\\mathfrak{m}(5) = \\mathfrak{m}(4) + \\mathfrak{m}(3) = 2</span>.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For the state transition <span class="math">S_{1} \\to S_{2}</span>, we have</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\mathfrak{m}(\\mathfrak{pc}_{1}) = \\mathfrak{m}(1) = 0 \\times 010780017 \\text{fff7fff}.</span></div>

    <p class="text-gray-300">It will follow from Section 4.5 that the state transition from <span class="math">S_{1}</span> to <span class="math">S_{2}</span> is valid if, and only if, <span class="math">\\mathsf{pc}_2 = \\mathsf{pc}_1 + \\mathfrak{m}(\\mathsf{pc}_1 + 1)</span> (that is, <span class="math">\\mathsf{pc}_2 = 1 + \\mathfrak{m}(2) = 1 + (-1) = 0</span>), <span class="math">\\mathsf{ap}_2 = \\mathsf{ap}_1</span> and <span class="math">\\mathsf{fp}_2 = \\mathsf{fp}_1</span>. So, we must set <span class="math">S_{2} = (0,6,5)</span>.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For the state transition <span class="math">S_{2} \\to S_{3}</span>, once again the "current" <span class="math">\\mathfrak{pc}</span> is 0, so the constraints are similar to those of the first state transition: <span class="math">\\mathfrak{pc}_3 = \\mathfrak{pc}_2 + 1</span>, <span class="math">\\mathfrak{ap}_3 = \\mathfrak{ap}_2 + 1</span>, <span class="math">\\mathfrak{fp}_2 = \\mathfrak{fp}_2</span> and <span class="math">\\mathfrak{m}(\\mathfrak{ap}_2) = \\mathfrak{m}(\\mathfrak{ap}_2 - 1) + \\mathfrak{m}(\\mathfrak{ap}_2 - 2)</span>. We deduce that we have to set <span class="math">S_{3} = (1,7,5)</span> and <span class="math">\\mathfrak{m}(6) = \\mathfrak{m}(5) + \\mathfrak{m}(4)</span>.</li>

    </ol>

    <p class="text-gray-300">One may observe that this behavior repeats itself: <span class="math">\\mathsf{fp}</span> remains constant, <span class="math">\\mathsf{pc}</span> alternates between 0 and 1, and each time it is 0 it forces <span class="math">\\mathfrak{m}(\\mathfrak{ap}_2) = \\mathfrak{m}(\\mathfrak{ap}_2 - 1) + \\mathfrak{m}(\\mathfrak{ap}_2 - 2)</span>, and increases <span class="math">\\mathfrak{ap}</span> by 1. Thus, the only way the Cairo machine returns "accept" is if the memory function continues with the Fibonacci sequence (starting from <span class="math">\\mathfrak{m}(3)</span>). To be more accurate, the values <span class="math">\\mathfrak{m}(3), \\mathfrak{m}(4), \\ldots, \\mathfrak{m}(4 + \\lceil T / 2 \\rceil)</span> should form the Fibonacci sequence.</p>

    <h2 id="sec-24" class="text-2xl font-bold">3.2 The nondeterministic Cairo machine</h2>

    <p class="text-gray-300"><strong>Definition 2.</strong> The nondeterministic Cairo machine is a nondeterministic version of the Cairo machine. It is a function that receives the following inputs:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>a number of steps <span class="math">T \\in \\mathbb{N}</span>,</li>

      <li>a partial memory function <span class="math">\\mathfrak{m}^<em> \\colon A^</em> \\to \\mathbb{F}</span>, where <span class="math">A^* \\subseteq \\mathbb{F}_P</span>,</li>

      <li>initial and final values for <span class="math">\\mathfrak{pc}</span> and <span class="math">\\mathfrak{ap}</span>: <span class="math">\\mathfrak{pc}_I</span>, <span class="math">\\mathfrak{pc}_F</span>, <span class="math">\\mathfrak{ap}_I</span>, and <span class="math">\\mathfrak{ap}_F</span> (<span class="math">\\mathfrak{ap}_I</span> is also used as the initial value for <span class="math">\\mathfrak{fp}</span>),</li>

    </ol>

    <p class="text-gray-300">and outputs "accept" or "reject".</p>

    <p class="text-gray-300">It accepts the input <span class="math">(T, \\mathfrak{m}^<em>, \\mathfrak{pc}_I, \\mathfrak{pc}_F, \\mathfrak{ap}_I, \\mathfrak{ap}_F)</span> if, and only if, there exists a memory function <span class="math">\\mathfrak{m} \\colon \\mathbb{F} \\to \\mathbb{F}</span> extending <span class="math">^{23}\\mathfrak{m}^</em></span>, and a list of states <span class="math">S_i = (\\mathfrak{pc}_i, \\mathfrak{ap}_i, \\mathfrak{fp}_i) \\in \\mathbb{F}^3</span> for <span class="math">i \\in [0, T]</span> satisfying <span class="math">(\\mathfrak{pc}_0, \\mathfrak{ap}_0, \\mathfrak{fp}_0) = (\\mathfrak{pc}_I, \\mathfrak{ap}_I, \\mathfrak{ap}_I)</span>, <span class="math">\\mathfrak{pc}_T = \\mathfrak{pc}_F</span> and <span class="math">\\mathfrak{ap}_T = \\mathfrak{ap}_F</span>, such that the deterministic Cairo machine from Definition 1 accepts the input <span class="math">(T, \\mathfrak{m}, S)</span>.</p>

    <p class="text-gray-300">Note, the main differences between Definitions 1 and 2:</p>

    <p class="text-gray-300">23 We say that <span class="math">\\mathfrak{m}</span> extends <span class="math">\\mathfrak{m}^<em></span> if both functions agree on <span class="math">A^</em></span>.</p>

    <p class="text-gray-300">25</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The deterministic version from Definition 1 gets the full list of states, while the nondeterministic version from Definition 2 only gets the initial and final values of pc and ap.</li>

      <li>The deterministic version gets the full memory function, while the nondeterministic version only gets a partial function.</li>

      <li>Computing whether the deterministic version accepts a particular input or not, can be done in polynomial time using a deterministic machine. For the nondeterministic version, one needs a nondeterministic machine in order to do it in polynomial time (see the discussion in Section 2.5).</li>

    </ul>

    <h6 id="sec-25" class="text-base font-medium mt-4">Example 2.</h6>

    <p class="text-gray-300">Let <span class="math">T&lt;P</span> be an even number, <span class="math">2\\leq j\\leq T/2</span> and <span class="math">y\\in\\mathbb{F}</span>. Set <span class="math">A^{<em>}=\\{0,1,2,3,4,j+3\\}</span>, <span class="math">\\mathsf{pc}_{I}=0</span>, <span class="math">\\mathsf{pc}_{F}=1,\\mathsf{ap}_{I}=5,\\mathsf{ap}_{F}=5+T/2</span>. Let <span class="math">\\mathfrak{m}^{</em>}\\colon A^{<em>}\\to\\mathbb{F}</span> have the same values that appear in (2) for <span class="math">0,\\ldots,4</span> and set <span class="math">\\mathfrak{m}^{</em>}(j+3)=y</span>. We claim that the nondeterministic Cairo machine accepts this input if, and only if, the <span class="math">j</span>-th Fibonacci number is <span class="math">y</span>. In fact, this follows from the last example: the nondeterministic Cairo machine accepts if, and only if, there exists a memory function extending <span class="math">\\mathfrak{m}^{<em>}</span> that makes the deterministic version accept. But as we saw, the deterministic version accepts only if the values <span class="math">\\mathfrak{m}(3),\\mathfrak{m}(4),\\ldots,\\mathfrak{m}(4+T/2)</span> form the Fibonacci sequence. In particular, <span class="math">\\mathfrak{m}(j+3)</span> is the <span class="math">j</span>-th Fibonacci number, but it must be equal to <span class="math">\\mathfrak{m}^{</em>}(j+3)=y</span>.</p>

    <h6 id="sec-26" class="text-base font-medium mt-4">Note 1.</h6>

    <p class="text-gray-300">Due to performance considerations of the Cairo AIR (more specifically, the implementation of the Cairo memory in the AIR. See Section 9.7), the AIR will enforce stricter constraints than just the fact that the nondeterministic Cairo machine accepts: the memory accesses performed during the execution of the code must result in a continuous address range. That is, the set of accessed addresses must be of the form <span class="math">\\{a_{0}+i:i\\in[0,k)\\}</span> for some initial address <span class="math">a_{0}</span> and some natural number <span class="math">k</span>. In particular, it means that only addresses from <span class="math">\\mathbb{F}_{P}</span> can be used (rather than addresses from the extension field, <span class="math">\\mathbb{F}</span>), and this is the reason <span class="math">A^{*}</span> is a subset of <span class="math">\\mathbb{F}_{P}</span>. We treat this additional requirement as follows: the programmer of Cairo code should not rely on this continuity guarantee (from a soundness perspective), but they should write the program such that this requirement will be satisfied if the inputs are valid (for completeness).</p>

    <h3 id="sec-27" class="text-xl font-semibold mt-8">3.3 The Cairo program bytecode</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The Cairo program bytecode is a sequence of field elements $\\mathfrak{b}=(\\mathfrak{b}_{0},\\ldots,\\mathfrak{b}_{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathfrak{b}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-1})<span class="math"> together with two indices </span>\\text{prog}_{\\text{start}},\\text{prog}_{\\text{end}}\\in[0,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathfrak{b}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> that define the computation we want the Cairo machine to perform. In order to “run” the program, we pick a field element </span>\\text{prog}_{\\text{base}}\\in\\mathbb{F}_{P}<span class="math">, which is called the program base, set the partial memory function </span>\\mathfrak{m}^{<em>}<span class="math"> so that </span>\\mathfrak{m}^{</em>}(\\text{prog}_{\\text{base}}+i)=\\mathfrak{b}_{i}<span class="math"> for </span>i\\in[0,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathfrak{b}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">, and set </span>\\mathsf{pc}_{I}=\\text{prog}_{\\text{base}}+\\text{prog}_{\\text{start}}<span class="math">, </span>\\mathsf{pc}_{F}=\\text{prog}_{\\text{base}}+\\text{prog}_{\\text{end}}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">######</p>

    <p class="text-gray-300">In addition to the bytecode of the program, the partial memory function may contain additional entries that provide additional constraints on the execution of the code (for example, input arguments for the execution are handled this way).</p>

    <h6 id="sec-28" class="text-base font-medium mt-4">Example 3.</h6>

    <p class="text-gray-300">The bytecode of the Fibonacci program in the previous example was:</p>

    <p class="text-gray-300"><span class="math">\\mathsf{b}=(0\\mathsf{x48307}\\mathsf{f}\\mathsf{f}\\mathsf{e}7\\mathsf{f}\\mathsf{f}\\mathsf{f}8000,0\\mathsf{x010780017}\\mathsf{f}\\mathsf{f}\\mathsf{f}\\mathsf{f}7\\mathsf{f}\\mathsf{f},-1),\\quad\\mathsf{prog}_{\\mathsf{start}}=0.</span></p>

    <p class="text-gray-300">The bytecode was “loaded” to <span class="math">\\mathsf{m}^{<em>}(0),\\mathsf{m}^{</em>}(1),\\mathsf{m}^{*}(2)</span>, so the program base in that example was <span class="math">\\mathsf{prog}_{\\mathsf{base}}=0</span>.</p>

    <p class="text-gray-300">The values <span class="math">\\mathsf{m}^{<em>}(3),\\mathsf{m}^{</em>}(4),\\mathsf{m}^{<em>}(3+j)</span> (or, in the more general form: <span class="math">\\mathsf{m}^{</em>}(\\mathsf{a}\\mathsf{p}_{I}-2),\\mathsf{m}^{<em>}(\\mathsf{a}\\mathsf{p}_{I}-1),\\mathsf{m}^{</em>}(\\mathsf{a}\\mathsf{p}_{I}-2+j)</span>) are the additional constraints.</p>

    <h3 id="sec-29" class="text-xl font-semibold mt-8">3.4 Cairo programs</h3>

    <p class="text-gray-300">The following Fibonacci program is written in Cairo assembly (see Section 5 for more detail). For convenience, we added the state transition constraints of each instruction (all of the instructions in the example imply <span class="math">\\mathsf{f}\\mathsf{p}_{i+1}=\\mathsf{f}\\mathsf{p}_{i}</span>).</p>

    <h6 id="sec-30" class="text-base font-medium mt-4">Example 4.</h6>

    <p class="text-gray-300">[ap] = 1; ap++</p>

    <p class="text-gray-300"><span class="math">\\mathrm{pc}_{i+1}=\\mathrm{pc}_{i}+2,\\quad\\mathrm{ap}_{i+1}=\\mathrm{ap}_{i}+1,\\quad\\mathrm{m}(\\mathrm{ap}_{i})=1</span></p>

    <p class="text-gray-300">[ap] = 1; ap++</p>

    <p class="text-gray-300"><span class="math">\\mathrm{pc}_{i+1}=\\mathrm{pc}_{i}+2,\\quad\\mathrm{ap}_{i+1}=\\mathrm{ap}_{i}+1,\\quad\\mathrm{m}(\\mathrm{ap}_{i})=1</span></p>

    <p class="text-gray-300">body:</p>

    <p class="text-gray-300">[ap] = [ap - 3] - 1; ap++</p>

    <p class="text-gray-300"><span class="math">\\mathrm{pc}_{i+1}=\\mathrm{pc}_{i}+2,\\quad\\mathrm{ap}_{i+1}=\\mathrm{ap}_{i}+1,</span></p>

    <p class="text-gray-300"><span class="math">\\mathrm{m}(\\mathrm{ap}_{i})=\\mathrm{m}(\\mathrm{ap}_{i}-3)-1</span></p>

    <p class="text-gray-300">[ap] = [ap - 2]; ap++</p>

    <p class="text-gray-300"><span class="math">\\mathrm{pc}_{i+1}=\\mathrm{pc}_{i}+1,\\quad\\mathrm{ap}_{i+1}=\\mathrm{ap}_{i}+1,\\quad\\mathrm{m}(\\mathrm{ap}_{i})=\\mathrm{m}(\\mathrm{ap}_{i}-2)</span></p>

    <p class="text-gray-300">[ap] = [ap - 3] + [ap - 4]; ap++</p>

    <p class="text-gray-300"><span class="math">\\mathrm{pc}_{i+1}=\\mathrm{pc}_{i}+1,\\quad\\mathrm{ap}_{i+1}=\\mathrm{ap}_{i}+1,</span></p>

    <p class="text-gray-300"><span class="math">\\mathrm{m}(\\mathrm{ap}_{i})=\\mathrm{m}(\\mathrm{ap}_{i}-3)+\\mathrm{m}(\\mathrm{ap}_{i}-4)</span></p>

    <p class="text-gray-300">jmp body if [ap - 3] != 0</p>

    <p class="text-gray-300">\\[ \\mathrm{pc}_{i+1}=\\begin{cases}\\mathrm{pc}_{i}-4,&\\mathrm{m}(\\mathrm{ap}_{i}-3)\\neq 0\\\\ \\mathrm{pc}_{i}+2,&\\mathrm{otherwise}\\end{cases},\\quad\\mathrm{ap}_{i+1}=\\mathrm{ap}_{i}, \\]</p>

    <p class="text-gray-300">___end__:</p>

    <p class="text-gray-300">jmp __end__ # Infinite loop</p>

    <p class="text-gray-300"><span class="math">\\mathrm{pc}_{i+1}=\\mathrm{pc}_{i},\\quad\\mathrm{ap}_{i+1}=\\mathrm{ap}_{i}</span></p>

    <p class="text-gray-300">This program works as follows: it assumes that <span class="math">\\mathfrak{m}(\\mathsf{ap}_{f}-1)=j</span> is the index of the Fibonacci number we want to compute. After the first two steps, we have <span class="math">(\\mathfrak{m}(\\mathsf{ap}-3),\\mathfrak{m}(\\mathsf{ap}-2),\\mathfrak{m}(\\mathsf{ap}-1))=(j,1,1)</span>. After the next three steps, the values are <span class="math">(j-1,1,2)</span>. Then we check whether <span class="math">j-1=0</span>. If not, we jump back to the body label. After another iteration the values are <span class="math">(j-2,2,3)</span>, then <span class="math">(j-3,3,5)</span>, <span class="math">(j-4,5,8)</span>, and so on. When the iteration counter gets to 0, we start an infinite loop. At that point, the result is <span class="math">\\mathfrak{m}(\\mathsf{ap}-2)</span>. Since the loop keeps the value of <span class="math">\\mathsf{ap}</span> constant, the result can be found in <span class="math">\\mathfrak{m}(\\mathsf{ap}_{F}-2)</span>.</p>

    <p class="text-gray-300">A Cairo assembler can take this program and turn it into Cairo bytecode:</p>

    <p class="text-gray-300"><span class="math">\\mathsf{b}=</span> <span class="math">(0x480680017fff8000,1,</span> <span class="math">0x480680017fff8000,1,</span> <span class="math">0x482480017ffd8000,-1,</span> <span class="math">0x48127ffe7fff8000,</span> <span class="math">0x48307ffc7ffd8000,</span> <span class="math">0x20680017fff7ffd,-4,</span> <span class="math">0x10780017fff7fff,0)</span> <span class="math">\\text{prog}_{\\text{start}}=0,\\quad\\text{prog}_{\\text{end}}=10.</span></p>

    <p class="text-gray-300">Usually, the last instruction of a Cairo program is an infinite loop – this makes the number of steps, <span class="math">T</span>, independent of the program, as long as it is large enough to make the program reach <span class="math">\\text{prog}_{\\text{end}}</span>.</p>

    <h3 id="sec-36" class="text-xl font-semibold mt-8">3.5 The Cairo Runner</h3>

    <p class="text-gray-300">The Cairo Runner is a computer program responsible for executing a compiled Cairo program. Executing a Cairo program is different from executing a regular computer program. The main difference is due to the fact that Cairo allows nondeterministic code. For example, the following Cairo instruction “computes” the square root of <span class="math">25</span> by asserting that the square of an uninitialized cell is <span class="math">25</span>:</p>

    <pre><code class="language-text">[ap] = 25; ap++
# [ap - 1] is now 25, so the next line enforces that [ap] is the
# square root of 25.
[ap - 1] = [ap] * [ap]; ap++</code></pre>

    <p class="text-gray-300">In fact, even if we recognize this particular instruction as saying; “take the square root of <span class="math">[\\mathsf{ap}-1]</span>”, there are <span class="math">2</span> possible values: <span class="math">5</span> and <span class="math">-5</span>, and it is possible that only one of them will allow satisfying the rest of the instructions. In a similar way, you can write a Cairo program that solves an NP-complete problem, such as SAT.</p>

    <p class="text-gray-300">This means that some Cairo programs cannot be efficiently executed without some additional information (such as the specific square root of <span class="math">25</span></p>

    <p class="text-gray-300">or a satisfying SAT assignment). This information is given by what we call <em>hints</em>. Hints are special instructions for the Cairo Runner; used to resolve nondeterminism where a value cannot be easily deduced. In theory, hints can be written in any programming language. For example, in the existing implementation of the Cairo Runner (see <em>[4]</em>), the hints are code blocks of Python code.</p>

    <p class="text-gray-300">The output of the Runner consists of</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>an accepting input to the Cairo nondeterministic machine:</li>

    </ol>

    <p class="text-gray-300"><span class="math">(T,\\mathfrak{m}^{*},\\mathfrak{pc}_{I},\\mathfrak{pc}_{F},\\mathfrak{ap}_{I},\\mathfrak{ap}_{F}),</span></p>

    <p class="text-gray-300">where <span class="math">\\mathfrak{m}^{<em>}</span> includes the program bytecode (starting at <span class="math">\\text{prog}_{\\text{base}}</span>) and any additional information that should be revealed (the hints may specify what memory cells should be added to <span class="math">\\mathfrak{m}^{</em>}</span>), <span class="math">\\mathfrak{pc}_{I}=\\text{prog}_{\\text{base}}+\\text{prog}_{\\text{start}}</span> and <span class="math">\\mathfrak{pc}_{F}=\\text{prog}_{\\text{base}}+\\text{prog}_{\\text{end}}</span>.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>an accepting input to the Cairo deterministic machine, <span class="math">(T,\\mathfrak{m},S)</span> that constitutes the witness to the nondeterministic machine.</li>

    </ol>

    <p class="text-gray-300">Alternatively, the Runner may return a failure in the case that the execution results in a contradiction, or was unable to compute the value of a memory cell due to insufficient hints.</p>

    <h6 id="sec-37" class="text-base font-medium mt-4">Example 5.</h6>

    <p class="text-gray-300">Continuing with Example 4, the hints will have to set <span class="math">\\mathfrak{m}(\\mathfrak{ap}_{I}-1)=j</span> and add <span class="math">\\mathfrak{ap}_{I}-1</span> and <span class="math">\\mathfrak{ap}_{F}-2</span> to <span class="math">A^{*}</span> (in order to reveal which Fibonacci number was computed and what the result was).</p>

    <h3 id="sec-38" class="text-xl font-semibold mt-8">3.6 Generating proofs of computational integrity using Cairo</h3>

    <p class="text-gray-300">Below is an overview of the process of generating a proof of computational integrity for a given computation. We use the following assertion as an example of what we wish to prove:</p>

    <p class="text-gray-300">“The <span class="math">j</span>-th Fibonacci number is <span class="math">y</span>”. (3)</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Write a Cairo program for the computation (either using the Cairo assembly language directly or using any other language that can be compiled to Cairo bytecode); with hints that resolve the nondeterministic components. In our example, we use the code of Example 4 with a hint that set <span class="math">\\mathfrak{m}^{*}(\\mathfrak{ap}_{I}-1)=j</span>.</li>

      <li>Compile the program to Cairo bytecode.</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run the program using the Cairo Runner to obtain the execution trace <span class="math">S</span>, the partial memory function <span class="math">\\mathfrak{m}^{<em>}</span>, and the full memory function <span class="math">\\mathfrak{m}</span>. In our case, <span class="math">\\mathfrak{m}^{</em>}</span> will include the program bytecode, <span class="math">\\mathfrak{m}^{<em>}(\\mathsf{ap}_{I}-1)=j</span> for the index, and <span class="math">\\mathfrak{m}^{</em>}(\\mathsf{ap}_{F}-2)=y</span> for the result.</li>

      <li>Use a STARK prover for the Cairo AIR to generate a proof for the assertion:</li>

    </ol>

    <p class="text-gray-300">“The nondeterministic Cairo machine accepts given the input <span class="math">(T,\\mathfrak{m}^{*},\\mathsf{pc}_{I},\\mathsf{pc}_{F},\\mathsf{ap}_{I},\\mathsf{ap}_{F})</span>”. (4)</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We now have to show that the correctness of (4) implies the correctness of (3): The fact that the nondeterministic Cairo machine accepts implies that there exists an input <span class="math">(T,\\mathfrak{m},S)</span> accepted by the deterministic Cairo machine. Since <span class="math">\\mathfrak{m}</span> extends <span class="math">\\mathfrak{m}^{*}</span>, we know that the bytecode of the Fibonacci program appears in $\\{\\mathfrak{m}(\\text{prog}_{\\text{base}}+i)\\}_{i\\in[0,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathfrak{b}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)}<span class="math">. Moreover, since </span>\\mathsf{pc}_{I}=\\text{prog}_{\\text{base}}+\\text{prog}_{\\text{start}}<span class="math">, we deduce that the first instruction that is executed by the deterministic Cairo machine is the first instruction of the Fibonacci program. Similarly, the rest of the program’s instructions will be executed, for </span>T<span class="math"> steps. As </span>\\mathsf{pc}_{F}=\\text{prog}_{\\text{base}}+\\text{prog}_{\\text{end}}<span class="math">, we know that the infinite loop at the end of the program was reached, which implies that the program was completed successfully, and that the </span>j<span class="math">-th Fibonacci number is equal to </span>\\mathfrak{m}(\\mathsf{ap}_{F}-2)=\\mathfrak{m}^{*}(\\mathsf{ap}_{F}-2)=y$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h2 id="sec-39" class="text-2xl font-bold">4 The CPU architecture</h2>

    <p class="text-gray-300">The Cairo architecture, which defines the core of the deterministic Cairo machine, presented in Section 3.1, consists of a “CPU” that operates on 3 registers – <span class="math">\\mathsf{pc}</span>, <span class="math">\\mathsf{ap}</span>, and <span class="math">\\mathsf{fp}</span>, and has access to the (read-only) memory, <span class="math">\\mathfrak{m}</span>.</p>

    <h3 id="sec-40" class="text-xl font-semibold mt-8">4.1 The registers</h3>

    <p class="text-gray-300">contains the address in memory of the current Cairo instruction to be executed. , by convention, points to the first memory cell that has not been used by the program so far. Many instructions may increase its value by one to indicate that another memory cell has been used by the instruction. Note that this is merely a convention – the Cairo machine does not force that the memory cell <span class="math">\\mathsf{ap}</span> has not been used, and the programmer may decide to use it in different ways. points to the beginning of the stack frame of the current function. The value of <span class="math">\\mathsf{fp}</span> allows a stack-like behavior: When a function starts, <span class="math">\\mathsf{fp}</span> is set to be the same as the current <span class="math">\\mathsf{ap}</span>, and when</p>

    <p class="text-gray-300">the function returns, fp resumes its previous value. Thus, the value of fp stays the same for all the instructions in the same invocation of a function. Due to this property, fp may be used to address the function’s arguments and local variables. See more in Section 6.</p>

    <h3 id="sec-41" class="text-xl font-semibold mt-8">4.2 The memory</h3>

    <p class="text-gray-300">The CPU has access to a nondeterministic read-only random-access memory. Read-only means that the values of the memory cells do not change during the execution of Cairo code. Nondeterministic means that the prover is allowed to choose the initial and, thus also, final values of all the memory cells. The Cairo code simply consists of assertions on the memory values, which play the role of reading and writing (once) memory values, see Section 2.6. Sections 6 and 8 explain how one can use a nondeterministic read-only memory for common programming tasks, including simulating a read-write memory.</p>

    <p class="text-gray-300">We are using the notations m(a) and [a] to represent the value of the memory at address a.</p>

    <h3 id="sec-42" class="text-xl font-semibold mt-8">4.3 Execution of a program</h3>

    <p class="text-gray-300">As you have seen in Section 3.1, the input of the deterministic Cairo machine consists of (1) the read-only memory and (2) an execution trace represented by a sequence of register states <span class="math">(\\mathsf{pc}_{i},\\mathsf{ap}_{i},\\mathsf{fp}_{i})</span>. The validity of the transition between two consecutive states is defined by the instruction the pc register is pointing to (m(pc_{i})) and is the main topic covered by this section. Each instruction induces some constraints on the transition from one state to the next. In common CPU architectures, the state transition is deterministic – the CPU must be able to compute the next state, given the current one. Cairo is designed to verify statements, and thus, it can support nondeterministic state transitions. Moreover, there may be states that allow no following states. If such a case happens during the execution of a program, we say that the execution is rejected, and the prover will not be able to generate a proof for it.</p>

    <h3 id="sec-43" class="text-xl font-semibold mt-8">4.4 Instruction structure</h3>

    <p class="text-gray-300">The CPU’s native word is a field element, where the field is some fixed finite field of characteristic <span class="math">P&gt;2^{63}</span>. Each Cairo instruction spreads over one or two words. Instructions that use an immediate value (such as “[ap] = 123456789”) are spread over two words, and the value is stored in the second word. The first word of each instruction consists of: (1) three 16-bit signed integer offsets <span class="math">\\text{off}_{\\text{dst}},\\text{off}_{\\text{op0}},\\text{off}_{\\text{op1}}</span> in the range <span class="math">[-2^{15},2^{15})</span> encoded</p>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a> Figure 3: The structure of the 63-bits that form the first word of each instruction. Bits are ordered in a little-endian-like encoding (least significant bit first): offdst appears as the low 16 bits, and dst_reg is bit 48 (starting from the least significant bit).</p>

    <p class="text-gray-300">using biased representation <span class="math">^{25}</span> ; and (2) 15 bits of flags divided into seven groups as shown in Figure 3.</p>

    <p class="text-gray-300">Cairo's state transition function is designed to have an efficient AIR implementation. We give here one implication of this fact: A valid flag group of three bits (such as op1_src) may only take the values 0, 1, 2, and 4 (instead of 0, 1, ..., 7). To understand why, denote the three bits representing op1_src by  <span class="math">b_{0}, b_{1}, b_{2} \\in \\{0, 1\\}</span> . Now we have the four linear functionals:  <span class="math">b_{0}, b_{1}, b_{2}</span>  and  <span class="math">1 - b_{0} - b_{1} - b_{2}</span> , where exactly one of them is 1, and the rest are 0. Such functionals are used in the construction of the AIR, as you will see in Section 9.</p>

    <p class="text-gray-300">The state transition function uses four auxiliary values: op0, op1, dst, and res. The auxiliary values can be computed from the memory values, the three offsets, and the instruction flags.</p>

    <p class="text-gray-300">This section introduces the formal definition of the state transition function. Refer to Section 5 for examples of various ways to set the instruction flags in order to obtain meaningful instructions.</p>

    <p class="text-gray-300">We use the term Unused to describe a variable that will not be used later in the flow. As such, we don't need to assign it a concrete value.</p>

    <p class="text-gray-300">We use the term Undefined Behavior to describe a computation that leads to an undefined behavior of the Cairo machine. This means that the definition of the valid next states in such a case may be different across different implementations of the Cairo machine. Therefore, programmers</p>

    <p class="text-gray-300">should ensure that their programs cannot reach such cases.</p>

    <p class="text-gray-300">We use the notation assert x = y to represent an additional equality requirement between two values. If this requirement does not hold, this is not a valid state transition. In such a case, it may be that no valid state transition exists, in which case the Cairo machine will reject the entire statement, and no proof will be generated.</p>

    <p class="text-gray-300">Note: mathematically, the state transition function may return either a state, undefined or reject.</p>

    <p class="text-gray-300">The state transition is formally defined by the following pseudo-code:</p>

    <pre><code class="language-python">if dst_reg == 0:
dst = m(ap + offdst)
else:
dst = m(fp + offdst)

# Compute the new value of pc.
switch pc_update:
case 0: # The common case:
next_pc = pc + instruction_size
case 1: # Absolute jump:
next_pc = res
case 2: # Relative jump:
next_pc = pc + res
case 4: # Conditional relative jump (jnz):
next_pc =
if dst == 0: pc + instruction_size
else: pc + op1
default: Undefined Behavior

#Compute new value of ap and fp based on the opcode.
if opcode == 1:
# &quot;Call&quot; instruction.
assert op0 == pc + instruction_size
assert dst == fp

#Update fp.
next_fp = ap + 2

#Update ap.
switch ap_update:
case 0: next_ap = ap + 2
default: Undefined Behavior
else if opcode is one of 0, 2, 4:
#Update ap.
switch ap_update:
case 0: next_ap = ap
case 1: next_ap = ap + res
case 2: next_ap = ap + 1
default: Undefined Behavior

switch opcode:
case 0:
next_fp = fp
case 2:
# &quot;ret&quot; instruction.
next_fp = dst
case 4:
# &quot;assert equal&quot; instruction.
assert res = dst
next_fp = fp
else: Undefined Behavior

5 The Cairo Assembly

The previous section described how every possible combination of the flags affects the new state, given the old state and the memory function. Notice that the number of possible combinations is pretty large: there are thousands of valid flag combinations, and $2^{3\\cdot 16}$ independent possible values for the 3 offsets.

In practice, a programmer needs a better way to describe instructions – rather than listing all the flag values. In this section, we introduce the Cairo assembly syntax that gives textual names to common sets of flag combinations. This section is not a full manual for the Cairo assembly. Instead, it provides a high-level description of the Cairo assembly together with a few examples of instructions. A full manual for the Cairo assembly is out of the scope of this paper. See *[5]*. Examples of common algorithm implementations can be found in Section 8.

### 5.1 Common syntax

The [.] operator refers to the memory value at address $x$. $x$ can be one of the registers ap or fp or their value added to a constant (e.g., [ap + 5]). The value stored in the given address can be used as an address as well. For example, [[fp + 4] - 2]. Up to two layers of dereferencing are supported by the Cairo machine in a single instruction.
The value of ap can be increased by 1 by most of the instructions by appending the command ap++ to the instruction. The only instruction that may not use ap++ is the call instruction.

### 5.2 Assert equal

The assert equal instruction is represented by the syntax:

&lt;left_hand_op&gt; = &lt;right_hand_op&gt;

It ensures that both sides are equal and rejects the program execution otherwise.

The left-hand side takes the form [fp + off_{dst}] or [ap + off_{dst}] and the right-hand side has a few possible forms (reg_{0} and reg_{1} can be fp or ap, $\\circ$ can be either addition or multiplication and imm can be any fixed field element):

- imm
- [reg_{1} + off_{op1}]
- [reg_{0} + off_{op0}] $\\circ$ [reg_{1} + off_{op1}]

-  $\\left[\\mathrm{reg}_{0} + \\mathrm{off}_{\\mathrm{op0}}\\right] \\circ \\mathrm{imm}$
-  $\\left[\\left[\\mathrm{reg}_{0} + \\mathrm{off}_{\\mathrm{op0}}\\right] + \\mathrm{off}_{\\mathrm{op1}}\\right]$

Note 2. Division and subtraction can be represented as multiplication and addition (respectively) with a different order of operands.

As explained in page 18, an assert instruction can be thought of as an assignment instruction where one of the sides is known and the other one is unknown. For example,  $[ap] = 4$  can be thought of as an assertion that the value of  $[ap]$  is 4 or as an assignment setting  $[ap]$  to 4, according to the context.

A selected sample of assert equal instructions, and the flag values for each instruction, is given in Fig. 4.

![img-3.jpeg](img-3.jpeg)
Figure 4: Assert equal instruction examples

# 5.3 Conditional and Unconditional Jumps

The jmp instruction allows changing the value of the program counter.

Cairo supports relative jumps (where the operand represents an offset from the current pc) and absolute jumps – represented by the keywords rel and abs, respectively. A jmp instruction may be conditioned, in which case the jump will occur only if a given memory cell is not zero.

The instruction syntax:

Unconditional jumps.

jmp abs &lt;address&gt;

jmp rel &lt;offset&gt;&lt;/offset&gt;

Conditional jumps.
jmp rel &lt;offset&gt; if &lt;op&gt; != 0

A selected sample of jump instructions, and the flag values for each instruction, are available in Fig. 5.

![img-4.jpeg](img-4.jpeg)
Figure 5: Jump instruction examples

# 5.4 call and ret

The call and ret instructions allow implementation of a function stack. The call instruction updates the program counter (pc) and the frame pointer (fp) registers. The program counter is updated similarly to the jmp instruction. The previous value of fp is written to [ap] to allow the ret instruction to reset the value of fp to the value prior to the call. Similarly, the return pc (the address of the instruction following the call instruction) is written to  $[ap + 1]$  to allow the ret instruction to jump back and continue the execution of the code following the call instruction. Since two memory cells were written, ap is advanced by 2, and fp is set to the new ap.

The instruction syntax is:

call abs &lt;address&gt;
call rel &lt;offset&gt;
ret

A selected sample of call and ret instructions, and the flag values for each instruction, are available in Fig. 6.

# 5.5 Advancing ap

The instruction ap  $+= &amp;lt;\\text{op}&amp;gt;$  increases the value of ap by the given operand. A selected sample of this instruction and the corresponding flag values, is available in Fig. 7.&lt;/offset&gt;&lt;/address&gt;&lt;/op&gt;&lt;/offset&gt;

![img-5.jpeg](img-5.jpeg)
Figure 6: call and ret instruction examples

![img-6.jpeg](img-6.jpeg)
Figure 7: ap register update instruction examples

# 6 Recommended memory layout

This section describes what we consider to be best practices for managing the memory layout in Cairo programs. The patterns described in this section are not enforced by the Cairo architecture. Rather, they are described here to show how common memory management concepts, such as the function call stack, may be implemented given Cairo&#x27;s unique memory model - the nondeterministic read-only memory (Section 2.6).

# 6.1 Function call stack

This section suggests a way to implement the function call stack in the Cairo architecture. The call stack is a widely-used pattern, which enables programming flows such as recursion. In common architectures, the depth of the call stack is increased, and a new frame is created whenever a function is called; and decreased whenever a function returns - releasing the memory of the frame. The memory can then be overridden with frames of future function calls. This approach cannot be implemented as-is in Cairo, since the memory is read-only. However, only minor adjustments are required.

The frame pointer register (fp) points to the current frame in the &quot;call stack&quot;. As you will see, it is convenient not to define fp as the beginning of the frame but rather as the beginning of the local variables&#x27; section, in a similar way to the behavior of the stack in common architectures. Each

frame consists of four parts (fp refers to the current frame):

1. The arguments of the function provided by the caller. For example, [fp - 3], [fp - 4], ...
2. Pointer to the caller function&#x27;s frame. Located at [fp - 2].
3. The address of the instruction to be executed once the function returns (the instruction following the call instruction). Located at [fp - 1].
4. Local variables allocated by the function. For example, [fp], [fp + 1], ...

In addition, the return values of the function are placed in the memory at [ap - 1], [ap - 2], ..., where ap is the value of the ap register at the end of the function.
</code></pre>

    <p class="text-gray-300">f: call g ret g: call h call h ret h: ret</p>

    <pre><code class="language-text">
Figure 8: Function calls code

Fig. 8 presents a code example of function calls, and Fig. 9 presents the function call stack for this example. Frame 1 is the frame of the function  $f()$ , and at the beginning of the code example,  $fp$  points to this frame. After the call to  $g()$ , the active frame (pointed by  $fp$ ) is Frame 2. The first call to  $h()$  changes the active frame to Frame 3. When  $h()$  returns, the value of  $fp$  is restored to point to Frame 2 (based on the value of  $[fp - 2]$ ). The second call to  $h()$  creates Frame 4, and when it returns  $fp$  moves to point to Frame 2 again. When  $g()$  returns,  $fp$  is changed back to point to Frame 1.

# 6.2 Memory segments

The Cairo machine, as defined in Definition 1, allows random access memory and can support a very big address domain (as big as the field size). On the other hand, in order to gain maximum efficiency in the Cairo AIR implementation, Cairo imposes an additional requirement that the set of accessed memory addresses must be continuous (see Note 1 and Section 9.7).

It is possible to take advantage of Cairo&#x27;s nondeterminism in order to mitigate the continuity requirement: The Cairo Runner supports the concept of relocatable memory segments. A memory segment is a contiguous

![img-7.jpeg](img-7.jpeg)
Figure 9: The call stack. Indentation represents the call stack depth at that point.

segment of the memory whose address range is not fixed, and can be chosen by the Cairo Runner (Section 3.5) at the end of the computation. We refer to this process as segment relocation. Before the segment relocation process, addresses of memory cells that belong to a relocatable segment may be represented as a pair $(s,t)$ where $s$ is an integer identifying the segment, and $t$ is a non-negative integer specifying the offset within the segment. At the end of the run, the size of each segment is computed (the size is the least positive integer greater than all $t$ for the given segment identifier $s$). Then, the Cairo Runner assigns each segment a final base address so that the memory segments will be positioned one after the other. For example, if segment $s$ was assigned a base address $a\\in\\mathbb{F}$, then the relocatable memory address $(s,t)$ will be relocated to $a+t$.

The segment mechanism provides an effective alternative to the dynamic memory allocation process in other programming languages. Usually, the dynamic memory allocation is a complicated process: the standard library and the operating system have to track the allocated segments, handle releasing the memory, and find the best position to allocate a new segment to reduce fragmentation. In Cairo, this is much simpler; all one has to do is allocate a new memory segment (the Cairo Runner picks an unused $s$). The programmer doesn’t even have to specify the segment size!

As the relocation is done by the Cairo Runner, it will not be proven. For example, a malicious prover may define overlapping segments. In a read-write memory, this would have been a problem – how can one know that changing a value in one segment will not change the value in another segment? However, since Cairo’s memory is read-only, this problem does not exist: as long as the program is agnostic to address differences across segments, overlapping segments are indistinguishable from non-overlapping segments.

There are several common segments defined by the Cairo Runner:

- stores the bytecode of the executed Cairo program.
- stores the execution stack, as described in Section 6.1.
- general purpose segments defined by the program (dynamic allocation).
- segments allocated for builtins, as covered by Section 7.

##

7 Builtins

Although Cairo is a Turing-complete²⁶ architecture and can express every computation, it incurs an overhead cost over raw AIRs. In a similar fashion to the approach taken for physical CPUs, a way to overcome this is to add numerous predefined optimized low-level execution units, called *builtins*.

Examples for such builtins are:

Verify that a value is in some bounded range $[0,n)$.

such as hash functions, encryption, and signature validation.

such as a builtin that executes any given arithmetic circuit.

Practically, the use of builtins may tremendously reduce the overhead costs of moving from raw AIRs to Cairo programs – for many common programs. This section describes how builtins work as part of the Cairo architecture, and in particular, how Cairo programs use them.

7.1 Memory communication

Each builtin is assigned a memory segment (see Section 6.2), through which the Cairo program can communicate with the builtin (see Fig. 2 in Section 2.8).

For example, consider a hash builtin, whose purpose is to take 2 inputs $x$ and $y$, and compute their hash $H(x,y)$. We can divide the “shared” memory segment to triplets $(\\mathfrak{m}(3i),\\mathfrak{m}(3i+1),\\mathfrak{m}(3i+2))$ for $i$ in some range $[a,b)$. The responsibility of the hash builtin is to verify that $\\mathfrak{m}(3i+2) = H(\\mathfrak{m}(3i),\\mathfrak{m}(3i+1))$. Then, when the Cairo program wishes to “invoke” the hash function, it could simply write $x$ and $y$ to $\\mathfrak{m}(3i)$ and $\\mathfrak{m}(3i+1)$, respectively, and read²⁷ the result from $\\mathfrak{m}(3i+2)$. Once we use the addresses $\\mathfrak{m}(3i),\\mathfrak{m}(3i+1),\\mathfrak{m}(3i+2)$ in order to compute the first hash, we cannot use them again to compute a different hash since Cairo’s memory is immutable.

Another implication of the immutability of the memory is that one cannot maintain a global pointer to the “last” used memory address in the builtin segment. Instead, one has to pass this pointer to and from each function that uses that builtin. In particular, the main() entry-point should get and return the pointer for each used builtin. It gets the (start) pointer to the beginning of the memory segment and should return the (stop) pointer after the last usage of the builtin.

²⁶See footnote on page 14.

²⁷From the point of view of the Cairo code, the result is computed nondeterministically.

42

To check that there was no overflow from the memory segment allocated for the builtin, these two pointers (start and stop) are exported via the public memory mechanism (see Section 9.8) and verified by the verifier. For example, say that the hash builtin has $b-a$ instances and its allocated segment spread over the addresses $[3a,3b)$ (recall that each instance takes three cells). Then the verifier should check that the pointer sent to main() is $3a$ and the pointer returned by main() satisfies $3a\\leq\\texttt{returned pointer}\\leq 3b$.

The Cairo Runner (see Section 3.5) comes with predefined hints to deduce values in some of the builtin memory segments. For example, in the hash builtin, a useful hint is to deduce the value of $\\texttt{m}(3i+2)$ by computing the hash of the previous two elements.

## 8 Cairo Constructs

In this section, we describe how to construct basic building blocks of modern programming languages using Cairo instructions. Specifically, how to deal with the memory restrictions (immutability) and the fact that the basic type is a field element rather than an integer.

The code examples in this section will be given in pseudo-code assembly, whose syntax will not be explicitly defined. Since Cairo is nondeterministic, the code will employ the concept of nondeterministic &quot;guesses&quot;. See Section 2.5.1.

### 8.1 Loops and recursion

We have already seen the layout of the Cairo stack and how the Cairo machine supports function calls (see Section 6). For example, consider the following recursive function that computes $x\\cdot a^{n}$.

⬇
def exp(x, a, n):
# Compute x * a ** n.
if n == 0:
return x
return exp(x * a, a, n - 1)

One can implement it using Cairo instructions as follows:

⬇
exp:
# [fp - 5], [fp - 4], [fp - 3] are x, a, n, respectively.
jmp body if [fp - 3] != 0

# n == 0. Return x.
[ap] = [fp - 5]; ap++
ret

body:
# Return exp(x * a, a, n - 1).
[ap] = [fp - 5] * [fp - 4]; ap++

[ap] = [fp - 4]; ap++
[ap] = [fp - 3] - 1; ap++
call exp
ret

In particular, note the pattern of a call instruction followed immediately by a ret instruction. This is a tail recursion – where the return values of the called function are forwarded. Functions with loops can be implemented by defining helper functions that use tail recursion. This pattern is common in functional programming languages.

### 8.2 Integer arithmetic

Since the basic word in Cairo is a field element, one might wonder how to implement primitive integer arithmetic operations over bounded integers or modulo other numbers (such as $2^{64}$) as per standard architectures. This can be achieved by using the range check builtin (see Section 2.8). Let $M$ be the bound of the range check builtin. One can treat the range check builtin as if it introduces a new primitive instruction to our pseudo-code, of the form:

⬇
assert x in [0, M)

For the rest of this section, we assume $M$ is much smaller than $P$ (at least by a factor of two).

###### Example 6 (Addition bounded by $B\\leq M$).

Given two elements $x,y\\in[0,B)$, compute their sum, and verify that it is also in $[0,B)$.

⬇
z := x + y # Field operation.
assert z in [0, M)
assert B - z in [0, M)

This shows that two range check invocations are enough to check for any range smaller than $B$.

###### Example 7 (Multiplication modulo $B\\leq M$ assuming $(B-1)^{2}+B\\leq P$).

Computing $x\\cdot y\\mod B$ (where $x$ and $y$ are in the range $[0,B)$) can be accomplished by guessing residue $&lt;B$ and quotient, and then verifying that $x\\cdot y=\\text{residue}+\\text{quotient}\\cdot B$. Since the latter is verified in the field, a check that quotient is small enough is required to avoid overflow.

The largest possible quotient we need to support is $\\lfloor(B-1)^{2}/B\\rfloor$.

This gives rise to the following algorithm:

⬇
z := x * y
residue := guess
quotient := guess
assert residue in [0, B)
assert quotient in [0, $\\lfloor(B-1)^{2}/B\\rfloor$]
assert z == residue + quotient * B
return residue

Note the use of nondeterminism – the line residue := guess should be translated to the use of an uninitialized memory cell (whose value will be set by a hint). For more information about nondeterminism, see Section 2.5.

### 8.3 Fixed and floating-point arithmetic

Fixed point operations are similar to integer operations except that after each multiplication, one has to divide by $2^{b}$, where $b$ is the fixed precision (in bits). For this, one needs the integer division with remainder operation.

###### Notation.

A fixed-point number $x$ with $b$ precision bits is represented by an integer $X$, where $x=\\frac{X}{2^{b}}$.

To see how to compute the multiplication of two fixed-point numbers $z=xy$, note that $Z=2^{b}xy=\\frac{XY}{2^{b}}$. Since $X\\cdot Y$ is not guaranteed to be divisible by $2^{b}$, one needs to use integer division, and we lose $b$ precision bits here – as expected when working with fixed-point arithmetic. Integer division can be implemented almost identically to the multiplication modulo operation in Example 7. Given $x,y&lt;B$, and assuming $(B-1)^{2}+B\\leq P$:

⬇
# Compute x // y.
residue := guess
quotient := guess

assert residue in [0, y)
assert quotient in [0, B)
assert x == residue + quotient * y
return quotient

Floating-point numbers are less efficient but still possible. Each floating-point number can be represented by 2 words, the exponent and the mantissa. For example, the pair $(x_{e},x_{m})$ represents the number $(1+x_{m}/2^{b})\\cdot 2^{x_{e}}$.

###### Example 8 (Multiplication of floating-point numbers).

Given two floating-point numbers $(x_{e},x_{m})$ and $(y_{e},y_{m})$, the following pseudo-code computes their product:

⬇
z_e := bounded_addition(x_e, y_e)
z_m := fixed_point_multiplication(x_m, y_m)
if fixed_point_less_than(z_m, 2):
return (z_e, z_m)
else:
return (bounded_addition(z_e, 1), integer_division(z_m , 2))

Addition can be implemented by first shifting one of the numbers so that their exponents will be the same, and then summing the resulting mantis

46

## 8.4 Obtaining the values of the registers

Cairo has no specialized instruction for obtaining the values of the registers ap, fp, pc. Still, one can retrieve those values and store them in the memory, using the call (Section 5.4) instruction, as follows: The call instruction pushes the values of fp and pc to the memory and then sets fp to ap. Thus, after two consecutive calls, the 4 values at the top of the memory stack (that is, [ap - 4], [ap - 3], [ap - 2], [ap - 1]) are fp, pc, ap + 2, and another value we don&#x27;t care about.

The following code may be used to obtain the values of the registers:
</code></pre>

    <p class="text-gray-300">get_registers: call get_ap ret</p>

    <p class="text-gray-300">get_ap: ret</p>

    <p class="text-gray-300">... call get_registers</p>

    <pre><code class="language-text">
## 8.5 Read-write memory

Cairo&#x27;s memory model does not support read-write memory natively. Instead, one can take advantage of nondeterminism to build a data structure that simulates a random-access read-write memory.

### 8.5.1 Append-only array

Before describing how to implement a read-write dictionary in Cairo, we describe an important building block: the append-only array.

An append-only array is a data structure that supports two operations in constant time: appending a value and querying a value at an arbitrary index. It does not support modifying or removing values.

To implement an append-only array in Cairo, one stores the values of the array in a memory segment²⁸ (see Section 6.2) and maintains two pointers into this segment: array_start, which points to the beginning of the array, and array_end, which points to the first cell that hasn&#x27;t been written yet.

The size of the array can be computed using array_end - array_start. In order to access the element at index i, simply take [array_start + i].

²⁸Note that using a memory segment means that one doesn&#x27;t have to handle memory reallocation when additional elements are added, as done in similar data structures in other architectures.

The append function gets the two pointers and returns the two updated pointers:
</code></pre>

    <p class="text-gray-300">append_to_array(array_start, array_end, new_value):</p>

    <p class="text-gray-300">[array_end] = new_value</p>

    <p class="text-gray-300">return (array_start, array_end + 1)</p>

    <pre><code class="language-text">
An append-only array can function as an operation log: say you have a sequence of read and write operations. One can nondeterministically guess the result of each operation and log the operation and its alleged result in such an array. At the end of the execution, one can go over the log and check that the log is consistent and the guessed values were correct.

#### 8.5.2 Read-write dictionary

The read-write dictionary data structure holds a mapping from keys to values and allows the setting of, and retrieval of, arbitrary keys. One can implement this in Cairo using an append-only array:

The array will hold triplets of (key, previous value, new value); each represents a single read and write access to the dictionary at a specific key. The order of the triplets in the array will be the chronological order of the accesses. Each key may appear (and, in fact, is likely to appear) in more than one triplet. When accessing the dictionary, the correct previous value (which is, in fact, the current value at the given key) can be (nondeterministically) guessed.

After using the dictionary, the program must verify that the array of access triplets is consistent. Namely, that for every access $(k,p_{0},n_{0})$, the next access with the same key, $(k,p_{1},n_{1})$, should satisfy $n_{0}=p_{1}$. This constraint guarantees that, when setting a key to some value, the next access to that key will return the written value.

To check this constraint, one takes the following approach:

1. The prover (with the assistance of a hint) sorts the access array by the key (preserving the order of accesses within the same key).
2. Verify that the (guessed) sorted array matches the result of sorting the original array of accesses (due to nondeterminism, this can be done in $O(n)$, instead of the usual cost of sorting, which is $O(n\\log n)$).
3. Iterate over the sorted array and check the consistency condition locally.

#### 8.5.3 Sorting with permutation checking

Given two arrays $A,B$ of size $n$, it is possible to check that $A$ is the stable sorting of $B$. This can be done by guessing an injection from $A$ to $B$: a

mapping that has no collisions, from indices in $A$ to indices in $B$, s.t. $A[i]=B[f(i)]$. Since $f$ is injective and $n$ to $n$, it is, in fact, a permutation. The sorting can be done in the following manner:

1. Check that $A$ is sorted: iterate the values of $A$ and check that they are non decreasing.
2. Check that $A$ is a permutation of $B$: For the sake of simplicity, assume that the set of distinct ordered keys is $0,1,\\ldots,m-1$, and $j_{0},j_{1},\\ldots,j_{m-1}$ are the first indices of each segment in $A$ (respectively). For the sake of completeness, define $j_{m}=n$. For each segment $S_{i}=[j_{i},j_{i+1})$:

1. Guess the indices in $B$ where these values appear $I_{i}:S_{i}\\rightarrow[0,n)$, and ensure it is indeed the case:

$B[I_{i}(k)]=A[k].$
2. Ensure the sorting is stable by checking that $I_{i}$ is increasing:

$I_{i}(k+1)&gt;I_{i}(k).$

This algorithm can also be used to check that two arrays are a permutation of one another by introducing a third array and checking that it is the sorting of the two original arrays.

## 9 An Algebraic Intermediate Representation (AIR) for Cairo

This section describes how to construct an AIR – Arithmetic Intermediate Representation (see Section 2.1) for the Cairo machine (Section 3.2). In Section 2.1, we defined an AIR as a system of polynomial constraints operating on a table of field elements (the *trace*). An AIR for the Cairo machine is such a system for which the constraints are satisfiable if, and only if, the Cairo machine outputs &quot;accept&quot;. Such an AIR allows the prover to convince the verifier that the machine accepts. Note that understanding this section is not required in order to understand the Cairo language or architecture.

While this paper does not include formal proofs for the completeness (if the Cairo machine accepts then the AIR has a valid assignment) and the soundness (a valid assignment implies that the Cairo machine accepts) of the presented AIR, most of the constraints are rather intuitive and they closely follow the definition in Section 4.5. Both the soundness and the completeness are not perfect due to the memory (Section 9.7) and permutation range check (Section 9.9) constraints. The soundness error of the memory constraint is analyzed in Theorem 2 and the soundness error of the permutation range checks can be analyzed similarly. A coming paper, *[7]*, provides

a LEAN proof for the soundness of the Cairo AIR, using the LEAN theorem prover *[6]*.

The straightforward way to describe an AIR entails describing what each cell in the trace *means* and then listing each constraint, explaining what it enforces. This section presents the AIR in an alternative way that alternates between listing constraints and expanding the trace cells. For our purposes, we won’t examine the exact location of each cell in the table. We will only focus on how many instances of the cell exist. For example, we may have $N=T+1$ trace cells representing $\\mathsf{pc}_{i}$ for $i\\in[0,T]$, but $16N$ trace cells for the 15 bits representing the flags of the instructions (for technical reasons, the number of cells must be a power of 2).

A set of trace cells with the same role is called a *virtual column*. After collecting all the required virtual columns, we can decide how to place them in a two-dimensional table. Every virtual column is placed inside a single column periodically. For example, if the trace length (the number of rows) is $L=16N$, then the virtual column representing $\\mathsf{pc}_{i}$ will have a cell in the table every $16$ rows. The process of optimal placement is easy, due to the fact that the ratios between the sizes are powers of two, however, we don’t deal with this in this paper.

We also define the notion of a *virtual subcolumn*, where one takes a periodic subset of the cells that constitute a virtual column, and treat those cells as a virtual column. For example, we may define a virtual column of size $4N$ on which we will enforce that all the values are in the range $[0,2^{16})$, and then define three subcolumns of size $N$ for $\\text{off}_{\\text{dst}}$, $\\text{off}_{\\text{op0}}$ and $\\text{off}_{\\text{op1}}$. This allows us to write one set of constraints for the parent column (for example, constraints for validating that the values are in range), and three sets of constraints for $\\text{off}_{\\text{dst}}$, $\\text{off}_{\\text{op0}}$, and $\\text{off}_{\\text{op1}}$ according to the way they are used in the instruction.

Thus, we proceed as follows: describe several of the virtual columns; then some constraints involving them; then possibly describe more virtual columns and more constraints; and so on.

### 9.1 Notation

Let $\\mathbb{F}$ denote the base field – a finite field of size $|\\mathbb{F}|$ and characteristic $P&gt;2^{63}$. Let $T$ denote the number of steps, as in Definition 2. The number of states is $N=T+1$. The trace length, $L$, is $16N$. As the trace length must be a power of 2, so should be $N$. Throughout this section, we assume that $L$ is less than $P$. Note that each integer in the range $[-\\lfloor P/2\\rfloor,\\lfloor P/2\\rfloor]$ corresponds to a unique element in $\\mathbb{F}$. We will use the two representations interchangeably.

9.2 The proven integrity statement

Recall from Section 3 that the nondeterministic Cairo machine is a function that receives the following inputs:

1. a number of steps $T\\in\\mathbb{N}$,
2. a partial memory function $\\mathfrak{m}^{*}\\colon A^{*}\\to\\mathbb{F}$, where $A^{*}\\subseteq\\mathbb{F}_{P}$,
3. initial and final values for $\\mathsf{pc}$ and $\\mathsf{ap}$: $\\mathsf{pc}_{I}$, $\\mathsf{pc}_{F}$, $\\mathsf{ap}_{I}$, and $\\mathsf{ap}_{F}$ ($\\mathsf{ap}_{I}$ is also used as the initial value for $\\mathsf{fp}$),

and outputs “accept” or “reject”.

The parameters of the statement are called the public input, and they are precisely $(T,\\mathfrak{m}^{*},\\mathsf{pc}_{I},\\mathsf{pc}_{F},\\mathsf{ap}_{I},\\mathsf{ap}_{F})$. They represent the information known both to the prover and the verifier.

For each set of values to the parameters (public input), we define a statement which will be referred to as the integrity statement:

###### Definition 3 (Integrity statement).

The nondeterministic Cairo machine outputs “accept” when applied to $(T,\\mathfrak{m}^{*},\\mathsf{pc}_{I},\\mathsf{pc}_{F},\\mathsf{ap}_{I},\\mathsf{ap}_{F})$ (see Definition 2 on page 25).

The rest of this section is dedicated to the description of the AIR for the above statement.

### 9.3 Quadratic AIR

One metric that was not mentioned in Section 2.3.1 is the maximal degree of the constraints in the AIR. As long as the degree is not too large, the number of trace cells is a good estimation for the performance of the AIR. However, in some cases it is beneficial to add a few additional trace cells in order to reduce the maximal degree of the constraints. As you will see below, most of the constraints of the Cairo AIR are natively of degree 2 (quadratic constraints). The exceptions are two constraints described in Section 9.5, which are natively of degree 3. For these constraints, we add additional trace cells to reduce their degree to 2, so that all of the constraints of the Cairo AIR will be linear or quadratic.

### 9.4 Instruction flags

As explained in Section 4, each instruction consists of:

1. First word: 15 bits of flags ($f_{*}$) and 3 offsets (off_{∗}).
2. Second word (optional): An immediate value (a field element).

The flag groups are defined as follows:
</code></pre>

    <p class="text-gray-300">dst_reg = fDST_REG op0_reg = fOP0_REG op1_src = fOP1_IMM + 2 · fOP1_FP + 4 · fOP1_AP res_logic = fRES_ADD + 2 · fRES_MUL pc_update = fPC_JUMP_ABS + 2 · fPC_JUMP_REL + 4 · fPC_JNZ ap_update = fAP_ADD + 2 · fAP_ADD1 opcode = fOPCODE_CALL + 2 · fOPCODE_RET + 4 · fOPCODE_ASSENT_EQ</p>

    <pre><code>
Define $\\widetilde{\\mathrm{off}}_{*} = \\mathrm{off}_{*} + 2^{15}$ (where $*$ is one of op0, op1, dst) so that $\\widetilde{\\mathrm{off}}_{*}$ should be in the range $[0, 2^{16})$. We allocate a virtual column for $\\widetilde{\\mathrm{off}}_{*}$ rather than $\\mathrm{off}_{*}$ (three virtual columns, each of size $N$). In order to unpack the first word of an instruction to its ingredients, we use a bit-unpacking component: Let $\\{f_i\\}_{i=0}^{14}$ be the flag bits. We have:

$$
\\mathrm{inst} = \\widetilde{\\mathrm{off}}_{\\mathrm{dst}} + 2^{16} \\cdot \\widetilde{\\mathrm{off}}_{\\mathrm{op0}} + 2^{16 \\cdot 2} \\cdot \\widetilde{\\mathrm{off}}_{\\mathrm{op1}} + 2^{16 \\cdot 3} \\cdot \\sum_{i=0}^{14} \\left(2^i \\cdot f_i\\right).
$$

Denote $\\tilde{f}_i = \\sum_{j=i}^{14} 2^{j-i} \\cdot f_j$ (so that $\\tilde{f}_0$ is the full 15-bit value and $\\tilde{f}_{15} = 0$). Note that $\\tilde{f}_i$ are the bit prefixes of $\\tilde{f}_0$. Instead of allocating 15 virtual columns of size $N$ for the flags, we allocate one virtual column for $\\{\\tilde{f}_i\\}_{i=0}^{15}$ of size $16N$. This is an optimization of the number of constraints in the AIR (thus slightly reducing the verification time). To obtain the value of a flag $f_i$ from the sequence $\\{\\tilde{f}_i\\}_{i=0}^{15}$, we use the following identity:

$$
\\begin{array}{l}
\\tilde{f}_i - 2\\tilde{f}_{i+1} = \\sum_{j=i}^{14} 2^{j-i} \\cdot f_j - 2 \\cdot \\sum_{j=i+1}^{14} 2^{j-i-1} \\cdot f_j = \\\\
= \\sum_{j=i}^{14} 2^{j-i} \\cdot f_j - \\sum_{j=i+1}^{14} 2^{j-i} \\cdot f_j = f_i
\\end{array}
$$

Thus, the instruction-unpacking constraints are:

**Instruction** $\\mathrm{inst} = \\widetilde{\\mathrm{off}}_{\\mathrm{dst}} + 2^{16} \\cdot \\widetilde{\\mathrm{off}}_{\\mathrm{op0}} + 2^{16 \\cdot 2} \\cdot \\widetilde{\\mathrm{off}}_{\\mathrm{op1}} + 2^{16 \\cdot 3} \\cdot \\tilde{f}_0$.

**Bit** $(\\tilde{f}_i - 2\\tilde{f}_{i+1})(\\tilde{f}_i - 2\\tilde{f}_{i+1} - 1) = 0$ for all $i \\in [0,15)$.

**Last value is zero** $\\tilde{f}_{15} = 0$.

Offsets are in range The virtual columns $\\widetilde{\\mathrm{off}}_{*}$ (where $*$ is one of op0, op1, dst) are, in fact, subcolumns of the permutation range-check described in Section 9.9 forcing $\\widetilde{\\mathrm{off}}_{*} \\in [0,2^{16})$, and thus $\\mathrm{off}_{*} \\in [-2^{15}, 2^{15})$.

Theorem 1 (Instruction decoding). Assume the constraints above on the values of inst, $\\widetilde{\\mathrm{off}}_{\\mathrm{dst}}$, $\\widetilde{\\mathrm{off}}_{\\mathrm{op0}}$, $\\widetilde{\\mathrm{off}}_{\\mathrm{op1}}$, and $\\{\\tilde{f}_i\\}_{i=0}^{15}$, and that $P &amp;gt; 2^{63}$. Then, there exists a unique integer $\\mathrm{inst}_{\\mathbb{Z}} \\in \\mathbb{Z}$ in the range $[0, 2^{63})$ such that $\\mathrm{inst} = \\mathrm{inst}_{\\mathbb{Z}}$ (recall that $\\mathrm{inst} \\in \\mathbb{F}$). Moreover, the value of $f_i = \\tilde{f}_i - 2\\tilde{f}_{i+1}$ is the $(3 \\cdot 16 + i)$-th bit of $\\mathrm{inst}_{\\mathbb{Z}}$, and the value of $\\widetilde{\\mathrm{off}}_*$ is bits $16 \\cdot i, \\ldots, 16 \\cdot i + 15$ of $\\mathrm{inst}_{\\mathbb{Z}}$, where $i$ is either 0, 1, or 2 according to $*$.

Proof. The fact that $P &amp;gt; 2^{63}$ guarantees that any representation of a field element by an integer in the range $[0, 2^{63})$ (or any smaller range) is unique.

The &quot;Bit&quot; constraint enforces $\\tilde{f}_i = 2\\tilde{f}_{i+1}$ or $\\tilde{f}_i = 2\\tilde{f}_{i+1} + 1$. By induction on $i$, we have that $\\tilde{f}_{15-i} \\in [0,2^i)$. Thus, $\\tilde{f}_0 \\in [0,2^{15})$. The permutation range-checks enforce $\\widetilde{\\mathrm{off}}_* \\in [0,2^{16})$. Hence, we have

$$
0 \\leq \\widetilde {\\mathrm {o f f}} _ {\\mathrm {d s t}} + 2 ^ {1 6} \\cdot \\widetilde {\\mathrm {o f f}} _ {\\mathrm {o p 0}} + 2 ^ {1 6 \\cdot 2} \\cdot \\widetilde {\\mathrm {o f f}} _ {\\mathrm {o p 1}} + 2 ^ {1 6 \\cdot 3} \\cdot \\tilde {f} _ {0} &amp;lt;   2 ^ {6 3}.
$$

Thus, the &quot;Instruction&quot; constraint proves the existence of $\\mathrm{inst}_{\\mathbb{Z}} \\in [0,2^{63})$ and its required properties.

## 9.5 Updating pc

Most of the constraints for the validation of instructions are relatively straightforward, and the full list appears in Section 9.10. One exception is the constraints for updating the pc register, whose derivation is explained in this section.

As we saw in Section 4.5, pc may be updated in a few ways - regular update (pc_update = 0), absolute/relative jump (pc_update = 1,2) and conditional jump (pc_update = 4). This case is also referred to as jnz - Jump Non-Zero). In order to follow this section, the reader is encouraged to refer to the part about computing the new value of pc in Section 4.5.

As explained in Section 9.4, we have

$$
p c \\_ u p d a t e = f _ {P C \\_ J U M P \\_ A B S} + 2 \\cdot f _ {P C \\_ J U M P \\_ R E L} + 4 \\cdot f _ {P C \\_ J N Z}.
$$

Denote

$$
\\text {r e g u l a r} _ {\\text {- u p d a t e}} = 1 - f _ {\\mathrm {P C} _ {\\text {- J U M P} _ {\\text {- A B S}}}} - f _ {\\mathrm {P C} _ {\\text {- J U M P} _ {\\text {- R E L}}}} - f _ {\\mathrm {P C} _ {\\text {- J N Z}}},
$$

and note that we may assume that exactly one of regular_update, $f_{\\mathrm{PC\\_JUMP\\_ABS}}$, $f_{\\mathrm{PC\\_JUMP\\_REL}}$, $f_{\\mathrm{PC\\_JNZ}}$ is one and the other three are zero$^{31}$.

$^{30}$In fact, the field element values in the equation should be replaced by their unique integer representation in the range $[0,2^{63})$.

$^{31}$Otherwise, we’re in an Undefined Behavior.

Consider the following constraint:

$(1-f_{\\text{\\sc pc\\_jnz}})\\cdot\\textsf{next\\_pc}-($
$\\textsf{regular\\_update}\\cdot(\\textsf{pc}+\\textsf{instruction\\_size})+$
$f_{\\text{\\sc pc\\_jump\\_abs}}\\cdot\\textsf{res}+$
$f_{\\text{\\sc pc\\_jump\\_rel}}\\cdot(\\textsf{pc}+\\textsf{res}))=0$ (5)

Note that this constraint handles all the cases except for jnz (in jnz, the constraint becomes $0=0$). In the case of jnz, we either perform a regular update (if $\\texttt{dst}=0$) or make a relative jump according to op1 (if $\\texttt{dst}\\neq 0$).

The following constraint enforces that if $\\texttt{dst}\\neq 0$, we make the relative jump:

$f_{\\text{\\sc pc\\_jnz}}\\cdot\\textsf{dst}\\cdot(\\textsf{next\\_pc}-(\\textsf{pc}+\\textsf{op1}))=0$

As we prefer to use quadratic constraints (see Section 9.3), we allocate a new virtual column of size $N$, $t_{0}$, and we replace the constraint with the following two:

$t_{0}=f_{\\text{\\sc pc\\_jnz}}\\cdot\\textsf{dst},$
$t_{0}\\cdot(\\textsf{next\\_pc}-(\\textsf{pc}+\\textsf{op1}))=0.$ (6)

To verify that we make a regular update if $\\texttt{dst}=0$, we need an auxiliary variable (a new virtual column of size $N$), $v$ (to fill the trace in the case $\\texttt{dst}\\neq 0$, set $v=\\texttt{dst}^{-1}$):

$f_{\\text{\\sc pc\\_jnz}}\\cdot(\\texttt{dst}\\cdot v-1)\\cdot(\\textsf{next\\_pc}-(\\textsf{pc}+\\textsf{instruction\\_size}))=0.$

To make it quadratic, we add another virtual column, $t_{1}$, and we rewrite it as:

$t_{1}=t_{0}\\cdot v,$
$(t_{1}-f_{\\text{\\sc pc\\_jnz}})\\cdot(\\textsf{next\\_pc}-(\\textsf{pc}+\\textsf{instruction\\_size}))=0.$

We finish by applying two more optimizations:

1. Note that in a jnz (conditional jump) instruction, res is not used (it is either Unused or Undefined Behavior). Hence, we can use it to hold the value of $v$ (in other words, instead of allocating a new virtual column for $v$, one can use the virtual column of res).
2. Note that according to the value of $f_{\\text{\\sc pc\\_jnz}}$, one of the left-hand sides of Eq. (5) and Eq. (6) must be zero. Thus, we can combine them to one constraint:

$t_{0}\\cdot(\\textsf{next\\_pc}-(\\textsf{pc}+\\textsf{op1}))+(1-f_{\\text{\\sc pc\\_jnz}})\\cdot\\textsf{next\\_pc}-($
$\\textsf{regular\\_update}\\cdot(\\textsf{pc}+\\textsf{instruction\\_size})+$
$f_{\\text{\\sc pc\\_jump\\_abs}}\\cdot\\textsf{res}+$
$f_{\\text{\\sc pc\\_jump\\_rel}}\\cdot(\\textsf{pc}+\\textsf{res}))=0.$

9.6 Permutations and interaction step

A key component that is required to make Cairo efficient in terms of trace cells, is an additional interaction step between the prover and the verifier during the construction of the trace. This construction is based on a technique originally introduced in *[9]*.

As an example, let’s say that we want to prove that the cells of one trace column $a$ are the same as the cells of another column $b$, up to some permutation. The problem is that this property is not local, and thus there is no simple AIR constraint that enforces it.

The key idea is to observe that the two polynomials $f(X)=\\prod_{i=0}^{n-\\frac{1}{2}}(X-a_{i})$ and $g(X)=\\prod_{i=0}^{n-\\frac{1}{2}}(X-b_{i})$ are identical if, and only if, the values of $a_{i}$ and $b_{i}$ are the same up to a permutation. Second, note that if the two polynomials are not identical, we can observe this by picking a random field element $z\\in\\mathbb{F}$ and substituting it in the two polynomials. With high probability, the results will not be the same (assuming that the polynomials’ degrees are much smaller than the field size).

To translate this concept to an AIR, we introduce two new trace columns: $c_{j}=\\prod_{i=0}^{j}(z-a_{i})$ and $d_{j}=\\prod_{i=0}^{j}(z-b_{i})$ which represent the computation of $f(z)$ and $g(z)$, for a field element $z\\in\\mathbb{F}$ (we describe below how $z$ is chosen). The constraints will enforce that the cumulative products are computed correctly, and that the last cell in the column $c$ is the same as the last cell in $d$. This will convince the verifier that $f(z)=g(z)$, which implies (with high probability) that $f=g$, which in turn implies that the values in $a$ and $b$ are the same up to a permutation.

There is one crucial problem with the construction above: On the one hand, it is important that $z$ will be (randomly) chosen by the verifier *after* the prover has committed to $a$ and $b$ (otherwise, the probability argument above fails). But on the other hand, it must be chosen before the commitment to $c$ and $d$ (as they depend on it). With the regular STARK protocol, this is not possible since the commitment to the trace is done in one step.

Therefore, Cairo uses a slightly modified version of STARK, in which the prover first commits to some columns ($a$ and $b$ in our example), then the verifier generates some randomness. Now, the prover commits to the rest of the columns ($c$ and $d$), which may depend on the random values. We refer to this method as adding another interaction step between the prover and the verifier (in which the verifier sends the additional randomness).

Cairo uses a slightly improved version of the permutation-check described above for its range-checks and memory, as explained in the following sections.

9.7 Nondeterministic continuous read-only memory

9.7.1 Definition

Definition 4. A memory access is a pair $(a, v) \\in \\mathbb{F}^2$ where $a$ represents an address and $v$ represents the value of the memory at $a$. A list of memory accesses $(a_i, v_i)$ for $i \\in [0, n)$ ($1 \\leq n &amp;lt; P$) is said to form a read-only memory if for all $i, j \\in [0, n)$, if $a_i = a_j$, then $v_i = v_j$. It is said to be continuous if the set $\\{a_i : i \\in [0, n)\\}$ equals $[m_0, m_1)$ for some $m_0, m_1 \\in \\mathbb{F}$ that satisfy $m_1 = m_0 + t$ for a natural number $t &amp;lt; P$. In particular, for a given continuous read-only memory list of accesses, we can define a function $f: [m_0, m_1) \\to \\mathbb{F}$ such that $f(a_i) = v_i$ for all $i \\in [0, n)$. Any function $\\mathfrak{m}: \\mathbb{F} \\to \\mathbb{F}$ extending $f$ is said to be a memory function for the list of memory accesses.

9.7.2 Constraints

Theorem 2. Let $L_{1} = \\{(a_{i}, v_{i})\\}_{i=0}^{n-1}$, $L_{2} = \\{(a_{i}&#x27;, v_{i}&#x27;)\\}_{i=0}^{n-1}$ be two lists of memory accesses, and $\\{p_{i}\\}_{i=0}^{n-1}$ an additional sequence of field elements, satisfying the following constraints with non-negligible probability over the choice of two random elements $z, \\alpha \\in \\mathbb{F}$:

Continuity $(a_{i+1}&#x27; - a_i&#x27;) (a_{i+1}&#x27; - a_i&#x27; - 1) = 0$ for all $i \\in [0, n-1)$.

Single-valued $(v_{i+1}&#x27; - v_i&#x27;) (a_{i+1}&#x27; - a_i&#x27; - 1) = 0$ for all $i \\in [0, n-1)$.

Permutation:

Initial value $(z - (a_0&#x27; + \\alpha v_0&#x27;)) \\cdot p_0 = z - (a_0 + \\alpha v_0)$.

Final value $p_{n-1} = 1$.

Cumulative product step $(z - (a_i&#x27; + \\alpha v_i&#x27;)) \\cdot p_i = (z - (a_i + \\alpha v_i)) \\cdot p_{i-1}$ for all $i \\in [1, n)$.

Then, $L_{1}$ forms a continuous read-only memory.

Proof. First, show that $L_{2}$ forms a continuous read-only memory. By the continuity constraint, $a_{i+1}&#x27; \\in \\{a_i&#x27;, a_i&#x27; + 1\\}$ and so $L_{2}$ is continuous$^{34}$. To see that $L_{2}$ forms a read-only memory, note that if $a_i&#x27; = a_j&#x27;$ for $i &amp;lt; j$ then $a_i&#x27; = a_j&#x27; = a_k&#x27;$ for all $i &amp;lt; k &amp;lt; j$ by the &quot;Continuity&quot; constraint. The &quot;Single-valued&quot; constraint then guarantees that $v_i&#x27; = v_{i+1}&#x27; = v_{i+2}&#x27; = \\dots = v_j&#x27;$.

Next, show that

$$
\\prod_{i=0}^{n-1} \\left(z - \\left(a_i&#x27; + \\alpha v_i&#x27;\\right)\\right) = \\prod_{i=0}^{n-1} \\left(z - \\left(a_i + \\alpha v_i\\right)\\right). \\tag{7}
$$

33Here we use the notation $[m_0, m_1)$ to mean $\\{m_0 + i : i = 0, 1, \\ldots, t - 1\\}$.

34Note that there cannot be an overflow since $n &amp;lt; L &amp;lt; P$, where $L$ is the trace length.

55

We show by induction that for all $n&#x27; \\in [0, n)$:

$$
p_{n&#x27;} \\cdot \\prod_{i=0}^{n&#x27;} \\left(z - \\left(a_i&#x27; + \\alpha v_i&#x27;\\right)\\right) = \\prod_{i=0}^{n&#x27;} \\left(z - \\left(a_i + \\alpha v_i\\right)\\right). \\tag{8}
$$

For $n&#x27; = 0$, this holds by the &quot;Initial value&quot; constraint. For $n&#x27; &amp;gt; 0$, this follows from the &quot;Cumulative product step&quot; constraint: Multiply both hands of Eq. (8) for $n&#x27; - 1$ by $(z - (a_{n&#x27;} + \\alpha v_{n&#x27;}))$. Then, replace $(z - (a_{n&#x27;} + \\alpha v_{n&#x27;})) \\cdot p_{n&#x27; - 1}$ in the left-hand side by $(z - (a_{n&#x27;}&#x27; + \\alpha v_{n&#x27;}&#x27;)) \\cdot p_{n&#x27;}$ to obtain Eq. (8) for $n&#x27;$. It remains to substitute $n&#x27; = n - 1$ and use the &quot;Final value&quot; constraint to obtain Eq. (7).

We have shown that $L_{2}$ forms a continuous read-only memory and that Eq. (7) holds. The following proposition will imply that $L_{1}$ also forms a continuous read-only memory.

**Proposition 1.** Let $L_{1} = \\{(a_{i}, v_{i})\\}_{i=0}^{n-1}$, $L_{2} = \\{(a_{i}&#x27;, v_{i}&#x27;)\\}_{i=0}^{n-1}$ be two lists of memory accesses, where $L_{2}$ forms a continuous read-only memory. Denote by $\\mathcal{E}$ the event that $\\prod_{i=0}^{n-1} (z - (a_{i}&#x27; + \\alpha v_{i}&#x27;)) = \\prod_{i=0}^{n-1} (z - (a_{i} + \\alpha v_{i}))$. If

$$
\\Pr_{\\alpha, z \\in \\mathbb{F}} \\left[ \\mathcal{E} \\right] &amp;gt; \\frac{n^2 + n}{\\mathbb{F}},
$$

then $L_{1}$ forms a continuous read-only memory.

**Proof.** Let $\\mathcal{E}&#x27;$ be the event that the function $(a, v) \\mapsto a + \\alpha v$ has no collisions with respect to the two lists. Namely, for all $i$ and $j$ if $a_i + \\alpha v_i = a_j&#x27; + \\alpha v_j&#x27;$ then $(a_i, v_i) = (a_j&#x27;, v_j&#x27;)$. By the union bound, we have $Pr_{\\alpha, z \\in \\mathbb{F}}[\\overline{\\mathcal{E}&#x27;}] &amp;lt; \\frac{n^2}{\\mathbb{F}}$ and thus $\\operatorname{Pr}_{\\alpha, z \\in \\mathbb{F}}[\\mathcal{E} \\cap \\mathcal{E}&#x27;] &amp;gt; \\frac{n}{\\mathbb{F}}$.

Fix $\\alpha$ satisfying $\\operatorname{Pr}_{z \\in \\mathbb{F}}[\\mathcal{E} \\cap \\mathcal{E}&#x27;] &amp;gt; \\frac{n}{\\mathbb{F}}$. Consider the polynomial

$$
\\prod_{i=0}^{n-1} \\left(X - \\left(a_i + \\alpha v_i\\right)\\right) - \\prod_{i=0}^{n-1} \\left(X - \\left(a_i&#x27; + \\alpha v_i&#x27;\\right)\\right).
$$

This polynomial vanishes for at least $n + 1$ values of $X$, and thus it is the zero polynomial. Since $a_i + \\alpha v_i$ is a root of the left product, there must be $j$ for which $a_i + \\alpha v_i = a_j&#x27; + \\alpha v_j&#x27;$. Since $(a, v) \\mapsto a + \\alpha v$ has no collisions, we have $(a_i, v_i) = (a_j&#x27;, v_j&#x27;)$. Remove the two terms from the products and apply the same argument to obtain that the list $L_1$ is a permutation of $L_2$. Since the property &quot;continuous read-only memory&quot; does not depend on the order of the list, it holds for $L_1$ as well.

## 9.8 Public memory

Verifying that $L_{1} = \\{(a_{i}, v_{i})\\}_{i=0}^{n-1}$ forms a continuous read-only memory is not enough. Part of the statement is to verify that there exists a memory function $\\mathfrak{m}$ that extends $\\mathfrak{m}^*$ (specified in the public input). To do it, it suffices

to artificially add the accesses $\\{(a,\\mathfrak{m}^{*}(a))\\}_{a\\in A^{*}}$ to $L_{1}$ and $L_{2}$ . This can be done by allocating additional trace cells for these artificial accesses and enforcing the values of the $L_{1}$ cells to be $(a,\\mathfrak{m}^{*}(a))$ using $2\\cdot|A^{*}|$ boundary constraints (for each address in $A^{*}$, one boundary constraint for the address and one for the value).

While this solution works, it is rather inefficient due to the large number of additional constraints. Instead, we replace the $|A^{*}|$ $L_{1}$-accesses with the dummy memory accesses $(0,0)$ (the $L_{2}$-accesses remain with the real accesses induced by $\\mathfrak{m}^{*}$) and change the constraints given in Section 9.7.2 to *treat* those accesses as if they were $\\{(a,\\mathfrak{m}^{*}(a))\\}_{a\\in A^{*}}$. Going over the constraints, we see that the only thing that needs to change is the computation of the product. Moving from the product computed using the $(0,0)$ accesses to the real product is relatively straightforward: we just need to multiply by

$\\frac{\\prod_{a\\in A^{*}}(z-(a+\\alpha\\cdot\\mathfrak{m}^{*}(a)))}{z^{|A^{*}|}}.$

Therefore, we change the “Final value” constraint to:

$p_{n-1}=\\frac{z^{|A^{*}|}}{\\prod_{a\\in A^{*}}(z-(a+\\alpha\\cdot\\mathfrak{m}^{*}(a)))}.$ (9)

If this new constraint holds for the data with the $(0,0)$ accesses, the product of the real accesses will be $1$ as required.

This gives an extremely efficient way to handle the output of the Cairo program: for every field element in the output, the verifier has to do only two additions and two multiplications (for computing the denominator in Eq. (9)).

### 9.9 Permutation range-checks

As explained in Section 9.4, some of the trace cells should be constrained to be in the range $[0,2^{16})$. To check that the values $\\{a_{i}\\}_{i=0}^{n-1}$ of a virtual column are all in that range, we use the same technique we saw in Section 9.7, with the following changes:

1. Make sure that the set $\\{a_{i}:i\\in[0,n)\\}$ is continuous. To do so, one may artificially add trace cells and populate them to fill the holes that existed in the original list of values.
2. Set $v_{i}=0$ for all $i\\in[0,n)$ and add constraints to check that $\\{(a_{i},v_{i})\\}_{i=0}^{n-1}$ forms a continuous read-only memory. Of course, some of the constraints can be simplified (e.g., $\\alpha$ is not needed anymore), and some can be removed (e.g., the “Single valued” constraint).

3. Add two constraints on the first and last values of  $a&#x27;$ :

Min range-check value  $a_0&#x27; = \\mathrm{rc}_{\\min}$ ,

Max range-check value  $a_{n-1}&#x27; = \\mathrm{rc}_{\\max}$ ,

where the values of  $\\mathrm{rc}_{\\mathrm{min}}$  and  $\\mathrm{rc}_{\\mathrm{max}}$  are shared with the verifier. The verifier checks explicitly that  $0 \\leq \\mathrm{rc}_{\\mathrm{min}} \\leq \\mathrm{rc}_{\\mathrm{max}} &amp;lt; 2^{16}$ .

# 9.10 List of constraints

This section summarizes Section 9 and lists all of the Cairo AIR constraints. We start with a list of definitions to simplify the constraints below. These definitions do not constitute constraints themselves.

off  $* = \\widetilde{\\mathrm{off}}_{*} - 2^{15}$  (where \\* is one of op0, op1, dst)

$f_{i} = \\tilde{f}_{i} - 2\\tilde{f}_{i + 1}$

$f_{\\mathrm{DST\\_REG}} = f_0$ $f_{\\mathrm{PC\\_JUMP\\_REL}} = f_8$

$f_{\\mathrm{OP0\\_REG}} = f_1$ $f_{\\mathrm{PC\\_JNZ}} = f_9$

$f_{\\mathrm{OP1\\_IMM}} = f_2$ $f_{\\mathrm{AP\\_ADD}} = f_{10}$

$f_{\\mathrm{OP1\\_FP}} = f_3$ $f_{\\mathrm{AP\\_ADD1}} = f_{11}$

$f_{\\mathrm{OP1\\_AP}} = f_4$ $f_{\\mathrm{OPCODE\\_CALL}} = f_{12}$

$f_{\\mathrm{RES\\_ADD}} = f_5$ $f_{\\mathrm{OPCODE\\_RET}} = f_{13}$

$f_{\\mathrm{RES\\_MUL}} = f_6$ $f_{\\mathrm{OPCODE\\_ASSERT\\_EQ}} = f_{14}$

$f_{\\mathrm{PC\\_JUMP\\_ABS}} = f_7$

instruction_size =  $f_{\\mathrm{OP1\\_IMM}} + 1$

Instruction unpacking (see Section 9.4):

inst  $= \\widetilde{\\mathrm{off}}_{\\mathrm{dst}} + 2^{16}\\cdot \\widetilde{\\mathrm{off}}_{\\mathrm{op0}} + 2^{16\\cdot 2}\\cdot \\widetilde{\\mathrm{off}}_{\\mathrm{op1}} + 2^{16\\cdot 3}\\cdot \\tilde{f}_0$

$f_{i}\\cdot (f_{i} - 1) = 0,$  for all  $i\\in [0,15)$

$\\tilde{f}_{15} = 0$

# Operand constraints:

dst_addr =  $f_{\\mathrm{DST\\_REG}} \\cdot \\mathsf{fp} + (1 - f_{\\mathrm{DST\\_REG}}) \\cdot \\mathsf{ap} + \\mathsf{off}_{\\mathrm{dst}}$

op0_addr =  $f_{\\mathrm{OP0\\_REG}} \\cdot \\mathsf{fp} + (1 - f_{\\mathrm{OP0\\_REG}}) \\cdot \\mathsf{ap} + \\mathsf{off}_{\\mathrm{op0}}$

op1_addr =  $f_{\\mathrm{OP1\\_IMM}} \\cdot \\mathsf{pc} + f_{\\mathrm{OP1\\_AP}} \\cdot \\mathsf{ap} + f_{\\mathrm{OP1\\_FP}} \\cdot \\mathsf{fp} +$

$(1 - f_{\\mathrm{OP1\\_IMM}} - f_{\\mathrm{OP1\\_AP}} - f_{\\mathrm{OP1\\_FP}})\\cdot \\mathsf{op0} + \\mathsf{off}_{\\mathsf{op1}}$

The ap and fp registers:

next_ap = ap + fAP_ADD · res + fAP_ADD1 · 1 + fOPCODE_CALL · 2
next_fp = fOPCODE_RET · dst + fOPCODE_CALL · (ap + 2) +
(1 - fOPCODE_RET - fOPCODE_CALL) · fp
ap0 = fp0 = apI
apT = apF

The pc register (Section 9.5):

t0 = fPC_JNZ · dst
t1 = t0 · res
(t1 - fPC_JNZ) · (next_pc - (pc + instruction_size)) = 0
t0 · (next_pc - (pc + op1)) + (1 - fPC_JNZ) · next_pc - (
(1 - fPC_JUMP_ABS - fPC_JUMP_REL - fPC_JNZ) · (pc + instruction_size) +
fPC_JUMP_ABS · res +
fPC_JUMP_REL · (pc + res)) = 0
pc0 = pcI
pcT = pcF

Opcodes and res:

mul = op0 · op1
(1 - fPC_JNZ) · res =
fRES_ADD · (op0 + op1) + fRES_MUL · mul +
(1 - fRES_ADD - fRES_MUL - fPC_JNZ) · op1,
fOPCODE_CALL · (dst - fp) = 0
fOPCODE_CALL · (op0 - (pc + instruction_size)) = 0
fOPCODE_ASCERTE_Q · (dst - res) = 0

Memory (Section 9.7.2): Here $a^{m}, v^{m}$ are two virtual columns with the following pairs of subcolumns: 1. (pc, inst), 2. (dst_addr, dst), 3. (op0_addr, op0), and 4. (op1_addr, op1). If the AIR contains builtins (see Sections 2.8 and 7), each builtin may use additional pairs of subcolumns. Another pair of subcolumns is dedicated to the public memory mechanism (Section 9.8); for

those cells, we add constraints that both the addresses and the values are zeros. The size of the virtual columns $a^m, v^m$ is determined by the sum of the required subcolumns. $a&#x27;^m$ and $v&#x27;^m$ are two virtual columns of the same size as $a^m$ and $v^m$, that hold the sorted list of memory accesses.

$$
(a_{i+1}&#x27;^m - a_i&#x27;^m)(a_{i+1}&#x27;^m - a_i&#x27;^m - 1) = 0 \\quad \\text{for all } i \\in [0, n-1)
$$

$$
(v_{i+1}&#x27;^m - v_i&#x27;^m)(a_{i+1}&#x27;^m - a_i&#x27;^m - 1) = 0 \\quad \\text{for all } i \\in [0, n-1)
$$

$$
(z^m - (a_0&#x27;^m + \\alpha v_0&#x27;^m)) \\cdot p_0^m = z^m - (a_0^m + \\alpha v_0^m)
$$

$$
p_{n^m-1}^m = \\frac{z^{|A^+|}}{\\prod_{a^m \\in A^+}(z - (a^m + \\alpha \\cdot \\mathfrak{m}^*(a^m)))} \\quad \\text{(see Section 9.8)}
$$

$$
(z^m - (a_i&#x27;^m + \\alpha v_i&#x27;^m)) \\cdot p_i^m = (z^m - (a_i^m + \\alpha v_i^m)) \\cdot p_{i-1}^m \\quad \\text{for all } i \\in [0, n-1)
$$

**Permutation range-checks** (see Section 9.9): Here, $a^m$ is a virtual column with subcolumns for: $\\widehat{\\mathrm{off}}_{\\mathrm{dst}}$, $\\widehat{\\mathrm{off}}_{\\mathrm{op0}}$, $\\widehat{\\mathrm{off}}_{\\mathrm{op1}}$ (at least $3T$ values, with additional unused cells for filling holes).

$$
(a_{i+1}&#x27;^m - a_i&#x27;^m)(a_{i+1}&#x27;^m - a_i&#x27;^m - 1) = 0 \\quad \\text{for all } i \\in [0, n-1)
$$

$$
(z^m - a_0&#x27;^m) \\cdot p_0^m = z^m - a_0^m
$$

$$
p_{n^{m-1}}^m = 1
$$

$$
(z^m - a_i&#x27;^m) \\cdot p_i^m = (z^m - a_i^m) \\cdot p_{i-1}^m \\quad \\text{for all } i \\in [0, n-1)
$$

$$
a_0&#x27;^m = \\mathrm{rc}_{\\min}
$$

$$
a_{n^{m-1}}^m = \\mathrm{rc}_{\\max}
$$

## A Running untrusted code

As explained in Section 2.2.2, it is possible to run several different programs within the same proof. This can be done using a &quot;bootloader&quot; that runs the following loop:

1. Guess the bytecode of an inner program.
2. Compute its hash.
3. Jump to the first instruction using a **call** opcode.

This schema only works if all the inner programs are honest: A malicious program could perform a jump to the end of the bootloader loop (instead of properly returning using the **ret** opcode). This would skip the execution of the other programs.

As one may want to be able to execute untrusted programs, we need to amend the AIR constraints, and require some properties from the bootloader program, to enforce that every **call** has a corresponding **ret**.

60

Our goal is to prove the following theorem:

**Theorem 3.** Under the constraints that will be described in this section, every call always returns properly. Specifically, there is a corresponding ret opcode which results in the correct pc and fp values.

We do so by adding the following constraints:

1. **Disjoint flags** Each of the following expressions is either 0 or 1 (enforced by a constraint of the form $z \\cdot (z - 1) = 0$, where $z$ is the expression):

(a) $f_{\\mathsf{OP1\\_IMM}} + f_{\\mathsf{OP1\\_AP}} + f_{\\mathsf{OP1\\_FP}}$
(b) $f_{\\mathsf{OPCODE\\_RET}} + f_{\\mathsf{OPCODE\\_CALL}}$
(c) $f_{\\mathsf{PC\\_JUMP\\_ABS}} + f_{\\mathsf{PC\\_JUMP\\_REL}} + f_{\\mathsf{PC\\_JNZ}}$
(d) $f_{\\mathsf{RES\\_ADD}} + f_{\\mathsf{RES\\_MUL}} + f_{\\mathsf{PC\\_JNZ}}$

Together with the constraints $f_{i} \\cdot (f_{i} - 1) = 0$, this ensures that at most one of the expressions in each group is 1. For example, an opcode cannot be both call and ret at the same time.

2. **call restrictions** The following constraints must hold for every call opcode:

(a) $\\mathrm{off}_{\\mathrm{dst}} = 0$ ($f_{\\mathsf{OPCODE\\_CALL}} \\cdot \\mathrm{off}_{\\mathrm{dst}} = 0$)
(b) $\\mathrm{off}_{\\mathrm{op0}} = 1$ ($f_{\\mathsf{OPCODE\\_CALL}} \\cdot (\\mathrm{off}_{\\mathrm{op0}} - 1) = 0$)
(c) $f_{\\mathrm{DST\\_REG}} = 0$ and $f_{\\mathrm{OP0\\_REG}} = 0$ ($f_{\\mathrm{OPCODE\\_CALL}} \\cdot (f_{\\mathrm{DST\\_REG}} + f_{\\mathrm{OP0\\_REG}}) = 0$)

3. **ret restrictions** The following constraints must hold for every ret opcode:

(a) $\\mathrm{off}_{\\mathrm{dst}} = -2$ ($f_{\\mathsf{OPCODE\\_RET}} \\cdot (\\mathrm{off}_{\\mathrm{dst}} + 2) = 0$)
(b) $\\mathrm{off}_{\\mathrm{op1}} = -1$ ($f_{\\mathsf{OPCODE\\_RET}} \\cdot (\\mathrm{off}_{\\mathrm{op1}} + 1) = 0$)
(c) $f_{\\mathsf{PC\\_JUMP\\_ABS}} = 1$, $f_{\\mathsf{DST\\_REG}} = 1$, $f_{\\mathsf{OP1\\_FP}} = 1$, $f_{\\mathsf{RES\\_ADD}} = 0$, $f_{\\mathsf{RES\\_MUL}} = 0$, and $f_{\\mathsf{PC\\_JNZ}} = 0$
$$
(f_{\\mathsf{OPCODE\\_RET}} \\cdot (f_{\\mathsf{PC\\_JUMP\\_ABS}} + f_{\\mathsf{DST\\_REG}} + f_{\\mathsf{OP1\\_FP}} - f_{\\mathsf{RES\\_ADD}} - f_{\\mathsf{RES\\_MUL}} - f_{\\mathsf{PC\\_JNZ}} - 3) = 0)
$$

4. **Final fp** The final value of the fp register must be identical to the initial value: $\\mathsf{fp}_{\\mathcal{T}} = \\mathsf{fp}_0 = \\mathsf{ap}_I$.
5. **fp cycle**: $\\mathfrak{m}(\\mathfrak{ap}_I - 2) = \\mathfrak{ap}_I$. This can be enforced in the verifier by adding an entry to the public memory.

61

Furthermore, we require the bootloader to start with the following opcodes:

⬇
ap += C # C $\\neq-2$. This opcode is optional.
call ...
jmp rel 0 # Infinite loop.

###### Proposition 2.

If $f_{OPCODE\\_CALL}=1$ then

$\\mathsf{m}(next\\_fp-2)=fp,$
$\\mathsf{m}(next\\_fp-1)=pc+instruction\\_size.$

If $f_{OPCODE\\_RET}=1$ then

$next\\_pc=\\mathsf{m}(fp-1),\\ \\ \\ \\ \\ next\\_fp=\\mathsf{m}(fp-2).$

###### Proof.

For a call opcode, we have:

$\\mathsf{fp}$ $=\\mathsf{dst}=\\mathsf{m}(\\mathsf{dst\\_addr})=\\mathsf{m}(\\mathsf{ap}+\\mathsf{off}_{\\mathsf{dst}})=$
$=\\mathsf{m}(\\mathsf{ap})=\\mathsf{m}(\\mathsf{next\\_fp}-2),$
$\\mathsf{pc}+$ $\\mathsf{instruction\\_size}$ $=\\mathsf{op0}=\\mathsf{m}(\\mathsf{op0\\_addr})=$
$=\\mathsf{m}(\\mathsf{ap}+1)=\\mathsf{m}(\\mathsf{next\\_fp}-1).$

For a ret opcode, we have:

$\\mathsf{next\\_pc}=\\mathsf{res}=\\mathsf{op1}=\\mathsf{m}(\\mathsf{op1\\_addr})=\\mathsf{m}(\\mathsf{fp}+\\mathsf{off}_{\\mathsf{op1}})=\\mathsf{m}(\\mathsf{fp}-1),$
$\\mathsf{next\\_fp}=\\mathsf{dst}=\\mathsf{m}(\\mathsf{dst\\_addr})=\\mathsf{m}(\\mathsf{fp}+\\mathsf{off}_{\\mathsf{dst}})=\\mathsf{m}(\\mathsf{fp}-2).$

∎

Consider the value of fp at a certain step of the execution. $\\mathsf{m}(\\mathsf{fp}-2)$ should be the value of fp of the caller function, $\\mathsf{m}(\\mathsf{m}(\\mathsf{fp}-2)-2)$ should be the value of its caller, and so on. Define two functions: $f(x)=\\mathsf{m}(x-2)$ and $g(x)=(x,f(x),f(f(x)),\\ldots)$. $g(\\mathsf{fp})$ represents the stack trace at a certain point in time – the sequence of the fp values of all the caller functions.

The following proposition describes how the sequence $g(\\mathsf{fp})$ may change during the execution of a step.

###### Proposition 3.

If $g(\\mathsf{fp})=(g_{0},g_{1},\\ldots)$ at a certain step, then $g(\\mathsf{next\\_fp})$ is either

1. Unchanged: $(g_{0},g_{1},\\ldots)$,
2. call: $(\\mathsf{next\\_fp},g_{0},g_{1},\\ldots)$,
3. ret: $(g_{1},g_{2},\\ldots)$.

###### Proof.

1. If $f_{\\text{OPCODE\\_CALL}} = f_{\\text{OPCODE\\_RET}} = 0$, we have $\\text{next\\_fp} = \\text{fp}$ and thus the value of $g(\\text{fp})$ remains unchanged: $g(\\text{next\\_fp}) = g(\\text{fp}) = (g_0, g_1, \\ldots)$.
2. If $f_{\\text{OPCODE\\_CALL}} = 1$, then by Proposition 2, $\\mathfrak{m}(\\text{next\\_fp} - 2) = \\text{fp}$ and therefore $f(\\text{next\\_fp}) = \\mathfrak{m}(\\text{next\\_fp} - 2) = \\text{fp} = g_0$. This implies $g(\\text{next\\_fp}) = (\\text{next\\_fp}, g_0, g_1, \\ldots)$.
3. If $f_{\\text{OPCODE\\_RET}} = 1$, we have $\\text{next\\_fp} = \\mathfrak{m}(\\text{fp} - 2) = f(\\text{fp}) = g_1$. Thus, $g(\\text{next\\_fp}) = (g_1, g_2, \\ldots)$.

Note that the constraint $\\mathfrak{m}(\\mathsf{ap}_I - 2) = \\mathsf{ap}_I$ implies that $f(\\mathsf{ap}_I) = \\mathsf{ap}_I$, and thus $g(\\mathsf{fp}_0) = g(\\mathsf{fp}_T) = (\\mathsf{ap}_I, \\mathsf{ap}_I, \\mathsf{ap}_I, \\ldots)$. Define the stack depth function $h(\\mathsf{fp})$ to be the number of elements in the sequence $g(\\mathsf{fp})$ different from $\\mathsf{ap}_I$. We have $h(\\mathsf{fp}_0) = h(\\mathsf{fp}_T) = 0$. It follows from Proposition 3 that each step may either increase $h$ by 1, decrease it by 1 or leave it unchanged (note that the value may be unchanged even if the opcode is call or ret).

**Proposition 4.** Let $0 \\leq i &amp;lt; i + 1 &amp;lt; j \\leq T$. If the $i$-th opcode is call, $h(fp_i) = h(fp_j)$, and for every $i &amp;lt; k &amp;lt; j$, $h(fp_k) \\neq h(fp_i)$, then (1) the $(j-1)$-th opcode is ret, (2) $fp_j = fp_i$, (3) $fp_{j-1} = fp_{i+1}$, and (4) $h(fp_k) &amp;gt; h(fp_i)$ for every $i &amp;lt; k &amp;lt; j$.

**Proof.** First show that for every $i &amp;lt; k &amp;lt; j - 1$, if $g(\\mathsf{fp}_{i + 1})$ is a suffix of $g(\\mathsf{fp}_k)$ then $g(\\mathsf{fp}_{i + 1})$ is also a suffix of $g(\\mathsf{fp}_{k + 1})$: The only interesting case is when the $k$-th opcode is ret and $g(\\mathsf{fp}_k) = g(\\mathsf{fp}_{i + 1})$. In that case, $g(\\mathsf{fp}_{k + 1}) = g(\\mathsf{fp}_i)$, so $h(\\mathsf{fp}_{k + 1}) = h(\\mathsf{fp}_i)$, which leads to a contradiction.

As $g(\\mathsf{fp}_{i + 1})$ is a suffix of itself, we can apply this property inductively and obtain that $g(\\mathsf{fp}_{i + 1})$ is a suffix of $g(\\mathsf{fp}_{j - 1})$.

Since the $i$-th opcode is call, $h(\\mathsf{fp}_{i + 1})$ can be either $h(\\mathsf{fp}_i)$ or $h(\\mathsf{fp}_i) + 1$. The former case is impossible by the assumption of the proposition. We conclude that $h(\\mathsf{fp}_k) \\geq h(\\mathsf{fp}_{i + 1}) &amp;gt; h(\\mathsf{fp}_i)$ for every $i &amp;lt; k &amp;lt; j$.

Since $h(\\mathsf{fp}_{i + 1}) = h(\\mathsf{fp}_i) + 1 = h(\\mathsf{fp}_j) + 1 &amp;gt; h(\\mathsf{fp}_j)$, $g(\\mathsf{fp}_{i + 1})$ cannot be a suffix of $g(\\mathsf{fp}_j)$. This implies that the $(j - 1)$-th opcode is ret and $g(\\mathsf{fp}_{j - 1}) = g(\\mathsf{fp}_{i + 1})$. Thus, $\\mathsf{fp}_{j - 1} = \\mathsf{fp}_{i + 1}$ and $\\mathsf{fp}_j = \\mathsf{next\\_fp}_{j - 1} = f(\\mathsf{fp}_{j - 1}) = f(\\mathsf{fp}_{i + 1}) = f(\\mathsf{next\\_fp}_i) = \\mathsf{fp}_i$.

**Proposition 5.** If the $i$-th opcode is call and $h(fp_{i+1}) &amp;gt; h(fp_i)$, then there exists $j &amp;gt; i+1$ such that (1) the $(j-1)$-th opcode is ret, (2) $fp_j = fp_i$, (3) $pc_j = pc_i + instruction\\_size_i$, and (4) $h(fp_k) &amp;gt; h(fp_i)$ for every $i &amp;lt; k &amp;lt; j$.

**Proof.** Note that $i \\neq T - 1$ since otherwise $h(\\mathsf{fp}_i) &amp;lt; h(\\mathsf{fp}_{i + 1}) = h(\\mathsf{fp}_T) = 0$.

Let $j$ be the smallest value for which $j &amp;gt; i + 1$ and $h(\\mathsf{fp}_j) = h(\\mathsf{fp}_i)$ (such $j$ must exist since $h(\\mathsf{fp}_{i + 1}) &amp;gt; h(\\mathsf{fp}_i) \\geq 0 = h(\\mathsf{fp}_T)$ and $h$ changes by at most 1 in each step). Proposition 4 implies that $\\mathsf{fp}_j = \\mathsf{fp}_i$ and $\\mathsf{fp}_{j - 1} = \\mathsf{fp}_{i + 1}$.

63

Since the $i$-th opcode is call and the $(j-1)$-th opcode is ret, we get:

$$
\\begin{array}{l}
\\mathsf{pc}_j = \\mathsf{next\\_pc}_{j-1} = \\mathsf{m}(\\mathsf{fp}_{j-1} - 1) = \\mathsf{m}(\\mathsf{fp}_{i+1} - 1) = \\\\
= \\mathsf{m}(\\mathsf{next\\_fp}_i - 1) = \\mathsf{pc}_i + \\mathsf{instruction\\_size}_i.
\\end{array}
$$

From the first two opcodes of the bootloader, we deduce that:

$$
\\begin{array}{l}
\\mathsf{ap}_0 = \\mathsf{ap}_I, \\quad \\quad \\quad \\mathsf{ap}_1 = \\mathsf{ap}_I + C, \\quad \\quad \\quad \\mathsf{ap}_2 = \\mathsf{ap}_I + C + 2, \\\\
\\mathsf{fp}_0 = \\mathsf{ap}_I, \\quad \\quad \\quad \\mathsf{fp}_1 = \\mathsf{ap}_I, \\quad \\quad \\quad \\mathsf{fp}_2 = \\mathsf{ap}_I + C + 2 \\neq \\mathsf{ap}_I.
\\end{array}
$$

Hence,

$$
\\begin{array}{l}
g(\\mathsf{fp}_0) = g(\\mathsf{fp}_1) = (\\mathsf{ap}_I, \\mathsf{ap}_I, \\mathsf{ap}_I, \\dots), \\\\
g(\\mathsf{fp}_2) = (\\mathsf{ap}_I + C + 2, \\mathsf{ap}_I, \\mathsf{ap}_I, \\dots), \\\\
h(\\mathsf{fp}_0) = h(\\mathsf{fp}_1) = 0, \\\\
h(\\mathsf{fp}_2) = 1.
\\end{array}
$$

We can now prove Theorem 3:

Proof. Apply Proposition 5 with $i = 1$. Note that indeed $h(\\mathsf{fp}_2) = 1 &amp;gt; 0 = h(\\mathsf{fp}_1)$. Denote the $j$ obtained in the proposition by $n$. Since $\\mathsf{pc}_n = \\mathsf{pc}_1 + \\mathsf{instruction\\_size}_1$, the $n$-th opcode is jmp rel 0, which forms an infinite loop. So for every $k \\geq n$, we have $\\mathsf{pc}_k = \\mathsf{pc}_n$. We also obtain that $h(\\mathsf{fp}_k) &amp;gt; 0$ for every $1 &amp;lt; k &amp;lt; n$.

Let $1 &amp;lt; i &amp;lt; n$ be a step where the opcode was call. From Proposition 3 we get that $h(\\mathsf{fp}_{i+1}) = h(\\mathsf{fp}_i) + 1$, as $h(\\mathsf{fp}_{i+1}) = h(\\mathsf{fp}_i)$ is possible for call opcodes only if $\\mathsf{next\\_fp}_i = \\mathsf{ap}_I$. But in that case, $h(\\mathsf{fp}_i) = h(\\mathsf{fp}_{i+1}) = 0$. The result follows from Proposition 5.

# References

[1] [Online]. Available: https://zkp.science/
[2] [Online]. Available: https://medium.com/starkware/hello-cairo-3cb43b13b209
[3] [Online]. Available: https://hackmd.io/@aztec-network/plonk-arithmetiization-air
[4] [Online]. Available: https://github.com/starkware-libs/cairo-lang
[5] [Online]. Available: https://cairo-lang.org/docs
[6] [Online]. Available: https://leanprover.github.io/

[7] J. Avigad, L. Goldberg, D. Levit, Y. Seginer, and A. Titleman, “A verified algebraic representation of cairo program execution,” 2021, preprint.

[8] L. Babai, L. Fortnow, and C. Lund, “Non-deterministic exponential time has two-prover interactive protocols,” *Computational Complexity*, vol. 1, pp. 3–40, 1991, preliminary version appeared in FOCS &#x27;90.

[9] S. Bayer and J. Groth, &quot;Efficient zero-knowledge argument for correctness of a shuffle,&quot; in *Annual International Conference on the Theory and Applications of Cryptographic Techniques*. Springer, 2012, pp. 263–280.

[10] E. Ben-Sasson, I. Bentov, Y. Horesh, and M. Riabzev, &quot;Scalable, transparent, and post-quantum secure computational integrity,&quot; *IACR Cryptology ePrint Archive*, vol. 2018, p. 46, 2018.

[11] E. Ben-Sasson, A. Chiesa, D. Genkin, E. Tromer, and M. Virza, &quot;SNARKs for C: Verifying program executions succinctly and in zero knowledge,&quot; in *Proceedings of the 33rd Annual International Cryptology Conference*, ser. CRYPTO &#x27;13, 2013, pp. 90–108.

[12] E. Ben-Sasson, A. Chiesa, M. Riabzev, N. Spooner, M. Virza, and N. P. Ward, “Aurora: Transparent succinct arguments for R1CS,” *IACR Cryptology ePrint Archive*, vol. 2018, p. 828, 2018.

[13] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza, &quot;Succinct noninteractive zero knowledge for a von neumann architecture,&quot; in *23rd {USENIX} Security Symposium ({USENIX} Security 14)*, 2014, pp. 781–796.

[14] B. Bünz, J. Bootle, D. Boneh, A. Poelstra, P. Wuille, and G. Maxwell, &quot;Bulletproofs: Short proofs for confidential transactions and more,&quot; in *2018 IEEE Symposium on Security and Privacy, SP 2018, Proceedings, 21-23 May 2018, San Francisco, California, USA*, 2018, pp. 315–334.

[15] R. Gennaro, C. Gentry, B. Parno, and M. Raykova, &quot;Quadratic span programs and succinct NIZKs without PCPs,&quot; in *Proceedings of the 32nd Annual International Conference on Theory and Application of Cryptographic Techniques*, ser. EUROCRYPT &#x27;13, 2013, pp. 626–645.

[16] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum, &quot;Delegating computation: Interactive proofs for Muggles,&quot; in *Proceedings of the 40th Annual ACM Symposium on Theory of Computing*, ser. STOC &#x27;08, 2008, pp. 113–122.

[17] S. Goldwasser, S. Micali, and C. Rackoff, &quot;The knowledge complexity of interactive proof systems,&quot; *SIAM Journal on Computing*, vol. 18, no. 1, pp. 186–208, 1989, preliminary version appeared in STOC &#x27;85.

65

[18] A. E. Kosba, C. Papamanthou, and E. Shi, “xjsnark: A framework for efficient verifiable computation,” in 2018 IEEE Symposium on Security and Privacy, SP 2018, Proceedings, 21-23 May 2018, San Francisco, California, USA. IEEE Computer Society, 2018, pp. 944–961. [Online]. Available: https://doi.org/10.1109/SP.2018.00018
- [19] C. Lund, L. Fortnow, H. J. Karloff, and N. Nisan, “Algebraic methods for interactive proof systems,” Journal of the ACM, vol. 39, no. 4, pp. 859–868, 1992.
- [20] S. Meiklejohn, C. C. Erway, A. Küpçü, T. Hinkle, and A. Lysyanskaya, “ZKPDL: A language-based system for efficient zero-knowledge proofs and electronic cash,” in 19th USENIX Security Symposium, Washington, DC, USA, August 11-13, 2010, Proceedings. USENIX Association, 2010, pp. 193–206. [Online]. Available: http://www.usenix.org/events/sec10/tech/full_papers/Meiklejohn.pdf
- [21] N. Osaka, “A versatile memory-mapped i/o interface for microcomputers,” Behavior Research Methods &amp;amp; Instrumentation, vol. 13, no. 6, pp. 727–731, 1981.
- [22] B. Parno, J. Howell, C. Gentry, and M. Raykova, “Pinocchio: Nearly practical verifiable computation,” in 2013 IEEE Symposium on Security and Privacy, 2013, pp. 238–252.
- [23] P. Valiant, “Incrementally verifiable computation or proofs of knowledge imply time/space efficiency,” in Theory of Cryptography Conference. Springer, 2008, pp. 1–18.</code></pre>`;
---

<BaseLayout title="Cairo – a Turing-complete STARK-friendly CPU architecture (2021/1063)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2021 &middot; eprint 2021/1063
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
