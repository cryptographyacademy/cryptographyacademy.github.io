---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2017/1016';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Differentially Private Access Patterns in Secure Computation';
const AUTHORS_HTML = 'Sahar Mazloom, S.  Dov Gordon';

const CONTENT = `    <p class="text-gray-300">Sahar Mazloom [ George Mason University ] S. Dov Gordon [ George Mason University ]</p>

    <h6 id="sec-2" class="text-base font-medium mt-4">Abstract</h6>

    <p class="text-gray-300">We explore a new security model for secure computation on large datasets. We assume that two servers have been employed to compute on private data that was collected from many users, and, in order to improve the efficiency of their computation, we establish a new tradeoff with privacy. Specifically, instead of claiming that the servers learn nothing about the input values, we claim that what they do learn from the computation preserves the differential privacy of the input. Leveraging this relaxation of the security model allows us to build a protocol that leaks some information in the form of access patterns to memory, while also providing a formal bound on what is learned from the leakage.</p>

    <p class="text-gray-300">We then demonstrate that this leakage is useful in a broad class of computations. We show that computations such as histograms, PageRank and matrix factorization, which can be performed in common graph-parallel frameworks such as MapReduce or Pregel, benefit from our relaxation. We implement a protocol for securely executing graph-parallel computations, and evaluate the performance on the three examples just mentioned above. We demonstrate marked improvement over prior implementations for these computations.</p>

    <h2 id="sec-3" class="text-2xl font-bold">1 Introduction</h2>

    <p class="text-gray-300">Privacy and utility in today’s Internet is a tradeoff, and for most users, utility is the clear priority. Citizens continue to contribute greater amounts of private data to an increasing number of entities in exchange for a wider variety of services. From a theoretical perspective, we can maintain privacy and utility if these service providers are willing and able to compute on encrypted data. The theory of secure computation has been around since the earliest days of modern cryptography, but the practice of secure computation is relatively new, and still lags behind the advancements in data-mining and machine learning that have helped to create today’s tradeoff.</p>

    <p class="text-gray-300">Recently, we have seen some signs that the gap might be narrowing. The advancements in the field of secure computation have been tremendous in the last decade. The first implementations computed roughly 30 circuit gates per second, and today they compute as many as 6 million per second <em>[40]</em>. Scattered examples of live deployments have been referenced repeatedly, but most recently, in one of the more promising signs of change, Google has started using secure computation to help advertisers compute the value of their ads, and they will soon start using it to securely construct machine learning classifiers from mobile user data <em>[23]</em>. A separate, more recent line of research also offers promise: the theory and techniques of differential privacy give service providers new mechanisms for aggregating user data in a way that reasonably combines utility and privacy. The guarantee of these mechanisms is that, whatever can be learned from the aggregated data, the amount that it reveals about any single user input is minimal. The Chrome browser uses these techniques when aggregating crash reports <em>[14]</em>, and Apple claims to be employing them for collecting usage information from mobile devices. In May, 2017, U.S. Senator Ron Wyden wrote an open letter to the commission on evidence-based policymaking, urging that both secure computation and differential privacy be employed by “agencies and organizations that seek to draw public policy related insights from the private data of Americans <em>[39]</em>.”</p>

    <p class="text-gray-300">The common thread in these applications is large scale computation, run by big organizations, on data that has been collected from many individual users. To address this category of problems, we explore new improvements for two-party secure computation, carried out by two dedicated computational servers, over secret shares of user data. We use a novel approach: rather than attempting to improve on known generic constructions, or tailoring a new solution for a particular problem, we instead explore a new trade-off between efficiency and privacy. Specifically, we propose a model of secure computation in which some small information is leaked to the computation servers, but this leakage is proven to preserve differential privacy for the users that have contributed data. More technically, the leakage is a random function of the input, revealed in the form of access patterns to memory, and the output of this function does not change “by too much” when one user’s input is modified or removed.</p>

    <p class="text-gray-300">The question of what is leaked by memory access patterns during computation is central to secure computation. Although the circuit model of computation allows us to skirt the issue, because circuits are data oblivious, when computing on large data there are better ways of handling the problem, the most well-studied being the use of secure two-party ORAM <em>[31, 16, 38, 24, 41, 40]</em>. However, when looking at very large data sets, it is often the case that both circuits and ORAM are too slow for practical requirements, and there is strong motivation to look for better approaches. In the area of encrypted search, cryptographers have frequently proposed access-pattern leakage as a tradeoff for efficiency <em>[5, 4, 33, 20]</em>. Unfortunately, analyzing and quantifying the leakage caused by the computation’s access pattern is quite difficult, as it depends heavily on the specific computation, the particulars of the data, and even the auxiliary information of the adversary. Furthermore, recent progress on study</p>

    <p class="text-gray-300">ing this leakage has mostly drawn negative conclusions, suggesting that a lot more is revealed than we might originally have hoped <em>[19, 27, 3, 21, 11]</em>. Employing the definition of differential privacy as a way to bound the leakage of our computation allows us to offer an efficiency / privacy tradeoff that cryptographers have been trying to provide, while quantifying, in a rigorous and meaningful way, precisely what we have leaked.</p>

    <h3 id="sec-4" class="text-xl font-semibold mt-8">1.1 Graph-Parallel Computations</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">While the proposed security relaxation is appealing, it is not immediately clear that it provides a natural way to improve efficiency. Our main contribution is that we identify a broad class of highly parallelizable computations that are amenable to the privacy/ efficiency tradeoff we propose. When computing on plaintext data, frameworks such as MapReduce, Pregel, GraphLab and PowerGraph have very successfully enabled developers to leverage large networks of parallelized CPUs <em>[9, 26, 25, 15]</em>. The latter three mentioned systems are specifically designed to support computations on data that resides in a graph, either at the nodes or edges. The computation proceeds by iteratively gathering data from incoming edges to the nodes, performing some simple computation at the node, and pushing the data back to the outgoing edges. This simple iterative procedure captures many important computational tasks, including histogram, gradient descent and page-rank, which we focus on in our experimental section, as well as Markov random field parameter learning, parallelized Gibbs samplers, and name entity resolution, to name a few more. Recently, Nayak et al. <em>[28]</em>, generalizing the work of Nikolaenko et al. <em>[29]</em>, constructed a framework for securely computing graph-parallel algorithms. They did this by designing a nicely parallelizable circuit for the gather and scatter phases, requiring $O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)\\log^{2}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$ AND gates.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-5" class="text-xl font-semibold mt-8">1.2 A Connection to Differential Privacy</h3>

    <p class="text-gray-300">The memory access pattern induced by this computation is easily described: during the gather stage, each edge is touched when fetching the data, and the adjacent node is touched when copying the data. A similar pattern is revealed during the scatter phase. (The computation performed during the apply phase is typically very simple, and can be executed in a circuit, which is memory oblivious.) Let’s consider what might be revealed by this access pattern in some concrete application. In our framework, each user is represented by a node in the graph, and provides the data on the edges adjacent to that node. For example, in a recommendation system, the graph is bipartite, each node on the left represents a user, each node on the right represents an item that users might review, and the edges are labeled with scores indicating the user’s review of an item. The access pattern just described would reveal exactly which items every user reviewed!</p>

    <p class="text-gray-300">Our first observation is that if we use a secure computation to obliviously shuffle all of the edges in between the gather and scatter phases, we break the correlation between the nodes. Now the only thing revealed to the computing</p>

    <p class="text-gray-300">parties is a <em>histogram</em> of how many times each node is accessed – i.e. a count of each node’s in-degree and out-degree. When building a recommendation system, this would reveal how many items each user reviewed, as well as how many times each item was reviewed. Fortunately, histograms are the canonical problem for differential privacy. Our second observation is that we can shuffle in dummy edges to help obscure this information, and, by sampling the dummy edges from an appropriate distribution (which has to be done within a secure computation), we can claim that the degrees of each node remain differentially private.</p>

    <h3 id="sec-6" class="text-xl font-semibold mt-8">1.3 Contributions and Related Work</h3>

    <p class="text-gray-300">Contributions. We make several new contributions, of both a theoretical and a practical nature.</p>

    <p class="text-gray-300">Introducing the model. As cryptographers have attempted to support secure computation on increasingly large datasets, they have often allowed their protocols to leak some information to the computing parties in the form of access patterns to memory. This is especially true in the literature on encrypted search. The idea of bounding the leakage in a formal way, using the definitions from literature on differential privacy, is novel and important. (Concurrent and independent of our work, He et al. <em>[18]</em> proposed a very similar security relaxation, which we discuss below.)</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Asymptotic improvement. The relaxation we introduce enables us to improve the asymptotic complexity of the target computations by a factor of (roughly) <span class="math">\\log n</span> over the best known, fully oblivious construction. Using the best known sorting networks, the construction of Nayak et al. <em>[28]</em> requires $O((</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)\\log(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">))<span class="math"> AND gates. In comparison, our construction requires </span>O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> AND gates, where </span>\\alpha<span class="math"> depends on the privacy parameters, </span>\\epsilon<span class="math"> and </span>\\delta<span class="math">. For graphs with </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=O(\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">, our improvement is by a factor of </span>\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$. While we do not have a lower bound in the fully oblivious model, we find it very exciting that there exist computations where our relaxation is this meaningful, and we suspect that improved asymptotic results in the fully oblivious model are not possible. The details of this improvement appear in Section 5.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Concrete improvement. We demonstrate that the asymptotic improvements lead to tangible gains. We have implemented our system, and compared the results to the system of Nayak et al. <em>[28]</em>. We demonstrate up to a 20X factor improvement in the number of garbled AND gates required in the computation, while preserving differential privacy with strong parameters: <span class="math">\\epsilon=.3</span> and <span class="math">\\delta=2^{-40}</span>. We note that, in practice, both results are worse than previously described by a factor of $\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. In their implementation, Nayak et al. rely on a practical oblivious sort, using </span>O((</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)\\log(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">))^{2}<span class="math"> AND gates. Our construction using </span>O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> gates requires performing decryption inside a garbled circuit, which we avoid in our implementation through the use of a two-party oblivious shuffle, resulting in </span>O((</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)\\log(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">))<span class="math"> AND gates. However, we still save a factor of </span>\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ for sufficiently dense graphs. The details of this</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">construction appear in Section 4, and an evaluation of its performance appears in Section 6.</p>

    <p class="text-gray-300"><em>Securely generating noise</em> We describe a new noise distribution that is amenable to efficient implementation in a garbled circuit. Dwork et al. previously described an efficient method for sampling the geometric distribution in a garbled circuit <em>[12]</em>, but they did this for the 1-sided geometric distribution, which is not immediately useful for providing differential privacy. Unfortunately, the standard 2-sided geometric distribution needs to be normalized in a way that ruins the simplicity of the circuit they describe. We construct a slightly modified distribution that addresses this problem, and prove that it provides differential privacy.</p>

    <p class="text-gray-300">Related Work. The most relevant work, as already discussed, is that by Nayak et al. <em>[28]</em>, which generalizes the work of Nikolaenko et al. <em>[29]</em>, computing graph parallel computations with full security. (The latter work focused solely on the problem of sparse matrix factorization.) Papadimitriou et al. <em>[32]</em> also build a system for the secure computation of graph-structured data, and ensure differential privacy of the output. They do not consider differentially private leakage in the access patterns, and they focus on MPC and the networking challenges that arise in that setting; in particular, they do not rely on computational servers, but assume that all data contributors are involved in the computation, and focus on how to hide the movement of data between users in a way that preserves privacy of the edge structure. Kellaris et al. construct protocols for encrypted search, and use differential privacy to bound the leakage from access patterns <em>[22]</em>. This work directly inspired us to consider a more general approach to modeling leakage in secure computation through differential privacy. Wagh et al. <em>[35]</em> define and construct differentially private ORAM in which the server’s views are “similar” on two neighboring access patterns. They consider the client/server model, and don’t consider using their construction in a secure computation, but it is very interesting to note that we could use their result in a generic way to build a protocol for generic secure computation with differentially private access patterns. While feasibility follows from their work, the resulting protocol provides no asymptotic improvement, and would be quite impractical.</p>

    <p class="text-gray-300">Independent of our work, He et al. define a security notion that is similar to our own, and construct new protocols for private record linkage <em>[18]</em>. Informally, their definition requires that for any input set <span class="math">D_{1}</span>, and for two neighbors <span class="math">D_{2},D_{2}^{\\prime}</span> for which <span class="math">f(D_{1},D_{2})=f(D_{1},D_{2}^{\\prime})</span>, the protocol views should preserve differential privacy. We note that their definition is not in the simulation paradigm, which leads to some important differences. For one, they only require security on inputs that map to the same output, and in particular, cannot apply their definition to randomized functionalities. They also have no correctness requirement (which is captured in the simulation paradigm by default): this is</p>

    <p class="text-gray-300">intentional, as they explore not just an efficiency / privacy tradeoff, but a correctness tradeoff as well. Perhaps the biggest difference between their work and our own is the application space. In private record linkage protocols, items are typically hashed into bins, and dummy items are used to hide the load of each bin. When applying their relaxation, they gain efficiency over fully secure protocols by cutting down on the number of dummy items and claiming differential privacy, in place of statistically hiding the bin load. Since the maximum load on a bin is <span class="math">\\frac{\\log n}{\\log\\log n}</span> with high probability, they can only claim improvement if they use very few dummy items, and as such they can only claim fairly weak security. Specifically, in most of their experiments <span class="math">\\delta=2^{-16}</span>. While there may be settings where this security parameter suffices, it is important to recognize that <span class="math">\\delta</span> denotes the statistical probability that a user’s data is completely recovered, and this value is typically set to <span class="math">2^{-40}</span> in MPC research. Finding an application space where the security relaxation provides significant efficiency improvements while also guaranteeing strong security parameters was a major challenge, and we view it as one of our main contributions.</p>

    <p class="text-gray-300">Chan et al. study differential obliviousness in the client / server model <em>[6]</em>. They also show asymptotic improvement for several computations, together with lower bounds for fully secure variants of the same algorithms, demonstrating that this relaxation allows us to bypass impossibility results. Their results are purely theoretical, but raise the very interesting question of whether we can lower-bound the number of AND gates needed in fully secure graph parallel computation. An initial version of our work did not include Section 5, where we show how to remove the oblivious shuffle, improving the asymptotic complexity of our solution. While our initial work predates the work of Chan et al., the asymptotic improvement of Section 5 was concurrent with their work.</p>

    <p class="text-gray-300">M2R <em>[10]</em> and Ohrimenko et al. <em>[30]</em> consider secure implementation of MapReduce jobs on untrusted cloud servers, where the adversary has access to the network and storage back-end, and can observe all encrypted traffic between Map and Reduce nodes, but cannot corrupt those nodes; they assume secure hardware, such as SGX. They hide flow between map and reduce operations by shuffling the data produced by the Mappers in secure hardware before sending it to the Reducers. They do not use any notion of differential privacy. Finally, Airavat <em>[34]</em> protects the output of the map-reduce computation by adding exponentially distributed noise to the output of computation.</p>

    <h2 id="sec-7" class="text-2xl font-bold">2 Notation and Definitions</h2>

    <p class="text-gray-300">Secret-Shares: We let <span class="math">\\langle x\\rangle</span> denote a variable which is XOR secret-shared between parties. Arrays have a public length and are accessed via public indices; we use <span class="math">\\langle x\\rangle_{i}</span> to specify element <span class="math">i</span> within a shared array, and <span class="math">\\langle x\\rangle_{i:j}</span> to indicate a specific portion of the array containing elements <span class="math">i</span> through <span class="math">j</span>, inclusive. When we write <span class="math">\\langle x\\rangle\\leftarrow c</span>, we mean that both users should fix their shares of <span class="math">x</span> (using some agreed upon manner) to ensure that <span class="math">x=c</span>. For example, one party might set his share to be <span class="math">c</span> while the other sets his share to <span class="math">0</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Multi-Sets: We represent multi-sets over a set  <span class="math">V</span>  by a  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  dimensional vector of natural numbers:  </span>D \\in \\mathbb{N}^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math"> . We refer to the  </span>i<span class="math"> th element of this vector by  </span>D(i)<span class="math"> . We use  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">D</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  in the natural way to mean  </span>\\sum_{i=1}^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">} D(i)<span class="math"> . We use  </span>\\mathcal{DB}_i<span class="math">  to denote the set of all multi-sets over  </span>V<span class="math">  of size  </span>i<span class="math"> , and  </span>\\mathcal{DB} = \\bigcup_{i} \\mathcal{DB}_i<span class="math"> . We define a metric on these multi-sets in the natural way:  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">D_1 - D_2</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\sum_{i=1}^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">D_1(i) - D_2(i)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> . We say two multi-sets are neighboring if they have distance at most 1:  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">D_1 - D_2</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq 1$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Neighboring Graphs: In our main protocol of Section 4, the input is a data-augmented directed graph, denoted by  <span class="math">G = (V,E)</span> , with user-defined data on each edge. We need to define a metric on these input graphs, in order to claim security for graphs of bounded distance. For each  <span class="math">v \\in V</span> , we let  <span class="math">\\mathsf{in-deg}(v)</span>  and  <span class="math">\\mathsf{out-deg}(v)</span>  denote the in-degree and out-degree of node  <span class="math">v</span> . We define the in-degree profile of a graph  <span class="math">G</span>  as the multi-set  <span class="math">\\mathsf{D}_{\\mathsf{in}}(G) = \\{\\mathsf{in-deg}(v_1), \\ldots, \\mathsf{in-deg}(v_n)\\}</span> . Intuitively, this is a multi-set over the node identifiers from the input graph, with vertex identifier  <span class="math">v</span>  appearing  <span class="math">k</span>  times if  <span class="math">\\mathsf{in-deg}(v) = k</span> . We define the full-degree profile of  <span class="math">G</span>  as the pair of multi-sets:  <span class="math">\\{\\mathsf{D}_{\\mathsf{in}}(G), \\mathsf{D}_{\\mathsf{out}}(G)\\}</span> , where</p>

    <p class="text-gray-300"><span class="math">\\mathsf{D}_{\\mathrm{out}}(G) = \\{\\mathrm{out - deg}(v_1),\\ldots ,\\mathrm{out - deg}(v_n)\\}</span> . We now define two different metrics on graphs, using these degree profiles. Later in this section, we provide two different security definitions: we rely on the first distance metric below when claiming security as defined in Definition 5, and rely on the second metric below when claiming security as defined in Definition 6.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Definition 1 We say two graphs  <span class="math">G</span>  and  <span class="math">G&#x27;</span>  have distance at most  <span class="math">d</span>  if they have in-degree profiles of distance at most  <span class="math">d</span> :  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathsf{D}_{\\mathrm{in}}(G) - \\mathsf{D}_{\\mathrm{in}}(G')</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq d<span class="math"> . We say that  </span>G<span class="math">  and  </span>G'$  are neighboring if they have distance 1.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Definition 2 We say two graphs  <span class="math">G</span>  and  <span class="math">G&#x27;</span>  have full-degree profiles of distance  <span class="math">d</span>  if the sum of the distances in their in-degree profiles and their out-degree profiles is at most  <span class="math">d</span> :  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathsf{D}_{\\mathrm{in}}(G) - \\mathsf{D}_{\\mathrm{in}}(G')</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathsf{D}_{\\mathrm{out}}(G) - \\mathsf{D}_{\\mathrm{out}}(G')</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq d<span class="math"> . We say that  </span>G<span class="math">  and  </span>G'$  have neighboring full-degree profiles if they have full-degree profiles of distance 2.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We use the definition that appears in [13].</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Definition 3 A randomized algorithm  <span class="math">\\mathcal{L}:\\mathcal{DB}\\to \\mathcal{R}_{\\mathcal{L}}</span> , with an input domain  <span class="math">\\mathcal{DB}</span>  that is the set of all multi-sets over some fixed set  <span class="math">V</span> , and output  <span class="math">\\mathcal{R}_{\\mathcal{L}}\\subset \\{0,1\\}^*</span> , is  <span class="math">(\\epsilon ,\\delta)</span> -differentially private if for all  <span class="math">T\\subseteq \\mathcal{R}_{\\mathcal{L}}</span>  and  <span class="math">\\forall D_1,D_2\\in \\mathcal{DB}</span>  such that  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">D_{1} - D_{2}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq 1$ :</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\mathcal {L} \\left(D _ {1}\\right) \\in T \\right] \\leq e ^ {\\epsilon} \\Pr \\left[ \\mathcal {L} \\left(D _ {2}\\right) \\in T \\right] + \\delta</span></div>

    <p class="text-gray-300">where the probability space is over the coin flips of the mechanism  <span class="math">\\mathcal{L}</span> .</p>

    <p class="text-gray-300">The above definition describes differential privacy for neighboring multi-sets. Letting <span class="math">\\mathcal{G}</span> denote the set of all graphs, we define it for neighboring graphs as well:</p>

    <h6 id="sec-9" class="text-base font-medium mt-4">Definition 4</h6>

    <p class="text-gray-300">A randomized algorithm <span class="math">\\mathcal{L}:\\mathcal{G}\\rightarrow\\mathcal{R}_{\\mathcal{L}}</span> is <span class="math">(\\epsilon,\\delta)</span>-edge private if for all neighboring graphs, <span class="math">G_{1},G_{2}\\in\\mathcal{G}</span>, we have:</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mathcal{L}(G_{1})\\in T]\\leq e^{\\epsilon}\\Pr[\\mathcal{L}(G_{2})\\in T]+\\delta</span></p>

    <h3 id="sec-10" class="text-xl font-semibold mt-8">2.2 Secure computation with differentially private access patterns</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Input model: We try to keep the definitions general, as we expect they will find application beyond the space of graph-structured data. However, we use notation that is suggestive of computation on graphs, in order to keep our notation consistent with the later sections. We assume that two computation servers have been entrusted to compute on behalf of a large set of users, <span class="math">\\mathcal{V}</span>, with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{V}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=n<span class="math">, and having sequential identifiers, </span>1,\\ldots,n<span class="math">. Each user </span>i<span class="math"> contributes data </span>v_{i}<span class="math">. They might each entrust their data to one of the two servers (we call this the disjoint collection setting), or they might each secret-share their input with the two-servers (joint collection setting). In the latter case, we note that both servers learn the size of each </span>v_{i}$ but neither learns the input values; in the former case, each server learns a subset of the input values, but learns nothing about the remaining input values (other than the sum of their sizes). Below we will define two variant security notions that capture these two scenarios.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In all computations that we consider in our constructions, the input is represented by a graph. In every case, each user is represented as a node in this graph, and each user input is a set of weighted, directed edges that originate at their node. In some applications, the graph is bipartite, with user nodes on the left, and some distinct set of item nodes on the right: in this case, all edges go from user nodes to item nodes. In other applications, there are only user nodes, and every edge is from one user to another. In the joint collection setting, we can leak the out-degree of each node, which is the same as the user input size, but must hide (among other things) the in-degree of each node. In the disjoint collection setting, the protocol must hide both the in-degree and out-degree of each node. We note that in some applications, such as when we perform gradient descent, the graph is bipartite, and it is publicly known that the in-degree of every user is 0 (i.e. the movies don’t review the viewers). In the joint collection setting, this knowledge allows for some improvement in efficiency that we will leverage in Section 6.</p>

    <p class="text-gray-300">##</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Defining secure computation with leakage: For simplicity, we start with a standard definition of semi-honest security <span class="math">^4</span> , but make two important changes. The first change is that we allow certain leakage in the ideal world, in order to reflect what is learned by the adversary in the real world through the observed access pattern on memory. The leakage function is a randomized function of the inputs. The second change is an additional requirement that this leakage function be proven to preserve the differential privacy for the users that contribute data. Our ideal world experiment is as follows. There are two parties,  <span class="math">P_{1}</span>  and  <span class="math">P_{2}</span> , and an adversary  <span class="math">\\mathcal{S}</span>  that corrupts one of them. The parties are given input, as described above; we use  <span class="math">V_{1}</span>  and  <span class="math">V_{2}</span>  to denote the inputs of the computing parties, regardless of whether we are in the joint collection setting or the disjoint collection setting, and we let  <span class="math">V = \\{v_{1},\\ldots ,v_{n}\\}</span>  denote the user input. Technically, in the joint collection setting,  <span class="math">V = V_{1}\\oplus V_{2}</span> , while in the disjoint collection setting,  <span class="math">V = V_{1}\\cup V_{2}</span> . Each computing party submits their input to the ideal functionality, unchanged. The ideal functionality reconstructs the  <span class="math">n</span>  user inputs,  <span class="math">v_{1},\\dots,v_{n}</span> , either by taking the union of the inputs submitted by the computation servers in the disjoint collection setting, or by reconstructing the input set from the provided secret shares in the joint collection setting. The ideal functionality then outputs  <span class="math">f_{1}(v_{1},\\ldots ,v_{n})</span>  to  <span class="math">P_{1}</span>  and  <span class="math">f_{2}(v_{1},\\ldots ,v_{n})</span>  to  <span class="math">P_{2}</span> . These outputs might be correlated, and, in particular, in our own use-cases, each party receives a secret share of a single function evaluation:  <span class="math">\\langle f(v_1,\\ldots ,v_n)\\rangle_1</span> ,  <span class="math">\\langle f(v_1,\\ldots ,v_n)\\rangle_2</span> . The ideal functionality also applies some leakage function to the data,  <span class="math">\\mathcal{L}(V)</span> , and provides the output of  <span class="math">\\mathcal{L}(V)</span> , along with  $\\sum_{i\\in \\mathcal{V}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">v_i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  to  </span>\\mathcal{S}<span class="math"> . Additionally, depending on the choice of security definition, the ideal functionality might or might not give the simulator,  </span>\\forall i\\in \\mathcal{V}<span class="math"> ,  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">v_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Our protocols are described in a hybrid world, in which the parties are given access to several secure, ideal functionalities. In our implementation, these are replaced using generic constructions of secure computation (i.e. garbled circuits). Relying on a classic result of Canetti [2], when proving security, it suffices to treat these as calls to a trusted functionality. In the definitions that follow, we let  <span class="math">\\mathcal{G}</span>  denote an appropriate collection of ideal functionalities.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">As is conventionally done in the literature on secure computation, we let  <span class="math">\\mathrm{HYBRID}_{\\pi, \\mathcal{A}(z)}^{\\mathcal{G}}(V_1, V_2, \\kappa)</span>  denote a joint distribution over the output of the honest party and, the view of the adversary  <span class="math">\\mathcal{A}</span>  with auxiliary input  <span class="math">z \\in \\{0, 1\\}^*</span> , when the parties interact in the hybrid protocol  <span class="math">\\pi^{\\mathcal{G}}</span>  on inputs  <span class="math">V_1</span>  and  <span class="math">V_2</span> , each held by one of the two parties, and computational security parameter  <span class="math">\\kappa</span> . We let  $\\mathrm{IDEAL}_{\\mathcal{F}, \\mathcal{S}(z, \\mathcal{L}(V), \\forall i \\in V:</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">v_i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)}(V_1, V_2, \\kappa)<span class="math">  denote the joint distribution over the output of the honest party, and the view output by the simulator  </span>\\mathcal{S}<span class="math">  with auxiliary input  </span>z \\in \\{0, 1\\}^*<span class="math"> , when the parties interact with an ideal functionality  </span>\\mathcal{F}<span class="math">  on inputs  </span>V_1<span class="math">  and  </span>V_2$ , each submitted by one of the two parties, and secu</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">4We stress that our allowance of differentially private leakage brings gains in the circuit construction, so we could use any generic secure computation of Boolean circuits, including those that are maliciously secure, and benefit from the same gains. See more details below.</p>

    <p class="text-gray-300">5In the joint collection setting, the simulator can infer this value from the size of the input that was submitted to the ideal functionality. But it simplifies things to give it to him explicitly.</p>

    <p class="text-gray-300">9</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">rity parameters <span class="math">\\kappa</span>. Letting $v=\\sum_{i\\in V}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">v_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">, we define the joint distribution </span>\\textsc{ideal}_{\\mathcal{F},\\mathcal{S}(z,\\mathcal{L}(V),v)}(V_{1},V_{2},\\kappa)$ in a similar way, the only difference being that the simulator is given the sum of the input sizes and not the value of each input size.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-11" class="text-base font-medium mt-4">Definition 5</h6>

    <p class="text-gray-300">Let <span class="math">\\mathcal{F}</span> be some functionality, and let <span class="math">\\pi</span> be a two-party protocol for computing <span class="math">\\mathcal{F}</span>, while making calls to an ideal functionality <span class="math">\\mathcal{G}</span>. <span class="math">\\pi</span> is said to securely compute <span class="math">\\mathcal{F}</span> in the <span class="math">\\mathcal{G}</span>-hybrid model with <span class="math">\\mathcal{L}</span> leakage, known input sizes, and <span class="math">(\\kappa,\\epsilon,\\delta)</span>-security if <span class="math">\\mathcal{L}</span> is <span class="math">(\\epsilon,\\delta)</span>-differentially private, and, for every PPT, semi-honest, non-uniform adversary <span class="math">\\mathcal{A}</span> corrupting a party in the <span class="math">\\mathcal{G}</span>-hybrid model, there exists a PPT, non-uniform adversary <span class="math">\\mathcal{S}</span> corrupting the same party in the ideal model, such that, on any valid inputs <span class="math">V_{1}</span> and <span class="math">V_{2}</span></p>

    <p class="text-gray-300"><span class="math">\\left\\{\\textsc{hybrid}_{\\pi,\\mathcal{A}(z)}^{\\mathcal{G}}(V_{1},V_{2},\\kappa)\\right\\}_{z\\in\\{0,1\\}^{*},\\kappa\\in\\mathbb{N}}\\overset{c}{=}</span> (1)</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\{\\textsc{ideal}_{\\mathcal{F},\\mathcal{S}(z,\\mathcal{L}(V),\\forall i\\in V:</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">v_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)}^{(1)}(V_{1},V_{2},\\kappa)\\right\\}_{z\\in\\{0,1\\}^{*},\\kappa\\in\\mathbb{N}}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The above definition is the one that we use in our implementations. However, in Section 4 we also describe a modified protocol that achieves the stronger security definition that follows, where the adversary does not learn the sizes of individual inputs. This property might be desirable (or maybe even essential) in the disjoint collection model, where users have not entrusted one of the two computing parties with their inputs, or even the sizes of their inputs. On the other hand, the previous definition is, in some sense, more “typical” of definitions in cryptography, where we assume that inputs sizes are leaked. It is only in this model where data is outsourced that we can hope to hide each individual input size among the other inputs.</p>

    <h6 id="sec-12" class="text-base font-medium mt-4">Definition 6</h6>

    <p class="text-gray-300">Let <span class="math">\\mathcal{F}</span> be some functionality, and let <span class="math">\\pi</span> be a two-party protocol for computing <span class="math">\\mathcal{F}</span>, while making calls to an ideal functionality <span class="math">\\mathcal{G}</span>. <span class="math">\\pi</span> is said to securely compute <span class="math">\\mathcal{F}</span> in the <span class="math">\\mathcal{G}</span>-hybrid model with <span class="math">\\mathcal{L}</span> leakage, and <span class="math">(\\kappa,\\epsilon,\\delta)</span>-security if <span class="math">\\mathcal{L}</span> is <span class="math">(\\epsilon,\\delta)</span>-differentially private, and, for every PPT, semi-honest, non-uniform adversary <span class="math">\\mathcal{A}</span> corrupting a party in the <span class="math">\\mathcal{G}</span>-hybrid model, there exists a PPT, non-uniform adversary <span class="math">\\mathcal{S}</span> corrupting the same party in the ideal model, such that, on any valid inputs <span class="math">V_{1}</span> and <span class="math">V_{2}</span></p>

    <p class="text-gray-300"><span class="math">\\left\\{\\textsc{hybrid}_{\\pi,\\mathcal{A}(z)}^{\\mathcal{G}}(V_{1},V_{2},\\kappa)\\right\\}_{z\\in\\{0,1\\}^{*},\\kappa\\in\\mathbb{N}}\\overset{c}{=}</span> (2)</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\{\\textsc{ideal}_{\\mathcal{F},\\mathcal{S}(z,\\mathcal{L}(V),\\sum_{i\\in V}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">v_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)}^{(2)}(V_{1},V_{2},\\kappa)\\right\\}_{z\\in\\{0,1\\}^{*},\\kappa\\in\\mathbb{N}}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Differentially Private Output: As is typical in secure computation, we are concerned here with <em>how</em> to securely compute some agreed upon function, rather than <em>what</em> function ought to be computed. In other words, we view the question of what the output itself might reveal about the input to be beyond scope of our work. Our concern is only that the process of computing the output should not</p>

    <p class="text-gray-300">reveal too much. Nevertheless, one could ask that the output of all computations also be made to preserve differential privacy. Interestingly, for the specific case of histograms, which we present as an example in Section 3, adding differentially private noise to the output is substantially more efficient than preserving an exact count. This is not true for the general protocol, but the cost of adding noise for these cases has been studied elsewhere <em>[32]</em>, and it would be minor compared to the rest of the protocol.</p>

    <p class="text-gray-300">Nevertheless, we take a different approach. In all of our computations, the output of each server is a secret share of the desired output, and thus it is unconditionally secure. The question of where to deliver these shares is left to the user, though we can imagine several useful choices. Perhaps most obvious, the shares might never be reconstructed, but rather used later inside another secure computation that makes decisions driven by the output. Or, as Nikolaenko et al. suggest <em>[29]</em>, when computing gradient descent to provide users with recommendations, the recommendation vectors can be sent to the user to store for themselves. Regardless, since the aim of our work is to study the utility of our relaxation, this concern is orthogonal, and we mainly leave it alone.</p>

    <p class="text-gray-300">Privacy versus efficiency In the “standard” settings where differential privacy is employed, additional noise affects the accuracy of the result. Here, added noise has no impact on the output, which is always correct, and is protected by the secure computation. Instead, the tradeoff is with efficiency: using more noise helps to further hide the true memory accesses among the fake ones, but requires additional, costly oblivious computation.</p>

    <p class="text-gray-300">Malicious security and multi-party computation: Extending these definitions to model malicious adversaries and/or multi-party computation is straightforward, so we omit redundant detail. Similarly, we stress that by leveraging the security relaxation defined above, we gain improvement at the circuit level, so we can easily extend our protocols to either (or both) of these two settings in a generic way. To make our protocol from Section 4 secure against a malicious adversary, the only subtlety to address is that our protocols make iterative use of multiple secure computations (i.e. the functionality we realize is reactive), so we would need to authenticate outputs and verify inputs in each of these computations. While this can be done generically, such authentication comes “for free” in many common protocols for secure computation (e.g. <em>[37, 8]</em>). To extend our protocols to a multiparty setting, the only subtlety is in constructing a multiparty oblivious shuffle. With a small number of parties, <span class="math">c</span>, it is very efficient to implement <span class="math">c</span> iterations of a permutation network, where in each iteration, a different party chooses the control bits that determine the permutation. As <span class="math">c</span> grows, it becomes less clear what the best method is for implementing an oblivious shuffle. Interestingly, we note that there has been some recent work on parallelizing multi-party oblivious shuffle <em>[7]</em>. We do not explore this direction in our work; presenting our protocols in the two-party, semi-honest setting greatly simplifies the exposition, and suffices to demonstrate the advantages of our security relaxation. In our performance analysis, we primarily focus on counting the number of AND gates in our construction, which makes the analysis more</p>

    <p class="text-gray-300">general and allows for more accurate comparison with prior work (than, say, comparing the timed performance of systems that use different frameworks for implementing secure computation).</p>

    <h2 id="sec-13" class="text-2xl font-bold">3 A Differentially Private Protocol for Computing Histograms</h2>

    <p class="text-gray-300">To illustrate our main idea, we describe an algorithm that computes the data histogram (i.e. counting, or data frequency) with differentially private access patterns. Although this computation can be formalized in the context of our general framework, it is instructive to demonstrate some of the main technical ideas with this simple example before considering how they generalize (which we do in Section 4). We defer a discussion about security until we present the more general protocol.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In this computation, we assume that each user in the system contributes a single input value, <span class="math">x_{i}\\in S</span>, where we call the set <span class="math">S</span> the set of <em>types</em>. The computation servers (parties) each begin the computation with secret shares of the input array, denoted by <span class="math">\\langle\\mathsf{real}\\rangle</span>. The output is a secret share of $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ counters, where the counter for each type contains the exact number of inputs of that type. The full protocol specification appears in Figure 1.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The protocol is in a hybrid model, where the parties have access to three ideal functionalities: <span class="math">\\mathsf{DumGen}_{p,\\alpha},\\mathcal{F}_{\\mathsf{Shuffle}},\\mathcal{F}_{\\mathsf{add}}</span>. The two parties begin by calling <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span>, which generates some number of dummy inputs. The ideal functionality for this is described in the left of Figure 2, and it is realized using a generic secure two-party computation. As part of this computation, the parties have to securely sample from the distribution <span class="math">\\mathfrak{D}_{p,\\alpha}</span>. In the next section, we define this distribution and describe our method for sampling it. We simply remark now that it has integer support, and is negative with only negligible probability (in <span class="math">\\delta</span>). The output of <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span> is a secret sharing of values in <span class="math">S\\cup\\{\\bot\\}</span>: the size of the output is $2\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, where </span>\\alpha<span class="math"> is determined by the desired privacy values </span>\\epsilon<span class="math"> and </span>\\delta<span class="math"> (see Section 4). The number of dummy items of each type is random, and neither party should learn this value; shares of </span>\\bot<span class="math"> are used to pad the number of dummy items of each type until they total </span>2\\alpha$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Each party locally concatenates their share of the real input array with their share of the dummy values. They also initialize shares of an array of flags, denoted as <span class="math">\\mathsf{isReal}</span>, which will be used to keep track of which item is real and which is dummy. They then shuffle the real and dummy items together using an oblivious shuffle. This is presented as an ideal functionality, but in practice we implement this using two sequential, generic secure computations of the Waksman permutation network <em>[1]</em>, where each party randomly choose one of the two permutations. The same permutations are used to shuffle the array <span class="math">\\mathsf{isReal}</span> flags, ensuring that these flags are “moved around with” the items. We note that all secret shares are updated during the process of shuffling, so while the parties knew which items and flags were real and which were not before the</p>

    <p class="text-gray-300">Input: Each party,  <span class="math">P_{1}</span>  and  <span class="math">P_{2}</span> , receives a secret-share of real items denoted as  <span class="math">\\langle \\text{real} \\rangle</span>  ( <span class="math">r</span>  stands for number of real items, and  <span class="math">d</span>  for number of dummy ones)</p>

    <p class="text-gray-300">Output: Secret share of counter values denoted as  <span class="math">\\langle \\text{Counter} \\rangle</span> , where the counter for each type contains the exact number of inputs of that type ( <span class="math">S</span>  is the number of counter types)</p>

    <p class="text-gray-300">Preprocessing:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\langle \\mathrm{Counter}\\rangle_{1:</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\gets 0$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Computation:</p>

    <p class="text-gray-300"><span class="math">\\langle \\mathrm{dummy}\\rangle_{1:d} \\gets \\mathrm{DumGen}_{p,\\alpha}</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\langle \\mathrm{data}\\rangle_{1:(r + d)} = \\langle \\mathrm{real}\\rangle_{1:r}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\langle \\mathrm{dummy}\\rangle_{1:d}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\langle \\mathrm{isReal}\\rangle_{1:r} \\gets 1</span> ,  <span class="math">\\langle \\mathrm{isReal}\\rangle_{(r+1):(r+d)} \\gets 0</span></p>

    <p class="text-gray-300"><span class="math">\\langle \\widehat{\\text{data}} \\rangle \\gets \\mathcal{F}_{\\text{Shuffle}}(\\langle \\text{data} \\rangle, \\langle \\rho \\rangle)</span></p>

    <p class="text-gray-300"><span class="math">\\langle \\widehat{\\text{isReal}} \\rangle \\gets \\mathcal{F}_{\\text{Shuffle}}(\\langle \\text{isReal} \\rangle, \\langle \\rho \\rangle)</span></p>

    <p class="text-gray-300">data  <span class="math">\\leftarrow</span>  Open(  <span class="math">\\langle \\widehat{\\mathrm{data}}\\rangle</span></p>

    <p class="text-gray-300">for  <span class="math">i = 1\\ldots (n + d)</span></p>

    <p class="text-gray-300"><span class="math">\\mathcal{F}_{\\mathrm{add}}(\\langle \\mathrm{isReal}\\rangle_i,\\langle \\mathrm{Counter}\\rangle_t)</span>  where  <span class="math">t = \\widehat{\\mathrm{data}}_i</span></p>

    <p class="text-gray-300">Figure 1: A protocol for two parties to compute a histogram on secret-shared data with an access pattern that preserves differential privacy.</p>

    <p class="text-gray-300">shuffle, they have no way of knowing this after they receive fresh shares of the shuffled items and isReal flags.</p>

    <p class="text-gray-300">The parties now open their shares of the data types, while leaving the flag values unknown. This is where our protocol leaks some information: revealing the data types allows the parties to see a noisy sum of the number inputs of each type. On the other hand, this is also where we gain in efficiency: the remainder of the protocol requires only a linear scan over the data array, with a small secure computation for each element in order to update the appropriate counter value. More specifically, the parties iterate through the shuffled array, opening each type. On data type  <span class="math">i</span> , they fetch their shares of the counter for type  <span class="math">i</span>  from memory, and call the  <span class="math">\\mathcal{F}_{\\mathrm{add}}</span>  functionality. This functionality adds the (reconstructed) flag value to the (reconstructed) counter; if the item was a real item, the counter is incremented, while if it was a dummy item, the counter remains the same. The functionality returns fresh shares of the counter value. Neither party ever learns whether the counter was updated. In particular, they cannot know whether they fetched that counter from memory because of a real input value, or because of a dummy value. In our implementation, we instantiate  <span class="math">\\mathcal{F}_{\\mathrm{add}}</span>  with a garbled circuit.</p>

    <p class="text-gray-300">Simple extensions: In Section 4 we show how to generalize this protocol to the wider function class. However, we note that in this specific case, if we did want</p>

    <p class="text-gray-300">to add noise to the output, we could simply instruct the servers to count the number of times each counter is accessed. They would no longer have to update the counter values through a secure computation, so this would be a (slightly) faster protocol. The output would contain the one-sided noise, but they could simply subtract off <span class="math">\\alpha</span> from each counter to get a more accurate estimate of the counts. We stress that in this modified protocol, the dummy items are still shuffled in with the real items, so the access pattern still preserves differential privacy for each user. The modification ensures that the (reconstructed) output preserves differential privacy as well.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We also note that the protocol in Figure 1 can be applied to other similar computations, such as taking averages or sums over <span class="math">r</span> values of $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> types (though, now again <em>without</em> adding noise to the output). For example, if each user contributed a salary value and a zip-code, we could use the above method for computing the average salary in each zip-code, while ensuring that the access patterns preserve user privacy. We simply need to modify the </span>\\mathcal{F}_{\\texttt{add}}<span class="math"> functionality: instead of incrementing the secret-shared counter by </span>1<span class="math"> when the input is a real item, the functionality would increment the counter by the value of the secret-shared salary. In this case, though, the noisy access pattern alone does not suffice for creating noisy output: the use of </span>\\mathcal{F}_{\\texttt{add}}$ is essential. If we want ensure that the reconstructed output preserves privacy, the noise would have to be generated independently, through a secure computation, and then added obliviously to the output.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h2 id="sec-15" class="text-2xl font-bold">4 The OblivGraph Protocol</h2>

    <p class="text-gray-300">When considering how the protocol from the previous section might be generalized, it is helpful to recognize the essential property of the computation’s access pattern that we were leveraging. When computing a histogram, the access pattern to memory exactly leaks a histogram of the input! This might sound like a trivial observation, but it is in fact fairly important, as histograms are the canonical example in the field of differential privacy, and finding other computations where the access pattern reveals a histogram of the input will allow us to broadly apply our techniques.</p>

    <p class="text-gray-300">With that in mind, we extend our techniques to graph structured data, and the graph-parallel frameworks that support highly parallelized computation. There are several frameworks of this type, including MapReduce, Pregel, GraphLab and others <em>[9, 25, 26]</em>. We describe the framework by Gonzalez et al. <em>[15]</em> called PowerGraph since it combines the best features from both Pregel and GraphLab. PowerGraph is a graph-parallel abstraction, consisting of a sparse graph that encodes computation as <em>vertex-programs</em> that run in parallel and interact along edges in the graph. While the implementation of vertex-programs in Pregel and GraphLab differ in how they collect and disseminate information, they share a common structure called the GAS model of graph computation. The GAS model represents three conceptual phases of a vertex-program: Gather, Apply, and Scatter. The computation proceeds in iterations,</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Figure 2: Three variations on the Ideal functionality,  <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span> . Each is parameterized by  <span class="math">\\alpha, p</span> . The leftmost functionality is used in the histogram protocol described in Section 3. The middle definition is the one used in our implementation, and suffices for satisfying security according to Definition 5. The right-most adds differential privacy to out-degrees, which is needed in the disjoint collection model (i.e. when hiding the input sizes for all users, in Definition 6).</p>

    <p class="text-gray-300">and in each iteration, every node gathers (copy) data from their incoming edges, applies some simple computation to the data, and then scatters (copy) the result to their outgoing edges. Viewing each node as a CPU (or by assigning multiple nodes to each CPU), the apply step, which constitutes the bulk of the computational work, is easily parallelized.</p>

    <p class="text-gray-300">When performing such computations securely, the data is secret-shared between the computing servers as it moves from edge to node and back, as well as during the Apply phase. The Apply phase is performed on these secret shares using any protocol for secure computation as a black-box. The main challenge is to hide the movement of the data during the Gather and Scatter phases, as these memory accesses reveal substantial information about the user data.</p>

    <p class="text-gray-300">Take matrix factorization as an example: an edge  <span class="math">(\\mathsf{u},\\mathsf{v},\\mathsf{Data})</span>  indicates that user  <span class="math">\\mathsf{u}</span>  reviewed item  <span class="math">\\mathsf{v}</span> , and the data stored on the edge indicates the value of the user's review. Because the data is secret shared, the value of the review is never revealed. During the Gather phase, the right vertex of every edge is opened, and the data is moved to the corresponding vertex. After the Apply phase, the left</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Figure 3: Ideal functionality for a single iteration of the GAS model operations</p>

    <p class="text-gray-300">vertex of every edge is open, and data is pulled back to the edge. If this data movement were performed in the clear, the memory access pattern would reveal the edges between nodes, exactly revealing which users reviewed which items. Our first observation is that, because we touch only the right node of every edge during the gather, and only the left node of every edge during the scatter, by adding an oblivious shuffle of the edges between these two phases, we can hide the connection between neighboring nodes. The leakage of the computation is then reduced to two histograms: the in-degrees of each node, and, after the shuffle, the out-degrees of each node!</p>

    <p class="text-gray-300">Histograms are the canonical problem in differential privacy; we preserve privacy by adding noise to these two histograms, just as we do in Section 3. Details follow below, the formal protocol specification appears in Figure 4, and the ideal functionality for the PowerGraph framework appears in Figure 3.</p>

    <p class="text-gray-300">We denote the data graph by  <span class="math">G = (V, E)</span> . The structure of each edge is comprised of  <span class="math">(\\mathsf{u}, \\mathsf{v}, \\mathsf{uData}, \\mathsf{vData}, \\mathsf{isReal})</span> , where isReal indicates if an edge is "real" or "dummy". Each vertex is represented as  <span class="math">(\\mathsf{x}, \\mathsf{xData})</span> . The  <span class="math">\\mathsf{xData}</span>  field is large enough to hold edge data from multiple adjacent edges. As in Section 3, our protocol is in a hybrid model where we assume we have access to three ideal functionalities:  <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span> ,  <span class="math">\\mathcal{F}_{\\mathsf{Shuffle}}</span> ,  <span class="math">\\mathcal{F}_{\\mathsf{func}}</span> . As compared to Section 3, here we have dropped an explicit specification of the permutation used in  <span class="math">\\mathcal{F}_{\\mathsf{Shuffle}}</span> .</p>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a> Figure 4: A protocol for two parties to compute a single iteration of the GAS model operation on secret-shared data. This protocol realizes the ideal functionality described in Figure 3.</p>

    <p class="text-gray-300">During the initialization phase, the  <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span>  functionality is used to generate secret-shares of the dummy edges. These are placed alongside the real edges, and are then repeatedly shuffled in with the real edges during the iterative phases. We describe  <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span>  in detail later in this section. Every call to  <span class="math">\\mathcal{F}_{\\mathsf{Shuffle}}</span>  uses a new random permutation. (Since the dummy flags are now included inside the edge structure, we no longer need to specify that they are shuffled using the same permutation as the data elements.)</p>

    <p class="text-gray-300">Both the Gather and Scatter phases begin with calls to  <span class="math">\\mathcal{F}_{\\mathrm{Shuffle}}</span> , which takes</p>

    <p class="text-gray-300">secret shares of the edge data from each party, and outputs fresh shares of the randomly permuted data. In practice we implement this using two sequential, generic secure computations of the Waksman permutation network [1], where each party randomly chooses one of the two permutations. Then, the parties iterate through the shuffled edge set, opening one side of each edge to reveal the neighboring vertex. Opening these vertices in the clear is where we leak information, and gain in efficiency. As we mentioned previously, this reveals a noisy histogram of the node degrees. In doing so, the parties can fetch the appropriate vertex from memory, without performing expensive oblivious sort operations, as in GraphSC, and without resorting to ORAM. After fetching the appropriate node, the secret shared data is copied to/from the adjacent edge.</p>

    <p class="text-gray-300">During Apply, the parties make a call to an ideal functionality, <span class="math">\\mathcal{F}_{\\textsf{func}}</span>. This functionality takes secret shares of all vertices, reconstructs the data from the shares, applies the specified function to the real data at each vertex (while ignoring data from dummy edges), and returns fresh secret shares of the aggregated vertex data. In our implementation, we realize this ideal functionality using garbled circuits. We don't focus on the details here, as they have been described elsewhere (e.g. [28; 29]).</p>

    <p class="text-gray-300">DumGen_{p,α} in detail: The ideal functionality for <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span> appears in Figure 2 The role of <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span> is to generate the dummy elements that create a “noisy” degree profile, <span class="math">\\widehat{\\mathcal{D}}</span>. Starting with in-degree profile <span class="math">\\mathcal{D}=\\mathsf{D}_{\\mathsf{in}}(G)</span>, for each <span class="math">i\\in V</span>, <span class="math">\\widehat{\\mathcal{D}}(i)=\\mathcal{D}(i)+\\gamma_{i}</span>, where each <span class="math">\\gamma_{i}</span> is drawn independently from a shifted geometric distribution, parameterized by a “stopping” probability <span class="math">p</span>, and “shift” of <span class="math">\\alpha</span>: we denote the distribution by <span class="math">\\mathfrak{D}_{p,\\alpha}</span>, and define it more precisely below. The shift ensures that negative values are negligible likely to occur. This is necessary because the noisy set determines our access pattern to memory, and we cannot accommodate a negative number of accesses (or, more accurately, we do not want to omit any accesses needed for the real data). More specifically, we will define below a “shift function” <span class="math">\\alpha:\\mathbb{R}\\times\\mathbb{R}\\to\\mathbb{N}</span> that maps every <span class="math">(\\epsilon,\\delta)</span> pair to a natural number. (When <span class="math">\\epsilon</span> and <span class="math">\\delta</span> are fixed, we will simply use <span class="math">\\alpha</span> to denote <span class="math">\\alpha(\\epsilon,\\delta)</span>.)</p>

    <p class="text-gray-300">The functionality iterates through each vertex identifier <span class="math">i\\in V</span>, sampling a random number <span class="math">\\gamma_{i}\\leftarrow\\mathfrak{D}_{p,\\alpha}</span>, and creating <span class="math">\\gamma_{i}</span> edges of the form <span class="math">(\\bot,i)</span>. The remainder of the array contains “blank” edges, <span class="math">(\\bot,\\bot)</span>, which can be tossed away as they are discovered later in the protocol, after the dummy edges have all been shuffled <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span> returns secret shares of the dummy edges, <span class="math">\\langle\\mathsf{DummyEdges}\\rangle</span>. The only difference between the functionality described in the middle column, and the one in the left portion of the figure (which was used in Section 3), is that our “types” are now node identifiers, and they are stored within edge structures. However, the reader should note that only the right node in each edge is assigned a dummy value, while the left nodes all remain <span class="math">\\bot</span>. This design choice is for efficiency, and comes at the cost of leaking the exact histogram</p>

    <p class="text-gray-300">defined by the out-degrees of the graph nodes when executing <span class="math">\\mathsf{Open(Edges_{i}.u)}</span> in the Scatter operation. As an example of how this impacts privacy, when computing gradient descent for matrix factorization, this reveals the number of reviews written by each user, while ensuring that the number of reviews received by each item remains differentially private. This hides whether any given user reviewed any specific item, which suffices for achieving security with known input sizes, as defined in Definition 5. This is the protocol that we use in our implementation, but we briefly discuss what is needed to achieve Definition 6 below.</p>

    <p class="text-gray-300">In some computations, the graph is known to be bipartite, with all edges starting in the left vertex set and ending in the right vertex set (again, recommendation systems are a natural example). In this case, since it is known that all nodes in the left vertex set have in-degree 0, we do not need to add dummy edges containing these nodes. This cuts down on the number of dummies required, and we take advantage of this when implementing matrix factorization.</p>

    <p class="text-gray-300">Implementing <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span>: Intuitively, we sample <span class="math">\\gamma_{i}</span> by flipping a biased coin <span class="math">p</span> until it comes up heads. We flip one more unbiased coin to determine the sign of the noise, and then add the result to <span class="math">\\alpha</span>. We will determine <span class="math">p</span> based on <span class="math">\\epsilon</span> and <span class="math">\\delta</span>. Formally, <span class="math">\\gamma_{i}</span> is sampled as follows:</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\gamma_{i}=\\alpha]=\\frac{p}{2}</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\forall k\\in\\mathbb{N},k\\neq 0:\\Pr[\\gamma_{i}=\\alpha+k]=\\frac{1}{2}(1-\\frac{p}{2})p(1-p)^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">k</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-1}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">As just previously described, we view <span class="math">p</span> as the stopping probability. However, in the first coin flip, we stop with probability <span class="math">p/2</span>. We note that this is a slight modification to the normalized 2-sided geometric distribution, which would typically be written as $\\Pr[\\gamma_{i}=\\alpha+k]=\\frac{1}{2-p}p(1-p)^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">k</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">. The advantage of the distribution as it is written above is that it is very easy to sample in a garbled circuit, so long as </span>p<span class="math"> is an inverse power of 2; normalizing by </span>\\frac{1}{2-p}<span class="math"> introduces problems of finite precision and greatly complicates the sampling circuit. We note that Dwork et al. <em>[12]</em> suggest using the geometric distribution with </span>p=2^{\\ell}$, precisely because it is easy to sample in a garbled circuit. However, they describe a 1-sided geometric distribution, which is not immediately useful for preserving differential privacy, and did not seem to consider that, after normalizing, the 2-sided distribution cannot be sampled as cleanly. A security analysis of our mechanism, including concrete settings of the parameters, appears in Section 4.1.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We note that with some probability that is dependent on the choice of <span class="math">\\alpha</span>, <span class="math">\\exists i\\in V</span> s.t. <span class="math">\\widetilde{\\mathcal{D}}(i)&lt;0</span>, which leaves us with a bad representation of a multiset. We therefore modify the definition of <span class="math">\\mathcal{F}</span> to output <span class="math">\\emptyset</span> whenever this occurs, and we always choose <span class="math">\\alpha</span> so that this occurs with probability bound by <span class="math">\\delta</span>. In our implementation, we set <span class="math">\\delta=2^{-40}</span>.</p>

    <p class="text-gray-300">To securely sample <span class="math">\\mathfrak{D}_{p,\\alpha}</span>, each party inputs a random string, and we let the XOR of these strings define the random tape for flipping the biased coins.</p>

    <p class="text-gray-300">If the first <span class="math">\\ell</span> bits of the random tape are <span class="math">1</span>, the first coin is set to heads, and otherwise it set to tails: this is computed with a single <span class="math">\\ell</span>-input AND gate. We iterate through the random tape, <span class="math">\\ell</span> bits at a time, determining the value of each coin, and setting the dummy elements appropriately. We use one bit from the random tape to determine the sign of our coin flips, and we add <span class="math">\\alpha</span> dummies to the result. Recall that the output length is fixed, regardless of this random tape, so after we set the appropriate number of dummy items based on our coin flips, the remaining output values are set to <span class="math">\\bot</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The cost of this implementation of <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span> is <span class="math">O(V)</span>, though this hides a dependence on <span class="math">\\epsilon</span> and <span class="math">\\delta</span>: an exact accounting for various values can be found in Section 6. This cost is small relative to the cost of the oblivious shuffle, but we did first consider a much simpler protocol for <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span> that is worth describing. Instead of performing a coin flip inside a secure computation, by choosing a different distribution, we can implement <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span> without any interaction at all! To do this, we have each party choose <span class="math">d</span> random values from $\\{1,\\ldots,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\}<span class="math">, and view them as additive shares (modulo </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">) of each dummy item. Note that this distribution is already one-sided, so we do not need to worry about </span>\\alpha<span class="math">, and it already has fixed length output, so we do not need to worry about padding the dummy array with </span>\\bot<span class="math"> values. Intuitively, this can be viewed as </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> correlated samples from the binomial distribution, where the bias of the coin is </span>1/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. Unfortunately, the binomial distribution performs far worse than the geometric distribution, and in concrete terms, for the same values of </span>\\epsilon<span class="math"> and </span>\\delta<span class="math">, this protocol resulted in 250X more dummy items. The savings from avoiding the secure computation of </span>\\mathsf{DumGen}_{p,\\alpha}$ were easily washed away by the cost of shuffling so many additional items.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-16" class="text-xl font-semibold mt-8">4.1 Proof of security</h3>

    <p class="text-gray-300">We begin by describing the leakage function <span class="math">\\mathcal{L}(G)</span>. Intuitively, we leak a noisy degree profile. As we mentioned previously, we analyze the simpler <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span> algorithm, and prove that the mechanism provides differential privacy for graphs that have neighboring in-degree profiles. Then, we proceed afterwards to show that this leakage function suffices for simulating the protocol, achieving security in the joint-collection model, corresponding to Definition 5. (Extending the proof to meet Definition 6 is not much harder to do: we would use the <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span> algorithm defined for the disjoint collection model, and prove that differential privacy holds for graphs that have neighboring full-degree profiles.)</p>

    <p class="text-gray-300">We remind the reader that we use the following distribution, <span class="math">\\mathfrak{D}_{p,\\alpha}</span> for sampling noise:</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\gamma_{i}=\\alpha]</span> <span class="math">=\\frac{p}{2}</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">\\forall k\\in\\mathbb{N},k\\neq 0:\\Pr[\\gamma_{i}=\\alpha+k]</span> $=\\frac{1}{2}(1-\\frac{p}{2})p(1-p)^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">k</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-1}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We define a randomized algorithm, <span class="math">\\mathcal{F}_{\\epsilon,\\delta}:\\ D\\to\\widehat{\\mathcal{D}}</span>, whose input and output are multi-sets over <span class="math">V</span>: $\\ \\forall i\\in\\{1,\\ldots,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\}<span class="math">, </span>\\widehat{\\mathcal{D}}(i)=\\mathcal{D}(i)+\\gamma_{i}<span class="math">, where </span>\\gamma_{i}\\leftarrow\\mathfrak{D}_{p,\\alpha}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Definition 7 The leakage function is</p>

    <p class="text-gray-300"><span class="math">\\mathcal{L}(G)=(\\mathcal{F}_{\\epsilon,\\delta}(\\mathsf{D}_{\\mathsf{in}}(G)),\\mathsf{D}_{\\mathsf{out}}G)</span> where <span class="math">\\mathsf{D}_{\\mathsf{in}}(G)</span> denotes the in-degree profile of graph <span class="math">G</span>, and <span class="math">\\mathsf{D}_{\\mathsf{out}}(G)</span> denotes the out-degree profile.</p>

    <p class="text-gray-300">Theorem 1 The randomized algorithm <span class="math">\\mathcal{L}</span> is <span class="math">(\\epsilon,\\delta)</span>-approximate differentially private, as defined in Definition 4.</p>

    <p class="text-gray-300">We note that <span class="math">\\mathsf{D}_{\\mathsf{out}}(G)</span> can be modeled as auxiliary information about <span class="math">\\mathsf{D}_{\\mathsf{in}}(G)</span>, so the proof that <span class="math">\\mathcal{L}</span> preserves differential privacy follows from the fact that the algorithm <span class="math">\\mathcal{F}_{\\epsilon,\\delta}</span> is differentially private for graphs with neighboring in-degree profiles. It is well known that similar noise mechanisms preserve differential privacy, but, for completeness, we prove it below for our modified distribution, which is much simpler to execute in a garbled circuit.</p>

    <p class="text-gray-300">Proof: To simplify notation, we use <span class="math">\\mathcal{F}</span> to denote <span class="math">\\mathcal{F}_{\\epsilon,\\delta}</span>. Consider any two neighboring graphs, and let <span class="math">D_{1},D_{2}</span> denote their neighboring in-degree profiles. Let <span class="math">\\mathcal{F}_{R}</span> denote the range of <span class="math">\\mathcal{F}</span>, and let <span class="math">\\widehat{\\mathcal{D}}</span> be a multi-set in <span class="math">\\mathcal{F}_{R}</span>. We say that <span class="math">\\widehat{\\mathcal{D}}\\in\\mathsf{Bad}</span> if <span class="math">\\exists i\\in\\{1,\\ldots,V\\},\\widehat{\\mathcal{D}}(i)&lt;0</span>, and assume for now that <span class="math">\\widehat{\\mathcal{D}}\\notin\\mathsf{Bad}</span>. Let <span class="math">\\widehat{\\mathcal{D}}_{1}=\\mathcal{F}(D_{1})</span>, let <span class="math">\\widehat{\\mathcal{D}}_{2}=\\mathcal{F}(D_{2})</span>, and (without loss of generality) let <span class="math">i</span> be the value for which <span class="math">D_{1}(i)=D_{2}(i)+1</span>. By the definition of <span class="math">\\mathcal{F}</span>, for <span class="math">j\\neq i</span>, <span class="math">\\Pr[\\widehat{\\mathcal{D}}_{1}(j)=\\widehat{\\mathcal{D}}(j)]=\\Pr[\\widehat{\\mathcal{D}}_{2}(j)=\\widehat{\\mathcal{D}}(j)]</span>. Furthermore, for <span class="math">k\\neq j,k\\neq i</span>, <span class="math">b\\in\\{1,2\\}</span>, <span class="math">\\widehat{\\mathcal{D}}_{b}(k)</span> and <span class="math">\\widehat{\\mathcal{D}}_{b}(j)</span> are sampled independently. Therefore,</p>

    <p class="text-gray-300"><span class="math">\\frac{\\Pr[\\widehat{\\mathcal{D}}_{1}=\\widehat{\\mathcal{D}}]}{\\Pr[\\widehat{\\mathcal{D}}_{2}=\\widehat{\\mathcal{D}}]}=\\frac{\\Pr[\\widehat{\\mathcal{D}}_{1}(i)=\\widehat{\\mathcal{D}}(i)]}{\\Pr[\\widehat{\\mathcal{D}}_{2}(i)=\\widehat{\\mathcal{D}}(i)]}\\leq\\frac{1}{(1-p)}</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(Note that the case $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\widehat{\\mathcal{D}}(i)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\widehat{\\mathcal{D}}_{1}(i)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> – i.e. where there is no noise of type </span>i<span class="math"> added to the first dataset – </span>\\frac{\\Pr[\\widehat{\\mathcal{D}}_{1}=\\widehat{\\mathcal{D}}]}{\\Pr[\\widehat{\\mathcal{D}}_{2}=\\widehat{\\mathcal{D}}]}\\leq\\frac{1}{1-p/2}<\\frac{1}{1-p}<span class="math">.) By choosing </span>1-p=e^{-\\epsilon}<span class="math">, we achieve the desired bound. Then, for any </span>T_{\\mathsf{g}}\\subseteq\\mathcal{F}_{R}\\setminus\\mathsf{Bad}$,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\Pr[\\mathcal{F}(D_{1})\\in T_{\\mathsf{g}}]</span> <span class="math">=</span> <span class="math">\\sum_{D\\in T_{\\mathsf{g}}}\\Pr[\\mathcal{F}(D_{1})=D]</span> <span class="math">\\leq</span> <span class="math">\\sum_{D\\in T_{\\mathsf{g}}}e^{\\epsilon}\\Pr[\\mathcal{F}(D_{2})=D]</span> <span class="math">=</span> <span class="math">e^{\\epsilon}\\Pr[\\mathcal{F}(D_{2})\\in T_{\\mathsf{g}}]</span></p>

    <p class="text-gray-300">We now consider the probability that <span class="math">\\mathcal{F}(D)\\in\\mathsf{Bad}</span>. Recall, this is exactly the probability that for some <span class="math">i\\in V</span>, <span class="math">\\gamma_{i}&lt;0</span>, which grows as a negligible function in <span class="math">\\alpha</span>. We choose <span class="math">\\alpha</span> such that this probability is <span class="math">\\delta</span>. (We will derive the exact function below, and demonstrate some sample parameters.) Then, for any <span class="math">T\\subseteq\\mathcal{F}_{R}</span>, letting <span class="math">T_{\\mathsf{g}}=T\\setminus\\mathsf{Bad}</span>,</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mathcal{F}(D_{1})\\in T]</span> <span class="math">=</span> <span class="math">\\Pr[\\mathcal{F}(D_{1})\\in T_{\\mathsf{g}}]+\\Pr[\\mathcal{F}(D_{1})\\in\\mathsf{Bad}]</span> <span class="math">\\leq</span> <span class="math">e^{\\epsilon}\\Pr[\\mathcal{F}(D_{2})\\in T_{\\mathsf{g}}]+\\delta</span> <span class="math">\\leq</span> <span class="math">e^{\\epsilon}\\Pr[\\mathcal{F}(D_{2})\\in T]+\\delta</span></p>

    <p class="text-gray-300">Setting the parameters Note that the sensitivity of the distance metric defined in Definition 1 is 1. Although our proof here is for neighboring graphs, we can use standard composition theorems to claim differential privacy for graphs of distance <span class="math">d</span>, at the cost of scaling <span class="math">\\epsilon</span> by a factor of <span class="math">d</span>. We also note that <span class="math">e^{\\epsilon}=1/(1-p)</span>, where <span class="math">p</span> is the stopping probability defined in our noise distribution.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We set <span class="math">\\delta=2^{-40}</span>, and show how to calculate <span class="math">\\alpha</span>; this allows us to give the expected size of <span class="math">\\widehat{\\mathcal{D}}</span> as a function of <span class="math">\\epsilon</span> and <span class="math">\\delta</span>. We first fix some <span class="math">i\\in V</span> and calculate <span class="math">\\Pr[\\gamma_{i}&lt;0]</span>, and then we take a union bound over $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\Pr[\\gamma_{i}&lt;0]</span> <span class="math">=</span> <span class="math">\\sum_{k=\\alpha+1}^{\\infty}\\frac{1}{2}(1-\\frac{p}{2})p(1-p)^{k-1}</span> <span class="math">=</span> <span class="math">\\frac{p}{2}(1-\\frac{p}{2})\\sum_{k=0}^{\\infty}(1-p)^{\\alpha}(1-p)^{k}</span> <span class="math">=</span> <span class="math">\\frac{p}{2}(1-\\frac{p}{2})(1-p)^{\\alpha}\\frac{1}{1-(1-p)}</span> <span class="math">=</span> <span class="math">\\frac{1}{2}(1-\\frac{p}{2})(1-p)^{\\alpha}</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">After taking a union bound over $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, we have </span>\\Pr[\\mathcal{F}(D)\\in\\mathsf{Bad}]\\leq 2^{-40}<span class="math"> when </span>\\alpha>\\frac{-40-\\log(\\frac{1}{2}-\\frac{p}{4})-\\log(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)}{\\log(1-p)}<span class="math">. Recall that </span>(1-p)=e^{-\\epsilon}<span class="math">. So, as an example, setting </span>\\epsilon=.3<span class="math"> and </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=2^{12}<span class="math">, we have </span>\\alpha=118<span class="math">, and </span>\\mathbb{E}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{F}(D)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)=118</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">D</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$. That is, for these privacy parameters, we expect to add 118 dummy edges for each node in the graph.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-17" class="text-base font-medium mt-4">Theorem 2</h6>

    <p class="text-gray-300">The protocol <span class="math">\\pi_{\\mathsf{g}as}</span> defined in Figure 4 securely computes <span class="math">\\mathcal{F}_{\\mathsf{gas}}</span> with <span class="math">\\mathcal{L}</span> leakage in the <span class="math">(\\mathcal{F}_{\\mathsf{func}},\\mathcal{F}_{\\mathsf{Shuffle}},\\mathsf{DumGen}_{p,\\alpha})</span>-hybrid model according to Definition 5 (respectively Definition 6) when using the second (resp. third) variant of <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span>.</p>

    <p class="text-gray-300">Proof: <em>(</em>sketch.) We only prove the first Theorem statement, and omit the proof that we can meet the stronger security definition. At the end of this section, we give some intuition for what would change in such a proof.</p>

    <p class="text-gray-300">Recall that the leakage functionality contains</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">(\\mathcal{F}(\\mathcal{DB}_{R}),\\mathsf{out\\mathchar 45\\relax deg}(V))</span>. In particular, then, we assume that <span class="math">\\mathsf{out\\mathchar 45\\relax deg}(V)</span> is public knowledge and given to the simulator, which holds in the joint collection model of Definition 5. Note that $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> and </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> are both determined by </span>\\mathsf{out\\mathchar 45\\relax deg}(V)$, and these values will be used by the simulator as well.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We construct a simulator for a semi-honest <span class="math">P_{1}</span>. For all three ideal functionalities, the output is simply an XOR secret sharing of some computed value. The output of all calls to these functionalities can be perfectly simulated using random binary strings of the appropriate length. Let <span class="math">\\mathsf{simEdges}_{1}</span> denote the random string used to simulate the output of <span class="math">\\mathcal{F}_{\\mathsf{Shuffle}}</span> the first time the functionality</p>

    <p class="text-gray-300">is called, and let <span class="math">\\mathsf{simEdges}_{2}</span> denote the random string used to simulate the output on the second call. Let <span class="math">\\mathsf{simEdges}_{1}.u</span> denote the restriction of <span class="math">\\mathsf{simEdges}_{1}</span> to the bits that make up the sharings of <span class="math">\\mathsf{Edges}.u</span>, and let <span class="math">\\mathsf{simEdges}_{2}.v</span> be defined similarly.</p>

    <p class="text-gray-300">There are only two remaining messages to simulate:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">\\mathsf{Open(edge.u)}</span>, and <span class="math">\\mathsf{Open(edge.v)}</span>. Recall that there are $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+2\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> edges in the </span>\\mathsf{Edges}<span class="math"> array: the original </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> real edges, and the </span>2\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> dummy edges generated in </span>\\mathsf{DumGen}_{p,\\alpha}<span class="math">. To simulate the message sent when opening </span>\\mathsf{Edges}.u<span class="math">, the simulator uses the values </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> and </span>\\mathsf{out\\mathchar 45\\relax deg}(V)<span class="math"> to create a bit string representing a random shuffling of the following array of size </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+2\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. For each </span>u\\in V<span class="math">, the array contains the identifier of </span>u<span class="math"> exactly </span>\\mathsf{out\\mathchar 45\\relax deg}(u)<span class="math"> times. This accounts for </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\sum_{u}\\mathsf{out\\mathchar 45\\relax deg}(u)<span class="math"> positions of the array; the remaining </span>2\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> positions are set to </span>\\bot<span class="math">, consistent with the left nodes output by </span>\\mathsf{DumGen}_{p,\\alpha}<span class="math">. Letting </span>r<span class="math"> denote the resulting bit-string, the simulator sends </span>r\\oplus\\mathsf{simEdges}_{1}.u$ to the adversary.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">To simulate <span class="math">\\mathsf{simEdges}_{2}.v</span>, the simulator creates another bit-string representing a random shuffling of the following array, again of size $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+2\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. Letting </span>\\widetilde{\\mathcal{D}}=\\mathcal{F}(\\mathcal{DB}_{R})<span class="math"> denote the first element output by the leakage </span>\\mathcal{L}<span class="math">, the simulator adds the node identifiers in </span>\\widetilde{\\mathcal{D}}<span class="math"> to the array. In the remaining </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+2\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\widetilde{\\mathcal{D}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> positions of the array, he adds </span>\\bot<span class="math">. Letting </span>r<span class="math"> denote the resulting bit-string, the simulator sends </span>r\\oplus\\mathsf{simEdges}_{2}.v$ to the adversary.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">So far, this results in a perfect simulation of the adversary’s view. However, note that the outputs of the two parties should be correlated. To ensure that the joint distribution over the adversary’s view and the honest party’s output is correct, the simulator has to submit the adversary’s input, <span class="math">\\langle\\mathsf{Vertices}\\rangle</span>, to the trusted party. He receives back a new sharing of <span class="math">\\mathsf{Vertices}</span>, and has to “plant” this value in his simulation. Specifically, in the final iteration of the protocol, when simulating the output of <span class="math">\\mathcal{F}_{\\mathsf{func}}</span> for the last time, the simulator uses <span class="math">\\langle\\mathsf{Vertices}\\rangle</span>, as received from the trusted party, as the simulated output of this function call. ∎</p>

    <h4 id="sec-18" class="text-lg font-semibold mt-6">Hiding the out-degree of each node.</h4>

    <p class="text-gray-300">We include another variant of <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span> on the right side of Figure 2. In that variant, separate noise is added to the left node of each edge as well as to the right, which provides security according to Definition 6. We do not implement or analyze the security of this variant. Intuitively, though, for a graph <span class="math">G=(E,V)</span>, it is helpful to think of the edge set as defining two databases of elements over <span class="math">V</span>: for each (directed) edge <span class="math">(u,v)</span>, we will view <span class="math">u</span> as an element in database <span class="math">E_{L}</span> and <span class="math">v</span> as an element in database <span class="math">E_{R}</span>. Because the oblivious shuffle hides the edges between these two databases, the access pattern can be fully simulated from two noisy histograms (one for each database). This doubles the “sensitivity” of the “query”, and, because differential privacy composes, the added noisy information has the affect of cutting <span class="math">\\epsilon</span> in half. Since our analysis includes multiple values of <span class="math">\\epsilon</span>, the reader can easily extrapolate to get a sense of how we perform under our stronger security notion.</p>

    <h4 id="sec-19" class="text-lg font-semibold mt-6">Hiding a user’s full edge set.</h4>

    <p class="text-gray-300">The leakage function described above provide edge privacy to each contributing party. That is, we have defined two databases</p>

    <p class="text-gray-300">to be neighboring when they differ in a single edge. To understand the distinction, consider the application of building a movie recommendation system through matrix factorization. If we guarantee edge privacy, then nobody can learn whether a particular user reviewed a particular movie, but we cannot rule out the possibility that an adversary could learn something about the <em>set</em> of movies they have reviewed, perhaps, say, the genre that they enjoy. We could also define two neighboring databases as differing in a single node. Using the same example, this would guarantee that nothing can be learned about any individual user’s reviews, at all. It would require more noise: if the maximum degree of any node is <span class="math">d</span>, ensuring node privacy would have the affect of scaling <span class="math">\\epsilon</span> by <span class="math">d</span>. In our experiments, we have included some smaller values of <span class="math">\\epsilon</span> to help the reader evaluate how this additional noise would impact performance. However, we note that if the maximum degree in the graph is large, achieving node privacy might be difficult. We defer investigating other possible notions of neighboring graphs to future work.</p>

    <p class="text-gray-300">Sequential composition. The standard security definition for secure computation composes sequentially, allowing the servers to perform repeated computations on the same data without impacting security. With our relaxation, if we later use the same user data in a new computation, the leakage does compound. The standard composition theorems from the literature on differential privacy do apply, and we do not address here how privacy ought to be budgeted across multiple computations. The reader should note that in our iterative protocol, there is no additional leakage beyond the first iteration, because we do not regenerate the dummy items: the leakage in each iteration is the exactly the same noisy degree profile that was leaked in all prior iterations.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">## 5 Differentially Private Graph Computation with $O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$ complexity</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The construction in Section 4 requires $O((</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)\\log(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">))<span class="math"> garbled AND gates. In comparison, the implementation of Nayak et al. <em>[28]</em> uses </span>O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)\\log^{2}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> garbled gates. As we found in the previous section, </span>\\alpha=O(\\frac{\\log\\delta-\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{\\epsilon})<span class="math">. When </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=O(\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">, this amounts to an asymptotic improvement of </span>O(\\log(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">))<span class="math">. This improvement stems from our ability to replace several oblivious sorting circuits with oblivious shuffle circuits, which we are able to do only because of our security relaxation. However, while less practical, Nayak et al. could instead rely on an asymptotically better algorithm for oblivious sort, reducing their runtime to </span>O((</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)\\log(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">))<span class="math">. We therefore find it interesting to ask whether our security relaxation admits <em>asymptotic</em> improvement for this class of computations, in addition to the practical improvements described in the previous section. Indeed, we show that we can remove the need for an oblivious shuffle altogether by allowing one party to shuffle the data locally. As long as the party that knows the shuffling permutation does not see the access pattern to </span>V$ during the Scatter and Gather phases, the protocol</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">remains secure. The reason this protocol is less practical then the protocol of Section 4 is because <span class="math">\\mathcal{F}_{\\text{func}}</span> now has to perform decryption and encryption, which would require large garbled circuits.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The construction we present here requires $O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+ \\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> garbled AND gates, demonstrating asymptotic improvement over the best known construction for this class of computations, whenever </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= O(\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">. Figure 5 shows the formal description of the protocol. We assume that the two computation servers hold key pairs, </span>(\\mathsf{sk}_{\\text{Alice}}, \\mathsf{pk}_{\\text{Alice}})<span class="math"> and </span>(\\mathsf{sk}_{\\text{Bob}}, \\mathsf{pk}_{\\text{Bob}})<span class="math">. When data owners upload their data, they encrypt the data under Alice&#x27;s key, encrypt the resulting ciphertext under Bob&#x27;s key, and send the result to Bob (obviously this second encryption is unnecessary, but it simplifies the exposition to assume Bob receives the input in this form). Recall that edge data contains </span>(\\mathsf{u}, \\mathsf{v}, \\mathsf{uData}, \\mathsf{vData}, \\mathsf{isReal})<span class="math">, and vertex data contains </span>(\\mathsf{x}, \\mathsf{xData})<span class="math">. We assume each of these elements are encrypted independently, so that we can decrypt portions of edges when needed. We also assume that these encryption schemes are publicly re-randomizable: anyone can take an encryption of </span>x<span class="math"> under </span>\\mathsf{pk}<span class="math">, and re-randomize the ciphertext to give an encryption of </span>x<span class="math">, with fresh randomness, under the same </span>\\mathsf{pk}<span class="math">. We assume that re-randomized ciphertexts and &quot;fresh&quot; ciphertexts are equivalently distributed. Throughout this protocol, we use </span>\\llbracket x \\rrbracket_y<span class="math"> to denote the encryption of </span>x<span class="math"> using </span>y$'s public key.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The protocol follows the same outline as the one in Section 4, but here we separate the tasks of shuffling and data copying. Bob locally shuffles the edges, <span class="math">\\llbracket \\llbracket \\text{Edges} \\rrbracket_{\\text{Alice}} \\rrbracket_{\\text{Bob}}</span> according to a permutation of his choice. He sends the encrypted, shuffled arrays to Alice. For each edge, he also partially decrypts the node identifier for the right node, recovering <span class="math">\\llbracket \\text{Edges.v} \\rrbracket_{\\text{Alice}}</span>. He re-randomizes the resulting ciphertext, and sends it to Alice. Alice can now find the right vertex of every edge. She executes the Gather operation locally by performing a linear scan over the edge data, opening the right vertex of edge, and copying data from edge to vertex.</p>

    <p class="text-gray-300">The two parties then execute the Apply operation together, performing a linear scan over the vertices, and calling a two-party functionality at vertex. <span class="math">^{8}</span> Alice supplies the functionality, <span class="math">\\mathcal{F}_{\\text{func}}</span>, with the encrypted data at each vertex, and both parties provide their decryption key. The functionality decrypts, performs the Apply function to all real data, and re-encrypts. The updated, encrypted vertex data is output to Alice.</p>

    <p class="text-gray-300">Bob now reshuffles all the edges and dummy flags, just as before, re-randomizing Alice's ciphertexts. He sends</p>

    <p class="text-gray-300"><span class="math">\\llbracket \\llbracket \\text{Edges} \\rrbracket_{\\text{Alice}} \\rrbracket_{\\text{Bob}}</span> to Alice, who now performs the Scatter operation, as with Gather. That is, for each edge, she receives the re-randomized encryption of the left vertex id, <span class="math">\\llbracket \\text{Edges.u} \\rrbracket_{\\text{Alice}}</span>, recovers the vertex identifier, and copies the vertex data from <span class="math">\\mathsf{u}</span> back to the appropriate edge. She re-randomizes all ciphertexts, and sends the edge data back to Bob.</p>

    <p class="text-gray-300">7The data could instead be uploaded as in the previous section, and the servers could perform a linear scan on the data to encrypt it as described here. This wouldn't impact the asymptotic claim; we chose the simpler presentation.</p>

    <p class="text-gray-300">8As before, we can replace this functionality with a two-party computation.</p>

    <p class="text-gray-300">25</p>

    <p class="text-gray-300">The proof of security is not substantially different than in the previous section, so we only give an intuition here. Instead of using random strings to simulate secret shares, we now rely on the semantic security of the encryption scheme. When simulating Alice’s view, for each <span class="math">u\\in\\mathsf{Vertices}</span>, the leakage function is used to determine how many times the identifier for <span class="math">u</span> should be encrypted. The rest of the ciphertexts can be simulated with encryptions of 0 strings. The rest of the simulation is straightforward. When simulating Bob’s view, an interesting subtlety arises. Even though Bob does not get to see the access pattern to the vertices during the Gather and Scatter operations, he does in fact still learn <span class="math">\\mathcal{F}(\\mathcal{DB}_{R})</span>. This is because the instantiation of <span class="math">\\mathcal{F}_{\\mathsf{func}}</span> with a secure computation will leak the input size of Alice (assuming we use a generic two-party computation for realizing the functionality). This reveals the number of data items that were moved to that vertex during Gather. These input sizes can be exactly simulated using the leakage function.</p>

    <h2 id="sec-20" class="text-2xl font-bold">6 Implementation and Evaluation</h2>

    <p class="text-gray-300">In this section, we describe and evaluate the implementation of our proposed framework. We implement OblivGraph using FlexSC, a Java-based garbled circuit framework. We measure the performance of our framework on a set of benchmark algorithms in order to evaluate our design. These benchmarks consist of histogram, PageRank and matrix factorization problems which are commonly used for evaluating highly-parallelizable frameworks. In all scenarios, we assume that the data is secret-shared across two non-colluding cloud providers, as motivated in Section 1. For comparison, we compare our results with the closest large-scale secure parallel graph computation, called GraphSC <em>[28]</em>.</p>

    <h3 id="sec-21" class="text-xl font-semibold mt-8">6.1 Implementation</h3>

    <p class="text-gray-300">Using the OblivGraph framework, the histogram and matrix factorization problems can be represented as directed bipartite graphs, and PageRank as a directed non-bipartite graph. When we are computing on bipartite graphs, if we consider Definition 5 where we aim to hide the in-degree of the nodes (nodes on the left have in-degree 0), the growth rate of dummy edges is linear in the number of nodes on the right and it is independent of the real edges or users. If we consider the stronger Definition 6, the growth rate of dummy edges is linear with max(users, items).</p>

    <p class="text-gray-300"><em>Histogram:</em> In histogram, left vertices represent data elements, right vertices are the counters for each type of data element, and existence of an edge indicates that the data element on the left has the type on the right.</p>

    <p class="text-gray-300">Edge data is represented as  <span class="math">(\\mathsf{u},\\mathsf{v},\\mathsf{uData},\\mathsf{vData},\\mathsf{isReal})</span> , and vertex data is represented as  <span class="math">(\\mathsf{u},\\mathsf{uData})</span> . We assume that each server holds and encryption key pair,  <span class="math">(\\mathsf{sk}_{\\mathrm{Alice}},\\mathsf{pk}_{\\mathrm{Alice}})</span>  and  <span class="math">(\\mathsf{sk}_{\\mathrm{Bob}},\\mathsf{pk}_{\\mathrm{Bob}})</span> , and that the public keys are known to the data owners at the time the data is uploaded.</p>

    <p class="text-gray-300">Users encrypt their edge data under Alice's public key, then under Bob's public key, and upload the data to Bob:  <span class="math">\\llbracket \\llbracket \\text{RealEdges} \\rrbracket_{\\text{Alice}} \\rrbracket_{\\text{Bob}}</span> . (We assume that the 4 data elements in the edge are encrypted separately.)</p>

    <p class="text-gray-300">Dummy Generation: The parties call the ideal functionality for  <span class="math">\\mathsf{DumGen}_{p,\\alpha}</span> . The functionality is just as described in either the middle or right of Figure 2, except that we modify the format of the output. Instead of providing XOR shares of the output,  <span class="math">\\langle \\mathsf{DummyEdges} \\rangle</span> , the functionality is assumed to return a doubly encrypted array of dummy edges,  <span class="math">\\llbracket \\llbracket \\mathsf{DummyEdges} \\rrbracket_{\\mathsf{Alice}} \\rrbracket_{\\mathsf{Bob}}</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Shuffle: Bob randomly permutes the arrays  <span class="math">\\llbracket \\llbracket \\text{Edges} \\rrbracket_{\\text{Alice}} \\rrbracket_{\\text{Bob}}</span>  according to a single random permutation,  <span class="math">p</span> . He re-randomizes the (outer) ciphertexts and sends the encrypted arrays to Alice.</li>

      <li>Gather: For each edge in  <span class="math">\\llbracket \\llbracket \\text{Edges} \\rrbracket_{\\text{Alice}} \\rrbracket_{\\text{Bob}}</span> , Bob decrypts the outer ciphertext of the right vertex id, re-randomizes  <span class="math">\\llbracket \\text{Edges.v} \\rrbracket_{\\text{Alice}}</span> , and sends it to Alice. For each edge in  <span class="math">\\llbracket \\llbracket \\text{Edges} \\rrbracket_{\\text{Alice}} \\rrbracket_{\\text{Bob}}</span> , Alice recovers  <span class="math">\\text{Edges.v}</span>  and copies the encrypted edge data to vertex v.</li>

      <li>Apply: For each vertex, Alice and Bob query a modified  <span class="math">\\mathcal{F}_{\\mathrm{func}}</span>  functionality. Alice provides  <span class="math">\\llbracket \\llbracket \\text{Vertices.vData} \\rrbracket_{\\text{Alice}} \\rrbracket_{\\text{Bob}}</span> , and both parties provide their secret keys. Alice receives updated, re-encrypted vertex data as output, still denoted by  <span class="math">\\llbracket \\llbracket \\text{Vertices.vData} \\rrbracket_{\\text{Alice}} \\rrbracket_{\\text{Bob}}</span> .</li>

      <li>Shuffle: Bob executes the second shuffling operation by randomly permuting  <span class="math">\\llbracket \\llbracket \\text{Edges} \\rrbracket_{\\text{Alice}} \\rrbracket_{\\text{Bob}}</span>  according to a random permutation  <span class="math">p&#x27;</span> . He re-randomizes the (outer) ciphertexts, and sends the encrypted array to Alice.</li>

      <li>Scatter: For each edge in  <span class="math">\\llbracket \\llbracket \\text{Edges} \\rrbracket_{\\text{Alice}} \\rrbracket_{\\text{Bob}}</span> , Bob decrypts the outer ciphertext of the left vertex id, re-randomizes  <span class="math">\\llbracket \\text{Edges.u} \\rrbracket_{\\text{Alice}}</span> , and sends it to Alice. For each edge in  <span class="math">\\llbracket \\llbracket \\text{Edges} \\rrbracket_{\\text{Alice}} \\rrbracket_{\\text{Bob}}</span> , Alice recovers  <span class="math">\\text{Edges.u}</span>  and copies the encrypted vertex data at  <span class="math">u</span>  to the corresponding edge. She re-randomizes all ciphertexts, and sends  <span class="math">\\llbracket \\llbracket \\text{Edges} \\rrbracket_{\\text{Alice}} \\rrbracket_{\\text{Bob}}</span>  back to Bob.</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Figure 5: An  $O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$  protocol for OblivGraph.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Matrix Factorization: In matrix factorization, left vertices represent the users, right vertices are items (e.g. movies in movie recommendation systems), an edge indicates that a user ranked an item, and the weight of the edge represents the rating value.</p>

    <p class="text-gray-300">PageRank: In PageRank, each vertex corresponds to a webpage and each edge is a link between two webpages. The vertex data comprises of two real</p>

    <p class="text-gray-300">values, one for the PageRank of the vertex and the other for the number of its outgoing edges. Edge data is a real value corresponding to the weighted contribution of the source vertex to the PageRank of the sink vertex.</p>

    <p class="text-gray-300">Vertex and Edge representation: In all scenarios, vertices are identified using 16-bit integers and 1 bit is used to indicate if the edge is real or dummy. For Histograms, we use an additional 20 bits to represent the counter values. In PageRank, we represent the PageRank value using a 40-bit fixed-point representation, with 20-bits for the fractional part. In our matrix factorization experiments, we factorized the matrix to user and movie feature vectors; each vector has dimension 10, and each value is represented as 40-bit fixed-point number, with 20-bits for the fractional part. We chose these values to be consistent with GraphSC representation.</p>

    <p class="text-gray-300">System setting: We conduct experiments on both a lab testbed, and on a real-world scale Amazon AWS deployment. Our lab testbed comprises 8 virtual machines each with dedicated (reserved) hardware of 4 CPU cores (2.4 GHz) and 16 GB RAM. These VMs were deployed on a vSphere Cluster of 3 physical servers and they were interconnected with 1Gbps virtual interfaces. We run our experiments on <span class="math">p\\in\\{1,2,4,8,16,32\\}</span> pairs of these processors, where in each pair, one processor works as the garbler, and the other as the evaluator. Each processor can be implemented by a core in a multi-core VM, or can be a VM in our compute cluster.</p>

    <h3 id="sec-24" class="text-xl font-semibold mt-8">6.2 Evaluation</h3>

    <p class="text-gray-300">We use two metrics in evaluating the impact of our security relaxation: circuit complexity (e.g. # of AND gates), and runtime. Counting AND gates provides a “normalized” comparison with other frameworks, since circuit size is independent of the hardware configuration and of the chosen secure computation implementation. However, it is also nice to have a sense of concrete runtime, so we provide this evaluation as well. Of course, runtime is highly affected by the choice of hardware, and ours can be improved by using more processors or dedicated hardware (e.g. AES-NI).</p>

    <p class="text-gray-300">Evaluation setting: For the LAN setup, we use synthesized data and run all the benchmarks with the similar set of parameters that have been used in the GraphSC framework. In our histogram and matrix factorization experiments, we run the experiments for 2048 users and 128 items. The number of nodes in our PageRank experiment is set to be 2048.</p>

    <p class="text-gray-300">For real world experiment using AWS, we run matrix factorization using gradient descent on the real-world MovieLens dataset that contains 1 million ratings provided by 6040 users to 3883 movies <em>[17]</em> on 2 m4.16xlarge AWS instances on the Northern Virginia Data-center.</p>

    <p class="text-gray-300">Circuit Complexity: The results presented in Figures 6(a), 6(b) and 6(c) are for execution on a single processor, to show the performance of our design without leveraging the desired effect of parallelization.</p>

    <h5 id="sec-25" class="text-base font-semibold mt-4">Histogram</h5>

    <p class="text-gray-300">Figure 6(a) demonstrates the number of AND gates for computing histogram in both the GraphSC and OblivGraph frameworks. With 2048 data elements and 128 data types, we always do better than GraphSC when <span class="math">\\epsilon&gt;=0.3</span>. When <span class="math">\\epsilon=0.1</span>, we start outperforming GraphSC when there are at least 3400 edges.</p>

    <h5 id="sec-26" class="text-base font-semibold mt-4">Matrix Factorization</h5>

    <p class="text-gray-300">In Figure 6(b), we use the (batch) gradient decent method for generating the recommendation model, as in <em>[29, 28]</em>. With 2048 users, 128 items, and <span class="math">\\epsilon=0.3</span>, we outperform GraphSC once there are at least 15000 edges. When <span class="math">\\epsilon=0.1</span>, we start outperforming them on 54000 edges. We always do better than GraphSC when the <span class="math">\\epsilon=1</span> or higher.</p>

    <h5 id="sec-27" class="text-base font-semibold mt-4">PageRank</h5>

    <p class="text-gray-300">Figure 6(c) provides the result of running PageRank in our framework with 2048 nodes and different values of <span class="math">\\epsilon</span>. With <span class="math">\\epsilon=0.3</span>, we outperform GraphSC when the number of edges are about 400000, and with <span class="math">\\epsilon=1</span> we outperform them on just 130000 edges. In both cases, the graph is quite sparse, compared to a complete graph of 2 million edges. Note, though, that our comparison is slightly less favorable for this computation. Recall, the number of dummy edges grow with the number of nodes in the graph, and, when hiding only in-degree in a bipartite graph, this amounts to growing only with the number of nodes on the right. In contrast, the runtime of GraphSC grows equivalently with any increase in users, items, or edges, because their protocol hides any distinction between these data types. We therefore compare best with them when there are more users than items. When looking at a non-bipartite graph, such as PageRank, our protocol grows with any increase in the size of the singular set of nodes, just as theirs does. If we increase the number of items in matrix factorization to 2048, or decrease the number of nodes in PageRank to 128, the comparison to GraphSC in the resulting experiments would look similar. We let the reader extrapolate, and avoid the redundancy of adding such experiments.</p>

    <p class="text-gray-300">Large scale experiments on Amazon AWS: OblivGraph factorizes the MovieLens recommendation matrix consist of 1 million ratings provided by 6040 users to 3883 movies, in almost 2 hours while GraphSC does it in 13 hours. We provide results of computing matrix factorization problem for different values of <span class="math">\\epsilon</span> and different numbers of ratings in Table 2. We outperform the best result achieved by GraphSC, using 128 processors and 1M ratings.</p>

    <p class="text-gray-300">Effect of Parallelization: Figure 7 illustrates that the execution time can be significantly reduced through parallelization. We achieve nearly a linear speedup in the computation time. The lines corresponds to two different numbers of edges for 2048 users and 128 movies. Since in our these problems, the computation is the bottleneck, parallelization can significantly speed up the computation process. Table 1 shows the effect of parallelization in our framework as compared to GraphSC in terms of number of AND gates. As shown in the Table 1, adding more processors in the GraphSC framework increases the total number of AND Gates by some small amount. In contrast, the size of the circuit generated in our framework is constant in the number of processors: parallelization does not affect total number of AND gates in the OblivGraph GAS operations, or in DumGen.</p>

    <p class="text-gray-300">!<a href="img-3.jpeg">img-3.jpeg</a> (a) Histogram</p>

    <p class="text-gray-300">!<a href="img-4.jpeg">img-4.jpeg</a> (b) Matrix factorization</p>

    <p class="text-gray-300">!<a href="img-5.jpeg">img-5.jpeg</a> (c) PageRank Figure 6: Histogram and Matrix Factorization with 2048 users and 128 types, PageRank with 2048 webpages, with varying  <span class="math">\\epsilon</span></p>

    <p class="text-gray-300">!<a href="img-6.jpeg">img-6.jpeg</a> Figure 7: Effect of parallelization on Matrix Factorization computation time</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Processors</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">GraphSC [28]</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">OblivGraph</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">E</td>

            <td class="px-3 py-2 border-b border-gray-700">=8192</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">E</td>

            <td class="px-3 py-2 border-b border-gray-700">=24576</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">E</td>

            <td class="px-3 py-2 border-b border-gray-700">=8192</td>

            <td class="px-3 py-2 border-b border-gray-700">E</td>

            <td class="px-3 py-2 border-b border-gray-700">=24576</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">4.047E+09</td>

            <td class="px-3 py-2 border-b border-gray-700">1.035E+10</td>

            <td class="px-3 py-2 border-b border-gray-700">2.018E+09</td>

            <td class="px-3 py-2 border-b border-gray-700">4.480E+09</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

            <td class="px-3 py-2 border-b border-gray-700">4.055E+09</td>

            <td class="px-3 py-2 border-b border-gray-700">1.039E+10</td>

            <td class="px-3 py-2 border-b border-gray-700">2.018E+09</td>

            <td class="px-3 py-2 border-b border-gray-700">4.480E+09</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">4</td>

            <td class="px-3 py-2 border-b border-gray-700">4.070E+09</td>

            <td class="px-3 py-2 border-b border-gray-700">1.046E+10</td>

            <td class="px-3 py-2 border-b border-gray-700">2.018E+09</td>

            <td class="px-3 py-2 border-b border-gray-700">4.480E+09</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">8</td>

            <td class="px-3 py-2 border-b border-gray-700">4.092E+09</td>

            <td class="px-3 py-2 border-b border-gray-700">1.057E+10</td>

            <td class="px-3 py-2 border-b border-gray-700">2.018E+09</td>

            <td class="px-3 py-2 border-b border-gray-700">4.480E+09</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 1: Cost of Parallelization on OblivGraph vs. GraphSC in computing Matrix Factorization</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Optimization using Compaction: It is important to note that the measured circuit sizes in our OblivGraph experiments correspond to the worst-case scenario in which the number of dummy edges are equal to  $d = 2\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> , which is the maximum number of dummies per type. Consequently the time for OblivShuffle is its maximum value. However, looking at the geometric distribution used in the DumGen procedure, the expected number of dummy edges is  </span>\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ , so half of the dummy items are unnecessary. Removing these extra dummy items during DumGen is non-trivial, because, while it is safe to reveal the total number of dummy items in the system, revealing the number of dummy items of each type would violate differential privacy. After the first iteration of the computation, once the dummy items are shuffled in with the real items, an extra flag marking the excessive dummy items can be used to safely remove them from the system; this optimization can significantly reduce the shuffling time (roughly by half) in the following iterations. However, our graphs are showing only the first iteration of the algorithm and they do not reflect this simple optimization.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Comparison with a Cleartext Baseline GraphSC [28] compared their execution time with GraphLab [25], a state-of-the-art framework for running graph-parallel algorithms on clear text. They ran Matrix Factorization using gradient</p>

    <p class="text-gray-300">descent with input length of 32K in both frameworks and demonstrated that GraphSC is about 200K - 500K times slower than GraphLab when run on 2 to 16 processors. Considering our improvements over GraphSC, we estimate our secure computation to be about 16K-32K times slower than insecure baseline computation (GraphLab), running the same experiments.</p>

    <p class="text-gray-300">Oblivious Shuffle: We use an Oblivious Shuffle in our OblivGraph framework, which has a factor of  <span class="math">\\log (n)</span>  less overhead than the Bitonic sort used in GraphSC. We designed the Oblivious Shuffle operation based on the Waksman network [36]. The cost of shuffling is approximately  <span class="math">BW(n)</span>  using a Waksman network, where  <span class="math">W(n) = n\\log n - n + 1</span>  is the number of oblivious swaps required to permute  <span class="math">n</span>  input elements, and  <span class="math">B</span>  indicates the size of the elements being shuffled. In the original Waksman switching network, the size of the input,  <span class="math">n</span> , is assumed to be a power of two. However, in order to have an Oblivious Shuffle for arbitrary sized input, we must use an improved version of the Waksman network proposed in [1] which is called AS-Waksman (Arbitrary-Sized Waksman). In our current set of experiments, we have only implemented the original version of the Waksman network and have not implemented AS-Waksman. We interpolate precisely to determine the size of arbitrary AS-Waksman when using arbitrary sized input. Details of this appear in the full version of the paper.</p>

    <p class="text-gray-300">Cost of each operation in OblivGraph framework: In order to understand how expensive the DumGen and OblivShuffle procedures are, as compared to other GAS model operations, we show the number of AND gates for each of these procedures in Figure 8. The figure corresponds to Matrix Factorization problem, with 2048 users, 128 movies and 20K ratings, with epsilon 0.5. The cost of a single iteration in the OblivGraph framework is first dominated by the Apply operation which computes the gradient descent and second by Oblivious Shuffle. Figure shows the effect of parallelization on decreasing the circuit size of each operation. See the full version to compare the cost of DumGen procedure in different protocols.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">OblivGraph</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">GraphSC[28]</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">ε=0.3</td>

            <td class="px-3 py-2 border-b border-gray-700">ε=0.5</td>

            <td class="px-3 py-2 border-b border-gray-700">ε=1</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"># Real Edges</td>

            <td class="px-3 py-2 border-b border-gray-700">1.2M</td>

            <td class="px-3 py-2 border-b border-gray-700">1.5M</td>

            <td class="px-3 py-2 border-b border-gray-700">1.8M</td>

            <td class="px-3 py-2 border-b border-gray-700">1M</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Time(hours)</td>

            <td class="px-3 py-2 border-b border-gray-700">2.2</td>

            <td class="px-3 py-2 border-b border-gray-700">2.3</td>

            <td class="px-3 py-2 border-b border-gray-700">2.4</td>

            <td class="px-3 py-2 border-b border-gray-700">13</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 2: Runtime of a single iteration of OblivGraph vs. GraphSC to solve matrix factorization problem in scale, with real-world dataset, MovieLens with 6040 users ranked 3883 movies</p>

    <p class="text-gray-300">We have established a new tradeoff between privacy and efficiency in secure computation by defining a new security model in which the adversary is provided some leakage that is proven to preserve differential privacy. We show that</p>

    <p class="text-gray-300">!<a href="img-7.jpeg">img-7.jpeg</a> Figure 8: Cost of each operation in OblivGraph for Matrix Factorization</p>

    <p class="text-gray-300">this leakage allows us to construct a more efficient protocol for a broad class of computations: those that can be computed in graph-parallel frameworks such as MapReduce. We have evaluated the impact of our relaxation by comparing the performance of our protocol with the best prior implementation of secure computation for graph-parallel frameworks.</p>

    <p class="text-gray-300">Our work demonstrates that differentially private leakage is useful, in that it provides opportunity for more efficient protocols. The protocol we present has broad applicability, but we leave open the very interesting question of determining, more precisely, for which class of computations this leakage might be help. Graph-parallel algorithms have the property that the access pattern to memory can be easily reduced to revealing only a histogram of the memory that is accessed, and histograms are the canonical example in the differential privacy literature. Looking at other algorithms will likely introduce very interesting leakage functions that are new to the differential privacy literature, and security might not naturally follow from known mechanisms in that space.</p>

    <p class="text-gray-300">[1] B. Beauquier and É. Darrot. On arbitrary size waksman networks and their vulnerability. Parallel Processing Letters, 12(03n04):287-296, 2002. [2] R. Canetti. Security and composition of multiparty cryptographic protocols. Journal of Cryptology, 13(1):143-202, 2000. [3] D. Cash, P. Grubbs, J. Perry, and T. Ristenpart. Leakage-abuse attacks against searchable encryption. In ACM CCS 2015, pages 668-679, Oct. 2015.</p>

    <p class="text-gray-300">[4] D. Cash, J. Jaeger, S. Jarecki, C. S. Jutla, H. Krawczyk, M.-C. Rosu, and M. Steiner. Dynamic searchable encryption in very-large databases: Data structures and implementation. In NDSS 2014. The Internet Society, Feb. 2014.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[5] D. Cash, S. Jarecki, C. S. Jutla, H. Krawczyk, M.-C. Rosu, and M. Steiner. Highly-scalable searchable symmetric encryption with support for Boolean queries. In Crypto 2013, Part I, volume 8042 of LNCS, pages 353–373, Aug. 2013.</li>

      <li>[6] T.-H. H. Chan, K.-M. Chung, B. Maggs, and E. Shi. Foundations of differentially oblivious algorithms. Cryptology ePrint Archive, Report 2017/1033, 2017. https://eprint.iacr.org/2017/1033.</li>

      <li>[7] T.-H. H. Chan, K.-M. Chung, and E. Shi. On the depth of oblivious parallel RAM. In ASIACRYPT 2017, Part I, LNCS, pages 567–597, Dec. 2017.</li>

      <li>[8] I. Damgård, V. Pastro, N. P. Smart, and S. Zakarias. Multiparty computation from somewhat homomorphic encryption. In Crypto 2012, volume 7417 of LNCS, pages 643–662, Aug. 2012.</li>

      <li>[9] J. Dean and S. Ghemawat. Mapreduce: Simplified data processing on large clusters. In Proceedings of the 6th Conference on Symposium on Opearting Systems Design & Implementation - Volume 6, OSDI’04, pages 10–10, Berkeley, CA, USA, 2004. USENIX Association.</li>

      <li>[10] T. T. A. Dinh, P. Saxena, E.-C. Chang, B. C. Ooi, and C. Zhang. M2r: Enabling stronger privacy in mapreduce computation. In 24th USENIX Security Symposium (USENIX Security 15), pages 447–462, Washington, D.C., 2015. USENIX Association.</li>

      <li>[11] F. B. Durak, T. M. DuBuisson, and D. Cash. What else is revealed by order-revealing encryption? In ACM CCS 2016, pages 1155–1166, Oct. 2016.</li>

      <li>[12] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor. Our data, ourselves: Privacy via distributed noise generation. In Eurocrypt 2006, volume 4004 of LNCS, pages 486–503, May / June 2006.</li>

      <li>[13] C. Dwork and A. Roth. The algorithmic foundations of differential privacy. Foundations and Trends in Theoretical Computer Science, 9(3-4):211–407, 2014.</li>

      <li>[14] Ú. Erlingsson, V. Pihur, and A. Korolova. RAPPOR: Randomized aggregatable privacy-preserving ordinal response. In ACM CCS 2014, pages 1054–1067, Nov. 2014.</li>

      <li>[15] J. E. Gonzalez, Y. Low, H. Gu, D. Bickson, and C. Guestrin. Powergraph: Distributed graph-parallel computation on natural graphs. In Presented as part of the 10th USENIX Symposium on Operating Systems Design and Implementation (OSDI 12), pages 17–30, Hollywood, CA, 2012. USENIX.</li>

    </ul>

    <p class="text-gray-300">[16] S. D. Gordon, J. Katz, V. Kolesnikov, F. Krell, T. Malkin, M. Raykova, and Y. Vahlis. Secure two-party computation in sublinear (amortized) time. In ACM CCS 2012, pages 513–524, 2012.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[17] F. M. Harper and J. A. Konstan. The movielens datasets: History and context. ACM Trans. Interact. Intell. Syst., 5(4):19:1–19:19, Dec. 2015.</li>

      <li>[18] X. He, A. Machanavajjhala, C. J. Flynn, and D. Srivastava. Composing differential privacy and secure computation: A case study on scaling private record linkage. In ACM CCS 2017, pages 1389–1406, 2017.</li>

      <li>[19] M. S. Islam, M. Kuzu, and M. Kantarcioglu. Access pattern disclosure on searchable encryption: Ramification, attack and mitigation. In NDSS 2012. The Internet Society, Feb. 2012.</li>

      <li>[20] S. Kamara and T. Moataz. Boolean searchable symmetric encryption with worst-case sub-linear complexity. In J. Coron and J. B. Nielsen, editors, Advances in Cryptology - EUROCRYPT 2017 - 36th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Paris, France, April 30 - May 4, 2017, Proceedings, Part III, volume 10212 of Lecture Notes in Computer Science, pages 94–124, 2017.</li>

      <li>[21] G. Kellaris, G. Kollios, K. Nissim, and A. O’Neill. Generic attacks on secure outsourced databases. In ACM CCS 2016, pages 1329–1340, Oct. 2016.</li>

      <li>[22] G. Kellaris, G. Kollios, K. Nissim, and A. O’Neill. Accessing data while preserving privacy. https://www.youtube.com/watch?v=u9LIU4Frce8, 2017. Communication with the authors.</li>

      <li>[23] B. Kreuter. Secure multiparty computation at google. https://www.youtube.com/watch?v=ee7oRsDnNNc, 2017. Real World Crypto.</li>

      <li>[24] C. Liu, X. S. Wang, K. Nayak, Y. Huang, and E. Shi. ObliVM: A programming framework for secure computation. In 2015 IEEE Symposium on Security & Privacy, pages 359–376, 2015.</li>

      <li>[25] Y. Low, J. E. Gonzalez, A. Kyrola, D. Bickson, C. Guestrin, and J. M. Hellerstein. Graphlab: A new framework for parallel machine learning. CoRR, abs/1408.2041, 2014.</li>

      <li>[26] G. Malewicz, M. H. Austern, A. J. Bik, J. C. Dehnert, I. Horn, N. Leiser, and G. Czajkowski. Pregel: A system for large-scale graph processing. In Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data, SIGMOD ’10, pages 135–146, New York, NY, USA, 2010. ACM.</li>

      <li>[27] M. Naveed, S. Kamara, and C. V. Wright. Inference attacks on property-preserving encrypted databases. In ACM CCS 2015, pages 644–655, Oct. 2015.</li>

    </ul>

    <p class="text-gray-300">[28] K. Nayak, X. S. Wang, S. Ioannidis, U. Weinsberg, N. Taft, and E. Shi. GraphSC: Parallel secure computation made easy. In 2015 IEEE Symposium on Security & Privacy, pages 377–394, May 2015.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[29] V. Nikolaenko, S. Ioannidis, U. Weinsberg, M. Joye, N. Taft, and D. Boneh. Privacy-preserving matrix factorization. In ACM CCS 2013, pages 801–812, Nov. 2013.</li>

      <li>[30] O. Ohrimenko, M. Costa, C. Fournet, C. Gkantsidis, M. Kohlweiss, and D. Sharma. Observing and preventing leakage in mapreduce. In Proceedings of the 22Nd ACM SIGSAC Conference on Computer and Communications Security, CCS ’15, pages 1570–1581, New York, NY, USA, 2015. ACM.</li>

      <li>[31] R. Ostrovsky and V. Shoup. Private information storage. In 29th ACM STOC, pages 294–303, 1997.</li>

      <li>[32] A. Papadimitriou, A. Narayan, and A. Haeberlen. Dstress: Efficient differentially private computations on distributed data. In G. Alonso, R. Bianchini, and M. Vukolic, editors, Proceedings of the Twelfth European Conference on Computer Systems, EuroSys 2017, Belgrade, Serbia, April 23-26, 2017, pages 560–574. ACM, 2017.</li>

      <li>[33] V. Pappas, F. Krell, B. Vo, V. Kolesnikov, T. Malkin, S. G. Choi, W. George, A. D. Keromytis, and S. Bellovin. Blind seer: A scalable private DBMS. In 2014 IEEE Symposium on Security & Privacy, pages 359–374, May 2014.</li>

      <li>[34] I. Roy, S. T. V. Setty, A. Kilzer, V. Shmatikov, and E. Witchel. Airavat: Security and privacy for mapreduce. In Proceedings of the 7th USENIX Conference on Networked Systems Design and Implementation, NSDI’10, pages 20–20, Berkeley, CA, USA, 2010. USENIX Association.</li>

      <li>[35] S. Wagh, P. Cuff, and P. Mittal. Root ORAM: A tunable differentially private oblivious RAM. CoRR, abs/1601.03378, 2016.</li>

      <li>[36] A. Waksman. A permutation network. Journal of the ACM (JACM), 15(1):159–163, 1968.</li>

      <li>[37] X. Wang, S. Ranellucci, and J. Katz. Authenticated garbling and efficient maliciously secure two-party computation. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, CCS ’17, pages 21–37, New York, NY, USA, 2017. ACM.</li>

      <li>[38] X. S. Wang, Y. Huang, T.-H. H. Chan, A. Shelat, and E. Shi. SCORAM: Oblivious RAM for secure computation. In ACM CCS 2014, pages 191–202, 2014.</li>

      <li>[39] R. Wyden. Letter to commission on evidence-based policymaking. https://www.wyden.senate.gov/download/?id=B10146F5-EDEB-4A2C-AD5E-812B363EE0DC&download=1, 2017. U.S. Senate.</li>

    </ul>

    <p class="text-gray-300">[40] S. Zahur and D. Evans. Obliv-c: A language for extensible data-oblivious computation. Cryptology ePrint Archive, Report 2015/1153, 2015. http://eprint.iacr.org/2015/1153.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[41] S. Zahur, X. S. Wang, M. Raykova, A. Gascón, J. Doerner, D. Evans, and J. Katz. Revisiting square-root ORAM: Efficient random access in multi-party computation. In 2016 IEEE Symposium on Security & Privacy, pages 218–234, 2016.</li>

    </ul>`;
---

<BaseLayout title="Differentially Private Access Patterns in Secure Computation (2017/1016)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2017 &middot; eprint 2017/1016
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
