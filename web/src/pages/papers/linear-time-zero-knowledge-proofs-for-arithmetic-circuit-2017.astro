---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2017/872';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Linear-Time Zero-Knowledge Proofs for Arithmetic Circuit Satisfiability';
const AUTHORS_HTML = 'Jonathan Bootle, Andrea Cerulli, Essam Ghadafi, Jens Groth, Mohammad Hajiabadi, Sune K.  Jakobsen';

const CONTENT = `    <p class="text-gray-300">Jonathan Bootle<span class="math">^{1}</span>, Andrea Cerulli<span class="math">^{1}</span>, Essam Ghadafi<span class="math">^{2\\dagger}</span>, Jens Groth<span class="math">^{1}</span>, Mohammad Hajiabadi<span class="math">^{3\\dagger}</span>, and Sune K. Jakobsen<span class="math">^{1}</span></p>

    <p class="text-gray-300"><span class="math">^{1}</span> University College London, London, UK {jonathan.bootle.14,andrea.cerulli.13,j.groth,s.jakobsen}@ucl.ac.uk</p>

    <p class="text-gray-300"><span class="math">^{2}</span> University of the West of England, Bristol, UK essam.ghadafi@uwe.ac.uk</p>

    <p class="text-gray-300"><span class="math">^{3}</span> University of California, Berkeley, CA, USA mdhajiabadi@berkeley.edu</p>

    <p class="text-gray-300">Abstract. We give computationally efficient zero-knowledge proofs of knowledge for arithmetic circuit satisfiability over a large field. For a circuit with <span class="math">N</span> addition and multiplication gates, the prover only uses <span class="math">\\mathcal{O}(N)</span> multiplications and the verifier only uses <span class="math">\\mathcal{O}(N)</span> additions in the field. If the commitments we use are statistically binding, our zero-knowledge proofs have unconditional soundness, while if the commitments are statistically hiding we get computational soundness. Our zero-knowledge proofs also have sub-linear communication if the commitment scheme is compact.</p>

    <p class="text-gray-300">Our construction proceeds in three steps. First, we give a zero-knowledge proof for arithmetic circuit satisfiability in an ideal linear commitment model where the prover may commit to secret vectors of field elements, and the verifier can receive certified linear combinations of those vectors. Second, we show that the ideal linear commitment proof can be instantiated using error-correcting codes and non-interactive commitments. Finally, by choosing efficient instantiations of the primitives we obtain linear-time zero-knowledge proofs.</p>

    <p class="text-gray-300">Keywords. Zero-knowledge, arithmetic circuit, ideal linear commitments.</p>

    <p class="text-gray-300">A zero-knowledge proof [GMR85] is a protocol between two parties: a prover and a verifier. The prover wants to convince the verifier that an instance <span class="math">u</span> belongs</p>

    <p class="text-gray-300">*The research leading to these results has received funding from the European Research Council under the European Union’s Seventh Framework Programme (FP/2007-2013) / ERC Grant Agreement n. 307937.</p>

    <p class="text-gray-300"><span class="math">^{\\dagger}</span>Part of the work was done while at University College London.</p>

    <p class="text-gray-300">to a specific language <span class="math">\\mathcal{L}_{\\mathcal{R}}</span> in NP. She has a witness <span class="math">w</span> such that <span class="math">(u,w)</span> belongs to the NP relation <span class="math">\\mathcal{R}</span> defining the language, but wants to convince the verifier that the statement <span class="math">u\\in\\mathcal{L}_{\\mathcal{R}}</span> is true without revealing the witness or any other confidential information.</p>

    <p class="text-gray-300">Zero-knowledge proofs are widely used in cryptography since it is often useful to verify that a party is following a protocol without requiring her to divulge secret keys or other private information. Applications range from digital signatures and public-key encryption to secure multi-party computation and verifiable cloud computing.</p>

    <p class="text-gray-300">Efficiency is crucial for large and complex statements such as those that may arise in the latter applications. Important efficiency parameters include the time complexity of the prover, the time complexity of the verifier, the amount of communication measured in bits, and the number of rounds the prover and verifier need to interact. Three decades of research on zero-knowledge proofs have gone into optimizing these efficiency parameters and many insights have been learned.</p>

    <p class="text-gray-300">For zero-knowledge proofs with unconditional soundness where it impossible for any cheating prover to convince the verifier of a false statement, it is possible to reduce communication to the witness size <em>[x10, x15, GGI^{+}14]</em>. For zero-knowledge arguments where it is just computationally intractable for the prover to cheat the verifier we can do even better and get sub-linear communication complexity <em>[x16]</em>.</p>

    <p class="text-gray-300">There are many constant-round zero-knowledge proofs and arguments, for instance Bellare, Jakobsson and Yung <em>[x3]</em> construct four round arguments based on one-way functions. In the common reference string model, it is even possible to give non-interactive proofs where the prover computes a convincing zero-knowledge proof directly without receiving any messages from the verifier <em>[x2]</em>.</p>

    <p class="text-gray-300">The verifier computation is in general at least proportional to the instance size because the verifier must read the entire instance in order to verify it. However, the verifier computation can be sub-linear in the time it takes for the relation to verify a witness for the statement being true <em>[x13]</em>, which is useful in both zero-knowledge proofs and verifiable computation.</p>

    <p class="text-gray-300">Having reduced the cost of many other efficiency parameters, today the major bottleneck is the prover’s computation. Classical number-theoretic constructions for circuit satisfiability such as <em>[x4]</em> require a linear number of exponentiations, i.e., the cost is <span class="math">\\mathcal{O}(\\lambda N)</span> group multiplications where <span class="math">N</span> is the number of gates and <span class="math">\\lambda</span> is a security parameter. Relying on different techniques and underlying cryptography <em>[x11]</em> has reduced the computational overhead further to being <span class="math">\\mathcal{O}(\\log(\\lambda))</span>. This leaves a tantalizing open question of whether we can come all the way down to constant overhead <span class="math">\\mathcal{O}(1)</span>, i.e., make the prover’s cost within a constant factor of the time it takes to verify <span class="math">(u,w)\\in R</span> directly.</p>

    <p class="text-gray-300">1.1 Our Contributions</p>

    <p class="text-gray-300">We construct zero-knowledge proofs of knowledge for the satisfiability of arithmetic circuits. An instance is an arithmetic circuits with <span class="math">N</span> fan-in 2 addition and multiplication gates over a finite field <span class="math">\\mathbb{F}</span> and a specification of the values of some of the wires. A witness consists of the remaining wires such that the values are consistent with the gates and the wire values specified in the instance.</p>

    <p class="text-gray-300">Our zero-knowledge proofs are highly efficient asymptotically:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Prover time is <span class="math">\\mathcal{O}(N)</span> field additions and multiplications.</li>

      <li>Verifier time is <span class="math">\\mathcal{O}(N)</span> field <em>additions</em>.</li>

    </ul>

    <p class="text-gray-300">This is optimal up to a constant factor for both the prover and verifier. The prover only incurs a constant overhead compared to the time needed to evaluate the circuit from scratch given an instance and a witness, and for instances of size equivalent to <span class="math">\\Omega(N)</span> field elements the verifier only incurs a constant overhead compared to the time it takes to read the instance. The constants are large, so we do not recommend implementing the zero-knowledge proof as it is, but from a theoretical perspective we consider it a big step forward to get constant overhead for both prover and verifier.</p>

    <p class="text-gray-300">Our zero-knowledge proofs have perfect completeness, i.e., when the prover knows a satisfactory witness she is always able to convince the verifier. Our constructions are proofs of knowledge, that is, not only does the prover demonstrate the statement is true but also that she knows a witness. The proofs have special honest-verifier zero-knowledge, which means that given a set of verifier challenges it is possible to simulate a proof answering the challenges without knowing a witness. The flavour of knowledge soundness and special honest-verifier zero-knowledge depends on the underlying commitment scheme we use. When instantiated with statistically binding commitment schemes, we obtain proofs (statistically knowledge sound) with computational zero-knowledge. When we use statistically hiding commitments we obtain arguments of knowledge with statistical special honest verifier zero-knowledge. The communication complexity of our proofs with unconditional soundness is only <span class="math">\\mathcal{O}(N)</span> field elements, while our arguments with computational soundness have sub-linear communication of <span class="math">\\text{poly}(\\lambda)\\sqrt{N}</span> field elements when the commitments are compact. Round complexity is also low, when we optimize for computational efficiency for prover and verifier we only use <span class="math">\\mathcal{O}(\\log\\log N)</span> rounds.</p>

    <h3 id="sec-3" class="text-xl font-semibold mt-8">1.2 Construction and Techniques</h3>

    <p class="text-gray-300">Our construction is modular and consists of three steps. First, we construct a proof in a communication model we call the Ideal Linear Commitment (ILC) channel. In the ILC model, the prover can commit vectors of secret field elements to the channel. The verifier may later query openings to linear combinations of the committed vectors, which the channel will answer directly. We show that idealizing the techniques by Groth et al. <em>[groth2009, BCC^{+}16]</em> gives us efficient proofs in the ideal linear commitment model. By optimizing primarily for prover</p>

    <p class="text-gray-300">computation and secondarily for round efficiency, we get a round complexity of <span class="math">\\mathcal{O}(\\log\\log N)</span> rounds, which is better than the <span class="math">\\mathcal{O}(\\log N)</span> rounds of Bootle et al. <em>[BCC^{+}16]</em> that optimized for communication complexity.</p>

    <p class="text-gray-300">Next, we compile proofs in the ILC model into proof and argument systems using non-interactive commitment schemes; however, unlike previous works we do not commit directly to the vectors. Instead, we encode the vectors as randomized codewords using a linear error-correcting code. We now consider the codewords as rows of a matrix and commit to the columns of that matrix. When the verifier asks for a linear combination of the vectors, the prover simply tells the verifier what the linear combination is. However, the verifier does not have to have blind confidence in the prover because she can ask for openings of some of the committed columns and use them to spot check that the resulting codeword is correct.</p>

    <p class="text-gray-300">Finally, we instantiate the scheme with concrete error-correcting codes and non-interactive commitment schemes. We use the error-correcting codes of Druk and Ishai <em>[x10]</em>, which allow the encoding of <span class="math">k</span> field elements using <span class="math">\\mathcal{O}(k)</span> additions in the field. Statistically hiding commitment schemes can be constructed from collision-resistant hash functions, and using the recent hash functions of Applebaum et al. <em>[AHI^{+}17]</em> we can hash <span class="math">t</span> field elements at a cost equivalent to <span class="math">\\mathcal{O}(t)</span> field additions. Statistically binding commitment schemes on the other hand can be built from pseudorandom number generators. Using the linear-time computable pseudorandom number generators of Ishai et al. <em>[x14]</em> we get linear-time computable statistically binding commitments. Plugging either of the commitment schemes into our construction yields zero-knowledge proofs with linear-time computation for both prover and verifier.</p>

    <h3 id="sec-4" class="text-xl font-semibold mt-8">1.3 Related Work</h3>

    <p class="text-gray-300">There is a rich body of research on zero-knowledge proofs. Early practical zero-knowledge proofs such as Schnorr <em>[x22]</em> and Guillou-Quisquater <em>[x11]</em> used number-theoretic assumptions. There have been several works extending these results to prove more general statements <em>[x5, x6, x12, BCC^{+}16]</em> with the latter giving discrete-logarithm based arguments for arithmetic circuit satisfiability with logarithmic communication complexity and a linear number of exponentiations for the prover, i.e., a computation cost of <span class="math">\\mathcal{O}(\\lambda N)</span> group multiplications for <span class="math">\\lambda</span>-bit exponents and a circuit with <span class="math">N</span> multiplication gates.</p>

    <p class="text-gray-300">Ishai et al. <em>[x14]</em> showed how to use secure multi-party computation (MPC) protocols to construct zero-knowledge proofs. The intuition behind this generic construction is that the prover first executes in <em>her head</em> an MPC protocol for computing a circuit verifying some relation <span class="math">R</span> and then commits to the views of all the virtual parties. The verifier asks the prover to open a subset of those views and then verifies their correctness and consistency with each other. Soundness and zero-knowledge follow from robustness and privacy of the MPC protocol. Applying this framework to efficient MPCs gives asymptotically efficient zero-knowledge proofs. For example, the perfectly secure MPC of <em>[x11]</em> is used in <em>[x14]</em> to obtain zero-knowledge proofs for the satisfiability of Boolean</p>

    <p class="text-gray-300">circuits with communication linear in the circuit size, <span class="math">\\mathcal{O}(N)</span>, and a computational cost of <span class="math">\\Omega(\\lambda N)</span>, for circuits of size <span class="math">N</span> and security parameter <span class="math">\\lambda</span>. Damgård et al. <em>[x10]</em> used the MPC framework to construct zero-knowledge proofs for the satisfiability of arithmetic circuits. Their construction has more balanced efficiency and achieves <span class="math">\\mathcal{O}(\\text{polylog}(\\lambda)N)</span> complexity for both computation and communication.</p>

    <p class="text-gray-300">Jawurek et al. <em>[x24]</em> gave a very different approach to building zero-knowledge proofs based on garbled circuits. Their approach proved <em>[x15, x11]</em> to be very efficient in practice for constructing proofs for languages represented as Boolean circuits. These techniques are appealing for proving small statements as they require only a constant number of symmetric-key operations per gate, while the main bottleneck is in their communication complexity. Asymptotically, this approach yields computational and communication complexity of <span class="math">\\mathcal{O}(\\lambda N)</span> bit operations and bits, respectively, when <span class="math">\\lambda</span> is the cost of a single symmetric-key operation. Recently, these techniques found applications in zero-knowledge proofs for checking the execution of RAM programs <em>[x16, x20]</em>. For instances that can be represented as RAM programs terminating in <span class="math">T</span> steps and using memory of size <span class="math">M</span>, these zero-knowledge proofs yield communication and computation with <span class="math">\\text{polylog}(M)</span> overhead compared to the running time <span class="math">T</span> of the RAM program.</p>

    <p class="text-gray-300">Cramer et al. <em>[x7]</em> introduce zero-knowledge proofs for verifying multiplicative relations of committed values using techniques related to ours. When applied to zero-knowledge proofs for the satisfiability of Boolean circuits, the asymptotic communication and computation complexities of <em>[x7]</em> are close to <em>[x17]</em>, although the constants are smaller. Unlike <em>[x7]</em>, we do not require any homomorphic property from the commitment scheme, and instead of relying on linear secret sharing schemes with product reconstruction, we use linear error-correcting codes.</p>

    <p class="text-gray-300">In past years, a lot of attention has been dedicated to the study of succinct non-interactive arguments of knowledge (SNARKs) <em>[x12, x6, x8, x9, x13, x18, BCG^{+}13, x14]</em>. These are very compact arguments offering very efficient verification time. In the most efficient cases, the arguments consist of only a constant number of group elements and verification consists of a constant number of pairings and a number of group exponentiations that is linear in the instance size but independent of the witness size. The main bottleneck of these arguments is the computational complexity of the prover which requires <span class="math">\\mathcal{O}(N)</span> group exponentiations.</p>

    <p class="text-gray-300">Recently, Ben-Sasson, Chiesa and Spooner <em>[x4]</em> proposed the notion of interactive oracle proofs (IOPs), which are interactive protocols where the prover may send a probabilisticaly checkable proof (PCP) in each round. Ben-Sasson et al. <em>[BSCG^{+}16]</em> construct a 3-round public-coin IOP (with soundness error <span class="math">1/2</span>) for Boolean circuit satisfiability with linear proof length and quasi-linear running times for both the prover and the verifier. Moreover, the constructed IOP has constant query complexity (the number of opening queries requested by the verifier), while prior PCP constructions require sub-linear query complexity.</p>

    <p class="text-gray-300">Another follow-up work by Ben-Sasson et al. <em>[x1]</em> gives 2-round zero-knowledge IOPs (duplex PCPs) for any language in <span class="math">\\mathrm{NTIME}(T(n))</span> with quasi-linear prover computation in <span class="math">n+T(n)</span>.</p>

    <p class="text-gray-300">Efficiency Comparison. All the proofs we list above have super-linear cost for the prover. This means our zero-knowledge proofs are the most efficient zero-knowledge proofs for arithmetic circuits for the prover. We also know that our verification time is optimal for an instance of size <span class="math">\\Omega(N)</span> field elements since the verification time is comparable to the time it takes just to read the instance.</p>

    <p class="text-gray-300">Another well-studied class of languages is Boolean circuit satisfiability but here our techniques do not fare as well since there would be an overhead in representing bits as field elements. We therefore want to make clear that our claim of high efficiency and a significant performance improvement over the state of the art relates only to arithmetic circuits. Nevertheless, we find the linear cost for arithmetic circuits a significant result in itself. This is the first time for any general class of NP-complete language that true linear cost is achieved for the prover when compared to the time it takes to evaluate the statement directly given the prover’s witness.</p>

    <h2 id="sec-5" class="text-2xl font-bold">2 Preliminaries</h2>

    <h3 id="sec-6" class="text-xl font-semibold mt-8">2.1 Notation and Computational Model</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We write <span class="math">y\\leftarrow A(x)</span> for an algorithm outputting <span class="math">y</span> on input <span class="math">x</span>. When the algorithm is randomized, and we wish to explicitly refer to a particular choice of random coins <span class="math">r</span> chosen by the algorithm, we write <span class="math">y\\leftarrow A(x;r)</span>. We write PPT/DPT for algorithms running in probabilistic polynomial time and deterministic polynomial time in the size of their inputs. Typically, the size of inputs and output will be polynomial in a <em>security parameter</em> <span class="math">\\lambda</span>, with the intention that larger <span class="math">\\lambda</span> means better security. For functions <span class="math">f,g:\\mathbb{N}\\rightarrow[0,1]</span>, we write <span class="math">f(\\lambda)\\approx g(\\lambda)</span> if $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">f(\\lambda)-g(\\lambda)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\frac{1}{\\lambda^{n(1)}}<span class="math">. We say a function </span>f<span class="math"> is <em>overwhelming</em> if </span>f(\\lambda)\\approx 1<span class="math"> and </span>f<span class="math"> is <em>negligible</em> if </span>f(\\lambda)\\approx 0$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Throughout the paper, we will be working over a finite field <span class="math">\\mathbb{F}</span>. To get negligible risk of an adversary breaking our zero-knowledge proofs, we need the field to be large enough such that $\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\omega(\\lambda)<span class="math">. When considering efficiency of our zero-knowledge proofs, we will assume the prover and verifier are RAM machines where operations on </span>W<span class="math">-bit words have unit cost. We assume a field element is represented by </span>\\mathcal{O}(\\frac{\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{W})<span class="math"> words and that additions in </span>\\mathbb{F}<span class="math"> carry a cost of </span>\\mathcal{O}\\left(\\frac{\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{W}\\right)<span class="math"> machine operations. We expect multiplications to be efficiently computable as well but at a higher cost of </span>\\omega\\left(\\frac{\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{W}\\right)$ machine operations.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">For a positive integer <span class="math">n</span>, <span class="math">[n]</span> denotes the set <span class="math">\\{1,\\ldots,n\\}</span>. We use bold letters such as <span class="math">\\bm{v}</span> for row vectors. For <span class="math">\\bm{v}\\in\\mathbb{F}^{n}</span> and a set <span class="math">J=\\{j_{1},\\ldots,j_{k}\\}\\subset[n]</span> with <span class="math">j_{1}&lt;\\cdots&lt;j_{k}</span> we define the vector $\\bm{v}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{J}<span class="math"> to be </span>(\\bm{v}_{j_{1}},\\ldots,\\bm{v}_{j_{k}})<span class="math">. Similarly, for a matrix </span>V\\in\\mathbb{F}^{m\\times n}<span class="math"> we let </span>V</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{J}\\in\\mathbb{F}^{m\\times k}<span class="math"> be the submatrix of </span>V<span class="math"> restricted to the columns indicated in </span>J$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">2.2 Proofs of Knowledge</p>

    <p class="text-gray-300">A <em>proof system</em> is defined by a triple of stateful PPT algorithms <span class="math">(\\mathcal{K},\\mathcal{P},\\mathcal{V})</span>, which we call the setup <em>generator</em>, the <em>prover</em> and <em>verifier</em>, respectively. The setup generator <span class="math">\\mathcal{K}</span> creates public parameters <span class="math">pp</span> that will be used by the prover and the verifier. We think of <span class="math">pp</span> as being honestly generated, however, in the proofs we construct it consists of parts that are either publicly verifiable or could be generated by the verifier, so we use the public parameter model purely for simplicity and efficiency of our proofs, not for security.</p>

    <p class="text-gray-300">The prover and verifier communicate with each other through a <em>communication channel</em> <span class="math">\\xleftrightarrow{\\text{chan}}</span>. When <span class="math">\\mathcal{P}</span> and <span class="math">\\mathcal{V}</span> interact on inputs <span class="math">s</span> and <span class="math">t</span> through a communication channel <span class="math">\\xleftrightarrow{\\text{chan}}</span> we let <span class="math">\\mathsf{view}_{\\mathcal{V}}\\leftarrow\\langle\\mathcal{P}(s)\\xleftrightarrow{\\text{chan}}\\mathcal{V}(t)\\rangle</span> be the view of the verifier in the execution, i.e., all inputs he gets including random coins and let <span class="math">\\mathsf{trans}_{\\mathcal{P}}\\leftarrow\\langle\\mathcal{P}(s)\\xleftrightarrow{\\text{chan}}\\mathcal{V}(t)\\rangle</span> denote the transcript of the communication between prover and channel. This overloads the notation <span class="math">\\leftarrow\\langle\\mathcal{P}(s)\\xleftrightarrow{\\text{chan}}\\mathcal{V}(t)\\rangle</span> but it will always be clear from the variable name if we get the verifier’s view or the prover’s transcript. At the end of the interaction the verifier accepts or rejects. We write <span class="math">\\langle\\mathcal{P}(s)\\xleftrightarrow{\\text{chan}}\\mathcal{V}(t)\\rangle=b</span> depending on whether the verifier rejects (<span class="math">b=0</span>) or accepts (<span class="math">b=1</span>).</p>

    <p class="text-gray-300">In the <em>standard channel</em> <span class="math">\\longleftrightarrow</span>, all messages are forwarded between prover and verifier. We also consider an <em>ideal linear commitment</em> channel, <span class="math">\\xleftrightarrow{\\text{ILC}}</span>, or simply ILC, described in Figure 1. When using the ILC channel, the prover can submit a commit command to commit to vectors of field elements of some fixed length <span class="math">k</span>, specified in <span class="math">pp_{\\text{ILC}}</span>. The vectors remain secretly stored in the channel, and will not be forwarded to the verifier. Instead, the verifier only learns how many vectors the prover has committed to. The verifier can submit a send command to the ILC to send field elements to the prover. In addition, the verifier can also submit open queries to the ILC for obtaining the opening of any linear combinations of the vectors sent by the prover. We stress that the verifier can request several linear combinations within a single open query, as depicted in Figure 1.</p>

    <p class="text-gray-300">In a proof system over the ILC channel, sequences of commit, send and open queries could alternate in an arbitrary order. We call a proof system over the ILC channel <em>non-adaptive</em> if the verifier only makes one <em>open</em> query to the ILC channel before terminating his interaction with the channel, otherwise we call it <em>adaptive</em>. Although adaptive proof systems are allowed by the model, in this paper we will only consider non-adaptive ILC proof systems to simplify the exposition.</p>

    <p class="text-gray-300">We remark that ILC proof systems are different from linear interactive proofs considered in <em>[BCI^{+}13]</em>. In linear interactive proofs both the prover and verifier send vectors of field elements, but the prover can only send linear (or affine) transformations of the verifier’s previously sent vectors. However, for our constructions it is important that the prover can compute on field elements received by the verifier and for instance evaluate polynomials.</p>

    <p class="text-gray-300">We say a proof system is <em>public coin</em> if the verifier’s messages to the communication channel are chosen uniformly at random and independently of the</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Fig. 1: Description of the ILC channel.</p>

    <p class="text-gray-300">actions of the prover, i.e., the verifier's messages to the prover correspond to the verifier's randomness  <span class="math">\\rho</span> .</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We will consider relations  <span class="math">\\mathcal{R}</span>  consisting of tuples  <span class="math">(pp,u,w)</span> , and define  $\\mathcal{L}_{\\mathcal{R}} = \\{(pp,u)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\exists w:(pp,u,w)\\in \\mathcal{R}\\}<span class="math"> . We refer to  </span>u<span class="math">  as the instance and  </span>w<span class="math">  as the witness that  </span>(pp,u)\\in \\mathcal{L}_{\\mathcal{R}}<span class="math"> . The public parameter  </span>pp<span class="math">  will specify the security parameter  </span>\\lambda<span class="math"> , perhaps implicitly through its length, and may also contain other parameters used for specifying the specific relation, e.g. a description of a field. Typically,  </span>pp<span class="math">  will also contain parameters that do not influence membership of  </span>\\mathcal{R}$  but may aid the prover and verifier, for instance, a description of an encoding function that they will use.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We will construct SHVZK proofs of knowledge for the relation  <span class="math">\\mathcal{R}_{\\mathrm{AC}}</span> , where the instances are arithmetic circuits over a field  <span class="math">\\mathbb{F}</span>  specified by  <span class="math">pp</span> . An instance consists of many fan-in 2 addition and multiplication gates over  <span class="math">\\mathbb{F}</span> , a description of how wires in the circuit connect to the gates, and values assigned to some of the input wires. Witnesses  <span class="math">w</span>  are the remaining inputs such that the output of the circuit is 0. For an exact definition of how we represent an arithmetic circuit, see Section 3. We would like to stress the fact that the wiring of the circuit is part of the instance and we allow a fully adaptive choice of the arithmetic circuit. This stands in contrast to pairing-based SNARKs that usually only consider circuits with fixed wires, i.e., the arithmetic circuit is partially non-adaptive, and getting full adaptivity through a universal circuit incurs an extra efficiency overhead.</p>

    <p class="text-gray-300">The protocol  <span class="math">(\\mathcal{K},\\mathcal{P},\\mathcal{V})</span>  is called a proof of knowledge over communication channel  <span class="math">\\stackrel{\\mathrm{chan}}{\\longleftrightarrow}</span>  for relation  <span class="math">\\mathcal{R}</span>  if it has perfect completeness and computational knowledge soundness as defined below.</p>

    <h6 id="sec-7" class="text-base font-medium mt-4">Definition 1 (Perfect Completeness).</h6>

    <p class="text-gray-300">The proof is <em>perfectly complete</em> if for all PPT adversaries <span class="math">\\mathcal{A}</span></p>

    <p class="text-gray-300">\\[ \\Pr\\left[\\begin{array}[]{c}pp\\leftarrow\\mathcal{K}(1^{\\lambda});(u,w)\\leftarrow\\mathcal{A}(pp):\\\\ (pp,u,w)\\notin\\mathcal{R}\\ \\lor\\ \\langle\\mathcal{P}(pp,u,w)\\xleftarrow{\\text{chan}}\\mathcal{V}(pp,u)\\rangle=1\\end{array}\\right]=1. \\]</p>

    <h6 id="sec-8" class="text-base font-medium mt-4">Definition 2 (Knowledge soundness).</h6>

    <p class="text-gray-300">A public-coin proof system has <em>computational (strong black-box) knowledge soundness</em> if for all DPT <span class="math">\\mathcal{P}^{*}</span> there exists an expected PPT extractor <span class="math">\\mathcal{E}</span> such that for all PPT adversaries <span class="math">\\mathcal{A}</span></p>

    <p class="text-gray-300">\\[ \\Pr\\left[\\begin{array}[]{c}pp\\leftarrow\\mathcal{K}(1^{\\lambda});(u,s)\\leftarrow\\mathcal{A}(pp);w\\leftarrow\\mathcal{E}^{\\langle\\mathcal{P}^{*}(s)\\xrightleftharpoons{\\text{han}}\\mathcal{V}(pp,u)\\rangle}(pp,u):\\\\ b=1\\ \\land\\ (pp,u,w)\\notin\\mathcal{R}\\end{array}\\right]\\approx 0. \\]</p>

    <p class="text-gray-300">Here the oracle <span class="math">\\langle\\mathcal{P}^{*}(s)\\xrightleftharpoons{\\text{chan}}\\mathcal{V}(pp,u)\\rangle</span> runs a full protocol execution and if the proof is successful it returns a transcript of the prover’s communication with the channel. The extractor <span class="math">\\mathcal{E}</span> can ask the oracle to rewind the proof to any point in a previous transcript and execute the proof again from this point on with fresh public-coin challenges from the verifier. We define <span class="math">b\\in\\{0,1\\}</span> to be the verifier’s output in the first oracle execution, i.e., whether it accepts or not, and we think of <span class="math">s</span> as the state of the prover. The definition can then be paraphrased as saying that if the prover in state <span class="math">s</span> makes a convincing proof, then we can extract a witness.</p>

    <p class="text-gray-300">If the definition holds also for unbounded <span class="math">\\mathcal{P}^{<em>}</span> and <span class="math">\\mathcal{A}</span> we say the proof has </em>statistical knowledge soundness*.</p>

    <p class="text-gray-300">If the definition of knowledge soundness holds for a non-rewinding extractor, i.e., a single transcript of the prover’s communication with the communication channel suffices, we say the proof system has knowledge soundness with <em>straight-line extraction</em>.</p>

    <p class="text-gray-300">We will construct public-coin proofs that have special honest-verifier zero-knowledge. This means that if the verifier’s challenges are known, or even adversarially chosen, then it is possible to simulate the verifier’s view without the witness. In other words, the simulator works for verifiers who may use adversarial coins in choosing their challenges but they follow the specification of the protocol as an honest verifier would.</p>

    <h6 id="sec-9" class="text-base font-medium mt-4">Definition 3 (Special Honest-Verifier Zero-Knowledge).</h6>

    <p class="text-gray-300">The proof of knowledge is <em>computationally special honest-verifier zero-knowledge (SHVZK)</em> if there exists a PPT simulator <span class="math">\\mathcal{S}</span> such that for all stateful interactive PPT adversaries <span class="math">\\mathcal{A}</span> that output <span class="math">(u,w)</span> such that <span class="math">(pp,u,w)\\in R</span> and randomness <span class="math">\\rho</span> for the verifier</p>

    <p class="text-gray-300">\\[ \\Pr\\left[\\begin{array}[]{c}pp\\leftarrow\\mathcal{K}(1^{\\lambda});(u,w,\\rho)\\leftarrow\\mathcal{A}(pp);\\\\ \\textsf{view}_{\\mathcal{V}}\\leftarrow\\langle\\mathcal{P}(pp,u,w)\\xrightleftharpoons{\\text{han}}\\mathcal{V}(pp,u;\\rho)\\rangle:\\mathcal{A}(\\textsf{view}_{\\mathcal{V}})=1\\end{array}\\right] \\]</p>

    <p class="text-gray-300"><span class="math">\\approx\\Pr\\left[pp\\leftarrow\\mathcal{K}(1^{\\lambda});(u,w,\\rho)\\leftarrow\\mathcal{A}(pp);\\textsf{view}_{\\mathcal{V}}\\leftarrow\\mathcal{S}(pp,u,\\rho):\\mathcal{A}(\\textsf{view}_{\\mathcal{V}})=1\\right].</span></p>

    <p class="text-gray-300">We say the proof is <em>statistically SHVZK</em> if the definition holds also against unbounded adversaries, and we say the proof is <em>perfect SHVZK</em> if the probabilities are exactly equal.</p>

    <p class="text-gray-300">From Honest-Verifier to General Zero-Knowledge. Honest-verifier zero-knowledge only guarantees the simulator works for verifiers following the proof system specifications. It might be desirable to consider general zero-knowledge where the simulator works for arbitrary malicious verifiers that may deviate from the specification of the proof. However, honest-verifier zero-knowledge is a first natural stepping stone to get efficient zero-knowledge proofs. We recall that our proofs are public coin, which means that the verifier’s messages are chosen uniformly at random and independently from the messages received from the verifier. Below we recall few options to obtain general zero-knowledge proofs from a public-coin SHVZK proof. All these transformations are very efficient in terms of computation and communication such that the efficiency properties of our special honest-verifier zero-knowledge protocols are preserved.</p>

    <p class="text-gray-300">In the Fiat-Shamir transform <em>[x10]</em> the verifier’s challenges are computed using a cryptographic hash function applied to the transcript up to the challenge. The Fiat-Shamir transform is more generally used to turn a public-coin proof into a non-interactive one. Since interaction with the verifier is no longer needed, general zero-knowledge is immediately achieved. If the hash function can be computed in linear time in the input size, then the Fiat-Shamir transform only incurs an additive linear overhead in computation for the prover and verifier. The drawback of the Fiat-Shamir transform is that security is usually proved in the random oracle model <em>[x3]</em> where the hash function is modelled as an ideal random function.</p>

    <p class="text-gray-300">Assuming a common reference string and relying on trapdoor commitments, Damgård <em>[x6]</em> gave a transformation yielding concurrently secure protocols for <span class="math">\\Sigma</span>-Protocols. The transformation can be optimized <em>[x14]</em> using the idea that for each public-coin challenge <span class="math">x</span>, the prover first commits to a value <span class="math">x^{\\prime}</span>, then the verifier sends a value <span class="math">x^{\\prime\\prime}</span>, after which the prover opens the commitment and uses the challenge <span class="math">x=x^{\\prime}+x^{\\prime\\prime}</span>. The coin-flipping can be interleaved with the rest of the proof, which means the transformation preserves the number of rounds and only incurs a very small efficiency cost to do the coin-flipping for the challenges.</p>

    <p class="text-gray-300">If one does not wish to rely on a common reference string for security, one can use a private-coin transformation where the verifier does not reveal the random coins used to generate the challenges sent to the prover (hence the final protocol is no longer public coin). One example is the Micciancio and Petrank <em>[x16]</em> transformation (yielding concurrently secure protocols) while incurring a small overhead of <span class="math">\\omega(\\log\\lambda)</span> with respect to the number of rounds as well as the computational and communication cost in each round. The transformation preserves the soundness and completeness errors of the original protocol; however, it does not preserve statistical zero-knowledge as the obtained protocol only has computational zero-knowledge.</p>

    <p class="text-gray-300">There are other public-coin transformations to general zero-knowledge e.g. Goldreich et al. <em>[x11]</em>. The transformation relies on a random-selection protocol between the prover and verifier to specify a set of messages and restricting the verifier to choose challenges from this set. This means to get negligible sound</p>

    <p class="text-gray-300">ess error these transformations require <span class="math">\\omega(1)</span> sequential repetitions so the round complexity goes up.</p>

    <h3 id="sec-10" class="text-xl font-semibold mt-8">2.3 Linear-Time Linear Error-Correcting Codes</h3>

    <p class="text-gray-300">A <em>code</em> over an alphabet <span class="math">\\Sigma</span> is a subset <span class="math">\\mathcal{C}\\subseteq\\Sigma^{n}</span>. A code <span class="math">\\mathcal{C}</span> is associated with an encoding function <span class="math">E_{\\mathcal{C}}:\\Sigma^{k}\\to\\Sigma^{n}</span> mapping messages of length <span class="math">k</span> into <em>codewords</em> of length <span class="math">n</span>. We assume there is a setup algorithm <span class="math">\\text{Gen}_{\\mathsf{E}_{\\mathcal{C}}}</span> which takes as input a finite field <span class="math">\\mathbb{F}</span> and the parameter <span class="math">k\\in\\mathbb{N}</span>, and outputs an encoding function <span class="math">E_{\\mathcal{C}}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In what follows, we restrict our attention to <em><span class="math">\\mathbb{F}</span>-linear codes</em> for which the alphabet is a finite field <span class="math">\\mathbb{F}</span>, the code <span class="math">\\mathcal{C}</span> is a <span class="math">k</span>-dimensional linear subspace of <span class="math">\\mathbb{F}^{n}</span>, and <span class="math">E_{\\mathcal{C}}</span> is an <span class="math">\\mathbb{F}</span>-linear map. The <em>rate</em> of the code is defined to be <span class="math">\\frac{k}{n}</span>. The <em>Hamming distance</em> between two vectors <span class="math">\\bm{x},\\bm{y}\\in\\mathbb{F}^{n}</span> is denoted by <span class="math">\\mathsf{hd}(\\bm{x},\\bm{y})</span> and corresponds to the number of coordinates in which <span class="math">\\bm{x},\\bm{y}</span> differ. The <em>(minimum) distance</em> of a code is defined to be the minimum Hamming distance <span class="math">\\mathsf{hd}_{\\min}</span> between distinct codewords in <span class="math">\\mathcal{C}</span>. We denote by <span class="math">[n,k,\\mathsf{hd}_{\\min}]_{\\mathbb{F}}</span> a linear code over <span class="math">\\mathbb{F}</span> with length <span class="math">n</span>, dimension <span class="math">k</span> and minimum distance <span class="math">\\mathsf{hd}_{\\min}</span>. The <em>Hamming weight</em> of a vector <span class="math">\\bm{x}</span> is $\\mathsf{wt}(\\bm{x})=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\{i\\in[n]:\\bm{x}_{i}\\neq 0\\}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In the next sections, we will use families of linear codes achieving asymptotically good parameters. More precisely, we require codes with linear length, <span class="math">n=\\Theta(k)</span>, and linear distance, <span class="math">\\mathsf{hd}_{\\min}=\\Theta(k)</span>, in the <em>dimension</em> <span class="math">k</span> of the code. We recall that random linear codes achieve with high probability the best trade-off between distance and rate. However, in this work we are particularly concerned with computational efficiency of the encoding procedure and random codes are not known to be very efficient.</p>

    <p class="text-gray-300">To obtain zero-knowledge proofs and arguments with linear cost for prover and verifier, we need to use codes that can be encoded in linear time. Starting from the seminal work of Spielman <em>[x20]</em>, there has been a rich stream of research <em>[x10, x11, x12, x13, x14, CDD^{+}16]</em> regarding linear codes with linear-time encoding. Our construction can be instantiated, for example, with one of the families of codes presented by Druk and Ishai <em>[x13]</em>. These are defined over a generic finite field <span class="math">\\mathbb{F}</span> and meets all the above requirements.</p>

    <h6 id="sec-11" class="text-base font-medium mt-4">Theorem 1 (<em>[x13]</em>).</h6>

    <p class="text-gray-300">There exist constants <span class="math">c_{1}&gt;1</span> and <span class="math">c_{2}&gt;0</span> such that for every finite field <span class="math">\\mathbb{F}</span> there exists a family of <span class="math">[\\lceil c_{1}k\\rceil,k,\\lfloor c_{2}k\\rfloor]_{\\mathbb{F}}</span> linear codes, which can be encoded by a uniform family of linear-size arithmetic circuit of addition gates.</p>

    <h3 id="sec-12" class="text-xl font-semibold mt-8">2.4 Commitment Schemes</h3>

    <p class="text-gray-300">A non-interactive commitment scheme allows a sender to commit to a secret message and later reveal the message in a verifiable way. Here we are interested in commitment schemes that take as input an arbitrary length message so the message space is <span class="math">\\{0,1\\}^{*}</span>. A commitment scheme is defined by a pair of PPT algorithms (Setup, Commit).</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Given a security parameter, this returns a commitment key <span class="math">ck</span></li>

    </ul>

    <p class="text-gray-300"><span class="math">\\mathsf{Commit}_{ck}(m)\\to c</span>: Given a message <span class="math">m</span>, this picks a randomness <span class="math">r\\leftarrow\\{0,1\\}^{\\mathrm{poly}(\\lambda)}</span> and computes a commitment <span class="math">c=\\mathsf{Commit}_{ck}(m;r)</span>.</p>

    <p class="text-gray-300">A commitment scheme must be <em>binding</em> and <em>hiding</em>. The binding property means that it is infeasible to open a commitment to two different messages, whereas the hiding property means that the commitment does not reveal anything about the committed message.</p>

    <h6 id="sec-13" class="text-base font-medium mt-4">Definition 4 (Binding)</h6>

    <p class="text-gray-300">A commitment scheme is <em>computationally binding</em> if for all PPT adversaries <span class="math">\\mathcal{A}</span></p>

    <p class="text-gray-300">\\[ \\Pr\\left[\\begin{array}[]{c}ck\\leftarrow\\mathsf{Setup}(1^{\\lambda});\\ (m_{0},r_{0},m_{1},r_{1})\\leftarrow\\mathcal{A}(ck):\\\\ m_{0}\\neq m_{1}\\ \\wedge\\ \\mathsf{Commit}_{ck}(m_{0};r_{0})=\\mathsf{Commit}_{ck}(m_{1};r_{1})\\end{array}\\right]\\approx 0. \\]</p>

    <p class="text-gray-300">If this holds also for unbounded adversaries, we say the commitment scheme is <em>statistically binding</em>.</p>

    <h6 id="sec-14" class="text-base font-medium mt-4">Definition 5 (Hiding)</h6>

    <p class="text-gray-300">A commitment scheme is <em>computationally hiding</em> if for all PPT stateful adversaries <span class="math">\\mathcal{A}</span></p>

    <p class="text-gray-300">\\[ \\Pr\\left[\\begin{array}[]{c}ck\\leftarrow\\mathsf{Setup}(1^{\\lambda});\\ (m_{0},m_{1})\\leftarrow\\mathcal{A}(ck);\\ b\\leftarrow\\{0,1\\};\\\\ c\\leftarrow\\mathsf{Commit}_{ck}(m_{b}):\\ \\mathcal{A}(c)=b\\end{array}\\right]\\approx\\frac{1}{2}, \\]</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where <span class="math">\\mathcal{A}</span> outputs messages of equal length $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">m_{0}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">m_{1}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$. If the definition holds also for unbounded adversaries, we say the commitment scheme is <em>statistically hiding</em>.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We will be interested in using highly efficient commitment schemes. We say a commitment scheme is <em>linear-time</em> if the time to compute <span class="math">\\mathsf{Commit}_{ck}(m)</span> is $\\mathrm{poly}(\\lambda)+\\mathcal{O}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">m</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> bit operations, which we assume corresponds to </span>\\mathrm{poly}(\\lambda)+\\mathcal{O}(\\frac{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">m</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{W})<span class="math"> machine operations on our </span>W<span class="math">-bit RAM machine. We will also be interested in having small size commitments. We say a commitment scheme is compact if there is a polynomial </span>\\ell(\\lambda)<span class="math"> such that commitments have size at most </span>\\ell(\\lambda)<span class="math"> regardless of how long the message is. We say a commitment scheme is <em>public coin</em> if there is a polynomial </span>\\ell(\\lambda)<span class="math"> such that </span>\\mathsf{Setup}(1^{\\lambda})<span class="math"> picks the commitment key uniformly at random as </span>ck\\leftarrow\\{0,1\\}^{\\ell(\\lambda)}<span class="math">. We will now discuss some candidate linear-time commitment schemes. Applebaum et al. <em>[AHI^{+}17]</em> gave constructions of low-complexity families of collision-resistant hash functions, where it is possible to evaluate the hash function in linear time in the message size. Their construction is based on the binary shortest vector problem assumption, which is related to finding non-trivial low-weight vectors in the null space of a matrix over </span>\\mathbb{F}_{2}$. To get down to linear-time complexity, they conjecture the binary shortest vector problem is hard when the matrix is sparse, e.g., an LDPC parity check matrix <em>[x11]</em>. Halevi and Micali <em>[x12]</em> show that a collision-resistant hash function gives rise to a compact statistically hiding commitment scheme. Their transformation is very efficient, so starting with a linear-time hash function, one obtains a linear-time statistically hiding compact commitment scheme. Moreover, if we instantiate the hash function with the one by Applebaum et</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">al. <em>[AHI^{+}17]</em>, which is public coin, we obtain a linear-time public-coin statistically hiding commitment scheme. Ishai et al. <em>[x14]</em> propose linear-time computable pseudorandom generators. If we have statistically binding commitment scheme this means we can commit to an arbitrary length message <span class="math">m</span> by picking a seed <span class="math">s</span> for the pseudorandom generator, stretch it to <span class="math">t=\\text{PRG}(s)</span> of length $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">m</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> and let </span>(\\mathsf{Commit}_{ck}(s),t\\oplus m)<span class="math"> be the commitment to </span>m$. Assuming the commitment scheme is statistically binding, this gives us a linear-time statistically binding commitment scheme for arbitrary length messages. It can also easily be seen that commitments have the same length as the messages plus an additive polynomial overhead that depends only on the security parameter. The construction also preserves the public-coin property of the seed commitment scheme.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h2 id="sec-15" class="text-2xl font-bold">3 Zero-Knowledge Proofs for Arithmetic Circuit Satisfiability in the Ideal Linear Commitment Model</h2>

    <p class="text-gray-300">In this section, we construct a SHVZK proof of knowledge for arithmetic circuit satisfiability relations <span class="math">\\mathcal{R}_{\\mathsf{AC}}</span> in the ILC model. Our proof can be seen as an abstraction of the zero-knowledge argument of Groth <em>[x20]</em> in an idealized vector commitment setting. In the ILC model, the prover can commit to vectors in <span class="math">\\mathbb{F}^{k}</span> by sending them to the channel. The ILC channel stores the received vectors and communicates to verifier the number of vectors it received. The verifier can send messages to the prover via the ILC channel, which in the case of Groth’s and our proof system consist of field elements in <span class="math">\\mathbb{F}</span>. Finally, the verifier can query the channel to open arbitrary linear combinations of the committed vectors sent by the prover. The field <span class="math">\\mathbb{F}</span> and the vector length <span class="math">k</span> is specified by the public parameter <span class="math">pp_{\\mathsf{ILC}}</span>. It will later emerge that to get the best communication and computation complexity for arithmetic circuits with <span class="math">N</span> gates, <span class="math">k</span> should be approximately <span class="math">\\sqrt{N}</span>.</p>

    <p class="text-gray-300">Consider a circuit with a total of <span class="math">N</span> fan-in 2 gates, which can be either addition gates or multiplication gates over a field <span class="math">\\mathbb{F}</span>. Each gate has two inputs (left and right) and one output wire, and each output wire can potentially be attached as input to several other gates. In total, we have <span class="math">3N</span> inputs and outputs to gates. Informally, the description of an arithmetic circuit consists of a set of gates, the connection of wires between gates and known values assigned to some of the inputs and outputs. A circuit is said to be satisfiable if there exists an assignment complying with all the gates, the wiring, and the known values specified in the instance.</p>

    <p class="text-gray-300">At a high level, the idea of the proof is for the prover to commit to the <span class="math">3N</span> inputs and outputs of all the gates in the circuit, and then prove that these assignments are consistent with the circuit description. This amounts to performing the following tasks:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Prove for each value specified in the instance that this is indeed the value the prover has committed to.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Prove for each addition gate that the committed output is the sum of the committed inputs.</li>

      <li>Prove for each multiplication gate that the committed output is the product of the committed inputs.</li>

      <li>Prove for each wire that all committed values corresponding to this wire are the same.</li>

    </ul>

    <p class="text-gray-300">To facilitate these proofs, we arrange the committed values into row vectors <span class="math">\\pmb{v}_i \\in \\mathbb{F}^k</span> similarly to [Gro09]. Without loss of generality we assume both the number of addition gates and the number of multiplication gates are divisible by <span class="math">k</span>, which can always be satisfied by adding few dummy gates to the circuit. We can then number addition gates from <span class="math">(1,1)</span> to <span class="math">(m_A, k)</span> and multiplication gates <span class="math">(m_A + 1, 1)</span> to <span class="math">(m_A + m_M, k)</span>. We insert assignments to left inputs, right inputs and outputs of addition gates into entries of three matrices <span class="math">A, B, C \\in \\mathbb{F}^{m_A \\times k}</span>, respectively. We sort entries to the matrices so that wires attached to the same gate correspond to the same entry of the three matrices, as shown in Figure 2. A valid assignment to the wires then satisfies <span class="math">A + B = C</span>. We proceed in a similar way for the <span class="math">m_M - k</span> multiplication gates to obtain three matrices <span class="math">D, E, F \\in \\mathbb{F}^{m_M \\times k}</span> such that <span class="math">D \\circ E = F</span>, where <span class="math">\\circ</span> denotes the Hadamard (i.e. entry-wise) product of matrices. All the committed wires then constitute a matrix</p>

    <div class="my-4 text-center"><span class="math-block">V = \\left( \\begin{array}{c} A \\\\ B \\\\ C \\\\ D \\\\ E \\\\ F \\end{array} \\right) \\in \\mathbb {F} ^ {(3 m _ {A} + 3 m _ {M}) \\times k}</span></div>

    <p class="text-gray-300">Without loss of generality, we also assume the gates to be sorted so that the wire values specified in the instance correspond to full rows in <span class="math">V</span>. Again, this is without loss of generality because we can always add a few dummy gates to the circuit and to the instance to complete a row.</p>

    <p class="text-gray-300">With these transformations in mind, let us write the arithmetic circuit relation as follows</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal {R} _ {\\mathsf {A C}} = \\left\\{ \\begin{array}{c} (p p, u, w) = \\left((\\mathbb {F}, k, *) , (m _ {A}, m _ {M}, \\pi , \\{\\pmb {v} _ {i} \\} _ {i \\in S}) , (\\{\\pmb {v} _ {i} \\} _ {i \\in \\bar {S}})\\right): \\\\ \\qquad m = 3 m _ {A} + 3 m _ {M} \\wedge \\pi \\in \\Sigma_ {[ m ] \\times [ k ]} \\\\ \\wedge S \\subseteq [ m ] \\qquad \\wedge \\bar {S} = [ m ] \\setminus S \\\\ \\wedge A = (\\pmb {v} _ {i}) _ {i = 1} ^ {m _ {A}} \\qquad \\wedge D = (\\pmb {v} _ {i}) _ {i = 3 m _ {A} + 1} ^ {3 m _ {A} + m _ {M}} \\\\ \\wedge B = (\\pmb {v} _ {i}) _ {i = m _ {A} + 1} ^ {2 m _ {A}} \\wedge E = (\\pmb {v} _ {i}) _ {i = 3 m _ {A} + m _ {M} + 1} ^ {3 m _ {A} + 2 m _ {M}} \\\\ \\wedge C = (\\pmb {v} _ {i}) _ {i = 2 m _ {A} + 1} ^ {3 m _ {A}} \\wedge F = (\\pmb {v} _ {i}) _ {i = 3 m _ {A} + 2 m _ {M} + 1} ^ {3 m _ {A} + 3 m _ {M}} \\\\ \\wedge A + B = C \\qquad \\wedge D \\circ E = F \\\\ \\wedge V = (\\pmb {v} _ {i}) _ {i = 1} ^ {m} \\qquad \\wedge V _ {i, j} = V _ {\\pi (i, j)} \\forall (i, j) \\in [ m ] \\times [ k ] \\end{array} \\right\\}</span></div>

    <p class="text-gray-300">The role of the permutation <span class="math">\\pi</span> is to specify the wiring of the arithmetic circuit. For each wire, we can write a cycle <span class="math">((i_1,j_1),\\ldots ,(i_t,j_t))</span> that lists the location of the committed values corresponding to this wire. Then we let <span class="math">\\pi \\in \\Sigma_{[m]\\times [k]}</span> be the</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Fig.2: Representation of an arithmetic circuit and arrangements of the wires into 6 matrices.</p>

    <p class="text-gray-300">product of all these cycles, which unambiguously defines the wiring of the circuit. To give an example using the circuit in Figure 2, the output wire of the first addition gate also appears as input of the first multiplication gate and the second addition gate. Therefore, if they appear as entries (5,1), (9,1), (1,2) in the matrix  <span class="math">V</span>  defined by the rows  <span class="math">\\pmb{v}_i</span> , then we would have the cycle  <span class="math">((5,1),(9,1),(1,2))</span>  indicating entries that must be identical. The output of the second addition gate feeds into the third addition gate, so this might give us a cycle  <span class="math">((5,2),(4,1))</span>  of entries that should have the same value. The permutation  <span class="math">\\pi</span>  is the product of all these cycles that define which entries should have the same value.</p>

    <p class="text-gray-300">In the proof for arithmetic circuit satisfiability, the prover starts by committing to all values  <span class="math">\\{\\pmb{v}_i\\}_{i=1}^m</span> . She will then call suitable sub-proofs to handle the four constraints these committed values should specify. We describe all the sub-proofs after the main proof given in Figure 3 and refer to Appendix A for the detailed constructions.</p>

    <p class="text-gray-300">Here we use the convention that when vectors or matrices are written in square brackets, i.e., when we write  <span class="math">[A]</span>  in the instance, it means that these are values that have already been committed to the ILC channel. The prover knows these values, but the verifier may not know them. The first sub-proof  <span class="math">\\left\\langle \\mathcal{P}_{\\mathrm{eq}}\\left(pp_{\\mathrm{ILC}},\\left(\\{\\pmb {v}_i\\}_{i\\in S},[U]\\right)\\right)\\xleftrightarrow{\\mathrm{ILC}}\\mathcal{V}_{\\mathrm{eq}}\\left(pp_{\\mathrm{ILC}},\\left(\\{\\pmb {u}_i\\}_{i\\in S},[U]\\right)\\right)\\right\\rangle</span>  allows the verifier to check that values included in the instance are contained in the corresponding commitments the prover previously sent to the ILC channel. The second subproof  <span class="math">\\left\\langle \\mathcal{P}_{\\mathrm{sum}}\\left(pp_{\\mathrm{ILC}},\\left([A],[B],[C]\\right)\\right)\\xleftrightarrow{\\mathrm{ILC}}\\mathcal{V}_{\\mathrm{sum}}\\left(pp_{\\mathrm{ILC}},\\left([A],[B],[C]\\right)\\right)\\right\\rangle</span>  is used to prove the committed matrices  <span class="math">A,B</span>  and  <span class="math">C</span>  satisfy  <span class="math">A + B = C</span> . The sub-proof  <span class="math">\\left\\langle \\mathcal{P}_{\\mathrm{prod}}\\left(pp_{\\mathrm{ILC}},\\left([D],[E],[F]\\right)\\right)\\xleftrightarrow{\\mathrm{ILC}}\\mathcal{V}_{\\mathrm{prod}}\\left(pp_{\\mathrm{ILC}},\\left([D],[E],[F]\\right)\\right)\\right\\rangle</span>  is used to prove that the committed matrices  <span class="math">D,E</span>  and  <span class="math">F</span>  satisfy  <span class="math">D\\circ E = F</span> . The last sub-proof  <span class="math">\\left\\langle \\mathcal{P}_{\\mathrm{perm}}\\left(pp_{\\mathrm{ILC}},\\left(\\pi ,[A],[B]\\right)\\right)\\xleftrightarrow{\\mathrm{ILC}}\\mathcal{V}_{\\mathrm{perm}}\\left(pp_{\\mathrm{ILC}},\\left(\\pi ,[A],[B]\\right)\\right)\\right\\rangle</span>  is used to prove that  <span class="math">A</span>  has the same entries as  <span class="math">B</span>  except they have been permuted according to the</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">PILC(ppILC, u, w)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">VILC(ppILC, u)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Parse u = (mA, mM, π, {vi}i∈S)</td>

            <td class="px-3 py-2 border-b border-gray-700">- Parse u = (mA, mM, π, {ui}i∈S)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Parse w = {vi}i∈S</td>

            <td class="px-3 py-2 border-b border-gray-700">- Run Veq(ppILC, {ui}i∈S, [U]))</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Send (commit, {vi}m1=1) to the ILC channel</td>

            <td class="px-3 py-2 border-b border-gray-700">- Run Vsum(ppILC, ([A], [B], [C]))</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- The vectors define V ∈ Fm×k and sub-matrices A, B, C, D, E, F as described earlier</td>

            <td class="px-3 py-2 border-b border-gray-700">- Run Vprod(ppILC, ([D], [E], [F]))</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Let U = (vi)i∈S</td>

            <td class="px-3 py-2 border-b border-gray-700">- Run Vperm(ppILC, (π, [V], [V]))</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Run Peq(ppILC, {vi}i∈S, [U]))</td>

            <td class="px-3 py-2 border-b border-gray-700">- Return 1 if all the sub-proofs are accepted and 0 otherwise</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  - Run Psum(ppILC, ([A], [B], [C])) |   |</p>

    <p class="text-gray-300">|  - Run Pprod(ppILC, ([D], [E], [F])) |   |</p>

    <p class="text-gray-300">|  - Run Pperm(ppILC, (π, [V], [V])) |   |</p>

    <p class="text-gray-300">Fig. 3: Arithmetic circuit satisfiability proof in the ILC model.</p>

    <p class="text-gray-300">permutation  <span class="math">\\pi</span> . Note that when we call the permutation sub-proof with  <span class="math">B = A</span> , then the statement is that  <span class="math">A</span>  remains unchanged when we permute the entries according to  <span class="math">\\pi</span> . This in turn means that all committed values that lie on the same cycle in the permutation must be identical, i.e., the matrix  <span class="math">A</span>  respects the wiring of the circuit.</p>

    <p class="text-gray-300">Theorem 2.  <span class="math">(\\mathcal{K}_{\\mathrm{ILC}},\\mathcal{P}_{\\mathrm{ILC}},\\mathcal{V}_{\\mathrm{ILC}})</span>  is a proof system for  <span class="math">\\mathcal{R}_{\\mathrm{AC}}</span>  in the ILC model with perfect completeness, statistical knowledge soundness with straight-line extraction, and perfect special honest-verifier zero-knowledge.</p>

    <p class="text-gray-300">Proof. Perfect completeness follows from the perfect completeness of the subproofs.</p>

    <p class="text-gray-300">Perfect SHVZK follows from the perfect SHVZK of the sub-proofs. A simulated transcript is obtained by combining the outputs of the simulators of all the sub-proofs.</p>

    <p class="text-gray-300">Also statistical knowledge soundness follows from the knowledge soundness of the sub-proofs. The statistical knowledge soundness of the equality sub-proof guarantees that commitments to values included in the instance indeed contain the publicly known values. The correctness of the addition gates and multiplication gates follows from the statistical knowledge soundness of the respective sub-proofs. Finally, as we have argued above, the permutation sub-proof guarantees the committed values respect the wiring of the circuit.</p>

    <p class="text-gray-300">Since all sub-proofs have knowledge soundness with straight line extraction, so does the main proof.</p>

    <p class="text-gray-300">The efficiency of our arithmetic circuit satisfiability proof in the ILC model is given in Figure 4. A detailed breakdown of the costs of each sub-protocol can be found in Appendix A. The asymptotic results displayed below are obtained when the parameter  <span class="math">k</span>  specified by  <span class="math">pp_{\\mathrm{ILC}}</span>  is approximately  <span class="math">\\sqrt{N}</span> . The query complexity</p>

    <p class="text-gray-300">qc is the number of linear combinations the verifier queries from the ILC channel in the opening query. The verifier communication  <span class="math">C_{\\mathrm{ILC}}</span>  is the number of messages sent from the verifier to the prover via the ILC channel and in our proof system it is proportional to the number of rounds. Let  <span class="math">\\mu</span>  be the number of rounds in the ILC proof and  <span class="math">t_1, \\ldots, t_\\mu</span>  be the numbers of vectors that the prover sends to the ILC channel in each round, and let  <span class="math">t = \\sum_{i=1}^{\\mu} t_i</span> .</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Prover computation</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TPILC = O(N) multiplications in F</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Verifier computation</td>

            <td class="px-3 py-2 border-b border-gray-700">TVILC = O(N) additions in F</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Query complexity</td>

            <td class="px-3 py-2 border-b border-gray-700">qc = 20</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Verifier communication</td>

            <td class="px-3 py-2 border-b border-gray-700">CILC = O(log log(N)) field elements</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Round complexity</td>

            <td class="px-3 py-2 border-b border-gray-700">μ = O(log log(N))</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Total number of committed vectors</td>

            <td class="px-3 py-2 border-b border-gray-700">t = O(√N) vectors in Fk</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Fig. 4: Efficiency of our arithmetic circuit satisfiability proof in the ILC model  <span class="math">(\\mathcal{K}_{\\mathrm{ILC}},\\mathcal{P}_{\\mathrm{ILC}},\\mathcal{V}_{\\mathrm{ILC}})</span>  for  <span class="math">(pp,u,w)\\in \\mathcal{R}_{\\mathrm{AC}}</span></p>

    <p class="text-gray-300">In this section, we show how to compile a proof of knowledge with straight-line extraction for relation  <span class="math">\\mathcal{R}</span>  over the communication channel ILC into a proof of knowledge without straight-line extraction for the same relation over the standard channel. Recall that the ILC channel allows the prover to submit vectors of length  <span class="math">k</span>  to the channel and the verifier can then query linear combinations of those vectors.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The idea behind the compilation of an ILC proof is that instead of committing to vectors  <span class="math">\\pmb{v}_{\\tau}</span>  using the channel ILC, the prover encodes each vector  <span class="math">\\pmb{v}_{\\tau}</span>  as  <span class="math">\\mathsf{E}_{\\mathcal{C}}(\\pmb{v}_{\\tau})</span>  using a linear error-correcting code  <span class="math">\\mathsf{E}_{\\mathcal{C}}</span> . In any given round, we can think of the codewords as rows  <span class="math">\\mathsf{E}_{\\mathcal{C}}(\\pmb{v}_{\\tau})</span>  in a matrix  <span class="math">\\mathsf{E}_{\\mathcal{C}}(V)</span> . However, instead of committing to the rows of the matrix, the prover commits to the columns of the matrix. When the verifier wants to open a linear combination of the original vectors, he sends the coefficients  <span class="math">\\pmb{q} = (q_{1},\\dots,q_{t})</span>  of the linear combination to the prover, and the prover responds with the linear combination  <span class="math">\\pmb{v}_{(\\pmb{q})} \\gets \\pmb{q}V</span> . Notice that we will use the notation  <span class="math">\\pmb{v}_{(\\pmb{q})}</span> , and later on  <span class="math">\\pmb{v}_{(\\pmb{\\gamma})}</span> , to denote vectors that depend on  <span class="math">\\pmb{q}</span>  and  <span class="math">\\pmb{\\gamma}</span> : the  <span class="math">\\pmb{q}</span>  and  <span class="math">\\pmb{\\gamma}</span>  are not indices. Now, to spot check that the prover is not giving a wrong  <span class="math">\\pmb{v}_{(\\pmb{q})}</span> , the verifier may request the  <span class="math">j</span> th element of each committed codeword  <span class="math">\\pmb{e}_{\\tau}</span> . This corresponds to revealing the  <span class="math">j</span> th column of error-corrected matrix  <span class="math">\\mathsf{E}_{\\mathcal{C}}(V)</span> . Since the code  <span class="math">\\mathsf{E}_{\\mathcal{C}}</span>  is linear, the revealed elements should satisfy  $\\mathsf{E}_{\\mathcal{C}}(\\pmb{v}_{(\\pmb{q})})_j = \\sum_{\\tau=1}^{t} q_{\\tau} \\mathsf{E}_{\\mathcal{C}}(\\pmb{v}_{\\tau})_j = \\pmb{q}(\\mathsf{E}_{\\mathcal{C}}(V)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_j)$ . The verifier will spot check on multiple columns, so that if the code has sufficiently large minimum distance</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">and the prover gives a wrong  <span class="math">\\pmb{v}_{(q)}</span> , then with overwhelming probability, the verifier will open at least one column  <span class="math">j</span>  where the above equality does not hold.</p>

    <p class="text-gray-300">Revealing entries in a codeword may leak information about the encoded vector. To get SHVZK, instead of using  <span class="math">\\mathsf{E}_{\\mathcal{C}}</span> , we use a randomized encoding  <span class="math">\\tilde{\\mathsf{E}}_{\\mathcal{C}}</span>  defined by  <span class="math">\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb {v};\\pmb {r}) = (\\mathsf{E}_{\\mathcal{C}}(\\pmb {v}) + \\pmb {r},\\pmb {r})</span> . This doubles the code-length to  <span class="math">2n</span>  but ensures that when you reveal entry  <span class="math">j</span> , but not entry  <span class="math">j + n</span> , then the verifier only learns a random field element. The spot checking technique using  <span class="math">\\tilde{\\mathsf{E}}_{\\mathcal{C}}</span>  is illustrated in Fig. 5. In the following, we use the notation  <span class="math">\\pmb {e}_{\\tau} = (\\mathsf{E}_{\\mathcal{C}}(\\pmb{v}_{\\tau}) + \\pmb{r}_{\\tau},\\pmb{r}_{\\tau})</span>  and  <span class="math">E = (\\mathsf{E}_{\\mathcal{C}}(V) + R,R)</span> . We also add a check, where the verifier sends an extra</p>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Fig.5: Vectors  <span class="math">\\pmb{v}_{\\tau}</span>  organized in matrix  <span class="math">V</span>  are encoded row-wise as matrix  <span class="math">E = \\tilde{\\mathsf{E}}_{\\mathcal{C}}(V;R)</span> . The vertical line in the right matrix and vector denotes concatenation of matrices respectively vectors. The prover commits to each column of  <span class="math">E</span> . When the prover given  <span class="math">\\pmb{q}</span>  wants to reveal the linear combination  <span class="math">\\pmb{v}_{(q)} = \\pmb{q}V</span>  she also reveals  <span class="math">\\pmb{r}_{(q)} = \\pmb{q}R</span> . The verifier now asks for openings of  <span class="math">2\\lambda</span>  columns  <span class="math">J = \\{j_1,\\dots ,j_{2\\lambda}\\}</span>  in  <span class="math">E</span>  and verifies for these columns that  $\\pmb{q}E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{J} = \\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{(q)};\\pmb{r}_{(q)})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{J}<span class="math"> . To avoid revealing any information about  </span>\\mathsf{E}_{\\mathcal{C}}(V)<span class="math"> , we must ensure that  </span>\\forall j\\in [n]:j\\in J\\Rightarrow j + n\\notin J<span class="math"> . If the spot checks pass, the verifier believes that  </span>\\pmb{v}_{(q)} = \\pmb{q}V$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">random linear combination  <span class="math">\\pmb{\\gamma} \\in \\mathbb{F}^t</span>  to ensure that if a malicious prover commits to values of  <span class="math">e_{\\tau}</span>  that are far from being codewords, the verifier will most likely reject. The reason the challenges  <span class="math">\\pmb{q}</span>  from the ILC proof are not enough to ensure this is that they are not chosen uniformly at random. One could, for instance, imagine that there was a vector  <span class="math">\\pmb{v}_{\\tau}</span>  that was never queried in a non-trivial way, and hence the prover could choose it to be far from a codeword. To make sure this extra challenge  <span class="math">\\pmb{\\gamma}</span>  does not reveal information to the verifier, the prover picks a random blinding vector  <span class="math">\\pmb{v}_0</span> , which is added as the first row of  <span class="math">V</span>  and will be added to the linear combination of the challenge  <span class="math">\\pmb{\\gamma}</span> .</p>

    <p class="text-gray-300">Let  <span class="math">(\\mathcal{K}_{\\mathrm{ILC}},\\mathcal{P}_{\\mathrm{ILC}},\\mathcal{V}_{\\mathrm{ILC}})</span>  be a non-adaptive  <span class="math">\\mu</span>  -round SHVZK proof of knowledge with straight-line extraction over ILC for a relation  <span class="math">\\mathcal{R}</span> . Here, non-adaptive means that</p>

    <p class="text-gray-300">19</p>

    <p class="text-gray-300">the verifier waits until the last round before querying linear combinations of vectors and they are queried all at once instead of the queries depending on each other.⁴ Let <span class="math">\\mathrm{Gen}_{\\mathsf{E}_{\\mathcal{C}}}</span> be a generator that gives field <span class="math">\\mathbb{F}</span> and length parameter <span class="math">k</span> outputs a constant rate linear code <span class="math">\\mathsf{E}_{\\mathcal{C}}</span> that is linear-time computable given its description and has linear minimum distance. Define the <span class="math">\\tilde{\\mathsf{E}}_{\\mathcal{C}}</span> with code length <span class="math">2n</span> as above: <span class="math">\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\boldsymbol{v};\\boldsymbol{r}) = (\\mathsf{E}_{\\mathcal{C}}(\\boldsymbol{v}) + \\boldsymbol{r},\\boldsymbol{r})</span>. Finally, let (Setup, Commit) be a non-interactive commitment scheme.</p>

    <p class="text-gray-300">We now define a proof of knowledge <span class="math">(\\mathcal{K},\\mathcal{P},\\mathcal{V})</span> in Fig. 6, where we use the following notation: given matrices <span class="math">V_{1},\\ldots ,V_{\\mu}</span>, <span class="math">R_{1},\\ldots ,R_{\\mu}</span> and <span class="math">E_1,\\dots ,E_\\mu</span> we define</p>

    <div class="my-4 text-center"><span class="math-block">V = \\left( \\begin{array}{c} V _ {1} \\\\ \\vdots \\\\ V _ {\\mu} \\end{array} \\right) \\qquad R = \\left( \\begin{array}{c} R _ {1} \\\\ \\vdots \\\\ R _ {\\mu} \\end{array} \\right) \\qquad E = \\left( \\begin{array}{c} E _ {1} \\\\ \\vdots \\\\ E _ {\\mu} \\end{array} \\right).</span></div>

    <p class="text-gray-300">The matrices <span class="math">V_{1},\\ldots ,V_{\\mu}</span> are formed by the row vectors <span class="math">\\mathcal{P}_{\\mathrm{ILC}}</span> commits to, and we let <span class="math">t_1,\\dots ,t_\\mu</span> be the numbers of vectors in each round, i.e., for all <span class="math">i</span> we have <span class="math">V_{i}\\in \\mathbb{F}^{t_{i}\\times k}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We say that a set <span class="math">J \\subset [2n]</span> is allowed if $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">J \\cap [n]</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\lambda<span class="math"> and </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">J \\setminus [n]</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\lambda<span class="math"> and there is no </span>j \\in J<span class="math"> such that </span>j + n \\in J<span class="math">. In the following we will always assume codewords have length </span>n \\geq 2\\lambda<span class="math">. We use </span>\\tilde{\\mathsf{E}}_{\\mathcal{C}}(V;R)<span class="math"> to denote the function that applies </span>\\tilde{\\mathsf{E}}_{\\mathcal{C}}<span class="math"> row-wise. In the protocol for </span>\\mathcal{V}<span class="math">, we are using that </span>\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v};\\pmb{r})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_J<span class="math"> can be computed from just </span>\\pmb{v}<span class="math"> and </span>\\pmb{r}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{\\{j \\in [n]: j \\in J \\lor j + n \\in J\\}}<span class="math">. We use Commit </span>(E; s)<span class="math"> to denote the function that applies Commit column-wise on </span>E<span class="math"> and returns a vector </span>\\pmb{c}<span class="math"> of </span>2n<span class="math"> commitments. We group all </span>\\mathcal{V}_{\\mathrm{ILC}}<span class="math">&#x27;s queries in one matrix </span>Q \\in \\mathbb{F}^{qc \\times t}<span class="math">, where </span>t<span class="math"> is the total number of vectors committed to by </span>\\mathcal{P}<span class="math"> and qc is the query complexity of </span>\\mathcal{V}_{\\mathrm{ILC}}<span class="math">, i.e., the total number of linear combinations </span>q<span class="math"> that </span>\\mathcal{V}_{\\mathrm{ILC}}$ requests to be opened.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h2 id="sec-18" class="text-2xl font-bold">4.2 Security Analysis</h2>

    <p class="text-gray-300"><strong>Theorem 3 (Completeness).</strong> If <span class="math">(\\mathcal{K}_{\\mathrm{ILC}},\\mathcal{P}_{\\mathrm{ILC}},\\mathcal{V}_{\\mathrm{ILC}})</span> is complete for relation <span class="math">\\mathcal{R}</span> over ILC, then <span class="math">(\\mathcal{K},\\mathcal{P},\\mathcal{V})</span> in Fig. 6 is complete for relation <span class="math">\\mathcal{R}</span>.</p>

    <p class="text-gray-300"><strong>Proof.</strong> All the commitment openings are correct, so they will be accepted by the verifier. In the execution of <span class="math">\\langle \\mathcal{P}(pp,u,w)\\longleftrightarrow \\mathcal{V}(pp,u)\\rangle</span>, the fact that <span class="math">\\mathsf{E}_{\\mathcal{C}}</span> is linear implies <span class="math">\\tilde{\\mathsf{E}}_{\\mathcal{C}}</span> is linear and hence all the linear checks will be true. If <span class="math">(pp,u,w)\\in \\mathcal{R}</span> then <span class="math">(pp_{\\mathrm{ILC}},u,w)\\in \\mathcal{R}</span> and being complete <span class="math">\\langle \\mathcal{P}_{\\mathrm{ILC}}(pp_{\\mathrm{ILC}},u,w)\\longleftrightarrow \\mathcal{V}_{\\mathrm{ILC}}(pp_{\\mathrm{ILC}},stm)\\rangle = 1</span> so <span class="math">\\mathcal{V}</span>'s internal copy of <span class="math">\\mathcal{V}_{\\mathrm{ILC}}</span> will accept. Thus, in this case, <span class="math">\\langle \\mathcal{P}(pp,u,w)\\longleftrightarrow \\mathcal{V}(pp,u)\\rangle = 1</span>, which proves completeness.</p>

    <p class="text-gray-300"><strong>Theorem 4 (Knowledge Soundness).</strong> If <span class="math">(\\mathcal{K}_{\\mathrm{ILC}},\\mathcal{P}_{\\mathrm{ILC}},\\mathcal{V}_{\\mathrm{ILC}})</span> is statistically knowledge sound with a straight-line extractor for relation <span class="math">\\mathcal{R}</span> over ILC and (Setup, Commit) is computationally (statistically) binding, then <span class="math">(\\mathcal{K},\\mathcal{P},\\mathcal{V})</span> as constructed above is computationally (statistically) knowledge sound for relation <span class="math">\\mathcal{R}</span>.</p>

    <p class="text-gray-300">⁴The construction can be easily modified to an adaptive ILC proof. For each round of queries in the ILC proof, there will one extra round in the compiled proof.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">P(pp,u,w)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">K(1λ)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Parse input: · Parse pp = (pplLC,EC,ck) · Parse pplLC = (F,k) · Get n from EC</td>

            <td class="px-3 py-2 border-b border-gray-700">- pplLC← KILC(1λ) - Parse pplLC = (F,k) - EC← GenEC(F,k) - ck← Setup(1λ)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Round 1: · v0← Fk · e0← EC(v0;r0) · (commit,V1)← PILC(pplLC,u,w) · E1← EC(V1;R1)</td>

            <td class="px-3 py-2 border-b border-gray-700">- Return pp = (pplLC,EC,ck)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">· Let E01 = (e0/E1) · c1 = Commit(E01;s1) · Send (c1,t1) to V</td>

            <td class="px-3 py-2 border-b border-gray-700">V(pp,u)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Rounds 2 ≤ i ≤ μ: · Get challenge xi-1 from V · (commit,Vi)← PILC(xi-1) · Ei← EC(Vi;Ri) · ci = Commit(Ei;si) · Send (ci,t1) to V</td>

            <td class="px-3 py-2 border-b border-gray-700">- Parse input · Parse pp = (pplLC,EC,ck) · Parse pplLC = (F,k) · Get n from EC · Give input (pplLC,u) to VILC</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Round μ + 1: · Get (γ,Q) from V · v(γ)← v0 + γV · r(γ)← r0 + γR · V(γ)← QV · R(γ)← QR · Send (v(γ),r(γ),V(γ),R(γ)) to V</td>

            <td class="px-3 py-2 border-b border-gray-700">- Rounds 1 ≤ i < μ: · Receive (ci,ti) · (send,xi)← VILC(ti) · Send xi to P</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Round μ + 2: · Get J ⊂ [2n] from V · Send (E01</td>

            <td class="px-3 py-2 border-b border-gray-700">J,s1</td>

            <td class="px-3 py-2 border-b border-gray-700">J,...,Eμ,sμ</td>

            <td class="px-3 py-2 border-b border-gray-700">J) to V</td>

            <td class="px-3 py-2 border-b border-gray-700">- Rounds μ: · Receive (cμ,tμ) · γ← F∞i=1ti · (open,Q)← VILC(tμ) · Send (γ,Q) to P</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|   | - Round μ + 1: · Receive (v(γ),r(γ),V(γ),R(γ))  |</p>

    <p class="text-gray-300">|   | · Choose random allowed J ⊂ [2n]  |</p>

    <p class="text-gray-300">|   | · Send J to P  |</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- Round μ + 2: · Receive (E01</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">J,s1</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">J,...,Eμ,sμ</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">J)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">· Check E∈(v(γ),r(γ))</td>

            <td class="px-3 py-2 border-b border-gray-700">J = e0</td>

            <td class="px-3 py-2 border-b border-gray-700">J + γE</td>

            <td class="px-3 py-2 border-b border-gray-700">J</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">· Check E∈(V(γ),R(γ))</td>

            <td class="px-3 py-2 border-b border-gray-700">J = QE</td>

            <td class="px-3 py-2 border-b border-gray-700">J</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|   | · If all checks pass, return decision of VILC(V(γ)), else return 0  |</p>

    <p class="text-gray-300">Fig.6: Construction of  <span class="math">(\\mathcal{K},\\mathcal{P},\\mathcal{V})</span>  from  <span class="math">(\\mathcal{K}_{\\mathrm{ILC}},\\mathcal{P}_{\\mathrm{ILC}},\\mathcal{V}_{\\mathrm{ILC}})</span> , commitment scheme (Setup, Commit) and error-correcting code  <span class="math">\\mathcal{C}</span> .</p>

    <p class="text-gray-300">Proof. We prove the computational case. The statistical case is similar.</p>

    <p class="text-gray-300">In order to argue that  <span class="math">(\\mathcal{K},\\mathcal{P},\\mathcal{V})</span>  is computationally knowledge sound, we will first show that for every DPT  <span class="math">\\mathcal{P}^*</span>  there exists a deterministic (but not necessarily</p>

    <p class="text-gray-300">21</p>

    <p class="text-gray-300">efficient) <span class="math">\\mathcal{P}_{\\mathrm{ILC}}^{*}</span> such that for all PPT <span class="math">\\mathcal{A}</span> we have</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c} p p \\leftarrow \\mathcal {K} \\left(1 ^ {\\lambda}\\right); \\left(p p _ {\\mathrm {I L C}}, \\cdot\\right) = p p; (u, s) \\leftarrow \\mathcal {A} (p p): \\\\ \\langle \\mathcal {P} ^ {*} (s) \\longleftrightarrow \\mathcal {V} (p p, u; (\\rho_ {\\mathrm {I L C}}, \\rho)) \\rangle = 1 \\\\ \\wedge \\quad \\langle \\mathcal {P} _ {\\mathrm {I L C}} ^ {*} (s, p p, u) \\xleftrightarrow {\\mathrm {I L C}} \\mathcal {V} _ {\\mathrm {I L C}} \\left(p p _ {\\mathrm {I L C}}, u; \\rho_ {\\mathrm {I L C}}\\right) \\rangle = 0 \\end{array} \\right] \\approx 0. \\tag {1}</span></div>

    <p class="text-gray-300">Note that the randomness <span class="math">\\rho_{\\mathrm{ILC}}</span> in <span class="math">\\mathcal{V}</span> which comes from the internal <span class="math">\\mathcal{V}_{\\mathrm{ILC}}</span> in line two is the same as the randomness used by <span class="math">\\mathcal{V}_{\\mathrm{ILC}}</span> in line three.</p>

    <p class="text-gray-300">Our constructed <span class="math">\\mathcal{P}_{\\mathrm{ILC}}^{<em>}</span> will run an internal copy of <span class="math">\\mathcal{P}^</em></span>. When the internal <span class="math">\\mathcal{P}^<em></span> in round <span class="math">i</span> sends a message <span class="math">(c_{i},t_{i})</span>, <span class="math">\\mathcal{P}_{\\mathrm{ILC}}^{</em>}</span> will simulate <span class="math">\\mathcal{P}^<em></span> on every possible continuation of the transcript, and for each <span class="math">j = 1,\\dots ,2n</span> find the most frequently occurring correct opening <span class="math">((E_i)_j,(\\pmb {s}_i)_j)</span> of <span class="math">(c_{i})_{j}</span>. <span class="math">\\mathcal{P}_{\\mathrm{ILC}}^{</em>}</span> will then use this to get matrices <span class="math">E_{i}^{<em>}</span>. For each row <span class="math">\\pmb{e}_{\\tau}^{</em>}</span> of these matrices, <span class="math">\\mathcal{P}_{\\mathrm{ILC}}^{<em>}</span> finds a vector <span class="math">\\pmb{v}_{\\tau}</span> and randomness <span class="math">\\pmb{r}_{\\tau}</span> such that <span class="math">\\mathsf{hd}(\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{\\tau},\\pmb{r}_{\\tau}),\\pmb{e}_{\\tau}^{</em>}) &amp;lt; \\frac{\\mathsf{hd}_{\\min}}{3}</span> if such a vector exists. If for some <span class="math">\\tau</span> no such vector <span class="math">\\pmb{v}_{\\tau}</span> exists, then <span class="math">\\mathcal{P}_{\\mathrm{ILC}}^{<em>}</span> aborts. Otherwise we let <span class="math">V_{i}</span> and <span class="math">R_{i}</span> denote the matrices formed by the row vectors <span class="math">\\pmb{v}_{\\tau}</span> and <span class="math">\\pmb{r}_{\\tau}</span> in round <span class="math">i</span> and <span class="math">\\mathcal{P}_{\\mathrm{ILC}}^{</em>}</span> sends <span class="math">V_{i}</span> to the ILC. Notice that since the minimum distance of <span class="math">\\tilde{\\mathsf{E}}_{\\mathcal{C}}</span> is at least <span class="math">\\mathsf{hd}_{\\min}</span>, there is at most one such vector <span class="math">\\pmb{v}_{\\tau}</span> for each <span class="math">\\pmb{e}_{\\tau}^{*}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The internal copy of <span class="math">\\mathcal{P}^<em></span> will expect to get two extra rounds, where in the first it should receive <span class="math">\\gamma</span> and <span class="math">Q</span> and should respond with <span class="math">\\pmb{v}_{(\\gamma)}^{</em>},\\pmb{r}_{(\\gamma)}^{*},V_{(Q)}</span> and <span class="math">R_{(Q)}</span> and in the second it should receive <span class="math">J</span> and send $E_{01}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{J},\\pmb{s}_{1}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{J},\\dots,E_{\\mu},\\pmb{s}_{\\mu}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{J}<span class="math">. Since </span>\\mathcal{P}_{\\mathrm{ILC}}^{<em>}<span class="math"> does not send and receive corresponding messages, </span>\\mathcal{P}_{\\mathrm{ILC}}^{</em>}<span class="math"> does not have to run this part of </span>\\mathcal{P}^<em><span class="math">. Of course, for each commitment sent by </span>\\mathcal{P}^</em><span class="math">, these rounds are internally simulated many times to get the most frequent opening. Notice that a </span>\\mathcal{V}_{\\mathrm{ILC}}<span class="math"> communicating over ILC with our constructed </span>\\mathcal{P}_{\\mathrm{ILC}}^{*}<span class="math"> will, on challenge </span>Q<span class="math"> receive </span>V_{(Q)} = QV$ from the ILC.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The verifier <span class="math">\\mathcal{V}</span> accepts only if its internal copy of <span class="math">\\mathcal{V}_{\\mathrm{ILC}}</span> accepts. Hence, the only three ways <span class="math">\\langle \\mathcal{P}^<em>(s) \\longleftrightarrow \\mathcal{V}(pp, u; (\\rho_{\\mathrm{ILC}}, \\rho)) \\rangle</span> can accept without <span class="math">\\langle \\mathcal{P}_{\\mathrm{ILC}}^</em>(s, pp, u) \\xleftrightarrow{\\mathrm{ILC}} \\mathcal{V}_{\\mathrm{ILC}}(pp_{\\mathrm{ILC}}, u; \\rho_{\\mathrm{ILC}}) \\rangle</span> being accepting are</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>if <span class="math">\\mathcal{P}^*</span> makes an opening of a commitment that is not its most frequent opening of that commitment, or</li>

      <li>if <span class="math">\\mathcal{P}_{\\mathrm{ILC}}^{<em>}</span> has an error because for some <span class="math">\\tau</span> no <span class="math">\\pmb{v}_{\\tau}, \\pmb{r}_{\\tau}</span> with <span class="math">\\mathsf{hd}(\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{\\tau}, \\pmb{r}_{\\tau}), \\pmb{e}_{\\tau}^{</em>}) &amp;lt; \\frac{\\mathsf{hd}_{\\min}}{3}</span> exists, or</li>

      <li>if <span class="math">\\mathcal{P}^<em></span> sends some <span class="math">V_{(Q)}^</em> \\neq V_{(Q)}</span>.</li>

    </ol>

    <p class="text-gray-300">We will now argue that for each of these three cases, the probability that they happen and <span class="math">\\mathcal{V}</span> accepts is negligible.</p>

    <p class="text-gray-300">Since <span class="math">\\mathcal{P}^<em></span> runs in polynomial time and the commitment scheme is computationally binding, there is only negligible probability that <span class="math">\\mathcal{P}^</em></span> sends a valid opening that is not the most frequent. Since <span class="math">\\mathcal{V}</span> will reject any opening that is not valid, the probability of <span class="math">\\mathcal{V}</span> accepting in case 1 is negligible.</p>

    <p class="text-gray-300">Next, we consider the second case. To do so, define the event <span class="math">Err</span> that <span class="math">E^{<em>}</span> is such that for some <span class="math">\\gamma^{</em>} \\in \\mathbb{F}^{t}</span> we have <span class="math">\\mathsf{hd}(\\tilde{\\mathcal{C}}, \\gamma^{<em>}E^{</em>}) \\geq \\frac{\\mathsf{hd}_{\\min}}{3}</span>. Here <span class="math">\\tilde{\\mathcal{C}}</span> denotes the image of <span class="math">\\tilde{\\mathsf{E}}_{\\mathcal{C}}</span>, i.e. <span class="math">\\tilde{\\mathcal{C}} = \\{(c + r, r) : c \\in \\mathcal{C}, r \\in \\mathbb{F}^{n}\\}</span>. Clearly, if <span class="math">\\mathcal{P}_{\\mathrm{ILC}}^{<em>}</span> returns an error because no <span class="math">\\pmb{v}_{i}, \\pmb{r}_{i}</span> with <span class="math">\\mathsf{hd}(\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{i}, \\pmb{r}_{i}), \\pmb{e}_{i}^{</em>}) &amp;lt; \\frac{\\mathsf{hd}_{\\min}}{3}</span> exist then we have <span class="math">Err</span>.</p>

    <p class="text-gray-300">The proof of the following claim can be found in Appendix B.</p>

    <p class="text-gray-300">22</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Claim. Let <span class="math">\\pmb{e}_0^<em>, \\dots, \\pmb{e}_t^</em> \\in \\mathbb{F}^{2n}</span>. If <span class="math">Err</span> occurs, then for uniformly chosen <span class="math">\\pmb{\\gamma} \\in \\mathbb{F}^t</span>, there is probability at most $\\frac{1}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math"> that </span>\\mathsf{hd}(\\tilde{\\mathcal{C}}, \\pmb{e}_0^<em> + \\pmb{\\gamma} E^</em>) &lt; \\frac{\\mathsf{hd}_{\\min}}{6}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Thus, if <span class="math">Err</span> then with probability at least $1 - \\frac{1}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math"> the vector </span>\\pmb{\\gamma}<span class="math"> is going to be such that </span>\\mathsf{hd}(\\tilde{\\mathcal{C}},\\pmb{e}_0^<em> +\\pmb {\\gamma}E^</em>)\\geq \\frac{\\mathsf{hd}_{\\min}}{6}<span class="math">. If this happens, then for the vectors </span>(\\pmb{v}_{(\\pmb{\\gamma})}^{<em>},\\pmb{r}_{(\\pmb{\\gamma})}^{</em>})<span class="math"> sent by </span>\\mathcal{P}^<em><span class="math">, we must have </span>\\mathsf{hd}(\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{(\\pmb{\\gamma})}^{</em>},\\pmb{r}_{(\\pmb{\\gamma})}^{<em>}),\\pmb{e}_0^</em> +\\pmb {\\gamma}E^<em>)\\geq \\frac{\\mathsf{hd}_{\\min}}{6}<span class="math">. This means that either in the first half of the codeword </span>\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{(\\pmb{\\gamma})}^{</em>},\\pmb{r}_{(\\pmb{\\gamma})}^{<em>})<span class="math"> or in the second half, there will be at least </span>\\frac{\\mathsf{hd}_{\\min}}{12}<span class="math"> values of </span>j<span class="math"> where it differs from </span>\\pmb{e}_0^</em> +\\pmb {\\gamma}E^*<span class="math">. It is easy to see that the </span>\\lambda<span class="math"> values of </span>j<span class="math"> in one half of </span>[2n]$ are chosen uniformly and independently at random conditioned on being different.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">For each of these <span class="math">j</span>, there is a probability at most <span class="math">1 - \\frac{\\mathsf{hd}_{\\min}}{12n}</span> that $\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{(\\pmb{\\gamma})},\\pmb{r}_{(\\pmb{\\gamma})})_j = \\pmb{e}_{0,j}^<em> + \\pmb{\\gamma}E^</em></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_j<span class="math">, and since the </span>j<span class="math">&#x27;s are chosen uniformly under the condition that they are distinct, given that this holds for the first </span>i<span class="math"> values, the probability is even smaller for the </span>i + 1<span class="math">&#x27;th. Hence, the probability that it holds for all </span>j<span class="math"> in this half is negligible. This shows that the probability that </span>Err<span class="math"> happens and </span>\\mathcal{V}$ accepts is negligible.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Now we turn to case 3, where <span class="math">Err</span> does not happen but <span class="math">\\mathcal{P}^<em></span> sends a <span class="math">V_{(Q)}^</em> \\neq V_{(Q)}</span>. In this case, for all <span class="math">\\pmb{\\gamma}^{<em>} \\in \\mathbb{F}^{t}</span>, we have <span class="math">\\mathsf{hd}(\\tilde{\\mathcal{C}}, \\sum_{\\tau=1}^{t} \\pmb{\\gamma}_{\\tau}^{</em>} \\pmb{e}_{\\tau}^{*}) &amp;lt; \\frac{\\mathsf{hd}_{\\min}}{3}</span>. In particular, this holds for the vector <span class="math">\\pmb{\\gamma}</span> given by <span class="math">\\pmb{\\gamma}_{\\tau} = 1</span> and <span class="math">\\pmb{\\gamma}_{\\tau&#x27;} = 0</span> for <span class="math">\\tau&#x27; \\neq \\tau</span>, so the <span class="math">\\pmb{v}_{\\tau}</span>'s are well-defined.</p>

    <p class="text-gray-300">For two matrices <span class="math">A</span> and <span class="math">B</span> of the same dimensions, we define their Hamming distance <span class="math">\\mathsf{hd}_2(A,B)</span> to be the number of <span class="math">j</span>'s such that the <span class="math">j</span>th column of <span class="math">A</span> and <span class="math">j</span>th column of <span class="math">B</span> are different. This agrees with the standard definition of Hamming distance, if we consider each matrix to be a string of column vectors. The proof of the following claim can be found in Appendix B.</p>

    <p class="text-gray-300">Claim. Assume <span class="math">\\neg Err</span> and let <span class="math">V</span> and <span class="math">R</span> be defined as above. Then for any <span class="math">\\pmb{q} \\in \\mathbb{F}^t</span> there exists an <span class="math">\\pmb{r}_{(\\pmb{q})}</span> with <span class="math">\\mathsf{hd}(\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{q}V, \\pmb{r}_{(\\pmb{q})}), \\pmb{q}E^{*}) &amp;lt; \\frac{\\mathsf{hd}_{\\min}}{3}</span>.</p>

    <p class="text-gray-300">In particular, for any <span class="math">V_{(Q)}^{<em>} \\neq QV</span>, and any <span class="math">R_{(Q)}^{</em>}</span> we have</p>

    <div class="my-4 text-center"><span class="math-block">\\mathrm{hd}_2 \\left(\\tilde{\\mathrm{E}}_{\\mathcal{C}} \\left(V_{(Q)}^*, R_{(Q)}^*\\right), QE^*\\right) \\geq 2 \\frac{\\mathrm{hd}_{\\min}}{3}.</span></div>

    <p class="text-gray-300">This means that if <span class="math">\\neg Err</span> occurs and <span class="math">\\mathcal{P}^<em></span> attempts to open a <span class="math">V_{(Q)}^</em> \\neq V_{(Q)} = QV</span> then</p>

    <div class="my-4 text-center"><span class="math-block">\\mathrm{hd}_2 \\left(\\tilde{\\mathrm{E}}_{\\mathcal{C}} \\left(V_{(Q)}^*, R_{(Q)}^*\\right), QE^*\\right) \\geq 2 \\frac{\\mathrm{hd}_{\\min}}{3}.</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">As argued above, if the distance between two strings of length <span class="math">2n</span> is at least <span class="math">\\frac{\\mathsf{hd}_{\\min}}{3}</span>, the probability that <span class="math">J</span> will not contain a <span class="math">j</span> such that the two strings differ in position <span class="math">j</span> is negligible. Hence, the probability that $\\tilde{\\mathsf{E}}_{\\mathcal{C}}\\left(V_{(Q)}^<em>, R_{(Q)}^</em>\\right)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_J = QE^*</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_J<span class="math"> is negligible. Thus, the probability that </span>\\neg Err<span class="math"> and </span>\\mathcal{V}<span class="math"> accepts while </span>\\mathcal{V}_{\\mathrm{ILC}}$ does not is negligible. This proves (1).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Next, we want to define a transcript extractor <span class="math">\\mathcal{T}</span> that gives rewindable access to <span class="math">\\langle \\mathcal{P}^<em>(s) \\longleftrightarrow \\mathcal{V}(pp, u) \\rangle</span> outputs <span class="math">\\widehat{\\text{trans}_{\\mathcal{P}_{\\mathrm{ILC}}}}</span>, which we would like to correspond to all messages sent between <span class="math">\\mathcal{P}_{\\mathrm{ILC}}^</em></span> and the channel in <span class="math">\\langle \\mathcal{P}_{\\mathrm{ILC}}^*(s, pp, u) \\longleftrightarrow^{\\mathrm{ILC}}</span></p>

    <p class="text-gray-300"><span class="math">\\mathcal{V}_{\\mathrm{ILC}}(pp_{\\mathrm{ILC}},u;\\rho_{\\mathrm{ILC}})\\rangle</span>. Here <span class="math">\\rho_{\\mathrm{ILC}}</span> is the randomness used by the <span class="math">\\mathcal{V}_{\\mathrm{ILC}}</span> inside <span class="math">\\mathcal{V}</span> in the first execution of <span class="math">\\mathcal{T}</span>'s oracle <span class="math">\\langle \\mathcal{P}^* (s)\\longleftrightarrow \\mathcal{V}(pp,u)\\rangle</span>. However, we allow <span class="math">\\mathcal{T}</span> to fail if <span class="math">\\mathcal{V}</span> does not accept in this first transcript and further to fail with negligible probability. Formally, we want <span class="math">\\mathcal{T}</span> to run in expected PPT such that for all PPT <span class="math">\\mathcal{A}</span>:</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c} p p \\leftarrow \\underset {\\text {t r a n s} \\mathcal {P} _ {\\mathrm {I L C}}} {\\mathcal {K}} (1 ^ {\\lambda}); (p p _ {\\mathrm {I L C}}, \\cdot) = p p; (u, s) \\leftarrow \\mathcal {A} (p p); \\\\ \\overbrace {\\operatorname {t r a n s} \\mathcal {P} _ {\\mathrm {I L C}}} \\leftarrow \\mathcal {T} ^ {\\langle \\mathcal {P} ^ {*} (s) \\longleftrightarrow \\mathcal {V} (p p, u) \\rangle} (p p, u); \\\\ \\operatorname {t r a n s} _ {\\mathcal {P} _ {\\mathrm {I L C}}} \\leftarrow \\langle \\mathcal {P} _ {\\mathrm {I L C}} ^ {*} (s, p p, u) \\xleftrightarrow {\\mathrm {I L C}} \\mathcal {V} _ {\\mathrm {I L C}} (\\underline {{p p _ {\\mathrm {I L C}}}}, u; \\rho_ {\\mathrm {I L C}}) \\rangle : \\\\ b = 1 \\quad \\wedge \\quad \\operatorname {t r a n s} _ {\\mathcal {P} _ {\\mathrm {I L C}}} \\neq \\overbrace {\\operatorname {t r a n s} _ {\\mathcal {P} _ {\\mathrm {I L C}}}} \\end{array} \\right] \\approx 0. \\tag {2}</span></div>

    <p class="text-gray-300">Here <span class="math">b</span> is the value output by <span class="math">\\mathcal{V}</span> the first time <span class="math">\\mathcal{T}</span>'s oracle runs <span class="math">\\langle \\mathcal{P}^<em>(s) \\longleftrightarrow \\mathcal{V}(pp, u) \\rangle</span>, and the randomness <span class="math">\\rho_{\\mathrm{ILC}}</span> used by <span class="math">\\mathcal{V}_{\\mathrm{ILC}}</span> in the third line is identical to the random value used by the <span class="math">\\mathcal{V}_{\\mathrm{ILC}}</span> inside <span class="math">\\mathcal{V}</span> in the first transcript. On input <span class="math">(pp, u)</span>, the transcript extractor <span class="math">\\mathcal{T}</span> will first use its oracle to get a transcript of <span class="math">\\langle \\mathcal{P}^</em>(s) \\longleftrightarrow \\mathcal{V}(pp, u; (\\rho_{\\mathrm{ILC}}, \\rho)) \\rangle</span>. If <span class="math">\\mathcal{V}</span> rejects, <span class="math">\\mathcal{T}</span> will just abort. If <span class="math">\\mathcal{V}</span> accepts, <span class="math">\\mathcal{T}</span> will rewind the last message of <span class="math">\\mathcal{P}^<em></span> to get a transcript for a new random challenge <span class="math">J</span>. <span class="math">\\mathcal{T}</span> continues this way, until it has an accepting transcript for <span class="math">2n</span> independently chosen sets <span class="math">J</span>. Notice that if there is only one choice of <span class="math">J</span> that results in <span class="math">\\mathcal{V}</span> accepting, <span class="math">\\mathcal{P}^</em></span> will likely have received each allowed challenge around <span class="math">2n</span> times and <span class="math">\\mathcal{T}</span> will get the exact same transcript <span class="math">2n</span> times before it is done rewinding. Still, <span class="math">\\mathcal{T}</span> runs in expected polynomial time: if a fraction <span class="math">p</span> of all allowed set <span class="math">J</span> results in accept, the expected number of rewindings given that the first transcripts accepts is <span class="math">\\frac{2n - 1}{p}</span>. However, the probability that the first run accepts is <span class="math">p</span>, and if it does not accept, <span class="math">\\mathcal{T}</span> does not do any rewindings. In total, that gives <span class="math">\\frac{(2n - 1)p}{p} = 2n - 1</span> rewindings in expectation.</p>

    <p class="text-gray-300">We let <span class="math">J_{1}, \\ldots, J_{2n}</span> denote the set of challenges <span class="math">J</span> in the accepting transcripts obtained by <span class="math">\\mathcal{T}</span>. If <span class="math">\\bigcup_{i=1}^{2n} J_{i}</span> has less than <span class="math">2n - \\frac{\\mathrm{hd}_{\\min}}{3}</span> elements, <span class="math">\\mathcal{T}</span> terminates. Otherwise, <span class="math">\\mathcal{T}</span> is defined similarly to <span class="math">\\mathcal{P}_{\\mathrm{ILC}}^{*}</span>: it uses the values of the openings to get at least <span class="math">2n - \\frac{\\mathrm{hd}_{\\min}}{3}</span> columns of each <span class="math">E_{i}</span>. For each of the row vectors, <span class="math">\\pmb{e}_{\\tau}</span>, it computes <span class="math">\\pmb{v}_{\\tau}</span> and <span class="math">\\pmb{r}_{\\tau}</span> such that <span class="math">\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{\\tau}, \\pmb{r}_{\\tau})</span> agrees with <span class="math">\\pmb{e}_{\\tau}</span> in all entries <span class="math">(\\pmb{e}_{\\tau})_{j}</span> for which the <span class="math">j</span>'th column have been revealed, if such <span class="math">\\pmb{v}</span> exists. Since <span class="math">\\mathcal{T}</span> will not correct any errors, finding such <span class="math">\\pmb{v}_{\\tau}</span> and <span class="math">\\pmb{r}_{\\tau}</span> corresponds to solving a linear set of equations. Notice that since the minimum distance is more than <span class="math">2\\frac{\\mathrm{hd}_{\\min}}{3}</span> there is at most one such <span class="math">\\pmb{v}_{\\tau}</span> for each <span class="math">\\tau \\in [t]</span>. If for some <span class="math">\\tau</span> there is no such <span class="math">\\pmb{v}_{\\tau}</span>, then <span class="math">\\mathcal{T}</span> aborts, otherwise <span class="math">\\mathcal{T}</span> use the resulting vectors <span class="math">\\pmb{v}_{\\tau}</span> as the prover messages to define <span class="math">\\overbrace{\\mathrm{trans}_{\\mathcal{P}_{\\mathrm{ILC}}}}^{\\mathrm{hd}_{\\min}}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">If $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\bigcup_{i=1}^{\\kappa} J_i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">&lt; 2n - \\frac{\\mathrm{hd}_{\\min}}{3}<span class="math">, there are at least </span>\\frac{\\mathrm{hd}_{\\min}}{6}<span class="math"> numbers in </span>[n] \\setminus \\bigcup_{i=1}^{\\kappa} J_i<span class="math"> or in </span>\\{n+1, \\ldots, 2n\\} \\setminus \\bigcup_{i=1}^{\\kappa} J_i<span class="math">. In either case, a random allowed </span>J<span class="math"> has negligible probability of being contained in </span>\\bigcup_{i=1}^{\\kappa} J_i<span class="math">. Since </span>\\mathcal{T}<span class="math"> runs in expected polynomial time, this implies by induction that there is only negligible probability that </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\bigcup_{i=1}^{\\kappa} J_i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">&lt; \\min(\\kappa, 2n - \\frac{\\mathrm{hd}_{\\min}}{3})<span class="math"> and therefore </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\bigcup_{i=1}^{2n} J_i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">&lt; 2n - \\frac{\\mathrm{hd}_{\\min}}{3}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Finally, we need to show</p>

    <p class="text-gray-300">Claim. The probability that for some <span class="math">\\tau</span> there are no <span class="math">\\pmb{v}_{\\tau}</span> and <span class="math">\\pmb{r}_{\\tau}</span> such that <span class="math">\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{\\tau},\\pmb{r}_{\\tau})</span> agrees with <span class="math">\\pmb{e}_{\\tau}</span> on the opened <span class="math">j\\in \\bigcup_{i = 1}^{2n}J_{i}</span> and <span class="math">b = 1</span> is negligible.</p>

    <p class="text-gray-300">24</p>

    <p class="text-gray-300">In particular, the probability that <span class="math">b = 1</span> but <span class="math">\\mathcal{T}</span> does not extract the transcript of <span class="math">\\mathcal{P}_{\\mathrm{ILC}}^*</span> is negligible.</p>

    <p class="text-gray-300">Proof. Since we can ignore events that happen with negligible probability, and the expected number of rewindings is polynomial, we can assume that in all the rewindings, <span class="math">\\mathcal{P}^<em></span> only makes openings to the most common openings. We showed that the probability that <span class="math">b = 1</span> but <span class="math">\\mathcal{P}^</em></span> sends a <span class="math">V_{(Q)}^<em> \\neq V</span> is negligible and by the same argument the probability that <span class="math">b = 1</span> but <span class="math">\\mathcal{P}^</em></span> sends <span class="math">\\pmb{v}_{(\\pmb{\\gamma})}^<em> \\neq \\pmb{v}_{(\\pmb{\\gamma})}</span> is negligible. Therefore, in the following, we will assume <span class="math">\\pmb{v}_{(\\pmb{\\gamma})}^</em> = \\pmb{v}_{(\\pmb{\\gamma})}</span>.</p>

    <p class="text-gray-300">Now suppose that there is some <span class="math">\\pmb{e}_{\\tau}</span> such that the opened values are inconsistent with being <span class="math">\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{\\tau},\\pmb{r}_{\\tau})</span> for any <span class="math">\\pmb{r}_{\\tau}</span>. That is, there is some <span class="math">j</span> such that <span class="math">j,n + j\\in \\bigcup_{i = 1}^{2n}J_{i}</span> and <span class="math">(\\pmb{e}_{\\tau})_j - (\\pmb{e}_{\\tau})_{n + j}\\neq \\mathsf{E}_{\\mathcal{C}}(\\pmb {v})_j</span>. For uniformly chosen <span class="math">\\gamma_{\\tau}\\in \\mathbb{F}</span>, we get that <span class="math">\\gamma_{\\tau}((\\pmb{e}_{\\tau})_j - (\\pmb{e}_{\\tau})_{n + j} - \\mathsf{E}_{\\mathcal{C}}(\\pmb {v})_j)</span> is uniformly distributed in <span class="math">\\mathbb{F}</span>. Hence for a random <span class="math">\\gamma \\in \\mathbb{F}^t</span>, we have that <span class="math">\\gamma \\cdot ((\\pmb {e})_j - (\\pmb {e})_{n + j} - \\mathsf{E}_{\\mathcal{C}}(\\pmb {v})_j)</span> is uniformly distributed. When <span class="math">\\mathcal{V}</span> sends <span class="math">\\gamma</span>, <span class="math">\\mathcal{P}^<em></span> will respond with <span class="math">\\pmb{v}_{(\\gamma)}^{</em>} = \\pmb{v}_{(\\gamma)}</span> and some <span class="math">\\pmb{r}_{(\\gamma)}^{<em>}</span>. <span class="math">\\mathcal{V}</span> will only accept on a challenge <span class="math">J</span> if for all <span class="math">j\\in J</span> we have <span class="math">(\\pmb {e}_0 + \\pmb {\\gamma}\\pmb {e})_j = \\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{(\\gamma)},\\pmb{r}_{(\\gamma)}^</em>)_j</span>. Since <span class="math">j,n + j\\in \\bigcup_{i = 1}^{2n}J_{i}</span> we have <span class="math">(\\pmb {e}_0 + \\pmb {\\gamma}\\pmb {e})_j = \\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{(\\gamma)},\\pmb{r}_{(\\gamma)}^<em>)_j</span> and <span class="math">(\\pmb {e}_0 + \\pmb {\\gamma}\\pmb {e})_{n + j} = \\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{(\\gamma)},\\pmb{r}_{(\\gamma)}^</em>)_{n + j}</span> so</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} (\\pmb {e} _ {0}) _ {j} - (\\pmb {e} _ {0}) _ {n + j} + \\pmb {\\gamma} \\pmb {e} _ {j} - \\pmb {\\gamma} \\pmb {e} _ {n + j} = \\tilde {\\mathsf {E}} _ {\\mathcal {C}} (\\pmb {v} _ {(\\pmb {\\gamma})}, \\pmb {r} _ {(\\pmb {\\gamma})} ^ {*}) _ {j} - \\tilde {\\mathsf {E}} _ {\\mathcal {C}} (\\pmb {v} _ {(\\pmb {\\gamma})}, \\pmb {r} _ {(\\pmb {\\gamma})} ^ {*}) _ {n + j} \\\\ = \\mathsf {E} _ {\\mathcal {C}} (\\boldsymbol {v} _ {(\\boldsymbol {\\gamma})}) _ {j} \\\\ = \\left(\\mathsf {E} _ {\\mathcal {C}} (\\boldsymbol {v} _ {0}) + \\boldsymbol {\\gamma} \\mathsf {E} _ {\\mathcal {C}} (\\boldsymbol {v})\\right) _ {j} \\\\ \\end{array}</span></div>

    <p class="text-gray-300">that is,</p>

    <div class="my-4 text-center"><span class="math-block">\\boldsymbol {\\gamma} \\boldsymbol {e} _ {j} - \\boldsymbol {\\gamma} \\boldsymbol {e} _ {n + j} - \\boldsymbol {\\gamma} \\mathsf {E} _ {\\mathcal {C}} (\\boldsymbol {v}) _ {j} = \\mathsf {E} _ {\\mathcal {C}} (\\boldsymbol {v} _ {0}) _ {j} - (\\boldsymbol {e} _ {0}) _ {j} + (\\boldsymbol {e} _ {0}) _ {n + j}</span></div>

    <p class="text-gray-300">For random <span class="math">\\gamma</span> the left-hand side is uniform and the right-hand side is fixed, hence equality only happens with negligible probability. That proves the claim.</p>

    <p class="text-gray-300">Since <span class="math">\\mathcal{E}_{\\mathrm{ILC}}^{\\langle \\mathcal{P}_{\\mathrm{ILC}}^{*}(s,pp,u)\\leftarrow \\mathrm{ILC}} \\mathcal{V}_{\\mathrm{ILC}}(pp_{\\mathrm{ILC}},u) \\rangle}(pp,u)</span> is a straight-line extractor, we can simply assume that it gets the transcript as an input, and can be written as <span class="math">\\mathcal{E}_{\\mathrm{ILC}}(pp_{\\mathrm{ILC}},u,\\mathsf{trans}_{\\mathcal{P}_{\\mathrm{ILC}}})</span>. For any PPT <span class="math">\\mathcal{A}</span> consider the following experiment.</p>

    <div class="my-4 text-center"><span class="math-block">\\left[ \\begin{array}{c} p p \\leftarrow \\underline {{\\mathcal {K}}} (1 ^ {\\lambda}); (p p _ {\\mathrm {I L C}}, \\cdot) = p p; (u, s) \\leftarrow \\mathcal {A} (p p); \\\\ \\operatorname {t r a n s} _ {\\mathcal {P} _ {\\mathrm {I L C}}} \\leftarrow \\mathcal {T} ^ {\\langle \\mathcal {P} ^ {*} (s) \\leftarrow \\rightarrow \\mathcal {V} (p p, u)} (p p, u); \\\\ \\operatorname {t r a n s} _ {\\mathcal {P} _ {\\mathrm {I L C}}} \\leftarrow \\langle \\mathcal {P} _ {\\mathrm {I L C}} ^ {*} (s, p p, u) \\xleftarrow {\\mathrm {I L C}} \\mathcal {V} _ {\\mathrm {I L C}} (p p _ {\\mathrm {I L C}}, u; \\rho_ {\\mathrm {I L C}}) \\rangle = b _ {\\mathrm {I L C}}; \\\\ w \\leftarrow \\mathcal {E} _ {\\mathrm {I L C}} (p p _ {\\mathrm {I L C}}, u, \\widehat {\\operatorname {t r a n s} _ {\\mathcal {P} _ {\\mathrm {I L C}}}}); \\\\ \\widetilde {w} \\leftarrow \\mathcal {E} _ {\\mathrm {I L C}} (p p _ {\\mathrm {I L C}}, u, \\widehat {\\operatorname {t r a n s} _ {\\mathcal {P} _ {\\mathrm {I L C}}}}); \\\\ \\end{array} \\right] \\tag {3}</span></div>

    <p class="text-gray-300">We have shown that when doing this experiment, the probability that <span class="math">b = 1 \\wedge b_{\\mathrm{ILC}} = 0</span> and the probability that <span class="math">b = 1 \\wedge \\mathsf{trans}_{\\mathcal{P}_{\\mathrm{ILC}}} \\neq \\widehat{\\mathsf{trans}_{\\mathcal{P}_{\\mathrm{ILC}}}}</span> are both negligible. By knowledge soundness of <span class="math">(\\mathcal{K}_{\\mathrm{ILC}}, \\mathcal{P}_{\\mathrm{ILC}}, \\mathcal{V}_{\\mathrm{ILC}})</span>, the probability that <span class="math">b_{\\mathrm{ILC}} = 1 \\wedge (pp, u, w) \\notin \\mathcal{R}</span> is also negligible. Finally, if <span class="math">\\mathsf{trans}_{\\mathcal{P}_{\\mathrm{ILC}}} = \\widehat{\\mathsf{trans}_{\\mathcal{P}_{\\mathrm{ILC}}}}</span> then clearly <span class="math">w = \\widetilde{w}</span>. Taken together this implies that the probability of <span class="math">b = 1 \\wedge (pp, u, \\widetilde{w}) \\notin R</span> is negligible. We now define <span class="math">\\mathcal{E}^{\\langle \\mathcal{P}^{<em>}(s) \\leftarrow \\to \\mathcal{V}(pp, u) \\rangle}(pp, u)</span> to compute <span class="math">\\mathcal{E}_{\\mathrm{ILC}}(pp_{\\mathrm{ILC}}, u, \\mathcal{T}^{\\langle \\mathcal{P}^{</em>}(s) \\leftarrow \\to \\mathcal{V}(pp, u) \\rangle}(pp, u))</span>. The above experiment shows that <span class="math">(\\mathcal{K}, \\mathcal{P}, \\mathcal{V})</span> is knowledge sound with <span class="math">\\mathcal{E}</span> as extractor.</p>

    <p class="text-gray-300">25</p>

    <p class="text-gray-300">Theorem 5 (SHVZK). If <span class="math">(\\mathcal{K}_{\\mathrm{ILC}},\\mathcal{P}_{\\mathrm{ILC}},\\mathcal{V}_{\\mathrm{ILC}})</span> is perfect SHVZK and (Setup, Commit) is computationally (statistically) hiding then <span class="math">(\\mathcal{K},\\mathcal{P},\\mathcal{V})</span> is computationally (statistically) SHVZK.</p>

    <p class="text-gray-300">Proof. To prove we have SHVZK we describe how the simulator <span class="math">\\mathcal{S}(pp,u,\\rho)</span> should simulate the view of <span class="math">\\mathcal{V}</span>. Along the way, we will argue why, the variables output by <span class="math">\\mathcal{S}</span> have the correct joint distribution. To keep the proof readable, instead of saying that "the joint distribution of [random variable] and all previously defined random variables is identical to the distribution in the real view of <span class="math">\\mathcal{V}</span> in <span class="math">\\langle \\mathcal{P}(pp,u,w)\\longleftrightarrow \\mathcal{V}(pp,u)\\rangle</span>" we will simply say that "[random variable] has the correct distribution".</p>

    <p class="text-gray-300">Using the randomness <span class="math">\\rho</span> the simulator learns the queries <span class="math">\\rho_{\\mathrm{ILC}} = (x_1, \\ldots, x_{\\mu - 1}, Q)</span> the internal <span class="math">\\mathcal{V}_{\\mathrm{ILC}}</span> run by the honest <span class="math">\\mathcal{V}</span> will send. <span class="math">\\mathcal{S}</span> can therefore run <span class="math">\\mathcal{S}_{\\mathrm{ILC}}(pp_{\\mathrm{ILC}}, u, \\rho_{\\mathrm{ILC}})</span> to simulate the view of the internal <span class="math">\\mathcal{V}_{\\mathrm{ILC}}</span>. This gives it <span class="math">(t_1, \\ldots, t_\\mu, V_{(Q)})</span>. By the SHVZK property of <span class="math">(\\mathcal{K}_{\\mathrm{ILC}}, \\mathcal{P}_{\\mathrm{ILC}}, \\mathcal{V}_{\\mathrm{ILC}})</span> these random variables will all have the correct joint distribution.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Then <span class="math">\\mathcal{S}</span> reads the rest of <span class="math">\\rho</span> to learn also the challenges <span class="math">\\gamma</span> and <span class="math">J</span> that <span class="math">\\mathcal{V}</span> will send. The simulator picks uniformly at random <span class="math">\\pmb{v}_{(\\gamma)} \\gets \\mathbb{F}^k</span>. Since in a real proof <span class="math">\\pmb{v}_0</span> is chosen at random, we see that the simulated <span class="math">\\pmb{v}_{(\\gamma)}</span> has the correct distribution. Now <span class="math">\\mathcal{S}</span> picks $E_{01}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_J, \\ldots, E_\\mu</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_J<span class="math"> uniformly at random. Recall that we defined </span>\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}; \\pmb{r}) = (\\mathsf{E}_{\\mathcal{C}}(\\pmb{v}) + \\pmb{r}, \\pmb{r})<span class="math"> and by definition of </span>J<span class="math"> being allowed, we have for all </span>j \\in J<span class="math"> that </span>j + n \\notin J<span class="math">. This means for any choice of </span>\\pmb{v}_0 \\in \\mathbb{F}^k<span class="math"> and </span>V \\in \\mathbb{F}^{t \\times k}<span class="math"> that when we choose random </span>\\pmb{r}_0 \\gets \\mathbb{F}^n<span class="math"> and </span>R \\gets \\mathbb{F}^{t \\times n}<span class="math"> we get uniformly random </span>\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_0; \\pmb{r}_0)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_J<span class="math"> and </span>\\tilde{\\mathsf{E}}_{\\mathcal{C}}(V; R)<span class="math">. Consequently, </span>E_{01}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_J, \\ldots, E_\\mu</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_J$ have the correct distribution.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Next, the simulator picks <span class="math">\\pmb{r}_{(\\gamma)} \\in \\mathbb{F}^n</span> and <span class="math">R_{(Q)} \\in \\mathbb{F}^{t \\times n}</span> one entry and column at a time. For all <span class="math">j</span> such that <span class="math">j \\notin J</span> and <span class="math">j + n \\notin J</span> the simulator picks random <span class="math">(\\pmb{r}_{(\\gamma)})_j \\gets \\mathbb{F}</span> and random <span class="math">R_j \\gets \\mathbb{F}^t</span>. For all <span class="math">j</span> such that <span class="math">j \\in J</span> or <span class="math">j + n \\in J</span>, the simulator then computes the unique <span class="math">(\\pmb{r}_{(\\gamma)})_j \\in \\mathbb{F}</span> and <span class="math">R_j \\in \\mathbb{F}^t</span> such that we get $\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{(\\gamma)}; \\pmb{r}_{(\\gamma)}) = \\pmb{e}_0</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_J + \\pmb{\\gamma} E</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_J<span class="math"> and </span>\\tilde{\\mathsf{E}}_{\\mathcal{C}}(V_{(Q)}; R_{(Q)}) = QE</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_J$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Finally, <span class="math">\\mathcal{S}</span> defines $E_{01}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{\\bar{J}}, \\ldots, E_{\\mu}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{\\bar{J}}<span class="math"> to be 0 matrices. It then picks </span>\\pmb{s}_1, \\ldots, \\pmb{s}_{\\mu}<span class="math"> at random and makes the commitments </span>\\pmb{c}_1, \\ldots, \\pmb{c}_{\\mu}<span class="math"> as in the protocol. For </span>j \\in J<span class="math"> we see that all the </span>\\pmb{c}_i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_j<span class="math"> commitments are computed as in the real execution from values that have the same distribution as in a real proof. Hence, they will have the correct distribution. The </span>\\pmb{c}_i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_j<span class="math"> s for </span>j \\notin J$ are commitments to different values than in a real proof. However, by the computational (statistical) hiding property of the commitment scheme, they have a distribution that is computationally (statistically) indistinguishable from the correct distribution.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">4.3 Efficiency</p>

    <p class="text-gray-300">We will now estimate the efficiency of a compiled proof of knowledge <span class="math">(\\mathcal{K},\\mathcal{P},\\mathcal{V})</span> for <span class="math">(pp,u,w)\\in \\mathcal{R}</span>. Let <span class="math">\\mu</span> be the number of rounds, <span class="math">t = \\sum_{i = 1}^{\\mu}t_i</span>, <span class="math">k,n</span> given in <span class="math">\\mathsf{E}_{\\mathcal{C}}</span>, and qc the query complexity, i.e., <span class="math">Q\\in \\mathbb{F}^{qc\\times t}</span>. Let <span class="math">T_{\\mathcal{P}_{\\mathrm{ILC}}}</span> be the running time of <span class="math">\\mathcal{P}_{\\mathrm{ILC}}(pp_{\\mathrm{ILC}},u,w)</span>, <span class="math">T_{\\tilde{\\mathsf{E}}_{\\mathcal{C}}}(k)</span> be the encoding time for a vector in <span class="math">\\mathbb{F}^k</span>, <span class="math">T_{\\mathrm{Commit}}(t_i)</span> be</p>

    <p class="text-gray-300">the time to commit to  <span class="math">t_i</span>  field elements,  <span class="math">T_{\\mathrm{Mmul}}(\\mathrm{qc},t,b)</span>  be the time it takes to multiply matrices in  <span class="math">\\mathbb{F}^{\\mathrm{qc}\\times t}</span>  and  <span class="math">\\mathbb{F}^{t\\times b}</span> , and  <span class="math">T_{\\mathcal{V}_{\\mathrm{ILC}}}</span>  is the running time of  <span class="math">\\mathcal{V}_{\\mathrm{ILC}}(pp_{\\mathrm{ILC}},u)</span> . Let furthermore  <span class="math">C_{\\mathrm{ILC}}</span>  be the communication from the verifier to the prover in  <span class="math">\\langle \\mathcal{P}_{\\mathrm{ILC}}\\xleftrightarrow{\\mathrm{ILC}}\\mathcal{V}_{\\mathrm{ILC}}\\rangle</span> ,  <span class="math">C_{\\mathrm{Commit}}(t_i)</span>  be the combined size of commitment and randomness for a message consisting of  <span class="math">t_i</span>  field elements. We give the dominant factors of efficiency of the compiled proof in Fig. 7. The estimates presume  <span class="math">T_{\\mathrm{Commit}}(t_1 + 1)</span>  is not too far from  <span class="math">T_{\\mathrm{Commit}}(t_1)</span> .</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Measure</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Cost</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Prover Computation</td>

            <td class="px-3 py-2 border-b border-gray-700">TPILC+t·TEC(k)+2n·∑i=1μTCommit(ti)+TMmul(qc+1,t,k+n)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Verifier Computation</td>

            <td class="px-3 py-2 border-b border-gray-700">TVILC+(qc+1)·TEC(k)+2λ·∑i=1μTCommit(ti)+TMmul(qc+1,t,2λ)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Communication</td>

            <td class="px-3 py-2 border-b border-gray-700">CILC+2n·∑i=1μTCommit(ti)+(qc+1)·(k+n)+(qc+1)·t+2λ·t</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Round Complexity</td>

            <td class="px-3 py-2 border-b border-gray-700">μ+2</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Fig. 7: Efficiency of a compiled proof of knowledge  <span class="math">(\\mathcal{K},\\mathcal{P},\\mathcal{V})</span>  for  <span class="math">(pp,u,w)\\in \\mathcal{R}</span> . Communication is measured in field elements and computation in field operations.</p>

    <p class="text-gray-300">Putting together the sequence of proofs and sub-proofs in the ILC model, compiling into the standard model using an error-correcting code and a commitment scheme, and finally instantiating the commitment scheme yields special honest-verifier zero-knowledge proofs for arithmetic circuit satisfiability.</p>

    <p class="text-gray-300">Let us now analyze the efficiency of the compilation we get from Fig. 7. If the error-correcting code is linear-time computable, we get  <span class="math">T_{\\tilde{\\mathbf{E}}_C}(k) = \\mathcal{O}(k)</span>  operations in  <span class="math">\\mathbb{F}</span> , and with the code from Druk and Ishai [DI14] is will actually be  <span class="math">\\mathcal{O}(k)</span>  additions in  <span class="math">\\mathbb{F}</span> .</p>

    <p class="text-gray-300">Let us now plug in the efficiency of our ILC proof given in Fig. 4 into the efficiency formulas in Fig. 7. We use  <span class="math">k \\approx \\sqrt{N}</span> ,  <span class="math">n = \\mathcal{O}(k)</span> ,  <span class="math">t = \\mathcal{O}(\\sqrt{N})</span> ,  <span class="math">\\mu = \\mathcal{O}(\\log \\log N)</span> ,  <span class="math">\\mathrm{qc} = 20 = \\mathcal{O}(1)</span>  and assume  <span class="math">k \\gg \\lambda</span> . We then get prover computation  <span class="math">T_{\\mathcal{P}} = \\mathcal{O}(N)</span>  multiplications  <span class="math">+2n \\cdot \\sum_{i=1}^{\\mu} T_{\\mathrm{Commit}}(t_i)</span> , verifier computation  <span class="math">T_{\\mathcal{V}} = \\mathcal{O}(N)</span>  additions  <span class="math">+2\\lambda \\cdot \\sum_{i=1}^{\\mu} T_{\\mathrm{Commit}}(t_i)</span> , communication  <span class="math">C = 2n \\cdot \\sum_{i=1}^{\\mu} C_{\\mathrm{Commit}}(t_i) + \\mathcal{O}(\\lambda \\sqrt{N})</span>  field elements, and round complexity  <span class="math">\\mu = \\mathcal{O}(\\log \\log N)</span> .</p>

    <p class="text-gray-300">Instantiating with the commitment scheme from Applebaum et al. [AHI+17] we get computational knowledge soundness and statistical SHVZK. The commitments are compact, a commitment has size  <span class="math">C_{\\mathrm{Commit}}(t_i) = \\mathrm{poly}(\\lambda)</span>  regardless of the message size, giving us sub-linear communication. The commitments can be computed in linear time at a cost of  <span class="math">T_{\\mathrm{Commit}}(t_i) = \\mathrm{poly}(\\lambda) + \\mathcal{O}(t_i)</span>  additions., giving us linear time computation for prover and verifier.</p>

    <p class="text-gray-300">Instantiating with the commitment from Ishai et al. [IKOS08] we get statistical knowledge soundness and computational SHVZK. The commitments have</p>

    <p class="text-gray-300">linear size  <span class="math">C_{\\mathrm{Commit}}(t_i) = \\mathrm{poly}\\lambda + t_i</span>  giving us linear communication overall. The commitments can be computed in linear time at a cost of  <span class="math">T_{\\mathrm{Commit}}(t_i) = \\mathrm{poly}(\\lambda) + \\mathcal{O}(t_i)</span>  additions, again giving us linear time computation for prover and verifier.</p>

    <p class="text-gray-300">We summarize the costs in Table 8 below and conclude that we now have SHVZK proof systems for arithmetic circuit satisfiability where the prover computation only has constant overhead compared to direct computation of the arithmetic circuit given the witness. Moreover, the verifier computation is a linear number of additions, which is proportional to the time it takes simply to read the instance.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Measure\\Instantiation</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Using [AHI+17]</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Using [IKOS08]</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Prover Computation</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) multiplications in F</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) multiplications in F</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Verifier Computation</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) additions in F</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) additions in F</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Communication</td>

            <td class="px-3 py-2 border-b border-gray-700">poly(λ)√N field elements</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) field elements</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Round Complexity</td>

            <td class="px-3 py-2 border-b border-gray-700">O(log log N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(log log N)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Completeness</td>

            <td class="px-3 py-2 border-b border-gray-700">Perfect</td>

            <td class="px-3 py-2 border-b border-gray-700">Perfect</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Knowledge Soundness</td>

            <td class="px-3 py-2 border-b border-gray-700">Computational</td>

            <td class="px-3 py-2 border-b border-gray-700">Statistical</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">SHVZK</td>

            <td class="px-3 py-2 border-b border-gray-700">Statistical</td>

            <td class="px-3 py-2 border-b border-gray-700">Computational</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Fig. 8: Efficiency of two instantiations of our SHVZK proofs.</p>

    <p class="text-gray-300"><span class="math">\\left[\\mathrm{AHI}^{+}17\\right]</span>  B. Applebaum, N. Haramaty, Y. Ishai, E. Kushilevitz, and V. Vaikuntanathan. Low-complexity cryptographic hash functions. Cryptology ePrint Archive, Report 2017/036, 2017. http://eprint.iacr.org/2017/036. <span class="math">\\left[\\mathrm{BCC}^{+}16\\right]</span>  J. Bootle, A. Cerulli, P. Chaidos, J. Groth, and C. Petit. Efficient zero-knowledge arguments for arithmetic circuits in the discrete log setting. In Advances in Cryptology-EUROCRYPT, LNCS. Springer, 2016. [BCCT12] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer. From extractable collision resistance to succinct non-interactive arguments of knowledge, and back again. In Innovations in Theoretical Computer Science Conference-ITCS. ACM, 2012. [BCCT13] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer. Recursive composition and bootstrapping for SNARKS and proof-carrying data. In ACM Symposium on Theory of Computing-STOC. ACM, 2013. <span class="math">\\left[\\mathrm{BCG}^{+}13\\right]</span>  E. Ben-Sasson, A. Chiesa, D. Genkin, E. Tromer, and M. Virza. SNARKs for C: Verifying program executions succinctly and in zero knowledge. In Advances in Cryptology-CRYPTO, LNCS. Springer, 2013. <span class="math">\\left[\\mathrm{BCI}^{+}13\\right]</span>  N. Bitansky, A. Chiesa, Y. Ishai, R. Ostrovsky, and O. Paneth. Erratum: Succinct non-interactive arguments via linear interactive proofs. In Theory of Cryptography-TCC, LNCS. Springer, 2013.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[BFM88] M. Blum, P. Feldman, and S. Micali. Non-interactive zero-knowledge and its applications. In ACM Symposium on Theory of Computing–STOC. ACM, 1988.</li>

      <li>[BJY97] M. Bellare, M. Jakobsson, and M. Yung. Round-optimal zero-knowledge arguments based on any one-way function. In Advances in Cryptology–EUROCRYPT, LNCS. Springer, 1997.</li>

      <li>[BR93] M. Bellare and P. Rogaway. Random oracles are practical: A paradigm for designing efficient protocols. In ACM Conference on Computer and Communications Security (ACM CCS). ACM, 1993.</li>

      <li>[BSCG^{+}16] E. Ben-Sasson, A. Chiesa, A. Gabizon, M. Riabzev, and N. Spooner. Short interactive oracle proofs with constant query complexity, via composition and sumcheck. In Electronic Colloquium on Computational Complexity (ECCC). 2016.</li>

      <li>[BSCGV16] E. Ben-Sasson, A. Chiesa, A. Gabizon, and M. Virza. Quasi-linear size zero knowledge from linear-algebraic PCPs. In Theory of Cryptography–TCC, LNCS. Springer, 2016.</li>

      <li>[BSCS16] E. Ben-Sasson, A. Chiesa, and N. Spooner. Interactive oracle proofs. In Theory of Cryptography–TCC, LNCS. Springer, 2016.</li>

      <li>[CD98] R. Cramer and I. Damgård. Zero-knowledge proofs for finite field arithmetic; or: Can zero-knowledge be for free? In Advances in Cryptology–CRYPTO, LNCS. Springer, 1998.</li>

      <li>[CDD^{+}16] I. Cascudo, I. Damgård, B. David, N. Döttling, and J. B. Nielsen. Rate-1, linear time and additively homomorphic UC commitments. In Advances in Cryptology–CRYPTO, LNCS. Springer, 2016.</li>

      <li>[CDP12] R. Cramer, I. Damgård, and V. Pastro. On the amortized complexity of zero knowledge protocols for multiplicative relations. In Information Theoretic Security–ICITS, LNCS. Springer, 2012.</li>

      <li>[CDS94] R. Cramer, I. Damgård, and B. Schoenmakers. Proofs of partial knowledge and simplified design of witness hiding protocols. In Advances in Cryptology–CRYPTO, LNCS. Springer, 1994.</li>

      <li>[CGM16] M. Chase, C. Ganesh, and P. Mohassel. Efficient zero-knowledge proof of algebraic and non-algebraic statements with applications to privacy preserving credentials. Cryptology ePrint Archive, Report 2016/583, 2016. http://eprint.iacr.org/2016/583.</li>

      <li>[Dam00] I. Damgård. Efficient concurrent zero-knowledge in the auxiliary string model. In Advances in Cryptology–EUROCRYPT, LNCS. Springer, 2000.</li>

      <li>[DI06] I. Damgård and Y. Ishai. Scalable secure multiparty computation. In Advances in Cryptology–CRYPTO, LNCS. Springer, 2006.</li>

      <li>[DI14] E. Druk and Y. Ishai. Linear-time encodable codes meeting the Gilbert-Varshamov bound and their cryptographic applications. In Innovations in Theoretical Computer Science Conference–ITCS. ACM, 2014.</li>

      <li>[DIK10] I. Damgård, Y. Ishai, and M. Krøigaard. Perfectly secure multiparty computation and the computational overhead of cryptography. In Advances in Cryptology–EUROCRYPT, LNCS. Springer, 2010.</li>

      <li>[FNO15] T. K. Frederiksen, J. B. Nielsen, and C. Orlandi. Privacy-free garbled circuits with applications to efficient zero-knowledge. In Advances in Cryptology–EUROCRYPT, LNCS. Springer, 2015.</li>

      <li>[FS86] A. Fiat and A. Shamir. How to prove yourself: Practical solutions to identification and signature problems. In Advances in Cryptology–CRYPTO, LNCS. Springer, 1986.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[Gal62] R. G. Gallager. Low-density parity-check codes. IRE Trans. Information Theory, 8(1):21, 1962.</li>

      <li>[GGI^{+}14] C. Gentry, J. Groth, Y. Ishai, C. Peikert, A. Sahai, and A. Smith. Using fully homomorphic hybrid encryption to minimize non-interative zero-knowledge proofs. Journal of Cryptology, 2014.</li>

      <li>[GGPR13] R. Gennaro, C. Gentry, B. Parno, and M. Raykova. Quadratic span programs and succinct NIZKs without PCPs. In Advances in Cryptology–EUROCRYPT, LNCS. Springer, 2013.</li>

      <li>[GI01] V. Guruswami and P. Indyk. Expander-based constructions of efficiently decodable codes. In Symposium on Foundations of Computer Science–FOCS. IEEE Computer Society, 2001.</li>

      <li>[GI02] V. Guruswami and P. Indyk. Near-optimal linear-time codes for unique decoding and new list-decodable codes over smaller alphabets. In ACM Symposium on Theory of Computing–STOC. ACM, 2002.</li>

      <li>[GI03] V. Guruswami and P. Indyk. Linear time encodable and list decodable codes. In ACM Symposium on Theory of Computing–STOC. ACM, 2003.</li>

      <li>[GI05] V. Guruswami and P. Indyk. Linear-time encodable/decodable codes with near-optimal rate. IEEE Trans. Information Theory, 51(10):3393, 2005.</li>

      <li>[GKR08] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum. Delegating computation: interactive proofs for muggles. In ACM Symposium on Theory of Computing–STOC. ACM, 2008.</li>

      <li>[GMR85] S. Goldwasser, S. Micali, and C. Rackoff. The knowledge complexity of interactive proof-systems (extended abstract). In ACM Symposium on Theory of Computing–STOC. ACM, 1985.</li>

      <li>[GQ88] L. C. Guillou and J.-J. Quisquater. A practical zero-knowledge protocol fitted to security microprocessor minimizing both trasmission and memory. In Advances in Cryptology–EUROCRYPT, LNCS. Springer, 1988.</li>

      <li>[Gro04] J. Groth. Honest verifier zero-knowledge arguments applied. BRICS, 2004.</li>

      <li>[Gro09] J. Groth. Linear algebra with sub-linear zero-knowledge arguments. In Advances in Cryptology–CRYPTO, LNCS. Springer, 2009.</li>

      <li>[Gro10] J. Groth. Short pairing-based non-interactive zero-knowledge arguments. In Advances in Cryptology–ASIACRYPT, LNCS. Springer, 2010.</li>

      <li>[Gro16] J. Groth. On the size of pairing-based non-interactive arguments. In Advances in Cryptology–EUROCRYPT, LNCS. Springer, 2016.</li>

      <li>[GSV98] O. Goldreich, A. Sahai, and S. Vadhan. Honest-verifier statistical zero-knowledge equals general statistical zero-knowledge. In ACM Symposium on Theory of Computing–STOC. ACM, 1998.</li>

      <li>[HM96] S. Halevi and S. Micali. Practical and provably-secure commitment schemes from collision-free hashing. In Advances in Cryptology–CRYPTO, vol. 1109 of LNCS. Springer, 1996.</li>

      <li>[HMR15] Z. Hu, P. Mohassel, and M. Rosulek. Efficient zero-knowledge proofs of non-algebraic statements with sublinear amortized cost. In Advances in Cryptology–CRYPTO, LNCS. Springer, 2015.</li>

      <li>[IKOS08] Y. Ishai, E. Kushilevitz, R. Ostrovsky, and A. Sahai. Cryptography with constant computational overhead. In ACM Symposium on Theory of Computing–STOC. ACM, 2008.</li>

      <li>[IKOS09] Y. Ishai, E. Kushilevitz, R. Ostrovsky, and A. Sahai. Zero-knowledge proofs from secure multiparty computation. SIAM Journal on Computing, 39(3):1121, 2009.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[JKO13] M. Jawurek, F. Kerschbaum, and C. Orlandi. Zero-knowledge using garbled circuits: how to prove non-algebraic statements efficiently. In ACM Conference on Computer and Communications Security (ACM CCS). ACM, 2013.</li>

      <li>[Kil92] J. Kilian. A note on efficient zero-knowledge proofs and arguments. In ACM Symposium on Theory of Computing–STOC. ACM, 1992.</li>

      <li>[KR08] Y. T. Kalai and R. Raz. Interactive PCP. In Automata, Languages and Programming: International Colloquium – ICALP, LNCS. Springer, 2008.</li>

      <li>[MP03] D. Micciancio and E. Petrank. Simulatable commitments and efficient concurrent zero-knowledge. In Advances in Cryptology–EUROCRYPT, LNCS. Springer, 2003.</li>

      <li>[MRS17] P. Mohassel, M. Rosulek, and A. Scafuro. Sublinear zero-knowledge arguments for RAM programs. In Advances in Cryptology–EUROCRYPT, LNCS. Springer, 2017.</li>

      <li>[PHGR13] B. Parno, J. Howell, C. Gentry, and M. Raykova. Pinocchio: Nearly practical verifiable computation. In IEEE Symposium on Security and Privacy. IEEE Computer Society, 2013.</li>

      <li>[Sch91] C.-P. Schnorr. Efficient signature generation by smart cards. Journal of Cryptology, 4(3):161, 1991.</li>

      <li>[Spi95] D. A. Spielman. Linear-time encodable and decodable error-correcting codes. In ACM Symposium on Theory of Computing–STOC. ACM, 1995.</li>

    </ul>

    <p class="text-gray-300">We will now give full descriptions of all the sub-proofs used in Section 3. Some of the sub-proofs require additional sub-proofs, the full structure of the arithmetic circuit satisfiability proof in the ILC model is given in Fig. 9.</p>

    <p class="text-gray-300">!<a href="img-3.jpeg">img-3.jpeg</a> Fig. 9: ILC proof for arithmetic circuit satisfiability decomposed into sub-proofs.</p>

    <p class="text-gray-300">Many of the sub-proofs are presented as stand-alone proofs, but when run as part of a larger arithmetic circuit protocol, it may be that certain vectors will already have been committed to the ILC channel. This is emphasized by putting square brackets around committed values. As most of the proofs involves relations over previously committed vectors, we introduce a new notation for them. A relation  <span class="math">\\mathcal{R}</span>  consists of pairs  <span class="math">(pp,u)</span>  for which instances  <span class="math">u</span>  can contain committed vectors, denoted by the presence of square brackets around the vectors. Whenever the prover  <span class="math">\\mathcal{P}</span>  gets as input a pair  <span class="math">(pp,u)</span> , we use the bracket notation to indicate that she knows the content of committed elements in  <span class="math">u</span> . Differently, we use the bracket notation to denote that the verifier  <span class="math">\\mathcal{V}</span>  does not learn what is inside the commitments, apart that these are already stored in the ILC channel and how many vectors there are.</p>

    <p class="text-gray-300">In the proof of knowledge soundness of each sub-protocol, we assume that the knowledge extractor for the sub-protocols will have access to any values that the prover has committed to as part of the larger arithmetic circuit protocol.</p>

    <p class="text-gray-300">Next, we give a proof for checking consistency of committed vectors with values in the statement. In this proof the prover  <span class="math">\\mathcal{P}_{\\mathrm{eq}}</span>  simply commits to a set of vectors by sending (commit,  <span class="math">\\pmb{u}_1,\\dots ,\\pmb{u}_t</span> ) to the ILC. As we use this sub-proof as a building</p>

    <p class="text-gray-300">block for more complex proofs, the vectors will be already stored in the ILC at earlier stages of the proof, thus the prover is not required any further action. Let  <span class="math">U = (\\pmb{u}_i)_{i=1}^t</span> , we denote with  <span class="math">[U]</span>  the commitments stored in the ILC. The description of the verifier  <span class="math">\\mathcal{V}_{\\mathrm{eq}}</span>  is given in Figure 10. The verifier asks for a random linear combination of the corresponding vectors and checks it against the values in the statement. The corresponding relation is</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal {R} _ {\\mathrm {e q}} = \\left\\{ \\begin{array}{c} (p p _ {\\mathrm {I L C}}, u) = ((\\mathbb {F}, k), (\\boldsymbol {u} _ {1}, \\ldots , \\boldsymbol {u} _ {t}, [ U ])): \\\\ \\boldsymbol {u} _ {1}, \\ldots , \\boldsymbol {u} _ {t} \\in \\mathbb {F} ^ {k} \\quad \\wedge \\quad U = (\\boldsymbol {u} _ {i}) _ {i = 1} ^ {t} \\end{array} \\right\\}.</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Peq((F,k),(u1,...,ut),[U])</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Psum((F,k),([A],[B],[C]))</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Do nothing</td>

            <td class="px-3 py-2 border-b border-gray-700">- Do nothing</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Veq((F,k),(u1,...,ut),[U])</td>

            <td class="px-3 py-2 border-b border-gray-700">Vsum((F,k),([A],[B],[C]))</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Pick random x← F</td>

            <td class="px-3 py-2 border-b border-gray-700">- Pick x← F and set</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Set X=(x1,...,xm)</td>

            <td class="px-3 py-2 border-b border-gray-700">X=(x1,...,xm,x1,...,xm,-x1,...,xm)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Query ILC on (open,X) and get response v</td>

            <td class="px-3 py-2 border-b border-gray-700">- Query ILC on (open,X) and get response v</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Return 1 if v = ∑j=1m xjuj, Return 0 otherwise</td>

            <td class="px-3 py-2 border-b border-gray-700">- Return 1 if v = 0, Return 0 otherwise</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Fig. 10: Left hand side has equality check; right hand side has sum check.</p>

    <p class="text-gray-300">Theorem 6.  <span class="math">(\\mathcal{K}_{\\mathrm{ILC}},\\mathcal{P}_{\\mathrm{eq}},\\mathcal{V}_{\\mathrm{eq}})</span>  is a proof system for the relation  <span class="math">\\mathcal{R}_{\\mathrm{eq}}</span>  in the ILC model with perfect completeness, statistical knowledge soundness with straight-line extraction and perfect special honest verifier zero-knowledge.</p>

    <p class="text-gray-300">Proof. The proof is perfectly complete, as it follows by inspection.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The proof has statistical knowledge soundness with straight-line extraction. This is because the knowledge extractor already has access to the committed vectors of  <span class="math">[U]</span> , having seen all messages sent between the prover  <span class="math">\\mathcal{P}_{\\mathrm{eq}}</span>  and the ILC. By the Schwartz-Zippel Lemma we have that if the committed vectors are not equal to the  <span class="math">\\pmb{u}_j</span> , then they pass the consistency check with probability at most  $\\frac{m}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}$ , which is negligible.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The proof is perfect zero-knowledge as the verifier knows the values in the statement and can compute the response directly.</p>

    <p class="text-gray-300">Efficiency. Since the prover is inactive, the efficiency is easy to analyze. There is no communication between prover and verifier, so the round complexity is  <span class="math">\\mu = 0</span> .</p>

    <p class="text-gray-300">The verifier makes a single query to the ILC channel, so the query complexity is  <span class="math">\\mathrm{qc} = 1</span> . The prover has computation time  <span class="math">T_{\\mathcal{P}_{\\mathrm{eq}}} = 0</span>  and commits to  <span class="math">t = 0</span>  vectors during the proof (we do not count the already committed vectors that are part of the instance).</p>

    <p class="text-gray-300">The computational cost of the verifier would be around  <span class="math">mk</span>  multiplications in  <span class="math">\\mathbb{F}</span>  if the verifier checks everything. Perhaps surprisingly, one can reduce the cost of this check to a linear number of additions  <span class="math">\\mathcal{O}(mk)</span>  in  <span class="math">\\mathbb{F}</span> . The verifier can achieve this by encoding both the response  <span class="math">\\pmb{v}</span>  and the vectors  <span class="math">\\pmb{u}_j</span>  using a linear error correcting code as the one in Theorem 1. Then, instead of checking the entire encoded vectors, he can perform the check only on a subset of positions of the codewords. This is made possible since the code has linear minimum distance.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TPeq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TVeq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">qc</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">#rounds</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">t</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">O(mk) additions in F</td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In this section, we introduce a proof of knowledge of matrices  <span class="math">A, B, C \\in \\mathbb{F}^{m \\times k}</span>  such that  <span class="math">A + B = C</span> . As for the previous sub-proof, we assume that the matrices have already been stored in the ILC, in which case the prover  <span class="math">\\mathcal{P}_{\\mathrm{sum}}</span>  is not required to do any further action. We let  <span class="math">[A], [B], [C]</span>  be the commitments to the rows of the matrices  <span class="math">A, B, C</span> , respectively. Moreover, we assume the prover committed the rows of the matrices in order, starting with all the rows of  <span class="math">A, B</span>  and then  <span class="math">C</span> . The verifier picks a challenge  <span class="math">x</span>  and queries the ILC on linear combinations the vectors, weighted on powers of the challenge. The idea is that entries in  <span class="math">A, B, C</span>  are associated with the same power of  <span class="math">x</span>  but the ones in  <span class="math">C</span>  have opposite sign. Therefore, we expect them to sum up to zero if  <span class="math">A + B - C = 0</span>  holds. The description of  <span class="math">\\mathcal{V}_{\\mathrm{sum}}</span>  is given in Figure 10 and the corresponding relation is</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal {R} _ {\\mathrm {s u m}} = \\left\\{ \\begin{array}{c} (p p _ {\\mathsf {I L C}}, u) = ((\\mathbb {F}, k), ([ A ], [ B ], [ C ])): \\\\ A, B, C \\in \\mathbb {F} ^ {m \\times k} \\quad \\wedge \\quad A + B = C \\end{array} \\right\\}.</span></div>

    <p class="text-gray-300">Theorem 7.  <span class="math">(\\mathcal{K}_{\\mathrm{ILC}},\\mathcal{P}_{\\mathrm{sum}},\\mathcal{V}_{\\mathrm{sum}})</span>  is a proof system for the relation  <span class="math">\\mathcal{R}_{\\mathrm{sum}}</span>  in the ILC model with perfect completeness, statistical knowledge soundness with straight-line extraction, and perfect special honest verifier zero-knowledge.</p>

    <p class="text-gray-300">Proof. The proof is perfectly complete, as it follows by inspection.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The proof has statistical knowledge soundness with straight-line extraction. This is because the knowledge extractor already has access to the committed vectors committed as  <span class="math">[A],[B]</span>  and  <span class="math">[C]</span> , having seen all messages sent between the prover and the ILC. By the Schwartz-Zippel Lemma, the probability that committed vectors not satisfying the addition gates pass the sum check is at most  $\\frac{m}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}$ , which is negligible.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The proof is perfect zero-knowledge as the verifier only sees the zero vector, which can be trivially simulated.</p>

    <p class="text-gray-300">Efficiency. The efficiency is easy to analyze and given in the table below. The verifier's computation is dominated by  <span class="math">m - 1</span>  multiplications required to compute the query.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TPsum</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TVsum</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">qc</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">#rounds</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">t</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">m-1 multiplications in F</td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We now describe a proof of knowledge of matrices  <span class="math">A, B, C \\in \\mathbb{F}^{\\mathfrak{m}\\mathfrak{n} \\times k}</span>  such that  <span class="math">A \\circ B = C</span> , where  <span class="math">A \\circ B</span>  is the Hadamard (entry-wise) product of the matrices. We assume that the prover has already committed to  <span class="math">A, B, C</span>  which we will write with square brackets in the instance  <span class="math">([A], [B], [C])</span> . The corresponding relation is</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal {R} _ {\\mathrm {p r o d}} = \\left\\{ \\begin{array}{c} (p p _ {\\mathrm {l L C}}, u) = ((\\mathbb {F}, k), ([ A ], [ B ], [ C ])): \\\\ A, B \\in \\mathbb {F} ^ {\\mathfrak {n m} \\times k} \\quad \\wedge \\quad A \\circ B = C \\end{array} \\right\\}.</span></div>

    <p class="text-gray-300">First, parse matrix  <span class="math">A</span>  as a collection of  <span class="math">\\mathfrak{mn}</span>  row vectors  <span class="math">\\pmb{a}_{i,j} \\in \\mathbb{F}^k</span>  for  <span class="math">0 \\leq i \\leq \\mathfrak{m} - 1</span> ,  <span class="math">1 \\leq j \\leq \\mathfrak{n}</span> , and similarly obtain  <span class="math">\\pmb{b}_{i,j}</span>  and  <span class="math">\\pmb{c}_{i,j}</span> . If  <span class="math">A \\circ B = C</span> , then  <span class="math">\\pmb{a}_{i,j} \\circ \\pmb{b}_{i,j} = \\pmb{c}_{i,j}</span>  for  <span class="math">0 \\leq i \\leq \\mathfrak{m} - 1</span> ,  <span class="math">1 \\leq j \\leq \\mathfrak{n}</span> .</p>

    <p class="text-gray-300">Without loss of generality we assume  <span class="math">\\mathfrak{m} = 2^{\\mu}</span>  for some integer  <span class="math">\\mu</span> . We will use  <span class="math">\\mu</span>  challenges  <span class="math">X_0, \\ldots, X_{\\mu-1}</span>  to compress  <span class="math">2\\mathfrak{mn}</span>  vectors  <span class="math">\\pmb{a}_{i,j}, \\pmb{b}_{i,j}</span>  of length  <span class="math">k</span> , corresponding to left and right inputs of multiplication gates, into  <span class="math">2\\mathfrak{m}</span>  vectors  <span class="math">\\hat{\\pmb{a}}_j, \\hat{\\pmb{b}}_j</span>  of the same length. The compressed vectors are computed by inserting vectors  <span class="math">\\pmb{a}_{i,j}</span>  (resp.  <span class="math">\\pmb{b}_{i,j}</span> ) into distinct coefficients of  <span class="math">\\mathfrak{n}</span>  multivariate polynomials in  <span class="math">X_0, \\ldots, X_{\\mu-1}</span> . More precisely, vector  <span class="math">\\pmb{a}_{i,j}</span>  is positioned in the  <span class="math">j</span> th polynomial as coefficient of  <span class="math">X_0^{i_0} \\cdots X_{\\mu-1}^{i_{\\mu-1}}</span> , where  <span class="math">i_{\\mu-1} i_{\\mu-2} \\ldots i_0</span>  are the digits of the binary expansion of  <span class="math">i</span> . The  <span class="math">2\\mathfrak{n}</span>  vectors of length  <span class="math">k</span>  are then obtained by evaluating the multivariate polynomials into challenges  <span class="math">(x_0, x_1, \\ldots, x_{\\mu-1})</span> , as shown in what follows.</p>

    <div class="my-4 text-center"><span class="math-block">\\dot {\\boldsymbol {a}} _ {j} (x _ {0}, \\dots , x _ {\\mu - 1}) = \\sum_ {i = 0} ^ {\\mathfrak {m} - 1} \\boldsymbol {a} _ {i, j} y ^ {i} x _ {0} ^ {i _ {0}} x _ {1} ^ {i _ {1}} \\dots x _ {\\mu - 1} ^ {i _ {\\mu - 1}}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\dot {\\boldsymbol {b}} _ {j} (x _ {0}, \\dots , x _ {\\mu - 1}) = \\sum_ {i = 0} ^ {\\mathfrak {m} - 1} \\boldsymbol {b} _ {i, j} x _ {0} ^ {- i _ {0}} x _ {1} ^ {- i _ {1}} \\dots x _ {\\mu - 1} ^ {- i _ {\\mu - 1}}</span></div>

    <p class="text-gray-300">for  <span class="math">1 \\leq j \\leq \\mathfrak{n}</span>  and  <span class="math">(i_0, i_1, \\ldots, i_{\\mu - 1}) \\in \\{0, 1\\}^\\mu</span>  such that  <span class="math">i = \\sum_{t=0}^{\\mu - 1} 2^{i_t}</span> . These expressions can be efficiently evaluated. More details are given in the efficiency analysis following the protocol.</p>

    <p class="text-gray-300">Following a similar process as above, we then embed the above <span class="math">2\\mathfrak{n}</span> vectors into the coefficients of two polynomials in <span class="math">X</span> of degree <span class="math">\\mathfrak{n}</span>.</p>

    <p class="text-gray-300"><span class="math">\\dot{\\bm{a}}(X,x_{0},\\ldots,x_{\\mu-1})</span> <span class="math">=\\sum_{j=1}^{\\mathfrak{n}}\\dot{\\bm{a}}_{j}(x_{0},\\ldots,x_{\\mu-1})y^{j\\mathfrak{m}}X^{j}</span> <span class="math">\\dot{\\bm{b}}(X,x_{0},\\ldots,x_{\\mu-1})</span> <span class="math">=\\sum_{j=1}^{\\mathfrak{n}}\\dot{\\bm{b}}_{j}(x_{0},\\ldots,x_{\\mu-1})X^{-j}</span></p>

    <p class="text-gray-300">Note that when we take the Hadamard product of the two vectors of polynomials, the Hadamard products <span class="math">\\dot{\\bm{a}}_{j}\\circ\\dot{\\bm{b}}_{j}</span> end up in the constant coefficient, i.e., <span class="math">X^{0}</span>. Similarly, all other <em>waste</em> products <span class="math">\\dot{\\bm{a}}_{j}\\circ\\dot{\\bm{b}}_{j^{\\prime}}</span>, for <span class="math">j\\neq j^{\\prime}</span>, end up in coefficients of other powers of <span class="math">X</span>. The verifier will check the following polynomial expression evaluated in a random challenge <span class="math">x</span>, connecting the Hadamard products of the <span class="math">\\bm{a}_{i,j}</span> and <span class="math">\\bm{b}_{i,j}</span> with the <span class="math">\\bm{c}_{i,j}</span>.</p>

    <p class="text-gray-300"><span class="math">\\dot{\\bm{a}}\\circ\\dot{\\bm{b}}=\\sum_{i=0,j=1}^{\\mathfrak{m}-1,\\mathfrak{n}}\\bm{c}_{i,j}y^{i+j\\mathfrak{m}}+\\sum_{t=0}^{\\mu-1}\\left(\\bm{d}_{t}^{+}x_{t}+\\bm{d}_{t}^{-}x_{t}^{-1}\\right)+\\sum_{r=1-\\mathfrak{n},r\\neq 0}^{\\mathfrak{n}-1}\\bm{e}_{r}x^{r}</span></p>

    <p class="text-gray-300">In this expression, the vectors <span class="math">\\bm{d}_{j}^{+},\\bm{d}_{j}^{-}</span> are compression factors to make up for the lossy compression, and the <span class="math">\\bm{e}_{r}</span> are coefficients containing <em>waste</em> Hadamard products. Observe that different Hadamard products are separated by different powers of <span class="math">y</span>.</p>

    <p class="text-gray-300">Finally, note that the polynomials chosen above leak information about the wire values, so we must also incorporate some random blinders into the real protocol to achieve zero-knowledge.</p>

    <p class="text-gray-300">The proof is presented as a stand-alone protocol, but when run as part of a larger arithmetic circuit proof, the vectors <span class="math">\\bm{a}_{i,j},\\bm{b}_{i,j}</span> and <span class="math">\\bm{c}_{i,j}</span> will already have been sent to ILC. This is emphasized by putting square brackets around committed values.</p>

    <h3 id="sec-25" class="text-xl font-semibold mt-8">Formal Description</h3>

    <p class="text-gray-300">Next, we provide a formal description of the proof of knowledge of committed matrices satisfying Hadamard product relation <span class="math">\\mathcal{R}_{\\mathrm{prod}}</span>.</p>

    <h6 id="sec-26" class="text-base font-medium mt-4">Proof:</h6>

    <p class="text-gray-300">Instance: The prover has already sent <span class="math">[\\bm{a}_{i,j},\\bm{b}_{i,j},\\bm{c}_{i,j}]_{i=0,j=1}^{\\mathfrak{m}-1,\\mathfrak{n}}</span> to the ILC channel.</p>

    <p class="text-gray-300"><span class="math">\\mathcal{P}_{\\mathrm{prod}}\\rightarrow\\texttt{ILC}</span>: The prover picks <span class="math">\\dot{\\bm{a}}_{0},\\dot{\\bm{b}}_{0}\\leftarrow\\mathbb{F}^{k}</span>.</p>

    <p class="text-gray-300">The prover computes <span class="math">\\dot{\\bm{c}}_{0}=\\dot{\\bm{a}}_{0}\\circ\\dot{\\bm{b}}_{0}</span>.</p>

    <p class="text-gray-300">The prover sends <span class="math">\\dot{\\bm{a}}_{0},\\dot{\\bm{b}}_{0},\\dot{\\bm{c}}_{0}</span> to ILC.</p>

    <p class="text-gray-300">ILC<span class="math">\\leftarrow\\mathcal{V}_{\\mathrm{prod}}</span> : Verifier sends <span class="math">y\\leftarrow\\mathbb{F}^{\\times}</span> to ILC</p>

    <p class="text-gray-300">36</p>

    <p class="text-gray-300"><span class="math">\\mathcal{P}_{\\mathrm{prod}} \\to \\mathsf{ILC}</span>: The prover computes polynomials with vector coefficients in the variables <span class="math">X_0, \\ldots, X_{\\mu-1}</span>, where <span class="math">\\mathfrak{m} = 2^{\\mu}</span>. Here, <span class="math">i_0, \\ldots, i_{\\mu-1}</span> represent the digits of the binary expansion of <span class="math">i</span>.</p>

    <div class="my-4 text-center"><span class="math-block">\\dot{\\boldsymbol{a}}_j(X_0, \\dots, X_{\\mu-1}) = \\sum_{i=0}^{\\mathfrak{m}-1} \\boldsymbol{a}_{i,j} y^i X_0^{i_0} X_1^{i_1} \\dots X_{\\mu-1}^{i_{\\mu-1}}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\dot{\\boldsymbol{b}}_j(X_0, \\dots, X_{\\mu-1}) = \\sum_{i=0}^{\\mathfrak{m}-1} \\boldsymbol{b}_{i,j} X_0^{-i_0} X_1^{-i_1} \\dots X_{\\mu-1}^{-i_{\\mu-1}}</span></div>

    <p class="text-gray-300">for <span class="math">1 \\leq j \\leq \\mathfrak{n}</span>.</p>

    <p class="text-gray-300">The prover computes the following polynomials with vector coefficients in the variable <span class="math">X</span>.</p>

    <div class="my-4 text-center"><span class="math-block">\\dot{\\boldsymbol{a}}(X, X_0, \\dots, X_{\\mu-1}) = \\dot{\\boldsymbol{a}}_0 + \\sum_{j=1}^{\\mathfrak{n}} \\dot{\\boldsymbol{a}}_j(X_0, \\dots, X_{\\mu-1}) y^{j\\mathfrak{m}} X^j</span></div>

    <div class="my-4 text-center"><span class="math-block">\\dot{\\boldsymbol{b}}(X, X_0, \\dots, X_{\\mu-1}) = \\dot{\\boldsymbol{b}}_0 + \\sum_{j=1}^{\\mathfrak{n}} \\dot{\\boldsymbol{b}}_j(X_0, \\dots, X_{\\mu-1}) X^{-j}</span></div>

    <p class="text-gray-300">The prover writes the Hadamard product of the above vectors of polynomials</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} \\dot{\\boldsymbol{a}}(X, X_0, \\dots, X_{\\mu-1}) \\circ \\dot{\\boldsymbol{b}}(X, X_0, \\dots, X_{\\mu-1}) &amp;amp;= \\dot{\\boldsymbol{a}}_0 \\circ \\dot{\\boldsymbol{b}}_0 \\\\ &amp;amp;\\quad + \\sum_{i=0, j=1}^{\\mathfrak{m}-1, \\mathfrak{n}} \\boldsymbol{a}_{i,j} \\circ \\boldsymbol{b}_{i,j} y^{i+j\\mathfrak{m}} \\\\ &amp;amp;\\quad + \\boldsymbol{d}_0^+ X_0 + \\boldsymbol{d}_0^- X_0^{-1} \\\\ &amp;amp;\\quad + \\boldsymbol{d}_1^+(X_0) X_1 + \\boldsymbol{d}_1^-(X_0) X_1^{-1} \\\\ &amp;amp;\\quad \\vdots \\\\ &amp;amp;\\quad + \\boldsymbol{d}_{\\mu-1}^+(X_0, \\dots, X_{\\mu-2}) X_{\\mu-1} \\\\ &amp;amp;\\quad \\quad + \\boldsymbol{d}_{\\mu-1}^-(X_0, \\dots, X_{\\mu-2}) X_{\\mu-1}^{-1} \\\\ &amp;amp;\\quad + \\sum_{r=-\\mathfrak{n}, r\\neq0}^{\\mathfrak{n}} \\boldsymbol{e}_r(X_0, \\dots, X_{\\mu-1}) X^r \\end{aligned}</span></div>

    <p class="text-gray-300">The prover sends <span class="math">\\boldsymbol{d}_0^+, \\boldsymbol{d}_0^-</span> to ILC.</p>

    <p class="text-gray-300"><span class="math">\\mathsf{ILC} \\leftarrow \\mathcal{V}_{\\mathrm{prod}}</span>: The verifier sends <span class="math">x_0 \\leftarrow \\mathbb{F}^\\times</span> to ILC.</p>

    <p class="text-gray-300"><span class="math">\\mathcal{P}_{\\mathrm{prod}} \\to \\mathsf{ILC}</span>: The prover sends <span class="math">\\boldsymbol{d}_1^+ = \\boldsymbol{d}_1^+(x_0), \\boldsymbol{d}_1^- = \\boldsymbol{d}_1^-(x_0)</span> to ILC.</p>

    <p class="text-gray-300">For <span class="math">t = 1</span> to <span class="math">\\mu - 2</span>:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>ILC <span class="math">\\leftarrow \\mathcal{V}_{\\mathrm{prod}}</span>: The verifier sends <span class="math">x_{t} \\leftarrow \\mathbb{F}^{\\times}</span> to ILC</li>

      <li><span class="math">\\mathcal{P}_{\\mathrm{prod}} \\to \\mathrm{ILC}</span>: The prover sends <span class="math">\\pmb{d}_{t+1}^{+} = \\pmb{d}_{t+1}^{+}(x_0, \\ldots, x_t)</span> and <span class="math">\\pmb{d}_{t+1}^{-} = \\pmb{d}_{t+1}^{-}(x_0, \\ldots, x_t)</span> to ILC.</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\mathsf{ILC}\\gets \\mathcal{V}_{\\mathrm{prod}}</span>: The verifier sends <span class="math">x_{\\mu -1}\\gets \\mathbb{F}^{\\times}</span> to ILC</p>

    <p class="text-gray-300"><span class="math">\\mathcal{P}_{\\mathrm{prod}} \\to \\mathrm{ILC}</span>: The prover computes <span class="math">\\pmb{e}_r = \\pmb{e}_r(x_0, \\dots, x_{\\mu - 1})</span> for <span class="math">-\\mathfrak{n} \\leq r \\leq \\mathfrak{n}, r \\neq 0</span>.</p>

    <p class="text-gray-300">The prover sends <span class="math">\\{\\pmb{e}_r\\}_{r = -\\mathfrak{n},r\\neq 0}^{\\mathfrak{n}}</span> to ILC.</p>

    <p class="text-gray-300"><strong>Verification:</strong></p>

    <p class="text-gray-300"><span class="math">\\mathsf{ILC}\\gets \\mathcal{V}_{\\mathrm{prod}}</span>: The verifier selects <span class="math">x \\leftarrow \\mathbb{F}^{\\times}</span> uniformly at random. The verifier queries the ILC channel to get</p>

    <div class="my-4 text-center"><span class="math-block">\\dot {\\boldsymbol {a}} = \\quad \\dot {\\boldsymbol {a}} _ {0} + \\sum_ {i = 0, j = 1} ^ {\\mathfrak {m} - 1, \\mathfrak {n}} \\boldsymbol {a} _ {i, j} y ^ {i + j \\mathfrak {m}} x _ {0} ^ {i _ {0}} x _ {1} ^ {i _ {1}} \\dots x _ {\\mu - 1} ^ {i _ {\\mu - 1}} x ^ {j}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\dot {\\boldsymbol {b}} = \\quad \\dot {\\boldsymbol {b}} _ {0} + \\sum_ {i = 0, j = 1} ^ {\\mathfrak {m} - 1, \\mathfrak {n}} \\boldsymbol {b} _ {i, j} x _ {0} ^ {i _ {0}} x _ {1} ^ {i _ {1}} \\dots x _ {\\mu - 1} ^ {i _ {\\mu - 1}} x ^ {- j}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\dot {\\boldsymbol {c}} = \\quad \\dot {\\boldsymbol {c}} _ {0} + \\sum_ {i = 0, j = 1} ^ {\\mathfrak {m} - 1, \\mathfrak {n}} \\boldsymbol {c} _ {i, j} y ^ {i + j \\mathfrak {m}} + \\sum_ {t = 0} ^ {\\mu - 1} \\left(\\boldsymbol {d} _ {t} ^ {+} x _ {t} + \\boldsymbol {d} _ {t} ^ {-} x _ {t} ^ {- 1}\\right) + \\sum_ {r = - \\mathfrak {n}, r \\neq 0} ^ {\\mathfrak {n}} \\boldsymbol {e} _ {r} x ^ {r}</span></div>

    <p class="text-gray-300">The verifier then checks whether the following equation holds and in that case accepts.</p>

    <div class="my-4 text-center"><span class="math-block">\\dot {\\boldsymbol {a}} \\circ \\dot {\\boldsymbol {b}} \\stackrel {?} {=} \\dot {\\boldsymbol {c}}</span></div>

    <p class="text-gray-300"><strong>Security Analysis.</strong> Before analysing the security of the above protocol, we prove a variation of the Schwarz-Zippel Lemma. This will be used when analysing the knowledge soundness of both the Hadamard product proof and the double-shift proof described in the next section.</p>

    <p class="text-gray-300"><strong>Lemma 1.</strong> Let <span class="math">\\mathbb{F}</span> be a field. Let <span class="math">P</span> be a function of the following form, where <span class="math">p_{0,i_0}</span> are constant values, and <span class="math">p_{1,i_1}(Z_0),\\ldots ,p_{u,i_u}(Z_0,\\ldots ,Z_{u - 1})</span> are arbitrary functions and not necessarily polynomials.</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} P (Z _ {0}, \\dots , Z _ {u}) = \\sum_ {i _ {0} = - d _ {0}} ^ {d _ {0}} p _ {0, i _ {0}} Z _ {0} ^ {i _ {0}} + \\sum_ {i _ {1} = - d _ {1}, i _ {1} \\neq 0} ^ {d _ {1}} p _ {1, i _ {1}} (Z _ {0}) Z _ {1} ^ {i _ {1}} \\\\ + \\dots + \\sum_ {i _ {u} = - d _ {u}, i _ {u} \\neq 0} ^ {d _ {u}} p _ {u, i _ {u}} \\left(Z _ {0}, \\dots , Z _ {u - 1}\\right) Z _ {u} ^ {i _ {u}} \\\\ \\end{array}</span></div>

    <p class="text-gray-300">Let <span class="math">S</span> be a finite subset of <span class="math">\\mathbb{F}^{\\times}</span>. Let <span class="math">z_{0},\\ldots,z_{u}</span> be selected at random independently and uniformly from <span class="math">S</span>. Let <span class="math">F</span> be the event that at least one value among <span class="math">p_{0,i_{0}}</span> or <span class="math">p_{s,i_{s}}(z_{0},\\ldots,z_{s-1})</span> is not zero.</p>

    <p class="text-gray-300">Then</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\Pr\\left[\\{P(z_{0},\\ldots,z_{u})=0\\}\\wedge F\\right]\\leq\\frac{\\sum_{t=0}^{u}(2d_{t}+1)}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-27" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">We prove the lemma by induction on <span class="math">u</span>. The case <span class="math">u=0</span> follows from the fact that a Laurent polynomial of degree <span class="math">(2d_{0}+1)</span> has at most <span class="math">(2d_{0}+1)</span> roots.</p>

    <p class="text-gray-300">Assume that the result holds for <span class="math">u-1</span>. We prove the lemma for <span class="math">u</span>. Write</p>

    <p class="text-gray-300"><span class="math">P(Z_{0},\\ldots,Z_{u})=Q(Z_{0},\\ldots,Z_{u-1})+\\sum_{i_{u}=-d_{u},i_{u}\\neq 0}^{d_{u}}p_{u,i_{u}}(Z_{0},\\ldots,Z_{u-1})Z_{u}^{i_{u}}</span></p>

    <p class="text-gray-300">For fixed values of <span class="math">z_{0},\\ldots,z_{u-1}</span>, this is a polynomial of degree <span class="math">d_{u}</span> in <span class="math">Z_{u}</span>. Let <span class="math">G</span> be the event that <span class="math">P</span> is the zero polynomial in <span class="math">Z_{u}</span>. Let <span class="math">F_{P}</span> and <span class="math">F_{Q}</span> be the event <span class="math">F</span> interpreted in the obvious way for <span class="math">P</span> and <span class="math">Q</span>.</p>

    <p class="text-gray-300"><span class="math">\\Pr\\left[\\{P(z_{0},\\ldots,z_{u})=0\\}\\wedge F_{P}\\right]</span> <span class="math">=\\Pr\\left[\\{P(z_{0},\\ldots,z_{u})=0\\}\\wedge F_{P}\\wedge G\\right]</span> <span class="math">+\\Pr\\left[\\{P(z_{0},\\ldots,z_{u})=0\\}\\wedge F_{P}\\wedge\\neg G\\right]</span></p>

    <p class="text-gray-300">If <span class="math">G</span> holds, then <span class="math">P</span> is the zero polynomial in <span class="math">Z_{u}</span>, so since <span class="math">Q</span> is the constant term, then <span class="math">Q</span> is necessarily zero. On the other hand, if <span class="math">G</span> and <span class="math">F_{P}</span> hold simultaneously, then each value <span class="math">p_{u,i_{u}}(z_{0},\\ldots,z_{u-1})</span> must be zero, so the non-zero value must occur among <span class="math">p_{0,i_{0}}</span> or <span class="math">p_{s,i_{s}}(z_{0},\\ldots,z_{s-1})</span> for <span class="math">s&lt;u</span>. Therefore, <span class="math">F_{Q}</span> holds. We use these facts to bound the first probability. We bound the second probability by simply removing the event <span class="math">F_{P}</span>.</p>

    <p class="text-gray-300"><span class="math">\\Pr\\left[\\{P(z_{0},\\ldots,z_{u})=0\\}\\wedge F\\right]</span> <span class="math">\\leq\\Pr\\left[\\{Q(z_{0},\\ldots,z_{u-1})=0\\}\\wedge F_{Q}\\right]</span> <span class="math">+\\Pr\\left[\\{P(z_{0},\\ldots,z_{u})=0\\}\\wedge\\neg G\\right]</span></p>

    <p class="text-gray-300">Apply the induction hypothesis to bound the first probability. To bound the second probability, observe that for any values of <span class="math">z_{0},\\ldots,z_{u-1}</span> such that <span class="math">\\neg G</span> holds, <span class="math">P</span> is a non-zero Laurent polynomial of degree at most <span class="math">(2d_{u}+1)</span> in <span class="math">Z_{u}</span>, and has at most <span class="math">(2d_{u}+1)</span> roots <span class="math">z_{u}</span>. The result follows. ∎</p>

    <h6 id="sec-28" class="text-base font-medium mt-4">Theorem 8.</h6>

    <p class="text-gray-300"><span class="math">(\\mathcal{K}_{\\mathsf{ILC}},\\mathcal{P}_{\\mathrm{prod}},\\mathcal{V}_{\\mathrm{prod}})</span> is a proof of knowledge for the relation <span class="math">\\mathcal{R}_{\\mathrm{prod}}</span> in the <span class="math">\\mathsf{ILC}</span> model with perfect completeness, statistical knowledge soundness with straight-line extraction and perfect special honest verifier zero-knowledge.</p>

    <h6 id="sec-29" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Perfect completeness follows by careful inspection of the polynomial expressions computed by the prover in the above protocol.</p>

    <p class="text-gray-300">Next, we show that the proof has statistical knowledge soundness with straight-line extraction. This is because the knowledge extractor already has access to</p>

    <p class="text-gray-300">the vectors committed as <span class="math">[A],[B]</span> and <span class="math">[C]</span>, having seen all messages sent between the prover and the ILC. It remains to show that for any deterministic malicious prover <span class="math">\\mathcal{P}^{*}_{\\mathrm{prod}}</span>, if the committed vectors are not a valid witness for <span class="math">\\mathcal{R}_{\\mathrm{prod}}</span>, then there is negligible probability of accept. Recall that verifier queries the following values.</p>

    <p class="text-gray-300"><span class="math">\\dot{\\bm{a}}</span> <span class="math">=\\dot{\\bm{a}}_{0}+\\sum_{i=0,j=1}^{\\mathfrak{m}-1,\\mathfrak{n}}\\bm{a}_{i,j}y^{i+j\\mathfrak{m}}x_{0}^{i_{0}}x_{1}^{i_{1}}\\ldots x_{\\mu-1}^{i_{\\mu-1}}x^{j}</span> <span class="math">\\dot{\\bm{b}}</span> <span class="math">=\\dot{\\bm{b}}_{0}+\\sum_{i=0,j=1}^{\\mathfrak{m}-1,\\mathfrak{n}}\\bm{b}_{i,j}x_{0}^{i_{0}}x_{1}^{i_{1}}\\ldots x_{\\mu-1}^{i_{\\mu-1}}x^{-j}</span> <span class="math">\\dot{\\bm{c}}</span> <span class="math">=\\dot{\\bm{c}}_{0}+\\sum_{i=0,j=1}^{\\mathfrak{m}-1,\\mathfrak{n}}\\bm{c}_{i,j}y^{i+j\\mathfrak{m}}+\\sum_{t=0}^{\\mu-1}\\left(\\bm{d}_{t}^{+}x_{t}+\\bm{d}_{t}^{-}x_{t}^{-1}\\right)+\\sum_{r=-\\mathfrak{n},r\\neq 0}^{\\mathfrak{n}}\\bm{e}_{r}x^{r}</span></p>

    <p class="text-gray-300">Now, substitute the expressions for <span class="math">\\dot{\\bm{a}}</span> and <span class="math">\\dot{\\bm{b}}</span> into the left-hand side of the third equality. The verifier only accepts if the equation holds. By assumption <span class="math">\\mathcal{P}^{*}_{\\mathrm{prod}}</span> is deterministic, and we know when it made it’s commitments. Hence, <span class="math">\\dot{\\bm{a}}_{0},\\dot{\\bm{b}}_{0}</span> and <span class="math">\\dot{\\bm{c}}_{0}</span> are constants, <span class="math">\\bm{d}_{0}^{+},\\bm{d}_{0}^{-}</span> are functions of <span class="math">y</span>, <span class="math">\\bm{d}_{1}^{+},\\bm{d}_{1}^{-}</span> are functions of <span class="math">y</span> and <span class="math">x_{0},\\ldots,x_{\\mu-1}</span> and the <span class="math">\\bm{e}_{r}</span> are functions of <span class="math">y,x_{0},\\ldots,x_{\\mu-1}</span>. We can now apply Lemma 1. The coefficient of <span class="math">y^{i+j\\mathfrak{m}}</span> on the right-hand side is <span class="math">\\bm{c}_{i,j}</span> while on the left-hand side it is <span class="math">\\bm{a}_{i,j}\\circ\\bm{b}_{i,j}</span>. If there exist <span class="math">i</span> and <span class="math">j</span> such that <span class="math">\\bm{a}_{i,j}\\circ\\bm{b}_{i,j}\\neq\\bm{c}_{i,j}</span>, that means we have <span class="math">F</span>. Verifier can only accept if we have equality, so this shows that the probability that the committed values does not satisfy the product relation but verifier accepts is negligible, which proves statistical knowledge soundness.</p>

    <p class="text-gray-300">For honest-verifier zero-knowledge, we describe how to simulate the verifier’s view efficiently. Since <span class="math">\\dot{\\bm{a}}_{0},\\dot{\\bm{b}}_{0}\\leftarrow\\mathbb{F}^{k}</span>, and these are added to <span class="math">\\dot{\\bm{a}}</span> and <span class="math">\\dot{\\bm{b}}</span> respectively in an honest transcript, we see that <span class="math">\\dot{\\bm{a}}</span> and <span class="math">\\dot{\\bm{b}}</span> are also uniformly distributed. This is trivial to simulate. In an accepting transcript the answer to the last query is always <span class="math">\\dot{\\bm{a}}\\circ\\dot{\\bm{b}}</span> which can be computed from <span class="math">\\dot{\\bm{a}}</span> and <span class="math">\\dot{\\bm{b}}</span>, so we have special honest verifier zero knowledge. ∎</p>

    <h4 id="sec-30" class="text-lg font-semibold mt-6">Efficiency.</h4>

    <p class="text-gray-300">The verifier sends <span class="math">\\mu+1</span> field elements to the prover through the ILC channel and has a computational cost dominated by <span class="math">\\mathfrak{mn}</span> multiplications in <span class="math">\\mathbb{F}</span> to compute the queries to the channel. The query complexity is <span class="math">\\mathrm{qc}=3</span> and the prover’s communication consists of commitments to <span class="math">2\\mu+2\\mathfrak{n}+3</span> vectors in <span class="math">\\mathbb{F}^{k}</span>.</p>

    <p class="text-gray-300">In the protocol as written, the prover has computed on multivariate polynomials with vector coefficients. However, the prover only needs to commit to elements of <span class="math">\\mathbb{F}^{k}</span>. Therefore, the prover can save considerable computational effort by computing mostly on vectors, and using challenges <span class="math">y,x_{0},\\ldots,x_{\\mu-1}</span> as they become available to partially evaluate expressions and ‘collapse’ multiple vectors into fewer vectors. We analyse the prover’s computation from the final round to the first round. Details follow.</p>

    <p class="text-gray-300">After receiving  <span class="math">x_{\\mu - 1}</span> , and computing  <span class="math">\\dot{\\pmb{a}}_j, \\dot{\\pmb{b}}_j</span> , the prover must compute the values  <span class="math">\\pmb{e}_r</span> . This is done by expressing  <span class="math">\\dot{\\pmb{a}}, \\dot{\\pmb{b}}</span>  as polynomials in  <span class="math">X</span>  of degree  <span class="math">\\mathfrak{n}</span>  with vector coefficients  <span class="math">\\dot{\\pmb{a}}_j, \\dot{\\pmb{b}}_j</span> . Then, the  <span class="math">\\pmb{e}_r</span>  are the coefficients of the Hadamard product polynomial. Using FFT techniques for each vector component, the cost is  <span class="math">O(k\\mathfrak{n}\\log \\mathfrak{n})</span> .</p>

    <p class="text-gray-300">Now we explain how the prover computes the values  <span class="math">\\pmb{d}_j^+, \\pmb{d}_j^-</span>  by computing the values of  <span class="math">\\dot{\\pmb{a}}_j, \\dot{\\pmb{b}}_j</span>  and  <span class="math">\\dot{\\pmb{a}}_j \\circ \\dot{\\pmb{b}}_j</span>  recursively. Consider the following expressions, assuming that the prover has already evaluated in all challenges preceding  <span class="math">X_{\\mu - 1}</span> .</p>

    <div class="my-4 text-center"><span class="math-block">\\dot {\\boldsymbol {a}} _ {j} \\left(x _ {0}, \\dots , x _ {\\mu - 2}, X _ {\\mu - 1}\\right) = \\sum_ {i = 0} ^ {\\mathrm {m} - 1} \\boldsymbol {a} _ {i, j} y ^ {i} x _ {0} ^ {i _ {0}} x _ {1} ^ {i _ {1}} \\dots x _ {\\mu - 2} ^ {i _ {\\mu - 2}} X _ {\\mu - 1} ^ {i _ {\\mu - 1}} \\quad = \\boldsymbol {A} _ {0, j} + \\boldsymbol {A} _ {1, j} X _ {\\mu - 1}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\dot {\\boldsymbol {b}} _ {j} (x _ {0}, \\dots , x _ {\\mu - 2}, X _ {\\mu - 1}) = \\sum_ {i = 0} ^ {\\mathrm {m} - 1} \\boldsymbol {b} _ {i, j} x _ {0} ^ {- i _ {0}} x _ {1} ^ {- i _ {1}} \\dots x _ {\\mu - 2} ^ {- i _ {\\mu - 2}} X _ {\\mu - 1} ^ {- i _ {\\mu - 1}} = \\boldsymbol {B} _ {0, j} + \\boldsymbol {B} _ {1, j} X _ {\\mu - 1} ^ {- 1}</span></div>

    <p class="text-gray-300">By assumption,  <span class="math">A_{0,j}, A_{1,j}, B_{0,j}, B_{1,j}</span>  have already been computed at this stage. The cost of evaluating  <span class="math">\\dot{\\pmb{a}}_j, \\dot{\\pmb{b}}_j</span>  and  <span class="math">\\dot{\\pmb{a}}_j \\circ \\dot{\\pmb{b}}_j</span>  and its  <span class="math">X_{\\mu-1}</span>  coefficients is then  <span class="math">5k</span>  multiplications to compute the necessary Hadamard products and multiply by  <span class="math">x_{\\mu-1}</span>  and its inverse, giving  <span class="math">5\\mathfrak{n}k</span>  multiplications, since we do the computation for  <span class="math">1 \\leq j \\leq \\mathfrak{n}</span> . Now,  <span class="math">\\pmb{d}_{\\mu-1}^{+} = \\sum_{j=1}^{\\mathfrak{n}} \\pmb{A}_{1,j} \\circ \\pmb{B}_{0,j}</span> , and  <span class="math">\\pmb{d}_{\\mu-1}^{-}</span>  can be computed using a similar expression, which costs only  <span class="math">(\\mathfrak{n}-1)k</span>  additions, given that the Hadamard products, such as  <span class="math">A_{1,j} \\circ B_{0,j}</span> , were already computed in evaluating  <span class="math">\\dot{\\pmb{a}}_j</span>  and  <span class="math">\\dot{\\pmb{b}}_j</span> .</p>

    <p class="text-gray-300">Clearly  <span class="math">A_{0,j}, A_{1,j}, B_{0,j}, B_{1,j}</span>  have the same structure as  <span class="math">\\dot{\\pmb{a}}_j, \\dot{\\pmb{b}}_j</span> , but without the variable  <span class="math">X_{\\mu-1}</span> . Splitting into coefficients of  <span class="math">X_{\\mu-2}</span>  in a similar way as with  <span class="math">X_{\\mu-1}</span> , and assuming that we already have evaluations with respect to  <span class="math">X_0, \\ldots, X_{\\mu-3}</span> , we can use the same techniques as above twice to obtain  <span class="math">A_{0,j}, A_{1,j}, B_{0,j}, B_{1,j}</span> , associated Hadamard products  <span class="math">A_{0,j} \\circ B_{0,j}, A_{1,j} \\circ B_{1,j}</span> , and  <span class="math">d_{\\mu-2}^{+}, d_{\\mu-2}^{-}</span>  using  <span class="math">2 \\cdot 5\\mathfrak{n}k</span>  multiplications.</p>

    <p class="text-gray-300">By repeatedly splitting and applying this procedure  <span class="math">\\mu</span>  times, we can use the same techniques 4, then 8, up to  <span class="math">2^{\\mu -1}</span>  times. Summing up, the overall cost is dominated by  <span class="math">5k\\mathfrak{n}(2^{\\mu} - 1)</span>  multiplications, which is  <span class="math">\\mathcal{O}(k\\mathfrak{nm})</span>  multiplications.</p>

    <p class="text-gray-300">Altogether, the computational costs for the prover are  <span class="math">\\mathcal{O}(k\\mathfrak{n}\\log \\mathfrak{n} + k\\mathfrak{nm})</span>  multiplications in  <span class="math">\\mathbb{F}</span> .</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TPprod</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TVprod</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">qc</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">#rounds</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">t</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">O(kn log n + kmn) mult.</td>

            <td class="px-3 py-2 border-b border-gray-700">O(mn + k) mult.</td>

            <td class="px-3 py-2 border-b border-gray-700">3</td>

            <td class="px-3 py-2 border-b border-gray-700">log m + 2</td>

            <td class="px-3 py-2 border-b border-gray-700">2μ + 2n + 3</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The following double-shift proof is used in the construction of a proof to show that the product of all entries in one matrix is equal to the product of all entries in another matrix.</p>

    <p class="text-gray-300">Consider the matrices  <span class="math">A</span>  and  <span class="math">B</span> , which have  <span class="math">\\mathfrak{mn}</span>  rows, given respectively by vectors  <span class="math">\\mathbf{a}_{i,j}, \\mathbf{b}_{i,j} \\in \\mathbb{F}^k</span> , with  <span class="math">0 \\leq i \\leq \\mathfrak{m} - 1, 1 \\leq j \\leq \\mathfrak{n}</span> . The top-right element of  <span class="math">A</span>  is a 1. Columns 2 up to  <span class="math">k</span>  of  <span class="math">A</span>  are equal to columns 1 up to  <span class="math">k - 1</span>  of  <span class="math">B</span> . Further, we can obtain the final column of  <span class="math">B</span>  from the first column of  <span class="math">A</span>  by deleting the first entry and appending  <span class="math">c</span> . In this case,  <span class="math">A</span>  is said to be the shift of  <span class="math">B</span> .</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a0,1</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">1</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a1,2</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">···</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a1,k</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b0,1</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a1,2</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a1,3</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">···</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a1,k</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a2,1</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">a1,1</td>

            <td class="px-3 py-2 border-b border-gray-700">a2,1</td>

            <td class="px-3 py-2 border-b border-gray-700">a2,2</td>

            <td class="px-3 py-2 border-b border-gray-700">···</td>

            <td class="px-3 py-2 border-b border-gray-700">a2,k</td>

            <td class="px-3 py-2 border-b border-gray-700">b1,1</td>

            <td class="px-3 py-2 border-b border-gray-700">a2,2</td>

            <td class="px-3 py-2 border-b border-gray-700">a2,3</td>

            <td class="px-3 py-2 border-b border-gray-700">···</td>

            <td class="px-3 py-2 border-b border-gray-700">a2,k</td>

            <td class="px-3 py-2 border-b border-gray-700">a3,1</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">:</td>

            <td class="px-3 py-2 border-b border-gray-700">:</td>

            <td class="px-3 py-2 border-b border-gray-700">:</td>

            <td class="px-3 py-2 border-b border-gray-700">···</td>

            <td class="px-3 py-2 border-b border-gray-700">:</td>

            <td class="px-3 py-2 border-b border-gray-700">:</td>

            <td class="px-3 py-2 border-b border-gray-700">:</td>

            <td class="px-3 py-2 border-b border-gray-700">:</td>

            <td class="px-3 py-2 border-b border-gray-700">:</td>

            <td class="px-3 py-2 border-b border-gray-700">:</td>

            <td class="px-3 py-2 border-b border-gray-700">:</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">amn,1</td>

            <td class="px-3 py-2 border-b border-gray-700">amn,2</td>

            <td class="px-3 py-2 border-b border-gray-700">···</td>

            <td class="px-3 py-2 border-b border-gray-700">amn,k</td>

            <td class="px-3 py-2 border-b border-gray-700">bm-1,n</td>

            <td class="px-3 py-2 border-b border-gray-700">amn,2</td>

            <td class="px-3 py-2 border-b border-gray-700">amn,3</td>

            <td class="px-3 py-2 border-b border-gray-700">···</td>

            <td class="px-3 py-2 border-b border-gray-700">amn,k</td>

            <td class="px-3 py-2 border-b border-gray-700">c</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Here, we give an proof which allows a prover to convince a verifier in zero-knowledge that for committed matrices  <span class="math">A, B, C</span>  and  <span class="math">D</span> , we have  <span class="math">A</span>  the shift of  <span class="math">B</span> ,  <span class="math">C</span>  the shift of  <span class="math">D</span> , and  <span class="math">B</span>  and  <span class="math">D</span>  have the same bottom-right-most entry  <span class="math">b_{\\mathfrak{mn},k} = d_{\\mathfrak{mn},k}</span> . This is referred to as the double-shift condition. The corresponding relation is</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal {R} _ {\\mathrm {s h i f t}} = \\left\\{ \\begin{array}{c} (p p _ {\\mathrm {I L C}}, u) = ((\\mathbb {F}, k), ([ A ], [ B ], [ C ], [ D ])): \\\\ A, B, C, D \\text {s a t i s f y t h e d o u b l e - s h i f t c o n d i t i o n} \\end{array} \\right\\}.</span></div>

    <p class="text-gray-300">Parsing each matrix as a collection of row vectors as above, we now describe a proof of knowledge of vectors satisfying the stated shift condition.</p>

    <p class="text-gray-300">The double-shift condition can be encoded as many linear consistency constraints between the entries of  <span class="math">A</span> ,  <span class="math">B</span> ,  <span class="math">C</span>  and  <span class="math">D</span> . For example, for the double shift condition to hold, it is necessary that  <span class="math">(\\pmb{a}_{0,1})_2 - (\\pmb{b}_{0,1})_1 = 0</span> . We will use a random challenge  <span class="math">y</span>  to embed all linear consistency constraints into one, with each individual constraint embedded with a different power of  <span class="math">y</span> .</p>

    <p class="text-gray-300">Similarly to the Hadamard product proof, we use challenges  <span class="math">X_0,\\ldots ,X_{\\mu -1}</span>  where  <span class="math">\\mathfrak{m} = 2^{\\mu}</span> , for compression, and reduce the number of vectors from  <span class="math">4\\mathfrak{mn}</span>  to  <span class="math">4\\mathfrak{n}</span> . Vectors are compressed as follows</p>

    <div class="my-4 text-center"><span class="math-block">\\hat {\\boldsymbol {a}} _ {j} (x _ {0}, \\dots , x _ {\\mu - 1}) = \\sum_ {i = 0} ^ {\\mathfrak {m} - 1} \\boldsymbol {a} _ {i, j} x _ {0} ^ {i _ {0}} x _ {1} ^ {i _ {1}} \\dots x _ {\\mu - 1} ^ {i _ {\\mu - 1}}</span></div>

    <p class="text-gray-300">with similar expressions when  <span class="math">a</span>  is replaced by  <span class="math">b, c</span>  and  <span class="math">d</span> .</p>

    <p class="text-gray-300">We then embed the compressed vectors into polynomials in  <span class="math">X</span> , again with similar expressions for  <span class="math">a</span>  replaced by  <span class="math">b, c</span>  and  <span class="math">d</span> .</p>

    <div class="my-4 text-center"><span class="math-block">\\hat {\\boldsymbol {a}} (X, x _ {0}, \\dots , x _ {\\mu - 1}) = \\sum_ {j = 1} ^ {n} \\hat {\\boldsymbol {a}} _ {j} (x _ {0}, \\dots , x _ {\\mu - 1}) X ^ {j}</span></div>

    <p class="text-gray-300">42</p>

    <p class="text-gray-300">We embed all linear consistency constraints into vectors <span class="math">\\hat{\\pmb{w}}_a</span>, <span class="math">\\hat{\\pmb{w}}_b</span>, <span class="math">\\hat{\\pmb{w}}_c</span> and <span class="math">\\hat{\\pmb{w}}_d</span> as follows. Set <span class="math">\\pmb{y} = (1, y, \\dots, y^{k-1})</span>. Set</p>

    <div class="my-4 text-center"><span class="math-block">\\hat {\\boldsymbol {w}} _ {a} (y, X, x _ {0}, \\dots , x _ {\\mu}) = \\boldsymbol {y} \\sum_ {i = 0, j = 1} ^ {\\mathrm {m} - 1, \\mathrm {n}} y ^ {k (i + (j - 1) \\mathrm {m})} x _ {0} ^ {- i _ {0}} \\dots x _ {\\mu - 1} ^ {- i _ {\\mu - 1}} X ^ {- j}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\hat {\\boldsymbol {w}} _ {b} (y, X, x _ {0}, \\dots , x _ {\\mu}) = - y \\hat {\\boldsymbol {w}} _ {a} (y, X, x _ {0}, \\dots , x _ {\\mu})</span></div>

    <div class="my-4 text-center"><span class="math-block">\\hat {\\boldsymbol {w}} _ {c} (y, X, x _ {0}, \\dots , x _ {\\mu}) = - y ^ {2 N} \\hat {\\boldsymbol {w}} _ {a} (y ^ {- 1}, X, x _ {0}, \\dots , x _ {\\mu})</span></div>

    <div class="my-4 text-center"><span class="math-block">\\hat {\\boldsymbol {w}} _ {d} (y, X, x _ {0}, \\dots , x _ {\\mu}) = y ^ {2 N - 1} \\hat {\\boldsymbol {w}} _ {a} (y ^ {- 1}, X, x _ {0}, \\dots , x _ {\\mu})</span></div>

    <p class="text-gray-300">To explain our choice of linear consistency constraint vectors, consider computing the scalar product of <span class="math">\\hat{\\pmb{a}}(y,X,x_0,\\dots,x_\\mu)</span> and <span class="math">\\hat{\\pmb{w}}_a(y,X,x_0,\\dots,x_\\mu)</span>. Focussing on the constant term in <span class="math">X,x_0,\\dots,x_\\mu</span>, we see that the only contributions come from perfect cancellation of a monomial <span class="math">x_0^{i_0}x_1^{i_1}\\dots x_{\\mu -1}^{i_{\\mu -1}}X^j</span> in <span class="math">\\hat{\\pmb{a}}</span> with a corresponding monomial <span class="math">x_0^{-i_0}\\dots x_{\\mu -1}^{-i_{\\mu -1}}X^{-j}</span> in <span class="math">\\hat{\\pmb{w}}_a</span>. In addition, each monomial in <span class="math">\\hat{\\pmb{w}}_a</span> is multiplied by a unique power of <span class="math">y^k</span>. Since <span class="math">\\hat{\\pmb{w}}_a</span> also contains <span class="math">\\pmb{y}</span> as a factor, the constant term of the expression is a sum of all elements of the matrix <span class="math">A</span>, each separated by a unique power of <span class="math">y</span>. Substituting <span class="math">y^{-1}</span> for <span class="math">y</span> produces the elements in the opposite order, and we can also multiply by powers of <span class="math">y</span> to move all elements of the matrix to different powers of <span class="math">y</span>. It is then straightforward to see that we can encode the double shift condition for <span class="math">A,B,C</span> and <span class="math">D</span> by using these two tricks.</p>

    <p class="text-gray-300">Careful calculation shows that</p>

    <div class="my-4 text-center"><span class="math-block">\\hat {\\boldsymbol {a}} \\cdot \\hat {\\boldsymbol {w}} _ {a} (y, X, x _ {0}, \\dots , x _ {\\mu - 1}) + \\hat {\\boldsymbol {b}} \\cdot \\hat {\\boldsymbol {w}} _ {b} (y, X, x _ {0}, \\dots , x _ {\\mu - 1})</span></div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>\\hat {\\boldsymbol {c}} \\cdot \\hat {\\boldsymbol {w}} _ {c} (y, X, x _ {0}, \\dots , x _ {\\mu - 1}) + \\hat {\\boldsymbol {d}} \\cdot \\hat {\\boldsymbol {w}} _ {d} (y, X, x _ {0}, \\dots , x _ {\\mu - 1})</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">has constant term in <span class="math">X, x_0, \\ldots, x_\\mu</span> equal to <span class="math">1 - y^{2N}</span> if and only if <span class="math">A, B, C</span> and <span class="math">D</span> satisfy the double-shift condition. This happens because when we take the scalar products of the vectors of polynomials, all of the linear consistency constraints end up in the constant term in <span class="math">X</span>, separated by different powers of <span class="math">y</span>. All other waste terms end up in other coefficients.</p>

    <p class="text-gray-300">The verifier will check the following polynomial expression evaluated in <span class="math">x</span>.</p>

    <div class="my-4 text-center"><span class="math-block">\\hat {\\boldsymbol {a}} \\cdot \\hat {\\boldsymbol {w}} _ {a} (X, x _ {0}, \\dots , x _ {\\mu - 1})</span></div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>\\hat {\\boldsymbol {b}} \\cdot \\hat {\\boldsymbol {w}} _ {b} (X, x _ {0}, \\dots , x _ {\\mu - 1})</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>\\hat {\\boldsymbol {c}} \\cdot \\hat {\\boldsymbol {w}} _ {c} (X, x _ {0}, \\dots , x _ {\\mu - 1})</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>\\hat {\\boldsymbol {d}} \\cdot \\hat {\\boldsymbol {w}} _ {d} (X, x _ {0}, \\dots , x _ {\\mu - 1}) = 1 - y ^ {2 N} + \\sum_ {t = 0} ^ {\\mu - 1} \\left(f _ {t} ^ {+} x _ {t} + f _ {t} ^ {-} x _ {t} ^ {- 1}\\right) + \\sum_ {r = 1 - n, r \\neq 0} ^ {n - 1} g _ {r} X ^ {r}</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">43</p>

    <p class="text-gray-300">In this expression, the values <span class="math">f_{j}^{+}, f_{j}^{-}</span> can be seen as compression factors to make up for the lossy compression, and the <span class="math">g_{r}</span> are coefficients containing waste values.</p>

    <p class="text-gray-300">As part of this protocol, the prover is required to send single values to ILC rather than vectors, but this is easily incorporated into the model by padding, and has no impact on the asymptotic efficiency.</p>

    <p class="text-gray-300">Note that the polynomials chosen above leak information about the wire values, so we must also incorporate some random blinders <span class="math">\\hat{\\pmb{a}}_0,\\hat{\\pmb{b}}_0,\\hat{\\pmb{c}}_0</span> and <span class="math">\\hat{\\pmb{d}}_0</span> into the real protocol to achieve zero-knowledge.</p>

    <p class="text-gray-300"><strong>Formal Description.</strong> Next, we provide a formal description of the proof of knowledge of committed matrices satisfying the double-shift relation <span class="math">\\mathcal{R}_{\\mathrm{shift}}</span>.</p>

    <p class="text-gray-300"><strong>Proof:</strong></p>

    <p class="text-gray-300">Instance: The prover has already sent <span class="math">[\\pmb{a}_{i,j},\\pmb{b}_{i,j},\\pmb{c}_{i,j},\\pmb{d}_{i,j}]_{i = 0,j = 1}^{\\mathfrak{m} - 1,\\mathfrak{n}}</span> to the ILC channel.</p>

    <p class="text-gray-300"><span class="math">\\mathcal{P}_{\\mathrm{shift}} \\to \\mathrm{ILC}</span>: The prover randomly selects <span class="math">\\hat{\\pmb{a}}_0, \\hat{\\pmb{b}}_0, \\hat{\\pmb{c}}_0, \\hat{\\pmb{d}}_0 \\gets \\mathbb{F}^k</span>.</p>

    <p class="text-gray-300">The prover sends <span class="math">\\hat{\\pmb{a}}_0, \\hat{\\pmb{b}}_0, \\hat{\\pmb{c}}_0</span> and <span class="math">\\hat{\\pmb{d}}_0</span> to ILC.</p>

    <p class="text-gray-300">ILC <span class="math">\\leftarrow</span> <span class="math">\\mathcal{V}_{\\mathrm{shift}}</span>: Verifier sends <span class="math">y \\gets \\mathbb{F}^{\\times}</span> to ILC.</p>

    <p class="text-gray-300"><span class="math">\\mathcal{P}_{\\mathrm{shift}} \\to \\mathrm{ILC}</span>: The prover computes the following polynomial with vector coefficients in the variables <span class="math">X_0, \\ldots, X_{\\mu-1}</span>, where <span class="math">\\mathfrak{m} = 2^{\\mu}</span>, and similar polynomials with <span class="math">a</span> replaced by <span class="math">b, c</span> and <span class="math">d</span>. Here, <span class="math">i_0, \\ldots, i_{\\mu-1}</span> represent the digits of the binary expansion of <span class="math">i</span>.</p>

    <div class="my-4 text-center"><span class="math-block">\\hat {\\boldsymbol {a}} _ {j} (X _ {0}, \\dots , X _ {\\mu - 1}) = \\sum_ {i = 0} ^ {\\mathfrak {m} - 1} \\boldsymbol {a} _ {i, j} X _ {0} ^ {i _ {0}} X _ {1} ^ {i _ {1}} \\dots X _ {\\mu - 1} ^ {i _ {\\mu - 1}}</span></div>

    <p class="text-gray-300">The prover computes the following polynomials with vector coefficients in the variable <span class="math">X</span>, and similarly for <span class="math">b, c</span> and <span class="math">d</span>.</p>

    <div class="my-4 text-center"><span class="math-block">\\hat {\\boldsymbol {a}} (X, X _ {0}, \\dots , X _ {\\mu - 1}) = \\hat {\\boldsymbol {a}} _ {0} + \\sum_ {j = 1} ^ {\\mathfrak {n}} \\hat {\\boldsymbol {a}} _ {j} (X _ {0}, \\dots , X _ {\\mu - 1}) X ^ {j}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\hat {\\boldsymbol {w}} _ {a} (y, X, x _ {0}, \\dots , x _ {\\mu}) = \\boldsymbol {y} \\sum_ {i = 0, j = 1} ^ {\\mathfrak {m} - 1, \\mathfrak {n}} y ^ {k (i + (j - 1) \\mathfrak {m})} x _ {0} ^ {- i _ {0}} \\dots x _ {\\mu - 1} ^ {- i _ {\\mu - 1}} X ^ {- j}</span></div>

    <p class="text-gray-300">44</p>

    <p class="text-gray-300">The prover finally takes the scalar product of the previous vectors of polynomials</p>

    <p class="text-gray-300">$$ \\begin{array}{l} \\hat{\\boldsymbol{a}}(X, X_0, \\dots, X_{\\mu-1}) \\cdot \\hat{\\boldsymbol{w}}_a(X, X_0, \\dots, X_{\\mu-1}) \\\\</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>\\hat{\\boldsymbol{b}}(X, X_0, \\dots, X_{\\mu-1}) \\cdot \\hat{\\boldsymbol{w}}_b(X, X_0, \\dots, X_{\\mu-1}) \\\\</li>

      <li>\\hat{\\boldsymbol{c}}(X, X_0, \\dots, X_{\\mu-1}) \\cdot \\hat{\\boldsymbol{w}}_c(X, X_0, \\dots, X_{\\mu-1}) \\\\</li>

      <li>\\hat{\\boldsymbol{d}}(X, X_0, \\dots, X_{\\mu-1}) \\cdot \\hat{\\boldsymbol{w}}_d(X, X_0, \\dots, X_{\\mu-1}) = 1 - y^{2N} + f_0^+ X_0 + f_0^- X_0^{-1} \\\\</li>

      <li>f_1^+(X_0) X_1 + f_1^-(X_0) X_1^{-1} \\\\</li>

    </ul>

    <p class="text-gray-300">\\vdots \\\\</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>f_{\\mu-1}^+(X_0, \\dots, X_{\\mu-2}) X_{\\mu-1} \\\\</li>

      <li>f_{\\mu-1}^-(X_0, \\dots, X_{\\mu-2}) X_{\\mu-1}^{-1} \\\\</li>

      <li>\\sum_{r=-\\mathfrak{n}, r\\neq0}^{\\mathfrak{n}-1} g_r(X_0, \\dots, X_{\\mu-1}) X^r</li>

    </ul>

    <p class="text-gray-300">\\end{array} $$</p>

    <p class="text-gray-300">The prover sends <span class="math">f_0^+, f_0^-</span> to ILC.</p>

    <p class="text-gray-300">ILC <span class="math">\\leftarrow</span> <span class="math">\\mathcal{V}_{\\mathrm{shift}}</span> : The verifier sends <span class="math">x_0 \\leftarrow \\mathbb{F}^\\times</span> to ILC.</p>

    <p class="text-gray-300"><span class="math">\\mathcal{P}_{\\mathrm{shift}} \\to \\mathrm{ILC}</span>: The prover sends <span class="math">f_1^+ = f_1^+(x_0), f_1^- = f_1^-(x_0)</span> to ILC.</p>

    <p class="text-gray-300">For <span class="math">t = 1</span> to <span class="math">\\mu - 2</span>:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>ILC <span class="math">\\leftarrow</span> <span class="math">\\mathcal{V}_{\\mathrm{shift}}</span> : The verifier sends <span class="math">x_t \\leftarrow \\mathbb{F}^\\times</span> to ILC</li>

      <li><span class="math">\\mathcal{P}_{\\mathrm{shift}} \\to \\mathrm{ILC}</span>: The prover sends <span class="math">f_{t+1}^{+} = f_{t+1}^{+}(x_0, \\ldots, x_t), f_{t+1}^{-} = f_{t+1}^{-}(x_0, \\ldots, x_t)</span> to ILC.</li>

    </ul>

    <p class="text-gray-300">ILC <span class="math">\\leftarrow</span> <span class="math">\\mathcal{V}_{\\mathrm{shift}}</span> : The verifier sends <span class="math">x_{\\mu-1} \\leftarrow \\mathbb{F}^\\times</span> to ILC.</p>

    <p class="text-gray-300"><span class="math">\\mathcal{P}_{\\mathrm{shift}} \\to \\mathrm{ILC}</span>: The prover computes <span class="math">g_r = g_r(x_0, \\ldots, x_{\\mu-1})</span> for <span class="math">-\\mathfrak{n} \\leq r \\leq \\mathfrak{n} - 1, r \\neq 0</span>.</p>

    <p class="text-gray-300">The prover sends <span class="math">\\{g_r\\}_{r = -\\mathfrak{n},r\\neq 0}^{\\mathfrak{n} - 1}</span> to ILC.</p>

    <p class="text-gray-300"><strong>Verification:</strong> The verifier selects <span class="math">x \\leftarrow \\mathbb{F}^\\times</span> uniformly at random. The verifier queries the ILC channel to get</p>

    <div class="my-4 text-center"><span class="math-block">\\hat{\\boldsymbol{a}} = \\hat{\\boldsymbol{a}}_0 + \\sum_{i=0,j=1}^{\\mathfrak{m}-1,\\mathfrak{n}} \\boldsymbol{a}_{i,j} x_0^{i_0} x_1^{i_1} \\dots x_{\\mu-1}^{i_{\\mu-1}} x^j</span></div>

    <p class="text-gray-300">and similarly for <span class="math">b, c</span> and <span class="math">d</span>. The verifier also queries the ILC channel to get</p>

    <div class="my-4 text-center"><span class="math-block">\\hat{e} = \\sum_{t=0}^{\\mu-1} \\left(f_t^+ x_t + f_t^- x_t^{-1}\\right) + \\sum_{r=-\\mathfrak{n}, r\\neq 0}^{\\mathfrak{n}-1} g_r x^r</span></div>

    <p class="text-gray-300">45</p>

    <p class="text-gray-300">The verifier then checks whether the following equation holds and in that case accepts.</p>

    <p class="text-gray-300">$$ \\begin{array}{l} \\hat{\\boldsymbol{a}} \\cdot \\hat{\\boldsymbol{w}}_{a}(x, x_{0}, \\dots, x_{\\mu - 1}) \\\\</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>\\hat{\\boldsymbol{b}} \\cdot \\hat{\\boldsymbol{w}}_{b}(x, x_{0}, \\dots, x_{\\mu - 1}) \\\\</li>

      <li>\\hat{\\boldsymbol{c}} \\cdot \\hat{\\boldsymbol{w}}_{c}(x, x_{0}, \\dots, x_{\\mu - 1}) \\\\</li>

      <li>\\hat{\\boldsymbol{d}} \\cdot \\hat{\\boldsymbol{w}}_{d}(x, x_{0}, \\dots, x_{\\mu - 1}) \\stackrel{?}{=} 1 - y^{2N} + \\hat{e} \\\\</li>

    </ul>

    <p class="text-gray-300">\\end{array} $$</p>

    <h2 id="sec-32" class="text-2xl font-bold">Security Analysis.</h2>

    <p class="text-gray-300"><strong>Theorem 9.</strong> <span class="math">(\\mathcal{K}_{\\mathrm{ILC}}, \\mathcal{P}_{\\mathrm{shift}}, \\mathcal{V}_{\\mathrm{shift}})</span> is a proof system for the relation <span class="math">\\mathcal{R}_{\\mathrm{shift}}</span> in the ILC model with perfect completeness, statistical knowledge soundness with straight-line extraction, and perfect special honest verifier zero-knowledge.</p>

    <p class="text-gray-300"><strong>Proof.</strong> Perfect completeness follows by careful inspection of the protocol and considering the various polynomial expressions computed by the prover.</p>

    <p class="text-gray-300">Next, we show that the proof has statistical knowledge soundness with straight-line extraction. This is because the knowledge extractor already has access to the committed matrices <span class="math">[A]</span>, <span class="math">[B]</span>, <span class="math">[C]</span> and <span class="math">[D]</span>, having seen all messages sent between the prover and the ILC. It remains to show that for any deterministic malicious prover <span class="math">\\mathcal{P}_{\\mathrm{shift}}^*</span>, if the committed vectors are not a valid witness for <span class="math">\\mathcal{R}_{\\mathrm{shift}}</span>, then there is negligible probability of accept. Recall that verifier queries to get the right-hand side of the following equations.</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\hat{\\boldsymbol{a}} = \\hat{\\boldsymbol{a}}_{0} + \\sum_{i = 0, j = 1}^{m - 1, n} \\boldsymbol{a}_{i, j} x_{0}^{i_{0}} x_{1}^{i_{1}} \\dots x_{\\mu - 1}^{i_{\\mu - 1}} x^{j} \\\\ \\hat{\\boldsymbol{b}} = \\hat{\\boldsymbol{b}}_{0} + \\sum_{i = 0, j = 1}^{m - 1, n} \\boldsymbol{b}_{i, j} x_{0}^{i_{0}} x_{1}^{i_{1}} \\dots x_{\\mu - 1}^{i_{\\mu - 1}} x^{j} \\\\ \\hat{\\boldsymbol{c}} = \\hat{\\boldsymbol{c}}_{0} + \\sum_{i = 0, j = 1}^{m - 1, n} \\boldsymbol{c}_{i, j} x_{0}^{i_{0}} x_{1}^{i_{1}} \\dots x_{\\mu - 1}^{i_{\\mu - 1}} x^{j} \\\\ \\hat{\\boldsymbol{d}} = \\hat{\\boldsymbol{d}}_{0} + \\sum_{i = 0, j = 1}^{m - 1, n} \\boldsymbol{d}_{i, j} x_{0}^{i_{0}} x_{1}^{i_{1}} \\dots x_{\\mu - 1}^{i_{\\mu - 1}} x^{j} \\\\ \\end{array}</span></div>

    <p class="text-gray-300"><span class="math">\\hat{\\bm{a}}\\cdot\\hat{\\bm{w}}_{a}(x,x_{0},\\ldots,x_{\\mu-1})</span> <span class="math">+\\hat{\\bm{b}}\\cdot\\hat{\\bm{w}}_{b}(x,x_{0},\\ldots,x_{\\mu-1})</span> <span class="math">+\\hat{\\bm{c}}\\cdot\\hat{\\bm{w}}_{c}(x,x_{0},\\ldots,x_{\\mu-1})</span> <span class="math">+\\hat{\\bm{d}}\\cdot\\hat{\\bm{w}}_{d}(x,x_{0},\\ldots,x_{\\mu-1})=1-y^{2N}+\\sum_{t=1}^{\\mu-1}\\left(f^{+}_{t}x_{t}+f^{-}_{t}x_{t}^{-1}\\right)+\\sum_{r=-\\mathbf{n},r\\neq 0}^{\\mathbf{n}-1}g_{r}x^{r}.</span></p>

    <p class="text-gray-300">Now, substitute in the expressions for <span class="math">\\hat{\\bm{a}}</span>, <span class="math">\\hat{\\bm{b}}</span>, <span class="math">\\hat{\\bm{c}}</span> and <span class="math">\\hat{\\bm{d}}</span> into the left-hand side of the final equality. The verifier only accepts if the last equation holds. By assumption, <span class="math">\\mathcal{P}_{\\text{shift}}^{*}</span> is deterministic, and we know when it made its commitments. Hence, <span class="math">\\hat{\\bm{a}}_{0},\\ldots\\hat{\\bm{d}}_{0}</span> are constants, <span class="math">f^{+}_{0},f^{-}_{0}</span> are functions of <span class="math">y</span>, and <span class="math">f^{+}_{1},f^{-}_{1}</span> are functions of <span class="math">y</span> and <span class="math">x_{0},\\ldots,,x_{\\mu-1}</span>, and the <span class="math">g_{r}</span> are functions of <span class="math">y,x_{0},\\ldots,x_{\\mu-1}</span>. We can now apply Lemma 1. Let <span class="math">\\bm{A}</span> denote the concatenation of all the <span class="math">\\bm{a}</span> vectors, indexed from <span class="math">0</span> so that <span class="math">\\bm{A}_{l-1+k(i+(j-1)\\mathfrak{m})}=(\\bm{a}_{i,j})_{l}</span>, and similarly for <span class="math">b,c</span> and <span class="math">d</span>. Suppose the committed vectors <span class="math">\\bm{a}_{i,j},\\bm{b}_{i,j},\\bm{c}_{i,j},\\bm{d}_{i,j}</span> do not satisfy the double-shift relation. This can happen in five ways:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\bm{A}_{0}\\neq 1</span></li>

      <li><span class="math">\\bm{A}_{i}\\neq\\bm{B}_{i-1}</span> for some <span class="math">i\\in[N-1]</span></li>

      <li><span class="math">\\bm{B}_{N-1}\\neq\\bm{D}_{N-1}</span></li>

      <li><span class="math">\\bm{C}_{i}\\neq\\bm{D}_{i-1}</span> for some <span class="math">i\\in[N-1]</span></li>

      <li><span class="math">\\bm{C}_{0}\\neq 1</span></li>

    </ol>

    <p class="text-gray-300">Consider the coefficients of the powers of <span class="math">y</span> in the equation obtained when substituting the expressions for <span class="math">\\hat{\\bm{a}}</span>, <span class="math">\\hat{\\bm{b}}</span>, <span class="math">\\hat{\\bm{c}}</span> and <span class="math">\\hat{\\bm{d}}</span> into the left-hand side of the above equation. The constant is <span class="math">\\bm{A}_{0}</span> on the left hand side and <span class="math">1</span> on the right-hand side. Hence, in the first of the five cases, the constant term would be different and we have the event <span class="math">F</span>. For <span class="math">i</span> from <span class="math">1</span> to <span class="math">N-1</span>, we see that the coefficient of <span class="math">y^{i}</span> is <span class="math">\\bm{A}_{i}-\\bm{B}_{i-1}</span> on the left-hand side and <span class="math">0</span> on the right-hand side, so in the second case, we will also have event <span class="math">F</span>. The coefficient of <span class="math">y^{N}</span> is <span class="math">\\bm{D}_{N-1}-\\bm{B}_{N-1}</span> on the left-hand side and <span class="math">0</span> on the right-hand side, so the third case also implies <span class="math">F</span>. The coefficients of <span class="math">y^{N+1},y^{N+2},\\ldots,y^{2N}</span> show that the fourth and fifth cases also imply <span class="math">F</span>. So if the input does not satisfy the double-shift relation, we have event <span class="math">F</span>. Now Lemma 1 implies that there is negligible probability that the equation will be satisfied, and hence negligible probability that verifier will accept.</p>

    <p class="text-gray-300">Finally, we show that the proof is honest-verifier zero-knowledge. We describe how to simulate the verifier’s view efficiently, given values <span class="math">y,x_{0},\\ldots,x_{\\mu-1},x\\leftarrow\\mathbb{F}^{\\times}</span> for the random challenges used in the protocol. In an honest transcript, <span class="math">\\hat{\\bm{a}}_{0}</span> is chosen uniformly at random and added to something independent of <span class="math">\\hat{\\bm{a}}_{0}</span> to obtain <span class="math">\\hat{\\bm{a}}</span>. Hence <span class="math">\\hat{\\bm{a}}</span> is uniformly distributed and can easily be simulated. Similarly for <span class="math">b,c</span> and <span class="math">d</span>. The final value to simulate is <span class="math">\\hat{e}</span>, but for an accepting transcript this is uniquely determined and easy to compute given <span class="math">\\hat{\\bm{a}},\\hat{\\bm{b}},\\hat{\\bm{c}}</span> and <span class="math">\\hat{\\bm{d}}</span>. Therefore, we can simulate the transcript and the proof system has special honest verifier zero knowledge.</p>

    <p class="text-gray-300">Efficiency. The verifier has a query complexity of 5 and sends  <span class="math">\\mu + 1</span>  field elements to the prover. The prover commits to a total of  <span class="math">2\\mu + 2\\mathbf{n} + 3</span>  vectors in  <span class="math">\\mathbb{F}^k</span> .</p>

    <p class="text-gray-300">Most of the terms in this proof have a similar structure to those in the Hadamard product proof. The prover must on compute more compressed vectors than before as part of the double-shift proof, but this does not change the asymptotic costs of the protocol. The major differences are that scalar products are computed instead of Hadamard products, and that both prover and verifier must compute  <span class="math">\\hat{\\pmb{w}}_a(y,x,x_0,\\dots ,x_{\\mu -1})</span> , and similarly for  <span class="math">b,c</span>  and  <span class="math">d</span> , in terms of the random challenges. We have that  <span class="math">\\pmb {y} = (1,y,\\ldots ,y^{k - 1})</span>  and</p>

    <div class="my-4 text-center"><span class="math-block">\\hat {\\boldsymbol {w}} _ {a} (y, x, x _ {0}, \\dots , x _ {\\mu}) = \\boldsymbol {y} \\sum_ {i = 0, j = 1} ^ {\\mathrm {m} - 1, \\mathrm {n}} y ^ {k (i + (j - 1) \\mathrm {m})} x _ {0} ^ {- i _ {0}} \\dots x _ {\\mu - 1} ^ {- i _ {\\mu - 1}} x ^ {- j}</span></div>

    <p class="text-gray-300">This can be done using  <span class="math">\\mathcal{O}(\\mathfrak{mn} + k)</span>  multiplications in  <span class="math">\\mathbb{F}</span> , since  <span class="math">\\pmb{y}</span>  requires  <span class="math">\\mathcal{O}(k)</span>  multiplications to compute, and the sum requires  <span class="math">\\mathcal{O}(\\mathfrak{mn})</span> . Aside from that, the dominant costs of the other parts of the protocol are the same, resulting in a cost of  <span class="math">\\mathcal{O}(k\\mathfrak{n}\\log \\mathfrak{n} + k\\mathfrak{mn})</span>  multiplications in  <span class="math">\\mathbb{F}</span>  for the prover, and  <span class="math">\\mathcal{O}(\\mathfrak{mn} + k)</span>  multiplications in  <span class="math">\\mathbb{F}</span>  for the verifier.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TPshift</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TVshift</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">qc</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">#rounds</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">t</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">O(kn log n + kmn) mult.</td>

            <td class="px-3 py-2 border-b border-gray-700">O(mn + k) mult.</td>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

            <td class="px-3 py-2 border-b border-gray-700">log m + 2</td>

            <td class="px-3 py-2 border-b border-gray-700">2μ + 2n + 3</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Now that we have an proof for the double-shift condition, and a Hadamard-product proof, it is easy to construct an proof which shows that the product of all entries in a matrix  <span class="math">A</span>  is the same of the product of all entries of a matrix  <span class="math">B</span> . The corresponding relation is</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal {R} _ {\\mathrm {s a m e - p r o d}} = \\left\\{ \\begin{array}{c} (p p _ {\\mathrm {l L C}}, u) = ((\\mathbb {F}, k), ([ A ], [ B ])): \\\\ A, B \\in \\mathbb {F} ^ {m \\times k} \\quad \\wedge \\quad A = (a _ {i, j}) \\quad \\wedge \\quad B = (b _ {i, j}) \\\\ \\quad \\wedge \\quad \\prod_ {i, j} a _ {i, j} = \\prod_ {i, j} b _ {i, j} \\end{array} \\right\\}.</span></div>

    <p class="text-gray-300">This is achieved by computing the partial products of entries of the matrix  <span class="math">A</span> , beginning with 1, and storing them in a matrix  <span class="math">A_{1}</span>  with the same dimensions as  <span class="math">A</span> . The partial products, ending with the product of all elements of  <span class="math">A</span> , are stored in another matrix  <span class="math">A_{2}</span> , and similarly for  <span class="math">B, B_{1}, B_{2}</span> . Now,  <span class="math">A_{2} = A \\circ A_{1}</span> , and  <span class="math">B_{2} = B \\circ B_{1}</span>  by design. Note that the product of all entries in  <span class="math">A</span>  is the same as the product of the entries in  <span class="math">B</span>  if and only if  <span class="math">A_{1}, A_{2}, B_{1}</span>  and  <span class="math">B_{2}</span>  satisfy the double shift condition. This gives rise to the Same-Product proof shown in Fig. 11. An example follows.</p>

    <p class="text-gray-300">!<a href="img-4.jpeg">img-4.jpeg</a> Fig. 11: Same-Product Argument for two committed matrices.</p>

    <p class="text-gray-300">Theorem 10.  <span class="math">(\\mathcal{K}_{\\mathrm{ILC}},\\mathcal{P}_{\\mathrm{same - prod}},\\mathcal{V}_{\\mathrm{same - prod}})</span>  is a proof system for the relation  <span class="math">\\mathcal{R}_{\\mathrm{same - prod}}</span>  in the ILC model with perfect completeness, statistical knowledge soundness with straight-line extraction, and perfect special honest verifier zero-knowledge.</p>

    <p class="text-gray-300">Proof. Perfect completeness follows by inspection.</p>

    <p class="text-gray-300">For statistical knowledge soundness with straight-line extraction, let matrices  <span class="math">A</span>  and  <span class="math">B</span>  be given. If there exists  <span class="math">A_{1}, A_{2}, B_{1}, B_{2}</span>  such that  <span class="math">((\\mathbb{F}, k), (A, A_{1}, A_{2})) \\in \\mathcal{R}_{\\mathrm{prod}}</span> ,  <span class="math">((\\mathbb{F}, k), (B, B_{1}, B_{2})) \\in \\mathcal{R}_{\\mathrm{prod}}</span>  and  <span class="math">((\\mathbb{F}, k), (A_{1}, A_{2}, B_{1}, B_{2})) \\in \\mathcal{R}_{\\mathrm{shift}}</span>  then  <span class="math">((\\mathbb{F}, k), (A, B)) \\in \\mathcal{R}_{\\mathrm{same - prod}}</span> . So by the soundness property of the underlying protocols, if  <span class="math">((\\mathbb{F}, k), (A, B)) \\notin \\mathcal{R}_{\\mathrm{same - prod}}</span> , one of the sub-protocol will have negligible probability of accept. Since the extractor can read the committed values, we have statistical knowledge soundness with straight-line extractions.</p>

    <p class="text-gray-300">To see we have perfect special honest verifier zero-knowledge, simulate that the verifier receives commitments to two matrices in  <span class="math">\\mathbb{F}^{m\\times k}</span> , commit to random matrices  <span class="math">A_{1}, A_{2}, B_{1}</span>  and  <span class="math">B_{2}</span>  in in  <span class="math">\\mathbb{F}^{m\\times k}</span>  and run the perfect special honest verifier zero-knowledge simulators on the product and double-shift proofs.</p>

    <p class="text-gray-300">Efficiency. The same-product proof involves running two product proofs and one double-shift proof. Asymptotically, these two sub-protocols have the same</p>

    <p class="text-gray-300">communication costs. Therefore, the cost of the same-product proof is asymptotically the same.</p>

    <p class="text-gray-300">The verifier has query complexity  <span class="math">\\mathrm{qc} = 11</span>  and the total number of committed vectors is  <span class="math">O(\\mathfrak{mn})</span> .</p>

    <p class="text-gray-300">The protocol has computational costs of  <span class="math">O(kn\\log n + kmn)</span>  multiplications in  <span class="math">\\mathbb{F}</span>  for the prover, and  <span class="math">O(mn + k)</span>  multiplications in  <span class="math">\\mathbb{F}</span>  for the verifier.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TPsame-prod</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TVsame-prod</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">qc</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">#rounds</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">t</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">O(kn log n + kmn) mult.</td>

            <td class="px-3 py-2 border-b border-gray-700">O(mn + k) mult.</td>

            <td class="px-3 py-2 border-b border-gray-700">11</td>

            <td class="px-3 py-2 border-b border-gray-700">log m + 2</td>

            <td class="px-3 py-2 border-b border-gray-700">O(mn)</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We will now give a known permutation proof for matrices. We deviate from [Gro09] here, since Groth's known permutation argument relies on computing powers of a challenge, which would cause the verifier to use a linear number of multiplications, where we get a verifier that uses a linear number of additions. Suppose the prover has committed to the rows of two matrices  <span class="math">A, B \\in \\mathbb{F}^{m \\times k}</span> , which we will write with square brackets and let the instance contain a permutation  <span class="math">\\pi \\in \\Sigma_{[m] \\times [k]}</span> , i.e.  <span class="math">u = (\\pi, [A], [B])</span> . Then the claim is that the committed matrices satisfy  <span class="math">B = A^{\\pi}</span> , where the notation  <span class="math">A^{\\pi}</span>  means the matrix with entries  <span class="math">a_{i,j}^{\\pi} = a_{\\pi(i,j)}</span> . The corresponding relation is</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal {R} _ {\\mathrm {p e r m}} = \\left\\{ \\begin{array}{c} (p p _ {\\mathrm {l L C}}, u) = ((\\mathbb {F}, k), (\\pi , [ A ], [ B ])): \\\\ A, B \\in \\mathbb {F} ^ {m \\times k} \\quad \\wedge \\quad \\pi \\in \\Sigma_ {[ m ] \\times [ k ]} \\quad \\mathrm {a n d} \\quad A = B ^ {\\pi} \\end{array} \\right\\}.</span></div>

    <p class="text-gray-300">Given a permutation  <span class="math">\\pi \\in \\Sigma_{[m]\\times [k]}</span> , implicitly using an equivalence  <span class="math">(i,j)\\leftrightarrow (i - 1)m + j</span> , we define matrices</p>

    <div class="my-4 text-center"><span class="math-block">V = \\left( \\begin{array}{cccc} 1 &amp;amp; 2 &amp;amp; \\dots &amp;amp; k \\\\ k + 1 &amp;amp; k + 2 &amp;amp; \\dots &amp;amp; 2k \\\\ &amp;amp; &amp;amp; \\ddots &amp;amp; \\\\ &amp;amp; &amp;amp; \\dots &amp;amp; mk \\end{array} \\right) \\qquad V ^ {\\pi} = \\left( \\begin{array}{cccc} \\pi (1) &amp;amp; \\pi (2) &amp;amp; \\dots &amp;amp; \\pi (k) \\\\ \\pi (k + 1) &amp;amp; \\pi (k + 2) &amp;amp; \\dots &amp;amp; \\pi (2k) \\\\ &amp;amp; &amp;amp; \\ddots &amp;amp; \\\\ &amp;amp; &amp;amp; \\dots &amp;amp; \\pi (mk) \\end{array} \\right)</span></div>

    <p class="text-gray-300">Assuming integers in  <span class="math">[mk]</span>  are mapped injectively into  <span class="math">\\mathbb{F}</span>  we can think of these matrices as belonging to  <span class="math">\\mathbb{F}^{m\\times k}</span> . Let us also define  <span class="math">J\\in \\mathbb{F}^{m\\times k}</span>  to be the matrix that has 1 in all entries, i.e.,  <span class="math">J = \\left( \\begin{array}{cc}1 &amp;amp; 1\\\\ &amp;amp; \\ddots \\\\ 1 &amp;amp; 1 \\end{array} \\right)</span> .</p>

    <p class="text-gray-300">We give the permutation proof for  <span class="math">\\mathcal{R}_{\\mathrm{perm}}</span>  in Fig. 12. The idea behind the construction is to let the verifier pick random challenges  <span class="math">x, y</span>  and let the prover commit to  <span class="math">A + yV - xJ</span>  and  <span class="math">B + yV^{\\pi} - xJ</span> . Notice that if  <span class="math">B = A^{\\pi}</span>  then  <span class="math">B + yV^{\\pi}</span>  contains a permutation of the entries in  <span class="math">A + yV</span> , however, if  <span class="math">B \\neq A^{\\pi}</span>  then with overwhelming probability over  <span class="math">y</span>  there will be entries in  <span class="math">B + yV^{\\pi}</span>  that do not</p>

    <p class="text-gray-300">appear anywhere in  <span class="math">A + yV</span> . The prover will now convince the verifier that the product of the entries in  <span class="math">A + yV - xJ</span>  is equal to the product of the entries in  <span class="math">B + yV^{\\pi} - xJ</span> . What happens if the prover is trying to cheat and  <span class="math">B \\neq A^{\\pi}</span> ? Writing out the products of entries, we then get that to cheat the prover must have</p>

    <div class="my-4 text-center"><span class="math-block">\\prod_ {i, j} (a _ {i, j} + y v _ {i, j} - x) = \\prod_ {i, j} (b _ {i, j} + y \\pi (v _ {i, j}) - x).</span></div>

    <p class="text-gray-300">By the Schwartz-Zippel lemma this is unlikely to hold over the random choice of  <span class="math">x</span>  unless indeed  <span class="math">B + yV^{\\pi}</span>  contains a permutation of the entries in  <span class="math">A + yV</span> .</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Pperm(ppILC, (π, [A], [B])</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">VILC(ppILC, (π, [A], [B]))</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Get challenges x, y ∈ F from ILC</td>

            <td class="px-3 py-2 border-b border-gray-700">- Pick x, y ← F and send them to Pperm</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Let U = yV - xJ and Uπ = yVπ - xJ</td>

            <td class="px-3 py-2 border-b border-gray-700">- Compute U = yV - xJ and Uπ = yVπ - xJ</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Let A' = A + yV - xJ and B' = B + yVπ - xJ</td>

            <td class="px-3 py-2 border-b border-gray-700">- Run Veq(ppILC, (U, [U]))</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Commit to the rows in U, Uπ, A', B'</td>

            <td class="px-3 py-2 border-b border-gray-700">- Run Veq(ppILC, (Uπ, [Uπ]))</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Run Peq(ppILC, (U, [U]))</td>

            <td class="px-3 py-2 border-b border-gray-700">- Run Vsum(ppILC, ([A], [U], [A'])</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Run Peq(ppILC, (Uπ, [Uπ]))</td>

            <td class="px-3 py-2 border-b border-gray-700">- Run Vsum(ppILC, ([B], [Uπ], [B'])</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Run Psum(ppILC, ([A], [U], [A]))</td>

            <td class="px-3 py-2 border-b border-gray-700">- Run Vsame-prod(ppILC, ([A'], [B'])</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Run Psum(ppILC, ([B], [Uπ], [B]))</td>

            <td class="px-3 py-2 border-b border-gray-700">- Return 1 if all proofs accept, Return 0 otherwise</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  - Run Psame-prod(ppILC, ([A'], [B'])) |   |</p>

    <p class="text-gray-300">Fig. 12: Known permutation proof for two committed matrices.</p>

    <p class="text-gray-300">Theorem 11.  <span class="math">(\\mathcal{K}_{\\mathrm{ILC}},\\mathcal{P}_{\\mathrm{perm}},\\mathcal{V}_{\\mathrm{perm}})</span>  is a proof system for the relation  <span class="math">\\mathcal{R}_{\\mathrm{perm}}</span>  in the ILC model with perfect completeness, statistical knowledge soundness with straight-line extraction, and perfect special honest verifier zero-knowledge.</p>

    <p class="text-gray-300">Proof. Perfect completeness follows by inspection.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">For statistical soundness, note that by the knowledge soundness of the equality and sum proofs we know the prover has indeed committed correctly to  <span class="math">A + yV - xJ</span>  and  <span class="math">B + yV^{\\pi} - xJ</span>  and can extract these committed values. By the knowledge soundness of the same product proof, we get  <span class="math">\\prod_{i,j}(a_{i,j} + yv_{i,j} - x) = \\prod_{i,j}(b_{i,j} + y\\pi (v_{i,j}) - x)</span> . The Schwartz-Zippel Lemma tells us that if  <span class="math">A + yV</span>  and  <span class="math">B + yV^{\\pi}</span>  have different entries, then the probability over the random choice of  <span class="math">x \\gets \\mathbb{F}</span>  of this equality to hold is at most  $\\frac{mk}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math"> , which is negligible. If  </span>B<span class="math">  is not equal to  </span>A^{\\pi}<span class="math">  then we have with probability  </span>\\frac{mk}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">  over the choice of  </span>y \\gets \\mathbb{F}<span class="math">  that one of the entries in  </span>B + yV^{\\pi}<span class="math">  does not appear as an entry in  </span>A + yV$ . Finally, note that each sub-protocol has straight-line extraction.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">To see we have perfect special honest verifier zero-knowledge, simulate that the verifier receives commitments to four matrices in  <span class="math">\\mathbb{F}^{m\\times k}</span>  and run the perfect</p>

    <p class="text-gray-300">special honest verifier zero-knowledge simulators on the equality, sum and same product proofs.</p>

    <p class="text-gray-300">Efficiency. The efficiency of the proof system is given in the table below, where  <span class="math">\\mathfrak{m},\\mathfrak{n}</span>  are chosen to get good performance in the sub-proofs on the condition  <span class="math">m = \\mathfrak{mn}</span> . The computational cost for the verifier includes  <span class="math">\\mathcal{O}(\\mathfrak{mn} + k)</span>  multiplications for the verifier, but for sufficiently large parameters this is dwarfed by  <span class="math">\\mathcal{O}(kmn) = \\mathcal{O}(mk)</span>  additions used in the equivalence sub-proofs.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TPperm</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TVperm</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">qc</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">#rounds</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">t</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">O(kn log n + kmn) mult.</td>

            <td class="px-3 py-2 border-b border-gray-700">O(kmn) add.</td>

            <td class="px-3 py-2 border-b border-gray-700">15</td>

            <td class="px-3 py-2 border-b border-gray-700">log m + 2</td>

            <td class="px-3 py-2 border-b border-gray-700">O(mn)</td>

          </tr>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">PILC(ppILC,u,w)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">VILC(ppILC,u)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Parse u=(mA,mM,π,{vi}i∈S)</td>

            <td class="px-3 py-2 border-b border-gray-700">- Parse u=(mA,mM,π,{ui}i∈S)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Parse w=({vi}i∈S)</td>

            <td class="px-3 py-2 border-b border-gray-700">- Run Veq(ppILC,({ui}i∈S,[U]))</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Send (commit,{vi}m) to the ILC</td>

            <td class="px-3 py-2 border-b border-gray-700">- Run Vsum(ppILC,([A],[B],[C]))</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- The vectors define V∈Fm×k and sub-matrices A,B,C,D,E,F as described earlier</td>

            <td class="px-3 py-2 border-b border-gray-700">- Run Vprod(ppILC,([D],[E],[F]))</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Let U=(vi)i∈S</td>

            <td class="px-3 py-2 border-b border-gray-700">- Run Vperm(ppILC,({[V],[V]})</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Run Peq(ppILC,({vi}i∈S,[U]))</td>

            <td class="px-3 py-2 border-b border-gray-700">- Return 1 if all the proofs accept</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Run Psum(ppILC,([A],[B],[C]))</td>

            <td class="px-3 py-2 border-b border-gray-700">Return 0 otherwise</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  - Run Psum(ppILC,([D],[E],[F])) |   |</p>

    <p class="text-gray-300">|  - Run Pprod(ppILC,([D],[E],[F])) |   |</p>

    <p class="text-gray-300">Fig. 3: Arithmetic circuit satisfiability proof in the ILC model.</p>

    <p class="text-gray-300">By observing the efficiency of all sub-protocols used in the main protocol, shown in Figure 3 and repeated above for convenience, we get the efficiency table below. The computational cost is dominated by the permutation proof, where the matrices have higher dimensions, so we choose  <span class="math">\\mathfrak{m},\\mathfrak{n}</span>  such that  <span class="math">m = 3m_A + 3m_M = \\mathfrak{mn}</span> . The total number of gates is  <span class="math">N = \\frac{k\\mathfrak{mn}}{3}</span> . Setting  <span class="math">\\mathfrak{m} = \\mathcal{O}(\\log N)</span>  and  <span class="math">k\\approx \\sqrt{N}</span>  we get the asymptotic complexities indicated in the table.</p>

    <p class="text-gray-300">We have given proof systems for arbitrary adaptively chosen arithmetic circuits with  <span class="math">N</span>  gates, where the verifier's cost is  <span class="math">\\mathcal{O}(N)</span>  additions. Field additions can</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TPhC</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TVhC</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">qc</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">#rounds</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">t</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">O(kn log n + kmn) mult.</td>

            <td class="px-3 py-2 border-b border-gray-700">O(kmn) add.</td>

            <td class="px-3 py-2 border-b border-gray-700">20</td>

            <td class="px-3 py-2 border-b border-gray-700">log m + 2</td>

            <td class="px-3 py-2 border-b border-gray-700">O(mn)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">O(N) multiplications</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N) additions</td>

            <td class="px-3 py-2 border-b border-gray-700">20</td>

            <td class="px-3 py-2 border-b border-gray-700">O(log log N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(√N)</td>

          </tr>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">be implemented in  $\\mathcal{O}\\left(\\frac{\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{P}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{W}\\right)<span class="math">  operations on a RAM machine with  </span>W<span class="math"> -bit words, so the computational cost is proportional to the word-length of the circuit description. The verifier complexity is therefore optimal up to a constant factor, since it will take  </span>\\Omega(N\\frac{\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{P}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{W})$  operations just to read the entire instance unless it is represented in more compact form.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">However, if we consider a non-adaptive setting where the same circuit wiring is used many times, then it is possible to amortize the verifier's computational cost. The place where the verifier's pays a linear computational cost is when encoding the wiring of the circuit into matrices  <span class="math">V</span>  and  <span class="math">V^{\\pi}</span>  in the known permutation proof, and when testing the correct constants  <span class="math">\\{\\pmb{v}_i\\}_{i\\in S}</span>  have been committed to using an equality proof. But if the wiring is fixed, we do not have to re-compute the encoding, and if the instance is small, i.e.,  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$  is small, then these costs diminish. In this special setting, which is commonly used in the SNARK world, we get verifier computation that is sub-linear in the size of the arithmetic circuit.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">53</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Claim. Let <span class="math">e_0^<em>, \\ldots, e_t^</em> \\in \\mathbb{F}^\\nu</span>. If <span class="math">Err</span> occurs, then for uniformly chosen <span class="math">\\gamma \\in \\mathbb{F}^t</span>, there is probability at most $\\frac{1}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math"> that </span>\\mathsf{hd}(\\tilde{\\mathcal{C}}, e_0^<em> + \\gamma E^</em>) &lt; \\frac{\\mathsf{hd}_{\\min}}{6}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Proof. Assume <span class="math">Err</span>, that is, there exist <span class="math">\\gamma^{<em>} \\in \\mathbb{F}^{t}</span> with <span class="math">\\mathsf{hd}\\left(\\tilde{\\mathcal{C}}, \\gamma^{</em>}E^{*}\\right) \\geq \\frac{\\mathsf{hd}_{\\min}}{3}</span>. We will show that for any <span class="math">r \\in \\mathbb{F}^{\\times}</span> we have</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{hd} \\left(\\tilde{\\mathcal{C}}, e_0^* + \\gamma E^*\\right) + \\operatorname{hd} \\left(\\tilde{\\mathcal{C}}, e_0^* + (\\gamma + r\\gamma^*) E^*\\right) \\geq \\operatorname{hd} \\left(\\tilde{\\mathcal{C}}, \\gamma^* E^*\\right) \\geq \\frac{\\operatorname{hd}_{\\min}}{3}. \\tag{4}</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">This implies that at most one of <span class="math">e_0^<em> + \\gamma E^</em></span> and <span class="math">e_0^<em> + (\\gamma + r\\gamma^</em>) E^<em></span> can have distance less than <span class="math">\\frac{\\mathsf{hd}_{\\min}}{6}</span> to <span class="math">\\tilde{\\mathcal{C}}</span>. That is, for at most one <span class="math">\\gamma \\in \\mathbb{F}^t</span> in each equivalence class in <span class="math">\\mathbb{F}^t / \\gamma^</em>\\mathbb{F}</span> can <span class="math">e_0^<em> + \\gamma E^</em></span> have distance less than <span class="math">\\frac{\\mathsf{hd}_{\\min}}{6}</span> to <span class="math">\\tilde{\\mathcal{C}}</span>. Since each such equivalence class contains $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> elements, there is probability at most </span>\\frac{1}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math"> that a random </span>\\gamma \\in \\mathbb{F}^t<span class="math"> satisfies </span>\\mathsf{hd}\\left(\\tilde{\\mathcal{C}}, e_0^<em> + \\gamma E^</em>\\right) &lt; \\frac{\\mathsf{hd}_{\\min}}{6}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">To finish the proof, we need to prove (4). Write <span class="math">e_0^<em> + \\gamma E^</em> = c_1 + v_1</span> and <span class="math">e_0^<em> + (\\gamma + r\\gamma^</em>) E^<em> = c_2 + v_2</span> with <span class="math">c_1, c_2 \\in \\tilde{\\mathcal{C}}</span> and <span class="math">\\mathsf{wt}(v_1) = \\mathsf{hd}\\left(\\tilde{\\mathcal{C}}, e_0^</em> + \\gamma E^<em>\\right), \\mathsf{wt}(v_2) = \\mathsf{hd}\\left(\\tilde{\\mathcal{C}}, e_0^</em> + (\\gamma + r\\gamma^<em>) E^</em>\\right)</span>. Now</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\gamma^* E^* = (e_0^* + (\\gamma + r\\gamma^*) E^* - (e_0^* + \\gamma E^*)) r^{-1} \\\\ = (c_2 + v_2 - c_1 - v_1) r^{-1} \\\\ = (c_2 - c_1) r^{-1} + (v_2 - v_1) r^{-1} \\end{array}</span></div>

    <p class="text-gray-300">Here <span class="math">(c_2 - c_1) r^{-1} \\in \\tilde{\\mathcal{C}}</span> and <span class="math">(v_2 - v_1) r^{-1}</span> has at most</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{wt}(v_1) + \\operatorname{wt}(v_2) = \\operatorname{hd} \\left(\\tilde{\\mathcal{C}}, e_0^* + \\gamma E^*\\right) + \\operatorname{hd} \\left(\\tilde{\\mathcal{C}}, e_0^* + (\\gamma + r\\gamma^*) E^*\\right)</span></div>

    <p class="text-gray-300">non-zero elements. This proves inequality (4), and hence the claim.</p>

    <p class="text-gray-300">Claim. Assume that <span class="math">\\neg Err</span> and let <span class="math">V</span> and <span class="math">R</span> be defined as above. Then for any <span class="math">\\pmb{q} \\in \\mathbb{F}^t</span> there exists a <span class="math">\\pmb{r}_{(\\pmb{q})}</span> with <span class="math">\\mathsf{hd}(\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{q}V, \\pmb{r}_{(\\pmb{q})}), \\pmb{q}E^*) &amp;lt; \\frac{\\mathsf{hd}_{\\min}}{3}</span>.</p>

    <p class="text-gray-300">In particular, for any <span class="math">V_{(Q)}^{<em>} \\neq QV</span>, and any <span class="math">R^{\\prime </em>}</span> we have</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{hd}_2 \\left(\\tilde{\\mathsf{E}}_{\\mathcal{C}} \\left(V_{(Q)}^*, R_{(Q)}^*\\right), Q E^*\\right) \\geq 2 \\frac{\\operatorname{hd}_{\\min}}{3}.</span></div>

    <p class="text-gray-300">Proof. Assume that <span class="math">\\neg Err</span>, that is for all <span class="math">\\pmb{q} \\in \\mathbb{F}^t</span> we have <span class="math">\\mathsf{hd}(\\tilde{\\mathcal{C}}, \\pmb{q}E^<em>) &amp;lt; \\frac{\\mathsf{hd}_{\\min}}{3}</span>. Informally, we need to strengthen this by showing that the elements in <span class="math">\\tilde{\\mathcal{C}}</span> that are close to each <span class="math">\\pmb{q}E^</em></span>, are themselves linear in <span class="math">\\pmb{q}</span>.</p>

    <p class="text-gray-300">We have chosen <span class="math">\\pmb{v}_{\\tau}</span>'s and <span class="math">\\pmb{r}_{\\tau}</span>'s such that <span class="math">\\mathsf{hd}(\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{\\tau}, \\pmb{r}_{\\tau}), \\pmb{e}_{\\tau}^{<em>}) &amp;lt; \\frac{\\mathsf{hd}_{\\min}}{3}</span>, and <span class="math">V</span> is the matrix where the <span class="math">\\tau</span>th row is <span class="math">v_{\\tau}</span>. We will show by induction on number of non-zero elements <span class="math">\\mathsf{wt}(\\pmb{q})</span> in <span class="math">\\pmb{q}</span> that there exists <span class="math">\\pmb{r}_{(\\pmb{q})}</span> with <span class="math">\\mathsf{hd}(\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{q}V, \\pmb{r}_{(\\pmb{q})}), \\pmb{q}E^{</em>}) &amp;lt; \\frac{\\mathsf{hd}_{\\min}}{3}</span>.</p>

    <p class="text-gray-300">54</p>

    <p class="text-gray-300">This is trivially true for <span class="math">\\mathsf{wt}(\\pmb {q}) = 0</span>. For <span class="math">\\mathsf{wt}(\\pmb {q}) = 1</span> it follows from our choice of <span class="math">\\pmb{v}_{\\tau}</span>. Assume for induction that it is true for all <span class="math">\\pmb{q}</span> with <span class="math">\\mathsf{wt}(\\pmb {q})\\leq \\kappa</span> and consider a <span class="math">\\pmb{q}</span> with <span class="math">\\mathsf{wt}(\\pmb {q})\\leq 2\\kappa</span>. We can now write <span class="math">\\pmb {q} = \\pmb{q}^{\\prime} + \\pmb{q}^{\\prime \\prime}</span> where <span class="math">\\mathsf{wt}(\\pmb{q}^{\\prime}),\\mathsf{wt}(\\pmb{q}^{\\prime \\prime})\\leq \\kappa</span>. By the induction hypothesis, there exists <span class="math">\\pmb{r}_{\\pmb{q}}</span> such that <span class="math">\\mathsf{hd}(\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{q}^{\\prime}V,\\pmb{r}_{(\\pmb{q}^{\\prime})}),\\pmb{q}^{\\prime}E^{*}) &amp;lt; \\frac{\\mathsf{hd}_{\\min}}{3}</span> and similar for <span class="math">\\pmb{q}^{\\prime \\prime}</span>. Since <span class="math">\\pmb {q} = \\pmb{q}^{\\prime} + \\pmb{q}^{\\prime \\prime}</span> this implies</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\mathsf{hd}\\left(\\tilde{\\mathsf{E}}_{\\mathcal{C}}\\left(\\boldsymbol {q} V, \\boldsymbol{r}_{(\\boldsymbol {q}^{\\prime})} + \\boldsymbol{r}_{(\\boldsymbol {q}^{\\prime \\prime})}\\right), \\boldsymbol {q} E^{*}\\right) \\\\ = \\mathsf{hd}\\left(\\tilde{\\mathsf{E}}_{\\mathcal{C}}\\left((\\boldsymbol{q}^{\\prime} + \\boldsymbol{q}^{\\prime \\prime})V, \\boldsymbol{r}_{(\\boldsymbol{q}^{\\prime})} + \\boldsymbol{r}_{(\\boldsymbol{q}^{\\prime \\prime})}\\right), (\\boldsymbol{q}^{\\prime} + \\boldsymbol{q}^{\\prime \\prime})E^{*}\\right) \\\\ \\leq \\mathsf{hd}\\left(\\tilde{\\mathsf{E}}_{\\mathcal{C}}\\left(\\boldsymbol{q}^{\\prime}V, \\boldsymbol{r}_{(\\boldsymbol{q}^{\\prime})}\\right), \\boldsymbol{q}^{\\prime}E^{*}\\right) + \\mathsf{hd}\\left(\\tilde{\\mathsf{E}}_{\\mathcal{C}}\\left(\\boldsymbol{q}^{\\prime \\prime}V, \\boldsymbol{r}_{(\\boldsymbol{q}^{\\prime \\prime})}\\right), \\boldsymbol{q}^{\\prime \\prime}E^{*}\\right) \\\\ &amp;lt; 2 \\frac{\\mathrm{hd}_{\\min}}{3}. \\end{array}</span></div>

    <p class="text-gray-300">Since we assume <span class="math">\\neg Err</span>, we know that there exist some <span class="math">\\pmb{v}_{(\\pmb{q})}</span> and <span class="math">\\pmb{r}_{(\\pmb{q})}</span> such that <span class="math">\\mathsf{hd}(\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{(\\pmb{q})},\\pmb{r}_{(\\pmb{q})}),\\pmb{q}E^{*}) &amp;lt; \\frac{\\mathsf{hd}_{\\min}}{3}</span>. Now, by the triangle inequality for Hamming distance, this implies</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\mathsf{hd}\\left(\\tilde{\\mathsf{E}}_{\\mathcal{C}}\\left(\\boldsymbol{v}_{(\\boldsymbol{q})}, \\boldsymbol{r}_{(\\boldsymbol{q})}\\right), \\tilde{\\mathsf{E}}_{\\mathcal{C}}\\left(\\boldsymbol{q} V, \\boldsymbol{r}_{(\\boldsymbol{q}^{\\prime})} + \\boldsymbol{r}_{(\\boldsymbol{q}^{\\prime \\prime})}\\right)\\right) \\\\ \\leq \\mathsf{hd}\\left(\\tilde{\\mathsf{E}}_{\\mathcal{C}}\\left(\\boldsymbol{v}_{(\\boldsymbol{q})}, \\boldsymbol{r}_{(\\boldsymbol{q})}\\right), \\boldsymbol{q}E^{*}\\right) + \\mathsf{hd}\\left(\\boldsymbol{q}E^{*}, \\tilde{\\mathsf{E}}_{\\mathcal{C}}\\left(\\boldsymbol{q} V, \\boldsymbol{r}_{(\\boldsymbol{q}^{\\prime})} + \\boldsymbol{r}_{(\\boldsymbol{q}^{\\prime \\prime})}\\right)\\right) \\\\ &amp;lt; \\frac{\\mathrm{hd}_{\\min}}{3} + 2 \\frac{\\mathrm{hd}_{\\min}}{3} = \\mathrm{hd}_{\\min} \\end{array}</span></div>

    <p class="text-gray-300">Since <span class="math">\\mathsf{hd}_{\\min}</span> is the minimum distance of <span class="math">\\tilde{\\mathsf{E}}_{\\mathcal{C}}</span>, we must have <span class="math">\\pmb{v}_{(\\pmb{q})} = \\pmb{q}V</span>, and hence <span class="math">\\mathsf{hd}(\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{q}V, \\pmb{r}_{(\\pmb{q})}), \\pmb{q}E^{*}) &amp;lt; \\frac{\\mathsf{hd}_{\\min}}{3}</span>. This finishes the induction argument.</p>

    <p class="text-gray-300">The triangle inequality for Hamming distance shows that for any <span class="math">(\\pmb{v}_{(\\pmb{q})}^{<em>},\\pmb{r}_{(\\pmb{q})}^{</em>})</span> with <span class="math">\\pmb{v}_{(\\pmb{q})}^{<em>}\\neq \\pmb{q}V</span> we have <span class="math">\\mathsf{hd}(\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{(\\pmb{q})}^{</em>},\\pmb{r}_{(\\pmb{q})}^{<em>}),\\pmb{q}E^{</em>})\\geq 2\\frac{\\mathsf{hd}_{\\min}}{3}</span>. Now for any <span class="math">V_{(Q)}^{<em>}\\neq QV</span> there is a row <span class="math">\\tau</span> where the two matrices differ. Let <span class="math">\\pmb{q}</span> be the <span class="math">\\tau</span>th row of <span class="math">Q</span>. Then <span class="math">\\mathsf{hd}(\\tilde{\\mathsf{E}}_{\\mathcal{C}}(\\pmb{v}_{(\\pmb{q})}^{</em>},\\pmb{r}_{(\\pmb{q})}^{<em>}),\\pmb{q}E^{</em>})\\geq 2\\frac{\\mathsf{hd}_{\\min}}{3}</span> tells us that the <span class="math">\\tau</span>th row of <span class="math">\\tilde{\\mathsf{E}}_{\\mathcal{C}}(V_{(Q)}^{<em>},R_{(Q)}^{</em>})</span> and <span class="math">\\tau</span>th row of <span class="math">QE^{<em>}</span> differs in at least <span class="math">2\\frac{\\mathsf{hd}_{\\min}}{3}</span> positions. In particular, <span class="math">\\mathsf{hd}_2\\left(\\tilde{\\mathsf{E}}_{\\mathcal{C}}\\left(V_{(Q)}^</em>,R_{(Q)}^<em>\\right),QE^</em>\\right)\\geq 2\\frac{\\mathsf{hd}_{\\min}}{3}</span>.</p>`;
---

<BaseLayout title="Linear-Time Zero-Knowledge Proofs for Arithmetic Circuit Sat... (2017/872)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2017 &middot; eprint 2017/872
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
