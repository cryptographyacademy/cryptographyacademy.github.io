---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2022/1633';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Linea Prover Documentation';
const AUTHORS_HTML = 'Linea Prover';

const CONTENT = `    <p class="text-gray-300">Linea, Prover Team</p>

    <h6 id="sec-2" class="text-base font-medium mt-4">Abstract</h6>

    <p class="text-gray-300">Rollup technology today promises long-term solutions to the scalability of the blockchain. Among a thriving ecosystem, Consensys has launched the Linea zkEVM Rollup network for Ethereum. At a high level, the Ethereum blockchain can be seen as a state machine and its state transition can be arithmetized carefully. Linea’s prover protocol uses this arithmetization, along with transactions on layer two in order to compute a cryptographic proof that the state transition is performed correctly.</p>

    <p class="text-gray-300">The proof is then sent over to the Ethereum layer, where the smart contract (verifier contract) on Ethereum checks the proof and accepts the state transition if the proof is valid. The interaction between layer two and Ethereum is costly, which imposes substantial limitations on the proof size. Therefore, Linea’s prover aims to compress the proof via cryptographic tools such as list polynomial commitments (LPCs), polynomial interactive oracle proofs (PIOPs), and Succinct Non-Interactive Arguments of Knowledge (SNARKs).</p>

    <p class="text-gray-300">We introduce Wizard-IOP, a cryptographic tool for handling a wide class of queries (such as range checks, scalar products, permutations checks, etc.) needed to ensure the correctness of the executions of the state machines efficiently and conveniently. Another cryptographic tool is the Arcane compiler, which outputs standard PIOPs and is employed by Wizard-IOP to make different queries homogeneous. After applying Arcane, all the queries constitute evaluation queries over the polynomials. We then apply the Unique Evaluation compiler (UniEval), which receives the output of the Arcane and provides us with a PIOP that requires only a single evaluation check.</p>

    <p class="text-gray-300">At this point, we employ Vortex, a list polynomial commitment (LPC) scheme to convert the resulting PIOP into an argument of knowledge. The argument of knowledge is then made succinct by applying different techniques such as self-recursion, standard recursion, and proof aggregations.</p>

    <h6 id="sec-3" class="text-base font-medium mt-4">Keywords:</h6>

    <p class="text-gray-300">Linea, zkEVM, SNARK, Ring-SIS, Self-Recursion, Arcane, Wizard-IOP, Range Checks, Lookup Proofs, Permutation Proofs.</p>

    <h2 id="sec-4" class="text-2xl font-bold">1 Introduction</h2>

    <p class="text-gray-300">The advent of blockchain technology and its underlying cryptographic mechanisms have ushered in a new era of secure and transparent digital transactions. Among these, the Ethereum Virtual Machine (EVM) stands out as a cornerstone for executing smart contracts on the Ethereum blockchain. As part of this ecosystem, Linea launched a zk-EVM, a scalable EVM execution environment leveraging cryptographic techniques to achieve higher transaction processing capability than the main Ethereum network. This paper delves into the cryptographic applications that ensure the integrity of Linea, specifically focusing on advancements in zero-knowledge proofs and their applications in zk-Virtual Machines (zk-VMs).</p>

    <h3 id="sec-5" class="text-xl font-semibold mt-8">1.1 zk-VMs and zk-EVMs</h3>

    <p class="text-gray-300">In a state machine, a transition is the process of moving from an old state to a new state by reading a series of inputs and performing sets of opcodes which are a limited and low-level set of instructions. Ethereum is, in essence, a transaction-based state machine, where the state contains all account addresses and their mapped account states. The Ethereum Virtual Machine (EVM) is the mechanism responsible for performing the transitions as a succession of opcodes. zk-VMs (zk-Virtual Machines) and, more specifically, the zk-EVM (Ethereum Virtual Machine) are complex and powerful cryptographic systems that allow one party to generate proofs assessing the correct execution of a Virtual Machine using a SNARK scheme. The proofs can be as short as a few hundred bytes and can be verified in a few milliseconds on any platform (Groth16 <em>[groth16]</em>). For these reasons, zk-VMs have important applications in blockchain scalability and interoperability. This is also the reason why this area of research has recently seen tremendous activity</p>

    <p class="text-gray-300">in research and development: Linea <em>[10]</em>, Cairo <em>[30]</em>, Polygon-zkEVM <em>[47]</em>, RISC0 <em>[50]</em> or Scroll <em>[1]</em>. However, building a system capable of proving arbitrary executions of the Ethereum Virtual Machine is no easy task. To give an idea, Linea’s arithmetization <em>[10]</em> models execution traces of the Ethereum Virtual Machine using hundreds of polynomials and thousands of arithmetic constraints of various types. In this setting, the total witness size for proving the execution of a regular block consists of hundreds of millions of field elements.</p>

    <h2 id="sec-6" class="text-2xl font-bold">Background and Motivation</h2>

    <p class="text-gray-300">Cryptographic primitives such as Polynomial Commitments and Succinct Non-Interactive Arguments of Knowledge (SNARKs) have been pivotal in enabling blockchain scalability and privacy. These tools can significantly reduce the computational overhead on the blockchain network. Our research is motivated by the challenge of proving the correctness of arbitrary execution traces of the EVM as specified in <em>[10]</em> in a manner that is both computationally efficient and verifiable.</p>

    <h3 id="sec-7" class="text-xl font-semibold mt-8">Polynomial Commitments</h3>

    <p class="text-gray-300">A polynomial commitment <em>[38]</em> is a cryptographic primitive in which a prover commits to a polynomial <span class="math">P(X)</span> and later proves the evaluation of <span class="math">P(X)</span> at a given point <span class="math">x</span>.</p>

    <h3 id="sec-8" class="text-xl font-semibold mt-8">List Polynomial Commitments (LPCs)</h3>

    <p class="text-gray-300">An LPC is a polynomial commitment with a relaxed security requirement: the commitment is not associated with a single polynomial but rather with a list of polynomials, where the prover can open the commitment to any polynomial from the list. Thus the commitment is not binding to one polynomial but to a list of polynomials.</p>

    <h3 id="sec-9" class="text-xl font-semibold mt-8">Succinct Non-Interactive Arguments of Knowledge (SNARKs)</h3>

    <p class="text-gray-300">Given a binary relation <span class="math">\\mathcal{R}(x,w)</span>, SNARKs allow proving knowledge of a witness <span class="math">w</span> such that the relation <span class="math">\\mathcal{R}</span> (usually drawn from a large family) is satisfied for a public input <span class="math">x</span>. In particular, the verifier needs less time to verify the proof, generated by a SNARK, rather than to re-do all the computations. In the last few years, an ever-growing number of SNARK constructions have emerged, including Groth16 <em>[33]</em>, Plonk <em>[7]</em>, Halo <em>[22]</em>, Halo2 <em>[28]</em>, Marlin <em>[25]</em>, Spartan <em>[44]</em>, Virgo <em>[51]</em>, Brakedown <em>[32]</em>, Orion <em>[49]</em>, Libra <em>[48]</em>, Aurora <em>[16]</em>, Fractal <em>[24]</em>, Sonic <em>[40]</em>, Nova <em>[37]</em>, and Lasso <em>[45]</em> to cite a fraction of the existing works.</p>

    <h3 id="sec-10" class="text-xl font-semibold mt-8">Interactive Oracle Proofs (IOPs)</h3>

    <p class="text-gray-300">Interactive Oracle Proofs (IOPs) are a family of abstract ideal protocols in which the verifier is not required to read the prover’s messages in full. Instead, the verifier has oracle access to the prover’s messages and may probabilistically query them at any positions <em>[14]</em>. IOP protocols can be transformed into concrete secure argument systems using Merkle trees thanks to the <em>[15]</em>. Later works have introduced several variants of IOPs such as polynomial-IOPs or tensor-IOPs, where the prover can perform polynomial evaluation queries <em>[7]</em> or tensor queries <em>[21]</em>. Similarly, these protocols can be converted into concrete argument systems (including SNARKs) using functional extractable commitments. This type of approach for building argument systems has led to an extensive line of works and has now become a standard.</p>

    <h3 id="sec-11" class="text-xl font-semibold mt-8">Recursion</h3>

    <p class="text-gray-300">is a technique that consists of verifying a publicly verifiable non-interactive proof inside another argument system. This technique can be used for building incrementally verifiable computation (IVC), proof-carrying data (PCD), proof aggregation, or further compression of proof size. <em>[19]</em> specifies how to instantiate proof-carrying data through recursion using a pairing-friendly cycle of elliptic curves. The works of Halo <em>[22]</em>, Halo2 <em>[28]</em> and Nova <em>[37]</em> present several techniques to implement PCD or IVC using a (possibly non-pairing-friendly) cycle of elliptic curves. In <em>[11]</em> the authors present a recursion technique that specifically targets recursion over the protocol of GKR <em>[31]</em> and more generally any interactive protocol whose Fiat-Shamir transform involves hashing long string in the first round.</p>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">Contributions</p>

    <p class="text-gray-300">We introduce a novel framework that leverages the Vortex List Polynomial Commitments (LPCs) <em>[13]</em> to instantiate a SNARK specifically tailored for the execution traces of the EVM. Our approach addresses the scalability challenges posed by existing zk-VMs and offers a more efficient mechanism for generating and verifying execution proofs. Furthermore, we present an innovative self-recursion technique and explore its application in optimizing proof verification, contributing to the broader field of incrementally verifiable computation (IVC) and post-quantum SNARKs.</p>

    <p class="text-gray-300">In synthesizing these cryptographic techniques, our research not only advances the state of the art in zk-VMs but also opens new avenues for secure and efficient blockchain computations.</p>

    <h3 id="sec-12" class="text-xl font-semibold mt-8">1.1 Our Contributions and Techniques</h3>

    <p class="text-gray-300">Arithmetization is a complex step that converts the state transition to some mathematical structure. In Linea’s system, the structure of the arithmetization is a set of columns of fixed length. The correct state transition is then verified by sending specific queries on these columns. The queries are usually from a wide class: range checks, permutation checks, scalar-product checks, etc. Since working with different queries can be prone to mistakes and more effort, we first homogenize the queries. For this purpose, we employ our Wizard-IOP, which receives the columns and different types of queries, and uses the Arcane compiler to provide us with a set of columns and just one type of query. The previous columns (input of Arcane) are technically a subset of a new set of columns (output of Arcane). The columns are treated as either the coefficients or evaluations of corresponding polynomials and the homogenized query is the evaluation of these polynomials.</p>

    <h4 id="sec-13" class="text-lg font-semibold mt-6">Wizard-IOP</h4>

    <p class="text-gray-300">In Section 4, we present the Wizard-IOP framework. It can be viewed as an extension of the notion of (polynomial-)IOP <em>[15]</em> supporting more complex queries. In this framework, the prover is allowed to send oracle-access to multiple vectors across several rounds of interactions and the verifier may perform queries from a wide class. To give an idea, the verifier may send queries evaluating scalar-products of committed vectors or polynomial evaluations. It may also send queries involving cyclic-shifts of committed vectors or queries asserting that two vectors are permutations of each other.</p>

    <p class="text-gray-300">Wizard-IOP allows designing protocols in a way that contrasts with the usual polynomial-IOP techniques. Compared to polynomial-IOPs, Wizard-IOP offers a higher-level framework for designing protocols. This makes Wizard-IOP suitable for designing protocols that would otherwise be more complex using solely the framework of polynomial-IOP. Most of all, the fact that Wizard-IOP supports queries with this level of abstraction makes it seamlessly compatible with the work of the zk-EVM specification of <em>[10]</em>.</p>

    <h4 id="sec-14" class="text-lg font-semibold mt-6">Arcane and UniEval compiler</h4>

    <p class="text-gray-300">Thereafter, Section 5 introduces the Arcane Compiler, a tool that allows transforming any secure protocol specified in the Wizard-IOP model into one secure in the polynomial-IOP model. The UniEval compiler then turns this PIOP into a PIOP where the verifier queries the oracle only on a single opening point for all polynomials. The techniques we use to build Arcane are derived from known modular polynomial-IOPs from past works such as Plonk, Halo2, or Cairo <em>[7, 20, 28, 30, 29]</em>. As the original goal of our work is to build a succinct proof system for the zk-EVM specified in <em>[10]</em>, this compiler approach has numerous benefits. An important one is that it allows specifying and implementing batching and optimization techniques that would be significantly more complex otherwise. While the sub-protocols we employ are not new, the succession of steps it follows is endemic to our work. The main feature of our compilation steps (Arcane and UniEval) is that it yields a single-point evaluation PIOP, allowing us to use the output of the compiler alongside a non-homomorphic polynomial commitment (i.e., Vortex) to create an efficient argument system.</p>

    <h4 id="sec-15" class="text-lg font-semibold mt-6">Vortex, a Batchable Polynomial Commitment (BPC)</h4>

    <p class="text-gray-300">A polynomial commitment allows a prover to open the committed polynomial over a given point. A Batchable Polynomial Commitment (BPC) allows the same type of opening for a batch of committed polynomials on the same point. In Section 7, we present Vortex, an adaptation of Ligero <em>[6]</em> into a BPC scheme inspired by the works of Brakedown <em>[32]</em>, batch-FRI <em>[18]</em>, and RedShift <em>[36]</em>.</p>

    <p class="text-gray-300">Similarly to Brakedown, our BPC does not rely on the FRI protocol and it has a proximity check and an evaluation check where the proximity check is indeed the Ligero test. The main difference from Brakedown is the security regime we are dealing with. Based on encoding schemes, one can imagine two security regimes: the unique decoding regime that is the counterpart for the standard binding and the list decoding regime leading to a relaxed binding property where the commitment can be opened to a fixed list.</p>

    <p class="text-gray-300">Working in the list decoding regime requires a new design. Indeed, the evaluation protocol of Vortex is different from the one in Brakedown, where we combine the proximity check and evaluation check as the evaluation protocol. More precisely, in Brakedown, the proximity check can be run independently of the evaluation point, while in Vortex the proximity check is run after seeing the evaluation point. Working in the list decoding regime also brings trade-offs between efficiency and soundness-error. In particular, if the field is large enough, the efficiency gain compared to the loss in the soundness-error becomes of practical interest. We show that a polynomial commitment scheme in the list decoding regime (Vortex LPC) is sufficient for the compilation of PIOP to an argument of knowledge (AoK).</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">From the instantiation point of view, for hashing the columns, our Vortex scheme relies on a hash function based on the Ring-SIS assumption <em>[39]</em> where we also apply an MIMC hash over the output of the SIS-hash. The first instance of Ring-SIS-based hash functions was introduced in <em>[39]</em>. It is a SNARK-friendly hash function with a linear structure defined over the ring of polynomials of degree less than <span class="math">d</span>, as <span class="math">H_{n}(s)=\\sum a_{i}(x)s_{i}(x)\\in\\mathcal{R}</span> for <span class="math">\\mathcal{R}=\\mathbb{Z}_{q}(X)/X^{d}+1</span>. Another advantage of using such a hash function is the possibility of using lookup arguments if the hash computation is not computed on the verifier side. To encode the rows, we use the (systematic) Reed-Solomon encoding <em>[43]</em>. Vortex commitments have size $O(\\sqrt{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">M</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">})<span class="math">, prover time </span>O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">M</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">M</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> and verification time </span>O(\\sqrt{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">M</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">})$. The reason our proving time is not linear is due to the use of the Reed-Solomon error-correcting codes (whose encoding algorithm requires FFT). Orion and Brakedown <em>[49, 32]</em> achieve linear-time prover algorithms thanks to dedicated and optimized linear-time encodable erasure codes. Although we believe our techniques could be adapted to their erasure codes, we motivate our choice with the fact that Reed-Solomon codes are fast enough for our needs and nicer to work with for recursion. We leave this as an area of optimization to be explored in later versions of this work.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-16" class="text-lg font-semibold mt-6">SNARK via Self-Recursion</h4>

    <p class="text-gray-300">Since Vortex is interactive and has verifier complexity and proof size <span class="math">O(\\sqrt{n})</span>, using the above compilation technique does not yield immediately a SNARK. Indeed, obtaining a SNARK requires polylogarithmic proof size and non-interactivity. To work around this problem, we use a technique named self-recursion. It works by re-arithmetizing the Vortex verifier in the Wizard-IOP framework. The self-recursion reduces the size of the proof by a square root every time it is applied. After <span class="math">O(\\log\\log n)</span> steps of recursion, we obtain a protocol with <span class="math">O(\\log\\log n)</span> proof size and verification time. The proof can then be made non-interactive in the random oracle model (ROM) using a suitably chosen hash function. Thereafter, the resulting SNARK can optionally be compressed further to <span class="math">O(1)</span> using existing proof systems such as Groth16<em>[33]</em> or Plonk<em>[7]</em> whose concrete proof sizes are small and verification times are efficient. The advantage of combining self-recursion together with simple recursion is that it greatly reduces the prover time compared to going for a simple recursion with Groth16 or Plonk. One might say that self-recursion compresses the proof loosely but fast, while recursion with pairing-based SNARKs compresses the proof tightly but slowly.</p>

    <p class="text-gray-300">1.2 Overview of Vortex and its Self-Recursion</p>

    <h4 id="sec-17" class="text-lg font-semibold mt-6">Vortex</h4>

    <p class="text-gray-300">Similarly to <em>Brakedown [32]</em> and <em>Orion [49]</em>, the Vortex construction is simple and can be succinctly described. Assume that <span class="math">\\mathcal{P}</span> and <span class="math">\\mathcal{V}</span> are the prover and the verifier. First, we elaborate on the commitment procedure. The prover commits to a matrix <span class="math">W</span> in two steps <em>row-encoding</em> and <em>column-hashing</em>. <span class="math">\\mathcal{P}</span> starts by encoding the rows of the matrix using a Reed-Solomon code to obtain a new matrix <span class="math">W^{\\prime}</span> (namely, row-encoding). The prover then hashes each column of <span class="math">W^{\\prime}</span> and sends them to the verifier as its commitment (namely, column hashing).</p>

    <p class="text-gray-300">The protocol is then followed by two other phases, <em>proximity check</em> and <em>evaluation check</em>. In the proximity check, the prover sends a vector <span class="math">u</span>, then the prover and the verifier apply the Ligero proximity test over the committed matrix and the encoding of vector <span class="math">u</span> (the encoding is called <span class="math">u^{\\prime}</span>). The Ligero test proves that if the random linear combination of rows is close to codeword <span class="math">u^{\\prime}</span> then all the rows are close to a codeword.</p>

    <p class="text-gray-300">Setting the distance to the unique decoding radius, there is only one polynomial close to the function embedded in the matrix. Finally, the evaluation check guarantees that the evaluation of the polynomial (obtained from the proximity check and unique decoding radius) over a given point <span class="math">x</span> is correct.</p>

    <p class="text-gray-300">The above description is the same as the polynomial commitment in <em>Brakedown [32]</em> and <em>Orion [49]</em>. The main difference between Vortex and Brakedown is the evaluation protocol, where we combine the Proximity check and evaluation check as the evaluation protocol. More precisely, in Brakedown, since we are in the unique decoding regime, the proximity check can be run independently of the evaluation point, while in Vortex the proximity check is run after seeing the evaluation point.</p>

    <p class="text-gray-300">For the instantiation of the hash used on the columns, we use Ring-SIS hashing on the columns of <span class="math">W^{\\prime}</span>, and we then apply MIMC over the SIS hash of the columns. Finally, a Merkle tree (based on MIMC) is used to achieve a constant-size commitment. SIS hashing can be seen as a variant of the SWIFFT hash function <em>[39]</em>. Its internal machinery is summed up in the following. Let <span class="math">v\\in\\mathbb{F}^{m}</span> be a vector to hash, and <span class="math">\\mathcal{R}</span> be a polynomial ring. First, the bits of <span class="math">v</span> are rearranged in a vector <span class="math">v_{b}</span> of limbs of <span class="math">\\log b</span> bits each (<span class="math">b</span> is a parameter of the hash function). In turn, <span class="math">v_{b}</span> is embedded in a vector of polynomials <span class="math">\\mathbf{w}=(w_{1},w_{2},\\cdots,w_{m})\\in\\mathcal{R}^{m}</span> such that each entry of <span class="math">v_{b}</span> corresponds to a coefficient in <span class="math">\\mathbf{w}</span> in order. Given a randomly sampled public hashing key <span class="math">\\mathbf{A}=(A_{0},A_{1},\\cdots,A_{m})\\in\\mathcal{R}^{m}</span>, the digest <span class="math">h_{v}</span> is obtained as the coefficients of the polynomial</p>

    <p class="text-gray-300"><span class="math">h_{v}(X)=\\sum_{i}A_{i}(X)w_{i}(X)</span></p>

    <p class="text-gray-300">.</p>

    <h4 id="sec-18" class="text-lg font-semibold mt-6">Self-Recursion</h4>

    <p class="text-gray-300">Vortex itself is transformed into a PIOP, and in order to convert this PIOP into a SNARK, we develop a technique that we call self-recursion. At a very high level, we design a Wizard-IOP for verifying Vortex proofs. This Wizard-IOP can be once again compiled through the Arcane compiler and Vortex. As a result, we obtain a shorter proof at the cost of a small overhead on the prover time. This operation can be repeated, and after <span class="math">O(\\log\\log n)</span> iterations, we obtain a short interactive proof that can be compiled into a SNARK using the Fiat-Shamir transform. Our self-recursion technique relies heavily on the fact that the Vortex verifier uses the Ring-SIS hash for hashing the columns and the Reed-Solomon code to encode the alleged evaluations <span class="math">u</span>. Indeed, these two operations are amenable to cheap arithmetization and probabilistic tests (due to their linear structures). Thus, they allow a very efficient recursion procedure.</p>

    <h2 id="sec-19" class="text-2xl font-bold">2 Preliminaries</h2>

    <p class="text-gray-300">Here we define the syntax of our main building blocks; SNARKs and polynomial commitment schemes (PCS).</p>

    <h3 id="sec-20" class="text-xl font-semibold mt-8">2.1 Argument of Knowledge</h3>

    <p class="text-gray-300">We define <span class="math">\\mathcal{R}_{\\lambda}</span> to be a relation generator (i.e., <span class="math">\\mathcal{R}\\leftarrow\\mathcal{R}_{\\lambda}</span>) such that <span class="math">\\mathcal{R}</span> is a polynomial time decidable binary relation. For <span class="math">\\mathcal{R}(x,w)</span>, we call <span class="math">x</span> as the statement and <span class="math">w</span> as the witness. The set of true statements is denoted by <span class="math">\\mathcal{L}_{\\mathcal{R}}=\\{x:\\exists\\ w\\ \\text{s.t.}\\ \\mathcal{R}(x,w)=1\\}</span>. The definitions in this section are mainly borrowed from <em>[33]</em>.</p>

    <p class="text-gray-300">###</p>

    <h6 id="sec-21" class="text-base font-medium mt-4">Definition 1 (<em>Non-Interactive</em> Arguments for <span class="math">\\mathcal{R}_{\\lambda}</span>).</h6>

    <p class="text-gray-300">A Non-Interactive Argument for <span class="math">\\mathcal{R}_{\\lambda}</span> is a tuple of three p.p.t. algorithms <span class="math">(\\mathsf{Setup},\\mathsf{Prove},\\mathsf{Verify})</span> defined as follows,</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\sigma\\leftarrow\\mathsf{Setup}(\\mathcal{R})</span>: on input <span class="math">\\mathcal{R}\\leftarrow\\mathcal{R}_{\\lambda}</span> generates a reference string <span class="math">\\sigma</span>. All the other algorithms implicitly receive the relation <span class="math">\\mathcal{R}</span>.</li>

      <li><span class="math">\\pi\\leftarrow\\mathsf{Prove}(\\sigma,x,w)</span>: it receives the reference string <span class="math">\\sigma</span>, statement <span class="math">x</span> and witness <span class="math">w</span>. If <span class="math">\\mathcal{R}(x,w)=1</span> it outputs a proof <span class="math">\\pi</span>.</li>

      <li><span class="math">1/0\\leftarrow\\mathsf{Verify}(\\sigma,x,\\pi)</span>: it receives the reference string <span class="math">\\sigma</span>, the statement <span class="math">x</span> and the proof <span class="math">\\pi</span> and returns <span class="math">0</span> (reject) or <span class="math">1</span> (accept).</li>

    </ul>

    <h6 id="sec-22" class="text-base font-medium mt-4">Definition 2 (Completeness).</h6>

    <p class="text-gray-300">Completeness says that given a true statement <span class="math">x\\in\\mathcal{L}_{\\mathcal{R}}</span>, the prover can convince the honest verifier; for all <span class="math">\\lambda\\in\\mathbb{N},\\ \\mathcal{R}\\in\\mathcal{R}_{\\lambda},x\\in\\mathcal{L}_{\\mathcal{R}}</span>:</p>

    <p class="text-gray-300"><span class="math">\\Pr\\left[1=\\mathsf{Verify}(\\sigma,x,\\pi):\\ \\sigma\\leftarrow\\mathsf{Setup}(\\mathcal{R}),\\ \\pi\\leftarrow\\mathsf{Prove}(\\sigma,x,w)\\right]=1</span></p>

    <h6 id="sec-23" class="text-base font-medium mt-4">Definition 3 (Soundness).</h6>

    <p class="text-gray-300">An argument of knowledge is sound if it is not feasible to convince the verifier of a wrong statement. More formally, for any non-uniform p.p.t. adversary <span class="math">\\mathcal{A}</span> we have,</p>

    <p class="text-gray-300"><span class="math">\\Pr[1=\\mathsf{Verify}(\\sigma,x,\\pi)\\ \\wedge\\ x\\notin\\mathcal{L}_{\\mathcal{R}}:\\ \\mathcal{R}\\leftarrow\\mathcal{R}_{\\lambda},\\ \\sigma\\leftarrow\\mathsf{Setup}(\\mathcal{R}),\\ (x,\\pi)\\leftarrow\\mathcal{A}(\\sigma)]\\approx 0</span></p>

    <h6 id="sec-24" class="text-base font-medium mt-4">Definition 4 (Knowledge-Soundness).</h6>

    <p class="text-gray-300">Knowledge-soundness strengthens the notion of soundness by adding an extractor that can compute a witness from a given valid proof. The extractor gets full access to the adversary’s state, including any random coins. Formally, for any non-uniform p.p.t adversary <span class="math">\\mathcal{A}</span> there exists a non-uniform (expected polynomial time) extractor <span class="math">\\mathcal{X}_{\\mathcal{A}}</span> such that:</p>

    <p class="text-gray-300">\\[ \\Pr\\left[1=\\mathsf{Verify}(\\sigma,x,\\pi)\\ \\wedge\\mathcal{R}(x;w)=0:\\ \\begin{array}[]{l}\\mathcal{R}\\leftarrow\\mathcal{R}_{\\lambda},\\ \\sigma\\leftarrow\\mathsf{Setup}(\\mathcal{R}),\\\\ ((x,\\pi),w)\\leftarrow(\\mathcal{A}\\parallel\\mathcal{X}_{\\mathcal{A}})(\\sigma)\\end{array}\\right]\\approx 0 \\]</p>

    <p class="text-gray-300">The advantage of the adversary in the knowledge-soundness game (the probability on the left side) is called knowledge-error.</p>

    <p class="text-gray-300">Compared to a non-interactive argument of knowledge, a succinct non-interactive argument of knowledge, or SNARKs, adds a requirement of succinctness. In short and informally, the proof and the verifier time must be small compared with the witness of the relation being proven. We adopt a broad notion of succinctness by only requiring the polylogarithmic proof size and verifier runtime in the witness size.</p>

    <h6 id="sec-25" class="text-base font-medium mt-4">Definition 5 (Succinctness, SNARK).</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A non-interactive argument system <span class="math">\\mathcal{X}</span> for a relation <span class="math">\\mathcal{R}_{\\lambda}</span> is succinct if the size of the proof <span class="math">\\pi</span> produced by the prover and the run-time of the verifier is $O(\\mathsf{polylog}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">, for all relations </span>\\mathcal{R}<span class="math"> drawn from </span>\\mathcal{R}_{\\lambda}$. A non-interactive argument system with this property is called SNARK.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-26" class="text-xl font-semibold mt-8">2.2 Roots of unity and Lagrange polynomials</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">\\mathbb{F}_{q}</span> be a finite field of prime order <span class="math">q</span>. We call the roots of the polynomials <span class="math">Z_{k}(X)=X^{k}-1</span> the <span class="math">k</span>-th roots of unity. Together, they form a multiplicative subgroup <span class="math">\\Omega_{k}</span> of <span class="math">\\mathbb{F}_{q}^{*}</span>, provided that $k</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">q-1<span class="math">. We say that </span>Z_{k}(X)=X^{k}-1<span class="math"> is the vanishing polynomial of </span>\\Omega_{k}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We assume <span class="math">k</span> is a power of <span class="math">2</span>, for each subgroup <span class="math">\\Omega_{k^{\\prime}}</span> of <span class="math">\\Omega_{k}</span> (thus, $k^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">k<span class="math">), we have </span>\\omega^{\\prime}=\\omega^{k/k^{\\prime}}<span class="math"> where </span>\\omega<span class="math"> and </span>\\omega^{\\prime}<span class="math"> are the generator of </span>\\Omega_{k}<span class="math"> and </span>\\Omega_{k^{\\prime}}$ (res.).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">For any subgroup <span class="math">\\Omega_{k}</span>, the collection of polynomials given by <span class="math">(\\mathcal{L}_{\\omega,\\Omega_{k}}(X))_{\\omega\\in\\Omega_{k}}</span> forms the Lagrange basis for polynomials of degree <span class="math">k-1</span> where,</p>

    <p class="text-gray-300"><span class="math">\\forall\\omega\\in\\Omega_{k}:\\mathcal{L}_{\\omega,\\Omega_{k}}(X)=\\frac{\\omega(X^{k}-1)}{k(X-\\omega)}</span></p>

    <p class="text-gray-300">Let <span class="math">v=(v_{1},\\cdots,v_{k})</span> be a vector of <span class="math">\\mathbb{F}^{k}.</span> We call <span class="math">v(X)</span> the polynomial encoding <span class="math">v</span> and we will often implicitly refer to a vector and its polynomial encoding with the same notation.</p>

    <p class="text-gray-300"><span class="math">v(X)=\\sum_{i\\in[k]}v_{i}\\mathcal{L}_{\\omega^{i},\\Omega_{k}}(X)=\\frac{X^{k}-1}{k}\\sum_{i\\in[k]}v_{i}\\cdot\\frac{\\omega^{i}}{X-\\omega^{i}}</span></p>

    <p class="text-gray-300">When <span class="math">k</span> is implicit, we use <span class="math">\\omega,\\Omega</span> and <span class="math">L_{\\omega}</span> instead of <span class="math">\\omega_{k},\\Omega_{k}</span> or <span class="math">L_{\\omega,\\Omega_{k}}</span> for convenience in our notations.</p>

    <h6 id="sec-27" class="text-base font-medium mt-4">Definition 6 (Domain Selector).</h6>

    <p class="text-gray-300">We define the (sub)domain-selector as the polynomial <span class="math">Z_{n,kn}(X)</span> that is <span class="math">1</span> over the subgroup <span class="math">\\Omega_{n}</span> of <span class="math">\\Omega_{nk}</span>, and zero everywhere else. Namely, we have <span class="math">Z_{n,kn}(X)=\\sum_{j=0}^{n-1}\\mathcal{L}_{\\omega^{kj},\\Omega_{kn}}(X)</span> and <span class="math">\\omega</span> (res. <span class="math">\\omega^{k}</span>) being the generator of <span class="math">\\Omega_{nk}</span> (res. <span class="math">\\Omega_{n}</span>).</p>

    <h3 id="sec-28" class="text-xl font-semibold mt-8">2.3 Polynomial Commitments</h3>

    <h6 id="sec-29" class="text-base font-medium mt-4">Definition 7.</h6>

    <p class="text-gray-300">A polynomial commitment is a tuple of p.p.t. algorithms <span class="math">(\\mathsf{Setup},\\mathsf{Commit},\\mathsf{Open})</span> where,</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{pp}\\leftarrow\\mathsf{Setup}(1^{\\lambda},t)</span> generates the public parameters <span class="math">\\mathsf{pp}</span> suitable to commit to polynomials of degree <span class="math">&lt;k</span>.</li>

      <li><span class="math">C\\leftarrow\\mathsf{Commit}(\\mathsf{pp},P(X))</span> outputs a commitment <span class="math">C</span> to a polynomial <span class="math">P(X)</span> of degree at most <span class="math">k</span> using <span class="math">\\mathsf{pp}</span>.</li>

      <li><span class="math">1/0\\leftarrow\\mathsf{Open}(\\mathsf{pp},C,x,y;P(X))</span> is a (public-coin) protocol between the prover and the verifier where the prover aims to prove the relation;</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\mathcal{R}=\\{(x,y,C;P(X)):\\ P(x)=y,C=\\mathsf{Commit}(\\mathsf{pp},P(X))\\}</span></p>

    <p class="text-gray-300">In this protocol, the prover’s input is <span class="math">(P(X),x,y,C,\\mathsf{pp})</span> and the verifier’s input is <span class="math">(x,y,C,\\mathsf{pp})</span>. The output of the protocol is <span class="math">1</span> if the verifier accepts the proof and <span class="math">0</span> otherwise.</p>

    <p class="text-gray-300">We use the definition of the correctness and the knowledge-soundness from <em>[7]</em>.</p>

    <h3 id="sec-30" class="text-xl font-semibold mt-8">2.4 IOPs and Polynomial-IOPs</h3>

    <p class="text-gray-300">An interactive oracle proof (IOP) for a relation <span class="math">\\mathcal{R}(x,w)</span> is an interactive proof in which the verifier is not required to read the prover’s messages in their entirety; rather, the verifier has oracle access to the prover’s messages, and may probabilistically query them. In polynomial IOP (PIOP) the messages are polynomials and the verifier has oracle access to the evaluation of polynomials on the queried points.</p>

    <h3 id="sec-31" class="text-xl font-semibold mt-8">2.5 Reed-Solomon Codes</h3>

    <h6 id="sec-32" class="text-base font-medium mt-4">Definition 8 (Linear Code <em>[49]</em>).</h6>

    <p class="text-gray-300">A linear error-correcting code with message length <span class="math">k</span> and codeword length <span class="math">n</span> with <span class="math">k&lt;n</span> is a linear subspace <span class="math">C\\subset\\mathbb{F}^{n}</span>, such that there exists an injective mapping from message to codeword <span class="math">EC:\\mathbb{F}^{k}\\rightarrow C</span> which is called the encoder of the code. Any linear combination of codewords is also a codeword. The rate of the code is defined as <span class="math">\\rho:=k/n</span>. The distance between two codewords <span class="math">u,v</span> is the number of coordinates on which they differ, denoted as the Hamming distance <span class="math">\\Delta(u,v)</span>. The relative (or fractional Hamming distance) is defined as <span class="math">\\delta(u,v)=\\Delta(u,v)/n</span>. The minimum distance is <span class="math">d:=\\min_{u,v}\\Delta(u,v)</span>.</p>

    <h6 id="sec-33" class="text-base font-medium mt-4">Definition 9 (Reed-Solomon Code).</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Consider positive integers <span class="math">n,k</span>, a finite field <span class="math">\\mathbb{F}</span>, and a set <span class="math">D\\subseteq\\mathbb{F}^{*}</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">D</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=n<span class="math"> (the set </span>D<span class="math"> will be referred to as the domain). The Reed-Solomon code over </span>\\mathbb{F}<span class="math"> with domain </span>D<span class="math"> and the message space of size </span>k$ is defined as:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\mathsf{RS}[\\mathbb{F},D,k]:=\\{p(x)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{x\\in D}:p(X)\\in\\mathbb{F}[X],\\deg(p)\\leq k\\},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">By $p(x)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{x\\in D}<span class="math">, we denote the set of evaluations of </span>p<span class="math"> over the set </span>D<span class="math"> and </span>n=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">D</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> is called the codeword size. For </span>v\\in D<span class="math"> and </span>p\\in\\mathsf{RS}[\\mathbb{F},D,k]<span class="math">, we will also use the notation </span>p</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{v}<span class="math"> to refer to </span>p(v)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">By <span class="math">F_{&lt;n}[X]</span>, we denote the set of polynomials of degree less than or equal to <span class="math">k</span>, i.e.</p>

    <p class="text-gray-300"><span class="math">\\mathbb{F}_{&lt;k}:=\\{p(X)\\in\\mathbb{F}[X]:\\deg(p)\\leq k\\},</span></p>

    <p class="text-gray-300">.</p>

    <h5 id="sec-34" class="text-base font-semibold mt-4">Distance to a Reed-Solomon Code</h5>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Consider arbitrary $f\\in\\mathbb{F}^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">D</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">. The distance of </span>f<span class="math"> from the set </span>V=\\mathsf{RS}[\\mathbb{F},D,k]<span class="math"> is defined as </span>\\Delta(f,V):=\\min_{v\\in V}\\Delta(f,v)$ (and similarly for relative distance).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-35" class="text-lg font-semibold mt-6">2.5.1 Reed-Solomon Codes over Roots of Unity</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In this work, we choose the domain set <span class="math">D=\\Omega_{n}</span> as the set of <span class="math">n^{\\mathrm{th}}</span> roots of unity. Consider a fixed generator <span class="math">\\omega</span> of <span class="math">\\Omega_{k}</span>. Then <span class="math">D=\\{\\omega^{i}\\}_{i=0}^{n-1}</span> and we will associate polynomial evaluations $p(x)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{D}<span class="math">, called codeword space, with vectors </span>(p(\\omega^{0}),p(\\omega^{1})\\dots p(\\omega^{n-1}))<span class="math">, ordered by the natural ordering induced by the exponents of generator </span>\\omega$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-36" class="text-xl font-semibold mt-8">2.6 A General Security Proof for Sub-Protocols</h3>

    <p class="text-gray-300">Apart from the security of Vortex that would be discussed in a separate work, all the sub-protocols that we use (particularly the one for the self-recursion) are secure following the same reasoning. This reasoning heavily depends on Schwartz-Zippel Lemma.</p>

    <h6 id="sec-37" class="text-base font-medium mt-4">Lemma 1 (Schwartz-Zippel Lemma).</h6>

    <p class="text-gray-300">Let <span class="math">P(X)</span> be a non-zero polynomial of degree <span class="math">d</span> over a field <span class="math">\\mathbb{F}</span>. Let <span class="math">S</span> be a finite subset of <span class="math">\\mathbb{F}</span> and let <span class="math">r</span> be selected at random from <span class="math">S</span>. Then</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\Pr_{r\\in\\mathbb{F}}[P(r)=0]\\leq d/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Throughout the paper, we always represent the sub-protocols in the PIOP framework. This would allow us to argue their security in a general manner.</p>

    <h5 id="sec-38" class="text-base font-semibold mt-4">PIOP and its Knowledge-Soundness.</h5>

    <p class="text-gray-300">The PIOP is knowledge-sound if there exists a probabilistic polynomial time algorithm <span class="math">E</span> (called the extractor) which interacts with the prover on a statement <span class="math">x</span> and it has the capability: to run the prover for a specified number of steps, inspect its state and rewind it repeatedly to a previous state. If the prover interactions cause the verifier to accept, the extractor is able to recover a witness <span class="math">w</span> such that <span class="math">R(x,w)=1</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Remark Generally, in many other protocols (and the ones we employ) the PIOP relation is reduced to global constraints which are evaluated at random points. The resulting protocol is secure if the global constraints are satisfied over the random points and if the size of the finite field is large enough (to have negligible probability $d/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> in the Schwartz-Zippel Lemma, </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ should be large). Note that the final protocol is made non-interactive using the final Fiat-Shamir transform and its soundness is not statistical but computational.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">It is well-known that a PIOP can be transformed into a concrete AOK by replacing the oracle with a polynomial commitment. For such a resulting protocol, we have:</p>

    <h6 id="sec-39" class="text-base font-medium mt-4">Lemma 2 (Knowledge-Soundness of AOK).</h6>

    <p class="text-gray-300">If the PIOP and the polynomial commitment are knowledge-sound, then the AOK is knowledge-sound.</p>

    <p class="text-gray-300">Putting everything together, all the sub-protocols can be proven to be knowledge-sound through this general approach: first the reduction of relations to some global constraints, then the Schwartz-Zippel lemma is applied to guarantee that the constraints are satisfied, and finally the oracle of the PIOP is replaced by a polynomial commitment.</p>

    <h3 id="sec-40" class="text-xl font-semibold mt-8">2.7 List Polynomial Commitment</h3>

    <p class="text-gray-300">We now present the syntax and security of the list polynomial commitment. The definitions here follow the ones from Redshift (<em>[36]</em>) but extended to a batched setting. Our presentation closely follows the formalization of <em>[20, 7]</em>. We considered batched openings of multiple polynomials. One difference is that we only consider openings of all these polynomials at the same evaluation point.</p>

    <p class="text-gray-300">The list polynomial commitment has a relaxed binding property, each commitment corresponding to a list of polynomials that is determined by a distance parameter. The commitment can be opened to any of the polynomials belonging to the list. Moreover, the polynomials in the list will jointly agree on the same agreement set.</p>

    <h6 id="sec-41" class="text-base font-medium mt-4">Definition 10 ((Batched) List Polynomial Commitment).</h6>

    <p class="text-gray-300">A list polynomial commitment scheme is a triplet <span class="math">(\\mathsf{Setup},\\mathsf{Commit},\\mathsf{OpenEval})</span> that is defined w.r.t. a linear code, distance parameter <span class="math">\\theta</span> and domain <span class="math">D</span>. It satisfies:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{Setup}(1^{\\lambda},k)</span> generates public parameters <span class="math">\\mathsf{pp}</span> (a structured reference string) suitable to commit to polynomials of degree <span class="math">&lt;k</span>. Implicitly, the parameters for encoding are included in <span class="math">\\mathsf{pp}</span>.</li>

      <li><span class="math">\\mathsf{Commit}(\\mathsf{pp},f_{1}(X)\\ldots f_{n}(X))</span> outputs a commitment <span class="math">C</span> to functions <span class="math">f_{1}(X)\\ldots f_{n}(X)\\in\\mathbb{F}[X]</span></li>

      <li><span class="math">\\mathsf{OpenEval}</span> is an IOP between a prover <span class="math">P_{\\mathrm{PC}}</span> and a verifier <span class="math">V_{\\mathrm{PC}}</span>, where the prover is given <span class="math">n</span> functions <span class="math">f_{1}(X)\\ldots f_{n}(X)\\in\\mathbb{F}[X]</span> and attempts to convince the verifier of the following relation:</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\exists A\\subset D\\ \\mathrm{s.t}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq(1-\\theta)\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">D</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\ \\mathrm{and}\\ \\exists(P_{1}\\ldots P_{n})\\in(\\mathbb{F}^{<k}[X])^{n}\\ \\mathrm{s.t.}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\wedge\\ C=\\mathsf{Commit}(\\mathsf{pp},f_{1}\\ldots f_{n})</span></p>

    <p class="text-gray-300">where both parties receive the following:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>security parameter <span class="math">\\lambda</span>, degree bound <span class="math">k</span> and batch size <span class="math">n</span>, such that <span class="math">k,n=\\text{poly}(\\lambda)</span>.</li>

      <li>The public parameters <span class="math">\\mathsf{pp}</span>, where <span class="math">\\mathsf{pp}=\\mathsf{Setup}(1^{\\lambda},k)</span>.</li>

      <li>An evaluation point <span class="math">x</span> and alleged openings <span class="math">y=(y_{1}\\ldots y_{n})</span>.</li>

      <li>Alleged commitment <span class="math">C</span> for functions <span class="math">f_{1}(X)\\ldots f_{n}(X)</span>.</li>

    </ul>

    <p class="text-gray-300">In addition, the verifier receives oracle access to evaluations of <span class="math">f_{i}</span> over <span class="math">D</span>.</p>

    <h6 id="sec-42" class="text-base font-medium mt-4">Definition 11 (Completeness of a List Polynomial Commitment Scheme).</h6>

    <p class="text-gray-300">We say that a polynomial commitment scheme has (perfect) completeness if for any security parameter <span class="math">\\lambda</span>, any integers <span class="math">k,n=\\text{poly}(\\lambda)</span>, any polynomials <span class="math">P_{1}(X)\\ldots P_{n}(X)\\in\\mathbb{F}_{&lt;k}[X]</span>, arbitrary evaluation point <span class="math">x</span> and alleged opening <span class="math">y</span>, if <span class="math">C=\\mathsf{Commit}(\\mathsf{pp},P_{1}(X)\\ldots P_{n}(X))</span> and <span class="math">P_{i}(x)=y_{i}</span> for all <span class="math">i\\in[n]</span> then an interaction of <span class="math">(P_{\\mathrm{PC}},V_{\\mathrm{PC}})</span> where <span class="math">P_{\\mathrm{PC}}</span> runs on the aforementioned parameters will result in the verifier accepting with probability one.</p>

    <h6 id="sec-43" class="text-base font-medium mt-4">Definition 12 (Knowledge Soundness in the Random Oracle Model).</h6>

    <p class="text-gray-300">There must exist a <span class="math">\\mathrm{PPT}</span> extractor <span class="math">E</span> such that for every <span class="math">\\mathrm{PPT}</span> adversary <span class="math">\\mathcal{A}</span> and arbitrary degree <span class="math">k=\\text{poly}(\\lambda)</span>, the probability that <span class="math">\\mathcal{A}</span> wins the following game is negligible, where the probability is taken over the coins of <span class="math">\\mathsf{Setup}</span>, <span class="math">\\mathcal{A}</span> and <span class="math">V_{\\mathrm{PC}}</span>. Moreover, the extractor has access to the random oracle queries of <span class="math">\\mathcal{A}</span>:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{A}</span> receives degree <span class="math">k</span> and <span class="math">\\mathsf{pp}=\\mathsf{Setup}(1^{\\lambda},k)</span>. <span class="math">\\mathcal{A}</span> outputs <span class="math">C</span>.</li>

      <li><span class="math">E</span> receives the commitment <span class="math">C</span> and inspects the random oracle queries made by <span class="math">A</span> in the previous step and recovers <span class="math">f_{1}(X)\\ldots f_{n}(X)\\in[X]</span>.</li>

      <li><span class="math">E</span> applies the efficient list-decoding algorithm on all <span class="math">f_{i}</span> simultaneously to obtain list <span class="math">L</span>, defined as:</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\[ L=\\left\\{(P_{1}(X),\\ldots,P_{n}(X))\\in(\\mathbb{F}^{<k}[X])^{n}\\ \\mathrm{s.t.}\\begin{array}[]{c}\\exists A\\subset D,\\ \\mathrm{s.t.}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">D</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\cdot(1-\\theta)\\\\</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{A}</span> outputs an evaluation point <span class="math">x</span> and claimed openings <span class="math">y:=(y_{i})_{i}</span>.</li>

      <li><span class="math">\\mathcal{A}</span> interacts with the <span class="math">V_{\\mathrm{PC}}</span> verifier of the <span class="math">\\mathsf{OpenEval}</span> algorithm. The inputs of <span class="math">\\mathcal{A}</span> for this subprotocol are <span class="math">C</span>, <span class="math">x</span> and <span class="math">y</span>.</li>

      <li>The extractor may check consistency and output a set <span class="math">S</span> of witnesses, where <span class="math">S\\subseteq L</span>.</li>

      <li><span class="math">\\mathcal{A}</span> succeeds if <span class="math">V_{\\mathrm{PC}}</span> accepts and there exists no tuple <span class="math">(P_{1}(X)\\ldots P_{n}(X))\\in L</span> such that <span class="math">P_{i}(x)=y_{i}</span> for all <span class="math">i\\in[n]</span>.</li>

    </ul>

    <p class="text-gray-300">##</p>

    <h2 id="sec-44" class="text-2xl font-bold">3 Linea’s Proof System Overview</h2>

    <p class="text-gray-300">This section outlines the structure of the prover’s stack of Linea and provides a high-level description of its subcomponents. Linea’s proof system is designed to ensure the integrity and efficiency of transactions within the Ethereum Virtual Machine (EVM) through a multi-faceted approach involving several specialized circuits and proof systems. Each circuit plays a critical role in validating different aspects of transaction execution and data compression, culminating in an aggregated proof. Below, we detail the components of the proof systems and their respective functionalities. The current document does not detail the compression proof and aggregation proofs beyond the current section and is essentially focused around the execution proof system.</p>

    <h3 id="sec-45" class="text-xl font-semibold mt-8">3.1 Execution proof</h3>

    <p class="text-gray-300">The execution proof is pivotal in validating the correct execution of transactions within the EVM. It employs a proof structure that integrates the work Vortex <em>[13]</em> and <em>[12]</em> and Plonk <em>[7]</em>. It represents the largest part of this work and is comprehensively described in Section 5, Section 6 Section 7, Section 8 and Section 9). The finality of this process is a Plonk proof based on the BLS12-377 curve. As an outline, the execution proof is generated from a set of execution traces satisfying the constraints of <span class="math">alex:ref</span> and from a set of EVM state accumulator proofs (see Appendix C) justifying the state-root transition allegedly from a state-diff indicated in the traces. The execution proofs statement includes:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>knowledge of EVM traces satisfying the arithmetization constraints</li>

      <li>correctness of the state-accumulator traces and their consistency with the EVM traces.</li>

      <li>the correctness of the execution of the precompiles, Keccak and Secp256k1 ECDSA verifications.</li>

      <li>the consistency of the public inputs of the proof with the above (state root hash transition, encoded transactions, timestamps, bridge-messages</li>

    </ul>

    <p class="text-gray-300">This is accomplished by following a multi-step cryptographic compilation process</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>A dedicated protocol in the Wizard-IOP model described in Section 4 is constructed specifically for the relation of the execution proof.</li>

      <li>The Wizard-IOP protocol is compiled down to a SNARK following the steps described in Section 5, Section 6 Section 7, Section 8 and Section 9. This is achieved by repeating a cycle of self-recursion compilation.</li>

      <li>The resulting SNARK is recursively verified within a Plonk proof to prepare it for the aggregation step</li>

    </ol>

    <h3 id="sec-46" class="text-xl font-semibold mt-8">3.2 Compression proof</h3>

    <p class="text-gray-300">Complementary to the execution proof, the Compression Circuit focuses on verifying the effective compression of data streams, which constitute the inputs for the EVM execution circuit. This verification is crucial for ensuring that the compressed data, once submitted on the Ethereum blockchain, can be accurately decompressed to reveal the essential inputs for the execution circuit’s validation process. The Compression Circuit utilizes the Plonk proof system also based on the BLS12-377 curve, to generate proofs of correct data compression.</p>

    <h3 id="sec-47" class="text-xl font-semibold mt-8">3.3 Finalization (Aggregation) proof</h3>

    <p class="text-gray-300">At the core of Linea’s proof system lies the Finalization (or Aggregation) Circuit, which serves as the linchpin for recursively verifying proofs generated by <span class="math">N</span> execution circuits and <span class="math">M</span> compression circuit instances. This circuit embodies the primary assertion of Linea’s prover system and is the only circuit subjected to external verification. It leverages a composite proof system that combines several Plonk circuits on the BW6, BLS12-377, and BN254 curves. This strategic use of 2-chained curves—BLS12-377 and BW6—enables efficient recursion of proofs. The final proof is formulated on the BN254 curve, chosen for its efficient verifiability on Ethereum, facilitated by the availability of precompiles. The aggregation proof is also responsible for “connecting” the public inputs of all proofs and assessing their consistency the public inputs of the final aggregation proof.</p>

    <p class="text-gray-300">4 Wizard IOP</p>

    <p class="text-gray-300">The prover <span class="math">\\mathcal{P}</span> of an IOP protocol<em>[15]</em> provides oracle access to (possibly large) messages to a verifier <span class="math">\\mathcal{V}</span>. The verifier can then send certain kinds of queries (from a small family) to the oracle. Several variants of IOP exist in the literature. In particular, polynomial-IOPs <em>[40]</em>, <em>[25]</em>, <em>[7]</em> specify a model in which all prover messages are viewed as polynomials and the verifier may make queries to evaluations of these polynomials at random points of the verifier’s choice. More recent works study tensor-IOP <em>[21]</em> protocols in which the verifier is granted the right to query scalar-products of the prover’s messages (seen as vectors over a field) by random vectors with the restriction that these vectors must have a tensor structure.</p>

    <p class="text-gray-300">Wizard-IOPs specify a model that extends this perspective on IOPs. The prover sends oracle access to vectors (columns) over a given field with a prespecified size and the verifier is allowed to perform queries chosen from a wide class: inclusion, permutation, inner-product, global-constraints. The terminology column is also used to denote prover messages or offline precomputed vectors of values. As we explain later in this section, queries can involve several columns or “abstract references” to them. We elaborate on the notion of “abstract references” later, but to give an initial idea: taking the “cyclic shift” of a column <span class="math">v</span> would be considered an “abstract reference”. The backbone idea behind Wizard-IOP is that it allows us to specify ever more complex protocols in the simplest possible way while intermediate protocol design techniques (such as proving a lookup relation or a permutation relation) are treated as automatable compilation steps. Subsequently, instead of mentally building modular protocols from the bottom up using the notion of univariate queries as atoms of a more complex system, the framework of Wizard-IOP allows specifying protocols with a top-down approach. We start from an abstract protocol and work out an optimized polynomial-IOP throughout the steps of the Arcane compiler Section 5. While this simplifies protocol specification and security analysis, it also allows to automate optimizations and batching techniques. The zk-EVM arithmetization specified in <em>[10]</em> involves hundreds of columns and thousands of constraints. It would be extremely tedious to manually unfold all the sub-protocols and optimization techniques required in order to present a concrete polynomial-IOP for this arithmetization. However, since their description is written in a formalism closely matching the Wizard-IOP model, we can almost directly transpile their arithmetization into a Wizard-IOP. Another advantage to reasoning in terms of compilation steps rather than sub-protocols is that it facilitates maintenance processes. Assuming that a new (purely hypothetical) batching technique for “range-check” is discovered and improves the prover’s runtime by a factor of 2, then we could simply add it to the compiler and this will propagate on every Wizard-specified protocol. Similarly, if a vulnerability is found in one of the techniques, fixing a compiler step will fix all protocols using it without any risk of forgetting any part.</p>

    <h3 id="sec-48" class="text-xl font-semibold mt-8">4.1 Random coins</h3>

    <p class="text-gray-300">The Wizard-IOP framework allows declaring random coins as part of the protocol. As in public-coin protocol, random coins are random messages sent by the verifier to the prover. Registered coins can then be used in the following parts of the protocol. The framework offers two types of coins: (1) random field: field elements on a field of size approximately 256 bits (2) random integer vector a list of integers of bounded size, usually representing random positions in a vector.</p>

    <h3 id="sec-49" class="text-xl font-semibold mt-8">4.2 Columns</h3>

    <p class="text-gray-300">Columns are the cornerstone of the Wizard-IOP framework. They symbolically represent a vector of values used as part of the protocol in a broad sense. They can be used to denote portions of the witness, messages sent to the verifier, portions of the proving or verifying key or intermediate committed values. Columns are declared as part of the protocol definition along with their sizes (restricted to be a power of two) and their visibility (e.g. whether the column is meant to be sent to the verifier, or to be part of the witness).</p>

    <p class="text-gray-300">The framework allows the following column’s visibilities:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Ignored: this marks the column as ”already compiled” and being disregardable by the compiler. They still exist in the protocol but stay purely internal to the prover. An example is: when “Committed” columns are eventually committed to, the compiler sets the “Ignored” tag on the column to indicate there is no need to commit a second time to it.</li>

      <li>Committed: this marks the column as being sent to the oracle. Implicitly, this indicates the intent to commit to this column during the compilation phase and to keep its content as part of the witness or an intermediate value visible only by the prover.</li>

      <li>Proof: this marks the column as being sent to the verifier directly</li>

      <li>Precomputed: this indicates that the column’s assignment is (1) internal to the prover, (2) destined to be committed to, (3) known at compile time.</li>

      <li>Verifying-key: the marks the column’s assignment as visible by the verifier and known at compile time.</li>

      <li>Verifier-defined: this indicates that the column is entirely constructible by the verifier from other values that the verifier has at its disposal. For instance, a column constructed by stacking the multiple of several random coins would bear this tag.</li>

    </ul>

    <h4 id="sec-50" class="text-lg font-semibold mt-6">4.2.1 Abstract references</h4>

    <p class="text-gray-300">Abstract references are a useful way to refer to vectors directly derived from pre-existing committed columns. These operators can be combined and used as the object of a query. For instance, one might declare a global constraint involving a cyclically shifted version of a committed column <span class="math">v</span> rather than on the entirety of the positions of <span class="math">v</span>. Importantly, abstract references are neither committed columns nor predicates about columns but can be seen as a way to make queries about committed columns more expressive. Abstract references do not have a status on their own as they may involve several queries having a different status in the protocol.</p>

    <p class="text-gray-300">Expression: defined as a polynomial expression involving columns of the same size and possibly scalar values.</p>

    <p class="text-gray-300">Cyclic shifting: Given a vector <span class="math">v</span> and an integer <span class="math">k</span> (possibly negative), we return a cyclically-shifted version of <span class="math">v</span> by <span class="math">k</span> elements. We may use the notation <span class="math">v\\ll k</span> to refer to the resulting vector.</p>

    <h4 id="sec-51" class="text-lg font-semibold mt-6">4.2.2 Verifier defined columns</h4>

    <p class="text-gray-300">Verifier-defined columns are columns that are constructed from other values known from the verifier. They are typically tiny or have a very sparse structure.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Periodic sampling: A periodic sampling column is a column repeating a sequence of the form <span class="math">1,0,0,0,\\ldots</span> where the pattern size is a power of two.</li>

      <li>Position indicatrice: A column that contains zeroes in every position except for a prespecified one.</li>

      <li>Constant column: A column whose position are all equal to a prespecified constant</li>

      <li>Integer vector coin: A column built by taking the values of a random integers vector coin, padded with a constant value.</li>

      <li>Stacked values: A column built by stacking values known by the verifier (including columns) padded with a constant.</li>

    </ul>

    <h3 id="sec-52" class="text-xl font-semibold mt-8">4.3 Available queries</h3>

    <p class="text-gray-300">In the following, we list and describe the queries available to the verifier <span class="math">\\mathcal{V}</span> in the wizard-IOP framework.</p>

    <p class="text-gray-300">Range check Let <span class="math">B</span> be a constant bound. The query is made over a column <span class="math">v</span>, and the oracle responds with <span class="math">1</span> if and only if all the entries <span class="math">v_{i}</span> of <span class="math">v</span> satisfy <span class="math">0\\leq v_{i}&lt;B</span>. We denote the range checks as, “Range” : <span class="math">v&lt;B</span>.</p>

    <p class="text-gray-300">Inclusion check (lookup) Given two lists of columns (or tables) <span class="math">S</span> and <span class="math">T</span>, we check that all rows in <span class="math">S</span> should be included among the rows of <span class="math">T</span>, ignoring multiplicities. We denote the inclusion query as, “Inclusion” : <span class="math">S\\subset T</span>.</p>

    <p class="text-gray-300">Inclusion queries also support additional features:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Fragmented tables: The table <span class="math">T</span> can be supplied in the form of several tables with the same number of columns. In this case, the query is understood as holding for the union of the two tables.</li>

      <li>Conditional inclusion: In addition to <span class="math">S</span> and <span class="math">T</span>, the user can provide a query filter <span class="math">F</span>. The inclusion constraints will be considered as ”void” in positions where the filter <span class="math">F</span> is zero.</li>

    </ul>

    <p class="text-gray-300">Fixed permutation check Given two lists of columns (seen as tables) and any (imposed) fixed permutation <span class="math">\\sigma</span>, the oracle checks if the <span class="math">i^{\\text{th}}</span> row in <span class="math">S</span> must equal the row at index <span class="math">\\sigma(i)</span> in <span class="math">T</span> for all rows <span class="math">i</span> of <span class="math">S</span>. If and only if that is the case, the oracle returns <span class="math">1</span>, otherwise <span class="math">0</span>. The tables <span class="math">S</span> and <span class="math">T</span> must have the same number of rows. We denote a fixed permutation check as, “FixedPermutation” : <span class="math">S\\sim_{\\sigma}T</span>.</p>

    <p class="text-gray-300">Fixed-permutation queries also support optional features:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Fragmented tables: The table <span class="math">T</span> and <span class="math">S</span> can be supplied in the form of several tables with the same number of columns. In this case, the query is understood as holding for the union of the two tables.</li>

    </ul>

    <p class="text-gray-300">Permutation check Given two tables (e.g. two lists of tables) <span class="math">S</span> and <span class="math">T</span>, all rows in <span class="math">S</span> should be included among the rows of <span class="math">T</span> (and vice-versa), accounting for multiplicities. Thus, <span class="math">S</span> and <span class="math">T</span> must have the same number of rows. Note that in fixed permutation queries, <span class="math">\\sigma</span> is imposed. Here the oracle accepts if a permutation <span class="math">\\sigma</span> exists. We denote a permutation query as, “Permutation”: <span class="math">S\\sim T</span>.</p>

    <p class="text-gray-300">Permutation queries also support optional features:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Fragmented tables: The table <span class="math">T</span> and <span class="math">S</span> can be supplied in the form of several tables with the same number of columns. In this case, the query is understood as holding for the union of the two tables.</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Inner product query Given two columns <span class="math">A</span> and <span class="math">B</span>, as well as a scalar <span class="math">c</span>, the oracle returns <span class="math">1</span> if and only if $\\langle a</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b\\rangle=c<span class="math">. We use the notation “InnerProduct” : </span>\\langle a</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b\\rangle=c$ to denote the declaration of a query within a protocol or sub-protocol.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Local constraint The verifier evaluates an arithmetic equality involving possibly random coins, particular positions of columns or the result of other queries and returns <span class="math">1</span> if and only if the equality is satisfied. The position at which columns are pointed to must be fixed as part of the protocol definition.</p>

    <p class="text-gray-300">For example, let <span class="math">u,v</span> be two columns to which we have oracle access. We may send the local constraint query “Local”: <span class="math">u[0]-2v[1]==0</span> to ask the oracle if the first entry of <span class="math">u</span> equals the double of the second entry of <span class="math">v</span>. We may conveniently express local constraints over polynomials (rather than vectors) over fixed points.</p>

    <p class="text-gray-300">Global constraint Given a <span class="math">k</span>-variate arithmetic expression <span class="math">\\mathcal{C}</span> whose (total) degree should be reasonably low and a list of <span class="math">k</span> columns <span class="math">v_{1},\\cdots,v_{k}</span> of the same size <span class="math">n</span> and possibly other scalar values arising in the protocol (random coins, query response, <span class="math">\\ldots</span>). The oracle returns <span class="math">1</span> if and only if for all <span class="math">i</span>, <span class="math">\\mathcal{C}(v_{1,i},\\cdots,v_{k,i})=0</span>.</p>

    <p class="text-gray-300">For instance, the global constraint “Global”: <span class="math">\\mathsf{Shift}(u,1)-u=0</span> asserts that “all” the entries of <span class="math">u</span> are equal to the next consecutive entry of <span class="math">u</span>. Thus, this constraint asserts that all entries of <span class="math">u</span> are equal. Again, we may express a Global constraint based on polynomials (rather than vectors) when convenient.</p>

    <p class="text-gray-300">Global constraints also support the following optional feature:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Bound cancellation: unless specifically stated otherwise, Global constraints are cancelled implicitly at positions where the cyclic shifts wraps around. In the above, example the Global constraint would be ineffective on the last row. This behaviour is motivated by the fact that this is what is intended most of the time.</li>

    </ul>

    <p class="text-gray-300">Local position opening: Given a column <span class="math">A</span> and a position <span class="math">k</span> indexing a row of the column <span class="math">A</span>, the oracle returns <span class="math">y=A_{k}</span></p>

    <p class="text-gray-300">Univariate evaluations (UniEval) For a column <span class="math">v</span> of size <span class="math">n</span>, let the polynomial <span class="math">v(X)</span> evaluate to <span class="math">v_{i}</span> on a subgroup of <span class="math">n</span>-roots of unity. The oracle returns a univariate evaluation of <span class="math">v(X)</span> over an unspecified point (possibly a random point) chosen by the verifier. For convenience, we will usually talk about one univariate query for multiple polynomials to let the compiler know these are queried at the same point. Note that they are not natively supported in the initial protocol definition. The reason is that (1) Lagrange basis evaluations are not nicely compatible with how the columns are segmented in the splitting compiler in Section 5 (2) the use cases we know of for this are niche (although far from irrelevance). Nonetheless, it is still possible to emulate Lagrange basis evaluation in the Wizard-IOP framework without using the Univariate query. We refer the reader to section Appendix A.2 for an example.</p>

    <h2 id="sec-53" class="text-2xl font-bold">5 The Arcane Compiler: Polynomial-IOP from Wizard-IOP</h2>

    <p class="text-gray-300">The Arcane compiler is a cryptographic compiler that converts Wizard Interactive Oracle Proofs (IOPs) into Polynomial IOPs through a series of compilation steps. Each step is designed to perform either minor optimizations or apply reduction techniques to simplify the protocol by reducing the variety of queries it uses. The process begins with substituting the range checks in favour of inclusion checks, which are then further simplified into local and global constraints. The process continues substituting queries for others until it ultimately yields a Polynomial IOP, where the only remaining queries are of type “univariate”. The compilation is performed in such a way that the protocol retains its functionality throughout the compilation phases only suffering minor polynomial statistical soundness losses.</p>

    <p class="text-gray-300">The Arcane compiler also addresses the challenge of working with columns of heterogeneous sizes and outputs a P-IOP whose oracle-message (committed columns) are all of the same size. This is achieved thanks to two complementary new techniques: ”column splitting” and “column sticking”. The former works by segmenting large columns into smaller ones preserving the sequentiality of the cells within the segments. The latter performs the opposite operation, by interleaving small columns into larger ones. An important benefit of this approach is its compatibility with statistical optimizations. Indeed, it turns out the arithmetization of <em>[10]</em> uses columns as CPU registers and prepends the “active” rows (i.e. corresponding to actual EVM execution traces) with padding values so that the resulting columns all have their target sizes. This results in constant column assignment for the corresponding segments and these can be tracked at runtime and lead to practical optimizations for the prover.</p>

    <p class="text-gray-300">The organization of the section follows the compilation sub-routines in order:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Section 5.1 specifies the compilation rules to simplify the range-checks.</li>

      <li>Section 5.2 details the above-mentioned column-splitting phase.</li>

      <li>Section 5.4 explores our techniques for compiling the inclusion queries using methods largely inspired from <em>[34]</em>.</li>

      <li>Section 5.5 and Section 5.6 discuss the reduction of the fixed-permutations and the permutation constraints, highlighting techniques inspired from <em>[9]</em> and <em>[7]</em>.</li>

      <li>Section 5.7 details the compilation of the inner-product queries, presenting en-route an efficient batch argument for inner-products.</li>

      <li>Section 5.8 discusses the aforementioned “column sticking” compilation phase.</li>

      <li>Section 5.11 expands on the techniques used of the compilation of the global constraints, initially presented in <em>[7]</em></li>

      <li>Section 5.12 concludes the Arcane compilation ironing out all the remaining artefacts into proper univariate queries.</li>

    </ul>

    <p class="text-gray-300">5.1 Reduction of the range checks</p>

    <p class="text-gray-300">We opt for a simple method for compiling range checks. During a preprocessing phase, we send oracle access to a column <span class="math">b=(0,1,2,\\cdots,B-1)</span> (e.g. we tag it as “precomputed”)for each bound <span class="math">B</span> appearing in the input protocol. Then, all range-checks, “Range” <span class="math">v&lt;B</span>, are converted into inclusion checks, assessing if all entries of <span class="math">v</span> are entries of <span class="math">b</span> regardless of the positions or multiplicity.</p>

    <h3 id="sec-54" class="text-xl font-semibold mt-8">5.2 Splitting the large columns</h3>

    <p class="text-gray-300">The splitting compilation step specifically addresses a challenge that we encounter while working with the EVM arithmetization: we are working with columns of heterogeneous sizes and the polynomial commitment Vortex expects a regular matrix to commit to. The splitting step is set with a target column length and its role is to cut all the columns whose length exceeds the target length. To illustrate, say we have a column <span class="math">A</span> of size <span class="math">2^{20}</span> and we have a target size of <span class="math">2^{15}</span>. The splitting step cuts <span class="math">A</span> in 32 consecutive column segments <span class="math">A_{1},\\ldots A_{32}</span> each representing a sequence of <span class="math">2^{15}</span> consecutive values of <span class="math">A</span> and then replaces all occurrences of <span class="math">A</span> in the original protocol by occurrences of <span class="math">A_{1\\ldots 32}</span>, namely in all queries objecting to <span class="math">A</span>.</p>

    <p class="text-gray-300">We detail the replacement procedure for each type of query and abstract references:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Inclusion check: When <span class="math">A</span> is part of the “including” side of the relation, the query is replaced by an equivalent one using the fragmented table feature over the segments <span class="math">A_{1\\ldots 32}</span>. When <span class="math">A</span> is on the “included” side of the query, then the query is replaced by multiple queries, one for each segment.</li>

      <li>Permutation and fixed-permutation checks: the query is replaced by an equivalent one using the fragmented table feature over the segments <span class="math">A_{1\\ldots 32}</span></li>

      <li>Inner product checks: the query is replaced by one equivalent query for each segment. The verifier checks that the sum of the alleged values for each segmented query matches the alleged value for the original one.</li>

      <li>Local openings and local constraints: The query is replaced by an equivalent one pointing to the relevant segment storing the requested position on the original column.</li>

      <li>Global constraints: This is the tricky bit. Naively replacing the constraint by a sequence of equivalent ones on each segment is unfortunately not sufficient. When the original constraints refer to a cyclically shifted version of an original column, applying the same shifting over the segment would cause boundary issues. To remediate, we cancel the constraint on the segments boundaries and add a “stitching” local constraint to cover the cancelled positions.</li>

    </ul>

    <p class="text-gray-300">Similarly, another set of technicalities arises when considering queries referencing columns of type expression and that these expressions refer to cyclically shifted columns. In this case, the “segmented” version of the shifted column overlaps two segments of the non-shifted segment. The compiler addresses to this by reconstructing an equivalent segment for the shifted segment by stitching together cyclic-shifting of the segments of the underlying column. The stitching operation is employed by using the position indicatrice columns, noted <span class="math">I_{k}</span> for position <span class="math">k</span>.</p>

    <p class="text-gray-300">Let <span class="math">A</span> be an original column of size <span class="math">N</span>, split in <span class="math">l</span> segments of size <span class="math">n</span>: <span class="math">A_{1},\\ldots A_{l}</span> and let us consider the reconstruction of the <span class="math">l</span> segments of <span class="math">A\\ll m</span> (noted <span class="math">B_{i}</span>) where <span class="math">m</span> is positive (for negative <span class="math">m</span> substitute <span class="math">m</span> by <span class="math">N+m</span>). Set <span class="math">q=m//n,r=m\\mod n</span> and set <span class="math">I_{[r+1,n)}=\\sum_{p\\in[r+1,n)}I_{p}</span> . <span class="math">B_{i}</span> is constructed as</p>

    <p class="text-gray-300"><span class="math">B_{i}</span> <span class="math">=(A_{i+q}\\ll r)+I_{[r+1,n)}\\left((A_{i+q+1}\\ll r)-(A_{i+q}\\ll r)\\right)</span> <span class="math">=(A_{i+q+1}\\ll r)+I_{[0,r)}\\left((A_{i+q}\\ll r)-(A_{i+q+1}\\ll r)\\right)</span></p>

    <p class="text-gray-300">depending on which one is cheaper to represent.</p>

    <p class="text-gray-300">.</p>

    <h4 id="sec-55" class="text-lg font-semibold mt-6">5.2.1 Example 1: Lookup</h4>

    <p class="text-gray-300">Let <span class="math">A</span> and <span class="math">B</span> be two columns of size 8 and 4 respectively and let a query <span class="math">Q_{L}:\\text{&#x27;}\\hat{\\text{Inclusion}}&quot;:A\\subset B</span>. Consider running the splitting on the resulting input Wizard with a splitting size of 4.</p>

    <p class="text-gray-300"><span class="math">A</span> <span class="math">=(a_{0},a_{1},a_{2},a_{3},a_{4},a_{5},a_{6},a_{7})</span> <span class="math">B</span> <span class="math">=(b_{0},b_{1},b_{2},b_{3})</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The compiler, keeps <span class="math">B</span> as is since it already has the target size. <span class="math">A</span> is replaced by two sub-columns <span class="math">(A_{1},A_{2})</span> of size 4 such that $A=A_{1}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A_{2}<span class="math">. </span>Q_{L}<span class="math"> is also split into two sub-queries </span>Q_{L,1}<span class="math"> and </span>Q_{L,2}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">A_{1}</span> <span class="math">=(a_{0},a_{1},a_{2},a_{3})</span> <span class="math">A_{2}</span> <span class="math">=(a_{4},a_{5},a_{6},a_{7})</span> <span class="math">Q_{L,1}</span> <span class="math">=\\text{\`<code>Inclusion&amp;#x27;&amp;#x27;}:A_{1}\\subset B&lt;/span&gt; &lt;span class=&quot;math&quot;&gt;Q_{L,2}&lt;/span&gt; &lt;span class=&quot;math&quot;&gt;=\\text{</code>\`Inclusion&#x27;&#x27;}:A_{2}\\subset B</span></p>

    <h3 id="sec-56" class="text-xl font-semibold mt-8">5.3 Example 2: Global constraint with shifting</h3>

    <p class="text-gray-300">Let <span class="math">A</span> be a column of size 8 and let <span class="math">Q_{G}</span> be a global constraint involving <span class="math">A</span>:</p>

    <p class="text-gray-300"><span class="math">A</span> <span class="math">=(a_{0},a_{1},a_{2},a_{3},a_{4},a_{5},a_{6},a_{7})</span> <span class="math">Q_{G}</span> <span class="math">=\\text{\`\`Global&#x27;&#x27;}:A+1=A\\ll 1</span></p>

    <p class="text-gray-300">As in the previous example, <span class="math">A</span> is split into two sub-columns <span class="math">A_{1}</span> and <span class="math">A_{2}</span>. The query <span class="math">Q_{G}</span> is also decomposed in two sub-queries <span class="math">Q_{G,1},Q_{G,2}</span>. Observe, that the same query as <span class="math">Q_{G}</span> applied over <span class="math">A_{1}</span> and <span class="math">A_{2}</span> does not work as it dismisses the constraint between <span class="math">a_{3}</span> and <span class="math">a_{4}</span> and introduces erroneous constraints between <span class="math">a_{3},a_{0}</span> and <span class="math">a_{7},a_{4}</span>. Therefore, we construct faithful images of the two sub-columns of <span class="math">A\\ll 1</span>: <span class="math">(A\\ll 1)_{1},(A\\ll 1)_{2}</span> and the corresponding sub-queries as follows:</p>

    <p class="text-gray-300">We have <span class="math">I_{\\{3\\}}=(0,0,0,1)</span> and <span class="math">A_{1}</span> and <span class="math">A_{2}</span> as above. Then,</p>

    <p class="text-gray-300"><span class="math">(A\\ll 1)_{1}</span> <span class="math">=(A_{1}\\ll 1)(1-I_{\\{3\\}})+(A_{2}&lt;&lt;\\ll 1)I_{\\{3\\}}</span> <span class="math">=(a_{1},a_{2},a_{3},a_{0}\\times 0)+(a_{5}\\times 0,a_{6}\\times 0,a_{7}\\times 0,a_{4})</span> <span class="math">=(a_{1},a_{2},a_{3},a_{4})</span> <span class="math">(A\\ll 1)_{2}</span> <span class="math">=(A_{2}\\ll 1)(1-I_{\\{3\\}})+(A_{1}&lt;&lt;\\ll 1)I_{\\{3\\}}</span> <span class="math">=(a_{5},a_{6},a_{7},a_{0})</span> <span class="math">Q_{G,1}</span> <span class="math">=\\text{\`<code>Global&amp;#x27;&amp;#x27;}:A_{1}+1=(A\\ll 1)_{1}&lt;/span&gt; &lt;span class=&quot;math&quot;&gt;Q_{G,2}&lt;/span&gt; &lt;span class=&quot;math&quot;&gt;=\\text{</code>\`Global&#x27;&#x27;}:A_{2}+1=(A\\ll 1)_{2}</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Our present technique is borrowed from [34] (a.k.a. univariate log-derivative lookups). Let  <span class="math">S = (S_0, \\ldots, S_{k-1})</span>  and  <span class="math">T = (T_0, \\ldots, T_{k-1})</span>  be two tables and assume a query  <span class="math">S \\subset T</span>  is being declared. Mathematically speaking, the techniques relies on the equivalence that  <span class="math">S \\subset T</span>  if and only if  $\\exists M \\in \\mathbb{F}^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">  such that the equality of rational function  </span>\\sum \\frac{1}{S_i + X} = \\sum \\frac{M_i}{T_i + X}<span class="math">  holds. Here, the sums are spanning respectively on the length of  </span>S<span class="math">  and  </span>T<span class="math"> . To test the functional equality, the verifier can make a probabilistic check. Namely, he can test it on a random point of  </span>\\mathbb{F}<span class="math">  instead of testing it for all  </span>X \\in \\mathbb{F}<span class="math"> . The soundness of the technique follows from a variant of the Schwartz-Zippel lemma holding for rational functions. We begin by describing the protocol in case  </span>S<span class="math">  and  </span>T$  consist of only a single column in Fig. 1 and explain step-by-step how the protocol is expanded and optimized to support every feature.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The prover commits to a column  <span class="math">M</span>  with an equal number of rows as  <span class="math">T</span> . Which contains the occurrence count of the entries of  <span class="math">T</span>  in  <span class="math">M</span> .</li>

      <li>The verifier responds with a random coin field element  <span class="math">\\gamma</span> .</li>

      <li>The prover commits to  <span class="math">\\Sigma_S</span>  a polynomial interpolating the vector of partial sums  <span class="math">(\\Sigma_S)</span>  such that  <span class="math">(\\Sigma_S)[i] = (\\Sigma_S)[i - 1] + \\frac{1}{S_i + \\gamma}</span>  and  <span class="math">(\\Sigma_S)[0] = \\frac{1}{S_0 + \\gamma}</span> .</li>

      <li>The prover commits to  <span class="math">\\Sigma_T</span> , interpolating the vector of partial sums  <span class="math">(\\Sigma_T)</span>  such that  <span class="math">(\\Sigma_T)[i] = (\\Sigma_T)[i - 1] + \\frac{M_i}{T_i + \\gamma}</span>  and  <span class="math">(\\Sigma_T)[0] = \\frac{M_0}{T_0 + \\gamma}</span> .</li>

      <li>The verifier uses a local opening query to open the last positions of  <span class="math">\\Sigma_S</span>  and  <span class="math">\\Sigma_T</span>  and checks that:</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\left(\\Sigma_ {S}\\right) \\left[</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- 1 \\right] = = \\left(\\Sigma_ {T}\\right) \\left[</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- 1 \\right]</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>"Local" constraint :</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\Sigma_ {S}\\right) [ 0 ] = \\frac {1}{S _ {0} + \\gamma}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>"Local" constraint :</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\Sigma_ {T}\\right) [ 0 ] = \\frac {M _ {0}}{T _ {0} + \\gamma}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>"Global" constraint :</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\left(\\Sigma_ {S}\\right) [ i ] - \\left(\\Sigma_ {S}\\right) [ i - 1 ]\\right) \\left(S _ {i} + \\gamma\\right) = 1</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>'Global' query :</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\left(\\Sigma_ {T}\\right) [ i ] - \\left(\\Sigma_ {T}\\right) [ i - 1 ]\\right) \\left(T _ {i} + \\gamma\\right) = M _ {i}</span></div>

    <p class="text-gray-300">Fig. 1. Compilation of a vanilla inclusion query</p>

    <p class="text-gray-300">When the table has multiple columns, we replace  <span class="math">S</span>  and  <span class="math">T</span>  by a random linear combination of the columns of  <span class="math">S</span>  and  <span class="math">T</span>  by powers of a distinct random coin field element  <span class="math">\\alpha</span>  to reduce to an equivalent single-column case. This substitution only occurs in the construction of  <span class="math">\\Sigma_{\\{S,T\\}}</span>  and the queries, beside that  <span class="math">\\alpha</span>  is the only addition to the protocol.</p>

    <p class="text-gray-300">Batching queries over the same table Sometimes we want to check the inclusion of multiple columns (or table)  <span class="math">S_0, S_1, S_2, S_3, \\dots, S_{n-1}</span>  within the same column (or table). In that case, we can run a protocol variant that is more efficient than running the lookup technique many times in parallel. The protocol is described in Fig. 2.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Conditional inclusion: We extend the inclusion functionality to subsets of  <span class="math">S</span>  and  <span class="math">T</span> , where the lookup function receives as additional arguments two boolean vectors  <span class="math">A, B</span> . Consider an ordering on sets  <span class="math">S = (s_1 \\ldots s_n)</span> , and  <span class="math">T = (t_1 \\ldots t_m)</span> , and define subsets  $S_A = (s_i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A_i<span class="math">  is true),  </span>T_B = (t_i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">B_i$  is true) and we want to</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Inclusion(\\{S_0,S_1,\\ldots \\} ,T)</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The prover commits to a single  <span class="math">M</span> , which is the vector of multiplicities of the elements of  <span class="math">T</span>  in all  <span class="math">S_0, S_1, S_2, \\dots, S_{n-1}</span> .</li>

      <li>The verifier responds with a random coin field element  <span class="math">\\gamma</span> .</li>

      <li>The prover commits to  <span class="math">\\Sigma_{S,k}</span>  for all  <span class="math">S_{k}</span>  independently as in the original protocol.</li>

      <li>The prover commits to a single  <span class="math">\\Sigma_T</span> , interpolating the vector of partial sums  <span class="math">(\\Sigma_T)</span>  such that</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\Sigma_ {T}\\right) [ i ] = \\left(\\Sigma_ {T}\\right) [ i - 1 ] + \\frac {M _ {i}}{T _ {i} + \\gamma}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\left(\\Sigma_ {T}\\right) [ 0 ] = \\frac {M _ {0}}{T _ {0} + \\gamma}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The verifier follows uses a local opening query to open the last positions of each  <span class="math">\\Sigma_{S,k}</span>  and  <span class="math">\\Sigma_T</span>  and checks that:</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\left(\\Sigma_ {S}\\right) \\left[</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- 1 \\right] = = \\left(\\Sigma_ {T}\\right) \\left[</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- 1 \\right]</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>"Local constraint": for all  <span class="math">k</span></li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\Sigma_ {S, k}\\right) [ 0 ] = \\frac {1}{S _ {k , 0} + \\gamma}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>"Local" constraint :</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\Sigma_ {T}\\right) [ 0 ] = \\frac {M _ {0}}{T _ {0} + \\gamma}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>"Global" constraint, for all  <span class="math">k</span> :</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\left(\\Sigma_ {S, k}\\right) [ i ] - \\left(\\Sigma_ {S, k}\\right) [ i - 1 ]\\right) \\left(S _ {k} [ i ] + \\gamma\\right) = 1</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>'Global' query :</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\left(\\Sigma_ {T}\\right) [ i ] - \\left(\\Sigma_ {T}\\right) [ i - 1 ]\\right) \\left(T _ {i} + \\gamma\\right) = M _ {i}</span></div>

    <p class="text-gray-300">Fig. 2. Multiple queries over the same column batched over the same  <span class="math">T</span></p>

    <p class="text-gray-300">test that the  <span class="math">S_A</span>  is included in  <span class="math">T_B</span> . This approach avoids extra commitments to the filtered versions of the columns. Filters  <span class="math">B</span>  on  <span class="math">T</span>  can be dealt with in an efficient, elegant and minimal manner. We modify the  <span class="math">T</span>  and  <span class="math">S</span>  tables as follows: we append the filter  <span class="math">B</span>  column as a column to the  <span class="math">T</span>  table (for simplicity, imagine it is the last column of the modified  <span class="math">T</span>  table. After appending  <span class="math">B</span>  to table  <span class="math">T</span> , we append a corresponding column containing only values of 1 to the  <span class="math">S</span> -table (this is done using "verifier-defined" constant column equal to "1", which avoids introducing an extra commitment). It can be easily checked that the conditional inclusion holds if and only if an ordinary inclusion holds for the modified tables. Filters on  <span class="math">S</span>  cannot be dealt with as above. What we opt for instead is to modify our formulas to take into account the  <span class="math">A</span>  filter, in a way described in Fig. 3.</p>

    <p class="text-gray-300">Fragmenting the column  <span class="math">T</span>  We extend the inclusion query to allow Wizard protocol to specify an inclusion query where the table  <span class="math">T</span>  is symbolically represented as the union of the rows of smaller tables  <span class="math">T_0, T_1, \\ldots, T_n</span> . In this case, the compiler handles in an analogous way of handling multiple table ways  <span class="math">S</span>  for a single table  <span class="math">T</span> . Namely, the compiler requires the prover to commit to multiple tables  <span class="math">M</span>  and  <span class="math">\\Sigma_T</span> , one for each table  <span class="math">T_i</span> . Each table  <span class="math">\\Sigma_{T,i}</span>  is individually constrained as  <span class="math">\\Sigma_T</span>  in the vanilla protocol. At the end the verifier compares the sum of the final value of every of these tables instead of just the final value of the vanilla column  <span class="math">\\Sigma_T</span> .</p>

    <p class="text-gray-300">5.4.1 Security analysis sketch We initially sketch our analysis for the multicolumn case and a conditional filter on  <span class="math">S</span>  and then highlight how the analysis can be extended to reflect the soundness of the batched and fragmented cases. We note  <span class="math">t</span>  as the number of rows in  <span class="math">T</span>  and  <span class="math">s</span>  as the number of rows in  <span class="math">S</span>  and then  <span class="math">n</span>  denotes the number of columns. As highlighted earlier in the section, the predicate of the inclusion query is equivalent to an equality of rational multivariate functions:</p>

    <p class="text-gray-300">Inclusion (S,A,T)</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The prover commits to  <span class="math">M</span> , which is the vector of multiplicities of the elements of  <span class="math">T</span>  in  <span class="math">S_A</span>  ( <span class="math">S_A</span>  is set  <span class="math">S</span>  filtered on  <span class="math">A</span> ).</li>

      <li>The verifier responds with a random coin  <span class="math">\\gamma</span></li>

      <li>The prover commits to  <span class="math">\\Sigma_S</span> , a polynomial interpolating the vector of partial sums  <span class="math">(\\Sigma_S)</span>  such that</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\left(\\Sigma_ {S}\\right) [ i ] - \\left(\\Sigma_ {S}\\right) [ i - 1 ]\\right) \\left(S _ {i} + \\gamma\\right) = A _ {i}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\left(\\Sigma_ {S}\\right) [ 0 ] = \\frac {A _ {0}}{S _ {0} + \\gamma}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The prover commits to  <span class="math">\\Sigma_T</span> , interpolating the vector of partial sums  <span class="math">(\\Sigma_T)</span>  such that</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\Sigma_ {T}\\right) [ i ] = \\left(\\Sigma_ {T}\\right) [ i - 1 ] + \\frac {M _ {i}}{T _ {i} + \\gamma}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\left(\\Sigma_ {T}\\right) [ 0 ] = \\frac {M _ {0}}{T _ {0} + \\gamma}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The verifier checks that</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\left(\\Sigma_ {S}\\right) [</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- 1 ] = = \\left(\\Sigma_ {T}\\right) [</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- 1 ]</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">. He obtains the values of  $(\\Sigma_S)[</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- 1]<span class="math">  and  </span>(\\Sigma_T)[</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- 1]$  via two local opening queries.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>"Local" query :</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\Sigma_ {S}\\right) [ 0 ] = \\frac {A _ {0}}{S _ {0} + \\gamma}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>"Local" query :</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\Sigma_ {T}\\right) [ 0 ] = \\frac {M _ {0}}{T _ {0} + \\gamma}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>"Global" query :</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\left(\\Sigma_ {S}\\right) [ i ] - \\left(\\Sigma_ {S}\\right) [ i - 1 ]\\right) \\left(S _ {i} + \\gamma\\right) = A _ {i}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The verier makes a "Global" query :</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\left(\\Sigma_ {T}\\right) [ i ] - \\left(\\Sigma_ {T}\\right) [ i - 1 ]\\right) \\left(T _ {i} + \\gamma\\right) = M _ {i}</span></div>

    <p class="text-gray-300">Fig. 3. Compiling a conditional inclusion query</p>

    <div class="my-4 text-center"><span class="math-block">\\sum_ {i \\in [ t ]} \\frac {M _ {i}}{X + \\sum_ {j \\in [ n ]} T _ {i , j} Y ^ {j}} = \\sum_ {i \\in [ s ]} \\frac {A _ {i}}{X + \\sum_ {j \\in [ n ]} S _ {i , j} Y ^ {j}}</span></div>

    <p class="text-gray-300">It is worth noting that the  <span class="math">S</span> -batching case or the  <span class="math">T</span> -fragmentation case are equivalent to splitting respectively the right and the left hand of the equality. Thus, to analyze these cases, it suffices to consider the equivalent case where the  <span class="math">S</span>  and  <span class="math">T</span>  tables are unified in a single table. Coming back to our soundness analysis, observe that the described protocol perfectly simulates the evaluation of the above functional equality at random points  <span class="math">(\\gamma, \\alpha)</span> . Therefore, a malicious prover attacking soundness can only succeed if she comes up with an assignment such that the two rational functions are unequal but coincide on the random evaluation points  <span class="math">(\\gamma, \\alpha)</span> . The Schwartz-Zippel applied to rational function gives that the protocol has statistical soundness error  <span class="math">O\\left(\\frac{(t + s)n}{\\overline{s}}\\right)</span></p>

    <p class="text-gray-300">5.4.2 Optimization When many lookups are declared over the same table, a possible optimization is to "group" multiple  <span class="math">\\Sigma_S</span>  into the same column. This reduces the number of committed columns through the compilation step at the expense of increasing the degree of the generated global constraints.</p>

    <p class="text-gray-300">5.5 Reduction of the fixed-permutation checks</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The technique we present is inspired by the work of <em>[28]</em> and <em>[7]</em>. Let <span class="math">n,m</span> be integers and let <span class="math">\\sigma</span> be a permutation of <span class="math">[n]</span> and <span class="math">A=\\{A_{i}\\}_{i\\in[m]}</span> and <span class="math">B=\\{B_{i}\\}_{i\\in[m]}</span> such that <span class="math">B</span> is obtained by permuting the rows of <span class="math">A</span> according to <span class="math">\\sigma</span>. As <span class="math">\\sigma</span> is known beforehand, we give oracle-access to a signature of <span class="math">\\sigma</span> in an offline phase. This signature consists of two vectors <span class="math">s=(1,\\omega,\\cdots,\\omega^{n-1})</span> and <span class="math">s^{\\prime}=(\\omega^{\\sigma(1)-1},\\cdots,\\omega^{\\sigma(n-1)-1})</span>. Naturally, the same <span class="math">s</span> and <span class="math">s^{\\prime}</span> can be reused for different queries and since the polynomial encoding of <span class="math">s</span> is <span class="math">s(X)=X</span> there is implicitly no need to send it to the oracle. The compiler then replaces every fixed permutation query on <span class="math">A</span> and <span class="math">B</span> by a permutation query on $A^{\\prime}=(A\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">s)<span class="math"> and </span>B^{\\prime}=(B\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">s^{\\prime})$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-59" class="text-xl font-semibold mt-8">5.6 Reduction of the permutation checks</h3>

    <p class="text-gray-300">Let <span class="math">A</span> and <span class="math">B</span> be two columns of equal length <span class="math">l</span>. The technique we present is borrowed from a series of works including <em>[30]</em>, <em>[7]</em>, <em>[28]</em> originating from the work of <em>[9]</em>. The intuition behind the protocol is as follows: a column <span class="math">A</span> is a permutation of <span class="math">B</span> if and only if the polynomials defined as <span class="math">\\prod_{i\\in[l]}(X+A_{i})</span> and <span class="math">\\prod_{i\\in[l]}(X+B_{i})</span> are equal. Our sub-protocol simulates an equality check between these two at a random point <span class="math">X=\\alpha</span>. Or equivalently</p>

    <p class="text-gray-300"><span class="math">Z(\\alpha)=\\prod_{i\\in[l]}\\frac{\\alpha+A_{i}}{\\alpha+B_{i}}=1</span></p>

    <p class="text-gray-300">This approach can be extended to the case where <span class="math">A</span> and <span class="math">B</span> consist of multiple columns by substituting <span class="math">A</span> and <span class="math">B</span> in the above polynomial equality by linear combinations of the columns for each table by powers of a random independent coin <span class="math">r</span>. Fig. 4 gives the pseudo-code of the Arcane compilation step for permutations. where the permutation function receives two sets of vectors <span class="math">\\{A_{i}\\}_{i\\in[m]}</span> and <span class="math">\\{B_{i}\\}_{i\\in[m]}</span> and highlights how Arcane converts a permutation check into local and global constraints.</p>

    <h6 id="sec-60" class="text-base font-medium mt-4">Permutation<span class="math">(\\{A_{i},B_{i}\\}_{i\\in[m]})</span></h6>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>if <span class="math">m&gt;1</span> :</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Verifier samples <span class="math">r\\leftarrow\\mathbb{F}</span> and sends it to the prover</li>

      <li>The prover internally set <span class="math">A^{\\prime}=\\sum_{i}r^{i}A_{i}</span> and <span class="math">B^{\\prime}=\\sum_{i}r^{i}B_{i}</span></li>

    </ul>

    <p class="text-gray-300">else : they set <span class="math">A^{\\prime}=A_{0}</span> and <span class="math">B=B_{0}</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Prover the column <span class="math">Z</span>, defined as:</li>

    </ol>

    <p class="text-gray-300"><span class="math">Z_{i}=\\prod_{j\\leq i}\\frac{A^{\\prime}+\\alpha}{B^{\\prime}+\\alpha}</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>“Local” query : <span class="math">Z_{0}=1</span></li>

      <li>“Global” query: <span class="math">(Z&gt;&gt;1)(B^{\\prime}+\\alpha)=Z(A^{\\prime}+\\alpha)\\quad\\text{(not cancelled on n-1)}</span></li>

    </ol>

    <p class="text-gray-300">Fig. 4. Reduction of a Permutation Check.</p>

    <p class="text-gray-300">Fragmented table: The case where either the table <span class="math">A</span> or <span class="math">B</span> or both are fragmented is handled by splitting the rational product in several sub-products. A consequence is that the sub-protocol uses several sub-products. For optimization, we distinguish the following cases:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>There are fragments in <span class="math">A</span> and <span class="math">B</span> that have the same size, <span class="math">A^{\\prime}</span>, <span class="math">B^{\\prime}</span>: in this case, it is interesting to group them in a single product</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\prod_{k\\in[l]}\\frac{A^{\\prime}_{k}+\\alpha}{B^{\\prime}_{k}+\\alpha}</span></p>

    <p class="text-gray-300">.</p>

    <p class="text-gray-300">##</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>There are fragments on either side of the permutation <span class="math">A^{\\prime}</span> or <span class="math">B^{\\prime}</span> whose size does not match any fragment on the other side: in this case, they are individually assigned a product</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\prod_{k \\in [l]} A_{k}^{\\prime} + \\alpha \\quad \\text{or} \\quad \\prod_{k \\in [l]} \\frac{1}{B_{k}^{\\prime} + \\alpha}</span></div>

    <p class="text-gray-300">In the sub-protocol description of Fig. 5, we assume that the mapping of the fragments <span class="math">\\{A_i\\}, \\{B_i\\}</span> to their respective product are clear from context and we also assume, for simplicity that the tables have a single column (the multi-column case is handled is in the vanilla case).</p>

    <p class="text-gray-300">Permutation(<span class="math">\\{A_i, B_i\\}_{i \\in [m]}</span>)</p>

    <p class="text-gray-300">For each product, indexed by <span class="math">v</span> and their respective fragments <span class="math">A&#x27;</span> and <span class="math">B&#x27;</span> or <span class="math">\\emptyset</span> if it does not apply</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Prover sends <span class="math">Z</span>, the unique polynomial such that:</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">Z_{v} = \\prod_{i \\leq k} \\frac{A_{i}^{\\prime} + \\alpha}{B_{i}^{\\prime} + \\alpha} \\quad \\text{or} \\quad \\prod_{k \\in [l]} A_{k}^{\\prime} + \\alpha \\quad \\text{or} \\quad \\prod_{k \\in [l]} \\frac{1}{B_{k}^{\\prime} + \\alpha}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>"Local" constraint: <span class="math">Z_{v,0} = 1</span></li>

      <li>"Global" constraint: <span class="math">(Z_v &amp;gt;&amp;gt; 1)(B&#x27; + \\alpha) = Z_v(A&#x27; + \\alpha)</span></li>

      <li>"Local opening": <span class="math">Z_v</span> at the last position</li>

    </ol>

    <p class="text-gray-300">Finally The verifier takes the final value of each <span class="math">Z_v</span> and checks that their product equals 1.</p>

    <p class="text-gray-300">Fig. 5. Reduction of a Permutation Check.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">5.6.1 Security analysis sketch Let us start with the single-column case. A malicious prover may pass the verification if and only if <span class="math">\\prod_{i\\in [l]}(X + v_{1,i})\\neq \\prod_{i\\in [l]}(X + v_{2,i})</span> and the equality holds for <span class="math">X = \\alpha</span>. Indeed, the functional equality between the two products is equivalent to the predicate stated by the permutation query. Following this, we have that the above sub-protocol has statistical soundness error $\\frac{a}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\overline{x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}$ by application of the Schartz-Zippel lemma. For the multi-column case, the predicate of the permutation query is equivalent to the following bivariate polynomials equality</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\prod_{i \\in [l]} (X + \\sum_{j &amp;lt; n \\operatorname{col}} v_{1,i} Y^{j}) = \\prod_{i \\in [l]} (X + \\sum_{j &amp;lt; n \\operatorname{col}} v_{1,i} Y^{j})</span></div>

    <p class="text-gray-300">From that point, applying the Schwartz-Zippel lemma gives us statistical soundness with error <span class="math">O\\left(\\frac{l(n \\operatorname{col})}{\\overline{x}}\\right)</span>. The same analysis can be applied to the more complex fragmented case by observing that the sub-protocol simulates the same evaluation as above for the union of all the tables on both sides.</p>

    <p class="text-gray-300">5.6.2 Optimizations As for the reduction of the inclusion checks, in the fragmented case, it is possible to pack the construction of multiple grand products into a single column <span class="math">Z</span> if they relate to columns of the same size. This optimization trades commitment complexity for an increase in the degree of the generated global constraints.</p>

    <p class="text-gray-300">5.7 Reduction of the inner-product queries</p>

    <p class="text-gray-300">As a reminder, inner-product queries allow the verifier to query the inner product of two committed columns <span class="math">A</span> and <span class="math">B</span>. We first explain how the inner-product reduction phase handles a single query concretely and then</p>

    <p class="text-gray-300">21</p>

    <p class="text-gray-300">explain how to extend it to handle multiple queries. In the outlines, the prover constructs a third column <span class="math">S</span> storing the cumulative sum of the row-wise products of <span class="math">A</span> and <span class="math">B</span>. The verifier then queries the last entry of the <span class="math">S</span> and expects it to equal the alleged value of the inner product as claimed by the prover.</p>

    <p class="text-gray-300">InnerProduct(<span class="math">A;B;c</span>)</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The prover sends the columns <span class="math">A</span> and <span class="math">B</span> to the oracle and claims <span class="math">c</span>.</li>

      <li>The prover computes <span class="math">S</span> such that <span class="math">S_{k}=\\sum_{j\\leq k}A_{j}B_{j}</span> and sends it to the oracle.</li>

      <li>“Local”: <span class="math">S_{0}=A_{0}B_{0}</span></li>

      <li>“Global”: <span class="math">S_{i}-S_{i-1}=A_{i}B_{i}</span> (except for <span class="math">i=0</span>)</li>

      <li>“LocalOpening”: the final position of <span class="math">S</span>, <span class="math">c^{\\prime}</span></li>

      <li>The verifier checks that <span class="math">c==c^{\\prime}</span></li>

    </ol>

    <p class="text-gray-300">Fig. 6. Reduction of the inner product Check</p>

    <p class="text-gray-300">Batching This technique can be extended to support multiple queries <span class="math">(A_{0},B_{0},c_{0}),(A_{1},B_{1},c_{1}),\\ldots,(A_{n},B_{n},c_{n})</span>. To support this feature, we equip the protocol with a ”batching” random coin <span class="math">r</span> and we construct <span class="math">S</span> as <span class="math">S_{k}=\\sum_{i\\in[n]}\\sum_{j\\leq k}r^{i}A_{i,j}B_{i,j}</span>. The queries created by the compilation step are equivalently modified by swapping <span class="math">A_{i}B_{i}</span> terms by <span class="math">\\sum_{i}r^{i}A_{i,j}B_{i,j}</span>. Finally, the verifier compares <span class="math">c^{\\prime}</span> with <span class="math">\\sum_{i}r^{i}c_{i}</span>.</p>

    <h4 id="sec-61" class="text-lg font-semibold mt-6">5.7.1 Security analysis sketch</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In the single-query case, soundness and completeness are perfect as <span class="math">S</span> is fully constrained to trace the inner product’s step-by-step computation. In the multi-query case, <span class="math">S</span> is perfectly constrained to compute the linear combination of the inner product of <span class="math">a</span> and <span class="math">b</span>. This has two consequences: (1) This justifies perfect completeness (2) The only way for a malicious prover to be successful with a false statement <span class="math">(c_{0}^{\\prime\\prime},c_{1}^{\\prime\\prime},\\ldots,c_{n}^{\\prime\\prime})</span> is that <span class="math">\\sum_{i\\in[n]}r^{i}(c_{i}^{\\prime\\prime}-A.B)</span> cancels. By the Schwartz-Zippel lemma, this can happen with probability at most $\\epsilon=\\frac{1}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{P}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">. This justifies </span>\\epsilon$-statistical soundness.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-62" class="text-xl font-semibold mt-8">5.8 Sticking the small columns together</h3>

    <p class="text-gray-300">The sticking compiler performs the opposite of the splitting step. Namely, it applies to all the columns whose size is smaller than some prespecified target size. These columns are regrouped into larger columns having the target size by interleaving. To illustrate, columns <span class="math">A=(a_{0},a_{1},a_{2},\\ldots a_{n-1})</span> and <span class="math">B=(b_{0},b_{1},\\ldots,b_{n-1})</span>, assuming they have half of the target size, would be regrouped into a column <span class="math">L=(a_{0},b_{0},a_{1},b_{1},\\ldots,a_{n-1},b_{n-1})</span>. This compilation stage is reached much later than the splitting step. This is motivated by the fact that (1) this limits the overheads of the inclusion and the permutation stages (2) this simplifies the current compilation stage since it can assume that the incoming protocol does not use inclusion, range, permutation, inner-product or fixed-permutation queries as they are already compiled out at this stage. The sticking compilation stage processes the impacted queries as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Local constraint and local opening: the queries are replaced by equivalent ones pointing to the corresponding positions in the regrouped columns.</li>

      <li>Global constraints: the query is replaced by an equivalent one retaining the same expression but whose variables are replaced by the corresponding regrouped column, shifted by the appropriate offset and multiplied by a periodic sampling column.</li>

    </ul>

    <p class="text-gray-300">The sticker also sets a lower bound on the columns it is working with. All columns smaller than this limit are sent directly to the verifier and the constraints applying to them are manually checked by the verifier. Passed this point, we may assume that all the column the protocol commits to are of the same size.</p>

    <h4 id="sec-63" class="text-lg font-semibold mt-6">5.8.1 Example 1: With a global constraint</h4>

    <p class="text-gray-300">Assume a Wizard-IOP protocol consisting of two columns <span class="math">A=(a_{1},a_{2},a_{3},a_{4})</span> and <span class="math">B=(b_{1},b_{2},b_{3},b_{4})</span> and say we apply the sticker compiler with a target size of 8. And assume a global constraint <span class="math">Q_{G}=</span> “Inclusion” <span class="math">:A^{2}=B</span>.</p>

    <p class="text-gray-300">The “sticking” compiler step, replaces <span class="math">A</span> and <span class="math">B</span> by <span class="math">L</span> and <span class="math">Q_{G}</span> by <span class="math">Q^{\\prime}_{G}</span> as</p>

    <p class="text-gray-300"><span class="math">L</span> <span class="math">=(a_{1},b_{1},a_{2},b_{2},a_{3},b_{3},a_{4},b_{4})</span> <span class="math">I_{1}</span> <span class="math">=(1,0,1,0,1,0,1,0)</span> <span class="math">I_{2}</span> <span class="math">=(0,1,0,1,0,1,0,1)</span> <span class="math">Q^{\\prime}_{G}</span> <span class="math">=</span> “Global” <span class="math">:(I_{0}L)^{2}=(I_{1}L\\ll 1)</span></p>

    <h3 id="sec-64" class="text-xl font-semibold mt-8">5.9 Example 2: With a local constraint</h3>

    <p class="text-gray-300">Assume a Wizard-IOP protocol consisting of two columns <span class="math">A</span> and <span class="math">B</span> as above and a local constraint stating that <span class="math">A[0]=B[0]</span>. Then <span class="math">L</span> is constructed identically as above and the constraints <span class="math">Q_{L}</span> is replaced by <span class="math">Q^{\\prime}_{L}</span> as:</p>

    <p class="text-gray-300"><span class="math">Q^{\\prime}_{L}=</span> “Local” <span class="math">:L[0]^{2}=L[1]</span></p>

    <h3 id="sec-65" class="text-xl font-semibold mt-8">5.10 Example 3: With a larger target size</h3>

    <p class="text-gray-300">Let again reuse a Wizard protocol declaring <span class="math">A</span> and <span class="math">B</span> as above and this time assume we apply the “sticking” compiler with a target size of 16. In this case, <span class="math">A</span> and <span class="math">B</span> are not large enough together to fill a column. In this situation, we use virtual ”zero columns” as fillings and construct</p>

    <p class="text-gray-300"><span class="math">L=(a_{1},b1,0,0,a_{2},b2,0,0,a_{3},b3,0,0,a_{4},b4,0,0)</span></p>

    <h3 id="sec-66" class="text-xl font-semibold mt-8">5.11 Reduction of the global constraints</h3>

    <p class="text-gray-300">We present a standard technique from the work of Plonk <em>[7]</em>. Let <span class="math">v_{1},\\cdots,v_{k}</span> be <span class="math">k</span> columns and a <span class="math">k</span>-variate arithmetic circuit <span class="math">C(X_{1},\\cdots,X_{k})</span> of degree <span class="math">d</span>. We denote by <span class="math">v_{\\bullet}(X)</span> the polynomials encoding <span class="math">v_{\\bullet}</span> in Lagrange basis. We have that the global constraint is satisfied if and only if there exists a polynomial <span class="math">Q(X)</span> of degree <span class="math">(d-1)n</span> such that,</p>

    <p class="text-gray-300"><span class="math">C(v_{1}(X)\\cdots v_{k}(X))=(X^{n}-1)Q(X)</span></p>

    <p class="text-gray-300">Following this observation, the Arcane compiler runs the following procedure separately for each global query.</p>

    <h4 id="sec-67" class="text-lg font-semibold mt-6">5.11.1 Optimizations</h4>

    <p class="text-gray-300">For efficiency, the compilation of the global constraint also involves several optimization routines which we outline below:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The columns of types “expression” are swallowed into the global constraints using them as input variables.</li>

      <li>To limit the degree of the expression, an optimization heuristically identifies frequent high-degree terms and assigns them to an intermediate column. This trades the degree of the constraints for commitment complexity.</li>

      <li>The queries are grouped in buckets by degree and for each bucket, we replace them with a merged constraint which is satisfied if a random linear combination of the initial constraints vanishes.</li>

      <li>The expressions are symbolically reduced using a symbolic expression simplifier (which performs several factorization routines)</li>

    </ol>

    <p class="text-gray-300">GlobalConstraint (C, v_{1}, \\dots, v_{k})</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The prover computes and commits to <span class="math">Q</span> computed as,</li>

    </ol>

    <p class="text-gray-300"><span class="math">Q=\\frac{C(v_{1}(X)\\cdots v_{k}(X)}{X^{n}-1}</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The verifier samples a random coin <span class="math">\\alpha\\leftarrow\\#\\ \\mathbb{F}</span></li>

      <li>“Univariate” query : <span class="math">v_{1}(\\alpha)\\dots v_{k}(\\alpha),Q(\\alpha)</span></li>

      <li>The verifier checks</li>

    </ol>

    <p class="text-gray-300"><span class="math">C(v_{1}(\\alpha)\\dots)\\stackrel{{\\scriptstyle?}}{{=}}(\\alpha^{n}-1)Q(\\alpha)</span></p>

    <p class="text-gray-300">Figure 7: Reduction of the Global Constraints</p>

    <h4 id="sec-68" class="text-lg font-semibold mt-6">5.11.2 Security analysis sketch</h4>

    <p class="text-gray-300">We start by analyzing the compilation of a single constraint and then extend the analysis to cover the merging operation that we carry when dealing with several constraints. First of all, note that since the existence of the quotient such that</p>

    <p class="text-gray-300"><span class="math">C(v_{1}(X)\\cdots v_{k}(X))=(X^{n}-1)Q(X)</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">is satisfied is mathematically equivalent to the predicate of a global constraint, we have a that a malicious prover can only succeed if the equation does not hold as equality between polynomials but does hold on <span class="math">\\alpha</span>. From the Schwartz-Zippel lemma, it follows that the protocol has statistical soundness with error at most $\\frac{d}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">). In the merged case, we also have to account for the possibility that the merged constraint is satisfied whereas some of the sub-constraints are not satisfied. This can happen with probability at most </span>\\frac{n}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math"> where </span>n<span class="math"> is the number of constraints. Thus, in this case, the statistical soundness error is at most </span>\\frac{n}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}+\\frac{d}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-69" class="text-xl font-semibold mt-8">5.12 Reduction to a polynomial IOP</h3>

    <p class="text-gray-300">From this point on, the partially compiled Wizard-IOP only uses local constraints, local opening and univariate queries, possibly involving cyclically shifted columns. We now discuss on the last steps of the Arcane compiler to reduce to a polynomial-IOP, eliminating the references to shifted columns.</p>

    <h4 id="sec-70" class="text-lg font-semibold mt-6">5.12.1 Local constraints and local openings</h4>

    <p class="text-gray-300">are compiled out by converting them into equivalent univariate queries by interpreting the committed columns as polynomials expressed in Lagrange basis as we did during the global constraint reduction step. Accounting for the shifting is quite straightforward as it suffices to offset the opened point with the relevant number of positions.</p>

    <h4 id="sec-71" class="text-lg font-semibold mt-6">5.12.2 Univariate queries over cyclically-shifted columns</h4>

    <p class="text-gray-300">: it remains to discuss how to convert them into univariate queries “directly” on oracle-given polynomials (shown by <span class="math">P</span> here). The conversion is performed following this observation:</p>

    <p class="text-gray-300"><span class="math">(P\\ll k)(x)=y\\ \\Longleftrightarrow\\ P(\\omega^{k}x)=y</span></p>

    <h2 id="sec-72" class="text-2xl font-bold">6 UniEval Compiler: from PIOP to UniEval PIOP</h2>

    <p class="text-gray-300">Let <span class="math">\\mathcal{P}</span> be a PIOP protocol, where for <span class="math">i\\in[n],j\\in S_{i}</span>, the verifier queries a polynomial <span class="math">P_{i}</span> over a point <span class="math">x_{j}</span>.</p>

    <p class="text-gray-300">The aim of the compiler, presented here, is to reduce the initial polynomial-IOP to a polynomial-IOP where the oracle-given polynomials are all queried at a single random point. We will call such a polynomial-IOP scheme a UniEval polynomial-IOP, and the single query is denoted “Grail query”. For any evaluation <span class="math">P_{i}(x)</span> where <span class="math">x</span> is not the Grail query, the verifier gets <span class="math">P_{i}(x)</span> directly from the prover. In this model, replacing the oracle with a polynomial commitment scheme requires a proof of the evaluation for all the polynomials</p>

    <p class="text-gray-300">at the same point i.e., over the Grail query. The gained advantage is that batching at the polynomial commitment level is now more straightforward as all the polynomials are queried on the same evaluation point. Indeed, due to this compiler, batching over different points is done at the polynomial-IOP level. At the polynomial commitment level, we only need batching over the same point. To build our compiler, we first present a batching technique of multiple polynomials over multiple points. We then use this protocol to compile any PIOP into a UniEval PIOP. This section briefly outlines the UniEval compiler presented in <em>[13]</em>, we refer to this document for a more comprehensive description and security analysis.</p>

    <h3 id="sec-73" class="text-xl font-semibold mt-8">6.1 Multiple-Point to Single-Point Reduction</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We assume a set of points <span class="math">T</span> and a set of <span class="math">n</span> polynomials <span class="math">\\{i\\in[n]:P_{i}(X)\\}</span>, each of degree <span class="math">d_{i}\\leq d</span>. Each <span class="math">P_{i}(X)</span> is queried on a set of evaluation points <span class="math">S_{i}\\subset T</span>. Define <span class="math">R_{i}(X)</span> as the alleged evaluations of <span class="math">P_{i}(X)</span> over the set <span class="math">S_{i}</span>, namely, <span class="math">R_{i}(X)</span> agrees with purported <span class="math">P_{i}(X)</span> over <span class="math">S_{i}</span> (and <span class="math">R_{i}(X)</span> is of degree $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$). The aim is to present a protocol for the relation;</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$R:=\\{(S_{i},R_{i}(X);P_{i}(X))_{i}\\quad\\forall i\\quad\\ P_{i}(X)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{S_{i}}=R_{i}(X)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{S_{i}}\\}$ (1)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-74" class="text-base font-medium mt-4">Claim.</h6>

    <p class="text-gray-300">The relation <span class="math">R</span> holds if and only if:</p>

    <p class="text-gray-300"><span class="math">\\forall i\\in[n]:(P_{i}(X)-R_{i}(X))\\prod_{x\\in T\\setminus S_{i}}(X-x)\\text{ is divided by }\\prod_{x\\in T}(X-x).</span> (2)</p>

    <p class="text-gray-300">Knowing this fact, in Fig. 8 we present our batching protocol for the relation Eq. (1). The protocol is inspired by the batching approach presented in <em>[20]</em>.</p>

    <p class="text-gray-300">MPSP<span class="math">(S_{1},\\cdots S_{n},R_{1},\\cdots,R_{n};P_{1},\\cdots,P_{n})</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>the prover sends oracle access to <span class="math">P_{i}</span>.</li>

      <li>The verifier samples <span class="math">\\alpha\\leftarrow\\mathds{1}\\mathbb{F}</span>.</li>

      <li>The prover computes and sends oracle-access to:</li>

    </ol>

    <p class="text-gray-300"><span class="math">Q(X)=\\sum_{i\\in[n]}\\alpha^{i}\\frac{P_{i}(X)-R_{i}(X)}{\\prod_{x\\in S_{i}}(X-x)}</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The verifier samples <span class="math">z\\leftarrow\\mathds{1}\\mathbb{F}</span> and queries <span class="math">P_{1}(z),\\cdots P_{n}(z),Q(z)</span>.</li>

      <li>Finally, the verifier checks that: relation in 3 is satisfied for <span class="math">X=z</span> i.e.,</li>

    </ol>

    <p class="text-gray-300"><span class="math">Q(z)\\prod_{x^{\\prime}\\in T}(z-x^{\\prime})=\\sum_{i\\in[n]}\\left(\\alpha^{i}(P_{i}(z)-R_{i}(z))\\prod_{x^{\\prime\\prime}\\notin S_{i}}(z-x^{\\prime\\prime})\\right)</span></p>

    <p class="text-gray-300">Fig. 8. Multi-point to single-point reduction procedure.</p>

    <h3 id="sec-75" class="text-xl font-semibold mt-8">6.2 Compiler: P-IOP to UniEval P-IOP</h3>

    <p class="text-gray-300">We are now ready to compile a PIOP to its UniEval version.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For any P-IOP, define its associated protocol P-IOP^{′} as follows; we let all the queries in P-IOP be sent directly to the prover, and let the prover respond to these queries (the prover replies with alleged values for the evaluations, without providing a proof at this stage, as that would be handled later in the protocol). Indeed P-IOP^{′} is the same as P-IOP where the prover also plays the role of the oracle by itself.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>By the end of an execution of P-IOP^{′}, we get the trace of the polynomial queries issued during P-IOP^{′}; the set of polynomials <span class="math">P_{i}</span>, the points <span class="math">S_{i}</span>, and the alleged evaluations of <span class="math">P_{i}(X)</span> over <span class="math">S_{i}</span> which we denote by <span class="math">R_{i}(X)</span> (prover’s responses).</li>

      <li>Now, we consider our multi-point to the single-point protocol in Fig. 8, for the statement <span class="math">(R_{i},S_{i})</span> and the witness <span class="math">P_{i}(X)</span> from the trace. Call this protocol <span class="math">\\mathrm{MPSP}(R_{i},S_{i};P_{i}(X))_{i}</span>.</li>

    </ul>

    <p class="text-gray-300">The compiler first runs P-IOP^{′}, get the trace, and then runs <span class="math">\\mathrm{MPSP}(R_{i},S_{i};P_{i}(X))_{i}</span>. The resulting PIOP is what we call UniEval-PIOP, denoted by UniEval-PIOP.</p>

    <p class="text-gray-300">Knowledge-Soundness. Let <span class="math">\\epsilon_{\\mathrm{UniEval}}</span>, <span class="math">\\epsilon_{\\mathrm{P-IOP^{\\prime}}}</span> and <span class="math">\\epsilon_{\\mathrm{MPSP}}</span> be, respectively, the soundness-error of protocols UniEval-P-IOP, protocol P-IOP^{′} and <span class="math">\\mathrm{MPSP}(R_{i},S_{i};P_{i}(X))_{i}</span>. Then, we have, <span class="math">\\epsilon_{\\mathrm{UniEval}}\\leq\\epsilon_{\\mathrm{P-IOP^{\\prime}}}+\\epsilon_{\\mathrm{MPSP}}</span>.</p>

    <h2 id="sec-76" class="text-2xl font-bold">7 Vortex: a List Polynomial Commitment</h2>

    <p class="text-gray-300">This section briefly presents the Vortex List Polynomial Commitment scheme introduced in <em>[13]</em> and how we instantiate it as part of Linea using a lattice-based hash (ring-SIS) hash function. Vortex is a variant of the commitment scheme proposed in Orion <em>[49]</em> and Brakedown <em>[32]</em>, and it relies on a lattice-based hash which we describe in Section 7.1, and an erasure-code and the MiMC hash function <em>[5]</em>.</p>

    <p class="text-gray-300">In this work, we use the systematic version of the Reed-Solomon code which has encoding time <span class="math">O(N\\log N)</span>, where <span class="math">N</span> is the size of the codeword. Vortex allows to perform a batched argument of multiple committed polynomials evaluated over the same given point <span class="math">x</span>. One of the main differences here is the way we treat not just one polynomial but a batch of polynomials. In Breakdown and Orion, they assume a large degree polynomial and fold it into a matrix, while here we assume each row of the matrix is a separate polynomial. This is beneficial for our use case (zkEVM) where we have to deal with many polynomials at once. Another difference is, that we discuss the security not in the unique decoding regime, but in the list decoding regime. This point helps us to improve the efficiency of the scheme but brings some challenges regarding the security proof and for the PIOP transformation into AoK (PIP) through the Vortex commitment which we will address later. Vortex is described in Section 7.2. Vortex additionally comes with a batching argument allowing to open simultaneously multiple matrices at the same point.</p>

    <p class="text-gray-300">For a matrix of size <span class="math">m\\cdot n=N</span>, the Vortex commitment and opening arguments have size <span class="math">O(\\sqrt{N})</span>. Moreover, the opening arguments have verification time <span class="math">O(\\sqrt{N})</span>. In Section 9, we present our self-recursion technique to achieve succinctness.</p>

    <h3 id="sec-77" class="text-xl font-semibold mt-8">7.1 Lattice-Based Hash</h3>

    <p class="text-gray-300">The lattice-based hash function we present relies on the Ring-SIS assumption to achieve collision resistance. The design of our hash function is essentially the same as the SWIFFT <em>[39]</em> hash function. The only concrete difference is that the design of SWIFFT restricts the input set of the Ring-SIS inputs to be <span class="math">\\{0,1\\}</span> while our hash function accepts an input set of the form <span class="math">[0,2^{n}-1]</span> (for small <span class="math">n</span>).</p>

    <p class="text-gray-300">Let <span class="math">q</span> be a prime, <span class="math">\\mathbb{F}_{q}</span> be the finite-field, <span class="math">b</span> a power of two such that <span class="math">b&lt;q</span> and <span class="math">d,m</span> two positive integers such that <span class="math">d</span> is a power of 2 and <span class="math">m&gt;\\frac{\\log q}{\\log b}</span>. We consider the ring <span class="math">\\mathcal{R}=\\frac{\\mathbb{F}_{q}[X]}{X^{d}+1}</span> of polynomials whose coefficients lie in <span class="math">\\mathbb{F}_{q}</span> modulo <span class="math">X^{d}+1</span>. To instantiate the hash function, we need first to go through a transparent setup phase where a Ring-SIS key is sampled. We set <span class="math">N=md\\frac{\\log b}{\\log q}</span>. A description of the procedure is given in Fig. 9</p>

    <p class="text-gray-300">Collision and preimage resistance are derived from the Ring-SIS and the Ring-ISIS problems respective to the instances (q, m, b).</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">If $(q-1)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(n+1)<span class="math">, the scalar product of </span>L\\cdot A<span class="math"> may be computed with the following procedure. Let </span>\\bar{\\omega}\\in\\mathbb{F}_{q}<span class="math"> such that </span>\\bar{\\omega}^{n}=-1<span class="math">. Note that </span>\\{\\bar{\\omega}^{2i+1}\\}<span class="math"> forms a coset of the </span>n<span class="math">-th roots of unity that all vanishes under </span>X^{n}+1<span class="math">. We can efficiently compute the evaluations of </span>L_{i}<span class="math"> and precompute the one for </span>A_{i}$ using the Cooley-Tuckey</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Setup(q,m,d,b) \\rightarrow pp</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{A} = (A_i)_{i &amp;lt;   m}\\gets \\ast \\mathcal{R}^m</span></li>

      <li>return  <span class="math">\\mathsf{pp} = \\mathsf{A}</span></li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">1. Encode each element of  <span class="math">\\mathbf{x}</span>  in  <span class="math">\\log q / \\log b</span>  limbs  <span class="math">l_{i}</span> , such that  $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">l_i\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">&lt; b<span class="math">  for all  </span>i$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Arrange the limbs  <span class="math">l_{i}</span>  as coefficients of polynomials to obtain a vector  <span class="math">L = (L_{i})_{i &amp;lt; m} \\in \\mathcal{R}^{m}</span></li>

      <li>Compute the scalar product  <span class="math">h = A \\cdot L</span>  (requiring polynomial multiplication in  <span class="math">\\mathcal{R}</span> )</li>

      <li>return  <span class="math">h</span>  by returning its coefficients</li>

    </ol>

    <p class="text-gray-300">Fig. 9. Description of the lattice-based hash</p>

    <p class="text-gray-300">algorithm (also known as FFT, or NTT in the literature). In this basis, the multiplication of polynomials coincides with the Hadamard (entry-wise) product, and we can get  <span class="math">h</span>  directly in evaluation before switching back to coefficient basis in the end. Overall, the complexity of the hashing procedure is  <span class="math">O(mn\\log n)</span> . For small values of  <span class="math">n</span>  and  <span class="math">b</span> , other techniques such as Tom-Cook are known to be efficient as well. In Appendix B we recap the security analysis of this hash function and give concrete parameters for a target level of security.</p>

    <p class="text-gray-300">In this subsection, we expand on the details of Vortex. We will first assume two integers  <span class="math">m</span>  and  <span class="math">k</span> , denoting the number of rows and columns.</p>

    <p class="text-gray-300">Let  <span class="math">\\mathcal{H}</span>  be our hash function (Section 7.1) parameterized to be able to hash vectors of size (at least)  <span class="math">m</span> . We also use a systematic <span class="math">^3</span>  Reed-Solomon  <span class="math">\\mathcal{L}</span>  with message size  <span class="math">k</span>  and codeword-size  <span class="math">n &amp;gt; k</span> . We denote its encoding algorithm  <span class="math">\\text{encode}_{\\mathcal{L}}</span> . Vortex consists of three algorithms: Setup, Commit, and OpenEval.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Setup is a transparent offline phase run by both the prover and verifier. During this phase, they perform precomputations involving sampling the parameters for the hash and the encoding scheme used as the public parameters.</li>

      <li>The Commit algorithm: Let  <span class="math">W</span> , be the matrix whose  <span class="math">i^{\\text{th}}</span>  row is  <span class="math">w_i \\in \\mathbb{F}^k</span> . Thus,  <span class="math">W</span>  has  <span class="math">m</span>  rows and  <span class="math">k</span>  columns. The prover encodes each row of  <span class="math">W</span>  (noted by  <span class="math">w_i</span> ) using the encoding function and obtains  <span class="math">W&#x27;</span>  (which has  <span class="math">n</span>  columns). The prover then computes the hash of the columns. The value  <span class="math">H = h_1, \\dots, h_n</span>  forms the commitment.</li>

      <li>The batch-opening phase or OpenEval is an interactive protocol where the prover runs the ProveOpening algorithm and the verifier runs the VerifyOpening. At the beginning of this phase, the prover holds  <span class="math">W, W&#x27;</span>  and the verifier holds the final commitment as input. Both hold the statement  <span class="math">x, y</span> . The prover's goal is to convince the verifier that for  <span class="math">\\forall i &amp;lt; m, w_i(x) = y_i</span> , if  <span class="math">W</span>  is a batch of polynomials and their evaluations stand in Lagrange basis. The verifier then sends the random scalar  <span class="math">\\alpha</span> , and the prover responds with  <span class="math">u</span>  claimed to be  <span class="math">u := \\alpha^\\top W</span> , if  <span class="math">W</span>  is polynomial, where  <span class="math">\\alpha = (1, \\alpha, \\alpha^2, \\ldots, \\alpha^{m-1})</span> . Then, the verifier samples  <span class="math">t</span>  columns  <span class="math">q_1, \\dots, q_t</span>  ( <span class="math">q_i \\leq n</span> ) uniformly at random, and the prover responds with  <span class="math">(s_1 \\dots s_t)</span>  chosen columns of  <span class="math">W&#x27;</span> . The verifier computes  <span class="math">u&#x27;</span>  as the Reed-Solomon encoding of  <span class="math">u</span>  and performs the following checks for all opened columns:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Proximity Check: the scalar-product  <span class="math">\\alpha^{\\top} s_i \\stackrel{?}{=} u_{q_i}&#x27;</span></li>

      <li>the hash of  <span class="math">s_i</span>  is correct and consistent with  <span class="math">h_{q_i}</span> .</li>

      <li>Evaluation Check: the relation  <span class="math">u(x) \\stackrel{?}{=} \\boldsymbol{\\alpha}^{\\top} \\cdot y</span>  where the vector  <span class="math">u</span>  is considered as the coefficient of polynomial  <span class="math">u(x)</span></li>

    </ul>

    <p class="text-gray-300">The first check (the random combination over random columns), is used for checking the proximity of a batch in [6]. Fig. 10 sums up the above.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Setup an instance of hash, Hash, corresponding to the security level  <span class="math">\\lambda</span></li>

      <li>Choose  <span class="math">t</span>  (the number of columns that should be opened later) to reach the security level  <span class="math">\\lambda</span></li>

      <li>Runs pre-computations relative to encode  <span class="math">\\mathcal{L}</span>  (e.g., finding  <span class="math">D\\subset \\mathbb{F}_q</span>  and relevant parameters for the security level  <span class="math">\\lambda</span> )</li>

      <li>Collect all the computed parameters in pp and return it.</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Encode each row of  <span class="math">W</span>  and obtain  <span class="math">W^{\\prime}</span></li>

      <li>Hash each column of  <span class="math">W^{\\prime}</span>  to obtain  <span class="math">(h_1\\cdots h_n)</span></li>

      <li>Return  <span class="math">(h_1\\cdots h_n)</span></li>

    </ol>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Fig. 10. Vortex Polynomial commitment</p>

    <p class="text-gray-300">Security of Vortex. The security of Vortex is thoroughly analyzed in [13], here we restate the results of this work. Vortex satisfies the knowledge-soundness of (batched) list polynomial commitment given in Definition 12 in the Random Oracle Model and has a straight line extractor. Writing  <span class="math">F(x) = \\mathsf{MiMC}(\\mathsf{SIS}(x))</span>  we heuristically model  <span class="math">F</span>  as a random oracle and use it to hash the columns. The intuition is that MiMC, being itself modifiable as a random oracle, breaks down all the linear properties of the SIS hash.</p>

    <p class="text-gray-300">List Polynomial Commitment for Long Polynomials Here we show how to build a polynomial commitment from Vortex. The prover  <span class="math">\\mathcal{P}</span>  can send a polynomial  <span class="math">P</span>  whose degree is larger than the number of columns in  <span class="math">W</span> . The polynomial can be folded in several chunks  <span class="math">P(X) = P_0(X) + X^n P_1(X) + \\dots</span> . Each one of the chunks  <span class="math">P_i(X)</span>  is then inserted into  <span class="math">W</span>  as an entire row. To commit and open the polynomials  <span class="math">P(X)</span>  via Vortex, set  <span class="math">W</span>  as above. The verifier can then recombine the  <span class="math">P_i(X)</span>  evaluations to obtain the  <span class="math">P(X)</span>  evaluation. This allows us to switch between the definitions of batched polynomial commitments to a version that only commits to one polynomial. This fact is provided as a side note and is not used in Linea's</p>

    <p class="text-gray-300">prover since the Arcane compiler is already responsible for splitting polynomials. Besides, our work stands for polynomials in Lagrange basis.</p>

    <h3 id="sec-83" class="text-xl font-semibold mt-8">7.3 Constant-size commitment</h3>

    <p class="text-gray-300">As a simple optimization over the commitment size, we apply a SNARK-friendly hash function (e.g., MiMC hash or Poseidon) over each <span class="math">h_{i}</span> and then compute a Merkle tree over the results. This is particularly useful for compiling PIOP to AoK via Vortex since the Vortex commitment phase will not be offline anymore and will be part of the proof. It is important to note, however, that the hash function used in constructing the Merkle tree needs to be modelled as a random oracle for the scheme to retain extractability.</p>

    <h3 id="sec-84" class="text-xl font-semibold mt-8">7.4 Batch opening for several batches of Polynomial</h3>

    <p class="text-gray-300">As shown above, Vortex allows committing to several polynomials (forming a matrix) at once. This can be extended to a “multi-batch” opening protocol in which the prover argues the evaluation of multiple batches (which may have been committed to at different moments) simultaneously at the same evaluation point. In this batched protocol, the prover sends only a single linear combination of all the rows of all the matrices as opposed to one per committed matrix in the non-batched setting. Additionally, during the column opening phase, the verifier queries the same columns position for all the matrices. This is the version of the protocol that we actually use to instantiate an Argument of Knowledge.</p>

    <h2 id="sec-85" class="text-2xl font-bold">8 AOK from PIOP and Vortex</h2>

    <p class="text-gray-300">This section briefly discusses the compiler described in <em>[13]</em> and compares it with related works. For a in-depth description of the compiler and its analysis, we refer to <em>[13]</em>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In <em>[23, appendix E]</em>, combining a knowledge-sound polynomial commitment with knowledge-sound PIOP results in a knowledge-sound argument system. This can not be applied directly to our setting. Particularly, since we are working with polynomial commitments in the list decoding regime (LPC), the knowledge-soundness of Vortex is not defined w.r.t a standard relation for a PC scheme. In KVP22 <em>[36]</em>, they show that Batch-FRI in the list-decoding regime (as an LPC) can be combined with PLONK-PIOP resulting in an argument system. Here we generalize their result and show that any PIOP can be combined with an LPC. There is some evidence that shows that such a transformation can still be possible for special PIOP and with the cost of losing a factor $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> of the soundness of PIOP <em>[36, 17]</em>. Slightly more formally, let </span>(P_{O},V_{O})<span class="math"> be a PIOP for the relation </span>\\mathcal{R}<span class="math"> that is transformed to an AoK </span>(P,V)<span class="math"> via a list polynomial commitment </span>(P_{c},V_{c})$. Then it is conjectured that the soundness of AoK follows from the following,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">.\\epsilon_{\\text{PIOP}}+\\epsilon_{\\text{LPC}}\\approx O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">.k^{c}/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+\\epsilon_{\\text{LPC}})$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where <span class="math">k</span> is the degree of polynomials involved in PIOP and $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> is the maximum size of the list associated with LPC. If the size of the field is big compared to </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ working in the list decoding regime can be beneficial. Here we give our proof intuition asserting the above conjecture is true. The proof is detailed in <em>[13]</em>.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Note that for LPC, a cheating prover can leverage the list decoding property to commit to a list and later decide which one to evaluate. This means for each round, the prover may use a different agreement set (or visually a different list index), this would increase the soundness loss to $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{r}/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. We force the prover to use the same agreement set over all the rounds by applying the evaluation protocol of Vortex over the concatenation of all the matrices from different rounds. This means that while for each round the commitment is applied over the relevant matrix, the opening is applied over a bigger matrix which is the concatenation of all the matrices. By this technique, we succeed in keeping the soundness loss to </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">r/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">As a reminder, the compiler starts from a UniEval P-IOP which is structured as follows. At every round and possibly once offline, the prover sends a batch of polynomials to the oracle and short messages to the prover and the protocol concludes on a Grail-query where all polynomials are queried at the same point. For simplicity, we will account for the offline precomputed polynomials as being part of the round <span class="math">-1</span> and suppose that all the polynomials involved in the protocol have the same size (this is ensured by the Arcane compiler already). Here, we use the variant of Vortex that uses Merkle roots of the ring-SIS hashes as commitment. For each of these batches <span class="math">W_{h}</span> of <span class="math">m_{h}</span> polynomials, the prover computes using Commit sends a Vortex commitment’s Merkle root <span class="math">\\mathsf{Root}_{h}</span>. Fig. 11 expands on how our compiler simulates the oracle. Note that all randomnesses used in the protocol are still managed as interactive messages between the prover and the verifier of UniEval and the compilation does not touch these.</p>

    <p class="text-gray-300">AoKCompiler(UniEval)</p>

    <p class="text-gray-300">AoKSetup<span class="math">(\\lambda,\\mathcal{L},n)</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{pp}_{\\mathsf{UniEval}}\\leftarrow\\mathsf{UniEvalSetup}(\\lambda)</span></li>

      <li>Set <span class="math">m</span> as the size of the largest batch of polynomials found in UniEval’s description.</li>

      <li><span class="math">\\mathsf{pp}_{\\mathsf{Vortex}}\\leftarrow\\mathsf{VortexSetup}(\\lambda,\\mathcal{L},m,n)</span></li>

      <li>Set <span class="math">W_{-1}</span> as the matrix constructed by taking all the precomputed polynomials and commits to it to obtain <span class="math">\\mathsf{Root}_{-1}</span></li>

      <li><span class="math">\\mathsf{pp}_{\\mathsf{AoK}}\\leftarrow(\\mathsf{pp}_{\\mathsf{UniEval}},\\mathsf{pp}_{\\mathsf{Vortex}},\\mathsf{Root}_{-1})</span></li>

      <li><span class="math">\\mathsf{return}\\ \\mathsf{pp}_{\\mathsf{AoK}}</span></li>

    </ol>

    <p class="text-gray-300">CommitmentPhase(<span class="math">\\mathsf{pp}_{\\mathsf{AoK}};W_{h}</span>)</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Prover computes <span class="math">\\mathsf{Root}_{h}\\leftarrow\\mathsf{VortexCommit}(\\mathsf{pp}_{\\mathsf{Vortex}},W_{h})</span> and sends it to the verifier</li>

    </ol>

    <p class="text-gray-300">OpeningPhase(<span class="math">\\mathsf{pp}_{\\mathsf{AoK}},\\mathsf{Root}_{-1,\\ldots,n_{\\mathsf{round}}},x,y</span>)</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The prover and the verifier engage in the batch opening protocol of Vortex for all the rounds at once.</li>

    </ol>

    <p class="text-gray-300">Fig. 11. From UniEval P-IOP to AoK using Vortex LPC</p>

    <h2 id="sec-87" class="text-2xl font-bold">9 Self-Recursion of Vortex</h2>

    <p class="text-gray-300">As Vortex proofs are large, to obtain a SNARK, we compress the proof via a self-recursion technique where instead of opening the chosen columns <span class="math">(s_{1},\\ldots,s_{t})</span> and sending them to the verifier, the prover computes the hashes and the scalar-products itself (while the verifier has oracle access to <span class="math">u^{\\prime}</span> and the hash outputs). It sends proofs for the following facts:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The encoding <span class="math">\\mathsf{encode}_{\\mathcal{L}}(u)</span> is correctly computed as <span class="math">u^{\\prime}</span>: in our self-recursion protocol we work directly with the Reed-Solomon encoded column. It remains to show that <span class="math">u^{\\prime}</span> is a Reed-Solomon codeword and this is addressed in Section 9.1.2</li>

      <li>The checks <span class="math">u(x)\\stackrel{{\\scriptstyle?}}{{=}}\\bm{\\alpha}^{T}y</span> is addressed in Section 9.1.2, it leverages the fact that <span class="math">u^{\\prime}(x)=u(x)</span> in our settings.</li>

      <li>The opened columns are consistent with <span class="math">u^{\\prime}</span> as <span class="math">\\bm{\\alpha}^{T}s^{\\prime}_{i}=u^{\\prime}_{q_{i}}</span>: this is addressed in Section 9.4.</li>

      <li>The opened column hashes are included in the commitment trees at the requested positions. This includes the correctness of the SIS hashing operation from the verifier. This is addressed in Section 9.2 and is the</li>

    </ul>

    <p class="text-gray-300">most involved part of the section. And additionally, the verifier is required to verify Merkle proofs to assess the membership of the computed SIS hashes in the trees. This later part is addressed in Section 9.3.</p>

    <p class="text-gray-300">For each of the above relation, a dedicated PIOP protocol is designed. Concretely, the process of <em>self-recursion</em> transforms Vortex into a Wizard-IOP in which the prover sends oracle access to the relevant messages instead of sending them to the verifier directly (including the columns, all hash values and vector <span class="math">u</span> of the Vortex commitment).</p>

    <p class="text-gray-300">The verifier is then tasked to perform a few queries so that he can convince himself that the prover’s messages add up to an accepting transcript. The resulting protocol can then be recompiled using the Arcane compiler (developed in Section 5) and Vortex Section 7 and we can reiterate this process by reusing different instances of Ring-SIS and Reed-Solomon codes. This technique allows us to play with the tradeoff that we have when choosing the Ring-SIS parameters and the erasure code. Typically, Ring-SIS instances that use a large modulus degree compress poorly but are very fast to run. On the other hand, Ring-SIS instances with a small modulus degree compress very well but are slower to run. This creates a trade-off between the prover time on one side and the verifier time and proof size on the other. The self-recursion strategy allows us to use Ring-SIS instances with a large degree for the initial steps and progressively reduce the degree. Similarly, we can use an error-correcting code with a large rate (and small relative distance) at the beginning and progressively decrease the rate as we loop into more applications of the self-recursion process.</p>

    <h4 id="sec-88" class="text-lg font-semibold mt-6">9.1.1 SNARKs from Arguments of Knowledge</h4>

    <p class="text-gray-300">Consider the AOK presented in Section 8. After applying multiple steps of self-recursion on Vortex, the proof achieves succinctness, and it is possible to finalize it into a SNARK using the Fiat-Shamir transform. Note that each of the cycles of self-recursion occurs in the interactive world, thus the Fiat-Shamir transform is applied only once at the end. The final SNARK has a proof size and verifier time of <span class="math">O(\\log\\log(N))</span> and linear prover time and the final Vortex proof stands for a witness of size <span class="math">O(1)</span>. While the asymptotic performances are good, the concrete size of the final proof does not allow it to be directly verified on Ethereum. To remediate, we recursively composite it with the Plonk <em>[7]</em> proof system. As an optimization, we use MiMC hashes <em>[5]</em> instead of the ring-SIS based hash function that we present in Section 7.1. The motivation is that, while MiMC’s runtime is slower than the lattice-based hash, the cost of emulating the computation within a Plonk circuit can be made drastically cheaper thanks to the optimizations of <em>[12]</em> which uses the GKR <em>[31]</em> proof system to reduce the cost of proving the hashes. This optimization is also ported to the Fiat-Shamir hashes in the circuit.</p>

    <h3 id="sec-89" class="text-xl font-semibold mt-8">9.1 Protocol description</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In the following, we assume an initial interactive protocol output by the Vortex compiler using Merkle-tree hashing for shorter proofs and thus, with the following structure: <span class="math">n_{\\text{round}}</span> rounds of interactions initiated by the prover where he sends a Merkle-root and possibly several queries result and the verifier responds with a sequence of random coins and the protocol concludes on a Vortex proof opening. For simplicity, we make a small technical assumption that will be helpful for the self-recursion process: the number of committed polynomials per round is a multiple of $K=\\frac{n\\log_{2}\\beta}{\\log_{2}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)}<span class="math">, when </span>K>1<span class="math"> where </span>n<span class="math"> is the output-size of the SIS instance, </span>\\log_{2}\\beta<span class="math"> the bit size of each limb and </span>\\mathbb{F}$ the underlying prime field. This can be ensured by adding zero polynomials at every round until this is reached. For reference, we use the following variable notations:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">n_{\\text{col}}</span>: the number of columns in the committed (and unencoded matrix). This matches the size of the polynomials we initially committed to using Vortex.</li>

      <li><span class="math">n_{\\text{row}}</span>: the total number of rows, all rounds included and including the precomputation rows.</li>

      <li><span class="math">n_{\\text{rounds}}</span>: the number of interaction rounds before the Vortex opening starts in the input protocol</li>

      <li><span class="math">t</span>: the number of opened column during the Vortex opening</li>

    </ul>

    <p class="text-gray-300">9.1.1 Casting the Vortex proof into Wizard column</p>

    <p class="text-gray-300">As outlined in the introduction of this section, the initial step of the self-recursion is to convert the Vortex proof messages into committed Wizard columns. Since the individual commitments are already short, they remain prover messages but they will be used as part of the protocol. The same goes for the alleged evaluations <span class="math">y</span>, they remain visible to the verifier but are used within the self-recursion protocol under the hood of a “verifier-defined” column which we name <span class="math">Y</span>. We list the columns below:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{Root}_{h}</span>: columns of size 1, tagged as “proof messages”</li>

      <li><span class="math">Y</span>: a “verifier-defined” column storing all the alleged evaluations of the Vortex opening.</li>

      <li><span class="math">U_{\\alpha}</span>: the random linear combination of the rows of the committed matrices, directly in encoded form.</li>

      <li><span class="math">Q</span>: a column storing the indices of the opened columns in the protocol as sampled by the verifier. This column is “verifier-defined”.</li>

      <li><span class="math">\\mathsf{Preimage}_{i}</span>: the opened columns of the matrices stacked round by round and limb-decomposed. Namely, <span class="math">\\mathsf{Preimage}_{0}</span> contains concatenated values of the first opened columns for all committed round matrices.</li>

      <li><span class="math">\\mathsf{MerkleProofs}</span>: the Merkle-proofs used to justify the membership of the MiMC hashes of the SIS hashes of the opened columns.</li>

    </ul>

    <h4 id="sec-90" class="text-lg font-semibold mt-6">9.1.2 The linear combination of the rows</h4>

    <p class="text-gray-300">As part of the opening phase of Vortex, the prover sends <span class="math">U_{\\alpha}</span>, storing the linear combination of the rows of the committed matrix (encoded) by powers of a random coin <span class="math">\\alpha</span> (<span class="math">\\beta</span> in the Vortex section). And the verifier is willing to ensure that:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">U_{\\alpha}(x)=\\mathcal{A}^{T}y</span> where <span class="math">\\mathcal{A}=(1,\\alpha^{1},\\alpha^{2},\\ldots,\\alpha^{n_{\\text{row}}-1})</span> (noted <span class="math">\\mathcal{B}</span> in the Vortex description)</li>

      <li><span class="math">U_{\\alpha}</span> is a Reed-Solomon codeword</li>

    </ol>

    <p class="text-gray-300">The first check can be carried by calling the sub-protocols presented in Appendix A.1 and Appendix A.2 and the Reed-Solomon membership can be taken by a probabilistic argument. Reed-Solomon membership is equivalent to proving low-degreeness of a polynomial described a <span class="math">U_{\\alpha}</span> in Lagrange basis. As part of this argument, the prover exhibits a column <span class="math">U_{\\mathsf{coeff}}</span> storing the coefficient of the polynomial represented by <span class="math">U_{\\alpha}</span> in Lagrange form. Note that the size of <span class="math">U_{\\mathsf{coeff}}</span> is shorter than the size of <span class="math">U_{\\alpha}</span>. The prover and the verifier then engage in an argument to check that <span class="math">U_{\\mathsf{coeff}}</span> and <span class="math">U_{\\alpha}</span> evaluate to the same value at a random point. Fig. 12 details this sub-protocol.</p>

    <p class="text-gray-300"><span class="math">\\mathsf{ReedSolomon}(\\mathsf{U}_{\\alpha})</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[label=0)]</li>

      <li>Prover commits to <span class="math">U_{\\mathsf{coeff}}</span></li>

      <li>Verifier samples and sends a random coin <span class="math">r</span></li>

      <li>The prover responds with an alleged evaluation point <span class="math">y=U_{\\mathsf{coeff}}(r)=U_{\\alpha}(r)</span> where the first evaluation is in monomial basis and the second one in Lagrange basis.</li>

      <li>The prover and the verifier engage in <span class="math">\\mathsf{MonomialEval}(U_{\\mathsf{coeff}},r,y)</span> as in Appendix A.1</li>

      <li>The prover and the verifier engage in <span class="math">\\mathsf{LagrangeEval}(U_{\\alpha},r,y)</span> as in Appendix A.2.</li>

    </ol>

    <p class="text-gray-300">Fig. 12. Reed-Solomon membership check</p>

    <h3 id="sec-91" class="text-xl font-semibold mt-8">9.2 SIS hashing of the columns</h3>

    <p class="text-gray-300">As part of the column opening phase, the verifier is tasked to computes the <span class="math">t\\cdot n_{\\mathsf{round}}</span> SIS hashes, one for each of the opened columns as sent by the verifier. We present an outline of how the sub-protocol emulating this part is constructed. To clarify our settings, recall that each column <span class="math">\\mathsf{Preimage}_{i}</span> stacks the limbs of the opened column <span class="math">q_{i}</span> for all the rounds <span class="math">0\\ldots n_{\\mathsf{round}}-1</span>. The protocol unfolds as follows:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>All <span class="math">\\mathsf{Preimage}_{0\\dots t-1}</span> are range-checked. Note that, at this point, the only thing that remains to be proved is the linear part of verifying SIS hashes.</li>

      <li>We declare the precomputed columns <span class="math">A_0, \\ldots, A_h, \\ldots, A_{n_{\\text{round}}-1}</span>, the SIS key shards. They are constructed by taking <span class="math">A</span> the SIS commitment key of Vortex and shifting it so that the first coefficient of <span class="math">A</span> lines up with the first row of <span class="math">\\mathsf{Preimages}_{\\bullet}</span> corresponding to round <span class="math">h</span> and all rows of <span class="math">A_h</span> corresponding to rows that are outside of round <span class="math">h</span> in <span class="math">\\mathsf{Preimages}_{\\bullet}</span> are zeroized.</li>

      <li>The prover initiates by sending a committed columns <span class="math">\\mathsf{ConcatenatedDhQ}</span> storing the concatenation of the <span class="math">t</span> SIS hashes of the <span class="math">t</span> opened column for every round <span class="math">h &amp;lt; n_{\\text{round}}</span>, with the following ordering ordered as <span class="math">\\mathsf{ConcatenatedDhQ}_{it+j} = d_{i,j}</span> where <span class="math">d_{i,j}</span> denotes the SIS hash for round <span class="math">i</span> and the opened column <span class="math">j</span>.</li>

      <li>From this point, the prover and the verifier engage in a batching argument. The verifier 2 random coins that we name <span class="math">r_{\\text{merge}}</span> and <span class="math">r_{\\text{collapse}}</span>. The philosophy of this step is that <span class="math">r_{\\text{collapse}}</span> is used to combine items across the <span class="math">t</span> linearly opened columns together, <span class="math">r_{\\text{merge}}</span> to linearly combine items across the <span class="math">n_{\\text{round}}</span>.</li>

      <li>The prover and the verifier engage in a folding protocol of Appendix A.4 over <span class="math">\\mathsf{ConcatenatedDhQ}</span>, a first time over <span class="math">r_{\\text{merge}}</span> to obtain a column <span class="math">\\mathsf{Dh}_{\\text{merge}}</span> and a second time over <span class="math">r_{\\text{collapse}}</span> to finally obtain <span class="math">\\mathsf{Dh}_{\\text{merge},\\text{collapse}}</span> representing a linear combination of all the individual SIS digests. It is tagged as a "proof" message.s</li>

      <li>The prover and the verifier set <span class="math">A_{\\text{merge}}</span> and <span class="math">\\mathsf{Preimage}_{\\text{collapse}}</span> as aliases for the linear combinations of the columns <span class="math">A_h</span> by powers of <span class="math">r_{\\text{merge}}</span> and of the columns <span class="math">\\mathsf{Preimage}_i</span> by <span class="math">r_{\\text{collapse}}</span></li>

      <li>At this point, we can reinterpret the columns <span class="math">A_{\\text{merge}}</span> and <span class="math">\\mathsf{Preimage}_{\\text{collapse}}</span> as vectors of ring elements <span class="math">\\mathbf{A} = (A_0(X), A_1(X), \\ldots)</span> and <span class="math">\\mathbf{P} = (P_0(X), P_1(X), \\ldots)</span> in the SIS ring <span class="math">\\mathcal{R}</span>, expressed in coefficient form and concatenated within their respective columns. Similarly, <span class="math">\\mathsf{Dh}_{\\text{merge},\\text{collapse}}</span> can be viewed as a ring element <span class="math">\\mathbf{D}</span> in <span class="math">\\mathcal{R}</span>. The rest of the protocol aims at proving that <span class="math">\\mathbf{D} = \\mathbf{A}^T\\mathbf{P}</span> where the inner-product is taken modulo <span class="math">X^d + 1</span>. We start from the following observation: let <span class="math">P(X)</span> be a polynomial of degree <span class="math">&amp;lt; 2d</span> and let <span class="math">Q(X) = P(X) \\mod X^d + 1</span> and <span class="math">R(X) = P(X) \\mod X^d - 1</span>, then we have:</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">2P(X) = (X^d - 1)Q(X) + (X^d + 1)R(X)</span></div>

    <p class="text-gray-300">The intent will be to test this equality at a random point. Concretely, the prover sends a column <span class="math">E_{\\text{dual}}</span> as "proof", containing the coefficient of the polynomial <span class="math">\\mathbf{A}^T\\mathbf{P} \\mod X^d - 1</span>.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The verifier samples a coin <span class="math">r_{\\text{fold}}</span> and engages with the prover in the folding protocol of Appendix A.4 for both <span class="math">A_{\\text{merge}}</span> and <span class="math">\\mathsf{Preimage}_{\\text{collapse}}</span> to obtain <span class="math">A_{\\text{merge},\\text{fold}}</span> and <span class="math">\\mathsf{Preimage}_{\\text{collapse},\\text{fold}}</span>. The verifier then queries the inner product of these two folded polynomials to obtain <span class="math">p</span>.</li>

      <li>Finally, the verifier checks that</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">2p \\stackrel{?}{=} (r_{\\text{fold}}^d - 1)\\mathsf{Dh}_{\\text{merge},\\text{collapse}}(r_{\\text{fold}}) + (r_{\\text{fold}}^d + 1)E_{\\text{dual}}(r_{\\text{fold}})</span></div>

    <h2 id="sec-92" class="text-2xl font-bold">9.3 Inclusion of the SIS hashes in the Merkle roots</h2>

    <p class="text-gray-300">This section briefly outlines how the sub-protocol responsible for hashing the SIS hashes into Merkle leaves and proving inclusion in the commitments Merkle roots. We start from the columns <span class="math">Q</span> storing the indices of the opened positions, Rooth each storing the roots of all the opened columns. We also reuse the column ConcatenatedDhQ from the SIS hashing phase, containing the concatenated SIS hashes computed by the verifier.</p>

    <p class="text-gray-300">5 In fact, in our implementation we use <span class="math">r_{\\text{merge}} = r_{\\text{collapse}}^t</span></p>

    <p class="text-gray-300">33</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>We first invoke the sub-protocol for Appendix A.7 in order to instantiate a column Leaves storing the hashes of the SIS hashes.</li>

      <li>Then, we construct the columns MerkleRoots and MerklePositions using two fixed-permutation query from a verifier-defined column constructed from <span class="math">\\mathsf{Root}_{h}</span> and from <span class="math">Q</span>. These will be used to construct the statement of the Merkle module Appendix A.8</li>

      <li>We conclude the sub-protocol by invoking the Merkle module using the MerkleProofs column.</li>

    </ol>

    <h3 id="sec-93" class="text-xl font-semibold mt-8">9.4 Consistency of the opened columns with <span class="math">U_{\\alpha}</span></h3>

    <p class="text-gray-300">This section briefly outlines how the sub-protocol emulating the check <span class="math">\\boldsymbol{\\alpha}^{T}s_{i}\\stackrel{{\\scriptstyle?}}{{=}}u_{q_{i}}^{\\prime}</span>. Our starting point is the columns <span class="math">\\mathsf{Preimages}_{i}</span> storing the values of <span class="math">s_{i}</span> in limb-decomposed form and the column <span class="math">U_{\\alpha}</span>. The verifier also has access to <span class="math">Q</span>, “verifier-defined” storing the opened positions of the column opening phase.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The first step of the sub-protocol aims at deriving a column <span class="math">U_{\\alpha,q}</span> from <span class="math">U_{\\alpha}</span> and <span class="math">Q</span>, storing the entries of <span class="math">U_{\\alpha}</span> at the positions indexed by <span class="math">Q</span>. This is implemented using an inclusion query and a precomputed table <span class="math">I</span> storing all the integers up to <span class="math">n_{\\mathsf{encoded}}</span> in increasing order <span class="math">(0,1,2,3,\\cdots,n_{\\mathsf{encoded}}-1)</span>. The verifier queries</li>

    </ol>

    <p class="text-gray-300"><span class="math">\\text{\`\`Inclusion&#x27;&#x27;}:\\quad(Q,U_{\\alpha,q})\\subset(I,U_{\\alpha})</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Then, it remains to ensure that the linear combination of <span class="math">\\mathsf{Preimages}_{i}</span> (recomposed in field elements) with <span class="math">\\boldsymbol{\\alpha}</span> matches the entries <span class="math">U_{\\alpha,i}</span>. To this end, we use the coin <span class="math">r_{\\mathsf{collapse}}</span> and the column <span class="math">\\mathsf{Preimages}_{\\mathsf{collapse}}</span> and we use the sub-protocols in Appendix A.1 and Appendix A.3 to check:</li>

    </ol>

    <p class="text-gray-300"><span class="math">\\mathsf{MonomialEval}(U_{\\alpha,q},r_{\\mathsf{collapse}})=\\mathsf{BivariateEval}(\\mathsf{Preimages}_{\\mathsf{collapse}},2,\\alpha)</span></p>

    <h3 id="sec-94" class="text-xl font-semibold mt-8">Acknowledgements</h3>

    <p class="text-gray-300">We are grateful to the Linea Prover team, zkEVM, Gnark team, and Nicolas Liochon for their feedback and useful discussions on the paper.</p>

    <h2 id="sec-95" class="text-2xl font-bold">References</h2>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[1] <em>A native zkEVM Layer 2 Solution for Ethereum</em>. url: https://scroll.io/.</li>

      <li>[2] Miklós Ajtai. “Generating Hard Instances of Lattice Problems”. In: <em>Electron. Colloquium Comput. Complex</em>. TR96 (1996).</li>

      <li>[3] Martin R. Albrecht, Rachel Player, and Sam Scott. “On the concrete hardness of Learning with Errors”. In: <em>Journal of Mathematical Cryptology</em> 9 (2015), pp. 169–203.</li>

      <li>[4] Martin R. Albrecht et al. “Estimate all the {LWE, NTRU} schemes!” In: <em>IACR Cryptol. ePrint Arch.</em> 2018.</li>

      <li>[5] Martin R. Albrecht et al. “MiMC: Efficient Encryption and Cryptographic Hashing with Minimal Multiplicative Complexity”. In: <em>ASIACRYPT</em>. Vol. 10031. LNCS. 2016, pp. 191–219.</li>

      <li>[6] Scott Ames et al. “Ligero: Lightweight Sublinear Arguments Without a Trusted Setup”. In: <em>Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security</em> (2017).</li>

      <li>[7] Zachary Ariel Gabizon, J. Williamson, and Oana Ciobotaru. “PLONK: Permutations over Lagrange-bases for Oecumenical Noninteractive arguments of Knowledge”. In: <em>IACR Cryptol. ePrint Arch.</em> (2019), p. 953.</li>

      <li>[8] Shi Bai et al. “Improved Combinatorial Algorithms for the Inhomogeneous Short Integer Solution Problem”. In: <em>J. Cryptol.</em> (2019).</li>

      <li>[9] Stephanie Bayer and Jens Groth. “Efficient Zero-Knowledge Argument for Correctness of a Shuffle”. In: <em>EUROCRYPT</em>. 2012.</li>

      <li>[10] Olivier Bégassat et al. <em>A ZK-EVM specification</em>. 2022.</li>

    </ul>

    <p class="text-gray-300">-</p>

    <p class="text-gray-300">[11] Alexandre Belling, Azam Soleimanian, and Olivier Bégassat. “Recursion over Public-Coin Interactive Proof Systems; Faster Hash Verification”. In: IACR Cryptol. ePrint Arch. (2022), p. 1072. url: https://eprint.iacr.org/2022/1072.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[12] Alexandre Belling, Azam Soleimanian, and Olivier Bégassat. Recursion over Public-Coin Interactive Proof Systems; Faster Hash Verification. Cryptology ePrint Archive, Paper 2022/1072. 2022. url: https://eprint.iacr.org/2022/1072.</li>

      <li>[13] Alexandre Belling, Azam Soleimanian, and Bogdan Ursu. Vortex: A List Polynomial Commitment and its Application to Arguments of Knowledge. Cryptology ePrint Archive, Paper 2024/185. https://eprint.iacr.org/2024/185. 2024. url: https://eprint.iacr.org/2024/185.</li>

      <li>[14] Eli Ben-Sasson, Alessandro Chiesa, and Nicholas Spooner. “Interactive Oracle Proofs”. In: Theory of Cryptography - 14th International Conference, TCC 2016-B, Beijing, China, October 31 - November 3, 2016, Proceedings, Part II. Ed. by Martin Hirt and Adam D. Smith. Vol. 9986. Lecture Notes in Computer Science. 2016, pp. 31–60. doi: 10.1007/978-3-662-53644-5\\_2. url: https://doi.org/10.1007/978-3-662-53644-5%5C_2.</li>

      <li>[15] Eli Ben-sasson, Alessandro Chiesa, and Nicholas Spooner. “Interactive Oracle Proofs”. In: Theory of Cryptography TCC 2016-B. Vol. 9986. LNCS. 2016, pp. 31–60.</li>

      <li>[16] Eli Ben-Sasson et al. “Aurora: Transparent Succinct Arguments for R1CS”. In: IACR Cryptol. ePrint Arch. 2018.</li>

      <li>[17] Eli Ben-Sasson et al. “DEEP-FRI: Sampling Outside the Box Improves Soundness”. In: 11th Innovations in Theoretical Computer Science Conference, ITCS 2020, January 12-14, 2020, Seattle, Washington, USA. Vol. 151. LIPIcs. 2020, 5:1–5:32.</li>

      <li>[18] Eli Ben-Sasson et al. “Proximity Gaps for Reed-Solomon Codes”. In: 61st IEEE Annual Symposium on Foundations of Computer Science, FOCS 2020, Durham, NC, USA, November 16-19, 2020. Ed. by Sandy Irani. IEEE, 2020, pp. 900–909. doi: 10.1109/FOCS46700.2020.00088.</li>

      <li>[19] Eli Ben-sasson et al. “Scalable Zero Knowledge Via Cycles of Elliptic Curves”. In: Algorithmica 79 (Oct. 2016), pp. 1–59.</li>

      <li>[20] Dan Boneh et al. “Efficient polynomial commitment schemes for multiple points and polynomials”. In: IACR Cryptol. ePrint Arch. (2020), p. 81.</li>

      <li>[21] Jonathan Bootle, Alessandro Chiesa, and Jens Groth. “Linear-Time Arguments with Sublinear Verification from Tensor Codes”. In: IACR Cryptol. ePrint Arch. 2020 (2020), p. 1426.</li>

      <li>[22] Sean Bowe, Jack Grigg, and Daira Hopwood. Recursive Proof Composition without a Trusted Setup. Cryptology ePrint Archive, Report 2019/1021. 2019.</li>

      <li>[23] Benedikt Bünz, Ben Fisch, and Alan Szepieniec. “Transparent SNARKs from DARK Compilers”. In: Advances in Cryptology - EUROCRYPT 2020 - 39th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Zagreb, Croatia, May 10-14, 2020, Proceedings, Part I. Ed. by Anne Canteaut and Yuval Ishai. Vol. 12105. Lecture Notes in Computer Science. Springer, 2020, pp. 677–706.</li>

      <li>[24] Alessandro Chiesa, Dev Ojha, and Nicholas Spooner. “Fractal: Post-quantum and Transparent Recursive Proofs from Holography”. In: LNSC. Vol. 12105. May 2020, pp. 769–793.</li>

      <li>[25] Alessandro Chiesa et al. “Marlin: Preprocessing zkSNARKs with Universal and Updatable SRS”. In: Advances in Cryptology EUROCRYPT. Vol. 12105. LNCS. Springer, 2020, pp. 738–768.</li>

      <li>[26] Ronald Cramer, Léo Ducas, and Benjamin Wesolowski. “Short Stickelberger Class Relations and Application to Ideal-SVP”. In: EUROCRYPT. 2017.</li>

      <li>[27] Léo Ducas et al. “CRYSTALS-Dilithium Algorithm Specifications and Supporting Documentation”. In: 2017. url: https://api.semanticscholar.org/CorpusID:198994007.</li>

      <li>[28] the Electric Coin Company. The Halo 2 book. url: https://zcash.github.io/halo2/.</li>

      <li>[29] Ariel Gabizon and Zachary J. Williamson. “Plookup: A simplified polynomial protocol for lookup tables”. In: IACR Cryptol. ePrint Arch. (2020).</li>

      <li>[30] Lior Goldberg, Shahar Papini, and Michael Riabzev. “Cairo - a Turing-complete STARK-friendly CPU architecture”. In: IACR Cryptol. ePrint Arch. 2021 (2021), p. 1063.</li>

    </ul>

    <p class="text-gray-300">[31] Shafi Goldwasser, Yael Kalai, and Guy Rothblum. “Delegating Computation: Interactive Proofs for Muggles”. In: ACM STOC. ACM, 2008, pp. 113–122.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[32] Alexander Golovnev et al. “Brakedown: Linear-time and post-quantum SNARKs for R1CS”. In: IACR Cryptol. ePrint Arch. 2021 (2021), p. 1043.</li>

      <li>[33] Jens Groth. “On the Size of Pairing-Based Non-interactive Arguments”. In: Advances in Cryptology - EUROCRYPT. Vol. 9666. LNCS. Springer, 2016, pp. 305–326.</li>

      <li>[34] Ulrich Haböck. Multivariate lookups based on logarithmic derivatives. Cryptology ePrint Archive, Paper 2022/1530. https://eprint.iacr.org/2022/1530. 2022. url: https://eprint.iacr.org/2022/1530.</li>

      <li>[35] Nick Howgrave-Graham and Antoine Joux. “New Generic Algorithms for Hard Knapsacks”. In: Advances in Cryptology – EUROCRYPT 2010. 2010, pp. 235–256.</li>

      <li>[36] Assimakis Kattis, Konstantin Panarin, and Alexander Vlasov. “RedShift: Transparent SNARKs from List Polynomial Commitment IOPs”. In: IACR Cryptol. ePrint Arch. (2019), p. 1400.</li>

      <li>[37] Abhiram Kothapalli, Srinath Setty, and Ioanna Tzialla. “Nova: Recursive Zero-Knowledge Arguments from Folding Schemes”. In: Advances in Cryptology – CRYPTO 2022. Ed. by Yevgeniy Dodis and Thomas Shrimpton. Cham: Springer Nature Switzerland, 2022, pp. 359–388.</li>

      <li>[38] Benoît Libert, Somindu C. Ramanna, and Moti Yung. Functional Commitment Schemes: From Polynomial Commitments to Pairing-Based Accumulators from Simple Assumptions. 2016.</li>

      <li>[39] Vadim Lyubashevsky et al. “SWIFFT: A Modest Proposal for FFT Hashing”. In: Fast Software Encryption, 15th International Workshop, FSE 2008. Vol. 5086. Lecture Notes in Computer Science. Springer, 2008, pp. 54–72. doi: 10.1007/978-3-540-71039-4\\_4. url: https://doi.org/10.1007/978-3-540-71039-4%5C_4.</li>

      <li>[40] Mary Maller et al. “Sonic: Zero-Knowledge SNARKs from Linear-Size Universal and Updatable Structured Reference Strings”. In: ACM SIGSAC -CCS. ACM, 2019, pp. 2111–2128.</li>

      <li>[41] Daniele Micciancio and Oded Regev. Class on lattice-based cryptography. 2008.</li>

      <li>[42] Priyanka Mukhopadhyay. “Improved algorithms for the Shortest Vector Problem and the Closest Vector Problem in the infinity norm”. In: Dec. 2018. doi: 10.4230/LIPIcs.ISAAC.2018.35.</li>

      <li>[43] I. S. Reed and G. Solomon. “Polynomial Codes Over Certain Finite Fields”. In: Journal of the Society for Industrial and Applied Mathematics 8.2 (1960), pp. 300–304. doi: 10 . 1137 / 0108018. eprint: https://doi.org/10.1137/0108018. url: https://doi.org/10.1137/0108018.</li>

      <li>[44] Srinath Setty. Spartan: Efficient and general-purpose zkSNARKs without trusted setup. CRYPTO. 2020.</li>

      <li>[45] Srinath T. V. Setty, Justin Thaler, and Riad S. Wahby. “Unlocking the lookup singularity with Lasso”. In: IACR Cryptol. ePrint Arch. (2023), p. 1216. url: https://eprint.iacr.org/2023/1216.</li>

      <li>[46] Zedong Sun, Chunxiang Gu, and Yonghui Zheng. “A Review of Sieve Algorithms in Solving the Shortest Lattice Vector Problem”. In: IEEE Access 8 (2020), pp. 190475–190486.</li>

      <li>[47] Polygon Hermez Team. Scalable payments. Decentralised by design, open for everyone. https://hermez.io.</li>

      <li>[48] Tiacheng Xie et al. “Libra: Succinct Zero-Knowledge Proofs with Optimal Prover Computation”. In: Advances in Cryptology - CRYPTO. Vol. 11694. LNCS. Springer, 2019, pp. 733–764.</li>

      <li>[49] Tiancheng Xie, Yupeng Zhang, and Dawn Xiaodong Song. “Orion: Zero Knowledge Proof with Linear Prover Time”. In: IACR Cryptol. ePrint Arch. 2022.</li>

      <li>[50] Risc Zero. https://github.com/risc0/risc0. 2022.</li>

      <li>[51] Jiaheng Zhang et al. Transparent Polynomial Delegation and Its Applications to Zero Knowledge Proof. 2020 IEEE Symposium on Security and Privacy (SP). 2019.</li>

    </ul>

    <h2 id="sec-96" class="text-2xl font-bold">Appendix A Useful wizard subprotocols</h2>

    <p class="text-gray-300">In this section, we present a set of utility Wizard protocols with simple functionality which can be seen as common sub-routines that we use as part of <span class="math">Section</span> 9.</p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">A.1 Monomial basis evaluation protocol</p>

    <p class="text-gray-300">In this sub-protocol, we assume a column <span class="math">P</span> of size <span class="math">n</span> and scalar values <span class="math">r</span> and <span class="math">y</span>, visible to the verifier, whose assignment value is unspecified during the protocol definition (<span class="math">r</span> is possibly a random coin). The goal of the Monomial basis sub-protocol is to construct a convincing argument for the statement:</p>

    <p class="text-gray-300"><span class="math">P(r)=\\sum_{i&lt;n}P_{i}r^{i}=y</span></p>

    <p class="text-gray-300">where <span class="math">P(X)</span> is the polynomial whose coefficients are the entries of <span class="math">P</span>. The Horner evaluation algorithm inspires the sub-protocol we present. The protocol uses an accumulator column <span class="math">H</span> retracing the computation steps of the algorithm and constructed as:</p>

    <p class="text-gray-300"><span class="math">H_{i}=\\sum_{i\\leq j&lt;n}P_{j}r^{j-i}</span></p>

    <p class="text-gray-300">Fig. 13 describes the protocol:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The prover constructs and commits to the column <span class="math">H</span></li>

      <li>“Local constraint”: <span class="math">H_{f}=P_{f}</span> where <span class="math">f</span> indicates that the last value of the column is used.</li>

      <li>“Global” <span class="math">H=x(H\\ll 1)+P</span></li>

      <li>The verifier checks that <span class="math">H_{0}=y</span> and gets <span class="math">H_{0}</span> via a local opening query</li>

    </ol>

    <p class="text-gray-300"><span class="math">\\mathbf{Mod}</span> <span class="math">\\mathbf{Mod}</span> <span class="math">\\mathbf{Mod}</span></p>

    <h3 id="sec-97" class="text-xl font-semibold mt-8">A.2 Lagrange basis evaluation protocol</h3>

    <p class="text-gray-300">In this sub-protocol, we assume a column <span class="math">P</span> of size <span class="math">n</span> and a verifier with access to a scalar value <span class="math">r</span> and <span class="math">y</span> whose assignment value is unspecified during the protocol definition (<span class="math">r</span> is possibly a random coin). <span class="math">a</span> must not be a root of unity. The goal of the Lagrange basis sub-protocol is to construct a convincing argument for the statement:</p>

    <p class="text-gray-300"><span class="math">P(r)=\\frac{1}{n}\\sum_{i&lt;n}\\frac{P_{i}}{\\frac{a}{\\omega^{i}}-1}=y</span></p>

    <p class="text-gray-300">where <span class="math">P(X)</span> is the Lagrange interpolation polynomial of <span class="math">P</span> over the usual roots of unity domain without resorting to using a univariate evaluation query. This addresses a limitation of the Arcane compiler as univariate queries cannot exist at the beginning of the compilation. As an outline, the sub-protocol requires the prover to commit to an accumulating polynomial <span class="math">I</span> retracing all the steps of computing <span class="math">P(a)</span> with the barycentric formula. Let <span class="math">\\omega</span> be a generator of the groups of roots of unity. The sub-protocol is detailed in Fig. 14. In the sub-protocol, we introduce, the intermediary alias <span class="math">\\Delta=I-(I\\ll-1)</span>. We have that</p>

    <p class="text-gray-300"><span class="math">\\forall i\\geq 1:\\Delta_{i}=\\frac{P_{i}}{\\frac{a}{\\omega^{i}}-1}</span> <span class="math">\\omega^{i}=\\frac{a\\Delta_{i}}{\\Delta_{i}+P_{i}}</span></p>

    <p class="text-gray-300">If we divide the equation by itself substituting <span class="math">i-1</span>, we eliminate the dependency with <span class="math">w^{i}</span></p>

    <p class="text-gray-300"><span class="math">\\omega=\\frac{\\Delta_{i}(\\Delta i-1+P_{i-1})}{\\Delta_{i-1}(\\Delta_{i}+P_{i})}</span></p>

    <p class="text-gray-300">We can now rearrange the term to obtain a polynomial relation as below. This us a relation that we can use for a global constraint.</p>

    <p class="text-gray-300">Interpolation <span class="math">(P, a, y)</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The prover constructs and commits to the column <span class="math">I</span> such that</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\forall i &amp;lt; n: I_i = \\sum_{0 \\leq j \\leq i} \\frac{P_j}{\\frac{a}{\\omega^j}} - 1</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>"Local constraint": <span class="math">I_0(a - 1) = P_0</span></li>

      <li>"Local constraint": <span class="math">(a - \\omega)(I_1 - I_1) = \\omega P_1</span></li>

      <li>"Global constraint":</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">(\\omega - 1) \\Delta(\\Delta \\ll -1) + \\omega(\\Delta \\ll -1) P - \\Delta(P \\ll -1) = 0</span></div>

    <p class="text-gray-300">The constraint is cancelled at points 0 and 1, implicitly.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The verifier checks that the last value of <span class="math">I</span> equals the alleged value <span class="math">y</span> using a local opening query.</li>

    </ol>

    <p class="text-gray-300">Fig. 14. Lagrange evaluation sub-protocol</p>

    <p class="text-gray-300">A.3 Evaluate in coefficient form a 2-variable polynomial</p>

    <p class="text-gray-300">Consider a column <span class="math">C</span> to the coefficients of a 2-variate polynomial. The protocol that we present here aims at proving evaluation of <span class="math">C</span> at a point <span class="math">(x, y)</span>, where the polynomial has degree <span class="math">k - 1</span> in <span class="math">x</span> and degree <span class="math">l - 1</span> in <span class="math">y</span>. The structure of the sub-protocol is analogous to the univariate coefficient evaluation one: it is also inspired from the Horner algorithm and uses an accumulating column <span class="math">H</span> such that</p>

    <div class="my-4 text-center"><span class="math-block">\\forall 0 \\leq i &amp;lt; n - 1: H_i = P_i + H_{i+1}(Z_{l,n,i+1}x + (1 - Z_{l,n,i+1})yx^{-k}) \\tag{3}</span></div>

    <p class="text-gray-300">Where <span class="math">Z_{l,n}</span> is a "periodic sampling" column satisfying</p>

    <div class="my-4 text-center"><span class="math-block">i = 0 \\mod l \\iff Z_{l,n,i} = 1</span></div>

    <div class="my-4 text-center"><span class="math-block">i \\neq 0 \\mod l \\iff Z_{l,n,i} = 0</span></div>

    <p class="text-gray-300">The subprotocol is described in Fig. 15</p>

    <p class="text-gray-300">BivariateEval <span class="math">(P, a, y)</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The prover computes and commits to <span class="math">H</span></li>

      <li>Global Constraint:</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">H = P + (H \\ll 1)((Z_{l,n} \\ll 1)x + (1 - (Z_{l,n} \\ll 1)yx^{-k})</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Local Constraint: <span class="math">H_f = P_f</span></li>

      <li>Local Opening: <span class="math">H_0</span> and the verifier checks <span class="math">H_0 \\stackrel{?}{=} y</span></li>

    </ol>

    <p class="text-gray-300">Fig. 15. Monomial bivariate evaluation sub-protocol</p>

    <p class="text-gray-300">A.4 Folding by one variable</p>

    <p class="text-gray-300">By "folding", we do not mean the popular folding technique introduced in Nova [37]. Consider <span class="math">P</span> a column seen as a bivariate polynomial in monomial form in <span class="math">X</span> and <span class="math">Y</span>. We aim to obtain the partial polynomial</p>

    <p class="text-gray-300"><span class="math">P(x,Y)=P_{x}(Y)</span> for some value <span class="math">x</span>. To this end we design a dedicated protocol reusing the univariate and bivariate monomial evaluation protocols:</p>

    <h6 id="sec-98" class="text-base font-medium mt-4">Folding <span class="math">(P,P_{x})</span></h6>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The verifier samples a random coin <span class="math">r_{y}</span>.</li>

      <li>The prover proves that <span class="math">P(x,r_{y})=P_{x}(r_{y})</span> using the bivariate evaluation technique on the left and the monomial one on the right.</li>

    </ol>

    <p class="text-gray-300">Fig. 16. Monomial bivariate evaluation sub-protocol</p>

    <h3 id="sec-99" class="text-xl font-semibold mt-8">A.5 Periodically subsampling a column</h3>

    <p class="text-gray-300">This section presents a sub-protocol that can be used to assert that a column <span class="math">S</span> of size <span class="math">n</span> and obtained by periodically subsampling a larger column <span class="math">L</span> of size <span class="math">rn</span> with offset <span class="math">k</span>. Namely, the statement of the protocol is</p>

    <p class="text-gray-300"><span class="math">\\forall i\\in[n]:S_{i}=L_{ri+k}</span></p>

    <p class="text-gray-300">The technique used by this protocol is analogue to the folding protocol: the protocol uses a random coin <span class="math">\\rho</span> and simulates the probabilistic check:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\sum_{i\\in[n]}S_{i}\\rho^{i}\\stackrel{{\\scriptstyle?}}{{=}}\\sum_{i\\in[rn]}\\mathbb{I}_{i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">r}L_{i}\\rho^{i/r}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where $\\mathbb{I}_{i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">r}<span class="math"> is the indicatrice function for </span>i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">r$. The left hand evaluation is done using the monomial evaluation protocol and the second is evaluated using an analogue of the bivariate evaluation protocol which we present in Fig. 17</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Subsampling<span class="math">(L,\\rho)</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The prover constructs and commits to the column <span class="math">H</span></li>

      <li>“Local constraint”:</li>

    </ol>

    <p class="text-gray-300"><span class="math">H_{f}=P_{f}I</span></p>

    <p class="text-gray-300">where <span class="math">f</span> indicates that the last value of the column is used and <span class="math">I</span> is a periodic sampling column indicating with a 1 the positions in <span class="math">H</span> to be used.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>“Global”</li>

    </ol>

    <p class="text-gray-300"><span class="math">H=I\\left[x(H\\ll 1)+P\\right]+[1-I)\\rvert(H\\ll 1)</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The verifier checks that <span class="math">H_{0}=y</span> and gets <span class="math">H_{0}</span> via a local opening query</li>

    </ol>

    <p class="text-gray-300">Fig. 17. Subsampling sub-protocol</p>

    <h3 id="sec-100" class="text-xl font-semibold mt-8">A.6 MiMC compression function</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">This section details a sub-protocol for computing the MiMC <em>[5]</em> block compression function. We start by providing a reminder of the MiMC compression function algorithm in Fig. 20. <span class="math">\\sigma_{0}</span> denotes the initial state of the compression function and <span class="math">b</span> denotes the block. <span class="math">\\alpha</span> is a small integer coprime with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-1<span class="math"> and </span>N<span class="math"> is the number of rounds of the compression function and </span>c_{i}<span class="math"> is the round constant of the round </span>i$. The compression function uses the Miyaguchi-Preneel construction.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">MiMCCompression (\\sigma_0,b)</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\sigma \\gets \\sigma_0</span></li>

      <li>for round  <span class="math">i &amp;lt; N</span></li>

      <li><span class="math">\\sigma \\gets (\\sigma + b + c_i)^\\alpha</span></li>

      <li>end for</li>

      <li><span class="math">\\sigma \\gets 2\\sigma_0 + b</span></li>

    </ol>

    <p class="text-gray-300">Fig. 18. MiMC compression function with the Miyaguchi-Preneel construction</p>

    <p class="text-gray-300">The sub-protocol we present Fig. 20 in the following justifies a statement of the form  <span class="math">S_{1} = \\mathsf{MiMCCompression}(S_{0},B)</span>  where  <span class="math">S_{1},S_{0}</span>  and  <span class="math">B</span>  are columns of the same size and the statement is to be understood as "row-by-row". The protocol works by creating intermediate columns for each round of the protocol and global constraints justifying the correctness of their assignment so that the overall degree of all the constraints stays reasonably low. To illustrate, we highlight the protocol using the scalar field of BLS-12-377 in our settings. In this context,  <span class="math">\\alpha = 17</span>  and  <span class="math">N = 62</span>  and the protocol declares two columns  <span class="math">(A_{i},B_{i})</span>  for each round  <span class="math">i</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">S\\gets S_0</span></li>

      <li>for round  <span class="math">i &amp;lt; N - 1</span></li>

      <li>The prover commits to and constraints (using global constraints)  <span class="math">(A_{i},B_{i})</span>  such that</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">A _ {i} = (S + c _ {i} + b) ^ {4}</span></div>

    <div class="my-4 text-center"><span class="math-block">B _ {i} = (S + c _ {i} + b) A _ {i} ^ {4}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">S\\gets B_{i}</span></li>

      <li>end for</li>

      <li>The prover commits to  <span class="math">A_{f}</span>  such that:</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">A _ {f} = (S + c _ {i} + b) ^ {4}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>"Global constraint":</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">S _ {1} = (S + c _ {i} + b) A _ {i} ^ {4} + 2 S _ {0} + B</span></div>

    <p class="text-gray-300">Fig. 19. Wizard sub-protocol for the MiMC compression function</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">This section presents a sub-protocol to justify the correctness of hashing  <span class="math">n</span>  small vectors of the same size  <span class="math">l</span> . Here, we assume  <span class="math">l</span>  and  <span class="math">n</span>  to be powers of two. The statement involves two columns  <span class="math">L</span>  and  <span class="math">H</span>  such that  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= l</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">H</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  and asserts that  </span>H<span class="math">  is constructed from  </span>L$  as follows:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">LinearHashing (L,H)</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>for  <span class="math">i\\in [n]</span></li>

      <li><span class="math">\\sigma \\gets 0</span></li>

      <li>for  <span class="math">j\\in [l]</span></li>

      <li><span class="math">\\sigma \\gets \\mathsf{MiMCCompress}(\\sigma ,L_{il + j})</span></li>

      <li>end for</li>

      <li><span class="math">H_{i}\\stackrel {\\mathrm{def}}{=}\\sigma</span></li>

      <li>end for</li>

    </ol>

    <p class="text-gray-300">Fig. 20. Linear hashing statement</p>

    <p class="text-gray-300">The sub-protocol works in two steps, the first steps operates on  <span class="math">L</span>  to justify the construction of a column  <span class="math">S</span>  storing the intermediate steps of the compression function and the second steps uses the sub-sampling protocol to checks that the final values of the hashes are the right ones. Thus, here we detail only the first part. The prover commits to two extra columns:  <span class="math">O_{\\sigma}</span>  and  <span class="math">N_{\\sigma}</span>  storing respectively, the old state and the new state of the permutation function. Then, the prover and the verifier engage in the MiMC block compression sub-protocol to ensure that  <span class="math">O_{\\sigma}</span>  and  <span class="math">N_{\\sigma}</span>  are consistent at every row and add an extra global constraint to ensure that the compression function calls are in sequence and that the state is reset at every new hash. Here,  <span class="math">I_r</span>  is a periodic sampling column</p>

    <div class="my-4 text-center"><span class="math-block">O _ {\\sigma} = I _ {r} \\left(N _ {\\sigma} \\ll - 1\\right)</span></div>

    <p class="text-gray-300">When the hashes don't all have the same size, it is possible to extend the above technique by replacing  <span class="math">I_r</span>  either by a column provided by the prover whose construction correctness should be enforced externally or using a precomputed column. This allows handling the cases where  <span class="math">n</span>  and  <span class="math">l</span>  are not known in advance also.</p>

    <h2 id="sec-103" class="text-2xl font-bold">A.8 Merkle-tree membership</h2>

    <p class="text-gray-300">This section outlines our techniques to verify binary Merkle-trees, detailing the structure and constraints involved in the verification process. The technique has also two steps: (1) creating a module responsible for computing the Merkle proofs and (2) linking the assignment of the computation module into a "result" module which contains the statement. The second step is made using a subsampling argument between these two modules.</p>

    <h3 id="sec-104" class="text-xl font-semibold mt-8">A.8.1 The result module</h3>

    <p class="text-gray-300">The result module contains the following columns totalling the statement of the protocol:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Leaf: storing the leaves whose membership is proved</li>

      <li>Position: storing the position of the leaves in the tree</li>

      <li>Root: storing the root of each tree, allegedly storing the corresponding leaf at the corresponding position</li>

      <li>IsActive: stores boolean flags indicating whether the current row of the module actually requires a Merkle proof verification. This is used to cancel constraints in the computation module to allow padding.</li>

    </ul>

    <h3 id="sec-105" class="text-xl font-semibold mt-8">A.8.2 The computation module</h3>

    <p class="text-gray-300">The table in Figure 21 represents how we model Merkle-tree verification, where each proof uses a segment of  <span class="math">d</span>  rows. In each segment, the Merkle root is recomputed bottom-up. The zero column is implicitly not really committed to (it is a constant). This can be confusing, so we say "bottom" to mean the last row of a segment, which corresponds to the first hash of the Merkle-proof. For convenience, we use the following two expressions to construct the constraints:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">IsInactive</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">NewProof</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">IsEndOfProof</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Root</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Curr</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Proof</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">PosBit</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">PosAcc</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><em>Zero</em></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">IntermState</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Right</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">NodeHash</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">R0</td>

            <td class="px-3 py-2 border-b border-gray-700">Hd-1,0</td>

            <td class="px-3 py-2 border-b border-gray-700">πd-1,0</td>

            <td class="px-3 py-2 border-b border-gray-700">bd-1,0=0</td>

            <td class="px-3 py-2 border-b border-gray-700">pd-1,0=bd-1,0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">Hd-1,0</td>

            <td class="px-3 py-2 border-b border-gray-700">Id-1,0</td>

            <td class="px-3 py-2 border-b border-gray-700">πd-1,0</td>

            <td class="px-3 py-2 border-b border-gray-700">R0</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">R0</td>

            <td class="px-3 py-2 border-b border-gray-700">Hd-2,0</td>

            <td class="px-3 py-2 border-b border-gray-700">πd-2,0</td>

            <td class="px-3 py-2 border-b border-gray-700">bd-2,0=1</td>

            <td class="px-3 py-2 border-b border-gray-700">pd-2,0=bd-2,0+2pd-1,0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">πd-2,0</td>

            <td class="px-3 py-2 border-b border-gray-700">Id-2,0</td>

            <td class="px-3 py-2 border-b border-gray-700">Hd-2,0</td>

            <td class="px-3 py-2 border-b border-gray-700">Hd-1,0</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">R0</td>

            <td class="px-3 py-2 border-b border-gray-700">L0</td>

            <td class="px-3 py-2 border-b border-gray-700">π0,0</td>

            <td class="px-3 py-2 border-b border-gray-700">b0,0=1</td>

            <td class="px-3 py-2 border-b border-gray-700">pd-2,0=b0,0+2p1,0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">π0,0</td>

            <td class="px-3 py-2 border-b border-gray-700">I0,0</td>

            <td class="px-3 py-2 border-b border-gray-700">L0</td>

            <td class="px-3 py-2 border-b border-gray-700">H1,0</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">R1</td>

            <td class="px-3 py-2 border-b border-gray-700">Hd-1,1</td>

            <td class="px-3 py-2 border-b border-gray-700">πd-1,1</td>

            <td class="px-3 py-2 border-b border-gray-700">bd-1,1=1</td>

            <td class="px-3 py-2 border-b border-gray-700">pd-1,1=bd-1,1</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">πd-1,1</td>

            <td class="px-3 py-2 border-b border-gray-700">Id-1,1</td>

            <td class="px-3 py-2 border-b border-gray-700">Hd-1,1</td>

            <td class="px-3 py-2 border-b border-gray-700">R0</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">R1</td>

            <td class="px-3 py-2 border-b border-gray-700">Hd-2,1</td>

            <td class="px-3 py-2 border-b border-gray-700">πd-2,1</td>

            <td class="px-3 py-2 border-b border-gray-700">bd-2,1=1</td>

            <td class="px-3 py-2 border-b border-gray-700">pd-2,1=bd-2,1+2pd-1,1</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">πd-2,1</td>

            <td class="px-3 py-2 border-b border-gray-700">Id-2,1</td>

            <td class="px-3 py-2 border-b border-gray-700">Hd-2,1</td>

            <td class="px-3 py-2 border-b border-gray-700">Hd-1,1</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">R1</td>

            <td class="px-3 py-2 border-b border-gray-700">L1</td>

            <td class="px-3 py-2 border-b border-gray-700">π0,1</td>

            <td class="px-3 py-2 border-b border-gray-700">b0,1=0</td>

            <td class="px-3 py-2 border-b border-gray-700">pd-2,1=b0,1+2p1,1</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">L1</td>

            <td class="px-3 py-2 border-b border-gray-700">I0,1</td>

            <td class="px-3 py-2 border-b border-gray-700">π0,1</td>

            <td class="px-3 py-2 border-b border-gray-700">H1,1</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">Ru</td>

            <td class="px-3 py-2 border-b border-gray-700">Lu</td>

            <td class="px-3 py-2 border-b border-gray-700">π0,n</td>

            <td class="px-3 py-2 border-b border-gray-700">b0,n=0</td>

            <td class="px-3 py-2 border-b border-gray-700">pd-2,n=b0,n+2p1,n</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">Lu</td>

            <td class="px-3 py-2 border-b border-gray-700">I0,n</td>

            <td class="px-3 py-2 border-b border-gray-700">π0,n</td>

            <td class="px-3 py-2 border-b border-gray-700">Hn,n</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">Idead</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">Hdead</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

            <td class="px-3 py-2 border-b border-gray-700">...</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">Idead</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">Hdead</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Fig. 21. Modeling Merkle-tree verification. Each proof uses a segment of  <span class="math">d</span>  rows.</p>

    <p class="text-gray-300">NotNewProof  <span class="math">= 1</span>  -NewProof</p>

    <p class="text-gray-300">IsActive  <span class="math">= 1</span>  -IsInactive</p>

    <p class="text-gray-300">NotEndOfProof  <span class="math">= 1</span>  -EndOfProof</p>

    <p class="text-gray-300">These are not materialized by columns but are used as subexpressions in the constraints for clarity. We now move on to list all the constraints that are enforced by the module:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Constance of Root over a segment Root is constant within a segment and it must be inactive when the "IsInactive" flag is set.</li>

    </ol>

    <p class="text-gray-300">"Global constraint":</p>

    <div class="my-4 text-center"><span class="math-block">\\left(\\operatorname {R o o t} [ i ] - \\operatorname {I s A c t i v e} [ i ] \\operatorname {R o o t} [ i + 1 ]\\right) \\operatorname {N o t N e w P r o o f} [ i ] = = 0</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Consistency of Root and Nodehash: At the end of each segment, the root must be equal to NodeHash.</li>

    </ol>

    <p class="text-gray-300">"Global constraint":</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname {E n d O f P r o o f} [ i ] (\\operatorname {R o o t} [ i ] - \\operatorname {N o d e H a s h} [ i ]) = = 0</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Booleanity of PosBit: This enforces PosBit to be boolean and zero if the inactive flag is set.</li>

    </ol>

    <p class="text-gray-300">"Global constraint":</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname {P o s B i t} [ i ] = \\operatorname {I s A c t i v e} [ i ] \\operatorname {P o s B i t} [ i ] ^ {2}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>PosAcc packs PosBit in an integer: this is aimed at reconstructing the leaf's position in the tree from its binary representation PosBit. PosAcc progressively computes the position of the opened leaf from the bits. It must be zero when the inactive flag is set.</li>

    </ol>

    <p class="text-gray-300">"Global constraint":</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname {P o s A c c} [ i ] = \\operatorname {I s A c t i v e} [ i ] (\\operatorname {P o s B i t} [ i ] + 2 \\operatorname {N o t E n d O f P r o o f} [ i ] \\operatorname {P o s A c c} [ i + 1 ])</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Left and Right assignment: the flag PosBit decides which one of Proof or Curr is mapped to Left or Right.</li>

    </ol>

    <p class="text-gray-300">"Global constraints":</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname {L e f t} [ i ] = \\operatorname {P o s B i t} [ i ] \\operatorname {P r o o f} [ i ] - (1 - \\operatorname {P o s B i t} [ i ]) \\operatorname {C u r r} [ i ]</span></div>

    <div class="my-4 text-center"><span class="math-block">\\operatorname {R i g h t} [ i ] = \\operatorname {P o s B i t} [ i ] \\operatorname {C u r r} [ i ] - (1 - \\operatorname {P o s B i t} [ i ]) \\operatorname {P r o o f} [ i ]</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Within a chunk, use the previous node hash as current node: when the inactive flag is set, this also enforces that Curr is zero.</li>

    </ol>

    <p class="text-gray-300">“Global Constraint”:</p>

    <p class="text-gray-300"><span class="math">\\text{NotNewProof}<a href="\\text{Curr}[i]-\\text{IsActive}[i]\\text{NodeHash}[i+1]">i</a></span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Correctness of the MiMC computations: this is done by using the MiMC compression function subprotocol:</li>

    </ol>

    <p class="text-gray-300"><span class="math">\\text{MiMC}(\\text{Zero},\\text{Left},\\text{Interm})</span></p>

    <p class="text-gray-300"><span class="math">\\text{MiMC}(\\text{Interm},\\text{Right},\\text{NodeHash})</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Zero padding of the proof: this enforces that the proof is padded wherever the inactive flag is set: “Global constraint”:</li>

    </ol>

    <p class="text-gray-300"><span class="math">\\text{Proof}[i]=\\text{IsActive}[i]\\text{Proof}[i]</span></p>

    <h2 id="sec-106" class="text-2xl font-bold">Appendix B Selecting ring-SIS instances</h2>

    <p class="text-gray-300">In Section 7.1, we specify a generalized version of the SWIFFT hash function. In the current section, we provide an overview of the existing attacks and their costs. As for SWIFFT, our hash function is directly an instantiation of ring-SIS. The hash function, or rather, the family of hash functions we analyze hashes into prime fields and support several norm bounds instead of <span class="math">\\{0,1\\}</span> for Ajtai <em>[2]</em> and SWIFFT <em>[39]</em>. The instances that we analyze span over a large range of parameters, and this requires evaluating both lattice reduction attacks and combinatorial attacks. Finally, the scope of this work is restricted to the classical setting.</p>

    <h3 id="sec-107" class="text-xl font-semibold mt-8">B.1 The Short-Integer-Solution and Its “Ring” Variant</h3>

    <p class="text-gray-300">Let <span class="math">m&gt;n</span> be integers, <span class="math">q</span> a prime and <span class="math">b&lt;q</span>.</p>

    <h6 id="sec-108" class="text-base font-medium mt-4">Definition 13 (Short-Integer-Solution Problem (SIS)).</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Given random <span class="math">A\\in\\mathbb{Z}_{q}^{n\\times m}</span>, find <span class="math">x</span> such that $Ax=0_{n}\\wedge\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{\\infty}<b$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-109" class="text-base font-medium mt-4">Definition 14 (Inhomogeneous-SIS (ISIS)).</h6>

    <p class="text-gray-300">Given random <span class="math">A\\in\\mathbb{Z}_{q}^{n\\times m}</span> and <span class="math">t\\in\\mathbb{Z}_{q}^{n}</span>, find <span class="math">x</span> such that <span class="math">Ax=t</span></p>

    <p class="text-gray-300">We start with a few observations on SIS:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>SIS (and ISIS) cannot become harder by increasing <span class="math">m</span>. That is because an attacker can always restrict the search space to <span class="math">m^{\\prime}&lt;m</span> by arbitrarily forcing some entries of <span class="math">x</span> to zero.</li>

      <li>The problem only becomes harder as we increase <span class="math">n</span>, this corresponds to adding more constraints on what can be a valid <span class="math">x</span>.</li>

      <li>It can only become harder as we restrict to smaller <span class="math">b</span>. That is because it is equivalent to restricting the search space.</li>

      <li><span class="math">b\\geq q</span> makes the problem trivial, as it can be solved by Gaussian elimination in polynomial-time.</li>

    </ul>

    <h6 id="sec-110" class="text-base font-medium mt-4">Remark 1.</h6>

    <p class="text-gray-300">The work of <em>[26]</em> uncovered an efficient procedure for solving <span class="math">\\gamma</span>-ideal-SVP in polynomial time, a problem closely related to ring-SIS. We argue that they do not apply to the scope of our analysis. Indeed,</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>They are in the quantum setting</li>

      <li>The approximation factor they apply the attack on is exponential. This is not what we typically use for cryptographic applications</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Ring-SIS is not exactly an ideal lattice problem (it is therefore not currently known if an efficient reduction from ring-SIS to Ideal-SVP actually exists).</li>

    </ul>

    <p class="text-gray-300">Now we define the ring version of the SIS problem.</p>

    <h6 id="sec-111" class="text-base font-medium mt-4">Definition 15 (The Ring-(Inhomogeneous)SIS Problem).</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Given <span class="math">A\\in\\mathcal{R}^{m}</span> drawn randomly, following the uniform distribution (for its coefficients) and <span class="math">b&lt;q</span>, the ring-ISIS problem is to find <span class="math">x\\in\\mathcal{R}^{m}</span>, non-zero, such that $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{\\infty}<b\\wedge Ax=0_{\\mathcal{R}}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The ring-(I)SIS assumptions can be seen as special cases of SIS where <span class="math">A</span> is drawn from a restricted set of matrices representing the polynomial multiplication module <span class="math">X^{n}+1</span>. One should note that <span class="math">m</span> means different things in our definitions of SIS and ring-SIS. For clarity “<span class="math">m_{\\text{SIS}}=nm_{\\text{RSIS}}</span>”. Working with ring-SIS has several practical benefits compared to SIS: the space taken to represent <span class="math">A</span> is <span class="math">n</span> times smaller, and the product <span class="math">Ax</span> can be computed much faster using FFT algorithms in <span class="math">nm\\log n</span> instead of <span class="math">mn^{2}</span>.</p>

    <h3 id="sec-112" class="text-xl font-semibold mt-8">B.2 Security properties</h3>

    <p class="text-gray-300">We require our hash function (as specified in Section 7.1 to have preimage resistance and collision resistance.</p>

    <h6 id="sec-113" class="text-base font-medium mt-4">Definition 16 (Preimage Resistance).</h6>

    <p class="text-gray-300">Given <span class="math">y</span>, find <span class="math">x</span> such that <span class="math">\\mathsf{H}(x)=y</span></p>

    <p class="text-gray-300">The definition of preimage resistance coincides with the InhomogenousSIS problem. We attack it by solving SIS <span class="math">(y,A)\\cdot(1,x)=0</span>. This is equivalently as hard as solving SIS with input size <span class="math">m</span>.</p>

    <h6 id="sec-114" class="text-base font-medium mt-4">Definition 17 (Collision Resistance).</h6>

    <p class="text-gray-300">Find <span class="math">x,x^{\\prime}</span> such that <span class="math">\\mathsf{H}(x)=\\mathsf{H}(x^{\\prime})</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">An attack against collision-resistance is obtained by breaking SIS for the matrix $(A\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-A)<span class="math">, under the constraint that a solution </span>s=(s_{1}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">s_{2})^{T}<span class="math"> satisfies </span>s_{1}\\neq s_{2}<span class="math">. This is equivalent to multiplying </span>m<span class="math"> by </span>2$. From that, we can deduce the fact that collisions are easier to find than preimages. Thus, in the following, we will restrict our attention to attacks for finding collisions.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-115" class="text-xl font-semibold mt-8">B.3 Overview of the cryptanalysis report</h3>

    <p class="text-gray-300">To estimate the hardness of ring-SIS instances, we consider two classes of attacks: combinatorial and lattice reductions. In practice, no attack is known to work significantly better on ring-SIS rather than an equivalent SIS instance. Additionally, in practice, the security of our hash function is bottlenecked by attacks on collision resistance. Thus, we will only consider the <em>equivalent</em> (not-ring)-SIS instance with parameters <span class="math">q,n,m^{\\prime}=nm,b</span>.</p>

    <h3 id="sec-116" class="text-xl font-semibold mt-8">B.4 Lattice Reduction Techniques (BKZ2.0)</h3>

    <p class="text-gray-300">Foremost, we note that solving an SIS instance is the same as finding a short vector in the kernel lattice.</p>

    <p class="text-gray-300"><span class="math">\\mathcal{L}=\\varLambda^{\\perp}(A)=\\{z\\in\\mathbb{Z}_{q}^{m^{\\prime}}:Az=0\\}</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We are always free to pick <span class="math">m_{0}&lt;m^{\\prime}-n</span> if that is convenient. The best-known algorithm to do so is BKZ2.0, a generalization of the seminal LLL algorithm. This algorithm works by repeatedly calling an SVP oracle which optimally reduces lattices to smaller dimension <span class="math">k&lt;m_{0}</span>. The BKZ algorithm will output, with overwhelming probability, a vector of size $b_{2}=\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">v\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{2}=\\delta^{m_{0}}\\mathsf{vol}(\\mathcal{L})^{1/m_{0}}$ and thus we need to set,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">b_{2}=\\delta^{m_{0}}q^{n/m_{0}}\\wedge b\\sqrt{m_{0}}&lt;q</span> (4)</p>

    <p class="text-gray-300">The second term comes from the fact that if <span class="math">m_{0}</span> is too big, then the smallest L2-ball containing the <span class="math">L_{\\infty}</span> ball of SIS candidate contains the whole space. This does not necessarily mean the instance is broken, but it</p>

    <p class="text-gray-300">means our estimations are irrelevant. Therefore, we will reject those cases. We recall that for random lattices, kernels <span class="math">\\mathsf{vol}(\\mathcal{L})=q^{n}</span> with overwhelming probability.</p>

    <p class="text-gray-300">Since the efficiency of BKZ has been widely studied in the <span class="math">L_{2}</span> norm settings but not in the <span class="math">L_{\\infty}</span> setting, we need a strategy to convert the <span class="math">L_{\\infty}</span> instances into equivalent ones over <span class="math">L_{2}</span>. Let <span class="math">\\mathcal{B}_{2}(r)</span> and <span class="math">\\mathcal{B}_{\\infty}(r)</span> denotes respectively the <span class="math">L_{2}</span> and <span class="math">L_{\\infty}</span> balls of radius <span class="math">r</span> centered at the origin. Then, from the Minkowski bound we have that</p>

    <p class="text-gray-300"><span class="math">\\mathcal{B}_{2}(r)\\subset\\mathcal{B}_{\\infty}(r)\\subset\\mathcal{B}_{2}(\\sqrt{m_{0}}r)</span></p>

    <p class="text-gray-300">To derive a cost estimate for BZK in the <span class="math">L_{\\infty}</span> setting, we try values of <span class="math">b_{2}</span> in the range <span class="math">[\\frac{b}{2};\\sqrt{m_{0}}\\frac{b}{2}]</span> estimate their security as we will explain the following of the section, and then account for a probability that the short <span class="math">L_{2}</span> is small enough in the <span class="math">L_{\\infty}</span> norm to be a solution of the target SIS instance. We retain the estimate of the value of <span class="math">b_{2}</span> that minimizes <span class="math">\\frac{C}{P}</span> where <span class="math">C</span> is the runtime of BKZ and <span class="math">P</span> is the success probability. We estimate <span class="math">P</span> by modelling the vector output by BKZ as being normally distributed (each coordinates independently) with a standard deviation of <span class="math">\\frac{b_{2}}{\\sqrt{m_{0}}}</span> as suggested in <em>[27]</em>.</p>

    <p class="text-gray-300">Here, we have two free parameters: <span class="math">m_{0}</span> and <span class="math">\\delta</span>. <span class="math">\\delta</span> is what we call the root Hermite factor. It can be interpreted as the “output quality” that we can expect from BKZ. For the most part, it depends on the BKZ block size <span class="math">k</span> (and also a little on <span class="math">m_{0}</span>).</p>

    <p class="text-gray-300">A comprehensive choice of the oracle, along with a model for their runtime can be found in the work of <em>[4]</em>. All oracles and models come with different tradeoffs. The most efficient ones (in runtime) are sieve ones, while enumeration ones require smaller space. Finally, based on the work of <em>[46]</em>, we take that LD Sieve is the fastest sieve algorithm. This gives us the following heuristic runtime formula (in CPU cycles) for a single call to the SVP oracle.</p>

    <p class="text-gray-300"><span class="math">\\log t_{\\mathsf{oracle}}=0.292k+16.4</span> (5)</p>

    <p class="text-gray-300"><em>[3]</em> gives the following cost estimates of the overall runtime of BKZ2 (number of calls to the oracle) and an estimation of the root-Hermite factor achieved by BKZ.</p>

    <p class="text-gray-300"><span class="math">\\rho=\\frac{{m_{0}}^{3}}{k^{2}}\\log m_{0}</span> <span class="math">\\log_{2}\\delta=\\frac{1}{2(k-1)}\\left(\\log_{2}(\\frac{k}{2\\pi e})+\\frac{\\log_{2}\\pi k}{k}\\right)</span> (6)</p>

    <p class="text-gray-300">One should note that Eq. (6) is only asymptotically correct and it returns imprecise results. For this reason, our analysis rules out small values of <span class="math">k</span> by setting a lower bound on the examined values. In practice, this is not a problem because the arbitrary lower bound that we set does not correspond to instances that are not hard enough for cryptographic purposes.</p>

    <h3 id="sec-117" class="text-xl font-semibold mt-8">B.5 Direct SVP attacks</h3>

    <p class="text-gray-300">Although BKZ has been shown to achieve superior results than direct SVP attacks we also consider the latter. We consider two attacks, one using the sieving algorithm over the <span class="math">L_{2}</span> norm (as in the BKZ case), accounting for success probability. And another one derived from the work of <em>[42]</em> directly targeting <span class="math">L_{\\infty}</span> SIS.</p>

    <h3 id="sec-118" class="text-xl font-semibold mt-8">B.6 Combinatorial Attack</h3>

    <p class="text-gray-300">In addition to lattice reduction techniques, an important class of attacks for SIS and ISIS stems from the field of attacks against the subset-sum problem.</p>

    <h4 id="sec-119" class="text-lg font-semibold mt-6">B.6.1</h4>

    <p class="text-gray-300">Camion-Patarin and Wagner attacks The course <em>[41]</em> describes the basic version of these attacks and gives an easy procedure to determine their efficiency. The attack is also known as CPW. In <em>[8]</em>, the authors present several improved methods over the former method, and they achieve a 10-bit reduction on SWIFFT. Those improvements have been obtained by generalizing the initial attack for which they used careful manual tuning of its parameters.</p>

    <p class="text-gray-300">As in <em>[8]</em> suggests, once we have found the optimal list-tree depth <span class="math">k</span>, we can reduce the value of <span class="math">m</span> to the smallest value that verifies</p>

    <p class="text-gray-300"><span class="math">\\frac{2^{k}}{k+1}&lt;\\frac{m\\log(b)}{n\\log q}</span></p>

    <p class="text-gray-300">We remind the reader that we are looking for collisions in the input space <span class="math">x\\in[0;b]^{m}</span> which differs from <span class="math">\\left\\lVert x\\right\\rVert_{\\infty}&lt;b</span>. This explains why our formula uses <span class="math">b</span> in place of <span class="math">2b-1</span> as it can be sometimes found in the literature. The above attack can, in fact, be generalized to a setting where the output space is split in <span class="math">k</span> chunks of size <span class="math">l_{1},l_{2},\\ldots,l_{k}</span> such that <span class="math">\\sum_{i}l_{i}=n</span>. By tweaking the size of each <span class="math">l_{i}</span> we can optimize the attack.</p>

    <p class="text-gray-300">Methodology We will consider two cases:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>If <span class="math">\\mathbf{n}\\leq\\mathbf{50}</span>, we exhaustively try every possible combination of <span class="math">l_{i}</span> such that <span class="math">\\sum_{i}l_{i}=n</span> for <span class="math">k&lt;\\log_{2}m</span>. And we simulate the attack by counting all operations. To reduce the cost of the exhaustive search, we restrict the search space to <span class="math">l_{i}\\leq l_{i+1}</span>.</li>

      <li>If <span class="math">\\mathbf{n}&gt;\\mathbf{50}</span>, then we apply the simplified analysis given in <em>[41]</em>. From <em>[41]</em>, the cost this will give us is an overly pessimistic result, but in practice, these SIS instances are better attacked using lattice reduction techniques. Thus, this fact is without consequence on our estimations.</li>

    </ul>

    <p class="text-gray-300">In our estimation, for values of <span class="math">n</span> (i.e., the dimension of the output space), we considered a refinement of the technique to account for the fact that different tunings are possible (splitting the output space in “non-equals” chunks). We exhaustively search the best set of parameters when <span class="math">n&lt;50</span>. Otherwise, the exhaustive search of parameters is too computationally heavy, and we fall back to the method of <em>[41]</em>. This is without consequence for our estimations. Indeed, in practice, for our choices of <span class="math">q</span>, we observe that SIS instances with <span class="math">n&lt;50</span> are typically bottlenecked by the BKZ attack—for our choices of <span class="math">q</span>—in practice.</p>

    <p class="text-gray-300">To estimate the cost of the attack:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In the basic case, we use the formula</li>

      <li>In the exhaustive case, we simply count all operations. We assume the running time of merging two lists is linear in the size of the resulting merged list. We consider that the running time of creating the initial leaves lists is roughly equal to enumerating all possibilities.</li>

    </ul>

    <h4 id="sec-120" class="text-lg font-semibold mt-6">B.6.2</h4>

    <p class="text-gray-300">On the HGJ and BCJ refinements Howgrave-Graham and Joux introduced these techniques in 2010, <em>[35]</em>. This class of attacks is somewhat similar to CPW, in the sense that it relies on recursively splitting the initial problem and merging the partial solutions. As an outline, the difference there is that it relies on splitting the problem in “weight” rather than in space.</p>

    <p class="text-gray-300">These techniques have proven to be more effective when the problem has a low-density of solutions, while CPW is more effective for higher-density instances. In our case, we seek to pick instances of SIS which maximize the “compression ratio” and hence the density. Typically, our instances have densities that are above the range of effectiveness of these attacks. Thus, we do not consider them in this work.</p>

    <h4 id="sec-121" class="text-lg font-semibold mt-6">B.6.3</h4>

    <p class="text-gray-300">On Optimizations for Ring-SIS In <em>[8]</em>, the authors present a technique to reduce the cost of the attack when the set of <em>acceptable</em> input polynomials is preserved by multiplication by the transformation <span class="math">\\psi:s(X)\\rightarrow Xs(X)</span>. This is the case when either the ring modulus is <span class="math">X^{n}-1</span> or the input space has sign symmetry (meaning <span class="math">\\mathcal{B}=-\\mathcal{B}</span>) and the modulus is <span class="math">X^{n}+1</span>. We stress that neither is our case, and we recall that we use the modulus <span class="math">X^{n}+1</span> with <span class="math">\\mathcal{B}=[0;b]</span>. It is however possible to reduce to a case where this technique</p>

    <p class="text-gray-300">is applicable nonetheless. Let <span class="math">\\mathbf{1}_{m}=(1,1,1,\\ldots),</span>, instead of directly trying to find <span class="math">s</span> such that <span class="math">As=0</span> we seek <span class="math">s^{\\prime}\\in\\mathcal{B}^{\\prime}=^{\\prime}\\mathcal{B}-\\frac{b-1}{2}</span> such that <span class="math">A(s^{\\prime}+\\frac{b-1}{2}(1,1,1,\\cdots))=0</span>. If <span class="math">b</span> is even (our case), then the solution space for <span class="math">s^{\\prime}</span> has sign symmetry. We note that although <span class="math">\\mathcal{B}^{\\prime}</span> is not a set of short integers, this does not affect the runtime of CPW. We do not expand on the technical details of the techniques. At a high-level, these techniques decrease the size of each list by a factor of <span class="math">2n</span>, where <span class="math">n</span> is the degree of the ring-modulus. Thus, it achieves a speed-up of <span class="math">2n</span>.</p>

    <p class="text-gray-300">However, as the work of <em>[8]</em> points out, this optimization is incompatible with the following one, based on the Hermite Normal Form (HNF).</p>

    <h4 id="sec-122" class="text-lg font-semibold mt-6">B.6.4 Optimization using the Hermite Normal Form (HNF)</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The Hermite Normal Form of a matrix is an equivalent representation of the (I)-SIS problem. If $A=(A_{0}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A_{1}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\ldots\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A_{n-1})<span class="math"> is the SIS matrix, then we call </span>H=(I\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A_{0}^{-1}A_{1}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A_{0}^{-1}A_{1}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\cdots)=(I\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A^{\\prime})$ its normal form. The (I)SIS can then be equivalently rephrased as, what we call, the <em>approximate</em> (I)SIS problem.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-123" class="text-base font-medium mt-4">Definition 18 (Approximate (I)SIS problem).</h6>

    <p class="text-gray-300">Find <span class="math">s,e\\in\\mathcal{B}</span>, such that <span class="math">Ax+e=R</span>, where <span class="math">R=0</span> in the homogeneous case.</p>

    <p class="text-gray-300">Based on this, we can adapt the CPW algorithm to turn it into an attack for the approximate (I)SIS problem. <em>[8]</em> expands on the details of the algorithm.</p>

    <h5 id="sec-124" class="text-base font-semibold mt-4">Some notes on the costs estimates</h5>

    <p class="text-gray-300">We note that both estimates are missing some hidden costs,</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The attacks we consider are typically as memory intensive as they cost in terms of computation.</li>

      <li>We do not account for the evaluation costs of each partial candidate solution. This would in practice add a few bits of security.</li>

      <li>The storage of each candidate is not “1”. On top of impacting the memory complexity (which we chose not to account for anyway), it has an impact on the costs of the memory accesses as well.</li>

    </ul>

    <p class="text-gray-300">For these reasons, we believe the costs are somewhat over-pessimistic. Nonetheless, we prefer to go with the initial approach and leave it as a future task to evaluate the concrete cost in CPU cycles of these attacks.</p>

    <h3 id="sec-125" class="text-xl font-semibold mt-8">B.7 Concrete parameters</h3>

    <p class="text-gray-300">Based on the above analysis, we have run a parameter selection. The table in Fig. 22 gives a set of parameters for the ring-SIS instance. Here, <span class="math">q</span> denotes the order of the underlying prime field, <span class="math">b</span> is the bound of the SIS instance, and <span class="math">n</span> is the degree of the ring modulus <span class="math">X^{n}+1</span>. For the instance, B1 the non-ring version of SIS is considered. The reason the attack costs are higher than the claimed security level has two explanations. First, we are willing to take conservative parameters for our SIS instances as our work is, to the best of our knowledge, the first to take SIS-based hash function in production. The second reason is that we revisited are our BKZ estimator and found that the our estimation <span class="math">\\delta=f(k,m_{0})</span> was returning values that were lower than what was used in <em>[4]</em> and thus giving very pessimistic results. The results we present Fig. 22 that we present are consistent with their estimates. We will reconsider these parameters in the future. We stress that the <span class="math">q</span> we are using are prime numbers</p>

    <h2 id="sec-126" class="text-2xl font-bold">Appendix C Linea’s state representation</h2>

    <p class="text-gray-300">This section briefly articulates how the state of Linea is Merkle-ized. The solution differs from the Keccak-based Patricia Merkle-Tree that Ethereum uses. The motivations are multiple: our use cases require a more prover-efficient solution as using Ethereum’s solution would necessitate in the 10000’s of Keccak per transaction block and this would dominate the prover costs. The second point is that a PMT-based solution involves more control flow logic making it more complex to arithmetize in practice.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">n</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">SVP (L2)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">SVP (L∞)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">BKZ attack</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">CPW attack</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">A1</td>

            <td class="px-3 py-2 border-b border-gray-700">≈ 264</td>

            <td class="px-3 py-2 border-b border-gray-700">22</td>

            <td class="px-3 py-2 border-b border-gray-700">32</td>

            <td class="px-3 py-2 border-b border-gray-700">315.41</td>

            <td class="px-3 py-2 border-b border-gray-700">634.88</td>

            <td class="px-3 py-2 border-b border-gray-700">371.53</td>

            <td class="px-3 py-2 border-b border-gray-700">144.0</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">A2</td>

            <td class="px-3 py-2 border-b border-gray-700">≈ 264</td>

            <td class="px-3 py-2 border-b border-gray-700">24</td>

            <td class="px-3 py-2 border-b border-gray-700">64</td>

            <td class="px-3 py-2 border-b border-gray-700">315.41</td>

            <td class="px-3 py-2 border-b border-gray-700">634.88</td>

            <td class="px-3 py-2 border-b border-gray-700">358.29</td>

            <td class="px-3 py-2 border-b border-gray-700">305.57</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">A3</td>

            <td class="px-3 py-2 border-b border-gray-700">≈ 264</td>

            <td class="px-3 py-2 border-b border-gray-700">26</td>

            <td class="px-3 py-2 border-b border-gray-700">128</td>

            <td class="px-3 py-2 border-b border-gray-700">415.27</td>

            <td class="px-3 py-2 border-b border-gray-700">872.96</td>

            <td class="px-3 py-2 border-b border-gray-700">415.0</td>

            <td class="px-3 py-2 border-b border-gray-700">598.14</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">A4</td>

            <td class="px-3 py-2 border-b border-gray-700">≈ 264</td>

            <td class="px-3 py-2 border-b border-gray-700">210</td>

            <td class="px-3 py-2 border-b border-gray-700">256</td>

            <td class="px-3 py-2 border-b border-gray-700">494.99</td>

            <td class="px-3 py-2 border-b border-gray-700">1111.04</td>

            <td class="px-3 py-2 border-b border-gray-700">380.99</td>

            <td class="px-3 py-2 border-b border-gray-700">1272.31</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">A5</td>

            <td class="px-3 py-2 border-b border-gray-700">≈ 264</td>

            <td class="px-3 py-2 border-b border-gray-700">216</td>

            <td class="px-3 py-2 border-b border-gray-700">512</td>

            <td class="px-3 py-2 border-b border-gray-700">614.42</td>

            <td class="px-3 py-2 border-b border-gray-700">1269.76</td>

            <td class="px-3 py-2 border-b border-gray-700">344.85</td>

            <td class="px-3 py-2 border-b border-gray-700">2741.67</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">A6</td>

            <td class="px-3 py-2 border-b border-gray-700">≈ 264</td>

            <td class="px-3 py-2 border-b border-gray-700">222</td>

            <td class="px-3 py-2 border-b border-gray-700">1024</td>

            <td class="px-3 py-2 border-b border-gray-700">886.27</td>

            <td class="px-3 py-2 border-b border-gray-700">1904.64</td>

            <td class="px-3 py-2 border-b border-gray-700">401.92</td>

            <td class="px-3 py-2 border-b border-gray-700">5967.82</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">B1</td>

            <td class="px-3 py-2 border-b border-gray-700">≈ 2254</td>

            <td class="px-3 py-2 border-b border-gray-700">22</td>

            <td class="px-3 py-2 border-b border-gray-700">7</td>

            <td class="px-3 py-2 border-b border-gray-700">275.99</td>

            <td class="px-3 py-2 border-b border-gray-700">551.18</td>

            <td class="px-3 py-2 border-b border-gray-700">324.59</td>

            <td class="px-3 py-2 border-b border-gray-700">259.03</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">B2</td>

            <td class="px-3 py-2 border-b border-gray-700">≈ 2254</td>

            <td class="px-3 py-2 border-b border-gray-700">24</td>

            <td class="px-3 py-2 border-b border-gray-700">16</td>

            <td class="px-3 py-2 border-b border-gray-700">313.07</td>

            <td class="px-3 py-2 border-b border-gray-700">634.88</td>

            <td class="px-3 py-2 border-b border-gray-700">355.56</td>

            <td class="px-3 py-2 border-b border-gray-700">270.0</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">B3</td>

            <td class="px-3 py-2 border-b border-gray-700">≈ 2254</td>

            <td class="px-3 py-2 border-b border-gray-700">26</td>

            <td class="px-3 py-2 border-b border-gray-700">32</td>

            <td class="px-3 py-2 border-b border-gray-700">412.06</td>

            <td class="px-3 py-2 border-b border-gray-700">853.12</td>

            <td class="px-3 py-2 border-b border-gray-700">411.68</td>

            <td class="px-3 py-2 border-b border-gray-700">637.0</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">B4</td>

            <td class="px-3 py-2 border-b border-gray-700">≈ 2254</td>

            <td class="px-3 py-2 border-b border-gray-700">210</td>

            <td class="px-3 py-2 border-b border-gray-700">64</td>

            <td class="px-3 py-2 border-b border-gray-700">491.19</td>

            <td class="px-3 py-2 border-b border-gray-700">1031.68</td>

            <td class="px-3 py-2 border-b border-gray-700">377.78</td>

            <td class="px-3 py-2 border-b border-gray-700">1262.46</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">B5</td>

            <td class="px-3 py-2 border-b border-gray-700">≈ 2254</td>

            <td class="px-3 py-2 border-b border-gray-700">216</td>

            <td class="px-3 py-2 border-b border-gray-700">128</td>

            <td class="px-3 py-2 border-b border-gray-700">609.74</td>

            <td class="px-3 py-2 border-b border-gray-700">1269.76</td>

            <td class="px-3 py-2 border-b border-gray-700">341.83</td>

            <td class="px-3 py-2 border-b border-gray-700">2720.33</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">B6</td>

            <td class="px-3 py-2 border-b border-gray-700">≈ 2254</td>

            <td class="px-3 py-2 border-b border-gray-700">224</td>

            <td class="px-3 py-2 border-b border-gray-700">256</td>

            <td class="px-3 py-2 border-b border-gray-700">807.72</td>

            <td class="px-3 py-2 border-b border-gray-700">1745.92</td>

            <td class="px-3 py-2 border-b border-gray-700">333.14</td>

            <td class="px-3 py-2 border-b border-gray-700">5921.27</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">B7</td>

            <td class="px-3 py-2 border-b border-gray-700">≈ 2254</td>

            <td class="px-3 py-2 border-b border-gray-700">232</td>

            <td class="px-3 py-2 border-b border-gray-700">512</td>

            <td class="px-3 py-2 border-b border-gray-700">1203.09</td>

            <td class="px-3 py-2 border-b border-gray-700">2539.52</td>

            <td class="px-3 py-2 border-b border-gray-700">405.68</td>

            <td class="px-3 py-2 border-b border-gray-700">13013.8</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Fig. 22. Lattice parameters targeting 128 bits of security</p>

    <p class="text-gray-300">Our solution employs Sparse Merkle Trees (SMTs) at its foundation and uses them as a random access memory where memory words are addressed by integers. The SMT is parametrized in such a way that it minimizes the number of required levels and has 40 levels. Our approach enhances the SMT to support key-value addressing by building a structure inspired by sorted doubly linked lists at the leaf level where each leaf references its immediate neighbours in the key set. This allows us to instantiate a key-value addressed state accumulator which can be addressed either be the hash of an Ethereum address (for the world state) or by a 32-byte value for the storage of each contract.</p>

    <p class="text-gray-300">Here, we present how to derive the value (and the implicit structure) of the non-empty leaves of the sparse Merkle tree. We set the (x) leaves as the hash of the following structure:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>HKey: the hash of the key</li>

      <li>Value: the value we wish to store</li>

      <li>Prev: the position of the leaf whose associated HKey is immediately below the current node's HKey</li>

      <li>Next: the position of the leaf whose associated HKey is immediately above the current node's HKey</li>

    </ul>

    <p class="text-gray-300">We refer to this structure as the opening of a leaf. Empty leaves have (cryptographically speaking) no opening since it is infeasible to find a preimage for 0 (which we use for empty leaves in our SMT).</p>

    <p class="text-gray-300">To initialize our accumulator, we insert two utility leaves in the tree. These leaves do not contain functional data by themselves. They are only here for convenience and practicality. Insert two nodes (that we will call the "head" and the "tail" by convention). By "position", we mean the index of the sparse Merkle-tree leaves. In our construction, we set up a doubly linked list and "head" and "tail" represent nodes that are respectively always at the beginning and always at the end of the list. But they are not associated with any particular "key" in the set. That's why their  <span class="math">HKey</span>  field is not the hash of something. It also ensures that these entries' values are never accessed via the accumulator protocol.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>HKey 0 (and not Hash(0))</li>

      <li>Value 0</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Prev 0 (it points to itself as an invariant)</li>

      <li>Next 1 (points to the tail at the beginning, but this will be updated as we add entries in the set)</li>

    </ul>

    <p class="text-gray-300">At position 1 (tail):</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>HKey <span class="math">p</span>-1 where <span class="math">p</span> is the size of the BLS12-377 scalar field</li>

      <li>Value 0</li>

      <li>Prev 0 (points to the head at the beginning, but this will be updated as we add entries in the set)</li>

      <li>Next 1 (it points to itself as an invariant)</li>

    </ul>

    <h3 id="sec-130" class="text-xl font-semibold mt-8">C.3 Tracking the position of the empty leaves</h3>

    <p class="text-gray-300">Without going into the details here, the state manager picks an empty leaf to write over when we insert into an empty storage address. However, we have a requirement that the position in which we insert new leaves must be deterministic: any person who looks at the transaction history should be able to reconstitute the Merkle-tree identically (e.g., with the same leaves at the same positions).</p>

    <p class="text-gray-300">If the state manager were given wiggle room to insert into any position of the SMT, then he would be able to perform an attack where he uses a random node for insertion and never discloses it. The accumulator state update would still be correct, but it would be infeasible to reconstruct an identical SMT since the exact positions where the insertion occurs are ultimately private.</p>

    <p class="text-gray-300">Countermeasure :</p>

    <p class="text-gray-300">As a countermeasure, we introduce the following mechanism: we force the state-manager to insert to the left. Namely, the state-manager never reuses a position twice even if the corresponding node has been deleted. While it may seem wasteful to not reuse erased leaves, we will never run out of leaves to write over. Under plausible hypothesis of storage usage, we estimate it would take over hundreds of years before we run out of leaves with this solution.</p>

    <p class="text-gray-300">That being said, it should be verifiable externally without maintaining more than a root hash. For that purpose, we extend the SMT with an extra level on the top whose children are the “SMT root hash” and position of the next free node: NextFreeNode. Note that the depth of the tree is now 41.</p>

    <p class="text-gray-300">Every time we make an insertion, we fetch the ‘NextFreeNode‘ value from the Merkle tree and increase it by 1. All updates to this field are justified by a Merkle-Proof (even though it contains only a single element) as any other leaves. With this modification in mind, when we refer to the root of the SMT, we mean the root of the upmost node and not the root of the sub-SMT root.</p>

    <h3 id="sec-131" class="text-xl font-semibold mt-8">C.4 Operations on Cryptographic Accumulator</h3>

    <p class="text-gray-300">The cryptographic accumulator, based on Sparse Merkle Trees (SMTs), facilitates operations such as insertions, deletions, and updates with verifiable proofs. This section outlines the procedures for these operations and their verification mechanisms.</p>

    <h4 id="sec-132" class="text-lg font-semibold mt-6">Insertion Operation</h4>

    <p class="text-gray-300">To insert an entry <span class="math">(k,v)</span> into the map, the process involves identifying the two surrounding keys, <span class="math">HKey-</span> and <span class="math">HKey+</span>, which are the largest and smallest keys, respectively, such that <span class="math">HKey-&lt;\\text{hash}(k)&lt;HKey+</span>. The positions of these keys within the tree are denoted as <span class="math">i-</span> and <span class="math">i+</span>. The next free node, <span class="math">i=\\text{nextFreeNode}</span>, is determined by taking the value stored near the root of the tree. This value is incremented at the end of the procedure.</p>

    <p class="text-gray-300">Procedure:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Obtain Merkle proofs for leaves at positions <span class="math">i+</span>, <span class="math">i-</span>, and <span class="math">i</span>, along with the opening nodes for <span class="math">i+</span> and <span class="math">i-</span> (<span class="math">N+</span> and <span class="math">N-</span>).</li>

      <li>Verify that <span class="math">N+.Prev=i-</span> and <span class="math">N-.Next=i+</span> to ensure no intermediate key exists between <span class="math">HKey-</span> and <span class="math">HKey+</span>.</li>

      <li>Update the SMT by setting <span class="math">N-.Next=i</span>, inserting the new value of <span class="math">\\text{hash}(N-)</span>, and similarly updating <span class="math">N+</span> and the new node <span class="math">N</span>.</li>

      <li>Increment nextFreeNode and derive the new root hash from the Merkle proof.</li>

    </ol>

    <p class="text-gray-300">Output: The prover generates three Merkle proofs and the positions <span class="math">i+</span>, <span class="math">i-</span>, and <span class="math">i</span>, along with the modified openings <span class="math">N-</span> and <span class="math">N+</span>.</p>

    <p class="text-gray-300">Verification: The verifier checks the consistency of <span class="math">N-</span> and <span class="math">N+</span> with their Merkle proofs and the current root hash.</p>

    <h5 id="sec-133" class="text-base font-semibold mt-4">Read Zero Operation</h5>

    <p class="text-gray-300">The ”Read Zero” operation is designed to demonstrate to an external verifier that a specific key <span class="math">k</span> is not present within the map. This operation is similar in nature to the insertion process, and thus, a concise explanation is provided here:</p>

    <p class="text-gray-300">Procedure:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Identify the two surrounding keys, <span class="math">HKey-</span> and <span class="math">HKey+</span>, which are the largest and smallest keys, respectively, such that <span class="math">HKey-&lt;\\mbox{hash}(k)&lt;HKey+</span>. Denote their positions within the tree as <span class="math">i-</span> and <span class="math">i+</span>.</li>

      <li>Retrieve and send the openings <span class="math">N-</span> and <span class="math">N+</span>, along with their respective Merkle proofs, to demonstrate the non-inclusion of key <span class="math">k</span> between these two keys.</li>

    </ol>

    <p class="text-gray-300">Verification: The external verifier conducts the following checks to validate the claim that key <span class="math">k</span> is not part of the map:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Verify the consistency of the Merkle proofs with the alleged openings <span class="math">N-</span> and <span class="math">N+</span> against the current root hash of the Sparse Merkle Tree (SMT).</li>

      <li>Confirm that <span class="math">N+.Prev=i-</span> and <span class="math">N-.Next=i+</span>, and that <span class="math">HKey-&lt;\\mbox{hash}(k)&lt;HKey+</span>, ensuring there is no intermediate key <span class="math">HKey^{\\prime}</span> that could exist between <span class="math">HKey-</span> and <span class="math">HKey+</span>.</li>

    </ol>

    <p class="text-gray-300">This operation effectively proves the non-existence of a key within the map by leveraging the structure and verifiability of the Sparse Merkle Tree.</p>

    <h5 id="sec-134" class="text-base font-semibold mt-4">Deletion Operation</h5>

    <p class="text-gray-300">Deleting a key from the map is analogous to removing an item from a doubly linked list, essentially reversing the insertion operation.</p>

    <p class="text-gray-300">Procedure:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Identify the positions <span class="math">i+</span>, <span class="math">i-</span>, and <span class="math">i</span> for the keys <span class="math">k+</span>, <span class="math">k-</span>, and the key to be deleted.</li>

      <li>Update <span class="math">N-</span> to point to <span class="math">N+</span> instead of <span class="math">N</span> and similarly update <span class="math">N+</span> to point to <span class="math">N-</span>, effectively removing <span class="math">N</span> from the list.</li>

      <li>Replace the leaf hash(<span class="math">N</span>) by 0 and update the rest of the SMT.</li>

    </ol>

    <p class="text-gray-300">Output: The prover provides three Merkle proofs and the positions <span class="math">i+</span>, <span class="math">i-</span>, and <span class="math">i</span>, along with the original openings <span class="math">N-</span>, <span class="math">N</span>, and <span class="math">N+</span>.</p>

    <p class="text-gray-300">Verification: The verifier checks the consistency of the updated nodes with their Merkle proofs and the current root hash.</p>

    <h5 id="sec-135" class="text-base font-semibold mt-4">Update Operation</h5>

    <p class="text-gray-300">Updating a value in the map follows a similar procedure to a normal Merkle-tree update.</p>

    <p class="text-gray-300">Procedure:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Locate the position <span class="math">i</span> and the node <span class="math">N</span> for the key to be updated.</li>

      <li>Obtain the Merkle proof for <span class="math">N</span>.</li>

      <li>Update the value field of <span class="math">N</span> and derive the new root hash using the Merkle proof.</li>

    </ol>

    <p class="text-gray-300">Verification</p>

    <p class="text-gray-300">The verifier checks the Merkle proof for <span class="math">N</span> against the current root hash and verifies the updated value.</p>

    <h4 id="sec-136" class="text-lg font-semibold mt-6">Read Operation</h4>

    <p class="text-gray-300">Reading a key from the map involves a standard Merkle proof verification to confirm the presence or absence of the key.</p>

    <h5 id="sec-137" class="text-base font-semibold mt-4">Procedure:</h5>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Find the position <span class="math">i</span> and the node <span class="math">N</span> for the key.</li>

      <li>Obtain and return the Merkle proof for <span class="math">N</span>.</li>

    </ol>

    <h5 id="sec-138" class="text-base font-semibold mt-4">Verification</h5>

    <p class="text-gray-300">The verifier checks the Merkle proof for <span class="math">N</span> against the current root hash to validate the read operation.</p>

    <h4 id="sec-139" class="text-lg font-semibold mt-6">C.4.1 Hash Functions and Sparse Merkle Tree Specifications</h4>

    <p class="text-gray-300">The MiMC hash function, operating over the scalar field of the BLS12-377 curve, is selected for its efficiency and security properties. The SMT is characterized by a binary arity and a depth of 40, ensuring adequate capacity and collision resistance for our applications. The implementation adheres to the MiMC construction with Miyaguchi-Preneel scheme, utilizing 62 rounds of the cipher with an S-box exponent of <span class="math">e=17</span>, in non-Feistel mode. The construction omits the XOR operations, replacing them with field additions within the BLS12-377 scalar field.</p>`;
---

<BaseLayout title="Linea Prover Documentation (2022/1633)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2022 &middot; eprint 2022/1633
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
