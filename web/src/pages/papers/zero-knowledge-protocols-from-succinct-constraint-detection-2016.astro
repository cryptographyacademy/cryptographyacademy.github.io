---
import BaseLayout from '../../layouts/BaseLayout.astro';
import PaperDisclaimer from '../../components/PaperDisclaimer.astro';
import PaperHistory from '../../components/PaperHistory.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2016/988';
const CRAWLER = 'modal-marker';
const CONVERTED_DATE = '2026-02-17';
const TITLE_HTML = 'Zero Knowledge Protocols from Succinct Constraint Detection';
const AUTHORS_HTML = 'Eli Ben-Sasson, Alessandro Chiesa, Michael A.  Forbes, Ariel Gabizon, Michael Riabzev, Nicholas Spooner';

const CONTENT = `    <section id="abstract" class="mb-10">
      <h2 class="text-2xl font-bold">Abstract</h2>
      <p class="text-gray-300">We study the problem of constructing proof systems that achieve both soundness and zero knowledge unconditionally (without relying on intractability assumptions). Known techniques for this goal are primarily *combinatorial*, despite the fact that constructions of interactive proofs (IPs) and probabilistically checkable proofs (PCPs) heavily rely on *algebraic* techniques to achieve their properties.

We present simple and natural modifications of well-known &quot;algebraic&quot; IP and PCP protocols that achieve unconditional (perfect) zero knowledge in recently introduced models, overcoming limitations of known techniques.

1. We modify the PCP of Ben-Sasson and Sudan [BS08] to obtain zero knowledge for NEXP in the model of Interactive Oracle Proofs [BCS16,RRR16], where the verifier, in each round, receives a PCP from the prover.

2. We modify the IP of Lund, Fortnow, Karloff, and Nisan [LFKN92] to obtain zero knowledge for #P in the model of Interactive PCPs [KR08], where the verifier first receives a PCP from the prover and then interacts with him.

The simulators in our zero knowledge protocols rely on solving a problem that lies at the intersection of coding theory, linear algebra, and computational complexity, which we call the *succinct constraint detection* problem, and consists of detecting dual constraints with polynomial support size for codes of exponential block length. Our two results rely on solutions to this problem for fundamental classes of linear codes:

* An algorithm to detect constraints for Reed--Muller codes of exponential length. This algorithm exploits the Raz--Shpilka [RS05] deterministic polynomial identity testing algorithm, and shows, to our knowledge, a first connection of algebraic complexity theory with zero knowledge.

* An algorithm to detect constraints for PCPs of Proximity of Reed--Solomon codes [BS08] of exponential degree. This algorithm exploits the recursive structure of the PCPs of Proximity to show that small-support constraints are &quot;locally&quot; spanned by a small number of small-support constraints.</p>
      <p class="text-gray-300"><strong>Keywords:</strong> probabilistically checkable proofs &middot; interactive proofs &middot; sumcheck &middot; zero knowledge &middot; polynomial identity testing</p>
    </section>

    <h2 id="sec-misc-1" class="text-2xl font-bold">Ariel Gabizon</h2>

    <p class="text-gray-300">ariel@z.cash ZcashCo&dagger;</p>

    <h2 id="sec-misc-2" class="text-2xl font-bold">Alessandro Chiesa</h2>

    <p class="text-gray-300">alexch@berkeley.edu UC Berkeley</p>

    <h3 id="sec-misc-3" class="text-xl font-semibold mt-8">Michael Riabzev</h3>

    <p class="text-gray-300">mriabzev@cs.technion.ac.il Technion</p>

    <p class="text-gray-300">September 20, 2017</p>

    <h2 id="sec-misc-4" class="text-2xl font-bold">Michael A. Forbes</h2>

    <p class="text-gray-300">miforbes@illinois.edu UIUC<sup>&lowast;</sup></p>

    <h2 id="sec-misc-5" class="text-2xl font-bold">Nicholas Spooner</h2>

    <p class="text-gray-300">nick.spooner@berkeley.edu UC Berkeley</p>

    <h4 id="sec-misc-6" class="text-lg font-semibold mt-6">Abstract</h4>

    <p class="text-gray-300">We study the problem of constructing proof systems that achieve both soundness and zero knowledge unconditionally (without relying on intractability assumptions). Known techniques for this goal are primarily <em>combinatorial</em>, despite the fact that constructions of interactive proofs (IPs) and probabilistically checkable proofs (PCPs) heavily rely on <em>algebraic</em> techniques to achieve their properties.</p>

    <p class="text-gray-300">We present simple and natural modifications of well-known 'algebraic' IP and PCP protocols that achieve unconditional (perfect) zero knowledge in recently introduced models, overcoming limitations of known techniques.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>We modify the PCP of Ben-Sasson and Sudan <a href="#page-57-0">[BS08]</a> to obtain zero knowledge for NEXP in the model of Interactive Oracle Proofs <a href="#page-56-0">[BCS16,</a> <a href="#page-58-0">RRR16]</a>, where the verifier, in each round, receives a PCP from the prover.</li>
      <li>We modify the IP of Lund, Fortnow, Karloff, and Nisan <a href="#page-58-1">[LFKN92]</a> to obtain zero knowledge for #P in the model of Interactive PCPs <a href="#page-58-2">[KR08]</a>, where the verifier first receives a PCP from the prover and then interacts with him.</li>
    </ul>

    <p class="text-gray-300">The simulators in our zero knowledge protocols rely on solving a problem that lies at the intersection of coding theory, linear algebra, and computational complexity, which we call the <em>succinct constraint detection</em> problem, and consists of detecting dual constraints with polynomial support size for codes of exponential block length. Our two results rely on solutions to this problem for fundamental classes of linear codes:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>An algorithm to detect constraints for Reed&ndash;Muller codes of exponential length. This algorithm exploits the Raz&ndash;Shpilka <a href="#page-58-3">[RS05]</a> deterministic polynomial identity testing algorithm, and shows, to our knowledge, a first connection of algebraic complexity theory with zero knowledge.</li>
      <li>An algorithm to detect constraints for PCPs of Proximity of Reed&ndash;Solomon codes <a href="#page-57-0">[BS08]</a> of exponential degree. This algorithm exploits the recursive structure of the PCPs of Proximity to show that small-support constraints are &quot;locally&quot; spanned by a small number of small-support constraints.</li>
    </ul>

    <p class="text-gray-300">Keywords: probabilistically checkable proofs, interactive proofs, sumcheck, zero knowledge, polynomial identity testing</p>

    <p class="text-gray-300"><sup>&lowast;</sup>Work conducted while at Stanford University.</p>

    <p class="text-gray-300"><sup>&dagger;</sup>Work conducted while at Technion.</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">1</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Introduction<br>1.1<br>Results</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">3<br>3</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Techniques<br>2.1<br>Detecting constraints for exponentially-large codes<br>2.2<br>From constraint detection to zero knowledge via masking<br><br>2.3<br>Achieving zero knowledge beyond NP<br><br>2.4<br>Roadmap</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7<br>7<br>9<br>11<br>12</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Definitions<br>3.1<br>Basic notations<br>3.2<br>Single-prover proof systems<br><br>3.3<br>Zero knowledge<br><br>3.4<br>Codes<br></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">13<br>13<br>13<br>15<br>16</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Succinct constraint detection<br>4.1<br>Definition of succinct constraint detection<br><br>4.2<br>Partial sums of low-degree polynomials<br><br>4.3<br>Univariate polynomials with BS proximity proofs<br></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">18<br>18<br>20<br>22</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Sumcheck with perfect zero knowledge<br>5.1<br>Step 1<br><br>5.2<br>Step 2<br></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">28<br>29<br>32</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Perfect zero knowledge for counting problems</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">34</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Perfect zero knowledge from succinct constraint detection<br>7.1<br>A general transformation<br>7.2<br>Perfect zero knowledge IOPs of proximity for Reed&ndash;Solomon codes</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">35<br>35<br>38</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">8</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Perfect zero knowledge for nondeterministic time<br>8.1<br>Perfect zero knowledge IOPs of proximity for LACSPs<br><br>8.2<br>Perfect zero knowledge IOPs for RLACSPs<br><br>8.3<br>Putting things together</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">40<br>41<br>42<br>44</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">A</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Prior work on single-prover unconditional zero knowledge</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">45</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">B</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Proof of Lemma 4.3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">46</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">C</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Proof of Lemma 4.6</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">47</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">D</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Proof of Lemma 4.11</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">48</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">E</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Proof of Claim 4.23</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">49</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">F</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Definition of the linear code family BS-RS</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">50</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">G Proof of Lemma 4.27<br>G.1<br>The recursive cover and its combinatorial properties<br>G.2<br>Computing spanning sets of dual codes in the recursive cover<br><br>G.3<br>Putting things together</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">52<br>52<br>54<br>55</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">H Folklore claim on interpolating sets</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">56</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Acknowledgements</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">57</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">References</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">57</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">The study of interactive proofs (IPs) <a href="#page-57-1">[BM88,</a> <a href="#page-57-2">GMR89]</a> that unconditionally achieve zero knowledge <a href="#page-57-2">[GMR89]</a> has led to a rich theory, with connections well beyond zero knowledge. For example, the class of languages with statistical zero knowledge IPs, which we denote by SZK-IP, has complete problems that make no reference to either zero knowledge or interaction <a href="#page-58-4">[SV03,</a> <a href="#page-57-3">GV99]</a> and is closed under complement <a href="#page-58-5">[Oka00,</a> <a href="#page-59-0">Vad99]</a>. Despite the fact that all PSPACE languages have IPs <a href="#page-58-6">[Sha92]</a>, SZK-IP is contained in AM &cap; coAM, and thus NP is not in SZK-IP unless the polynomial hierarchy collapses <a href="#page-57-4">[BHZ87]</a>; one consequence is that Graph Non-Isomorphism is unlikely to be NP-complete. Moreover, constructing SZK-IP for a language is equivalent to constructing instance-dependent commitments for the language <a href="#page-58-7">[IOS97,</a> <a href="#page-58-8">OV08]</a>, and has connections to other fundamental information-theoretic notions like randomized encodings <a href="#page-56-3">[AR16,</a> <a href="#page-59-1">VV15]</a> and secret-sharing schemes <a href="#page-59-1">[VV15]</a>.</p>

    <p class="text-gray-300">Unconditional zero knowledge in other models behaves very differently. Ben-Or, Goldwasser, Kilian, and Wigderson <a href="#page-56-4">[BGKW88]</a> introduced the model of multi-prover interactive proofs (MIPs) and showed that <em>all</em> such proofs can be made zero knowledge unconditionally. The analogous statement for IPs is equivalent to the existence of one-way functions, as shown by <a href="#page-57-2">[GMR89,</a> <a href="#page-58-9">IY87,</a> <a href="#page-56-5">BGG</a>+88] in one direction and by <a href="#page-58-10">[Ost91,</a> <a href="#page-58-11">OW93]</a> in the other (unless BPP = PSPACE, in which case the statement is trivial). Subsequent works not only established that all NEXP languages have MIPs <a href="#page-56-6">[BFL91]</a>, but also led to formulating probabilistically checkable proofs (PCPs) and proving the celebrated PCP Theorem <a href="#page-57-5">[FRS88,</a> <a href="#page-56-7">BFLS91,</a> <a href="#page-57-6">FGL</a><sup>+</sup>96, <a href="#page-56-8">AS98,</a> <a href="#page-56-9">ALM</a><sup>+</sup>98], as well as constructing statistical zero knowledge PCPs <a href="#page-58-12">[KPT97]</a> and applying them to black-box cryptography <a href="#page-58-13">[IMS12,</a> <a href="#page-58-14">IMSX15]</a>.</p>

    <p class="text-gray-300">The theory of zero knowledge for these types of proofs, however, is not as rich as in the case of IPs. Most notably, known techniques to achieve zero knowledge MIPs or PCPs are limited, and come with caveats. Zero knowledge MIPs are obtained via complex generic transformations <a href="#page-56-4">[BGKW88]</a>, assume the full power of the PCP Theorem <a href="#page-57-7">[DFK</a><sup>+</sup>92], or support only languages in NP <a href="#page-58-15">[LS95]</a>. Zero knowledge PCPs are obtained via a construction that incurs polynomial blowups in proof length and requires the honest verifier to adaptively query the PCP <a href="#page-58-12">[KPT97]</a>. Alternative approaches are not known, despite attempts to find them. For example, <a href="#page-58-16">[IWY16]</a> apply PCPs to leakage-resilient circuits, obtaining PCPs for NP that do have a non-adaptive honest verifier but are only witness indistinguishable.</p>

    <p class="text-gray-300">Even basic questions such as &quot;are there zero-knowledge PCPs of quasilinear-size?&quot; or &quot;are there zero-knowledge PCPs with non-adaptive honest verifiers?&quot; have remained frustratingly hard to answer, despite the fact the answers to these questions are well understood when removing the requirement of zero knowledge. This state of affairs begs the question of whether a richer theory about zero knowledge MIPs and PCPs could be established.</p>

    <p class="text-gray-300">The current situation is that known techniques to achieve zero knowledge MIPs and PCPs are combinatorial, namely they make black-box use of an underlying MIP or PCP, despite the fact that most MIP and PCP constructions have a rich algebraic structure arising from the use of error correcting codes based on evaluations of low-degree polynomials. This separation is certainly an attractive feature, and perhaps even unsurprising: while error-correcting codes are designed to help recover information, zero knowledge proofs are designed to hide it.</p>

    <p class="text-gray-300">Yet, a recent work by Ben-Sasson, Chiesa, Gabizon, and Virza <a href="#page-56-10">[BCGV16]</a> brings together linear error correcting codes and zero knowledge using an algebraic technique that we refer to as 'masking'. The paper introduces a &quot;2-round PCP&quot; for NP that unconditionally achieves zero knowledge and, nevertheless, has both quasilinear size and a nonadaptive honest verifier. Their work can be viewed not only as partial progress towards some of the open questions above, but also as studying the power of zero knowledge for a natural extension of PCPs (&quot;multi-round PCPs&quot; as discussed below) with its own motivations and applications <a href="#page-56-0">[BCS16,</a> <a href="#page-58-0">RRR16,</a> <a href="#page-56-11">BCG</a><sup>+</sup>17].</p>

    <p class="text-gray-300">The motivation of this work is to understand the power of algebraic tools, such as linear error correcting codes, for achieving zero knowledge unconditionally (without relying on intractability assumptions).</p>

      <h3 id="sec-1.1" class="text-xl font-semibold mt-8">1.1 Results</h3>

    <p class="text-gray-300">We present new protocols that unconditionally achieve soundness and zero knowledge in recently suggested models that combine features of PCPs and IPs <a href="#page-58-2">[KR08,</a> <a href="#page-56-0">BCS16,</a> <a href="#page-58-0">RRR16]</a>. Our protocols consist of simple and natural modifications to well-known constructions: the PCP of Ben-Sasson and Sudan <a href="#page-57-0">[BS08]</a> and the IP for polynomial summation of Lund, Fortnow, Karloff, and Nisan <a href="#page-58-1">[LFKN92]</a>. By leveraging the linear codes used in these constructions, we reduce the problem of achieving zero knowledge to solving exponentially-large instances of a new linear-algebraic problem that we call <em>constraint detection</em>, which we believe to be of independent interest. We design efficient algorithms for solving</p>

    <p class="text-gray-300">this problem for notable linear code families, along the way exploiting connections to algebraic complexity theory and local views of linear codes. We now elaborate on the above by discussing each of our results.</p>

      <h4 id="sec-1.1.1" class="text-lg font-semibold mt-6">1.1.1 Zero knowledge for non-deterministic exponential time</h4>

    <p class="text-gray-300">Two recent works <a href="#page-56-0">[BCS16,</a> <a href="#page-58-0">RRR16]</a> independently introduce and study the notion of an <em>interactive oracle proof</em> (IOP), which can be viewed as a &quot;multi-round PCP&quot;. Informally, an IOP is an IP modified so that, whenever the prover sends to the verifier a message, the verifier does not have to read the message in full but may probabilistically query it. Namely, in every round, the verifier sends the prover a message, and the prover replies with a PCP. IOPs enjoy better efficiency compared to PCPs <a href="#page-56-11">[BCG</a>+17], and have applications to constructing argument systems <a href="#page-56-0">[BCS16]</a> and IPs <a href="#page-58-0">[RRR16]</a>.</p>

    <p class="text-gray-300">The aforementioned work of <a href="#page-56-10">[BCGV16]</a> makes a simple modification to the PCP of Ben-Sasson and Sudan <a href="#page-57-0">[BS08]</a> and obtains a 2-round IOP for NP that is perfect zero knowledge, and yet has quasilinear size and a non-adaptive honest verifier. Our first result consists of extending this prior work to all languages in NEXP, positively answering an open question raised there. We do so by constructing, for each time T and query bound b, a suitable IOP for NTIME(T) that is zero knowledge against query bound b; the result for NEXP follows by setting b to be super-polynomial.</p>

    <p class="text-gray-300">The foregoing notion of zero knowledge for IOPs directly extends that for PCPs, and requires showing the existence of an algorithm that simulates the view of any (malicious and adaptive) verifier interacting with the honest prover and making at most b queries across all oracles; here, 'view' consists of the answers to queries across all oracles.<a href="#page-3-0">1</a></p>

    <p class="text-gray-300">Theorem 1.1 (informal statement of Thm. <a href="#page-39-1">8.1)</a>. <em>For every time bound</em> T <em>and query bound</em> b<em>, the complexity class</em> NTIME(T) <em>has</em> 2<em>-round Interactive Oracle Proofs that are perfect zero knowledge against</em> b <em>queries, and where the proof length is</em> O&tilde;(T + b) <em>and the (honest verifier's) query complexity is</em> polylog(T + b)<em>.</em></p>

    <p class="text-gray-300">The prior work of <a href="#page-56-10">[BCGV16]</a> was &quot;stuck&quot; at NP because their simulator runs in poly(T + b) time so that T, b must be polynomially-bounded. In contrast, we achieve all of NEXP by constructing, for essentially the same simple 2-round IOP, a simulator that runs in time poly(&tilde;q + log T + log b), where q&tilde; is the <em>actual</em> number of queries made by the malicious verifier. This is an <em>exponential</em> improvement in simulation efficiency, and we obtain it by conceptualizing and solving a linear-algebraic problem about Reed&ndash;Solomon codes, and their proximity proofs, as discussed in Section <a href="#page-4-0">1.1.3.</a></p>

    <p class="text-gray-300">In sum, our theorem gives new tradeoffs compared to <a href="#page-58-12">[KPT97]</a>'s result, which gives statistical zero knowledge PCPs for NTIME(T) with proof length poly(T, b) and an adaptive honest verifier. We obtain perfect zero knowledge for NTIME(T), with quasilinear proof length and a non-adaptive honest verifier, at the price of &quot;2 rounds of PCPs&quot;.</p>

      <h4 id="sec-1.1.2" class="text-lg font-semibold mt-6">1.1.2 Zero knowledge for counting problems</h4>

    <p class="text-gray-300">Kalai and Raz <a href="#page-58-2">[KR08]</a> introduce and study the notion of <em>interactive PCPs</em> (IPCPs), which &quot;sits in between&quot; IPs and IOPs: the prover first sends the verifier a PCP, and then the prover and verifier engage in a standard IP. IPCPs also enjoy better efficiency compared to PCPs or IPs alone <a href="#page-58-2">[KR08]</a>.</p>

    <p class="text-gray-300">We show how a natural and simple modification of the sumcheck protocol of Lund, Fortnow, Karloff, and Nisan <a href="#page-58-1">[LFKN92]</a> achieves perfect zero knowledge in the IPCP model, even with a non-adaptive honest verifier. By running this protocol on the usual arithmetization of the counting problem associated to 3SAT, we obtain our second result, which is IPCPs for #P that are <em>perfect zero knowledge against unbounded queries</em>. This means that there exists a polynomial-time algorithm that simulates the view of any (malicious and adaptive) verifier making any polynomial number of queries to the PCP oracle. Here, 'view' consists of answers to oracle queries and the transcript of interaction with the prover. (In particular, this notion of zero knowledge is a 'hybrid' of corresponding notions for PCPs and IPs.)</p>

    <p class="text-gray-300">Theorem 1.2 (informal statement of Thm. <a href="#page-33-1">6.2)</a>. <em>The complexity class</em> #P <em>has Interactive PCPs that are perfect zero knowledge against unbounded queries. The PCP proof length is exponential, and the communication complexity of the interaction and the (honest verifier's) query complexity are polynomial.</em></p>

    <p class="text-gray-300">Our construction relies on a random self-reducibility property of the sumcheck protocol (see Section <a href="#page-9-0">2.2.2</a> for a summary) and its completeness and soundness properties are straightforward to establish. As in our previous result, the</p>

    <p class="text-gray-300"><sup>1</sup>More precisely, while in a zero knowledge IP or MIP one is required to simulate the entire transcript of interaction (with one or multiple provers), in a zero knowledge IOP or PCP one is merely required to simulate answers to the oracle queries but not the entire oracle.</p>

    <p class="text-gray-300">&quot;magic&quot; lies in the construction of the simulator, which must solve the same type of exponentially-large linear-algebraic problem, except that this time it is about Reed&ndash;Muller codes rather than Reed&ndash;Solomon codes. The algorithm that we give to solve this task relies on connections to the problem of polynomial identity testing in the area of algebraic complexity theory, as we discuss further below.</p>

    <p class="text-gray-300">Goyal, Ishai, Mahmoody, and Sahai [GIMS10] also study zero knowledge for IPCPs, and show how to obtain IPCPs for NP that (i) are statistical zero knowledge against unbounded queries, and yet (ii) each location of the (necessarily) super-polynomial size PCP is polynomial-time computable given the NP witness. They further prove that these two properties are not attainable by zero knowledge PCPs. Their construction consists of replacing the commitment scheme in the zero knowledge IP for 3-colorability of [GMW91] with an information-theoretic analogue in the IPCP model. Our Theorem 1.2 also achieves zero knowledge against unbounded queries, but targets the complexity class #P (rather than NP), for which there is no clear analogue of property (ii) above.</p>

    <p class="text-gray-300">Information-theoretic commitments also underlie the construction of zero knowledge PCPs [KPT97]. One could apply the [KPT97] result for <strong>NEXP</strong> to obtain zero knowledge PCPs (thus also IPCPs) for #P, but this is an indirect and complex route (in particular, it relies on the PCP Theorem) that, moreover, yields an adaptive honest verifier. Our direct construction is simple and natural, and also yields a non-adaptive honest verifier.</p>

    <p class="text-gray-300">We now discuss the common algebraic structure that allowed us to obtain both of the above results. We believe that further progress in understanding these types of algebraic techniques will lead to further progress in understanding the power of unconditional zero knowledge for IOPs and IPCPs, and perhaps also for MIPs and PCPs.</p>

      <h4 id="sec-1.1.3" class="text-lg font-semibold mt-6">1.1.3 Succinct constraint detection for Reed-Muller and Reed-Solomon codes</h4>

    <p class="text-gray-300">The constructions underlying both of our theorems achieve zero knowledge by applying a simple modification to well-known protocols: the PCP of Ben-Sasson and Sudan [BS08] underlies our result for <strong>NEXP</strong> and the sumcheck protocol of Lund, Fortnow, Karloff, and Nisan [LFKN92] underlies our result for #P.</p>

    <p class="text-gray-300">In both of these protocols the verifier has access (either via a polynomial-size representation or via a PCP oracle) to an exponentially-large word that allegedly belongs to a certain linear code, and the prover 'leaks' hard-to-compute information in the process of convincing the verifier that this word belongs to the linear code. We achieve zero knowledge via a modification that we call <em>masking</em>: the prover sends to the verifier a PCP containing a random codeword in this code, and then convinces the verifier that the <em>sum</em> of these two (the original codeword and this random codeword) is close to the linear code.<sup>2</sup> Intuitively, zero knowledge comes from the fact that the prover now argues about a random shift of the original word.</p>

    <p class="text-gray-300">However, this idea raises a problem: how does the simulator 'sample' an exponentially-large random codeword in order to answer the verifier's queries to the PCP? Solving this problem crucially relies on solving a problem that lies at the intersection of coding theory, linear algebra, and computational complexity, which we call the <em>constraint detection problem</em>. We informally introduce it and state our results about it, and defer to Section 2.2 a more detailed discussion of its connection to zero knowledge.</p>

    <p class="text-gray-300"><strong>Detecting constraints in codes.</strong> Constraint detection is the problem of determining which linear relations hold across all codewords of a linear code  <span class="math">C \\subseteq \\mathbb{F}^D</span> , when considering only a given subdomain  <span class="math">I \\subseteq D</span>  of the code rather than all of the domain D. This problem can always be solved in time that is polynomial in |D| (via Gaussian elimination); however, if there is an algorithm that solves this problem in time that is <em>polynomial in the subdomain's size</em> |I|, rather than the domain's size |D|, then we say that the code has <em>succinct</em> constraint detection; in particular, the domain could have <em>exponential</em> size and the algorithm would still run in polynomial time.</p>

    <p class="text-gray-300"><strong>Definition 1.3</strong> (informal). We say that a linear code  <span class="math">C \\subseteq \\mathbb{F}^D</span>  has <strong>succinct constraint detection</strong> if there exists an algorithm that, given a subset  <span class="math">I \\subseteq D</span> , runs in time  <span class="math">\\operatorname{poly}(\\log |\\mathbb{F}| + \\log |D| + |I|)</span>  and outputs  <span class="math">z \\in \\mathbb{F}^I</span>  such that  <span class="math">\\sum_{i \\in I} z(i)w(i) = 0</span>  for all  <span class="math">w \\in C</span> , or &quot;no&quot; if no such z exists. (In particular, |D| may be exponential.)</p>

    <p class="text-gray-300">We further discuss the problem of constraint detection in Section 2.1, and provide a formal treatment of it in Section 4.1. Beyond this introduction, we shall use (and achieve) a stronger definition of constraint detection: the algorithm is required to output a basis for the space of dual codewords in  <span class="math">C^{\\perp}</span>  whose support lies in the subdomain I, i.e., a basis for</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;2</sup>This is reminiscent of the use of a random secret share of 0 to achieve privacy in information-theoretic multi-party protocols [BGW88].</p>

    <p class="text-gray-300">the space  <span class="math">\\{z \\in D^I: \\forall w \\in C, \\sum_{i \\in I} z(i)w(i) = 0\\}</span> . Note that in our discussion of succinct constraint detection we do not leverage the distance property of the code C, but we do leverage it in our eventual applications.</p>

    <p class="text-gray-300">Our zero knowledge simulators' strategy includes sampling a &quot;random PCP&quot;: a random codeword w in a linear code C with exponentially large domain size |D| (see Section 2.2 for more on this). Explicitly sampling w requires time  <span class="math">\\Omega(|D|)</span> , and so is inefficient. But a verifier makes only polynomially-many queries to w, so the simulator has to only simulate w when restricted to polynomial-size sets  <span class="math">I \\subseteq D</span> , leaving open the possibility of doing so in time  <span class="math">\\operatorname{poly}(|I|)</span> . Achieving such a simulation time is an instance of (efficiently and perfectly) &quot;implementing a huge random object&quot; [GGN10] via a  <span class="math">\\operatorname{stateful}</span>  algorithm [BW04]. We observe that if C has succinct constraint detection then this sampling problem for C has a solution: the simulator maintains the set  <span class="math">\\{(i,a_i)\\}_{i\\in I}</span>  of past query-answer pairs; then, on a new verifier query  <span class="math">j\\in D</span> , the simulator uses constraint detection to determine if  <span class="math">w_j</span>  is linearly dependent on  <span class="math">w_I</span> , and answers accordingly (such linear dependencies characterize the required probability distribution, see Lemma 4.3).</p>

    <p class="text-gray-300">Overall, our paper thus provides an application (namely, obtaining zero knowledge simulators) where the problem of efficient implementation of huge random objects arises naturally.</p>

    <p class="text-gray-300">We now state our results about succinct constraint detection.</p>

    <p class="text-gray-300">(1) <strong>Reed&ndash;Muller codes, and their partial sums.</strong> We prove that the family of linear codes comprised of evaluations of low-degree multivariate polynomials, along with their partial sums, has succinct constraint detection. This family is closely related to the <em>sumcheck protocol</em> [LFKN92], and indeed we use this result to obtain a PZK analogue of the sumcheck protocol (see Section 2.2.2 and Section 5), which yields Theorem 1.2 (see Section 2.3.1 and Section 6).</p>

    <p class="text-gray-300">Recall that the family of Reed&ndash;Muller codes, denoted RM, is indexed by tuples  <span class="math">n = (\\mathbb{F}, m, d)</span> , where  <span class="math">\\mathbb{F}</span>  is a finite field and m, d are positive integers, and the n-th code consists of codewords  <span class="math">w \\colon \\mathbb{F}^m \\to \\mathbb{F}</span>  that are the evaluation of an m-variate polynomial Q of individual degree less than d over  <span class="math">\\mathbb{F}</span> . We denote by  <span class="math">\\Sigma RM</span>  the family that extends RM with evaluations of all partial sums over certain subcubes of a hypercube:</p>

    <p class="text-gray-300"><strong>Definition 1.4</strong> (informal). We denote by  <span class="math">\\Sigma RM</span>  the linear code family that is indexed by tuples  <span class="math">\\mathfrak{n}=(\\mathbb{F},m,d,H)</span> , where H is a subset of  <span class="math">\\mathbb{F}</span> , and where the  <span class="math">\\mathfrak{n}</span> -th code consists of codewords  <span class="math">(w_0,\\ldots,w_m)</span>  such that there exists an m-variate polynomial Q of individual degree less than d over  <span class="math">\\mathbb{F}</span>  for which  <span class="math">w_i \\colon \\mathbb{F}^{m-i} \\to \\mathbb{F}</span>  is the evaluation of the i-th partial sum of Q over H, i.e,  <span class="math">w_i(\\vec{\\alpha}) = \\sum_{\\vec{\\gamma} \\in H^i} Q(\\vec{\\alpha}, \\vec{\\gamma})</span>  for every  <span class="math">\\vec{\\alpha} \\in \\mathbb{F}^{m-i}</span> .</p>

    <p class="text-gray-300">The domain size for codes in  <span class="math">\\Sigma RM</span>  is  <span class="math">\\Omega(|\\mathbb{F}|^m)</span> , but our detector's running time is exponentially smaller.</p>

    <p class="text-gray-300"><strong>Theorem 1.5</strong> (informal statement of Thm. 4.9). The family  <span class="math">\\Sigma RM</span>  has succinct constraint detection: there is a detector algorithm for  <span class="math">\\Sigma RM</span>  that runs in time poly( <span class="math">\\log |\\mathbb{F}| + m + d + |H| + |I|</span> ).</p>

    <p class="text-gray-300">We provide intuition for the theorem's proof in Section 2.1.1 and provide the proof's details in Section 4.2; the proof leverages tools from algebraic complexity theory. (Our proof also shows that the family RM, which is a restriction of  <span class="math">\\Sigma RM</span> , has succinct constraint detection.) Our theorem implies perfect and stateful implementation of a random low-degree multivariate polynomial and its partial sums over any hypercube; our proof extends an algorithm of [BW04], which solves this problem in the case of parity queries to boolean functions on subcubes of the boolean hypercube.</p>

    <p class="text-gray-300">(2) <strong>Reed&ndash;Solomon codes, and their PCPPs.</strong> Second, we prove that the family of linear codes comprised of evaluations of low-degree univariate polynomials concatenated with corresponding BS proximity proofs [BS08] has succinct constraint detection. This family is closely related to quasilinear-size PCPs for <strong>NEXP</strong> [BS08], and indeed we use this result to obtain PZK proximity proofs for this family (see Section 2.2.3 and Section 7), from which we derive Theorem 1.1 (see Section 2.3.2 and Section 8).</p>

    <p class="text-gray-300"><strong>Definition 1.6</strong> (informal). We denote by BS-RS the linear code family indexed by tuples  <span class="math">\\mathfrak{n}=(\\mathbb{F},L,d)</span> , where  <span class="math">\\mathbb{F}</span>  is an extension field of  <span class="math">\\mathbb{F}_2</span> , L is a linear subspace in  <span class="math">\\mathbb{F}</span> , and d is a positive integer; the  <span class="math">\\mathfrak{n}</span> -th code consists of evaluations on L of univariate polynomials Q of degree less than d, concatenated with corresponding [BS08] proximity proofs.</p>

    <p class="text-gray-300">The domain size for codes in BS-RS is  <span class="math">\\Omega(|L|)</span> , but our detector's running time is exponentially smaller.</p>

    <p class="text-gray-300"><strong>Theorem 1.7</strong> (informal statement of Thm. 4.12). <em>The family</em> BS-RS <em>has succinct constraint detection:</em> there is a detector algorithm for BS-RS that runs in time poly( <span class="math">\\log |\\mathbb{F}| + \\dim(L) + |I|</span> ).</p>

    <p class="text-gray-300">We provide intuition for the theorem's proof in Section 2.1.2 and provide the proof's details in Section 4.3; the proof leverages combinatorial properties of the recursive construction of BS proximity proofs.</p>

    <section id="sec-2" class="mb-10">
      <h2 class="text-2xl font-bold">2 Techniques</h2>

    <p class="text-gray-300">We informally discuss intuition behind our algorithms for detecting constraints (Section 2.1), their connection to zero knowledge (Section 2.2), and how we derive our results about #P and NEXP (Section 2.3). Throughout, we provide pointers to the technical sections that contain further details.</p>

      <h3 id="sec-2.1" class="text-xl font-semibold mt-8">2.1 Detecting constraints for exponentially-large codes</h3>

    <p class="text-gray-300">As informally introduced in Section 1.1.3, the <em>constraint detection problem</em> corresponding to a linear code family  <span class="math">\\mathscr{C} = \\{C_{\\mathtt{n}}\\}_{\\mathtt{n}}</span>  with domain  <span class="math">D(\\cdot)</span>  and alphabet  <span class="math">\\mathbb{F}(\\cdot)</span>  is the following: given an index  <span class="math">\\mathtt{n} \\in \\{0,1\\}^*</span>  and subset  <span class="math">I \\subseteq D(\\mathtt{n})</span> , output a basis for the space  <span class="math">\\{z \\in D(\\mathtt{n})^I : \\forall w \\in C_{\\mathtt{n}}, \\sum_{i \\in I} z(i)w(i) = 0\\}</span> . In other words, for a given subdomain I, we wish to determine all linear relations that hold for codewords in  <span class="math">C_{\\mathtt{n}}</span>  restricted to the subdomain I.</p>

    <p class="text-gray-300">If a generating matrix for  <span class="math">C_n</span>  can be found in polynomial time, this problem can be solved in  <span class="math">poly(|\\mathfrak{n}|+|D(\\mathfrak{n})|)</span>  time via Gaussian elimination (such an approach was implicitly taken by [BCGV16] to construct a perfect zero knowledge simulator for an IOP for NP). However, in our setting  <span class="math">|D(\\mathfrak{n})|</span>  is <em>exponential</em> in  <span class="math">|\\mathfrak{n}|</span> , so the straightforward solution is inefficient. With this in mind, we say that  <span class="math">\\mathscr{C}</span>  has <em>succinct constraint detection</em> if there exists an algorithm that solves its constraint detection problem in  <span class="math">poly(|\\mathfrak{n}|+|I|)</span>  time, even if  <span class="math">|D(\\mathfrak{n})|</span>  is exponential in  <span class="math">|\\mathfrak{n}|</span> .</p>

    <p class="text-gray-300">The formal definition of succinct constraint detection is in Section 4.1. In the rest of this section we provide intuition for two of our theorems: succinct constraint detection for the family  <span class="math">\\Sigma RM</span>  and for the family BS-RS. As will become evident, the techniques that we use to prove the two theorems differ significantly. Perhaps this is because the two codes are quite different:  <span class="math">\\Sigma RM</span>  has a simple and well-understood algebraic structure, whereas BS-RS is constructed recursively using proof composition.</p>

      <h4 id="sec-2.1.1" class="text-lg font-semibold mt-6">2.1.1 From algebraic complexity to detecting constraints for Reed-Muller codes and their partial sums</h4>

    <p class="text-gray-300">The purpose of this section is to provide intuition about the proof of Theorem 1.5, which states that the family  <span class="math">\\Sigma RM</span>  has succinct constraint detection. (Formal definitions, statements, and proofs are in Section 4.2.) We thus outline how to construct an algorithm that detects constraints for the family of linear codes comprised of evaluations of low-degree multivariate polynomials, along with their partial sums. Our construction generalizes the proof of [BW04], which solves the special case of parity queries to boolean functions on subcubes of the boolean hypercube by reducing this problem to a probabilistic identity testing problem that is solvable via an algorithm of [RS05].</p>

    <p class="text-gray-300">Below, we temporarily ignore the partial sums, and focus on constructing an algorithm that detects constraints for the family of Reed&ndash;Muller codes RM, and at the end of the section we indicate how we can also handle partial sums.</p>

    <p class="text-gray-300">Step 1: phrase as linear algebra problem. Consider a codeword  <span class="math">w \\colon \\mathbb{F}^m \\to \\mathbb{F}</span>  that is the evaluation of an m-variate polynomial Q of individual degree less than d over  <span class="math">\\mathbb{F}</span> . Note that, for every  <span class="math">\\vec{\\alpha} \\in \\mathbb{F}^m</span> ,  <span class="math">w(\\vec{\\alpha})</span>  equals the inner product of Q's coefficients with the vector  <span class="math">\\phi_{\\vec{\\alpha}}</span>  that consists of the evaluation of all  <span class="math">d^m</span>  monomials at  <span class="math">\\vec{\\alpha}</span> . One can argue that constraint detection for RM is equivalent to finding the nullspace of  <span class="math">\\{\\phi_{\\vec{\\alpha}}\\}_{\\vec{\\alpha} \\in I}</span> . However, &quot;writing out&quot; this  <span class="math">|I| \\times d^m</span>  matrix and performing Gaussian elimination is too expensive, so we must solve this linear algebra problem <em>succinctly</em>.</p>

    <p class="text-gray-300">Step 2: encode vectors as coefficients of polynomials. While each vector  <span class="math">\\phi_{\\vec{\\alpha}}</span>  is long, it has a succinct description; in fact, we can construct an m-variate polynomial  <span class="math">\\Phi_{\\vec{\\alpha}}</span>  whose coefficients (after expansion) are the entries of  <span class="math">\\phi_{\\vec{\\alpha}}</span> , but has an arithmetic circuit of only size O(md): namely,  <span class="math">\\Phi_{\\vec{\\alpha}}(\\vec{X}) := \\prod_{i=1}^{m} (1 + \\alpha_i X_i + \\alpha_i^2 X_i^2 + \\dots + \\alpha_i^{d-1} X_i^{d-1})</span> . Computing the nullspace of  <span class="math">\\{\\Phi_{\\vec{\\alpha}}\\}_{\\vec{\\alpha} \\in I}</span>  is thus equivalent to computing the nullspace of  <span class="math">\\{\\phi_{\\vec{\\alpha}}\\}_{\\vec{\\alpha} \\in I}</span> .</p>

    <p class="text-gray-300"><strong>Step 3: computing the nullspace.</strong> Computing the nullspace of a set of polynomials is a problem in algebraic complexity theory, and is essentially equivalent to the Polynomial Identity Testing (PIT) problem, and so we leverage tools from that area.<sup>3</sup> While there are simple randomized algorithms to solve this problem (see for example [Kay10, Lemma 8] and [BW04]), these algorithms, due to a nonzero probability of error, suffice to achieve statistical zero knowledge but do not suffice to achieve perfect zero knowledge. To obtain perfect zero knowledge, we need a solution that has <em>no probability of error</em>. Derandomizing PIT for arbitrary algebraic circuits seems to be beyond current</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;3</sup>PIT is the following problem: given a polynomial f expressed as an algebraic circuit, is f identically zero? This problem has well-known randomized algorithms [Zip79, Sch80], but deterministic algorithms for all circuits seem to be beyond current techniques [KI04]. PIT is a central problem in algebraic complexity theory, and suffices for solving a number of other algebraic problems. We refer the reader to [SY10] for a survey.</p>

    <p class="text-gray-300">techniques (as it implies circuit lower bounds [KI04]), but derandomizations are currently known for some restricted circuit classes. The polynomials that we consider are special: they fall in the well-studied class of &quot;sum of products of univariates&quot;, and for this case we can invoke the deterministic algorithm of [RS05] (see also [Kay10]). (It is interesting that derandomization techniques are ultimately used to obtain a qualitative improvement for an inherently probabilistic task, i.e., perfect sampling of verifier views.)</p>

    <p class="text-gray-300">The above provides an outline for how to detect constraints for RM. The extension to  <span class="math">\\Sigma RM</span> , which also includes partial sums, is achieved by considering a more general form of vectors  <span class="math">\\phi_{\\vec{\\alpha}}</span>  as well as corresponding polynomials  <span class="math">\\Phi_{\\vec{\\alpha}}</span> . These polynomials also have the special form required for our derandomization. See Section 4.2 for details.</p>

      <h4 id="sec-2.1.2" class="text-lg font-semibold mt-6">2.1.2 From recursive code covers to detecting constraints for Reed&ndash;Solomon codes and their PCPPs</h4>

    <p class="text-gray-300">The purpose of this section is to provide intuition about the proof of Theorem 1.7, which states that the family BS-RS has succinct constraint detection. (Formal definitions, statements, and proofs are in Section 4.3.) We thus outline how to construct an algorithm that detects constraints for the family of linear codes comprised of evaluations of low-degree univariate polynomials concatenated with corresponding BS proximity proofs [BS08].</p>

    <p class="text-gray-300">Our construction leverages the recursive structure of BS proximity proofs: we identify key combinatorial properties of the recursion that enable &quot;local&quot; constraint detection. To define and argue these properties, we introduce two notions that play a central role throughout the proof:</p>

    <pre><code class="language-text">A (local) view of a linear code C\\subseteq \\mathbb{F}^D is a pair (\\tilde{D},\\tilde{C}) such that \\tilde{D}\\subseteq D and \\tilde{C}=C|_{\\tilde{D}}\\subseteq \\mathbb{F}^{\\tilde{D}}. A cover of C is a set of local views S=\\{(\\tilde{D}_j,\\tilde{C}_j)\\}_j of C such that D=\\cup_j\\tilde{D}_j.
</code></pre>

    <p class="text-gray-300">Combinatorial properties of the recursive step. Given a finite field  <span class="math">\\mathbb{F}</span> , domain  <span class="math">D \\subseteq \\mathbb{F}</span> , and degree d, let  <span class="math">C := \\mathrm{RS}[\\mathbb{F}, D, d]</span>  be the Reed-Solomon code consisting of evaluations on D of univariate polynomials of degree less than d over  <span class="math">\\mathbb{F}</span> ; for concreteness, say that the domain size is  <span class="math">|D| = 2^n</span>  and the degree is  <span class="math">d = |D|/2 = 2^{n-1}</span> .</p>

    <p class="text-gray-300">The first level of [BS08]'s recursion appends to each codeword  <span class="math">f \\in C</span>  an auxiliary function  <span class="math">\\pi_1(f) \\colon D&#x27; \\to \\mathbb{F}</span>  with domain D' disjoint from D. Moreover, the mapping from f to  <span class="math">\\pi_1(f)</span>  is linear over  <span class="math">\\mathbb{F}</span> , so the set  <span class="math">C^1 := \\{f | \\pi_1(f)\\}_{f \\in C}</span> , where  <span class="math">f | \\pi_1(f) \\colon D \\cup D&#x27; \\to \\mathbb{F}</span>  is the function that agrees with f on D and with  <span class="math">\\pi_1(f)</span>  on D', is a linear code over  <span class="math">\\mathbb{F}</span> . The code  <span class="math">C^1</span>  is the &quot;first-level&quot; code of a BS proximity proof for f.</p>

    <p class="text-gray-300">The code  <span class="math">C^1</span>  has a naturally defined cover  <span class="math">S^1 = \\{(\\tilde{D}_j, \\tilde{C}_j)\\}_j</span>  such that each  <span class="math">\\tilde{C}_j</span>  is a Reed&ndash;Solomon code  <span class="math">\\mathrm{RS}[\\mathbb{F}, \\tilde{D}_j, d_j]</span>  with  <span class="math">2d_j \\leq |\\tilde{D}_j| = O(\\sqrt{d})</span> , that is, with rate 1/2 and block length  <span class="math">O(\\sqrt{d})</span> . We prove several combinatorial properties of this cover:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">S^1</span>  is 1-intersecting. For all distinct j, j' in  <span class="math">J, |\\tilde{D}_j \\cap \\tilde{D}_{j&#x27;}| \\leq 1</span>  (namely, the subdomains are almost disjoint).</li>
      <li><span class="math">S^1</span>  is  <span class="math">O(\\sqrt{d})</span> -local. Every partial assignment to  <span class="math">O(\\sqrt{d})</span>  domains  <span class="math">\\tilde{D}_j</span>  in the cover that is locally consistent with the cover can be extended to a globally consistent assignment, i.e., to a codeword of  <span class="math">C^1</span> . That is, there exists  <span class="math">\\kappa = O(\\sqrt{d})</span>  such that every partial assignment  <span class="math">h \\colon \\bigcup_{\\ell=1}^{\\kappa} \\tilde{D}_{j_\\ell} \\to \\mathbb{F}</span>  with  <span class="math">h|_{\\tilde{D}_{j_\\ell}} \\in \\tilde{C}_{j_\\ell}</span>  (for each  <span class="math">\\ell</span> ) equals the restriction to the subdomain  <span class="math">\\bigcup_{\\ell=1}^{\\kappa} \\tilde{D}_{j_\\ell}</span>  of some codeword  <span class="math">f \\| \\pi_1(f)</span>  in  <span class="math">C^1</span> .</li>
      <li><span class="math">S^1</span>  is  <span class="math">O(\\sqrt{d})</span> -independent. The ability to extend locally-consistent assignments to &quot;globally-consistent&quot; codewords of  <span class="math">C^1</span>  holds in a stronger sense: even when the aforementioned partial assignment h is extended arbitrarily to  <span class="math">\\kappa</span>  additional point-value pairs, this new partial assignment still equals the restriction of some codeword  <span class="math">f||\\pi_1(f)|</span>  in  <span class="math">C^1</span> .</li>
    </ul>

    <p class="text-gray-300">The locality property alone already suffices to imply that, given a subdomain  <span class="math">I \\subseteq D \\cup D&#x27;</span>  of size  <span class="math">|I| &lt; \\sqrt{d}</span> , we can solve the constraint detection problem on I by considering only those constraints that appear in views that intersect I (see Lemma 4.22). But C has exponential block length so a &quot;quadratic speedup&quot; does not yet imply succinct constraint detection. To obtain it, we also leverage the intersection and independence properties to reduce &quot;locality&quot; as follows.</p>

    <p class="text-gray-300"><strong>Further recursive steps.</strong> So far we have only considered the first recursive step of a BS proximity proof; we show how to obtain covers with smaller locality (and thereby detect constraints with more efficiency) by considering additional recursive steps. Each code  <span class="math">\\tilde{C}_j</span>  in the cover  <span class="math">S^1</span>  of  <span class="math">C^1</span>  is a Reed&ndash;Solomon code  <span class="math">\\mathrm{RS}[\\mathbb{F}, \\tilde{D}_j, d_j]</span>  with  <span class="math">|\\tilde{D}_j|, d_j = O(\\sqrt{d})</span> , and the next recursive step appends to each codeword in  <span class="math">\\tilde{C}_j</span>  a corresponding auxiliary function, yielding a new code</p>

    <p class="text-gray-300"><span class="math">C^2</span> . In turn,  <span class="math">C^2</span>  has a cover  <span class="math">S^2</span> , and another recursive step yields a new code  <span class="math">C^3</span> , which has its own cover  <span class="math">S^3</span> , and so on. The crucial technical observation (Lemma 4.20) is that the intersection and independence properties, which hold recursively, enable us to deduce that  <span class="math">C^i</span>  is 1-intersecting,  <span class="math">O(\\sqrt[2^i]{d})</span> -local, and  <span class="math">O(\\sqrt[2^i]{d})</span> -independent; in particular, for  <span class="math">r = \\log \\log d + O(1)</span> ,  <span class="math">S^r</span>  is 1-intersecting, O(1)-local, O(1)-independent.</p>

    <p class="text-gray-300">Then, recalling that detecting constraints for local codes requires only the views in the cover that intersect I (Lemma 4.22), our constraint detector works by choosing  <span class="math">i \\in \\{1, \\dots, r\\}</span>  such that the cover  <span class="math">S^i</span>  is  <span class="math">\\operatorname{poly}(|I|)</span> -local, finding in this cover a  <span class="math">\\operatorname{poly}(|I|)</span> -size set of  <span class="math">\\operatorname{poly}(|I|)</span> -size views that intersect I, and computing in  <span class="math">\\operatorname{poly}(|I|)</span>  time a basis for the dual of each of these views &mdash; thereby proving Theorem 1.7.</p>

    <p class="text-gray-300"><strong>Remark 2.1.</strong> For the sake of those familiar with BS-RS we remark that the domain D' is the carefully chosen subset of  <span class="math">\\mathbb{F} \\times \\mathbb{F}</span>  designated by that construction, the code  <span class="math">C^1</span>  is the code that evaluates bivariate polynomials of degree  <span class="math">O(\\sqrt{d})</span>  on  <span class="math">D \\cup D&#x27;</span>  (along the way mapping  <span class="math">D \\subseteq \\mathbb{F}</span>  to a subset of  <span class="math">\\mathbb{F} \\times \\mathbb{F}</span> ), the subdomains  <span class="math">\\tilde{D}_j</span>  are the axis-parallel &quot;rows&quot; and &quot;columns&quot; used in that recursive construction, and the codes  <span class="math">\\tilde{C}_j</span>  are Reed-Solomon codes of block length  <span class="math">O(\\sqrt{d})</span> . The  <span class="math">O(\\sqrt{d})</span> -locality and independence follow from basic properties of bivariate Reed-Muller codes; see Example 4.14.</p>

    <p class="text-gray-300">Remark 2.2. It is interesting to compare the above result with <em>linear lower bounds on query complexity</em> for testing proximity to random low density parity check (LDPC) codes [BHR05, BGK<sup>+</sup>10]. Those results are proved by obtaining a basis for the dual code such that every small-support constraint is spanned by a small subset of that basis. The same can be observed to hold for BS-RS, even though this latter code is locally testable with <em>polylogarithmic query complexity</em> [BS08, Thm. 2.13]. The difference between the two cases is due to the fact that, for a random LDPC code, an assignment that satisfies all but a single basis-constraint is (with high probability) far from the code, whereas the recursive and 1-intersecting structure of BS-RS implies the existence of words that satisfy all but a single basis constraint, yet are negligibly close to being a codeword.</p>

      <h3 id="sec-2.2" class="text-xl font-semibold mt-8">2.2 From constraint detection to zero knowledge via masking</h3>

    <p class="text-gray-300">We provide intuition about the connection between constraint detection and zero knowledge (Section 2.2.1), and how we leverage this connection to achieve two intermediate results: (i) a sumcheck protocol that is zero knowledge in the Interactive PCP model (Section 2.2.2); and (ii) proximity proofs for Reed&ndash;Solomon codes that are zero knowledge in the Interactive Oracle Proof model (Section 2.2.3).</p>

      <h4 id="sec-2.2.1" class="text-lg font-semibold mt-6">2.2.1 Local simulation of random codewords</h4>

    <p class="text-gray-300">Suppose that the prover and verifier both have oracle access to a codeword  <span class="math">w \\in C</span> , for some linear code  <span class="math">C \\subseteq \\mathbb{F}^D</span>  with exponential-size domain D, and that they need to engage in some protocol that involves w. During the protocol, the prover may leak information about w that is hard to compute (e.g., requires exponentially-many queries to w), and so would violate zero knowledge (as we see below, this is the case for protocols such as sumcheck).</p>

    <p class="text-gray-300">Rather than directly invoking the protocol, the prover first sends to the verifier a random codeword  <span class="math">r \\in C</span>  (as an oracle since r has exponential size) and the verifier replies with a random field element  <span class="math">\\rho \\in \\mathbb{F}</span> ; then the prover and verifier invoke the protocol on the new codeword  <span class="math">w&#x27; := \\rho w + r \\in C</span>  rather than w. Intuitively, running the protocol on w' now does not leak information about w, because w' is random in C (up to resolvable technicalities). This <em>random self-reducibility</em> makes sense for only some protocols, e.g., those where completeness is preserved for any choice of  <span class="math">\\rho</span>  and soundness is broken for only a small fraction of  <span class="math">\\rho</span> ; but this will indeed be the case for the settings described below.</p>

    <p class="text-gray-300">The aforementioned <em>masking</em> technique was used by [BCGV16] for codes with polynomial-size domains, but we use it for codes with exponential-size domains, which requires exponentially more efficient simulation techniques. Indeed, to prove (perfect) zero knowledge, a simulator must be able to reproduce, exactly, the view obtained by any malicious verifier that queries entries of w', a uniformly random codeword in C; however, it is too expensive for the simulator to explicitly sample a random codeword and answer the verifier's queries according to it. Instead, the simulator must sample the &quot;local view&quot; that the verifier sees while querying w' at a <em>small</em> number of locations  <span class="math">I \\subseteq D</span> .</p>

    <p class="text-gray-300">But simulating local views of the form  <span class="math">w&#x27;|_I</span>  is reducible to detecting <em>constraints</em>, i.e., codewords in the dual code  <span class="math">C^{\\perp}</span>  whose support is contained in I. Indeed, if no word in  <span class="math">C^{\\perp}</span>  has support contained in I then  <span class="math">w&#x27;|_I</span>  is uniformly random; otherwise, each additional linearly independent constraint of  <span class="math">C^{\\perp}</span>  with support contained in I further reduces</p>

    <p class="text-gray-300">the entropy of  <span class="math">w&#x27;|_I</span>  in a well-understood manner. (See Lemma 4.3 for a formal statement.) In sum, succinct constraint detection enables us to &quot;implement&quot; [GGN10, BW04] random codewords of C despite C having exponential size.</p>

    <p class="text-gray-300">Note that in the above discussion we implicitly assumed that the set I is known in advance, i.e., that the verifier chooses its queries in advance. This, of course, need not be the case: a verifier may adaptively make queries based on answers to previous queries and, hence, the set I need not be known a priori. This turns out to not be a problem because, given a constraint detector, it is straightforward to compute the conditional distribution of the view  <span class="math">w&#x27;|_I</span>  given  <span class="math">w&#x27;|_J</span>  for a subset J of I. This is expressed precisely in Lemma 4.3.</p>

    <p class="text-gray-300">We now discuss two concrete protocols for which the aforementioned random self-reducibility applies, and for which we also have constructed suitably-efficient constraint detectors.</p>

      <h4 id="sec-2.2.2" class="text-lg font-semibold mt-6">2.2.2 Zero knowledge sumchecks</h4>

    <p class="text-gray-300">The celebrated sumcheck protocol [LFKN92] is not zero knowledge. In the sumcheck protocol, the prover and verifier have oracle access to a low-degree m-variate polynomial F over a field  <span class="math">\\mathbb{F}</span> , and the prover wants to convince the verifier that  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} F(\\vec{\\alpha}) = 0</span>  for a given subset H of  <span class="math">\\mathbb{F}</span> . During the protocol, the prover communicates partial sums of F, which are #P-hard to compute and, as such, violate zero knowledge.</p>

    <p class="text-gray-300">We now explain how to use random self-reducibility to make the sumcheck protocol (perfect) zero knowledge, at the cost of moving from the Interactive Proof model to the Interactive PCP model.</p>

    <p class="text-gray-300"><strong>IPCP sumcheck.</strong> Consider the following tweak to the classical sumcheck protocol: rather than invoking sumcheck on F directly, the prover first sends to the verifier (the evaluation of) a random low-degree polynomial R as an oracle; then,</p>

    <p class="text-gray-300">the prover sends the value  <span class="math">z:=\\sum_{\\vec{\\alpha}\\in H^m}R(\\vec{\\alpha})</span>  and the verifier replies with a random field element  <span class="math">\\rho</span> ; finally, the two invoke sumcheck on the claim &quot; <span class="math">\\sum_{\\vec{\\alpha}\\in H^m}Q(\\vec{\\alpha})=z</span> &quot; where  <span class="math">Q:=\\rho F+R</span> .</p>

    <p class="text-gray-300">Completeness is clear because if  <span class="math">\\sum_{\\vec{\\alpha}\\in H^m}F(\\vec{\\alpha})=0</span>  and  <span class="math">\\sum_{\\vec{\\alpha}\\in H^m}R(\\vec{\\alpha})=z</span>  then  <span class="math">\\sum_{\\vec{\\alpha}\\in H^m}(\\rho F+R)(\\vec{\\alpha})=z</span> ; soundness is also clear because if  <span class="math">\\sum_{\\vec{\\alpha}\\in H^m}F(\\vec{\\alpha})\\neq 0</span>  then  <span class="math">\\sum_{\\vec{\\alpha}\\in H^m}(\\rho F+R)(\\vec{\\alpha})\\neq z</span>  with high probability over  <span class="math">\\rho</span> , we call the set of the choice of R. (Figure 1) in this interval in the standard transfer that the variety of the choice of R. regardless of the choice of R. (For simplicity, we ignore the fact that the verifier also needs to test that R has low degree.) We are thus left to show (perfect) zero knowledge, which turns out to be a much less straightforward argument.</p>

    <p class="text-gray-300"><strong>The simulator.</strong> Before we explain how to argue zero knowledge, we first clarify what we mean by it: since the verifier has oracle access to F we cannot hope to 'hide' it; nevertheless, we can hope to argue that the verifier, by participating in the protocol, does not learn anything about F beyond what the verifier can directly learn by querying F (and the fact that F sums to zero on  <span class="math">H^m</span> ). What we shall achieve is the following: an algorithm that simulates the verifier's view by making as many queries to F as the <em>total</em> number of verifier queries to either F or R.<sup>4</sup></p>

    <p class="text-gray-300">On the surface, zero knowledge seems easy to argue, because  <span class="math">\\rho F + R</span>  seems random among low-degree m-variate polynomials. More precisely, consider the simulator that samples a random low-degree polynomial Q and uses it instead of  <span class="math">\\rho F + R</span>  and answers the verifier queries as follows: (a) whenever the verifier queries  <span class="math">F(\\vec{\\alpha})</span> , respond by querying  <span class="math">F(\\vec{\\alpha})</span>  and returning the true value; (b) whenever the verifier queries  <span class="math">R(\\vec{\\alpha})</span> , respond by querying  <span class="math">F(\\vec{\\alpha})</span>  and returning  <span class="math">Q(\\vec{\\alpha}) - \\rho F(\\vec{\\alpha})</span> . Observe that the number of queries to F made by the simulator equals the number of (mutually) distinct queries to F and R made by the verifier, as desired.</p>

    <p class="text-gray-300">However, the above reasoning, while compelling, is insufficient. First,  <span class="math">\\rho F + R</span>  is not random because a malicious verifier can choose  <span class="math">\\rho</span>  depending on queries to R. Second, even if  <span class="math">\\rho F + R</span>  were random (e.g., the verifier does not query R before choosing  <span class="math">\\rho</span> ), the simulator must run in polynomial time, both producing correctly-distributed 'partial sums' of  <span class="math">\\rho F + R</span>  and answering queries to R, but sampling Q alone requires exponential time. In this high level discussion we ignore the first problem (which nonetheless has to be tackled), and focus on the second.</p>

    <p class="text-gray-300">At this point it should be clear from the discussion in Section 2.2.1 that the simulator does not have to sample Q explicitly, but only has to perfectly simulate local views of it by leveraging the fact that it can keep state across queries. And doing so requires solving the succinct constraint detection problem for a suitable code C. In this case, it suffices to consider the code  <span class="math">C = \\Sigma RM</span> , and our Theorem 1.5 guarantees the required constraint detector.</p>

    <p class="text-gray-300">The above discussion omits several details, so we refer the reader to Section 5 for further details.</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;4</sup>A subsequent work [CFS17] shows how to bootstrap this IPCP sumcheck protocol into a more complex one that has a stronger zero knowledge guarantee: the simulator can sample the verifier's view by making as many queries to F as the number of verifier queries (plus one). Nevertheless, the weaker zero knowledge guarantee that we achieve suffices for our purposes.</p>

      <h4 id="sec-2.2.3" class="text-lg font-semibold mt-6">2.2.3 Zero knowledge proximity proofs for Reed&ndash;Solomon</h4>

    <p class="text-gray-300">Testing proximity of a codeword w to a given linear code C can be aided by a <em>proximity proof</em> <a href="#page-57-13">[DR04,</a> <a href="#page-56-15">BGH</a>+06], which is an auxiliary oracle &pi; that facilitates testing (e.g., C is not locally testable). For example, testing proximity to the Reed&ndash;Solomon code, a crucial step towards achieving short PCPs, is aided via suitable proximity proofs <a href="#page-57-0">[BS08]</a>.</p>

    <p class="text-gray-300">From the perspective of zero knowledge, however, a proximity proof can be 'dangerous': a few locations of &pi; can in principle leak a lot of information about the codeword w, and a malicious verifier could potentially learn a lot about w with only a few queries to w and &pi;. The notion of zero knowledge for proximity proofs requires that this cannot happen: it requires the existence of an algorithm that simulates the verifier's view by making as many queries to w as the <em>total</em> number of verifier queries to either w or &pi; <a href="#page-58-20">[IW14]</a>; intuitively, this means that any bit of the proximity proof &pi; reveals no more information than one bit of w.</p>

    <p class="text-gray-300">We demonstrate again the use of random self-reducibility and show a general transformation that, under certain conditions, maps a PCP of proximity (P, V ) for a code C to a corresponding 2-round Interactive Oracle Proof of Proximity (IOPP) for C that is <em>(perfect) zero knowledge</em>.</p>

    <p class="text-gray-300">IOP of proximity for C. Consider the following IOP of Proximity: the prover and verifier have oracle access to a codeword w, and the prover wants to convince the verifier that w is close to C; the prover first sends to the verifier a random codeword r in C, and the verifier replies with a random field element &rho;; the prover then sends the proximity proof &pi; 0 := P(w 0 ) that attests that w 0 := &rho;w + r is close to C. Note that this is a 2-round IOP of Proximity for C, because completeness follows from the fact that C is linear, while soundness follows because if w is far from C, then so is &rho;w + r for every r with high probability over &rho;. But is the zero knowledge property satisfied?</p>

    <p class="text-gray-300">The simulator. Without going into details, analogously to Section <a href="#page-9-0">2.2.2,</a> a simulator must be able to sample local views for random codewords from the code L := { wkP(w) }w&isin;<sup>C</sup> , so the simulator's efficiency reduces to the efficiency of constraint detection for L. We indeed prove that if L has succinct constraint detection then the simulator works out. See Section <a href="#page-34-1">7.1</a> for further details.</p>

    <p class="text-gray-300">The case of Reed&ndash;Solomon. The above machinery allows us to derive a zero knowledge IOP of Proximity for Reed&ndash;Solomon codes, thanks to our Theorem <a href="#page-5-1">1.7,</a> which states that the family of linear codes comprised of evaluations of low-degree univariate polynomials concatenated with corresponding BS proximity proofs <a href="#page-57-0">[BS08]</a> has succinct constraint detection; see Section <a href="#page-37-0">7.2</a> for details. This is one of the building blocks of our construction of zero knowledge IOPs for NEXP, as described below in Section <a href="#page-10-3">2.3.2.</a></p>

      <h3 id="sec-2.3" class="text-xl font-semibold mt-8">2.3 Achieving zero knowledge beyond NP</h3>

    <p class="text-gray-300">We outline how to derive our results about zero knowledge for #P and NEXP.</p>

      <h4 id="sec-2.3.1" class="text-lg font-semibold mt-6">2.3.1 Zero knowledge for counting problems</h4>

    <p class="text-gray-300">We provide intuition for the proof of Theorem <a href="#page-3-1">1.2,</a> which states that the complexity class #P has Interactive PCPs that are perfect zero knowledge.</p>

    <p class="text-gray-300">We first recall the classical (non zero knowledge) Interactive Proof for #P <a href="#page-58-1">[LFKN92]</a>. The language L#3SAT, which consists of pairs (&phi;, N) where &phi; is a 3-CNF boolean formula and N is the number of satisfying assignments of &phi;, is #P-complete, and thus it suffices to construct an IP for it. The IP for L#3SAT works as follows: the prover and verifier both <em>arithmetize</em> &phi; to obtain a low-degree multivariate polynomial p<sup>&phi;</sup> and invoke the (non zero knowledge) sumcheck protocol on the claim &quot;P ~&alpha;&isin;{0,1}<sup>n</sup> p&phi;(~&alpha;) = N&quot;, where arithmetic is over a large-enough prime field.</p>

    <p class="text-gray-300">Returning to our goal, we obtain a perfect zero knowledge Interactive PCP by simply replacing the (non zero knowledge) IP sumcheck mentioned above with our perfect zero knowledge IPCP sumcheck, described in Section <a href="#page-9-0">2.2.2.</a> In Section <a href="#page-33-0">6</a> we provide further details, including proving that the zero knowledge guarantees of our sumcheck protocol suffice for this case.</p>

      <h4 id="sec-2.3.2" class="text-lg font-semibold mt-6">2.3.2 Zero knowledge for nondeterministic time</h4>

    <p class="text-gray-300">We provide intuition for the proof of Theorem <a href="#page-3-2">1.1,</a> which implies that the complexity class NEXP has Interactive Oracle Proofs that are perfect zero knowledge. Very informally, the proof consists of combining two building blocks: (i) [BCGV16]'s reduction from <strong>NEXP</strong> to <em>randomizable</em> linear algebraic constraint satisfaction problems, and (ii) our construction of perfect zero knowledge IOPs of Proximity for Reed&ndash;Solomon codes, described in Section 2.2.3. Besides extending [BCGV16]'s result from <strong>NP</strong> to <strong>NEXP</strong>, our proof provides a conceptual simplification over [BCGV16] by clarifying how the above two building blocks work together towards the final result. We now discuss this.</p>

    <p class="text-gray-300"><strong>Starting point:</strong> [BS08]. Many PCP constructions consist of two steps: (1) arithmetize the statement at hand (in our case, membership of an instance in some NEXP-complete language) by reducing it to a &quot;PCP-friendly&quot; problem that looks like a <em>linear-algebraic</em> constraint satisfaction problem (LACSP); (2) design a tester that probabilistically checks witnesses for this LACSP. In this paper, as in [BCGV16], we take [BS08]'s PCPs for NEXP as a starting point, where the first step reduces NEXP to a &quot;univariate&quot; LACSP whose witnesses are codewords in a Reed&ndash;Solomon code of exponential degree that satisfy certain properties, and whose second step relies on suitable <em>proximity proofs</em> [DR04, BGH+06] for that code. Thus, overall, the PCP consists of two oracles, one being the LACSP witness and the other being the corresponding BS proximity proof, and it is not hard to see that such a PCP is <em>not</em> zero knowledge, because both the LACSP witness and its proximity proof reveal hard-to-compute information.</p>

    <p class="text-gray-300"><strong>Step 1: sanitize the proximity proof.</strong> We first address the problem that the BS proximity proof &quot;leaks&quot;, by simply replacing it with our own perfect zero knowledge analogue. Namely, we replace it with our perfect zero knowledge 2-round IOP of Proximity for Reed&ndash;Solomon codes, described in Section 2.2.3. This modification ensures that there exists an algorithm that perfectly simulates the verifier's view by making as many queries to the LACSP witness as the <em>total</em> number of verifier queries to <em>either the LACSP witness or other oracles used to facilitate proximity testing</em>. At this point we have obtained a perfect zero knowledge 2-round IOP of Proximity for <strong>NEXP</strong> (analogous to the notion of a zero knowledge PCP of Proximity [IW14]); this part is where, previously, [BCGV16] were restricted to <strong>NP</strong> because their simulator only handled Reed&ndash;Solomon codes with <em>polynomial</em> degree while our simulator is efficient even for such codes with <em>exponential</em> degree. But we are not done yet: to obtain our goal, we also need to address the problem that the LACSP witness itself &quot;leaks&quot; when the verifier queries it, which we discuss next.</p>

    <p class="text-gray-300">Step 2: sanitize the witness. Intuitively, we need to inject randomness in the reduction from NEXP to LACSP because the prover ultimately sends an LACSP witness to the verifier as an oracle, which the verifier can query. This is precisely what [BCGV16]'s reduction from NEXP to randomizable LACSPs enables, and we thus use their reduction to complete our proof. Informally, given an a-priori query bound b on the verifier's queries, the reduction outputs a witness w with the property that one can efficiently sample another witness w' whose entries are b-wise independent. We can then simply use the IOP of Proximity from the previous step on this randomized witness. Moreover, since the efficiency of the verifier is polylogarithmic in b, we can set b to be super-polynomial (e.g., exponential) to preserve zero knowledge against any polynomial number of verifier queries.</p>

    <p class="text-gray-300">The above discussion is only a sketch and we refer the reader to Section 8 for further details. One aspect that we did not discuss is that an LACSP witness actually consists of two sub-witnesses, where one is a &quot;local&quot; deterministic function of the other, which makes arguing zero knowledge somewhat more delicate.</p>

      <h3 id="sec-2.4" class="text-xl font-semibold mt-8">2.4 Roadmap</h3>

    <p class="text-gray-300">After providing formal definitions in Section 3.1, the rest of the paper is organized as summarized by the table below.</p>

    <p class="text-gray-300">    <img src="_page_11_Figure_7.jpeg" alt="" class="my-4 max-w-full" />
</p>

    </section>

    <section id="sec-3" class="mb-10">
      <h2 class="text-2xl font-bold">3 Definitions</h2>

      <h3 id="sec-3.1" class="text-xl font-semibold mt-8">3.1 Basic notations</h3>

    <p class="text-gray-300"><strong>Functions, distributions, fields.</strong> We use  <span class="math">f: D \\to R</span>  to denote a function with domain D and range R; given a subset  <span class="math">\\tilde{D}</span>  of D, we use  <span class="math">f|_{\\tilde{D}}</span>  to denote the restriction of f to  <span class="math">\\tilde{D}</span> . Given a distribution  <span class="math">\\mathcal{D}</span> , we write  <span class="math">x \\leftarrow \\mathcal{D}</span>  to denote that x is sampled according to  <span class="math">\\mathcal{D}</span> . We denote by  <span class="math">\\mathbb{F}</span>  a finite field and by  <span class="math">\\mathbb{F}_q</span>  the field of size q; we say  <span class="math">\\mathbb{F}</span>  is a <em>binary field</em> if its characteristic is 2. Arithmetic operations over  <span class="math">\\mathbb{F}_q</span>  cost polylog q but we shall consider these to have unit cost (and inspection shows that accounting for their actual polylogarithmic cost does not change any of the stated results).</p>

    <p class="text-gray-300"><strong>Distances.</strong> A distance measure is a function  <span class="math">\\Delta \\colon \\Sigma^n \\times \\Sigma^n \\to [0,1]</span>  such that for all  <span class="math">x,y,z \\in \\Sigma^n</span> : (i)  <span class="math">\\Delta(x,x) = 0</span> , (ii)  <span class="math">\\Delta(x,y) = \\Delta(y,x)</span> , and (iii)  <span class="math">\\Delta(x,y) \\leq \\Delta(x,z) + \\Delta(z,y)</span> . We extend  <span class="math">\\Delta</span>  to distances to sets: given  <span class="math">x \\in \\Sigma^n</span>  and  <span class="math">S \\subseteq \\Sigma^n</span> , we define  <span class="math">\\Delta(x,S) := \\min_{y \\in S} \\Delta(x,y)</span>  (or 1 if S is empty). We say that a string x is  <span class="math">\\epsilon</span> -close to another string y if  <span class="math">\\Delta(x,y) \\leq \\epsilon</span> , and  <span class="math">\\epsilon</span> -far from y if  <span class="math">\\Delta(x,y) &gt; \\epsilon</span> ; similar terminology applies for a string x and a set S. Unless noted otherwise, we use the <em>relative Hamming distance</em> over alphabet  <span class="math">\\Sigma</span>  (typically implicit):  <span class="math">\\Delta(x,y) := |\\{i : x_i \\neq y_i\\}|/n</span> .</p>

    <p class="text-gray-300"><strong>Languages and relations.</strong> We denote by  <span class="math">\\mathscr{R}</span>  a (binary ordered) relation consisting of pairs (x, w), where x is the <em>instance</em> and w is the <em>witness</em>. We denote by  <span class="math">\\mathrm{Lan}(\\mathscr{R})</span>  the language corresponding to  <span class="math">\\mathscr{R}</span> , and by  <span class="math">\\mathscr{R}|_x</span>  the set of witnesses in  <span class="math">\\mathscr{R}</span>  for x (if  <span class="math">x \\notin \\mathrm{Lan}(\\mathscr{R})</span>  then  <span class="math">\\mathscr{R}|_x := \\emptyset</span> ). As always, we assume that |w| is bounded by some computable function of n := |x|; in fact, we are mainly interested in relations arising from nondeterministic languages:  <span class="math">\\mathscr{R} \\in \\mathbf{NTIME}(T)</span>  if there exists a T(n)-time machine M such that M(x, w) outputs 1 if and only if  <span class="math">(x, w) \\in \\mathscr{R}</span> . Throughout, we assume that  <span class="math">T(n) \\geq n</span> . We say that  <span class="math">\\mathscr{R}</span>  has relative distance  <span class="math">\\delta_{\\mathscr{R}} \\colon \\mathbb{N} \\to [0, 1]</span>  if  <span class="math">\\delta_{\\mathscr{R}}(n)</span>  is the minimum relative distance among witnesses in  <span class="math">\\mathscr{R}|_x</span>  for all x of size n. Throughout, we assume that  <span class="math">\\delta_{\\mathscr{R}}</span>  is a constant.</p>

    <p class="text-gray-300"><strong>Polynomials.</strong> We denote by  <span class="math">\\mathbb{F}[X_1,\\ldots,X_m]</span>  the ring of polynomials in m variables over  <span class="math">\\mathbb{F}</span> . Given a polynomial P in  <span class="math">\\mathbb{F}[X_1,\\ldots,X_m]</span> ,  <span class="math">\\deg_{X_i}(P)</span>  is the degree of P in the variable  <span class="math">X_i</span> . We denote by  <span class="math">\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span>  the subspace consisting of  <span class="math">P \\in \\mathbb{F}[X_1,\\ldots,X_m]</span>  with  <span class="math">\\deg_{X_i}(P) &lt; d</span>  for every  <span class="math">i \\in \\{1,\\ldots,m\\}</span> .</p>

    <p class="text-gray-300">Random shifts. We later use a folklore claim about distance preservation for random shifts in linear spaces.</p>

    <p class="text-gray-300"><strong>Claim 3.1.</strong> Let n be in  <span class="math">\\mathbb{N}</span> ,  <span class="math">\\mathbb{F}</span>  a finite field, S an  <span class="math">\\mathbb{F}</span> -linear space in  <span class="math">\\mathbb{F}^n</span> , and  <span class="math">x, y \\in \\mathbb{F}^n</span> . If x is  <span class="math">\\epsilon</span> -far from S, then  <span class="math">\\alpha x + y</span>  is  <span class="math">\\epsilon/2</span> -far from S, with probability  <span class="math">1 - |\\mathbb{F}|^{-1}</span>  over a random  <span class="math">\\alpha \\in \\mathbb{F}</span> . (Distances are relative Hamming distances.)</p>

      <h3 id="sec-3.2" class="text-xl font-semibold mt-8">3.2 Single-prover proof systems</h3>

    <p class="text-gray-300">We use two types of proof systems that combine aspects of interactive proofs [Bab85, GMR89] and probabilistically checkable proofs [BFLS91, AS98, ALM<sup>+</sup>98]: <strong>interactive PCPs</strong> (IPCPs) [KR08] and <strong>interactive oracle proofs</strong> (IOPs) [BCS16, RRR16]. We first describe IPCPs (Section 3.2.1) and then IOPs (Section 3.2.2), which generalize the former.</p>

      <h4 id="sec-3.2.1" class="text-lg font-semibold mt-6">3.2.1 Interactive probabilistically checkable proofs</h4>

    <p class="text-gray-300">An <strong>IPCP</strong> [KR08] is a PCP followed by an IP. Namely, the prover P and verifier V interact as follows: P sends to V a probabilistically checkable proof  <span class="math">\\pi</span> ; afterwards, P and  <span class="math">V^{\\pi}</span>  engage in an interactive proof. Thus, V may read a few bits of  <span class="math">\\pi</span>  but must read subsequent messages from P in full. An <em>IPCP system</em> for a relation  <span class="math">\\mathscr{R}</span>  is thus a pair (P,V), where P,V are probabilistic interactive algorithms working as described, that satisfies naturally-defined notions of perfect completeness and soundness with a given error  <span class="math">\\varepsilon(\\cdot)</span> ; see [KR08] for details.</p>

    <p class="text-gray-300">We say that an IPCP has k rounds if this &quot;PCP round&quot; is followed by a (k-1)-round interactive proof. (That is, we count the PCP round towards round complexity, unlike [KR08].) Beyond round complexity, we also measure how many bits the prover sends and how many the verifier reads: the <em>proof length</em> | is the length of  <span class="math">\\pi</span>  in bits plus the number of bits in all subsequent prover messages; the <em>query complexity</em> q is the number of bits of  <span class="math">\\pi</span>  read by the verifier plus the number of bits in all subsequent prover messages (since the verifier must read all of those bits).</p>

    <p class="text-gray-300">In this work, we do not count the number of bits in the verifier messages, nor the number of random bits used by the verifier; both are bounded from above by the verifier's running time, which we do consider. Overall, we say that a relation  <span class="math">\\mathcal{R}</span>  belongs to the complexity class  <span class="math">\\mathbf{IPCP}[k, l, q, \\varepsilon, tp, tv]</span>  if there is an IPCP system for  <span class="math">\\mathcal{R}</span>  in which: (1) the number of rounds is at most k(n); (2) the proof length is at most l(n); (3) the query complexity is at most q(n); (4) the soundness error is  <span class="math">\\varepsilon(n)</span> ; (5) the prover algorithm runs in time tp(n); (6) the verifier algorithm runs in time tv(n).</p>

      <h4 id="sec-3.2.2" class="text-lg font-semibold mt-6">3.2.2 Interactive oracle proofs</h4>

    <p class="text-gray-300">An IOP [BCS16, RRR16] is a &quot;multi-round PCP&quot;. That is, an IOP generalizes an interactive proof as follows: whenever the prover sends to the verifier a message, the verifier does not have to read the message in full but may probabilistically query it. In more detail, a k-round IOP comprises k rounds of interaction. In the <em>i</em>-th round of interaction: the verifier sends a message  <span class="math">m_i</span>  to the prover; then the prover replies with a message  <span class="math">\\pi_i</span>  to the verifier, which the verifier can query in this and later rounds (via oracle queries). After the k rounds of interaction, the verifier either accepts or rejects.</p>

    <p class="text-gray-300">An <em>IOP system</em> for a relation  <span class="math">\\mathcal{R}</span>  with soundness error  <span class="math">\\varepsilon</span>  is thus a pair (P, V), where P, V are probabilistic interactive algorithms working as described, that satisfies the following properties. (See [BCS16] for more details.)</p>

    <p class="text-gray-300">Completeness: For every instance-witness pair (x, w) in the relation  <span class="math">\\mathcal{R}</span> ,  <span class="math">\\Pr[\\langle P(x, w), V(x) \\rangle = 1] = 1</span> .</p>

    <p class="text-gray-300">Soundness: For every instance x not in  <span class="math">\\mathscr{R}</span> 's language and unbounded malicious prover  <span class="math">\\tilde{P}</span> ,  <span class="math">\\Pr[\\langle \\tilde{P}, V(x) \\rangle = 1] \\leq \\varepsilon(n)</span> .</p>

    <p class="text-gray-300">Beyond round complexity, we also measure how many bits the prover sends and how many the verifier reads: the <em>proof length</em> I is the total number of bits in all of the prover's messages, and the <em>query complexity</em> q is the total number of bits read by the verifier across all of the prover's messages. Considering all of these parameters, we say that a relation  <span class="math">\\mathscr{R}</span>  belongs to the complexity class  <span class="math">\\mathbf{IOP}[k, l, q, \\varepsilon, tp, tv]</span>  if there is an IOP system for  <span class="math">\\mathscr{R}</span>  in which: (1) the number of rounds is at most k(n); (2) the proof length is at most k(n); (3) the query complexity is at most k(n); (4) the soundness error is k(n); (5) the prover algorithm runs in time k(n); (6) the verifier algorithm runs in time k(n).</p>

    <p class="text-gray-300"><strong>IOP vs. IPCP.</strong> An IPCP (see Section 3.2.1) is a special case of an IOP because an IPCP verifier must read in full all of the prover's messages except the first one (while an IOP verifier may query any part of any prover message). The above complexity measures are consistent with those defined for IPCPs.</p>

      <h4 id="sec-3.2.3" class="text-lg font-semibold mt-6">3.2.3 Restrictions and extensions</h4>

    <p class="text-gray-300">The definitions below are about IOPs, but IPCPs inherit all of these definitions because they are a special case of IOP. <strong>Adaptivity of queries.</strong> An IOP system is <em>non-adaptive</em> if the verifier queries are non-adaptive, i.e., the queried locations depend only on the verifier's inputs.</p>

    <p class="text-gray-300"><strong>Public coins.</strong> An IOP system is <em>public coin</em> if each verifier message  <span class="math">m_i</span>  is chosen uniformly and independently at random, and all of the verifier queries happen after receiving the last prover message.</p>

    <p class="text-gray-300"><strong>Proximity.</strong> An <em>IOP of proximity</em> extends the definition of an IOP in the same way that a PCP of proximity extends that of a PCP [DR04, BGH<sup>+</sup>06]. An <em>IOPP system</em> for a relation  <span class="math">\\mathscr{R}</span>  with soundness error  <span class="math">\\varepsilon</span>  and proximity parameter  <span class="math">\\delta</span>  is a pair (P, V) that satisfies the following properties.</p>

    <p class="text-gray-300">Completeness: For every instance-witness pair (x, w) in the relation  <span class="math">\\mathscr{R}</span> ,  <span class="math">\\Pr[\\langle P(x, w), V^w(x) \\rangle = 1] = 1</span> .</p>

    <p class="text-gray-300">Soundness: For every instance-witness pair (x, w) with  <span class="math">\\Delta(w, \\mathscr{R}|_x) \\geq \\delta(n)</span>  and unbounded malicious prover  <span class="math">\\tilde{P}</span> ,  <span class="math">\\Pr[\\langle \\tilde{P}, V^w(x) \\rangle = 1] \\leq \\varepsilon(n)</span> .</p>

    <p class="text-gray-300">Similarly to above, a relation  <span class="math">\\mathscr{R}</span>  belongs to the complexity class  <span class="math">\\mathbf{IOPP}[\\mathsf{k},\\mathsf{l},\\mathsf{q},\\varepsilon,\\delta,\\mathsf{tp},\\mathsf{tv}]</span>  if there is an IOPP system for  <span class="math">\\mathscr{R}</span>  with the corresponding parameters. Following [IW14], we call an IOPP <em>exact</em> if  <span class="math">\\delta(n) = 0</span> .</p>

    <p class="text-gray-300"><strong>Promise relations.</strong> A promise relation is a relation-language pair  <span class="math">(\\mathscr{R}^{YES}, \\mathscr{L}^{NO})</span>  with  <span class="math">\\operatorname{Lan}(\\mathscr{R}^{YES}) \\cap \\mathscr{L}^{NO} = \\emptyset</span> . An IOP for a promise relation is the same as an IOP for the (standard) relation  <span class="math">\\mathscr{R}^{YES}</span> , except that soundness need only hold for  <span class="math">x \\in \\mathscr{L}^{NO}</span> . An IOPP for a promise relation is the same as an IOPP for the (standard) relation  <span class="math">\\mathscr{R}^{YES}</span> , except that soundness need only hold for  <span class="math">x \\in \\operatorname{Lan}(\\mathscr{R}^{YES}) \\cup \\mathscr{L}^{NO}</span> .</p>

      <h4 id="sec-3.2.4" class="text-lg font-semibold mt-6">3.2.4 Prior constructions</h4>

    <p class="text-gray-300">In this paper we give new IPCP and IOP constructions that achieve perfect zero knowledge for various settings. Below we summarize known constructions in these two models.</p>

    <p class="text-gray-300"><strong>IPCPs.</strong> Prior work obtains IPCPs with proof length that depends on the witness size rather than computation size [KR08, GKR08], and IPCPs with statistical zero knowledge [GIMS10] (see Section 3.3 for more details).</p>

    <p class="text-gray-300"><strong>IOPs.</strong> Prior work obtains IOPs with perfect zero knowledge for <strong>NP</strong> [BCGV16], IOPs with small proof length and query complexity [BCG<sup>+</sup>17], and an amortization theorem for &quot;unambiguous&quot; IOPs [RRR16]. Also, [BCS16] show how to compile public-coin IOPs into non-interactive arguments in the random oracle model.</p>

      <h3 id="sec-3.3" class="text-xl font-semibold mt-8">3.3 Zero knowledge</h3>

    <p class="text-gray-300">We define the notion of zero knowledge for IOPs and IPCPs achieved by our constructions: <em>unconditional (perfect) zero knowledge via straightline simulators</em>. This notion is quite strong not only because it unconditionally guarantees simulation of the verifier's view but also because straightline simulation implies desirable properties such as composability. We now provide some context and then give formal definitions.</p>

    <p class="text-gray-300">At a high level, zero knowledge requires that the verifier's view can be efficiently simulated without the prover. Converting the informal statement into a mathematical one involves many choices, including choosing which verifier class to consider (e.g., the honest verifier? all polynomial-time verifiers?), the quality of the simulation (e.g., is it identically distributed to the view? statistically close to it? computationally close to it?), the simulator's dependence on the verifier (e.g., is it non-uniform? or is the simulator universal?), and others. The definitions below consider two variants: perfect simulation via universal simulators against either unbounded-query or bounded-query verifiers.</p>

    <p class="text-gray-300">Moreover, in the case of universal simulators, one distinguishes between a non-blackbox use of the verifier, which means that the simulator takes the verifier's code as input, and a blackbox use of it, which means that the simulator only accesses the verifier via a restricted interface; we consider this latter case. Different models of proof systems call for different interfaces, which grant carefully-chosen &quot;extra powers&quot; to the simulator (in comparison to the prover) so to ensure that efficiency of the simulation does not imply the ability to efficiently decide the language. For example: in ZK IPs, the simulator may rewind the verifier; in ZK PCPs, the simulator may adaptively answer oracle queries. In ZK IPCPs and ZK IOPs (our setting), the natural definition would allow a blackbox simulator to rewind the verifier <em>and also</em> to adaptively answer oracle queries. The definitions below, however, consider only simulators that are straightline [FS89, DS98], that is they do not rewind the verifier, because our constructions achieve this stronger notion.</p>

    <p class="text-gray-300">We are now ready to define the notion of unconditional (perfect) zero knowledge via straightline simulators. We first discuss the notion for IOPs, then for IOPs of proximity, and finally for IPCPs.</p>

      <h4 id="sec-3.3.1" class="text-lg font-semibold mt-6">3.3.1 ZK for IOPs</h4>

    <p class="text-gray-300">We define zero knowledge (via straightline simulators) for IOPs. We begin by defining the view of an IOP verifier.</p>

    <p class="text-gray-300"><strong>Definition 3.2.</strong> Let A, B be algorithms and x, y strings. We denote by View  <span class="math">\\langle B(y), A(x) \\rangle</span>  the <strong>view</strong> of A(x) in an interactive oracle protocol with B(y), i.e., the random variable  <span class="math">(x, r, a_1, \\ldots, a_n)</span>  where x is A's input, r is A's randomness, and  <span class="math">a_1, \\ldots, a_n</span>  are the answers to A's queries into B's messages.</p>

    <p class="text-gray-300">Straightline simulators in the context of IPs were used in [FS89], and later defined in [DS98]. The definition below considers this notion in the context of IOPs, where the simulator also has to answer oracle queries by the verifier. Note that since we consider the notion of unconditional (perfect) zero knowledge, the definition of straightline simulation needs to allow the efficient simulator to work even with inefficient verifiers [GIMS10].</p>

    <p class="text-gray-300"><strong>Definition 3.3.</strong> We say that an algorithm B has <strong>straightline access</strong> to another algorithm A if B interacts with A, without rewinding, by exchanging messages with A and also answering any oracle queries along the way. We denote by  <span class="math">B^A</span>  the concatenation of A's random tape and B's output. (Since A's random tape could be super-polynomially large, B cannot sample it for A and then output it; instead, we restrict B to not see it, and we prepend it to B's output.)</p>

    <p class="text-gray-300">Recall that an algorithm A is b-query if, on input x, it makes at most b(|x|) queries to any oracles it has access to. We are now ready to define zero knowledge IOPs.</p>

    <p class="text-gray-300"><strong>Definition 3.4.</strong> An IOP system (P,V) for a relation  <span class="math">\\mathscr{R}</span>  is perfect zero knowledge (via straightline simulators) against unbounded queries (resp., against query bound b) if there exists a simulator algorithm S such that for every algorithm (resp., b-query algorithm)  <span class="math">\\tilde{V}</span>  and instance-witness pair  <span class="math">(x, w) \\in \\mathscr{R}</span> ,  <span class="math">S^{\\tilde{V}}(x)</span>  and View  <span class="math">\\langle P(x, w), \\tilde{V}(x) \\rangle</span>  are identically distributed. Moreover, S must run in time  <span class="math">poly(|x| + q_{\\tilde{V}}(|x|))</span> , where  <span class="math">q_{\\tilde{V}}(\\cdot)</span>  is  <span class="math">\\tilde{V}</span> 's query complexity.</p>

    <p class="text-gray-300">For zero knowledge against arbitrary polynomial-time adversaries, it suffices for b to be superpolynomial. Note that S's running time need not be polynomial in b (in our constructions it is polylogarithmic in b); rather its running time may be polynomial in the input size  <span class="math">|\\mathbf{x}|</span>  and the <em>actual</em> number of queries  <span class="math">\\tilde{V}</span>  makes (as a random variable).</p>

    <p class="text-gray-300">We say that a relation  <span class="math">\\mathscr{R}</span>  belongs to the complexity class <strong>PZK-IOP</strong>[k, l, q,  <span class="math">\\varepsilon</span> , tp, tv, b] if there is an IOP system for  <span class="math">\\mathscr{R}</span> , with the corresponding parameters, that is perfect zero knowledge with query bound b; also, it belongs to the complexity class <strong>PZK-IOP</strong>[k, l, q,  <span class="math">\\varepsilon</span> , tp, tv, *] if the same is true with unbounded queries.</p>

      <h4 id="sec-3.3.2" class="text-lg font-semibold mt-6">3.3.2 ZK for IOPs of proximity</h4>

    <p class="text-gray-300">We define zero knowledge (via straightline simulators) for IOPs of proximity. It is a straightforward extension of the corresponding notion for PCPs of proximity, introduced in [IW14].</p>

    <p class="text-gray-300"><strong>Definition 3.5.</strong> An IOPP system (P, V) for a relation  <span class="math">\\mathcal{R}</span>  is perfect zero knowledge (via straightline simulators) against unbounded queries (resp., against query bound b) if there exists a simulator algorithm S such that for every algorithm (resp., b-query algorithm)  <span class="math">\\tilde{V}</span>  and instance-witness pair  <span class="math">(x, w) \\in \\mathcal{R}</span> , the following two random variables are identically distributed:</p>

    <p class="text-gray-300"><span class="math">$\\left(S^{\\tilde{V},\\mathsf{w}}(\\mathsf{x})\\;,\\;q_S\\right)</span>$
and  <span class="math">\\left(\\mathrm{View}\\;\\langle P(\\mathsf{x},\\mathsf{w}),\\tilde{V}^{\\mathsf{w}}(\\mathsf{x})\\rangle\\;,\\;q_{\\tilde{V}}\\right)\\;,</span></p>

    <p class="text-gray-300">where  <span class="math">q_S</span>  is the number of queries to w made by S, and  <span class="math">q_{\\tilde{V}}</span>  is the number of queries to w or to prover messages made by  <span class="math">\\tilde{V}</span> . Moreover, S must run in time  <span class="math">\\operatorname{poly}(|x| + q_{\\tilde{V}}(|x|))</span> , where  <span class="math">q_{\\tilde{V}}(\\cdot)</span>  is  <span class="math">\\tilde{V}</span> 's query complexity.</p>

    <p class="text-gray-300">We say that a relation  <span class="math">\\mathscr{R}</span>  belongs to the complexity class <strong>PZK-IOPP</strong>[k, l, q,  <span class="math">\\varepsilon</span> ,  <span class="math">\\delta</span> , tp, tv, b] if there is an IOPP system for  <span class="math">\\mathscr{R}</span> , with the corresponding parameters, that is perfect zero knowledge with query bound b; also, it belongs to the complexity class <strong>PZK-IOPP</strong>[k, l, q,  <span class="math">\\varepsilon</span> ,  <span class="math">\\delta</span> , tp, tv, *] if the same is true with unbounded queries.</p>

    <p class="text-gray-300"><strong>Remark 3.6.</strong> Analogously to [IW14], our definition of zero knowledge for IOPs of proximity requires that the number of queries to w by S equals the total number of queries (to w or prover messages) by  <span class="math">\\tilde{V}</span> . Stronger notions are possible: &quot;the number of queries to w by  <span class="math">\\tilde{V}</span> &quot;; or, even more, &quot;S and  <span class="math">\\tilde{V}</span>  read the same locations of w&quot;. The definition above is sufficient for the applications of IOPs of proximity that we consider.</p>

      <h4 id="sec-3.3.3" class="text-lg font-semibold mt-6">3.3.3 ZK for IPCPs</h4>

    <p class="text-gray-300">The definition of perfect zero knowledge (via straightline simulators) for IPCPs follows directly from Definition 3.4 in Section 3.3.1 because IPCPs are a special case of IOPs. Ditto for IPCPs of proximity, whose perfect zero knowledge definition follows directly from Definition 3.5 in Section 3.3.2. (For comparison, [GIMS10] define statistical zero knowledge IPCPs, also with straightline simulators.)</p>

      <h3 id="sec-3.4" class="text-xl font-semibold mt-8">3.4 Codes</h3>

    <p class="text-gray-300">An error correcting code C is a set of functions  <span class="math">w\\colon D\\to \\Sigma</span> , where  <span class="math">D,\\Sigma</span>  are finite sets known as the domain and alphabet; we write  <span class="math">C\\subseteq \\Sigma^D</span> . The message length of C is  <span class="math">k:=\\log_{|\\Sigma|}|C|</span> , its block length is  <span class="math">\\ell:=|D|</span> , its rate is  <span class="math">\\rho:=k/\\ell</span> , its (minimum) distance is  <span class="math">d:=\\min\\{\\Delta(w,z):w,z\\in C,w\\neq z\\}</span>  when  <span class="math">\\Delta</span>  is the (absolute) Hamming distance, and its (minimum) relative distance is  <span class="math">\\tau:=d/\\ell</span> . At times we write  <span class="math">k(C),\\ell(C),\\rho(C),d(C),\\tau(C)</span>  to make the code under consideration explicit. All the codes we consider are linear codes, discussed next.</p>

    <p class="text-gray-300"><strong>Linearity.</strong> A code C is linear if  <span class="math">\\Sigma</span>  is a finite field and C is a  <span class="math">\\Sigma</span> -linear space in  <span class="math">\\Sigma^D</span> . The dual code of C is the set  <span class="math">C^{\\perp}</span>  of functions  <span class="math">z \\colon D \\to \\Sigma</span>  such that, for all  <span class="math">w \\colon D \\to \\Sigma</span> ,  <span class="math">\\langle z, w \\rangle := \\sum_{i \\in D} z(i)w(i) = 0</span> . We denote by  <span class="math">\\dim(C)</span>  the dimension of C; it holds that  <span class="math">\\dim(C) + \\dim(C^{\\perp}) = \\ell</span>  and  <span class="math">\\dim(C) = k</span>  (dimension equals message length).</p>

    <p class="text-gray-300"><strong>Code families.</strong> A code family  <span class="math">\\mathscr{C} = \\{C_{\\mathfrak{n}}\\}_{\\mathfrak{n} \\in \\{0,1\\}^*}</span>  has domain  <span class="math">D(\\cdot)</span>  and alphabet  <span class="math">\\mathbb{F}(\\cdot)</span>  if each code  <span class="math">C_{\\mathfrak{n}}</span>  has domain  <span class="math">D(\\mathfrak{n})</span>  and alphabet  <span class="math">\\mathbb{F}(\\mathfrak{n})</span> . Similarly,  <span class="math">\\mathscr{C}</span>  has message length  <span class="math">k(\\cdot)</span> , block length  <span class="math">\\ell(\\cdot)</span> , rate  <span class="math">\\rho(\\cdot)</span> , distance  <span class="math">d(\\cdot)</span> , and relative distance  <span class="math">\\tau(\\cdot)</span>  if each code  <span class="math">C_{\\mathfrak{n}}</span>  has message length  <span class="math">k(\\mathfrak{n})</span> , block length  <span class="math">\\ell(\\mathfrak{n})</span> , rate  <span class="math">\\rho(\\mathfrak{n})</span> , distance  <span class="math">d(\\mathfrak{n})</span> , and relative distance  <span class="math">\\tau(\\mathfrak{n})</span> . We also define  <span class="math">\\rho(\\mathscr{C}) := \\inf_{\\mathfrak{n} \\in \\mathbb{N}} \\rho(\\mathfrak{n})</span>  and  <span class="math">\\tau(\\mathscr{C}) := \\inf_{\\mathfrak{n} \\in \\mathbb{N}} \\tau(\\mathfrak{n})</span> .</p>

    <p class="text-gray-300"><strong>Reed&ndash;Solomon codes.</strong> The Reed&ndash;Solomon (RS) code is the code consisting of evaluations of <em>univariate</em> low-degree polynomials: given a field  <span class="math">\\mathbb{F}</span> , subset S of  <span class="math">\\mathbb{F}</span> , and positive integer d with  <span class="math">d \\leq |S|</span> , we denote by  <span class="math">RS[\\mathbb{F}, S, d]</span>  the linear</p>

    <p class="text-gray-300">code consisting of evaluations  <span class="math">w\\colon S\\to \\mathbb{F}</span>  over S of polynomials in  <span class="math">\\mathbb{F}^{&lt; d}[X]</span> . The code's message length is k=d, block length is  <span class="math">\\ell=|S|</span> , rate is  <span class="math">\\rho=\\frac{d}{|S|}</span> , and relative distance is  <span class="math">\\tau=1-\\frac{d-1}{|S|}</span> .</p>

    <p class="text-gray-300"><strong>Reed&ndash;Muller codes.</strong> The Reed&ndash;Muller (RM) code is the code consisting of evaluations of <em>multivariate</em> low-degree polynomials: given a field  <span class="math">\\mathbb{F}</span> , subset S of  <span class="math">\\mathbb{F}</span> , and positive integers m,d with  <span class="math">d \\leq |S|</span> , we denote by  <span class="math">\\mathrm{RM}[\\mathbb{F},S,m,d]</span>  the linear code consisting of evaluations  <span class="math">w\\colon S^m \\to \\mathbb{F}</span>  over  <span class="math">S^m</span>  of polynomials in  <span class="math">\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span>  (i.e., we bound individual degrees rather than their sum). The code's message length is  <span class="math">k=d^m</span> , block length is  <span class="math">\\ell=|S|^m</span> , rate is  <span class="math">\\rho=(\\frac{d}{|S|})^m</span> , and relative distance is  <span class="math">\\tau=(1-\\frac{d-1}{|S|})^m</span> .</p>

    </section>

    <section id="sec-4" class="mb-10">
      <h2 class="text-2xl font-bold">4 Succinct constraint detection</h2>

    <p class="text-gray-300">We introduce the notion of <em>succinct constraint detection</em> for linear codes. This notion plays a crucial role in constructing perfect zero knowledge simulators for super-polynomial complexity classes (such as  <span class="math">\\#\\mathbf{P}</span>  and  <span class="math">\\mathbf{NEXP}</span> ), but we believe that this naturally-defined notion is also of independent interest. Given a linear code  <span class="math">C \\subseteq \\mathbb{F}^D</span>  we refer to its dual code  <span class="math">C^{\\perp} \\subseteq \\mathbb{F}^D</span>  as the <em>constraint space</em> of C. The <em>constraint detection problem</em> corresponding to a family of linear codes  <span class="math">\\mathscr{C} = \\{C_n\\}_n</span>  with domain  <span class="math">D(\\cdot)</span>  and alphabet  <span class="math">\\mathbb{F}(\\cdot)</span>  is the following:</p>

    <p class="text-gray-300">Given an index
<span class="math">$n</span>$
and subset  <span class="math">I \\subseteq D(n)</span> , output a basis for  <span class="math">\\{z \\in D(n)^I : \\forall w \\in C_n, \\sum_{i \\in I} z(i)w(i) = 0\\}</span> .</p>

    <p class="text-gray-300">If  <span class="math">|D(\\mathfrak{m})|</span>  is polynomial in  <span class="math">|\\mathfrak{m}|</span>  and a generating matrix for  <span class="math">C_\\mathfrak{m}</span>  can be found in polynomial time, this problem can be solved in  <span class="math">\\operatorname{poly}(|\\mathfrak{m}|+|I|)</span>  time via Gaussian elimination; such an approach was implicitly taken by [BCGV16] to construct a perfect zero knowledge simulator for an IOP for NP. However, in our setting,  <span class="math">|D(\\mathfrak{m})|</span>  is <em>exponential</em> in  <span class="math">|\\mathfrak{m}|</span>  and |I|, and the aforementioned generic solution requires exponential time. With this in mind, we say  <span class="math">\\mathscr C</span>  has <em>succinct constraint detection</em> if there exists an algorithm that solves the constraint detection problem in  <span class="math">\\operatorname{poly}(|\\mathfrak{m}|+|I|)</span>  time when  <span class="math">|D(\\mathfrak{m})|</span>  is <em>exponential</em> in  <span class="math">|\\mathfrak{m}|</span> . After defining succinct constraint detection in Section 4.1, we proceed as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>In Section 4.2, we construct a succinct constraint detector for the family of linear codes comprised of evaluations of partial sums of low-degree polynomials. The construction of the detector exploits derandomization techniques from algebraic complexity theory. Later on (in Section 5), we leverage this result to construct a perfect zero knowledge simulator for an IPCP for #P.</li>
      <li>In Section 4.3, we construct a succinct constraint detector for the family of evaluations of univariate polynomials concatenated with corresponding BS proximity proofs [BS08]. The construction of the detector exploits the recursive structure of these proximity proofs. Later on (in Section 8), we leverage this result to construct a perfect zero knowledge simulator for an IOP for NEXP; this simulator can be interpreted as an analogue of [BCGV16]'s simulator that runs exponentially faster and thus enables us to &quot;scale up&quot; from NP to NEXP.</li>
    </ul>

    <p class="text-gray-300">Throughout this section we assume familiarity with terminology and notation about codes, introduced in Section 3.4. We assume for simplicity that  <span class="math">|\\mathfrak{n}|</span> , the number of bits used to represent  <span class="math">\\mathfrak{n}</span> , is at least  <span class="math">\\log D(\\mathfrak{n}) + \\log \\mathbb{F}(\\mathfrak{n})</span> ; if this does not hold, then one can replace  <span class="math">|\\mathfrak{n}|</span>  with  <span class="math">|\\mathfrak{n}| + \\log D(\\mathfrak{n}) + \\log \\mathbb{F}(\\mathfrak{n})</span>  throughout the section.</p>

    <p class="text-gray-300">Remark 4.1 (sparse representation). In this section we make statements about vectors v in  <span class="math">\\mathbb{F}^D</span>  where the cardinality of the domain D may be super-polynomial. When such statements are computational in nature, we assume that v is not represented as a list of |D| field elements (which requires  <span class="math">\\Omega(|D|\\log|\\mathbb{F}|)</span>  bits) but, instead, assume that v is represented as a list of the elements in  <span class="math">\\operatorname{supp}(v)</span>  (and each element comes with its index in D); this <em>sparse</em> representation only requires  <span class="math">\\Omega(|\\sup(v)| \\cdot (\\log|D| + \\log|\\mathbb{F}|))</span>  bits.</p>

      <h3 id="sec-4.1" class="text-xl font-semibold mt-8">4.1 Definition of succinct constraint detection</h3>

    <p class="text-gray-300">Formally define the notion of a constraint detector, and the notion of succinct constraint detection.</p>

    <p class="text-gray-300"><strong>Definition 4.2.</strong> Let  <span class="math">\\mathscr{C} = \\{C_n\\}_n</span>  be a linear code family with domain  <span class="math">D(\\cdot)</span>  and alphabet  <span class="math">\\mathbb{F}(\\cdot)</span> . A <strong>constraint detector</strong> for  <span class="math">\\mathscr{C}</span>  is an algorithm that, on input an index  <span class="math">\\mathbb{n}</span>  and subset  <span class="math">I \\subseteq D(\\mathbb{n})</span> , outputs a basis for the space</p>

    <p class="text-gray-300"><span class="math">$\\left\\{z \\in D(\\mathfrak{n})^I: \\, \\forall \\, w \\in C_{\\mathfrak{n}} \\, , \\sum_{i \\in I} z(i)w(i) \\right\\} \\, \\, .</span>$</p>

    <p class="text-gray-300">We say that  <span class="math">\\mathscr C</span>  has  <span class="math">T(\\cdot,\\cdot)</span> -time constraint detection if there exists a detector for  <span class="math">\\mathscr C</span>  running in time  <span class="math">T(\\mathfrak n,\\ell)</span> ; we also say that  <span class="math">\\mathscr C</span>  has succinct constraint detection if it has  <span class="math">\\operatorname{poly}(|\\mathfrak n|+\\ell)</span> -time constraint detection.</p>

    <p class="text-gray-300">A constraint detector induces a corresponding probabilistic algorithm for 'simulating' answers to queries to a random codeword; this is captured by the following lemma, the proof of which is in Appendix B. We shall use such probabilistic algorithms in the construction of perfect zero knowledge simulators (see Section 5 and Section 8).</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;5</sup>In fact, the following weaker definition suffices for the applications in our paper: given an index n and subset  <span class="math">I \\subseteq D(n)</span> , output  <span class="math">z \\in \\mathbb{F}(n)^I</span>  such that  <span class="math">\\sum_{i \\in I} z(i)w(i) = 0</span>  for all  <span class="math">w \\in C_n</span> , or 'independent' if no such z exists. We achieve the stronger definition, which is also easier to work with.</p>

    <p class="text-gray-300"><strong>Lemma 4.3.</strong> Let  <span class="math">\\mathscr{C} = \\{C_{\\mathfrak{n}}\\}_{\\mathfrak{n}}</span>  be a linear code family with domain  <span class="math">D(\\cdot)</span>  and alphabet  <span class="math">\\mathbb{F}(\\cdot)</span>  that has  <span class="math">T(\\cdot, \\cdot)</span> -time constraint detection. Then there exists a probabilistic algorithm  <span class="math">\\mathcal{A}</span>  such that, for every index  <span class="math">\\mathfrak{m}</span> , set of pairs  <span class="math">S = \\{(\\alpha_1, \\beta_1), \\ldots, (\\alpha_\\ell, \\beta_\\ell)\\} \\subseteq D(\\mathfrak{m}) \\times \\mathbb{F}(\\mathfrak{m})</span> , and pair  <span class="math">(\\alpha, \\beta) \\in D(\\mathfrak{m}) \\times \\mathbb{F}(\\mathfrak{m})</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[\\mathcal{A}(\\mathbf{m}, S, \\alpha) = \\beta\\right] = \\Pr_{w \\leftarrow C_{\\mathbf{n}}} \\left[ w(\\alpha) = \\beta \\middle| \\begin{array}{c} w(\\alpha_{1}) = \\beta_{1} \\\\ \\vdots \\\\ w(\\alpha_{\\ell}) = \\beta_{\\ell} \\end{array} \\right].</span>$</p>

    <p class="text-gray-300"><em>Moreover</em> A <em>runs in time</em>  <span class="math">T(\\mathfrak{n},\\ell) + \\operatorname{poly}(\\log |\\mathbb{F}(\\mathfrak{n})| + \\ell)</span> .</p>

    <p class="text-gray-300">For the purposes of <em>constructing</em> a constraint detector, the sufficient condition given in Lemma 4.6 below is sometimes easier to work with. To state it we need to introduce two ways of restricting a code, and explain how these restrictions interact with taking duals; the interplay between these is delicate (see Remark 4.7).</p>

    <p class="text-gray-300"><strong>Definition 4.4.</strong> Given a linear code  <span class="math">C \\subseteq \\mathbb{F}^D</span>  and a subset  <span class="math">I \\subseteq D</span> , we denote by (i)  <span class="math">C_{\\subseteq I}</span>  the set consisting of the codewords  <span class="math">w \\in C</span>  for which  <span class="math">\\operatorname{supp}(w) \\subseteq I</span> , and (ii)  <span class="math">C|_I</span>  the restriction to I of codewords  <span class="math">w \\in C</span> .</p>

    <p class="text-gray-300">Note that  <span class="math">C_{\\subseteq I}</span>  and  <span class="math">C|_I</span>  are different notions. Consider for example the 1-dimensional linear code  <span class="math">C=\\{00,11\\}</span>  in  <span class="math">\\mathbb{F}_2^{\\{1,2\\}}</span>  and the subset  <span class="math">I=\\{1\\}</span> : it holds that  <span class="math">C_{\\subseteq I}=\\{00\\}</span>  and  <span class="math">C|_I=\\{0,1\\}</span> . In particular, codewords in  <span class="math">C_{\\subseteq I}</span>  are defined over D, while codewords in  <span class="math">C|_I</span>  are defined over I. Nevertheless, throughout this section, we sometimes compare vectors defined over different domains, with the implicit understanding that the comparison is conducted over the union of the relevant domains, by filling in zeros in the vectors' undefined coordinates. For example, we may write  <span class="math">C_{\\subseteq I} \\subseteq C|_I</span>  to mean that  <span class="math">\\{00\\} \\subseteq \\{00,10\\}</span>  (the set obtained from  <span class="math">\\{0,1\\}</span>  after filling in the relevant zeros).</p>

    <p class="text-gray-300"><strong>Claim 4.5.</strong> Let C be a linear code with domain D and alphabet  <span class="math">\\mathbb{F}</span> . For every  <span class="math">I \\subseteq D</span> ,</p>

    <p class="text-gray-300"><span class="math">$(C|_I)^{\\perp} = (C^{\\perp})_{\\subset I} ,</span>$</p>

    <p class="text-gray-300">that is,</p>

    <p class="text-gray-300"><span class="math">$\\left\\{z \\in D(\\mathfrak{n})^I : \\forall w \\in C_{\\mathfrak{n}}, \\sum_{i \\in I} z(i)w(i)\\right\\} = \\left\\{z \\in C_{\\mathfrak{n}}^{\\perp} : \\operatorname{supp}(z) \\subseteq I\\right\\} \\ .</span>$</p>

    <p class="text-gray-300"><em>Proof.</em> For the containment  <span class="math">(C^{\\perp})_{\\subseteq I} \\subseteq (C|_I)^{\\perp}</span> : if  <span class="math">z \\in C^{\\perp}</span>  and  <span class="math">\\operatorname{supp}(z) \\subseteq I</span>  then z lies in the dual of  <span class="math">C|_I</span>  because it suffices to consider the subdomain I for determining duality. For the reverse containment  <span class="math">(C^{\\perp})_{\\subseteq I} \\supseteq (C|_I)^{\\perp}</span> : if  <span class="math">z \\in (C|_I)^{\\perp}</span>  then  <span class="math">\\operatorname{supp}(z) \\subseteq I</span>  (by definition) so that  <span class="math">\\langle z, w \\rangle = \\langle z, w|_I \\rangle</span>  for every  <span class="math">w \\in C</span> , and the latter inner product equals 0 because z is in the dual of  <span class="math">C|_I</span> ; in sum z is dual to (all codewords in) C and its support is contained in I, so z belongs to  <span class="math">(C^{\\perp})_{\\subseteq I}</span> , as claimed.</p>

    <p class="text-gray-300">Observe that Claim 4.5 tells us the constraint detection is equivalent to determining a basis of  <span class="math">(C_n|_I)^{\\perp} = (C_n^{\\perp})_{\\subseteq I}</span> . The following lemma asserts that if, given a subset  <span class="math">I \\subseteq D</span> , we can find a set of constraints W in  <span class="math">C^{\\perp}</span>  that spans  <span class="math">(C^{\\perp})_{\\subseteq I}</span>  then we can solve the constraint detection problem for C; we defer the proof of the lemma to Appendix C.</p>

    <p class="text-gray-300"><strong>Lemma 4.6.</strong> Let  <span class="math">\\mathscr{C} = \\{C_{\\mathfrak{n}}\\}_{\\mathfrak{n}}</span>  be a linear code family with domain  <span class="math">D(\\cdot)</span>  and alphabet  <span class="math">\\mathbb{F}(\\cdot)</span> . If there exists an algorithm that, on input an index  <span class="math">\\mathfrak{n}</span>  and subset  <span class="math">I \\subseteq D(\\mathfrak{n})</span> , outputs in  <span class="math">\\operatorname{poly}(|\\mathfrak{n}| + |I|)</span>  time a subset  <span class="math">W \\subseteq \\mathbb{F}(\\mathfrak{n})^{D(\\mathfrak{n})}</span>  (in sparse representation) with  <span class="math">(C_{\\mathfrak{n}}^{\\perp})_{\\subseteq I} \\subseteq \\operatorname{span}(W) \\subseteq C_{\\mathfrak{n}}^{\\perp}</span> , then  <span class="math">\\mathscr{C}</span>  has succinct constraint detection.</p>

    <p class="text-gray-300"><strong>Remark 4.7.</strong> The following operations do <em>not</em> commute: (i) expanding the domain via zero padding (for the purpose of comparing vectors over different domains), and (ii) taking the dual of the code. Consider for example the code  <span class="math">C = \\{0\\} \\subseteq \\mathbb{F}_2^{\\{1\\}}</span> : its dual code is  <span class="math">C^{\\perp} = \\{0,1\\}</span>  and, when expanded to  <span class="math">\\mathbb{F}_2^{\\{1,2\\}}</span> , the dual code is expanded to  <span class="math">\\{(0,0),(1,0)\\}</span> ; yet, when C is expanded to  <span class="math">\\mathbb{F}_2^{\\{1,2\\}}</span>  it produces the code  <span class="math">\\{(0,0)\\}</span>  and its dual code is  <span class="math">\\{(0,0),(1,0),(0,1),(1,1)\\}</span> . To resolve ambiguities (when asserting an equality as in Claim 4.5), we adopt the convention that expansion is done <em>always last</em> (namely, as late as possible without having to compare vectors over different domains).</p>

      <h3 id="sec-4.2" class="text-xl font-semibold mt-8">4.2 Partial sums of low-degree polynomials</h3>

    <p class="text-gray-300">We show that evaluations of partial sums of low-degree polynomials have succinct constraint detection (see Definition 4.2). In the following,  <span class="math">\\mathbb{F}</span>  is a finite field, m,d are positive integers, and H is a subset of  <span class="math">\\mathbb{F}</span> ; also,  <span class="math">\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span>  denotes the subspace of  <span class="math">\\mathbb{F}[X_1,\\ldots,X_m]</span>  consisting of those polynomials with individual degrees less than d. Moreover, given  <span class="math">Q \\in \\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span>  and  <span class="math">\\vec{\\alpha} \\in \\mathbb{F}^{\\le m}</span>  (vectors over  <span class="math">\\mathbb{F}</span>  of length at most m), we define  <span class="math">Q(\\vec{\\alpha}) := \\sum_{\\vec{\\gamma} \\in H^{m-|\\vec{\\alpha}|}} Q(\\vec{\\alpha},\\vec{\\gamma})</span> , i.e., the answer to a query that specifies only a suffix of the variables is the sum of the values obtained by letting the remaining variables range over H. We begin by defining the code that we study, which extends the Reed-Muller code (see Section 3.4) with partial sums.</p>

    <p class="text-gray-300"><strong>Definition 4.8.</strong> We denote by  <span class="math">\\Sigma \\mathrm{RM}[\\mathbb{F}, m, d, H]</span>  the linear code that comprises evaluations of partial sums of polynomials in  <span class="math">\\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span> ; more precisely,  <span class="math">\\Sigma \\mathrm{RM}[\\mathbb{F}, m, d, H] := \\{w_Q\\}_{Q \\in \\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]}</span>  where  <span class="math">w_Q \\colon \\mathbb{F}^{\\le m} \\to \\mathbb{F}</span>  is the function defined by  <span class="math">w_Q(\\vec{\\alpha}) := \\sum_{\\vec{\\gamma} \\in H^{m-|\\vec{\\alpha}|}} Q(\\vec{\\alpha}, \\vec{\\gamma})</span>  for each  <span class="math">\\vec{\\alpha} \\in \\mathbb{F}^{\\le m}</span> . We denote by  <span class="math">\\Sigma \\mathrm{RM}</span>  the linear code family indexed by tuples  <span class="math">\\mathfrak{n} = (\\mathbb{F}, m, d, H)</span>  and where the  <span class="math">\\mathfrak{n}</span> -th code equals  <span class="math">\\Sigma \\mathrm{RM}[\\mathbb{F}, m, d, H]</span> . (We represent indices  <span class="math">\\mathfrak{n}</span>  so to ensure that  <span class="math">|\\mathfrak{n}| = \\Theta(\\log |\\mathbb{F}| + m + d + |H|)</span> .)</p>

    <p class="text-gray-300">We prove that the linear code family  <span class="math">\\Sigma RM</span>  has succinct constraint detection:</p>

    <p class="text-gray-300"><strong>Theorem 4.9</strong> (formal statement of 1.5).  <span class="math">\\Sigma RM</span>  has poly( <span class="math">\\log |\\mathbb{F}| + m + d + |H| + \\ell</span> )-time constraint detection.</p>

    <p class="text-gray-300">Combined with Lemma 4.3, the theorem above implies that there exists a probabilistic polynomial-time algorithm for answering queries to a codeword sampled at random from  <span class="math">\\Sigma RM</span> , as captured by the following corollary.</p>

    <p class="text-gray-300"><strong>Corollary 4.10.</strong> There exists a probabilistic algorithm  <span class="math">\\mathcal{A}</span>  such that, for every finite field  <span class="math">\\mathbb{F}</span> , positive integers m, d, subset H of  <span class="math">\\mathbb{F}</span> , subset  <span class="math">S = \\{(\\alpha_1, \\beta_1), \\ldots, (\\alpha_\\ell, \\beta_\\ell)\\} \\subseteq \\mathbb{F}^{\\leq m} \\times \\mathbb{F}</span> , and  <span class="math">(\\alpha, \\beta) \\in \\mathbb{F}^{\\leq m} \\times \\mathbb{F}</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[\\mathcal{A}(\\mathbb{F}, m, d, H, S, \\alpha) = \\beta\\right] = \\Pr_{R \\leftarrow \\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]} \\left[ R(\\alpha) = \\beta \\middle| \\begin{array}{c} R(\\alpha_1) = \\beta_1 \\\\ \\vdots \\\\ R(\\alpha_\\ell) = \\beta_\\ell \\end{array} \\right] .</span>$</p>

    <p class="text-gray-300"><em>Moreover A runs in time</em> poly(log  <span class="math">|\\mathbb{F}| + m + d + |H| + \\ell</span> ).</p>

    <p class="text-gray-300">We sketch the proof of Theorem 4.9, for the simpler case where the code is  <span class="math">\\mathrm{RM}[\\mathbb{F},m,d,H]</span>  (i.e., without partial sums). We can view a polynomial  <span class="math">Q \\in \\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span>  as a vector over the monomial basis, with an entry for each possible monomial  <span class="math">X_1^{i_1}\\ldots X_m^{i_m}</span>  (with  <span class="math">0\\leq i_1,\\ldots,i_m&lt; d</span> ) containing the corresponding coefficient. The evaluation of Q at a point  <span class="math">\\vec{\\alpha}\\in\\mathbb{F}^m</span>  then equals the inner product of this vector with the vector  <span class="math">\\phi_{\\vec{\\alpha}}</span> , in the same basis, whose entry for  <span class="math">X_1^{i_1}\\ldots X_m^{i_m}</span>  is equal to  <span class="math">\\alpha_1^{i_1}\\ldots \\alpha_m^{i_m}</span> . Given  <span class="math">\\vec{\\alpha}_1,\\ldots,\\vec{\\alpha}_\\ell</span> , we could use Gaussian elimination on  <span class="math">\\phi_{\\vec{\\alpha}_1},\\ldots,\\phi_{\\vec{\\alpha}_\\ell}</span>  to check for linear dependencies, which would be equivalent to constraint detection for  <span class="math">\\mathrm{RM}[\\mathbb{F},m,d,H]</span> .</p>

    <p class="text-gray-300">However, we cannot afford to explicitly write down  <span class="math">\\phi_{\\vec{\\alpha}}</span> , because it has  <span class="math">d^m</span>  entries. Nevertheless, we can still implicitly check for linear dependencies, and we do so by reducing the problem, by building on and extending ideas of [BW04], to computing the nullspace of a certain set of polynomials, which can be solved via an algorithm of [RS05] (see also [Kay10]). The idea is to encode the entries of these vectors via a succinct description: a polynomial  <span class="math">\\Phi_{\\vec{\\alpha}}</span>  whose coefficients (after expansion) are the entries of  <span class="math">\\phi_{\\vec{\\alpha}}</span> . In our setting this polynomial has the particularly natural form:</p>

    <p class="text-gray-300"><span class="math">$\\Phi_{\\vec{\\alpha}}(\\vec{X}) := \\prod_{i=1}^{m} (1 + \\alpha_i X_i + \\alpha_i^2 X_i^2 + \\dots + \\alpha_i^{d-1} X_i^{d-1}) ;</span>$</p>

    <p class="text-gray-300">note that the coefficient of each monomial equals its corresponding entry in  <span class="math">\\phi_{\\vec{\\alpha}}</span> . Given this representation we can use standard polynomial identity testing techniques to find linear dependencies between these polynomials, which corresponds to linear dependencies between the original vectors. Crucially, we cannot afford any mistake, even with exponentially small probability, when looking for linear dependencies for otherwise we would not achieve perfect simulation; this is why the techniques we leverage rely on derandomization. We now proceed with the full proof.</p>

    <p class="text-gray-300"> <span class="math">&lt;sup&gt;^{6} \\&lt;/sup&gt;text{Note that } \\Sigma \\text{RM}[\\mathbb{F}, m, d, H] \\text{ is indeed linear: for every } w_{Q_{1}}, w_{Q_{2}} \\in \\Sigma \\text{RM}[\\mathbb{F}, m, d, H], a_{1}, a_{2} \\in \\mathbb{F}, \\text{ and } \\vec{\\alpha} \\in \\mathbb{F}^{\\leq m}, \\text{ it holds that } a_{1}w_{Q_{1}}(\\vec{\\alpha}) + a_{2}w_{Q_{2}}(\\vec{\\alpha}) = a_{1}\\sum_{\\vec{\\gamma} \\in H^{m-|\\vec{\\alpha}|}}Q_{1}(\\vec{\\alpha}, \\vec{\\gamma}) + a_{2}\\sum_{\\vec{\\gamma} \\in H^{m-|\\vec{\\alpha}|}}Q_{2}(\\vec{\\alpha}, \\vec{\\gamma}) = \\sum_{\\vec{\\gamma} \\in H^{m-|\\vec{\\alpha}|}}(a_{1}Q_{1} + a_{2}Q_{2})(\\vec{\\alpha}, \\vec{\\gamma}) = w_{a_{1}Q_{1} + a_{2}Q_{2}}(\\vec{\\alpha}). \\text{ But } w_{a_{1}Q_{1} + a_{2}Q_{2}} \\in \\Sigma \\text{RM}[\\mathbb{F}, m, d, H], \\text{ since } \\mathbb{F}^{&lt;d}[X_{1}, \\ldots, X_{m}] \\text{ is a linear space.}</span></p>

    <p class="text-gray-300"><em>Proof of Theorem 4.9.</em> We first introduce some notation. Define  <span class="math">[&lt; d] := \\{0, \\dots, d-1\\}</span> . For vectors  <span class="math">\\vec{\\alpha} \\in \\mathbb{F}^m</span>  and  <span class="math">\\vec{a} \\in [&lt; d]^m</span> , we define  <span class="math">\\vec{\\alpha}^{\\vec{a}} := \\prod_{i=1}^m \\alpha_i^{a_i}</span> ; similarly, for variables  <span class="math">\\vec{X} = (X_1, \\dots, X_m)</span> , we define  <span class="math">\\vec{X}^{\\vec{a}} := \\prod_{i=1}^m X_i^{a_i}</span> .</p>

    <p class="text-gray-300">We identify  <span class="math">\\Sigma \\text{RM}[\\mathbb{F}, m, d, H]</span>  with  <span class="math">\\mathbb{F}^{[&lt; d]^m}</span> ; a codeword  <span class="math">w_Q</span>  then corresponds to a vector  <span class="math">\\vec{Q}</span>  whose  <span class="math">\\vec{a}</span> -th entry is the coefficient of the monomial  <span class="math">\\vec{X}^{\\vec{a}}</span>  in Q. For  <span class="math">\\vec{\\alpha} \\in \\mathbb{F}^{\\leq m}</span> , let</p>

    <p class="text-gray-300"><span class="math">$\\phi_{\\vec{\\alpha}} := \\left( \\vec{\\alpha}^{\\vec{a}} \\sum_{\\vec{\\gamma} \\in H^{m-|\\vec{\\alpha}|} \\vec{\\gamma}^{\\vec{b}} \\right)_{\\vec{a} \\in [</span>$</p>

    <p class="text-gray-300">We can also view  <span class="math">\\phi_{\\vec{\\alpha}}</span>  as a vector in  <span class="math">\\mathbb{F}^{[\\leq d]^m}</span>  by merging the indices, so that, for all  <span class="math">\\vec{\\alpha} \\in \\mathbb{F}^{\\leq m}</span>  and  <span class="math">w_Q \\in \\Sigma RM[\\mathbb{F}, m, d, H]</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} w_Q(\\vec{\\alpha}) &amp;= \\sum_{\\vec{\\gamma} \\in H^{m-|\\vec{\\alpha}|}} Q(\\vec{\\alpha}, \\vec{\\gamma}) = \\sum_{\\vec{\\gamma} \\in H^{m-|\\vec{\\alpha}|}} \\sum_{\\vec{a} \\in [</span>$</p>

    <p class="text-gray-300">Hence for every  <span class="math">\\vec{\\alpha}_1,\\ldots,\\vec{\\alpha}_\\ell,\\vec{\\alpha}\\in\\mathbb{F}^{\\leq m}</span>  and  <span class="math">a_1,\\ldots,a_\\ell\\in\\mathbb{F}</span> , the following statements are equivalent (i)  <span class="math">w(\\vec{\\alpha})=</span>  <span class="math">\\sum_{i=1}^{\\ell} a_i w(\\vec{\\alpha}_i) \\text{ for all } w \\in \\Sigma \\text{RM}[\\mathbb{F}, m, d, H]; \\text{ (ii) } \\langle \\vec{f}, \\phi_{\\vec{\\alpha}} \\rangle = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} \\in \\mathbb{F}^{[&lt; d]^m} \\text{ (iii) } \\phi_{\\vec{\\alpha}} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} \\in \\mathbb{F}^{[&lt; d]^m} \\text{ (iii) } \\phi_{\\vec{\\alpha}} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} \\in \\mathbb{F}^{[&lt; d]^m} \\text{ (iii) } \\phi_{\\vec{\\alpha}} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} \\in \\mathbb{F}^{[&lt; d]^m} \\text{ (iii) } \\phi_{\\vec{\\alpha}} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} \\in \\mathbb{F}^{[&lt; d]^m} \\text{ (iii) } \\phi_{\\vec{\\alpha}} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} \\in \\mathbb{F}^{[&lt; d]^m} \\text{ (iii) } \\phi_{\\vec{\\alpha}} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} \\in \\mathbb{F}^{[&lt; d]^m} \\text{ (iii) } \\phi_{\\vec{\\alpha}} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} \\in \\mathbb{F}^{[&lt; d]^m} \\text{ (iii) } \\phi_{\\vec{\\alpha}} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} \\in \\mathbb{F}^{[&lt; d]^m} \\text{ (iii) } \\phi_{\\vec{\\alpha}} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} \\in \\mathbb{F}^{[&lt; d]^m} \\text{ (iii) } \\phi_{\\vec{\\alpha}} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} \\in \\mathbb{F}^{[&lt; d]^m} \\text{ (iii) } \\phi_{\\vec{\\alpha}} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} \\in \\mathbb{F}^{[&lt; d]^m} \\text{ (iii) } \\phi_{\\vec{\\alpha}} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{f}, \\phi_{\\vec{\\alpha}_i} \\rangle \\text{ for all } \\vec{f} = \\sum_{i=1}^{\\ell} a_i \\langle \\vec{</span>  <span class="math">\\sum_{i=1}^{\\ell} a_i \\phi_{\\vec{\\alpha}_i}</span> . We deduce that constraint detection for  <span class="math">\\Sigma \\text{RM}[\\mathbb{F}, m, d, H]</span>  is equivalent to the problem of finding  <span class="math">a_1, \\ldots, a_\\ell \\in \\mathbb{F}</span>  such that  <span class="math">\\phi_{\\vec{\\alpha}} = \\sum_{i=1}^\\ell a_i \\phi_{\\vec{\\alpha}_i}</span> , or returning 'independent' if no such  <span class="math">a_1, \\ldots, a_\\ell</span>  exist.</p>

    <p class="text-gray-300">However, the dimension of the latter vectors is  <span class="math">d^m</span> , which may be much larger than  <span class="math">\\operatorname{poly}(\\log |\\mathbb{F}| + m + d + |H| + \\ell)</span> , and so we cannot afford to &quot;explicitly&quot; solve the  <span class="math">\\ell \\times d^m</span>  linear system. Instead, we &quot;succinctly&quot; solve it, by taking advantage of the special structure of the vectors, as we now describe. For  <span class="math">\\vec{\\alpha} \\in \\mathbb{F}^m</span> , define the polynomial</p>

    <p class="text-gray-300"><span class="math">$\\Phi_{\\vec{\\alpha}}(\\vec{X}) := \\prod_{i=1}^{m} (1 + \\alpha_i X_i + \\alpha_i^2 X_i^2 + \\dots + \\alpha_i^{d-1} X_i^{d-1}) .</span>$</p>

    <p class="text-gray-300">Note that, while the above polynomial is computable via a small arithmetic circuit, its coefficients (once expanded over the monomial basis) correspond to the entries of the vector  <span class="math">\\phi_{\\vec{\\alpha}}</span> . More generally, for  <span class="math">\\vec{\\alpha} \\in \\mathbb{F}^{\\leq m}</span> , we define the polynomial</p>

    <p class="text-gray-300"><span class="math">$\\Phi_{\\vec{\\alpha}}(\\vec{X}) := \\left( \\prod_{i=1}^{|\\vec{\\alpha}|} (1 + \\alpha_i X_i + \\dots + \\alpha_i^{d-1} X_i^{d-1}) \\right) \\left( \\prod_{i=1}^{m-|\\vec{\\alpha}|} \\sum_{\\gamma \\in H} (1 + \\gamma X_{i+|\\vec{\\alpha}|} + \\dots + \\gamma^{d-1} X_{i+|\\vec{\\alpha}|}^{d-1}) \\right) .</span>$</p>

    <p class="text-gray-300">Note that  <span class="math">\\Phi_{\\vec{\\alpha}}</span>  is a product of univariate polynomials. To see that the above does indeed represent  <span class="math">\\phi_{\\vec{\\alpha}}</span> , we rearrange the expression as follows:</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\Phi_{\\vec{\\alpha}}(\\vec{X}) &amp;= \\left( \\prod_{i=1}^{|\\vec{\\alpha}|} (1 + \\alpha_i X_i + \\dots + \\alpha_i^{d-1} X_i^{d-1}) \\right) \\left( \\sum_{\\vec{\\gamma} \\in H^{m-|\\vec{\\alpha}|}} \\prod_{i=1}^{m-|\\vec{\\alpha}|} (1 + \\gamma_i X_{i+|\\vec{\\alpha}|} + \\dots + \\gamma_i^{d-1} X_{i+|\\vec{\\alpha}|}^{d-1}) \\right) \\\\ &amp;= \\Phi_{\\vec{\\alpha}}(X_1, \\dots, X_{|\\vec{\\alpha}|}) \\left( \\sum_{\\vec{\\gamma} \\in H^{m-|\\vec{\\alpha}|}} \\Phi_{\\vec{\\gamma}}(X_{|\\vec{\\alpha}|+1}, \\dots, X_m) \\right) ; \\end{split}</span>$</p>

    <p class="text-gray-300">indeed, the coefficient of  <span class="math">\\vec{X}^{\\vec{a},\\vec{b}}</span>  for  <span class="math">\\vec{a} \\in [&lt;d]^{|\\vec{\\alpha}|}</span>  and  <span class="math">\\vec{b} \\in [&lt;d]^{m-|\\vec{\\alpha}|}</span>  is  <span class="math">\\vec{\\alpha}^{\\vec{a}} \\sum_{\\vec{\\gamma} \\in H^{m-|\\vec{\\alpha}|}} \\vec{\\gamma}^{\\vec{b}}</span> , as required. Thus, to determine whether  <span class="math">\\phi_{\\alpha} \\in \\operatorname{span}(\\phi_{\\alpha_1},\\ldots,\\phi_{\\alpha_\\ell})</span> , it suffices to determine whether  <span class="math">\\Phi_{\\alpha} \\in \\operatorname{span}(\\Phi_{\\alpha_1},\\ldots,\\Phi_{\\alpha_\\ell})</span> . In fact, the linear dependencies are in correspondence: for  <span class="math">a_1, \\ldots, a_\\ell \\in \\mathbb{F}</span> ,  <span class="math">\\phi_\\alpha = \\sum_{i=1}^\\ell a_i \\phi_{\\alpha_i}</span>  if and only if  <span class="math">\\Phi_\\alpha = \\sum_{i=1}^\\ell a_i \\phi_{\\alpha_i}</span>  <span class="math">\\sum_{i=1}^{\\ell} a_i \\Phi_{\\alpha_i}</span> . Crucially, each  <span class="math">\\Phi_{\\alpha_i}</span>  is not only in  <span class="math">\\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span>  but is a product of m univariate polynomials each represented via an  <span class="math">\\mathbb{F}</span> -arithmetic circuit of size poly(|H|+d). We leverage this special structure and solve the above problem by relying on an algorithm of [RS05] that computes the nullspace for such polynomials (see also [Kay10]), as captured by the lemma below; for completeness, we provide an elementary proof of the lemma in Appendix D.</p>

    <p class="text-gray-300">One could use polynomial identity testing to solve the above problem in probabilistic polynomial time; see [Kay10, Lemma 8]. However, due to a nonzero probability of error, this suffices only to achieve statistical zero knowledge, but does not suffice to achieve perfect zero knowledge.</p>

    <p class="text-gray-300"><strong>Lemma 4.11.</strong> There exists a deterministic algorithm  <span class="math">\\mathcal{D}</span>  such that, on input a vector of m-variate polynomials  <span class="math">\\vec{Q} = (Q_1, \\ldots, Q_\\ell)</span>  over  <span class="math">\\mathbb{F}</span>  where each polynomial has the form  <span class="math">Q_k(\\vec{X}) = \\prod_{i=1}^m Q_{k,i}(X_i)</span>  and each  <span class="math">Q_{k,i}</span>  is univariate of degree less than d with  <span class="math">d \\leq |\\mathbb{F}|</span>  and represented via an  <span class="math">\\mathbb{F}</span> -arithmetic circuit of size s, outputs a basis for the linear space  <span class="math">\\vec{Q}^{\\perp} := \\{(a_1, \\ldots, a_\\ell) \\in \\mathbb{F}^\\ell : \\sum_{k=1}^\\ell a_k Q_k \\equiv 0\\}</span> . Moreover,  <span class="math">\\mathcal{D}</span>  runs in  <span class="math">\\operatorname{poly}(\\log |\\mathbb{F}| + m + d + s + \\ell)</span>  time.</p>

    <p class="text-gray-300">The above lemma immediately provides a way to construct a constraint detector for  <span class="math">\\Sigma RM</span> : given as input an index  <span class="math">n = (\\mathbb{F}, m, d, H)</span>  and a subset  <span class="math">I \\subseteq D(n)</span> , we construct the arithmetic circuit  <span class="math">\\Phi_{\\alpha}</span>  for each  <span class="math">\\alpha \\in I</span> , and then run the algorithm  <span class="math">\\mathcal{D}</span>  on vector of circuits  <span class="math">(\\Phi_{\\alpha})_{\\alpha \\in I}</span> , and directly output  <span class="math">\\mathcal{D}</span> 's result. The lemma follows.</p>

      <h3 id="sec-4.3" class="text-xl font-semibold mt-8">4.3 Univariate polynomials with BS proximity proofs</h3>

    <p class="text-gray-300">We show that evaluations of univariate polynomials concatenated with corresponding BS proximity proofs [BS08] have succinct constraint detection (see Definition 4.2). Recall that the Reed&ndash;Solomon code (see Section 3.4) is not locally testable, but one can test proximity to it with the aid of the quasilinear-size proximity proofs of Ben-Sasson and Sudan [BS08]. These latter apply when low-degree univariate polynomials are evaluated over <em>linear spaces</em>, so from now on we restrict our attention to Reed&ndash;Solomon codes of this form. More precisely, we consider Reed&ndash;Solomon codes  <span class="math">RS[\\mathbb{F}, L, d]</span>  where  <span class="math">\\mathbb{F}</span>  is an extension field of a base field  <span class="math">\\mathbb{K}</span> , L is a  <span class="math">\\mathbb{K}</span> -linear subspace in  <span class="math">\\mathbb{F}</span> , and  <span class="math">d = |L| \\cdot |\\mathbb{K}|^{-\\mu}</span>  for some  <span class="math">\\mu \\in \\mathbb{N}^+</span> . We then denote by  <span class="math">BS-RS[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  the code obtained by concatenating codewords in  <span class="math">RS[\\mathbb{F}, L, |L| \\cdot |\\mathbb{K}|^{-\\mu}]</span>  with corresponding BS proximity proofs whose recursion terminates at &quot;base dimension&quot;  <span class="math">k \\in \\{1, \\ldots, \\dim(L)\\}</span>  (for completeness we include a formal definition of these in Appendix F); typically  <span class="math">\\mathbb{K}</span> ,  <span class="math">\\mu</span> , k are fixed to certain constants (e.g., [BS08] fixes them to  <span class="math">\\mathbb{F}_2</span> , 3, 1, respectively) but below we state the cost of constraint detection in full generality. The linear code family BS-RS is indexed by tuples  <span class="math">\\mathbb{n} = (\\mathbb{K}, \\mathbb{F}, L, \\mu, k)</span>  and the  <span class="math">\\mathbb{n}</span> -th code is  <span class="math">BS-RS[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span> , and our result about BS-RS is the following:</p>

    <p class="text-gray-300"><strong>Theorem 4.12</strong> (formal statement of 1.7). BS-RS has poly( <span class="math">\\log |\\mathbb{F}| + \\dim(L) + |\\mathbb{K}|^{\\mu} + \\ell</span> )-time constraint detection.</p>

    <p class="text-gray-300">The proof of the above theorem is technically involved, and we present it via several steps, as follows. (1) In Section 4.3.1 we introduce the notion of a <em>code cover</em> and two key combinatorial properties of these:  <span class="math">\\kappa</span> -locality and  <span class="math">\\kappa</span> -independence. (2) In Section 4.3.2 we introduce the notion of a <em>recursive</em> code cover and relate its combinatorial properties to those of (standard) code covers. (3) In Section 4.3.3 we show how to construct succinct constraint detectors starting from algorithms that detect constraints only 'locally' for code covers and recursive code covers. (4) In Section 4.3.4 we show that BS-RS has a recursive code cover with the requisite properties and thus implies, via the results of prior steps, a succinct constraint detector, as claimed. Several sub-proofs are deferred to the appendices, and we provide pointers to these along the way.</p>

    <p class="text-gray-300">The role of code covers. We are interested in succinct constraint detection: solving the constraint detection problem for certain code families with exponentially-large domains (such as BS-RS). We now build some intuition about how code covers can, in some cases, facilitate this.</p>

    <p class="text-gray-300">Consider the simple case where the code  <span class="math">C \\subseteq \\mathbb{F}^D</span>  is a direct sum of many small codes: there exists  <span class="math">S = \\{(\\tilde{D}_j, \\tilde{C}_j)\\}_j</span>  such that  <span class="math">D = \\bigcup_j \\tilde{D}_j</span>  and  <span class="math">C = \\bigoplus_j \\tilde{C}_j</span>  where, for each  <span class="math">j, \\tilde{C}_j</span>  is a linear code in  <span class="math">\\mathbb{F}^{\\tilde{D}_j}</span>  and the subdomain  <span class="math">\\tilde{D}_j</span>  is small and disjoint from other subdomains. The detection problem for this case can be solved efficiently: use the generic approach of Gaussian elimination independently on each subdomain  <span class="math">\\tilde{D}_j</span> .</p>

    <p class="text-gray-300">Next consider a more general case where the subdomains are not necessarily disjoint: there exists  <span class="math">S = \\{(\\tilde{D}_j, \\tilde{C}_j)\\}_j</span>  as above but we do not require that the  <span class="math">\\tilde{D}_j</span>  form a partition of D; we say that each  <span class="math">(\\tilde{D}_j, \\tilde{C}_j)</span>  is a local view of C because  <span class="math">\\tilde{D}_j \\subseteq D</span>  and  <span class="math">\\tilde{C}_j = C|_{\\tilde{D}_j}</span> , and we say that S is a code cover of C. Now suppose that for each j there exists an efficient constraint detector for  <span class="math">\\tilde{C}_j</span>  (which is defined on  <span class="math">\\tilde{D}_j</span> ); in this case, the detection problem can be solved efficiently at least for those subsets I that are contained in  <span class="math">\\tilde{D}_j</span>  for some j. Generalizing further, we see that we can efficiently solve constraint detection for a code C if there is a cover  <span class="math">S = \\{(\\tilde{D}_j, \\tilde{C}_j)\\}_j</span>  such that, given a subset  <span class="math">I \\subseteq D</span> , (i) I is contained in some subdomain  <span class="math">\\tilde{D}_j</span> , and (ii) constraint detection for  <span class="math">\\tilde{C}_j</span>  can be solved efficiently.</p>

    <p class="text-gray-300">We build on the above ideas to derive analogous statements for recursive code covers, which arise naturally in the case of BS-RS. But note that recursive constructions are common in the PCP literature, and we believe that our cover-based techniques are of independent interest as, e.g., they are applicable to <em>other</em> PCPs, including [BFLS91, AS98].</p>

      <h4 id="sec-4.3.1" class="text-lg font-semibold mt-6">4.3.1 Covering codes with local views</h4>

    <p class="text-gray-300">The purpose of this section is to formally define the notion of cover and certain combinatorial properties of these.</p>

    <p class="text-gray-300"><strong>Definition 4.13.</strong> Let C be a linear code with domain D and alphabet  <span class="math">\\mathbb{F}</span> . A (local) view of C is a pair  <span class="math">(\\tilde{D}, \\tilde{C})</span>  such that  <span class="math">\\tilde{D} \\subseteq D</span>  and  <span class="math">C|_{\\tilde{D}} = \\tilde{C}</span> . A cover of C is a set of local views  <span class="math">S = \\{(\\tilde{D}_j, \\tilde{C}_j)\\}_j</span>  of C such that  <span class="math">D = \\cup_j \\tilde{D}_j</span> . Also, we define a cover's domain intersection as  <span class="math">di(S) := \\cup_{i \\neq j} (\\tilde{D}_i \\cap \\tilde{D}_j)</span>  and, given a set J, we define  <span class="math">\\tilde{D}_J := \\cup_{i \\in J} \\tilde{D}_i</span> .</p>

    <p class="text-gray-300"><strong>Example 4.14</strong> (line cover of RM). Suppose for instance that C is the Reed-Muller code  <span class="math">\\mathrm{RM}[\\mathbb{F},\\mathbb{F},m,d]\\colon C</span>  consists of evaluations over  <span class="math">D=\\mathbb{F}^m</span>  of polynomials in  <span class="math">\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span>  (see Definition 3.4). A cover of C that is extensively studied in the PCP and property-testing literature is the one given by (axis-parallel) <em>lines</em>. A line (in the i-th direction) is a set of  <span class="math">|\\mathbb{F}|</span>  points that agree on all but one coordinate (the i-th one); and the <em>line cover</em> of C is thus  <span class="math">S=\\{(\\tilde{D}_\\ell,\\tilde{C}_\\ell)\\}</span>  where  <span class="math">\\ell</span>  ranges over all (axis-parallel) lines and  <span class="math">\\tilde{C}_\\ell</span>  is the Reed-Solomon code  <span class="math">\\mathrm{RS}[\\mathbb{F},\\mathbb{F},d]</span>  (see Definition 3.4).</p>

    <p class="text-gray-300">Observe that the domain intersection of the line cover equals  <span class="math">\\mathbb{F}^m</span> , which is also the domain D of the base code C. However, for BS-RS, we consider a cover whose domain intersection is a strict subset of D (see Appendix G).</p>

    <p class="text-gray-300">Next, we specify a notion of <em>locality</em> for covers. A partial assignment  <span class="math">w&#x27; \\in \\mathbb{F}^{D&#x27;}</span>  is <em>locally consistent</em> with a cover  <span class="math">S = \\{(\\tilde{D}_j, \\tilde{C}_j)\\}_j</span>  if for every local view  <span class="math">(\\tilde{D}_j, \\tilde{C}_j)</span>  with  <span class="math">\\tilde{D}_j \\subseteq D&#x27;</span>  the restriction  <span class="math">w&#x27;|_{\\tilde{D}_j}</span>  is a codeword of  <span class="math">\\tilde{C}_j</span> . Then we say that a cover is  <span class="math">\\kappa</span> -local if any locally consistent assignment  <span class="math">w&#x27; \\in \\mathbb{F}^{D&#x27;}</span> , where D' is a union of at most  <span class="math">\\kappa</span>  domains in the cover, can be extended to a &quot;globally consistent&quot; codeword w of C.</p>

    <p class="text-gray-300"><strong>Definition 4.15.</strong> Let C be a linear code with domain D and alphabet  <span class="math">\\mathbb{F}</span> . Given  <span class="math">\\kappa \\in \\mathbb{N}</span> , a  <span class="math">\\kappa</span> -local cover of C is a cover  <span class="math">S = \\{(\\tilde{D}_j, \\tilde{C}_j)\\}_j</span>  of C such that: for every subset of view-indices J of size at most  <span class="math">\\kappa</span>  and every word  <span class="math">w&#x27; \\in \\mathbb{F}^{\\tilde{D}_J}</span>  with  <span class="math">w&#x27;|_{\\tilde{D}_j} \\in \\tilde{C}_j</span>  (for every  <span class="math">j \\in J</span> ), the word w' can be extended to some word w in C, i.e., w satisfies  <span class="math">w|_{\\tilde{D}_J} = w&#x27;</span> ). (The trivial cover  <span class="math">S = \\{(D, C)\\}</span>  of C is  <span class="math">\\kappa</span> -local for every  <span class="math">\\kappa</span> .)</p>

    <p class="text-gray-300">The following definition significantly strengthens the previous one. Informally, a cover is  <span class="math">\\kappa</span> -independent if every partial assignment over a subdomain D' that is the union of  <span class="math">\\kappa</span>  subdomains from the cover and  <span class="math">\\kappa</span>  auxiliary locations can be extended to a &quot;globally consistent&quot; codeword. We use this stronger notion in our main Lemma 4.20.</p>

    <p class="text-gray-300"><strong>Definition 4.16.</strong> Let C be a linear code with domain D and alphabet  <span class="math">\\mathbb{F}</span> . Given  <span class="math">\\kappa \\in \\mathbb{N}</span> , a  <span class="math">\\kappa</span> -independent cover of C is a  <span class="math">\\kappa</span> -local cover  <span class="math">S = \\{(\\tilde{D}_j, \\tilde{C}_j)\\}_j</span>  such that for every set J of size at most  <span class="math">\\kappa</span> , subdomain  <span class="math">D&#x27; \\subseteq \\operatorname{di}(S)</span>  of size at most  <span class="math">\\kappa</span> , and  <span class="math">w&#x27; \\in \\mathbb{F}^{D&#x27; \\cup \\tilde{D}_J}</span>  with  <span class="math">w&#x27;|_{\\tilde{D}_j} \\in \\tilde{C}_j</span>  for every  <span class="math">j \\in J</span> , there exists  <span class="math">w \\in C</span>  such that  <span class="math">w|_{D&#x27; \\cup \\tilde{D}_J} = w&#x27;</span> . (The trivial cover  <span class="math">S = \\{(D, C)\\}</span>  of C is  <span class="math">\\kappa</span> -independent for every  <span class="math">\\kappa \\in \\mathbb{N}</span>  because it is  <span class="math">\\kappa</span> -local and has  <span class="math">\\operatorname{di}(S) = \\emptyset</span> .)</p>

    <p class="text-gray-300"><strong>Example 4.17.</strong> The line cover from Example 4.14 is d-local because any evaluation on at most d (axis-parallel) lines  <span class="math">\\ell_1, \\ldots, \\ell_d</span>  that is a polynomial of degree (d-1) along each of  <span class="math">\\ell_1, \\ldots, \\ell_d</span>  can be extended to a codeword of  <span class="math">\\mathrm{RM}[\\mathbb{F}, \\mathbb{F}, m, d]</span> . Furthermore, it is d/2-independent because any locally consistent assignment to d/2 such lines and d/2 points  <span class="math">p_1, \\ldots, p_{d/2}</span>  can be extended to a valid Reed&ndash;Muller codeword. To see this, observe that there exists an interpolating set  <span class="math">H_1 \\times \\cdots \\times H_m</span>  (with  <span class="math">|H_i| = d</span> ) that contains  <span class="math">p_1, \\ldots, p_{d/2}</span>  and intersects each line in d points; we shall later use this observation for the bivariate case (m=2), a proof for that case is provided at Claim H.1.</p>

      <h4 id="sec-4.3.2" class="text-lg font-semibold mt-6">4.3.2 Recursive covers and locality</h4>

    <p class="text-gray-300">Proximity proofs for codes such as the Reed&ndash;Solomon code and the Reed&ndash;Muller code are typically obtained via techniques of proof composition [AS98]. Informally, a problem is reduced to a set of smaller sub-problems of the same kind (which are usually interconnected), and a sub-proof is constructed for each sub-problem. This process leads to a proof for the original problem that is &quot;covered&quot; by the sub-proofs for the sub-problems, and naturally imply a cover of the proof by these sub-proofs. This process is then repeated recursively until the sub-problems are small enough for the verifier to check directly &mdash; and in our case leads to the notion of <em>recursive covers</em>, which we define below.</p>

    <p class="text-gray-300">To support the definition of a recursive cover, we first introduce notation for rooted trees. Edges in a rooted tree T = (V, E) are directed from the root r towards the leaves; the edge directed from v to u is denoted (v, u); v is the predecessor of u and u the successor of v; if there is a path from v to v' we say that v is an ancestor of v'; if there is no directed path between v and v' (in either direction) we say that the two vertices are disconnected. The set of successors</p>

    <p class="text-gray-300">of v is denoted  <span class="math">\\operatorname{successors}(T,v)</span> . The  <span class="math">\\operatorname{depth}</span>  of a vertex v in T is denoted  <span class="math">\\operatorname{depth}(T,v)</span>  and equals the number of edges on the path from r to v. The depth of T is denoted  <span class="math">\\operatorname{depth}(T)</span>  and equals the maximum of  <span class="math">\\operatorname{depth}(T,v)</span>  as v ranges in V. The i-th  <span class="math">\\operatorname{layer}</span>  of T is denoted  <span class="math">\\operatorname{layer}(T,i)</span>  and equals the set of  <span class="math">v \\in V</span>  such that  <span class="math">\\operatorname{depth}(T,v)=i</span> . (Note that  <span class="math">\\operatorname{depth}(T,v)=0</span>  and  <span class="math">\\operatorname{layer}(T,0)=\\{r\\}</span> .) An  <span class="math">\\operatorname{equidepth}</span>  tree is a tree in which all leaves have equal depth.</p>

    <p class="text-gray-300"><strong>Definition 4.18.</strong> Let C be a linear code with domain D and alphabet  <span class="math">\\mathbb{F}</span> . A <strong>recursive cover</strong> of C is a directed rooted equidepth tree T of non-zero depth where each vertex v is labeled by a view  <span class="math">(\\tilde{C}_v, \\tilde{D}_v)</span>  such that: (i)  <span class="math">\\tilde{C}_v</span>  is a linear code with domain  <span class="math">\\tilde{D}_v</span>  and alphabet  <span class="math">\\mathbb{F}</span> ; (ii) if v is the root, then  <span class="math">(\\tilde{C}_v, \\tilde{D}_v) = (C, D)</span> ; and (iii) for every non-leaf v the set  <span class="math">T_v := \\{(\\tilde{C}_u, \\tilde{D}_u)\\}_{u \\in \\text{successors}(T,v)}</span>  is a cover of  <span class="math">\\tilde{C}_v</span> . Furthermore we define the following notions:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Given  <span class="math">d \\in \\{0, \\ldots, \\operatorname{depth}(T)\\}</span> , the d-depth restriction of T is  <span class="math">T|_d := \\bigcup_{v \\in \\operatorname{layer}(T,d)} \\{(\\tilde{C}_v, \\tilde{D}_v)\\}</span> . (Note that  <span class="math">T|_0 = \\{(C,D)\\}</span> .)</li>
      <li>Given  <span class="math">c \\in \\mathbb{N}</span> , we say that T is c-intersecting if  <span class="math">|\\tilde{D}_u \\cap \\tilde{D}_{u&#x27;}| \\leq c</span>  for every two disconnected vertices u, v.</li>
      <li>Given  <span class="math">\\kappa \\in \\mathbb{N}</span> , we say that T is  <span class="math">\\kappa</span> -independent if  <span class="math">T_v</span>  is a  <span class="math">\\kappa</span> -independent cover of  <span class="math">\\tilde{C}_v</span>  for every non-leaf vertex v in T.</li>
    </ul>

    <p class="text-gray-300"><strong>Remark 4.19.</strong> The above definition is restricted to equidepth trees, but can be extended to general trees as follows. Iteratively append to each leaf v of non-maximal depth a single successor u labeled by  <span class="math">(\\tilde{C}_u, \\tilde{D}_u) := (\\tilde{C}_v, \\tilde{D}_v)</span> ; this leads to a cover of  <span class="math">T_v</span>  that is 0-intersecting and  <span class="math">\\kappa</span> -doubly independent for  <span class="math">\\kappa</span>  that equals  <span class="math">\\tilde{C}_v</span> 's dual distance.</p>

    <p class="text-gray-300">Below we state the main lemma of this section. This lemma says that (given certain restrictions) if a recursive cover has the <em>local</em> property of <em>independence</em> (of some degree) at each internal vertex, then each of its layers has the <em>global</em> property of <em>locality</em> (of some degree) as a cover of the root. Later on (in Section 4.3.3) we show how cover locality is used to construct constraint detectors.</p>

    <p class="text-gray-300"><strong>Lemma 4.20</strong> (main). Let C be a linear code with domain D and alphabet  <span class="math">\\mathbb{F}</span> , and let T be a recursive cover of C such that (i) T is c-intersecting for c &gt; 0, and (ii) for every non-leaf vertex v in T it holds that  <span class="math">T_v</span>  is a  <span class="math">\\kappa</span> -independent cover of  <span class="math">\\tilde{C}_v</span> . Then, for every  <span class="math">d \\in \\{0, \\ldots, \\operatorname{depth}(T)\\}</span> ,  <span class="math">T|_d</span>  is a  <span class="math">\\frac{\\kappa}{c}</span> -local cover of C.</p>

    <p class="text-gray-300"><em>Proof.</em> We prove the statement by induction on the non-negative integer d. The base case is when d=0, and holds because  <span class="math">T|_0=\\{(D,C)\\}</span>  is the trivial cover, thus it is a  <span class="math">\\kappa&#x27;</span> -local cover of C for any  <span class="math">\\kappa&#x27;\\geq 0</span>  and, in particular, a  <span class="math">\\frac{\\kappa}{c}</span> -local cover. We now assume the statement for  <span class="math">d&lt;\\operatorname{depth}(T)</span>  and prove it for depth d+1.</p>

    <p class="text-gray-300">Let  <span class="math">T|_d=\\{(\\tilde{D}_j,\\tilde{C}_j)\\}_j</span>  be the d-depth cover of C, and let  <span class="math">T|_{d+1}=\\{(\\tilde{D}_{i,j},\\tilde{C}_{i,j})\\}_{i,j}</span>  be the (d+1)-depth cover of C, where, for every  <span class="math">i,T|_{d+1}^{(i)}=\\{(\\tilde{D}_{i,j},\\tilde{C}_{i,j})\\}_j</span>  is the cover of  <span class="math">\\tilde{C}_i</span>  (this can be ensured via suitable indexing). Let J be a set of pairs (i,j) of size at most  <span class="math">\\frac{\\kappa}{c}</span> , and let  <span class="math">w&#x27;\\in\\mathbb{F}^{\\tilde{D}_J}</span>  be such that  <span class="math">w&#x27;|_{\\tilde{D}_{i,j}}\\in\\tilde{C}_{i,j}</span>  for every  <span class="math">(i,j)\\in J</span> . We show that there exists  <span class="math">w\\in C</span>  such that  <span class="math">w|_{\\tilde{D}_J}=w&#x27;</span> . Define  <span class="math">I:=\\{i:\\exists j \\text{ s.t. } (i,j)\\in J\\}</span>  and note that  <span class="math">|I|\\leq |J|\\leq \\frac{\\kappa}{c}</span> . By the inductive assumption, it suffices to show that there exists  <span class="math">w\\in\\mathbb{F}^{\\tilde{D}_I}</span>  such that (a)  <span class="math">w|_{\\tilde{D}_{i,j}}=w&#x27;|_{\\tilde{D}_{i,j}}</span>  for every  <span class="math">(i,j)\\in J</span> , and (b)  <span class="math">w|_{\\tilde{D}_i}\\in\\tilde{C}_i</span>  for every  <span class="math">i\\in I</span> .</p>

    <p class="text-gray-300">For simplicity assume  <span class="math">I=\\{1,\\ldots,|I|\\}</span> . We construct w incrementally and view w as belonging to  <span class="math">(\\mathbb{F}\\cup\\{\\emptyset\\})^{\\tilde{D}_I}</span> , i.e., it is a partial mapping from  <span class="math">\\tilde{D}_I</span>  to  <span class="math">\\mathbb{F}</span> . Let  <span class="math">\\operatorname{def}(w):=\\{\\alpha\\in \\tilde{D}_I:w(\\alpha)\\neq\\emptyset\\}</span>  denote the set of locations where w is defined. Initialize  <span class="math">\\operatorname{def}(w)=\\tilde{D}_J</span>  and  <span class="math">w|_{\\tilde{D}_J}=w&#x27;</span> ; then, for increasing  <span class="math">i=1,\\ldots,|I|</span> , iteratively extend w to be defined (also) over  <span class="math">\\tilde{D}_i</span> , eventually obtaining  <span class="math">w\\in\\mathbb{F}^{\\tilde{D}_I}</span> . In the i-th iteration (that handles  <span class="math">\\tilde{D}_i</span> ), it is sufficient to prove the existence of a codeword  <span class="math">w_i\\in\\tilde{C}_i</span>  such that  <span class="math">w_i|_{\\tilde{D}_i\\cap\\operatorname{def}(w)}=w|_{\\tilde{D}_i\\cap\\operatorname{def}(w)}</span> . If such a codeword exists then we shall define w on  <span class="math">\\tilde{D}_i</span>  by  <span class="math">w|_{\\tilde{D}_i}=w_i</span> , thus eventually reaching w that satisfies the stated requirements.</p>

    <p class="text-gray-300">To show that during the i-th iteration the desired  <span class="math">w_i</span>  exists, partition the elements of  <span class="math">\\tilde{D}_i \\cap \\operatorname{def}(w)</span>  into two sets:  <span class="math">V := \\cup_{j \\text{ s.t. } (i,j) \\in J} \\tilde{D}_{i,j}</span>  and  <span class="math">W := (\\tilde{D}_i \\cap \\operatorname{def}(w)) \\setminus V</span> . Note that  <span class="math">W \\subseteq \\cup_{i&#x27; \\neq i} (\\tilde{D}_i \\cap \\tilde{D}_{i&#x27;})</span> , because defining  <span class="math">w(\\alpha)</span>  for any  <span class="math">\\alpha \\in W</span>  can be done only: (i) in the initialization phase, so that  <span class="math">\\alpha \\in \\tilde{D}_{i&#x27;,j&#x27;} \\subseteq \\tilde{D}_{i&#x27;}</span>  for some  <span class="math">(i&#x27;,j&#x27;) \\in J</span>  with  <span class="math">i&#x27; \\neq i</span>  (as otherwise  <span class="math">\\alpha \\in V</span> ); or (ii) in a previous iteration, so that  <span class="math">\\alpha \\in \\tilde{D}_{i&#x27;}</span>  for some i' &lt; i (as  <span class="math">\\tilde{D}_{i&#x27;}</span>  was already handled and w is already defined on all of  <span class="math">\\tilde{D}_{i&#x27;}</span> ). The above implies that  <span class="math">W \\subseteq \\operatorname{di}(T|_{d+1}^{(i)})</span>  and the assumption that T is c-intersecting implies</p>

    <p class="text-gray-300"><span class="math">$|W| \\leq \\sum_{i&#x27; \\neq i} |\\tilde{D}_i \\cap \\tilde{D}_{i&#x27;}| \\leq c \\cdot |I| \\leq c \\cdot |J| \\leq \\kappa .</span>$</p>

    <p class="text-gray-300">Similarly, note that for every fixed  <span class="math">i \\in I</span>  the number of pairs  <span class="math">(i, j) \\in J</span>  is at most  <span class="math">|J| \\le \\kappa</span> . By assumption  <span class="math">\\tilde{C}_i</span>  has a  <span class="math">\\kappa</span> -independent cover and thus we conclude (via Definition 4.16) that the desired  <span class="math">w_i</span>  exists, as required.</p>

      <h4 id="sec-4.3.3" class="text-lg font-semibold mt-6">4.3.3 From recursive covers to succinct constraint detection</h4>

    <p class="text-gray-300">The purpose of this section is to establish sufficient conditions for succinct constraint detection by leveraging covers with small-enough views and large-enough locality. First, in Definition 4.21 and Lemma 4.22, we define <em>cover-based constraint detection</em> and prove that it implies succinct constraint detection; informally, we consider the case when a code has a sequence of covers where view size and locality reduce together, and prove that we can locally detect constraints in a number of views that is proportional to the constraint's weight and each view's size is proportional to the constraint's weight, by choosing the right cover from the sequence. Then, in Definition 4.24 and Lemma 4.25, we extend our discussion to recursive code covers by defining <em>recursive-cover-based constraint detection</em> and establishing that it implies the previous notion. We conclude (in Corollary 4.26) that recursive-cover-based constraint detection implies succinct constraint detection.</p>

    <p class="text-gray-300"><strong>Definition 4.21.</strong> Let  <span class="math">\\mathscr{C} = \\{C_{\\mathfrak{n}}\\}_{\\mathfrak{n}}</span>  be a linear code family with domain  <span class="math">D(\\cdot)</span>  and alphabet  <span class="math">\\mathbb{F}(\\cdot)</span> . We say that  <span class="math">\\mathscr{C}</span>  has <strong>cover-based constraint detection</strong> if there exists an algorithm that, given an index  <span class="math">\\mathfrak{n}</span>  and subset  <span class="math">I \\subseteq D(\\mathfrak{n})</span> , outputs in  <span class="math">\\operatorname{poly}(|\\mathfrak{n}| + |I|)</span>  time a subset  <span class="math">W \\subseteq \\mathbb{F}(\\mathfrak{n})^{D(\\mathfrak{n})}</span>  for which there exists a subset S' of some |I|-local cover S of  <span class="math">C_{\\mathfrak{n}}</span> , and the following holds: (i)  <span class="math">|S&#x27;| \\leq |I|</span> ; (ii)  <span class="math">I \\subseteq (\\cup_{\\tilde{D},\\tilde{C}) \\in S&#x27;} \\tilde{D}</span> ); (iii)  <span class="math">\\operatorname{span}(W) = \\operatorname{span}(\\cup_{(\\tilde{D},\\tilde{C}) \\in S&#x27;} \\tilde{C}^{\\perp})</span> .</p>

    <p class="text-gray-300"><strong>Lemma 4.22.</strong> Let  <span class="math">\\mathscr{C} = \\{C_n\\}_n</span>  be a linear code family with domain  <span class="math">D(\\cdot)</span>  and alphabet  <span class="math">\\mathbb{F}(\\cdot)</span> . If  <span class="math">\\mathscr{C}</span>  has cover-based constraint detection then  <span class="math">\\mathscr{C}</span>  has succinct constraint detection.</p>

    <p class="text-gray-300">To prove this lemma we require a technical claim, the proof of which is deferred to Appendix E.</p>

    <p class="text-gray-300"><strong>Claim 4.23.</strong> Let C be a linear code with domain D and alphabet  <span class="math">\\mathbb{F}</span> , let  <span class="math">S = \\{(\\tilde{D}_j, \\tilde{C}_j)\\}_j</span>  be a  <span class="math">\\kappa</span> -local cover of C. For any set J of size at most  <span class="math">\\kappa</span>  it holds  <span class="math">\\operatorname{span}(\\cup_{j\\in J}\\tilde{C}_j^{\\perp}) = (C^{\\perp})_{\\subset (\\cup_{j\\in J}\\tilde{D}_j)}</span> .</p>

    <p class="text-gray-300">Proof of Lemma 4.22. By Lemma 4.6, it suffices to show an algorithm that, on input an index  <span class="math">\\mathbb{n}</span>  and subset  <span class="math">I\\subseteq D(\\mathbb{n})</span> , outputs a subset  <span class="math">W\\subseteq \\mathbb{F}(\\mathbb{n})^{D(\\mathbb{n})}</span>  with  <span class="math">(C_{\\mathbb{n}}^{\\perp})_{\\subseteq I}\\subseteq \\operatorname{span}(W)\\subseteq C_{\\mathbb{n}}^{\\perp}</span>  in  <span class="math">\\operatorname{poly}(|\\mathbb{n}|+|I|)</span>  time. We take this algorithm to be the one guaranteed by Definition 4.21. To see correctness, let  <span class="math">\\tilde{D}_{S&#x27;}:=\\cup_{(\\tilde{D},\\tilde{C})\\in S&#x27;}\\tilde{D}</span> , and note that Definition 4.21 and Claim 4.23 imply that  <span class="math">\\operatorname{span}(W)=(C_{\\mathbb{n}}^{\\perp})_{\\subset \\tilde{D}_{S&#x27;}}</span>  and  <span class="math">(C_{\\mathbb{n}}^{\\perp})_{\\subseteq I}\\subseteq (C_{\\mathbb{n}}^{\\perp})_{\\subset \\tilde{D}_{S&#x27;}}\\subseteq C_{\\mathbb{n}}^{\\perp}</span> , as required.  <span class="math">\\square</span></p>

    <p class="text-gray-300">Next we show that, under certain conditions, code families with recursive covers imply a sequence of covers that we can use to construct cover-based constraint detectors. Combined with Lemma 4.22, this result is key for establishing a connection from certain proximity proof constructions to succinct constraint detectors.</p>

    <p class="text-gray-300"><strong>Definition 4.24.</strong> Let  <span class="math">\\mathscr{C} = \\{C_n\\}_n</span>  be a linear code family with domain  <span class="math">D(\\cdot)</span>  and alphabet  <span class="math">\\mathbb{F}(\\cdot)</span> . We say that  <span class="math">\\mathscr{C}</span>  has recursive-cover-based constraint detection if:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>there exists  <span class="math">c \\in \\mathbb{N}</span>  such that, for every index n,  <span class="math">C_n</span>  has a c-intersecting recursive cover  <span class="math">T_n</span> ;</li>
      <li>there exists an algorithm that, given an index  <span class="math">\\mathfrak{n}</span>  and subset  <span class="math">I \\subseteq D(\\mathfrak{n})</span> , outputs in  <span class="math">\\operatorname{poly}(|\\mathfrak{n}| + |I|)</span>  time a subset  <span class="math">W \\subseteq \\mathbb{F}(\\mathfrak{n})^{D(\\mathfrak{n})}</span>  for which there exist  <span class="math">d \\in \\{0, \\ldots, \\operatorname{depth}(T_{\\mathfrak{n}})\\}</span>  and  <span class="math">U \\subseteq \\operatorname{layer}(T_{\\mathfrak{n}}, d)</span>  such that: (i) for every vertex v in  <span class="math">T_{\\mathfrak{n}}</span>  with  <span class="math">\\operatorname{depth}(T_{\\mathfrak{n}}, v) &lt; d</span> , the cover  <span class="math">T_{\\mathfrak{n}, v}</span>  is c|I|-independent; (ii)  <span class="math">|U| \\leq |I|</span> ; (iii)  <span class="math">I \\subseteq (\\cup_{u \\in U} \\tilde{D}_u)</span> ; (iv)  <span class="math">\\operatorname{span}(W) = \\operatorname{span}(\\cup_{u \\in U} \\tilde{C}_u^{\\perp})</span> .</li>
    </ul>

    <p class="text-gray-300"><strong>Lemma 4.25.</strong> Let  <span class="math">\\mathscr{C} = \\{C_n\\}_n</span>  be a linear code family with domain  <span class="math">D(\\cdot)</span>  and alphabet  <span class="math">\\mathbb{F}(\\cdot)</span> . If  <span class="math">\\mathscr{C}</span>  has recursive-coverbased constraint detection, then  <span class="math">\\mathscr{C}</span>  has cover-based constraint detection.</p>

    <p class="text-gray-300"><em>Proof.</em> The definition of recursive-cover-based detection says that there exist (a)  <span class="math">c \\in \\mathbb{N}</span>  such that, for every index  <span class="math">\\mathfrak{n}</span> ,  <span class="math">C_\\mathfrak{n}</span>  has a c-intersecting recursive cover  <span class="math">T_\\mathfrak{n}</span> , and (b) an algorithm satisfying certain properties. We show that this algorithm meets the requirements for being a cover-based constraint detector (see Definition 4.21). Consider any index  <span class="math">\\mathfrak{n}</span>  and subset  <span class="math">I \\subseteq D(\\mathfrak{n})</span> , and let W be the output of the algorithm. Let  <span class="math">d \\in \\{0, \\ldots, \\operatorname{depth}(T_\\mathfrak{n})\\}</span>  and  <span class="math">U \\subseteq \\operatorname{layer}(T_\\mathfrak{n}, d)</span>  be the objects associated to W (guaranteed by the definition of recursive-cover-based constraint detection). Let  <span class="math">S := T_\\mathfrak{n}|_d</span></p>

    <p class="text-gray-300">(i.e., S is the d-depth restriction of  <span class="math">T_n</span> ) and  <span class="math">S&#x27; := \\{(\\tilde{D}_u, \\tilde{C}_u)\\}_{u \\in U}</span> ; it suffices to show that S is |I|-local. The claim follows directly by the assumption on d and Lemma 4.20, because  <span class="math">T_{n,v}</span>  is c|I|-independent for every vertex v in  <span class="math">T_n</span>  with  <span class="math">\\operatorname{depth}(T_n, v) &lt; d</span> , and thus  <span class="math">S = T_n|_d</span>  is indeed a |I|-local cover of C.</p>

    <p class="text-gray-300"><strong>Corollary 4.26.</strong> Let  <span class="math">\\mathscr{C} = \\{C_n\\}_n</span>  be a linear code family with domain  <span class="math">D(\\cdot)</span>  and alphabet  <span class="math">\\mathbb{F}(\\cdot)</span> . If  <span class="math">\\mathscr{C}</span>  has recursive-cover-based constraint detection, then  <span class="math">\\mathscr{C}</span>  has succinct constraint detection.</p>

    <p class="text-gray-300"><em>Proof.</em> Follows directly from Lemma 4.25 (recursive-cover-based constraint detection implies cover-based constraint detection) and Lemma 4.22 (cover-based constraint detection implies succinct constraint detection).</p>

      <h4 id="sec-4.3.4" class="text-lg font-semibold mt-6">4.3.4 Proof of Theorem 4.12</h4>

    <p class="text-gray-300">The purpose of this section is to prove Theorem 4.12. By Corollary 4.26, it suffices to argue that the linear code family BS-RS has recursive-cover-based constraint detection (see Definition 4.24).</p>

    <p class="text-gray-300">Recall that we consider Reed&ndash;Solomon codes  <span class="math">\\mathrm{RS}[\\mathbb{F},L,d]</span>  where  <span class="math">\\mathbb{F}</span>  is an extension field of a base field  <span class="math">\\mathbb{K},L</span>  is a  <span class="math">\\mathbb{K}</span> -linear subspace in  <span class="math">\\mathbb{F}</span> , and  <span class="math">d=|L|\\cdot|\\mathbb{K}|^{-\\mu}</span>  for some  <span class="math">\\mu\\in\\mathbb{N}</span> ; and we denote by  <span class="math">\\mathrm{BS\\text{-}RS}[\\mathbb{K},\\mathbb{F},L,\\mu,k]</span>  the code obtained by concatenating codewords in  <span class="math">\\mathrm{RS}[\\mathbb{F},L,|L|\\cdot|\\mathbb{K}|^{-\\mu}]</span>  with corresponding [BS08] proximity proofs with &quot;base dimension&quot;  <span class="math">k\\in\\{1,\\ldots,\\dim(L)\\}</span>  (see Appendix F for details). The linear code family BS-RS is indexed by tuples  <span class="math">\\mathbb{N}=(\\mathbb{K},\\mathbb{F},L,\\mu,k)</span>  and the  <span class="math">\\mathbb{N}</span> -th code is  <span class="math">\\mathrm{BS\\text{-}RS}[\\mathbb{K},\\mathbb{F},L,\\mu,k]</span> .</p>

    <p class="text-gray-300">We represent indices  <span class="math">\\mathfrak m</span>  so that  <span class="math">\\log |\\mathbb F| + \\dim(L) + |\\mathbb K|^\\mu \\le \\operatorname{poly}(|\\mathfrak m|)</span> . The base field  <span class="math">\\mathbb K</span>  and extension field  <span class="math">\\mathbb F</span>  require  <span class="math">O(\\log |\\mathbb K|)</span>  and  <span class="math">O(\\log |\\mathbb F|)</span>  bits to represent; the subspace L requires  <span class="math">O(\\dim(L))</span>  elements in  <span class="math">\\mathbb F</span>  to represent; and the two integers  <span class="math">\\mu</span>  and k require  <span class="math">O(\\log \\mu)</span>  and  <span class="math">O(\\log k)</span>  bits to represent. In addition, we add  <span class="math">|\\mathbb K|^\\mu</span>  arbitrary bits of padding. Overall, we obtain that  <span class="math">|\\mathfrak m| = \\Theta(\\log |\\mathbb K| + \\log |\\mathbb F| + \\log |\\mathbb F| + \\log |\\mathbb F| + \\log \\mu + \\log \\mu + \\log \\mu + |\\mathbb K|^\\mu) = \\Theta(\\log |\\mathbb F| + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log \\mu + \\log</span></p>

    <p class="text-gray-300"><strong>Lemma 4.27.</strong> Define the depth function  <span class="math">d(\\mathbb{K}, L, \\mu, a) := \\log_2 \\dim(L) - \\log_2(\\log_{|\\mathbb{K}|} a + \\mu + 2) - 1</span> . The linear code family BS-RS satisfies the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>For every index  <span class="math">\\mathfrak{n} = (\\mathbb{K}, \\mathbb{F}, L, \\mu, k)</span> , BS-RS[ <span class="math">\\mathbb{K}, \\mathbb{F}, L, \\mu, k</span> ] has a 1-intersecting recursive cover  <span class="math">T_{\\mathfrak{n}}</span> . Also, for every positive integer m and non-leaf vertex v in  <span class="math">T_{\\mathfrak{n}}</span>  with  <span class="math">\\operatorname{depth}(T_{\\mathfrak{n}}, v) &lt; d(\\mathbb{K}, L, \\mu, m)</span> , the cover  <span class="math">T_{\\mathfrak{n}, v}</span>  is m-independent.</li>
      <li>There exists an algorithm that, given an index  <span class="math">\\mathfrak{n} = (\\mathbb{K}, \\mathbb{F}, L, \\mu, k)</span>  and subset  <span class="math">I \\subseteq D(\\mathfrak{n})</span> , outputs in time  <span class="math">\\operatorname{poly}(\\log |\\mathbb{F}| + \\dim(L) + |\\mathbb{K}|^{\\mu} + |I|)</span>  a subset  <span class="math">W \\subseteq \\mathbb{F}^{D(\\mathfrak{n})}</span>  for which there exist  <span class="math">U \\subseteq \\operatorname{layer}(T_{\\mathfrak{n}}, d(\\mathbb{K}, L, \\mu, |I|))</span>  such that: (i)  <span class="math">|U| \\le |I|</span> ; (ii)  <span class="math">I \\subseteq (\\cup_{u \\in U} \\tilde{D}_u)</span> ; (iii)  <span class="math">\\operatorname{span}(W) = \\operatorname{span}(\\cup_{u \\in U} \\tilde{C}_u^{\\perp})</span> .</li>
    </ul>

    <p class="text-gray-300">Given the above lemma, we can complete the proof of Theorem 4.12, as explained below. We defer the (long and technical) proof of the lemma to Appendix G, and instead end this section with an overview of that proof.</p>

    <p class="text-gray-300">Proof of Theorem 4.12. The proof follows from Lemma 4.27 above and from Corollary 4.26, as we now explain.</p>

    <p class="text-gray-300">Corollary 4.26 states that if a linear code family  <span class="math">\\mathscr{C}</span>  has recursive-cover-based constraint detection (see Definition 4.24), then  <span class="math">\\mathscr{C}</span>  has succinct constraint detection (see Definition 4.2). Also recall that the definition of recursive-cover-based detection requires having a c-intersecting recursive cover for each code in the class, and an algorithm satisfying certain properties.</p>

    <p class="text-gray-300">Observe that Lemma 4.27 guarantees that every code in BS-RS has a 1-intersecting recursive code and, moreover, guarantees the existence of an algorithm whose output satisfies the required properties. We are left to argue that the algorithm runs in time  <span class="math">\\operatorname{poly}(|\\mathfrak{n}|+|I|)</span> . But this immediately follows from the running time stated in Lemma 4.27 and the fact that  <span class="math">\\log |\\mathbb{F}| + \\dim(L) + |\\mathbb{K}|^{\\mu} \\leq \\operatorname{poly}(|\\mathfrak{n}|)</span> .</p>

    <p class="text-gray-300"><strong>Overview of Lemma 4.27's proof.</strong> We assume familiarity with the linear code family BS-RS from [BS08]; for completeness, we provide formal definitions and notations in Appendix F. Recall that the Reed&ndash;Solomon code is not locally testable, but one can test proximity to it with the aid of BS proximity proofs [BS08]; the linear code family BS-RS consists of the concatenation of Reed&ndash;Solomon codes with BS corresponding proximity proofs.</p>

    <p class="text-gray-300">The construction of the aforementioned proximity proofs is <em>recursive</em>, with each step in the recursion reducing both the evaluation domain size |L| and the degree d to (approximately) their square roots. Namely, testing proximity of a</p>

    <p class="text-gray-300">codeword w to  <span class="math">\\mathrm{RS}[\\mathbb{F}, L, d]</span>  is reduced to testing proximity of  <span class="math">\\Theta(\\sqrt{|L|})</span>  codewords  <span class="math">\\{w_i\\}_i</span>  to  <span class="math">\\{\\mathrm{RS}[\\mathbb{F}, L_i, d_i]\\}_i</span> , where  <span class="math">|L_i|, d_i = \\Theta(\\sqrt{|L|})</span>  for each i. This step is then recursively applied (by way of proof composition [AS98]) to each codeword  <span class="math">w_i</span> , until the domain size is &quot;small enough&quot;.</p>

    <p class="text-gray-300">The first part of the proof of Lemma 4.27 consists of various combinatorial claims (see Appendix G.1). First, we observe that the union of the domains of the codewords  <span class="math">w_i</span>  covers (and, actually, slightly expands) the domain of the original codeword w; this holds recursively, and induces a recursive cover T (see Definition G.3). We prove that T is 1-intersecting (see Claim G.4) and that, for every vertex v in T of depth at most d, the cover  <span class="math">T_v</span>  is  <span class="math">(|L|^{2^{-d-1}} \\cdot |\\mathbb{K}|^{-\\mu-2})</span> -independent, which implies the stated independence property about  <span class="math">T_v</span>  (see Claim G.5). The core of the argument for this second claim is to show that the code  <span class="math">\\tilde{C}_v</span>  equals BS-RS[ <span class="math">\\mathbb{K}</span> ,  <span class="math">\\mathbb{F}</span> ,  <span class="math">L_v</span> ,  <span class="math">\\mu</span> , k] for some subspace  <span class="math">L_v</span>  such that  <span class="math">\\dim(L) \\cdot 2^{-d} \\leq \\dim(\\tilde{L}) \\leq \\dim(L) \\cdot 2^{-d} + 2\\mu</span>  (see Claim G.6).</p>

    <p class="text-gray-300">The second part of the proof of Lemma 4.27 consists of establishing the computational efficiency of certain tasks related to the recursive cover (see Appendix G.2). Specifically, we bound the time required to compute a spanning set for covers in T (see Claim G.8). After a few more observations, we are able to conclude the proof.</p>

    </section>

    <section id="sec-5" class="mb-10">
      <h2 class="text-2xl font-bold">5 Sumcheck with perfect zero knowledge</h2>

    <p class="text-gray-300">We obtain an IPCPP for sumcheck that is perfect zero knowledge against unbounded queries. (Since the input F is an oracle given to the verifier, the proof system is formally an exact IPCP of proximity for a promise relation.)</p>

    <p class="text-gray-300"><strong>Sumcheck.</strong> The sumcheck protocol [LFKN92, Sha92] is an IP for the claim &quot; <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} F(\\vec{\\alpha}) = 0</span> &quot;, where F is a polynomial in  <span class="math">\\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span>  and H is a subset of  <span class="math">\\mathbb{F}</span> . The prover and verifier have input  <span class="math">(\\mathbb{F}, m, d, H)</span>  and oracle access to (the evaluation table on  <span class="math">\\mathbb{F}^m</span>  of) F. The sumcheck protocol has soundness error  <span class="math">1 - (1 - \\frac{d}{|\\mathbb{F}|})^m</span> ; the prover runs in space  <span class="math">\\operatorname{poly}(\\log |\\mathbb{F}| + m + d + |H|)</span>  and the verifier in time  <span class="math">\\operatorname{poly}(\\log |\\mathbb{F}| + m + d + |H|)</span> ; the number of rounds is m; finally, the protocol is public coin and the verifier queries F only at one random point.</p>

    <p class="text-gray-300"><strong>Leakage.</strong> The sumcheck protocol is <em>not</em> zero knowledge: a verifier, by interacting with the honest prover, learns partial sums of F, in addition to the fact that &quot; <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} F(\\vec{\\alpha}) = 0</span> &quot; is true. Assuming one way functions, one <em>can</em> make any interactive proof, including the sumcheck protocol, to be (computational) zero knowledge [GMR89, IY87, BGG<sup>+</sup>88]; moreover, one-way functions are necessary for obtaining zero knowledge IPs for non-trivial languages [OW93]. As we do not wish to make intractability assumptions, we now turn to a different proof system model.</p>

    <p class="text-gray-300"><strong>Perfect zero knowledge via IPCPPs.</strong> We obtain an IPCPP for sumcheck that is perfect zero knowledge against unbounded queries. Namely, a malicious verifier has oracle access to a proof string  <span class="math">\\pi</span>  and also interacts with the prover, but learns no information about F beyond the fact that the statement about F is true, in the following sense. There exists an algorithm that perfectly simulates the verifier's view by making as many queries to F as the <em>total</em> number of verifier queries to either F or the oracle  <span class="math">\\pi</span> . (Analogously to zero knowledge for proximity testers, a verifier may query F at any time, so any such information comes &quot;for free&quot; and, also, any query to  <span class="math">\\pi</span>  'counts' as a query to F; see Section 3.3.) Our construction proceeds in two steps:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Step 1. We modify the sumcheck protocol to make it perfect zero knowledge, but in a hybrid model where the prover and verifier have access to a random polynomial  <span class="math">R \\in \\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span> . Crucially, soundness relies only on the fact that R is low-degree, but not the fact that it is random. Also, the modified protocol does <em>not</em> depend on a bound on the malicious verifier's queries, and thus maintains zero knowledge even against unbounded queries.</li>
      <li>Step 2. We observe that in the IPCPP model the prover can send an oracle proof string  <span class="math">\\pi</span>  that represents the evaluation table of R, and the verifier can test that  <span class="math">\\pi</span>  is close to low-degree, and then use self correction to query it. This extension preserves the zero knowledge properties of the previous step.</li>
    </ul>

    <p class="text-gray-300">The more interesting of the two steps is the first one, so we briefly discuss the intuition behind it. Our idea is that, rather than executing the sumcheck protocol on F directly, the prover tells the verifier that  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} R(\\vec{\\alpha}) = z</span> , then they engage in the sumcheck protocol on the claim  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} \\rho F(\\vec{\\alpha}) + R(\\vec{\\alpha}) = z</span> , where  <span class="math">\\rho</span>  is chosen at random by the verifier (after R is sampled). Completeness is clear because if  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} F(\\vec{\\alpha}) = 0</span>  and  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} R(\\vec{\\alpha}) = z</span>  then  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} (\\rho F + R)(\\vec{\\alpha}) = z</span> ; soundness is also clear because if  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} F(\\vec{\\alpha}) \\neq 0</span>  then  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} (\\rho F + R)(\\vec{\\alpha}) \\neq z</span>  with high probability over  <span class="math">\\rho</span>  (regardless of whether  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} R(\\vec{\\alpha}) = z</span>  or not). We are thus left to show perfect zero knowledge, which turns out to be a much less straightforward argument.</p>

    <p class="text-gray-300">On the surface, perfect zero knowledge appears easy to argue: simply note that  <span class="math">\\rho F + R</span>  is random among all polynomials in  <span class="math">\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span> . However, this argument, while compelling, is not enough. First,  <span class="math">\\rho F + R</span>  is not random because a malicious verifier can choose  <span class="math">\\rho</span>  depending on queries to R; we discuss this issue further down below. Second, even if  <span class="math">\\rho F + R</span>  were random (e.g., the verifier does not query R before choosing  <span class="math">\\rho</span> ), the simulator must run in polynomial time but it is not clear how that is possible, as we now explain.</p>

    <p class="text-gray-300">Consider the following simulator: (1) sample a random polynomial  <span class="math">Q_{\\text{sim}} \\in \\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span>  and use it to simulate  <span class="math">\\rho F + R</span> ; (2) whenever the verifier queries  <span class="math">F(\\vec{\\alpha})</span> , respond by querying  <span class="math">F(\\vec{\\alpha})</span>  and returning the true value; (3) whenever the verifier queries  <span class="math">R(\\vec{\\alpha})</span> , respond by querying  <span class="math">F(\\vec{\\alpha})</span>  and returning  <span class="math">Q_{\\text{sim}}(\\vec{\\alpha}) - \\rho F(\\vec{\\alpha})</span> . One can argue that the simulator produces the correct distribution; moreover, the number of queries to F made by the simulator equals the number of (mutually) distinct queries to F and R made by the verifier, as desired.</p>

    <p class="text-gray-300">But how does the simulator sample a random polynomial in  <span class="math">\\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span>  in polynomial time? The size of the representation of such a polynomial is  <span class="math">\\Omega(d^m)</span> , which is exponential. We get around this problem by exploiting the fact that the number of queries the verifier can make is polynomially bounded, and the simulator can keep state about the answers to past queries and 'make up' on the fly the answer to a new query by resolving dependencies between queries.</p>

    <p class="text-gray-300">More precisely, we leverage our construction of a succinct constraint detector for evaluations of low-degree polynomials (see Section 4.2), which itself relies on tools borrowed from algebraic complexity theory. The same detector also allows to simulate <em>partial sums</em>, which the prover sends in the course of the sumcheck protocol itself.</p>

    <p class="text-gray-300">Finally, we explain how we address the issue that the verifier may choose to query R before sending  <span class="math">\\rho</span> . We handle this by first (implicitly) sampling a random polynomial  <span class="math">R_{\\rm sim}</span> , and responding to each verifier query to  <span class="math">R(\\vec{\\alpha})</span>  with  <span class="math">R_{\\rm sim}(\\vec{\\alpha})</span> . Then, when the verifier sends  <span class="math">\\rho</span> , we draw  <span class="math">Q_{\\rm sim}</span>  conditioned on the already-queried values for R being 'correct'; i.e., for each point  <span class="math">\\vec{\\alpha}</span>  queried before  <span class="math">\\rho</span>  is sent, we add the condition that  <span class="math">Q_{\\rm sim}(\\vec{\\alpha}) = \\rho F(\\vec{\\alpha}) + R_{\\rm sim}(\\vec{\\alpha})</span> . We then continue as described above, and it is not too difficult to argue that this strategy yields the correct distribution.</p>

    <p class="text-gray-300">We are now ready to turn the above discussions into formal definitions and proofs. First, we give the definition of the sumcheck relation and of a PZK IPCPP system for sumcheck; then we state and prove the PZK Sumcheck Theorem.</p>

    <p class="text-gray-300"><strong>Definition 5.1.</strong> The sumcheck relation and its promise variant are defined as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The sumcheck relation is the relation  <span class="math">\\mathscr{R}_{SC}</span>  of instance-witness pairs  <span class="math">((\\mathbb{F}, m, d, H, v), F)</span>  such that (i)  <span class="math">\\mathbb{F}</span>  is a finite field, H is a subset of  <span class="math">\\mathbb{F}</span> , v is an element of  <span class="math">\\mathbb{F}</span> , and m, d are positive integers with  <span class="math">\\frac{md}{|\\mathbb{F}|} &lt; \\frac{1}{2}</span> ; (ii) F is in  <span class="math">\\mathbb{F}^{&lt; d}[X_1, \\ldots, X_m]</span>  and sums to v on  <span class="math">H^m</span> .</li>
      <li>The sumcheck promise relation is the pair of relations  <span class="math">(\\mathscr{R}_{SC}^{YES}, \\mathscr{R}_{SC}^{NO})</span>  where  <span class="math">\\mathscr{R}_{SC}^{YES} := \\mathscr{R}_{SC}</span>  and  <span class="math">\\mathscr{R}_{SC}^{NO}</span>  are the pairs  <span class="math">((\\mathbb{F}, m, d, H, v), F)</span>  such that  <span class="math">(\\mathbb{F}, m, d, H, v)</span>  is as above and  <span class="math">F \\in \\mathbb{F}^{&lt; d}[X_1, \\ldots, X_m]</span>  but does <u>not</u> sum to v on  <span class="math">H^m</span> .</li>
    </ul>

    <p class="text-gray-300"><strong>Definition 5.2.</strong> A PZK exact IPCPP system for sumcheck with soundness error  <span class="math">\\varepsilon</span>  is a pair of interactive algorithms (P, V) that satisfies the following properties.<sup>9</sup></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\bullet \\ \\ \\text{Completeness. For every} \\ \\left( (\\mathbb{F}, m, d, H, v), F \\right) \\in \\mathscr{R}_{\\mathrm{SC}}^{\\mathrm{YES}}, \\ \\Pr \\left[ \\langle P^F(\\mathbb{F}, m, d, H, v), V^F(\\mathbb{F}, m, d, H, v) \\rangle = 1 \\right] = 1.</span></li>
      <li><span class="math">\\bullet \\ \\ \\text{Soundness. For every } \\left( (\\mathbb{F}, m, d, H, v), F \\right) \\in \\mathscr{R}^{\\text{NO}}_{\\mathrm{SC}} \\ \\ \\text{and malicious prover} \\ \\tilde{P}, \\ \\Pr \\left[ \\langle \\tilde{P}, V^F(\\mathbb{F}, m, d, H, v) \\rangle = 1 \\right] \\leq \\varepsilon.</span></li>
      <li>PERFECT ZERO KNOWLEDGE. There exists a straightline simulator S such that, for every  <span class="math">((\\mathbb{F}, m, d, H, v), F) \\in \\mathscr{R}^{\\mathsf{YES}}_{SC}</span>  and malicious verifier  <span class="math">\\tilde{V}</span> , the following two random variables are identically distributed</li>
    </ul>

    <p class="text-gray-300"><span class="math">$\\left(S^{\\tilde{V},F}(\\mathbb{F},m,d,H,v)\\;,\\;q_S\\right)\\quad \\text{and}\\quad \\left(\\mathrm{View}\\;\\langle P^F(\\mathbb{F},m,d,H,v),\\tilde{V}^F\\rangle\\;,\\;q_{\\tilde{V}}\\right)\\;,</span>$</p>

    <p class="text-gray-300">where  <span class="math">q_S</span>  is the number of queries to F made by S and  <span class="math">q_{\\tilde{V}}</span>  is the number of queries to F or the PCP oracle made by  <span class="math">\\tilde{V}</span> . Moreover, S runs in time  <span class="math">\\operatorname{poly}(\\log |\\mathbb{F}| + |H| + m + q_{\\tilde{V}})</span> , where  <span class="math">q_{\\tilde{V}}</span>  is  <span class="math">\\tilde{V}</span> 's query complexity.</p>

    <p class="text-gray-300"><strong>Theorem 5.3</strong> (PZK Sumcheck). There exists a PZK public-coin exact IPCPP system (P, V) for the sumcheck promise relation  <span class="math">(\\mathscr{R}_{SC}^{\\text{YES}}, \\mathscr{R}_{SC}^{\\text{NO}})</span>  with soundness error  <span class="math">\\varepsilon = O(\\frac{md}{|\\mathbb{F}|})</span>  and the following efficiency parameters.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Oracle round: P sends an oracle proof string  <span class="math">\\pi: \\mathbb{F}^m \\to \\mathbb{F}</span> .</li>
      <li>Interactive proof: after the oracle round, P and V engage in an (m+1)-round interactive proof; in total, the verifier sends to the prover O(m) field elements, while the prover sends to the verifier O(md) field elements.</li>
      <li>Queries: after the interactive proof, V non-adaptively queries  <span class="math">\\pi</span>  at poly(log  <span class="math">|\\mathbb{F}| + m + d</span> ) locations.</li>
      <li>Space and time: P runs in space  <span class="math">poly(log |\\mathbb{F}| + m + d + |H|)</span> , while V in time  <span class="math">poly(log |\\mathbb{F}| + m + d + |H|)</span> . (The prover's space complexity assumes that the randomness tape is two-way rather than one-way; see Remark 5.7 below.)</li>
    </ul>

      <h3 id="sec-5.1" class="text-xl font-semibold mt-8">5.1 Step 1</h3>

    <p class="text-gray-300">We construct a public-coin IP for sumcheck that is perfect zero knowledge, in the &quot;R-hybrid&quot; model, where the prover and verifier have access to a uniformly random  <span class="math">R \\in \\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span> .</p>

    <p class="text-gray-300"><strong>Construction 5.4.</strong> The IP system  <span class="math">(P_{\\mathrm{IP}}, V_{\\mathrm{IP}})</span>  is defined as follows. Both  <span class="math">P_{\\mathrm{IP}}</span>  and  <span class="math">V_{\\mathrm{IP}}</span>  receive a tuple  <span class="math">(\\mathbb{F}, m, d, H, v)</span>  as common input, and two polynomials  <span class="math">F, R \\in \\mathbb{F}^{&lt; d}[X_1, \\ldots, X_m]</span>  as oracles. The interaction proceeds as follows:</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;8</sup>This promise is <em>not</em> the same notion as in Section 3.2.3; there the promise is with respect to instances, whereas here it is with respect to witnesses.</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;9</sup>This is exactly the standard definition of an IPCPP (Section 3.3.2), but with a soundness condition respecting our current notion of a promise.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">P_{\\mathrm{IP}}</span>  sends  <span class="math">z := \\sum_{\\vec{\\alpha} \\in H^m} R(\\vec{\\alpha})</span>  to  <span class="math">V_{\\mathrm{IP}}</span> ;</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">V_{\\rm IP}</span>  draws a random element  <span class="math">\\rho</span>  in  <span class="math">\\mathbb{F}</span> , and sends  <span class="math">\\rho</span>  to  <span class="math">P_{\\rm IP}</span> ;</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">P_{\\text{IP}}</span>  and  <span class="math">V_{\\text{IP}}</span>  run the sumcheck IP [LFKN92, Sha92] on the statement &quot; <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} Q(\\vec{\\alpha}) = \\rho v + z</span> &quot; where  <span class="math">Q := \\rho F + R</span>  (with  <span class="math">P_{\\text{IP}}</span>  playing the role of the prover and  <span class="math">V_{\\text{IP}}</span>  that of the verifier).</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Note that  <span class="math">(P_{IP}, V_{IP})</span>  is public-coin, and satisfies the following efficiency properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Communication: The number of rounds is m+1. Across the interaction,  <span class="math">V_{\\rm IP}</span>  sends O(m) field elements to  <span class="math">P_{\\rm IP}</span> , while  <span class="math">P_{\\rm IP}</span>  sends O(md) field elements to  <span class="math">V_{\\rm IP}</span> .</li>
      <li>Queries:  <span class="math">V_{\\rm IP}</span>  queries F and R each at a single random point because, at the end of the sumcheck protocol, the verifier queries Q at a random point  <span class="math">\\vec{\\gamma}</span> , and such a query can be &quot;simulated&quot; by querying F and R at  <span class="math">\\vec{\\gamma}</span>  and then using these answers, along with  <span class="math">\\rho</span> , to compute the necessary value for Q.</li>
      <li>Space and time:  <span class="math">P_{\\text{IP}}</span>  runs in space  <span class="math">\\text{poly}(\\log |\\mathbb{F}| + m + d + |H|)</span> , while  <span class="math">V_{\\text{IP}}</span>  in time  <span class="math">\\text{poly}(\\log |\\mathbb{F}| + m + d + |H|)</span> . (The prover's space complexity assumes that the randomness tape is two-way; see Remark 5.7 below.)</li>
    </ul>

    <p class="text-gray-300">We now state and prove the completeness, soundness, and perfect zero knowledge properties.</p>

    <p class="text-gray-300"><strong>Lemma 5.5.</strong> The IP system  <span class="math">(P_{IP}, V_{IP})</span>  satisfies the following properties.</p>

    <p class="text-gray-300">&bull; Completeness. For every  <span class="math">\\left((\\mathbb{F},m,d,H,v),F\\right)\\in\\mathscr{R}_{\\mathrm{SC}}^{\\mathrm{YES}}</span>  and  <span class="math">R\\in\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span>  with  <span class="math">\\sum_{\\vec{\\alpha}\\in H^m}R(\\vec{\\alpha})=0</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[\\langle P_{\\mathrm{IP}}^{F,R}(\\mathbb{F},m,d,H,v), V_{\\mathrm{IP}}^{F,R}(\\mathbb{F},m,d,H,v)\\rangle = 1\\right] = 1 \\ .</span>$</p>

    <p class="text-gray-300">&bull; SOUNDNESS. For every  <span class="math">((\\mathbb{F}, m, d, H, v), F) \\in \\mathscr{R}^{NO}_{SC}</span> ,  <span class="math">R \\in \\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span> , and malicious prover  <span class="math">\\tilde{P}</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[\\langle \\tilde{P}, V_{\\text{IP}}^{F,R}(\\mathbb{F}, m, d, H, v) \\rangle = 1\\right] \\le \\frac{md + 1}{|\\mathbb{F}|}.</span>$</p>

    <p class="text-gray-300">&bull; PERFECT ZERO KNOWLEDGE. There exists a straightline simulator  <span class="math">S_{\\text{IP}}</span>  such that, for every  <span class="math">\\left((\\mathbb{F}, m, d, H, v), F\\right) \\in \\mathscr{R}_{\\text{SC}}^{\\text{YES}}</span>  and malicious verifier  <span class="math">\\tilde{V}</span> , the following two random variables are identically distributed</p>

    <p class="text-gray-300"><span class="math">$\\left(S_{\\mathrm{IP}}^{\\tilde{V},F}(\\mathbb{F},m,d,H,v)\\;,\\;q_{S_{\\mathrm{IP}}}\\right)\\quad\\text{and}\\quad\\left(\\mathrm{View}\\;\\langle P_{\\mathrm{IP}}^{F,R}(\\mathbb{F},m,d,H,v),\\tilde{V}^{F,R}\\rangle\\;,\\;q_{\\tilde{V}}\\right)\\;,</span>$</p>

    <p class="text-gray-300">where R is uniformly random in  <span class="math">\\mathbb{F}^{&lt; d}[X_1, \\ldots, X_m]</span> ,  <span class="math">q_{S_{\\mathrm{IP}}}</span>  is the number of queries to F made by  <span class="math">S_{\\mathrm{IP}}</span> , and  <span class="math">q_{\\tilde{V}}</span>  is the number of queries to F or R made by  <span class="math">\\tilde{V}</span> . Moreover,  <span class="math">S_{\\mathrm{IP}}</span>  runs in time  <span class="math">\\operatorname{poly}(\\log |\\mathbb{F}| + m + d + |H| + \\mathsf{q}_{\\tilde{V}})</span>  where  <span class="math">\\mathsf{q}_{\\tilde{V}}</span>  is  <span class="math">\\tilde{V}</span> 's query complexity.</p>

    <p class="text-gray-300"><em>Proof.</em> We argue first completeness, then soundness, and, finally, perfect zero knowledge.</p>

    <p class="text-gray-300"><strong>Completeness.</strong> If both F sums to v on  <span class="math">H^m</span>  and R sums to z on  <span class="math">H^m</span> , then  <span class="math">Q := \\rho F + R</span>  sums to  <span class="math">\\rho v + z</span>  on  <span class="math">H^m</span>  for every choice of  <span class="math">\\rho</span> . Then completeness follows from the completeness of standard sumcheck.</p>

    <p class="text-gray-300"><strong>Soundness.</strong> For every  <span class="math">F, R \\in \\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span>  with  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} F(\\vec{\\alpha}) \\neq v, \\sum_{\\vec{\\alpha} \\in H^m} Q(\\vec{\\alpha})</span>  equals  <span class="math">\\rho v + z</span>  for at most one choice of  <span class="math">\\rho</span> , namely,  <span class="math">(\\sum_{\\vec{\\alpha} \\in H^m} R(\\vec{\\alpha}) - z)/(v - \\sum_{\\vec{\\alpha} \\in H^m} F(\\vec{\\alpha}))</span> . Thus, except with probability  <span class="math">1/|\\mathbb{F}|</span> , the sumcheck protocol is invoked on an incorrect claim, which incurs a soundness error of at most  <span class="math">\\frac{md}{|\\mathbb{F}|}</span> . The claimed soundness error follows by a union bound.</p>

    <p class="text-gray-300"><strong>Perfect zero knowledge.</strong> We begin by proving perfect zero knowledge via a straightline simulator  <span class="math">S_{\\text{slow}}</span>  whose number of queries to F equals  <span class="math">q_{\\tilde{V}}</span> , but runs in time  <span class="math">\\text{poly}(|\\mathbb{F}|^m + q_{\\tilde{V}})</span> . After that, we explain how to modify  <span class="math">S_{\\text{slow}}</span>  into another simulator  <span class="math">S_{\\text{IP}}</span> , with an identical output distribution, that runs in the faster time claimed in the lemma.</p>

    <p class="text-gray-300">The simulator  <span class="math">S_{\\text{slow}}</span> , given straightline access to  <span class="math">\\tilde{V}</span>  and oracle access to F, works as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>1. Draw a uniformly random  <span class="math">R_{\\text{sim}} \\in \\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span>  and send  <span class="math">z_{\\text{sim}} := \\sum_{\\vec{\\alpha} \\in H^m} R_{\\text{sim}}(\\vec{\\alpha})</span>  to  <span class="math">\\tilde{V}</span> .</li>
      <li>2. Whenever  <span class="math">\\tilde{V}</span>  queries F at  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^m</span> , return  <span class="math">F(\\vec{\\gamma})</span> ; whenever  <span class="math">\\tilde{V}</span>  queries R at  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^m</span> , return  <span class="math">R_{\\text{sim}}(\\vec{\\gamma})</span> .</li>
      <li>3. Receive  <span class="math">\\tilde{\\rho}</span>  from  <span class="math">\\tilde{V}</span> , and draw a uniformly random  <span class="math">Q_{\\text{sim}} \\in \\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span>  conditioned on  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} Q_{\\text{sim}}(\\vec{\\alpha}) = \\tilde{\\rho}v + z_{\\text{sim}}</span>  and  <span class="math">Q_{\\text{sim}}(\\vec{\\gamma}) = \\tilde{\\rho}F(\\vec{\\gamma}) + R_{\\text{sim}}(\\vec{\\gamma})</span>  for every coordinate  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^m</span>  queried in Step 2. (This latter condition requires querying F at  <span class="math">\\vec{\\gamma}</span>  for every coordinate  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^m</span>  queried to  <span class="math">R_{\\text{sim}}</span>  in Step 2.)</li>
      <li>4. Hereafter: whenever  <span class="math">\\tilde{V}</span>  queries F at  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^m</span> , return  <span class="math">F(\\vec{\\gamma})</span> ; whenever  <span class="math">\\tilde{V}</span>  queries R at  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^m</span> , return  <span class="math">Q_{\\text{sim}}(\\vec{\\gamma}) - \\tilde{\\rho}F(\\vec{\\gamma})</span> . (In either case, a query to F is required.)</li>
      <li>5. Run the sumcheck protocol with  <span class="math">\\tilde{V}</span>  on  <span class="math">Q_{\\text{sim}}</span> . (Note that  <span class="math">\\tilde{V}</span>  may query F or R before, during, or after this protocol.)</li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Output the view of the simulated  <span class="math">\\tilde{V}</span> .</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Note that  <span class="math">S_{\\mathrm{slow}}</span>  runs in time  <span class="math">\\mathrm{poly}(|\\mathbb{F}|^m + q_{\\tilde{V}})</span> . Also,  <span class="math">S_{\\mathrm{slow}}</span>  makes one query to F for every query to F or R by  <span class="math">\\tilde{V}</span>  (at least provided that  <span class="math">\\tilde{V}</span> 's queries have no duplicates, which we can assume without loss of generality). Thus, overall, the number of queries to F by  <span class="math">S_{\\mathrm{slow}}</span>  is  <span class="math">q_{\\tilde{V}}</span> . We now argue that  <span class="math">S_{\\mathrm{slow}}</span> 's output is identically distributed to  <span class="math">\\tilde{V}</span> 's view when interacting with the honest prover  <span class="math">P_{\\mathrm{IP}}</span> , for R random in  <span class="math">\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span> .</p>

    <p class="text-gray-300">Claim.
<span class="math">$S_{\\text{slow}}^{\\tilde{V},F} \\equiv \\text{View } \\langle P_{\\text{IP}}^{F,R}, \\tilde{V}^{F,R} \\rangle</span>$
.</p>

    <p class="text-gray-300"><em>Proof.</em> Define the random variable  <span class="math">Q := \\tilde{\\rho}F + R</span> , where  <span class="math">\\tilde{\\rho}</span>  is chosen by  <span class="math">\\tilde{V}</span> . Observe that there exists a (deterministic) function  <span class="math">v(\\cdot)</span>  such that</p>

    <p class="text-gray-300">View
<span class="math">$\\langle P_{\\mathrm{IP}}^{F,R}, \\tilde{V}^{F,R} \\rangle = v(Q, F, r)</span>$
and  <span class="math">S_{\\mathrm{slow}}^{\\tilde{V},F} = v(Q_{\\mathrm{sim}}, F, r)</span> ,</p>

    <p class="text-gray-300">where the random variable r is  <span class="math">\\tilde{V}</span> 's private randomness. Indeed, (i) the messages sent and received by  <span class="math">\\tilde{V}</span>  are identical to those when interacting with  <span class="math">P_{\\rm IP}</span>  on Q and  <span class="math">Q_{\\rm sim}</span> , respectively; (ii)  <span class="math">\\tilde{V}</span> 's queries to F are answered honestly; (iii)  <span class="math">\\tilde{V}</span> 's queries to R are answered by  <span class="math">R=Q-\\tilde{\\rho}F</span>  and  <span class="math">R_{\\rm sim}=Q_{\\rm sim}-\\tilde{\\rho}F</span>  respectively. We are only left to argue that, for any choice of r, Q and  <span class="math">Q_{\\rm sim}</span>  are identically distributed:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">-Q = \\tilde{\\rho}F + R</span>  is uniformly random in  <span class="math">\\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span>  conditioned on  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} Q(\\vec{\\alpha}) = \\tilde{\\rho}v + z</span> , because R is uniformly random in  <span class="math">\\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span>  and satisfies  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} R(\\vec{\\alpha}) = z</span>  (and F is in  <span class="math">\\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span>  and satisfies  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} F(\\vec{\\alpha}) = v</span> ); and</li>
      <li><span class="math">Q_{\\mathrm{sim}}</span>  is uniformly random in  <span class="math">\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span>  conditioned on  <span class="math">\\sum_{\\vec{\\alpha}\\in H^m}Q_{\\mathrm{sim}}(\\vec{\\alpha})=\\tilde{\\rho}v+z_{\\mathrm{sim}}</span> , because  <span class="math">Q_{\\mathrm{sim}}</span>  is sampled at random in  <span class="math">\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span>  conditioned on  <span class="math">\\sum_{\\vec{\\alpha}\\in H^m}Q_{\\mathrm{sim}}(\\vec{\\alpha})=\\tilde{\\rho}v+z_{\\mathrm{sim}}</span>  and  <span class="math">Q_{\\mathrm{sim}}(\\vec{\\gamma}_i)=R_{\\mathrm{sim}}(\\vec{\\gamma}_i)+\\tilde{\\rho}F(\\vec{\\gamma}_i)</span>  for some (adversarial) choice of  <span class="math">\\vec{\\gamma}_1,\\ldots,\\vec{\\gamma}_k</span> . But  <span class="math">R_{\\mathrm{sim}}</span>  is uniformly random in  <span class="math">\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span> , so the latter condition says that  <span class="math">Q_{\\mathrm{sim}}</span>  matches a random polynomial on the set of points  <span class="math">\\{\\vec{\\gamma}_1,\\ldots,\\vec{\\gamma}_k\\}</span> , giving the claimed distribution for  <span class="math">Q_{\\mathrm{sim}}</span> .</li>
    </ul>

    <p class="text-gray-300">We explain how to modify  <span class="math">S_{\\text{slow}}</span>  so as to reduce the running time to  <span class="math">\\text{poly}(\\log |\\mathbb{F}| + m + d + |H| + q_{\\tilde{V}})</span> .</p>

    <p class="text-gray-300">Note that  <span class="math">S_{\\mathrm{slow}}</span> 's inefficiency arises from sampling two random polynomials in  <span class="math">\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span> , namely  <span class="math">R_{\\mathrm{sim}}</span>  and  <span class="math">Q_{\\mathrm{sim}}</span> , subject to certain constraints, and using them to answer  <span class="math">\\tilde{V}</span> 's messages and queries. We observe (and carefully justify below) that all information about  <span class="math">R_{\\mathrm{sim}}</span>  and  <span class="math">Q_{\\mathrm{sim}}</span>  received by  <span class="math">\\tilde{V}</span>  is answers to queries of the form &quot;given  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^{\\leq m}</span> , return the value  <span class="math">A(\\vec{\\gamma}) := \\sum_{\\vec{\\alpha} \\in H^{m-|\\vec{\\gamma}|}} A(\\vec{\\gamma}, \\vec{\\alpha})</span> &quot; for a random  <span class="math">A \\in \\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span> , possibly conditioned on previous such queries; when  <span class="math">\\vec{\\gamma}</span>  has length zero we use the symbol  <span class="math">\\bot</span> , so that  <span class="math">A(\\bot)</span>  denotes  <span class="math">\\sum_{\\vec{\\alpha} \\in H^m} A(\\vec{\\alpha})</span> . The new simulator can use the algorithm A from our Corollary 4.10 to adaptively answer such queries, without ever explicitly sampling the two polynomials.</p>

    <p class="text-gray-300">We now argue that all information about  <span class="math">R_{\\rm sim}</span>  and  <span class="math">Q_{\\rm sim}</span>  received by  <span class="math">\\tilde{V}</span>  from  <span class="math">S_{\\rm slow}</span>  can be viewed as queries of the above form, by discussing each step of  <span class="math">S_{\\rm slow}</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><p class="text-gray-300">In Step 1,  <span class="math">S_{\\text{slow}}</span>  draws a uniformly random  <span class="math">R_{\\text{sim}} \\in \\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span>  and sends  <span class="math">z_{\\text{sim}} = R_{\\text{sim}}(\\bot)</span> .</p></li>
      <li><p class="text-gray-300">In Step 2,  <span class="math">S_{\\text{slow}}</span>  answers any query  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^m</span>  to R with  <span class="math">R_{\\text{sim}}(\\vec{\\gamma})</span> .</p></li>
      <li><p class="text-gray-300">In Step 3,  <span class="math">S_{\\text{slow}}</span>  draws a uniformly random  <span class="math">Q_{\\text{sim}} \\in \\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span>  conditioned on  <span class="math">Q_{\\text{sim}}(\\bot) = \\tilde{\\rho}v + z_{\\text{sim}}</span>  and also on  <span class="math">Q_{\\text{sim}}(\\vec{\\gamma}) = R_{\\text{sim}}(\\vec{\\gamma}) + \\tilde{\\rho}F(\\vec{\\gamma})</span>  for at most  <span class="math">q_{\\tilde{V}}</span>  points  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^m</span>  (namely, the points corresponding to queries in Step 2).</p></li>
      <li><p class="text-gray-300">In Step 4,  <span class="math">S_{\\text{slow}}</span>  replies any query  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^m</span>  to R with  <span class="math">Q_{\\text{sim}}(\\vec{\\gamma}) \\tilde{\\rho}F(\\vec{\\gamma})</span> .</p></li>
      <li><p class="text-gray-300">In Step 5,  <span class="math">S_{\\mathrm{slow}}</span>  runs the sumcheck protocol with  <span class="math">\\tilde{V}</span>  on  <span class="math">Q_{\\mathrm{sim}}</span> , which requires computing univariate polynomials of the form  <span class="math">\\sum_{\\vec{\\alpha} \\in H^{m-|\\theta|-1}} Q_{\\mathrm{sim}}(\\vec{\\theta}, X, \\vec{\\alpha}) \\in \\mathbb{F}[X]</span>  for various choices of  <span class="math">\\vec{\\theta} \\in \\mathbb{F}^{&lt; m}</span> . Each of these polynomials has degree less than d, and so can be obtained by interpolation from its evaluation at any d distinct points; each of these is the answer of a query  <span class="math">Q_{\\mathrm{sim}}(\\vec{\\gamma})</span>  of the required form, with  <span class="math">\\vec{\\gamma} = (\\vec{\\theta}, \\delta)</span>  for some  <span class="math">\\delta \\in \\mathbb{F}</span> . Overall, during the protocol,  <span class="math">S_{\\mathrm{slow}}</span>  only needs to query  <span class="math">Q_{\\mathrm{sim}}</span>  at md points  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^{\\leq m}</span> .</p></li>
    </ul>

    <p class="text-gray-300">In sum, we can modify  <span class="math">S_{\\text{slow}}</span>  so that instead of explicitly sampling  <span class="math">R_{\\text{sim}}</span>  and  <span class="math">Q_{\\text{sim}}</span> , it uses  <span class="math">\\mathcal{A}</span>  to sample the answer for each query to  <span class="math">Q_{\\text{sim}}</span>  or  <span class="math">R_{\\text{sim}}</span> , conditioning the uniform distribution on the answers to previous queries. Putting all of this together, we obtain the simulator  <span class="math">S_{\\text{IP}}</span>  described below, whose output is identically distributed to the output of  <span class="math">S_{\\text{slow}}</span> .</p>

    <p class="text-gray-300">The simulator  <span class="math">S_{\\rm IP}</span> , given straightline access to  <span class="math">\\tilde{V}</span>  and oracle access to F, works as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Let  <span class="math">\\operatorname{ans}_{R_{\\operatorname{sim}}}</span>  be a subset of  <span class="math">\\mathbb{F}^{\\leq m} \\times \\mathbb{F}</span>  that records query-value pairs for  <span class="math">R_{\\operatorname{sim}}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Whenever  <span class="math">\\tilde{V}</span>  queries F at  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^m</span> , return  <span class="math">F(\\vec{\\gamma})</span> ; whenever  <span class="math">\\tilde{V}</span>  queries R at  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^m</span> , return  <span class="math">\\beta := \\mathcal{A}(\\mathbb{F}, m, d, H, \\mathsf{ans}_{R_{\\mathrm{sim}}}, \\vec{\\gamma})</span> . In the latter case, add  <span class="math">(\\vec{\\gamma}, \\beta)</span>  to  <span class="math">\\mathsf{ans}_{R_{\\mathrm{sim}}}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Send  <span class="math">z_{\\text{sim}} := \\mathcal{A}(\\mathbb{F}, m, d, H, \\mathsf{ans}_{R_{\\text{sim}}}, \\bot)</span> , and add  <span class="math">(\\bot, z_{\\text{sim}})</span>  to  <span class="math">\\mathsf{ans}_{R_{\\text{sim}}}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Receive  <span class="math">\\tilde{\\rho}</span>  from  <span class="math">\\tilde{V}</span> , and compute  <span class="math">\\operatorname{ans}_{Q_{\\mathrm{sim}}} := \\{(\\vec{\\gamma}, \\beta + \\tilde{\\rho}F(\\vec{\\gamma}))\\}_{(\\vec{\\gamma}, \\beta) \\in \\operatorname{ans}_{R_{\\mathrm{sim}}}}</span> ; this subset of  <span class="math">\\mathbb{F}^{\\leq m} \\times \\mathbb{F}</span>  records query-value pairs for  <span class="math">Q_{\\mathrm{sim}}</span> . Note that  <span class="math">\\operatorname{ans}_{Q_{\\mathrm{sim}}}</span>  includes the pair  <span class="math">(\\bot, \\tilde{\\rho}v + z_{\\mathrm{sim}})</span>  because  <span class="math">F(\\bot) = v</span>  by assumption.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Hereafter: whenever  <span class="math">\\tilde{V}</span>  queries F at  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^m</span> , return  <span class="math">F(\\vec{\\gamma})</span> ; whenever  <span class="math">\\tilde{V}</span>  queries R at  <span class="math">\\vec{\\gamma} \\in \\mathbb{F}^m</span> , return  <span class="math">\\beta&#x27; := \\beta \\tilde{\\rho}F(\\vec{\\gamma})</span>  where  <span class="math">\\beta := \\mathcal{A}(\\mathbb{F}, m, d, H, \\mathsf{ans}_{Q_{\\mathrm{sim}}}, \\vec{\\gamma})</span> . In the latter case, add  <span class="math">(\\vec{\\gamma}, \\beta)</span>  to  <span class="math">\\mathsf{ans}_{Q_{\\mathrm{sim}}}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Run the sumcheck protocol with  <span class="math">\\tilde{V}</span>  on  <span class="math">Q_{\\text{sim}}</span> , by using the algorithm  <span class="math">\\mathcal{A}</span>  and updating  <span class="math">\\operatorname{ans}_{Q_{\\text{sim}}}</span>  appropriately. (Note that  <span class="math">\\tilde{V}</span>  may query F or R before, during, or after this protocol.)</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Output the view of the simulated  <span class="math">\\tilde{V}</span> .</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Note that  <span class="math">S_{\\rm IP}</span>  makes the same number of queries to F as  <span class="math">S_{\\rm slow}</span>  does. Also, the number of pairs in  <span class="math">{\\sf ans}_{R_{\\rm sim}}</span>  is at most  <span class="math">q_{\\tilde{V}}+md+1</span> ; ditto for  <span class="math">{\\sf ans}_{Q_{\\rm sim}}</span> . Since the algorithm  <span class="math">{\\cal A}</span>  is called at most  <span class="math">q_{\\tilde{V}}+md</span>  times, the running time of  <span class="math">S_{\\rm IP}</span>  is  <span class="math">{\\sf poly}(\\log |\\mathbb{F}|+m+d+|H|+{\\sf q}_{\\tilde{V}})</span> , as required.</p>

      <h3 id="sec-5.2" class="text-xl font-semibold mt-8">5.2 Step 2</h3>

    <p class="text-gray-300">The IP described and analyzed in Section 5.1 is in the &quot;R-hybrid&quot; model. We now compile that IP into an IPCPP, by using proximity testing and self-correction, thereby concluding the proof of the PZK Sumcheck Theorem.</p>

    <p class="text-gray-300"><em>Proof of Theorem 5.3.</em> Construct an IPCPP system (P, V) for sumcheck as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The prover P, given input  <span class="math">(\\mathbb{F}, m, d, H, v)</span>  and oracle access to F, samples a uniformly random polynomial  <span class="math">R \\in \\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span>  and sends its evaluation  <span class="math">\\pi \\colon \\mathbb{F}^m \\to \\mathbb{F}</span>  to the verifier V. Then P simulates  <span class="math">P_{\\mathrm{IP}}^{F,R}(\\mathbb{F}, m, d, H, v)</span> .</li>
      <li>The verifier V, after receiving a proof string  <span class="math">\\pi \\colon \\mathbb{F}^m \\to \\mathbb{F}</span> , simulates  <span class="math">V_{\\mathrm{IP}}^{F,\\pi}(\\mathbb{F},m,d,H,v)</span>  up to  <span class="math">V_{\\mathrm{IP}}</span> 's single query  <span class="math">\\vec{\\alpha} \\in \\mathbb{F}^m</span>  to  <span class="math">\\pi</span>  (which occurs after the interaction), which V does not answer directly but instead answers as follows. First, V checks that  <span class="math">\\pi</span>  is  <span class="math">\\varrho</span> -close to the evaluation of a polynomial in  <span class="math">\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span>  by performing an individual-degree test with proximity parameter  <span class="math">\\varrho := \\frac{1}{8}</span>  and soundness error  <span class="math">\\epsilon := \\frac{md}{|\\mathbb{F}|}</span>  [GS06, GR15]; then, V computes  <span class="math">\\pi(\\vec{\\alpha})</span>  via self-correction with soundness error  <span class="math">\\epsilon</span>  [RS96, AS03], and replies with that value. Both procedures require poly(log  <span class="math">|\\mathbb{F}| + m + d</span> ) queries and time. Finally, V rejects if  <span class="math">V_{\\mathrm{IP}}</span>  rejects or the individual degree test rejects.</li>
    </ul>

    <p class="text-gray-300">Completeness and perfect zero knowledge of (P, V) are inherited, in a straightforward way, from those of  <span class="math">(P_{\\rm IP}, V_{\\rm IP})</span> . We now argue soundness. So consider an instance-witness pair  <span class="math">((\\mathbb{F}, m, d, H, v), F) \\in \\mathscr{R}_{\\rm SC}^{\\rm NO}</span>  and a malicious prover  <span class="math">\\tilde{P}</span> , and denote by  <span class="math">\\tilde{\\pi} : \\mathbb{F}^m \\to \\mathbb{F}</span>  the proof string sent by  <span class="math">\\tilde{P}</span> . We distinguish between the following two cases.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Case 1:  <span class="math">\\tilde{\\pi}</span>  is  <span class="math">\\varrho</span> -far from evaluations of polynomials in  <span class="math">\\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span> . In this case, the low-degree test accepts with probability at most  <span class="math">\\epsilon</span> .</li>
      <li>Case 2:  <span class="math">\\tilde{\\pi}</span>  is  <span class="math">\\varrho</span> -close to evaluations of polynomials in  <span class="math">\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span> . In this case, let  <span class="math">\\tilde{R}</span>  be the unique polynomial in  <span class="math">\\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span>  whose evaluation is  <span class="math">\\varrho</span> -close to  <span class="math">\\tilde{\\pi}</span> ; this polynomial exists because  <span class="math">\\varrho</span>  is less than the unique decoding radius (of the corresponding Reed&ndash;Muller code), which equals  <span class="math">\\frac{1}{2}(1-\\frac{d-1}{|\\mathbb{F}|})^m</span> , and is at least  <span class="math">\\frac{1}{4}</span>  by the assumption that  <span class="math">\\frac{md}{|\\mathbb{F}|}&lt;\\frac{1}{2}</span> . By the soundness of  <span class="math">(P_{\\mathrm{IP}},V_{\\mathrm{IP}})</span> , the probability that  <span class="math">V_{\\mathrm{IP}}^{F,\\tilde{R}}</span>  accepts is at most  <span class="math">\\frac{md+1}{|\\mathbb{F}|}</span>  (see Lemma 5.5). However V only has access to  <span class="math">\\tilde{\\pi}</span> , and uses self-correction on it to compute  <span class="math">\\tilde{R}</span>  at the single location  <span class="math">\\vec{\\alpha} \\in \\mathbb{F}^m</span>  required by  <span class="math">V_{\\mathrm{IP}}</span> ; the probability that the returned value is not correct is at most  <span class="math">\\epsilon</span> . Hence, by a union bound, V accepts with probability at most  <span class="math">\\frac{md+1}{|\\mathbb{F}|} + \\epsilon</span> .</li>
    </ul>

    <p class="text-gray-300">Overall, we deduce that V accepts with probability at most  <span class="math">\\max\\{\\epsilon\\,,\\,\\frac{md+1}{|\\mathbb{F}|}+\\epsilon\\}\\leq 3\\frac{md}{|\\mathbb{F}|}.</span></p>

    <p class="text-gray-300">Remark 5.6 (is interaction needed?). One may be tempted to &quot;flatten&quot; the IPCPP used to prove Theorem 5.3, by sending a single PCP that already contains all possible transcripts, relative to all possible  <span class="math">\\rho</span> 's. Such a modification does indeed preserve completeness and soundness. (In fact, even a small subset of  <span class="math">\\rho</span> 's is enough for constant soundness error, because only one  <span class="math">\\rho</span>  in  <span class="math">\\mathbb F</span>  is &quot;bad&quot;.) However, this modification does <em>not</em> preserve zero knowledge: if a verifier learns, say, the partial sums  <span class="math">\\alpha_1 := \\rho_1 F(\\vec{\\gamma}) + R(\\vec{\\gamma})</span>  and  <span class="math">\\alpha_2 := \\rho_2 F(\\vec{\\gamma}) + R(\\vec{\\gamma})</span>  for  <span class="math">\\rho_1 \\neq \\rho_2</span>  and some  <span class="math">\\vec{\\gamma} \\in \\mathbb F^{\\leq m}</span>  then he also learns  <span class="math">F(\\vec{\\gamma}) = \\frac{\\alpha_1 - \\alpha_2}{\\rho_1 - \\rho_2}</span> , violating zero knowledge. (Yet, the modification <em>does</em> preserve <em>honest-verifier</em> zero knowledge.)</p>

    <p class="text-gray-300"><strong>Remark 5.7</strong> (space complexity of the prover). The prover in a zero knowledge protocol is a probabilistic function, and hence reads bits from its randomness tape. In the case of the above protocol, the prover P must sample the evaluation of a random polynomial R in  <span class="math">\\mathbb{F}^{&lt; d}[X_1, \\ldots, X_m]</span> ; the entropy of R is exponential and thus requires reading an exponential number of random bits from the randomness tape. (Beyond this, P requires no other randomness.)</p>

    <p class="text-gray-300">It is easy to see that P can run in exponential time and space. However, if the prover has two-way access to its random tape, P can run in exponential time and polynomial space: the prover treats the random tape as the coefficients of R, computing an evaluation at a given point by reading the tape coefficient-by-coefficient and summing the contributions of each monomial.</p>

    <p class="text-gray-300">Two-way access to the randomness tape is a relaxation of the standard definition, which permits only <em>one</em>-way access to it [Nis93]; that is, random bits must be stored on the work tape in order to be accessed again. It is not known whether the relaxation makes polynomial-space machines more powerful for decision problems (the class is equivalent to &quot;almost&quot;-<strong>PSPACE</strong> [BVW98]), nor do we know how to obtain a polynomial-space prover with only one-way access. Nevertheless, we believe that polynomial space with two-way access to the random tape is still quite meaningful, e.g., it yields standard polynomial space relative to a random oracle.</p>

    </section>

    <section id="sec-6" class="mb-10">
      <h2 class="text-2xl font-bold">6 Perfect zero knowledge for counting problems</h2>

    <p class="text-gray-300">We prove that #P has an IPCP that is perfect zero knowledge against unbounded queries. (Recall that #P corresponds to all counting problems associated to decision problems in NP.) We do so by constructing a suitable protocol for the counting problem associated to 3SAT, which is #P-complete.</p>

    <p class="text-gray-300"><strong>Definition 6.1.</strong> Let  <span class="math">\\mathcal{L}_{\\#3SAT}</span>  be the language of pairs  <span class="math">(\\phi, N)</span>  where  <span class="math">\\phi</span>  is a 3-CNF boolean formula and N is the number of satisfying assignments of  <span class="math">\\phi</span> . We denote by n the number of variables and by c the number of clauses in  <span class="math">\\phi</span> .</p>

    <p class="text-gray-300">We construct a public-coin IPCP system for  <span class="math">\\mathcal{L}_{\\#3\\text{SAT}}</span>  that is perfect zero knowledge against unbounded queries, and has exponential proof length and polynomial query complexity. As in the non-ZK IP counterpart, the number of rounds is O(n), the prover runs in space poly(c) (with a caveat, see Remark 5.7), and the verifier in time poly(c).</p>

    <p class="text-gray-300"><strong>Theorem 6.2</strong> (formal statement of 1.2). There exists a IPCP system (P, V) that puts  <span class="math">\\mathcal{L}_{\\#3SAT}</span>  in the complexity class</p>

    <p class="text-gray-300"><span class="math">$\\textbf{PZK-IPCP} \\left[ \\begin{array}{cccc} \\text{rounds} &amp; \\mathsf{k} &amp; = &amp; O(n) \\\\ \\text{proof length} &amp; \\mathsf{l} &amp; = &amp; \\exp(n) \\\\ \\text{query complexity} &amp; \\mathsf{q} &amp; = &amp; \\operatorname{poly}(c) \\\\ \\text{soundness error} &amp; \\varepsilon &amp; = &amp; 1/2 \\\\ \\text{prover space} &amp; &amp; \\mathsf{sp} &amp; = &amp; \\operatorname{poly}(c) \\\\ \\text{verifier time} &amp; &amp; \\mathsf{tv} &amp; = &amp; \\operatorname{poly}(c) \\\\ \\text{query bound} &amp; &amp; \\mathsf{b} &amp; = &amp; * \\end{array} \\right] .</span>$</p>

    <p class="text-gray-300">Moreover, the verifier V is public-coin and non-adaptive.</p>

    <p class="text-gray-300"><em>Proof.</em> Let  <span class="math">(P_{SC}, V_{SC})</span>  be the PZK IPCPP system for sumcheck from Theorem 5.3, and let  <span class="math">S_{SC}</span>  be any simulator attesting to its perfect zero knowledge. We construct an IPCP system (P, V) for  <span class="math">\\mathcal{L}_{\\#3SAT}</span>  as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The prover P, given an instance  <span class="math">(\\phi, N)</span> , finds a prime  <span class="math">q \\in (2^n, 2^{2n}]</span> , computes the arithmetization  <span class="math">p_{\\phi} \\in \\mathbb{F}_q^{&lt;3c}[X_1, \\dots, X_n]</span>  of  <span class="math">\\phi</span>  and simulates  <span class="math">P_{\\text{SC}}^F(\\mathbb{F}, m, d, H, v)</span>  with  <span class="math">\\mathbb{F} := \\mathbb{F}_q</span> ,  <span class="math">m := n, d := 3c, H := \\{0, 1\\}, v := N</span> , and  <span class="math">F(X_1, \\dots, X_n) := p_{\\phi}(X_1, \\dots, X_n)</span> . (The prover P also communicates the prime q to the V verifier.)</li>
      <li>The verifier V, given an instance  <span class="math">(\\phi, N)</span> , also computes  <span class="math">\\mathbb{F}, m, d, H, v, F</span> , and then simulates  <span class="math">V_{\\mathrm{SC}}^F(\\mathbb{F}, m, d, H, v)</span> , and accepts if and only if the simulation accepts.</li>
    </ul>

    <p class="text-gray-300">Note that the arithmetization of a 3-CNF formula  <span class="math">\\phi</span>  can be computed in time poly(c), and the claimed given efficiency parameters follow from Theorem 5.3. We now argue completeness, then soundness, and finally perfect zero knowledge.</p>

    <p class="text-gray-300"><strong>Completeness.</strong> Completeness follows from the completeness of  <span class="math">(P_{SC}, V_{SC})</span>  and the fact that if  <span class="math">(\\phi, N) \\in \\mathcal{L}_{\\#3SAT}</span>  then  <span class="math">((\\mathbb{F}, m, d, H, v), F) = ((\\mathbb{F}_q, n, 3c, \\{0, 1\\}^n, N), p_\\phi) \\in \\mathscr{R}_{SC}^{\\text{YES}}</span> .</p>

    <p class="text-gray-300"><strong>Soundness.</strong> Soundness follows from the soundness of  <span class="math">(P_{SC}, V_{SC})</span>  and the fact that if  <span class="math">(\\phi, N) \\notin \\mathcal{L}_{\\#3SAT}</span>  then  <span class="math">((\\mathbb{F}, m, d, H, v), F) = ((\\mathbb{F}_q, n, 3c, \\{0, 1\\}^n, N), p_\\phi) \\in \\mathscr{R}_{SC}^{NO}</span> .</p>

    <p class="text-gray-300"><strong>Perfect zero knowledge.</strong> We construct a simulator S that provides perfect zero knowledge. Given an instance  <span class="math">(\\phi,N)</span>  and straightline access to a verifier  <span class="math">\\tilde{V}</span> , the simulator S computes  <span class="math">\\mathbb{F},m,d,H,v,F</span>  as above and simulates  <span class="math">S_{\\mathrm{SC}}^{\\tilde{V},F}(\\mathbb{F},m,d,H,v)</span> . By the perfect zero knowledge property of  <span class="math">(P_{\\mathrm{SC}},V_{\\mathrm{SC}})</span> , the simulator's output is identically distributed to View  <span class="math">\\langle P_{\\mathrm{SC}}^F(\\mathbb{F},m,d,H,v),\\tilde{V}^F\\rangle</span> ; but note that  <span class="math">\\tilde{V}</span>  does not query any oracles outside of its interaction with  <span class="math">P_{\\mathrm{SC}}</span>  so that  <span class="math">\\tilde{V}^F=\\tilde{V}</span> . By the construction of P above, this view equals  <span class="math">V_{\\mathrm{SC}}(\\mathbb{F},N,V,V,V,V,V,V,V,V,V,V,V,V,V,V,V,V,V,V,</span></p>

    </section>

    <section id="sec-7" class="mb-10">
      <h2 class="text-2xl font-bold">7 Perfect zero knowledge from succinct constraint detection</h2>

    <p class="text-gray-300">We show how to obtain perfect zero knowledge 2-round IOPs of Proximity for <em>any</em> linear code that has proximity proofs with succinct constraint detection (Section 7.1). Afterwards, we instantiate this general transformation for the case of Reed&ndash;Solomon codes (Section 7.2), whose proximity proofs we discussed in Section 4.3.</p>

      <h3 id="sec-7.1" class="text-xl font-semibold mt-8">7.1 A general transformation</h3>

    <p class="text-gray-300"><strong>PCPs of proximity for codes.</strong> A <em>PCP of Proximity</em> [DR04, BGH<sup>+</sup>06] for a code family  <span class="math">\\mathscr{C} = \\{C_n\\}_n</span>  is a pair  <span class="math">(P_{\\mathscr{C}}, V_{\\mathscr{C}})</span>  where for every index n and  <span class="math">w \\in \\mathbb{F}^{D(n)}</span> : if  <span class="math">w \\in C_n</span>  then  <span class="math">V_{\\mathscr{C}}^{w,\\pi}(n)</span>  accepts with probability 1 with  <span class="math">\\pi := P(n,w)</span> ; if w is 'far' from  <span class="math">C_n</span>  then  <span class="math">w \\in C_n</span>  rejects with high probability regardless of  <span class="math">\\pi</span> . We do not formally define this notion because it is a special case of a 1-round IOP of Proximity (see Section 3.2.3) where the verifier message is empty; we use  <span class="math">\\mathbf{PCPP}[\\mathsf{I}, \\mathsf{q}, \\varepsilon, \\delta, \\mathsf{tp}, \\mathsf{tv}]</span>  to denote the corresponding complexity class. Note that, since both  <span class="math">\\pi</span>  and w are provided as oracles to V, the query complexity of V is the <em>total</em> number of queries across both oracles.</p>

    <p class="text-gray-300"><strong>Leakage from proximity proofs.</strong> While proximity proofs facilitate local testing, they are a liability for zero knowledge: in principle even a single query to  <span class="math">\\pi</span>  may 'summarize' information that needs many queries to w to simulate. (This holds for BS proximity proofs [BS08], for instance.) Our construction facilitates local testing while avoiding this leakage.</p>

    <p class="text-gray-300"><strong>Perfect zero knowledge IOPs of Proximity.</strong> The notion of zero knowledge for IOPs of Proximity that we target is defined in Section 3.3.2 and is analogous to [IW14]'s notion for PCPs of Proximity (a special case of our setting). Informally, it requiress an algorithm that simulates the verifier's view by making as many queries to w as the <em>total</em> number of verifier queries to either w or any oracles sent by the prover; intuitively, this means that any bit of any message oracle reveals no more information than one bit of w.</p>

    <p class="text-gray-300">A generic 'masking' construction. Suppose that the linear code family  <span class="math">\\mathscr{C} = \\{C_n\\}_n</span>  has a PCP of Proximity. Consider the 2-round IOP of Proximity that uses masking via random self-reducibility (similarly to [BCGV16]) as follows. The prover and verifier have input  <span class="math">\\mathbb{R}</span>  and oracle access to a codeword w, and the prover wants to convince the verifier that w is close to  <span class="math">C_n</span> . Rather than sending a proximity proof for w, the prover samples a random codeword  <span class="math">z \\in C_n</span>  and sends it to the verifier; the verifier replies with a random field element  <span class="math">\\rho</span> ; the prover sends a proximity proof for the new codeword  <span class="math">\\rho w + z</span> . Completeness follows from linearity of  <span class="math">C_n</span> ; soundness follows from the fact that if w is far from  <span class="math">C_n</span>  then so is the word  <span class="math">\\rho w + z</span>  for every z with high probability over  <span class="math">\\rho</span> .</p>

    <p class="text-gray-300">Perfect zero knowledge intuitively follows from the observation that  <span class="math">\\rho w + z</span>  is essentially a random codeword (up to malicious choice of  <span class="math">\\rho</span> ). We formally prove this for the case where the linear code family consisting of the concatenation of codewords in  <span class="math">\\mathscr C</span>  with corresponding proximity proofs has succinct constraint detection.</p>

    <p class="text-gray-300">We are now ready to turn the above discussions into formal definitions and proofs. Throughout, given a code family  <span class="math">\\mathscr{C}</span> , we denote by  <span class="math">\\operatorname{Rel}(\\mathscr{C})</span>  the relation consisting of all pairs (n, w) such that  <span class="math">w \\in C_n</span> .</p>

    <p class="text-gray-300"><strong>Definition 7.1.</strong> Let  <span class="math">\\mathscr{C} = \\{C_{\\mathfrak{n}}\\}_{\\mathfrak{n}}</span>  be a linear code family with domain  <span class="math">D(\\cdot)</span>  and alphabet  <span class="math">\\mathbb{F}(\\cdot)</span> , and let (P, V) be a PCPP system for  <span class="math">Rel(\\mathscr{C})</span> . We say that (P, V) is <strong>linear</strong> if P is deterministic and is linear in its input codeword: for every index  <span class="math">\\mathfrak{m}</span>  there exists a matrix  <span class="math">A_{\\mathfrak{n}}</span>  with entries in  <span class="math">\\mathbb{F}(\\mathfrak{n})</span>  such that  <span class="math">P(\\mathfrak{n}, w) = A_{\\mathfrak{n}} \\cdot w</span>  for all  <span class="math">w \\in C_{\\mathfrak{n}}</span>  (equivalently, the set  <span class="math">\\{w || P(\\mathfrak{n}, w)\\}_{w \\in C_{\\mathfrak{n}}}</span>  is a linear code).</p>

    <p class="text-gray-300"><strong>Definition 7.2.</strong> Let  <span class="math">\\mathscr{C} = \\{C_{\\mathfrak{n}}\\}_{\\mathfrak{n}}</span>  be a linear code family with domain  <span class="math">D(\\cdot)</span>  and alphabet  <span class="math">\\mathbb{F}(\\cdot)</span> , and let (P, V) be a PCPP system for  <span class="math">\\operatorname{Rel}(\\mathscr{C})</span> . We say that (P, V) has  <span class="math">T(\\cdot, \\cdot)</span> -time constraint detection if (P, V) is linear and, moreover, the linear code family  <span class="math">\\mathscr{L} = \\{L_{\\mathfrak{n}}\\}</span>  has  <span class="math">T(\\cdot, \\cdot)</span> -time constraint detection, where  <span class="math">L_{\\mathfrak{n}} := \\{w || P(\\mathfrak{n}, w)\\}_{w \\in C_{\\mathfrak{n}}}</span> ; we also say that (P, V) has succinct constraint detection if the same holds with  <span class="math">T(\\mathfrak{n}, \\ell) = \\operatorname{poly}(\\mathfrak{n} + \\ell)</span> .</p>

    <p class="text-gray-300"><strong>Theorem 7.3.</strong> Let  <span class="math">\\mathscr{C} = \\{C_n\\}_n</span>  be a linear code family with domain  <span class="math">D(\\cdot)</span> , alphabet  <span class="math">\\mathbb{F}(\\cdot)</span> , block length  <span class="math">\\ell(\\cdot)</span> , and a  <span class="math">S(\\cdot)</span> -time sampler. Suppose that there exists a PCPP system  <span class="math">(P_{\\mathscr{C}}, V_{\\mathscr{C}})</span>  for  <span class="math">Rel(\\mathscr{C})</span>  that (is linear and) has succinct</p>

    <p class="text-gray-300">constraint detection and puts  <span class="math">Rel(\\mathscr{C})</span>  in the complexity class</p>

    <p class="text-gray-300">PCPP
<span class="math">$\\begin{bmatrix} \\text{answer alphabet} &amp; \\mathbb{F}(\\mathfrak{n}) \\\\ \\text{proof length} &amp; \\mathbb{I}_{\\mathscr{C}}(\\mathfrak{n}) \\\\ \\text{query complexity} &amp; \\mathbb{q}_{\\mathscr{C}}(\\mathfrak{n}) \\\\ \\text{soundness error} &amp; \\varepsilon_{\\mathscr{C}}(\\mathfrak{n}) \\\\ \\text{proximity parameter} &amp; \\delta_{\\mathscr{C}}(\\mathfrak{n}) \\\\ \\text{prover time} &amp; \\mathsf{tp}_{\\mathscr{C}}(\\mathfrak{n}) \\\\ \\text{verifier time} &amp; \\mathsf{tv}_{\\mathscr{C}}(\\mathfrak{n}) \\\\ \\text{verifier randomness} &amp; \\mathsf{rv}_{\\mathscr{C}}(\\mathfrak{n}) \\end{bmatrix}</span>$</p>

    <p class="text-gray-300">Then there exists an IOPP system (P, V) that puts  <span class="math">Rel(\\mathscr{C})</span>  in the complexity class</p>

    <pre><code class="language-text">answer alphabet
                                                                                             \\mathbb{F}(n)
                                                                                             k(n)
                                                                                                                        2
                                        rounds
                                                                                             I(n) = I_{\\mathscr{C}}(n) + \\ell(n)
                                        proof length
                                                                                             q(n) = 2q_{\\mathscr{C}}(n)
                                       query complexity
                                                                                            \\begin{array}{lll} \\varepsilon(\\mathbf{n}) &amp; = &amp; 2 \\mathfrak{q}_{\\mathscr{C}}(\\mathbf{n}) \\\\ \\varepsilon(\\mathbf{n}) &amp; = &amp; \\varepsilon_{\\mathscr{C}}(\\mathbf{n}) + \\frac{1}{|\\mathbb{F}(\\mathbf{n})|} \\\\ \\delta(\\mathbf{n}) &amp; = &amp; 2 \\delta_{\\mathscr{C}}(\\mathbf{n}) \\end{array}
PZK-IOPP
                                       proximity parameter
                                                                                                                        \\mathsf{tp}_{\\mathscr{C}}(\\mathsf{n}) + S(\\mathsf{n}) + O(\\ell(\\mathsf{n}))
                                                                                             tp(n) =
                                       prover time
                                                                                            tv(n) =
                                                                                                                        \\mathsf{tv}_\\mathscr{C}(\\mathsf{m}) + O(\\mathsf{q}_\\mathscr{C}(\\mathsf{m}))
                                                                                            rv(n) =
                                                                                                                        \\mathsf{rv}_{\\mathscr{C}}(\\mathsf{m}) + \\log |\\mathbb{F}(\\mathsf{m})|
                                                                                            b(m)
</code></pre>

    <p class="text-gray-300"><strong>Remark 7.4</strong> (the case of LTCs). It is tempting to apply Theorem 7.3 to the notable special case where the proximity proof is <em>empty</em> (e.g., when  <span class="math">\\mathscr{C}</span>  is locally testable so no proximity proofs are needed). However, in this case, the zero knowledge guarantee of our construction does not buy anything compared to when the verifier queries only the codeword (indeed, the verifier <em>already</em> learns precisely the value of codeword at those positions which it queries and nothing else).</p>

    <p class="text-gray-300"><strong>Construction 7.5.</strong> The IOPP system (P, V) is defined as follows. The prover receives a pair (n, w) as input, while the verifier receives the index n as input and w as an oracle. The interaction proceeds as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>P samples a random codeword z in  <span class="math">C_n</span>  and sends z to V;</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>V samples a random element  <span class="math">\\rho</span>  in  <span class="math">\\mathbb{F}(n)</span>  and sends  <span class="math">\\rho</span>  to P;</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>P computes the proof  <span class="math">\\pi := P_{\\mathscr{C}}(\\mathfrak{n}, \\rho w + z)</span>  and sends  <span class="math">\\pi</span>  to V;</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>V checks that  <span class="math">V_{\\mathscr{C}}^{w&#x27;,\\pi}(\\mathfrak{n})</span>  accepts, where  <span class="math">w&#x27; := \\rho w + z</span>  (any query  <span class="math">\\alpha</span>  to w' is computed as  <span class="math">\\rho w(\\alpha) + z(\\alpha)</span> ).</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">The round complexity, proof length, query complexity, and prover and verifier complexities claimed in Theorem 7.3 follow in a straightforward way from Construction 7.5. We now argue completeness and soundness (Claim 7.6) and perfect zero knowledge (Claim 7.7).</p>

    <p class="text-gray-300"><strong>Claim 7.6.</strong> The IOPP system
<span class="math">$(P,V)</span>$
has completeness 1 and soundness error  <span class="math">\\varepsilon(\\mathfrak{n}) = \\varepsilon_{\\mathscr{C}}(\\mathfrak{n}) + \\frac{1}{|\\mathbb{F}(\\mathfrak{n})|}</span></p>

    <p class="text-gray-300"><em>Proof.</em> First we argue completeness. Suppose that the instance-witness pair (n, w) is in the relation  <span class="math">Rel(\\mathscr{C})</span> , i.e., that the word w is in the code  <span class="math">C_n</span> . Then, the linearity of  <span class="math">C_n</span>  implies that, for every word z in  <span class="math">C_n</span>  and element  <span class="math">\\rho</span>  in  <span class="math">\\mathbb{F}(n)</span> , the word  <span class="math">\\rho w + z</span>  is also in  <span class="math">C_n</span> . Thus completeness of (P, V) follows from the completeness of  <span class="math">(P_{\\mathscr{C}}, V_{\\mathscr{C}})</span> .</p>

    <p class="text-gray-300">Next we argue soundness. Suppose that w is  <span class="math">2\\delta_{\\mathscr{C}}(\\mathfrak{n})</span> -far from  <span class="math">C_{\\mathfrak{n}}</span> . For every word z in  <span class="math">\\mathbb{F}(\\mathfrak{n})^{\\ell(\\mathfrak{n})}</span>  (not necessarily in  <span class="math">C_{\\mathfrak{n}}</span> ), there exists at most one  <span class="math">\\rho</span>  in  <span class="math">\\mathbb{F}(\\mathfrak{n})</span>  such that  <span class="math">\\rho w + z</span>  is  <span class="math">\\delta_{\\mathscr{C}}(\\mathfrak{n})</span> -close to  <span class="math">C_{\\mathfrak{n}}</span>  (see Claim 3.1). The soundness of  <span class="math">(P_{\\mathscr{C}}, V_{\\mathscr{C}})</span>  implies that  <span class="math">V_{\\mathscr{C}}</span>  accepts with probability at most  <span class="math">\\varepsilon_{\\mathscr{C}}(\\mathfrak{n})</span>  if  <span class="math">V_{\\mathscr{C}}</span>  is invoked on a word that is  <span class="math">\\delta_{\\mathscr{C}}(\\mathfrak{n})</span> -far from  <span class="math">C_{\\mathfrak{n}}</span> . Thus, since V invokes  <span class="math">V_{\\mathscr{C}}</span>  on the word  <span class="math">\\rho w + z</span> , the probability that V accepts is at most  <span class="math">\\varepsilon_{\\mathscr{C}}(\\mathfrak{n}) + \\frac{1}{|\\mathbb{F}(\\mathfrak{n})|}</span> .</p>

    <p class="text-gray-300"><strong>Claim 7.7.</strong> There exists a straightline simulator S such that, for every  <span class="math">(\\mathfrak{n}, w) \\in \\text{Rel}(\\mathscr{C})</span>  and malicious verifier  <span class="math">\\tilde{V}</span> , the following two random variables are identically distributed</p>

    <p class="text-gray-300"><span class="math">$\\left(S^{\\tilde{V},w}(\\mathfrak{n})\\;,\\;q_S\\right)</span>$
and  <span class="math">\\left(\\mathrm{View}\\;\\langle P^w(\\mathfrak{n}),\\tilde{V}^w\\rangle\\;,\\;q_{\\tilde{V}}\\right)\\;,</span></p>

    <p class="text-gray-300">where  <span class="math">q_S</span>  is the number of queries to w made by S and  <span class="math">q_{\\tilde{V}}</span>  is the number of queries to w or to prover messages made by  <span class="math">\\tilde{V}</span> . Moreover, S runs in time  <span class="math">\\operatorname{poly}(\\mathfrak{n}+\\mathfrak{q}_{\\tilde{V}})</span> , where  <span class="math">\\mathfrak{q}_{\\tilde{V}}</span>  is  <span class="math">\\tilde{V}</span> 's query complexity.</p>

    <p class="text-gray-300"><em>Proof.</em> We begin by proving perfect zero knowledge via a straightline simulator  <span class="math">S_{\\text{slow}}</span>  whose number of queries to w equals  <span class="math">q_{\\tilde{V}}</span> , but runs in time  <span class="math">\\text{poly}(\\mathsf{tp}(\\mathsf{n}) + q_{\\tilde{V}})</span> . After that, we explain how to modify  <span class="math">S_{\\text{slow}}</span>  into another simulator S, with an identical output distribution, that runs in the faster time claimed in the lemma.</p>

    <p class="text-gray-300">The simulator  <span class="math">S_{\\text{slow}}</span> , given straightline access to  <span class="math">\\tilde{V}</span>  and oracle access to w, works as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Draw a uniformly random  <span class="math">z_{\\rm sim} \\in C_{\\tt m}</span>  .</li>
    </ol></li>
      <li>2. Whenever  <span class="math">\\tilde{V}</span>  queries w at  <span class="math">\\alpha \\in D(\\mathfrak{n})</span> , return  <span class="math">w(\\alpha)</span> ; whenever  <span class="math">\\tilde{V}</span>  queries z at  <span class="math">\\alpha \\in D(\\mathfrak{n})</span> , return  <span class="math">z_{\\text{sim}}(\\alpha)</span> .</li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Receive  <span class="math">\\tilde{\\rho}</span>  from  <span class="math">\\tilde{V}</span> , and draw a uniformly random  <span class="math">w&#x27;_{\\text{sim}} \\| \\pi_{\\text{sim}} \\in L_n</span>  conditioned on  <span class="math">w&#x27;_{\\text{sim}}(\\alpha) = \\tilde{\\rho}w(\\alpha) + z_{\\text{sim}}(\\alpha)</span>  for every coordinate  <span class="math">\\alpha \\in D(n)</span>  queried in Step 2. (This latter condition requires querying w at  <span class="math">\\alpha</span>  for every coordinate  <span class="math">\\alpha \\in D(n)</span>  queried to  <span class="math">z_{\\text{sim}}</span>  in Step 2.)</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Hereafter: whenever  <span class="math">\\tilde{V}</span>  queries w at  <span class="math">\\alpha \\in D(\\mathfrak{n})</span> , return  <span class="math">w(\\alpha)</span> ; whenever  <span class="math">\\tilde{V}</span>  queries z at  <span class="math">\\alpha \\in D(\\mathfrak{n})</span> , return  <span class="math">w&#x27;_{\\text{sim}}(\\alpha) \\tilde{\\rho}w(\\alpha)</span> . (In either case, a query to w is required.)</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Tell  <span class="math">\\tilde{V}</span>  that the oracle  <span class="math">\\pi</span>  has been 'sent'; whenever  <span class="math">\\tilde{V}</span>  queries the i-th entry of  <span class="math">\\pi</span> , return the i-th entry of  <span class="math">\\pi_{\\text{sim}}</span> . (Note that  <span class="math">\\tilde{V}</span>  may query w or z before or after learning about  <span class="math">\\pi</span> .)</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Output the view of the simulated V.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Note that  <span class="math">S_{\\mathrm{slow}}</span>  runs in time  <span class="math">\\mathrm{poly}(\\mathsf{tp}(\\mathsf{n}) + q_{\\tilde{V}})</span> . Also,  <span class="math">S_{\\mathrm{slow}}</span>  makes one query to w for every query to w or z by  <span class="math">\\tilde{V}</span>  (at least provided that  <span class="math">\\tilde{V}</span> 's queries have no duplicates, which we can assume without loss of generality), and zero queries to w for every query to  <span class="math">\\pi</span>  by  <span class="math">\\tilde{V}</span> . Thus, overall, the number of queries to w by  <span class="math">S_{\\mathrm{slow}}</span>  is at most  <span class="math">q_{\\tilde{V}}</span> ; clearly, this number of queries can be padded to be equal to  <span class="math">q_{\\tilde{V}}</span> . We now argue that  <span class="math">S_{\\mathrm{slow}}</span> 's output is identically distributed to  <span class="math">\\tilde{V}</span> 's view when interacting with the honest prover P, for z random in  <span class="math">C_{\\mathrm{n}}</span> .</p>

    <p class="text-gray-300">Claim.
<span class="math">$S_{\\text{slow}}^{\\tilde{V},w} \\equiv \\text{View } \\langle P^w(\\mathfrak{n}), \\tilde{V}^w \\rangle.</span>$</p>

    <p class="text-gray-300"><em>Proof.</em> Define the random variable  <span class="math">w&#x27; := \\tilde{\\rho}w + z</span> , where  <span class="math">\\tilde{\\rho}</span>  is chosen by  <span class="math">\\tilde{V}</span> . Observe that there exists a (deterministic) function  <span class="math">v(\\cdot)</span>  such that</p>

    <p class="text-gray-300">View
<span class="math">$\\langle P^{w,z}, \\tilde{V}^{w,z} \\rangle = v(w&#x27;, w, r)</span>$
and  <span class="math">S_{\\text{slow}}^{\\tilde{V},w} = v(w&#x27;_{\\text{sim}}, w, r)</span> ,</p>

    <p class="text-gray-300">where the random variable r is  <span class="math">\\tilde{V}</span> 's private randomness. Indeed, (i) the messages sent and received by  <span class="math">\\tilde{V}</span>  are identical to those when interacting with P on w' and  <span class="math">w&#x27;_{\\rm sim}</span> , respectively; (ii)  <span class="math">\\tilde{V}</span> 's queries to w are answered honestly; (iii)  <span class="math">\\tilde{V}</span> 's queries to z are answered by  <span class="math">z=w&#x27;-\\tilde{\\rho}w</span>  and  <span class="math">z_{\\rm sim}=w&#x27;_{\\rm sim}-\\tilde{\\rho}w</span>  respectively; (iv)  <span class="math">\\tilde{V}</span> 's queries to  <span class="math">\\pi</span>  are answered by  <span class="math">P_{\\mathscr{C}}(\\mathfrak{n},w&#x27;)</span>  and  <span class="math">P_{\\mathscr{C}}(\\mathfrak{n},w&#x27;_{\\rm sim})</span>  respectively. We are only left to argue that, for any choice of r,w' and  <span class="math">w&#x27;_{\\rm sim}</span>  are identically distributed:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">-w&#x27;=\\tilde{\\rho}w+z</span>  is uniformly random in  <span class="math">C_n</span> , because z is uniformly random in  <span class="math">C_n</span> , w is in  <span class="math">C_n</span> , and  <span class="math">C_n</span>  is linear; and</li>
      <li><span class="math">-w_{\\rm sim}&#x27;</span>  is uniformly random in  <span class="math">C_{\\rm n}</span> , because  <span class="math">w_{\\rm sim}&#x27;</span>  is sampled at random in  <span class="math">C_{\\rm n}</span>  conditioned on  <span class="math">w_{\\rm sim}&#x27;(\\alpha_i)=z_{\\rm sim}(\\alpha_i)+\\tilde{\\rho}w(\\alpha_i)</span>  for some (adversarial) choice of  <span class="math">\\alpha_1,\\ldots,\\alpha_k</span> . But  <span class="math">z_{\\rm sim}</span>  is uniformly random in  <span class="math">C_{\\rm n}</span> , so the latter condition says that  <span class="math">w_{\\rm sim}&#x27;</span>  matches a random codeword on the set of points  <span class="math">\\{\\alpha_1,\\ldots,\\alpha_k\\}</span> , giving the claimed distribution for  <span class="math">w_{\\rm sim}&#x27;</span> .</li>
    </ul>

    <p class="text-gray-300">We explain how to modify  <span class="math">S_{\\rm slow}</span>  so as to reduce the running time to  <span class="math">{\\rm poly}({\\tt n}+{\\tt q}_{\\tilde{V}})</span> . The inefficiency of  <span class="math">S_{\\rm slow}</span>  comes from sampling  <span class="math">z_{\\rm sim}\\in C_{\\tt n}</span>  and  <span class="math">w&#x27;_{\\rm sim}\\|\\pi_{\\rm sim}\\in L_{\\tt n}</span> , which takes time  <span class="math">{\\rm poly}(S({\\tt n})+\\ell({\\tt n}))</span>  and  <span class="math">{\\rm poly}({\\rm tp}_{\\mathscr C}({\\tt n}))</span>  respectively, which need not be polynomial in  <span class="math">{\\tt n}</span> . In the following, we show how to not explicitly sample these codewords but, instead, adaptively sample them by relying on constraint detection.</p>

    <p class="text-gray-300">First, note that if  <span class="math">\\mathscr{L}</span>  has constraint detection with a certain efficiency then so does  <span class="math">\\mathscr{C}</span>  with the same efficiency. The theorem's hypothesis says that  <span class="math">\\mathscr{L}</span>  has succinct constraint detection; so both  <span class="math">\\mathscr{C}</span>  and  <span class="math">\\mathscr{L}</span>  have succinct constraint detection. We then invoke Lemma 4.3 to obtain probabilistic polynomial-time algorithms  <span class="math">\\mathscr{A}_{\\mathscr{C}}</span> ,  <span class="math">\\mathscr{A}_{\\mathscr{L}}</span>  for the code families  <span class="math">\\mathscr{C}</span> ,  <span class="math">\\mathscr{L}</span>  respectively. Using these algorithms, we write the more efficient simulator S, as follows.</p>

    <p class="text-gray-300">Let  <span class="math">D^*(\\mathfrak{n})</span>  be the domain of  <span class="math">L_\\mathfrak{n}</span> : this is the disjoint union of  <span class="math">D(\\mathfrak{n})</span>  (the domain of  <span class="math">C_\\mathfrak{n}</span> ) and  <span class="math">[l_\\mathscr{C}(\\mathfrak{n})]</span>  (the domain of  <span class="math">P_\\mathscr{C}(\\mathfrak{n}, C_\\mathfrak{n})</span> ). The simulator S, given straightline access to  <span class="math">\\tilde{V}</span>  and oracle access to w, works as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Let  <span class="math">\\operatorname{ans}_{z_{\\text{sim}}}</span>  be a subset of  <span class="math">D(\\mathfrak{m}) \\times \\mathbb{F}(\\mathfrak{m})</span>  that records query-value pairs for  <span class="math">z_{\\text{sim}}</span> ; initially,  <span class="math">\\operatorname{ans}_{z_{\\text{sim}}}</span>  equals  <span class="math">\\varnothing</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Whenever  <span class="math">\\tilde{V}</span>  queries w at  <span class="math">\\alpha \\in D(\\mathfrak{n})</span> , return  <span class="math">w(\\alpha)</span> ; whenever  <span class="math">\\tilde{V}</span>  queries z at  <span class="math">\\alpha \\in D(\\mathfrak{n})</span> , return  <span class="math">\\beta := \\mathcal{A}_{\\mathscr{C}}(\\mathfrak{n}, \\mathsf{ans}_{z_{\\mathrm{sim}}}, \\alpha)</span> . In the latter case, add  <span class="math">(\\alpha, \\beta)</span>  to  <span class="math">\\mathsf{ans}_{z_{\\mathrm{sim}}}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Receive  <span class="math">\\tilde{\\rho}</span>  from  <span class="math">\\tilde{V}</span> , and compute ans  <span class="math">:=\\{(\\alpha,\\beta+\\tilde{\\rho}w(\\alpha))\\}_{(\\alpha,\\beta)\\in\\mathsf{ans}_{z_{\\mathrm{sim}}}};</span>  this subset of  <span class="math">D^*(\\mathfrak{n})\\times\\mathbb{F}(\\mathfrak{n})</span>  records query-value pairs for  <span class="math">w&#x27;_{\\mathrm{sim}}\\|\\pi_{\\mathrm{sim}}.</span></li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Hereafter: whenever  <span class="math">\\tilde{V}</span>  queries w at  <span class="math">\\alpha \\in D(\\mathfrak{n})</span> , return  <span class="math">w(\\alpha)</span> ; whenever  <span class="math">\\tilde{V}</span>  queries z at  <span class="math">\\alpha \\in D(\\mathfrak{n})</span> , return  <span class="math">\\beta&#x27; := \\beta \\tilde{\\rho}w(\\alpha)</span>  where  <span class="math">\\beta := \\mathcal{A}_{\\mathscr{L}}(\\mathfrak{n}, \\mathsf{ans}, \\alpha)</span>  and add  <span class="math">(\\alpha, \\beta)</span>  to ans.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Tell  <span class="math">\\tilde{V}</span>  that the oracle  <span class="math">\\pi</span>  has been 'sent'; note that we do not yet commit to any entries in the proof, save for those which are implied by the verifier's previous queries to w. Whenever  <span class="math">\\tilde{V}</span>  queries the i-th location in  <span class="math">\\pi</span> , return  <span class="math">\\pi_i := \\mathcal{A}_{\\mathscr{L}}(\\mathfrak{n}, \\mathsf{ans}, i)</span>  and add  <span class="math">(i, \\pi_i)</span>  to ans. (Note that  <span class="math">\\tilde{V}</span>  may query w or z before or after learning about  <span class="math">\\pi</span> .)</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Output the view of the simulated  <span class="math">\\tilde{V}</span> .</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Note that S makes the same number of queries to w as  <span class="math">S_{\\text{slow}}</span>  does. Also, the number of pairs in  <span class="math">\\operatorname{ans}_{z_{\\text{sim}}}</span>  is at most  <span class="math">q_{\\tilde{V}}</span> ; ditto for ans. Since the algorithm A is called at most  <span class="math">q_{\\tilde{V}}</span>  times, the running time of S is  <span class="math">\\operatorname{poly}(\\mathfrak{n} + \\mathfrak{q}_{\\tilde{V}})</span> , as required.  <span class="math">\\square</span></p>

    <p class="text-gray-300">We conclude with a lemma that says that succinct constraint detection is in some sense inherent to the &quot;masking&quot; approach used in Construction 7.5.</p>

    <p class="text-gray-300"><strong>Lemma 7.8.</strong> If  <span class="math">(P_{\\mathscr{C}}, V_{\\mathscr{C}})</span>  is a linear PCPP such that Construction 7.5 yields (P, V) with perfect zero knowledge, then  <span class="math">(P_{\\mathscr{C}}, V_{\\mathscr{C}})</span>  has a constraint detector that runs in probabilistic polynomial time. (In fact, the same statement holds even if the construction yields (P, V) with only statistical zero knowledge.)</p>

    <p class="text-gray-300"><em>Proof.</em> The linear code  <span class="math">L_n := \\{ w || P(n, w) \\}_{w \\in C_n}</span>  has domain  <span class="math">D^*(n) := D(n) \\sqcup [I_{\\mathscr{C}}(n)]</span> , which is the disjoint union of D(n) (the domain of  <span class="math">C_n</span> ) and  <span class="math">[I_{\\mathscr{C}}(n)]</span>  (the domain of  <span class="math">P(n, C_n)</span> ); see Definition 7.2. Let  <span class="math">I \\subseteq D^*(n)</span> . We need, in probabilistic polynomial time, to output a basis for  <span class="math">(L_n|_I)^\\perp</span> . Construct a malicious verifier  <span class="math">\\tilde{V}</span>  that works as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Receive  <span class="math">z \\in C_n</span>  from P.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Send  <span class="math">\\rho = 0</span>  to P.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Receive  <span class="math">\\pi</span>  from P.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>For each  <span class="math">i \\in I</span> : if  <span class="math">i \\in D(\\mathfrak{m})</span>  then query z at i, and if  <span class="math">i \\in [l_{\\mathscr{C}}(\\mathfrak{m})]</span>  then query  <span class="math">\\pi</span>  at i; call the answer  <span class="math">\\beta_i</span> .</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">By PZK, there is a probabilistic polynomial time algorithm S such that the output of  <span class="math">S^{\\bar{V},w}(\\mathfrak{n})</span>  is identically distributed to View  <span class="math">\\langle P^w(\\mathfrak{n}), \\tilde{V}^w \\rangle</span> , for every  <span class="math">w \\in C_{\\mathfrak{n}}</span> . Set w to be the zero codeword, and suppose we run  <span class="math">S^{\\bar{V},w}(\\mathfrak{n})</span> ; this invocation makes S sample answers  <span class="math">(\\beta_i)_{i \\in I} = (z&#x27;(i))_{i \\in I}</span>  for  <span class="math">z&#x27; = z \\| P_{\\mathscr{C}}(\\mathfrak{n}, z)</span>  uniformly random in  <span class="math">L_{\\mathfrak{n}}</span> .</p>

    <p class="text-gray-300">Thus, to perform constraint detection in probabilistic polynomial time, we proceed as follows. We run  <span class="math">S^{\\vec{V},w}(n)</span>  k&gt;|I| times, recording a vector  <span class="math">\\vec{\\beta}^j=(\\beta_i)_{i\\in I}</span>  at the j-th iteration. Let B be the  <span class="math">k\\times |I|</span>  matrix with rows  <span class="math">\\vec{\\beta}^1,\\ldots,\\vec{\\beta}^k</span> . Output a basis for the nullspace of B, which we can find in  <span class="math">\\operatorname{poly}(\\log |\\mathbb{F}|+k+|I|)</span>  time.</p>

    <p class="text-gray-300">We now argue correctness of the above approach. First, for every  <span class="math">u \\in \\mathbb{F}^I</span>  such that  <span class="math">\\sum_{i \\in I} u(i)w&#x27;(i) = 0</span>  for every  <span class="math">w&#x27; \\in L_n</span> , it holds that u is in the nullspace of B, because codewords used to generate B satisfy the same relation. Next, the probability that there exists  <span class="math">u \\in \\mathbb{F}^I</span>  in the nullspace of B such that  <span class="math">\\sum_{i \\in I} u(i)w&#x27;(i) \\neq 0</span>  for some  <span class="math">w&#x27; \\in L_n</span>  is at most  <span class="math">1/|\\mathbb{F}|^{k-|I|}</span> . Indeed, for every such u,  <span class="math">\\Pr_{z&#x27; \\leftarrow L_n}[\\sum_{i \\in I} u(i)z&#x27;(i) = 0] \\leq 1/|\\mathbb{F}|</span>  (since  <span class="math">L_n</span>  is a linear code), so the probability that u is in the nullspace of B is at most  <span class="math">1/|\\mathbb{F}|^k</span> ; we then obtain the claimed probability by a union bound. Overall, the probability that the algorithm answers incorrectly is at most  <span class="math">1/|\\mathbb{F}|^{k-|I|}</span> .</p>

      <h3 id="sec-7.2" class="text-xl font-semibold mt-8">7.2 Perfect zero knowledge IOPs of proximity for Reed-Solomon codes</h3>

    <p class="text-gray-300">We have already proved that the linear code family BS-RS, which consists of low-degree univariate polynomials concatenated with corresponding BS proximity proofs [BS08], has succinct constraint detection. When combined with the results in Section 7.1, we obtain IOPs of Proximity for Reed&ndash;Solomon codes, as stated in the corollary below.</p>

    <p class="text-gray-300"><strong>Definition 7.9.</strong> We denote by  <span class="math">RS^+</span>  the linear code family indexed by tuples  <span class="math">\\mathfrak{n}=(\\mathbb{F},L,d)</span> , where  <span class="math">\\mathbb{F}</span>  is an extension field of  <span class="math">\\mathbb{F}_2</span>  and L is an  <span class="math">\\mathbb{F}_2</span> -linear subspace of  <span class="math">\\mathbb{F}</span>  with  <span class="math">d\\leq |L|/8</span> , and the  <span class="math">\\mathfrak{n}</span> -th code consists of the codewords from the Reed&ndash;Solomon code  <span class="math">RS[\\mathbb{F},L,d]</span> .</p>

    <p class="text-gray-300"><strong>Theorem 7.10</strong> ([BS08]). For every function  <span class="math">\\delta \\colon \\{0,1\\}^* \\to (0,1)</span> , the linear code family RS<sup>+</sup> has PCPs of Proximity with soundness error 1/2, proximity parameter  <span class="math">\\delta</span> , prover running time (and thus proof length) that is quasilinear in the block length  <span class="math">\\ell(\\mathfrak{n})</span> , and verifier running time (and thus query complexity) that is polylogarithmic in  <span class="math">\\ell(\\mathfrak{n})/\\delta(\\mathfrak{n})</span> .</p>

    <p class="text-gray-300"><strong>Corollary 7.11.</strong> For every function  <span class="math">\\delta \\colon \\{0,1\\}^* \\to (0,1)</span> , there exists an IOPP system that puts  <span class="math">Rel(RS^+)</span>  in the complexity class</p>

    <pre><code class="language-text">answer alphabet
                                                        \\mathbb{F}(n)
                         rounds
                         proof length
                                                        I(n)
                                                                         \\tilde{O}(\\ell(\\mathtt{m}))
                                                                         \\operatorname{polylog}(\\ell(\\mathtt{m})/\\delta(\\mathtt{m}))
                                                        q(n)
                         query complexity
PZK-IOPP
                                                        \\varepsilon(\\mathsf{n})
                         soundness error
                         proximity parameter
                                                        \\delta(\\mathtt{m})
                         prover time
                                                        tp(m) =
                         verifier time
                                                        tv(n)
                         query bound
                                                        b(m)
</code></pre>

    <p class="text-gray-300"><em>Proof.</em> Invoke Theorem 7.3 on the linear code family RS<sup>+</sup> with corresponding BS proximity proofs (Theorem 7.10). Indeed, the concatenation of codewords in RS<sup>+</sup> and proximity proofs yields the family BS-RS, which has succinct constraint detection by Theorem 4.12. (This last step omits a technical, but uninteresting, step: the proximity proofs from Theorem 4.12 consider the case where the degree d equals the special value |L|/8, rather than being bounded by it; but proximity proofs for smaller degree d are easily obtained from these, as explained in [BS08].)</p>

    <p class="text-gray-300">When constructing perfect zero knowledge IOPs for <strong>NEXP</strong> (Section 8) we shall need perfect zero knowledge IOPs of Proximity not quite for the family RS<sup>+</sup> but for an extension of it that we denote by ERS<sup>+</sup>, and for which [BS08] also gives PCPs of proximity. The analogous perfect zero knowledge result follows in a similar way, as explained below.</p>

    <p class="text-gray-300"><strong>Definition 7.12.</strong> Given a field  <span class="math">\\mathbb{F}</span>  of characteristic 2,  <span class="math">\\mathbb{F}_2</span> -linear subspaces  <span class="math">H, L \\subseteq \\mathbb{F}</span>  with  <span class="math">|H| \\le |L|/8</span> , and  <span class="math">d_0, d_1 \\in \\mathbb{N}</span>  with  <span class="math">d_0, d_1 \\le |L|/8</span> , we denote by  <span class="math">\\mathrm{ERS}^+[\\mathbb{F}, L, H, d_0, d_1]</span>  the linear code consisting of all pairs  <span class="math">(w_0, w_1)</span>  where  <span class="math">w_0 \\in \\mathrm{RS}[\\mathbb{F}, L, d_0]</span> ,  <span class="math">w_1 \\in \\mathrm{RS}[\\mathbb{F}, L, d_1]</span> , and  <span class="math">w_1(x) = 0</span>  for all  <span class="math">x \\in H</span> . We denote by  <span class="math">\\mathrm{ERS}^+</span>  the linear code family indexed by tuples  <span class="math">\\mathbb{n} = (\\mathbb{F}, L, d_0, d_1)</span>  for which the  <span class="math">\\mathbb{n}</span> -th code is  <span class="math">\\mathrm{ERS}^+[\\mathbb{F}, L, H, d_0, d_1]</span> .</p>

    <p class="text-gray-300"><strong>Theorem 7.13</strong> ([BS08]). For every function  <span class="math">\\delta \\colon \\{0,1\\}^* \\to (0,1)</span> , the linear code family ERS<sup>+</sup> has PCPs of Proximity with soundness error 1/2, proximity parameter  <span class="math">\\delta</span> , prover running time (and thus proof length) that is quasilinear in the block length  <span class="math">\\ell(\\mathfrak{m})</span> , and verifier running time (and thus query complexity) that is polylogarithmic in  <span class="math">\\ell(\\mathfrak{m})/\\delta(\\mathfrak{m})</span> .</p>

    <p class="text-gray-300"><em>Proof sketch.</em> A PCP of proximity for a codeword  <span class="math">(w_0, w_1)</span>  to  <span class="math">\\text{ERS}^+[\\mathbb{F}, L, H, d_0, d_1]</span>  consists of  <span class="math">(\\pi_0, w_1&#x27;, \\pi_1)</span> , where</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\pi_0</span>  is a PCP of proximity for  <span class="math">w_0</span>  to RS[F, L,  <span class="math">d_0</span> ];</li>
      <li><span class="math">w&#x27;_1</span>  is the evaluation of the polynomial obtained by dividing (the polynomial of)  <span class="math">w_1</span>  by the zero polynomial of H;</li>
      <li><span class="math">\\pi_1</span>  is a PCP of proximity for  <span class="math">w&#x27;_1</span>  to RS[ <span class="math">\\mathbb{F}</span> , L,  <span class="math">d_1 |H|</span> ].</li>
    </ul>

    <p class="text-gray-300">The verifier, which has oracle access to  <span class="math">(w_0, w_1)</span>  and  <span class="math">(\\pi_0, w_1&#x27;, \\pi_1)</span> , checks both PCPs or proximity and then performs a consistency check between  <span class="math">w_1</span>  and  <span class="math">w_1&#x27;</span> . See [BS08] for details.</p>

    <p class="text-gray-300"><strong>Corollary 7.14.</strong> For every function  <span class="math">\\delta \\colon \\{0,1\\}^* \\to (0,1)</span> , there exists an IOPP system that puts  <span class="math">Rel(ERS^+)</span>  in the complexity class</p>

    <pre><code class="language-text">answer alphabet
                          rounds
                                                           k(n)
                          proof length
                                                          I(n)
                                                                            \\tilde{O}(\\ell(\\mathtt{m}))
                                                                            \\widehat{\\operatorname{polylog}}(\\ell(\\mathtt{m})/\\delta(\\mathtt{m}))
                          query complexity
                                                          q(m)
PZK-IOPP
                          soundness error
                                                           \\varepsilon(\\mathtt{m})
                          proximity parameter
                                                          \\delta(\\mathtt{m})
                                                           tp(m)
                          prover time
                                                           tv(m)
                          query bound
                                                          b(m)
</code></pre>

    <p class="text-gray-300"><em>Proof.</em> Invoke Theorem 7.3 on the linear code family ERS<sup>+</sup> with corresponding BS proximity proofs (Theorem 7.13), which has succinct constraint detection as we now clarify. A codeword  <span class="math">(w_0, w_1)</span>  has proximity proof  <span class="math">(\\pi_0, w&#x27;_1, \\pi_1)</span> , and Theorem 4.12 implies that  <span class="math">(w_0, \\pi_0)</span>  and  <span class="math">(w&#x27;_1, \\pi_1)</span>  have succinct constraint detection. But every coordinate of  <span class="math">w&#x27;_1</span>  is easy to compute from the same coordinate in  <span class="math">w_1</span> , and concatenating codewords preserves succinct constraint detection.</p>

    <h2 id="sec-misc-7" class="text-2xl font-bold">Perfect zero knowledge for nondeterministic time</h2>

    <p class="text-gray-300">We prove that NEXP has 2-round IOPs that are perfect zero knowledge against unbounded queries. We do so by constructing a suitable IOP system for NTIME(T) against query bound b, for each time function T and query bound function b, where the verifier runs in time polylogarithmic in both T and b. Crucially, the simulator runs in time  <span class="math">\\operatorname{poly}(\\tilde{q} + \\log T + \\log b)</span> , where  <span class="math">\\tilde{q}</span>  is the actual number of queries made by the malicious verifier; this exponential improvement over [BCGV16], where the simulator runs in time poly(T + b), enables us to &quot;go up to NEXP&quot;.</p>

    <p class="text-gray-300"><strong>Theorem 8.1</strong> (formal statement of Theorem 1.1). For every constant d &gt; 0, time bound function  <span class="math">T : \\mathbb{N} \\to \\mathbb{N}</span>  with  <span class="math">n \\leq T(n) \\leq 2^{n^d}</span> , and query bound function b:  <span class="math">\\mathbb{N} \\to \\mathbb{N}</span>  with  <span class="math">\\mathsf{b}(n) \\leq 2^{n^d}</span> , there exists an IOP system (P,V) that makes  <span class="math">\\mathbf{NTIME}(T)</span>  a subset of the complexity class</p>

    <pre><code class="language-text">PZK-IOP  \\begin{bmatrix} \\text{rounds} &amp; \\mathsf{k}(n) &amp; = &amp; 2 \\\\ \\text{proof length} &amp; \\mathsf{l}(n) &amp; = &amp; \\tilde{O}(T(n) + \\mathsf{b}(n)) \\\\ \\text{query complexity} &amp; \\mathsf{q}(n) &amp; = &amp; \\text{polylog}(T(n) + \\mathsf{b}(n)) \\\\ \\text{soundness error} &amp; \\varepsilon(n) &amp; = &amp; 1/2 \\\\ \\text{prover time} &amp; \\mathsf{tp}(n) &amp; = &amp; \\text{poly}(n) \\cdot \\tilde{O}(T(n) + \\mathsf{b}(n)) \\\\ \\text{verifier time} &amp; \\mathsf{tv}(n) &amp; = &amp; \\text{poly}(n + \\log(T(n) + \\mathsf{b}(n))) \\\\ \\text{query bound} &amp; \\mathsf{b}(n) \\end{bmatrix} .
</code></pre>

    <p class="text-gray-300">Moreover, the verifier V is public-coin and non-adaptive.</p>

    <p class="text-gray-300">Our proof is similar to that of [BCGV16], and the only major difference is that [BCGV16]'s simulator explicitly samples random codewords, while we rely on succinct constraint detection to do so implicitly. Indeed, the reduction from  <span class="math">\\mathbf{NTIME}(T)</span>  generates codewords of size O(T), which means that sampling random codewords of that size is infeasible when T is super-polynomial. We structure our argument in three steps, highlighting the essential components that implicitly underlie [BCGV16]'s 'monolithic' argument; we view this as a conceptual contribution of our work.</p>

    <p class="text-gray-300">Step 1 (Section 8.1). We construct perfect zero knowledge IOPs of Proximity for linear algebraic constraint satisfaction problems (LACSPs) [BCGV16], a family of constraint satisfaction problems whose domain and range are linear codes. An instance x of LACSP is specified by a function g and a pair of codes  <span class="math">C_0</span> ,  <span class="math">C_1</span> ; a witness w for x is a pair  <span class="math">(w_0, w_1)</span>  such that  <span class="math">w_0 \\in C_0</span> ,  <span class="math">w_1 \\in C_1</span> , and  <span class="math">g(w_0) = w_1</span> . A natural approach to construct a perfect zero knowledge IOPP for this relation is the following: if we are given a perfect zero knowledge IOP of Proximity for the relation  <span class="math">Rel(C_0 \\times C_1)</span> , then the verifier can test proximity of  <span class="math">w = (w_0, w_1)</span>  to  <span class="math">C_0 \\times C_1</span>  and then sample a random index j and check that  <span class="math">g(w_0)[j] = w_1[j]</span> . In order for the verifier's strategy to make sense, we require g to (i) satisfy a distance condition with respect to  <span class="math">C_0, C_1</span> , namely, that  <span class="math">C_1 \\cup g(C_0)</span>  has large relative distance; (ii) be 'local', which means that computing  <span class="math">g(w_0)[j]</span>  requires examining only a few indices of  <span class="math">w_0</span> ; and (iii) be 'evasive', which means that if  <span class="math">\\tilde{w}_0</span>  is close to some  <span class="math">w_0 \\in C_0</span> , then  <span class="math">g(\\tilde{w}_0)</span>  is close to  <span class="math">g(w_0)</span> . All of this implies that if  <span class="math">(\\tilde{w}_0, \\tilde{w}_1)</span>  is far from any valid witness but close to  <span class="math">C_0 \\times C_1</span> , we know that  <span class="math">g(\\tilde{w}_0)</span>  is far from  <span class="math">\\tilde{w}_1</span> , so that examining a random index j gives good soundness.</p>

    <p class="text-gray-300">Step 2 (Section 8.2). We build on the above result to derive perfect zero knowledge IOPs for a subfamily of LACSPs called randomizable LACSPs (RLACSPs) [BCGV16]. The key difference between this protocol and the IOP of Proximity described above is that in the &quot;proximity setting&quot;, the verifier, and thus also the simulator, has oracle access to the witness, while in the &quot;non-proximity setting&quot; the witness is sent to the verifier but the simulator must make do without it; in particular, merely sending the witness  <span class="math">(w_0, w_1)</span>  is not zero knowledge. We thus rely on the randomizability property of RLACSPs to generate witnesses from a t-wise independent distribution, where t is larger than the query bound b. In particular, while the simulator runs in time polynomial in the actual number of queries made by a verifier, it runs in time polylogarithmic in t, and thus we can set b to be super-polynomial in order to obtain unbounded-query zero knowledge against polynomial-time verifiers.</p>

    <p class="text-gray-300">Step 3 (Section 8.3). We derive Theorem 8.1 (perfect zero knowledge IOPs for NTIME(T)) by combining: (1) the aforementioned result for RLACSPs; (2) [BCGV16]'s reduction from NTIME to RLACSPs; (3) a perfect zero knowledge IOP of Proximity for a suitable choice of  <span class="math">C_0 \\times C_1</span> , which we derived in Section 7.2. This last component is the one that makes use of succinct constraint detection, and relies on the technical innovations of our work.</p>

      <h3 id="sec-8.1" class="text-xl font-semibold mt-8">8.1 Perfect zero knowledge IOPs of proximity for LACSPs</h3>

    <p class="text-gray-300">A constraint satisfaction problem asks whether, for a given &quot;local&quot; function g, there exists an input w such that g(w) is an accepting output. For example, in the case of 3SAT with n variables and m clauses, the function g maps  <span class="math">\\{0,1\\}^n</span>  to  <span class="math">\\{0,1\\}^m</span> , and g(w) indicates which clauses are satisfied by  <span class="math">w \\in \\{0,1\\}^n</span> ; hence w yields an accepting output if (and only if)  <span class="math">g(w) = 1^m</span> . Below we introduce a family of constraint satisfaction problems whose domain and range are linear-algebraic objects, namely, linear codes.</p>

    <p class="text-gray-300">We begin by providing the notion of locality that we use for g, along with a measure of g's &quot;pseudorandomness&quot;.</p>

    <p class="text-gray-300"><strong>Definition 8.2.</strong> Let  <span class="math">g: \\Sigma^n \\to \\Sigma^m</span>  be a function. We say that g is q-local if for every  <span class="math">j \\in [m]</span>  there exists  <span class="math">I_j \\subseteq [n]</span>  with  <span class="math">|I_j| = q</span>  such that g(w)[j] (the j-th coordinate of g(w)) depends only on  <span class="math">w|_{I_j}</span>  (the restriction of w to  <span class="math">I_j</span> ). Moreover, we say that g is s-evasive if for every  <span class="math">I \\subseteq [n]</span>  the probability that  <span class="math">I_j</span>  intersects I for a uniform  <span class="math">j \\in [m]</span>  is at most  <span class="math">s \\cdot \\frac{|I|}{n}</span> .</p>

    <p class="text-gray-300">For example, if g is a 3SAT formula then g is 3-local because  <span class="math">I_j</span>  equals the variables appearing in clause j; moreover, g is s-evasive if and only if every variable  <span class="math">x_i</span>  appears in at most a fraction s/n of the clauses (i.e., the evasiveness property corresponds to the fraction of clauses in which a variable appears). Also, a natural case where g is g-evasive is when the elements of  <span class="math">I_j</span>  are individually uniform in [n] when g is uniform in [m].</p>

    <p class="text-gray-300"><strong>Definition 8.3.</strong> Let  <span class="math">g: \\Sigma^n \\to \\Sigma^m</span>  be a function. We say that g is c-efficient if there is a c-time algorithm that, given j and  <span class="math">w|_{I_j}</span> , computes the set  <span class="math">I_j</span>  and value g(w)[j].</p>

    <p class="text-gray-300">The above definition targets succinctly-described languages. For example, a succinct 3SAT instance is given by a circuit of size S that, on input j, outputs a description of the j-th clause; the definition is then satisfied with c = O(S).</p>

    <p class="text-gray-300"><strong>Definition 8.4</strong> (LACSP). Let  <span class="math">C_0(n)</span> ,  <span class="math">C_1(n)</span>  be (descriptions of) linear codes over  <span class="math">\\mathbb{F}(n)</span>  with block length  <span class="math">\\ell(n)</span>  and relative distance  <span class="math">\\tau(n)</span> . The promise relation of linear algebraic CSPs (LACSPs)</p>

    <p class="text-gray-300"><span class="math">$(\\mathcal{R}_{\\text{LACSP}}^{\\text{YES}}, \\mathcal{L}_{\\text{LACSP}}^{\\text{NO}})[\\mathbb{F}(n), C_0(n), C_1(n), \\ell(n), \\tau(n), q(n), c(n)]</span>$</p>

    <p class="text-gray-300">considers instance-witness pairs (x, w) of the following form.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>An instance x is a tuple  <span class="math">(1^n, g)</span>  where:    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">g: \\mathbb{F}(n)^{\\ell(n)} \\to \\mathbb{F}(n)^{\\ell(n)}</span>  is q(n)-local, q(n)-evasive, and c(n)-efficient;</li>
      <li><span class="math">C_1(n) \\cup g(C_0(n))</span>  has relative distance at least  <span class="math">\\tau(n)</span>  (though may not be a linear space).</li>
    </ul></li>
      <li>A witness w is a tuple  <span class="math">(w_0, w_1)</span>  where  <span class="math">w_0, w_1 \\in \\mathbb{F}(n)^{\\ell(n)}</span> .</li>
    </ul>

    <p class="text-gray-300">The yes-relation  <span class="math">\\mathcal{R}_{\\text{LACSP}}^{\\text{YES}}</span>  consists of all pairs (x, w) as above where the instance x and witness w jointly satisfy the following:  <span class="math">w_0 \\in C_0(n)</span> ,  <span class="math">w_1 \\in C_1(n)</span> , and  <span class="math">g(w_0) = w_1</span> . (In particular, a witness  <span class="math">w = (w_0, g(w_0))</span>  with  <span class="math">w_0 \\in C_0(n)</span>  satisfies x if and only if  <span class="math">g(w_0) \\in C_1(n)</span> .) The no-language consists of all instances x as above where  <span class="math">x \\notin \\text{Lan}(\\mathcal{R}_{\\text{LACSP}}^{\\text{YES}})</span> .</p>

    <p class="text-gray-300"><strong>Remark 8.5.</strong> In [BCGV16] the codes  <span class="math">C_0</span>  and  <span class="math">C_1</span>  are allowed to have distinct block lengths while, for simplicity, we assume that they have the same block length; this restriction does not change any of their, or our, results.</p>

    <p class="text-gray-300">We are now ready to give perfect zero knowledge IOPs of proximity for LACSPs.</p>

    <p class="text-gray-300"><strong>Theorem 8.6.</strong> Suppose that there exists an IOPP system  <span class="math">(\\hat{P}, \\hat{V})</span>  that puts  <span class="math">Rel(C_0 \\times C_1)</span>  in the complexity class</p>

    <p class="text-gray-300"><strong>PZK-IOPP</strong>[
<span class="math">$\\mathbb{F}, \\hat{k}, \\hat{l}, \\hat{q}, \\hat{\\delta}, \\hat{\\varepsilon}, \\hat{tp}, \\hat{tv}, *]</span>$
.</p>

    <p class="text-gray-300">Then there exists an IOPP system  <span class="math">(P_{\\text{LACSP}}, V_{\\text{LACSP}})</span>  that puts  <span class="math">(\\mathscr{R}_{\\text{LACSP}}^{\\text{YES}}, \\mathscr{L}_{\\text{LACSP}}^{\\text{NO}})[\\mathbb{F}, C_0, C_1, \\ell, \\tau, q, c]</span>  in the complexity class</p>

    <pre><code class="language-text">\\mathbf{PZK\\text{-}IOPP} \\begin{bmatrix} \\text{answer alphabet} &amp; \\mathbb{F}(n) \\\\ \\text{rounds} &amp; \\mathbf{k}(n) &amp; = &amp; \\hat{\\mathbf{k}}(n) \\\\ \\text{proof length} &amp; \\mathbf{l}(n) &amp; = &amp; \\hat{\\mathbf{l}}(n) \\\\ \\text{query complexity} &amp; \\mathbf{q}(n) &amp; = &amp; \\hat{\\mathbf{q}}(n) + q(n) + 1 \\\\ \\text{soundness error} &amp; \\varepsilon(n) &amp; = &amp; \\max\\left\\{\\hat{\\varepsilon}(n)\\,,\\,1 - \\tau(n) + 2\\hat{\\delta}(n)\\cdot(q(n) + 1)\\right\\} \\\\ \\text{proximity parameter} &amp; \\delta(n) &amp; = &amp; \\hat{\\delta}(n) \\\\ \\text{prover time} &amp; \\mathbf{tp}(n) &amp; = &amp; \\mathbf{t\\hat{p}}(n) \\\\ \\text{verifier time} &amp; \\mathbf{tv}(n) &amp; = &amp; \\mathbf{t\\hat{v}}(n) + c(n) \\\\ \\text{query bound} &amp; \\mathbf{b}(n) &amp; = &amp; * \\end{bmatrix}.
</code></pre>

    <p class="text-gray-300">Moreover, if  <span class="math">(\\hat{P}, \\hat{V})</span>  is non-adaptive (respectively, public-coin) then so is  <span class="math">(P_{LACSP}, V_{LACSP})</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> We construct the IOPP system  <span class="math">(P_{LACSP}, V_{LACSP})</span>  for  <span class="math">\\mathscr{R}</span> , where the prover receives  <span class="math">(x, w) = ((1^n, g), (w_0, w_1))</span>  as input while the verifier receives x as input and w as an oracle, as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">P_{\\text{LACSP}}</span>  and  <span class="math">V_{\\text{LACSP}}</span>  invoke the IOPP system  <span class="math">(\\hat{P}, \\hat{V})</span>  to prove that  <span class="math">(w_0, w_1) \\in C_0 \\times C_1</span> ;</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">V_{\\text{LACSP}}</span>  chooses a random  <span class="math">j \\in [\\ell]</span>  and checks that  <span class="math">g(w_0)[j] = w_1[j]</span> ;</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">V_{\\text{LACSP}}</span>  rejects if and only if  <span class="math">\\hat{V}</span>  rejects or the above check fails.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300"><strong>Completeness.</strong> If  <span class="math">(x, w) \\in \\mathcal{R}_{LACSP}^{YES}</span> , then (i)  <span class="math">w_0 \\in C_0, w_1 \\in C_1</span> , so  <span class="math">\\hat{V}</span>  always accepts, and (ii)  <span class="math">g(w_0) = w_1</span>  so the consistency check succeeds for every  <span class="math">j \\in [\\ell]</span> . We deduce that  <span class="math">V_{LACSP}</span>  always accepts.</p>

    <p class="text-gray-300"><strong>Soundness.</strong> Suppose that  <span class="math">\\mathbf{x} \\in \\operatorname{Lan}(\\mathscr{R}_{\\mathsf{LACSP}}^{\\mathsf{YES}}) \\cup \\mathscr{L}_{\\mathsf{LACSP}}^{\\mathsf{NO}}</span>  and  <span class="math">\\tilde{\\mathbf{w}}</span>  are such that  <span class="math">\\Delta(\\tilde{\\mathbf{w}}, \\mathscr{R}_{\\mathsf{LACSP}}^{\\mathsf{YES}}|_{\\mathbf{x}}) \\geq \\hat{\\delta}</span> . Writing  <span class="math">\\tilde{\\mathbf{w}} = (\\tilde{w}_0, \\tilde{w}_1)</span> , we argue as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Case 1:  <span class="math">\\Delta(\\tilde{w}, C_0 \\times C_1) \\geq \\hat{\\delta}</span> . In this case  <span class="math">\\hat{V}</span>  rejects with probability at least  <span class="math">1 \\hat{\\varepsilon}</span> .</li>
      <li>Case 2:  <span class="math">\\Delta(\\tilde{\\mathbf{w}}, C_0 \\times C_1) &lt; \\hat{\\delta}</span> . There exist codewords  <span class="math">w_0 \\in C_0</span>  and  <span class="math">w_1 \\in C_1</span>  such that  <span class="math">(w_0, w_1)</span>  is  <span class="math">\\delta</span> -close to  <span class="math">(\\tilde{w}_0, \\tilde{w}_1)</span>  for  <span class="math">\\delta &lt; \\hat{\\delta}</span> . By assumption,  <span class="math">\\Delta(\\tilde{\\mathbf{w}}, \\mathscr{B}_{\\mathsf{LACSP}}^{\\mathsf{YES}}|_{\\mathtt{x}}) \\geq \\hat{\\delta}</span> , so in particular  <span class="math">(w_0, w_1)</span>  cannot be in  <span class="math">\\mathscr{B}_{\\mathsf{LACSP}}^{\\mathsf{YES}}|_{\\mathtt{x}}</span> , and  <span class="math">g(w_0) \\neq w_1</span> . Since  <span class="math">C_1 \\cup g(C_0)</span>  has relative distance at least  <span class="math">\\tau</span> ,  <span class="math">\\Delta(g(w_0), w_1) \\geq \\tau</span> . Observe that since  <span class="math">C_0</span>  and  <span class="math">C_1</span>  have the same block length,  <span class="math">\\Delta(\\tilde{w}_0, w_0) \\leq 2\\hat{\\delta}</span>  and  <span class="math">\\Delta(\\tilde{w}_1, w_1) \\leq 2\\hat{\\delta}</span> . Thus since g is g-evasive, the probability that the set of coordinates  <span class="math">I := \\{i \\in [\\ell] : w_0[i] \\neq \\tilde{w}_0[i]\\}</span>  intersects with  <span class="math">I_j</span>  for random  <span class="math">j \\in [\\ell]</span>  is at most  <span class="math">2\\hat{\\delta}q</span> , so  <span class="math">\\Delta(g(w_0), g(\\tilde{w}_0)) \\leq 2\\hat{\\delta}q</span> . Using the triangle inequality, we deduce that</li>
    </ul>

    <p class="text-gray-300"><span class="math">$\\Delta(g(\\tilde{w}_0), \\tilde{w}_1) \\ge \\tau - 2\\hat{\\delta}(q+1),</span>$</p>

    <p class="text-gray-300">which means the consistency check rejects with probability at least  <span class="math">\\tau - 2\\hat{\\delta}(q+1)</span> .</p>

    <p class="text-gray-300">It follows that  <span class="math">V_{\\text{LACSP}}</span>  accepts with probability at most  <span class="math">\\max\\{\\hat{\\varepsilon}, 1-\\tau+2\\hat{\\delta}(q+1)\\}</span> .</p>

    <p class="text-gray-300"><strong>Perfect zero knowledge.</strong> We can choose the simulator  <span class="math">S_{\\text{LACSP}}</span>  for  <span class="math">(P_{\\text{LACSP}}, V_{\\text{LACSP}})</span>  to equal any simulator  <span class="math">\\hat{S}</span>  that fulfills the perfect zero knowledge guarantee of  <span class="math">(\\hat{P}, \\hat{V})</span> . Indeed, the behavior of  <span class="math">P_{\\text{LACSP}}</span>  is the same as  <span class="math">\\hat{P}</span> , and so the view of any malicious verifier  <span class="math">\\hat{V}</span>  when interacting with  <span class="math">P_{\\text{LACSP}}</span>  is identical to its view when interacting with  <span class="math">\\hat{P}</span> .</p>

      <h3 id="sec-8.2" class="text-xl font-semibold mt-8">8.2 Perfect zero knowledge IOPs for RLACSPs</h3>

    <p class="text-gray-300">The above discussion achieves perfect zero knowledge for LACSPs, &quot;up to queries to the witness&quot;. We now explain how to simulate these queries as well, without any knowledge of the witness, for a special class of LACSPs called randomizable LACSPs. For these, the prover can randomize a given witness  <span class="math">(w_0, g(w_0))</span>  by sampling a random u' in a t-wise independent subcode C' of  <span class="math">C_0</span> , and use the new 'shifted' witness  <span class="math">(w_0 + u&#x27;, g(w_0 + u&#x27;))</span>  instead of the original one. We now define the notion of randomizable LACSPs, and then show how to construct perfect zero knowledge IOPs for these, against bounded-query verifiers and where the the query bound depends on t.</p>

    <p class="text-gray-300"><strong>Definition 8.7</strong> (randomizability). An instance  <span class="math">\\mathbf{x} = (1^n, g)</span>  is t(n)-randomizable in time r(n) (with respect to code families  <span class="math">C_0(n), C_1(n)</span> ) if: (i) there exists a t(n)-wise independent subcode  <span class="math">C&#x27; \\subseteq C_0(n)</span>  such that if  <span class="math">(w_0, g(w_0))</span>  satisfies  <span class="math">\\mathbf{x}</span> , then, for every  <span class="math">w&#x27;_0</span>  in  <span class="math">C&#x27; + w_0 := \\{w&#x27; + w_0 \\mid w&#x27; \\in C&#x27;\\}</span> , the witness  <span class="math">(w&#x27;_0, g(w&#x27;_0))</span>  also satisfies  <span class="math">\\mathbf{x}</span> ; and (ii) one can sample, in time r(n), three uniformly random elements in  <span class="math">C&#x27;, C_0(n), C_1(n)</span>  respectively.</p>

    <p class="text-gray-300"><strong>Definition 8.8</strong> (RLACSP). The promise relation of randomizable linear algebraic CSPs (RLACSPs) is</p>

    <p class="text-gray-300"><span class="math">$(\\mathscr{R}_{\\mathsf{RIACSP}}^{\\mathsf{YES}}, \\mathscr{L}_{\\mathsf{RIACSP}}^{\\mathsf{NO}})[\\mathbb{F}(n), C_0(n), C_1(n), \\ell(n), \\tau(n), q(n), c(n), t(n), r(n)]</span>$</p>

    <p class="text-gray-300">where  <span class="math">\\mathscr{R}_{\\mathtt{RLACSP}}^{\\mathtt{YES}}</span>  is obtained by restricting  <span class="math">\\mathscr{R}_{\\mathtt{LACSP}}</span>  to instances that are t-randomizable in time r, and  <span class="math">\\mathscr{L}_{\\mathtt{RLACSP}}^{\\mathtt{NO}} := \\mathscr{L}_{\\mathtt{LACSP}}^{\\mathtt{NO}}</span></p>

    <p class="text-gray-300"><strong>Theorem 8.9.</strong> Suppose that there exists an IOPP system  <span class="math">(\\hat{P}, \\hat{V})</span>  that puts  <span class="math">Rel(C_0 \\times C_1)</span>  in the complexity class</p>

    <p class="text-gray-300"><strong>PZK-IOPP</strong>[
<span class="math">$\\mathbb{F}, \\hat{k}, \\hat{l}, \\hat{q}, \\hat{\\delta}, \\hat{\\varepsilon}, \\hat{tp}, \\hat{tv}, *]</span>$
.</p>

    <p class="text-gray-300">Then there exists an IOP system  <span class="math">(P_{\\text{RLACSP}}, V_{\\text{RLACSP}})</span>  that puts  <span class="math">(\\mathcal{R}_{\\text{RLACSP}}^{\\text{YES}}, \\mathcal{L}_{\\text{RLACSP}}^{\\text{NO}})[\\mathbb{F}, C_0, C_1, \\ell, \\tau, q, c, t, r]</span>  (with c polynomially bounded) in the complexity class</p>

    <pre><code class="language-text"> \\mathbf{PZK\\text{-}IOP} \\left[ \\begin{array}{lll} \\text{answer alphabet} &amp; \\mathbb{F}(n) \\\\ \\text{rounds} &amp; \\mathsf{k}(n) &amp; = &amp; \\hat{\\mathsf{k}}(n) \\\\ \\text{proof length} &amp; \\mathsf{l}(n) &amp; = &amp; \\hat{\\mathsf{l}}(n) + \\ell(n) \\\\ \\text{query complexity} &amp; \\mathsf{q}(n) &amp; = &amp; \\hat{\\mathsf{q}}(n) + q(n) + 1 \\\\ \\text{soundness error} &amp; \\varepsilon(n) &amp; = &amp; \\max \\left\\{ \\hat{\\varepsilon}(n) \\, , \\, 1 - \\tau(n) + 2 \\cdot \\hat{\\delta}(n) \\cdot (q(n) + 1) \\right\\} \\\\ \\text{prover time} &amp; \\mathsf{tp}(n) &amp; = &amp; \\hat{\\mathsf{tp}}(n) + c(n) \\cdot \\ell(n) + r(n) \\\\ \\text{verifier time} &amp; \\mathsf{tv}(n) &amp; = &amp; \\hat{\\mathsf{tv}}(n) + c(n) \\\\ \\text{query bound} &amp; \\mathsf{b}(n) &amp; = &amp; t(n)/q(n) \\end{array} \\right] .
</code></pre>

    <p class="text-gray-300">Moreover, if  <span class="math">(\\hat{P}, \\hat{V})</span>  is non-adaptive (respectively, public-coin) then so is  <span class="math">(P_{RLACSP}, V_{RLACSP})</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> Let  <span class="math">(P_{\\text{LACSP}}, V_{\\text{LACSP}})</span>  be the IOPP system for  <span class="math">\\mathscr{R}_{\\text{LACSP}}</span>  guaranteed by Theorem 8.6. We construct the IOP system  <span class="math">(P_{\\text{RLACSP}}, V_{\\text{RLACSP}})</span>  for  <span class="math">(\\mathscr{R}_{\\text{RLACSP}}^{\\text{YES}}, \\mathscr{L}_{\\text{RLACSP}}^{\\text{NO}})</span> , where the prover receives  <span class="math">(\\mathtt{x}, \\mathtt{w}) = ((1^n, g), (w_0, w_1))</span>  as input while the verifier receives  <span class="math">\\mathtt{x}</span>  as input, as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The prover  <span class="math">P_{\\text{RLACSP}}</span>  parses the witness w as  <span class="math">(w_0, w_1) \\in C_0 \\times C_1</span> , samples a random  <span class="math">u&#x27; \\in C&#x27;</span>  (the subcode of  <span class="math">C_0</span>  for which t-randomizability holds), sets  <span class="math">w&#x27;_0 := u&#x27; + w_0</span>  and  <span class="math">w&#x27;_1 := g(w&#x27;_0)</span> , and sends  <span class="math">w&#x27; := (w&#x27;_0, w&#x27;_1)</span>  to  <span class="math">V_{\\text{RLACSP}}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>In parallel to the above interaction, the prover  <span class="math">P_{\\text{RLACSP}}</span>  and verifier  <span class="math">V_{\\text{RLACSP}}</span>  invoke the IOPP system  <span class="math">(P_{\\text{LACSP}}, V_{\\text{LACSP}})</span>  on the input x and new &quot;prover-randomized&quot; witness w'. The verifier  <span class="math">V_{\\text{RLACSP}}</span>  accepts if and only if  <span class="math">V_{\\text{LACSP}}</span>  does.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">The claimed efficiency parameters immediately follow by construction. We now show that  <span class="math">(P_{\\text{RLACSP}}, V_{\\text{RLACSP}})</span>  satisfies completeness, soundness, and perfect zero-knowledge.</p>

    <p class="text-gray-300"><strong>Completeness.</strong> Suppose that  <span class="math">(\\mathbf{x},\\mathbf{w})=\\left((1^n,g),(w_0,w_1)\\right)</span>  is in the relation  <span class="math">\\mathscr{R}^{\\mathsf{YES}}_{\\mathsf{RLACSP}}</span> , so that  <span class="math">w_0\\in C_0,w_1\\in C_1</span> , and  <span class="math">g(w_0)=w_1</span> . By randomizability (Definition 8.8), since  <span class="math">w_0&#x27;\\in C&#x27;+w_0</span> , we deduce that  <span class="math">\\mathbf{w}&#x27;=(w_0&#x27;,w_1&#x27;)=(w_0&#x27;,g(w_0&#x27;))</span>  satisfies  <span class="math">\\mathbf{x}</span> , and so  <span class="math">(\\mathbf{x},\\mathbf{w}&#x27;)\\in\\mathscr{R}^{\\mathsf{YES}}_{\\mathsf{LACSP}}</span> . Completeness then follows by the completeness of  <span class="math">(P_{\\mathsf{LACSP}},V_{\\mathsf{LACSP}})</span> .</p>

    <p class="text-gray-300"><strong>Soundness.</strong> Suppose that  <span class="math">\\mathbf{x}=(1^n,g)</span>  is in the language  <span class="math">\\mathscr{L}^{\\text{NO}}_{\\text{RLACSP}}=\\mathscr{L}^{\\text{NO}}_{\\text{LACSP}}</span> , so that  <span class="math">\\mathscr{R}^{\\text{YES}}_{\\text{LACSP}}|_{\\mathbf{x}}=\\emptyset</span> . Regardless of what 'witness'  <span class="math">\\mathbf{w}&#x27;</span>  is sent by  <span class="math">P_{\\text{RLACSP}}</span> , it holds that  <span class="math">\\Delta(\\mathbf{w}&#x27;,\\mathscr{R}^{\\text{YES}}_{\\text{LACSP}}|_{\\mathbf{x}})=\\Delta(\\mathbf{w}&#x27;,\\emptyset)=1\\geq\\hat{\\delta}</span> , so that the soundness of  <span class="math">(P_{\\text{LACSP}},V_{\\text{LACSP}})</span>  implies that  <span class="math">V_{\\text{LACSP}}</span> , and thus  <span class="math">V_{\\text{RLACSP}}</span> , accepts with probability at most  <span class="math">\\max\\{\\hat{\\varepsilon},1-\\tau+2\\hat{\\delta}\\cdot(q+1)\\}</span> .</p>

    <p class="text-gray-300"><strong>Perfect zero knowledge.</strong> Let  <span class="math">\\tilde{V}</span>  be any verifier that makes at most b := t/q queries, and let  <span class="math">S_{LACSP}</span>  be the perfect zero knowledge simulator for  <span class="math">(P_{LACSP}, V_{LACSP})</span> . We construct a simulator  <span class="math">S_{RLACSP}</span>  for  <span class="math">(P_{RLACSP}, V_{RLACSP})</span>  as follows:</p>

    <p class="text-gray-300"><span class="math">S_{\\text{RIACSP}}^{\\tilde{V}}(\\mathbf{x})</span> :</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">S_{\\text{RLACSP}}</span>  initializes two empty strings  <span class="math">\\hat{w}_0</span>  and  <span class="math">\\hat{w}_1</span>  which will be partially filled during the simulation.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">S_{\\text{RLACSP}}</span>  invokes  <span class="math">S_{\\text{LACSP}}^{\\tilde{V},(\\hat{w}_0,\\hat{w}_1)}</span> , and during the execution answers oracle queries to  <span class="math">(\\hat{w}_0,\\hat{w}_1)</span>  in the following way.</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(a) If  <span class="math">S_{\\text{LACSP}}</span>  queries  <span class="math">\\hat{w}_0</span>  at a location  <span class="math">j \\in [\\ell]</span> : if  <span class="math">\\hat{w}_0[j]</span>  is already defined then return that value; otherwise sample a random  <span class="math">a \\in \\mathbb{F}(n)</span> , set  <span class="math">\\hat{w}_0[j] := a</span> , and reply with  <span class="math">\\hat{w}_0[j]</span> .</li>
      <li>(b) If  <span class="math">S_{\\text{LACSP}}</span>  queries  <span class="math">\\hat{w}_1</span>  at a location  <span class="math">j \\in [\\ell]</span> : if  <span class="math">\\hat{w}_1[j]</span>  is already defined then return that value; otherwise compute the set of indices  <span class="math">I_j \\subseteq [\\ell]</span>  that  <span class="math">g(\\cdot)_j</span>  depends on; then 'query' the values of  <span class="math">\\hat{w}_0[i]</span>  for all  <span class="math">i \\in I_j</span>  as in the previous step; then update  <span class="math">\\hat{w}_1[j] := g(\\hat{w}_0)[j]</span>  and reply with  <span class="math">\\hat{w}_1[j]</span> .</li>
    </ul></li>
    </ul>

    <p class="text-gray-300">Observe that  <span class="math">S_{\\text{RLACSP}}</span>  runs in time  <span class="math">\\operatorname{poly}(|\\mathbf{x}|+q_{\\tilde{V}}+c)</span> , where  <span class="math">q_{\\tilde{V}}</span>  denotes the actual number of queries made by  <span class="math">\\tilde{V}</span>  and c is g's efficiency (see Definition 8.3). Since c is polynomially bounded,  <span class="math">S_{\\text{RLACSP}}</span>  runs in time  <span class="math">\\operatorname{poly}(|\\mathbf{x}|+\\mathsf{q}_{\\tilde{V}})</span> , as required.</p>

    <p class="text-gray-300">We must show that View  <span class="math">\\langle P_{\\text{RLACSP}}(\\mathbf{x}, \\mathbf{w}), \\tilde{V}(\\mathbf{x}) \\rangle</span>  and  <span class="math">S_{\\text{RLACSP}}^{\\tilde{V}}(\\mathbf{x})</span>  are identically distributed. Recall that  <span class="math">P_{\\text{RLACSP}}(\\mathbf{x}, \\mathbf{w})</span>  samples  <span class="math">\\mathbf{w}&#x27;</span>  and then invokes  <span class="math">P_{\\text{LACSP}}(\\mathbf{x}, \\mathbf{w}&#x27;)</span> ; viewing  <span class="math">\\mathbf{w}&#x27;</span>  as a random variable, we get that  <span class="math">\\text{View } \\langle P_{\\text{RLACSP}}(\\mathbf{x}, \\mathbf{w}), \\tilde{V}(\\mathbf{x}) \\rangle \\equiv \\text{View } \\langle P_{\\text{LACSP}}(\\mathbf{x}, \\mathbf{w}&#x27;), \\tilde{V}(\\mathbf{x}) \\rangle</span> . By  <span class="math">(P_{\\text{LACSP}}, V_{\\text{LACSP}})</span> 's perfect zero knowledge guarantee, we also know that</p>

    <p class="text-gray-300"><span class="math">$\\left( \\mathrm{View} \\ \\langle P_{\\mathrm{LACSP}}(\\mathbf{x}, \\mathbf{w}&#x27;), \\tilde{V}(\\mathbf{x}) \\rangle, q_{\\tilde{V}} \\right) \\equiv \\left( S_{\\mathrm{LACSP}}^{\\tilde{V}, \\mathbf{w}&#x27;}(\\mathbf{x}), q_{S_{\\mathrm{LACSP}}} \\right) \\ .</span>$</p>

    <p class="text-gray-300">We are left to show that  <span class="math">S_{\\text{LACSP}}^{\\tilde{V},\\text{W}&#x27;}(\\mathbf{x}) \\equiv S_{\\text{RLACSP}}^{\\tilde{V}}(\\mathbf{x}).</span></p>

    <p class="text-gray-300">By the query bound, we know that  <span class="math">S_{\\text{LACSP}}</span>  makes at most t/q queries to w'. By construction of  <span class="math">S_{\\text{RLACSP}}</span> , this causes at most t entries in  <span class="math">\\hat{w}_0</span>  to be 'defined', since  <span class="math">|I_j| \\leq q</span>  for all  <span class="math">j \\in [\\ell]</span>  (by g's locality); let  <span class="math">E \\subseteq [\\ell]</span>  be these entries. Since  <span class="math">w_1 = g(w_0)</span> , all of the responses to  <span class="math">S_{\\text{LACSP}}</span> 's queries are determined by  <span class="math">w_0&#x27;|_E</span> . While E is itself dependent on  <span class="math">w_0&#x27;</span>  (as  <span class="math">\\tilde{V}</span> 's queries may be adaptive), this does not affect the distribution of the string  <span class="math">w_0&#x27;|_E</span>  because  <span class="math">|E| \\leq t</span>  and  <span class="math">w_0&#x27;</span>  is drawn from a t-wise independent distribution. We deduce that there exists a deterministic function  <span class="math">v(\\cdot)</span>  such that  <span class="math">S_{\\text{LACSP}}</span> 's queries to w' are answered by  <span class="math">v(w_0&#x27;|_E)</span>  in the 'real' execution, and  <span class="math">S_{\\text{RLACSP}}</span>  answers the same queries with v(U) where U is uniformly random in  <span class="math">\\mathbb{F}^E</span> . But  <span class="math">w_0&#x27;</span>  is |E|-wise independent, so that  <span class="math">w_0&#x27;|_E \\equiv U</span> , and thus  <span class="math">S_{\\text{LACSP}}^{\\tilde{V},w&#x27;}(x) \\equiv S_{\\text{RLACSP}}^{\\tilde{V}}(x)</span> .</p>

      <h3 id="sec-8.3" class="text-xl font-semibold mt-8"><strong>8.3</strong> Putting things together</h3>

    <p class="text-gray-300">We are almost ready to prove Theorem 8.1, the main theorem of this section. The last missing piece is a suitable reduction from  <span class="math">\\mathbf{NTIME}(T)</span>  to  <span class="math">\\mathcal{R}_{\\mathsf{RLACSP}}</span> , the promise relation of RLACSPs. Below, we state a special case of [BCGV16, Thm. 7.9], which provides the reduction that we need.</p>

    <p class="text-gray-300"><strong>Theorem 8.10</strong> (NTIME  <span class="math">\\to \\mathscr{R}_{\\mathsf{RLACSP}}</span> ). For every  <span class="math">T, t \\colon \\mathbb{N} \\to \\mathbb{N}</span> , constant  <span class="math">\\tau \\in (0, 1)</span> , and  <span class="math">\\mathscr{R} \\in \\mathbf{NTIME}(T)</span>  there exist algorithms inst, wit<sub>1</sub>, wit<sub>2</sub> satisfying the following conditions:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>EFFICIENT REDUCTION. For every instance x, letting x' := inst(x):    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>if  <span class="math">x \\in \\operatorname{Lan}(\\mathscr{R})</span>  then  <span class="math">x&#x27; \\in \\operatorname{Lan}(\\mathscr{R}_{RLACSP}^{YES})</span> ;</li>
      <li><span class="math">-if \\mathbf{x} \\notin \\operatorname{Lan}(\\mathscr{R}) \\text{ then } \\mathbf{x}&#x27; \\in \\mathscr{L}_{\\mathsf{RLACSP}}^{\\mathsf{NO}};</span></li>
      <li>for every witness w, if  <span class="math">(x, w) \\in \\mathcal{R}</span>  then  <span class="math">(x&#x27;, wit_1(x, w)) \\in \\mathcal{R}_{RLACSP}^{YES}</span> ;</li>
      <li>for every witness w', if  <span class="math">(x&#x27;, w&#x27;) \\in \\mathcal{R}_{RLACSP}^{YES}</span>  then  <span class="math">(x, wit_2(x, w&#x27;)) \\in \\mathcal{R}</span> .</li>
    </ul></li>
    </ul>

    <p class="text-gray-300">Moreover, inst runs in time  <span class="math">\\operatorname{poly}(n + \\log(T(n) + t(n)))</span>  and  <span class="math">\\operatorname{wit}_1</span> ,  <span class="math">\\operatorname{wit}_2</span>  run in time  <span class="math">\\operatorname{poly}(n) \\cdot \\tilde{O}(T(n) + t(n))</span> .</p>

    <p class="text-gray-300">&bull; RANDOMIZABLE LINEAR ALGEBRAIC CSP. The promise relation  <span class="math">(\\mathcal{R}_{RLACSP}^{YES}, \\mathcal{L}_{RLACSP}^{NO})</span>  has the parameters:</p>

    <p class="text-gray-300"><span class="math">$(\\mathscr{R}_{\\text{RLACSP}}^{\\text{YES}},\\mathscr{L}_{\\text{RLACSP}}^{\\text{NO}}) \\left[ \\begin{array}{cccc} \\text{field} &amp; \\mathbb{F} &amp; = &amp; \\mathbb{F}_{2^{\\log(T+t)+O(\\log\\log(T+t))}} \\\\ \\text{first code} &amp; &amp; C_0 \\\\ \\text{second code} &amp; &amp; C_1 \\\\ \\text{block length} &amp; &amp; \\ell &amp; = &amp; \\tilde{O}(T+t) \\\\ \\text{relative distance} &amp; &amp; \\tau \\\\ \\text{map locality} &amp; &amp; q &amp; = &amp; \\text{polylog}\\,T \\\\ \\text{map efficiency} &amp; &amp; c &amp; = &amp; \\text{poly}(n+\\log T) \\\\ \\text{randomizability} &amp; &amp; t \\\\ \\text{randomize time} &amp; &amp; r &amp; = &amp; \\tilde{O}(T+t) \\end{array} \\right].</span>$</p>

    <p class="text-gray-300">(The hidden constants depend on the choice of  <span class="math">\\tau</span> ; see [BCGV16, Thm. 7.9] for the dependence on  <span class="math">\\tau</span> .)</p>

    <p class="text-gray-300">&bull; ADDITIVE REED-SOLOMON CODES.  <span class="math">Rel(C_0 \\times C_1)</span>  is a subfamily of ERS<sup>+</sup>.</p>

    <p class="text-gray-300"><em>Proof of Theorem 8.1.</em> The theorem directly follows by having the prover and verifier reduce the given relation in  <span class="math">\\mathbf{NTIME}(T)</span>  to  <span class="math">(\\mathcal{R}_{\\mathtt{RLACSP}}^{\\mathtt{YES}}, \\mathcal{L}_{\\mathtt{RLACSP}}^{\\mathtt{NO}})</span> , following Theorem 8.10, and then invoking Theorem 8.9 with the perfect zero knowledge IOP of Proximity for ERS<sup>+</sup> from Corollary 7.14.</p>

    <p class="text-gray-300">We summarize prior work on <em>single</em>-prover proof systems that achieve zero knowledge unconditionally. First, the complexity classes of PZK IPs and SZK IPs are contained in AM &cap; coAM <a href="#page-57-20">[For87,</a> <a href="#page-56-18">AH91]</a>, so they do not contain NP unless the polynomial hierarchy collapses <a href="#page-57-4">[BHZ87]</a>; thus, IPs have strong limitations. Next, we discuss other single-prover proof systems: PCPs and IPCPs; all prior work for these is about <em>statistical</em> zero knowledge (SZK), via simulators that are straightline (which is needed in many of the cryptographic applications explored in these works).</p>

    <p class="text-gray-300">SZK PCP for NEXP. <a href="#page-58-12">[KPT97]</a> obtain PCPs for NEXP that are SZK against unbounded queries; the PCP has exponential length, the honest verifier makes a polynomial number of queries, and malicious verifiers can make any polynomial number of queries. Their construction has two steps: (1) transform a given PCP into a new one that is PZK against (several independent copies of) the honest verifier; (2) transform the latter PCP into a new one that is SZK against malicious verifiers. The first step uses secret sharing and builds on techniques of <a href="#page-57-7">[DFK</a><sup>+</sup>92]; the second uses <em>locking schemes</em>, which are information-theoretic PCP-analogues of commitment schemes. Subsequent work simplifies the steps: <a href="#page-58-20">[IW14]</a> use MPC techniques to simplify the first step; and <a href="#page-58-13">[IMS12,</a> <a href="#page-58-14">IMSX15]</a> give a simple construction of locking schemes, by obtaining a non-interactive PCP-analogue of <a href="#page-58-23">[Nao91]</a>'s commitment scheme.</p>

    <p class="text-gray-300">SZK PCP for NP against unbounded queries. A PCP must have super-polynomial length if it ensures SZK against any polynomial number of malicious queries: if not, a malicious verifier could read the entire PCP, in which case zero knowledge is impossible for non-trivial languages <a href="#page-57-21">[GO94]</a>. If one allows the prover to be inefficient, then invoking <a href="#page-58-12">[KPT97]</a>'s result for any language in NEXP, including NP languages, suffices. Yet, in the case of NP, one can still aim for <em>oracle efficiency</em>: the prover outputs a succinct representation of the oracle, i.e., a polynomial-size circuit that, given an index, outputs the value at that index. However, <a href="#page-58-13">[IMS12,</a> <a href="#page-58-24">MX13,</a> <a href="#page-58-14">IMSX15]</a> show that languages with oracle-efficient PCPs that are SZK against unbounded queries are contained in the complexity class of SZP IPs, which is unlikely to contain NP.</p>

    <p class="text-gray-300">SZK PCP for NP against bounded queries. <a href="#page-58-12">[KPT97]</a> obtain PCPs for NP that are SZK against b malicious queries, for a given polynomially-bounded function b. The construction is analogous to the one for NEXP, but with different parameter choices. (The simplifications in <a href="#page-58-13">[IMS12,</a> <a href="#page-58-14">IMSX15,</a> <a href="#page-58-20">IW14]</a> also apply to this case.)</p>

    <p class="text-gray-300">Subsequently, <a href="#page-58-20">[IW14]</a> consider the case of zero knowledge PCPs <em>of proximity</em>; they obtain PCPPs for NP that are SZK against b malicious queries. Like <a href="#page-58-12">[KPT97]</a>, their construction has two steps: (1) use MPC techniques to transform a given PCPP into a new one that is PZK against (several independent copies of) the honest verifier; (2) use locking schemes to transform the latter PCPP into a new one that is SZK against malicious verifiers.</p>

    <p class="text-gray-300">SZK IPCP for NP against unbounded queries. For an IPCP to ensure SZK against any polynomial number of queries, the prover must send a PCP with super-polynomial length: if not, a malicious verifier could read the entire PCP, forcing the IPCP model to &quot;collapse&quot; to IP (recall that the complexity class of SZK IPs is unlikely to contain NP). As in the PCP model, one may still aim for oracle efficiency, and this time no limitations apply because a positive result is known: <a href="#page-57-8">[GIMS10]</a> obtain oracle-efficient IPCPs for NP that are SZK against unbounded queries. Their construction is analogous to <a href="#page-58-12">[KPT97]</a>'s, but relies on <em>interactive locking schemes</em> in the IPCP model, rather than non-interactive ones in the PCP model; this circumvents the impossibility result for oracle-efficient PCPs.</p>

    </section>

    <section id="app-b" class="mb-10">
      <h2 class="text-2xl font-bold">B Proof of Lemma 4.3</h2>

    <p class="text-gray-300">The algorithm  <span class="math">\\mathcal{A}</span> , given  <span class="math">(\\mathfrak{n}, S, \\alpha)</span> , where  <span class="math">S = \\{(\\alpha_1, \\beta_1), \\ldots, (\\alpha_\\ell, \\beta_\\ell)\\} \\subseteq D(\\mathfrak{n}) \\times \\mathbb{F}(\\mathfrak{n})</span>  and  <span class="math">\\alpha \\in D(\\mathfrak{n})</span> , works as follows: (1) run  <span class="math">\\mathscr{C}</span> 's constraint detector on input  <span class="math">(\\mathfrak{n}, \\{\\alpha_1, \\ldots, \\alpha_\\ell, \\alpha\\})</span> ; (2) if the detector outputs an empty basis or a basis  <span class="math">z_1, \\ldots, z_d</span>  where  <span class="math">z_i(\\alpha) = 0</span>  for all i, then output a random element in  <span class="math">\\mathbb{F}(\\mathfrak{n})</span> ; (3) if the detector outputs some basis element  <span class="math">z_j</span>  where  <span class="math">z_j(\\alpha) \\neq 0</span> , then output  <span class="math">-\\sum_{i=1}^\\ell \\frac{z_j(\\alpha_i)}{z_j(\\alpha)}\\beta_i</span> . The stated time complexity of  <span class="math">\\mathcal{A}</span>  is clear from its construction. We now argue correctness. Define the probability</p>

    <p class="text-gray-300"><span class="math">$p := \\Pr_{w \\leftarrow C_n} \\left[ w(\\alpha) = \\beta \\middle| \\begin{array}{c} w(\\alpha_1) = \\beta_1 \\\\ \\vdots \\\\ w(\\alpha_\\ell) = \\beta_\\ell \\end{array} \\right] .</span>$</p>

    <p class="text-gray-300"><strong>Claim.</strong> (A) If there exist  <span class="math">a_1, \\ldots, a_\\ell \\in \\mathbb{F}(\\mathfrak{m})</span>  such that  <span class="math">w(\\alpha) = \\sum_{i=1}^\\ell a_i w(\\alpha_i)</span>  for all  <span class="math">w \\in C_n</span>  (Condition A), then p = 1 if  <span class="math">\\beta = \\sum_{i=1}^\\ell a_i \\beta_i</span>  and p = 0 otherwise. (B) If no such  <span class="math">a_1, \\ldots, a_\\ell</span>  exist, then  <span class="math">p = \\frac{1}{|\\mathbb{F}(\\mathfrak{m})|}</span> .</p>

    <p class="text-gray-300">Proof of claim. If Condition A holds, then, for any  <span class="math">w \\in C_n</span>  such that  <span class="math">w(\\alpha_1) = \\beta_1, \\dots, w(\\alpha_\\ell) = \\beta_\\ell</span> , it holds that  <span class="math">w(\\alpha) = \\sum_{i=1}^\\ell a_i w(\\alpha_i) = \\sum_{i=1}^\\ell a_i \\beta_i</span> , which proves the first part of the claim.</p>

    <p class="text-gray-300">Next, let  <span class="math">d := \\dim(C_n)</span>  and let  <span class="math">w_1, \\ldots, w_d</span>  be a basis of  <span class="math">C_n</span> . Define  <span class="math">\\phi_{\\alpha} := (w_1(\\alpha), \\ldots, w_d(\\alpha))</span> . We argue that Condition A holds if and only if  <span class="math">\\phi_{\\alpha} \\in \\operatorname{span}(\\phi_{\\alpha_1}, \\ldots, \\phi_{\\alpha_\\ell})</span> :</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Suppose that Condition A holds. Then  <span class="math">w_j(\\alpha) = \\sum_{i=1}^{\\ell} a_i w_j(\\alpha_i)</span>  for every  <span class="math">j \\in \\{1, \\ldots, d\\}</span> . Since  <span class="math">w_j(\\alpha)</span>  is the j-th coordinate of  <span class="math">\\phi_{\\alpha}</span> , it also holds that  <span class="math">\\phi_{\\alpha} = \\sum_{i=1}^{\\ell} a_i \\phi_{\\alpha_i}</span> , so that  <span class="math">\\phi_{\\alpha} \\in \\text{span}(\\phi_{\\alpha_1}, \\ldots, \\phi_{\\alpha_\\ell})</span> .</li>
      <li>Suppose that  <span class="math">\\phi_{\\alpha} \\in \\text{span}(\\phi_{\\alpha_1}, \\dots, \\phi_{\\alpha_{\\ell}})</span> . Then there exist  <span class="math">a_1, \\dots, a_{\\ell}</span>  such that  <span class="math">\\phi_{\\alpha} = \\sum_{i=1}^{\\ell} a_i \\phi_{\\alpha_i}</span> . For any  <span class="math">w \\in C_n</span> , we can write  <span class="math">w = \\sum_{j=1}^{d} b_j w_j</span>  (for some  <span class="math">b_j</span> 's), so that  <span class="math">w(\\alpha) = \\sum_{j=1}^{d} b_j w_j(\\alpha) = \\langle w, \\phi_{\\alpha} \\rangle = \\sum_{i=1}^{\\ell} a_i \\langle w, \\phi_{\\alpha_i} \\rangle = \\sum_{i=1}^{\\ell} a_i w(\\alpha_i)</span> .</li>
    </ul>

    <p class="text-gray-300">Thus, the negation of Condition A is equivalent to  <span class="math">\\phi_{\\alpha} \\notin \\operatorname{span}(\\phi_{\\alpha_1}, \\dots, \\phi_{\\alpha_\\ell})</span> , which we now assume to prove the second part of the claim, as follows.</p>

    <p class="text-gray-300">Let  <span class="math">\\Phi \\in \\mathbb{F}(\\mathfrak{n})^{\\ell \\times d}</span>  be the matrix whose rows are  <span class="math">\\phi_{\\alpha_1}, \\ldots, \\phi_{\\alpha_\\ell}</span> , and let  <span class="math">w&#x27;_1, \\ldots, w&#x27;_k</span>  be a basis for  <span class="math">\\Phi</span> 's nullspace. Let  <span class="math">\\Phi&#x27;</span>  be the matrix  <span class="math">\\Phi</span>  augmented with the row  <span class="math">\\phi_{\\alpha}</span> . Note that  <span class="math">\\operatorname{rank}(\\Phi&#x27;) = \\operatorname{rank}(\\Phi) + 1</span> , so the nullspace of  <span class="math">\\Phi&#x27;</span>  has dimension k-1, which implies that there exists  <span class="math">j \\in \\{1,\\ldots,k\\}</span>  such that  <span class="math">\\langle w&#x27;_j,\\phi_{\\alpha}\\rangle \\neq 0</span> . Also note that, for every  <span class="math">w \\in C_n</span>  such that  <span class="math">w(\\alpha_1) = \\beta_1,\\ldots,w(\\alpha_\\ell) = \\beta_\\ell</span>  and  <span class="math">r \\in \\mathbb{F}(\\mathfrak{n})</span> , the codeword  <span class="math">w+rw&#x27;_j</span>  satisfies the same equations as w does. Therefore, if w is drawn uniformly randomly from  <span class="math">C_n</span>  such that  <span class="math">w(\\alpha_1) = \\beta_1,\\ldots,w(\\alpha_\\ell) = \\beta_\\ell</span> , then  <span class="math">w+rw&#x27;_j</span>  for r uniformly random in  <span class="math">\\mathbb{F}(\\mathfrak{n})</span>  is identically distributed to w. We conclude that  <span class="math">\\Pr[w(\\alpha) = \\beta] = \\Pr[(w+rw&#x27;_j)(\\alpha) = \\beta] = \\Pr[r = \\frac{\\beta-\\langle w,\\phi_{\\alpha}\\rangle}{\\langle w&#x27;_j,\\phi_{\\alpha}\\rangle}] = \\frac{1}{|\\mathbb{F}(\\mathfrak{n})|}</span> , since  <span class="math">\\langle w&#x27;_i,\\phi_{\\alpha}\\rangle \\neq 0</span> .</p>

    <p class="text-gray-300">By the definition of constraint detection,  <span class="math">a_1, \\ldots, a_\\ell</span>  as above exist if and only if there exists z in the space output by the constraint detector such that  <span class="math">z(\\alpha) = 1</span> . If the constraint detector outputs  <span class="math">z_1, \\ldots, z_d</span>  such that  <span class="math">z_i(\\alpha) = 0</span>  for all i, then clearly the space contains no such vector. Otherwise, let j be such that  <span class="math">z_j(\\alpha) \\neq 0</span> ; then  <span class="math">a_i = -z_j(\\alpha_i)/z_j(\\alpha)</span>  for  <span class="math">i = 1, \\ldots, \\ell</span>  is a solution. Hence this distribution equals that of  <span class="math">\\mathcal{A}</span> 's output, and moreover fully describes the probability distribution of  <span class="math">w(\\alpha)</span> . The lemma follows.</p>

    </section>

    <section id="app-c" class="mb-10">
      <h2 class="text-2xl font-bold">C Proof of Lemma 4.6</h2>

    <p class="text-gray-300">By Claim 4.5, it suffices to show an algorithm that computes a basis of  <span class="math">(C_n^{\\perp})_{\\subseteq I}</span>  in  <span class="math">\\operatorname{poly}(|\\mathfrak{n}|+|I|)</span>  time. So consider the algorithm that, on input an index  <span class="math">\\mathfrak{n}</span>  and subset  <span class="math">I\\subseteq D(\\mathfrak{n})</span> , works as follows. First, invoke the hypothesis to compute the set W; since vectors are represented sparsely we conclude that  <span class="math">|W|, |\\operatorname{supp}(W)| \\leq \\operatorname{poly}(|\\mathfrak{n}|+|I|)</span> . (Recall that  <span class="math">\\operatorname{supp}(W) := \\cup_{z\\in W} \\operatorname{supp}(z)</span> .) We may assume W is linearly independent; otherwise, make it thus via Gaussian elimination which runs in time  <span class="math">\\operatorname{poly}(|W|+|\\operatorname{supp}(W)|)</span> . Similarly, the bound on |W| and  <span class="math">|\\operatorname{supp}(W)|</span>  implies that a basis W' for the subspace  <span class="math">W_{\\subseteq I}</span>  can be found in time  <span class="math">\\operatorname{poly}(|\\mathfrak{n}|+|I|)</span> , and we let W' be the output of our algorithm.</p>

    <p class="text-gray-300">To argue correctness it suffices to show that  <span class="math">\\operatorname{span}(W&#x27;) = (C_n^\\perp)_{\\subseteq I}</span> . We first  <span class="math">\\operatorname{argue} \\operatorname{span}(W&#x27;) \\subseteq (C_n^\\perp)_{\\subseteq I}</span> , so let  <span class="math">z&#x27; \\in \\operatorname{span}(W&#x27;)</span> , which can be represented as  <span class="math">z&#x27; = \\sum_{\\lambda \\in \\Lambda} a_\\lambda \\sum_{z \\in W} \\lambda(z) \\cdot z</span> ; note that  <span class="math">z&#x27; \\in \\operatorname{span}(W) \\subseteq C_n^\\perp</span>  and  <span class="math">\\operatorname{supp}(z&#x27;) \\subseteq \\operatorname{supp}(W) = I \\cup \\overline{I}</span> . Hence, it suffices to show that  <span class="math">\\operatorname{supp}(z&#x27;) \\cap \\overline{I} = \\emptyset</span> ; but this is true by the choice of  <span class="math">\\Lambda</span> , because  <span class="math">M \\cdot \\lambda = 0</span>  for every  <span class="math">\\lambda \\in \\Lambda</span> , so that  <span class="math">\\sum_{z \\in W} \\lambda(w) \\cdot z(\\alpha) = 0</span>  for every  <span class="math">\\alpha \\in \\overline{I}</span>  (by M's definition), so that  <span class="math">z&#x27;(\\alpha) = \\sum_{\\lambda \\in \\Lambda} a_\\lambda \\sum_{z \\in W} \\lambda(z) \\cdot z(\\alpha) = 0</span>  for every  <span class="math">\\alpha \\in \\overline{I}</span> , as required.</p>

    <p class="text-gray-300">We next argue that  <span class="math">\\operatorname{span}(W&#x27;)\\supseteq (C_{\\mathfrak{n}}^{\\perp})_{\\subseteq I}</span> , and for this it suffices to show that any  <span class="math">w\\in\\operatorname{span}(W)</span>  having representation  <span class="math">w=\\sum_{z\\in W}a_z\\cdot z</span>  such that  <span class="math">\\vec{a}:=(a_z)_{z\\in W}\\notin\\operatorname{span}(\\Lambda)</span>  can not be in  <span class="math">(C_{\\mathfrak{n}}^{\\perp})_{\\subseteq I}</span> . This follows by the definition of  <span class="math">\\Lambda</span> , because for any  <span class="math">\\vec{a}\\notin\\operatorname{span}(\\Lambda)</span>  there exists  <span class="math">\\alpha\\in \\overline{I}</span>  such that  <span class="math">w(\\alpha)=\\sum_{z\\in W}a_z\\cdot z(\\alpha)\\neq 0</span> , so that  <span class="math">w\\notin (C_{\\mathfrak{n}}^{\\perp})_{\\subseteq I}</span> .</p>

    </section>

    <section id="app-d" class="mb-10">
      <h2 class="text-2xl font-bold">D Proof of Lemma 4.11</h2>

    <p class="text-gray-300">For completeness, we give an elementary proof of Lemma 4.11, by simplifying the proof of [Kay10, Thm. 10] for polynomials of the form we require; note that [RS05] and [BW04] also use similar techniques. We first introduce some notation. We consider a polynomial  <span class="math">Q \\in \\mathbb{F}^{&lt; d}[X_1,\\ldots,X_m]</span>  equivalently as a univariate polynomial of degree less than d in  <span class="math">X_1</span>  with coefficients in  <span class="math">\\mathbb{F}^{&lt; d}[X_2,\\ldots,X_m]</span> , and let  <span class="math">\\partial_1^j Q</span>  be the coefficient of  <span class="math">X_1^j</span>  in this representation. Define  <span class="math">\\partial_1^j Q := (\\partial_1^j Q_1,\\ldots,\\partial_1^j Q_\\ell)</span> . In general, given an arbitrary arithmetic circuit representing a polynomial Q, it is not clear how to efficiently compute a circuit representing  <span class="math">\\partial_1^j Q</span> , because Q may have exponentially many monomials. Nevertheless, for circuits of the required form, this computation is trivial.</p>

    <p class="text-gray-300"><strong>Claim.</strong> Let
<span class="math">$\\vec{Q} := (Q_1, \\dots, Q_\\ell)</span>$
be a vector of polynomials in  <span class="math">\\mathbb{F}^{&lt; d}[X_1, \\dots, X_m]</span> . If  <span class="math">d \\leq |\\mathbb{F}|</span>  then  <span class="math">\\vec{Q}^{\\perp} = \\bigcap_{i=0}^{d-1} (\\partial_i^j \\vec{Q})^{\\perp}</span> .</p>

    <p class="text-gray-300">Proof. When  <span class="math">d \\leq |\\mathbb{F}|</span> ,  <span class="math">Q \\in \\mathbb{F}^{&lt; d}[X_1, \\dots, X_m] \\equiv 0</span>  if and only if all of its coefficients are zero when written as a formal sum. Then one direction of the set equality follows straightforwardly from the linearity of  <span class="math">\\partial_1^j</span> , namely,  <span class="math">\\vec{Q}^\\perp \\subseteq \\bigcap_{j=0}^{d-1} (\\partial_1^j \\vec{Q})^\\perp</span> . For the other direction, we argue as follows. Fix some  <span class="math">(a_1, \\dots, a_\\ell) \\in \\bigcap_{j=0}^{d-1} (\\partial_1^j \\vec{Q})^\\perp</span>  and let  <span class="math">T := \\sum_{k=1}^\\ell a_k Q_k</span> ; we have that  <span class="math">\\partial_1^j T \\equiv 0</span>  for all  <span class="math">j \\in \\{0, \\dots, d-1\\}</span> , by linearity. But  <span class="math">T = \\sum_{j=0}^{d-1} (\\partial_1^j T) X_1^j</span>  by definition, so  <span class="math">T \\equiv 0</span> , and thus  <span class="math">(a_1, \\dots, a_\\ell) \\in \\vec{Q}^\\perp</span> .</p>

    <p class="text-gray-300">Thus to compute a basis of  <span class="math">\\vec{Q}^{\\perp}</span>  it suffices to compute the intersection of the bases of  <span class="math">(\\partial_1^j \\vec{Q})^{\\perp}</span>  for all  <span class="math">j \\in \\{0, \\dots, d-1\\}</span> . The naive approach yields an exponential-time algorithm since we reduce the problem to d subproblems of roughly the same size. Observe, however, that for  <span class="math">Q_k</span>  of the specified form,</p>

    <p class="text-gray-300"><span class="math">$\\partial_1^j Q_k = c_{k,j} T_k \\quad \\text{ where } T_k := \\left(\\prod_{i=2}^m Q_{k,i}(X_i)\\right) \\;\\;,</span>$</p>

    <p class="text-gray-300">for constants  <span class="math">c_{k,j}</span>  computable in time  <span class="math">\\operatorname{poly}(s)</span> . Let  <span class="math">\\vec{T}:=(T_1,\\ldots,T_\\ell)</span>  and let  <span class="math">T^\\perp\\in\\mathbb{F}^{\\ell\\times b}</span>  be a basis for  <span class="math">\\vec{T}^\\perp</span> ; note that  <span class="math">b\\leq \\ell</span> . Let  <span class="math">\\vec{a}:=(a_1,\\ldots,a_\\ell)\\in\\mathbb{F}^\\ell</span> , and observe that for each  <span class="math">j,\\sum_{k=1}^\\ell a_k\\partial_1^jQ_k\\equiv 0</span>  if and only if  <span class="math">\\sum_{k=1}^\\ell a_kc_{k,j}T_k\\equiv 0</span> , or equivalently,  <span class="math">(a_1c_{1,j},\\ldots,a_\\ell c_{\\ell,j})\\in\\vec{T}^\\perp</span> . Hence  <span class="math">(a_1,\\ldots,a_\\ell)\\in\\bigcap_{j=0}^d(\\partial_1^j\\vec{Q})^\\perp</span>  if and only if for each j there exists  <span class="math">\\vec{v_j}\\in\\mathbb{F}^b</span>  such that  <span class="math">T^\\perp\\vec{v_j}=(a_1c_{1,j},\\ldots,a_\\ell c_{\\ell,j})</span> . This is a system of linear equations in  <span class="math">\\vec{a},\\vec{v_0},\\ldots,\\vec{v_{d-1}}</span>  of size  <span class="math">\\operatorname{poly}(\\ell+d+b)</span> , and hence we can compute a basis for its solution space in time  <span class="math">\\operatorname{poly}(\\log|\\mathbb{F}|+d+\\ell+b)</span> . Restricting this basis to  <span class="math">\\vec{a}</span>  yields a basis for  <span class="math">\\vec{Q}^\\perp</span> .</p>

    <p class="text-gray-300">If  <span class="math">Q_1,\\ldots,Q_n</span>  are univariate then we can easily determine a basis for  <span class="math">\\vec{Q}^\\perp</span>  in deterministic polynomial time (by Gaussian elimination). Otherwise, if the  <span class="math">Q_i</span>  are m-variate, we use the procedure above to reduce computing  <span class="math">\\vec{Q}^\\perp</span>  to computing  <span class="math">\\vec{T}^\\perp</span>  for some  <span class="math">\\vec{T}=(T_1,\\ldots,T_\\ell)</span>  where the  <span class="math">T_i</span>  are (m-1)-variate. This algorithm terminates in time poly( <span class="math">\\log |\\mathbb{F}| + m + d + s + \\ell</span> ).</p>

    </section>

    <section id="app-e" class="mb-10">
      <h2 class="text-2xl font-bold">E Proof of Claim 4.23</h2>

    <p class="text-gray-300">First we show that  <span class="math">\\operatorname{span}(\\cup_{j\\in J} \\tilde{C}_j^\\perp)\\subseteq (C^\\perp)_{\\subseteq \\left(\\cup_{j\\in J} \\tilde{D}_j\\right)}</span> . For every  <span class="math">j\\in J</span>  and  <span class="math">z\\in \\tilde{C}_j^\\perp</span> , it holds that  <span class="math">\\operatorname{supp}(z)\\subseteq \\tilde{D}_j</span> ; therefore, for every  <span class="math">z\\in \\operatorname{span}(\\cup_{j\\in J} \\tilde{C}_j^\\perp)</span> , it holds that  <span class="math">\\operatorname{supp}(z)\\subseteq \\cup_{j\\in J} \\tilde{D}_j</span> ; thus it is suffices to show that, for every  <span class="math">z\\in \\cup_{j\\in J} \\tilde{C}_j^\\perp</span>  and  <span class="math">w\\in C</span> , it holds that  <span class="math">\\langle w,z\\rangle=0</span> . But this holds because for every  <span class="math">z\\in \\cup_{j\\in J} \\tilde{C}_j^\\perp</span>  there exists  <span class="math">j\\in J</span>  such that  <span class="math">z\\in \\tilde{C}_j^\\perp</span>  and  <span class="math">C|_{\\tilde{D}_j}=\\tilde{C}_j</span>  so that  <span class="math">\\langle w,z\\rangle=\\langle w|_{\\tilde{D}_j},z\\rangle=0</span> , as required.</p>

    <p class="text-gray-300">Next we show that  <span class="math">\\operatorname{span}(\\cup_{j\\in J}\\tilde{C}_j^\\perp)\\supseteq (C^\\perp)_{\\subseteq \\left(\\cup_{j\\in J}\\tilde{D}_j\\right)}</span> , which is equivalent to  <span class="math">\\operatorname{span}(\\cup_{j\\in J}\\tilde{C}_j^\\perp)\\supseteq (C|_{\\cup_{j\\in J}\\tilde{D}_j})^\\perp</span>  by Claim 4.5. Recall that for any two linear spaces U,V it holds that  <span class="math">U\\subseteq V</span>  if and only if  <span class="math">U^\\perp\\supseteq V^\\perp</span> , thus it is sufficient to show that  <span class="math">\\operatorname{span}(\\cup_{j\\in J}\\tilde{C}_j^\\perp)^\\perp\\subseteq C|_{\\cup_{j\\in J}\\tilde{D}_j}</span> , i.e., that every  <span class="math">w\\in\\operatorname{span}(\\cup_{j\\in J}\\tilde{C}_j^\\perp)^\\perp</span>  can be extended to  <span class="math">w&#x27;\\in C</span> . This latter statement holds because  <span class="math">\\operatorname{span}(\\cup_{j\\in J}\\tilde{C}_j^\\perp)^\\perp|_{\\tilde{D}_j}\\subseteq (\\tilde{C}_j^\\perp)^\\perp=\\tilde{C}_j</span>  for every  <span class="math">j\\in J</span> , and thus  <span class="math">w|_{\\tilde{D}_j}\\in \\tilde{C}_j</span> . Recalling  <span class="math">|J|\\le\\kappa</span>  implies, by Definition 4.15, that w can be extended to a codeword  <span class="math">w&#x27;\\in C</span> , as claimed.</p>

    <p class="text-gray-300">In this section we define the linear code family BS-RS, which consists of evaluations of univariate polynomials concatenated with corresponding BS proximity proofs <a href="#page-57-0">[BS08]</a>. The definition is quite technical, and we refer the interested reader to <a href="#page-57-0">[BS08]</a> for a discussion of why it enables proximity testing. We begin with notation used later.</p>

    <p class="text-gray-300">Definition F.1. <em>Given a field</em> F<em>, a subfield</em> K &sube; F<em>, a</em> K<em>-linear space</em> L &sube; F <em>with a basis</em> (b1, b2, . . . , b\`)<em>, a positive integer</em> &micro;<em>, and a positive integer</em> k &gt; 2&micro;<em>, we make the following definitions.</em></p>

    <p class="text-gray-300">&bull; <em>Four subspaces of</em> L <em>and a subset of</em> L<em>:</em></p>

    <p class="text-gray-300"><span class="math">$L_0[\\mathbb{K}, \\mathbb{F}, L, \\mu] := \\operatorname{span}_{\\mathbb{K}}(b_1, b_2, \\dots, b_{\\lfloor \\ell/2 \\rfloor})</span>$</p>

    <p class="text-gray-300"><span class="math">$L&#x27;_0[\\mathbb{K}, \\mathbb{F}, L, \\mu] := \\operatorname{span}_{\\mathbb{K}}(b_1, b_2, \\dots, b_{\\lfloor \\ell/2 \\rfloor + \\mu - 1})</span>$</p>

    <p class="text-gray-300"><span class="math">$L_1[\\mathbb{K}, \\mathbb{F}, L, \\mu] := \\operatorname{span}_{\\mathbb{K}}(b_{\\lfloor \\ell/2 \\rfloor + 1}, \\dots, b_{\\ell})</span>$</p>

    <p class="text-gray-300"><span class="math">$\\forall \\beta \\in L_1[\\mathbb{K}, \\mathbb{F}, L, \\mu] , L_{\\beta}[\\mathbb{K}, \\mathbb{F}, L, \\mu] := \\operatorname{span}_{\\mathbb{K}}(b_1, b_2, \\dots, b_{\\lfloor \\ell/2 \\rfloor + \\mu - 1}, \\beta&#x27;)</span>$</p>

    <p class="text-gray-300"><span class="math">$\\forall \\beta \\in L_1[\\mathbb{K}, \\mathbb{F}, L, \\mu] , R_{\\beta}[\\mathbb{K}, \\mathbb{F}, L, \\mu] := L_{\\beta} \\setminus (L_0 + \\beta)</span>$</p>

    <p class="text-gray-300"><em>where</em> &beta; 0 := bb\`/2c+<sup>&micro;</sup> <em>if</em> &beta; &isin; L 0 <sup>0</sup> <em>and</em> &beta; 0 := &beta; <em>otherwise.</em></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><em>The vanishing polynomial of</em> L0<em>:</em> ZL<sup>0</sup> <a href="X">K, F, L, &micro;</a> := Q &alpha;&isin;L<sup>0</sup> (X &minus; &alpha;)<em>.</em></li>
      <li><em>The following domains:</em></li>
    </ul>

    <p class="text-gray-300"><span class="math">$\\begin{split} &amp;D_{\\mathrm{bi}}[\\mathbb{K}, \\mathbb{F}, L, \\mu] := \\{ (\\alpha, Z_{L_0}(\\beta)) : \\beta \\in L_1, \\alpha \\in L_\\beta \\} \\\\ &amp;D_{\\mathrm{pf}}[\\mathbb{K}, \\mathbb{F}, L, \\mu] := \\{ (\\alpha, Z_{L_0}(\\beta)) : \\beta \\in L_1, \\alpha \\in R_\\beta \\} \\\\ &amp;D_{\\square}[\\mathbb{K}, \\mathbb{F}, L, \\mu] := (\\{ \\mathrm{rs} \\} \\times L) \\sqcup (\\{ \\mathrm{px} \\} \\times D_{\\mathrm{pf}}) \\end{split}</span>$</p>

    <p class="text-gray-300"><em>where we use the symbols '</em>rs<em>' and '</em>px<em>' to distinguish different parts of the disjoint union.</em></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><em>The bijection</em> <sup>&phi;</sup>[K, <sup>F</sup>, L, &micro;]: <sup>D</sup>bi <sup>&rarr;</sup> <sup>D</sup> <em>is defined by</em> <sup>&phi;</sup>(&alpha;, &beta;) := ( (px,(&alpha;, &beta;)) (&alpha;, &beta;) &isin; Dpf (rs, &alpha;) <em>otherwise .</em></li>
      <li><em>Given</em> w &isin; F D[K,F,L,&micro;] <em>, the bivariate function</em> f<sup>w</sup> : Dbi[K, F, L, &micro;] &rarr; F <em>is defined by</em> fw(&alpha;, &beta;) := w(&phi;(&alpha;, &beta;))<em>.</em></li>
      <li><em>The fractional degree</em> &rho;[K, F, &micro;] := |K| <sup>&minus;</sup>&micro;<em>.</em></li>
      <li><em>The domain</em> DBS<em>-</em>RS px [K, F, L, &micro;, k] <em>implied by the recursion below:</em>    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><em>if</em> dim(L) &le; k <em>then</em> DBS<em>-</em>RS px [K, F, L, &micro;, k] := Dpf[K, F, L, &micro;]<em>;</em></li>
      <li><em>if</em> dim(L) &gt; k <em>then</em></li>
    </ul></li>
    </ul>

    <p class="text-gray-300"><span class="math">$D_{\\mathrm{px}}^{\\mathrm{BS-RS}}[\\mathbb{K}, \\mathbb{F}, L, \\mu, k] := D_{\\mathrm{pf}}[\\mathbb{K}, \\mathbb{F}, L, \\mu] \\bigsqcup \\Big( \\sqcup_{\\alpha \\in L_0&#x27;} \\{(\\mathrm{col}, \\alpha)\\} \\times D_{\\mathrm{px}}^{\\mathrm{BS-RS}}[\\mathbb{K}, \\mathbb{F}, Z_{L_0}(L_1), \\mu, k] \\Big)</span>$</p>

    <p class="text-gray-300"><span class="math">$\\bigsqcup \\Big( \\sqcup_{\\beta \\in L_1} \\{(\\mathrm{row}, \\beta)\\} \\times D_{\\mathrm{px}}^{\\mathrm{BS-RS}}[\\mathbb{K}, \\mathbb{F}, L_{\\beta}, \\mu, k] \\Big) .</span>$</p>

    <p class="text-gray-300"><em>where we use the symbols '</em>col<em>' and '</em>row<em>' to distinguish different parts of the disjoint union.</em></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><em>The domain</em> DBS<em>-</em>RS[K, F, L, &micro;, k] := ({rs} &times; L) t {px} &times; DBS<em>-</em>RS px [K, F, L, &micro;, k] <em>.</em></li>
      <li><em>Given</em> &alpha; &isin; L 0 0 <em>, the embedding</em> &phi;col,&alpha; : DBS<em>-</em>RS[K, F, Z<sup>L</sup><sup>0</sup> (L1), &micro;, k] ,&rarr; DBS<em>-</em>RS[K, F, L, &micro;, k] <em>is defined by</em></li>
    </ul>

    <p class="text-gray-300"><span class="math">$\\phi_{\\operatorname{col},\\alpha}(x) := \\begin{cases} (\\operatorname{px}, ((\\operatorname{col},\\alpha), x)) &amp; x \\in \\{\\operatorname{px}\\} \\times D_{\\operatorname{px}}^{\\operatorname{BS-RS}}[\\mathbb{K}, \\mathbb{F}, Z_{L_0}(L_1), \\mu, k] \\\\ \\phi(\\alpha, \\beta) &amp; x = (\\{\\operatorname{rs}\\}, Z_{L_0}(\\beta)) \\end{cases}</span>$</p>

    <p class="text-gray-300"><em>We denote by</em> Dcol,&alpha; <em>the image of</em> &phi;col,&alpha;<em>.</em></p>

    <p class="text-gray-300">&bull; Given  <span class="math">\\beta \\in L_1</span> , the embedding  <span class="math">\\phi_{row,\\beta} \\colon D^{BS-RS}[\\mathbb{K}, \\mathbb{F}, L_{\\beta}, \\mu, k] \\hookrightarrow D^{BS-RS}[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  is defined by</p>

    <p class="text-gray-300"><span class="math">$\\phi_{\\text{row},\\beta}(x) := \\begin{cases} (\\text{px}, ((\\text{row}, \\beta), x)) &amp; x \\in \\{\\text{px}\\} \\times D_{\\text{px}}^{\\text{BS-RS}}[\\mathbb{K}, \\mathbb{F}, L_{\\beta}, \\mu, k] \\\\ \\phi(\\alpha, \\beta) &amp; x = (\\{\\text{rs}\\}, \\alpha) \\end{cases}</span>$</p>

    <p class="text-gray-300">We denote by  <span class="math">D_{\\text{row},\\beta}</span>  the image of  <span class="math">\\phi_{\\text{row},\\beta}</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Given  <span class="math">\\alpha \\in L_0&#x27;</span> ,  <span class="math">\\psi_{\\operatorname{col},\\alpha} \\colon \\mathbb{F}^{D^{\\operatorname{BS-RS}}[\\mathbb{K},\\mathbb{F},L,\\mu,k]} \\to \\mathbb{F}^{D^{\\operatorname{BS-RS}}[\\mathbb{K},\\mathbb{F},Z_{L_0}(L_1),\\mu,k]}</span>  is the projection of  <span class="math">D^{\\operatorname{BS-RS}}[\\mathbb{K},\\mathbb{F},L,\\mu,k]</span>  on  <span class="math">D_{\\operatorname{col},\\alpha}</span>  with indices renamed to elements of  <span class="math">D^{\\operatorname{BS-RS}}[\\mathbb{K},\\mathbb{F},Z_{L_0}(L_1),\\mu,k]</span> . Formally,  <span class="math">\\psi_{\\operatorname{col},\\alpha}(w) = w&#x27;</span>  if and only if  <span class="math">w&#x27;(\\phi_{\\operatorname{col},\\alpha}(x)) = w(x)</span>  for all  <span class="math">x \\in D^{\\operatorname{BS-RS}}[\\mathbb{K},\\mathbb{F},Z_{L_0}(L_1),\\mu,k]</span> .</li>
      <li>Given  <span class="math">\\beta \\in L_1</span> ,  <span class="math">\\psi_{\\text{row},\\beta} \\colon \\mathbb{F}^{D^{\\text{BS-RS}}[\\mathbb{K},\\mathbb{F},L,\\mu,k]} \\to \\mathbb{F}^{D^{\\text{BS-RS}}[\\mathbb{K},\\mathbb{F},L_{\\beta},\\mu,k]}</span>  is the projection of  <span class="math">D^{\\text{BS-RS}}[\\mathbb{K},\\mathbb{F},L,\\mu,k]</span>  on  <span class="math">D_{\\text{row},\\beta}</span>  with indices renamed to elements of  <span class="math">D^{\\text{BS-RS}}[\\mathbb{K},\\mathbb{F},L_{\\beta},\\mu,k]</span> . Formally,  <span class="math">\\psi_{\\text{row},\\beta}(w) = w&#x27;</span>  if and only if  <span class="math">w&#x27;(\\phi_{\\text{row},\\beta}(x)) = w(x)</span>  for all  <span class="math">x \\in D^{\\text{BS-RS}}[\\mathbb{K},\\mathbb{F},L_{\\beta},\\mu,k]</span> .</li>
    </ul>

    <p class="text-gray-300">The following definition considers a code that extends the evaluation of a univariate polynomial with a bivariate function that represents the polynomial over a specially-chosen set.</p>

    <p class="text-gray-300"><strong>Definition F.2</strong> (RS <span class="math">_{\\square}</span> ). Given a field  <span class="math">\\mathbb{F}</span> , a subfield  <span class="math">\\mathbb{K} \\subseteq \\mathbb{F}</span> , a  <span class="math">\\mathbb{K}</span> -linear space  <span class="math">L \\subseteq \\mathbb{F}</span> , and a positive integer  <span class="math">\\mu</span> , the code RS <span class="math">_{\\square}[\\mathbb{K},\\mathbb{F},L,\\mu]</span>  consists of all  <span class="math">w \\in \\mathbb{F}^{D_{\\square}[\\mathbb{K},\\mathbb{F},L,\\mu]}</span>  such that  <span class="math">f_w \\colon D_{\\mathrm{bi}} \\to \\mathbb{F}</span>  is an evaluation of a low degree polynomial: there exists a polynomial  <span class="math">g \\in \\mathbb{F}[X,Y]</span>  such that: (i)  <span class="math">\\deg_X(g) &lt; |L_0|</span> , (ii)  <span class="math">\\deg_Y(g) &lt; |L_1| \\cdot \\rho[\\mathbb{K},\\mathbb{F},\\mu]</span> , (iii)  <span class="math">g|_{D_{\\mathrm{bi}}} = f_w</span> .</p>

    <p class="text-gray-300">Ben-Sasson and Sudhan [BS08] show that:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">v \\in \\mathrm{RS}[\\mathbb{F}, L, |L| \\cdot \\rho]</span>  if and only if there exists  <span class="math">w \\in \\mathrm{RS}_{\\square}[\\mathbb{K}, \\mathbb{F}, L, \\mu]</span>  such that  <span class="math">w|_{\\{\\mathrm{rs}\\} \\times L} = v</span> ;</li>
      <li><span class="math">w \\in \\mathrm{RS}_{\\square}[\\mathbb{K}, \\mathbb{F}, L, \\mu]</span>  if and only if    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>for every  <span class="math">\\alpha \\in L&#x27;_0</span> ,  <span class="math">f_w|_{\\{\\alpha\\} \\times Z_{L_0}(L_1)} \\in \\mathrm{RS}[\\mathbb{F}, Z_{L_0}(L_1), |L_1| \\cdot \\rho]</span>  (with the standard mapping between domains) and for every  <span class="math">\\beta \\in L_1</span> ,  <span class="math">f_w|_{L_\\beta \\times \\{Z_{L_0}(\\beta)\\}} \\in \\mathrm{RS}[\\mathbb{F}, L_\\beta, |L_0|]</span>  (with the standard mapping between domains).</li>
    </ul></li>
    </ul>

    <p class="text-gray-300">The above equivalences illustrate the 'quadratic reduction' from testing that  <span class="math">w \\in \\mathbb{F}^L</span>  is a codeword of  <span class="math">\\mathrm{RS}[\\mathbb{F}, L, |L| \\cdot \\rho]</span>  to a set of  <span class="math">\\Theta(\\sqrt{|L|})</span>  problems of testing membership in codes of the form  <span class="math">\\mathrm{RS}[\\mathbb{F}, L&#x27;, d&#x27;]</span>  with  <span class="math">|L&#x27;|, d&#x27; = \\Theta(\\sqrt{|L|})</span> .</p>

    <p class="text-gray-300">The code from Definition F.2 corresponds to one step of the recursive construction of [BS08]. We now build on that definition, and recursively define the linear code family BS-RS.</p>

    <p class="text-gray-300"><strong>Definition F.3</strong> (BS-RS). Given a field  <span class="math">\\mathbb{F}</span> , a subfield  <span class="math">\\mathbb{K} \\subseteq \\mathbb{F}</span> , a  <span class="math">\\mathbb{K}</span> -linear space  <span class="math">L \\subseteq \\mathbb{F}</span> , a positive integer  <span class="math">\\mu</span> , and a positive integer  <span class="math">k &gt; 2\\mu</span> , the code BS-RS[ <span class="math">\\mathbb{K}, \\mathbb{F}, L, \\mu, k</span> ] consists of all words  <span class="math">w \\in \\mathbb{F}^{D^{\\mathrm{BS-RS}}[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]}</span>  satisfying the following. If  <span class="math">\\dim(L) \\leq k</span>  then  <span class="math">w \\in \\mathrm{RS}_{\\square}[\\mathbb{K}, \\mathbb{F}, L, \\mu]</span> . If  <span class="math">\\dim(L) &gt; k</span>  the following holds: (1) for every  <span class="math">\\alpha \\in L&#x27;_0</span>  there exists  <span class="math">w_\\alpha \\in \\mathrm{BS-RS}[\\mathbb{K}, \\mathbb{F}, Z_{L_0}(L_1), \\mu, k]</span>  such that  <span class="math">w_\\alpha(\\phi_{\\mathrm{col},\\alpha}(x)) = w(x)</span>  for every  <span class="math">x \\in D[\\mathbb{K}, \\mathbb{F}, Z_{L_0}(L_1), \\mu, k]</span> ; (2) for every  <span class="math">\\beta \\in L_1</span>  there exists  <span class="math">w_\\beta \\in \\mathrm{BS-RS}[\\mathbb{K}, \\mathbb{F}, L_\\beta, \\mu, k]</span>  such that  <span class="math">w_\\beta(\\phi_{\\mathrm{row},\\beta}(x)) = w(x)</span>  for every  <span class="math">x \\in D[\\mathbb{K}, \\mathbb{F}, L_\\beta, \\mu, k]</span> .</p>

    <p class="text-gray-300">We conclude this section with two claims about BS-RS that we use in later sections. We omit the proof of the first claim (and refer the interested reader to [BS08]), and prove the second claim based on the first one.</p>

    <p class="text-gray-300"><strong>Claim F.4.</strong> For every codeword  <span class="math">w \\in RS[\\mathbb{F}, L, |L| \\cdot \\rho]</span> , positive integer  <span class="math">\\mu</span> , and positive integer  <span class="math">k &gt; 2\\mu</span> , there exists a unique  <span class="math">\\pi_w</span>  such that  <span class="math">w \\circ \\pi_w \\in BS-RS[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span> .</p>

    <p class="text-gray-300"><strong>Claim F.5.</strong> The following two statements hold for the code BS-RS[ <span class="math">\\mathbb{K}</span> ,  <span class="math">\\mathbb{F}</span> , L,  <span class="math">\\mu</span> , k]:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>for every  <span class="math">\\alpha \\in L&#x27;_0</span>  and  <span class="math">w&#x27; \\in BS-RS[\\mathbb{K}, \\mathbb{F}, Z_{L_0}(L_1), \\mu, k]</span>  there exists  <span class="math">w \\in BS-RS[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  such that  <span class="math">\\psi_{\\operatorname{col}, \\alpha}(w) = w&#x27;</span> ;</li>
      <li>for every  <span class="math">\\beta \\in L_1</span>  and  <span class="math">w&#x27; \\in BS-RS[\\mathbb{K}, \\mathbb{F}, L_{\\beta}, \\mu, k]</span>  there exists  <span class="math">w \\in BS-RS[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  such that  <span class="math">\\psi_{row, \\beta}(w) = w&#x27;</span> .</li>
    </ul>

    <p class="text-gray-300"><em>Proof.</em> The proofs for the two statements are similar, so we only give the proof for the first statement. Let  <span class="math">w&#x27; \\in BS\\text{-RS}[\\mathbb{K}, \\mathbb{F}, Z_{L_0}(L_1), \\mu, k]</span> , and define  <span class="math">w_{rs} := w&#x27;|_{\\{rs\\} \\times Z_{L_0}(L_1)}</span> ; observe that  <span class="math">w_{rs}</span>  in  <span class="math">RS[\\mathbb{F}, Z_{L_0}(L_1), |L_1| \\cdot \\rho]</span> . By Claim F.4, w' is uniquely determined by  <span class="math">w_{rs}</span> , thus it suffices to show that there exists  <span class="math">w_{\\square} \\in RS_{\\square}[\\mathbb{K}, \\mathbb{F}, L, \\mu]</span>  such that  <span class="math">f_{w_{\\square}}|_{\\{\\alpha\\} \\times Z_{L_0}(L_1)} = w_{rs}</span> . By definition of  <span class="math">RS_{\\square}</span> , it suffices to show that there exists a bivariate polynomial  <span class="math">g \\in \\mathbb{F}[X,Y]</span>  such that: (i)  <span class="math">\\deg_X(g) &lt; |L_0|</span> , (ii)  <span class="math">\\deg_Y(g) &lt; |L_1| \\cdot \\rho</span> , (iii)  <span class="math">g|_{\\{\\alpha\\} \\times Z_{L_0}(L_1)} = w_{rs} \\in RS[\\mathbb{F}, Z_{L_0}(L_1), |L_1| \\cdot \\rho]</span> . The existence of such g follows by considering a suitable interpolating set (see, e.g., Appendix H).</p>

    <h4 id="sec-misc-8" class="text-lg font-semibold mt-6"><strong>Proof of Lemma 4.27</strong> G</h4>

    <p class="text-gray-300">In this section we prove Lemma 4.27. In Appendix G.1 we define the recursive cover and prove its combinatorial properties; in Appendix G.2 we prove that a spanning set for the duals of codes in this cover can be computed efficiently; in Appendix G.3, we put these together to conclude the proof.</p>

    <h4 id="sec-misc-9" class="text-lg font-semibold mt-6">The recursive cover and its combinatorial properties</h4>

    <p class="text-gray-300">We define a recursive cover for BS-RS and then prove certain combinatorial properties for it. The definition relies on the definition of another cover, which we now introduce.</p>

    <p class="text-gray-300"><strong>Definition G.1.</strong> The native cover  <span class="math">S[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  of BS-RS <span class="math">[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  is defined as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>if  <span class="math">\\dim(L) \\le k</span>  then the cover contains only the trivial view  <span class="math">(D^{\\mathrm{BS-RS}}[\\mathbb{K}, \\mathbb{F}, L, \\mu, k], \\mathrm{BS-RS}[\\mathbb{K}, \\mathbb{F}, L, \\mu, k])</span> ;</li>
      <li>if  <span class="math">\\dim(L) &gt; k</span>  then the cover contains    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>the view (BS-RS[K, F,  <span class="math">Z_{L_0}(L_1), \\mu, k], D_{\\text{col},\\alpha}</span> ) for every  <span class="math">\\alpha \\in L&#x27;_0</span> , and</li>
      <li>the view (BS-RS[K, F,  <span class="math">L_{\\beta}</span> ,  <span class="math">\\mu</span> , k],  <span class="math">D_{\\text{row},\\beta}</span> ) for every  <span class="math">\\beta \\in L_1</span> .</li>
    </ul></li>
    </ul>

    <p class="text-gray-300">We now prove that the native cover is indeed a cover.</p>

    <p class="text-gray-300"><strong>Claim G.2.</strong> The native cover of BS-RS[ <span class="math">\\mathbb{K}</span> ,  <span class="math">\\mathbb{F}</span> , L,  <span class="math">\\mu</span> , k] is a code cover (see Definition 4.13).</p>

    <p class="text-gray-300"><em>Proof.</em> From Claim F.5 we know that:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>for every  <span class="math">\\alpha \\in L&#x27;_0</span> , the restriction of BS-RS[ <span class="math">\\mathbb{K}, \\mathbb{F}, L, \\mu, k</span> ] to  <span class="math">D_{\\text{col},\\alpha}</span>  equals BS-RS[ <span class="math">\\mathbb{K}, \\mathbb{F}, Z_{L_0}(L_1), \\mu, k</span> ];</li>
      <li>for every  <span class="math">\\beta \\in L_1</span> , the restriction of BS-RS[ <span class="math">\\mathbb{K}, \\mathbb{F}, L, \\mu, k</span> ] to  <span class="math">D_{\\text{row},\\beta}</span>  equals BS-RS[ <span class="math">\\mathbb{K}, \\mathbb{F}, L_{\\beta}, \\mu, k</span> ].</li>
    </ul>

    <p class="text-gray-300">Therefore, it suffices to show that  <span class="math">D_{\\square} \\subseteq (\\bigcup_{\\alpha \\in L&#x27;_0} D_{\\operatorname{col},\\alpha}) \\cup (\\bigcup_{\\beta \\in L_1} D_{\\operatorname{row},\\beta})</span> . So let x be an index in  <span class="math">D_{\\square}</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>If there exists  <span class="math">\\alpha \\in L_0&#x27;</span>  such that  <span class="math">x \\in \\{\\text{px}\\} \\times \\{(\\text{col}, \\alpha)\\} \\times D_{\\text{pf}}^{\\text{BS-RS}}[\\mathbb{K}, \\mathbb{F}, Z_{L_0}(L_1), \\mu, k]</span> , then  <span class="math">x \\in D_{\\text{col}, \\alpha}</span> .
If there exists  <span class="math">\\beta \\in L_1</span>  such that  <span class="math">x \\in \\{\\text{px}\\} \\times \\{(\\text{row}, \\beta)\\} \\times D_{\\text{pf}}^{\\text{BS-RS}}[\\mathbb{K}, \\mathbb{F}, L_{\\beta}, \\mu, k]</span> , then  <span class="math">x \\in D_{\\text{row}, \\beta}</span> .
If  <span class="math">x \\in \\{\\text{px}\\} \\times D_{\\text{pf}}[\\mathbb{K}, \\mathbb{F}, L_{\\beta}, \\mu, k]</span> , then  <span class="math">x \\in D_{\\text{row}, \\beta}</span> .</li>
      <li>If  <span class="math">x \\in \\{px\\} \\times D_{pf}[\\mathbb{K}, \\mathbb{F}, L, \\mu]</span> , then there exist  <span class="math">\\beta \\in L_1</span>  and  <span class="math">\\alpha \\in R_\\beta</span>  such that  <span class="math">x = (px, (\\alpha, Z_{L_0}(\\beta)))</span> , so  <span class="math">x \\in D_{row, \\beta}</span> .</li>
      <li>If  <span class="math">x \\in \\{rs\\} \\times L</span> , then there exist  <span class="math">\\beta \\in L_1</span>  and  <span class="math">\\alpha \\in L_\\beta</span>  such that  <span class="math">\\phi[\\mathbb{K}, \\mathbb{F}, L, \\mu](\\alpha, Z_{L_0}(\\beta)) = x</span> , so  <span class="math">x \\in D_{row, \\beta}</span> .  <span class="math">\\square</span></li>
    </ul>

    <p class="text-gray-300">The recursive cover of BS-RS is recursively defined based on the native cover of BS-RS.</p>

    <p class="text-gray-300"><strong>Definition G.3.</strong> The recursive cover  <span class="math">T[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  of BS-RS <span class="math">[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  is the tree of depth  <span class="math">|\\log \\dim(L) - \\log(k)|</span> where, for every non-leaf vertex v labeled by  <span class="math">(D, BS-RS[\\mathbb{K}, \\mathbb{F}, L, \\mu, k])</span> , the vertex v has  <span class="math">|S[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]|</span>  successors, all labeled by elements of  <span class="math">S[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  with the natural embedding of their domains into D.</p>

    <p class="text-gray-300"><strong>Claim G.4.</strong> The recursive cover of BS-RS[ <span class="math">\\mathbb{K}</span> ,  <span class="math">\\mathbb{F}</span> , L,  <span class="math">\\mu</span> , k] is 1-intersecting (see Definition 4.18).</p>

    <p class="text-gray-300"><em>Proof.</em> We must show that for every two disconnected vertices u, v it holds that  <span class="math">|\\tilde{D}_u \\cap \\tilde{D}_v| \\leq 1</span> . It suffices to do so for every two distinct siblings u, v, because if a is an ancestor of b then  <span class="math">\\tilde{D}_a</span>  contains  <span class="math">\\tilde{D}_b</span> . Hence, we only need to show that for every two distinct views  <span class="math">(\\tilde{D}, \\tilde{C}), (\\tilde{D}&#x27;, \\tilde{C}&#x27;)</span>  in the native cover  <span class="math">S[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span> , it holds that  <span class="math">|\\tilde{D} \\cap \\tilde{D}&#x27;| \\leq 1</span> . First we observe that for every  <span class="math">\\alpha_1 \\neq \\alpha_2 \\in L&#x27;_0</span>  and  <span class="math">\\beta_1 \\neq \\beta_2 \\in L_1</span> , the following sets are disjoint by definition:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\{\\text{px}\\} \\times \\{(\\text{col}, \\alpha_1)\\} \\times D_{\\text{pf}}^{\\text{BS-RS}}[\\mathbb{K}, \\mathbb{F}, Z_{L_0}(L_1), \\mu, k],</span></li>
      <li><span class="math">\\{\\operatorname{px}\\} \\times \\{(\\operatorname{col}, \\alpha_2)\\} \\times D_{\\operatorname{pf}}^{\\operatorname{BS-RS}}[\\mathbb{K}, \\mathbb{F}, Z_{L_0}(L_1), \\mu, k],</span>   <span class="math">\\{\\operatorname{px}\\} \\times \\{(\\operatorname{row}, \\beta_1)\\} \\times D_{\\operatorname{pf}}^{\\operatorname{BS-RS}}[\\mathbb{K}, \\mathbb{F}, L_{\\beta_1}, \\mu, k],</span></li>
      <li><span class="math">\\{px\\} \\times \\{(row, \\beta_2)\\} \\times D_{pf}^{BS-RS}[\\mathbb{K}, \\mathbb{F}, L_{\\beta_2}, \\mu, k].</span></li>
    </ul>

    <p class="text-gray-300">Thus it is enough to show that:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Any two columns are distinct:  <span class="math">\\phi(\\alpha_1, \\beta_1) \\neq \\phi(\\alpha_2, \\beta_2)</span>  for every  <span class="math">\\alpha_1 \\neq \\alpha_2 \\in L&#x27;_0</span>  and  <span class="math">\\beta_1, \\beta_2 \\in Z_{L_0}(L_1)</span> .</li>
      <li>Any two rows are distinct:  <span class="math">\\phi(\\alpha_1, \\beta_1) \\neq \\phi(\\alpha_2, \\beta_2)</span>  for every  <span class="math">\\beta_1 \\neq \\beta_2 \\in Z_{L_0}(L_1)</span> ,  <span class="math">\\alpha_1 \\in L_{\\beta_1}</span> , and  <span class="math">\\alpha_2 \\in L_{\\beta_2}</span> .</li>
      <li>The intersection of any row and column has at most one element:  <span class="math">\\phi(\\alpha, \\beta&#x27;) \\neq \\phi(\\alpha&#x27;, \\beta)</span>  for every  <span class="math">\\alpha, \\alpha&#x27; \\in L&#x27;_0</span>  and  <span class="math">\\beta, \\beta&#x27; \\in Z_{L_0}(L_1)</span>  with  <span class="math">(\\alpha&#x27;, \\beta&#x27;) \\neq (\\alpha, \\beta)</span> .</li>
    </ul>

    <p class="text-gray-300">But all the above follow from the fact that  <span class="math">\\phi[\\mathbb{K}, \\mathbb{F}, L, \\mu]</span>  is a bijection and, thus, an injection.</p>

    <p class="text-gray-300">The next claim establishes a connection between the depth of a vertex v in the recursive cover and the independence of the cover  <span class="math">T_v</span>  of the code  <span class="math">\\tilde{C}_v</span> .</p>

    <p class="text-gray-300">Claim G.5. For every vertex v in layer(T,d), the cover  <span class="math">T_v</span>  is  <span class="math">(|\\mathbb{K}|^{\\dim(L)\\cdot 2^{-d-1}-\\mu-2})</span> -independent. In particular, by assignment, it holds that, for every positive integer m and every non-leaf vertex v in  <span class="math">T[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  with depth less than  <span class="math">\\log_2 \\dim(L) - \\log_2(\\log_{|\\mathbb{K}|} m + \\mu + 2) - 1</span> , the cover  <span class="math">T_v</span>  is m-independent.</p>

    <p class="text-gray-300">The proof of the above claim directly follows from Claim G.7 and Claim G.6, stated and proved below. The first of these two claims connects the depth of a vertex v and the dimension of a space  <span class="math">L_v</span>  such that  <span class="math">\\tilde{C}_v = \\mathrm{BS-RS}[\\mathbb{F}, \\mathbb{K}, L_v, \\mu, k]</span>  (this claim is used separately also for establishing computational properties in Appendix G.2).</p>

    <p class="text-gray-300"><strong>Claim G.6.</strong> If  <span class="math">v \\in \\text{layer}(T[\\mathbb{K}, \\mathbb{F}, L, \\mu, k], d)</span>  then  <span class="math">\\tilde{C}_v = \\text{BS-RS}[\\mathbb{K}, \\mathbb{F}, \\tilde{L}, \\mu, k]</span>  for some  <span class="math">\\tilde{L}</span>  such that</p>

    <p class="text-gray-300"><span class="math">$\\dim(L) \\cdot 2^{-d} \\le \\dim(\\tilde{L}) \\le \\dim(L) \\cdot 2^{-d} + 2\\mu .</span>$</p>

    <p class="text-gray-300"><em>Proof.</em> The proof is by induction on d. The base case d=0 follows directly from the definition; so we now assume the claim for d-1 and prove it for d. Let  <span class="math">v\\in \\operatorname{layer}(T,d)</span>  be a vertex of depth d, and let  <span class="math">u\\in \\operatorname{layer}(T,d-1)</span>  be v's predecessor. By the inductive assumption,  <span class="math">\\tilde{C}_u=\\operatorname{BS-RS}[\\mathbb{K},\\mathbb{F},L_u,\\mu,k]</span>  for some  <span class="math">L_u</span>  such that  <span class="math">\\dim(L)\\cdot 2^{-(d-1)}\\leq \\dim(L_u)\\leq \\dim(L)\\cdot 2^{-(d-1)}+2\\mu</span> .</p>

    <p class="text-gray-300">First we argue that  <span class="math">T_u</span>  is not the trivial (singleton) cover. For this, it suffices to show that  <span class="math">\\dim(L_u) &gt; k</span> . But this follows from the inductive assumption, since  <span class="math">\\operatorname{depth}(T,u) &lt; \\lfloor \\log \\dim(L) - \\log(k) \\rfloor</span> , so that  <span class="math">\\dim(L_u) \\geq \\dim(L) \\cdot 2^{-(\\lfloor \\log \\dim(L) - \\log(k) \\rfloor - 1)} &gt; 2k</span> .</p>

    <p class="text-gray-300">Recall  <span class="math">\\tilde{C}_v = \\operatorname{BS-RS}[\\mathbb{K}, \\mathbb{F}, L_v, \\mu, k]</span>  for some space  <span class="math">L_v</span> ; we are thus left to show that  <span class="math">\\dim(L_u) \\cdot 2^{-1} \\leq \\dim(L_v) \\leq \\dim(L_u) \\cdot 2^{-1} + \\mu</span> . We do so by giving two cases, based on the form of  <span class="math">L_v</span> : (a) if  <span class="math">L_v = Z_{L_0[\\mathbb{K}, \\mathbb{F}, L_u, \\mu, k]}(L_1[\\mathbb{K}, \\mathbb{F}, L_u, \\mu, k])</span>  then  <span class="math">\\dim(L_v) = \\dim(L_1[\\mathbb{K}, \\mathbb{F}, L_u, \\mu, k]) = \\lceil \\frac{\\dim(L_u)}{2} \\rceil</span> ; (b) if there exists  <span class="math">\\beta \\in L_1[\\mathbb{K}, \\mathbb{F}, L_u, \\mu, k]</span>  such that  <span class="math">L_v = L_{\\beta}[\\mathbb{K}, \\mathbb{F}, L_u, \\mu, k]</span>  then  <span class="math">\\dim(L_v) = \\dim(L_0[\\mathbb{K}, \\mathbb{F}, L_u, \\mu, k]) + \\mu = \\lfloor \\frac{\\dim(L_u)}{2} \\rfloor + \\mu</span> . In either case  <span class="math">\\dim(L_u) \\cdot 2^{-1} \\leq \\dim(L_v) \\leq \\dim(L_v) \\cdot 2^{-1} + \\mu</span> , and the claim follows.</p>

    <p class="text-gray-300"><strong>Claim G.7.</strong> The native cover  <span class="math">S[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  is  <span class="math">|\\mathbb{K}|^{\\frac{\\dim(L)}{2} - \\mu - 2}</span> -independent.</p>

    <p class="text-gray-300"><em>Proof.</em> Recalling Definition 4.16, fix arbitrary subsets  <span class="math">D&#x27; \\subseteq (\\{\\text{col}\\} \\times L&#x27;_0) \\sqcup (\\{\\text{row}\\} \\times L_1)</span>  and  <span class="math">D&#x27;&#x27; \\subseteq D_{\\square}[\\mathbb{K}, \\mathbb{F}, L, \\mu]</span>  both of size at most  <span class="math">|\\mathbb{K}|^{\\frac{\\dim(L)}{2} - \\mu - 2}</span> , and define  <span class="math">\\tilde{D} := D&#x27;&#x27; \\cup (\\cup_{(\\text{col}, \\alpha) \\in D&#x27;} D_{\\text{col}, \\alpha}) \\cup (\\cup_{(\\text{row}, \\beta) \\in D&#x27;} D_{\\text{row}, \\beta})</span> . Let  <span class="math">w&#x27; \\in \\mathbb{F}^{D^{\\text{BS-RS}}}</span>  be such that: (i) for every  <span class="math">(\\text{col}, \\alpha) \\in D&#x27;</span>  it holds that  <span class="math">\\psi_{\\text{col}, \\alpha}(w&#x27;) \\in \\text{BS-RS}[\\mathbb{K}, \\mathbb{F}, Z_{L_0}(L_1), \\mu, k]</span> ; and (ii) for every  <span class="math">(\\text{row}, \\beta) \\in D&#x27;</span>  it holds that  <span class="math">\\psi_{\\text{row}, \\beta}(w&#x27;) \\in \\text{BS-RS}[\\mathbb{K}, \\mathbb{F}, L_{\\beta}, \\mu, k]</span> . We need to show that there exists  <span class="math">w \\in \\text{BS-RS}[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  such that  <span class="math">w|_{\\tilde{D}} = w&#x27;|_{\\tilde{D}}</span> .</p>

    <p class="text-gray-300">In fact, it suffices to show that there exists  <span class="math">w_{\\square} \\in \\mathrm{RS}_{\\square}[\\mathbb{K}, \\mathbb{F}, L, \\mu]</span>  such that  <span class="math">w_{\\square}|_{\\tilde{D} \\cap D_{\\square}} = w&#x27;|_{\\tilde{D} \\cap D_{\\square}}</span> , because Claim F.4 implies there exists a unique codeword  <span class="math">w \\in \\mathrm{BS-RS}[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  such that  <span class="math">w|_{D_{\\square}} = w_{\\square}</span>  and  <span class="math">w|_{\\tilde{D}} = w&#x27;|_{\\tilde{D}}</span> . Thus, we now argue that there exists  <span class="math">w_{\\square} \\in \\mathrm{RS}_{\\square}[\\mathbb{K}, \\mathbb{F}, L, \\mu]</span>  such that the following holds.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>For every  <span class="math">(\\operatorname{col}, \\alpha) \\in D&#x27;</span>  and  <span class="math">\\beta \\in Z_{L_0}(L_1)</span> , it holds that  <span class="math">f_{w_{\\square}}(\\alpha, \\beta) = w&#x27;(\\phi(\\alpha, \\beta)) = (\\psi_{\\operatorname{col}, \\alpha}(w&#x27;))</span>  (rs,  <span class="math">\\beta</span> ). In particular,  <span class="math">f_{w_{\\square}}|_{\\{\\alpha\\} \\times Z_{L_0}(L_1)} \\in \\operatorname{RS}[\\mathbb{F}, Z_{L_0}(L_1), |L_1| \\cdot \\rho]</span> , and let  <span class="math">p_{\\operatorname{col}, \\alpha}</span>  be its univariate low degree extension to  <span class="math">\\mathbb{F}</span> .</li>
      <li>For every  <span class="math">(\\text{row}, \\beta) \\in D&#x27;</span>  and  <span class="math">\\alpha \\in L_{\\beta}</span> , it holds that  <span class="math">f_{w_{\\square}}(\\alpha, Z_{L_0}(\\beta)) = w&#x27;(\\phi(\\alpha, Z_{L_0}(\\beta))) = (\\psi_{\\text{row},\\beta}(w&#x27;))</span>  (rs,  <span class="math">\\alpha</span> ). In particular,  <span class="math">f_{w_{\\square}}|_{L_{\\beta} \\times \\{Z_{L_0}(L_1)\\}} \\in \\text{RS}[\\mathbb{F}, L_{\\beta}, |L_0|]</span> , and let  <span class="math">p_{\\text{row},\\beta}</span>  be its univariate low degree extension to  <span class="math">\\mathbb{F}</span> .</li>
      <li>For every  <span class="math">(\\alpha, \\beta) \\in D&#x27;&#x27;</span> , it holds that  <span class="math">f_{w_{\\square}}(\\alpha, Z_{L_0}(\\beta)) = w&#x27;(\\phi(\\alpha, Z_{L_0}(\\beta)))</span> .</li>
    </ul>

    <p class="text-gray-300">By Definition F.2 it suffices to show that there exists a bivariate polynomial  <span class="math">g \\in \\mathbb{F}[X,Y]</span>  such that: (i)  <span class="math">\\deg_X(g) &lt; |L_0|</span> ; (ii)  <span class="math">\\deg_Y(g) &lt; |L_1| \\cdot \\rho</span> ; (iii)  <span class="math">g|_{X=\\alpha} = p_{\\operatorname{col},\\alpha}</span>  for every  <span class="math">(\\operatorname{col},\\alpha) \\in D&#x27;</span> ; (iv)  <span class="math">g|_{Y=Z_{L_0}(\\beta)} = p_{\\operatorname{row},\\beta}</span>  for every  <span class="math">(\\operatorname{row},\\beta) \\in D&#x27;</span> ; (v)  <span class="math">g(\\alpha,\\beta) = w&#x27;(\\phi(\\alpha,Z_{L_0}(\\beta)))</span>  for every  <span class="math">(\\alpha,\\beta) \\in D&#x27;&#x27;</span> . But notice that  <span class="math">|D&#x27;| + |D&#x27;&#x27;| \\leq 2 \\cdot |\\mathbb{K}|^{\\frac{\\dim(L)}{2} - \\mu - 2} = |\\mathbb{K}|^{\\frac{\\dim(L)}{2} - \\mu - 1} &lt; \\min\\{|L_0|, |L_1| \\cdot \\rho\\}</span> , because (a)  <span class="math">\\log_{|\\mathbb{K}|}(|L_0|) = \\dim(L_0) \\geq \\frac{\\dim(L)}{2} - 1</span> , and (b)  <span class="math">\\log_{|\\mathbb{K}|}(|L_1| \\cdot \\rho) = \\dim(L_1) - \\mu \\geq \\frac{\\dim(L)}{2} - \\mu</span> . The claim follows by considering a suitable interpolating set (see Section H).</p>

      <h3 id="app-g.2" class="text-xl font-semibold mt-8">G.2 Computing spanning sets of dual codes in the recursive cover</h3>

    <p class="text-gray-300">We prove that spanning sets for duals of codes in the recursive cover can be computed efficiently; this is the key fact that we later use to argue that the algorithm required by Lemma 4.27 satisfies the stated time complexity.</p>

    <p class="text-gray-300"><strong>Claim G.8.</strong> For every positive integer m and vertex v in  <span class="math">T[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  of depth at least  <span class="math">\\log_2 \\dim(L) - \\log_2 \\log_{|\\mathbb{K}|} m</span> , a spanning set of  <span class="math">\\tilde{C}_v^{\\perp}</span>  can be computed in time  <span class="math">\\operatorname{poly}(\\log_2 |\\mathbb{F}| + |\\mathbb{K}|^{\\mu} + m)</span> .</p>

    <p class="text-gray-300">The above claim directly follows from Claim G.9 and Claim G.10, stated and proved below.</p>

    <p class="text-gray-300">Claim G.9. For every positive integer m and vertex v in  <span class="math">T[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  of depth at least  <span class="math">\\log_2 \\dim(L) - \\log_2 \\log_{|\\mathbb{K}|} m</span> ,  <span class="math">|\\tilde{D}_v| \\leq \\operatorname{poly}(m + |\\mathbb{K}|^{\\mu})</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> Ben-Sasson and Sudan [BS08] show that the block length of BS-RS[ <span class="math">\\mathbb{K}, \\mathbb{F}, L, \\mu, k</span> ] is  <span class="math">\\tilde{O}_{\\mathbb{K},\\mu,k}(|L|)</span>  for any fixed  <span class="math">\\mathbb{K}, \\mu, k</span> . One can verify that, if we do not fix these parameters, the block length is  <span class="math">\\tilde{O}(|L| \\cdot |\\mathbb{K}|^{\\mu})</span> . Next, observe that  <span class="math">\\tilde{C}_v = \\text{BS-RS}[\\mathbb{K}, \\mathbb{F}, L_v, \\mu, k]</span>  for some  <span class="math">L_v</span>  such that  <span class="math">\\dim(L_v) \\leq \\log_{|\\mathbb{K}|} m + 2\\mu</span>  (Claim G.6); in this case, the aforementioned bound becomes  <span class="math">\\operatorname{poly}(m + |\\mathbb{K}|^{\\mu})</span> .</p>

    <p class="text-gray-300"><strong>Claim G.10.</strong> A spanning set for BS-RS[ <span class="math">\\mathbb{K}</span> ,  <span class="math">\\mathbb{F}</span> , L,  <span class="math">\\mu</span> , k] <span class="math">^{\\perp}</span>  can be found in time poly  <span class="math">(\\log_2 |\\mathbb{F}| + |D^{\\text{BS-RS}}[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]|)</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> We show an algorithm that constructs the desired spanning set in the stated time complexity. First, a spanning set for  <span class="math">\\mathrm{RS}[\\mathbb{F},S,d]^{\\perp}</span>  can be found in time  <span class="math">\\mathrm{poly}(\\log_2|\\mathbb{F}|+|S|)</span> , for any finite field  <span class="math">\\mathbb{F}</span> , subset  <span class="math">S\\subseteq\\mathbb{F}</span> , and degree bound d&lt;|S|. Hence, a spanning set for  <span class="math">\\mathrm{RS}_{\\square}[\\mathbb{K},\\mathbb{F},L,\\mu]^{\\perp}</span>  can be found in time  <span class="math">(\\log_2|\\mathbb{F}|\\cdot|L|\\cdot|\\mathbb{K}|^{\\mu})^c</span>  for some c&gt;0.</p>

    <p class="text-gray-300">We argue by induction on  <span class="math">\\dim(L)</span>  that a spanning set for BS-RS[ <span class="math">\\mathbb{K}, \\mathbb{F}, L, \\mu, k</span> ] <span class="math">^{\\perp}</span>  can be found in time  <span class="math">(\\log_2 |\\mathbb{F}| \\cdot |L| \\cdot |\\mathbb{K}|^{\\mu})^c</span> . We rely the property that the code BS-RS[ <span class="math">\\mathbb{K}, \\mathbb{F}, L, \\mu, k</span> ] is covered by</p>

    <p class="text-gray-300"><span class="math">$\\{(\\mathrm{BS-RS}[\\mathbb{K}, \\mathbb{F}, Z_{L_0}(L_1), \\mu, k], D_{\\mathrm{col},\\alpha})\\}_{\\alpha \\in L&#x27;_0} \\cup \\{(\\mathrm{BS-RS}[\\mathbb{K}, \\mathbb{F}, L_{\\beta}, \\mu, k], D_{\\mathrm{row},\\beta})\\}_{\\beta \\in L_1}</span>$</p>

    <p class="text-gray-300">and the property that  <span class="math">w \\in BS\\text{-RS}[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  if an only if:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\psi_{\\text{col},\\alpha}(w) \\in \\text{BS-RS}[\\mathbb{K}, \\mathbb{F}, Z_{L_0}(L_1), \\mu, k]</span>  for every  <span class="math">\\alpha \\in L&#x27;_0</span>  and</li>
      <li><span class="math">\\psi_{\\text{row},\\beta}(w) \\in \\text{BS-RS}[\\mathbb{K}, \\mathbb{F}, L_{\\beta}, \\mu, k]</span>  for every  <span class="math">\\beta \\in L_1</span> .</li>
    </ul>

    <p class="text-gray-300">Thus BS-RS[ <span class="math">\\mathbb{K}</span> ,  <span class="math">\\mathbb{F}</span> , L,  <span class="math">\\mu</span> , k] <span class="math">^{\\perp}</span>  is spanned by the duals of codes in its cover and, in particular, is spanned by their spanning sets; in sum, it suffices to construct a spanning set for its cover.</p>

    <p class="text-gray-300">In light of the above, we can bound the construction time of a spanning set for  <span class="math">BS-RS[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]^{\\perp}</span>  as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>If  <span class="math">\\dim(L) \\leq k</span> , the claim follows as the code in this case simply equals  <span class="math">RS_{\\square}[\\mathbb{K}, \\mathbb{F}, L, \\mu]</span> .</li>
      <li>If  <span class="math">\\dim(L) &gt; k</span> , the time to construct a spanning set is at most the time to construct spanning sets for the cover:</li>
    </ul>

    <p class="text-gray-300">
<span class="math">$|L_0&#x27;| \\cdot (\\log_2 |\\mathbb{F}| \\cdot |L_1| \\cdot |\\mathbb{K}|^{\\mu})^c + |L_1| \\cdot (\\log_2 |\\mathbb{F}| \\cdot |L_0&#x27;| \\cdot |\\mathbb{K}|^{\\mu+1})^c \\tag{1}</span>$</p>

    <p class="text-gray-300"><span class="math">$= |L_0| \\cdot |\\mathbb{K}|^{\\mu - 1} \\cdot (\\log_2 |\\mathbb{F}| \\cdot |L_1| \\cdot |\\mathbb{K}|^{\\mu})^c + |L_1| \\cdot (\\log_2 |\\mathbb{F}| \\cdot |L_0| \\cdot |\\mathbb{K}|^{2\\mu})^c</span>$
(2)</p>

    <p class="text-gray-300"><span class="math">$= |L| \\cdot (\\log_2 |\\mathbb{F}| \\cdot |\\mathbb{K}|^{\\mu})^c \\cdot (|\\mathbb{K}|^{\\mu-1} \\cdot |L_1|^{c-1} + |\\mathbb{K}|^{c\\mu} \\cdot |L_0|^{c-1})</span>$
(3)</p>

    <p class="text-gray-300"><span class="math">$\\leq |L| \\cdot (\\log_2 |\\mathbb{F}| \\cdot |\\mathbb{K}|^{\\mu})^c \\cdot \\left( |\\mathbb{K}|^{\\mu+c-2} \\cdot |L|^{\\frac{c-1}{2}} + |\\mathbb{K}|^{c\\mu} \\cdot |L|^{\\frac{c-1}{2}} \\right) \\tag{4}</span>$</p>

    <p class="text-gray-300"><span class="math">$= |L|^{\\frac{c+1}{2}} \\cdot (\\log_2 |\\mathbb{F}| \\cdot |\\mathbb{K}|^{\\mu})^c \\cdot (|\\mathbb{K}|^{\\mu+c-2} + |\\mathbb{K}|^{c\\mu})</span>$
(5)</p>

    <p class="text-gray-300">
<span class="math">$\\leq (\\log_2 |\\mathbb{F}| \\cdot |L| \\cdot |\\mathbb{K}|^{\\mu})^c . \\tag{6}</span>$</p>

    <p class="text-gray-300">Above, (1) is by the inductive assumption, (2) is by definition of  <span class="math">L&#x27;_0</span> , (3) is by the fact that  <span class="math">|L_0| \\cdot |L_1| = |L|</span> , and (4) is by definition of  <span class="math">L_0</span> ,  <span class="math">L_1</span> . We are left to show (6), and this follows from the fact that: (i)  <span class="math">\\dim(L) &gt; k</span> , (ii)  <span class="math">k &gt; 2\\mu</span>  by definition, and (iii) we can choose c to be large enough (namely, so that  <span class="math">|\\mathbb{K}|^{\\mu+c-2} + |\\mathbb{K}|^{c\\mu} &lt; |L|^{\\frac{c-1}{2}}</span>  holds).</p>

      <h3 id="app-g.3" class="text-xl font-semibold mt-8"><strong>G.3</strong> Putting things together</h3>

    <p class="text-gray-300">Proof of Lemma 4.27. Define the depth function  <span class="math">d(\\mathbb{K}, L, \\mu, a) := \\log_2 \\dim(L) - \\log_2(\\log_{|\\mathbb{K}|} a + \\mu + 2) - 1</span> . We argue the two conditions in the lemma. First, for every index  <span class="math">\\mathbb{n} = (\\mathbb{K}, \\mathbb{F}, L, \\mu, k), T[\\mathbb{K}, \\mathbb{F}, L, \\mu, k]</span>  is a 1-intersecting recursive cover of BS-RS[ <span class="math">\\mathbb{K}, \\mathbb{F}, L, \\mu, k</span> ] (by Claim G.4). Moreover, for every positive integer m and non-leaf vertex v in T with depth <span class="math">(T, v) &lt; d(\\mathbb{K}, L, \\mu, m)</span> , the cover  <span class="math">T_v</span>  is m-independent (by Claim G.5).</p>

    <p class="text-gray-300">Second, consider the algorithm that, given an index  <span class="math">\\mathbb{n}=(\\mathbb{K},\\mathbb{F},L,\\mu,k)</span>  and subset  <span class="math">I\\subseteq D^{\\mathrm{BS-RS}}[\\mathbb{K},\\mathbb{F},L,\\mu,k]</span> , works as follows: (1) for every  <span class="math">\\alpha\\in I</span>  choose an arbitrary vertex  <span class="math">v_\\alpha</span>  in  <span class="math">\\mathrm{layer}(T,d(\\mathbb{K},L,\\mu,|I|))</span>  such that  <span class="math">\\alpha\\in \\tilde{D}_{v_\\alpha}</span> , and then set  <span class="math">U:=\\{v_\\alpha\\}_{\\alpha\\in I};</span>  (2) compute a spanning set  <span class="math">W_v</span>  set for  <span class="math">\\tilde{C}_v^\\perp</span> ; (3) return  <span class="math">W:=\\cup_{u\\in U}W_u</span> . This algorithm satisfies the required properties. First, it runs in time  <span class="math">\\mathrm{poly}(\\log_2|\\mathbb{F}|+\\dim(L)+|\\mathbb{K}|^\\mu+|I|)</span>  because a spanning set set for  <span class="math">\\tilde{C}_u^\\perp</span>  can be computed in time  <span class="math">\\mathrm{poly}(\\log_2|\\mathbb{F}|+|\\mathbb{K}|^\\mu+|I|)</span>  (by Claim G.8). Next, its output W meets the requirements:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">U \\subseteq \\text{layer}(T[\\mathbb{K}, \\mathbb{F}, L, \\mu, k], d(\\mathbb{K}, L, \\mu, |I|));</span></li>
      <li><span class="math">|U| \\leq |I|</span> , by definition of U;</li>
      <li><span class="math">I \\subseteq (\\bigcup_{u \\in U} \\tilde{D}_u)</span> , by definition of U;</li>
      <li><span class="math">\\operatorname{span}(W) = \\operatorname{span}(\\bigcup_{u \\in U} W_u) = \\operatorname{span}(\\bigcup_{u \\in U} \\tilde{C}_u^{\\perp})</span> , by definition of W and  <span class="math">W_u</span> . This completes the proof of Lemma 4.27.</li>
    </ul>

    </section>

    <section id="app-h" class="mb-10">
      <h2 class="text-2xl font-bold">H Folklore claim on interpolating sets</h2>

    <p class="text-gray-300"><strong>Claim H.1.</strong> Let  <span class="math">\\mathbb{F}</span>  be a field, let  <span class="math">d_{\\mathsf{cols}}, d_{\\mathsf{rows}} \\in \\mathbb{N}</span> , and consider three sets  <span class="math">S_{\\mathsf{cols}}, S_{\\mathsf{rows}} \\subseteq \\mathbb{F}</span>  and  <span class="math">S_{\\mathsf{pnts}} \\subseteq \\mathbb{F} \\times \\mathbb{F}</span>  such that  <span class="math">|S_{\\mathsf{cols}}| + |S_{\\mathsf{rows}}| + |S_{\\mathsf{pnts}}| \\le \\min\\{d_{\\mathsf{cols}}, d_{\\mathsf{rows}}\\}</span> . Let  <span class="math">f : \\mathbb{F} \\times \\mathbb{F} \\to \\mathbb{F}</span>  be a function such that:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>for every  <span class="math">\\alpha \\in S_{\\text{cols}}</span>  there exists  <span class="math">g_{\\text{col},\\alpha} \\in \\mathbb{F}^{&lt; d_{\\text{rows}}}[x]</span>  such that  <span class="math">f(\\alpha,\\beta) = g_{\\text{col},\\alpha}(\\beta)</span>  for every  <span class="math">\\beta \\in \\mathbb{F}</span> ;</li>
      <li>for every  <span class="math">\\beta \\in S_{\\text{rows}}</span>  there exists  <span class="math">g_{\\text{row},\\beta} \\in \\mathbb{F}^{&lt; d_{\\text{cols}}}[x]</span>  such that  <span class="math">f(\\alpha,\\beta) = g_{\\text{row},\\beta}(\\alpha)</span>  for every  <span class="math">\\alpha \\in \\mathbb{F}</span> .</li>
    </ul>

    <p class="text-gray-300">Then there exists  <span class="math">g \\in \\mathbb{F}[X,Y]</span>  such that: (i)  <span class="math">\\deg_X(g) &lt; d_{\\mathsf{rows}}</span> ; (ii)  <span class="math">\\deg_Y(g) &lt; d_{\\mathsf{cols}}</span> ; (iii)  <span class="math">g|_{X=\\alpha} = g_{\\mathsf{col},\\alpha}</span>  for every  <span class="math">\\alpha \\in S_{\\mathsf{cols}}</span> ; (iv)  <span class="math">g|_{Y=\\beta} = g_{\\mathsf{row},\\beta}</span>  for every  <span class="math">\\beta \\in S_{\\mathsf{rows}}</span> ; (v)  <span class="math">g(\\alpha,\\beta) = f(\\alpha,\\beta)</span>  for every  <span class="math">(\\alpha,\\beta) \\in S_{\\mathsf{pnts}}</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> Any rectangle  <span class="math">D_X \\times D_Y \\subseteq \\mathbb{F} \\times \\mathbb{F}</span>  with  <span class="math">|D_X| = d_{\\mathsf{rows}}</span>  and  <span class="math">|D_Y| = d_{\\mathsf{cols}}</span>  is an interpolating set: for every  <span class="math">w \\in \\mathbb{F}^{D_X \\times D_Y}</span>  there exists a unique  <span class="math">g \\in \\mathbb{F}[X,Y]</span>  such that: (i)  <span class="math">\\deg_X(g) &lt; d_{\\mathsf{rows}}</span> ; (ii)  <span class="math">\\deg_Y(g) &lt; d_{\\mathsf{cols}}</span> ; (iii)  <span class="math">g|_{D_X \\times D_Y} = w</span> . Define</p>

    <p class="text-gray-300"><span class="math">$D_X := S_{\\mathsf{cols}} \\cup \\{\\alpha : \\exists \\beta \\text{ s.t. } (\\alpha, \\beta) \\in S_{\\mathsf{pnts}}\\} \\quad \\text{and} \\quad D_Y := S_{\\mathsf{rows}} \\cup \\{\\beta : \\exists \\alpha \\text{ s.t. } (\\alpha, \\beta) \\in S_{\\mathsf{pnts}}\\} .</span>$</p>

    <p class="text-gray-300">Note that  <span class="math">|D_X| \\leq d_{\\mathsf{rows}}</span>  and  <span class="math">|D_Y| \\leq d_{\\mathsf{cols}}</span> ; if either is strictly smaller, extend it arbitrarily to match the upper bound. Choose  <span class="math">w \\in \\mathbb{F}^{D_X \\times D_Y}</span>  to be a word that satisfies: (i)  <span class="math">w(\\alpha, \\beta) = f(\\alpha, \\beta)</span>  for every  <span class="math">\\alpha \\in S_{\\mathsf{cols}}</span>  and  <span class="math">\\beta \\in D_Y</span> ; (ii)  <span class="math">w(\\alpha, \\beta) = f(\\alpha, \\beta)</span>  for every  <span class="math">\\beta \\in S_{\\mathsf{rows}}</span>  and  <span class="math">\\alpha \\in D_X</span> ; (iii)  <span class="math">w(\\alpha, \\beta) = f(\\alpha, \\beta)</span>  for every  <span class="math">\\beta \\in S_{\\mathsf{pnts}}</span> . Denote by  <span class="math">g_w \\in \\mathbb{F}[X, Y]</span>  the unique &quot;low degree extension&quot; of w; we show that  <span class="math">g_w</span>  satisfies the requirements of the claim.</p>

    <p class="text-gray-300">The degree bounds and the equivalence on  <span class="math">S_{pnts}</span>  follows by definition of  <span class="math">g_w</span> ; thus it suffices to show equivalence of  <span class="math">g_w</span>  with f when restricted to the required rows and columns.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>For every  <span class="math">\\alpha \\in S_{\\text{cols}}</span> : it holds by definition of  <span class="math">g_w</span>  that  <span class="math">g_w|_{\\{\\alpha\\} \\times D_Y} = f|_{\\{\\alpha\\} \\times D_Y}</span> ; moreover,  <span class="math">g_w|_{\\{\\alpha\\} \\times \\mathbb{F}}</span>  and  <span class="math">f|_{\\{\\alpha\\} \\times \\mathbb{F}}</span>  are evaluations of polynomials of degree less than  <span class="math">|D_Y|</span> , which implies that  <span class="math">g_w|_{\\{\\alpha\\} \\times \\mathbb{F}} = f|_{\\{\\alpha\\} \\times \\mathbb{F}}</span> .</li>
      <li>For every  <span class="math">\\beta \\in S_{\\text{rows}}</span> : it holds by definition of  <span class="math">g_w</span>  that  <span class="math">g_w|_{D_X \\times \\{\\beta\\}} = f|_{D_X \\times \\{\\beta\\}}</span> ; moreover,  <span class="math">g_w|_{\\mathbb{F} \\times \\{\\beta\\}}</span>  and  <span class="math">f|_{\\mathbb{F} \\times \\{\\beta\\}}</span>  are evaluations of polynomials of degree less than  <span class="math">|D_X|</span> , which implies that  <span class="math">g_w|_{\\mathbb{F} \\times \\{\\beta\\}} = f|_{\\mathbb{F} \\times \\{\\beta\\}}</span> .</li>
    </ul>

    <p class="text-gray-300">Work of E. Ben-Sasson, A. Gabizon, and M. Riabzev was supported by the Israel Science Foundation (grant 1501/14). Work of A. Chiesa and N. Spooner was partially supported in part by the UC Berkeley Center for Long-Term Cybersecurity. Work of M. A. Forbes was supported by the NSF, including NSF CCF-1617580, and the DARPA Safeware program; it was also partially completed when the author was at Princeton University, supported by the Princeton Center for Theoretical Computer Science.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><p class="text-gray-300">[AH91] William Aiello and Johan Hastad. Statistical zero-knowledge languages can be recognized in two rounds. &#730; <em>Journal of Computer and System Sciences</em>, 42(3):327&ndash;345, 1991. Preliminary version appeared in FOCS '87.</p></li>
      <li><p class="text-gray-300">[ALM<sup>+</sup>98] Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy. Proof verification and the hardness of approximation problems. <em>Journal of the ACM</em>, 45(3):501&ndash;555, 1998. Preliminary version in FOCS '92.</p></li>
      <li><p class="text-gray-300">[AR16] Benny Applebaum and Pavel Raykov. On the relationship between statistical zero-knowledge and statistical randomized encodings. In <em>Proceedings of the 36th Annual International Cryptology Conference</em>, CRYPTO '16, pages 449&ndash;477, 2016.</p></li>
      <li><p class="text-gray-300">[AS98] Sanjeev Arora and Shmuel Safra. Probabilistic checking of proofs: a new characterization of NP. <em>Journal of the ACM</em>, 45(1):70&ndash;122, 1998. Preliminary version in FOCS '92.</p></li>
      <li><p class="text-gray-300">[AS03] Sanjeev Arora and Madhu Sudan. Improved low-degree testing and its applications. <em>Combinatorica</em>, 23(3):365&ndash;426, 2003. Preliminary version appeared in STOC '97.</p></li>
      <li><p class="text-gray-300">[Bab85] Laszl &acute; o Babai. Trading group theory for randomness. In &acute; <em>Proceedings of the 17th Annual ACM Symposium on Theory of Computing</em>, STOC '85, pages 421&ndash;429, 1985.</p></li>
      <li><p class="text-gray-300">[BCG<sup>+</sup>17] Eli Ben-Sasson, Alessandro Chiesa, Ariel Gabizon, Michael Riabzev, and Nicholas Spooner. Interactive oracle proofs with constant rate and query complexity. In <em>Proceedings of the 44th International Colloquium on Automata, Languages and Programming</em>, ICALP '17, pages 40:1&ndash;40:15, 2017.</p></li>
      <li><p class="text-gray-300">[BCGV16] Eli Ben-Sasson, Alessandro Chiesa, Ariel Gabizon, and Madars Virza. Quasilinear-size zero knowledge from linearalgebraic PCPs. In <em>Proceedings of the 13th Theory of Cryptography Conference</em>, TCC '16-A, pages 33&ndash;64, 2016.</p></li>
      <li><p class="text-gray-300">[BCS16] Eli Ben-Sasson, Alessandro Chiesa, and Nicholas Spooner. Interactive oracle proofs. In <em>Proceedings of the 14th Theory of Cryptography Conference</em>, TCC '16-B, pages 31&ndash;60, 2016.</p></li>
      <li><p class="text-gray-300">[BFL91] Laszl &acute; o Babai, Lance Fortnow, and Carsten Lund. Non-deterministic exponential time has two-prover interactive &acute; protocols. <em>Computational Complexity</em>, 1:3&ndash;40, 1991. Preliminary version appeared in FOCS '90.</p></li>
      <li><p class="text-gray-300">[BFLS91] Laszl &acute; o Babai, Lance Fortnow, Leonid A. Levin, and Mario Szegedy. Checking computations in polylogarithmic time. &acute; In <em>Proceedings of the 23rd Annual ACM Symposium on Theory of Computing</em>, STOC '91, pages 21&ndash;32, 1991.</p></li>
      <li><p class="text-gray-300">[BGG<sup>+</sup>88] Michael Ben-Or, Oded Goldreich, Shafi Goldwasser, Johan Hastad, Joe Kilian, Silvio Micali, and Phillip Rogaway. &#730; Everything provable is provable in zero-knowledge. In <em>Proceedings of the 8th Annual International Cryptology Conference</em>, CRYPTO '89, pages 37&ndash;56, 1988.</p></li>
      <li><p class="text-gray-300">[BGH<sup>+</sup>06] Eli Ben-Sasson, Oded Goldreich, Prahladh Harsha, Madhu Sudan, and Salil P. Vadhan. Robust PCPs of proximity, shorter PCPs, and applications to coding. <em>SIAM Journal on Computing</em>, 36(4):889&ndash;974, 2006.</p></li>
      <li><p class="text-gray-300">[BGK<sup>+</sup>10] Eli Ben-Sasson, Venkatesan Guruswami, Tali Kaufman, Madhu Sudan, and Michael Viderman. Locally testable codes require redundant testers. <em>SIAM Journal on Computing</em>, 39(7):3230&ndash;3247, 2010.</p></li>
      <li><p class="text-gray-300">[BGKW88] Michael Ben-Or, Shafi Goldwasser, Joe Kilian, and Avi Wigderson. Multi-prover interactive proofs: how to remove intractability assumptions. In <em>Proceedings of the 20th Annual ACM Symposium on Theory of Computing</em>, STOC '88, pages 113&ndash;131, 1988.</p></li>
      <li><p class="text-gray-300">[BGW88] Michael Ben-Or, Shafi Goldwasser, and Avi Wigderson. Completeness theorems for non-cryptographic fault-tolerant distributed computation. In <em>Proceedings of the 20th Annual ACM Symposium on Theory of Computing</em>, STOC '88, pages 1&ndash;10, 1988.</p></li>
      <li><p class="text-gray-300">[BHR05] Eli Ben-Sasson, Prahladh Harsha, and Sofya Raskhodnikova. Some 3CNF properties are hard to test. <em>SIAM Journal on Computing</em>, 35(1):1&ndash;21, 2005.</p></li>
      <li><p class="text-gray-300">[BHZ87] Ravi B. Boppana, Johan Hastad, and Stathis Zachos. Does co-NP have short interactive proofs? &#730; <em>Information Processing Letters</em>, 25(2):127&ndash;132, 1987.</p></li>
      <li><p class="text-gray-300">[BM88] Laszl &acute; o Babai and Shlomo Moran. Arthur-merlin games: A randomized proof system, and a hierarchy of complexity &acute; classes. <em>Journal of Computer and System Sciences</em>, 36(2):254&ndash;276, 1988.</p></li>
      <li><p class="text-gray-300">[BS08] Eli Ben-Sasson and Madhu Sudan. Short PCPs with polylog query complexity. <em>SIAM Journal on Computing</em>, 38(2):551&ndash;607, 2008. Preliminary version appeared in STOC '05.</p></li>
      <li><p class="text-gray-300">[BVW98] Ronald V. Book, Heribert Vollmer, and Klaus W. Wagner. Probabilistic type-2 operators and &quot;almost&quot;-classes. <em>Computational Complexity</em>, 7(3):265&ndash;289, 1998.</p></li>
      <li><p class="text-gray-300">[BW04] Andrej Bogdanov and Hoeteck Wee. A stateful implementation of a random function supporting parity queries over hypercubes. In <em>Proceedings of the 7th International Workshop on Approximation Algorithms for Combinatorial Optimization Problems, and of the 8th International Workshop on Randomization and Computation</em>, APPROX-RANDOM '04, pages 298&ndash;309, 2004.</p></li>
      <li><p class="text-gray-300">[CFS17] Alessandro Chiesa, Michael A. Forbes, and Nicholas Spooner. A zero knowledge sumcheck and its applications. Cryptology ePrint Archive, Report 2017/305, 2017.</p></li>
      <li><p class="text-gray-300">[DFK<sup>+</sup>92] Cynthia Dwork, Uriel Feige, Joe Kilian, Moni Naor, and Shmuel Safra. Low communication 2-prover zero-knowledge proofs for NP. In <em>Proceedings of the 11th Annual International Cryptology Conference</em>, CRYPTO '92, pages 215&ndash;227, 1992.</p></li>
      <li><p class="text-gray-300">[DR04] Irit Dinur and Omer Reingold. Assignment testers: Towards a combinatorial proof of the PCP theorem. In <em>Proceedings of the 45th Annual IEEE Symposium on Foundations of Computer Science</em>, FOCS '04, pages 155&ndash;164, 2004.</p></li>
      <li><p class="text-gray-300">[DS98] Cynthia Dwork and Amit Sahai. Concurrent zero-knowledge: Reducing the need for timing constraints. In <em>Proceedings of the 18th Annual International Cryptology Conference</em>, CRYPTO '98, pages 442&ndash;457, 1998.</p></li>
      <li><p class="text-gray-300">[FGL<sup>+</sup>96] Uriel Feige, Shafi Goldwasser, Laszlo Lovasz, Shmuel Safra, and Mario Szegedy. Interactive proofs and the hardness &acute; of approximating cliques. <em>Journal of the ACM</em>, 43(2):268&ndash;292, 1996. Preliminary version in FOCS '91.</p></li>
      <li><p class="text-gray-300">[For87] Lance Fortnow. The complexity of perfect zero-knowledge (extended abstract). In <em>Proceedings of the 19th Annual ACM Symposium on Theory of Computing</em>, STOC '87, pages 204&ndash;209, 1987.</p></li>
      <li><p class="text-gray-300">[FRS88] Lance Fortnow, John Rompel, and Michael Sipser. On the power of multi-prover interactive protocols. In <em>Theoretical Computer Science</em>, pages 156&ndash;161, 1988.</p></li>
      <li><p class="text-gray-300">[FS89] Uriel Feige and Adi Shamir. Zero knowledge proofs of knowledge in two rounds. In <em>Proceedings of the 9th Annual International Cryptology Conference</em>, CRYPTO '89, pages 526&ndash;544, 1989.</p></li>
      <li><p class="text-gray-300">[GGN10] Oded Goldreich, Shafi Goldwasser, and Asaf Nussboim. On the implementation of huge random objects. <em>SIAM Journal on Computing</em>, 39(7):2761&ndash;2822, 2010. Preliminary version appeared in FOCS '03.</p></li>
      <li><p class="text-gray-300">[GIMS10] Vipul Goyal, Yuval Ishai, Mohammad Mahmoody, and Amit Sahai. Interactive locking, zero-knowledge PCPs, and unconditional cryptography. In <em>Proceedings of the 30th Annual Conference on Advances in Cryptology</em>, CRYPTO'10, pages 173&ndash;190, 2010.</p></li>
      <li><p class="text-gray-300">[GKR08] Shafi Goldwasser, Yael Tauman Kalai, and Guy N. Rothblum. Delegating computation: Interactive proofs for Muggles. In <em>Proceedings of the 40th Annual ACM Symposium on Theory of Computing</em>, STOC '08, pages 113&ndash;122, 2008.</p></li>
      <li><p class="text-gray-300">[GMR89] Shafi Goldwasser, Silvio Micali, and Charles Rackoff. The knowledge complexity of interactive proof systems. <em>SIAM Journal on Computing</em>, 18(1):186&ndash;208, 1989. Preliminary version appeared in STOC '85.</p></li>
      <li><p class="text-gray-300">[GMW91] Oded Goldreich, Silvio Micali, and Avi Wigderson. Proofs that yield nothing but their validity or all languages in NP have zero-knowledge proof systems. <em>Journal of the ACM</em>, 38(3):691&ndash;729, 1991. Preliminary version appeared in FOCS '86.</p></li>
      <li><p class="text-gray-300">[GO94] Oded Goldreich and Yair Oren. Definitions and properties of zero-knowledge proof systems. <em>Journal of Cryptology</em>, 7(1):1&ndash;32, December 1994.</p></li>
      <li><p class="text-gray-300">[GR15] Tom Gur and Ron D. Rothblum. Non-interactive proofs of proximity. In <em>Proceedings of the 6th Innovations in Theoretical Computer Science Conference</em>, ITCS '15, pages 133&ndash;142, 2015.</p></li>
      <li><p class="text-gray-300">[GS06] Oded Goldreich and Madhu Sudan. Locally testable codes and PCPs of almost-linear length. <em>Journal of the ACM</em>, 53:558&ndash;655, July 2006. Preliminary version in STOC '02.</p></li>
      <li><p class="text-gray-300">[GV99] Oded Goldreich and Salil P. Vadhan. Comparing entropies in statistical zero knowledge with applications to the structure of SZK. In <em>Proceedings of the 14th Annual IEEE Conference on Computational Complexity</em>, CCC '99, page 54, 1999.</p></li>
      <li><p class="text-gray-300">[IMS12] Yuval Ishai, Mohammad Mahmoody, and Amit Sahai. On efficient zero-knowledge PCPs. In <em>Proceedings of the 9th Theory of Cryptography Conference on Theory of Cryptography</em>, TCC '12, pages 151&ndash;168, 2012.</p></li>
      <li><p class="text-gray-300">[IMSX15] Yuval Ishai, Mohammad Mahmoody, Amit Sahai, and David Xiao. On zero-knowledge PCPs: Limitations, simplifications, and applications, 2015. Available at <a href="http://www.cs.virginia.edu/~mohammad/files/papers/ZKPCPs-Full.pdf" target="_blank" rel="noopener noreferrer">http://www.cs.virginia.edu/&tilde;mohammad/files/papers/</a> <a href="http://www.cs.virginia.edu/~mohammad/files/papers/ZKPCPs-Full.pdf" target="_blank" rel="noopener noreferrer">ZKPCPs-Full.pdf</a>.</p></li>
      <li><p class="text-gray-300">[IOS97] Toshiya Itoh, Yuji Ohta, and Hiroki Shizuya. A language-dependent cryptographic primitive. <em>Journal of Cryptology</em>, 10(1):37&ndash;50, 1997.</p></li>
      <li><p class="text-gray-300">[IW14] Yuval Ishai and Mor Weiss. Probabilistically checkable proofs of proximity with zero-knowledge. In <em>Proceedings of the 11th Theory of Cryptography Conference</em>, TCC '14, pages 121&ndash;145, 2014.</p></li>
      <li><p class="text-gray-300">[IWY16] Yuval Ishai, Mor Weiss, and Guang Yang. Making the best of a leaky situation: Zero-knowledge PCPs from leakageresilient circuits. In <em>Proceedings of the 13th Theory of Cryptography Conference</em>, TCC '16-A, pages 3&ndash;32, 2016.</p></li>
      <li><p class="text-gray-300">[IY87] Russell Impagliazzo and Moti Yung. Direct minimum-knowledge computations. In <em>Proceedings of the 7th Annual International Cryptology Conference</em>, CRYPTO '87, pages 40&ndash;51, 1987.</p></li>
      <li><p class="text-gray-300">[Kay10] Neeraj Kayal. Algorithms for arithmetic circuits, 2010. ECCC TR10-073.</p></li>
      <li><p class="text-gray-300">[KI04] Valentine Kabanets and Russell Impagliazzo. Derandomizing polynomial identity tests means proving circuit lower bounds. <em>Computational Complexity</em>, 13(1-2):1&ndash;46, 2004.</p></li>
      <li><p class="text-gray-300">[KPT97] Joe Kilian, Erez Petrank, and Gabor Tardos. Probabilistically checkable proofs with zero knowledge. In &acute; <em>Proceedings of the 29th Annual ACM Symposium on Theory of Computing</em>, STOC '97, pages 496&ndash;505, 1997.</p></li>
      <li><p class="text-gray-300">[KR08] Yael Kalai and Ran Raz. Interactive PCP. In <em>Proceedings of the 35th International Colloquium on Automata, Languages and Programming</em>, ICALP '08, pages 536&ndash;547, 2008.</p></li>
      <li><p class="text-gray-300">[LFKN92] Carsten Lund, Lance Fortnow, Howard J. Karloff, and Noam Nisan. Algebraic methods for interactive proof systems. <em>Journal of the ACM</em>, 39(4):859&ndash;868, 1992.</p></li>
      <li><p class="text-gray-300">[LS95] Dror Lapidot and Adi Shamir. A one-round, two-prover, zero-knowledge protocol for NP. <em>Combinatorica</em>, 15(2):204&ndash; 214, 1995.</p></li>
      <li><p class="text-gray-300">[MX13] Mohammad Mahmoody and David Xiao. Languages with efficient zero-knowledge PCPs are in SZK. In <em>Proceedings of the 10th Theory of Cryptography Conference</em>, TCC '13, pages 297&ndash;314, 2013.</p></li>
      <li><p class="text-gray-300">[Nao91] Moni Naor. Bit commitment using pseudorandomness. <em>Journal of Cryptology</em>, 4(2):151&ndash;158, 1991. Preliminary version appeared in CRYPTO '89.</p></li>
      <li><p class="text-gray-300">[Nis93] Noam Nisan. On read-once vs. multiple access to randomness in logspace. <em>Theoretical Computer Science</em>, 107(1):135&ndash; 144, 1993.</p></li>
      <li><p class="text-gray-300">[Oka00] Tatsuaki Okamoto. On relationships between statistical zero-knowledge proofs. <em>Journal of Computer and System Sciences</em>, 60(1):47&ndash;108, 2000.</p></li>
      <li><p class="text-gray-300">[Ost91] Rafail Ostrovsky. One-way functions, hard on average problems, and statistical zero-knowledge proofs. In <em>Proceedings of the 6th Annual Structure in Complexity Theory Conference</em>, CoCo '91, pages 133&ndash;138, 1991.</p></li>
      <li><p class="text-gray-300">[OV08] Shien Jin Ong and Salil P. Vadhan. An equivalence between zero knowledge and commitments. In <em>Proceedings of the 5th Theory of Cryptography Conference</em>, TCC '08, pages 482&ndash;500, 2008.</p></li>
      <li><p class="text-gray-300">[OW93] Rafail Ostrovsky and Avi Wigderson. One-way functions are essential for non-trivial zero-knowledge. In <em>Proceedings of the 2nd Israel Symposium on Theory of Computing Systems</em>, ISTCS '93, pages 3&ndash;17, 1993.</p></li>
      <li><p class="text-gray-300">[RRR16] Omer Reingold, Ron Rothblum, and Guy Rothblum. Constant-round interactive proofs for delegating computation. In <em>Proceedings of the 48th ACM Symposium on the Theory of Computing</em>, STOC '16, pages 49&ndash;62, 2016.</p></li>
      <li><p class="text-gray-300">[RS96] Ronitt Rubinfeld and Madhu Sudan. Robust characterizations of polynomials with applications to program testing. <em>SIAM Journal on Computing</em>, 25(2):252&ndash;271, 1996.</p></li>
      <li><p class="text-gray-300">[RS05] Ran Raz and Amir Shpilka. Deterministic polynomial identity testing in non-commutative models. <em>Computational Complexity</em>, 14(1):1&ndash;19, 2005. Preliminary version appeared in CCC '04.</p></li>
      <li><p class="text-gray-300">[Sch80] Jacob T. Schwartz. Fast probabilistic algorithms for verification of polynomial identities. <em>Journal of the ACM</em>, 27(4):701&ndash;717, 1980.</p></li>
      <li><p class="text-gray-300">[Sha92] Adi Shamir. IP = PSPACE. <em>Journal of the ACM</em>, 39(4):869&ndash;877, 1992.</p></li>
      <li><p class="text-gray-300">[SV03] Amit Sahai and Salil P. Vadhan. A complete problem for statistical zero knowledge. <em>Journal of the ACM</em>, 50(2):196&ndash;249, 2003.</p></li>
      <li><p class="text-gray-300">[SY10] Amir Shpilka and Amir Yehudayoff. Arithmetic circuits: A survey of recent results and open questions. <em>Foundations and Trends in Theoretical Computer Science</em>, 5(3-4):207&ndash;388, 2010.</p></li>
      <li><p class="text-gray-300">[Vad99] Salil P. Vadhan. <em>A Study of Statistical Zero-Knowledge Proofs</em>. PhD thesis, MIT, August 1999.</p></li>
      <li><p class="text-gray-300">[VV15] Vinod Vaikuntanathan and Prashant Nalini Vasudevan. Secret sharing and statistical zero knowledge. In <em>Proceedings of the 21st International Conference on the Theory and Application of Cryptology and Information Security</em>, ASIACRYPT '15, pages 656&ndash;680, 2015.</p></li>
      <li><p class="text-gray-300">[Zip79] Richard Zippel. Probabilistic algorithms for sparse polynomials. In <em>Proceedings of the 1979 International Symposium on Symbolic and Algebraic Computation</em>, EUROSAM '79, pages 216&ndash;226, 1979.</p></li>
    </ul>

    </section>
`;
---

<BaseLayout title="Zero Knowledge Protocols from Succinct Constraint Detection (2016/988)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2016 &middot; eprint 2016/988
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <PaperDisclaimer eprintUrl={EPRINT_URL} />
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

    <PaperHistory slug="zero-knowledge-protocols-from-succinct-constraint-detection-2016" />
  </article>
</BaseLayout>
