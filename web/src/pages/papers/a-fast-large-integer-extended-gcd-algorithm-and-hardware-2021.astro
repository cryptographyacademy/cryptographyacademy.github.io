---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2021/1292';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'A Fast Large-Integer Extended GCD Algorithm and Hardware Design for Verifiable Delay Functions and Modular Inversion';
const AUTHORS_HTML = 'Kavya Sreedhar, Mark Horowitz, Christopher Torng';

const CONTENT = `    <p class="text-gray-300">IACR Transactions on Cryptographic Hardware and Embedded Systems ISSN 2569-2925, Vol. 2022, No. 4, pp. 163-187.</p>

    <p class="text-gray-300">DOI:10.46586/tches.v2022.i4.163-187</p>

    <p class="text-gray-300">Kavya Sreedhar, Mark Horowitz and Christopher Torng</p>

    <p class="text-gray-300">Stanford University, Stanford, CA, USA skavya@stanford.edu, horowitz@ee.stanford.edu, ctorng@stanford.edu</p>

    <p class="text-gray-300">Abstract. The extended GCD (XGCD) calculation, which computes Bézout coefficients <span class="math">b_{a}, b_{b}</span> such that <span class="math">b_{a} <em> a_{0} + b_{b} </em> b_{0} = GCD(a_{0}, b_{0})</span>, is a critical operation in many cryptographic applications. In particular, large-integer XGCD is computationally dominant for two applications of increasing interest: verifiable delay functions that square binary quadratic forms within a class group and constant-time modular inversion for elliptic curve cryptography. Most prior work has focused on fast software implementations. The few works investigating hardware acceleration build on variants of Euclid's division-based algorithm, following the approach used in optimized software. We show that adopting variants of Stein's subtraction-based algorithm instead leads to significantly faster hardware. We quantify this advantage by performing a large-integer XGCD accelerator design space exploration comparing Euclid- and Stein-based algorithms for various application requirements. This exploration leads us to an XGCD hardware accelerator that is flexible and efficient, supports fast average and constant-time evaluation, and is easily extensible for polynomial GCD. Our 16nm ASIC design calculates 1024-bit XGCD in 294ns (8× faster than the state-of-the-art ASIC) and constant-time 255-bit XGCD for inverses in the field of integers modulo the prime <span class="math">2^{255} - 19</span> in 85ns (31× faster than state-of-the-art software). We believe our design is the first high-performance ASIC for the XGCD computation that is also capable of constant-time evaluation. Our work is publicly available at https://github.com/kavyasreedhar/sreedhar-xgcd-hardware-ches2022.</p>

    <p class="text-gray-300">Keywords: Extended GCD · ASIC · Verifiable delay function · Class groups · Squaring binary quadratic forms · Constant-time · Modular inversion · Curve25519</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Computing the greatest common divisor (GCD) is a fundamental operation in number theory, with wide-ranging applications in cryptography [SRC20, Wes19, NLRC10, RSA78, Mil85, Kob87]. GCD algorithms repeatedly apply GCD-preserving transformations, primarily building from Stein's binary GCD algorithm [Ste67, Pur83, BK85, YZ86, Por20] or Euclid's algorithm [Leh38, Jeb93, Web95, Jeb95, Sor95, WTM05]. Both of these algorithms rely on the fact that the GCD between two numbers is the same as the GCD between their difference and the smaller number: $GCD(a,b) = GCD(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a - b</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, \\min(a,b))<span class="math">. Stein&#x27;s algorithm [Ste67] directly uses this property when both </span>a<span class="math"> and </span>b<span class="math"> are odd but also removes factors of two to reduce the number of iterations: </span>GCD(a,b) = GCD(a/2,b)<span class="math"> if </span>a<span class="math"> is even and </span>GCD(a,b) = GCD(a,b/2)<span class="math"> if </span>b<span class="math"> is even. Euclid&#x27;s algorithm subtracts as many multiples of the smaller input as possible by dividing: </span>GCD(a,b) = GCD(\\min(a,b), \\max(a,b) \\mod \\min(a,b))$. Other GCD algorithms are asymptotically fast and based on subquadratic multiplication [Knu70, Sch71, Sch91, TY00, PW02, Möl08, SZ04]. These algorithms</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Licensed under Creative Commons License CC-BY 4.0.</p>

    <p class="text-gray-300">Received: 2022-04-15</p>

    <p class="text-gray-300">Accepted: 2022-06-15</p>

    <p class="text-gray-300">CC BY</p>

    <p class="text-gray-300">Published: 2022-08-31</p>

    <p class="text-gray-300">primarily build from Lehmer’s algorithm <em>[x10]</em> (which, in turn, builds from Euclid’s algorithm) and use a divide-and-conquer approach to recursively determine the quotients sequence.</p>

    <p class="text-gray-300">Until recently, there has been little advancement in fast GCD algorithms and the extended GCD (XGCD) computation that also computes Bézout coefficients <span class="math">b_{a},b_{b}</span> satisfying the Bézout identity: <span class="math">b_{a}<em>a_{0}+b_{b}</em>b_{0}=GCD(a_{0},b_{0})</span>. However, two recent developments suggest an increasing need for faster large-integer XGCD algorithms and implementations. The first is increased interest in a verifiable delay function <em>[x2]</em> construction based on squaring binary quadratic forms over class groups <em>[x16]</em>, a computation for which XGCD is the bottleneck. The second is the realization that constant-time XGCD can be faster than Fermat’s Little Theorem <em>[x5]</em> for use in constant-time modular inversion <em>[x7, x13]</em>.</p>

    <p class="text-gray-300">These applications motivate rigorous exploration of fast XGCD hardware acceleration. However, only four relevant works currently exist in the literature. The first pair of works present 1024-bit XGCD ASIC designs based on Euclid’s algorithm for squaring binary quadratic forms over a class group <em>[ZST^{+}20, x17]</em>. The other two works present FPGA designs for the Bernstein-Yang algorithm <em>[x7]</em> for constant-time modular inversion <em>[DdPM^{+}21]</em> and Euclid’s algorithm <em>[x1]</em>. All these prior works provide point solutions to improve either average performance (for squaring binary quadratic forms) or worst-case performance (for constant-time applications). They also all build from Euclid’s algorithm, citing its low iteration count and efficient software implementations.</p>

    <p class="text-gray-300">We make two key observations to improve upon prior work. First, we observe that while individual applications may favor point solutions, one unified design that can efficiently support multiple applications is desirable since ASIC solutions can be expensive. Second, we show that Euclid’s algorithm is not the optimal target for hardware acceleration, despite low iteration counts, since execution time depends on the iteration count <em>and</em> the time per iteration. Unlike in software, hardware designs are not constrained by a processor’s instruction set architecture and can instead implement fast and wide custom datapaths that do not correspond to any instruction, enabling extremely short iteration times.</p>

    <p class="text-gray-300">Leveraging these observations, we create an efficient parameterizable hardware architecture and conduct a large-integer XGCD design space exploration that considers different application requirements and XGCD algorithms. In Section 2, we review the importance and requirements of the XGCD computation in our motivating applications. Then, in Section 3, we analytically compare hardware execution times for Euclid- and Stein-based algorithms within the context of our application requirements. Despite the lower average number of iterations for Euclid-based algorithms, we find that using a redundant representation and carry-save adders for repeated addition significantly decreases the iteration time for Stein-based algorithms, resulting in faster average execution times. Since both algorithm types have similar worst-case iteration counts, this approach also results in faster worst-case execution times, which is used for constant-time XGCD. Thus, unlike all prior XGCD hardware papers, we choose to build from Stein-based algorithms, specifically the two-bit PM algorithm <em>[x14]</em>. In Section 4, we present our optimized XGCD design for higher performance and in Section 5, we build full accelerators with our XGCD design for our motivating applications. Finally, we evaluate our design in Section 6.</p>

    <p class="text-gray-300">Our 16nm design computes 1024-bit XGCD 8<span class="math">\\times</span> faster than the current state-of-the-art ASIC <em>[ZST^{+}20]</em>, after scaling its performance to the same technology, enabling squaring binary quadratic forms 14<span class="math">\\times</span> faster than optimized C++ on Apple’s M1 processor in 5nm. We also compute 255-bit XGCD 31<span class="math">\\times</span> faster than the state-of-the-art software <em>[x13]</em>, directly translating into a 31<span class="math">\\times</span> speedup for computing modular inverses for Curve25519. We believe this work contributes the first high-performance ASIC for constant-time XGCD.</p>

    <p class="text-gray-300">Kavya Sreedhar, Mark Horowitz, and Christopher Torng</p>

    <p class="text-gray-300">Table 1: Summary of motivating cryptographic applications using large-integer XGCD.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">VDF: Squaring binary quadratic forms over class groups [Wes19]</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Computing inverses mod 2255 - 19 for Curve25519 [Ber06]</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Constant-time</td>

            <td class="px-3 py-2 border-b border-gray-700">No</td>

            <td class="px-3 py-2 border-b border-gray-700">Yes</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">State-of-the-art algorithm</td>

            <td class="px-3 py-2 border-b border-gray-700">NUDUPL [JvdP02]</td>

            <td class="px-3 py-2 border-b border-gray-700">Optimized Stein's [Por20]</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Number of XGCDs</td>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- XGCD % of execution time</td>

            <td class="px-3 py-2 border-b border-gray-700">91%</td>

            <td class="px-3 py-2 border-b border-gray-700">100%</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- XGCD input bitwidth</td>

            <td class="px-3 py-2 border-b border-gray-700">1024</td>

            <td class="px-3 py-2 border-b border-gray-700">255</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- GCD = 1</td>

            <td class="px-3 py-2 border-b border-gray-700">Yes for 1st XGCD</td>

            <td class="px-3 py-2 border-b border-gray-700">Yes</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">- Requires minimal pair</td>

            <td class="px-3 py-2 border-b border-gray-700">Yes for 2nd XGCD</td>

            <td class="px-3 py-2 border-b border-gray-700">Yes</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  Other approaches |  |   |</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- that use XGCD</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">[Lon19]</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Bernstein-Yang [BY19]</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We focus on two cryptographic applications of XGCD that have drawn recent interest: a verifiable delay function construction based on squaring binary quadratic forms over class groups and modular inversion for elliptic curve cryptography (Table 1). These applications represent two distinct spaces of application requirements (1024-bit fast average XGCD versus 255-bit constant-time XGCD), showcasing the flexibility of our design.</p>

    <p class="text-gray-300">A verifiable delay function (VDF) is a cryptographic primitive that requires a specified amount of sequential work to be evaluated but outputs a unique result that is still efficiently and publicly verifiable. This fast verification but slow evaluation property is useful for adding delays in decentralized systems to avoid adversarial data manipulation [BBBF18]. In particular, VDFs have been considered a promising candidate to serve as the core function for blockchain systems to disincentivize dishonest behavior: they have been integrated into the Chia Network's blockchain design [chi21], while the Ethereum Foundation and Protocol Labs anticipate that VDFs will also be crucial to their designs.</p>

    <p class="text-gray-300">One proposed VDF construction is exponentiation in a group of unknown order such as an RSA group [Wes19, Pie18] or a class group [Wes19], which requires  <span class="math">T</span>  sequential squarings performed in a group using a modulus  <span class="math">N</span>  in order to compute  <span class="math">f(x) = x^{2^T}</span>  [BBF18]. The Chia Network chose to incorporate a VDF construction based on squaring binary quadratic forms over a class group [Wes19] in their blockchain design. We refer the reader to Buell's textbook [Bue89] for detail on binary quadratic forms. Since the repeated squaring in this construction continually doubles the output bitwidth, each squaring operation is followed by a reduction operation (Algorithm 5.4.2 of [Coh93]) to ensure that the output (and subsequent input) bitwidth do not exceed the bitwidth of the original input.</p>

    <p class="text-gray-300">The Chia Network has hosted several competitions for fast software implementations for this repeated squaring computation. Both the Chia Network reference and the competition winner chose to implement the NUDUPL algorithm [JvdP02]. This algorithm not only computes the squaring operation, but it also partially reduces the output values to help with the reduction operation to ensure that values stay within a certain size.</p>

    <p class="text-gray-300">Profiling the operations required for the NUDUPL algorithm with 1024-bit inputs shows that XGCD dominates, requiring  <span class="math">91\\%</span>  of the total execution time (Table 2). We averaged over one million trials of the Chia Network's reference  <span class="math">\\mathrm{C + + }</span>  implementation (compiled with  <span class="math">\\mathrm{g + + }</span>  and -O3 optimization) on a 2020 MacBook Pro with the M1 chip and</p>

    <p class="text-gray-300">A Fast Large-Integer Extended GCD Algorithm and Hardware Design</p>

    <p class="text-gray-300">Table 2: NUDUPL algorithm profiling on Apple's M1 processor with 1024-bit inputs.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Operation</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">% of execution time in 99.999% of squarings</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">% of execution time in few remaining squarings</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">XGCD</td>

            <td class="px-3 py-2 border-b border-gray-700">91</td>

            <td class="px-3 py-2 border-b border-gray-700">85</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Modular Multiplication</td>

            <td class="px-3 py-2 border-b border-gray-700">4</td>

            <td class="px-3 py-2 border-b border-gray-700">7</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Additions, Multiplications, Divisions</td>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

            <td class="px-3 py-2 border-b border-gray-700">8</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">used the standard  <span class="math">\\mathrm{C + + }</span>  chrono library with nanosecond precision. The algorithm takes one of two branches in each squaring, depending on whether the size of intermediate variables need to be reduced. The branch taken significantly more often (99.999% of the time) computes two XGCDs: the first is the conventional XGCD while the second is a partial XGCD that terminates when the remainder in Euclid's algorithm is below a precomputed value instead of waiting until it is zero. The other branch only requires the first XGCD.</p>

    <p class="text-gray-300">For this application, the GCD will always be one in the first XGCD, so the important operation is finding a pair of Bézout coefficients. We observe that the second partial XGCD can be replaced by a XGCD that does not terminate early as long as the returned Bézout coefficients are one of the two minimal pairs possible. While multiple solutions can satisfy Bézout's identity for a pair of inputs, solutions are called minimal pairs only if the absolute values of the Bézout coefficients are less than the absolute values of the inputs divided by the GCD [MH94]. Euclid's algorithm always returns such a pair, while Stein-based algorithms may require extra iterations or a final correction to produce minimal results.</p>

    <p class="text-gray-300">Understanding the speedup that dedicated hardware can achieve for this squaring helps determine the security level needed (i.e., the number of squarings and the minimum input bitwidth required) to guarantee a certain amount of time has passed with the VDF evaluation. Thus, high performance is the primary objective for VDF solutions. In addition, since this work is sequential by definition and not much computation can be done in parallel, area and power consumption are lesser concerns. Finally, since VDFs have a verification step, their inputs are not secret. Thus, there is no need for constant-time evaluation to protect against timing attacks and it is beneficial to minimize the average XGCD execution time even if constant-time execution does not improve.</p>

    <p class="text-gray-300">To ensure our XGCD speedup translates well into overall squaring speedup, we accelerate the other large-integer operations required (one modular multiplication and various additions, multiplications, and divisions) to build the first hardware accelerator for the NUDUPL algorithm (Section 5). We note that there are varying reports on a reasonable input bitwidth for class-group-based VDFs, ranging from 833 bits [HM00] to  <span class="math">3000+</span>  bits [DGS20]. Since both the Chia Network and recent work  <span class="math">\\left[\\mathrm{ZST}^{+}20\\right.</span> , ZTW21] evaluate 1024-bit XGCD, we also use 1024-bit inputs, as listed in Table 1. Fortunately, we use a redundant representation which makes our iteration time relatively independent of bitwidth (Section 4.2). Thus, our design ensures high performance even as bitwidths change.</p>

    <p class="text-gray-300">A modular inverse of an integer  <span class="math">x</span>  (mod  <span class="math">y</span> ) is defined as the integer  <span class="math">x^{-1}</span>  such that  <span class="math">x * x^{-1} = 1</span>  (mod  <span class="math">y</span> ). This computation is used in public-key cryptography, including RSA [RSA78] and elliptic curve cryptography (ECC) [Mil85, Kob87]. In both of these applications, some value must be kept a secret: in RSA, the secret key is generated by inverting the public key and in ECC, the value to be inverted is a secret while the modulus is publicly known. To protect such systems from timing attacks, we require constant-time solutions where the execution time does not depend on the secret values. For ECC, computing the modular inverse must take the same execution time regardless of the input value.</p>

    <p class="text-gray-300">One part of ECC consists of elliptic curves defined over a finite field of positive integers modulo a prime number  <span class="math">p</span> . Curve25519 is one of the fastest and mostly commonly used elliptic curves defined with  <span class="math">p = 2^{255} - 19</span>  [Ber06]. Operations on points of the elliptic</p>

    <p class="text-gray-300">curve consist of field operations, the most time-consuming of which is modular inversion with modulus <span class="math">p</span>. As a result, many ECC implementations use different coordinate systems for most of the computation to minimize the number of inversions required <em>[x17]</em>.</p>

    <p class="text-gray-300">There are two approaches to compute the modular inverse when the modulus is prime. The first approach is Fermat’s Little Theorem (FLT) <em>[x5]</em>, which states that <span class="math">x^{-1}=x^{p-2}</span> (mod <span class="math">p</span>). For Curve25519, this computation requires 254 squarings and 11 multiplications <em>[x1, x11]</em>. The second approach computes the XGCD between <span class="math">x</span>, the value to be inverted, and <span class="math">p</span>, the modulus. This approach is valid because <span class="math">x<em>x^{-1}=1</span> (mod <span class="math">p</span>) <span class="math">\\rightarrow x</em>x^{-1}-1=0</span> (mod <span class="math">p</span>) <span class="math">\\rightarrow x<em>x^{-1}-1</span> is divisible by <span class="math">p</span>, so <span class="math">x</em>x^{-1}-1=y<em>p</span> for some <span class="math">y</span> or <span class="math">x</em>x^{-1}-1=-z<em>p</span> for <span class="math">z=-y</span>. This can be rewritten as the Bézout Identity: <span class="math">x</em>x^{-1}+z*p=1</span>. Thus, finding the XGCD returns the Bézout coefficient <span class="math">x^{-1}</span>. Note that the modular inverse is unique and corresponds to one of the minimal pairs.</p>

    <p class="text-gray-300">In 2019, the Bernstein-Yang algorithm, a subquadratic XGCD algorithm, showed that constant-time XGCD can be faster than FLT <em>[x11]</em>, leading to a shift in the state of the art. In 2020, Pornin achieved faster results for computing inverses mod <span class="math">2^{255}-19</span> on recent 64-bit x86 CPUs by optimizing Stein’s algorithm <em>[x20]</em>. Pornin’s work is used to generate RSA key pairs in several projects <em>[x21, FaPKL^{+}]</em>. In 2021, the Bernstein-Yang algorithm was incorporated into the MirageOS unikernel operating system <em>[x14]</em>. This work is up to <span class="math">2.5\\times</span> faster compared to FLT implementations but <span class="math">3.8\\times</span> slower than Pornin’s Curve25519 results, so Pornin’s work remains the state-of-the-art software for computing inverses mod <span class="math">2^{255}-19</span>. Only one prior work considers constant-time XGCD hardware. This prior work implements the Bernstein-Yang algorithm on an FPGA and is faster than prior FLT-based designs for Curve25519 <em>[DdPM^{+}21]</em>. Note that the FPGA execution time is slower than the software records <em>[x11, x20]</em> since the FPGA is run at a <span class="math">7\\times</span> to <span class="math">11\\times</span> slower frequency compared to the frequency of the Intel processors in the software papers.</p>

    <p class="text-gray-300">These works show the recent adoption of XGCD-based modular inversion with modulus <span class="math">2^{255}-19</span>. However, most of these approaches (all but Pornin’s) build from Euclid-based algorithms. Given this growing interest, an in-depth design-space exploration is useful to determine the more suitable XGCD algorithm for fast constant-time execution in hardware.</p>

    <h2 id="sec-6" class="text-2xl font-bold">3 Hardware Performance Analysis of XGCD Algorithms</h2>

    <p class="text-gray-300">As previously discussed, all the prior XGCD hardware papers build from Euclid-based algorithms and represent point solutions in the XGCD hardware acceleration space, optimizing either for fast average-case or worst-case performance. Thus, we explore the broader design space over multiple axes: algorithm family (Euclid versus Stein), target platform (software versus hardware), and application requirements (fast average-case execution versus worst-case execution). We find that using a redundant representation with the two-bit PM algorithm <em>[x28]</em> in the Stein family is faster in hardware for fast average-case <em>and</em> worst-case execution (the latter of which we use for constant-time XGCD).</p>

    <h3 id="sec-7" class="text-xl font-semibold mt-8">3.1 Algorithm Family</h3>

    <p class="text-gray-300">XGCD algorithms use the same control flow as GCD algorithms and iteratively apply GCD-preserving reduction transformations. This section overviews the transformations used by the three major GCD algorithm families and their suitability for our applications.</p>

    <p class="text-gray-300">Stein’s algorithm continually reduces its inputs by replacing the larger number with their difference when both numbers are odd or by dividing by two when a number is even <em>[x25]</em>. The Purdy algorithm also removes factors of two when possible but replaces the subtraction transformation with <span class="math">GCD(a,b)=GCD(\\frac{a+b}{2},\\frac{a-b}{2})</span> to avoid comparing the two numbers <em>[x22]</em>. Note that <span class="math">a\\pm b</span> will be even when <span class="math">a,b</span> are odd. To further avoid large-integer comparisons, the Plus-Minus (PM) algorithm approximates the binary</p>

    <p class="text-gray-300">logarithm of <span class="math">a-b</span> <em>[x1]</em> and the two-bit PM algorithm duplicates cases in the PM algorithm and removes two factors of two when possible in a single iteration <em>[x30]</em>.</p>

    <p class="text-gray-300">Euclid’s algorithm continually reduces its inputs by replacing the larger number with the remainder from dividing the two numbers. Lehmer’s algorithm <em>[x24]</em> is faster for large integers by observing that most quotients are small and the initial parts of the quotients only depend on the most significant bits of the large inputs. Other papers build on this work with efficient techniques to detect when approximate division based on the MSBs is correct, further reducing the number of large-integer divisions required <em>[x23, x22, x36]</em>.</p>

    <p class="text-gray-300">Subquadratic XGCD algorithms are based on subquadratic multiplication and are thus asymptotically fast. The Knuth-Schönhage algorithm <em>[x21, x27]</em>, one of the earliest subquadratic GCD algorithms, uses a divide-and-conquer approach based on Lehmer’s algorithm to recursively determine the quotients sequence. Further work more clearly details and extends these ideas <em>[x29, x31, x29, x26]</em>, including binary recursive approaches <em>[x30, x32]</em> and Bernstein and Yang’s recent constant-time approach <em>[x5]</em>.</p>

    <p class="text-gray-300">For the input bitwidths in our applications (Table 1), profiling from existing literature already strongly suggests that Euclid’s and Stein’s algorithms are faster than subquadratic algorithms <em>[x23]</em>. More recently, Pornin’s XGCD implementation <em>[x28]</em>, published after Bernstein-Yang’s subquadratic XGCD algorithm <em>[x5]</em>, uses a quadratic approach (Stein’s algorithm) to achieve higher performance: 2000+ fewer cycles on recent x86 CPUs. Thus, we focus on comparing the XGCD execution time in hardware for Euclid- and Stein-based algorithms to determine the more promising family for hardware acceleration.</p>

    <h3 id="sec-8" class="text-xl font-semibold mt-8">3.2 Target Platform</h3>

    <p class="text-gray-300">In both software and hardware, execution time is the product of the number of iterations and the time per iteration. The number of iterations only depends on the XGCD algorithm and is independent of the target platform. Thus, optimizations to reduce the number of iterations directly translate from software to hardware. The time per iteration, or iteration time, is the latency for the longest series of data-dependent operations that complete in an iteration. This is also known as the critical path. Note that the critical path delay may not be the sum of delays for all operations since some operations may be performed in parallel. Since software is constrained to using instructions predefined in the processor’s instruction set architecture (ISA), software iteration times correspond to the longest set of dependent instructions. In contrast, hardware is not limited to an ISA and allows for implementing fast, wide, and custom datapaths with extremely short iteration times. This additional control over the iteration time in hardware opens the opportunity to accelerate XGCD algorithms that require more iterations but have far simpler operations, resulting in shorter iteration times and faster overall execution times.</p>

    <h3 id="sec-9" class="text-xl font-semibold mt-8">3.3 Hardware Design Performance Comparison</h3>

    <p class="text-gray-300">To select the most suitable XGCD algorithm for hardware acceleration across our applications, we compare the number of iterations (Section 3.3.1) and iteration time (Section 3.3.2) for the Stein and Euclid algorithm families in the average case and in the worst case. The key difference between the average- and worst-case is the algorithm termination condition, which affects the number of iterations. In the average case, the algorithm is run until the GCD is found (i.e., one of the two inputs has been reduced to zero). In the worst case, the algorithm is run for a fixed number of iterations, set to the worst-case number.</p>

    <h4 id="sec-10" class="text-lg font-semibold mt-6">3.3.1 Number of Iterations</h4>

    <p class="text-gray-300">We use uniform random 1024-bit inputs with our functional models to find the average number of iterations required for various algorithms. Since Euclid’s algorithm divides every</p>

    <p class="text-gray-300">iteration while Stein’s algorithm <em>[x20]</em> only reduces a factor of two, Euclid’s algorithm requires <span class="math">3.6\\times</span> fewer iterations compared to Stein’s algorithm on average (598 versus 2163). The PM algorithm <em>[x1]</em> requires more iterations compared to Stein’s algorithm since it can incorrectly approximate <span class="math">a&gt;b</span> and reduce the smaller number instead of the larger one. The two-bit PM algorithm <em>[x26]</em> reduces more bits per iteration than Stein’s algorithm and thus requires only <span class="math">2\\times</span> more iterations (1195) compared to Euclid’s algorithm. Since Euclid-based algorithms have low iteration counts but require expensive divisions, prior work improving Euclid has focused on optimizing iteration time over iteration count. Thus, most Euclid-based algorithms still require 598 iterations on average <em>[x15, x22]</em>.</p>

    <p class="text-gray-300">We next consider the number of iterations required for these algorithms in the worst-case. For Euclid’s algorithm, the maximum number of iterations is <span class="math">5\\log(\\min(a,b))</span> <em>[x18]</em>, with the Fibonacci numbers as inputs <em>[x14]</em>. While all Stein-based algorithms reduce at least one bit per iteration, only the two-bit PM algorithm reduces at least two bits when <span class="math">a,b</span> are odd. Thus, in the Stein family, this algorithm requires the lowest worst-case number of iterations: <span class="math">1.51<em>n+1</span>, where n is the input bitwidth </em>[x26]*. These equations closely track each other for the bitwidths in our applications. For 255-bit inputs, Euclid’s algorithm requires 384 iterations, which is marginally smaller than the two-bit PM’s 387.</p>

    <h4 id="sec-11" class="text-lg font-semibold mt-6">3.3.2 Iteration Time and Execution Time</h4>

    <p class="text-gray-300">Given the simplicity of operations in the two-bit PM algorithm, we expect the iteration time for the two-bit PM algorithm to be shorter than that for Euclid’s algorithm. Then, for the worst-case execution time, the similarity in the worst-case number of iterations between the two algorithms in Section 3.3.1 alone indicates that the two-bit PM algorithm will likely yield faster constant-time implementations. In the average case, the two-bit PM algorithm requires twice the number of iterations as Euclid’s algorithm. Thus, the two-bit PM can be faster overall if its hardware critical path is less than half of the critical path of Euclid’s algorithm. We find this to be the case when comparing 1024-bit hardware designs.</p>

    <p class="text-gray-300">Using two bits to represent each bit of a number is a redundant number representation called carry-save form (CSA form), and enables one to build adders with no carry propagation delays. Carry-save adders (CSAs) add three inputs and produce two outputs (the sum of the two outputs is equal to the sum of the three inputs) and have <span class="math">O(1)</span> instead of <span class="math">O(\\log(n))</span> delays, where <span class="math">n</span> is the input bitwidth <em>[x23, x19, x16, x26]</em>. These savings are especially important in wide-word arithmetic with large bitwidths. Since the actual result is not directly stored, the value of the result is not known and it thus cannot be compared to other values. The actual result can be recovered with a normal addition with carry propagation. We further describe CSAs in our hardware design in Section 4.2.</p>

    <p class="text-gray-300">Since XGCD algorithms require repeated additions, the iteration times for hardware designs can be reported in units of CSA delays, which also serves as a technology-agnostic unit. One CSA delay is approximately equal to the delay of two two-input XOR gates in series. Multiplier arrays also use CSAs to efficiently sum partial products <em>[x10, x17, x15, JLL^{+}15]</em>, so we can easily translate this operation into CSA delays. For non-CSA operations, we report latency in equivalent fractions of a CSA delay.</p>

    <p class="text-gray-300">The critical path for computing the XGCD with the two-bit PM algorithm consists of adding three numbers and shifting two bits to the right when <span class="math">a</span>, <span class="math">b</span>, and other variables are all odd (please see details in Section 4.1). Since shifting is a fast rewiring operation in hardware, we only consider the delay for the addition. This addition translates to adding five values in total: two values in CSA form and one constant. This operation requires three CSAs in series, where each CSA reduces three inputs into two outputs. We then multiply this critical path delay (three CSA delays) by the average iteration count (1195) to estimate the average execution time as 3585 CSA delays.</p>

    <p class="text-gray-300">The critical path for computing the XGCD with Euclid’s algorithm consists of generating the quotient <span class="math">q=\\max(a,b)/\\min(a,b)</span> and computing the remainder <span class="math">\\max(a,b)-q*\\min(a,b)</span>.</p>

    <p class="text-gray-300">The algorithm applies the Bézout coefficient updates in parallel with the GCD computation by similarly multiplying this quotient by the corresponding variables and subtracting. Thus, these operations do not increase the critical path delay. We denote <span class="math">a</span> as the larger number and rewrite the critical path computation as <span class="math">a-q*b</span> for the rest of this section.</p>

    <p class="text-gray-300">We first consider generating the quotient. Division algorithms are iterative, requiring repeated multiplication or subtraction. Multiplication-based division algorithms <em>[x10, x13]</em> are not competitive since each division would require hundreds of CSA delays for large-integer multiplications. However, subtraction-based division algorithms are also slow because they iterate bit-by-bit, requiring many iterations. Thus, Euclid-based algorithms instead avoid full-bitwidth divisions by looking at the most significant bits (MSBs) of the inputs to estimate quotients <em>[x16, x18, x19, x26]</em>. Using lookup tables (LUTs) is the fastest estimation approach. However, since only the MSBs are used, this estimate can be incorrect and the algorithm then needs to fall back to slow large-integer division.</p>

    <p class="text-gray-300">We find that even in the optimistic scenario where no large-integer divisions are required, the critical path delay for Euclid’s algorithm will be long enough such that it will be slower than the two-bit PM algorithm for overall execution time. We calculate critical path delay by splitting the computation into three steps and assigning a delay (in CSA delays) to each. These three steps are generating the quotient (<span class="math">q</span>), multiplying <span class="math">q</span> and <span class="math">b</span> (<span class="math">q<em>b</span>), and subtracting to generate the remainder (<span class="math">a-q</em>b</span>). For an optimistic estimate, we assume the lookup for the quotient estimate requires zero delay. The LUT takes pairs of the <span class="math">c</span> MSBs of <span class="math">a,b</span> as input, denoted <span class="math">a_{c},b_{c}</span>, respectively. Since <span class="math">a,b</span> are stored in CSA form, retrieving the values of <span class="math">a_{c},b_{c}</span> requires <span class="math">c</span>-bit carry-propagate adds. This requires <span class="math">\\lfloor log_{2}(c)\\rfloor+1</span> CSA delays for a binary logarithmic adder tree structure (three CSA delays for <span class="math">c=6</span>). Note that the LUT has <span class="math">2^{2*c}</span> entries and <span class="math">c</span> bits per entry. Thus, LUTs with <span class="math">c\\geq 10</span> require over a million entries and are impractical. We precompute the LUT entries for <span class="math">a_{c}/(b_{c}+2)</span> instead of <span class="math">a_{c}/b_{c}</span> to guarantee that the quotient estimate is not greater than the true quotient. Then, the LUT entry can be shifted to the left to obtain the quotient estimate, denoted <span class="math">q_{estimate}</span>.</p>

    <p class="text-gray-300">The next step computes the partial products for <span class="math">q_{estimate}<em>b</span>. Since <span class="math">b</span> is in CSA form, this becomes <span class="math">q_{estimate}</em>b_{carry}+q_{estimate}<em>b_{sum}</span>. Summing the partial products can be combined with the subtraction step for the final remainder as <span class="math">a-q_{estimate}</em>b_{carry}-q_{estimate}<em>b_{sum}</span>. First, we assume that generating the partial products takes zero delay since this minimally requires a few shifts, which are fast rewiring operations in hardware. We then need to sum <span class="math">2</em>c+2</span> values, where <span class="math">2<em>c</span> values represent the partial products and the last two values represent <span class="math">a</span> in CSA form. Since each CSA has three inputs and two outputs, we need an adder tree with roughly <span class="math">\\lfloor\\log_{3/2}(c)\\rfloor</span> CSAs in series (six CSA delays for <span class="math">c=6</span>). Finally, we sum the CSAs delays for generating <span class="math">q_{estimate}</span> and for evaluating the remainder <span class="math">a-q_{estimate}</em>b</span>, resulting in <span class="math">3+6=9</span> CSA delays for a six-bit <span class="math">q_{estimate}</span> example. We then multiply this delay (nine CSA delays) by the average iteration count (598) to estimate the average execution time for Euclid’s algorithm as 5382 CSA delays.</p>

    <p class="text-gray-300">Thus, even with our conservative estimate, the two-bit PM iteration time is <span class="math">3\\times</span> shorter than the Euclid iteration time. As a result, the two-bit PM execution time (3585 CSA delays) is <span class="math">1.5\\times</span> shorter than the Euclid execution time (5382 CSA delays) and we conclude that division-based XGCD is not competitive for hardware designs.</p>

    <h2 id="sec-12" class="text-2xl font-bold">4 Fast XGCD Algorithm and Hardware Design Space</h2>

    <p class="text-gray-300">Based on our analysis in Section 3, we build from the two-bit PM algorithm <em>[x27]</em>. Since this algorithm was originally not completely specified, especially regarding iterative updates for odd Bézout coefficient values, we first present a complete extended two-bit PM algorithm (Section 4.1). We then consider further optimizations that enable high-performance XGCD hardware acceleration: using carry-save adders (Section 4.2), increasing the number of bits reduced per iteration (Section 4.3), handling carry propagation for the termination</p>

    <p class="text-gray-300">Kavya Sreedhar, Mark Horowitz, and Christopher Torng</p>

    <p class="text-gray-300">XGCD Accelerator Execution Flow</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Pre-processing</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Iterations Loop (each iteration completes in one clock cycle)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Post-processing</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">(A)</td>

            <td class="px-3 py-2 border-b border-gray-700">(B),(C) → (B),(C) → (D) → loop until termination condition is satisfied (D)</td>

            <td class="px-3 py-2 border-b border-gray-700">(E)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">4 cycles</td>

            <td class="px-3 py-2 border-b border-gray-700">Worst-case 1548 cycles for Design (1) and 387 cycles for Design (2)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">12 cycles</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  Execution Time → |  |  |   |</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> (A) Pre-processing (D) Control flow</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a></p>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a> (E) Post-processing Figure 1: XGCD Execution Flow Diagram - Key components in the execution flow are broken out in detail. (A) Pre-processing step to generate odd inputs to iterations loop; (B) Update for  <span class="math">\\delta</span>  register; (C) Variable updates for  <span class="math">a, b, u, y, m, n</span>  registers in the iterations loop illustrating the wide parallel datapath with late selects (the logic for unique update types are shown in detail); (D) Control flow state diagram with termination condition; (E) Post-processing step to generate XGCD outputs.</p>

    <p class="text-gray-300">!<a href="img-3.jpeg">img-3.jpeg</a> (C) Variable  <span class="math">(\\mathbf{u},\\mathbf{y},\\mathbf{m},\\mathbf{n},\\mathbf{a},\\mathbf{b})</span>  updates</p>

    <p class="text-gray-300">condition for non-constant-time execution (Section 4.4), and minimizing control overhead (Section 4.5). Finally, we show how our design easily supports constant-time evaluation and polynomial XGCD (Section 4.6).</p>

    <p class="text-gray-300">Figure 1 shows the execution flow of our hardware with the sequence of operations on the critical path. Note that in our hardware design, we execute one iteration every clock cycle. Thus, the operations on the iteration critical path (Section 3.3.2) must finish in a single clock cycle and the maximum frequency is determined by this critical path delay.</p>

    <p class="text-gray-300">Listing 1 includes our variable definitions and pseudocode for our XGCD algorithm. This section explains the subset of the algorithm that corresponds to the two-bit PM algorithm and our extensions to compute the XGCD. Section 4.3 explains the additional updates included and their suitability for constant-time versus fast average-case evaluation.</p>

    <p class="text-gray-300">XGCD algorithms calculate Bézout coefficients by introducing four variables  <span class="math">u, m, y, n</span>  such that  <span class="math">u <em> a_{m} + m </em> b_{m} = a</span>  and  <span class="math">y <em> a_{m} + n </em> b_{m} = b</span>  hold true for inputs  <span class="math">a_{m}, b_{m}</span>  and variables  <span class="math">a, b</span>  in every iteration. We denote these relations together as Equation 1. At the start of the iterations loop,  <span class="math">a = a_{m}</span>  and  <span class="math">b = b_{m}</span> , so initially,  <span class="math">u = 1, m = 0</span>  and  <span class="math">y = 0, n = 1</span> .</p>

    <p class="text-gray-300">def xgcd(<span class="math">a_{0}</span>, <span class="math">b_{0}</span>, constant_time, bitwidth):</p>

    <p class="text-gray-300">if (<span class="math">a_{0}\\%2==0</span>): <span class="math">a_{m}=a_{0}+b_{0}</span>; <span class="math">b_{m}=b_{0}</span> elif (<span class="math">b_{0}\\%2==0</span>): <span class="math">a_{m}=a_{0}</span>; <span class="math">b_{m}=a_{0}+b_{0}</span> else: <span class="math">a_{m}=a_{0}</span>; <span class="math">b_{m}=b_{0}</span> if constant_time: iterations = 0</p>

    <p class="text-gray-300"><span class="math">a=a_{m}</span>; <span class="math">b=b_{m}</span>; <span class="math">u=1</span>; <span class="math">m=0</span>; <span class="math">y=0</span>; <span class="math">n=1</span>; <span class="math">\\delta=0</span>; end_loop=False</p>

    <p class="text-gray-300">def xgcd_update(num_bits_reduced, <span class="math">u</span>, <span class="math">m</span>, <span class="math">b_{m}</span>, <span class="math">a_{m}</span>): for i in range(num_bits_reduced): if <span class="math">u\\%2==1</span>: <span class="math">u=(u+b_{m})//2</span>; <span class="math">m=(m-a_{m})//2</span> else: <span class="math">u=u//2</span>; <span class="math">m=m//2</span> return (<span class="math">u,m</span>) while (not end_loop): if (not constant_time and (<span class="math">a\\%8==0</span>)): <span class="math">a=a//8</span>; <span class="math">\\delta=\\delta-3</span>; (<span class="math">u,m</span>) = xgcd_update(<span class="math">3</span>, <span class="math">u</span>, <span class="math">m</span>, <span class="math">b_{m}</span>, <span class="math">a_{m}</span>) elif (not constant_time and (<span class="math">a\\%4==0</span>)): <span class="math">a=a//4</span>; <span class="math">\\delta=\\delta-2</span>; (<span class="math">u,m</span>) = xgcd_update(<span class="math">2</span>, <span class="math">u</span>, <span class="math">m</span>, <span class="math">b_{m}</span>, <span class="math">a_{m}</span>) elif (<span class="math">a\\%2==0</span>): <span class="math">a=a//2</span>; <span class="math">\\delta=\\delta-1</span>; (<span class="math">u,m</span>) = xgcd_update(<span class="math">1</span>, <span class="math">u</span>, <span class="math">m</span>, <span class="math">b_{m}</span>, <span class="math">a_{m}</span>) elif (not constant_time and (<span class="math">b\\%8==0</span>)): <span class="math">b=b//8</span>; <span class="math">\\delta=\\delta+3</span>; (<span class="math">y,n</span>) = xgcd_update(<span class="math">3</span>, <span class="math">y</span>, <span class="math">n</span>, <span class="math">b_{m}</span>, <span class="math">a_{m}</span>) elif (not constant_time and (<span class="math">b\\%4==0</span>)): <span class="math">b=b//4</span>; <span class="math">\\delta=\\delta+2</span>; (<span class="math">y,n</span>) = xgcd_update(<span class="math">2</span>, <span class="math">y</span>, <span class="math">n</span>, <span class="math">b_{m}</span>, <span class="math">a_{m}</span>) elif (<span class="math">b\\%2==0</span>): <span class="math">b=b//2</span>; <span class="math">\\delta=\\delta+1</span>; (<span class="math">y,n</span>) = xgcd_update(<span class="math">1</span>, <span class="math">y</span>, <span class="math">n</span>, <span class="math">b_{m}</span>, <span class="math">a_{m}</span>) elif ((<span class="math">\\delta\\geq 0</span>) and ((<span class="math">b+a</span>)%<span class="math">4==0</span>)): <span class="math">a=(a+b)//4</span>; <span class="math">\\delta=\\delta-1</span>; (<span class="math">u,m</span>) = xgcd_update(<span class="math">2</span>, <span class="math">u+y</span>, <span class="math">m+n</span>, <span class="math">b_{m}</span>, <span class="math">a_{m}</span>) elif ((<span class="math">\\delta\\geq 0</span>) and ((<span class="math">b-a</span>)%<span class="math">4==0</span>)): <span class="math">a=(a-b)//4</span>; <span class="math">\\delta=\\delta-1</span>; (<span class="math">u,m</span>) = xgcd_update(<span class="math">2</span>, <span class="math">u-y</span>, <span class="math">m-n</span>, <span class="math">b_{m}</span>, <span class="math">a_{m}</span>) elif ((<span class="math">\\delta&lt;0</span>) and ((<span class="math">b+a</span>)%<span class="math">4==0</span>)): <span class="math">b=(a+b)//4</span>; <span class="math">\\delta=\\delta+1</span>; (<span class="math">y,n</span>) = xgcd_update(<span class="math">2</span>, <span class="math">u+y</span>, <span class="math">m+n</span>, <span class="math">b_{m}</span>, <span class="math">a_{m}</span>) else: <span class="math">b=(a-b)//4</span>; <span class="math">\\delta=\\delta+1</span>; (<span class="math">y,n</span>) = xgcd_update(<span class="math">2</span>, <span class="math">u-y</span>, <span class="math">m-n</span>, <span class="math">b_{m}</span>, <span class="math">a_{m}</span>)</p>

    <p class="text-gray-300">if constant_time: iterations = iterations + 1 end_loop = (iterations >= 1.51 * bitwidth + 1) else: end_loop = (<span class="math">a==0</span> or <span class="math">b==0</span>)</p>

    <p class="text-gray-300">gcd = <span class="math">a+b</span>; <span class="math">u=u+y</span>; <span class="math">m=m+n</span> if (<span class="math">a_{0}\\%2==0</span>): <span class="math">m=u+m</span> elif (<span class="math">b_{0}\\%2==0</span>): <span class="math">u=u+m</span> if gcd < 0: gcd = -gcd; <span class="math">u=-u</span>; <span class="math">m=-m</span> <span class="math">b_{a}=u</span>; <span class="math">b_{b}=m</span> return gcd,<span class="math">b_{a},b_{b}</span> Listing 1: Our XGCD algorithm (building from the two-bit PM GCD algorithm [YZ86])</p>

    <p class="text-gray-300">Kavya Sreedhar, Mark Horowitz, and Christopher Torng</p>

    <p class="text-gray-300">Table 3: Update possibilities for Bézout coefficient variables  <span class="math">u, m</span>  when  <span class="math">a</span>  is shifted by two.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Divisibility of u, m</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">uupdate</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">mupdate</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">u, m divisible by 4</td>

            <td class="px-3 py-2 border-b border-gray-700">u/4</td>

            <td class="px-3 py-2 border-b border-gray-700">m/4</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">u, m divisible by 2 but not 4</td>

            <td class="px-3 py-2 border-b border-gray-700">(u + 2 * b_m)/4</td>

            <td class="px-3 py-2 border-b border-gray-700">(m - 2 * a_m)/4</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">u + b_m, m - a_m divisible by 4</td>

            <td class="px-3 py-2 border-b border-gray-700">(u + b_m)/4</td>

            <td class="px-3 py-2 border-b border-gray-700">(m - a_m)/4</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">u + b_m, m - a_m divisible by 2 but not 4</td>

            <td class="px-3 py-2 border-b border-gray-700">(u + 3 * b_m)/4</td>

            <td class="px-3 py-2 border-b border-gray-700">(m - 3 * a_m)/4</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">During the iterations loop, the two-bit PM algorithm updates either  <span class="math">a</span>  or  <span class="math">b</span> . When  <span class="math">a</span>  is not updated, there is no need to update  <span class="math">u, m</span>  since Equation 1 automatically holds. The same is true for  <span class="math">b</span>  and  <span class="math">y, n</span> . When  <span class="math">a</span>  or  <span class="math">b</span>  is divided by two or four, we need to divide  <span class="math">u, m</span>  or  <span class="math">y, n</span>  by the same factor to maintain the relations in Equation 1. However, the divisibility of the coefficient variables may not match that of  <span class="math">a</span>  and  <span class="math">b</span> . For example, if odd coefficients are shifted right, their truncated values may not satisfy Equation 1.</p>

    <p class="text-gray-300">To address this problem, we consider the shift-by-one case first. If  <span class="math">a</span>  is even and thus divided by two, we need to ensure that  <span class="math">u_{update} <em> a_m + m_{update} </em> b_m = \\frac{a}{2}</span> . If the previous  <span class="math">u, m</span>  are even, the update is straightforward:  <span class="math">u_{update} = \\frac{a}{2}, m_{update} = \\frac{m}{2}</span> . If the previous  <span class="math">u, m</span>  are odd, we add  <span class="math">b_m</span>  to  <span class="math">u</span>  and subtract  <span class="math">a_m</span>  from  <span class="math">m</span>  as similarly done to extend the PM algorithm to compute XGCD [BK85]. Since  <span class="math">b_m, a_m</span>  are odd by construction and the sum of two odd numbers is even,  <span class="math">u + b_m, m - a_m</span>  will be even. Then, we can reduce one bit by computing  <span class="math">u_{update} = \\frac{u + b_m}{2}, m_{update} = \\frac{m - a_m}{2}</span> . This update preserves the relations in Equation 1 since we have added and subtracted  <span class="math">\\frac{a_m * b_m}{2}</span>  from the result.</p>

    <p class="text-gray-300">For the shift-by-two case, we apply our updates rules for the shift-by-one case twice to satisfy  <span class="math">u_{update} <em> a_m + m_{update} </em> b_m = \\frac{a}{4}</span> . The worst-case update rule is when  <span class="math">m</span>  is not divisible by two and  <span class="math">m - a_m</span>  is not divisible by four, resulting in  <span class="math">m_{update} = \\frac{\\frac{m - a_m}{2} - a_m}{2}</span> . To reduce this update delay, we rewrite this update as  <span class="math">\\frac{m - 3<em>a_m}{4}</span> . Note that this result is truncated the same way as the original result when shifting. Since  <span class="math">a_m</span>  is known at the start,  <span class="math">3 </em> a_m</span>  is a constant that we can precompute in a pre-processing step (A in Figure 1). Table 3 shows how we similarly rewrite the other  <span class="math">u, m</span>  updates. Thus, the worst-case update delay is half the original form and similar to the shift-by-one case.</p>

    <p class="text-gray-300">While half of the updates in the two-bit PM algorithm directly reduce bits from  <span class="math">a</span>  or  <span class="math">b</span>  (when  <span class="math">a</span>  or  <span class="math">b</span>  is even), the other half reduce two bits from  <span class="math">a \\pm b</span>  (when  <span class="math">a, b</span>  are odd). To preserve the relations in Equation 1 in these other updates, we apply the shift-by-two strategy on  <span class="math">u \\pm y</span> ,  <span class="math">m \\pm n</span>  instead of individually on  <span class="math">u, y, m, n</span>  (i.e., substitute  <span class="math">u</span>  with  <span class="math">u \\pm y</span>  and  <span class="math">m</span>  with  <span class="math">m \\pm n</span>  in Table 3). Thus, the critical path in this algorithm has two subtractions and one right shift to compute  <span class="math">\\frac{m - n - 3*a_m}{4}</span>  as an update for  <span class="math">m</span> , which requires one extra subtraction compared to the worst-case updates for  <span class="math">m</span>  when  <span class="math">a</span>  or  <span class="math">b</span>  is even. This finishes extending the variable updates in the iterations loop for the XGCD (C in Figure 1).</p>

    <p class="text-gray-300">Finally, we consider necessary pre-processing and post-processing steps. Typically, GCD algorithms assume that the inputs have no common factors of two since such factors can be easily accounted for by shifting before the iterations loop and then shifting the common factor back in at the end. As a result, at most one input may be even. In this case, we apply a pre-processing step (A in Figure 1) that replaces the even input with the sum of the inputs to ensure that the inputs to the iterations loop are odd, as done in prior work [YZ86]. In a post-processing step after the iterations loop (E in Figure 1), we calculate the Bézout coefficients as  <span class="math">b_{a} = u + y</span>  and  <span class="math">b_{b} = m + n</span>  since  <span class="math">a + b</span>  is the GCD and adding the relations in Equation 1 results in  <span class="math">(u + y)<em>a_{m} + (m + n)</em>b_{m} = a + b = GCD(a_{m},b_{m})</span> . If we applied the pre-processing step, we need to replace the even input's Bézout coefficient with the sum of the coefficients to satisfy Equation 1. If the gcd is negative (due to updating the smaller number when incorrectly approximating  <span class="math">a &amp;gt; b</span> ), we negate the gcd and coefficients.</p>

    <p class="text-gray-300">4.2 Carry-Save Adders</p>

    <p class="text-gray-300">As previewed in Section 3.3.2, carry-save adder (CSA) designs improve the delay of back-to-back additions by removing carry propagation in all intermediate computations and storing the resulting sum in CSA form. As a result, CSAs have been used for many cryptography applications <em>[x18, x26, x22]</em>. Since CSAs have constant delays, an added benefit is that the clock frequency for such designs will not be sensitive to the input bitwidth.</p>

    <p class="text-gray-300">We keep our main variables <span class="math">(a,b,u,y,m,n)</span> in CSA form while constants (<span class="math">a_{m},b_{m}</span> and their multiples) are not kept in CSA form since they do not change. The approximate difference of <span class="math">a</span> and <span class="math">b</span> is not stored in CSA form since its sign determines which value to update when both <span class="math">a,b</span> are odd. Fortunately, we use binary logarithms for this approximation, so this value is small (e.g., ten bits for 1024-bit inputs) and updates for this variable (B in Figure 1) do not limit cycle time. While prior work has also suggested using CSAs for GCD algorithms <em>[x23, x30]</em>, we find that using CSAs in practice in an XGCD hardware design surfaces challenges that have not been previously addressed:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>To ensure the carry-propagate adds required in our pre-processing and post-processing steps do not limit the cycle time, we run these steps at one-quarter of the clock frequency of the system clock. As shown in Figure 1, this slower frequency allows these few cycles at the start and end to support the longer carry propagation while keeping the short CSA-defined cycle time as our system clock period.</li>

      <li>When <span class="math">carry</span> and <span class="math">sum</span> are shifted right (and inherently truncated) in CSA form, we must efficiently add one to the result in the case where summing the bits that were shifted out would have generated a carry. Note that we cannot simply set the lowest bit of <span class="math">carry</span> or <span class="math">sum</span> to one, since these bits can both be one after a shift. Thus, we instead use a full-bitwidth half adder to add the shifted <span class="math">carry</span> and <span class="math">sum</span> to produce another (<span class="math">carry</span>, <span class="math">sum</span>) pair for the same number represented in CSA form, where the lowest bit of the <span class="math">carry</span> output will be zero by design. We can set that bit to one when needed. This adds one XOR gate delay to the critical path delay.</li>

      <li>We approximate <span class="math">a&gt;b</span> when <span class="math">a,b</span> are odd, as done in prior work <em>[x1]</em>. If this approximation is incorrect, we update the smaller number and our variables become negative. Thus, when shifting right, we need to preserve sign in CSA form (even though it is unknown). Earlier work provides a truth table relating the two most significant bits of <span class="math">carry</span> and <span class="math">sum</span> before and after shifting to preserve sign <em>[x24]</em>. We adapt and extend this prior work to determine balanced equations for these bits for right shifts by several bits in CSA form to minimize the critical path delay.</li>

    </ul>

    <h3 id="sec-28" class="text-xl font-semibold mt-8">4.3 Optimal Reduction of Bits Per Cycle</h3>

    <p class="text-gray-300">Stein-based algorithms reduce the average number of iterations required by removing factors of two or four when possible. The higher the factor of two that can be removed per iteration, the fewer the iterations required. While removing these factors by shifting is cheap, this increases the number of update choices for <span class="math">u,y,m,n</span> since they may not be divisible by powers of two. This added control logic can increase the cycle time if deciding which branch to take becomes more expensive than computing the variable updates.</p>

    <p class="text-gray-300">We explore this hardware design space to quantify the tradeoff between the cycle time and the average- and worst-case number of clock cycles required in order to determine the optimal reduction of bits per cycle. We separately vary the maximum reduction factor for updates when <span class="math">a</span> or <span class="math">b</span> is even and updates when <span class="math">a</span> and <span class="math">b</span> are odd (referred to as even and odd reduction factors) to see which parameterizations yield a net benefit for total execution time, the product of the number of clock cycles and the cycle time.</p>

    <p class="text-gray-300">We update <span class="math">a,b</span> with <span class="math">\\frac{a-b}{2}</span> for an odd reduction factor of two since <span class="math">a-b</span> will be even when <span class="math">a,b</span> are odd. Using the procedure in Section 4.1, we support an odd reduction factor</p>

    <p class="text-gray-300">Kavya Sreedhar, Mark Horowitz, and Christopher Torng</p>

    <p class="text-gray-300">Table 4: Execution time and area in 16nm technology for 1024-bit XGCD ASIC designs for various even and odd reduction factor combinations.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Max factor of two reduced when a or b is even</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Max factor of two reduced when a and b are odd</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Average Number of Cycles</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Cycle Time (ns)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">XGCD Execution Time (ns)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">ASIC Area (mm2)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

            <td class="px-3 py-2 border-b border-gray-700">2214</td>

            <td class="px-3 py-2 border-b border-gray-700">0.193</td>

            <td class="px-3 py-2 border-b border-gray-700">427</td>

            <td class="px-3 py-2 border-b border-gray-700">0.16</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">4</td>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

            <td class="px-3 py-2 border-b border-gray-700">1849</td>

            <td class="px-3 py-2 border-b border-gray-700">0.218</td>

            <td class="px-3 py-2 border-b border-gray-700">403</td>

            <td class="px-3 py-2 border-b border-gray-700">0.22</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">8</td>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

            <td class="px-3 py-2 border-b border-gray-700">1744</td>

            <td class="px-3 py-2 border-b border-gray-700">0.256</td>

            <td class="px-3 py-2 border-b border-gray-700">446</td>

            <td class="px-3 py-2 border-b border-gray-700">0.36</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

            <td class="px-3 py-2 border-b border-gray-700">4</td>

            <td class="px-3 py-2 border-b border-gray-700">1454</td>

            <td class="px-3 py-2 border-b border-gray-700">0.234</td>

            <td class="px-3 py-2 border-b border-gray-700">340</td>

            <td class="px-3 py-2 border-b border-gray-700">0.22</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">4</td>

            <td class="px-3 py-2 border-b border-gray-700">4</td>

            <td class="px-3 py-2 border-b border-gray-700">1215</td>

            <td class="px-3 py-2 border-b border-gray-700">0.247</td>

            <td class="px-3 py-2 border-b border-gray-700">300</td>

            <td class="px-3 py-2 border-b border-gray-700">0.28</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">8</td>

            <td class="px-3 py-2 border-b border-gray-700">4</td>

            <td class="px-3 py-2 border-b border-gray-700">1147</td>

            <td class="px-3 py-2 border-b border-gray-700">0.257</td>

            <td class="px-3 py-2 border-b border-gray-700">295</td>

            <td class="px-3 py-2 border-b border-gray-700">0.41</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

            <td class="px-3 py-2 border-b border-gray-700">8</td>

            <td class="px-3 py-2 border-b border-gray-700">1095</td>

            <td class="px-3 py-2 border-b border-gray-700">0.297</td>

            <td class="px-3 py-2 border-b border-gray-700">325</td>

            <td class="px-3 py-2 border-b border-gray-700">0.27</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">4</td>

            <td class="px-3 py-2 border-b border-gray-700">8</td>

            <td class="px-3 py-2 border-b border-gray-700">976</td>

            <td class="px-3 py-2 border-b border-gray-700">0.320</td>

            <td class="px-3 py-2 border-b border-gray-700">312</td>

            <td class="px-3 py-2 border-b border-gray-700">0.33</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">8</td>

            <td class="px-3 py-2 border-b border-gray-700">8</td>

            <td class="px-3 py-2 border-b border-gray-700">942</td>

            <td class="px-3 py-2 border-b border-gray-700">0.330</td>

            <td class="px-3 py-2 border-b border-gray-700">311</td>

            <td class="px-3 py-2 border-b border-gray-700">0.47</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">of up to eight. Our efficient rewriting of the updates requires us to compute  <span class="math">k <em> b_{m}</span>  and  <span class="math">k </em> a_{m}</span>  for  <span class="math">k = 1</span>  to  <span class="math">k = 7</span>  for the three-bit reductions and does not increase the data path delay compared to a design with an odd reduction factor of four. Note that the following (even, odd) maximum reduction factor pairs correspond to reduction factors of two in prior GCD algorithms: (2, 1) is Stein's, (2, 2) is Purdy's and PM, and (4, 4) is two-bit PM.</p>

    <p class="text-gray-300">Table 4 shows the execution time and area for various reduction factor pairs and all optimizations in Section 4. The longest sequence of operations is updating  <span class="math">m, n</span>  when  <span class="math">a, b</span>  are odd. This is the critical path for all the designs but the (8, 8) design, where the critical path becomes the control path. Finally, since the execution time for designs with an odd reduction factor of eight does not improve compared to designs with an odd reduction factor of four, factors of  <span class="math">16+</span>  would not be beneficial due to the longer control path delay.</p>

    <p class="text-gray-300">We observe that the execution times for these designs are close, especially if the odd reduction factor is the same. Thus, while average number of cycles is reduced when more bits are reduced per cycle, the resulting increase in the cycle time mostly negates that benefit. Choosing which design to use depends on the target application requirements, namely the number of XGCDs computed and whether XGCD must be constant-time.</p>

    <p class="text-gray-300">These small execution time differences become important when this computation is repeated many times. Since most VDF applications require a large delay, we may need to compute over a million or billion squarings, each of which requires two XGCDs in the NUDUPL algorithm. In this context, the five-nanosecond difference between the (4, 4) and (8, 4) designs becomes critical. Since this application requires high performance, the fastest design — the (8, 4) design — would be most appropriate.</p>

    <p class="text-gray-300">For constant-time applications like modular inversion for Curve25519, we consider the worst-case number of cycles to determine the optimal reduction factors. The two-bit PM algorithm — corresponding to the (4, 4) design — takes a maximum of  <span class="math">1.51n + 1</span>  cycles for n-bit inputs [YZ86] since every cycle, at least one bit is reduced if  <span class="math">a</span>  or  <span class="math">b</span>  is even and two bits are reduced if they are both odd (since either  <span class="math">a + b</span>  or  <span class="math">a - b</span>  will be divisible by four). The two-bit PM algorithm [YZ86] notes that reducing three bits — corresponding to the (8, 8) design — will not reduce the worst-case number of cycles because there is no guarantee that  <span class="math">a + b</span>  or  <span class="math">a - b</span>  will be divisible by eight when  <span class="math">a, b</span>  are odd (just as  <span class="math">a, b</span>  may not be divisible by eight when they are even), so these branches may never be taken.</p>

    <p class="text-gray-300">We observe that this logic also applies for the (2, 8), (4, 8), (2, 4), and (8, 4) designs since the only guaranteed transitions remain dividing by two when  <span class="math">a, b</span>  are even and dividing  <span class="math">a + b</span>  or  <span class="math">a - b</span>  by four when  <span class="math">a, b</span>  are odd. Thus, shifting by more than one bit when  <span class="math">a, b</span>  are even or more than two bits when  <span class="math">a, b</span>  are odd only adds further value for the average case, not the worst case. In addition, the average execution times for the designs</p>

    <p class="text-gray-300">with an odd reduction factor of two is higher than the worst-case execution time for the other designs, so these designs are not competitive in this context. Thus, the optimal reduction factors for constant-time applications are (2, 4).</p>

    <h3 id="sec-29" class="text-xl font-semibold mt-8">4.4 Termination Condition Carry Propagation</h3>

    <p class="text-gray-300">For non-constant-time XGCD execution, algorithms terminate when <span class="math">a</span> or <span class="math">b</span> is zero (D in Figure 1). However, when <span class="math">a,b</span> are in CSA form, their values are not known. Computing two carry-propagate adds in parallel to find <span class="math">a=a_{carry}+a_{sum}</span> and <span class="math">b=b_{carry}+b_{sum}</span> every cycle would negate the benefit of using CSAs. As a more minor concern, this operation also requires a large AND-gate tree to check whether all the bits of <span class="math">a,b</span> are zero. We investigate two approaches to improve the delay of this termination condition check.</p>

    <p class="text-gray-300">Our first approach computes our variable updates for each iteration in a clock cycle, while in parallel, <span class="math">a=a_{carry}+a_{sum}</span> and <span class="math">b=b_{carry}+b_{sum}</span> are computed over <span class="math">x</span> cycles. The true values of <span class="math">a,b</span> are then sampled every <span class="math">x</span> cycles. For 1024-bit inputs, <span class="math">x=4</span> ensures that these additions do not limit the cycle time. With this approach, we can only check if the termination condition has been satisfied every four cycles and at most require four extra iterations to compute the XGCD. This is a very small overhead: 0.18% to 0.42% of the number of cycles for the (2, 2) to (8, 8) reduction factor designs (Section 4.3).</p>

    <p class="text-gray-300">Our second approach repurposes <span class="math">\\alpha\\approx\\log_{2}(a),\\beta\\approx\\log_{2}(b)</span> from the PM algorithm <em>[x10]</em>. In prior work, these variables approximate <span class="math">a&gt;b</span> and are updated every cycle by the minimum number of bits <span class="math">a,b</span> will be reduced by. We instead use <span class="math">\\alpha,\\beta</span> in our termination condition: when <span class="math">\\alpha</span> or <span class="math">\\beta</span> is zero, we run one more iteration (to ensure <span class="math">a</span> or <span class="math">b</span> is zero since <span class="math">\\alpha,\\beta</span> can be zero when <span class="math">a,b</span> are one) and initiate the post-processing step. Since the termination condition no longer checks <span class="math">a,b</span>, we avoid the carry-propagation for <span class="math">a=a_{carry}+a_{sum}</span> and <span class="math">b=b_{carry}+b_{sum}</span>. In addition, we reduce the AND-gate tree delay by checking whether <span class="math">\\log_{2}(a)+\\log_{2}(b)</span> bits are zero instead of the number of bits for <span class="math">a,b</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">However, <span class="math">\\alpha,\\beta</span> can significantly diverge from the true values of <span class="math">\\log_{2}(a),\\log_{2}(b)</span>. For example, when <span class="math">a</span> is updated with <span class="math">a-b</span>, multiple bits may be reduced, but <span class="math">\\alpha</span> is only updated with <span class="math">\\alpha-1</span>. Thus, checking if <span class="math">\\alpha,\\beta</span> are equal to zero instead of <span class="math">a,b</span> adds 150+ cycles for 1024-bit inputs (a 7 to 16% overhead for different reduction factor designs). We experimented with correcting <span class="math">\\alpha,\\beta</span> to the true values of <span class="math">\\log_{2}(a),\\log_{2}(b)</span> as often as possible. This requires computing 1024-bit carry-propagate adds to produce <span class="math">a,b</span>, the absolute values of <span class="math">a,b</span> (since <span class="math">a,b</span> can be negative), and $\\log_{2}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">),\\log_{2}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">. We ran these operations in parallel to the variable updates and, as in the sampling approach, found that these operations can complete every four cycles without limiting our cycle time. While this approach is functional, the sampling approach without </span>\\alpha,\\beta$ requires less computation and also runs in parallel to the iterations loop. Thus, our design uses the first approach.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-30" class="text-xl font-semibold mt-8">4.5 Minimal Control Overhead</h3>

    <p class="text-gray-300">Having improved the data path delay, we focus on minimizing the control path delay. We note that our control logic for detecting divisibility by factors of two is not as simple as checking if bits are zero since our variables are in CSA form. To minimize the delay for this logic, we duplicate computation to allow control signals to arrive as late as possible (late selects) and precompute control signals each cycle for the next cycle’s branching decisions.</p>

    <p class="text-gray-300">First, we use late selects. Either <span class="math">a,u,m</span> or <span class="math">b,y,n</span> is updated every cycle. The update logic for these values is identical but requires different inputs. Re-purposing the same hardware to perform these updates would add an extra two-to-one multiplexer before each input, doubling the number of branches. Thus, we intentionally duplicate hardware for separate update modules for <span class="math">a,b</span> and <span class="math">u,y,m,n</span> to allow control signals to arrive late in the cycle. We also apply this parallel computation and late select strategy wherever possible</p>

    <p class="text-gray-300">within all the update modules, avoiding redundant computation for updates that use the same inputs regardless of the updated variable (e.g., <span class="math">a\\pm b</span> is computed only once).</p>

    <p class="text-gray-300">Second, we precompute control signals. For 1024-bit inputs, our control signals determine the updates for 1028-bit numbers since several extra bits account for carry bits from repeated addition. As a result, these gates have very high fanout. For a (4, 4) reduction factor pair design, we initially observed that the critical path was the control path and not the data path due to long delays of 0.15ns from several large buffers in 16nm designs. To reduce this delay, we compute the control signals that determine which branch to take for the next cycle in parallel with the updates for <span class="math">a,b,u,y,m,n</span>, rather than generating this control from the values computed in the same cycle. For example, when we update <span class="math">u</span>, we compute whether the updated <span class="math">u</span> for the next cycle will be divisible by factors of two by computing the divisibility of all the possible <span class="math">u</span> update options in parallel. Then, we select the control signal update based on the <span class="math">u</span> update chosen. To similarly compute the divisibility of <span class="math">a\\pm b</span>, <span class="math">u\\pm y</span>, and <span class="math">n\\pm m</span> for the next cycle, we add a few XORs (<span class="math">\\approx 20</span>ps each in 16nm), which is significantly smaller than the 0.15ns large buffer delay. Due to this optimization, the critical path is the data path for our designs, except for the (8, 8) reduction factor pair. In the (8, 8) design, the disproportional increase in the number of branches compared to the increase in computation makes the control path dominant.</p>

    <h3 id="sec-31" class="text-xl font-semibold mt-8">4.6 Extensions</h3>

    <p class="text-gray-300">Our design supports constant-time XGCD and polynomial XGCD execution. For constant-time XGCD, we pad our algorithm so that it always runs for its worst-case execution time (D in Figure 1). Note that running beyond the nominal termination condition still yields the correct answer. Since inputs to the iterations loop have no common factors of two, the XGCD has been found when either <span class="math">a</span> or <span class="math">b</span> is zero and the other is an odd value. With padding, the algorithm will continually detect the zero as even and divide it by two. Since all variables are in CSA form, we do not know when they become zero. Thus, we can keep track of the number of cycles and exit the iterations loop when that count is equal to the worst-case cycle count. The (2, 4) reduction factor pair is most optimal for constant-time XGCD and requires <span class="math">1.51*n+1</span> iterations for n-bit inputs (Section 4.3).</p>

    <p class="text-gray-300">We can use the same algorithmic control flow to find the XGCD between two polynomials with integer coefficients by describing the polynomial equivalents for all the integer XGCD operations required, building from prior work <em>[x1, x2]</em>. The polynomial equivalent of reducing factors of two, the smallest prime, is reducing factors of <span class="math">x</span> (<span class="math">x,x^{2},x^{3}</span>, etc.), i.e., reducing the polynomial degree. Similarly, evenness translates to polynomial divisibility by <span class="math">x</span>. To ensure adding “odd” polynomials guarantees an “even” result (like with integers), we can multiply the polynomials by the other polynomial’s constant term to enable cancelling the constant terms in addition <em>[x2]</em>. For comparisons, we compare polynomial degrees. To find the XGCD, we maintain the relations in Equation 1 each iteration: <span class="math">a_{m},b_{m}</span> are now polynomials, where <span class="math">a_{m}=a</span> if <span class="math">a</span> is not divisible by <span class="math">x</span> or <span class="math">a/x</span> if <span class="math">a</span> is, and similarly for <span class="math">b_{m}</span> with <span class="math">b</span>. Then, we initialize <span class="math">u=1,m=0</span> and <span class="math">y=0,n=1</span>, as with integer GCD, and apply the same updates, with shifts converted to divisions by <span class="math">x</span>.</p>

    <h2 id="sec-32" class="text-2xl font-bold">5 Complete Hardware Accelerators for Target Applications</h2>

    <p class="text-gray-300">Since XGCD directly implements constant-time modular inversion (the first Bézout coefficient is itself the modular inverse), we accelerate the remaining operations required for the NUDUPL algorithm (Section 2.1) in this section (summarized in Table 5). Since the additions on the critical path are in isolation, there is no benefit to using CSAs and we use efficient adders from our synthesis tool library. After the first XGCD, every execution requires a single modular multiplication. Since this operation is not repeated, conventional</p>

    <p class="text-gray-300">A Fast Large-Integer Extended GCD Algorithm and Hardware Design</p>

    <p class="text-gray-300">Table 5: Critical path operations and our implementations for the NUDUPL algorithm.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Operation (Op)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Implementation</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Op Runtime (ns)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Count</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Total Runtime (ns)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Addition</td>

            <td class="px-3 py-2 border-b border-gray-700">Designware</td>

            <td class="px-3 py-2 border-b border-gray-700">0.159</td>

            <td class="px-3 py-2 border-b border-gray-700">51</td>

            <td class="px-3 py-2 border-b border-gray-700">8</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|   |  Parallel-Prefix Adder |  |  |   |</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Multiplication</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Toom-3</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">17.58</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">54</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">949</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">XGCD</td>

            <td class="px-3 py-2 border-b border-gray-700">Our design with (8, 4) reduction factors</td>

            <td class="px-3 py-2 border-b border-gray-700">295</td>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

            <td class="px-3 py-2 border-b border-gray-700">590</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Total</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">1547</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">techniques like Montgomery multiplication (which converts to an intermediate representation) and Barrett Reduction (which precomputes constants) are expensive. Given that this operation minimally contributes to execution time, we use a straightforward approach and compute  <span class="math">x = y <em> z</span>  (mod  <span class="math">a</span> ) as a multiplication ( <span class="math">m_1 = y </em> z</span> ), division ( <span class="math">d = m_1 / a</span> ), another multiplication ( <span class="math">m_2 = d * a</span> ), and a subtraction for ( <span class="math">m_1 - m_2</span> ), all with 1024-bit inputs.</p>

    <p class="text-gray-300">The Karatsuba algorithm recursively splits a large-integer multiplication into three smaller multiplications and a few additions and shifts until a base case input bitwidth [Kar63]. Several papers have implemented this algorithm in hardware  <span class="math">\\left[\\mathrm{wMZ}^{+}08\\right.</span> , vzGS05, ROH17,  <span class="math">\\mathrm{ZST}^{+}20]</span> . However, the Toom-Cook polynomial algorithm is more efficient and general [Too63, CA69, BZ07]. It splits numbers into  <span class="math">k</span>  parts ( <span class="math">k = 3</span>  for Toom-3, which we implement) to use as polynomial coefficients, finds the product of evaluating these polynomials at various points to find the product polynomial, and then uses the product's coefficients to find the integer product. This algorithm is well-suited for our inputs since it is faster than asymptotically fast algorithms for numbers smaller than  <span class="math">2^{2^{15}}</span>  [Sch77]. However, few hardware designs use Toom-Cook [GL18, DLG18] since it requires an expensive hardware operation, division by three. We reduce the cost of this division by rewriting this problem as  <span class="math">\\frac{x}{3} + \\frac{2x}{3} = x</span> , as shown in Listing 2. Given  <span class="math">x_0 \\ldots x_{n-1}</span> , we solve for  <span class="math">y = \\frac{x}{3}</span>  bit by bit, starting from the least significant bit with  <span class="math">y_0 = x_0</span> . Note that  <span class="math">y_{n-1} = 0</span>  is also known, since dividing by three reduces at least one bit.</p>

    <p class="text-gray-300">!<a href="img-4.jpeg">img-4.jpeg</a></p>

    <p class="text-gray-300">Listing 2: Rewriting  <span class="math">\\frac{x}{3}</span>  as  <span class="math">x - \\frac{2x}{3}</span>  to reduce the complexity of division by three in Toom-3.</p>

    <p class="text-gray-300">The Newton-Raphson [Fly70] and Goldschmidt [Gol64] algorithms are often used for fast division. They initially estimate the reciprocal of the divisor and then iteratively multiply to refine this estimate. Few papers implement division in hardware [HSGJ10, ZST+20]. The NUDUPL critical path requires two divisions with 2048-bit dividends and 1024-bit divisors. Since these divisions constitute a small portion of total execution time, we directly implement the Newton-Raphson algorithm with Toom-3 multiplication. We include the additions and multiplications required for this division under those operations in Table 5.</p>

    <p class="text-gray-300">We use a vertically integrated methodology spanning cycle-level performance modeling, VLSI-level modeling, and detailed physical design. We wrote our RTL in Kratos 0.0.33 [Zha], a hardware design language capable of generating SystemVerilog, and built a testbench with Fault 3.052  <span class="math">\\mathrm{[THS^{+}20]}</span>  to verify our designs with our functional model in Python for various parameterizations (bitwidth, reduction factors, constant time support) and randomly-generated inputs. We use mflowgen 0.3.1  <span class="math">\\mathrm{[CTN^{+}22]}</span>  for our physical design flow, with Synopsys DC 2019.03 for synthesis and Cadence Innovus 19.10.000 for floorplan, power, place, clock tree synthesis, and route. We report post layout signoff numbers.</p>

    <p class="text-gray-300">Kavya Sreedhar, Mark Horowitz, and Christopher Torng</p>

    <p class="text-gray-300">Table 6: XGCD critical path breakdown for 1024-bit Design (1) and 255-bit Design (2).</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Operation</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Design (1) Delay (ns)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Design (1) FO4 Inv Delay</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Design (2) Delay (ns)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Design (2) FO4 Inv Delay</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">DFF clk to Q</td>

            <td class="px-3 py-2 border-b border-gray-700">0.040</td>

            <td class="px-3 py-2 border-b border-gray-700">4.4</td>

            <td class="px-3 py-2 border-b border-gray-700">0.045</td>

            <td class="px-3 py-2 border-b border-gray-700">5</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Inverter</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0.007</td>

            <td class="px-3 py-2 border-b border-gray-700">0.8</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Add u + y: CSA 1</td>

            <td class="px-3 py-2 border-b border-gray-700">0.039</td>

            <td class="px-3 py-2 border-b border-gray-700">4.3</td>

            <td class="px-3 py-2 border-b border-gray-700">0.018</td>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Add u + y: CSA 2</td>

            <td class="px-3 py-2 border-b border-gray-700">0.039</td>

            <td class="px-3 py-2 border-b border-gray-700">4.3</td>

            <td class="px-3 py-2 border-b border-gray-700">0.031</td>

            <td class="px-3 py-2 border-b border-gray-700">3.4</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Buffer</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0.013</td>

            <td class="px-3 py-2 border-b border-gray-700">1.4</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Add u + y + 2bm: CSA</td>

            <td class="px-3 py-2 border-b border-gray-700">0.034</td>

            <td class="px-3 py-2 border-b border-gray-700">3.8</td>

            <td class="px-3 py-2 border-b border-gray-700">0.030</td>

            <td class="px-3 py-2 border-b border-gray-700">3.3</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Shift in CSA form</td>

            <td class="px-3 py-2 border-b border-gray-700">0.018</td>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

            <td class="px-3 py-2 border-b border-gray-700">0.015</td>

            <td class="px-3 py-2 border-b border-gray-700">1.7</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Late select multiplexers</td>

            <td class="px-3 py-2 border-b border-gray-700">0.018</td>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

            <td class="px-3 py-2 border-b border-gray-700">0.018</td>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Precomputing control</td>

            <td class="px-3 py-2 border-b border-gray-700">0.022</td>

            <td class="px-3 py-2 border-b border-gray-700">2.4</td>

            <td class="px-3 py-2 border-b border-gray-700">0.027</td>

            <td class="px-3 py-2 border-b border-gray-700">3</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Setup Time</td>

            <td class="px-3 py-2 border-b border-gray-700">0.005</td>

            <td class="px-3 py-2 border-b border-gray-700">0.56</td>

            <td class="px-3 py-2 border-b border-gray-700">0.002</td>

            <td class="px-3 py-2 border-b border-gray-700">0.22</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Clock Skew</td>

            <td class="px-3 py-2 border-b border-gray-700">0.041</td>

            <td class="px-3 py-2 border-b border-gray-700">4.6</td>

            <td class="px-3 py-2 border-b border-gray-700">0.016</td>

            <td class="px-3 py-2 border-b border-gray-700">1.8</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Total</td>

            <td class="px-3 py-2 border-b border-gray-700">0.257</td>

            <td class="px-3 py-2 border-b border-gray-700">28.6</td>

            <td class="px-3 py-2 border-b border-gray-700">0.220</td>

            <td class="px-3 py-2 border-b border-gray-700">24.4</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We evaluate two parameterizations of our ASIC design: Design (1) is a 1024-bit XGCD with (8, 4) reduction factors for squaring binary quadratic forms over class groups, and Design (2) is a 255-bit constant-time XGCD with (2, 4) reduction factors for modular inversion for Curve25519. Both designs are in TSMC  <span class="math">16\\mathrm{nm}</span> , using SVT, LVT, and ULVT libraries at  <span class="math">0.8\\mathrm{V}</span> . Table 6 shows the critical path delay breakdown for the designs. We include technology-agnostic delays in units of inverter fanout-of-4 (FO4) delays [HHWH97], with the  <span class="math">16\\mathrm{nm}</span>  ULVT FO4 delay as 9ps. Since both designs have an odd reduction factor of four, they have identical critical paths limited by the same worst-case sequence of operations. As expected from Section 4.1, the critical path requires three CSAs to add the Bézout coefficient variables and a multiple of  <span class="math">b_{m}</span>  or  <span class="math">a_{m}</span>  when  <span class="math">a</span> ,  <span class="math">b</span> , and these variables are odd. Then, we need to preserve sign when shifting in CSA form and use a full-bitwidth half-adder to correctly truncate these results. Finally, we use late selects to choose our variable updates and precompute control signals for the next cycle. The extra inverter and buffer delays in Design (2) compared to Design (1) are not tied to specific logic and reflect stochastic decisions made by the physical design tools. Our critical path includes clock skew delay that could be removed with manual optimization. We conservatively assume it remains in the critical path. Since we use CSAs, our designs have similar cycle times even though Design (1) has a  <span class="math">4\\times</span>  longer input bitwidth.</p>

    <p class="text-gray-300">The post layout areas for our Design (1) and (2) ASICs are  <span class="math">0.41mm^2</span>  and  <span class="math">0.059mm^2</span>  ( <span class="math">0.26mm^2</span>  and  <span class="math">0.04mm^2</span>  for standard cells excluding physical cells), respectively. The modules to update the Bézout coefficient variables comprise the majority of the standard cells area ( <span class="math">68\\%</span>  and  <span class="math">61\\%</span>  in Designs (1) and (2), respectively), since they have the most update possibilities and we duplicate computation for late selects (Section 4.5). We compute the  <span class="math">u \\pm y</span>  and  <span class="math">m \\pm n</span>  updates only in the update  <span class="math">u, m</span>  modules since they are the same for  <span class="math">(u, y)</span>  and  <span class="math">(m, n)</span> . Thus, the  <span class="math">u, m</span>  modules in Designs (1) and (2) are respectively  <span class="math">2 \\times</span>  and  <span class="math">5 \\times</span>  bigger than the  <span class="math">y, n</span>  modules. The  <span class="math">m, n</span>  modules are slightly larger, since the  <span class="math">m, n</span>  updates require subtractions with  <span class="math">a_m</span>  while  <span class="math">u, y</span>  updates require additions with  <span class="math">b_m</span> .</p>

    <p class="text-gray-300">In Table 7, we compare Design (1) to prior software, FPGA, and ASIC designs. We ran the GNU Multiple Precision Arithmetic Library (GMP) XGCD C++ function optimized for large integers on a 2020 MacBook Pro with the M1 chip in  <span class="math">5\\mathrm{nm}</span> , compiled with  <span class="math">\\mathrm{g}++</span>  and -O3 optimization. We use the standard C++ chrono library with nanosecond precision to profile this code with random 1024-bit inputs. Our  <span class="math">16\\mathrm{nm}</span>  ASIC for Design (1) is  <span class="math">36\\times</span>  faster than the  <span class="math">\\mathrm{C}++</span> , showing that building specialized hardware for XGCD is worthwhile.</p>

    <p class="text-gray-300">A Fast Large-Integer Extended GCD Algorithm and Hardware Design</p>

    <p class="text-gray-300">Table 7: Comparison of our non-constant-time 1024-bit design to prior work, split by software, FPGA, and ASIC results. NR = not reported. * Please see Table 9.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">XGCD Design</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Technology Node / Platform</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Area (mm2)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Clock Frequency</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Cycles</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Time (ns)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">GNU XGCD C++</td>

            <td class="px-3 py-2 border-b border-gray-700">Apple M1</td>

            <td class="px-3 py-2 border-b border-gray-700">5nm</td>

            <td class="px-3 py-2 border-b border-gray-700">-</td>

            <td class="px-3 py-2 border-b border-gray-700">-</td>

            <td class="px-3 py-2 border-b border-gray-700">-</td>

            <td class="px-3 py-2 border-b border-gray-700">10650</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[AHAJS16]</td>

            <td class="px-3 py-2 border-b border-gray-700">Xilinx XC7K70T-2-FBG676</td>

            <td class="px-3 py-2 border-b border-gray-700">28nm</td>

            <td class="px-3 py-2 border-b border-gray-700">NR</td>

            <td class="px-3 py-2 border-b border-gray-700">39.94 MHz</td>

            <td class="px-3 py-2 border-b border-gray-700">NR</td>

            <td class="px-3 py-2 border-b border-gray-700">NR</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Our Design (1)</td>

            <td class="px-3 py-2 border-b border-gray-700">Xilinx XC7K410T FBG676-1</td>

            <td class="px-3 py-2 border-b border-gray-700">28nm</td>

            <td class="px-3 py-2 border-b border-gray-700">*</td>

            <td class="px-3 py-2 border-b border-gray-700">204 MHz</td>

            <td class="px-3 py-2 border-b border-gray-700">1147</td>

            <td class="px-3 py-2 border-b border-gray-700">5623</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[ZTW21]</td>

            <td class="px-3 py-2 border-b border-gray-700">TSMC 28nm ASIC</td>

            <td class="px-3 py-2 border-b border-gray-700">2.4</td>

            <td class="px-3 py-2 border-b border-gray-700">250 MHz</td>

            <td class="px-3 py-2 border-b border-gray-700">1623</td>

            <td class="px-3 py-2 border-b border-gray-700">6490</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[ZST+20]</td>

            <td class="px-3 py-2 border-b border-gray-700">TSMC 28nm ASIC</td>

            <td class="px-3 py-2 border-b border-gray-700">9.9</td>

            <td class="px-3 py-2 border-b border-gray-700">500 MHz</td>

            <td class="px-3 py-2 border-b border-gray-700">3000</td>

            <td class="px-3 py-2 border-b border-gray-700">6000</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Our Design (1)</td>

            <td class="px-3 py-2 border-b border-gray-700">TSMC 16nm ASIC</td>

            <td class="px-3 py-2 border-b border-gray-700">0.41</td>

            <td class="px-3 py-2 border-b border-gray-700">3.89 GHz</td>

            <td class="px-3 py-2 border-b border-gray-700">1147</td>

            <td class="px-3 py-2 border-b border-gray-700">295</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Our Design (1) runs at a  <span class="math">5 \\times</span>  faster clock frequency post place-and-route (with Xilinx Vivado 2019.2) on the Xilinx XC7K410TFBG676-1 FPGA compared to the prior 1024-bit FPGA work [AHAJS16] on the Xilinx XC7K70T-2-FBG676. We use a bigger FPGA in the same Kintex-7 family since Design (1) does not fit on the smaller XC7K70T. While this prior work mentions using CSAs, it does not report any further implementation details, the number of cycles required for XGCD, or the FPGA utilization for us to compare to. We likely achieve this speedup by building from the two-bit PM algorithm instead of Euclid's algorithm like this prior work. We conservatively use 598 cycles (the average number of cycles for Euclid's algorithm for 1024-bit inputs) for this prior work to estimate that Design (1) is at least  <span class="math">2.7 \\times</span>  faster for XGCD execution time and our 16nm ASIC for Design (1) is at least  <span class="math">21 \\times</span>  faster after technology-scaling this prior work to 16nm. Since the XC7K70T-2-FBG676 FPGA is built in an older node (28nm versus 5nm) and run at a slower frequency compared to the M1 processor (40MHz versus a max of 3.2 GHz), their work is slower than software. Finally, we report the utilization of Design (1) in Table 9.</p>

    <p class="text-gray-300">Our Design (1) ASIC is  <span class="math">8 \\times</span>  faster and  <span class="math">8 \\times</span>  smaller than the state-of-the-art 1024-bit XGCD ASIC  <span class="math">\\left[\\mathrm{ZST}^{+}20\\right]</span> , after technology-scaling the prior work to  <span class="math">16\\mathrm{nm}</span>  for a fair comparison. We achieve this speedup by reducing the number of cycles by over  <span class="math">60\\%</span>  and also reducing the cycle time. The prior work builds from Euclid's algorithm and uses the most significant bits to estimate division. As we found in Section 3, building from the two-bit PM algorithm with simpler operations (carry-save adds and shifts) will result in shorter cycle times: our Design (1) ASIC runs at a  <span class="math">3.2 \\times</span>  faster clock frequency (technology-scaled). In addition, our Design (1) on the XC7K410 FPGA is slightly faster overall than this prior ASIC. Finally, this prior paper reports synthesis results, which may use simpler wire delay approximations. We instead execute the full physical design flow including place-and-route with signoff-quality RC extracted wire delays for our results.</p>

    <p class="text-gray-300">Table 8 compares Design (2) to prior software and FPGA designs. We are not aware of prior ASIC designs and believe our work presents the first ASIC for constant-time XGCD.</p>

    <p class="text-gray-300">Design (2) achieves a  <span class="math">31 \\times</span>  speedup over the state-of-the-art software implementation [Por20], which also builds from Stein's algorithm. This shows that building an ASIC for constant-time XGCD is also worth the designer time and effort. Pornin focuses on equalizing the time for each iteration, which naturally happens in hardware with a set clock frequency. Pornin also approximates large values for faster computation, while we instead use CSA form (Section 4.2) and sample true values (Section 4.4) for the same goal.</p>

    <p class="text-gray-300">Note that despite our lower cycle counts in Table 8, we do not expect our algorithm to be significantly faster than [Por20] and [BY19] in software. As discussed in Section 3.2, datapaths in software and custom hardware greatly differ. Our hardware design completes</p>

    <p class="text-gray-300">Kavya Sreedhar, Mark Horowitz, and Christopher Torng</p>

    <p class="text-gray-300">Table 8: Comparison of our constant-time 255-bit XGCD design to prior work, split by software, FPGA, and ASIC results. NR = not reported. * Please see Table 9.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">XGCD Design</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Technology Node / Platform</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Area (mm2)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Clock Frequency</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Cycles</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Time (ns)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[BY19]</td>

            <td class="px-3 py-2 border-b border-gray-700">Intel Kaby Lake</td>

            <td class="px-3 py-2 border-b border-gray-700">14nm</td>

            <td class="px-3 py-2 border-b border-gray-700">-</td>

            <td class="px-3 py-2 border-b border-gray-700">NR</td>

            <td class="px-3 py-2 border-b border-gray-700">8543</td>

            <td class="px-3 py-2 border-b border-gray-700">NR</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[Por20]</td>

            <td class="px-3 py-2 border-b border-gray-700">Intel Coffee Lake</td>

            <td class="px-3 py-2 border-b border-gray-700">14nm</td>

            <td class="px-3 py-2 border-b border-gray-700">-</td>

            <td class="px-3 py-2 border-b border-gray-700">2.3 GHz</td>

            <td class="px-3 py-2 border-b border-gray-700">6253</td>

            <td class="px-3 py-2 border-b border-gray-700">2720</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[DdPM+21] (1)</td>

            <td class="px-3 py-2 border-b border-gray-700">Zynq UltraScale+ XCZU7EG</td>

            <td class="px-3 py-2 border-b border-gray-700">16nm</td>

            <td class="px-3 py-2 border-b border-gray-700">*</td>

            <td class="px-3 py-2 border-b border-gray-700">207 MHz</td>

            <td class="px-3 py-2 border-b border-gray-700">8466</td>

            <td class="px-3 py-2 border-b border-gray-700">40900</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[DdPM+21] (2)</td>

            <td class="px-3 py-2 border-b border-gray-700">Zynq UltraScale+ XCZU7EG</td>

            <td class="px-3 py-2 border-b border-gray-700">16nm</td>

            <td class="px-3 py-2 border-b border-gray-700">*</td>

            <td class="px-3 py-2 border-b border-gray-700">346 MHz</td>

            <td class="px-3 py-2 border-b border-gray-700">73700</td>

            <td class="px-3 py-2 border-b border-gray-700">213000</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Our Design (2)</td>

            <td class="px-3 py-2 border-b border-gray-700">Zynq UltraScale+ XCZU7EG</td>

            <td class="px-3 py-2 border-b border-gray-700">16nm</td>

            <td class="px-3 py-2 border-b border-gray-700">*</td>

            <td class="px-3 py-2 border-b border-gray-700">447 MHz</td>

            <td class="px-3 py-2 border-b border-gray-700">403</td>

            <td class="px-3 py-2 border-b border-gray-700">902</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Our Design (2)</td>

            <td class="px-3 py-2 border-b border-gray-700">TSMC 16nm ASIC</td>

            <td class="px-3 py-2 border-b border-gray-700">0.059</td>

            <td class="px-3 py-2 border-b border-gray-700">4.55 GHz</td>

            <td class="px-3 py-2 border-b border-gray-700">403</td>

            <td class="px-3 py-2 border-b border-gray-700">89</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 9: Comparison of FPGA utilization post place-and-route against prior work. FPGAs used: Xilinx XC7K410TFBG676-1 for Design (1) and Zynq UltraScale+ XCZU7EG for Design (2) and  <span class="math">\\left[\\mathrm{DdPM}^{+}21\\right]</span> . TAP = time-area product, with time equal to the microseconds required to compute one XGCD and area equal to the number of slices. NR = not reported.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">XGCD Design</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Slices</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">LUTs</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Flip-flops</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">BRAMs</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">DSPs</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">% Utilization</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">TAP (103)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Our Design (1)</td>

            <td class="px-3 py-2 border-b border-gray-700">57012</td>

            <td class="px-3 py-2 border-b border-gray-700">225776</td>

            <td class="px-3 py-2 border-b border-gray-700">31438</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">89.71</td>

            <td class="px-3 py-2 border-b border-gray-700">319</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Our Design (2)</td>

            <td class="px-3 py-2 border-b border-gray-700">4199</td>

            <td class="px-3 py-2 border-b border-gray-700">27074</td>

            <td class="px-3 py-2 border-b border-gray-700">5888</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">14.58</td>

            <td class="px-3 py-2 border-b border-gray-700">3.79</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[DdPM+21] (1)</td>

            <td class="px-3 py-2 border-b border-gray-700">1847</td>

            <td class="px-3 py-2 border-b border-gray-700">NR</td>

            <td class="px-3 py-2 border-b border-gray-700">6704</td>

            <td class="px-3 py-2 border-b border-gray-700">NR</td>

            <td class="px-3 py-2 border-b border-gray-700">NR</td>

            <td class="px-3 py-2 border-b border-gray-700">6.41</td>

            <td class="px-3 py-2 border-b border-gray-700">76</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[DdPM+21] (2)</td>

            <td class="px-3 py-2 border-b border-gray-700">115</td>

            <td class="px-3 py-2 border-b border-gray-700">NR</td>

            <td class="px-3 py-2 border-b border-gray-700">241</td>

            <td class="px-3 py-2 border-b border-gray-700">0.5</td>

            <td class="px-3 py-2 border-b border-gray-700">NR</td>

            <td class="px-3 py-2 border-b border-gray-700">0.4</td>

            <td class="px-3 py-2 border-b border-gray-700">25</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">all operations for one iteration in one clock cycle, resulting in a low cycle count equal to the iteration count. In software, each iteration of our algorithm would expand to many instructions emulating large-integer operations, resulting in larger cycle counts closer to prior work [Por20]. In addition, since there is no CSA instruction in most processor ISAs, our speedups attributed to CSAs would not translate into software gains.</p>

    <p class="text-gray-300">The only prior constant-time XGCD FPGA work presents two designs with different time-area tradeoffs:  <span class="math">\\left[\\mathrm{DdPM}^{+}21\\right]</span>  (1) is faster than  <span class="math">\\left[\\mathrm{DdPM}^{+}21\\right]</span>  (2) but utilizes more resources. Note that we use their 16-bit architecture variant for  <span class="math">\\left[\\mathrm{DdPM}^{+}21\\right]</span>  (2) since that has the shortest clock period within the second design group. Compared to  <span class="math">\\left[\\mathrm{DdPM}^{+}21\\right]</span>  (1) and (2), our Design (2) is  <span class="math">45\\times</span>  and  <span class="math">236\\times</span>  faster, respectively, post place-and-route (with Xilinx Vivado 2019.2) on the same Zynq UltraScale+ XCZU7EG FPGA in this prior work.</p>

    <p class="text-gray-300">We achieve this speedup due to three reasons. First, our critical path consists of fast carry-save adds and shifts while their critical path requires modifying fractions and dividing to implement the Bernstein-Yang algorithm [BY19]. Second, we use CSAs to eliminate the carry-propagation delay for iterative large-integer additions while this prior work pipelines this delay. Third, we reduce the cycle count by over  <span class="math">95\\%</span>  since we complete one XGCD iteration in one clock cycle, while this prior work's cycle count is comparable to software [BY19]. Since their FPGA design is run at a  <span class="math">7\\times</span>  to  <span class="math">11\\times</span>  slower frequency compared to the Intel processor in Pornin's work, their work is slower than software. Thus, our 16nm ASIC for Design (2) is  <span class="math">460\\times</span>  faster than  <span class="math">\\mathrm{[DdPM^{+}21]}</span>  (1) (their faster design).</p>

    <p class="text-gray-300">Finally, we compare the utilization of Design (2) to  <span class="math">\\left[\\mathrm{DdPM}^{+}21\\right]</span>  on the same FPGA in Table 9. We compare time-area products, with time equal to the microseconds required to compute one XGCD and area equal to the number of slices (since number of slices dominates design area)  <span class="math">\\left[\\mathrm{DdPM}^{+}21\\right]</span> . Our Design (2) has a time-area product of  <span class="math">3.79 * 10^{3}</span> . Compared to  <span class="math">\\left[\\mathrm{DdPM}^{+}21\\right]</span>  (1) (their faster design), our Design (2) has a  <span class="math">20 \\times</span>  lower time-area product. Compared to  <span class="math">\\left[\\mathrm{DdPM}^{+}21\\right]</span>  (2) (their smaller design), our Design (2) still has a  <span class="math">7 \\times</span>  lower time-area product. Thus, our approach is faster and yields lower time-area products.</p>

    <p class="text-gray-300">6.3 Unified ASIC Design</p>

    <p class="text-gray-300">Our 1024-bit Design (1) can be deployed and repurposed for constant-time 255-bit modular inversion by setting the constant time configuration to true and the bitwidth to 255. The bitwidth is not specified for functionality and is instead used to determine the constant worst-case number of cycles required for 255-bit inputs rather than 1024-bit inputs. Our unified ASIC is <span class="math">26\\times</span> faster than Pornin’s work <em>[Pornin2020]</em> and <span class="math">395\\times</span> faster than the fastest prior FPGA design <em>[DdPM^{+}21]</em>. Since ASICs can be expensive, achieving high performance by re-purposing one hardware unit for several applications that vary in bitwidth (1024 versus 255 bits) and constant-time requirements is advantageous and a key benefit of our work.</p>

    <h3 id="sec-36" class="text-xl font-semibold mt-8">6.4 Squaring Comparison</h3>

    <p class="text-gray-300">We ran over one million trials of the Chia Network’s C++ for the NUDUPL algorithm on a 2020 MacBook Pro with the M1 chip in 5nm, compiled with g++ and -O3 optimization. Their code uses functions from the GMP library for large-integers and takes an average of <span class="math">21us</span> per squaring and partial reduction. If we accelerate only the two XGCD computations required by using our 1024-bit XGCD Design (1), we reduce the <span class="math">0.91<em>21us=19.11us</span> XGCD execution time to <span class="math">2</em>295ns=590ns</span> and speed up the full algorithm by <span class="math">8.5\\times</span>, which is close to <span class="math">9.1\\times</span>, the best speedup possible if accelerating only the XGCD.</p>

    <p class="text-gray-300">By accelerating the remaining operations on the critical path (Section 5), we can execute the full computation in <span class="math">1.5us</span>, achieving a <span class="math">14\\times</span> speedup over the C++. We believe our work is the first to accelerate the NUDUPL algorithm in hardware. One prior work implements a different squaring algorithm without the reduction algorithm <em>[ZST^{+}20]</em>. Comparing these works would not be fair since NUDUPL squares and also partially reduces the outputs. In terms of core components, our XGCD design is faster (Section 6.1) and we implement the more efficient Toom-3 algorithm instead of the Karatsuba algorithm.</p>

    <h2 id="sec-37" class="text-2xl font-bold">7 Conclusion</h2>

    <p class="text-gray-300">Fast XGCD implementations are becoming increasingly important as the cryptography community investigates applications dominated by large-integer XGCDs, including verifiable delay function constructions based on squaring over class groups and modular inversion for elliptic curve cryptography. Our algorithm and design-space exploration for large-integer XGCD showed that building hardware using Stein’s subtraction-based algorithm and carry-free carry-save adders yields the highest performance. Our accelerator completes a full XGCD iteration in each clock cycle (a task that takes a processor tens of instructions), with clock frequencies that still match or exceed those in high-performance processors. In a 16nm technology, our hardware design runs at 4+ GHz clock frequencies and leverages further optimizations to achieve state-of-the-art performance for both average- and worst-case XGCD execution. It is <span class="math">8\\times</span> faster than the state-of-the-art ASIC for 1024-bit XGCD and <span class="math">31\\times</span> faster than the state-of-the-art software for constant-time 255-bit XGCD, significantly advancing XGCD performance for future cryptographic applications.</p>

    <h2 id="sec-38" class="text-2xl font-bold">8 Acknowledgements</h2>

    <p class="text-gray-300">We thank Dan Boneh and Riad Wahby for early discussions on VDFs and Taeyoung Kong for help on JTAG in our design. This work was supported by the DSSoC DARPA program, the Stanford AHA Agile Hardware Center and Affiliates Program, and the Stanford SystemX Alliance. Kavya Sreedhar is supported by a graduate fellowship award as a Knight-Hennessy Scholar at Stanford University.</p>

    <p class="text-gray-300">References</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[AHAJS16] Qasem Abu Al-Haija, Monther Al-Ja’fari, and Mahmoud Smadi. A comparative study up to 1024 bit euclid’s gcd algorithm fpga implementation and synthesizing. International Conference on Electronic Devices, Systems and Applications (ICEDSA), 2016.</li>

      <li>[BBBF18] Dan Boneh, Joseph Bonneau, Benedikt Bünz, and Ben Fisch. Verifiable delay functions. In Hovav Shacham and Alexandra Boldyreva, editors, CRYPTO 2018, Part I, volume 10991 of LNCS, pages 757–788. Springer, Heidelberg, August 2018.</li>

      <li>[BBF18] Dan Boneh, Benedikt Bünz, and Ben Fisch. A survey of two verifiable delay functions. Cryptology ePrint Archive, Report 2018/712, 2018. https://eprint.iacr.org/2018/712.</li>

      <li>[Ber06] Daniel J Bernstein. Curve25519: new diffie-hellman speed records. International Workshop on Public Key Cryptography, pages 207–228, 2006.</li>

      <li>[BK84] Richard P. Brent and H. T. Kung. Systolic vlsi arrays for polynomial gcd computation. IEEE Transactions on Computers, C-33(8):731–736, 1984.</li>

      <li>[BK85] R. P. Brent and H. T. Kung. A systolic algorithm for integer gcd computation. Symposium on Computer Arithmetic (ARITH), pages 118–125, 1985.</li>

      <li>[Bue89] Duncan A Buell. Binary quadratic forms: classical theory and modern computations. Springer Science & Business Media, 1989.</li>

      <li>[BY19] Daniel J Bernstein and Bo-Yin Yang. Fast constant-time gcd computation and modular inversion. IACR Transactions on Cryptographic Hardware and Embedded Systems, pages 340–398, 2019.</li>

      <li>[BZ07] Marco Bodrato and Alberto Zanoni. Integer and polynomial multiplication: Towards optimal toom-cook matrices. International Symposium on Symbolic and Algebraic Computation (ISSAC), 2007.</li>

      <li>[CA69] Stephen A Cook and Stål O Aanderaa. On the minimum computation time of functions. Transactions of the American Mathematical Society, 142:291–314, 1969.</li>

      <li>[chi21] Chia network consensus explained. Online Webpage, 2021. https://manuals.plus/chia/chia-network-consensus-explained.</li>

      <li>[Coh93] Henri Cohen. A course in computational algebraic number theory, volume 8. Springer-Verlag Berlin, 1993.</li>

      <li>[CTN^{+}22] Alex Carsello, James Thomas, Ankita Nayak, Po-Han Chen, Mark Horowitz, Priyanka Raina, and Christopher Torng. mflowgen: A modular flow generator and ecosystem for community-driven physical design. Design Automation Conference (DAC), 2022.</li>

      <li>[DdPM^{+}21] Sanjay Deshpande, Santos Merino del Pozo, Victor Mateu, Marc Manzano, Najwa Aaraj, and Jakub Szefer. Modular inverse for integers using fast constant time gcd algorithm and its applications. International Conference on Field-Programmable Logic and Applications (FPL), 2021.</li>

      <li>[DG11] Ulrich Daepp and Pamela Gorkin. Fermat’s little theorem. pages 315–323. Springer, 2011.</li>

    </ul>

    <p class="text-gray-300">A Fast Large-Integer Extended GCD Algorithm and Hardware Design</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[DGS20] Samuel Dobson, Steven D Galbraith, and Benjamin Smith. Trustless groups of unknown order with hyperelliptic curves. Cryptology ePrint Archive, Report 2020/196, 2020. https://eprint.iacr.org/2020/196.</li>

      <li>[DLG18] Jinnan Ding, Shuguo Li, and Zhen Gu. High-speed ecc processor over nist prime fields applied with toom–cook multiplication. IEEE Transactions on Circuits and Systems I: Regular Papers, 66(3):1003–1016, 2018.</li>

      <li>[FaPKL^{+}] Pierre-Alain Fouque, Jeffrey Hoffstein annd Paul Kirchner, Vadim Lyuba- shevsky, Thomas Pornin, Thomas Prest, Thomas Ricosset, Gregor Seiler, William Whyte, and Zhenfei Zhang. Falcon: Fast-fourier lattice-based compact signatures over ntru. Online Webpage. https://falcon-sign.info/.</li>

      <li>[FdCBM05] Mateus Fonseca, Eduardo da Costa, Sergio Bampi, and José Monteiro. Design of a radix-2m hybrid array multiplier using carry save adder format. Symposium on Integrated Circuits and Systems Design (SBCCI), 2005.</li>

      <li>[Fly70] Michael J Flynn. On division by functional iteration. IEEE Transactions on Computers, 100(8):702–706, 1970.</li>

      <li>[GL18] Zhen Gu and Shuguo Li. A division-free toom–cook multiplication-based montgomery modular multiplication. IEEE Transactions on Circuits and Systems II: Express Briefs, 66(8):1401–1405, 2018.</li>

      <li>[Gol64] Robert E Goldschmidt. Applications of division by convergence. PhD thesis, Massachusetts Institute of Technology, 1964.</li>

      <li>[HAS21] Benjamin Salling Hvass, Diego F Aranha, and Bas Spitters. High-assurance field inversion for curve-based cryptography. Cryptology ePrint Archive, Report 2021/549, 2021. https://eprint.iacr.org/2021/549.</li>

      <li>[HHWH97] David Harris, Ron Ho, Gu-Yeon Wei, and Mark Horowitz. The fanout-of-4 inverter delay metric, 1997. http://odin.ac.hmc.edu/~harris/research/F04.pdf.</li>

      <li>[HM00] Safuat Hamdy and Bodo Möller. Security of cryptosystems based on class groups of imaginary quadratic orders. International Conference on the Theory and Application of Cryptology and Information Security (ASIACRYPT), 2000.</li>

      <li>[HSGJ10] Andreas Habegger, Andreas Stahel, Josef Goette, and Marcel Jacomet. An efficient hardware implementation for a reciprocal unit. IEEE International Symposium on Electronic Design, Test, and Applications, pages 183–187, 2010.</li>

      <li>[Jeb93] Tudor Jebelean. Improving the multiprecision euclidean algorithm. Design and Implementation of Symbolic Computation Systems (DISCO), pages 45–58, 1993.</li>

      <li>[Jeb95] Tudor Jebelean. A double-digit lehmer-euclid algorithm for finding the gcd of long integers. Journal of Symbolic Computation, 19(1):145–157, 1995.</li>

      <li>[JLL^{+}15] Song Jia, Shigong Lyu, Xiayu Li, Li Liu, and Yandong He. Simplified carry save adder-based array multiplier scheme and circuits design. International Journal of Circuit Theory and Applications, 43(9):1226–1234, 2015.</li>

      <li>[JvdP02] Michael J. Jacobson and Alfred J. van der Poorten. Computational aspects of nucomp. Algorithmic Number Theory, pages 120–133, 2002.</li>

    </ul>

    <p class="text-gray-300">[Kar63] Anatolii Karatsuba. Multiplication of multidigit numbers on automata. Soviet Physics Doklady, 7:595–596, 1963.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[Knu70] Donald E Knuth. The analysis of algorithms. Actes du congres international des Mathématiciens, 3, 1970.</li>

      <li>[Kob87] Neal Koblitz. Elliptic curve cryptosystems. Mathematics of Computation, 48(177):203–209, 1987.</li>

      <li>[Lam44] Gabriel Lamé. Note sur la limite du nombre des divisions dans la recherche du plus grand commun diviseur entre deux nombres entiers. 1844.</li>

      <li>[Leh38] Derrick H Lehmer. Euclid’s algorithm for large numbers. The American Mathematical Monthly, 45(4):227–233, 1938.</li>

      <li>[Lon19] Lipa Long. Binary quadratic forms. Online Webpage, 2019. https://github.com/Chia-Network/vdf-competition/blob/main/classgroups.pdf.</li>

      <li>[MH94] Bohdan S Majewski and George Havas. The complexity of greatest common divisor computations. International Algorithmic Number Theory Symposium (ANTS), 1994.</li>

      <li>[Mil85] Victor S Miller. Use of elliptic curves in cryptography. Conference on the Theory and Applications of Cryptographic Techniques (EUROCRYPT), 1985.</li>

      <li>[MMM03] Ciaran Mclvor, Maire McLoone, and John V McCanny. Fast montgomery modular multiplication and rsa cryptographic processor architectures. Asilomar Conference on Signals, Systems & Computers, 1, 2003.</li>

      <li>[Mol97] Richard A Mollin. Fundamental number theory with applications. Crc Press, 1997.</li>

      <li>[Möl08] Niels Möller. On schönhage’s algorithm and subquadratic integer gcd computation. Mathematics of Computation, 77(261):589–607, 2008.</li>

      <li>[NLRC10] JAM Naranjo, JA López-Ramos, and LG Casado. Applications of the extended euclidean algorithm to privacy and secure communications. International Conference on Computational and Mathematical Methods in Science and Engineering, 2010.</li>

      <li>[Pie18] Krzysztof Pietrzak. Simple verifiable delay functions. Innovations in Theoretical Computer Science Conference (ITCS), 2018.</li>

      <li>[Por18] Thomas Pornin. Bearssl: a smaller ssl/tls library. Online Webpage, 2018. https://bearssl.org/.</li>

      <li>[Por20] Thomas Pornin. Optimized binary gcd for modular inversion. Cryptology ePrint Archive, 2020.</li>

      <li>[Pur83] George B Purdy. A carry-free algorithm for finding the greatest common divisor of two integers. Computers & Mathematics with Applications, 9(2):311–316, 1983.</li>

      <li>[PW02] Victor Y Pan and Xinmao Wang. Acceleration of euclidean algorithm and extensions. International Symposium on Symbolic and Algebraic Computation (ISSAC), 2002.</li>

      <li>[Ras17] Bahram Rashidi. A survey on hardware implementations of elliptic curve cryptosystems. CoRR arXiv:1710.08336, 2017.</li>

    </ul>

    <p class="text-gray-300">A Fast Large-Integer Extended GCD Algorithm and Hardware Design</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[RM19] Debapriya Basu Roy and Debdeep Mukhopadhyay. High-speed implementation of ecc scalar multiplication in gf (p) for generic montgomery curves. IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 27(7):1587–1600, 2019.</li>

      <li>[ROH17] Ciara Rafferty, Máire O’Neill, and Neil Hanley. Evaluation of large integer multiplication methods on hardware. IEEE Transactions on Computers, 66(8):1369–1382, 2017.</li>

      <li>[RSA78] Ronald L Rivest, Adi Shamir, and Leonard Adleman. A method for obtaining digital signatures and public-key cryptosystems. Communications of the ACM, 21(2):120–126, 1978.</li>

      <li>[RSPR11] N Ravi, Y Subbaiah, T Jayachandra Prasad, and T Subba Rao. A novel low power, low area array multiplier design for dsp applications. International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSPCC), 2011.</li>

      <li>[Sch71] Arnold Schönhage. Schnelle berechnung von kettenbruchentwicklungen. Acta Informatica, 1(2):139–144, 1971.</li>

      <li>[Sch77] Arnold Schönhage. Schnelle multiplikation von polynomen über körpern der charakteristik 2. Acta Informatica, 7(4):395–398, 1977.</li>

      <li>[Sch91] Arnold Schönhage. Fast reduction and composition of binary quadratic forms. International Symposium on Symbolic and Algebraic Computation (ISSAC), 1991.</li>

      <li>[SKN08] Koji Shigemoto, Kensuke Kawakami, and Koji Nakano. Accelerating montgomery modulo multiplication for redundant radix-64k number system on the fpga using dual-port block rams. IEEE/IFIP International Conference on Embedded and Ubiquitous Computing (EUC), 1, 2008.</li>

      <li>[SKS09] Raminder Preet Pal Singh, Parveen Kumar, and Balwinder Singh. Performance analysis of 32-bit array multiplier with a carry save adder and with a carry-look-ahead adder. International Journal of Recent Trends in Engineering, 2(6):83, 2009.</li>

      <li>[Sor94] Jonathan Sorenson. Two fast gcd algorithms. Journal of Algorithms, 16(1):110–144, 1994.</li>

      <li>[Sor95] Jonathan Sorenson. An analysis of lehmer’s euclidean gcd algorithm. International Symposium on Symbolic and Algebraic Computation (ISSAC), 1995.</li>

      <li>[SRC20] M Siddhartha, Jelwin Rodriques, and BR Chandavarkar. Greatest common divisor and its applications in security: Case study. International Conference on Interdisciplinary Cyber Physical Systems (ICPS), 2020.</li>

      <li>[Ste67] Josef Stein. Computational problems associated with racah algebra. Journal of Computational Physics, 1(3):397–405, 1967.</li>

      <li>[SZ04] Damien Stehlé and Paul Zimmermann. A binary recursive gcd algorithm. International Algorithmic Number Theory Symposium (ANTS), pages 411–425, 2004.</li>

    </ul>

    <p class="text-gray-300">Kavya Sreedhar, Mark Horowitz, and Christopher Torng</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[THS^{+}20] Lenny Truong, Steven Herbst, Rajsekhar Setaluri, Makai Mann, Ross Daly, Keyi Zhang, Caleb Donovick, Daniel Stanley, Mark Horowitz, Clark Barrett, et al. fault: A python embedded domain-specific language for metaprogramming portable hardware verification components. International Conference on Computer Aided Verification (CAV), 2020.</li>

      <li>[Too63] Andrei L Toom. The complexity of a scheme of functional elements realizing the multiplication of integers. Soviet Mathematics Doklady, 3(4):714–716, 1963.</li>

      <li>[TPT06] A.F. Tenca, S. Park, and L.A. Tawalbeh. Carry-save representation is shift-unsafe: the problem and its solution. IEEE Transactions on Computers, 55(5):630–635, 2006.</li>

      <li>[TY00] Klaus Thull and Chee Yap. A unified approach to fast gcd algorithms for polynomials and integers: Technical report from fachbereich mathematik, frie universitaet berlin. In Fundamental Problems in Algorithmic Algebra, pages Chapter–2. Oxford University Press, 2000.</li>

      <li>[vzGS05] Joachim von zur Gathen and Jamshid Shokrollahi. Efficient fpga-based karatsuba multipliers for polynomials over f2. International Workshop on Selected Areas in Cryptography, pages 359–369, 2005.</li>

      <li>[Web95] Kenneth Weber. The accelerated integer gcd algorithm. ACM Transactions on Mathematical Software (TOMS), 21(1):111–122, 1995.</li>

      <li>[Wes19] Benjamin Wesolowski. Efficient verifiable delay functions. In Yuval Ishai and Vincent Rijmen, editors, EUROCRYPT 2019, Part III, volume 11478 of LNCS, pages 379–407. Springer, Heidelberg, May 2019.</li>

      <li>[wMZ^{+}08] El hadj youssef wajih, Mohsen Machhout, Medien Zeghid, Belgacem Bouallegue, and Rached Tourki. Efficient hardware architecture of recursive karatsuba-ofman multiplier. International Conference on Design and Technology of Integrated Systems in Nanoscale Era, 2008.</li>

      <li>[WTM05] Kenneth Weber, Vilmar Trevisan, and Luiz Felipe Martins. A modular integer gcd algorithm. Journal of Algorithms, 54(2):152–167, 2005.</li>

      <li>[YZ86] D. Y. Y. Yun and C. N. Zhang. A fast carry-free algorithm and hardware design for extended integer gcd computation. ACM Symposium on Symbolic and Algebraic Computation, page 82–84, 1986.</li>

      <li>[Zha] Keyi Zhang. Kratos: Debuggable Hardware Generator. Github Repository. https://github.com/Kuree/kratos.</li>

      <li>[ZST^{+}20] Danyang Zhu, Yifeng Song, Jing Tian, Zhongfeng Wang, and Haobo Yu. An efficient accelerator of the squaring for the verifiable delay function over a class group. IEEE Asia Pacific Conference on Circuits and Systems (APCCAS), 2020.</li>

      <li>[ZTW21] Danyang Zhu, Jing Tian, and Zhongfeng Wang. Low-latency architecture for the parallel extended gcd algorithm of large numbers. IEEE International Symposium on Circuits and Systems (ISCAS), pages 1–5, 2021.</li>

    </ul>`;
---

<BaseLayout title="A Fast Large-Integer Extended GCD Algorithm and Hardware Des... (2021/1292)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2021 &middot; eprint 2021/1292
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
