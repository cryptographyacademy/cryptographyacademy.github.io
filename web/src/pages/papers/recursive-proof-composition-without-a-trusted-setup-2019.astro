---
import BaseLayout from '../../layouts/BaseLayout.astro';
import PaperDisclaimer from '../../components/PaperDisclaimer.astro';
import PaperHistory from '../../components/PaperHistory.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2019/1021';
const CRAWLER = 'marker';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Recursive Proof Composition without a Trusted Setup';
const AUTHORS_HTML = 'Sean Bowe, Jack Grigg, Daira Hopwood';

const CONTENT = `    <section id="abstract" class="mb-10">
      <h2 class="text-2xl font-bold">Abstract</h2>
      <p class="text-gray-300">Non-interactive arguments of knowledge are powerful cryptographic tools that can
be used to demonstrate the faithful execution of arbitrary computations with
publicly verifiable proofs. Increasingly efficient protocols have been described
in recent years, with verification time and/or communication complexity that is
sublinear in the size of the computation being described. These efficiencies can
be exploited to realize recursive proof composition: the concept of
proofs that attest to the correctness of other instances of themselves, thereby
allowing large computational effort to be incrementally verified. All previously
known realizations of recursive proof composition have required a trusted setup
and cycles of expensive pairing-friendly elliptic curves. We obtain and
implement Halo, the first practical example of recursive proof
composition without a trusted setup, using the discrete log assumption over
normal cycles of elliptic curves. In the process we develop several novel
techniques that may be of independent interest.</p>
      <p class="text-gray-300"><strong>Keywords:</strong> recursive proofs &middot; incrementally verifiable computation &middot; zero knowledge</p>
    </section>

    <p class="text-gray-300">Proofs of knowledge <a href="#page-22-0">[24]</a>, introduced by Goldwasser, Micali and Rackoff, allow us to demonstrate knowledge of a satisfying witness to some NP statement. If these proofs also do not reveal anything about the witness we refer to them as zero-knowledge proofs of knowledge. The works of Kilian, Micali and others showed that proofs of knowledge could be non-interactive, and that these proofs could even be smaller than the statement being proven. <a href="#page-23-0">[31</a><a href="#page-23-1">,33,</a><a href="#page-21-0">10,</a><a href="#page-21-1">9]</a> In the decades since, significant reductions in the size and verification time of such protocols have been made, culminating in zero-knowledge succinct non-interactive arguments of knowledge, or zk-SNARKs for short. Today, the most efficient zk-SNARKs require pairing-friendly elliptic curves and trusted setup assumptions as in [25] but in return admit small, constant-size proofs with constant-time verification.</p>

    <p class="text-gray-300">One of the motivating use cases for zk-SNARKs is the application of verifiable computation [23], whereby computations can be delegated to an untrusted third party who returns the result as well as a cryptographic proof that the result is correct. Ideally this proof would be asymptotically smaller and less expensive to check than the computation itself, a property of zk-SNARKs that we call succinctness. A direct consequence of a succinct argument is the concept of incrementally verifiable computation [36] in which proofs not only attest to the correct execution of a computation but also, by exploiting succinctness, the validity of a previous proof. In this way a large and virtually unbounded amount of computation can be verified with a single proof, and with this proof alone we may extend the computation with further proofs.</p>

    <p class="text-gray-300">As a concrete motivation for incrementally verifiable computation, consider a blockchain network that requires all participants in the network to download the entire history of the blockchain and validate each individual state transition (transaction) merely in order to validate and process <em>new</em> state changes. SNARKs allow us to partially address this scalability problem by outsourcing some of these verification steps to a third party. However, the participant still must download and check each proof. Incrementally verifiable computation solves this issue, allowing a single proof to inductively demonstrate the correctness of many previous proofs. The participant in the blockchain network need only download the current state of the network as well as a single proof that this state is correct. Further proofs of state changes can be constructed with the latest proof alone, allowing active participants to prune old state changes.</p>

    <p class="text-gray-300">We can obtain incremental verifiable computation via recursive proof composition, i.e. proofs that can feasibly attest to the correctness of other instances of themselves. These proofs can be used to ensure the satisfaction of compliance predicates between old and new states, leading to concepts such as proof-carrying data [19] which can be extended to obtain verifiable distributed computations as in [8]. The first practical realization of recursive proof composition was shown in [4] and relies on SNARKs built over pairing-friendly elliptic curves. Elliptic curve groups are typically instantiated over a base field  <span class="math">\\mathbb{F}_p</span> , but these groups are often of a prime order  <span class="math">q \\neq p</span>  so that the SNARK construction, which demonstrates satisfiability of an arithmetic circuit over the scalar field  <span class="math">\\mathbb{F}_q</span> , cannot efficiently encode the  <span class="math">\\mathbb{F}_p</span>  arithmetic needed to verify its own proofs. The authors of [4] sidestep this issue by constructing a 2-cycle of pairing-friendly elliptic curves such that the base field of either curve is the scalar field of the other. Unfortunately, only a single family of pairing-friendly curves is known to admit cycles of this form [16], and due to their low embedding degrees secure curves in this family must be constructed over large (780-bit) fields, disturbing performance. Perhaps more importantly, all known pairing-based SNARKs require a trusted setup.</p>

    <p class="text-gray-300">In theory it should be possible to instantiate recursive proof composition using any zk-SNARK, and in recent years protocols such as STARKs [3] offer alternatives to pairing-based SNARKs that do not require trusted setups.</p>

    <p class="text-gray-300">However, recursive proof composition has never been practically realized with these protocols due to large constants; for example STARKs have proofs that are hundreds of kilobytes in size even for relatively simple computations.</p>

      <h3 id="sec-1.1" class="text-xl font-semibold mt-8">1.1 Our Contributions</h3>

    <p class="text-gray-300">We present Halo, the first practical realization of recursive proof composition without a trusted setup. As in <a href="#page-21-3">[4]</a>, we use a cycle of elliptic curves such that proofs constructed with one curve can efficiently verify proofs constructed over the other. However, neither curve is pairing-friendly; the cycle consists of normal 255-bit prime-order curves that are conjectured to approach the 128-bit security level. Such cycles are easy to construct, as discussed in <a href="#page-17-0">Section 6.1.</a> Proof size and verification time in our protocol does not increase with the depth of recursion.</p>

    <p class="text-gray-300">Polynomial Commitments with Amortized Succinctness In <a href="#page-6-0">Section 3</a> we present a new polynomial commitment scheme based on the inner product argument of <a href="#page-21-5">[12</a><a href="#page-22-4">,13]</a>, inspired by a similar protocol from <a href="#page-23-4">[37]</a>. We make a novel observation that, by exploiting the smooth structure of vectors that the verifier must work with, we can amortize away (across many proofs) the linear-time verification operation for commitment openings with the assistance of an untrusted third party &quot;helper.&quot; In particular, instead of performing a linear-time operation for each commitment opening proof, the helper provides the claimed output of these linear-time operations for each proof and then uses a new argument to demonstrate that every claimed output was correct. This new argument requires that the verifier perform the same linear-time operation, but this time only once for the entire batch of proofs. This strategy allows us to build proofs for arithmetic circuit satisfiability in which the marginal verification time is logarithmic in the size of the circuit, improving asymptotically over Bulletproofs <a href="#page-22-4">[13]</a>. This is similar to the helped variant of the Sonic protocol <a href="#page-23-5">[32,</a> Section 8], except that our approach avoids the need for a trusted setup.</p>

    <p class="text-gray-300">Nested Amortization All previously known attempts at achieving recursive proof composition have followed a similar strategy: build a fully succinct, noninteractive argument system and then construct a verification circuit for this system. Due to the succinctness property, at some threshold the verification circuit will be smaller than the size of the circuit being checked, allowing arbitrarydepth recursion to be achieved. Argument systems based on elliptic curve groups have the smallest communication complexity known in the literature, but currently they either require trusted setups (as in all pairing-based SNARKs) or have linear-time verifiers (as in Bulletproofs <a href="#page-22-4">[13]</a>) and so are not fully succinct.</p>

    <p class="text-gray-300">Our primary contribution is a novel approach for reducing the verification circuit size by exploiting the amortization strategy explained previously. In short, the verification circuit never performs linear-time operations itself, but rather takes the input and (claimed) output of the linear-time operation to be public inputs to the circuit, i.e. they are encoded in the statement being proven. The circuit proceeds on the assumption that the claimed output is correct and so the circuit is sublinear in size. This effectively defers the full verification of the &quot;inner&quot; proof to the verifier, who must also perform a similar linear-time operation to check the &quot;outer&quot; proof. Using the amortization argument described previously, the verifier can collapse these two computations together into one with the assistance of a helper. In the recursive context we simply embed the verifier of this amortization argument at each depth of the recursion so as to continually collapse the cost of verifying arguments. The linear-time verification operation is thus only performed once at the end of the recursive chain, and never as part of the verification circuit itself, bypassing the conventional need for a fully succinct argument and in fact avoiding the need for pre-processing.</p>

    <p class="text-gray-300">Implementation We fully implement our protocol in <a href="#page-15-0">Section 6</a> to demonstrate its practicality and assist in comparison with future work. In the process, we describe a 2-cycle of elliptic curves &ndash; which we refer to as Tweedledum and Tweedledee, respectively &ndash; with attractive performance and security. We instantiate an argument for arithmetic circuit satisfiability over each elliptic curve group, exploiting their cyclic nature to efficiently express verification circuits as in <a href="#page-21-3">[4]</a>. The curves we choose are also specifically designed to support certain endomorphisms which we exploit to reduce the size of our verification circuit in various novel ways described in <a href="#page-18-0">Section 6.2,</a> which are likely of independent interest.</p>

      <h3 id="sec-1.2" class="text-xl font-semibold mt-8">1.2 Concurrent Work</h3>

    <p class="text-gray-300">In concurrent work, Fractal <a href="#page-22-5">[18]</a> is a proposed recursive zero-knowledge protocol based on recent efficient low-degree testing techniques, with plausible postquantum security and full succinctness. Our work is not fully succinct (in that the verifier's work is linear in the circuit size) but our fully-recursive proofs are 3.5 KiB in size, compared to Fractal's which are over 120 KiB in size at the 128-bit security level. Further, Halo's recursion threshold<a href="#page-3-0">1</a> is less than 2<sup>17</sup> multiplication gates &mdash; at least an order of magnitude smaller than Fractal's &mdash; which has the potential for substantially reducing proving time/memory requirements.</p>

    <p class="text-gray-300">Supersonic <a href="#page-22-6">[14]</a> is a recent zk-SNARK based on groups of unknown order, which does not require a trusted setup. It is not clear to us if recursion can be practically achieved using this scheme or, if so, how competitive it would be with our results.</p>

    <p class="text-gray-300">We take &lambda; as our security parameter, and unless explicitly noted, all algorithms and adversaries are probablistic interactive Turing machines that run in polynomial time in this security parameter. We use negl(&lambda;) to describe a function that is negligible in &lambda;.</p>

    <p class="text-gray-300"><sup>1</sup> The recursion threshold is the number of (multiplication) gates in the smallest circuit that can achieve arbitrary-depth proof composition.</p>

      <h3 id="sec-2.1" class="text-xl font-semibold mt-8">2.1 Zero-Knowledge Arguments of Knowledge</h3>

    <p class="text-gray-300">Zero-knowledge proofs of knowledge allow a prover  <span class="math">\\mathcal{P}</span>  to demonstrate knowledge of a witness w such that  <span class="math">(x,w) \\in \\mathcal{R}</span>  for a polynomial-time decidable relation  <span class="math">\\mathcal{R}</span>  and some statement x, without revealing any information about w to the verifier  <span class="math">\\mathcal{V}</span>  of the proof except that which can be inferred from the truth of the statement. We'll write relations in the form  <span class="math">\\{(\\text{statement}; \\text{witness}) : \\text{predicate}\\}.</span></p>

    <p class="text-gray-300">We will work with arguments of knowledge which assume computationally bounded provers. We will model  <span class="math">\\mathcal{P}, \\mathcal{V}</span>  as interactive algorithms, with a preliminary algorithm Setup that produces a common reference string  <span class="math">\\sigma</span> . We will denote the transcript of the interaction as  <span class="math">\\langle \\mathcal{P}(\\sigma, x, w), \\mathcal{V}(\\sigma, x; \\rho) \\rangle</span> , with the verifier's internal randomness  <span class="math">\\rho</span>  sometimes being omitted.</p>

    <p class="text-gray-300"><strong>Definition 1 (Perfect Completeness).</strong> (Setup,  <span class="math">\\mathcal{P}, \\mathcal{V}</span> ) has perfect completeness if for all non-uniform polynomial-time adversaries  <span class="math">\\mathcal{A}</span></p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[(x,w) \\notin \\mathcal{R} \\,\\vee\\, \\langle \\mathcal{P}(\\sigma,x,w), \\mathcal{V}(\\sigma,x)\\rangle \\text{ accepts } \\middle| \\begin{array}{l} \\sigma \\leftarrow \\mathsf{Setup}(1^\\lambda) \\\\ (x,w) \\leftarrow \\mathcal{A}(\\sigma) \\end{array}\\right] = 1</span>$</p>

    <h2 id="sec-misc-1" class="text-2xl font-bold">Definition 2 (Computational Witness-Extended Emulation).</h2>

    <p class="text-gray-300">(Setup,  <span class="math">\\mathcal{P}, \\mathcal{V}</span> ) has witness-extended emulation if for all deterministic polynomial-time  <span class="math">\\mathcal{P}^*</span>  there exists an expected polynomial-time emulator  <span class="math">\\mathcal{E}</span>  such that for all pairs of interactive adversaries  <span class="math">\\mathcal{A}_1, \\mathcal{A}_2</span></p>

    <p class="text-gray-300"><span class="math">$\\left| \\Pr \\left[ \\begin{array}{c} \\mathcal{A}_1(tr) = 1 \\\\ \\mathcal{A}_1(tr) = 1 \\\\ x, s) \\leftarrow \\mathcal{A}_2(\\sigma) \\\\ tr \\leftarrow \\left\\langle \\mathcal{P}^*(\\sigma, x, s), \\mathcal{V}(\\sigma, x) \\right\\rangle \\right] - \\left| \\mathbf{c} \\right| \\\\ \\Pr \\left[ \\begin{array}{c} \\mathcal{A}_1(tr) = 1 \\\\ \\wedge (tr \\text{ accepts} \\Rightarrow (x, w) \\in \\mathcal{R}) \\\\ (tr, w) \\leftarrow \\mathcal{E}^{\\mathcal{O}}(\\sigma, x) \\end{array} \\right] \\right| \\leq \\operatorname{negl}(\\lambda)</span>$</p>

    <p class="text-gray-300">where the oracle is given by  <span class="math">\\mathcal{O} = \\langle \\mathcal{P}^*(\\sigma, x, s), \\mathcal{V}(\\sigma, x) \\rangle</span>  and permits rewinding to a specific point and resuming with fresh randomness for the verifier from that point onward. We also define computational witness-extended emulation by restricting to non-uniform polynomial-time adversaries  <span class="math">\\mathcal{A}_1</span>  and  <span class="math">\\mathcal{A}_2</span> .</p>

    <p class="text-gray-300"><strong>Definition 3 (Argument of Knowledge).</strong> (Setup,  <span class="math">\\mathcal{P}</span> ,  <span class="math">\\mathcal{V}</span> ) is an argument of knowledge if it has perfect completeness and computational witness-extended emulation.</p>

    <p class="text-gray-300"><strong>Definition 4 (Public-Coin).</strong> (Setup,  <span class="math">\\mathcal{P}, \\mathcal{V}</span> ) is a public-coin argument if the verifier chooses their messages uniformly at random and independently of the messages sent by the prover, i.e., the challenges correspond to the verifier's randomness  <span class="math">\\rho</span> .</p>

    <h4 id="sec-misc-2" class="text-lg font-semibold mt-6">Definition 5 (Perfect Special Honest-Verifier Zero Knowledge).</h4>

    <p class="text-gray-300">(Setup,  <span class="math">\\mathcal{P}, \\mathcal{V}</span> ) has perfect special honest-verifier zero knowledge (PSHVZK) if for all non-uniform polynomial-time adversaries  <span class="math">\\mathcal{A}_1, \\mathcal{A}_2</span>  and polynomially decidable relation  <span class="math">\\mathcal{R}</span>  with  <span class="math">(x, w) \\in \\mathcal{R}</span>  there exists a probablistic polynomial-time simulator  <span class="math">\\mathcal{S}</span>  such that</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[ \\begin{array}{l} \\mathcal{A}_{1}(tr,\\sigma,x) = 1 \\, \\left| \\, \\begin{array}{l} \\sigma \\leftarrow \\mathsf{Setup}(1^{\\lambda}) \\\\ (x,w,\\rho) \\leftarrow \\mathcal{A}_{2}(\\sigma) \\\\ tr \\leftarrow \\langle \\mathcal{P}(\\sigma,x,w), \\mathcal{V}(\\sigma,x;\\rho) \\rangle \\end{array} \\right] = \\\\ \\Pr\\left[ \\begin{array}{l} \\mathcal{A}_{1}(tr,\\sigma,x) = 1 \\, \\left| \\begin{array}{l} \\sigma \\leftarrow \\mathsf{Setup}(1^{\\lambda}) \\\\ (x,w,\\rho) \\leftarrow \\mathcal{A}_{2}(\\sigma) \\\\ tr \\leftarrow \\mathcal{S}(\\sigma,x,\\rho) \\end{array} \\right. \\right] \\end{array} \\right.</span>$</p>

    <p class="text-gray-300">where  <span class="math">\\rho</span>  is the verifier's internal randomness.</p>

      <h3 id="sec-2.2" class="text-xl font-semibold mt-8">2.2 Groups</h3>

    <p class="text-gray-300">We use the notation  <span class="math">\\mathbb{G}</span>  for a group of prime order p, and  <span class="math">\\mathbb{F}_p</span>  to denote its scalar field. We will often write the field as  <span class="math">\\mathbb{F}</span>  if the size of the field is implied or unimportant. Rather than drawing verifier challenges from  <span class="math">\\mathbb{F}^{\\times}</span>  we will draw them instead from a challenge space  <span class="math">\\mathbb{I} \\subset \\mathbb{F}^{\\times}</span>  that is of size  <span class="math">2^{\\lambda}</span> .</p>

    <p class="text-gray-300">We use uppercase letters to denote group elements, and lowercase letters to denote scalars. Group operations are written additively, and scalar multiplication is denoted by [a] G for  <span class="math">a \\in \\mathbb{F}</span>  and  <span class="math">G \\in \\mathbb{G}</span> . The additive identity in  <span class="math">\\mathbb{G}</span>  is written as  <span class="math">\\mathcal{O}</span> . We use boldface variable names for vectors, such that  <span class="math">\\mathbf{a}</span>  is a vector of scalars and  <span class="math">\\mathbf{G}</span>  is a vector of group elements. All vectors are zero-indexed unless explicitly noted.</p>

    <p class="text-gray-300">We write the inner product  <span class="math">a_0b_0 + a_1b_1 + \\cdots + a_{n-1}b_{n-1}</span>  of scalar vectors  <span class="math">\\mathbf{a}, \\mathbf{b} \\in \\mathbb{F}^n</span> , as  <span class="math">\\langle \\mathbf{a}, \\mathbf{b} \\rangle</span> . Similarly we write the multiscalar multiplication  <span class="math">[a_0]G_0 + [a_1]G_1 + \\cdots + [a_{n-1}]G_{n-1}</span>  of a scalar vector  <span class="math">\\mathbf{a} \\in \\mathbb{F}^n</span>  with a vector of group elements  <span class="math">\\mathbf{G} \\in \\mathbb{G}^n</span> , as  <span class="math">\\langle \\mathbf{a}, \\mathbf{G} \\rangle</span> . We will sometimes write  <span class="math">\\mathbf{G}_{lo}</span>  or  <span class="math">\\mathbf{G}_{hi}</span>  to refer to the first half or second half of a vector of group elements or scalars.</p>

    <p class="text-gray-300">Definition 6 (Discrete Log Relation Assumption). For all adversaries  <span class="math">\\mathcal{A}</span>  and for all  <span class="math">n \\geq 2</span></p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[\\mathbf{G} \\stackrel{\\</span>}{\\leftarrow} \\mathbb{G}^n; \\mathbf{a} \\in \\mathbb{F}^n \\leftarrow \\mathcal{A}(\\mathbb{G}, \\mathbf{G}) : \\exists \\mathbf{a}_i \\neq 0 \\land \\langle \\mathbf{a}, \\mathbf{G} \\rangle = \\mathcal{O}\\right] \\leq \\operatorname{negl}(\\lambda)$$</p>

    <p class="text-gray-300">The discrete log relation assumption generalizes the discrete log assumption to arbitrary numbers of random group elements. We say that  <span class="math">\\langle \\mathbf{a}, \\mathbf{G} \\rangle = \\mathcal{O}</span>  is a non-trivial discrete log relation between elements of  <span class="math">\\mathbf{G}</span>  when at least one of  <span class="math">\\mathbf{a}</span>  is nonzero.</p>

    <p class="text-gray-300">Polynomial commitment schemes [30] form a fundamental building block in many modern arguments of knowledge. [32,17,22,14] In these schemes, a prover can construct commitments to polynomials and then later provably evaluate the committed polynomials at arbitrary points. We present a univariate polynomial commitment scheme (Setup, Commit, Open, VerifyOpen) based on the multivariate scheme of [37], which is itself a variant of the inner product argument first presented in [12], with adaptations from Bulletproofs [13].</p>

    <p class="text-gray-300">First, for a given degree bound d-1 we define  <span class="math">\\mathsf{Setup}(1^{\\lambda}, d)</span>  as an algorithm that produces a common reference string  <span class="math">\\sigma = (\\mathbb{G}, \\mathbb{F}_p, \\mathbf{G}, H)</span>  for group  <span class="math">\\mathbb{G}</span>  of prime order p, with random  <span class="math">\\mathbf{G} \\in \\mathbb{G}^d</span>  and  <span class="math">H \\in \\mathbb{G}</span> . Let Commit be defined as</p>

    <p class="text-gray-300"><span class="math">$\\mathsf{Commit}(\\sigma, p(X); r) = \\langle \\mathbf{a}, \\mathbf{G} \\rangle + [r]H</span>$</p>

    <p class="text-gray-300">for blinding factor r, where  <span class="math">\\mathbf{a}_i \\in \\mathbb{F}</span>  is the coefficient for the ith degree term of p(X), and  <span class="math">p(X) \\in \\mathbb{F}_p[X]</span>  is of maximal degree d-1. We will sometimes omit the blinding factor r if it is either implicit or unnecessary. This is a Pedersen vector commitment to the polynomial coefficients, and we remark that such commitments are perfectly hiding and additively homomorphic:  <span class="math">\\forall a, b, r, s \\in \\mathbb{F}_p</span>  and  <span class="math">p(X), q(X) \\in \\mathbb{F}_p[X]</span>  we have</p>

    <p class="text-gray-300"><span class="math">$\\begin{aligned} &amp;[a]\\operatorname{Commit}(\\sigma,p(X);r)\\\\ &amp;+[b]\\operatorname{Commit}(\\sigma,q(X);s) \\end{aligned} = \\operatorname{Commit}(\\sigma,a\\cdot p(X)+b\\cdot q(X);ar+bs).</span>$</p>

    <p class="text-gray-300">We will have  <span class="math">(\\mathsf{Setup}, \\mathsf{Open}, \\mathsf{VerifyOpen})</span>  be a PSHVZK argument of knowledge for the relation</p>

    <p class="text-gray-300"><span class="math">$\\left\\{ ((P,x,v);(\\mathbf{a},r)): P = \\langle \\mathbf{a},\\mathbf{G} \\rangle + [r]H \\, \\wedge \\, v = \\langle \\mathbf{a},(1,x,x^2,...,x^{d-1}) \\rangle \\right\\}</span>$</p>

    <p class="text-gray-300">which will allow a prover to demonstrate to a verifier that the polynomial contained &quot;inside&quot; the commitment P evaluates to v at x, and moreover, that the committed polynomial has maximum degree d-1.</p>

      <h3 id="sec-3.1" class="text-xl font-semibold mt-8">3.1 Protocol Description</h3>

    <p class="text-gray-300">The protocol takes the polynomial commitment P, point x, and claimed evaluation v as common inputs. In the first move the verifier VerifyOpen sends a random group element  <span class="math">U \\in \\mathbb{G}</span> . Both parties compute</p>

    <p class="text-gray-300"><span class="math">$P&#x27; = P + [v] U</span>$</p>

    <p class="text-gray-300">and begin an argument (described next) to demonstrate that the prover Open knows  <span class="math">\\mathbf{a} \\in \\mathbb{F}_p^d</span>  and  <span class="math">r, v&#x27; \\in \\mathbb{F}_p</span>  such that</p>

    <p class="text-gray-300"><span class="math">$P&#x27; = \\langle \\mathbf{a}, \\mathbf{G} \\rangle + [r]H + [v&#x27;]U</span>$</p>

    <p class="text-gray-300">and that  <span class="math">v&#x27; = \\langle \\mathbf{a}, (1, x, x^2, ..., x^{d-1}) \\rangle</span> . As the prover did not know U in advance, this establishes that v = v'. (In this respect we differ from the protocol described in [37, Appendix A.3] which effectively has U fixed prior to the argument; a prover with malicious control of P would then be able to interfere with the argument by including terms involving U in P.)</p>

    <p class="text-gray-300">Modified Inner Product Bulletproofs [13] presents a variant of the inner product argument [12] in which a prover aims to convince a verifier that they know  <span class="math">\\mathbf{a}, \\mathbf{b} \\in \\mathbb{F}^d</span>  such that</p>

    <p class="text-gray-300"><span class="math">$P&#x27; = \\langle \\mathbf{a}, \\mathbf{G} \\rangle + \\langle \\mathbf{b}, \\mathbf{H} \\rangle + [\\langle \\mathbf{a}, \\mathbf{b} \\rangle] U</span>$</p>

    <p class="text-gray-300">for some given P', and random generators  <span class="math">\\mathbf{G}, \\mathbf{H} \\in \\mathbb{G}^d, U \\in \\mathbb{G}</span> . We use a variant of this argument in which the second vector  <span class="math">\\mathbf{b} = (1, x, x^2, ..., x^{n-1})</span>  is fixed for the given choice of x, and known to both the prover and verifier. As a result no vector  <span class="math">\\mathbf{H}</span>  is necessary. Further, we allow an additional generator H to serve as a mechanism for perfectly blinding both prover messages and the commitment P' itself.</p>

    <p class="text-gray-300">Assume  <span class="math">d = 2^k</span>  for k &gt; 0. Initializing for the prover  <span class="math">\\mathbf{G}&#x27; := \\mathbf{G}, \\mathbf{a}&#x27; := \\mathbf{a}, \\mathbf{b}&#x27; := \\mathbf{b}</span> , we will proceed in k rounds of interaction, where in the jth round (starting with j = k and finishing with j = 1) the prover sends</p>

    <p class="text-gray-300"><span class="math">$L_{j} = \\langle \\mathbf{a&#x27;}_{lo}, \\mathbf{G&#x27;}_{hi} \\rangle + [l_{j}]H + [\\langle \\mathbf{a&#x27;}_{lo}, \\mathbf{b&#x27;}_{hi} \\rangle] U</span>$</p>

    <p class="text-gray-300"><span class="math">$R_{j} = \\langle \\mathbf{a&#x27;}_{hi}, \\mathbf{G&#x27;}_{lo} \\rangle + [r_{j}]H + [\\langle \\mathbf{a&#x27;}_{hi}, \\mathbf{b&#x27;}_{lo} \\rangle] U</span>$</p>

    <p class="text-gray-300">with random blinding factors  <span class="math">l_j, r_j \\in \\mathbb{F}_p</span> . The verifier responds with a random challenge  <span class="math">u_j \\in \\mathbb{I}</span>  and the prover computes</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{a}&#x27; \\leftarrow \\mathbf{a&#x27;}_{\\text{hi}} \\cdot u_j^{-1} + \\mathbf{a&#x27;}_{\\text{lo}} \\cdot u_j</span>$</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{b}&#x27; \\leftarrow \\mathbf{b&#x27;}_{\\text{lo}} \\cdot u_j^{-1} + \\mathbf{b&#x27;}_{\\text{hi}} \\cdot u_j</span>$</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{G}&#x27; \\leftarrow \\mathbf{G&#x27;}_{\\text{lo}} \\cdot u_j^{-1} + \\mathbf{G&#x27;}_{\\text{hi}} \\cdot u_j</span>$</p>

    <p class="text-gray-300">for the next round. After the final round,  <span class="math">\\mathbf{G}&#x27;, \\mathbf{a}&#x27;, \\mathbf{b}&#x27;</span>  are each of length 1. Note that the verifier can compute  <span class="math">G = \\mathbf{G}&#x27;_0</span>  as  <span class="math">\\langle \\mathbf{s}, \\mathbf{G} \\rangle</span>  and  <span class="math">b = \\mathbf{b}&#x27;_0</span>  as  <span class="math">\\langle \\mathbf{s}, \\mathbf{b} \\rangle</span>  where</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{s} = (u_1^{-1} u_2^{-1} \\cdots u_k^{-1}, u_1 u_2^{-1} \\cdots u_k^{-1}, u_1^{-1} u_2 \\cdots u_k^{-1}, u_1 u_2 \\cdots u_k^{-1}, u_1 u_2 \\cdots u_k^{-1}, \\dots</span>$</p>

    <p class="text-gray-300"><span class="math">$\\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\vdots \\qquad \\qquad \\qquad \\vdots \\qquad \\qquad \\qquad \\vdots \\qquad \\qquad \\qquad \\vdots \\qquad \\qquad \\qquad \\vdots \\qquad \\qquad \\qquad \\vdots \\qquad \\qquad \\qquad \\vdots \\qquad \\qquad \\qquad \\qquad \\vdots \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\vdots \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad</span>$</p>

    <p class="text-gray-300">which has a binary counting structure arising from the fact that in each round the inverted challenges are used to scale bases in the first half  <span class="math">\\mathbf{G&#x27;}_{lo}</span> , while the ordinary challenges scale the bases in the second half  <span class="math">\\mathbf{G&#x27;}_{hi}</span> .</p>

    <p class="text-gray-300">The verifier next computes</p>

    <p class="text-gray-300"><span class="math">$Q = \\sum_{j=1}^{k} ([u_j^2]L_j) + P&#x27; + \\sum_{j=1}^{k} ([u_j^{-2}]R_j)</span>$</p>

    <p class="text-gray-300">and the prover proceeds to demonstrate knowledge of  <span class="math">a=\\mathbf{a}&#x27;_0</span>  and synthetic blinding factor  <span class="math">r&#x27;=\\sum_{j=1}^k(l_ju_j^2)+r+\\sum_{j=1}^k(r_ju_j^{-2})</span>  such that</p>

    <p class="text-gray-300">
<span class="math">$Q = [a] G + [r&#x27;]H + [ab] U</span>$</p>

    <p class="text-gray-300">=  <span class="math">[a] (G + [b] U) + [r&#x27;]H</span>  (2)</p>

    <p class="text-gray-300">which establishes the claim that  <span class="math">v = v&#x27; = \\langle \\mathbf{a}, \\mathbf{b} \\rangle</span>  as described in [13, Section 3].</p>

    <p class="text-gray-300">Zero-Knowledge Opening The prover demonstrates knowledge of a, r<sup>0</sup> &isin; F<sup>p</sup> such that <a href="#page-7-0">Equation 2</a> is satisfied, without revealing a, r<sup>0</sup> , in order to establish the claim without revealing anything else about the committed polynomial. We use a generalized Schnorr protocol that is modified from the protocol in <a href="#page-23-4">[37,</a> Appendix A.3] to improve efficiency.</p>

    <p class="text-gray-300">The prover begins by sampling random d, s &isin; F<sup>p</sup> and sending</p>

    <p class="text-gray-300"><span class="math">$R = [d](G + [b]U) + [s]H</span>$</p>

    <p class="text-gray-300">which the verifier responds to with random challenge c &isin; I. The prover now sends</p>

    <p class="text-gray-300"><span class="math">$z_1 = ac + d</span>$
<span class="math">$z_2 = cr&#x27; + s</span>$</p>

    <p class="text-gray-300">and the verifier accepts if [c] Q + R = [z1] (G + [b]U) + [z2]H.</p>

    <p class="text-gray-300">Theorem 1. The protocol presented in <a href="#page-6-1">Section 3.1</a> has perfect completeness, computational witness-extended emulation, and perfect special honest-verifier zero knowledge.</p>

    <p class="text-gray-300">This proof appears in <a href="#page-24-0">Appendix A.</a></p>

      <h3 id="sec-3.2" class="text-xl font-semibold mt-8">3.2 Amortization Strategy</h3>

    <p class="text-gray-300">The polynomial commitment scheme just described suffers from an undesirable asymptotic property: although the communication complexity is logarithmic in the degree bound, the verifier must compute G = hs, Gi and b = hs, bi to accept the argument. One of our novel observations is to exploit the structure of s and b by defining a polynomial</p>

    <p class="text-gray-300">
<span class="math">$g(X, u_1, u_2, ..., u_k) = \\prod_{i=1}^k (u_i + u_i^{-1} X^{2^{i-1}})</span>$
(3)</p>

    <p class="text-gray-300">such that b = hs, bi = g(x, u1, u2, ..., uk) which can be computed by the verifier in logarithmic time. This alone seems uninteresting, as computing G still requires a linear-time multiscalar multiplication. However, observe that</p>

    <p class="text-gray-300"><span class="math">$G = \\mathsf{Commit}(\\sigma, g(X, u_1, u_2, ..., u_k))</span>$</p>

    <p class="text-gray-300">which suggests the following strategy: instead of the verifier computing G itself for multiple (independent) arguments, it can ask an untrusted third-party &quot;helper&quot; to compute each G1, G2, ..., G<sup>m</sup> for m separate arguments and provide an argument that each are correct by demonstrating that a random linear combination of the commitments opens at a random point to a value that the verifier can compute in time O(m log(d)). Due to the degree bound of the polynomial commitment scheme the helper convinces the verifier with high probability (given a large enough field) only if the claimed commitments are correct. This new argument itself requires an invocation of the polynomial commitment opening protocol, and so the verifier still must ultimately perform a linear-time operation. However, the verifier has traded m linear-time operations for one, with a marginal cost that is logarithmic in the degree bound. This is of crucial importance for our later techniques.</p>

    <p class="text-gray-300">The general approach for achieving recursive proof composition is to first obtain a non-interactive argument of knowledge for arithmetic circuit satisfiability (i.e. C(x, w) = 1 for auxiliary input w and public input x), and then to encode the verification algorithm for this argument into such an arithmetic circuit. Assuming that the verification circuit for a proof is sublinear in the size of the circuit that the proof reasons about, then at some threshold it will be possible to recursively verify proofs. In our setting we do not have a protocol which can be fully verified in sublinear time, and so naively applying this strategy will not yield results beyond fixed-depth composition. Instead, we devise a novel technique which allows us to avoid fully verifying proofs at each layer of the recursion, leveraging the fact that our protocol in <a href="#page-10-0">Section 5</a> has sublinear marginal verification time and logarithmic proof size.</p>

    <p class="text-gray-300">Arithmetic circuits are often encoded into systems of constraints such that, given a satisfying assignment of variables (the prover's witness), the satisfaction of the constraint system implies the satisfiability of the circuit. The inherent non-determinism in this process means that some expensive operations can be performed more efficiently when the prover is allowed to assist. As an example, in circuits where a field inversion of a variable u must be computed, rather than exponentiating &quot;in the circuit&quot; (u <sup>p</sup>&minus;<sup>2</sup> which requires log(p) multiplication constraints), the prover can instead witness v = u <sup>&minus;</sup><sup>1</sup> and show that it is the correct inverse with the single multiplication constraint uv = 1. We will exploit this non-determinism in a slightly different way: when our circuit contains an expensive fixed operation f that is invoked with some input x we will instead allow the prover to witness y = f(x) and then take (x, y) as public inputs to the circuit. The circuit can then proceed under the assumption that y is correct, delegating the responsibility of checking the correctness of y to the verifier of the proof.</p>

    <p class="text-gray-300">In the context of proof composition, we apply this optimization so that a verification circuit for a proof will not perform any linear-time (or otherwise expensive) operation f but rather take their inputs and the prover's alleged outputs (x, y) as public inputs to its own circuit. Observe that as proofs are continually composed, increasing instances of (x, y) accumulate because the verification circuit will not check them but rather continually delegate these checks to its verifier. In order to prevent this runaway cost we introduce an amortization strategy: given instances (x, y) and (x 0 , y<sup>0</sup> ), the prover will provide a non-interactive proof that y = f(x) and y <sup>0</sup> = f(x 0 ) as a witness to the verification circuit, and the verification circuit will check this proof. In order to fully check this amortization proof the verification circuit may need to perform a linear-time (or otherwise expensive) operation. However, if this operation is equivalent to invoking f then the verifier has collapsed the two instances (x, y) and (x 0 , y<sup>0</sup> ) into a single fresh instance (x <sup>00</sup>, y00), allowing us to continually amortize away the cost of invoking f as proofs are composed. It is only &quot;outside&quot; of the circuit that f is invoked once by the ultimate verifier, demonstrating the correctness of the entire underlying tree of proofs by induction. We refer to this strategy as &quot;nested amortization.&quot;</p>

    <p class="text-gray-300">The public-coin PSHVZK argument of knowledge for arithmetic circuit satisfiability described in <a href="#page-10-0">Section 5</a> is designed to exploit this nested amortization strategy, leveraging the polynomial commitment amortization technique we explored in <a href="#page-8-0">Section 3.2.</a> The setting is described as a stream of arguments from the prover to the verifier, where the verifier will maintain logarithmic-size state and perform logarithmic-time operations to partially verify each proof in sequence. Finally, at the end of a stream of proofs the verifier will choose to accept or reject all of them simultaneously in linear time. By applying the Fiat&ndash;Shamir heuristic <a href="#page-22-9">[21]</a> in <a href="#page-15-0">Section 6</a> we can transform this argument into a non-interactive zero-knowledge argument of knowledge. The result is then grafted to the nested amortization technique, where the &quot;state&quot; maintained by the verifier is merely the deferred values that are shepherded through public inputs. This leads directly to a recursive proof of arbitrary depth<a href="#page-10-1">2</a> where the verifier outside of the circuit will be responsible only for checking the correctness of the verifier state once, with a linear-time operation that is never performed inside the circuit.</p>

    <p class="text-gray-300">The main argument of Sonic <a href="#page-23-5">[32]</a> allows a prover to demonstrate the satisfiability of an arithmetic circuit (e.g., C(x, w) = 1) for some public input x and auxiliary input w. Our main protocol is a variant of Sonic that is adapted to the polynomial commitment scheme described in <a href="#page-6-0">Section 3.</a> We will work within a restricted setting to aid later exposition: the circuit C is fixed, and the prover will repeatedly interact with the verifier to engage in multiple arguments in sequence. Our goal will be for the verifier to perform logarithmic marginal work in choosing to accept or reject all of the arguments simultaneously, leveraging the technique described in <a href="#page-8-0">Section 3.2</a> as well as an analogous technique described in Section 8 of <a href="#page-23-5">[32]</a>.</p>

    <p class="text-gray-300">In all of the following let N, Q, k be integers such that d = 4N = 2<sup>k</sup> and 3Q &lt; d. Let the common reference string &sigma; &larr; Setup(1<sup>&lambda;</sup> , d) be shared between the prover and verifier.</p>

      <h3 id="sec-5.1" class="text-xl font-semibold mt-8">5.1 Central Argument</h3>

    <p class="text-gray-300">The prover aims to demonstrate that C(x, w) = 1 for public input x and auxiliary (witness) input w without revealing w. It will do so by demonstrating that a</p>

    <p class="text-gray-300"><sup>2</sup> We remark that, theoretically, the knowledge extractor requires a number of transcripts from the prover that increases exponentially as the depth increases. However, there are no known attacks and this concern is often disregarded in practice. In any case, applications can sometimes sidestep this theoretical concern by restricting to a fixed-depth tree of proofs as in <a href="#page-21-2">[8]</a>.</p>

    <p class="text-gray-300">system of arithmetic constraints that encodes  <span class="math">\\mathcal{C}</span>  is satisfied for witness  <span class="math">\\mathbf{a}, \\mathbf{b}, \\mathbf{c} \\in \\mathbb{F}^N</span>  known only to the prover and some instance  <span class="math">\\mathbf{k} \\in \\mathbb{F}^Q</span>  which encodes the public inputs. This system of constraints consists of N multiplication constraints, where the ith such constraint is of the form</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{a}_i \\cdot \\mathbf{b}_i = \\mathbf{c}_i</span>$</p>

    <p class="text-gray-300">and Q linear constraints, where the qth such constraint is of the form</p>

    <p class="text-gray-300"><span class="math">$\\left(\\sum_{i=1}^{N}\\mathbf{a}_{i}\\cdot(\\mathbf{u}_{q})_{i}\\right)+\\left(\\sum_{i=1}^{N}\\mathbf{b}_{i}\\cdot(\\mathbf{v}_{q})_{i}\\right)+\\left(\\sum_{i=1}^{N}\\mathbf{c}_{i}\\cdot(\\mathbf{w}_{q})_{i}\\right)=\\mathbf{k}_{q}</span>$</p>

    <p class="text-gray-300">for some fixed  <span class="math">\\mathbf{u}_q, \\mathbf{v}_q, \\mathbf{w}_q \\in \\mathbb{F}^N</span>  that encode  <span class="math">\\mathcal{C}</span> . Just as in [32] we will embed all of these constraints into a single equation in formal indeterminate Y</p>

    <p class="text-gray-300">
<span class="math">$\\sum_{i=1}^{N} \\mathbf{a}_{i} \\cdot Y^{N} u_{i}(Y) + \\sum_{i=1}^{N} \\mathbf{b}_{i} \\cdot Y^{N} v_{i}(Y) + \\sum_{i=1}^{N} \\mathbf{c}_{i} \\cdot (Y^{N} w_{i}(Y) - Y^{i} - Y^{-i}) + \\sum_{i=1}^{N} \\mathbf{a}_{i} \\mathbf{b}_{i} \\cdot (Y^{i} + Y^{-i}) - Y^{N} k(Y) = 0</span>$
(4)</p>

    <p class="text-gray-300">where we define the polynomials</p>

    <p class="text-gray-300"><span class="math">$u_i(Y) = \\sum_{q=1}^{Q} Y^q(\\mathbf{u}_q)_i \\qquad v_i(Y) = \\sum_{q=1}^{Q} Y^q(\\mathbf{v}_q)_i</span>$
<span class="math">$w_i(Y) = \\sum_{q=1}^{Q} Y^q(\\mathbf{w}_q)_i \\qquad k(Y) = \\sum_{q=1}^{Q} Y^q \\mathbf{k}_q</span>$</p>

    <p class="text-gray-300">such that given a choice of  <span class="math">\\mathbf{a}, \\mathbf{b}, \\mathbf{c}, \\mathbf{k}</span>  we have that Equation 4 holds at all points when the constraint system is satisfied. Thus, given a large enough field the equation will not hold at a random point (with high probability) if the constraint system is not safisfied. Given a second formal indeterminate X let us define the polynomials</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} r(X,Y) &amp;= \\sum_{i=1}^{N} \\mathbf{a}_{i} X^{i} Y^{i} \\, + \\, \\sum_{i=1}^{N} \\mathbf{b}_{i} X^{-i} Y^{-i} \\, + \\, \\sum_{i=1}^{N} \\mathbf{c}_{i} X^{-i-N} Y^{-i-N} \\\\ s(X,Y) &amp;= \\sum_{i=1}^{N} u_{i}(Y) X^{-i} \\, + \\, \\sum_{i=1}^{N} v_{i}(Y) X^{i} \\, + \\, \\sum_{i=1}^{N} w_{i}(Y) X^{i+N} \\\\ s&#x27;(X,Y) &amp;= Y^{N} s(X,Y) \\, - \\, \\sum_{i=1}^{N} (Y^{i} + Y^{-i}) X^{i+N} \\\\ t(X,Y) &amp;= r(X,1) (r(X,Y) + s&#x27;(X,Y)) - Y^{N} k(Y) \\end{split}</span>$</p>

    <p class="text-gray-300">such that the constant term of t(X,Y) is exactly the left-hand side of Equation 4. Observe that because r(X,Y)=r(XY,1) the prover can commit to r(X,Y) using a univariate polynomial commitment scheme, i.e.  <span class="math">\\mathsf{Commit}(\\sigma,r(X,1))</span> . The</p>

    <p class="text-gray-300">remaining polynomials are fully determined by this choice of r(X,Y) and do not depend on the witness  <span class="math">\\mathbf{a}, \\mathbf{b}, \\mathbf{c}</span> . The general strategy is for the prover to send a commitment to r(X,Y) and then to demonstrate that the constant term of t(X,Y) is the zero polynomial. The verifier will sample a random  <span class="math">y \\in \\mathbb{I}</span>  and ask the prover to commit to t(X,y). The commitments will be checked for consistency: the verifier will choose a random  <span class="math">x \\in \\mathbb{I}</span> , and the prover will open its commitments to a = r(x,1), b = r(x,y) and t = t(x,y), such that</p>

    <p class="text-gray-300"><span class="math">$t = a(r + s&#x27;(x, y)) - k(y)</span>$</p>

    <p class="text-gray-300">gives us that the commitment to t(X,y) is correct with high probability. If the prover can convince the verifier that their commitment to r(X,Y) is bounded at degree N then we have that the constant term of t(X,Y) is exactly the left-hand side of Equation 4, and if the constant term of this commitment can be shown to be zero then with high probability the prover has knowledge of a satisfying witness.</p>

    <p class="text-gray-300">Committing to r(X,Y) In order to show that the degree of r(X,Y) is bound at N, the prover will instead send  <span class="math">R = \\mathsf{Commit}(\\sigma, r(X,1)X^{3N-1}; \\delta_R)</span>  for some blinding factor  <span class="math">\\delta_R \\in \\mathbb{F}</span>  so that the degree bound d-1=4N-1 restricts the prover. The verifier need only rescale openings of this commitment by  <span class="math">X^{-3N+1}</span>  to obtain the desired value.</p>

    <p class="text-gray-300">Blinding r(X,Y) The commitment R is perfectly blinded by the prover's choice of  <span class="math">\\delta_R</span> . The prover will eventually open r(X,Y) at various points for the verifier to check consistency with the prover's commitment to t(X,y). This will reveal some information about the witness  <span class="math">\\mathbf{a}, \\mathbf{b}, \\mathbf{c}</span> . We resolve this by designating seven of these wire values as random blinding factors; as shown in the proof of Theorem 2 the verifier will then not learn a sufficient number of evaluations of r(X,Y) to distinguish the committed polynomial from random.</p>

    <p class="text-gray-300">Committing to t(X,y) Observe that t(X,y) has exponents of X that span from  <span class="math">X^{-4N}</span>  to  <span class="math">X^{3N}</span> , with a constant term of zero. Let  <span class="math">t_{\\rm lo}(X,y)</span>  and  <span class="math">t_{\\rm hi}(X,y)</span>  be polynomials of degree d-1 such that  <span class="math">t(X,y)=t_{\\rm lo}(X,y)X^{-d}+t_{\\rm hi}(X,y)X</span> . Rather than committing directly to t(X,y) the prover will demonstrate that its constant term is zero by separately sending  <span class="math">T_{\\rm lo}={\\sf Commit}(\\sigma,t_{\\rm lo}(X,y),\\delta_{\\rm lo})</span>  and  <span class="math">T_{\\rm hi}={\\sf Commit}(\\sigma,t_{\\rm hi}(X,y),\\delta_{\\rm hi})</span>  for blinding factors  <span class="math">\\delta_{\\rm lo},\\delta_{\\rm hi}\\in\\mathbb{F}</span> , and the pair of commitments will then be taken as a commitment to a Laurent polynomial with a constant term of zero due to the degree bound of the polynomial commitment scheme, and the verifier will again rescale commitment openings as appropriate.</p>

    <p class="text-gray-300">Committing to k(Y) In our setting it will ultimately be more efficient for the prover and verifier to compute  <span class="math">K = \\mathsf{Commit}(\\sigma, k(Y))</span>  so that the prover can open this commitment at y on behalf of the verifier, rather than requiring the verifier to evaluate k(y) itself.</p>

    <p class="text-gray-300">Amortizing the Evaluation of s 0 (x, y) In the protocol described so far, the verifier must evaluate s 0 (x, y) to accept the argument. Instead we will borrow a strategy from <a href="#page-23-5">[32]</a> in which the prover sends S = Commit(&sigma;, s(X, y)X<sup>N</sup> ) prior to the verifier's choice of x and then later opens this commitment at x, which the verifier rescales by x <sup>&minus;</sup><sup>N</sup> to obtain the desired value s(x, y) and uses this to compute s 0 (x, y) in logarithmic time. It remains for the verifier to check that the commitment S is correct, which would ordinarily require work that is linear in |C|. Recall that in our setting we permit the verifier to perform a linear-time operation only at the end of a sequence of arguments, and that the marginal cost of checking an argument must be logarithmic in |C|.</p>

    <p class="text-gray-300">We address this using a technique inspired by Section 8 of <a href="#page-23-5">[32]</a>. Each argument will produce a value ynew and a value Snew that is purportedly equal to Commit(&sigma;, s(X, ynew)X<sup>N</sup> ). Let (yold, Sold) be the values (ynew, Snew) produced from the previous argument. The prover will demonstrate that S and Sold are correct by sending C = Commit(&sigma;, s(x, Y ) x <sup>N</sup> ) following the verifier's choice of x, and then opening C at yold, y to the same values that Sold and S open at x, respectively. This establishes with high probability that each commitment is to the correct polynomial assuming that C is a commitment to the correct polynomial. Instead of checking the correctness of C the verifier will sample random ynew &isin; I and ask the prover to supply Snew = Commit(&sigma;, s(X, ynew)X<sup>N</sup> ). The prover will demonstrate that Snew opens at x to the same value that C opens at ynew. The correctness of Snew then demonstrates the correctness of C with high probability. The verifier will now take this (ynew, Snew) for the next argument. In order to accept a sequence of arguments the verifier will need to check that Snew = Commit(&sigma;, s(X, ynew)X<sup>N</sup> ) for the final argument but otherwise does not perform linear-time marginal work with respect to evaluating s(X, Y ).</p>

    <p class="text-gray-300">Combining Polynomial Commitment Opening Arguments In the protocol described so far the prover and verifier must engage in several separate polynomial commitment opening arguments. The commitments R, Sold, S, Snew, Tlo, Thi must each be opened at x, the commitments K, C must be opened at y, the commitment R must be opened at xy and the commitment C must be opened at yold and ynew. We use a batch opening strategy from <a href="#page-23-6">[30]</a> which leverages the fact that our polynomial commitments are additively homomorphic. Given a verifier challenge z<sup>1</sup> let</p>

    <p class="text-gray-300"><span class="math">$P = R + [z_1]\\,S_{\\rm old} + [z_1^2]\\,S + [z_1^3]\\,S_{\\rm new} + [z_1^4]\\,T_{\\rm lo} + [z_1^5]\\,T_{\\rm hi} = {\\sf Commit}(\\sigma, p(X))</span>$</p>

    <p class="text-gray-300">and Q = K + [z1] C = Commit(&sigma;, q(X)) for implicitly defined polynomials p(X), q(X) &isin; F[X]. The prover will send the openings for each of R, Sold, S, Snew, Tlo, Thi at x and for each of K, C at y prior to the choice of z1, and then the prover will proceed to open P at x and Q at y to values the verifier can compute itself, convincing it with high probability that the openings are each correct due to the degree bound of the polynomial commitment scheme.</p>

    <p class="text-gray-300">In order to reduce five separate opening arguments to one we use a technique inspired by [11]. In general for distinct evaluation points  <span class="math">x_0, x_1, ..., x_{m-1}</span>  we will define the polynomial</p>

    <p class="text-gray-300"><span class="math">$h(X,Y) = \\sum_{i=0}^{m-1} Y^{i} \\frac{e_{i}(X) - v_{i}}{X - x_{i}}</span>$</p>

    <p class="text-gray-300">where for m commitments  <span class="math">E_0, E_1, ..., E_{m-1}</span>  each  <span class="math">E_i = \\mathsf{Commit}(\\sigma, e_i(X))</span>  will be opened at point  <span class="math">x_i</span>  to value  <span class="math">v_i</span> . The prover sends the openings  <span class="math">v_i = p_i(x_i)</span>  for all i and is then given a random challenge  <span class="math">z_2</span> . The prover sends the commitment  <span class="math">H = \\mathsf{Commit}(\\sigma, h(X, z_2); \\delta_H)</span>  for some blinding factor  <span class="math">\\delta_H \\in \\mathbb{F}</span> . In order to establish the correctness of H with respect to the previous commitments the prover will open P, Q, R, C, H at a fresh challenge point  <span class="math">z_3</span>  from the verifier, where the verifier can compute the expected opening of H itself given the prover's claimed openings. Given that P, Q, R, C are fixed prior to the choice of  <span class="math">z_2, z_3</span>  we see that H is a commitment to the correct polynomial with high probability, and thus by the factor theorem we conclude that the openings of P, Q, R, C are correct with high probability. In order to collapse the openings of P, Q, R, C, H at  <span class="math">z_3</span>  together into a single invocation of the polynomial commitment opening argument we will use the same technique as before, i.e. the verifier will sample random  <span class="math">z_4</span>  and the prover will open  <span class="math">P + [z_4] Q + [z_4^2] R + [z_4^3] C + [z_4^4] H</span>  to the value the verifier can compute itself using the prover's claimed openings.</p>

    <p class="text-gray-300">Amortizing the Evaluation of G The argument so far requires the verifier to compute  <span class="math">G = \\langle \\mathbf{s}, \\mathbf{G} \\rangle</span>  as described in Section 3.2. This requires a multiscalar multiplication that is linear in the degree bound and thus also linear in  <span class="math">|\\mathcal{C}|</span> . As mentioned previously, in our setting we require that the verifier only perform a single operation that is linear time in  <span class="math">|\\mathcal{C}|</span>  at the end of the argument and otherwise expend only logarithmic marginal work to accept each individual argument.</p>

    <p class="text-gray-300">We resolve this with a similar strategy as before, amortizing evaluations of s'(X,Y) by using the technique discussed in Section 3.2. The prover will provide the verifier with the purported value  <span class="math">G \\in \\mathbb{G}</span> . The verification of each argument will produce values  <span class="math">G_{\\text{new}} = G</span>  and challenges  <span class="math">(u_{\\text{new}})_1, (u_{\\text{new}})_2, ..., (u_{\\text{new}})_k</span> . Rather than checking  <span class="math">G_{\\text{new}} = \\text{Commit}(\\sigma, g(X, (u_{\\text{new}})_1, (u_{\\text{new}})_2, ..., (u_{\\text{new}})_k))</span>  the verifier will ask the prover to open  <span class="math">G_{\\text{new}}</span>  at  <span class="math">x \\in \\mathbb{F}</span>  in the next argument. Let  <span class="math">(G_{\\text{old}}, (u_{\\text{old}})_1, (u_{\\text{old}})_2, ..., (u_{\\text{old}})_k)</span>  be the values  <span class="math">(G_{\\text{new}}, (u_{\\text{new}})_1, (u_{\\text{new}})_2, ..., (u_{\\text{new}})_k)</span>  produced from the previous argument. We will modify P such that</p>

    <p class="text-gray-300"><span class="math">$P = R + [z_1]\\,S_{\\rm old} + [z_1^2]\\,S + [z_1^3]\\,S_{\\rm new} + [z_1^4]\\,T_{\\rm lo} + [z_1^5]\\,T_{\\rm hi} + [z_1^6]\\,G_{\\rm old}</span>$</p>

    <p class="text-gray-300">so that  <span class="math">G_{\\text{old}}</span>  is opened at x, and we note that the verifier can compute the expected opening of  <span class="math">G_{\\text{old}}</span>  in logarithmic time using Equation 3. The verifier will thus be convinced of the correctness of each value  <span class="math">G_{\\text{new}}</span>  in a sequence of arguments so long as the final  <span class="math">G_{\\text{new}}</span>  sent by the prover is correct.</p>

      <h3 id="sec-5.2" class="text-xl font-semibold mt-8">5.2 Full Protocol</h3>

    <p class="text-gray-300">We now bring together a full description of the protocol. The prover and verifier will engage in a series of PSHVZK arguments of knowledge for relation R defined as</p>

    <p class="text-gray-300">$$\\mathcal{R} = \\begin{cases}
((G_{\\text{old}}, S_{\\text{old}}, y_{\\text{old}}, (u_{\\text{old}})<em>1, (u</em>{\\text{old}})<em>2, ..., (u</em>{\\text{old}})<em>k, \\mathbf{k}); (\\mathbf{a}, \\mathbf{b}, \\mathbf{c})) : \\
\\forall i \\ (\\mathbf{a}_i \\cdot \\mathbf{b}_i = \\mathbf{c}_i) \\
\\land \\forall q \\left[ \\left( \\sum</em>{i=1}^N \\mathbf{a}<em>i \\cdot (\\mathbf{u}_q)_i \\right) + \\left( \\sum</em>{i=1}^N \\mathbf{b}<em>i \\cdot (\\mathbf{v}_q)_i \\right) + \\left( \\sum</em>{i=1}^N \\mathbf{c}<em>i \\cdot (\\mathbf{w}_q)_i \\right) = \\mathbf{k}_q \\right] \\
\\land G</em>{\\text{old}} = \\mathsf{Commit}(\\sigma, g(X, (u_{\\text{old}})<em>1, (u</em>{\\text{old}})<em>2, ..., (u</em>{\\text{old}})<em>k)) \\
\\land S</em>{\\text{old}} = \\mathsf{Commit}(\\sigma, s(X, y_{\\text{old}}))
\\end{cases} (5)$$</p>

    <p class="text-gray-300">where the verifier will not immediately choose to accept or reject each individual argument, as it requires the computation of Gnew, Snew each requiring linear time in |C|. Instead the prover will take the values as Gold, Sold for the next argument and suspend its decision to accept. After the final argument the verifier will check the values Gnew, Snew in linear time. The full interactive protocol is described in <a href="#page-16-0">Figure 1.</a></p>

    <p class="text-gray-300">Theorem 2. The protocol presented in <a href="#page-16-0">Figure 1</a> has perfect completeness, perfect special honest-verifier zero knowledge, and computational witness-extended emulation.</p>

    <p class="text-gray-300">This proof appears in <a href="#page-25-0">Appendix B.</a></p>

    <p class="text-gray-300">We apply the Fiat&ndash;Shamir heuristic to the protocol from <a href="#page-10-0">Section 5</a> to obtain a non-interactive argument of knowledge that is secure in the random oracle model and has perfect zero knowledge. The verifier's challenges are substituted for outputs of a secure hash function over the transcript of messages sent previously by the prover. We instantiate this scheme in the uniform random string model by taking the group elements in &sigma; as outputs of a hash function that models a random function. Recall from <a href="#page-10-0">Section 5</a> that the verifier performs two distinct operations when checking a stream of proofs. The verifier maintains a state st and, upon receiving a proof, performs a verification operation that is logarithmictime in the circuit size. This operation produces an updated st that the verifier uses for the next proof. Finally, at the end of a sequence of proofs the verifier performs a linear-time operation to check the correctness of st and then chooses to accept or reject all previous proofs. This arrangement is deliberately designed to leverage the nested amortization strategy described in <a href="#page-9-0">Section 4.</a> The circuit encodes the logarithmic-time proof checking operation, taking st as a public input to the circuit. The ultimate verifier of the recursive proof performs the final linear-time operation outside of the circuit. The result is that the circuit converges to a finite size and so recursive proof composition can be achieved.</p>

    <p class="text-gray-300">
<span class="math">$\\begin{array}{llll} &amp; \\text{Common inputs: } \\sigma, G_{\\text{old}}, (u_{\\text{old}})_1, (u_{\\text{old}})_2, ..., (u_{\\text{old}})_k, S_{\\text{old}}, y_{\\text{old}}, K = \\text{Commit}(\\sigma, k(Y)) \\\\ &amp; \\text{Prover inputs: } \\mathbf{a}, \\mathbf{b}, \\mathbf{c} \\\\ &amp; &amp; \\\\ &amp; Prover \\\\ &amp; \\delta_R \\overset{\\</span>}{\\leftarrow} \\mathbb{F}, \\quad R \\leftarrow \\text{Commit}(\\sigma, r(X, 1)X^{3N-1}; \\delta_R) \\ &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; \\ &amp; &amp; &amp; \\ &amp; &amp; &amp; \\ &amp; &amp; &amp; \\ &amp; &amp; &amp; \\ &amp; &amp; &amp; \\ &amp; &amp; &amp; \\ &amp; &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp; &amp; \\ &amp;$$</p>

    <p class="text-gray-300">The verifier now checks that  <span class="math">v_5x^{-d} + v_6x = v_1x^{-3N+1}(v_9x^{-3N+1} + v_3y^n - \\sum_{i=1}^N (y^i + y^{-i})x^{i+N}) - v_8y^n</span>  in logarithmic time, checks  <span class="math">v_7</span>  in logarithmic time using Equation 3 and engages in the polynomial commitment opening argument with the prover to see that the commitment</p>

    <p class="text-gray-300"><span class="math">$R + [z_1] S_{\\text{old}} + [z_1^2] S + [z_1^3] S_{\\text{new}} + [z_1^4] T_{\\text{lo}} + [z_1^5] T_{\\text{hi}} + [z_1^6] G_{\\text{old}}</span>$</p>

    <p class="text-gray-300"><span class="math">$+ [z_4] (K + [z_1] C) + [z_4^2] R + [z_4^3] C + [z_4^4] H</span>$</p>

    <p class="text-gray-300">opens at  <span class="math">z_3</span>  to the expected value</p>

    <p class="text-gray-300"><span class="math">$v_{10} + z_4 v_{11} + z_4^2 v_{12} + z_4^3 v_{13} + z_4^4 \\left( z_2 \\frac{v_{11} - (v_8 + z_1 v_3)}{z_3 - y} + z_2^2 \\frac{v_{12} - v_9}{z_3 - xy} + z_2^3 \\frac{v_{13} - v_2}{z_3 - y_{\\text{old}}} \\right) + z_2^4 \\frac{v_{13} - v_4}{z_3 - y_{\\text{new}}} + \\frac{v_{10} - (v_1 + z_1 v_2 + z_1^2 v_3 + z_1^3 v_4 + z_1^4 v_5 + z_1^5 v_6 + z_1^6 v_7)}{z_3 - x}.</span>$</p>

    <p class="text-gray-300">Fig. 1: PSHVZK argument of knowledge for relation  <span class="math">\\mathcal{R}</span> .</p>

    <p class="text-gray-300">In practice we will use the Rescue [1] algebraic hash function for prime fields to obtain verifier challenges. We instantiate it with a duplex sponge construction [7] where prover messages are &quot;absorbed&quot; and verifier challenges are &quot;squeezed.&quot;</p>

      <h3 id="sec-6.1" class="text-xl font-semibold mt-8">6.1 Cycles of Curves</h3>

    <p class="text-gray-300">The partial verification operation for a proof (which is encoded in the circuit) is dominated by group operations. If we were to instantiate our protocol over an arbitrary elliptic curve E over base field  <span class="math">\\mathbb{F}_p</span> , for security reasons we must obtain a group of prime order  <span class="math">q \\neq p</span> . This presents a challenge as our protocol will demonstrate arithmetic circuit satisfaction over the scalar field  <span class="math">\\mathbb{F}_q</span> , and simulating  <span class="math">\\mathbb{F}_p</span>  arithmetic over a distinct field is expensive. This efficiency problem was addressed in [4] by finding a &quot;2-cycle&quot;  <span class="math">E_p, E_q</span>  of elliptic curves, constructed over the base fields  <span class="math">\\mathbb{F}_p</span>  and  <span class="math">\\mathbb{F}_q</span>  respectively, such that  <span class="math">\\#E_p = q</span>  and  <span class="math">\\#E_q = p</span> . This allows proofs constructed using the group  <span class="math">E_p</span>  to efficiently reason about proofs constructed over  <span class="math">E_q</span> , and vice versa, as the group operations needed to verify proofs consist of operations in each proving system's native field. We remark that although [4] sought pairing-friendly elliptic curve groups, we can use &quot;normal&quot; elliptic curve groups, and secure 2-cycles of such groups are empirically abundant and easy to find.</p>

    <p class="text-gray-300">We performed a search for the 2-cycle used in our implementation, seeking curves that had highly 2-adic scalar fields; both fields have large  <span class="math">2^k</span>  primitive roots of unity for applying radix-2 FFTs to accelerate polynomial multiplication. We also ensured that both fields have elements of multiplicative order 3 so that we can apply curve endomorphisms to optimize our circuit, and that  <span class="math">\\gcd(p-1,5)=\\gcd(q-1,5)=1</span>  in order to allow instantiating the Rescue hash function with  <span class="math">\\alpha=5</span> . We affectionately refer to the resulting curves as Tweedledum and Tweedledee. [15]</p>

    <pre><code class="language-text">E_p/\\mathbb{F}_p: y^2=x^3+5 of order q is called Tweedledum; E_q/\\mathbb{F}_q: y^2=x^3+5 of order p is called Tweedledee;
</code></pre>

    <p class="text-gray-300">where p and q are 255-bit primes:</p>

    <pre><code class="language-text">\\begin{array}{l} p = 2^{254} + 4707489545178046908921067385359695873; \\\\ q = 2^{254} + 4707489544292117082687961190295928833. \\end{array}
</code></pre>

    <p class="text-gray-300">The software used to generate these curves and to test various security properties is available at [26]. Its documentation describes how to reproduce this generation.</p>

    <p class="text-gray-300">Both curves have 126-bit security against Pollard rho attacks; this takes into account that the additional endomorphisms may be used to speed up Pollard rho and similar discrete log algorithms [5] [20].<sup>3</sup></p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;3</sup> A conservative estimate of the available improvement to Pollard rho is that on a group of prime order q with an automorphism group of order 6, the attack cost is  <span class="math">\\sqrt{\\frac{\\pi q}{12}}</span> , as compared to  <span class="math">\\sqrt{\\frac{\\pi q}{4}}</span>  using only the negation map as described in [6]. That is, the maximum speed-up is only a factor of  <span class="math">\\sqrt{3} \\approx 1.732</span>  for a given success probability.</p>

    <p class="text-gray-300">Use of prime-order curves simplifies protocols and security analysis, avoiding error-prone techniques such as cofactor multiplication that may be applied incorrectly. However, the most efficient addition formulae for these curves are incomplete: they do not work correctly when adding two points with the same x-coordinate. In our circuits, we pay due attention to this issue and specify additional checks where necessary. With care, we can safely use incomplete addition within the scalar multiplications that dominate the circuit size [27]. In curve arithmetic performed outside the circuit, or if the same curves are used elsewhere in an application protocol, close attention to this issue is needed from implementors. Suitable complete, constant-time formulae for prime-order short Weierstrass curves are given in [34] or [35]. We recommend that fault attacks on the prover be addressed by validating the proof immediately after creating it.</p>

      <h3 id="sec-6.2" class="text-xl font-semibold mt-8">6.2 Endomorphism-based Optimizations</h3>

    <p class="text-gray-300">Our method of searching for 2-cycles finds curves  <span class="math">E/\\mathbb{F}_p</span>  with an endomorphism  <span class="math">\\phi</span>  defined on  <span class="math">\\mathbb{F}_p</span> -rational points by  <span class="math">\\phi((x,y)) = (\\zeta_p x,y)</span> , where  <span class="math">\\phi(P) = [\\zeta_q]P</span>  for some  <span class="math">\\zeta_q \\in \\mathbb{F}_q</span>  of multiplicative order 3 (and similarly with p and q exchanged). We leverage this endomorphism to optimize the multiplication of group elements by challenges, which is the dominating cost of partial proof verification in the circuit. Let  <span class="math">\\mathbf{r} \\in \\{0,1\\}^{\\lambda}</span>  be a verifier challenge. Rather than interpreting  <span class="math">\\mathbf{r}</span>  as a scalar and performing a scalar multiplication of a  <span class="math">\\mathbb{F}_p</span> -rational point P, we will apply the endomorphism to multiply by a scalar that is dependent on  <span class="math">\\mathbf{r}</span>  using the following algorithm:</p>

    <pre><code class="language-text">ALGORITHM 1
Inputs: \\mathbf{r} \\in \\{0,1\\}^{\\lambda}, P \\in E \\setminus \\{\\mathcal{O}\\}
Acc := [2](\\phi(P) + P)
for i from \\lambda/2 - 1 down to 0:
let S_i = \\begin{cases} [2\\mathbf{r}_{2i} - 1]P, &amp; \\text{if } \\mathbf{r}_{2i+1} = 0\\\\ \\phi([2\\mathbf{r}_{2i} - 1]P), &amp; \\text{otherwise} \\end{cases}
Acc := (\\mathsf{Acc} + S_i) + \\mathsf{Acc}
Output Acc
</code></pre>

    <p class="text-gray-300">Algorithm 1 can be implemented with 3.5 multiplication constraints per bit of  <span class="math">\\mathbf{r}</span> . We show in Appendix C that this algorithm is equivalent to computing  <span class="math">[n(\\mathbf{r})]P</span>  where for the Tweedledum and Tweedledee curves with  <span class="math">\\lambda=128,\\ n:\\{0,1\\}^\\lambda\\mapsto\\mathbb{I}</span>  is injective.</p>

      <h3 id="sec-6.3" class="text-xl font-semibold mt-8">6.3 Other Optimizations</h3>

    <p class="text-gray-300">In the polynomial commitment scheme described in Section 3 the verifier samples a challenge u in each round of the modified inner product argument. The verifier will compute  <span class="math">[u^{-2}]L</span>  and  <span class="math">[u^2]R</span>  in each round to check the proof. It is possible for the prover to witness  <span class="math">L&#x27; = [u^{-2}]L</span>  and then in the circuit multiply L' by  <span class="math">u^2</span></p>

    <p class="text-gray-300">to obtain the expected value L, demonstrating the correctness of L'. In order to improve the performance of computing  <span class="math">[u^2]P</span>  for arbitrary  <span class="math">P \\in \\mathbb{G}</span>  we modify the protocol so that the verifier samples its challenge as  <span class="math">u^2</span>  instead. Approximately half of all challenges in  <span class="math">\\mathbb{I}</span>  will be square, and so the prover can always rewind and sample new randomness for their values L, R until the verifier samples a square challenge. Thus, rather than computing [u] ([u]P) the circuit can directly compute  <span class="math">[u^2]P</span>  using Algorithm 1.</p>

    <p class="text-gray-300">Recall from Figure 1 that the verifier must, in addition to some group arithmetic, perform a check to see that the circuit is satisfied and also compute the expected opening of the polynomial commitment. This arithmetic occurs in the scalar field  <span class="math">\\mathbb{F}_p</span>  of the embedded elliptic curve, which is not the native field  <span class="math">\\mathbb{F}_q</span>  of the proving system. (The native field is the base field of the embedded elliptic curve.) We modify the protocol in practice, introducing a collision-resistant hash function (i.e. Rescue) over the scalar field which the prover uses to commit to their openings. These commitments are sent through public inputs to the proving system over the other curve, where the correct field is native. The commitments are opened in the proving system for that circuit and all scalar field arithmetic is performed there, where it is significantly cheaper. The expected polynomial commitment openings are sent through public inputs. As a result no field arithmetic is ever &quot;simulated&quot; over the wrong field.</p>

    <p class="text-gray-300">We remark that the protocol described in Section 5 has the verifier compute  <span class="math">K = \\mathsf{Commit}(\\sigma, k(Y))</span>  so that it can be opened by the prover rather than forcing the verifier to evaluate k(y) which would require the circuit over  <span class="math">\\mathbb{F}_q</span>  to again simulate arithmetic over  <span class="math">\\mathbb{F}_p</span> . It is more efficient for the verification circuit to construct the commitment K, and we implement an efficient circuit for computing K that can leverage the curve endomorphism and the fact that  <span class="math">\\sigma</span>  is fixed.</p>

      <h3 id="sec-6.4" class="text-xl font-semibold mt-8">6.4 Evaluation</h3>

    <p class="text-gray-300">We obtain benchmarks for our protocol on a 16-core Intel i9-7960X CPU @ 2.80 GHz, using 16 threads. The results are presented in Figure 2. Recursion is achieved at a cross-over point that is just below  <span class="math">2^{17}</span>  multiplication gates. Fully recursive proofs in our protocol are at least 3.5 KiB in size.</p>

    <section id="sec-7" class="mb-10">
      <h2 class="text-2xl font-bold">7 Conclusion</h2>

    <p class="text-gray-300">We devised a novel strategy (nested amortization) for achieving a practical realization of recursive proof composition without a trusted setup. After several optimizations we obtain a fully recursive proof that is only 3.5 KiB in size at the 128-bit security level. We implement our scheme to show that it is efficient to create and verify proofs on consumer hardware.</p>

    <p class="text-gray-300">In the process we obtained a modified variant of the polynomial commitment scheme from [37] and observed a new technique for amortizing away the cost of verifying many inner product arguments. We also devised a proving system with marginal verification time that is logarithmic in the size of the circuit, improving</p>

    <p class="text-gray-300">    <img src="_page_20_Figure_0.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Fig. 2: Performance of Halo. (a) The runtime of the prover (top left) and verifier (top right) for circuits of varying sizes, along with the size of the resulting proof (bottom left). (b) The cross-over point between the size of the verification circuit and the size of the circuit it is verifying (bottom right).</p>

    <p class="text-gray-300">asymptotically on Bulletproofs <a href="#page-22-4">[13]</a> and realizing the &quot;helped&quot; mode of Sonic <a href="#page-23-5">[32]</a> without the need for pairings or trusted setups.</p>

      <h3 id="sec-7.1" class="text-xl font-semibold mt-8">7.1 Future Work</h3>

    <p class="text-gray-300">We remark that our nested amortization technique can be applied using cycles of elliptic curves such that only one curve is pairing-friendly, and a pairingbased SNARK can be constructed on one end of the cycle instead; this is trivial to obtain using Barreto&ndash;Naehrig <a href="#page-21-11">[2]</a> curves with an embedding degree of 12, which allows for the use of smaller fields to improve performance compared to MNT4/MNT6 cycles proposed in <a href="#page-21-3">[4]</a>.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><p class="text-gray-300">1. Aly, A., Ashur, T., Ben-Sasson, E., Dhooghe, S., Szepieniec, A.: Efficient symmetric primitives for advanced cryptographic protocols (a Marvellous contribution). Cryptology ePrint Archive: Report 2019/426. Last revised May 20, 2017, <a href="https://eprint.iacr.org/2019/426" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2019/426</a></p></li>
      <li><p class="text-gray-300">2. Barreto, P., Naehrig, M.: Pairing-friendly elliptic curves of prime order. Cryptology ePrint Archive: Report 2005/133. Last revised February 28, 2006, <a href="https://eprint.iacr.org/2005/133" target="_blank" rel="noopener noreferrer">https:</a> <a href="https://eprint.iacr.org/2005/133" target="_blank" rel="noopener noreferrer">//eprint.iacr.org/2005/133</a></p></li>
      <li><p class="text-gray-300">3. Ben-Sasson, E., Bentov, I., Horesh, Y., Riabzev, M.: Scalable, transparent, and post-quantum secure computational integrity. Cryptology ePrint Archive, Report 2018/046. Last revised March 5, 2018, <a href="https://eprint.iacr.org/2018/046" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2018/046</a></p></li>
      <li><p class="text-gray-300">4. Ben-Sasson, E., Chiesa, A., Tromer, E., Virza, M.: Scalable Zero Knowledge via cycles of elliptic curves. In: Garay, J.A., Gennaro, R. (eds.) Advances in Cryptology &ndash; CRYPTO 2014. pp. 276&ndash;294. Springer (2014). <a href="https://doi.org/10.1007/978-3-662-44381-1_16" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/978-3-662-</a> <a href="https://doi.org/10.1007/978-3-662-44381-1_16" target="_blank" rel="noopener noreferrer">44381-1</a> 16, <a href="https://eprint.iacr.org/2014/595" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2014/595</a></p></li>
      <li><p class="text-gray-300">5. Bernstein, D., Lange, T.: SafeCurves: choosing safe curves for elliptic-curve cryptography, <a href="https://safecurves.cr.yp.to" target="_blank" rel="noopener noreferrer">https://safecurves.cr.yp.to</a></p></li>
      <li><p class="text-gray-300">6. Bernstein, D., Lange, T., Schwabe, P.: On the correct use of the negation map in the Pollard rho method. In: Catalano, D., Fazio, N., Gennaro, R., Nicolosi, A. (eds.) PKC 2011 &ndash; Proceedings of the 14th International Conference on Practice and Theory in Public Key Cryptography (Taormina, Italy, March 6&ndash;9, 2011). Lecture Notes in Computer Science, vol. 6571, pp. 128&ndash;146. International Association for Cryptologic Research, Springer (2011). <a href="https://doi.org/10.1007/978-3-642-19379-8_8" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/978-3-642-19379-</a> 8 <a href="https://doi.org/10.1007/978-3-642-19379-8_8" target="_blank" rel="noopener noreferrer">8,</a> <a href="https://www.iacr.org/archive/pkc2011/65710132/65710132.pdf" target="_blank" rel="noopener noreferrer">https://www.iacr.org/archive/pkc2011/65710132/65710132.pdf</a></p></li>
      <li><p class="text-gray-300">7. Bertoni, G., Daemen, J., Peeters, M., Van Assche, G.: Duplexing the sponge: Single-pass authenticated encryption and other applications. In: Miri, A., Vaudenay, S. (eds.) Selected Areas in Cryptography. pp. 320&ndash;337. Springer, Berlin, Heidelberg (2012). <a href="https://doi.org/10.1007/978-3-642-28496-0_19" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/978-3-642-28496-0</a> 19, <a href="https://eprint.iacr.org/2011/499" target="_blank" rel="noopener noreferrer">https://eprint.</a> <a href="https://eprint.iacr.org/2011/499" target="_blank" rel="noopener noreferrer">iacr.org/2011/499</a></p></li>
      <li><p class="text-gray-300">8. Bitansky, N., Canetti, R., Chiesa, A., Tromer, E.: Recursive composition and bootstrapping for SNARKs and Proof-Carrying Data. In: Proceedings of the Forty-Fifth Annual ACM Symposium on Theory of Computing. pp. 111&ndash;120. STOC '13, Association for Computing Machinery, New York, NY, USA (2013). <a href="https://doi.org/10.1145/2488608.2488623" target="_blank" rel="noopener noreferrer">https://doi.org/10.1145/2488608.2488623,</a> <a href="https://eprint.iacr.org/2012/095" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2012/095</a></p></li>
      <li><p class="text-gray-300">9. Blum, M., De Santis, A., Micali, S., Persiano, G.: Noninteractive Zero-Knowledge. SIAM J. Comput. 20(6), 1084&ndash;1118 (Dec 1991). <a href="https://doi.org/10.1137/0220068" target="_blank" rel="noopener noreferrer">https://doi.org/10.1137/0220068,</a> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.8702&rep=rep1&type=pdf" target="_blank" rel="noopener noreferrer">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.8702&amp;</a> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.8702&rep=rep1&type=pdf" target="_blank" rel="noopener noreferrer">rep=rep1&amp;type=pdf</a></p></li>
      <li><p class="text-gray-300">10. Blum, M., Feldman, P., Micali, S.: Proving security against chosen ciphertext attacks. In: Goldwasser, S. (ed.) Advances in Cryptology &ndash; CRYPTO '88. Proceedings (Santa Barbara, California, USA, August 21&ndash;25, 1988). Lecture Notes in Computer Science, vol. 403, pp. 256&ndash;268. Springer, Berlin, Heidelberg (1990). <a href="https://doi.org/10.1007/0-387-34799-2_20" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/0-387-34799-2</a> 20, <a href="https://link.springer.com/content/pdf/10.1007/0-387-34799-2_20.pdf" target="_blank" rel="noopener noreferrer">https://link.springer.com/</a> <a href="https://link.springer.com/content/pdf/10.1007/0-387-34799-2_20.pdf" target="_blank" rel="noopener noreferrer">content/pdf/10.1007/0-387-34799-2\\_20.pdf</a></p></li>
      <li><p class="text-gray-300">11. Boneh, D., Drake, J., Fisch, B., Gabizon, A.: Efficient polynomial commitment schemes for multiple points and polynomials. Cryptology ePrint Archive, Report 2020/081. Last revised January 31, 2020, <a href="https://eprint.iacr.org/2020/081" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2020/081</a></p></li>
      <li><p class="text-gray-300">12. Bootle, J., Cerulli, A., Chaidos, P., Groth, J., Petit, C.: Efficient Zero-Knowledge arguments for arithmetic circuits in the Discrete Log setting. In: Fischlin, M.,</p></li>
      <li><p class="text-gray-300">Coron, J.S. (eds.) Advances in Cryptology EUROCRYPT 2016. pp. 327&ndash; 357. Springer, Berlin, Heidelberg (2016). <a href="https://doi.org/10.1007/978-3-662-49896-5_12" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/978-3-662-49896-</a> 5 <a href="https://doi.org/10.1007/978-3-662-49896-5_12" target="_blank" rel="noopener noreferrer">12,</a> <a href="https://eprint.iacr.org/2016/263" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2016/263</a></p></li>
      <li><p class="text-gray-300">13. B&uml;unz, B., Bootle, J., Boneh, D., Poelstra, A., Wuille, P., Maxwell, G.: Bulletproofs: Short proofs for confidential transactions and more. 2018 IEEE Symposium on Security and Privacy (SP) pp. 315&ndash;334. <a href="https://doi.org/10.1109/SP.2018.00020" target="_blank" rel="noopener noreferrer">https://doi.org/10.1109/SP.2018.00020,</a> <a href="https://eprint.iacr.org/2017/1066" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2017/1066</a></p></li>
      <li><p class="text-gray-300">14. B&uml;unz, B., Fisch, B., Szepieniec, A.: Transparent SNARKs from DARK compilers. Cryptology ePrint Archive, Report 2019/1229. Last revised November 18, 2019, <a href="https://eprint.iacr.org/2019/1229" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2019/1229</a></p></li>
      <li><p class="text-gray-300">15. Carroll, L.: Through the Looking-Glass, and What Alice Found There. Macmillan and Co. (1872), <a href="https://archive.org/details/throughlooking00carr" target="_blank" rel="noopener noreferrer">https://archive.org/details/throughlooking00carr</a></p></li>
      <li><p class="text-gray-300">16. Chiesa, A., Chua, L.: On cycles of pairing-friendly elliptic curves. SIAM J. Appl. Algebra Geometry 3(2), 175&ndash;192 (2018). <a href="https://doi.org/10.1137/18M1173708" target="_blank" rel="noopener noreferrer">https://doi.org/10.1137/18M1173708,</a> <a href="https://arxiv.org/abs/1803.02067" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/1803.02067</a></p></li>
      <li><p class="text-gray-300">17. Chiesa, A., Hu, Y., Maller, M., Mishra, P., Vesely, N., Ward, N.: Marlin: Preprocessing zkSNARKs with universal and updatable SRS. Cryptology ePrint Archive, Report 2019/1047. Last revised January 1, 2020, <a href="https://eprint.iacr.org/2019/1047" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2019/</a> <a href="https://eprint.iacr.org/2019/1047" target="_blank" rel="noopener noreferrer">1047</a></p></li>
      <li><p class="text-gray-300">18. Chiesa, A., Ojha, D., Spooner, N.: Fractal: Post-quantum and transparent recursive proofs from holography. Cryptology ePrint Archive, Report 2019/1076. Last revised October 25, 2019, <a href="https://eprint.iacr.org/2019/1076" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2019/1076</a></p></li>
      <li><p class="text-gray-300">19. Chiesa, A., Tromer, E.: Proof-Carrying Data and hearsay arguments from signature cards. In: Symposium on Innovations in Computer Science (ICS) (2010), <a href="https://projects.csail.mit.edu/pcd/" target="_blank" rel="noopener noreferrer">https:</a> <a href="https://projects.csail.mit.edu/pcd/" target="_blank" rel="noopener noreferrer">//projects.csail.mit.edu/pcd/</a></p></li>
      <li><p class="text-gray-300">20. Duursma, I., Gaudry, P., Morain, F.: Speeding up the discrete log computation on curves with automorphisms. In: Lam, K.Y., Okamoto, E., Xing, C. (eds.) Advances in Cryptology &ndash; ASIACRYPT 1999. Proceedings, International Conference on the Theory and Application of Cryptology and Information Security (Singapore, November 14&ndash;18, 1999). Lecture Notes in Computer Science, vol. 1716, pp. 103&ndash;121. Springer (1999). <a href="https://doi.org/10.1007/b72231" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/b72231,</a> <a href="https://hal.inria.fr/inria-00511639" target="_blank" rel="noopener noreferrer">https:</a> <a href="https://hal.inria.fr/inria-00511639" target="_blank" rel="noopener noreferrer">//hal.inria.fr/inria-00511639</a></p></li>
      <li><p class="text-gray-300">21. Fiat, A., Shamir, A.: How to prove yourself: Practical solutions to identification and signature problems. In: Odlyzko, A.M. (ed.) Advances in Cryptology &ndash; CRYPTO '86. Proceedings (Santa Barbara, California, USA, 1986). Lecture Notes in Computer Science, vol. 263, pp. 311&ndash;323. Springer, Berlin, Heidelberg (1987). <a href="https://doi.org/10.1007/3-540-47721-7_12" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/3-540-47721-7</a> 12, <a href="https://link.springer.com/content/pdf/10.1007/3-540-47721-7_12.pdf" target="_blank" rel="noopener noreferrer">https://link.springer.com/</a> <a href="https://link.springer.com/content/pdf/10.1007/3-540-47721-7_12.pdf" target="_blank" rel="noopener noreferrer">content/pdf/10.1007/3-540-47721-7\\_12.pdf</a></p></li>
      <li><p class="text-gray-300">22. Gabizon, A., Williamson, Z.J., Ciobotaru, O.: PLONK: Permutations over Lagrange-bases for Oecumenical Noninteractive arguments of Knowledge. Cryptology ePrint Archive, Report 2019/953. Last revised December 10, 2019, <a href="https://eprint.iacr.org/2019/953" target="_blank" rel="noopener noreferrer">https:</a> <a href="https://eprint.iacr.org/2019/953" target="_blank" rel="noopener noreferrer">//eprint.iacr.org/2019/953</a></p></li>
      <li><p class="text-gray-300">23. Gennaro, R., Gentry, C., Parno, B.: Non-interactive verifiable computing: Outsourcing computation to untrusted workers. In: Rabin, T. (ed.) Advances in Cryptology &ndash; CRYPTO 2010. pp. 465&ndash;482. Springer (2010). <a href="https://doi.org/10.1007/978-3-642-14623-7_25" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/978-</a> <a href="https://doi.org/10.1007/978-3-642-14623-7_25" target="_blank" rel="noopener noreferrer">3-642-14623-7</a> 25, <a href="https://eprint.iacr.org/2009/547" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2009/547</a></p></li>
      <li><p class="text-gray-300">24. Goldwasser, S., Micali, S., Rackoff, C.: The knowledge complexity of interactive proof systems. SIAM Journal on Computing 18(1), 186&ndash;208 (February 1989). <a href="https://doi.org/10.1137/0218012" target="_blank" rel="noopener noreferrer">https://doi.org/10.1137/0218012,</a> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.419.8132&rep=rep1&type=pdf" target="_blank" rel="noopener noreferrer">http : / / citeseerx . ist . psu . edu / viewdoc /</a> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.419.8132&rep=rep1&type=pdf" target="_blank" rel="noopener noreferrer">download?doi=10.1.1.419.8132&amp;rep=rep1&amp;type=pdf</a></p></li>
      <li><p class="text-gray-300">25. Groth, J.: On the size of pairing-based non-interactive arguments. Cryptology ePrint Archive: Report 2016/260. Last revised May 31, 2016, <a href="https://eprint.iacr.org/2016/260" target="_blank" rel="noopener noreferrer">https://eprint.</a> <a href="https://eprint.iacr.org/2016/260" target="_blank" rel="noopener noreferrer">iacr.org/2016/260</a></p></li>
      <li><p class="text-gray-300">26. Hopwood, D.: GitHub repository 'daira/tweedle': Generator and supporting evidence for security of the Tweedledum/Tweedledee pair of elliptic curves, <a href="https://github.com/daira/tweedle" target="_blank" rel="noopener noreferrer">https:</a> <a href="https://github.com/daira/tweedle" target="_blank" rel="noopener noreferrer">//github.com/daira/tweedle</a></p></li>
      <li><p class="text-gray-300">27. Hopwood, D.: GitHub repository 'zcash/zcash': Issue 3924 &ndash; Faster variable-base scalar multiplication in zk-SNARK circuits, <a href="https://github.com/zcash/zcash/issues/3924" target="_blank" rel="noopener noreferrer">https://github.com/zcash/zcash/</a> <a href="https://github.com/zcash/zcash/issues/3924" target="_blank" rel="noopener noreferrer">issues/3924</a></p></li>
      <li><p class="text-gray-300">28. Hopwood, D., Bowe, S., Hornby, T., Wilcox, N.: Zcash protocol specification, <a href="https://zips.z.cash/protocol/protocol.pdf" target="_blank" rel="noopener noreferrer">https://zips.z.cash/protocol/protocol.pdf</a></p></li>
      <li><p class="text-gray-300">29. Hopwood, D., Israel, R.: Under what conditions on A and v is the size of the sumset v &middot;A + A over F<sup>p</sup> equal or close to |A| 2 ? MathOverflow question and comment, <a href="https://mathoverflow.net/q/340006/50608" target="_blank" rel="noopener noreferrer">https://mathoverflow.net/q/340006/50608</a></p></li>
      <li><p class="text-gray-300">30. Kate, A., Zaverucha, G.M., Goldberg, I.: Constant-size commitments to polynomials and their applications. In: Abe, M. (ed.) Advances in Cryptology &ndash; ASIACRYPT 2010. pp. 177&ndash;194. Springer, Berlin, Heidelberg (2010). <a href="https://doi.org/10.1007/978-3-642-17373-8_11" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/978-3-642-17373-8</a> 11, <a href="https://www.iacr.org/archive/asiacrypt2010/6477178/6477178.pdf" target="_blank" rel="noopener noreferrer">https://www.iacr.org/archive/</a> <a href="https://www.iacr.org/archive/asiacrypt2010/6477178/6477178.pdf" target="_blank" rel="noopener noreferrer">asiacrypt2010/6477178/6477178.pdf</a></p></li>
      <li><p class="text-gray-300">31. Kilian, J.: A Note on Efficient Zero-knowledge Proofs and Arguments (extended abstract). In: Proceedings of the Twenty-fourth Annual ACM Symposium on Theory of Computing. pp. 723&ndash;732. STOC '92, ACM, New York, NY, USA (1992). <a href="https://doi.org/10.1145/129712.129782" target="_blank" rel="noopener noreferrer">https://doi.org/10.1145/129712.129782,</a> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.127.2236&rep=rep1&type=pdf" target="_blank" rel="noopener noreferrer">http://citeseerx.ist.psu.edu/</a> <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.127.2236&rep=rep1&type=pdf" target="_blank" rel="noopener noreferrer">viewdoc/download?doi=10.1.1.127.2236&amp;rep=rep1&amp;type=pdf</a></p></li>
      <li><p class="text-gray-300">32. Maller, M., Bowe, S., Kohlweiss, M., Meiklejohn, S.: Sonic: Zero-Knowledge SNARKs from linear-size universal and updatable Structured Reference Strings. In: Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. p. 2111&ndash;2128. CCS '19, Association for Computing Machinery, New York, NY, USA (2019). <a href="https://doi.org/10.1145/3319535.3339817" target="_blank" rel="noopener noreferrer">https://doi.org/10.1145/3319535.3339817,</a> <a href="https://eprint.iacr.org/2019/099" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2019/099</a></p></li>
      <li><p class="text-gray-300">33. Micali, S.: Computationally sound proofs. SIAM Journal on Computing 30(4), 1253&ndash;1298 (October 2000). <a href="https://doi.org/10.1137/S0097539795284959" target="_blank" rel="noopener noreferrer">https://doi.org/10.1137/S0097539795284959,</a> <a href="https://projecteuclid.org/euclid.lnl/1235415908" target="_blank" rel="noopener noreferrer">https:</a> <a href="https://projecteuclid.org/euclid.lnl/1235415908" target="_blank" rel="noopener noreferrer">//projecteuclid.org/euclid.lnl/1235415908</a></p></li>
      <li><p class="text-gray-300">34. Renes, J., Costello, C., Batina, L.: Complete addition formulas for prime order elliptic curves. Cryptology ePrint Archive: Report 2015/1060. Last revised March 8, 2016, <a href="https://eprint.iacr.org/2015/1060" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2015/1060</a></p></li>
      <li><p class="text-gray-300">35. Susella, R., Montrasio, S.: A compact and exception-free ladder for all short Weierstrass elliptic curves. In: Lemke-Rust, K., Tunstall, M. (eds.) Smart Card Research and Advanced Applications: 15th International Conference, CARDIS 2016 (Cannes, France, November 7&ndash;9, 2016), Revised Selected Papers. Security and Cryptology, vol. 10146, pp. 156&ndash;173. Springer (2017). <a href="https://doi.org/10.1007/978-3-319-54669-8_10" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/978-</a> <a href="https://doi.org/10.1007/978-3-319-54669-8_10" target="_blank" rel="noopener noreferrer">3-319-54669-8</a> 10</p></li>
      <li><p class="text-gray-300">36. Valiant, P.: Incrementally verifiable computation or proofs of knowledge imply time/space efficiency. In: Canetti, R. (ed.) Theory of Cryptography. pp. 1&ndash;18. Springer, Berlin, Heidelberg (2008). <a href="https://doi.org/10.1007/978-3-540-78524-8_1" target="_blank" rel="noopener noreferrer">https://doi.org/10.1007/978-3-540-78524-8</a> 1, <a href="https://iacr.org/archive/tcc2008/49480001/49480001.pdf" target="_blank" rel="noopener noreferrer">https://iacr.org/archive/tcc2008/49480001/49480001.pdf</a></p></li>
      <li><p class="text-gray-300">37. Wahby, R.S., Tzialla, I., abhi shelat, Thaler, J., Walfish, M.: Doubly-efficient zk-SNARKs without trusted setup. Cryptology ePrint Archive: Report 2017/1132. Last revised April 19, 2018, <a href="https://eprint.iacr.org/2017/1132" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2017/1132</a></p></li>
    </ul>

    </section>

    <section id="app-a" class="mb-10">
      <h2 class="text-2xl font-bold">A Proof of Theorem 1</h2>

    <p class="text-gray-300"><em>Proof.</em> Perfect completeness follows trivially. In order to establish perfect special honest-verifier zero knowledge we demonstrate that a simulator  <span class="math">\\mathcal{S}</span>  exists which, when given the verifier's randomness and the statement, can produce a transcript that is equally distributed with transcripts from an honest prover that has a witness.</p>

    <p class="text-gray-300">In each round of the modified inner product argument the simulator will simply output random group elements, which are distributed identically to the honest prover's outputs. Upon calculation of Q the simulator chooses  <span class="math">d,s\\in\\mathbb{F}_p</span>  at random and uses its access to c to send the verifier</p>

    <p class="text-gray-300"><span class="math">$R = [d](G + [b]U) + [s]H - [c]Q</span>$</p>

    <p class="text-gray-300">which has the same distribution as the honest prover. Finally, since by definition we have</p>

    <p class="text-gray-300"><span class="math">$[c] Q + R = [d] (G + [b] U) + [s] H</span>$</p>

    <p class="text-gray-300">the simulator sends  <span class="math">z_1 = d</span>  and  <span class="math">z_2 = s</span> , which are again distributed the same as an honest prover, and which satisfy the verifier's check.</p>

    <p class="text-gray-300">In order to show computational witness-extended emulation we first prove the existence of an extractor  <span class="math">\\mathcal{X}_{\\text{poly}}</span>  which, with full access to an adversary  <span class="math">\\mathcal{P}^*</span>  that outputs accepting transcripts, can extract a witness in expected polynomial time. We show that we can extract a, r' such that</p>

    <p class="text-gray-300"><span class="math">$Q = [a] (G + [b] U) + [r&#x27;] H</span>$
(6)</p>

    <p class="text-gray-300">by rewinding  <span class="math">\\mathcal{P}^*</span>  once and continuing the argument with fresh challenge c'. If  <span class="math">\\mathcal{P}^*</span>  succeeds in both arguments, then we have pairs of responses  <span class="math">(z_1, z_2)</span>  and  <span class="math">(z&#x27;_1, z&#x27;_2)</span>  such that</p>

    <p class="text-gray-300"><span class="math">$[c] Q + R = [z_1] (G + [b] U) + [z_2] H</span>$</p>

    <p class="text-gray-300"><span class="math">[c&#x27;] Q + R = [z&#x27;_1] (G + [b] U) + [z&#x27;_2] H</span></p>

    <p class="text-gray-300">which can be rewritten as</p>

    <p class="text-gray-300"><span class="math">$[ac + d] (G + [b] U) + [cr&#x27; + s] H = [z_1] (G + [b] U) + [z_2] H</span>$</p>

    <p class="text-gray-300"><span class="math">$[ac&#x27; + d] (G + [b] U) + [c&#x27;r&#x27; + s] H = [z&#x27;_1] (G + [b] U) + [z&#x27;_2] H.</span>$</p>

    <p class="text-gray-300">Observe by the equalities  <span class="math">ac + d = z_1</span>  and  <span class="math">ac&#x27; + d = z&#x27;_1</span>  and the fact that  <span class="math">c \\neq c&#x27;</span>  that a, d are fully determined, and similarly for r', s. If it is then not the case that Q = [a](G + [b]U) + [r']H we have extracted a non-trivial discrete log relation between G, U, H.</p>

    <p class="text-gray-300">We now proceed with our extracted a, r' to obtain a witness  <span class="math">\\mathbf{a}, v&#x27;</span>  such that</p>

    <p class="text-gray-300">
<span class="math">$P&#x27; = \\langle \\mathbf{a}, \\mathbf{G} \\rangle + [r]H + [v&#x27;]U \\tag{7}</span>$</p>

    <p class="text-gray-300">and that  <span class="math">v&#x27; = \\langle \\mathbf{a}, (1, x, x^2, ..., x^{n-1}) \\rangle</span> . We proceed in a similar fashion as in the proof of [13, Theorem 1]. In each of the k rounds of the inner product argument starting with j = 1 where  <span class="math">n&#x27; = 2^j</span> , the extractor (on input  <span class="math">\\mathbf{G}&#x27; \\in \\mathbb{G}^{n&#x27;}, \\mathbf{b}&#x27; \\in \\mathbb{F}^{n/2}</span> ,</p>

    <p class="text-gray-300"><span class="math">P_j \\in \\mathbb{G}</span> ) will run the prover to obtain  <span class="math">L_j</span>  and  <span class="math">R_j</span> , and then by rewinding the prover four times with distinct challenges  <span class="math">u_{j,1}, u_{j,2}, u_{j,3}, u_{j,4}</span>  the extractor obtains four pairs  <span class="math">\\mathbf{a}&#x27;_i \\in \\mathbb{F}^{n/2}, r&#x27;_i \\in \\mathbb{F}</span>  such that for all i</p>

    <p class="text-gray-300"><span class="math">$[u_{j,i}^2]L_j + P_j + [u_{j,i}^{-2}]R_j = \\langle \\mathbf{a}&#x27;_i, \\mathbf{G}&#x27;_{lo} \\cdot u_{j,i}^{-1} + \\mathbf{G}&#x27;_{hi} \\cdot u_{j,i} \\rangle + [\\langle \\mathbf{a}&#x27;_i, \\mathbf{b}&#x27; \\rangle] U + [r&#x27;_i]H</span>$
(8)</p>

    <p class="text-gray-300">Let some  <span class="math">\\mathbf{a}_L, \\mathbf{a}_R, \\mathbf{a}_P \\in \\mathbb{F}^{n&#x27;}</span>  and  <span class="math">v_L, r_L, v_R, r_R, v_P, r_P \\in \\mathbb{F}</span>  exist such that</p>

    <p class="text-gray-300"><span class="math">$L = \\langle \\mathbf{a}_L, \\mathbf{G}&#x27; \\rangle + [v_L] U + [r_L] H</span>$</p>

    <p class="text-gray-300"><span class="math">$R = \\langle \\mathbf{a}_R, \\mathbf{G}&#x27; \\rangle + [v_R] U + [r_R] H</span>$</p>

    <p class="text-gray-300"><span class="math">$P_j = \\langle \\mathbf{a}_P, \\mathbf{G}&#x27; \\rangle + [v_P] U + [r_P] H</span>$</p>

    <p class="text-gray-300">so that we can take the equalities</p>

    <p class="text-gray-300">
<span class="math">$u_{j,i}^{2}v_{L} + v_{P} + u_{j,i}^{-2}v_{R} = \\langle \\mathbf{a}&#x27;_{i}, \\mathbf{b}&#x27; \\rangle</span>$</p>

    <p class="text-gray-300"><span class="math">$u_{j,i}^{2}r_{L} + r_{P} + u_{j,i}^{-2}r_{R} = r&#x27;_{i}</span>$</p>

    <p class="text-gray-300"><span class="math">$u_{j,i}^{2}(\\mathbf{a}_{L})_{lo} + (\\mathbf{a}_{P})_{lo} + u_{j,i}^{-2}(\\mathbf{a}_{R})_{lo} = u_{j,i}^{-1}\\mathbf{a}&#x27;_{i}</span>$</p>

    <p class="text-gray-300"><span class="math">$u_{j,i}^{2}(\\mathbf{a}_{L})_{hi} + (\\mathbf{a}_{P})_{hi} + u_{j,i}^{-2}(\\mathbf{a}_{R})_{hi} = u_{j,i}\\mathbf{a}&#x27;_{i}</span>$
(9)</p>

    <p class="text-gray-300">which fully determine  <span class="math">\\mathbf{a}_L</span> ,  <span class="math">\\mathbf{a}_R</span> ,  <span class="math">\\mathbf{a}_P</span> ,  <span class="math">v_L</span> ,  <span class="math">v_R</span> ,  <span class="math">v_P</span> ,  <span class="math">r_L</span> ,  <span class="math">r_R</span> ,  <span class="math">r_P</span>  given three distinct challenges  <span class="math">u_{j,1}</span> ,  <span class="math">u_{j,2}</span> ,  <span class="math">u_{j,3}</span>  or else reveal a non-trivial discrete logarithm relation between  <span class="math">\\mathbf{G}</span> , U, H. Following the third and fourth equations of (9) we have that</p>

    <p class="text-gray-300"><span class="math">$u_{j,i}^3(\\mathbf{a}_L)_{\\rm lo} + u_{j,i}((\\mathbf{a}_P)_{\\rm lo} - (\\mathbf{a}_L)_{\\rm hi}) + u_{j,i}^{-1}((\\mathbf{a}_R)_{\\rm lo} - (\\mathbf{a}_P)_{\\rm hi}) - u_{j,i}^{-3}(\\mathbf{a}_R)_{\\rm hi} = 0</span>$</p>

    <p class="text-gray-300">holds for all i. Given that this holds for four distinct challenges the left-hand side must be zero for all challenges and so we have</p>

    <p class="text-gray-300">
<span class="math">$(\\mathbf{a}_L)_{\\text{lo}} = (\\mathbf{a}_R)_{\\text{hi}} = 0</span>$
<span class="math">$(\\mathbf{a}_P)_{\\text{lo}} = (\\mathbf{a}_L)_{\\text{hi}}</span>$
<span class="math">$(\\mathbf{a}_P)_{\\text{hi}} = (\\mathbf{a}_R)_{\\text{lo}}</span>$</p>

    <p class="text-gray-300">Inspection of (9) shows that the extracted  <span class="math">v_L, v_P, v_R</span>  are of the correct form. In the final round j=k we extract from  <span class="math">P_j=P&#x27;</span>  a witness  <span class="math">(\\mathbf{a},v&#x27;,r)</span>  that satisfies Equation 7. In order to establish that v=v' we rewind  <span class="math">\\mathcal{P}^*</span>  one last time and provide a fresh challenge U'. Given two successful arguments we obtain v'=v or otherwise obtain a non-trivial discrete log relation between  <span class="math">\\mathbf{G}, H, U, U&#x27;</span> . We see that our extractor  <span class="math">\\mathcal{X}_{\\text{poly}}</span>  is efficient (requiring  <span class="math">4d^2</span>  transcripts in total, which is polynomial in  <span class="math">\\lambda</span> ) and so by the general forking lemma [13, Theorem 6] we have shown computational witness-extended emulation for the extractor  <span class="math">\\mathcal{X}&#x27;_{\\text{poly}}</span>  which is taken identically to  <span class="math">\\mathcal{X}_{\\text{poly}}</span>  except that it fails whenever  <span class="math">\\mathcal{X}_{\\text{poly}}</span>  extracts a non-trivial discrete log relation. Such failures happen with negligible probability under the discrete log relation assumption.</p>

    <p class="text-gray-300">It will be helpful for us to supply the following simple lemma.</p>

    <p class="text-gray-300"><strong>Lemma 1.</strong> Let  <span class="math">p(X) \\in \\mathbb{F}[X]</span>  be a polynomial of maximal degree d-1, and let  <span class="math">q(X) \\in \\mathbb{F}[X]</span>  be a polynomial of maximal degree d-1 such that q(x) = (p(x)-v)/(x-y) holds for d+1 distinct values  <span class="math">x_1, x_2, ..., x_{d+1} \\in \\mathbb{F}</span>  and some fixed  <span class="math">y \\in \\mathbb{F} \\setminus \\{x_1, x_2, ..., x_{d+1}\\}</span>  and fixed  <span class="math">v \\in \\mathbb{F}</span> . Then p(y) = v.</p>

    <p class="text-gray-300">Proof. Let  <span class="math">f(X) = q(X) \\cdot (X - y)</span>  be a polynomial of maximal degree d, and let g(X) = p(X) - v be a polynomial of maximal degree d - 1. Since we have that f(X) = g(X) over a domain of size d + 1, by the degree bounds of f(X) and g(X) this gives us that f(X) = g(X). Following the definition of f(X) we have that g(X) is perfectly divisible by (X - y) and so by the factor theorem p(y) = v.</p>

    <p class="text-gray-300">We now present a proof of Theorem 2.</p>

    <p class="text-gray-300"><em>Proof.</em> Perfect completeness follows from the perfect completeness of the polynomial commitment opening argument, and the fact that the protocol trivially succeeds for every valid verifier challenge  <span class="math">x, y, y_{\\text{new}}, z_1, z_2, z_4 \\in \\mathbb{I}</span>  and  <span class="math">z_3 \\in \\mathbb{I} \\setminus \\{x, y, xy, y_{\\text{old}}, y_{\\text{new}}\\}</span>  when the prover has a valid witness  <span class="math">\\mathbf{a}, \\mathbf{b}, \\mathbf{c}</span> .</p>

    <p class="text-gray-300">Perfect special honest-verifier zero knowledge is shown with a simulator  <span class="math">\\mathcal{S}</span>  that behaves identically to the honest prover except that it outputs random  <span class="math">R, T_{\\text{lo}}, T_{\\text{hi}}, H \\in \\mathbb{G}</span>  and supplies random  <span class="math">v_1, v_5, v_6, v_9, v_{10}, v_{12} \\in \\mathbb{F}</span>  such that the verifier's check is satisfied. The honest prover blinds their polynomial r(X,Y) with seven blinding factors, and the verifier learns only six evaluations of r(X,Y) and t(X,Y) so that the honest prover and simulator messages are indistinguishable. The simulator then invokes the simulator of the polynomial commitment opening argument described in Appendix A to simulate a transcript that is indistinguishable from an honest prover's transcript.</p>

    <p class="text-gray-300">In order to show computational witness-extended emulation we will define an extractor  <span class="math">\\mathcal{X}</span>  with full access to an adversary  <span class="math">\\mathcal{P}^*</span>  which always produces accepting transcripts. We will invoke the extractor  <span class="math">\\mathcal{X}_{poly}</span>  of the polynomial commitment opening argument while running the prover with fresh challenges  <span class="math">x, y, y_{new}, z_1, z_2, z_3, z_4</span>  as needed. First, the prover is run with five distinct values of the challenge  <span class="math">z_4</span>  so that the extractor obtains five polynomials where the coefficients can be interpreted as evaluations of a degree-4 polynomial in  <span class="math">z_4</span>  and thus with interpolation we extract polynomials p'(X), q'(X), r'(X), c'(X), h'(X) or else recover a non-trivial discrete log relation. Observe that we have</p>

    <p class="text-gray-300"><span class="math">$h&#x27;(z_3) = \\frac{v_{10} - (v_1 + z_1 v_2 + z_1^2 v_3 + z_1^3 v_4 + z_1^4 v_5 + z_1^5 v_6 + z_1^6 v_7)}{z_3 - x} + z_2 \\frac{v_{11} - (v_8 + z_1 v_3)}{z_3 - y} + z_2^2 \\frac{v_{12} - v_9}{z_3 - xy} + z_2^3 \\frac{v_{13} - v_2}{z_3 - y_{\\text{old}}} + z_2^4 \\frac{v_{13} - v_4}{z_3 - y_{\\text{new}}}</span>$</p>

    <p class="text-gray-300">and so by running the prover with d+1 distinct challenges  <span class="math">z_3</span>  we extract from the degree bound of p'(X), q'(X), r'(X), c'(X), h'(X) that</p>

    <p class="text-gray-300"><span class="math">$h&#x27;(X) = \\frac{p&#x27;(X) - (v_1 + z_1v_2 + z_1^2v_3 + z_1^3v_4 + z_1^4v_5 + z_1^5v_6 + z_1^6v_7)}{X - x} + z_2\\frac{q&#x27;(X) - (v_8 + z_1v_3)}{X - y} + z_2^2\\frac{r&#x27;(X) - v_9}{X - xy} + z_2^3\\frac{c&#x27;(X) - v_2}{X - y_{\\text{old}}} + z_2^4\\frac{c&#x27;(X) - v_4}{X - y_{\\text{new}}}</span>$</p>

    <p class="text-gray-300">is a polynomial of degree d-1, or otherwise obtain a non-trivial discrete log relation. The prover is run with five distinct challenges  <span class="math">z_2</span>  so that we can extract via interpolation each term in h'(X) as a polynomial of maximal degree d-1, or otherwise obtain a non-trivial discrete log relation. We use the d+1 distinct challenges  <span class="math">z_3 \\in \\mathbb{I} \\setminus \\{x, y, xy, y_{\\text{old}}, y_{\\text{new}}\\}</span>  to apply Lemma 1 for each term, obtaining that  <span class="math">p&#x27;(x) = v_1 + z_1v_2 + z_1^2v_3 + z_1^3v_4 + z_1^4v_5 + z_1^5v_6 + z_1^6v_7</span> ,  <span class="math">q&#x27;(y) = v_8 + z_1v_3</span> ,  <span class="math">r&#x27;(xy) = v_9</span> ,  <span class="math">c&#x27;(y_{\\text{old}}) = v_2</span>  and  <span class="math">c&#x27;(y_{\\text{new}}) = v_4</span> .</p>

    <p class="text-gray-300">Next, by running the prover with seven distinct challenges  <span class="math">z_1</span>  we obtain (by interpolation) from our extracted polynomials p'(X) and q'(X) the polynomials  <span class="math">r&#x27;&#x27;(X), s&#x27;_{\\text{old}}(X), s&#x27;(X), s&#x27;_{\\text{new}}(X), t&#x27;_{\\text{lo}}(X), t&#x27;_{\\text{hi}}(X), g&#x27;(X)</span>  and k'(X), c''(X) or else we obtain a non-trivial discrete log relation. We directly obtain a non-trivial discrete log relation if  <span class="math">r&#x27;&#x27;(X) \\neq r&#x27;(X)</span>  or  <span class="math">c&#x27;&#x27;(X) \\neq c&#x27;(X)</span> . The extractor computes  <span class="math">K = \\text{Commit}(\\sigma, k(Y))</span>  and checks  <span class="math">S_{\\text{new}} = \\text{Commit}(\\sigma, s(X, y_{\\text{new}})X^N)</span>  just as the verifier does, and so if either  <span class="math">k&#x27;(X) \\neq k(Y)</span>  or  <span class="math">s&#x27;_{\\text{new}}(X) \\neq s(X, y_{\\text{new}})X^N</span>  the extractor obtains a non-trivial discrete log relation. It then follows from before that  <span class="math">r&#x27;(x) = v_1, s&#x27;_{\\text{old}}(x) = c&#x27;(y_{\\text{old}}) = v_2, s&#x27;(x) = c&#x27;(y) = v_3, s&#x27;_{\\text{new}}(x) = c&#x27;(y_{\\text{new}}) = v_4, t&#x27;_{\\text{lo}}(x) = v_5, t&#x27;_{\\text{hi}}(x) = v_6, g&#x27;(x) = v_7, k&#x27;(y) = v_8</span> , and  <span class="math">r&#x27;(xy) = v_9</span> .</p>

    <p class="text-gray-300">The prover is run with d distinct challenges  <span class="math">y_{\\text{new}}</span> , and we obtain from this that since  <span class="math">s&#x27;_{\\text{new}}(x) = c&#x27;(y_{\\text{new}})</span>  holds for d distinct  <span class="math">y_{\\text{new}}</span>  that  <span class="math">c&#x27;(Y) = s(x,Y)x^N</span> . The prover is run with 2d distinct challenges x so that since c'(y) = s'(x) and  <span class="math">c&#x27;(y_{\\text{old}}) = s&#x27;_{\\text{old}}(x)</span>  hold for d distinct x that  <span class="math">s&#x27;(X) = s(X,y)X^N</span>  and  <span class="math">s&#x27;_{\\text{old}}(X) = s(X,y_{\\text{old}})X^N</span> , which establishes that  <span class="math">S_{\\text{old}} = \\text{Commit}(\\sigma,s(X,y_{\\text{old}})X^N)</span> . Because  <span class="math">g&#x27;(x) = g(x,(u_{\\text{old}})_1,(u_{\\text{old}})_2,...,(u_{\\text{old}})_k)</span>  holds for d distinct x we have that  <span class="math">g&#x27;(X) = g(X,(u_{\\text{old}})_1,(u_{\\text{old}})_2,...,(u_{\\text{old}})_k)</span>  which establishes that  <span class="math">G_{\\text{old}} = \\text{Commit}(\\sigma,g(X,(u_{\\text{old}})_1,(u_{\\text{old}})_2,...,(u_{\\text{old}})_k))</span> . Finally we extract from r'(X) a witness a,b,c which satisfies our system of constraints. Let  <span class="math">t&#x27;(X) = t&#x27;_{\\text{lo}}(X)X^{-d} + t&#x27;_{\\text{hi}}(X)X</span> . Due to the fact that  <span class="math">t&#x27;(x) = (r&#x27;(x)x^{-3n+1}) \\cdot (r&#x27;(xy)(xy)^{-3n+1} + s&#x27;(x) - \\sum_{i=1}^{N} (y^i + y^{-i})x^{i+N}) - y^N k(y)</span>  for 2d distinct x we obtain t(X,y) = t'(X) and that the constant term of t(X,y) is zero. The prover is run with d distinct values of the challenge y so that we can conclude the left-hand side of Equation 4 is the zero polynomial for our extracted a,b,c and thus that the constraint system is satisfied.</p>

    <p class="text-gray-300">In total the extractor  <span class="math">\\mathcal{X}</span>  requires  <span class="math">5 \\cdot (d+1) \\cdot 5 \\cdot 7 \\cdot 2d \\cdot d \\cdot d</span>  invocations of the extractor  <span class="math">\\mathcal{X}_{\\text{poly}}</span>  which is polynomial in  <span class="math">\\lambda</span>  and so by the general forking lemma [13, Theorem 6] we have shown computational witness-extended emulation for the extractor  <span class="math">\\mathcal{X}&#x27;</span>  which is taken identically to  <span class="math">\\mathcal{X}</span>  except that it fails whenever  <span class="math">\\mathcal{X}</span>  extracts a non-trivial discrete log relation. Such failures happen with negligible probability under the discrete log relation assumption.</p>

    </section>

    <section id="app-c" class="mb-10">
      <h2 class="text-2xl font-bold">C Proof for Algorithm 1</h2>

    <p class="text-gray-300">Collecting the scalars by which  <span class="math">\\phi_p(P)</span>  and P are multiplied, we see that Algorithm 1 is equivalent to:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Algorithm 2
Inputs:
<span class="math">$\\mathbf{r} \\in \\{0,1\\}^{\\lambda}, P \\in E_p \\setminus \\{\\mathcal{O}_p\\}</span>$</li>
    </ul>

    <p class="text-gray-300"><span class="math">$(a : \\mathbb{F}_q, b : \\mathbb{F}_q) := (2,2)</span>$
for  <span class="math">i</span>  from  <span class="math">\\lambda/2 - 1</span>  down to 0:
<span class="math">$\\det (\\mathbf{c}_i, \\mathbf{d}_i) = \\begin{cases} (0, 2\\mathbf{r}_{2i} - 1), &amp; \\text{if } \\mathbf{r}_{2i+1} = 0 \\\\ (2\\mathbf{r}_{2i} - 1, 0), &amp; \\text{otherwise} \\end{cases}</span>$</p>

    <p class="text-gray-300"><span class="math">$(a,b) := (2a + \\mathbf{c}_i, 2b + \\mathbf{d}_i)</span>$
Output  <span class="math">[a\\zeta_q + b]P</span> .</p>

    <p class="text-gray-300">The equivalence holds because invariants  <span class="math">Acc = [a]\\phi_p(P) + [b]P = [a\\zeta_q + b]P</span>  and  <span class="math">S_i = [\\mathbf{c}_i]\\phi_p(P) + [\\mathbf{d}_i]P = [\\mathbf{c}_i\\zeta_q + \\mathbf{d}_i]P</span>  are maintained at corresponding steps. Now we aim to show that the effect of Algorithm 2 (and hence also Algorithm 1) is to compute  <span class="math">[n_p(\\mathbf{r})]P = [a\\zeta_q + b]P</span>  for some injective  <span class="math">n_p : \\{0, 1\\}^{\\lambda} \\to \\mathbb{I}_q</span> . As a first step, we show that the mapping from  <span class="math">\\mathbf{r}</span>  to (a, b) is injective.</p>

    <p class="text-gray-300">For each  <span class="math">i \\in [0, ^{\\lambda}/2)</span> , the mapping  <span class="math">(\\mathbf{r}_{2i}, \\mathbf{r}_{2i+1}) \\mapsto (\\mathbf{c}_i, \\mathbf{d}_i)</span>  is injective, and exactly one of  <span class="math">\\mathbf{c}_i, \\mathbf{d}_i : \\{-1, 0, +1\\}</span>  is 0. Let  <span class="math">M_k = \\{(\\mathbf{c}, \\mathbf{d} : \\{-1, 0, +1\\}^k) : \\text{ for all } i</span> , exactly one of  <span class="math">\\mathbf{c}_i, \\mathbf{d}_i</span>  is 0}. So  <span class="math">\\mathbf{r} \\mapsto (\\mathbf{c}, \\mathbf{d}) : M_{\\lambda/2}</span>  is also injective.</p>

    <p class="text-gray-300"><strong>Lemma 2.</strong> For
<span class="math">$k \\geq 0</span>$
,  <span class="math">(\\mathbf{c}, \\mathbf{d}) \\in M_k \\mapsto \\left(\\sum_{j=0}^{k-1} \\mathbf{c}_j 2^j, \\sum_{j=0}^{k-1} \\mathbf{d}_j 2^j\\right)</span>  is injective.</p>

    <p class="text-gray-300"><em>Proof</em> (sketch). If  <span class="math">(\\mathbf{c}, \\mathbf{d})</span>  and  <span class="math">(\\mathbf{c}&#x27;, \\mathbf{d}&#x27;)</span>  coincide on a prefix of length m, then the statement reduces to a smaller instance of the lemma with that prefix deleted and k reduced by m. So we need only consider the case  <span class="math">(\\mathbf{c}_0, \\mathbf{d}_0) \\neq (\\mathbf{c}&#x27;_0, \\mathbf{d}&#x27;_0)</span>  and show that the resulting sums always differ. In fact they always differ modulo 4:</p>

    <p class="text-gray-300"><span class="math">$\\begin{aligned} (\\mathbf{c}_0, \\mathbf{d}_0) \\neq (\\mathbf{c}_0&#x27;, \\mathbf{d}_0&#x27;) &amp;\\implies \\left(\\sum_{j=0}^{k-1} \\mathbf{c}_j 2^j \\bmod 4, \\sum_{j=0}^{k-1} \\mathbf{d}_j 2^j \\bmod 4\\right) \\\\ &amp;\\neq \\left(\\sum_{j=0}^{k-1} \\mathbf{c}_j&#x27; 2^j \\bmod 4, \\sum_{j=0}^{k-1} \\mathbf{d}_j&#x27; 2^j \\bmod 4\\right) \\end{aligned}</span>$</p>

    <p class="text-gray-300">Therefore, it is sufficient to verify this property exhaustively for k=1 and k=2 (see injectivitylemma.py in [26]), since terms with  <span class="math">j \\geq 2</span>  do not affect the sums modulo 4.</p>

    <p class="text-gray-300">Corollary 1.  <span class="math">\\mathbf{r} \\mapsto (a, b)</span>  is injective.</p>

    <p class="text-gray-300"><em>Proof.</em> This follows from injectivity of  <span class="math">\\mathbf{r} \\mapsto (\\mathbf{c}, \\mathbf{d})</span> , the above lemma, and from  <span class="math">a = 2^{\\lambda/2} + 1 + 2\\sum_{j=0}^{\\lambda/2-1} \\mathbf{c}_j 2^j</span>  and  <span class="math">b = 2^{\\lambda/2} + 1 + 2\\sum_{j=0}^{\\lambda/2-1} \\mathbf{d}_j 2^j</span>  in Algorithm 2.</p>

    <p class="text-gray-300">Let  <span class="math">A = [0, 2^{\\lambda/2+1} + 2^{\\lambda/2} - 1] \\subset \\mathbb{F}_q</span> . It is straightforward to verify that  <span class="math">a, b \\in A</span>  at the end of Algorithm 2 for any input  <span class="math">\\mathbf{r}</span> . Next we need to show that the mapping  <span class="math">(a : A, b : A) \\mapsto (a\\zeta_q + b) \\mod q</span>  is injective. This will depend on the specific values of  <span class="math">\\zeta_q</span>  and q. We use the sumset notation  <span class="math">v \\cdot A + A</span>  for  <span class="math">\\{av + b \\in \\mathbb{F}_q : a, b \\in A\\}</span> . The question is then whether  <span class="math">|\\zeta_q \\cdot A + A| = |A|^2</span> .</p>

    <p class="text-gray-300">For intuition, note that if  <span class="math">av + b = a&#x27;v + b&#x27; \\pmod{q}</span> , with  <span class="math">a \\neq a&#x27;</span> , we would have  <span class="math">v = \\frac{b&#x27;-b}{a-a&#x27;} \\pmod{q}</span> . Thus the number of  <span class="math">v \\in \\mathbb{F}_q</span>  for which  <span class="math">|v \\cdot A + A| &lt; |A|^2</span>  is at most  <span class="math">(|A-A|-1)^2</span> . A Since in our case where  <span class="math">q \\approx 2^{254}</span>  and  <span class="math">\\lambda = 128</span> ,</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;4</sup> We thank Robert Israel for this observation. [29]</p>

    <p class="text-gray-300"><span class="math">(|A-A|-1)^2 \\approx 9 \\cdot 2^{130}</span>  is small compared to q, we would heuristically expect that  <span class="math">|\\zeta_q \\cdot A + A| = |A|^2</span>  unless there is some reason why  <span class="math">\\zeta_q</span>  does not behave like a random element of  <span class="math">\\mathbb{F}_q</span> .</p>

    <p class="text-gray-300">Of course  <span class="math">\\zeta_q</span>  is <em>not</em> a random element of  <span class="math">\\mathbb{F}_q</span> , and so the above argument can only be used for intuition. Even when  <span class="math">(|A-A|-1)^2</span>  is small compared to q, there are clearly values of  <span class="math">\\zeta_q</span>  and q for which it would not hold. To prove that it holds in the needed cases for the Tweedledum and Tweedledee curves used in our implementation, we take a different tack.</p>

    <p class="text-gray-300">Define a distance metric  <span class="math">\\delta_q</span>  on  <span class="math">\\mathbb{F}_q</span>  so that  <span class="math">\\delta_q(x,y)</span>  is the minimum distance between x and y around the ring of integers modulo q in either direction, and let  <span class="math">D_{q,\\,\\zeta_q}(m)</span>  be the minimum  <span class="math">\\delta_q</span> -distance between any two elements of  <span class="math">\\zeta_q \\cdot [0, m]</span> :</p>

    <p class="text-gray-300"><span class="math">$\\delta_q(x,y) = \\min(z, q-z) \\text{ where } z = (x-y) \\bmod q</span>$</p>

    <p class="text-gray-300"><span class="math">$D_{q,\\zeta_q}(m) = \\min\\{\\delta_q(a\\zeta_q, a&#x27;\\zeta_q) : a, a&#x27; \\in [0, m]\\}</span>$</p>

    <p class="text-gray-300">An algorithm to compute  <span class="math">D_{q,\\zeta_q}(m)</span>  is implemented by checksumsets.py in [26]; it works by iteratively finding each m at which  <span class="math">D_{q,\\zeta_q}(m)</span>  decreases.</p>

    <p class="text-gray-300">Now if  <span class="math">D_{q, \\zeta_q}(2^{\\lambda/2+1}+2^{\\lambda/2}-1) \\geq 2^{\\lambda/2+1}+2^{\\lambda/2}</span> , then copies of A will &quot;fit within the gaps&quot; in  <span class="math">\\zeta_q \\cdot A</span> . That is,  <span class="math">\\zeta_q \\cdot A + A</span>  will have  <span class="math">|A|^2</span>  elements, because all of the sets  <span class="math">\\{\\zeta_q \\cdot \\{a\\} + A : a \\in A\\}</span>  will be disjoint.</p>

    <p class="text-gray-300">Corollary 2. Let  <span class="math">n_p(\\mathbf{r}) = (a_{\\mathbf{r}}\\zeta_q + b_{\\mathbf{r}}) \\mod q</span>  as computed by Algorithm 2 for  <span class="math">\\lambda = 128</span> , and similarly for  <span class="math">n_q</span> , where p, q,  <span class="math">\\zeta_p</span>  and  <span class="math">\\zeta_q</span>  are as defined for the Tweedledum and Tweedledee curves (Section 6.1). Then  <span class="math">n_p</span>  and  <span class="math">n_q</span>  are injective.</p>

    <p class="text-gray-300">Hence, on each curve, sampling  <span class="math">\\mathbf{r}</span>  uniformly at random from  <span class="math">\\{0,1\\}^{\\lambda}</span>  and computing  <span class="math">[n(\\mathbf{r})]P</span>  via Algorithm 1 will be equivalent to sampling the challenge scalar uniformly at random from  <span class="math">\\mathbb{I}</span> . This is sufficient for security of our protocol, which does not depend on the specific set  <span class="math">\\mathbb{I}</span>  but only that its size is at least  <span class="math">2^{\\lambda}</span> .</p>

    <p class="text-gray-300">We have glossed over a complication. In order to implement Algorithm 1 in 3.5 constraints per bit, we must use incomplete short Weierstrass additions. Thus we need to show that the inputs to addition do not encounter the exceptional cases where two points being added have the same x-coordinate. We first write out [28, Theorem A.3.4] adapted to short Weierstrass curves:</p>

    <p class="text-gray-300"><strong>Theorem 3 (Distinct-</strong>x <strong>theorem).</strong> Let Q be a point of odd-prime order s on a short Weierstrass curve  <span class="math">E: y^2 = x^3 + ax + b</span>  over  <span class="math">\\mathbb{F}</span> . Let  <span class="math">k_{1...2}</span>  be integers in  <span class="math">\\left\\{-\\frac{s-1}{2} ... \\frac{s-1}{2}\\right\\} \\setminus \\{0\\}</span> . Let  <span class="math">P_i = [k_i]Q = (x_i, y_i)</span>  for  <span class="math">i \\in \\{1...2\\}</span> , with  <span class="math">k_2 \\neq \\pm k_1</span> . Then  <span class="math">P_{1,2} \\neq \\mathcal{O}</span>  and  <span class="math">x_1 \\neq x_2</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> Neither  <span class="math">P_i</span>  can be  <span class="math">\\mathcal{O}</span>  since  <span class="math">k_i \\neq 0 \\pmod{s}</span> . Assume for a contradiction that  <span class="math">x_1 = x_2</span> . For any  <span class="math">P_1 = [k_1] Q</span> , there can be only one other point  <span class="math">-P_1</span>  with the same x-coordinate (since the curve equation determines  <span class="math">\\pm y</span>  as a function of x). But  <span class="math">-P_1 = -[k_1] Q = [-k_1] Q</span> . Since  <span class="math">k : \\{-\\frac{s-1}{2} ... \\frac{s-1}{2}\\} \\mapsto [k] Q</span>  is injective and  <span class="math">k_{1...2}</span>  are in  <span class="math">\\{-\\frac{s-1}{2} ... \\frac{s-1}{2}\\}</span> , then  <span class="math">k_2 = \\pm k_1</span>  (contradiction).</p>

    <p class="text-gray-300">Now we take the same approach as [27], applying the above theorem and augmenting Algorithm 2 (the &quot;indexed version&quot; of Algorithm 1) with the assertions that need to hold:</p>

    <pre><code class="language-text">ALGORITHM 2A Inputs: \\mathbf{r} \\in \\{0,1\\}^{\\lambda}, P \\in E_p \\setminus \\{\\mathcal{O}_p\\} (a : \\mathbb{F}_q, b : \\mathbb{F}_q) := (2,2) for i from \\lambda/2 - 1 down to 0: let (\\mathbf{c}_i, \\mathbf{d}_i) = \\begin{cases} (0, 2\\mathbf{r}_{2i} - 1), &amp; \\text{if } \\mathbf{r}_{2i+1} = 0 \\\\ (2\\mathbf{r}_{2i} - 1, 0), &amp; \\text{otherwise} \\end{cases} &#9312; assert a\\zeta_q + b \\neq \\pm (\\mathbf{c}_i\\zeta_q + \\mathbf{d}_i) \\pmod{q} &#9313; assert (a\\zeta_q + b) + (\\mathbf{c}_i\\zeta_q + \\mathbf{d}_i) \\neq \\pm (a\\zeta_q + b) \\pmod{q} (a,b) := (2a + \\mathbf{c}_i, 2b + \\mathbf{d}_i) &#9314; assert a, b \\in [1, 2^{\\lambda/2 + 1} + 2^{\\lambda/2} - 1] &#9315; assert a\\zeta_q + b \\neq 0 \\pmod{q} Output [a\\zeta_q + b]P.
</code></pre>

    <p class="text-gray-300"><strong>Lemma 3.</strong> Suppose we are given a prime q,  <span class="math">\\zeta_q \\in \\mathbb{F}_q</span> , and  <span class="math">A \\subset \\mathbb{F}_q</span>  with  <span class="math">0 \\in A</span>  and  <span class="math">|\\zeta_q \\cdot A + A| = |A|^2</span> . Then  <span class="math">\\not\\equiv (\\alpha, \\beta) \\neq (0, 0) \\in A^2</span>  such that  <span class="math">\\alpha \\zeta_q + \\beta = 0 \\pmod{q}</span> .</p>

    <p class="text-gray-300"><em>Proof.</em>  <span class="math">0\\zeta_q + 0 = 0 \\pmod{q}</span>  and  <span class="math">(\\alpha : A, \\beta : A) \\mapsto (\\alpha\\zeta_q + \\beta) \\mod{q}</span>  is injective.</p>

    <p class="text-gray-300">As previously shown, the condition  <span class="math">|\\zeta_q \\cdot A + A| = |A|^2</span>  holds for q and  <span class="math">\\zeta_q</span>  corresponding to the Tweedledum and Tweedledee curves from Section 6.1. So we can use the lemma to show that the assertions in Algorithm 2a always hold for those curves:</p>

    <p class="text-gray-300">Assertion &#9312; can be split into  <span class="math">(a+\\mathbf{c}_i)\\zeta_q+(b+\\mathbf{d}_i)\\neq 0\\pmod{q}</span>  and  <span class="math">(a-\\mathbf{c}_i)\\zeta_q+(b-\\mathbf{d}_i)\\neq 0\\pmod{q}</span> . In both cases the assertion becomes  <span class="math">\\alpha\\zeta_q+\\beta\\neq 0\\pmod{q}</span>  where  <span class="math">\\alpha,\\beta\\in[1,2^{\\lambda/2}+2^{\\lambda/2-1}]\\subset A</span> , which holds by applying the lemma. Assertion &#9313; can be split into  <span class="math">\\mathbf{c}_i\\zeta_q+\\mathbf{d}_i\\neq 0\\pmod{q}</span> , which is true by construction, and  <span class="math">2(a\\zeta_q+b)+(\\mathbf{c}_i\\zeta_q+\\mathbf{d}_i)\\neq 0\\pmod{q}</span> . The latter is equivalent to asserting that  <span class="math">(2a+\\mathbf{c}_i)\\zeta_q+(2b+\\mathbf{d}_i)\\neq 0\\pmod{q}</span> , in other words it is redundant with assertion &#9315; following the update to (a,b). Assertion &#9314; is straightforward to verify, and then assertion &#9315; holds by applying the lemma.</p>

    </section>
`;
---

<BaseLayout title="Recursive Proof Composition without a Trusted Setup (2019/1021)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2019 &middot; eprint 2019/1021
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <PaperDisclaimer eprintUrl={EPRINT_URL} />
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <nav id="toc" class="mb-10 p-6 rounded-lg" style="background: rgba(255,255,255,0.03); border: 1px solid rgba(255,255,255,0.06);">
      <h2 class="text-lg font-bold mb-4">Table of Contents</h2>
      <ol class="space-y-1 text-sm text-gray-300
        list-decimal list-inside">
        <li>
          <a href="#sec-1" class="hover:text-white">Introduction</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-1.1" class="hover:text-white">Our Contributions</a></li>
            <li><a href="#sec-1.2" class="hover:text-white">Concurrent Work</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-2" class="hover:text-white">Preliminaries</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-2.1" class="hover:text-white">Zero-Knowledge Arguments of Knowledge</a></li>
            <li><a href="#sec-2.2" class="hover:text-white">Groups</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-3" class="hover:text-white">Polynomial Commitments</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-3.1" class="hover:text-white">Protocol Description</a></li>
            <li><a href="#sec-3.2" class="hover:text-white">Amortization Strategy</a></li>
          </ol>
        </li>
        <li><a href="#sec-4" class="hover:text-white">Nested Amortization</a></li>
        <li>
          <a href="#sec-5" class="hover:text-white">Main Argument</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-5.1" class="hover:text-white">Central Argument</a></li>
            <li><a href="#sec-5.2" class="hover:text-white">Full Protocol</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-6" class="hover:text-white">Implementation</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-6.1" class="hover:text-white">Cycles of Curves</a></li>
            <li><a href="#sec-6.2" class="hover:text-white">Endomorphism-based Optimizations</a></li>
            <li><a href="#sec-6.3" class="hover:text-white">Other Optimizations</a></li>
            <li><a href="#sec-6.4" class="hover:text-white">Evaluation</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-7" class="hover:text-white">Conclusion</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-7.1" class="hover:text-white">Future Work</a></li>
          </ol>
        </li>
      </ol>
      <p class="text-xs text-gray-500 mt-4 mb-1 font-semibold">
        Appendices
      </p>
      <ol class="space-y-1 text-sm text-gray-400
        list-[upper-alpha] list-inside">
        <li><a href="#app-a" class="hover:text-white">Proof of Theorem 1</a></li>
        <li><a href="#app-b" class="hover:text-white">Proof of Theorem 2</a></li>
        <li><a href="#app-c" class="hover:text-white">Proof for Algorithm 1</a></li>
      </ol>
      <p class="text-xs text-gray-500 mt-4 mb-1 font-semibold">
        Additional
      </p>
      <ul class="space-y-1 text-sm text-gray-400
        list-disc list-inside">
        <li><a href="#references" class="hover:text-white">References</a></li>
      </ul>
    </nav>


    <Fragment set:html={CONTENT} />

    <PaperHistory slug="recursive-proof-composition-without-a-trusted-setup-2019" />
  </article>
</BaseLayout>
