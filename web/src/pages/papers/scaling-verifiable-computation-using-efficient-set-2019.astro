---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2019/1494';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Scaling Verifiable Computation Using Efficient Set Accumulators';
const AUTHORS_HTML = 'Alex Ozdemir, Riad S.  Wahby, Barry Whitehat, Dan Boneh';

const CONTENT = `    <p class="text-gray-300">Alex Ozdemir Stanford Riad S. Wahby Stanford Barry Whitehat No Affiliation Dan Boneh Stanford {aozdemir,rsw,dabo}@cs.stanford.edu barrywhitehat@protonmail.com</p>

    <h6 id="sec-2" class="text-base font-medium mt-4">Abstract</h6>

    <p class="text-gray-300">Verifiable outsourcing systems offload a large computation to a remote server, but require that the remote server provide a succinct proof, called a SNARK, that proves that the server carried out the computation correctly. Real-world applications of this approach can be found in several blockchain systems that employ verifiable outsourcing to process a large number of transactions off-chain. This reduces the on-chain work to simply verifying a succinct proof that transaction processing was done correctly. In practice, verifiable outsourcing of state updates is done by updating the leaves of a Merkle tree, recomputing the resulting Merkle root, and proving using a SNARK that the state update was done correctly.</p>

    <p class="text-gray-300">In this work, we use a combination of existing and novel techniques to implement an RSA accumulator inside of a SNARK, and use it as a replacement for a Merkle tree. We specifically optimize the accumulator for compatibility with SNARKs. Our experiments show that the resulting system reduces costs compared to existing approaches that use Merkle trees for committing to the current state. These results apply broadly to any system that needs to offload batches of state updates to an untrusted server.</p>

    <h2 id="sec-3" class="text-2xl font-bold">1 Introduction</h2>

    <p class="text-gray-300">Verifiable outsourcing <em>[4, 13, 15, 16, 21, 32, 45, 47, 49, 52, 56, 61, 78, 79, 96, 106, 107, 108, 111, 112, 113, 121, 123, 124]</em> is a technique that enables a weak client to outsource a computation to a powerful server. The server returns the result of the computation along with a proof that the computation was done correctly. The proof must be succinct, which means that it must be short and cheap to verify. Verifiable outsourcing is relevant in a number of scenarios, including weak IoT devices, wearables, and low-power devices.</p>

    <p class="text-gray-300">More recently, verifiable outsourcing has been deployed in blockchain environments, because on-chain work is expensive—literally. Here, a batch of <span class="math">k</span> transactions, say <span class="math">k=1000</span>, is outsourced to an untrusted server, called an aggregator, for processing. The aggregator (1) verifies that the transactions are valid (e.g., properly signed), (2) computes the updated global state resulting from these transactions, and (3) generates a succinct proof that the aggregator correctly executed steps (1) and (2). The updated state and the succinct proof are then sent to the blockchain. In this approach, the (expensive) on-chain work is reduced to only verifying the proof—which is fast, taking time independent of the number of transactions <span class="math">k</span>—and then recording the updated state. Example systems that operate this way include Rollup <em>[7]</em>, Coda <em>[89]</em>, Matter <em>[86]</em>, and Zexe <em>[29]</em>.</p>

    <p class="text-gray-300">The process described above is called verifiable outsourcing of state update <em>[32]</em>. In more detail, the state is a set of elements <span class="math">S=\\{x_{1},\\ldots,x_{M}\\}</span> from some universe <span class="math">\\mathcal{X}</span>. The blockchain (or a low-power device) stores only a succinct digest of <span class="math">S</span>, e.g., the root of a Merkle tree whose leaves comprise the elements of <span class="math">S</span>. The untrusted but powerful aggregator stores the full set <span class="math">S</span>, in the clear. (Note that we treat <span class="math">S</span> as public data—privacy is orthogonal to our goal, which is scalability). When processing a batch of transactions as described above, the aggregator updates <span class="math">S</span> to produce a new set <span class="math">S^{\\prime}</span>, then computes a new Merkle digest for <span class="math">S^{\\prime}</span> that it sends to the blockchain to be verified and recorded. The aggregator’s proof establishes that its starting state <span class="math">S</span> is consistent with the current digest, that correctly applying transactions yields the ending state <span class="math">S^{\\prime}</span>, and that the new digest is consistent with <span class="math">S^{\\prime}</span>.</p>

    <p class="text-gray-300">The succinct proof needed here is called a SNARK <em>[19]</em>, which we define in more detail in the next section. Constructing efficient SNARKs and optimizing their implementation is a very active area of research <em>[13, 15, 16, 49, 64, 70, 96]</em>, with several new systems just in the last year <em>[11, 37, 43, 44, 62, 63, 85, 122]</em>. A common thread in all of these systems is that the proving costs are enormous. In particular, proving imposes multiple-orders-of-magnitude slowdown compared to native execution <em>[96, 106, 116]</em>; this can be defrayed via parallel execution, e.g., in clusters <em>[45, 121]</em> or on GPUs <em>[108, 112]</em>.</p>

    <p class="text-gray-300">Perhaps more importantly, for widely deployed SNARKs, proving correctness of large computations requires an amount of RAM proportional to the computation’s execution time <em>[16, 96]</em>. The result is that, even when proving is distributed across hundreds of workers, the largest reachable computation sizes are relatively small: only about 2 billion steps <em>[121]</em>. This imposes a strict upper bound on the number of transactions <span class="math">k</span> that can be processed in a single batch.</p>

    <p class="text-gray-300">This state of affairs has motivated a large body of work on computational primitives that yield efficient proofs. Examples include arithmetic <em>[79, 96, 108]</em>, control flow <em>[96, 108, 116]</em>, persistent state <em>[4, 32, 49, 56, 105]</em>, and random-access memory <em>[12, 13, 16, 32, 79, 116]</em>. Our work continues in this vein, with a focus on reducing proving costs for computations involving persistent state or random-access memory.</p>

    <h4 id="sec-4" class="text-lg font-semibold mt-6">Our work.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A Merkle tree <em>[90]</em> is an example of an <em>accumulator</em> <em>[17]</em>, a cryptographic primitive that lets one commit to a set <span class="math">S</span>, and later prove that an element <span class="math">x</span> is a member of <span class="math">S</span>. Although Merkle trees are used pervasively in today’s general-purpose verifiable state update applications, in this work we show that a Merkle tree is not the best choice for large batches of state updates when <span class="math">S</span> is moderately to very large, say $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq 2^{10}$. In particular, we show that replacing Merkle trees with RSA-based accumulators <em>[24, 40, 81]</em> significantly improves proving time and/or reachable computation size. Our contributions are:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>We define a new operation for RSA accumulators, which we call MultiSwap, that provides a precise sequential semantics for batched verifiable state updates (§3).</li>

      <li>We synthesize existing and novel techniques for efficiently implementing MultiSwap (and, more generally, RSA accumulators) in the context of SNARKs (§4). These techniques include a hash function that outputs provable prime numbers, and a new division-intractable hash function. Our approach makes use of very recent advances in manipulating RSA accumulators <em>[24]</em>.</li>

      <li>We apply our techniques in two contexts (§5). The first, called Rollup <em>[7, 65, 94]</em>, is a technique for batching cryptocurrency transactions off-chain in order to save on-chain work. The second is a general-purpose RAM abstraction with long-lived state (i.e., over many proofs), which builds upon and improves prior work <em>[12, 13, 16, 32, 116]</em>.</li>

      <li>We implement and evaluate (§6, §7). In particular, we compare our RSA accumulator implementation to Merkle trees in two benchmarks: one that measures only set operations, and one that implements a Rollup-style distributed payment application. We also compare our RAM abstraction with existing work via a cost model analysis.</li>

    </ul>

    <p class="text-gray-300">In the set operations benchmark, we find that RSA accumulators surpass <span class="math">2^{20}</span>-element Merkle trees for batches of <span class="math">\\approx</span>1,300 operations, and allow for 3.3<span class="math">\\times</span> more operations to be performed in the largest proof sizes we consider. In the Rollup application, RSA accumulators surpass <span class="math">2^{20}</span>-element Merkle trees for <span class="math">\\approx</span>600 transactions, and allow 1.9<span class="math">\\times</span> more transactions in the largest proofs. For RAM, we find that for a RAM of size <span class="math">2^{20}</span>, RSA accumulators surpass Merkle trees for <span class="math">\\approx</span>1000–4000 accesses, depending on write load.</p>

    <h2 id="sec-5" class="text-2xl font-bold">2 Background and definitions</h2>

    <h4 id="sec-6" class="text-lg font-semibold mt-6">Multisets.</h4>

    <p class="text-gray-300">A <em>multiset</em> is an unordered collection that may contain multiple copies of any element. <span class="math">S_{1}\\uplus S_{2}</span> denotes the union of multisets <span class="math">S_{1}</span> and <span class="math">S_{2}</span>, i.e., the multiset <span class="math">S_{3}</span> where each element <span class="math">x\\in S_{3}</span> has multiplicity equal to the sum of the multiplicities of <span class="math">x</span> in <span class="math">S_{1}</span> and <span class="math">S_{2}</span>. <span class="math">S_{1}\\boxminus S_{2}</span> denotes the strict difference of multisets <span class="math">S_{1}</span> and <span class="math">S_{2}</span>, i.e., the multiset <span class="math">S_{3}</span> where each element <span class="math">x\\in S_{3}</span> has multiplicity equal to the difference of multiplicities of <span class="math">x</span> in <span class="math">S_{1}</span> and <span class="math">S_{2}</span>. Note that <span class="math">S_{1}\\boxminus S_{2}</span> is only defined if <span class="math">S_{2}\\subseteq S_{1}</span>.</p>

    <h4 id="sec-7" class="text-lg font-semibold mt-6">RSA groups.</h4>

    <p class="text-gray-300">An <em>RSA group</em> is the group <span class="math">\\mathbb{Z}_{N}^{\\times}</span>, i.e., the multiplicative group of invertible integers modulo <span class="math">N</span>, where <span class="math">N</span> is the product of two secret primes. We define the <em>RSA quotient group</em> for <span class="math">N</span> as the group <span class="math">\\mathbb{Z}_{N}^{\\times}/\\{\\pm 1\\}</span>. In this group, the elements <span class="math">x</span> and <span class="math">N-x</span> are the same, meaning that all elements can be represented by integers in the interval <span class="math">[1,\\lfloor N/2\\rfloor]</span>. It is believed that this group has no element of known order, other than the identity.</p>

    <h4 id="sec-8" class="text-lg font-semibold mt-6">Proofs and arguments.</h4>

    <p class="text-gray-300">Informally, a <em>proof</em> is a protocol between a prover <span class="math">\\mathcal{P}</span> and a PPT verifier <span class="math">\\mathcal{V}</span> by which <span class="math">\\mathcal{P}</span> convinces <span class="math">\\mathcal{V}</span> that <span class="math">\\exists\\upsilon:\\mathfrak{R}(\\mathfrak{t},\\mathfrak{v})=1</span>, for a relation <span class="math">\\mathfrak{R}</span>, <span class="math">\\mathfrak{t}</span> an input from <span class="math">\\mathcal{V}</span>, and <span class="math">\\mathfrak{v}</span> a (possibly empty) <em>witness</em> from <span class="math">\\mathcal{P}</span>. A proof satisfies the following properties:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><em>Completeness:</em> If <span class="math">\\exists\\upsilon:\\mathfrak{R}(\\mathfrak{t},\\mathfrak{v})=1</span>, then an honest <span class="math">\\mathcal{P}</span> convinces <span class="math">\\mathcal{V}</span> except with probability at most <span class="math">\\epsilon_{c}\\ll 1/2</span>.</li>

      <li><em>Soundness:</em> If <span class="math">\\nexists\\upsilon:\\mathfrak{R}(\\mathfrak{t},\\mathfrak{v})=1</span>, no cheating prover <span class="math">\\mathcal{P}^{\\star}</span> convinces <span class="math">\\mathcal{V}</span> except with probability at most <span class="math">\\epsilon_{s}\\ll 1/2</span>.</li>

    </ul>

    <p class="text-gray-300">If soundness holds only against PPT <span class="math">\\mathcal{P}^{\\star}</span>, this protocol is instead called an <em>argument</em>. When the witness <span class="math">\\mathfrak{v}</span> exists, one may also require the proof system to provide <em>knowledge soundness</em>. Informally this means that whenever <span class="math">\\mathcal{P}</span> convinces <span class="math">\\mathcal{V}</span> that <span class="math">\\exists\\upsilon:\\mathfrak{R}(\\mathfrak{t},\\mathfrak{v})=1</span>, <span class="math">\\mathfrak{v}</span> exists <em>and</em> <span class="math">\\mathcal{P}</span> “knows” a witness <span class="math">\\mathfrak{v}</span> (slightly more formally, there exists a PPT algorithm, an <em>extractor</em>, that can produce a witness via oracle access to <span class="math">\\mathcal{P}</span>).</p>

    <h4 id="sec-9" class="text-lg font-semibold mt-6">Proof of exponentiation.</h4>

    <p class="text-gray-300">Let <span class="math">\\mathbb{G}</span> be a finite group of unknown order. Wesolowski <em>[120]</em> describes a protocol that allows <span class="math">\\mathcal{P}</span> to convince <span class="math">\\mathcal{V}</span> that <span class="math">y=x^{n}</span> in <span class="math">\\mathbb{G}</span>, namely a protocol for the relation <span class="math">\\mathfrak{R}</span> given by <span class="math">\\mathfrak{R}\\big{(}(n,x,y),\\cdot\\big{)}=1\\iff y=x^{n}\\in\\mathbb{G}</span>. The protocol is: on input <span class="math">(n,x,y)</span>, <span class="math">\\mathcal{V}</span> sends to <span class="math">\\mathcal{P}</span> a random <span class="math">\\ell</span> chosen from the first <span class="math">2^{k}</span> primes. <span class="math">\\mathcal{P}</span> sends back <span class="math">Q=x^{\\lfloor n/\\ell\\rfloor}\\in\\mathbb{G}</span>, and <span class="math">\\mathcal{V}</span> accepts only if <span class="math">Q^{\\ell}\\cdot x^{n\\bmod\\ell}=y\\in\\mathbb{G}</span> holds.</p>

    <p class="text-gray-300">This protocol is complete by inspection. Wesolowski shows that it is sound if the group <span class="math">\\mathbb{G}</span> satisfies the <em>adaptive root assumption</em>, roughly, it is infeasible for an adversary to find a random root of an element of <span class="math">\\mathbb{G}</span> chosen by the adversary. The RSA quotient group <span class="math">\\mathbb{Z}_{N}^{\\times}/\\{\\pm 1\\}</span> is conjectured to satisfy this assumption when <span class="math">\\mathcal{P}</span> cannot factor <span class="math">N</span> <em>[23]</em>.</p>

    <h4 id="sec-10" class="text-lg font-semibold mt-6">Division-intractable hashing.</h4>

    <p class="text-gray-300">Recall that a hash function <span class="math">H:\\mathcal{X}\\to\\mathcal{D}</span> is collision resistant if it is infeasible for a PPT</p>

    <p class="text-gray-300">dversary to find distinct <span class="math">x_{0},x_{1}</span> such that <span class="math">H(x_{0})=H(x_{1})</span>. Informally, <span class="math">H</span> is division intractable if the range of <span class="math">H</span> is <span class="math">\\mathbb{Z}</span>, and it is infeasible for a PPT adversary to find <span class="math">\\hat{x}</span> and a set <span class="math">\\{x_{i}\\}</span> in <span class="math">\\mathcal{X}</span> such that <span class="math">\\hat{x}\\not\\in\\{x_{i}\\}</span> and <span class="math">H(\\hat{x})</span> divides <span class="math">\\prod_{i}H(x_{i})</span>. A collision-resistant hash function that outputs prime numbers is division intractable. We construct a different division intractable hash function in Section 4.2.</p>

    <h4 id="sec-11" class="text-lg font-semibold mt-6">Pocklington primality certificates.</h4>

    <p class="text-gray-300">Let <span class="math">p</span> be a prime, and <span class="math">r&lt;p</span> and <span class="math">a</span> be positive integers. Define <span class="math">p^{\\prime}=p\\cdot r+1</span>. Pocklington’s criterion <em>[34]</em> states that if <span class="math">a^{p\\cdot r}\\equiv 1\\mod p^{\\prime}</span> and <span class="math">\\gcd(a^{r}-1,p^{\\prime})=1</span>, then <span class="math">p^{\\prime}</span> is prime. In this case, we say that <span class="math">(p,r,a)</span> is a Pocklington witness for <span class="math">p^{\\prime}</span>.</p>

    <p class="text-gray-300">Pocklington’s criterion is useful for constructing primality certificates. For a prime <span class="math">p_{n}</span>, this certificate comprises</p>

    <p class="text-gray-300"><span class="math">\\big{(}p_{0},\\{(r_{i},a_{i})\\}_{0&lt;i\\leq n}\\big{)}</span></p>

    <p class="text-gray-300">where <span class="math">p_{i}=p_{i-1}\\cdot r_{i}+1</span>. To check this certificate, first verify the primality of the small prime <span class="math">p_{0}</span> (e.g., using a deterministic primality test), then verify the Pocklington witness <span class="math">(p_{i-1},r_{i},a_{i})</span> for <span class="math">p_{i}</span>, <span class="math">0&lt;i\\leq n</span>. If each <span class="math">r_{i}</span> is nearly as large as <span class="math">p_{i}</span>, the bit lengths double at each step, meaning that the total verification cost is dominated by the cost of the final step.</p>

    <h3 id="sec-12" class="text-xl font-semibold mt-8">2.1 Accumulators</h3>

    <p class="text-gray-300">A cryptographic accumulator <em>[17]</em> commits to a collection of values (e.g., a vector, set, or multiset) as a succinct digest. This digest is binding, meaning informally that it is computationally infeasible to equivocate about the collection represented by the digest. In addition, accumulators admit succinct proofs of membership and, in some cases, non-membership.</p>

    <h4 id="sec-13" class="text-lg font-semibold mt-6">Merkle trees.</h4>

    <p class="text-gray-300">The best-known vector accumulator is the Merkle tree <em>[90]</em>. To review, this is a binary tree that stores a vector in the labels of its leaves; the label associated with an internal node of this tree is the result of applying a collision-resistant hash <span class="math">H</span> to the concatenation of the children’s labels; and the digest representing the collection is the label of the root node.</p>

    <p class="text-gray-300">A membership proof for the leaf at index <span class="math">i</span> is a path through the tree, i.e., the labels of the siblings of all nodes between the purported leaf and the root. Verifying the proof requires computing the node labels along the path and comparing the final value to the digest (the bits of <span class="math">i</span> indicate whether each node is the right or left child of its parent). Updating a leaf’s label is closely related: given a membership proof for the old value, the new digest is computed by swapping the old leaf for the new one, then computing the hashes along the path. Merkle trees do not support succinct non-membership proofs.</p>

    <p class="text-gray-300">The cost of verifying <span class="math">k</span> membership proofs for a vector comprising <span class="math">2^{m}</span> values is <span class="math">k\\cdot m</span> evaluations of <span class="math">H</span>. The cost of <span class="math">k</span> leaf updates is <span class="math">2\\cdot k\\cdot m</span> evaluations. Membership proofs and updates cannot be batched for savings.</p>

    <h4 id="sec-14" class="text-lg font-semibold mt-6">RSA accumulators.</h4>

    <p class="text-gray-300">The RSA multiset accumulator <em>[40, 81]</em> represents a multiset <span class="math">S</span> with the digest</p>

    <p class="text-gray-300"><span class="math">\\llbracket S\\rrbracket=g^{\\prod_{s\\in S}H(s)}\\in\\mathbb{G},</span></p>

    <p class="text-gray-300">where <span class="math">g</span> is a fixed member of an RSA quotient group <span class="math">\\mathbb{G}</span> and <span class="math">H</span> is a division-intractable hash function (§2). Inserting a new element <span class="math">s</span> into <span class="math">S</span> thus requires computing <span class="math">\\llbracket S\\rrbracket^{H(s)}</span>.</p>

    <p class="text-gray-300">To prove membership of <span class="math">s\\in S</span>, the prover furnishes the value <span class="math">\\pi=\\llbracket S\\rrbracket^{1/H(s)}</span>, i.e., a <span class="math">H(s)</span>’th root of <span class="math">\\llbracket S\\rrbracket</span>. This proof is verified by checking that <span class="math">\\pi^{H(s)}=\\llbracket S\\rrbracket</span>.</p>

    <p class="text-gray-300">Non-membership proofs are also possible <em>[81]</em>, leveraging the fact that <span class="math">s^{\\prime}\\not\\in S</span> if and only if <span class="math">\\gcd(H(s^{\\prime}),\\prod_{s\\in S}H(s))=1</span>. This means that the Bézout coefficients <span class="math">a,b</span>, i.e., integers satisfying</p>

    <p class="text-gray-300"><span class="math">a\\cdot H(s^{\\prime})+b\\cdot\\prod_{s\\in S}H(s)=1</span></p>

    <p class="text-gray-300">are a non-membership witness, since the above implies that</p>

    <p class="text-gray-300"><span class="math">\\llbracket S\\rrbracket^{b}\\cdot(g^{a})^{H(s^{\\prime})}=g</span></p>

    <p class="text-gray-300">Because <span class="math">a</span> is large and <span class="math">b</span> is small, the proof <span class="math">(g^{a},b)</span> is succinct.</p>

    <p class="text-gray-300">Insertions, membership proofs, and non-membership proofs can all be batched <em>[24]</em> via Wesolowski proofs (§2). For example, since <span class="math">\\llbracket S\\uplus\\{s_{i}\\}\\rrbracket=\\llbracket S\\rrbracket^{\\prod_{i}s_{i}}</span>, computing an updated digest directly requires an exponentiation by <span class="math">\\prod_{i}s_{i}</span>. In contrast, checking the corresponding proof only requires computing and then exponentiating by <span class="math">\\prod_{i}s_{i}</span> mod <span class="math">\\ell</span>, for <span class="math">\\ell</span> a prime of less than 200 bits. This means that the exponentiation (but not the multiplication) to verify a batch proof has constant size.</p>

    <h3 id="sec-15" class="text-xl font-semibold mt-8">2.2 Verifiable computation and SNARKs</h3>

    <p class="text-gray-300">Several lines of built systems <em>[13, 15, 16, 21, 32, 47, 49, 61, 79, 96, 106, 107, 108, 112, 113, 124]</em> enable the following high-level model. A verifier <span class="math">\\mathcal{V}</span> asks a prover <span class="math">\\mathcal{P}</span> to convince it that <span class="math">y=\\Psi(x)</span>, where <span class="math">\\Psi</span> is a program taking input <span class="math">x</span> and returning output <span class="math">y</span>. To do so, <span class="math">\\mathcal{P}</span> produces a short certificate that the claimed output is correct. Completeness holds with <span class="math">\\epsilon_{c}=0</span>; soundness holds as long as <span class="math">\\mathcal{P}</span> is computationally bounded, with <span class="math">\\epsilon_{s}</span> negligible in a security parameter (§2).</p>

    <p class="text-gray-300">Roughly speaking, these systems comprise two parts. In the front-end, <span class="math">\\mathcal{V}</span> compiles <span class="math">\\Psi</span> into a system of equations <span class="math">\\mathcal{C}(X,Y,Z)</span>, where <span class="math">X,Y</span>, and <span class="math">Z</span> are (vectors of) formal variables. <span class="math">\\mathcal{V}</span> constructs <span class="math">\\mathcal{C}</span> such that <span class="math">z</span> satisfying <span class="math">\\mathcal{C}(X=x,Y=y,Z=z)</span> exists (that is, the formal variable <span class="math">X</span> is bound to the value <span class="math">x</span>, and so on) if and only if <span class="math">y=\\Psi(x)</span>. The back-end comprises cryptographic and complexity-theoretic machinery by which <span class="math">\\mathcal{P}</span> convinces <span class="math">\\mathcal{V}</span> that a witness <span class="math">z</span> exists for <span class="math">X=x</span> and <span class="math">Y=y</span>.</p>

    <p class="text-gray-300">This paper focuses on compilation in the front-end. We target back-ends derived from GGPR <em>[64]</em> via Pinocchio <em>[96]</em> (including <em>[15, 16, 70]</em>), which we briefly describe below.</p>

    <p class="text-gray-300">Our work is also compatible with other back-ends, e.g., Zaatar [106], Ligero [2], Bulletproofs [36], Sonic [85], and Aurora [14].</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">GGPR, Pinocchio and their derivatives instantiate zero-knowledge Succinct Non-interactive ARguments of Knowledge with preprocessing (zkSNARKs), which are argument protocols satisfying completeness, knowledge soundness, and zero knowledge ( <span class="math">\\S 2</span> ), where knowledge soundness and zero knowledge apply to the assignment to  <span class="math">Z</span> . In addition, these protocols satisfy succinctness: informally, proof length and verification time are both sublinear in  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  (here, proofs are of constant size, while  </span>\\mathcal{V}<span class="math"> &#x27;s work is  </span>O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> ). These protocols include a preprocessing phase, in which  </span>\\mathcal{V}<span class="math">  (or someone that  </span>\\mathcal{V}<span class="math">  trusts) processes  </span>\\mathcal{C}<span class="math">  to produce a structured reference string (SRS), which is used by  </span>\\mathcal{P}<span class="math">  to prove and  </span>\\mathcal{V}<span class="math">  to verify. The cost of the preprocessing phase and the length of the SRS are  </span>O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> . The cost of the proving phase is  </span>O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">  in time and  </span>O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$  in space (i.e., prover RAM).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The system of equations  <span class="math">\\mathcal{C}(X,Y,Z)</span>  is a rank-1 constraint system (R1CS) over a large finite field  <span class="math">\\mathbb{F}_p</span> . An R1CS is defined by three matrices,  $A,B,C\\in \\mathbb{F}_p^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\times (1 +</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)}<span class="math"> . Its satisfiability is defined as follows: for  </span>W<span class="math">  the column vector of formal variables  </span>[1,X,Y,Z]^{\\top}<span class="math"> ,  </span>\\mathcal{C}(X,Y,Z)<span class="math">  is the system of  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  equations  </span>(A\\cdot W)\\circ (B\\cdot W) = C\\cdot W<span class="math"> , where  </span>\\circ<span class="math">  denotes the Hadamard (element-wise) product. In other words, an R1CS  </span>\\mathcal{C}<span class="math">  is a conjunction of  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  constraints in  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$  variables, where each constraint has the form "linear combination times linear combination equals linear combination."</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">These facts outline a computational setting whose costs differ significantly from those of CPUs. On a CPU, bit operations are cheap and word-level arithmetic is slightly more costly. In an R1CS, addition is free, word-level multiplication has unit cost, and bitwise manipulation and many inequality operations are expensive; details are given below.</p>

    <p class="text-gray-300">Compiling programs to constraints. A large body of prior work [13, 16, 32, 79, 96, 106-108, 115, 116] deals with efficiently compiling from programming languages to constraints.</p>

    <p class="text-gray-300">An important technique for non-arithmetic operations is the use of advice, variables in  <span class="math">Z</span>  whose values are provided by the prover. For example, consider the program fragment  <span class="math">x! = 0</span> , which cannot be concisely expressed in terms of rank-1 constraints. Since constraints are defined over  <span class="math">\\mathbb{F}_p</span> , this assertion might be rewritten as  <span class="math">X^{p - 1} = 1</span> , which is true just when  <span class="math">X \\neq 0</span>  by Fermat's little theorem. But this is costly: it requires  <span class="math">O(\\log p)</span>  multiplications. A less expensive way to express this constraint is  <span class="math">Z \\cdot X = 1</span> ; the satisfying assignment</p>

    <p class="text-gray-300">to  <span class="math">Z</span>  is  <span class="math">X^{-1} \\in \\mathbb{F}_p</span> . Since every element of  <span class="math">\\mathbb{F}_p</span>  other than 0 has a multiplicative inverse, this is satisfiable just when  <span class="math">X \\neq 0</span> .</p>

    <p class="text-gray-300">Comparisons, modular reductions, and bitwise operations make heavy use of advice from  <span class="math">\\mathcal{P}</span> . For example, the program fragment  <span class="math">y = x1 \\&amp;amp; x2</span> , where  <span class="math">x1</span>  and  <span class="math">x2</span>  have bit width  <span class="math">b</span>  and  <span class="math">\\&amp;amp;</span>  is bitwise AND, is represented by the following constraints:</p>

    <div class="my-4 text-center"><span class="math-block">Z _ {1, 0} + 2 \\cdot Z _ {1, 1} + \\dots + 2 ^ {b - 1} \\cdot Z _ {1, b - 1} = X _ {1}</span></div>

    <div class="my-4 text-center"><span class="math-block">Z _ {2, 0} + 2 \\cdot Z _ {2, 1} + \\dots + 2 ^ {b - 1} \\cdot Z _ {2, b - 1} = X _ {2}</span></div>

    <div class="my-4 text-center"><span class="math-block">Z _ {3, 0} + 2 \\cdot Z _ {3, 1} + \\dots + 2 ^ {b - 1} \\cdot Z _ {3, b - 1} = Y</span></div>

    <div class="my-4 text-center"><span class="math-block">Z _ {1, 0} \\cdot (1 - Z _ {1, 0}) = 0</span></div>

    <p class="text-gray-300">.</p>

    <div class="my-4 text-center"><span class="math-block">Z _ {1, b - 1} \\cdot (1 - Z _ {1, b - 1}) = 0</span></div>

    <div class="my-4 text-center"><span class="math-block">Z _ {2, 0} \\cdot (1 - Z _ {2, 0}) = 0</span></div>

    <p class="text-gray-300">.</p>

    <div class="my-4 text-center"><span class="math-block">Z _ {2, b - 1} \\cdot (1 - Z _ {2, b - 1}) = 0</span></div>

    <div class="my-4 text-center"><span class="math-block">Z _ {1, 0} \\cdot Z _ {2, 0} = Z _ {3, 0}</span></div>

    <p class="text-gray-300">.</p>

    <div class="my-4 text-center"><span class="math-block">Z _ {1, b - 1} \\cdot Z _ {2, b - 1} = Z _ {3, b - 1}</span></div>

    <p class="text-gray-300">Here, the variables  <span class="math">Z_{1,0} \\ldots Z_{1,b-1}</span>  contain a purported bitwise expansion of  <span class="math">X_1</span> , and likewise  <span class="math">Z_{2,0} \\ldots Z_{2,b-1}</span>  and  <span class="math">Z_{3,0} \\ldots Z_{3,b-1}</span>  for  <span class="math">X_2</span>  and  <span class="math">Y</span> , respectively. The first three constraints ensure that the assignment to  <span class="math">Z</span>  meets this requirement provided that each  <span class="math">Z_{i,j}</span>  is assigned either 0 or 1; the remaining constraints ensure the latter. This operation is known as bit splitting; its cost for a  <span class="math">b</span> -bit value is  <span class="math">b + 1</span> , so the above program fragment costs  <span class="math">3 \\cdot b + 3</span>  constraints in total. Comparisons and modular reductions also require bit splitting.</p>

    <p class="text-gray-300">Compiling conditionals to constraints requires expanding all branches into their corresponding constraints and selecting the correct result. Loops are similar; loop bounds must be statically known. For example, the program fragment</p>

    <p class="text-gray-300">if (x1 != 0) { y = x2 + 1 } else { y = x2 * 3 }</p>

    <p class="text-gray-300">compiles to the constraints</p>

    <div class="my-4 text-center"><span class="math-block">Z _ {1} \\cdot X _ {1} = Z _ {2} \\tag {1}</span></div>

    <div class="my-4 text-center"><span class="math-block">Z _ {3} \\cdot \\left(Z _ {2} - 1\\right) = 0 \\tag {2}</span></div>

    <div class="my-4 text-center"><span class="math-block">(1 - Z _ {3}) \\cdot X _ {1} = 0 \\tag {3}</span></div>

    <div class="my-4 text-center"><span class="math-block">(1 - Z _ {3}) \\cdot (Y - X _ {2} - 1) = 0 \\tag {4}</span></div>

    <div class="my-4 text-center"><span class="math-block">Z _ {3} \\cdot (Y - 3 \\cdot X _ {2}) = 0 \\tag {5}</span></div>

    <p class="text-gray-300">This works as follows: if  <span class="math">X_{1} = 0</span> ,  <span class="math">Z_{2} = 0</span>  by (1), so  <span class="math">Z_{3} = 0</span>  by (2) and  <span class="math">Y = X_{2} + 1</span>  by (4). Otherwise,  <span class="math">Z_{3} = 1</span>  by (3), so  <span class="math">Z_{2} = 1</span>  by (2),  <span class="math">Z_{1} = X_{1}^{-1}</span>  by (1), and  <span class="math">Y = 3 \\cdot X_{2}</span>  by (5).</p>

    <p class="text-gray-300">Multiprecision arithmetic. xJspark [79] describes techniques for compiling multiprecision arithmetic to efficient constraint systems. In brief, large integers are represented as a sequence of limbs in  <span class="math">\\mathbb{F}_p</span> . The limb width,  <span class="math">b_{l}</span> , is defined such</p>

    <p class="text-gray-300">that a <span class="math">b</span>-bit number <span class="math">a</span> is represented as <span class="math">\\eta=\\lceil b/b_{l}\\rceil</span> limbs <span class="math">\\{\\hat{a}_{i}\\}</span>, where <span class="math">a=\\sum_{i=0}^{\\eta-1}\\tilde{a}_{i}\\cdot 2^{b_{l}\\cdot i}</span>. For correctness, the compiler must track the maximum value of each number and ensure that <span class="math">\\mathcal{C}</span> contains constraints that encode a sufficient number of limbs.</p>

    <p class="text-gray-300">Multiprecision operations rely heavily on advice from <span class="math">\\mathcal{P}</span>. At a high level, <span class="math">\\mathcal{P}</span> supplies the result of a multiplication or addition, and the compiler emits constraints to check that result. Subtractions and divisions are checked by verifying the inverse addition or multiplication, respectively. xJsnark describes a range of optimizations that reduce the required number of constraints. We leave details to <em>[79]</em>, because they are not necessary to understand our further optimizations (§4.3).</p>

    <h4 id="sec-16" class="text-lg font-semibold mt-6">Random-access memory</h4>

    <p class="text-gray-300">Programs that make use of RAM—in particular, programs whose memory accesses depend on the input, and thus cannot be statically analyzed—present a challenge for compiling to constraints. Prior work demonstrates three solutions. We now describe each, and compare costs and functionality below.</p>

    <h5 id="sec-17" class="text-base font-semibold mt-4">Linear scan.</h5>

    <p class="text-gray-300">The most direct approach to emulating RAM in constraints is to perform a linear scan <em>[79, 96]</em>. Concretely, <span class="math">Y=\\mathsf{LOAD}(Z)</span> compiles to a loop that scans through an array, comparing the loop index to <span class="math">Z</span> and, if they match, setting <span class="math">Y</span> to the corresponding value. (STORE is analogous.)</p>

    <h5 id="sec-18" class="text-base font-semibold mt-4">The Pantry approach.</h5>

    <p class="text-gray-300">In Pantry <em>[32]</em>, the authors borrow a technique from the memory-checking literature <em>[20]</em> based on Merkle trees <em>[90]</em> (see also §2.1). In particular, Pantry stores the contents of RAM in the leaves of a Merkle tree whose root serves as ground truth for the state of memory.</p>

    <p class="text-gray-300">For a <span class="math">\\mathsf{LOAD}</span>, <span class="math">\\mathcal{P}</span> furnishes advice comprising a purported value from memory, plus a Merkle path authenticating that value. The corresponding constraints encode verification of the Merkle path, i.e., a sequence of hash function invocations and an equality check against the Merkle root. For a STORE, <span class="math">\\mathcal{P}</span> furnishes, and the constraints verify, the same values as for a <span class="math">\\mathsf{LOAD}</span>. In addition, the constraints encode a second sequence of hash function invocations that compute a new Merkle root corresponding to the updated memory state.</p>

    <h5 id="sec-19" class="text-base font-semibold mt-4">The BCGT approach.</h5>

    <p class="text-gray-300">Ben-Sasson et al. <em>[12]</em> introduce, and other work <em>[13, 16, 79, 116]</em> refines, an approach building on the observation <em>[3]</em> that one can check a sequence of RAM operations using an <em>address-ordered transcript</em>, i.e., the sequence of RAM operations sorted by address accessed, breaking ties by execution order. In such a transcript, each <span class="math">\\mathsf{LOAD}</span> is preceded either by the corresponding STORE or by another <span class="math">\\mathsf{LOAD}</span> from the same address; correctness of RAM dictates that this <span class="math">\\mathsf{LOAD}</span> should return the same value as the preceding operation. (A <span class="math">\\mathsf{LOAD}</span> from an address to which no value was previously stored returns a default value, say, 0.)</p>

    <p class="text-gray-300">Leveraging this observation, correctness of memory operations is compiled to constraints as follows. First, every access to memory appends a tuple <span class="math">(\\mathsf{IDX}_{i},\\mathsf{OP}_{i},\\mathsf{ADDR}_{i},\\mathsf{DATA}_{i})</span> to an <em>execution-ordered transcript</em>; here, <span class="math">\\mathsf{IDX}_{i}=i</span> is the index of the memory operation and <span class="math">\\mathsf{OP}_{i}</span> is either <span class="math">\\mathsf{LOAD}</span> or STORE. Then <span class="math">\\mathcal{P}</span> furnishes a purported address-ordered transcript <span class="math">\\mathcal{T}</span>, and the constraints check its correctness by ensuring that (1) transcript <span class="math">\\mathcal{T}</span> is a permutation of the execution-ordered transcript, (2) each sequential pair of entries in transcript <span class="math">\\mathcal{T}</span> is indeed correctly ordered, and (3) each sequential pair of entries in transcript <span class="math">\\mathcal{T}</span> is <em>coherent</em>, i.e., each <span class="math">\\mathsf{LOAD}</span> returns the value of the previous STORE (or the default if no such STORE exists). Check (1) is implemented with a <em>routing network</em> <em>[18, 118]</em>.</p>

    <h5 id="sec-20" class="text-base font-semibold mt-4">Costs and functionality.</h5>

    <p class="text-gray-300">Roughly speaking, for tiny memories linear scan is cheapest; otherwise, BCGT-style RAM is. In more detail, assume a memory of size <span class="math">2^{m}</span>, accessed <span class="math">k</span> times. For a linear scan, each RAM operation costs <span class="math">O(2^{m})</span> constraints. (i.e., <span class="math">2^{m}</span> copies of constraints encoding conditional assignment). For Pantry, each <span class="math">\\mathsf{LOAD}</span> entails <span class="math">m</span> copies of constraints encoding a collision-resistant hash function and each STORE entails <span class="math">2m</span> such copies, where such hash functions entail a few hundred to a few thousand constraints (§6; <em>[15, 32, 79]</em>). For BCGT, each RAM operation costs <span class="math">O(\\log k)</span> constraints for the routing network, <span class="math">O(m)</span> constraints for address comparison, and <span class="math">O(1)</span> constraints for coherence checking, all with good constants <em>[116, Fig. 5]</em>.</p>

    <p class="text-gray-300">Although Pantry-style RAM is costly, it offers functionality that the other two do not: the ability to pass the full state of a large RAM from one computation to another. Pantry accomplishes this by including in <span class="math">X</span> the Merkle root corresponding to the initial RAM state; this has constant size (usually one element of <span class="math">\\mathbb{F}_{p}</span>). In contrast, BCGT and linear scan would both require <span class="math">2^{m}</span> values in <span class="math">X</span> for a <span class="math">2^{m}</span>-sized RAM; as discussed above, this would incur <span class="math">2^{m}</span> cost for <span class="math">\\mathcal{V}</span> in verification. (Prior work <em>[15, 16]</em> uses this approach to <em>partially</em> initialize RAM.)</p>

    <h2 id="sec-21" class="text-2xl font-bold">3 Swap sequences via batched operations</h2>

    <p class="text-gray-300">In this section, we define a new primitive, which we call MultiSwap, that exposes a sequential update semantics for RSA accumulators (§2.1). MultiSwap takes an accumulator and a list of pairs of elements, removing the first element from each pair and inserting the second. The key property of this primitive is that it is defined in terms of <em>batched</em> insertions and removals. In Section 4, we show how these batched operations are efficiently implemented as a system of constraints (§2.2).</p>

    <p class="text-gray-300">In more detail, let <span class="math">S</span> and <span class="math">S^{\\prime}</span> be multisets, and let <span class="math">(x_{1},y_{1}),\\ldots,(x_{n},y_{n})</span> be a sequence of operations, called <em>swaps</em>, that replaces each <span class="math">x_{i}</span> by <span class="math">y_{i}</span> <em>in order</em>: <span class="math">(x_{1},y_{1})</span> applied to <span class="math">S</span> produces some new set <span class="math">S_{1}=S\\boxminus\\{x_{1}\\}\\uplus\\{y_{1}\\}</span>; then <span class="math">(x_{2},y_{2})</span> applied to <span class="math">S_{1}</span> produces <span class="math">S_{2}=S_{1}\\boxminus\\{x_{2}\\}\\uplus\\{y_{2}\\}</span>, etc. Our goal is to verify that when the above sequence is applied to <span class="math">S</span>, the result</p>

    <p class="text-gray-300">is  <span class="math">S&#x27; = S_n</span> . Recall from Section 2.1 that RSA accumulators admit efficient batched insertions (deletions are analogous; §4). Our question is: how can we use this un-ordered primitive to implement one with ordered semantics?</p>

    <p class="text-gray-300">Consider the following naive solution: first verify the deletions, then verify the insertions. In other words, verify that there exists some  <span class="math">S_{\\mathrm{mid}}</span>  such that  <span class="math">S \\boxminus \\{x_i\\} = S_{\\mathrm{mid}}</span>  and  <span class="math">S_{\\mathrm{mid}} \\boxplus \\{y_i\\} = S&#x27;</span> . The problem with this approach is that it does not permit certain valid sequences, i.e., those in which a later swap deletes an item inserted by an earlier swap. (To see why, notice that  <span class="math">S_{\\mathrm{mid}}</span>  only exists if all  <span class="math">x_i \\in S</span> .)</p>

    <p class="text-gray-300">Instead, our solution first verifies all the insertions, and then verifies all the deletions, irrespective of the order in which the operations are listed. In other words, it verifies the predicate</p>

    <p class="text-gray-300"><span class="math">\\exists S_{\\mathrm{mid}}:\\quad S\\uplus \\{y_i\\} = S_{\\mathrm{mid}}\\quad \\wedge \\quad S_{\\mathrm{mid}}\\boxdot \\{x_i\\} = S^{\\prime}</span>  (6)</p>

    <p class="text-gray-300">(Note that  <span class="math">S_{\\mathrm{mid}} \\boxdot \\{x_i\\} = S&#x27;</span>  is equivalent to  <span class="math">S&#x27; \\uplus \\{x_i\\} = S_{\\mathrm{mid}}</span> .) Intuitively, Equation (6) holds just when each element of an unordered multiset of swaps  <span class="math">\\{(x_i, y_i)\\}</span>  can be applied to  <span class="math">S</span>  in some order to produce  <span class="math">S&#x27;</span> . As we discuss below, this multiset may include cycles, subsets of swaps that have no net effect.</p>

    <p class="text-gray-300">We now give a precise semantics for MultiSwap. Let MultiSwap  <span class="math">(S, \\sigma, S&#x27;)</span>  denote the predicate that holds just when Equation (6) is satisfied. Let  <span class="math">\\sigma</span>  denote an unordered multiset of swaps  <span class="math">\\{(x_i, y_i)\\}</span> . A swap  <span class="math">(x_i, y_i)</span>  is valid for  <span class="math">S^<em></span>  if  <span class="math">x_i \\in S^</em></span> . We say that  <span class="math">\\sigma</span>  is sequentially consistent with respect to  <span class="math">S</span>  if there exists some ordering on  <span class="math">\\sigma</span>  such that all swaps are valid when applied in that order starting from  <span class="math">S</span> . Furthermore, we say that  <span class="math">\\sigma</span>  produces  <span class="math">S&#x27;</span>  from  <span class="math">S</span>  if  <span class="math">S&#x27;</span>  is the product of such an application order to  <span class="math">S</span> , and we say that  <span class="math">\\sigma^c</span>  is a cycle if it comprises  <span class="math">\\{(c_0, c_1), (c_1, c_2), \\ldots, (c_n, c_0)\\}</span> .</p>

    <p class="text-gray-300">Lemma 1. MultiSwap  <span class="math">(S, \\sigma, S&#x27;)</span>  holds if and only if there exist any number of cycles  <span class="math">\\sigma_i^c</span>  and cycle-free  <span class="math">\\sigma&#x27; \\subseteq \\sigma</span>  such that  <span class="math">\\sigma = \\sigma&#x27; \\uplus \\bigoplus_i \\sigma_i^c</span> ,  <span class="math">\\sigma&#x27;</span>  is sequentially consistent with respect to  <span class="math">S</span> , and  <span class="math">\\sigma&#x27;</span>  produces  <span class="math">S&#x27;</span>  from  <span class="math">S</span> .</p>

    <p class="text-gray-300">The proof of Lemma 1 is in Appendix A. Section 5 applies MultiSwap to problems that need sequential semantics for batched verifiable state updates.</p>

    <p class="text-gray-300">In the previous section we described how the MultiSwap primitive is built from batched insertions and removals. In this section we describe these batched operations, the primitives that they are built on, and how those primitives are implemented as a set of constraints  <span class="math">\\mathcal{C}</span>  (§2.2).</p>

    <p class="text-gray-300">Recall (§2.1) that RSA accumulators support batched insertions through an interactive protocol whose final check is</p>

    <div class="my-4 text-center"><span class="math-block">Q ^ {\\ell} \\cdot [   [ S ]   ] ^ {\\prod_ {i} H _ {\\Delta} (y _ {i}) \\bmod \\ell} = [   [ S \\uplus \\{y _ {i} \\} ]   ] \\tag {7}</span></div>

    <p class="text-gray-300">where  <span class="math">\\llbracket \\cdot \\rrbracket</span>  denotes a digest;  <span class="math">S</span> , the initial multiset;  <span class="math">\\ell</span> , a random prime challenge;  <span class="math">\\{y_i\\}</span> , the inserted elements;  <span class="math">H_{\\Delta}</span> , a division-intractable hash function; and  <span class="math">Q</span> , a witness from  <span class="math">\\mathcal{P}</span> . Removing</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Figure 1: Insertion proof verification procedure (§4), which checks that  <span class="math">Q</span>  is a valid Wesolowski proof (§2) for the exponentiation  <span class="math">\\llbracket S^{\\prime}\\rrbracket = \\llbracket S\\rrbracket^{\\prod_{i}H_{\\Delta}(y_{i})}</span>  on challenge  <span class="math">\\ell</span> . To do so, it computes  <span class="math">\\ell = H_{p}(y_{1},\\ldots ,y_{k})</span>  (purple box, bottom left), computes  <span class="math">\\prod_{i}H_{\\Delta}(y_{i})</span>  mod  <span class="math">\\ell</span>  (red and blue boxes, top), computes the LHS of the verification equation (cyan boxes, bottom right), and checks that equation (black box, bottom right).  <span class="math">H_{\\Delta}</span>  is a division-intractable hash function (§4.2),  <span class="math">H_{p}</span>  is a hash to a prime (§4.1), and  <span class="math">G</span>  is an RSA quotient group (§2).</p>

    <p class="text-gray-300">elements  <span class="math">\\{x_{i}\\}</span>  is similar, except that  <span class="math">S\\boxdot \\{x_i\\}</span>  is regarded as the initial multiset and  <span class="math">S</span>  the final one.6</p>

    <p class="text-gray-300">To instantiate this interactive protocol in constraints, we apply the Fiat-Shamir heuristic [55], i.e.,  <span class="math">\\mathcal{C}</span>  computes the challenge  <span class="math">\\ell</span>  by hashing all of the inputs to the protocol. Figure 1 illustrates the insertion proof's verification procedure. MultiSwap requires two proofs (one for insertion and one for removal); for this purpose, we hash all inputs to both proofs to derive a common challenge, as is standard [50].</p>

    <p class="text-gray-300">In the rest of this section we explain how to efficiently implement the blocks of Figure 1 in constraints. In particular, we explain how to implement  <span class="math">H_{p}</span> , the prime hash function used to compute  <span class="math">\\ell</span>  (§4.1) and  <span class="math">H_{\\Delta}</span> , the division-intractable hash function used to hash each element (§4.2). We also describe optimizations for multiprecision operations (§4.3). Finally, we discuss  <span class="math">\\mathcal{P}</span> 's cost for generating the witness input  <span class="math">Z</span>  to  <span class="math">\\mathcal{C}</span>  (§2.2), notably, the digests  <span class="math">S \\uplus \\{y_{i}\\}</span>  and  <span class="math">S \\boxminus \\{x_{i}\\}</span>  and the corresponding witnesses  <span class="math">Q</span>  for insertion and removal (§4.4).</p>

    <p class="text-gray-300">The hash function  <span class="math">H_{p}</span>  (Fig. 1) generates the challenge  <span class="math">\\ell</span>  used in the Wesolowski proofs of batch insertion and removal. These proofs are sound when  <span class="math">\\mathcal{P}</span>  has negligible probability of guessing the factors of  <span class="math">\\ell</span>  before evaluating  <span class="math">H_{p}</span>  [120]. In the non-interactive setting, one way to ensure this is by choosing  <span class="math">\\ell</span>  at random from the first  <span class="math">2^{2\\lambda}</span>  primes (Fn. 1, §2). In our context, however, a more efficient approach is for  <span class="math">H_{p}</span>  to output slightly larger primes that are guaranteed by construction to have  <span class="math">2\\lambda</span>  bits of entropy. Soundness is identical.</p>

    <p class="text-gray-300">In standard settings (i.e., outside of constraints), a typical approach ( <span class="math">\\S 8</span> ) for hashing to a random prime is rejection sampling. Here, the input is fed to a collision-resistant hash whose output seeds a pseudorandom generator (PRG), then the PRG's outputs are tested in sequence until a prime is found. Verifying correct execution requires, at the very least, testing primality of the purported output. This is typically done with a probabilistic primality test like Miller-Rabin [98]. Such tests, however, generally require many iterations for soundness, where each iteration involves an exponentiation modulo the prime being tested. This would be far too costly if implemented directly in constraints.</p>

    <p class="text-gray-300">Instead, we take advantage of advice from  <span class="math">\\mathcal{P}</span>  (§2.2). At a high level,  <span class="math">\\mathcal{P}</span>  helps to recursively construct a Pocklington certificate (§2) for  <span class="math">H_{p}</span> 's output, where each intermediate prime  <span class="math">p_i</span>  is the result of hashing  <span class="math">H_{p}</span> 's input. (This is related to prior approaches; see §8.) This strategy is economical when implemented in constraints, because it uses very little pseudorandomness and requires only one exponentiation modulo the resulting prime, plus a few smaller exponentiations.</p>

    <p class="text-gray-300">We now describe the recursive step used to construct  <span class="math">p_i</span>  from  <span class="math">p_{i-1}</span> . Further below, we describe the base case and give implementation details. Recall (§2) that a Pocklington witness for  <span class="math">p_i</span>  comprises  <span class="math">(p_{i-1}, r_i, a_i)</span>  such that  <span class="math">p_i = p_{i-1} \\cdot r_i + 1</span> . (If  <span class="math">p_i</span>  is prime, some  <span class="math">a_i</span>  must exist.) Notice that, given  <span class="math">p_{i-1}</span> , one can find  <span class="math">p_i</span>  by testing candidate  <span class="math">r_i</span>  values until  <span class="math">p_{i-1} \\cdot r_i + 1</span>  is prime. To implement this in constraints, we let  <span class="math">r_i = 2^{b_{n_i}} \\cdot h_i + n_i</span> , where  <span class="math">n_i</span>  is a  <span class="math">b_{n_i}</span> -bit number provided by  <span class="math">\\mathcal{P}</span>  as advice and  <span class="math">h_i</span>  is a  <span class="math">b_{h_i}</span> -bit pseudorandom number (we discuss its generation below).  <span class="math">\\mathcal{P}</span>  furnishes a corresponding  <span class="math">a_i</span>  and  <span class="math">C</span>  includes constraints that compute  <span class="math">p_i</span>  and  <span class="math">r_i</span> , and check the witness.</p>

    <p class="text-gray-300">The base case is  <span class="math">p_0 = 2^{b_{n_0}} \\cdot h_0 + n_0</span> , for  <span class="math">h_0</span>  a pseudorandom number and  <span class="math">n_0</span>  supplied by  <span class="math">\\mathcal{P}</span> . We fix  <span class="math">b_{n_0} + b_{h_0} = 32</span> , i.e.,  <span class="math">p_0 &amp;lt; 2^{32}</span> , and the constraints test primality of  <span class="math">p_0</span>  using a deterministic 3-round Miller-Rabin test that works for all values up to  <span class="math">2^{32}</span>  [73]. This test requires 3 exponentiations modulo  <span class="math">p_0</span>  with exponents less than 32 bits; these are inexpensive.</p>

    <p class="text-gray-300">We choose bit widths  <span class="math">b_{n_i}</span>  such that a valid  <span class="math">n_i</span>  exists with overwhelming probability, then choose  <span class="math">b_{h_i}</span>  subject to the constraint that  <span class="math">b_{h_i} + b_{n_i} &amp;lt; \\log p_{i-1}</span> , which ensures that  <span class="math">r_i &amp;lt; p_{i-1}</span>  as required (§2). The entropy of each  <span class="math">p_i</span>  is  <span class="math">\\sum_{j=0}^{i} b_{h_j}</span> ; four</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Iteration, i</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">0</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">1</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">2</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">3</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">4</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">max. pi bitwidth</td>

            <td class="px-3 py-2 border-b border-gray-700">32</td>

            <td class="px-3 py-2 border-b border-gray-700">63</td>

            <td class="px-3 py-2 border-b border-gray-700">124</td>

            <td class="px-3 py-2 border-b border-gray-700">245</td>

            <td class="px-3 py-2 border-b border-gray-700">322</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">bhi</td>

            <td class="px-3 py-2 border-b border-gray-700">21</td>

            <td class="px-3 py-2 border-b border-gray-700">20</td>

            <td class="px-3 py-2 border-b border-gray-700">49</td>

            <td class="px-3 py-2 border-b border-gray-700">108</td>

            <td class="px-3 py-2 border-b border-gray-700">63</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">bni</td>

            <td class="px-3 py-2 border-b border-gray-700">11</td>

            <td class="px-3 py-2 border-b border-gray-700">11</td>

            <td class="px-3 py-2 border-b border-gray-700">12</td>

            <td class="px-3 py-2 border-b border-gray-700">13</td>

            <td class="px-3 py-2 border-b border-gray-700">14</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Figure 2: Bitwidths for recursive primality proofs in our system. While the  <span class="math">b_{h_i}</span>  sum to 261, there are only 256 bits of entropy because each  <span class="math">h_i</span>  has its high bit fixed to 1 (§4.1).</p>

    <p class="text-gray-300">rounds suffice for 256 bits of entropy using the parameters listed in Figure 2.  <span class="math">\\mathcal{C}</span>  generates  <span class="math">h_i</span>  by hashing the input to  <span class="math">H_p</span>  with a hash function  <span class="math">H</span>  modeled as a random oracle.</p>

    <p class="text-gray-300">Each iteration yields a prime approximately twice as wide as the prior iteration's; meanwhile, the cost of each iteration is dominated by an exponentiation. This means that our approach has cost less than that of two exponentiations modulo the final prime. In contrast, using Miller-Rabin to check a 264-bit prime (which has roughly 256 bits of entropy) would require 80 exponentiations modulo that prime to give  <span class="math">\\approx 2^{-80}</span>  probability of outputting a composite (because Miller-Rabin is a probabilistic primality test). Our approach thus saves more than an order of magnitude and provably outputs a prime.</p>

    <p class="text-gray-300">One final optimization is to force the most significant bit of each  <span class="math">h_i</span>  to 1; this establishes a lower bound on each  <span class="math">p_i</span>  and on  <span class="math">\\ell</span>  (which is the final  <span class="math">p_i</span> ). As we discuss in Section 4.3, having this lower bound reduces the cost of modular reductions. The tradeoff is a small loss in entropy, namely, 1 bit per iteration. Even so, four rounds suffice to produce a 322-bit prime with 256 bits of entropy.</p>

    <p class="text-gray-300">Coron and Naccache show [48] that a hash function  <span class="math">H</span>  that outputs sufficiently large integers is division intractable when modeled as a random oracle. Informally, this is because in any randomly-selected set of large (say, 2000 bit) numbers, each element has a distinct, moderately sized (say, 200 bit) prime factor with high probability.</p>

    <p class="text-gray-300">Security of this hash function rests on the fact that the density of integers in the interval  <span class="math">[0, \\alpha)</span>  with factors all less than  <span class="math">\\mu</span>  approaches  <span class="math">\\beta^{-\\beta + o(1)}</span>  as  <span class="math">\\alpha \\to \\infty</span> , where  <span class="math">\\beta = \\frac{\\log \\alpha}{\\log \\mu}</span> . We conjecture that this density also holds for a large interval around  <span class="math">\\alpha</span> , namely,  <span class="math">[\\alpha, \\alpha + \\alpha^{1/8})</span> . (This is closely related to a conjecture on which the elliptic curve factorization method relies; there, the interval is  <span class="math">[\\alpha - \\sqrt{\\alpha}, \\alpha + \\sqrt{\\alpha}]</span>  [71].)</p>

    <p class="text-gray-300">Our hash function is defined as follows: let  <span class="math">\\Delta</span>  be a public 2048-bit integer chosen at random, and let  <span class="math">H</span>  be a hash function with codomain  <span class="math">[0,2^{256})</span>  with 128-bit collision resistance. Then  <span class="math">H_{\\Delta}(x) = H(x) + \\Delta</span> . Security of this construction follows from the analysis of [48] in the random oracle model,</p>

    <p class="text-gray-300">assuming the conjecture stated above. Concretely, we conjecture that an adversary making <span class="math">q</span> queries to <span class="math">H_{\\Delta}</span> has probability roughly <span class="math">q\\cdot 2^{-128}</span> of breaking division intractability.</p>

    <p class="text-gray-300"><span class="math">H_{\\Delta}</span>’s advantage over prior work is that its implementation in constraints is much smaller. The system parameter <span class="math">\\Delta</span> is baked into the constraints, and the only dynamic values to compute are the base hash <span class="math">H(x)</span> and the sum <span class="math">H(x)+\\Delta</span>; using known techniques <em>[79]</em>, this sum is inexpensive. Moreover, since all hashes must be reduced modulo the challenge <span class="math">\\ell</span> (Eq. (7)) and <span class="math">H_{\\Delta}(x)\\bmod\\ell=(H(x)+(\\Delta\\bmod\\ell))\\bmod\\ell</span>, the (costly) reduction <span class="math">\\Delta\\bmod\\ell</span> can be checked once in the constraints and the result can be re-used for each <span class="math">H_{\\Delta}(x)</span>. We note that while this approach gives smaller <span class="math">\\mathcal{C}</span> than hashing to primes (because <span class="math">H_{\\Delta}</span> and modular reductions are cheaper), it increases <span class="math">\\mathcal{P}</span>’s work (because <span class="math">H_{\\Delta}</span>’s bit length is longer; §4.4).</p>

    <h3 id="sec-25" class="text-xl font-semibold mt-8">4.3 Multiprecision arithmetic optimizations</h3>

    <p class="text-gray-300">We describe two optimizations for multiprecision arithmetic in constraints, building on ideas described in Section 2.2.</p>

    <h4 id="sec-26" class="text-lg font-semibold mt-6">Computing greatest common divisor.</h4>

    <p class="text-gray-300">We observe that addition and multiplication checks can be leveraged to verify a statement <span class="math">\\gcd(x,y)=d</span> by checking three equations over <span class="math">\\mathbb{Z}</span>:</p>

    <p class="text-gray-300"><span class="math">\\exists a,b</span> <span class="math">a\\cdot x+b\\cdot y=d</span> (8) <span class="math">\\exists x^{\\prime}</span> <span class="math">x^{\\prime}\\cdot d=x</span> <span class="math">\\exists y^{\\prime}</span> <span class="math">y^{\\prime}\\cdot d=y</span></p>

    <p class="text-gray-300">In constraints, the existential variables above correspond to advice provided by <span class="math">\\mathcal{P}</span>. Verifying coprimality (<span class="math">\\gcd(x,y)=1</span>) reduces to condition (8), i.e., materializing the multiplicative inverse of <span class="math">x</span> modulo <span class="math">y</span>. We use this simplification in Section 4.1 to verify a Pocklington witness (§2).</p>

    <h4 id="sec-27" class="text-lg font-semibold mt-6">Optimizing division and modular reduction.</h4>

    <p class="text-gray-300">Prior work implements division and modular reduction for a dividend <span class="math">x</span> and divisor <span class="math">d</span> by having the prover provide, as advice, the quotient <span class="math">q</span> and remainder <span class="math">r&lt;d</span> such that <span class="math">x=q\\cdot d+r</span>; this equality is then checked with multiprecision arithmetic (§2.2). For correctness, <span class="math">\\mathcal{C}</span> must enforce upper bounds on the bit widths of <span class="math">q</span> and <span class="math">r</span> via bit splitting (§2.2), which requires as many constraints as the sum of the bit widths of <span class="math">q</span> and <span class="math">r</span>.</p>

    <p class="text-gray-300">Since <span class="math">r</span> can range from <span class="math">0</span> to <span class="math">d-1</span>, its width is just that of <span class="math">d</span>. The width of <span class="math">q</span>, however, is slightly more subtle. Since <span class="math">q</span>’s value is <span class="math">\\lfloor s/d\\rfloor</span>, a conservative choice is to assume <span class="math">q</span> is as wide as <span class="math">x</span>. But this choice is imprecise: <span class="math">q</span> is only as wide as <span class="math">\\lceil\\log_{2}(\\lfloor s_{\\max}/d_{\\min}\\rfloor)\\rceil</span>, where <span class="math">x_{\\max}</span> denotes <span class="math">x</span>’s maximum possible value, and <span class="math">d_{\\min}</span> denotes <span class="math">d</span>’s minimum possible value. (Intuitively, this is because <span class="math">q</span> is small when <span class="math">d</span> is large.)</p>

    <p class="text-gray-300">As in prior work <em>[79]</em>, our system uses a dataflow analysis to track the maximum value of each number, in order to determine the required representation size. To bound <span class="math">q</span>’s width more tightly using the above expression, we augment this dataflow analysis to also track <em>minimum</em> values.</p>

    <h3 id="sec-28" class="text-xl font-semibold mt-8">4.4 Optimizing the cost of advice generation</h3>

    <p class="text-gray-300">The prior sections have treated <span class="math">\\mathcal{P}</span> as an advice oracle. We now discuss <span class="math">\\mathcal{P}</span>’s cost in computing this advice. Prior work <em>[116, 121]</em> shows that <span class="math">\\mathcal{P}</span>’s (single-threaded) cost per constraint is <span class="math">\\approx</span>100 <span class="math">\\mu s</span> or more (this includes, e.g., an elliptic curve point multiplication per constraint <em>[16, 64, 70, 96]</em>). Computing most advice values—including for multiprecision operations and prime hashing—is negligible by comparison. Possible exceptions are the witnesses for Wesolowski proofs (§2) used by batch insertion and removal operations (§2.1). (Recall that one of each operation is required for a MultiSwap; §3.)</p>

    <p class="text-gray-300">The witness for a batch insertion <span class="math">\\llbracket S\\uplus\\{y_{i}\\}\\rrbracket=\\llbracket S\\rrbracket^{\\prod_{i}H_{\\Delta}(y_{i})}</span> is the value <span class="math">\\llbracket S\\rrbracket^{\\lfloor(\\prod_{i}H_{\\Delta}(y_{i}))/\\ell\\rfloor}</span>. This exponent has length <span class="math">\\approx</span>2048<span class="math">\\cdot k</span> bits for <span class="math">k</span> elements inserted. In microbenchmarks, GMP <em>[66]</em> computes a 2048-bit exponentiation modulo a 2048-bit <span class="math">N</span> in <span class="math">\\approx</span>2.5 milliseconds (i.e., roughly <span class="math">25\\times</span> <span class="math">\\mathcal{P}</span>’s per-constraint proving cost), so computing this value costs roughly the same as <span class="math">25\\cdot k</span> constraints, which is inconsequential (§5, Fig. 3).</p>

    <p class="text-gray-300">Batch removal is much more expensive. To prove that removing the elements <span class="math">\\{x_{i}\\}</span> from the multiset <span class="math">S</span> yields a new multiset <span class="math">S^{\\prime}</span>, <span class="math">\\mathcal{P}</span> must prove that <span class="math">\\llbracket S\\rrbracket=\\llbracket S^{\\prime}\\rrbracket^{\\prod_{i}H_{\\Delta}(x_{i})}</span>, where</p>

    <p class="text-gray-300"><span class="math">\\llbracket S^{\\prime}\\rrbracket=\\llbracket S\\boxdot\\{x_{i}\\}\\rrbracket=g^{\\prod_{s\\in S\\boxdot\\{x_{i}\\}}H_{\\Delta}(s)}</span> (9)</p>

    <p class="text-gray-300">No known method for computing <span class="math">\\llbracket S^{\\prime}\\rrbracket</span> is faster than directly evaluating this expression because the order of <span class="math">\\mathbb{G}</span> is unknown (recall that this computation is in <span class="math">\\mathbb{G}=\\mathbb{Z}_{N}^{\\times}/\\{\\pm 1\\}</span> where <span class="math">N</span> has unknown factorization; §2). Meanwhile, this exponent has bit length <span class="math">\\approx</span>2048<span class="math">\\cdot M</span>, for <span class="math">M</span> the <em>total size</em> of the multiset <span class="math">S^{\\prime}</span>, i.e., it costs roughly the same as <span class="math">25\\cdot M</span> constraints. (As discussed in the prior paragraph, given <span class="math">\\llbracket S^{\\prime}\\rrbracket</span> it is inexpensive to compute the witness for batch removal, namely, <span class="math">\\llbracket S^{\\prime}\\rrbracket^{\\lfloor(\\prod_{i}H_{\\Delta}(x_{i}))/\\ell\\rfloor}</span>).</p>

    <p class="text-gray-300">Even for large accumulators, this cost may be reasonable: as we show in Section 7, MultiSwap can easily save tens of millions of constraints compared to Merkle trees. On the other hand, proof generation can be parallelized <em>[121]</em>, whereas at first glance the exponentiation in (9) appears to be strictly serial <em>[22, 101]</em>. We observe, however, that since <span class="math">g</span> is fixed, a pre-computation phase can be used to sidestep this issue <em>[33]</em>. Specifically, for some upper bound <span class="math">2^{m}</span> on the maximum size of the accumulator, the above exponent is at most <span class="math">2^{2048\\cdot 2^{m}}</span>, so pre-computing the values <span class="math">g_{i}=g^{2^{i\\cdot 2^{m}}}</span>, <span class="math">0\\leq i&lt;2048</span> (via successive squaring) turns the above exponentiation into a 2048-way multi-exponentiation <em>[91]</em> (which can be computed in parallel): for each <span class="math">g_{i}</span>, the exponent is a <span class="math">2^{m}</span>-bit chunk of the value <span class="math">\\prod_{s\\in S\\boxdot\\{x_{i}\\}}H_{\\Delta}(s)</span>. Further parallelism is possible simply by computing more <span class="math">g_{i}</span> with closer spacing.</p>

    <p class="text-gray-300">This precomputation also enables a time-space tradeoff, via windowed multi-exponentiation <em>[91, 110]</em>. In brief, when computing a multi-exponentiation over many bases, first split the bases into groups of size <span class="math">t</span> and compute for each group a table of size <span class="math">2^{t}</span>. This turns <span class="math">t</span> multiplications into a table lookup and one multiplication, for a factor of <span class="math">t</span> speedup. <span class="math">t=20</span> is rea</p>

    <p class="text-gray-300">sonable, and reduces the cost of computing the exponentiation in (9) to roughly the equivalent of <span class="math">1.25 \\cdot M</span> constraints.</p>

    <p class="text-gray-300">The above pre-computation is a serial process that requires <span class="math">\\approx 2048 \\cdot 2^{m}</span> squarings in <span class="math">\\mathbb{G}</span>. Assuming that 2048 squarings takes <span class="math">\\approx 2.5</span> milliseconds (i.e., the same amount of time as a general 2048-bit exponentiation; this is pessimistic), this precomputation takes <span class="math">\\approx 2^{m} \\cdot 2.5</span> milliseconds. For <span class="math">m = 20</span>, this is <span class="math">\\approx 45</span> minutes; for <span class="math">m = 25</span>, it is <span class="math">\\approx 1</span> day. Note, however, that this pre-computation is entirely untrusted, so it can be done once by anyone and reused indefinitely for the same <span class="math">g</span>.</p>

    <p class="text-gray-300">Finally, the above precomputation requires materializing <span class="math">\\prod_{s\\in \\mathbb{S}\\boxplus \\{s_j\\}}H_{\\Delta}(s)</span>, which is <span class="math">2^{31}</span> bits when <span class="math">M = 2^{20}</span>. This product can be expressed as a highly parallel computation; the final step is a multiplication of two, <span class="math">2^{30}</span>-bit values, which can itself be parallelized via a Karatsuba-like approach.</p>

    <p class="text-gray-300">We evaluate <span class="math">\\mathcal{P}</span>'s witness generation costs in Section 7.1.</p>

    <p class="text-gray-300">In this section we discuss two applications of MultiSwap and compare constraint costs for these applications when implemented using Merkle swaps and MultiSwaps.</p>

    <p class="text-gray-300">MultiSwap Costs. The first two rows of Figure 3 model the costs of Merkle swaps and swaps computed via MultiSwap.</p>

    <p class="text-gray-300">A Merkle swap requires hashing the old and new values and Merkle path verifications for each (§2.1), so the number of hash invocations is logarithmic in the number of leaves.</p>

    <p class="text-gray-300">For a MultiSwap, each swap requires a <span class="math">H_{\\Delta}</span> invocation (§4.2), which comprises an invocation of the underlying hash <span class="math">H</span> and multiprecision arithmetic to compute the result and multiply it mod <span class="math">\\ell</span> (§4, Fig. 1). In addition, each swap is an input to <span class="math">H_{p}</span>, which requires another hash invocation. All of these costs are independent of the number of elements in the accumulator. MultiSwap also costs a large constant overhead, however; this is to generate <span class="math">\\ell</span> (§4.1) and check two Wesolowski proofs via modular exponentiations (§2, §4).</p>

    <p class="text-gray-300">Blockchain systems [26] like Ethereum [53] enable smart contracts: computations defined by a blockchain's users and executed as part of the block validation procedure. One application of smart contracts is implementing a form of verifiable state update (§1): for global state <span class="math">\\Gamma</span> (stored on the blockchain) and a transaction <span class="math">\\gamma</span> (submitted by a user), the computation (1) checks that <span class="math">\\gamma</span> is valid according to some predicate, and if so (2) updates the global state to a new value <span class="math">\\Gamma&#x27;</span>.</p>

    <p class="text-gray-300">Consider, for example, a distributed payment system where <span class="math">\\Gamma</span> comprises a list of users and their public keys and balances. Transactions let users send payments to one another. When Alice wishes to send a payment, she constructs a transaction <span class="math">\\gamma</span> that includes (1) the target user; (2) the amount to send; and</p>

    <p class="text-gray-300">(3) a digital signature over the prior two items; she submits this to the smart contract, which verifies it and updates <span class="math">\\Gamma</span>.</p>

    <p class="text-gray-300">A major practical limitation of this approach is that computation, storage, and network traffic are extremely expensive for smart contracts.¹⁰ One solution to this issue, Rollup [7, 65, 94], is an instance of verifiable computation (§2.2): the smart contract delegates the work of checking transactions to an untrusted aggregator, and then checks a proof that this work was done correctly.¹¹ To effect this, users submit transactions <span class="math">\\gamma_{i}</span> to the aggregator rather than directly to the smart contract. The aggregator assembles these transactions into a batch <span class="math">\\{\\gamma_i\\}</span>, then generates a proof <span class="math">\\pi</span> certifying the correct execution of a computation <span class="math">\\Psi</span> that verifies the batch and updates the global state from <span class="math">\\Gamma</span> to <span class="math">\\Gamma&#x27;</span>. Finally, the aggregator submits <span class="math">\\pi</span> and <span class="math">\\Gamma&#x27;</span> to the smart contract, which verifies the proof and stores the updated state. Checking this proof is substantially cheaper for the smart contract than verifying each transaction individually, and the exorbitant cost of smart contract execution justifies the aggregator's cost in generating the proof [115].</p>

    <p class="text-gray-300">In more detail, the constraints <span class="math">\\mathcal{C}</span> corresponding to <span class="math">\\Psi</span> (§2.2) take the current state <span class="math">\\Gamma</span> as the input <span class="math">X</span> and the updated state <span class="math">\\Gamma&#x27;</span> as the output <span class="math">Y</span>. <span class="math">\\mathcal{P}</span> (i.e., the aggregator) supplies the batch <span class="math">\\{\\gamma_i\\}</span> as part of the witness (i.e., the advice vector <span class="math">Z</span>), meaning that the smart contract can verify the proof without reading <span class="math">\\{\\gamma_i\\}</span>. This saves both computation and network traffic.</p>

    <p class="text-gray-300">Notably, though, even reading <span class="math">\\Gamma</span> and <span class="math">\\Gamma&#x27;</span> is too expensive for the smart contract, as is storing <span class="math">\\Gamma</span> on the blockchain. (Recall that verifying a proof requires work proportional to the size of the inputs and outputs; §2.2.) The original Rollup design [7] addresses this by storing <span class="math">\\Gamma</span> in a Merkle tree (§2.1). The inputs and outputs of <span class="math">\\mathcal{C}</span> are just Merkle roots, and only this root is stored on the blockchain. Each leaf of this tree contains a tuple <span class="math">(pk, \\text{bal}, \\#tx)</span> comprising a user's public key, their balance, and a transaction count (which prevents replaying past transactions). The constraints that verify a transaction in <span class="math">\\mathcal{C}</span> thus require two Merkle tree updates, one each for payer and payee. (Each update comprises two Merkle paths; §2.1).</p>

    <p class="text-gray-300">We observe that a single MultiSwap (§3) can replace all of the Merkle tree updates for a batch of transactions. In particular, MultiSwap's semantics guarantee sequential consistency of the transactions with respect to <span class="math">\\Gamma</span> and <span class="math">\\Gamma&#x27;</span>. And whereas the per-swap cost of Merkle swaps increase logarithmically with the number of accounts stored in <span class="math">\\Gamma</span>, the per-swap cost of MultiSwap is essentially independent of the number of users. This means that for large batches of transactions and/or large numbers of users, a MultiSwap-based Rollup requires far fewer constraints than a Merkle-based one.</p>

    <p class="text-gray-300">Costs. The middle two rows of Figure 3 show costs for Rollup using Merkle and MultiSwap. Both cases pay to ver</p>

    <p class="text-gray-300">¹⁰ Anecdotally, recent Ethereum prices [54] result in storage costs of more than <span class="math">1 per kilobyte. Similarly, per-transaction costs are frequently in the </span>0.25 to $1 range even when executing minimal computation.</p>

    <p class="text-gray-300">¹¹ Rollup is distinct from Optimistic Rollup [58], which does not use cryptographic proofs and is not discussed in this paper.</p>

    <p class="text-gray-300">Number of constraints</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">System</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Per-Operation Costs</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Per-Proof Costs</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Merkle swap</td>

            <td class="px-3 py-2 border-b border-gray-700">2(che + m·ch)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">MultiSwap (§3, §4)</td>

            <td class="px-3 py-2 border-b border-gray-700">2(che + chm + csplit + c+ℓ(f) + c×ℓ)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">4ceG(</td>

            <td class="px-3 py-2 border-b border-gray-700">ℓ</td>

            <td class="px-3 py-2 border-b border-gray-700">) + 2c×G + chp + cmodℓ(bHλ)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Payments (Merkle swap)</td>

            <td class="px-3 py-2 border-b border-gray-700">Merkle swap ×2 + csig + ctx</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Payments (MultiSwap)</td>

            <td class="px-3 py-2 border-b border-gray-700">MultiSwap ×2 + csig + ctx</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">MultiSwap</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">RAM (Merkle-based [32])</td>

            <td class="px-3 py-2 border-b border-gray-700">(1 + w)(che + m·ch)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">RAM (MultiSwap)</td>

            <td class="px-3 py-2 border-b border-gray-700">MultiSwap + cmem-check</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">MultiSwap</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">λ</td>

            <td class="px-3 py-2 border-b border-gray-700">security parameter (128)</td>

            <td class="px-3 py-2 border-b border-gray-700">f</td>

            <td class="px-3 py-2 border-b border-gray-700">field width (log2</td>

            <td class="px-3 py-2 border-b border-gray-700">F</td>

            <td class="px-3 py-2 border-b border-gray-700">) (255)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">bHλ</td>

            <td class="px-3 py-2 border-b border-gray-700">bits in division-intractable hash output (2048)</td>

            <td class="px-3 py-2 border-b border-gray-700">bG</td>

            <td class="px-3 py-2 border-b border-gray-700">group element bits (log2</td>

            <td class="px-3 py-2 border-b border-gray-700">G</td>

            <td class="px-3 py-2 border-b border-gray-700">) (2048)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">ch*</td>

            <td class="px-3 py-2 border-b border-gray-700">cost of multiset item hash to F (varies)</td>

            <td class="px-3 py-2 border-b border-gray-700">ch</td>

            <td class="px-3 py-2 border-b border-gray-700">cost of F2 → F hash (varies)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">chp</td>

            <td class="px-3 py-2 border-b border-gray-700">cost of prime generation (217703)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">ℓ</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">prime challenge bits (352)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">csplit</td>

            <td class="px-3 py-2 border-b border-gray-700">cost of strict bitsplit in F (388)</td>

            <td class="px-3 py-2 border-b border-gray-700">c×G</td>

            <td class="px-3 py-2 border-b border-gray-700">operation cost in G (7563)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">csig</td>

            <td class="px-3 py-2 border-b border-gray-700">cost of signature check (12000)</td>

            <td class="px-3 py-2 border-b border-gray-700">w</td>

            <td class="px-3 py-2 border-b border-gray-700">write fraction (RAM) (varies)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">ctx</td>

            <td class="px-3 py-2 border-b border-gray-700">cost of tx validity check (255)</td>

            <td class="px-3 py-2 border-b border-gray-700">c×ℓ</td>

            <td class="px-3 py-2 border-b border-gray-700">cost of multiplication, mod ℓ (479)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">m</td>

            <td class="px-3 py-2 border-b border-gray-700">log2 of accumulator capacity (varies)</td>

            <td class="px-3 py-2 border-b border-gray-700">chm</td>

            <td class="px-3 py-2 border-b border-gray-700">per-operation cost of full-input hash (varies)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">cmem-check</td>

            <td class="px-3 py-2 border-b border-gray-700">cost of memory checks, 21 + log2k + 2·m for k operations [116, Fig. 5; 79, Appx. B.A] (< 125)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">c+ℓ(b)</td>

            <td class="px-3 py-2 border-b border-gray-700">cost of addition with two inputs of maximum width b, mod ℓ (16 + b)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">cmodℓ(b)</td>

            <td class="px-3 py-2 border-b border-gray-700">cost of reduction mod ℓ, with a b-bit input (16 + b)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">ceG(b)</td>

            <td class="px-3 py-2 border-b border-gray-700">cost of exponentiation with a b-bit exponent, in G (7044b)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Figure 3: Constraint count models for Merkle swaps (§2.1), MultiSwap (§3, §4), Payments (§5.1), and Persistent RAM (§5.2). The approximate value of each parameter in our implementation (§6, §7) is given in parentheses. See Section 5 for discussion.</p>

    <p class="text-gray-300">ify the payer's signature and ensure that the payer's balance is sufficient. The difference is in the swap costs, which are discussed above (§5); Rollup requires two swaps per transaction, one each to update the payer's and payee's accounts.</p>

    <p class="text-gray-300">Recall from Section 2.2 that Pantry-style RAM, while expensive, offers unique functionality: the ability to pass the full state of RAM from one proof to another. This enables computations over persistent state [32], recursively verifiable state machine execution [15, 89], and other useful applications.</p>

    <p class="text-gray-300">Unfortunately, the high cost (in constraints) of hash functions ( <span class="math">\\S 6</span> ) limits the number of Pantry-style RAM operations that can be used in a computation—especially for large RAMs [32, 79, 116]. In this section, we show how to use the batched RSA accumulator construction of Section 4 to address this issue. Our design yields a persistent RAM abstraction whose per-access constraint cost is lower than Pantry's even at modest RAM sizes, and is nearly insensitive to RAM size.</p>

    <p class="text-gray-300">To begin, notice that Pantry's RAM abstraction essentially stores memory values in a fixed-size Merkle tree, executing a membership proof for each LOAD and a swap for each STORE. Moreover, since our goal is efficiency, our design will ideally check all memory operations using a small number of batched accumulator operations (§4).</p>

    <p class="text-gray-300">This seems to suggest the following (incorrect) approach.</p>

    <p class="text-gray-300">First, replace the Merkle tree with an RSA accumulator, representing memory locations as  <span class="math">\\langle</span>  addr, data  <span class="math">\\rangle</span>  tuples. Then, verify all LOAD and STORE operations in a batch using MultiSwap (§3) as follows. For each LOAD from address  <span class="math">\\delta</span> ,  <span class="math">\\mathcal{P}</span>  supplies as advice the value  <span class="math">\\nu</span>  purportedly stored at  <span class="math">\\delta</span> , and the constraints encode a swap that replaces the tuple  <span class="math">\\langle \\delta, \\nu \\rangle</span>  with itself. For each STORE of the value  <span class="math">\\nu&#x27;</span>  to address  <span class="math">\\delta</span> ,  <span class="math">\\mathcal{P}</span>  supplies as advice the value  <span class="math">\\nu</span>  purportedly being overwritten, and the constraints encode the swap  <span class="math">(\\langle \\delta, \\nu \\rangle, \\langle \\delta, \\nu&#x27; \\rangle)</span> .</p>

    <p class="text-gray-300">The reason this approach is incorrect is that it does not enforce the consistency of LOAD operations with program execution. In particular, recall (§3) that MultiSwap  <span class="math">(S, \\sigma, S&#x27;)</span>  only guarantees that  <span class="math">S&#x27;</span>  is produced by a sequentially-consistent cycle-free subsequence  <span class="math">\\sigma&#x27; \\subseteq \\sigma</span> . Since LOAD operations are self-cycles, they are not included in  <span class="math">\\sigma&#x27;</span> . This use of MultiSwap thus only guarantees that  <span class="math">\\sigma</span>  correctly encodes STORE operations—LOADs can return any value.</p>

    <p class="text-gray-300">We might attempt to fix this issue by checking LOAD operations using membership proofs. But this is inefficient: checking such a proof requires the constraints to materialize an accumulator that contains the value being loaded; meanwhile, the LOAD might correspond to a prior STORE, in which case the accumulator against which the proof must be checked would first have to be computed. In other words, this strategy makes batching accumulator operations impossible.</p>

    <p class="text-gray-300">Our key insight is that a hybrid of the Pantry and BCGT approaches solves this issue. At a high level, our design enforces</p>

    <p class="text-gray-300">the correctness of LOAD and STORE operations using an address-ordered transcript (§2.2) while ensuring that this transcript is consistent with the initial and final state of RAM using batched accumulator operations. As above, each memory location is stored in the accumulator as an  <span class="math">\\langle \\mathrm{addr},\\mathrm{data}\\rangle</span>  tuple. As in BCGT-style RAM, the constraints build an execution-ordered transcript,  <span class="math">\\mathcal{P}</span>  supplies an address-ordered transcript  <span class="math">\\mathcal{T}</span> , and the constraints ensure that  <span class="math">\\mathcal{T}</span>  is correctly ordered, coherent, and a permutation of the execution-ordered transcript.</p>

    <p class="text-gray-300">For the initial state of RAM, the constraints enforce consistency by ensuring that the first time an address  <span class="math">\\delta</span>  is accessed in  <span class="math">\\mathcal{T}</span> , the tuple  <span class="math">\\langle \\delta, \\nu \\rangle</span>  is removed from the accumulator. If the first access is a LOAD,  <span class="math">\\nu</span>  is the corresponding DATA value from  <span class="math">\\mathcal{T}</span> . Otherwise,  <span class="math">\\mathcal{P}</span>  supplies as advice a claimed  <span class="math">\\nu</span>  value such that  <span class="math">\\langle \\delta, \\nu \\rangle</span>  is in the accumulator. (For now, we assume that memory location  <span class="math">\\delta</span>  has some corresponding tuple in the accumulator; we discuss uninitialized memory below.) Observe that this ensures consistency, because a removal is only possible if  <span class="math">\\langle \\delta, \\nu \\rangle</span>  is indeed in the accumulator.</p>

    <p class="text-gray-300">For the final state of RAM, the constraints enforce consistency by ensuring that the last time an address  <span class="math">\\delta</span>  is accessed in  <span class="math">\\mathcal{T}</span> , the tuple  <span class="math">\\langle \\delta, \\nu&#x27; \\rangle</span>  is inserted into the accumulator. The value  <span class="math">\\nu&#x27;</span>  is the corresponding DATA value from  <span class="math">\\mathcal{T}</span> . Together with the above, this ensures that all of the accesses to address  <span class="math">\\delta</span>  collectively result in the swap  <span class="math">(\\langle \\delta, \\nu \\rangle, \\langle \\delta, \\nu&#x27; \\rangle)</span> .</p>

    <p class="text-gray-300">Constraints for the above checks work as follows. First, for entry  <span class="math">i</span>  in  <span class="math">\\mathcal{T}</span> , the constraints compute  <span class="math">h_{i,\\mathrm{del}} = H_{\\Delta}(\\langle \\mathrm{ADDR}_i,\\nu \\rangle)</span>  and  <span class="math">h_{i,\\mathrm{ins}} = H_{\\Delta}(\\langle \\mathrm{ADDR}_i,\\nu &#x27;\\rangle)</span>  (§4.2). Then, for each sequential pair of entries  <span class="math">i</span> ,  <span class="math">i + 1</span>  in  <span class="math">\\mathcal{T}</span> , if  <span class="math">\\mathrm{ADDR}_i\\neq \\mathrm{ADDR}_{i + 1}</span> , then entry  <span class="math">i</span>  must be the last access to  <span class="math">\\mathrm{ADDR}_i</span>  and entry  <span class="math">i + 1</span>  must be the first access to  <span class="math">\\mathrm{ADDR}_{i + 1}</span> . Finally, the constraints compute  <span class="math">\\prod_{i\\in \\mathcal{F}}h_{i,\\mathrm{del}}</span>  mod  <span class="math">\\ell</span>  and  <span class="math">\\prod_{i\\in \\mathcal{L}}h_{i,\\mathrm{ins}}</span>  mod  <span class="math">\\ell</span>  (§4), the values inserted into and removed from the accumulator, respectively, for  <span class="math">\\mathcal{F}</span>  the first-accessor set and  <span class="math">\\mathcal{L}</span>  the last-accessor set.</p>

    <p class="text-gray-300">Handling uninitialized memory. A remaining issue is how to handle the case where memory is uninitialized. Recall that in the BCGT approach, a LOAD not preceded by a STORE to the same address is serviced with a default value, say, 0. That does not work here, because this approach relies crucially on swapping old values for new ones, to ensure consistency with both the initial and final accumulators.</p>

    <p class="text-gray-300">A straightforward solution is to ensure that every memory location is initialized, by executing a setup phase that constructs an accumulator containing the tuple  <span class="math">\\langle \\delta, 0 \\rangle</span>  for every address  <span class="math">\\delta</span> . The cost of constructing this accumulator is high when the address space is large, since it amounts to one exponentiation per entry in RAM. Note, however, that this computation can be parallelized using the pre-computed values described in Section 4.4, and admits the same time-space tradeoff described in that section.[12]</p>

    <p class="text-gray-300">Costs. The constraint costs of memory accesses are shown in the bottom two rows of Figure 3. The Merkle-based RAM requires two proofs of membership for each STORE, but only one for each LOAD [32], so it is slightly cheaper than a Merkle swap—but logarithmic in RAM size.</p>

    <p class="text-gray-300">The RSA accumulator-based RAM uses one MultiSwap for all LOADs and STOREs, with attendant per-operation costs (which are independent of RAM size; §5). It also incurs extra per-operation costs to check  <span class="math">\\mathcal{T}</span>  as described above; these are logarithmic in the number of accesses but concretely very inexpensive (§2.2, [116, Fig. 5; 79, Appx. B-A]).</p>

    <p class="text-gray-300">We implement a library comprising multiprecision arithmetic, Pocklington prime certification, RSA accumulators, and Merkle trees. This library extends Bellman [9], a library for building constraint systems and generating proofs using the pairing-based argument due to Groth [70]. Based on this library, we implement two end-to-end applications: one that verifies a sequence of swaps, and one that verifies a batch of transactions for a distributed payment system (§5.1).</p>

    <p class="text-gray-300">We also implement or adapt four hash functions: MiMC [1], which costs 731 constraints (91 rounds of the  <span class="math">x^2</span>  permutation); Poseidon [69], which costs 316 constraints; Pedersen [72, 97], which costs 2753 constraints (based on the JubJub elliptic curve [28]), and SHA-256 [57], which costs 45567 constraints. We adapt the latter three hashes from Sapling [104].</p>

    <p class="text-gray-300">Finally, we implement custom Bellman constraint synthesizers (ConstraintSystems, in the jargon of Bellman) that allow us to quickly measure a constraint system's size and  <span class="math">\\mathcal{P}</span> 's cost computing a corresponding witness.</p>

    <p class="text-gray-300">We use a 2048-bit RSA quotient group (§2) modulo the RSA-2048 challenge number [76, 102], and choose a random 2048-bit  <span class="math">\\Delta</span>  to define the division-intractable hash function  <span class="math">H_{\\Delta}</span>  (§4.2); we give concrete values in Appendix B. We synthesize all constraints over the BLS12-381 [27] curve.</p>

    <p class="text-gray-300">In total, our implementation comprises  <span class="math">\\approx 11,300</span>  lines of Rust. We have released it under an open-source license [10].</p>

    <p class="text-gray-300">We evaluate our MultiSwap implementation, comparing it to Merkle trees by answering the following questions:</p>

    <p class="text-gray-300">(1) How does the cost of a MultiSwap compare to the cost of Merkle swaps for a batch of swaps? In particular, what is the break-even point (i.e., the number of operations beyond which MultiSwap is cheaper), and how do costs compare for a fixed (large) constraint budget? (2) What is the effect of hash function cost on the tradeoff between RSA accumulators and Merkle trees?</p>

    <p class="text-gray-300">We answer the first question by synthesizing constraint systems for both MultiSwap and Merkle swaps, at varying set and batch sizes (§7.1). We also synthesize constraints for the Rollup application (§7.2) and compare the persistent RAM application using a cost model (§7.3). Our cost metric is number of constraints; to validate this metric, we measure end-to-end times for MultiSwap and Merkle swaps (§7.1).</p>

    <p class="text-gray-300">For the second question, we evaluate the break-even point for MultiSwap versus the cost of the underlying hash function, for four different hash functions (§7.1).</p>

    <p class="text-gray-300">In sum, we find that MultiSwap breaks even for batch sizes of at most several thousand operations; for large sets, this value is several hundred. We also find that MultiSwap's advantage is greater when hashing is more expensive.</p>

    <p class="text-gray-300">Baseline. Our baselines are constraint systems (§2.2) that use Merkle trees (§2.1) to store state. For each baseline, we fix capacity to be  <span class="math">M = 2^{m}</span> , for a range of  <span class="math">m</span>  values. In all experiments except persistent RAM, the basic Merkle tree operation is a swap (§5, Fig. 3). Merkle-based RAMs use a mix of membership proofs and swaps (§2.1, §2.2); we discuss further in Section 7.3.</p>

    <p class="text-gray-300">Setup. Except in the hash cost experiment (§7.1), both Merkle and MultiSwap fix the hash function  <span class="math">H</span>  (§4.1, §4.2) as our Poseidon [69] implementation (§6). As we show in Section 7.1, this is the most favorable choice for the Merkle baseline, because Poseidon is inexpensive in constraints.</p>

    <p class="text-gray-300">For execution time (§7.1), our testbed has two Intel Xeon E5-2687Wv4 CPUs (12 physical cores per socket, 48 threads total) and 128 GiB of RAM, and runs Ubuntu 18.04. We compile with Rust 1.41-nightly (c9290dcee 2020-02-04) [103].</p>

    <p class="text-gray-300">Method. Our primary cost metric is number of constraints, which we measure with a custom Bellman synthesizer (§6). We use this metric because  <span class="math">\\mathcal{P}</span> 's costs (both time and space) are dominated by constraint count in the back-ends we target (§2.2).  <span class="math">\\mathcal{V}</span> 's costs are small and essentially constant.</p>

    <p class="text-gray-300">To validate this metric, in Section 7.1 we measure  <span class="math">\\mathcal{P}</span> 's and  <span class="math">\\mathcal{V}</span> 's time for MultiSwap and Merkle swaps, for  <span class="math">2^{20}</span> -element sets. Limitations of the underlying Bellman and Sapling libraries (§6) cause our MultiSwap and Merkle implementations to unnecessarily resynthesize all constraints when generating proofs. To sidestep this, for each experiment we measure total proving time (synthesis, witness computation, and proof generation), separately measure just synthesis time, and report the difference. Fixing this issue (by rewriting Bellman/Sapling) is future work.</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Figure 4: Constraint count v. number of swaps (§7.1). "Merkle  <span class="math">m</span> " denotes a Merkle tree with  <span class="math">2^{m}</span>  leaves.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Accumulator</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Swaps</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Merkle 5</td>

            <td class="px-3 py-2 border-b border-gray-700">263 713</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Merkle 10</td>

            <td class="px-3 py-2 border-b border-gray-700">143 843</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Merkle 15</td>

            <td class="px-3 py-2 border-b border-gray-700">98 892</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Merkle 20</td>

            <td class="px-3 py-2 border-b border-gray-700">75 346</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">RSA</td>

            <td class="px-3 py-2 border-b border-gray-700">250 201</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">(a) Swaps (§7.1).</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Accumulator</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Transactions</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Merkle 5</td>

            <td class="px-3 py-2 border-b border-gray-700">48 463</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Merkle 10</td>

            <td class="px-3 py-2 border-b border-gray-700">37 100</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Merkle 15</td>

            <td class="px-3 py-2 border-b border-gray-700">30 053</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Merkle 20</td>

            <td class="px-3 py-2 border-b border-gray-700">25 256</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">RSA</td>

            <td class="px-3 py-2 border-b border-gray-700">47 203</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">(b) Payments (§7.2).</p>

    <p class="text-gray-300">Figure 5: Number of operations verifiable in  <span class="math">10^{9}</span>  constraints (higher is better).</p>

    <p class="text-gray-300">Benchmark. This experiment compares the costs of MultiSwap and Merkle trees for a computation comprising only swaps, varying the number of swaps and set size.</p>

    <p class="text-gray-300">Constraint costs. Figure 4 shows the results. The cost of Merkle trees varies with set size, because the number of hash invocations depends on this value (§2.1; §5, Fig. 3). In contrast, the constraint cost of MultiSwap is independent of the number of elements in the set; for moderately sized sets ( <span class="math">\\approx 2^{10}</span>  elements), the per-swap cost is less than for Merkle trees.</p>

    <p class="text-gray-300">On the other hand, MultiSwap pays a large overhead ( <span class="math">\\approx 11</span>  million constraints) to evaluate  <span class="math">H_{p}</span>  and verify two Wesolowski proofs (§4; §5, Fig. 3). Thus, MultiSwap requires some minimum batch size before it breaks even. For small sets (say,  <span class="math">2^{5}</span>  elements) there is no break-even point; for sets with  <span class="math">2^{10}</span>  or more elements, the break-even point is at most a few thousand swaps, and decreases with set size.</p>

    <p class="text-gray-300">Figure 5a shows the number of swaps that fit in  <span class="math">10^{9}</span>  constraints, for different accumulators. (We compare at this size because it is close to the largest that prior work can handle [121].) Depending on set size, MultiSwap improves reachable batch sizes by up to  <span class="math">\\approx 3.3\\times</span></p>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a> Figure 6: Witness computation plus proof generation time v. number of swaps, for accumulators with  <span class="math">2^{20}</span>  elements (§7.1).</p>

    <p class="text-gray-300">!<a href="img-3.jpeg">img-3.jpeg</a> Figure 7: Constraint count v. number of swaps, varying hash function (§7.1). Merkle trees are all of depth 20.</p>

    <p class="text-gray-300">Proving and verifying time. Figure 6 shows proving times (witness computation plus proof generation) for MultiSwap and Merkle with sets having  <span class="math">2^{20}</span>  elements, for varying batch sizes. Verification costs  <span class="math">\\approx 7</span>  ms in all cases. MultiSwap has longer proving times for small batches but shorter times for large batches, and the break-even point between 1200 and 1600 swaps. This is slightly larger than in Figure 4 because of the added cost of computing the new accumulator digest ( <span class="math">\\S 4.4</span> ).</p>

    <p class="text-gray-300">For an accumulator with  <span class="math">2^{20}</span>  elements, computing a new digest after batch removal takes  <span class="math">\\approx 43</span>  seconds and uses  <span class="math">\\approx 4</span>  GiB of RAM via the preprocessing approach described in Section 4.4. For smaller accumulators this cost is correspondingly smaller. Larger accumulators have slower witness generation, which affects break-even batch size; we discuss in Section 9.</p>

    <p class="text-gray-300">Effect of hash cost. Figure 7 shows the effect of hash cost on MultiSwap's break-even point for sets of  <span class="math">2^{20}</span>  elements</p>

    <p class="text-gray-300">!<a href="img-4.jpeg">img-4.jpeg</a> Figure 8: Constraint count v. number of transactions (§7.2). "Merkle  <span class="math">m</span> " denotes a Merkle tree with  <span class="math">2^{m}</span>  leaves.</p>

    <p class="text-gray-300">(other set sizes are analogous; note that the axes are logarithmic). We measure MiMC, Poseidon, Pedersen/Jobjub, <span class="math">^{14}</span>  and SHA-256 (§6). As expected, in all cases Merkle trees are cheaper for small numbers of operations. For the least expensive hash (Poseidon), MultiSwap's break-even point is the highest; as hash cost increases, so does MultiSwap's advantage. (We report results in all other experiments with Poseidon, which is the worst case for MultiSwap.)</p>

    <p class="text-gray-300">Benchmark. This experiment compares the costs of MultiSwap and Merkle trees for the Rollup application described in Section 5.1. We measure cost versus the number of transactions (a signature verification, a validity check, and two swaps). Signatures use the scheme from ZCash [72].</p>

    <p class="text-gray-300">Results. Figure 8 shows the results. In contrast with the previous experiment, here all accumulator types pay a fixed overhead per transaction (this is dominated by signature verification), which reduces MultiSwap's per-transaction advantage. In this application, set size corresponds to the number of accounts. As in Section 7.1, MultiSwap does not break even for the smallest set size. The break-even point for  <span class="math">2^{10}</span>  accounts is  <span class="math">\\approx 2000</span>  transactions, and  <span class="math">\\approx 600</span>  for  <span class="math">2^{20}</span>  accounts.</p>

    <p class="text-gray-300">Figure 5b shows the number of transactions that fit in  <span class="math">10^{9}</span>  constraints, for different accumulators. MultiSwap's advantage is as large as  <span class="math">\\approx 1.9\\times</span> , depending on set size.</p>

    <p class="text-gray-300">!<a href="img-5.jpeg">img-5.jpeg</a> Figure 9: Constraint count v. number of accesses (§7.3). "Merkle  <span class="math">m</span> " denotes a Merkle tree with  <span class="math">2^{m}</span>  leaves. Ribbons indicate variation according to write load, from 0 to  <span class="math">100\\%</span> .</p>

    <p class="text-gray-300">Benchmark. This experiment compares the costs of MultiSwap-based and Pantry's [32] Merkle-based persistent RAM 5.2. We compare using the cost model of Figure 3 (§5), which is derived from prior work [79, 116]; future work is to port Buffet's RAM compiler to Bellman and synthesize. We report cost versus RAM size.</p>

    <p class="text-gray-300">Results. Figure 9 shows the results. For Merkle-based RAM, bands in the figure represent varying write loads, from 0 (lowest cost) to  <span class="math">100\\%</span>  (highest cost). As in prior experiments, MultiSwap's cheaper per-operation cost yields a break-even point of several thousand operations for a large RAM. This model includes the cost of memory consistency checks ( <span class="math">\\S 2.2</span> ,  <span class="math">\\S 5.2</span> , Fig. 3); these cost fewer than 100 constraints per operation and are thus negligible.</p>

    <p class="text-gray-300">Verifiable computation. The literature on verifiable computation is both broad and deep; a somewhat recent survey [119] gives a thorough treatment of the area's beginnings.</p>

    <p class="text-gray-300">Our work builds most directly on xJsnark's [79] multiprecision arithmetic and on the RAM primitives first described by Ben-Sasson et al. [12] and further refined by Ben-Sasson et al. [13, 16], in Buffet [116], and in xJsnark. Buffet and xJsnark both extend lines of work concerned with efficiently compiling high-level programs to constraints, including Pepper [107], Ginger [108], Pinocchio [96], and Pantry [32].</p>

    <p class="text-gray-300">Several other works in this area deal with persistent state. Pantry [32] was the first to use Merkle trees for stateful computations, and its persistent RAM primitive inspired ours (§5.2). vSQL [123] builds a verifiable subset of SQL, building on</p>

    <p class="text-gray-300">the interactive proofs of Goldwasser et al. [67], Cormode et al. [47], and Thaler [111], and on the polynomial commitments of Papamanthou et al. [95], which build on the work of Kate et al. [77]. In contrast to the persistent RAM and multiset abstractions we develop, vSQL exposes a database abstraction; queries operate on all rows in parallel.</p>

    <p class="text-gray-300">ADSNARK [4] extends the Pinocchio [96] SNARK to support operations on authenticated data provided by a third party. Geppetto [49] also extends Pinocchio, allowing the verifier to commit to inputs for a specific computation and later verify a proof against that commitment, and also enabling data transfer between separate constraint systems bundled into one proof. Fiore et al. [56] take Geppetto's commitments to inputs a step further, making them computation independent. In contrast to a multiset or persistent RAM abstraction, however, all of these systems require a number of constraints sufficient to read every input value—in other words, a multiset of size  <span class="math">M</span>  implies at least  <span class="math">M</span>  constraints. Further, they do not efficiently support programs whose multiset or RAM accesses depend on inputs and thus cannot be statically analyzed (§2.2).</p>

    <p class="text-gray-300">Spice [105] aims to enable zero-knowledge auditing of concurrent services. Spice's amortized cost per state operation is  <span class="math">\\approx 2\\times</span>  lower than ours for large batches, but its approach differs from ours in two key ways. First, Spice's core state verification primitive requires a number of constraints linear in the total size of the state; this cost is amortized over a batch of requests, each containing one or more state operations. In contrast, MultiSwap operations (§3) have constraint costs that depend only on the number of state updates, not on total state size. Second, verification costs in Spice scale with the number of requests in a batch; in our work, verification cost is independent of batch size. Piperine [80] optimizes Spice's state verification primitive and saves verification work by combining all requests from a batch into one proof; this yields verification cost independent of batch size.</p>

    <p class="text-gray-300">Accumulators. Cryptographic accumulators [17] based on RSA have a long history [5, 40, 81, 84]. The recent work of Boneh et al. [24] builds upon work by Wesolowski [120] to construct batched membership and non-membership proofs for these accumulators. Our work builds directly on this line.</p>

    <p class="text-gray-300">Merkle-based accumulators have also seen extensive study [38, 90], and related structures have seen applications, e.g., in the blockchain [99] and PKI contexts [100]. These works all rely crucially on collision-resistant hashing, which is expensive when expressed as constraints (§6, §7).</p>

    <p class="text-gray-300">Two other lines of work build accumulators [39, 42, 51, 93] and vector commitments [41, 82, 83] from bilinear maps. Elliptic curve operations and pairings appear to be very expensive when compiled to constraints [15], but these lines may nevertheless be an interesting direction for further study.</p>

    <p class="text-gray-300">Prime generation. A long line of work [30, 31, 68, 74, 75] aims to efficiently generate pseudorandom prime numbers. In some cases, uniformly distributed primes [59] are desirable.</p>

    <p class="text-gray-300">All of these proceed in “guess-and-check” fashion, which is inefficient when implemented in constraints (see §4.1). Most closely, Maurer <em>[87, 88]</em> and Shawe-Taylor <em>[109]</em> describe prime generation methods based on Pocklington certificates; Clavier et al. <em>[46]</em> optimize for embedded devices. To our knowledge, no prior work tackles this problem in our context.</p>

    <h2 id="sec-38" class="text-2xl font-bold">9 Discussion and conclusion</h2>

    <p class="text-gray-300">We have shown that in verifiable state applications with moderate to large state, accessed thousands of times, RSA accumulators are less costly than Merkle trees.</p>

    <p class="text-gray-300">There are two caveats: first, RSA accumulators require a trusted setup. In practice, most SNARKs <em>[15, 64, 70, 96]</em> also require a trusted setup, so this is not a significant burden. Moreover, it is possible to mitigate trust requirements by generating an RSA modulus using a multiparty computation <em>[25, 60]</em>. A conjectured alternative that avoids trusted setup is a class group of imaginary quadratic order <em>[24, 35]</em>; exploring efficient constraint implementations is future work.</p>

    <p class="text-gray-300">Second, for very large sets (say, <span class="math">&gt;2^{25}</span>) <span class="math">\\mathcal{P}</span>’s cost (in time) for advice generation is high (§4.4). For small batch sizes, this cost overwhelms the time saved because of reduced constraint count. Note, however, that there will be <em>some</em> batch size at which RSA breaks even, since per-swap cost is smaller than Merkle for <span class="math">\\stackrel{{\\scriptstyle\\raisebox{-0.60275pt}{</span>\\textstyle<<span class="math">}}}{{\\sim}}</span> <span class="math">2^{10}</span> elements. Moreover, reducing the number of constraints also reduces <span class="math">\\mathcal{P}</span>’s RAM requirements; meanwhile, <span class="math">\\mathcal{P}</span>’s advice generation task requires little memory. This means that <em>even if</em> an RSA accumulator requires greater total proving <em>time</em> than a Merkle tree, the RSA accumulator’s use may still be justified because it reduces the amount of RAM <span class="math">\\mathcal{P}</span> needs to generate a proof. Since RAM is a major bottleneck <em>[116, 121]</em> (§1), such a time-space tradeoff may have significant practical benefit. Exploring this tradeoff is future work.</p>

    <h2 id="sec-39" class="text-2xl font-bold">Acknowledgments</h2>

    <p class="text-gray-300">This work was supported in part by the NSF, the ONR, the Simons Foundation, the Stanford Center for Blockchain Research, and the Ripple Foundation. The authors thank Justin Drake, Srinath Setty, and Justin Thaler for helpful comments.</p>

    <h2 id="sec-40" class="text-2xl font-bold">References</h2>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[1] M. R. Albrecht, L. Grassi, C. Rechberger, A. Roy, and T. Tiessen. MiMC: Efficient encryption and cryptographic hashing with minimal multiplicative complexity. In ASIACRYPT, Dec. 2016.</li>

      <li>[2] S. Ames, C. Hazay, Y. Ishai, and M. Venkitasubramaniam. Ligero: Lightweight sublinear arguments without a trusted setup. In ACM CCS, Oct. / Nov. 2017.</li>

      <li>[3] L. Babai, L. Fortnow, L. A. Levin, and M. Szegedy. Checking computations in polylogarithmic time. In ACM STOC, May 1991.</li>

      <li>[4] M. Backes, M. Barbosa, D. Fiore, and R. M. Reischuk. ADSNARK: Nearly practical and privacy-preserving proofs on authenticated data. In IEEE S&P, May 2015.</li>

      <li>[5] N. Bari and B. Pfitzmann. Collision-free accumulators and fail-stop signature schemes without trees. In EUROCRYPT, May 1997.</li>

      <li>[6] P. S. L. M. Barreto, B. Lynn, and M. Scott. Constructing elliptic curves with prescribed embedding degrees. In SCN, Sept. 2003.</li>

      <li>[7] barryWhiteHat. roll_up: Scale ethereum with SNARKs. https://github.com/barryWhiteHat/roll_up.</li>

      <li>[8] M. Bellare and P. Rogaway. Random oracles are practical: A paradigm for designing efficient protocols. In ACM CCS, Nov. 1993.</li>

      <li>[9] Bellman circuit library, community edition. https://github.com/matter-labs/bellman.</li>

      <li>[10] Bellman-BigNat. https://github.com/alex-ozdemir/bellman-bignat.</li>

      <li>[11] E. Ben-Sasson, I. Bentov, Y. Horesh, and M. Riabzev. Scalable zero knowledge with no trusted setup. In CRYPTO, Aug. 2019.</li>

      <li>[12] E. Ben-Sasson, A. Chiesa, D. Genkin, and E. Tromer. Fast reductions from RAMs to delegatable succinct constraint satisfaction problems: extended abstract. In ITCS, Jan. 2013.</li>

      <li>[13] E. Ben-Sasson, A. Chiesa, D. Genkin, E. Tromer, and M. Virza. SNARKs for C: Verifying program executions succinctly and in zero knowledge. In CRYPTO, Aug. 2013.</li>

      <li>[14] E. Ben-Sasson, A. Chiesa, M. Riabzev, N. Spooner, M. Virza, and N. P. Ward. Aurora: Transparent succinct arguments for R1CS. In EUROCRYPT, May 2019.</li>

      <li>[15] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza. Scalable zero knowledge via cycles of elliptic curves. In CRYPTO, Aug. 2014.</li>

      <li>[16] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza. Succinct non-interactive zero knowledge for a von neumann architecture. In USENIX Security, Aug. 2014.</li>

      <li>[17] J. C. Benaloh and M. de Mare. One-way accumulators: A decentralized alternative to digital sinatures (extended abstract). In EUROCRYPT, May 1994.</li>

      <li>[18] V. Beneš. Mathematical theory of connecting networks and telephone traffic. Mathematics in Science and Engineering. Elsevier Science, 1965.</li>

      <li>[19] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer. From extractable collision resistance to succinct non-interactive arguments of knowledge, and back again. In ITCS, Jan. 2012.</li>

      <li>[20] M. Blum, W. S. Evans, P. Gemmell, S. Kannan, and M. Naor. Checking the correctness of memories. In FOCS, Oct. 1991.</li>

      <li>[21] A. J. Blumberg, J. Thaler, V. Vu, and M. Walfish. Verifiable computation using multiple provers. Cryptology ePrint Archive, Report 2014/846, 2014. http://eprint.iacr.org/2014/846.</li>

      <li>[22] D. Boneh, J. Bonneau, B. Bünz, and B. Fisch. Verifiable delay functions. In CRYPTO, Aug. 2018.</li>

      <li>[23] D. Boneh, B. Bünz, and B. Fisch. A survey of two verifiable delay functions. Cryptology ePrint Archive, Report 2018/712, 2018. https://eprint.iacr.org/2018/712.</li>

      <li>[24] D. Boneh, B. Bünz, and B. Fisch. Batching techniques for accumulators with applications to IOPs and stateless blockchains. In CRYPTO, Aug. 2019.</li>

      <li>[25] D. Boneh and M. K. Franklin. Efficient generation of shared RSA keys (extended abstract). In CRYPTO, Aug. 1997.</li>

      <li>[26] J. Bonneau, A. Miller, J. Clark, A. Narayanan, J. A. Kroll, and E. W. Felten. SoK: Research perspectives and challenges for bitcoin and cryptocurrencies. In IEEE S&P, May 2015.</li>

      <li>[27] S. Bowe. BLS12-381: New zk-SNARK elliptic curve construction. https://electriccoin.co/blog/new-snark-curve/, Mar. 2017.</li>

      <li>[28] S. Bowe. Cultivating Sapling: Faster zk-SNARKs. https://electriccoin.co/blog/cultivating-sapling-faster-zksnarks/, Sept. 2017.</li>

    </ul>

    <p class="text-gray-300">-</p>

    <p class="text-gray-300">[29] S. Bowe, A. Chiesa, M. Green, I. Miers, P. Mishra, and H. Wu. Zexe: Enabling decentralized private computation. Cryptology ePrint Archive, Report 2018/962, 2018. https://eprint.iacr.org/2018/962.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[30] J. Brandt and I. Damgård. On generation of probable primes by incremental search. In CRYPTO, Aug. 1993.</li>

      <li>[31] J. Brandt, I. Damgård, and P. Landrock. Speeding up prime number generation. In ASIACRYPT, Nov. 1993.</li>

      <li>[32] B. Braun, A. J. Feldman, Z. Ren, S. Setty, A. J. Blumberg, and M. Walfish. Verifying computations with state. In SOSP, Nov. 2013.</li>

      <li>[33] E. F. Brickell, D. M. Gordon, K. S. McCurley, and D. B. Wilson. Fast exponentiation with precomputation (extended abstract). In EUROCRYPT, May 1993.</li>

      <li>[34] J. Brillhart, D. H. Lehmer, and J. L. Selfridge. New primality criteria and factorizations of <span class="math">2^{m}\\pm 1</span>. Math. Comp., 29(130):620–647, Apr. 1975.</li>

      <li>[35] J. Buchmann and S. Hamdy. A survey on IQ cryptography. In Public Key Cryptography and Computational Number Theory, 2001.</li>

      <li>[36] B. Bünz, J. Bootle, D. Boneh, A. Poelstra, P. Wuille, and G. Maxwell. Bulletproofs: Short proofs for confidential transactions and more. In IEEE S&P, May 2018.</li>

      <li>[37] B. Bünz, B. Fisch, and A. Szepieniec. Transparent SNARKs from DARK compilers. Cryptology ePrint Archive, Report 2019/1229, 2019. https://eprint.iacr.org/2019/1229.</li>

      <li>[38] P. Camacho, A. Hevia, M. A. Kiwi, and R. Opazo. Strong accumulators from collision-resistant hashing. In ISC, Sept. 2008.</li>

      <li>[39] J. Camenisch, M. Kohlweiss, and C. Soriente. An accumulator based on bilinear maps and efficient revocation for anonymous credentials. In PKC, Mar. 2009.</li>

      <li>[40] J. Camenisch and A. Lysyanskaya. Dynamic accumulators and application to efficient revocation of anonymous credentials. In CRYPTO, Aug. 2002.</li>

      <li>[41] D. Catalano and D. Fiore. Vector commitments and their applications. In PKC, Feb. / Mar. 2013.</li>

      <li>[42] A. Chepurnoy, C. Papamanthou, and Y. Zhang. Edrax: A cryptocurrency with stateless transaction validation. Cryptology ePrint Archive, Report 2018/968, 2018. https://eprint.iacr.org/2018/968.</li>

      <li>[43] A. Chiesa, Y. Hu, M. Maller, P. Mishra, N. Vesely, and N. Ward. Marlin: Preprocessing zkSNARKs with universal and updatable SRS. Cryptology ePrint Archive, Report 2019/1047, 2019. https://eprint.iacr.org/2019/1047.</li>

      <li>[44] A. Chiesa, D. Ojha, and N. Spooner. Fractal: Post-quantum and transparent recursive proofs from holography. Cryptology ePrint Archive, Report 2019/1076, 2019. https://eprint.iacr.org/2019/1076.</li>

      <li>[45] A. Chiesa, E. Tromer, and M. Virza. Cluster computing in zero knowledge. In EUROCRYPT, Apr. 2015.</li>

      <li>[46] C. Clavier, B. Feix, L. Thierry, and P. Paillier. Generating provable primes efficiently on embedded devices. In PKC, May 2012.</li>

      <li>[47] G. Cormode, M. Mitzenmacher, and J. Thaler. Practical verified computation with streaming interactive proofs. In ITCS, Jan. 2012.</li>

      <li>[48] J.-S. Coron and D. Naccache. Security analysis of the Gennaro-Halevi-Rabin signature scheme. In EUROCRYPT, May 2000.</li>

      <li>[49] C. Costello, C. Fournet, J. Howell, M. Kohlweiss, B. Kreuter, M. Naehrig, B. Parno, and S. Zahur. Geppetto: Versatile verifiable computation. In IEEE S&P, May 2015.</li>

      <li>[50] R. J. F. Cramer. Modular design of secure yet practical cryptographic protocols. PhD thesis, Universiteit van Amsterdam, Jan. 1997.</li>

      <li>[51] I. Damgård and N. Triandopoulos. Supporting non-membership proofs with bilinear-map accumulators. Cryptology ePrint Archive, Report 2008/538, 2008. http://eprint.iacr.org/2008/538.</li>

      <li>[52] A. Delignat-Lavaud, C. Fournet, M. Kohlweiss, and B. Parno. Cinderella: Turning shabby X.509 certificates into elegant anonymous credentials with the magic of verifiable computation. In IEEE S&P, May 2016.</li>

      <li>[53] Ethereum. https://ethereum.org.</li>

      <li>[54] ETH Gas Station. https://ethgasstation.info.</li>

      <li>[55] A. Fiat and A. Shamir. How to prove yourself: Practical solutions to identification and signature problems. In CRYPTO, Aug. 1987.</li>

      <li>[56] D. Fiore, C. Fournet, E. Ghosh, M. Kohlweiss, O. Ohrimenko, and B. Parno. Hash first, argue later: Adaptive verifiable computations on outsourced data. In ACM CCS, Oct. 2016.</li>

      <li>[57] Secure hash standard. NIST FIPS PUB 180-4, Aug. 2015.</li>

      <li>[58] K. Floersch. Ethereum smart contracts in L2: Optimistic rollup. https://medium.com/plasma-group/ethereum-smart-contracts-in-l2-optimistic-rollup-2clcef2ec537.</li>

      <li>[59] P.-A. Fouque and M. Tibouchi. Close to uniform prime number generation with fewer random bits. In ICALP, July 2014.</li>

      <li>[60] T. K. Frederiksen, Y. Lindell, V. Osheter, and B. Pinkas. Fast distributed RSA key generation for semi-honest and malicious adversaries. In CRYPTO, Aug. 2018.</li>

      <li>[61] M. Fredrikson and B. Livshits. Zø: An optimizing distributing zero-knowledge compiler. In USENIX Security, Aug. 2014.</li>

      <li>[62] A. Gabizon. AuroraLight: Improved prover efficiency and SRS size in a sonic-like system. Cryptology ePrint Archive, Report 2019/601, 2019. https://eprint.iacr.org/2019/601.</li>

      <li>[63] A. Gabizon, Z. J. Williamson, and O. Ciobotaru. PLONK: Permutations over lagrange-bases for oecumenical noninteractive arguments of knowledge. Cryptology ePrint Archive, Report 2019/953, 2019. https://eprint.iacr.org/2019/953.</li>

      <li>[64] R. Gennaro, C. Gentry, B. Parno, and M. Raykova. Quadratic span programs and succinct NIZKs without PCPs. In EUROCRYPT, May 2013.</li>

      <li>[65] A. Gluchowski. Optimistic vs. ZK rollup: Deep dive. https://medium.com/matter-labs/optimistic-vs-zk-rollup-deep-dive-ea141e71e075.</li>

      <li>[66] GNU multiple precision arithmetic library. https://gmplib.org.</li>

      <li>[67] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum. Delegating computation: interactive proofs for muggles. In ACM STOC, May 2008.</li>

      <li>[68] J. Gordon. Strong primes are easy to find. In EUROCRYPT, Apr. 1985.</li>

      <li>[69] L. Grassi, D. Kales, D. Khovratovich, A. Roy, C. Rechberger, and M. Schofnegger. Starkad and Poseidon: New hash functions for zero knowledge proof systems. Cryptology ePrint Archive, Report 2019/458, 2019. https://eprint.iacr.org/2019/458.</li>

      <li>[70] J. Groth. On the size of pairing-based non-interactive arguments. In EUROCRYPT, May 2016.</li>

      <li>[71] J. Hendrik W. Lenstra. Factoring integers with elliptic curves. Annals of Mathematics, 126(3):649–673, 1987.</li>

      <li>[72] D. Hopwood, S. Bowe, T. Hornby, and N. Wilcox. Zcash protocol specification. https://github.com/zcash/zips/blob/master/protocol/protocol.pdf.</li>

      <li>[73] G. Jaeschke. On strong pseudoprimes to several bases. Mathematics of Computation, 61(204):915–926, 1993.</li>

      <li>[74] M. Joye and P. Paillier. Fast generation of prime numbers on portable devices: An update. In CHES, Oct. 2006.</li>

      <li>[75] M. Joye, P. Paillier, and S. Vaudenay. Efficient generation of prime numbers. In CHES, Aug. 2000.</li>

      <li>[76] B. Kaliski. RSA factoring challenge. In H. C. A. van Tilborg, editor, Encyclopedia of Cryptography. Springer, 2005.</li>

    </ul>

    <p class="text-gray-300">[77] A. Kate, G. M. Zaverucha, and I. Goldberg. Constant-size commitments to polynomials and their applications. In ASIACRYPT, Dec. 2010.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[78] A. E. Kosba, D. Papadopoulos, C. Papamanthou, M. F. Sayed, E. Shi, and N. Triandopoulos. TRUESET: Faster verifiable set computations. In USENIX Security, Aug. 2014.</li>

      <li>[79] A. E. Kosba, C. Papamanthou, and E. Shi. xJsnark: A framework for efficient verifiable computation. In IEEE S&P, May 2018.</li>

      <li>[80] J. Lee, K. Nikitin, and S. Setty. Replicated state machines without replicated execution. In IEEE S&P, May 2020.</li>

      <li>[81] J. Li, N. Li, and R. Xue. Universal accumulators with efficient nonmembership proofs. In ACNS, June 2007.</li>

      <li>[82] B. Libert, S. C. Ramanna, and M. Yung. Functional commitment schemes: From polynomial commitments to pairing-based accumulators from simple assumptions. In ICALP, July 2016.</li>

      <li>[83] B. Libert and M. Yung. Concise mercurial vector commitments and independent zero-knowledge sets with short proofs. In TCC, Feb. 2010.</li>

      <li>[84] H. Lipmaa. Secure accumulators from euclidean rings without trusted setup. In ACNS, June 2012.</li>

      <li>[85] M. Maller, S. Bowe, M. Kohlweiss, and S. Meiklejohn. Sonic: Zero-knowledge SNARKs from linear-size universal and updatable structured reference strings. In ACM CCS, Nov. 2019.</li>

      <li>[86] Matter network. https://demo.matter-labs.io/explorer/.</li>

      <li>[87] U. M. Maurer. Fast generation of secure RSA-moduli with almost maximal diversity. In EUROCRYPT, Apr. 1990.</li>

      <li>[88] U. M. Maurer. Fast generation of prime numbers and secure public-key cryptographic parameters. Journal of Cryptology, 8(3):123–155, Sept. 1995.</li>

      <li>[89] I. Meckler and E. Shapiro. Coda: Decentralized cryptocurrency at scale. https://cdn.codaprotocol.com/v2/static/coda-whitepaper-05-10-2018-0.pdf, May 2018.</li>

      <li>[90] R. C. Merkle. A digital signature based on a conventional encryption function. In CRYPTO, Aug. 1988.</li>

      <li>[91] B. Möller. Algorithms for multi-exponentiation. In SAC, Aug. 2001.</li>

      <li>[92] N. Nethercote and J. Seward. How to shadow every byte of memory used by a program. In VEE, June 2007.</li>

      <li>[93] L. Nguyen. Accumulators from bilinear pairings and applications. In CT-RSA 2005, Feb. 2005.</li>

      <li>[94] On-chain scaling to potentially ~500 tx/sec through mass tx validation. https://ethresear.ch/t/on-chain-scaling-to-potentially-500-tx-sec-through-mass-tx-validation/3477.</li>

      <li>[95] C. Papamanthou, E. Shi, and R. Tamassia. Signatures of correct computation. In TCC, Mar. 2013.</li>

      <li>[96] B. Parno, J. Howell, C. Gentry, and M. Raykova. Pinocchio: Nearly practical verifiable computation. In IEEE S&P, May 2013.</li>

      <li>[97] T. P. Pedersen. Non-interactive and information-theoretic secure verifiable secret sharing. In CRYPTO, Aug. 1992.</li>

      <li>[98] M. O. Rabin. Probabilistic algorithm for testing primality. J. Number Theory, 12(1):128–138, Feb. 1980.</li>

      <li>[99] L. Reyzin, D. Meshkov, A. Chepurnoy, and S. Ivanov. Improving authenticated dynamic dictionaries, with applications to cryptocurrencies. In FC, Apr. 2017.</li>

      <li>[100] L. Reyzin and S. Yakoubov. Efficient asynchronous accumulators for distributed PKI. In SCN, Aug. / Sept. 2016.</li>

      <li>[101] R. L. Rivest, A. Shamir, and D. A. Wagner. Time-lock puzzles and timed-release crypto. Technical report, MIT LCS, Mar. 1996.</li>

      <li>[102] The RSA challenge numbers. https://web.archive.org/web/20130921041734/http://www.emc.com/emc-plus/rsa-labs/historical/the-rsa-challenge-numbers.htm.</li>

      <li>[103] Rust programming language. https://www.rust-lang.org/.</li>

      <li>[104] Sapling cryptography library, community edition. https://github.com/matter-labs/sapling-crypto.</li>

      <li>[105] S. Setty, S. Angel, T. Gupta, and J. Lee. Proving the correct execution of concurrent services in zero-knowledge. In OSDI, Oct. 2018.</li>

      <li>[106] S. Setty, B. Braun, V. Vu, A. J. Blumberg, B. Parno, and M. Walfish. Resolving the conflict between generality and plausibility in verified computation. In EuroSys, Apr. 2013.</li>

      <li>[107] S. T. V. Setty, R. McPherson, A. J. Blumberg, and M. Walfish. Making argument systems for outsourced computation practical (sometimes). In NDSS, Feb. 2012.</li>

      <li>[108] S. T. V. Setty, V. Vu, N. Panpalia, B. Braun, A. J. Blumberg, and M. Walfish. Taking proof-based verified computation a few steps closer to practicality. In USENIX Security, Aug. 2012.</li>

      <li>[109] J. Shawe-Taylor. Generating strong primes. Electronics Letters, 22(16):875–877, 1986.</li>

      <li>[110] E. G. Straus. Addition chains of vectors (problem 5125). Amer. Math. Monthly, 70:806–808, 1964.</li>

      <li>[111] J. Thaler. Time-optimal interactive proofs for circuit evaluation. In CRYPTO, Aug. 2013.</li>

      <li>[112] J. Thaler, M. Roberts, M. Mitzenmacher, and H. Pfister. Verifiable computation with massively parallel interactive proofs. In HotCloud, June 2012.</li>

      <li>[113] V. Vu, S. T. V. Setty, A. J. Blumberg, and M. Walfish. A hybrid architecture for interactive verifiable computation. In IEEE S&P, May 2013.</li>

      <li>[114] R. S. Wahby, M. Howald, S. J. Garg, a. shelat, and M. Walfish. Verifiable ASICs. In IEEE S&P, May 2016.</li>

      <li>[115] R. S. Wahby, Y. Ji, A. J. Blumberg, a. shelat, J. Thaler, M. Walfish, and T. Wies. Full accounting for verifiable outsourcing. In ACM CCS, Oct. / Nov. 2017.</li>

      <li>[116] R. S. Wahby, S. T. V. Setty, Z. Ren, A. J. Blumberg, and M. Walfish. Efficient RAM and control flow in verifiable outsourced computation. In NDSS, Feb. 2015.</li>

      <li>[117] R. S. Wahby, I. Tzialla, a. shelat, J. Thaler, and M. Walfish. Doubly-efficient zkSNARKs without trusted setup. In IEEE S&P, May 2018.</li>

      <li>[118] A. Waksman. A permutation network. Journal of the ACM, 15(1):159–163, Jan. 1968.</li>

      <li>[119] M. Walfish and A. J. Blumberg. Verifying computations without reexecuting them: from theoretical possibility to near practicality. Communications of the Association for Computing Machinery, Feb. 2015.</li>

      <li>[120] B. Wesolowski. Efficient verifiable delay functions. In EUROCRYPT, May 2019.</li>

      <li>[121] H. Wu, W. Zheng, A. Chiesa, R. A. Popa, and I. Stoica. DIZK: A distributed zero knowledge proof system. In USENIX Security, Aug. 2018.</li>

      <li>[122] T. Xie, J. Zhang, Y. Zhang, C. Papamanthou, and D. Song. Libra: Succinct zero-knowledge proofs with optimal prover computation. In CRYPTO, Aug. 2019.</li>

      <li>[123] Y. Zhang, D. Genkin, J. Katz, D. Papadopoulos, and C. Papamanthou. vSQL: Verifying arbitrary SQL queries over dynamic outsourced databases. In IEEE S&P, May 2017.</li>

      <li>[124] Y. Zhang, D. Genkin, J. Katz, D. Papadopoulos, and C. Papamanthou. vRAM: Faster verifiable RAM with program-independent preprocessing. In IEEE S&P, May 2018.</li>

    </ul>

    <p class="text-gray-300">A Proof of MultiSwap Consistency</p>

    <p class="text-gray-300">Let <span class="math">\\sigma</span> denote a multiset of swaps. Let <span class="math">\\mathrm{in}_{\\sigma}</span> denote <span class="math">\\{y:(x,y)\\in\\sigma\\}</span> and let <span class="math">\\mathrm{rm}_{\\sigma}</span> denote <span class="math">\\{x:(x,y)\\in\\sigma\\}</span>.</p>

    <h6 id="sec-41" class="text-base font-medium mt-4">Claim 1.</h6>

    <p class="text-gray-300">Let <span class="math">\\sigma</span> be a multiset of swaps and <span class="math">\\sigma^{\\mathrm{c}}</span> be a cycle. <span class="math">\\mathsf{MultiSwap}(S,\\sigma\\uplus\\sigma^{\\mathrm{c}},S^{\\prime})</span> holds if and only if <span class="math">\\mathsf{MultiSwap}(S,\\sigma,S^{\\prime})</span> does.</p>

    <p class="text-gray-300">Proof: We prove both directions simultaneously, by illustrating a bidirectional chain of mutually implicating equalities. We start with the definition of <span class="math">\\mathsf{MultiSwap}(S,\\sigma\\uplus\\sigma^{\\mathrm{c}},S^{\\prime})</span>:</p>

    <p class="text-gray-300"><span class="math">S^{\\prime}</span> <span class="math">=S\\uplus\\mathrm{in}_{\\sigma\\uplus\\sigma^{\\mathrm{c}}}\\boxminus\\mathrm{rm}_{\\sigma\\uplus\\sigma^{\\mathrm{c}}}</span> <span class="math">S^{\\prime}</span> <span class="math">=S\\uplus\\mathrm{in}_{\\sigma^{\\mathrm{c}}}\\uplus\\mathrm{in}_{\\sigma}\\boxminus\\mathrm{rm}_{\\sigma^{\\mathrm{c}}}\\boxminus\\mathrm{rm}_{\\sigma}\\quad\\text{properties of }\\uplus,\\boxminus</span></p>

    <p class="text-gray-300">Since <span class="math">\\sigma^{\\mathrm{c}}</span> is a cycle, we have that <span class="math">\\mathrm{in}_{\\sigma^{\\mathrm{c}}}=\\mathrm{rm}_{\\sigma^{\\mathrm{c}}}</span>, so <span class="math">\\mathrm{rm}_{\\sigma^{\\mathrm{c}}}\\subseteq S\\uplus\\mathrm{in}_{\\sigma^{\\mathrm{c}}}</span>, and the removal of <span class="math">\\mathrm{rm}_{\\sigma^{\\mathrm{c}}}</span> can be moved earlier</p>

    <p class="text-gray-300"><span class="math">S^{\\prime}</span> <span class="math">=S\\uplus\\mathrm{in}_{\\sigma^{\\mathrm{c}}}\\boxminus\\mathrm{rm}_{\\sigma^{\\mathrm{c}}}\\uplus\\mathrm{in}_{\\sigma}\\boxminus\\mathrm{rm}_{\\sigma}</span> <span class="math">S^{\\prime}</span> <span class="math">=S\\uplus\\mathrm{in}_{\\sigma}\\boxminus\\mathrm{rm}_{\\sigma}</span></p>

    <p class="text-gray-300">This last line is exactly our goal: the statement that <span class="math">\\mathsf{MultiSwap}(S,\\sigma,S^{\\prime})</span> holds. ∎</p>

    <h6 id="sec-42" class="text-base font-medium mt-4">Claim 2.</h6>

    <p class="text-gray-300">If <span class="math">\\sigma</span> contains no cycles and <span class="math">\\mathsf{MultiSwap}(S,\\sigma,S^{\\prime})</span> holds, then <span class="math">\\sigma</span> is sequentially consistent with respect to <span class="math">S</span>, producing <span class="math">S^{\\prime}</span>.</p>

    <p class="text-gray-300">Proof: Let <span class="math">n</span> be the number of swaps in <span class="math">\\sigma</span>. For a set <span class="math">S</span> and multiset of swaps <span class="math">\\tau</span>, define the directed multigraph <span class="math">G_{S,\\tau}</span> as a multigraph where the vertices are the universe of multiset elements, the edges point from each removal to its corresponding insertion, and each vertex is labeled with a <em>multiplicity</em> equal to to the multiplicity of that vertex’s element in <span class="math">S</span>, minus the out-degree, plus the in-degree. Observe that in <span class="math">G=G_{S,\\sigma}</span>, the multiplicity of each vertex is equal to the multiplicity of that element in <span class="math">S^{\\prime}</span>. Furthermore, by the predicate <span class="math">\\mathsf{MultiSwap}(S,\\sigma,S^{\\prime})</span> and the soundness of the proofs of insertions and removal, all multiplicities in <span class="math">G</span> are non-negative.</p>

    <p class="text-gray-300">We now construct the sequentially valid ordering of <span class="math">\\sigma</span>. Since <span class="math">\\sigma</span> has no swap cycles, <span class="math">G</span> has no edge cycles. Thus, the edges of <span class="math">G</span> can be topologically sorted such that all edges to a vertex occur before any edge from that vertex. We lift this edge order to a swap order, observing that in this swap order, all swaps inserting an element occur before all swaps removing it.</p>

    <p class="text-gray-300">It suffices to show that when <span class="math">\\sigma</span> is applied to <span class="math">S</span> in this order, each swap is valid. Let <span class="math">\\sigma_{i}</span> denote the first <span class="math">i</span> elements of <span class="math">\\sigma</span> in the aforementioned order. Thus, <span class="math">G_{S,\\sigma_{n}}</span> is equal to <span class="math">G</span>. Furthermore, the order ensures for all <span class="math">i&gt;j</span> and for all vertices <span class="math">v</span>, the multiplicity of <span class="math">v</span> in <span class="math">G_{S,\\sigma_{i}}</span> is at most the multiplicity of <span class="math">v</span> in <span class="math">G_{S,\\sigma_{j}}</span>. Suppose that the <span class="math">i^{\\text{th}}</span> element of this order, <span class="math">(x_{i},y_{i})</span> were invalid, where <span class="math">i\\leq n</span>. This implies that the multiplicity of <span class="math">x_{i}</span> in <span class="math">G_{S,\\sigma_{i}}</span> is negative. This would imply that the multiplicity of <span class="math">x_{i}</span> in <span class="math">G_{S,\\sigma_{n}}=G</span> were negative, a contradiction. Thus no swap <span class="math">(x_{i},y_{i})</span> is invalid in this order. ∎</p>

    <p class="text-gray-300">Proof of Lemma 1. The reverse direction follows immediately from the definition of <span class="math">\\mathsf{MultiSwap}</span>.</p>

    <p class="text-gray-300">We prove the forward direction by (strong) induction on the size of <span class="math">\\sigma</span>. Say that <span class="math">\\sigma</span> has no cycles. Then the lemma follows from Claim 2. Otherwise, let <span class="math">\\tau</span> be a multiset of swaps and let <span class="math">\\sigma^{\\mathrm{c}}</span> be a cycle such that <span class="math">\\sigma=\\tau\\uplus\\sigma^{\\mathrm{c}}</span>. By Claim 1, <span class="math">\\mathsf{MultiSwap}(S,\\tau,S^{\\prime})</span> holds. Then, by the inductive hypothesis, <span class="math">\\tau</span> can be decomposed into cycle-free <span class="math">\\tau^{\\prime}</span> and cycles <span class="math">\\tau^{\\prime}_{i}</span> such that <span class="math">\\tau=\\tau^{\\prime}\\uplus\\bigcup_{i}\\tau^{\\mathrm{c}}_{i}</span> and <span class="math">\\tau^{\\prime}</span> is sequentially consistent with respect to <span class="math">S</span>, producing <span class="math">S^{\\prime}</span>. By observing that <span class="math">\\tau^{\\prime}\\uplus(\\bigcup_{i}\\tau^{\\mathrm{c}}_{i})\\uplus\\sigma^{\\mathrm{c}}</span> is a decomposition of <span class="math">\\sigma</span> into a cycle-free swap multiset and cycles, we conclude this direction of the proof. ∎</p>

    <h2 id="sec-43" class="text-2xl font-bold">Appendix B Parameter Values</h2>

    <p class="text-gray-300">Our RSA accumulators work in <span class="math">\\mathbb{G}=\\mathbb{Z}_{N}^{\\times}/\\{\\pm 1\\}</span>, where <span class="math">N</span> is the RSA-2048 challenge number <em>[102]</em>, <span class="math">N=0</span>x$c7970ceedcc3b0754490201a7aa613cd73911081c790f5f1a8726f463550bb5b7ff0db8e1ea1189ec72f93d1650011bd721aeeacc2acde32a04107f0648c2813a31f5b0b7765ff8b44b4b6ffc93384b646eb09c7cf5e8592d40ea33c80039f35b4f14a04b51f7bfd781be4d1673164ba8eb991c2c4d730bbbe35f592bdef524af7e8daefd26c66fc02c479af89d64d373f442709439de66ceb955f3ea37d5159f6135809f85334b5cb1813addc80cd05609f10ac6a95ad65872c909525bdad32bc729592642920f24c61dc5b3c3b7923e56b16a4d9d373d8721f24a3fc0f1b3131f55615172866bccc30f95054c824e733a5eb6817f7bc16399d48c6361cc7e5.</p>

    <p class="text-gray-300">We randomly selected a 2048-bit offset <span class="math">\\Delta</span> for our division-intractable hash <span class="math">H_{\\Delta}</span> (§4.2); we use the value <span class="math">\\Delta=0</span>x$f3709c40772816d668926cae548ffea31f49034ab1b30fb84b595ca6c126a6646a4341abea2f8b07bf8d366801ac293e5a286abb43accdec39ac8f0bc599519cf1e532f9c70b5406c4b652ca7da4e1cb102b69953841ae20d4bcab055c5338487ba00fe95e821abd381b191dfb77bae3e022ccd818d4064882d28481ffa2db45093a4deab05f6ebfbadcf11afe7369caeaaaf1f02572348a17f0510b333b8a2d56e67d892f1e1182b26301d9347ae0a900cff2a0979caddb1a86e04a6cbc9704d6549e5b3aef0d5c3dc4aba648ed421b0ba37c3f8e8edc12ef42b86d8e5fbc0dbd903238ca2e9ed6873ccb68e8103b5d01b4249bfbe8e70cb4f4983f41df8c8f.</p>

    <p class="text-gray-300">Our evaluation (§7) builds on the BLS12-381 elliptic curve <em>[27]</em>, which is the Barreto-Lynn-Scott curve <em>[6]</em> with parameter <span class="math">z=-0</span>x<span class="math">d201000000010000</span> whose subgroup order is <span class="math">p=0</span>x<span class="math">73</span>e<span class="math">da</span>753299<span class="math">d</span>7d483339<span class="math">d</span>80809a1<span class="math">d</span>80553b<span class="math">da402fffe5bfefffffff00000001</span>. This is the characteristic of the field <span class="math">\\mathbb{F}_{p}</span> for which we synthesize constraints.</p>`;
---

<BaseLayout title="Scaling Verifiable Computation Using Efficient Set Accumulat... (2019/1494)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2019 &middot; eprint 2019/1494
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
