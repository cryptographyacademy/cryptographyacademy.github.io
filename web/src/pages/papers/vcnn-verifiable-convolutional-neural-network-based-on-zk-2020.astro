---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2020/584';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'vCNN: Verifiable Convolutional Neural Network based on zk-SNARKs';
const AUTHORS_HTML = 'Seunghwa Lee, Hankyung Ko, Jihye Kim, Hyunok Oh';

const CONTENT = `    <p class="text-gray-300">Seunghwa Lee [ Kookmin University Seoul, Korea ttyhgo@kookmin.ac.kr ] Hankyung Ko [ Hanyang University Seoul, Korea hankyungko@hanyang.ac.kr ] Jihye Kim [ Kookmin University Seoul, Korea jihyek@kookmin.ac.kr ] Hyunok Oh [ Hanyang University Seoul, Korea hoh@hanyang.ac.kr ]</p>

    <h6 id="sec-2" class="text-base font-medium mt-4">Abstract</h6>

    <p class="text-gray-300">With the development of AI systems, services using them expand to various applications. The widespread adoption of AI systems relies substantially on the ability to trust their output. Therefore, it is becoming important for a client to be able to check whether the AI inference services have been correctly calculated. Since the weight value in a CNN model is an asset of service providers, the client should be able to check the correctness of the result without the weight value. Furthermore, when the result is checked by a third party, it should be possible to verify the correctness even without the user’s input data. Fortunately, zero-knowledge Succinct Non-interactive ARguments of Knowledge (zk-SNARKs) allow to verify the result without input and weight values. However, the proving time in zk-SNARKs is too slow to be applied to real AI applications.</p>

    <p class="text-gray-300">This paper proposes a new efficient verifiable convolutional neural network (vCNN) framework which accelerates the proving performance tremendously. To increase the proving performance, we propose a new efficient relation representation for convolution equations. While the proving complexity of convolution is <span class="math">O(ln)</span> in the existing zk-SNARK approaches, it reduces to <span class="math">O(l+n)</span> in the proposed approach where <span class="math">l</span> and <span class="math">n</span> denote the size of kernel and the data in CNNs. Experimental results show that the proposed vCNN improves prove performance by 20 fold for a simple MNIST and 18000 fold for VGG16. The security of the proposed scheme is proven formally.</p>

    <h6 id="sec-3" class="text-base font-medium mt-4">Index Terms:</h6>

    <p class="text-gray-300">Convolutional Neural Networks, Verifiable Computation, zk-SNARKs</p>

    <h2 id="sec-4" class="text-2xl font-bold">I Introduction</h2>

    <p class="text-gray-300">Machine learning and neural networks have greatly expanded our understanding of data and the insights it carries. Among these, convolutional neural networks (CNNs), based on the convolution operation, are particularly useful tools for classification and recognition, as compared with standard neural networks. CNNs are easily trained with considerably fewer connections and parameters while providing a better recognition rate. Thus, CNNs generate various business opportunities such as those based on law, banking, insurance, document digitization, healthcare predictive analytics, etc. However, extra caution is required when applying CNNs to safety critical applications since the incorrect result can cause a severe damage. Hence, it is preferred to validate that the result is correctly computed according to a given CNN model.</p>

    <p class="text-gray-300">Consider a clinical decision support service application via AI, such as IBM Watson as shown in Figure 1. In this application, a hospital takes a patient’s CT scan or X-ray, and sends the scanned image to the AI doctor. Then the AI doctor diagnoses the disease based on the image and returns the diagnosis result to the hospital and the patient. The integrity check of the AI results is required since incorrect results may endanger the life of the patient <em>[1]</em>.</p>

    <p class="text-gray-300">The most straightforward approach to verify the result is to re-execute the same AI program. However, it is impossible in most cases since the AI weight parameters are important IPs and are not available publicly. In addition, the privacy of input data is another issue to consider. In our scenario, we allow the AI doctor to know the user’s input for diagnosis, but it may be desirable to hide the user’s private information when the diagnosis result is transferred to the third party such as an insurance company. In this situation, it should be possible for the insurance company to verify that the diagnosis result is correct without the private information of input data as well as AI weights.</p>

    <p class="text-gray-300">Fortunately the recently advanced cryptographic tool called zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARKs) <em>[2, 3, 4, 5, 6, 7]</em> can solve the problem to verify the correctness of results without revealing private information. In zk-SNARKs, a prover generates a proof <span class="math">\\pi</span> using public input/output data (or statement <span class="math">\\phi</span>) and secret input data (or witness <span class="math">w</span>) for a given function. A verifier can check the validity of the statement <span class="math">\\phi</span> with the proof <span class="math">\\pi</span> without the secret input data <span class="math">w</span>. zk-SNARKs can also be used to protect the privacy of user’s input data from the verifier when used together with a commitment scheme. The commitment scheme <em>[8]</em> is a cryptographic primitive that allows one to commit to his choice while keeping it hidden to others (hiding) so that he can no longer change his choice (binding). Since the zk-SNARKs proof can include the correct computation of the commitment scheme, it can be verified with proof and commitment alone that the result is computed correctly.</p>

    <p class="text-gray-300">Figure 1 shows how zk-SNARKs is applied to an AI doctor. The AI doctor first generates a commitment <span class="math">c_{a}</span> by committing to AI weight values <span class="math">a</span> and publishes the commitment <span class="math">c_{a}</span> in a public repository so that the correctness computation of the model can be transparently checked against the published <span class="math">c_{a}</span>. The AI doctor computes a diagnosis result on received input data <span class="math">x</span> from the hospital and AI weights <span class="math">a</span>. In addition, the AI doctor makes a commitment <span class="math">c_{x}</span> from the input data <span class="math">x</span> to hide the input data, and generates a proof <span class="math">\\pi</span> for a statement including the input commitment, the weight commitment and</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Fig. 1: Verifiable AI doctor service scenario</p>

    <p class="text-gray-300">the output result  <span class="math">(\\phi = (c_x, c_a, y))</span>  with a witness comprising  <span class="math">(w = (x, a))</span> . The proof  <span class="math">\\pi</span>  and the statement  <span class="math">\\phi</span>  is provided to the hospital and the patient. Then they can check the correctness of the statement  <span class="math">\\phi</span>  with the proof  <span class="math">\\pi</span> . Moreover, the hospital and the patient can transfer the statement  <span class="math">\\phi</span>  to any third party like an insurance company. The insurance company can also check the statement  <span class="math">\\phi</span>  with the proof  <span class="math">\\pi</span>  without input data  <span class="math">x</span>  and weight values  <span class="math">a</span> .</p>

    <p class="text-gray-300">The zk-SNARKs, however, require significant amount of computations on the prover's side. In zk-SNARKs, a function is translated to an arithmetic circuit comprising addition and multiplication gates to be represented as quadratic arithmetic programs (QAPs). The proving time is proportional to the number of multiplications in QAPs. In addition, the size of public parameters called common reference string (CRS) linearly increases according to the number of multiplications. Thus, the main hurdle to apply zk-SNARKs to real applications is how to minimize the proving time.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In CNNs, the convolution operations become main performance bottleneck to generate a proof. If the convolution is expressed as an arithmetic circuit, the number of multiplications becomes  $O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\times</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{a}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">  where  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  and  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{a}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$  represent the size of the input and kernel data. For instance, the circuit size is more than 6TB and the CRS size is approximately 1400TB, and the proving time takes about 10 years in the state-of-the-art zk-SNARKs [3] for VGG16 [9], a commonly used model for image classification. Consequently, the main goal of this paper is to improve the proving performance of CNNs.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">It is crucial to optimize the convolution circuit to improve the proving time in zk-SNARKs for CNNs since more than  <span class="math">90\\%</span>  operations are convolution operations in CNNs.</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Fig. 2: Convolution in sum of products representation</p>

    <p class="text-gray-300">Optimizing Convolutional Relation: We propose a new efficient QAP formula for convolution that significantly curtails the number of multiplications. While existing approaches check the correctness of the convolutions for every operation, our approach builds an optimized checking relation for convolution operations by introducing an indeterminate variable.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Consider a convolution equation in the sum of products as shown in Figure 2:  <span class="math">y_{i} = \\sum_{j=0}^{l-1} a_{j} \\cdot x_{i+l-1-j}</span>  where  <span class="math">\\vec{x}_{i} = (x_{i}, \\dots, x_{i+l-1})</span>  denotes the  <span class="math">i</span> -th input vector,  <span class="math">y_{i}</span>  the  <span class="math">i</span> -th output, and  <span class="math">\\vec{a} = (a_{0}, \\dots, a_{l-1})</span>  the kernel vector for  <span class="math">0 \\leq i \\leq n-l</span> . Notably, the sum of product representation contains  $O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{a}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$  number of multiplications.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Let us change the representation into a product of sums to reduce the number of operations. A simple representation with a product of sums is not sufficient to guarantee the convolution relation. For example, in relation  <span class="math">(\\sum_{i=0}^{n-1} x_i) \\cdot (\\sum_{i=0}^{l-1} a_i) = \\sum_{i=0}^{n+l-2} y_i</span> , many different  <span class="math">y_i&#x27;</span>  values can satisfy the relation if  <span class="math">\\sum_{i=0}^{n+l-2} y_i&#x27; = \\sum_{i=0}^{n+l-2} y_i</span> .</p>

    <p class="text-gray-300">To safeguard each  <span class="math">y_{i}</span>  equation, we combine indeterminate</p>

    <p class="text-gray-300"><span class="math">Z</span> in the convolution representation as follows:</p>

    <p class="text-gray-300"><span class="math">(\\sum_{i=0}^{n-1}x_{i}Z^{i})\\cdot(\\sum_{i=0}^{l-1}a_{i}Z^{i})=\\sum_{i=0}^{n+l-2}y_{i}Z^{i}.</span> (1)</p>

    <p class="text-gray-300">In Equation (1) an identity holds for all choices of <span class="math">Z</span>. Figure 3 shows how the product of sums representation is mapped to the sum of products representations shown in Figure 2. Note that due to the compact representation in product of sums, it requires additional equations called dummies including head and tail parts.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Equation (1) requires a single multiplication of polynomials or <span class="math">x(Z)\\cdot a(Z)=y(Z)</span>. Quadratic polynomial program (QPP) <em>[10]</em> is a natural approach to allow polynomials in QAP. As a result, the proving computation complexity becomes $O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{a}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> (</span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{a}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-2<span class="math"> is the maximum degree of polynomials), which is much smaller than </span>O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{a}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$. Note that the number of multiplications becomes amplified by the maximum degree of polynomials in QPP.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a> Figure 3: Convolution in product of sums</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Connection with ReLU and Pooling: Our newly proposed formula using QPP minimizes a prover’s computation only when convolution is verified; however, it is inefficient when the prover proves computation of the whole CNNs with other operations such as ReLU or pooling. Polynomial circuits are represented using a single bivariate equation in QPP. Since the division (required to generate a proof) is slow when QPP is expressed as a bivariate polynomial, we convert it to a univariate polynomial by increasing the polynomial degree to utilize the fast division algorithm based on number theoretic transform (NTT). To eliminate one variable, we change it into the form of another variable with a higher degree. However, the substitution of one variable by another incurs excessive overheads in non-convolution operations, such as ReLU and Pooling, thereby amplifying the degree of the equation to $O((</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{a}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)^{2})$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Since the intermediates of convolutions and non-convolution operations are independent, it is better to treat those operations separately to avoid mutual effects. In particular, to alleviate the degree increments involving ReLU and Pooling, we apply the polynomial circuit only to the convolution and the arithmetic circuit to the rest part of CNNs, and build a connecting proof between QPP and QAP using the commit and prove SNARK (CP-SNARK) technique <em>[11]</em>. The CP-SNARK technique guarantees that QPP and QAP are interconnected with inputs for one component corresponding to outputs from the other. To use this technique, we adopt commit and carry SNARK (cc-SNARKs) <em>[11]</em> rather than traditional SNARK for QPP and QAP, as commitments are required for interconnected values with proofs. Figure 4 illustrates the overview of our verifiable convolutional neural network scheme called vCNN. As shown in Figure 1, CNNs are proved by generating <span class="math">(cm_{qpp},\\pi_{qpp})</span> from QPP cc-SNARKs and <span class="math">(cm_{qap},\\pi_{qap})</span> from QAP cc-SNARKs, respectively, and then interconnecting the commitments through <span class="math">\\pi_{cp}</span>. Hence, the final proof for our proposed scheme is a tuple of two commitments and three proofs (<span class="math">cm_{qap},cm_{qpp},\\pi_{qap},\\pi_{qpp},\\pi_{cp}</span>). The proposed scheme generates a single proof for QAP and QPP circuits even for multiple layer CNNs, as all the convolution layers are collected, QPP is applied to the collected convolution layer, and QAP is applied to the other collected circuit in a similar manner. See Section IV for details.</p>

    <h3 id="sec-6" class="text-xl font-semibold mt-8">III-B Contributions</h3>

    <p class="text-gray-300">We summarize our contributions as follows.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>We propose a new QPP relation optimized for the convolutions and construct an efficient zk-SNARK scheme of which CRS size and proving time are linear with the input size and the kernel size, i.e., <span class="math">O(n+l)</span>. The proposed scheme is a verifier-friendly zk-SNARK scheme with a constant proof size, and its verification time complexity linearly depends on the input and output only, regardless of convolution intricacy.</li>

      <li>We propose an efficient construction of vCNN to verify the evaluation of the whole CNNs. Our construction includes QPP-based zk-SNARKs optimized for convolutions and QAP-based zk-SNARKs effectively working for Pooling and ReLU, and interconnects them using CP-SNARKs.</li>

      <li>We prove that our construction provides computational knowledge soundness and perfect zero-knowledge properties under the security properties of QAP- and QPP-based zk-SNARKs and CP-SNARKs.</li>

      <li>We implement vCNN and compare it with the existing zk-SNARKs in terms of size and computation. The proposed scheme improves the key generation/proving time 25 fold and the CRS size 30 fold compared with the state-of-art zk-SNARK scheme <em>[3]</em> for a small example of MNIST (2-layer model) comprising a single convolution layer with ReLU and a single pooling layer. For the realistic application of VGG16, the proposed scheme improves the performance at least 18000 fold, compared with <em>[3]</em>; the proving time is reduced to 8 hours from 10 years, and the CRS size is shortened to 80 GB from 1400 TB. Thus, we provide the first efficient verifiable convolutional neural network, which has been nearly impossible to realize so far.</li>

    </ol>

    <p class="text-gray-300">!<a href="img-3.jpeg">img-3.jpeg</a></p>

    <p class="text-gray-300">!<a href="img-4.jpeg">img-4.jpeg</a> Fig. 4: Proposed vCNN overview</p>

    <p class="text-gray-300">The remainder of this paper is organized as follows: Section II discusses related work. Section III describes preliminaries for the proposed schemes. Section IV constructs a verifiable CNN scheme using zk-SNARKs and Section V represents experiment results. Finally, Section VI summarizes and concludes the paper. Security proofs are presented in the Appendix.</p>

    <p class="text-gray-300">Verifiable Computation. Various cryptographic proof systems [2]–[6], [10], [19]–[22] have been proposed to provide the privacy and computational integrity. These systems have been improved into many forms for the efficiency of their provers and verifiers, and the expressiveness of the statement being proven. Each scheme supports a general function, but it tends to be efficient only for a specific function, so performance issues may occur when applied to an application composed of functions with multiple characteristic.</p>

    <p class="text-gray-300">Goldwasser et al. [5] proposed the GKR protocol, an interactive proof protocol for a general function, where the function was represented as a layered arithmetic circuit, and the circuit was proved using the sum-check protocol. GKR takes  <span class="math">O(S \\log S)</span>  computations for proof generation and  <span class="math">O(d \\log S)</span>  computations for verifying the proof, where  <span class="math">S</span>  denotes the circuit size and  <span class="math">d</span>  the circuit depth. Cormode et al. [20] and Thaler [23] subsequently optimized GKR, and Wahby et al. [6] added zero-knowledge property, producing zk-SNARKs in the ROM.</p>

    <p class="text-gray-300">In contrast, Gennaro et al. [4] proposed a quadratic arithmetic program (QAP) based zk-SNARK scheme, where QAP is the representation of an arithmetic circuit as a polynomial equation, and the circuit satisfiability is checked using polynomial division. Parno et al. [2] proposed Pinocchio, the first nearly practical QAP-based zk-SNARK scheme with eight group elements for its proof, and implemented zk-SNARKs tools. Groth [3] improved Pinocchio with a shorter proof comprising only three group elements.</p>

    <p class="text-gray-300">Other than theoretical developments, many studies have investigated practical zk-SNARKs implementations. Libsnark [22], [24] implemented QAP-based zk-SNARK</p>

    <p class="text-gray-300">schemes. Privacy preserving cryptocurrency Zcash [25] utilizes libsnark as a real-world case, and other systems, such as Zokrates and ZSL [26], [27], have also been proposed by implementing zk-SNARKs using libsnark. The zk-SNARKs system also requires a front-end compiler that converts a function into a arithmetic circuit. Pinocchio [2] provides a C-compiler that produces arithmetic circuits for its own scheme. Kosba built Jsnark [28] which generates the arithmetic circuit for zk-SNARKs using java language. It provides gadgets that can easily convert conditional statements, loops, and cryptographic schemes such as hashes and encryptions into the arithmetic circuits that are difficult to perform in Pinocchio compiler. He also proposed xjsnark [29] to convert their own high-level language to an arithmetic circuit and optimized it.</p>

    <p class="text-gray-300">Verifiable Neural Networks. To protect the privacy of the input data and the model of deep neural networks, Dowlin et al. proposed CryptoNets [12] based on using the fully homomorphic encryption (FHE). Juvekar et al. accelerates the overall performance through homomorphic matrix multiplication technique by proposing [13]-[15]. These schemes based on homomorphic encryption focused on privacy and did not consider execution integrity. Slalom [30] was proposed as a verifiable neural network scheme using a trusted hardware, Intel SGX. It uses Freivalds' algorithm [31] on SGX which verifies the correctness of matrix multiplication. Since the inputs and outputs are exposed to use the algorithm, Slalom adds random values to protect the privacy of the inputs and outputs. However, Slalom aims to provide the privacy of the inputs and outputs, and it does not focus on the privacy of the model weight values.</p>

    <p class="text-gray-300">Even though zk-SNARKs are generally applicable for CNNs, they are not very efficient for some functions, particularly convolutions. Ghodsi et al. [16] proposed SafetyNet, the first SNARK-based scheme supporting neural networks specifically. SafetyNet is based on the GKR protocol [5], which is suitable for linear functions. To effectively use this advantage, it adopts a quadratic activation function  <span class="math">(x^{2})</span>  rather than ReLU, which reduces the neural network accuracy. Thus, it is difficult to apply SafetyNet to actual models, since most modern neural networks use ReLU. Zhao et al. proposed</p>

    <p class="text-gray-300">TABLE I: Verifiable neural network scheme security coverage and performance, where  <span class="math">\\vec{x}</span>  denotes the input,  <span class="math">\\vec{a}</span>  the kernel, and  <span class="math">\\vec{y}</span>  the output.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Approach</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Privacy</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Integrity</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Activation function</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Proving time</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Proof size</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Verifying time</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">FHE [12]-[15]</td>

            <td class="px-3 py-2 border-b border-gray-700">O</td>

            <td class="px-3 py-2 border-b border-gray-700">X</td>

            <td class="px-3 py-2 border-b border-gray-700">ReLU</td>

            <td class="px-3 py-2 border-b border-gray-700">-</td>

            <td class="px-3 py-2 border-b border-gray-700">-</td>

            <td class="px-3 py-2 border-b border-gray-700">-</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">SafetyNet [16]</td>

            <td class="px-3 py-2 border-b border-gray-700">X</td>

            <td class="px-3 py-2 border-b border-gray-700">O</td>

            <td class="px-3 py-2 border-b border-gray-700">Quadratic</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">a</td>

            <td class="px-3 py-2 border-b border-gray-700">·</td>

            <td class="px-3 py-2 border-b border-gray-700">x</td>

            <td class="px-3 py-2 border-b border-gray-700">+</td>

            <td class="px-3 py-2 border-b border-gray-700">y</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">a</td>

            <td class="px-3 py-2 border-b border-gray-700">·</td>

            <td class="px-3 py-2 border-b border-gray-700">x</td>

            <td class="px-3 py-2 border-b border-gray-700">+</td>

            <td class="px-3 py-2 border-b border-gray-700">y</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">a</td>

            <td class="px-3 py-2 border-b border-gray-700">·</td>

            <td class="px-3 py-2 border-b border-gray-700">x</td>

            <td class="px-3 py-2 border-b border-gray-700">+</td>

            <td class="px-3 py-2 border-b border-gray-700">y</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">VeriML [17]</td>

            <td class="px-3 py-2 border-b border-gray-700">O</td>

            <td class="px-3 py-2 border-b border-gray-700">O</td>

            <td class="px-3 py-2 border-b border-gray-700">Quadratic</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">a</td>

            <td class="px-3 py-2 border-b border-gray-700">·</td>

            <td class="px-3 py-2 border-b border-gray-700">x</td>

            <td class="px-3 py-2 border-b border-gray-700">+</td>

            <td class="px-3 py-2 border-b border-gray-700">y</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">x</td>

            <td class="px-3 py-2 border-b border-gray-700">+</td>

            <td class="px-3 py-2 border-b border-gray-700">y</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Embedded proof [18]</td>

            <td class="px-3 py-2 border-b border-gray-700">O</td>

            <td class="px-3 py-2 border-b border-gray-700">O</td>

            <td class="px-3 py-2 border-b border-gray-700">ReLU</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">a</td>

            <td class="px-3 py-2 border-b border-gray-700">·</td>

            <td class="px-3 py-2 border-b border-gray-700">x</td>

            <td class="px-3 py-2 border-b border-gray-700">+</td>

            <td class="px-3 py-2 border-b border-gray-700">y</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">x</td>

            <td class="px-3 py-2 border-b border-gray-700">+</td>

            <td class="px-3 py-2 border-b border-gray-700">y</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">vCNN (ours)</td>

            <td class="px-3 py-2 border-b border-gray-700">O</td>

            <td class="px-3 py-2 border-b border-gray-700">O</td>

            <td class="px-3 py-2 border-b border-gray-700">ReLU</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">a</td>

            <td class="px-3 py-2 border-b border-gray-700">+</td>

            <td class="px-3 py-2 border-b border-gray-700">x</td>

            <td class="px-3 py-2 border-b border-gray-700">+</td>

            <td class="px-3 py-2 border-b border-gray-700">y</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">x</td>

            <td class="px-3 py-2 border-b border-gray-700">+</td>

            <td class="px-3 py-2 border-b border-gray-700">y</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">VeriML [17] to verify neural networks using QAP-based zk-SNARKs for machine learning as a service (MLaaS). Although VeriML ensures both privacy and integrity, it requires a long proving time,  $(O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{a}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{y}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">))<span class="math"> , where  </span>\\vec{x}<span class="math">  denotes the input,  </span>\\vec{a}<span class="math">  the kernel, and  </span>\\vec{y}$  the output.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Keuffer et al. [18] proposed an embedded proofs protocol that combines the GKR and QAP schemes, using GKR for linear and QAP for non-linear functions. To combine them, the verifying process of GKR is verified in the QAP circuit. However, it still has large computation complexity of  $(O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{a}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{y}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">))<span class="math"> , as the input  </span>(\\vec{x})<span class="math">  and kernel  </span>(\\vec{a})$  sizes are significantly large in real applications.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">First, we define some notations to avoid duplicate words. The term  <span class="math">[n]</span>  denotes the set of indices  <span class="math">\\{0,1,\\dots ,n - 1\\}</span> . The input of convolution is represented as  <span class="math">\\{x_{i}\\}_{i\\in [n]}</span>  where the input size is  <span class="math">n</span>  and the kernel of convolution is represented as  <span class="math">\\{a_i\\}_{i\\in [l]}</span>  where the kernel size is  <span class="math">l</span> .</p>

    <p class="text-gray-300">We use a Type III bilinear group  <span class="math">(p, \\mathbb{G}_1, \\mathbb{G}_2, \\mathbb{G}_T, e, G_1, G_2)</span>  with the following properties:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathbb{G}_1, \\mathbb{G}_2, \\mathbb{G}_T</span>  are groups of prime order  <span class="math">p</span>  with generator  <span class="math">G_1 \\in \\mathbb{G}_1, G_2 \\in \\mathbb{G}_2</span> .</li>

      <li>The pairing  <span class="math">e: \\mathbb{G}_1 \\times \\mathbb{G}_2 \\to \\mathbb{G}_T</span>  is a bilinear map.</li>

      <li><span class="math">e(G_1, G_2)</span>  generates  <span class="math">\\mathbb{G}_T</span> .</li>

    </ul>

    <p class="text-gray-300">Gennaro et al. [4] defined QAP as an efficient encoding method for circuit satisfiability. QAP represents an arithmetic circuit that encodes the constraints into the multiplication gates. The correctness of the computation can be tested using QAP by performing a divisibility check between polynomials. A cryptographic protocol enables to check divisibility for a single polynomial and prevents a cheating prover from building a proof for a false statement that might be accepted.</p>

    <p class="text-gray-300">Definition 1. Quadratic Arithmetic Program (QAP) A QAP comprises three sets of polynomials  <span class="math">\\{u_i(X), v_i(X), w_i(X)\\}_{i=0}^m</span>  and a target polynomial  <span class="math">t(X)</span> . The QAP computes an arithmetic circuit if  <span class="math">(c_1, \\ldots, c_{l-1})</span>  are valid assignments of both the inputs and outputs for the circuit iff there exist coefficients  <span class="math">(c_l, \\ldots, c_m)</span>  such that  <span class="math">t(X)</span>  divides  <span class="math">p(X)</span> , as follows:</p>

    <p class="text-gray-300"><span class="math">p(X,Z) = (\\Sigma_{i = 1}^{m}c_{i}(Z)\\cdot u_{i}(X))\\cdot (\\Sigma_{i = 1}^{m}c_{i}(Z)\\cdot v_{i}(X))</span> <span class="math">(2)</span> <span class="math">-\\left(\\Sigma_{i = 1}^{m}c_{i}(Z)\\cdot w_{k}(X)\\right)</span></p>

    <p class="text-gray-300">A QAP that satisfies the aforementioned definition computes an arithmetic circuit. The size of QAP is  <span class="math">m</span>  and its degree is the degree of  <span class="math">t(X)</span> .</p>

    <p class="text-gray-300">In the above-mentioned definition,  <span class="math">t(X) = \\prod_{i\\in mul}(x - r_i)</span> , where  <span class="math">mul</span>  is the set of multiplication gates of the arithmetic circuit and each  <span class="math">r_j</span>  is a random labeling for corresponding multiplication gate. The polynomial  <span class="math">u_i(X)</span>  encodes the left inputs,  <span class="math">v_i(X)</span>  encodes the right inputs, and  <span class="math">w_i(X)</span>  encodes the gate outputs. By definition, if  <span class="math">r_j</span>  is a root for polynomial  <span class="math">p(X)</span> ,  <span class="math">p(r_j)</span>  represents the relation between inputs and outputs for the corresponding multiplicative gate  <span class="math">g</span> .</p>

    <p class="text-gray-300">QAP verifies wires that are represented as an arithmetic value in an arithmetic circuit. Kosba et al. [10] subsequently defined the quadratic polynomial program (QPP), similar to QAP, except circuit wires that can be represented as a univariate polynomial.</p>

    <p class="text-gray-300">Definition 2. Quadratic Polynomial Program(QPP) A QPP for a polynomial circuit comprises three sets of polynomials  <span class="math">\\{u_i(X), v_i(X), w_i(X)\\}_{i=1}^m</span>  and a target polynomial  <span class="math">t(X)</span> . The QPP computes the circuit if  <span class="math">(c_1(Z), \\ldots, c_l(Z))</span>  are valid assignments of both the inputs and outputs iff there exist coefficients  <span class="math">(c_{l+1}, \\ldots, c_m)</span>  such that  <span class="math">t(X)</span>  divides  <span class="math">p(X, Z)</span> :</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} p (X, Z) = \\left(\\Sigma_ {i = 1} ^ {m} c _ {i} (Z) \\cdot u _ {i} (X)\\right) \\cdot \\left(\\Sigma_ {i = 1} ^ {m} c _ {i} (Z) \\cdot v _ {i} (X)\\right) \\tag {2} \\\\ - \\left(\\Sigma_ {i = 1} ^ {m} c _ {i} (Z) \\cdot w _ {k} (X)\\right) \\\\ \\end{array}</span></div>

    <p class="text-gray-300">A QPP that satisfies this definition computes the circuit. The size of QPP is  <span class="math">m</span>  and its degree is the degree of  <span class="math">t(X)</span> .</p>

    <p class="text-gray-300">Similarly to the QAP definition,  <span class="math">u_{i}(X), v_{i}(X)</span> , and  <span class="math">w_{i}(X)</span>  represent a gate, where  <span class="math">u_{i}(X)</span>  encodes a left input,  <span class="math">v_{i}(X)</span>  a right input, and  <span class="math">w_{i}(X)</span>  an output. If the left input wire of a multiplication gate  <span class="math">r_{j}</span>  is  <span class="math">c_{l}(Z)</span> , then the right wire is  <span class="math">c_{r}(Z)</span>  and the output is  <span class="math">c_{o}(Z)</span> ; hence  <span class="math">c_{l}(Z) \\cdot c_{r}(Z) = c_{o}(Z)</span>  and it can be represented as  <span class="math">(\\sum_{i=1}^{m} c_{i}(Z) \\cdot u_{i}(r_{j})) (\\sum_{i=1}^{m} c_{i}(Z) \\cdot v_{i}(r_{j})) = (\\sum_{i=1}^{m} c_{i}(Z) \\cdot w_{i}(r_{j}))</span> .</p>

    <p class="text-gray-300">D. Zero-Knowledge Succinct Non-interactive Arguments of Knowledge</p>

    <p class="text-gray-300">In this section, we recall the zk-SNARKs definition [2], [3].</p>

    <p class="text-gray-300">Definition 3. A zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARKs) scheme for a relation  <span class="math">R</span>  is the quadruple of PPT algorithms (KeyGen, Prove, Verify, Sim)</p>

    <p class="text-gray-300"><span class="math">p(X) = (\\Sigma_{i = 1}^{m}c_{i}\\cdot u_{i}(X))\\cdot (\\Sigma_{i = 1}^{m}c_{i}\\cdot v_{i}(X)) - (\\Sigma_{i = 1}^{m}c_{i}\\cdot w_{k}(X))</span>  as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">(crs,\\tau)\\leftarrow\\mathsf{Setup}(R)</span>: The setup algorithm takes a relation <span class="math">R\\in\\mathcal{R}_{\\lambda}</span> as input, and returns a common reference string <span class="math">crs</span> and a simulation trapdoor <span class="math">td</span>.</li>

      <li><span class="math">\\pi\\leftarrow\\mathsf{Prove}(crs,\\phi,w)</span>: The prover algorithm takes a <span class="math">crs</span> for a relation <span class="math">R</span> and <span class="math">(\\phi,w)\\in R</span> as input, and returns a proof <span class="math">\\pi</span>.</li>

      <li><span class="math">0/1\\leftarrow\\mathsf{Verify}(crs,\\phi,\\pi)</span>: the verifier algorithm takes a <span class="math">crs</span>, a statement <span class="math">\\phi</span>, and a proof <span class="math">\\pi</span> as input, and returns 0(reject) or 1(accept).</li>

      <li><span class="math">\\pi\\leftarrow\\mathsf{Sim}(crs,td,\\phi)</span>: The simulator algorithm takes a <span class="math">crs</span>, a simulation trapdoor <span class="math">td</span>, and a statement <span class="math">\\phi</span> as input, and returns a proof <span class="math">\\pi</span>.</li>

    </ul>

    <p class="text-gray-300">Completeness: An argument is complete if given true statement <span class="math">\\phi</span>, a prover with a witness can convince the verifier. For all <span class="math">(\\phi,w)\\in R</span>, the probability of completeness is:</p>

    <p class="text-gray-300">\\[ Pr\\left[\\begin{array}[]{c}\\mathsf{Verify}(crs,\\phi,\\pi)=1\\\\</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\end{array}\\right.\\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\begin{array}[]{c}(crs,td)\\leftarrow\\mathsf{Setup}(R),\\\\</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Computational knowledge soundness: An argument is computational knowledge sound if the prover must know a witness and such knowledge can be efficiently extracted from the prover by using a knowledge extractor. Proof of knowledge requires that for a PPT adversary <span class="math">\\mathcal{A}</span> generating an accepting proof, there must be an extractor <span class="math">\\chi_{\\mathcal{A}}</span> that, given the same input of <span class="math">\\mathcal{A}</span>, outputs a valid witness such that</p>

    <p class="text-gray-300">\\[ Pr\\left[\\begin{array}[]{c}\\mathsf{Verify}(crs,\\phi,\\pi)=1\\\\</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\wedge(\\phi,w)\\not\\in R\\end{array}\\right.\\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\begin{array}[]{c}(crs,td)\\leftarrow\\mathsf{Setup}(R),\\\\</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where <span class="math">z</span> is auxiliary input.</p>

    <p class="text-gray-300">Succinctness: The length of a proof is</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\pi</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\mathsf{poly}(k)\\mathsf{polylog}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">.</p>

    <p class="text-gray-300">Perfect zero-knowledge: An argument is zero-knowledge if it does not leak any information other than the truth of the statement. Notably, zk-SNARKs are perfect zero-knowledge if for all <span class="math">(R,z)\\leftarrow\\mathcal{R}</span>, <span class="math">(\\phi,w)\\leftarrow R</span> and all adversaries <span class="math">\\mathcal{A}</span>, one has the following:</p>

    <p class="text-gray-300">$Pr\\left[\\begin{array}[]{c}\\mathcal{A}(R,z,crs,td,\\pi)=1\\\\</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\end{array}\\right.\\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\begin{array}[]{c}(crs,td)\\leftarrow\\mathsf{Setup}(R),\\\\</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">\\pi\\leftarrow\\mathsf{Prove}(crs,\\phi,w)\\end{array}\\right.\\end{array}\\right]<span class="math"> </span>=<span class="math"> </span>Pr\\left[\\begin{array}[]{c}\\mathcal{A}(R,z,crs,td,\\pi)=1\\\\</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\end{array}\\right.\\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\begin{array}[]{c}(crs,td)\\leftarrow\\mathsf{Setup}(R),\\\\</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">\\pi\\leftarrow\\mathsf{Sim}(crs,td,\\phi)\\end{array}\\right.\\end{array}\\right]$</p>

    <h3 id="sec-13" class="text-xl font-semibold mt-8">III-E Commit and Prove SNARKs</h3>

    <p class="text-gray-300">Commit and prove SNARKs (CP-SNARKs) <em>[11]</em> prove the knowledge of <span class="math">(\\phi,w)</span> such that <span class="math">u</span> is a message of commitment <span class="math">cm</span> and a relation <span class="math">R(\\phi,w)=1</span> where the witness <span class="math">u\\in w</span>.</p>

    <h6 id="sec-14" class="text-base font-medium mt-4">Definition 4.</h6>

    <p class="text-gray-300">CP-SNARKs include the quadruple PPT algorithms (KeyGen, Prove, Verify, Sim) defined as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">(crs,td)\\leftarrow\\mathsf{Setup}(ck,R)</span>: The setup algorithm takes a relation <span class="math">R\\in\\mathcal{R}_{\\lambda}</span> and commitment key ck as input, and returns a common reference string <span class="math">crs</span> and a trapdoor <span class="math">td</span>.</li>

      <li><span class="math">\\pi\\leftarrow\\mathsf{Prove}(crs,\\phi,\\{c_{j},u_{j},o_{j}\\}_{j=1}^{l},w)</span>: The prover algorithm takes as input a <span class="math">crs</span> for a relation <span class="math">R</span>, <span class="math">(\\phi,w)\\in R</span>, commitments <span class="math">c_{j}</span>, inputs <span class="math">u_{j}</span> and opening <span class="math">o_{j}</span>, and returns a proof <span class="math">\\pi</span>.</li>

      <li><span class="math">0/1\\leftarrow\\mathsf{Verify}(crs,\\phi,\\{c_{j}\\}_{j=1}^{l},\\pi)</span>: The verifier algorithm takes as input a <span class="math">crs</span>, a statement <span class="math">\\phi</span>, commitments <span class="math">c_{j}</span> and a proof <span class="math">\\pi</span>, and returns 0 (reject) or 1 (accept).</li>

      <li><span class="math">\\pi\\leftarrow\\mathsf{Sim}(crs,td,\\phi,\\{c_{j}\\}_{j=1}^{l})</span>: The simulator algorithm takes a <span class="math">crs</span>, a trapdoor <span class="math">td</span>, a statement <span class="math">\\phi</span>, and commitments <span class="math">c_{j}</span> as input, and returns a proof <span class="math">\\pi</span>.</li>

    </ul>

    <h3 id="sec-15" class="text-xl font-semibold mt-8">III-F Commit and Carry SNARKs</h3>

    <p class="text-gray-300">Similar to the case of CP-SNARKs, the commit and carry SNARKs (cc-SNARKs) scheme <em>[11]</em> proves a relation with commitment, but it generates a commitment while proving the relation.</p>

    <h6 id="sec-16" class="text-base font-medium mt-4">Definition 5.</h6>

    <p class="text-gray-300">cc-SNARKs have the quintuple of PPT algorithms (KeyGen, Prove, Verify, VerifyCom, Sim) defined as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">(ck,crs,td)\\leftarrow\\mathsf{Setup}(R)</span>: The setup algorithm takes as input a relation <span class="math">R\\in\\mathcal{R}_{\\lambda}</span>, and returns a commitment key <span class="math">ck</span>, a <span class="math">crs</span>, and a simulation trapdoor <span class="math">td</span>.</li>

      <li><span class="math">(cm,\\pi,\\nu)\\leftarrow\\mathsf{Prove}(crs,\\phi,w)</span>: The prover algorithm takes as a <span class="math">crs</span> for a relation <span class="math">R</span> and <span class="math">(\\phi=(\\psi,\\overline{\\psi}),w)\\in R</span>, and returns a commitment <span class="math">cm</span> for <span class="math">\\overline{\\psi}</span> which is a private part of <span class="math">\\phi</span>, a proof <span class="math">\\pi</span>, and an opening <span class="math">\\nu</span>.</li>

      <li><span class="math">0/1\\leftarrow\\mathsf{Verify}(crs,\\psi,cm,\\pi)</span>: The verifier algorithm takes as input a <span class="math">crs</span>, a public part of statement <span class="math">\\psi</span>, commitments <span class="math">cm</span> and a proof <span class="math">\\pi</span>, and returns 0(reject) or 1(accept).</li>

      <li><span class="math">0/1\\leftarrow\\mathsf{VerifyCom}(ck,\\overline{\\psi},\\nu,cm)</span>: The verifier algorithm takes as input a commitment key <span class="math">ck</span>, a commitments <span class="math">cm</span>, a private part of statement <span class="math">\\overline{\\psi}</span>, and an opening <span class="math">\\nu</span>, and returns 0(reject) or 1(accept).</li>

      <li><span class="math">(cm,\\pi)\\leftarrow\\mathsf{Sim}(crs,td,\\phi)</span>: The simulator algorithm takes as a <span class="math">crs</span>, a simulation trapdoor <span class="math">td</span>, and a statement <span class="math">\\phi</span>, and returns a commitment <span class="math">cm</span> and a proof <span class="math">\\pi</span>.</li>

    </ul>

    <h2 id="sec-17" class="text-2xl font-bold">IV Verifiable Convolutional Neural Network</h2>

    <p class="text-gray-300">This section constructs Verifiable Convolutional Neural Network (vCNN) scheme to prove CNNs efficiently. Convolution computations deteriorate the proving performance severely, since it requires more than 90% of total proof generation time in CNNs. First, we optimize the convolution relation utilizing QPP <em>[10]</em> and construct an efficient QPP-based zk-SNARK scheme for convolutions. Although the QPP approach improves convolution performance, QPP representation of a whole CNN degrades the performance due to the other CNN components, such as ReLU and Pooling. Hence, we propose a new efficient zk-SNARK framework for CNNs by applying QPP to convolutions and QAP to the other components, and</p>

    <p class="text-gray-300">we build a connecting proof between QPP and QAP by using CP-SNARKs technique <em>[11]</em>.</p>

    <h3 id="sec-18" class="text-xl font-semibold mt-8">III-A Optimizing Convolution Relation</h3>

    <p class="text-gray-300">The convolution filters inputs using kernels by computing the inner product for inputs and kernels, as depicted in Figure 2. Thus, convolution can be expressed as</p>

    <p class="text-gray-300"><span class="math">y_{i}=\\sum_{j\\in[l]}a_{j}\\cdot x_{i-j+l-1}</span> (3)</p>

    <p class="text-gray-300">for <span class="math">i\\in[n]</span> where <span class="math">\\{a_{j}\\}_{j\\in[l]}</span> are convolution kernels, <span class="math">\\{x_{i}\\}_{i\\in[n]}</span> are convolution inputs, and <span class="math">\\{y_{i}\\}_{i\\in[n-l]}</span> are convolution outputs. When the convolution is represented as QAP, <span class="math">n\\times l</span> multiplication gates are required, since there are <span class="math">n</span> outputs and <span class="math">l</span> multiplications per output. Figure 5 shows a small convolution example, where input size is <span class="math">5</span>, kernel size is <span class="math">3</span>, and output size is <span class="math">3</span>, hence the QAP requires <span class="math">9</span> multiplication gates.</p>

    <p class="text-gray-300"><span class="math">\\sum_{i\\in[n+l-1]}y_{i}=(\\sum_{i\\in[n]}x_{i})\\cdot(\\sum_{i\\in[l]}a_{i})</span> (4)</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Since Equation (3) is the sum of products, which requires many multiplication gates, we transform it into the product of sums as shown in Equation (4) which includes a single multiplication gate to reduce the number of multiplications. However, the naive transformation is not sound, as it is easy to find the incorrect output <span class="math">\\vec{y}^{\\prime}</span> which is different from the correct output <span class="math">\\vec{y}</span> such that sums of two outputs are equivalent. Therefore, to distinguish each output <span class="math">y_{i}</span>, we introduce an indeterminate variable <span class="math">Z</span> for each equation as shown in Equation (5) which has $O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\vec{a}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)(=O(n+l))$ multiplications.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\sum_{i\\in[n+l-1]}y_{i}\\cdot Z^{i}=(\\sum_{i\\in[n]}x_{i}\\cdot Z^{i})\\cdot(\\sum_{i\\in[l]}a_{i}\\cdot Z^{i})</span> (5)</p>

    <p class="text-gray-300">Notably, the transformation slightly increases the number of outputs by <span class="math">n+l-1</span> from that in the original Equation (3) with <span class="math">n</span> outputs.</p>

    <p class="text-gray-300">!<a href="img-5.jpeg">img-5.jpeg</a> Figure 5: Example of convolution</p>

    <p class="text-gray-300">To formulate Equation (5), we can devise two approaches: a point evaluation approach and a polynomial circuit with an indeterminate variable. In the point evaluation approach, for a polynomial of degree <span class="math">d</span>, <span class="math">d+1</span> different points should be evaluated, requiring <span class="math">O(d^{2})</span> (multiplicative) operations since there are <span class="math">d</span> multiplications per point evaluation and there are <span class="math">d+1</span> points. Point evaluation can be performed using number theoretic transform (NTT) in <span class="math">O(d\\log d)</span>. However, due to the NTT complexity, the computation overhead in NTT is severer than the naive point evaluation, unless <span class="math">d</span> is large enough.</p>

    <p class="text-gray-300">In a polynomial circuit (called Quadratic Polynomial Program (QPP) <em>[10]</em>) a wire can have a polynomial as value. Thus, we can directly express the revised equation as a single multiplication gate with two input polynomials and one output polynomial. While the point evaluation approach requires quadratic <span class="math">O(d^{2})</span> or quasi-linear <span class="math">O(d\\log d)</span> multiplication operations, the QPP approach requests <span class="math">O(d)</span> operations. Therefore, this paper adopts QPP representation for convolution.</p>

    <p class="text-gray-300">Construction of QPP-based zk-SNARKs: We construct a QPP-based zk-SNARK scheme to prove Equation (5), similar to <em>[10]</em>, except we utilize Gro16 <em>[3]</em> rather than the Pinocchio scheme <em>[2]</em>. While each wire can have only a value in QAP, QPP allows each wire to have a polynomial. The concrete QPP-based zk-SNARK scheme is as follows.</p>

    <p class="text-gray-300"><span class="math">(crs,td)\\leftarrow\\mathsf{Setup}(\\mathcal{R}_{QPP}):\\mathsf{Pick}\\ \\alpha,\\,\\beta,\\,\\gamma,\\,\\delta,\\,x,\\,z\\stackrel{{\\scriptstyle\\</span>}}{{\\leftarrow}}\\mathbb{Z}_{p}^{*}.<span class="math"> Define </span>td<span class="math">=(</span>\\alpha,\\,\\beta,\\,\\gamma,\\,\\delta,\\,x,\\,z$) and set</p>

    <p class="text-gray-300">\\[ crs=\\left(\\begin{array}[]{c}G_{1}^{\\alpha},G_{1}^{\\beta},G_{1}^{\\delta},\\{G_{1}^{x^{i}\\cdot z^{j}}\\}_{i=0,j=0}^{d_{x}-1,d_{z}},\\\\ G_{2}^{\\beta},G_{2}^{\\gamma},G_{2}^{\\delta},\\{G_{2}^{x^{i}\\cdot z^{j}}\\}_{i=0,j=0}^{d_{x}-1,d_{z}},\\\\ \\{G_{1}^{\\frac{\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x)}{\\delta}}z^{j}\\}_{i=0,j=0}^{l,d_{z}},\\\\ \\{G_{1}^{\\frac{\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x)}{\\delta}}z^{j}\\}_{i=l+1,j=0}^{m,d_{z}}\\\\ \\{G_{1}^{\\frac{x^{i}\\cdot z^{j}\\cdot t(x)}{\\delta}}\\}_{i=0,j=0}^{d_{x}-2,d_{z}}\\end{array}\\right) \\]</p>

    <p class="text-gray-300"><span class="math">\\pi\\leftarrow\\mathsf{Prove}(crs,\\phi,w)</span>: Parse <span class="math">\\phi</span> as <span class="math">(a_{0}(Z),a_{1}(Z),\\,\\ldots,\\,a_{l}(Z))</span> and <span class="math">w</span> as <span class="math">(a_{l+1}(Z),\\,\\ldots,\\,a_{m}(Z))</span>. Use the witness to compute <span class="math">h(X,Z)</span> from the QPP. Choose <span class="math">r,s\\stackrel{{\\scriptstyle\\</span>}}{{\\leftarrow}}\\mathbb{Z}_{p}^{*}<span class="math"> and output a proof </span>\\pi=(G_{1}^{a},\\,G_{2}^{b},\\,G_{1}^{c})$ such that</p>

    <p class="text-gray-300"><span class="math">a=\\alpha+\\sum_{i=0}^{m}a_{i}(z)u_{i}(x)+r\\delta\\qquad b=\\beta+\\sum_{i=0}^{m}a_{i}(z)v_{i}(x)+s\\delta</span> <span class="math">c=\\frac{\\Sigma_{i=l+1}^{m}a_{i}(z)\\cdot(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))+h(x,z)t(x)}{\\delta}</span> <span class="math">+as+rb-rs\\delta</span></p>

    <p class="text-gray-300"><span class="math">0/1\\leftarrow\\mathsf{Verify}(crs,\\phi,\\pi)</span> : Parse the statement <span class="math">\\phi</span> as <span class="math">(a_{0}(Z),a_{1}(Z),\\,\\ldots,\\,a_{l}(Z))</span> and the proof <span class="math">\\pi</span> as <span class="math">(A,B,C)</span>. Accept the proof if and only if the following equation is satisfied:</p>

    <p class="text-gray-300"><span class="math">e(A,B)=</span> <span class="math">e(G_{1}^{\\alpha},G_{2}^{\\beta})\\cdot e(\\prod_{i=0}^{l}G_{1}^{a_{i}(z)\\cdot\\frac{\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x)}{\\gamma}},G_{2}^{\\gamma})</span> <span class="math">\\cdot e(C,G_{2}^{\\delta})</span></p>

    <p class="text-gray-300"><span class="math">\\pi\\leftarrow\\mathsf{Sim}(crs,td,\\phi)</span> : Pick <span class="math">a,b\\stackrel{{\\scriptstyle\\</span>}}{{\\leftarrow}}\\mathbb{Z}_{p}^{*}<span class="math"> and compute a simulated proof </span>\\pi=(G_{1}^{a},G_{2}^{b},G_{1}^{c})$ with</p>

    <p class="text-gray-300"><span class="math">c=\\frac{ab-\\alpha\\beta-\\Sigma_{i=0}^{l}a_{i}(z)(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))}{\\delta}</span></p>

    <p class="text-gray-300">Theorem 1. The above protocol is a non-interactive zero-knowledge arguments of knowledge with completeness and perfect zero-knowledge. It has computational knowledge</p>

    <p class="text-gray-300">soundness against adversaries that only use a polynomial number of generic bilinear group operations.</p>

    <p class="text-gray-300">The QPP-based zk-SNARK scheme has the same as that of the original QAP-based zk-SNARK scheme except that in the former the terms in CRS include unknown value <span class="math">z</span> to generate a polynomial <span class="math">f(Z)</span>. We prove the knowledge soundness in Appendix A.</p>

    <p class="text-gray-300">Implementation challenge: To prove convolution in Equation (5), a prover computes <span class="math">h(X,Z)</span> by performing polynomial division (<span class="math">p(X,Z)/t(X)</span>) for Equation (2). Although the polynomial division can be efficiently performed using NTT for univariate polynomials, NTT is not directly applicable for the bivariate polynomials in QPP. Therefore, we transform bivariate polynomials to univariate polynomials. In QPP, the degree of <span class="math">X</span> in <span class="math">p(X,Z)</span> is <span class="math">2d_{x}-2</span>, where <span class="math">d_{x}</span> is the number of multiplication gates. Therefore, by setting <span class="math">Z=X^{2d_{x}-1}</span>, all terms can be distinct and the degree of <span class="math">p(X,X^{2d_{x}-1})</span> is <span class="math">(2d_{x}-1)d_{z}</span> where <span class="math">d_{z}</span> is the maximum degree of <span class="math">Z</span>. Since there is one multiplication in Equation (5), and maximum degree of <span class="math">Z</span> is <span class="math">n+l-1</span>, the degree of <span class="math">p(X,Z)</span> becomes <span class="math">n+l-1</span>. Although converting bivariate polynomials to univariate polynomials increases the equation degree, it is significantly more efficient than QAP based approaches.</p>

    <p class="text-gray-300">Although the total performance is expected to increase significantly since QPP improves convolution proving time dramatically, the actual performance for CNNs is not improved. Even if no <span class="math">Z</span> variable is required in ReLU and Pooling, the transformation of bivariate polynomials to univariate polynomials increases the degree of <span class="math">X</span>, which populates unnecessary terms. The following subsection tackles this problem.</p>

    <h3 id="sec-19" class="text-xl font-semibold mt-8">III-B Connection with ReLU and Pooling</h3>

    <p class="text-gray-300">To solve the above problem, we apply QPP to convolution and QAP to the remaining CNN modules, i.e., ReLU and Pooling, respectively. To guarantee consistency between the QAP-based ReLU and Pooling circuits and QPP-based convolution circuits, we adopt CP-SNARKs <em>[11]</em>.</p>

    <p class="text-gray-300">Construction of commit and prove SNARKs: Commit and prove SNARKs (CP-SNARKs) prove that multiple Pedersen-like commitments are constructed on the same input. We refer to the scheme in LegoSNARK’s Appendix. D <em>[11]</em>. Setup takes two commitment keys, <span class="math">ck</span> and <span class="math">ck^{\\prime}</span> as inputs and combines them to generate a CRS. Prove creates a new proof <span class="math">\\pi</span> in which the commitments are combined. If commitments <span class="math">c</span> and <span class="math">c^{\\prime}</span> were made using the same input, proof <span class="math">\\pi</span> passes verification.</p>

    <p class="text-gray-300"><span class="math">(crs,td)\\leftarrow\\texttt{Setup}(\\mathcal{R}_{cp},ck,ck^{\\prime}):</span> parse <span class="math">ck=\\{G_{1}^{h_{i}}\\}_{i=0}^{l}</span>, <span class="math">ck^{\\prime}=\\{G_{1}^{f_{i}}\\}_{i=0}^{l}</span>. Pick <span class="math">k_{1},k_{2},a\\stackrel{{\\scriptstyle\\</span>}}{{\\leftarrow}}\\mathbb{Z}_{p}<span class="math"> and set </span>crs=(G_{1}^{k_{1}\\cdot h_{0}}<span class="math">, </span>G_{1}^{k_{2}\\cdot f_{0}}<span class="math">, </span>\\{G_{1}^{k_{1}\\cdot h_{i}+k_{2}\\cdot f_{i}}\\}_{i=1}^{l}<span class="math">, </span>G_{2}^{ak_{1}}<span class="math">, </span>G_{2}^{ak_{2}}<span class="math">, </span>G_{2}^{a})<span class="math"> and trapdoor </span>td=(k_{1},k_{2})$.</p>

    <p class="text-gray-300"><span class="math">\\pi\\leftarrow\\texttt{Prove}(crs,\\phi,w)</span>: parse <span class="math">r,r^{\\prime},\\{u_{i}\\}_{i=1}^{l}\\in w</span> and <span class="math">(A</span>, <span class="math">B</span>, <span class="math">\\{C_{i}\\}_{i=1}^{l}</span>, <span class="math">vk_{1}</span>, <span class="math">vk_{2}</span>, <span class="math">vk_{3})\\in crs</span>. Compute <span class="math">\\pi</span> as</p>

    <p class="text-gray-300"><span class="math">\\pi=A^{r}\\cdot B^{r^{\\prime}}\\cdot\\prod_{i=1}^{l}C_{i}^{a_{i}}</span> (6)</p>

    <p class="text-gray-300"><span class="math">1/0\\leftarrow\\texttt{Verify}(crs,\\phi,\\pi)</span>: parse <span class="math">c</span>, <span class="math">c^{\\prime}\\in\\phi</span> and <span class="math">(A</span>, <span class="math">B</span>, <span class="math">\\{C_{i}\\}_{i=1}^{l}</span>, <span class="math">vk_{1}</span>, <span class="math">vk_{2}</span>, <span class="math">vk_{3})\\in crs</span>. Accept the proof iff the following equation is satisfied:</p>

    <p class="text-gray-300"><span class="math">e(c,vk_{1})\\cdot e(c^{\\prime},vk_{2})=e(\\pi,vk_{3})</span></p>

    <p class="text-gray-300"><span class="math">\\pi\\leftarrow\\texttt{Sim}(crs,td,\\phi)</span>: parse <span class="math">k_{1},k_{2}\\in td</span> and <span class="math">c,c^{\\prime}\\in\\phi</span>. Compute a proof <span class="math">\\pi</span> as</p>

    <p class="text-gray-300"><span class="math">\\pi=c^{k_{1}}\\cdot c^{\\prime k_{2}}</span></p>

    <p class="text-gray-300">Construction of cc-SNARKs from zk-SNARKs: To prove that the same data are used in different zk-SNARKs using CP-SNARKs, commitments should be generated in zk-SNARKs, which is called cc-SNARKs. Fortunately, since the zk-SNARK scheme in the previous subsection computes a Pedersen-like commitment in verification, the cc-SNARK scheme can be naturally constructed by utilizing the Pedersen-like commitment without any additional overhead. Note that the Pedersen-like commitment in the verification is as follows:</p>

    <p class="text-gray-300"><span class="math">\\prod_{i=0}^{l}G_{1}^{a_{i}(z)\\cdot y(x)}=\\prod_{i\\in[l],j\\in[d_{z}+1]}\\left(G_{1}^{y(x)\\cdot z^{j}}\\right)^{a_{i,j}}</span></p>

    <p class="text-gray-300">where <span class="math">y(x)=\\frac{\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x)}{\\gamma}</span>.</p>

    <p class="text-gray-300">We describe algorithms in cc-SNARKs based on zk-SNARKs focusing on additional procedures. Setup adds a commitment key <span class="math">G_{1}^{\\frac{\\pi}{2}}</span> and a random <span class="math">G_{1}^{\\frac{\\pi}{2}}</span> to the CRS. Prove generates a commitment <span class="math">G_{1}^{d}</span>, and adds the <span class="math">-\\nu\\frac{\\eta}{\\delta}</span> term to <span class="math">c</span> to cancel out the random part of the commitment during verification. Verify takes <span class="math">cm</span> as input and verifies proof <span class="math">\\pi</span>. A new algorithm VerifyCom verifies the commitment <span class="math">cm</span>. The concrete algorithms are as follows.</p>

    <p class="text-gray-300"><span class="math">(cm,\\pi,\\nu)\\leftarrow\\texttt{Prove}(crs,\\phi,w)</span>: Parse <span class="math">\\phi</span> as <span class="math">\\psi=(a_{0}(Z),a_{1}(Z)</span>, <span class="math">\\ldots</span>, <span class="math">a_{c}(Z))</span>, and <span class="math">\\overline{\\psi}=(a_{c+1}(Z),a_{c+2}(Z)</span>, <span class="math">\\ldots</span>, <span class="math">a_{l}(Z))</span> and <span class="math">w</span> as <span class="math">(a_{l+1}(Z)</span>, <span class="math">\\ldots</span>, <span class="math">a_{m}(Z))</span>. Use the witness to compute <span class="math">h(X,Z)</span> from the QPP. Choose <span class="math">r,s,\\nu\\stackrel{{\\scriptstyle\\</span>}}{{\\leftarrow}}\\mathbb{Z}_{p}^{*}<span class="math"> and output a random </span>\\nu<span class="math">, a commitment </span>cm=G_{1}^{d}<span class="math">, and a proof </span>\\pi<span class="math"> </span>=(G_{1}^{a}<span class="math">, </span>G_{2}^{b}<span class="math">, </span>G_{1}^{c})$ such that</p>

    <p class="text-gray-300"><span class="math">a=</span> <span class="math">\\alpha+\\sum_{i=0}^{m}a_{i}(z)u_{i}(x)+r\\delta\\qquad b=\\beta+\\sum_{i=0}^{m}a_{i}(z)v_{i}(x)+s\\delta</span> <span class="math">c=</span> <span class="math">\\frac{\\sum_{i=l+1}^{m}a_{i}(z)\\cdot(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))+h(x,z)t(x)}{\\delta}</span> <span class="math">\\qquad\\qquad\\qquad\\qquad+As+rB-rs\\delta-\\nu\\frac{\\eta}{\\delta}</span> <span class="math">d=</span> <span class="math">\\frac{\\sum_{i=c+1}^{l}a_{i}(z)\\cdot(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))}{\\gamma}+\\nu\\frac{\\eta}{\\gamma}</span></p>

    <p class="text-gray-300"><span class="math">0/1\\leftarrow\\texttt{Verify}(crs,\\psi,cm,\\pi)</span> : Parse the proof <span class="math">\\psi</span> as <span class="math">(a_{0}(Z),a_{1}(Z)</span>, <span class="math">\\ldots</span>, <span class="math">a_{c}(Z))</span> and <span class="math">\\pi</span> as <span class="math">(A,B,C)</span>. Accept the proof iff the following equation is satisfied:</p>

    <p class="text-gray-300"><span class="math">e(A,B)=</span> <span class="math">e(G_{1}^{c},G_{2}^{\\beta})\\cdot e(cm,G_{2}^{\\gamma})</span> <span class="math">\\qquad\\qquad\\qquad\\qquad\\cdot e(G_{1}^{\\frac{\\sum_{i=0}^{c}a_{i}(z)\\cdot(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))}{\\gamma}},G_{2}^{\\gamma})\\cdot e(C,G_{2}^{\\delta})</span></p>

    <p class="text-gray-300"><span class="math">0/1\\leftarrow\\text{VerifyCom}(ck,\\overline{\\psi},\\nu,cm)</span> : Parse <span class="math">\\overline{\\psi}</span> as <span class="math">(a_{c+1}(Z),a_{c+2}(Z)</span>, <span class="math">\\ldots</span>, <span class="math">a_{l}(Z))</span>. Accept the proof iff the following equation is satisfied:</p>

    <p class="text-gray-300"><span class="math">cm=G_{1}^{\\sum_{i=c+1}^{l}a_{i}(z)\\cdot(\\beta u_{i}(x)+\\alpha v_{i}(x)+\\vphantom{\\frac{1}{2}}w_{i}(x))}\\cdot G_{1}^{\\nu\\frac{\\eta}{2}}</span></p>

    <p class="text-gray-300"><span class="math">(\\nu,cm,\\pi)\\leftarrow\\text{Sim}(crs,td,\\phi)</span> : Pick <span class="math">a,b,\\nu\\stackrel{{\\scriptstyle\\</span>}}{{\\leftarrow}}\\mathbb{Z}_{p}^{*}<span class="math"> and compute a simulated commitment </span>cm=G_{1}^{d}<span class="math"> and simulated proof </span>\\pi=(G_{1}^{a},G_{2}^{b},G_{1}^{c})$ with</p>

    <p class="text-gray-300"><span class="math">c</span> <span class="math">=\\frac{ab-\\alpha\\beta-\\sum_{i=0}^{l}a_{i}(z)(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))-\\nu\\eta}{\\delta}</span> <span class="math">d</span> <span class="math">=\\frac{\\sum_{i=0}^{l}a_{i}(z)(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))+\\nu\\eta}{\\gamma}</span></p>

    <h6 id="sec-20" class="text-base font-medium mt-4">Theorem 2.</h6>

    <p class="text-gray-300">The protocol given above is a non-interactive zero-knowledge arguments of knowledge with completeness and perfect zero-knowledge. It has computational knowledge soundness against adversaries that only use a polynomial number of generic bilinear group operations.</p>

    <p class="text-gray-300">The proof for Theorem 2 is available in Appendix A. We omit the concrete construction and security proof for the QAP-based cc-SNARKs here since it is a special case of the QPP-based cc-SNARKs; the degree of <span class="math">Z</span> is zero.</p>

    <h3 id="sec-21" class="text-xl font-semibold mt-8">IV-C Main Construction of vCNN</h3>

    <p class="text-gray-300">The proposed vCNN proves CNNs using cc-SNARKs and CP-SNARKs. The relation of CNNs, <span class="math">\\mathcal{R}_{CNN}</span>, comprises <span class="math">\\mathcal{R}_{convol}</span>, <span class="math">\\mathcal{R}_{ReLU+Pool}</span>, and <span class="math">\\mathcal{R}_{cp}</span>, where <span class="math">\\mathcal{R}_{convol}</span> is encoded in QPP and <span class="math">\\mathcal{R}_{ReLU+Pool}</span> is in QAP. Let <span class="math">\\Pi_{qap}=(\\text{Setup, Prove, Verify, VerifyCom, Sim})</span> be a QAP-based cc-SNARK scheme, <span class="math">\\Pi_{qpp}=(\\text{Setup, Prove, Verify, VerifyCom, Sim})</span> be a QPP-based cc-SNARK scheme, and <span class="math">\\Pi_{cp}=(\\text{Setup, Prove, Verify, Sim})</span> be a CP-SNARK scheme.</p>

    <p class="text-gray-300"><span class="math">(crs,td)\\leftarrow\\text{Setup}(\\mathcal{R}_{CNN})</span> : Parse <span class="math">\\mathcal{R}_{CNN}</span> as relation of convolution <span class="math">\\mathcal{R}_{convol}</span>, and ReLU and Pooling <span class="math">\\mathcal{R}_{ReLU+Pool}</span>. Compute common reference string <span class="math">crs</span> and trapdoor <span class="math">td</span> as follows:</p>

    <p class="text-gray-300"><span class="math">ck_{qap},crs_{qap},td_{qap}\\leftarrow\\Pi_{qap}.\\text{Setup}(\\mathcal{R}_{ReLU+Pool})</span> <span class="math">ck_{qpp},crs_{qpp},td_{qpp}\\leftarrow\\Pi_{qpp}.\\text{Setup}(\\mathcal{R}_{conv})</span> <span class="math">crs_{cp},td_{cp}\\leftarrow\\Pi_{cp}.\\text{Setup}(\\mathcal{R}_{cp},ck_{qap},ck_{qpp})</span></p>

    <p class="text-gray-300">Set <span class="math">crs=(crs_{qap},crs_{qpp},crs_{cp})</span> and <span class="math">td=(td_{qap},td_{qpp},td_{cp})</span>.</p>

    <p class="text-gray-300"><span class="math">\\pi\\leftarrow\\text{Prove}(crs,\\phi,w)</span>: Parse (<span class="math">\\phi</span>, <span class="math">w</span>) as (<span class="math">\\phi_{qap},w_{qap}</span>) and (<span class="math">\\phi_{qpp},w_{qpp}</span>). Parse <span class="math">crs</span> as <span class="math">(crs_{qap}</span>, <span class="math">crs_{qpp}</span>, <span class="math">crs_{cp})</span>. Compute a proof as follows:</p>

    <p class="text-gray-300"><span class="math">\\pi_{qap},r_{qap},cm_{qap}\\leftarrow\\Pi_{qap}.\\text{Prove}(crs_{qap},\\phi_{qap},w_{qap})</span> <span class="math">\\pi_{qpp},r_{qpp},cm_{qpp}\\leftarrow\\Pi_{qpp}.\\text{Prove}(crs_{qpp},\\phi_{qpp},w_{qpp})</span> <span class="math">\\phi_{cp}=(cm_{qap},cm_{qpp})</span> <span class="math">parse\\quad\\phi_{qap}\\quad as\\quad(\\psi_{qap},\\overline{\\psi}_{qap})</span> <span class="math">parse\\quad\\phi_{qpp}\\quad as\\quad(\\psi_{qpp},\\overline{\\psi}_{qpp})</span> <span class="math">w_{cp}=(r_{qap},\\overline{\\psi}_{qap},r_{qpp},\\overline{\\psi}_{qpp})</span> <span class="math">\\pi_{cp}\\leftarrow\\Pi_{cp}.\\text{Prove}(crs_{cp},\\phi_{cp},w_{cp})</span></p>

    <p class="text-gray-300">Set <span class="math">\\pi=(\\pi_{qap},\\pi_{qpp},\\pi_{cp},cm_{qap},cm_{qpp})</span>.</p>

    <p class="text-gray-300"><span class="math">0/1\\leftarrow\\text{Verify}(crs,\\psi,\\pi)</span> : Parse <span class="math">\\psi</span> = (<span class="math">\\psi_{qap}</span>, <span class="math">\\psi_{qpp}</span>). Parse <span class="math">crs</span> as <span class="math">(crs_{qap}</span>, <span class="math">crs_{qpp}</span>, <span class="math">crs_{cp})</span> and <span class="math">\\pi</span> as <span class="math">(\\pi_{qap}</span>, <span class="math">\\pi_{qpp}</span>, <span class="math">\\pi_{cp}</span>, <span class="math">cm_{qap}</span>, <span class="math">cm_{qpp})</span>. And parse <span class="math">\\pi_{qap}=(A_{qap}</span>, <span class="math">B_{qap}</span>, <span class="math">C_{qap})</span> and <span class="math">\\pi_{qpp}=(A_{qpp}</span>, <span class="math">B_{qpp}</span>, <span class="math">C_{qpp})</span>. Accept the proof iff the following equation is satisfied:</p>

    <p class="text-gray-300"><span class="math">assert\\quad\\Pi_{qap}.\\text{Verify}(crs_{qap},\\psi_{qap},cm_{qap},\\pi_{qap})=1</span> <span class="math">assert\\quad\\Pi_{qpp}.\\text{Verify}(crs_{qpp},\\psi_{qpp},cm_{qpp},\\pi_{qpp})=1</span> <span class="math">assert\\quad\\Pi_{cp}.\\text{Verify}(crs_{cp},(cm_{qap},cm_{qpp}),\\pi_{cp})=1</span></p>

    <p class="text-gray-300"><span class="math">\\pi\\leftarrow\\text{Sim}(crs,td,\\phi)</span> :Parse <span class="math">\\phi</span>=(<span class="math">\\phi_{qap}</span>,<span class="math">\\phi_{qpp}</span>) and <span class="math">td</span> = <span class="math">(td_{qap},td_{qpp},td_{cp})</span>. Compute a proof <span class="math">\\pi</span> as follows:</p>

    <p class="text-gray-300"><span class="math">cm_{qap},\\pi_{qap}\\leftarrow\\Pi_{qap}.\\text{Sim}(crs_{qap},td_{qap},\\phi_{qap})</span> <span class="math">cm_{qpp},\\pi_{qpp}\\leftarrow\\Pi_{qpp}.\\text{Sim}(crs_{qpp},td_{qpp},\\phi_{qpp})</span> <span class="math">\\phi_{cp}=(cm_{qap},cm_{qpp})</span> <span class="math">\\pi_{cp}\\leftarrow\\Pi_{cp}.\\text{Sim}(crs_{cp},td_{cp},\\phi_{cp})</span></p>

    <p class="text-gray-300">Set <span class="math">\\pi=(\\pi_{qap},\\pi_{qpp},\\pi_{cp},cm_{qap},cm_{qpp})</span>.</p>

    <h6 id="sec-22" class="text-base font-medium mt-4">Theorem 3.</h6>

    <p class="text-gray-300">If <span class="math">\\Pi_{qap}</span>, <span class="math">\\Pi_{qpp}</span>, and <span class="math">\\Pi_{cp}</span> are computationally knowledge sound and perfect zero-knowledge, then the protocol given above is a non-interactive zero-knowledge arguments of knowledge with completeness and perfect zero-knowledge. It has computational knowledge soundness against adversaries that only use a polynomial number of generic bilinear group operations.</p>

    <p class="text-gray-300">The proposed vCNN scheme generates a constant size proof regardless of the number of layers in the neural network models. Note that since the constraint relations are checked in proof systems, the computation order can be ignored. Therefore, we can build proofs for QPP and QAP at once using given values without iterating layers. Consequently, the proposed vCNN generates 9 group elements as proof: three for QAP, three for QPP, two for commitment, and one for CP-SNARKs.</p>

    <h3 id="sec-23" class="text-xl font-semibold mt-8">IV-D Extension for Privacy Protection</h3>

    <p class="text-gray-300">The privacy of the data is required when the generated proof is verified by a third party. If a commitment is used as input rather than values in proof verification then the privacy can be supported. The naive method to support commitment is to include a relation of ”cm=commit(s)” in the circuit where values <span class="math">x</span> are provided as witness. Instead of adopting</p>

    <p class="text-gray-300">the commitment circuit, if we use CP-SNARKs then we can accelerate the proving performance.</p>

    <p class="text-gray-300">We perform Pedersen vector commitment to CNNs’ input (or weight) values to use CP-SNARKs.</p>

    <p class="text-gray-300"><span class="math">(cm,r)\\leftarrow\\texttt{Commit}(ck,\\psi)\\colon\\text{Parse }ck\\text{ as }(G_{1}^{ck_{0}},\\,G_{1}^{ck_{1}},\\ldots,G_{1}^{ck_{l}})</span> and <span class="math">\\psi</span> as (<span class="math">a_{1},\\ldots,a_{l}</span>). Choose <span class="math">r\\stackrel{{\\scriptstyle\\</span>}}{{\\leftarrow}}\\mathbb{Z}_{p}^{*}$. Compute a commitment as follows:</p>

    <p class="text-gray-300"><span class="math">cm=G_{1}^{ck_{0}\\cdot r}\\prod_{i=1}^{l}G_{1}^{ck_{i}\\cdot a_{i}}</span></p>

    <p class="text-gray-300">CP-SNARKs proves that value <span class="math">a_{i}</span> in the commitment <span class="math">cm</span> is equivalent to values used for the commitments in QAP and QPP. A commitment key <span class="math">G_{1}^{ck_{i}}</span> is included in CRS. Note that <span class="math">ck_{i}=0</span> if value <span class="math">a_{i}</span> is not included in commitment <span class="math">cm</span>. In the following we describe the CP-SNARKs construction. For better delivery, the differences are highlighted in blue.</p>

    <p class="text-gray-300"><span class="math">(crs,td)\\leftarrow\\texttt{Setup}(\\mathcal{R}_{cp},ck_{qap},ck_{qpp},ck):\\text{parse }ck_{qap}=\\{G_{1}^{h_{i}}\\}_{i=0}^{l}</span>, <span class="math">ck_{qpp}=\\{G_{1}^{f_{i}}\\}_{i=0}^{l}</span>, and <span class="math">ck=\\{G_{1}^{ck_{i}}\\}_{i=0}^{l}</span>. Pick <span class="math">k_{1}</span>, <span class="math">k_{2}</span>, <span class="math">k_{3}</span>, <span class="math">a\\stackrel{{\\scriptstyle\\</span>}}{{\\leftarrow}}\\mathbb{Z}_{p}<span class="math"> and set </span>crs=(G_{1}^{k_{1}\\cdot h_{0}},\\,G_{1}^{k_{2}\\cdot f_{0}},\\,G_{1}^{k_{3}\\cdot ck_{0}}\\{G_{1}^{k_{1}\\cdot h_{i}+k_{2}\\cdot f_{i}+k_{3}\\cdot ck_{i}}\\}_{i=1}^{l}<span class="math">, </span>G_{2}^{ak_{1}},\\,G_{2}^{ak_{2}},\\,G_{2}^{ak_{3}},\\,G_{2}^{a})<span class="math"> and trap-door </span>td=(k_{1}<span class="math">, </span>k_{2}<span class="math">, </span>k_{3}$).</p>

    <p class="text-gray-300"><span class="math">\\pi\\leftarrow\\texttt{Prove}(crs,\\phi,w)\\colon\\text{parse }r_{qap}</span>, <span class="math">r_{qpp}</span>, <span class="math">r</span>, <span class="math">\\{u_{i}\\}_{i=1}^{l}</span> <span class="math">\\in</span> <span class="math">w</span> and <span class="math">(A</span>, <span class="math">B</span>, <span class="math">C</span>, <span class="math">\\{D_{i}\\}_{i=1}^{l}</span>, <span class="math">vk_{1}</span>, <span class="math">vk_{2}</span>, <span class="math">vk_{3}</span>, <span class="math">vk_{4})\\in crs</span>. Compute <span class="math">\\pi</span> as</p>

    <p class="text-gray-300"><span class="math">\\pi=A^{r_{qap}}\\cdot B^{r_{qpp}}\\cdot C^{r}\\cdot\\prod_{i=1}^{l}D_{i}^{u_{i}}</span></p>

    <p class="text-gray-300"><span class="math">1/0\\leftarrow\\texttt{Verify}(crs,\\phi,\\pi)\\colon\\text{parse }cm_{qap}</span>, <span class="math">cm_{qpp}</span>, <span class="math">cm\\in\\phi</span> and <span class="math">(A</span>, <span class="math">B</span>, <span class="math">C</span>, <span class="math">\\{D_{i}\\}_{i=1}^{l}</span>, <span class="math">vk_{1}</span>, <span class="math">vk_{2}</span>, <span class="math">vk_{3}</span>, <span class="math">vk_{4})\\in crs</span>. Accept the proof iff the following equation is satisfied:</p>

    <p class="text-gray-300"><span class="math">e(cm_{qap},vk_{1})\\cdot e(cm_{qpp},vk_{2})\\cdot e(cm,vk_{3})=e(\\pi,vk_{4})</span></p>

    <p class="text-gray-300"><span class="math">\\pi\\leftarrow\\texttt{Sim}(crs,td,\\phi)\\colon\\text{parse }k_{1}</span>, <span class="math">k_{2}</span>, <span class="math">k_{3}\\in td</span> and <span class="math">cm_{qap}</span>, <span class="math">cm_{qpp}</span>, <span class="math">cm\\in\\phi</span>. Compute a proof <span class="math">\\pi</span> as</p>

    <p class="text-gray-300"><span class="math">\\pi=cm_{qap}^{k_{1}}\\cdot cm_{qpp}^{k_{2}}\\cdot cm^{k_{3}}</span></p>

    <p class="text-gray-300">Finally, we construct a vCNN to provide input privacy with the revised CP-SNARKs which receives commitment <span class="math">cm</span> as input.</p>

    <h2 id="sec-24" class="text-2xl font-bold">V Experiment</h2>

    <p class="text-gray-300">This section compares the proving performance and the CRS size in vCNN with existing zk-SNARKs scheme (Gro16) <em>[3]</em>. Note that embedded proof <em>[18]</em> doubles the proving performance compared with Gro16 while its computational complexity remains. It is reasonable to speculate that the performance result is double in the embedded proof compared with Gro16 for applications in this section even if the experimental result of the embedded proof is not included.</p>

    <p class="text-gray-300">As real applications, we utilize LeNet-5 <em>[32]</em>, AlexNet <em>[33]</em>, and VGG16 <em>[9]</em> models. We execute them on a Quad-core Intel CPU i5 3.4 GHz and Ubuntu 16.04.</p>

    <h3 id="sec-25" class="text-xl font-semibold mt-8">V-A Convolutions</h3>

    <p class="text-gray-300">We first compare the performance and the size for convolutions in the proposed scheme with the existing scheme <em>[3]</em>. Figures 6 and 7 illustrate the setup and the proof generation time, and the CRS size, respectively by varying the input size and the kernel depth (or channel). Since the proposed convolution optimization reduces the complexity of the proving time and the CRS size to the addition of the input size and the kernel depth from the multiplication, the performance gain increases as the kernel depth increases.</p>

    <h3 id="sec-26" class="text-xl font-semibold mt-8">V-B Convolutional Neural Networks</h3>

    <p class="text-gray-300">We compare the proposed vCNN scheme with Gro16 scheme on various deep neural models from small CNNs to real large models.</p>

    <p class="text-gray-300">Small size CNNs: Figures 8 and 9 illustrate the experimental results for a small CNN with one convolution layer and one pooling layer. Figures 8 (a), (b), and (c) show the setup time, the proving time, and the CRS size, respectively, by varying the convolution input size where the kernel size is <span class="math">10</span>, the kernel depth is <span class="math">3</span>, and the quantization bit depth is <span class="math">10</span>. Figure 9 increases the kernel depth to 15 while the other parameters remain. In vCNN, the setup time is 2.6x faster , the proving time is 3.3x faster, and the CRS size is 3.3x smaller than Gro16 when the kernel size is 10. The setup time is up to 9x faster, the proving time is 7.5x faster, and the CRS size is 12.3x smaller as the kernel size becomes 50.</p>

    <p class="text-gray-300">Figure 10 shows the result for a MNIST CNN model which consists of a single convolution and pooling layer with the 9 (= <span class="math">3\\times 3</span>) sized kernel and the 64 sized kernel depth by varying the quantization bit depth from 16 to 32. Since non-linear functions, such as ReLU, are required to be encoded into bitwise operations, both the proving time and the CRS size increase proportionally to the quantization bit depth. The setup and the proof generation performance is up to 20x higher and the CRS size is up to 30x smaller in vCNN than Gro16 when the quantization bit depth is <span class="math">32</span>.</p>

    <p class="text-gray-300">Figure 11 illustrates multi-layer CNNs on the MNIST dataset when the kernel size is 9 (=<span class="math">3\\times 3</span>) and the quantization bit depth is 10. In this model, convolution and pooling (including ReLU) layers alternate. The <span class="math">x</span> axis represents the number of layers, e.g., the model with 2 layers consists of a convolution and a pooling layer, whereas in the model with 6 layers there are three convolution layers and three pooling layers, respectively. Each convolution layer has a different kernel depth. Kernel depths are given as 32, 64, and 128 for the first, the second, and the third convolution layer, respectively. Figures 11 (a)-(c) show that for the two layer model, the setup time is 10.6x faster, the proving time is 12x faster, and the CRS size is 14.5x smaller in vCNN than Gro16. The proposed vCNN generates a proof in less than 11 seconds with 55MB size CRS while the Gro16 scheme fails to generate proofs when the number of layers is more than two due to the large run-time memory requirement.</p>

    <p class="text-gray-300">!<a href="img-6.jpeg">img-6.jpeg</a> (a) kernel depth  <span class="math">= 1</span></p>

    <p class="text-gray-300">!<a href="img-7.jpeg">img-7.jpeg</a> (b) kernel depth=3</p>

    <p class="text-gray-300">!<a href="img-8.jpeg">img-8.jpeg</a> (c) kernel depth=5</p>

    <p class="text-gray-300">!<a href="img-9.jpeg">img-9.jpeg</a> Fig. 6: Proving time in Gro16 and vCNN for convolutions where the kernel size is 10 (a) kernel depth=1</p>

    <p class="text-gray-300">!<a href="img-10.jpeg">img-10.jpeg</a> (b) kernel depth=3</p>

    <p class="text-gray-300">!<a href="img-11.jpeg">img-11.jpeg</a> (c) kernel depth=5</p>

    <p class="text-gray-300">!<a href="img-12.jpeg">img-12.jpeg</a> Fig. 7: CRS size in Gro16 and vCNN for convolutions where the kernel size is 10 (a)</p>

    <p class="text-gray-300">!<a href="img-13.jpeg">img-13.jpeg</a> (b) Fig. 8: Comparison between vCNN and Gro16 [3] when the kernel size  <span class="math">= 10</span> , the kernel depth size  <span class="math">= 3</span> , and the quantization bit depth  <span class="math">= 10</span>  bits</p>

    <p class="text-gray-300">!<a href="img-14.jpeg">img-14.jpeg</a> (c)</p>

    <p class="text-gray-300">Real CNNs: We evaluate vCNN on several canonical CNNs models: LeNet-5 [32], AlexNet [33], VGG16 and VGG16wFC [9]. We utilize the average pool rather than the max pool since the average pool requires a smaller circuit than the max pool. In LeNet-5, AlexNet, and VGG16, the fully connected layers are not considered while VGG16wFC includes the fully connected layers.</p>

    <p class="text-gray-300">Figures 12, 13, and 14 show the proving time and the CRS size for AlexNet, VGG16, VGG16wFC in vCNN, respectively. To evaluate various size models, we introduce a scale factor which reduces the kernel depth and the input size. For</p>

    <p class="text-gray-300">example,  <span class="math">\\left(\\frac{1}{32},\\frac{1}{7}\\right)</span>  denotes that the kernel depth decreases by  <span class="math">\\frac{1}{32}</span>  and the input size by  <span class="math">\\frac{1}{7}</span>  in every layer. Note that (1,1) represents the real model. As shown in the figures, the proving performance and the CRS size are proportional to the number of arithmetic gates in CNN circuits. Note that the results with a scale factor (1,1) in AlexNet, and scale factors larger than (1/2,1/7) in VGG16 are estimated values based on the number of gates.</p>

    <p class="text-gray-300">Table II summarizes the performance and the size in vCNN and Gro16 [3]. In the table, we estimate the results in Gro16 due to insufficient memory. In vCNN, the setup time,</p>

    <p class="text-gray-300">!<a href="img-15.jpeg">img-15.jpeg</a> (a)</p>

    <p class="text-gray-300">!<a href="img-16.jpeg">img-16.jpeg</a> (b) Fig. 9: Comparison between vCNN and Gro16 [3] when kernel size  <span class="math">= 10</span> , depth size  <span class="math">= 15</span> , and quantization bit depth  <span class="math">= 10</span>  bits</p>

    <p class="text-gray-300">!<a href="img-17.jpeg">img-17.jpeg</a> (c)</p>

    <p class="text-gray-300">TABLE II: Comparison between vCNN and Gro16 for real CNN models</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">vCNN</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Gro16</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">setup</td>

            <td class="px-3 py-2 border-b border-gray-700">prove</td>

            <td class="px-3 py-2 border-b border-gray-700">verify</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">CRS</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">proof</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">setup</td>

            <td class="px-3 py-2 border-b border-gray-700">prove</td>

            <td class="px-3 py-2 border-b border-gray-700">verify</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">CRS</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">proof</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">LeNet-5</td>

            <td class="px-3 py-2 border-b border-gray-700">19.47 s</td>

            <td class="px-3 py-2 border-b border-gray-700">9.34 s</td>

            <td class="px-3 py-2 border-b border-gray-700">75ms</td>

            <td class="px-3 py-2 border-b border-gray-700">40.07MB</td>

            <td class="px-3 py-2 border-b border-gray-700">2803 bits</td>

            <td class="px-3 py-2 border-b border-gray-700">1.5 hours</td>

            <td class="px-3 py-2 border-b border-gray-700">0.75 hours</td>

            <td class="px-3 py-2 border-b border-gray-700">75ms</td>

            <td class="px-3 py-2 border-b border-gray-700">11 GB</td>

            <td class="px-3 py-2 border-b border-gray-700">1019 bits</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">AlexNet</td>

            <td class="px-3 py-2 border-b border-gray-700">20 min</td>

            <td class="px-3 py-2 border-b border-gray-700">18 min</td>

            <td class="px-3 py-2 border-b border-gray-700">130ms</td>

            <td class="px-3 py-2 border-b border-gray-700">2.1 GB</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">16 days</td>

            <td class="px-3 py-2 border-b border-gray-700">14 days</td>

            <td class="px-3 py-2 border-b border-gray-700">130 ms</td>

            <td class="px-3 py-2 border-b border-gray-700">2.5 TB</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">VGG16</td>

            <td class="px-3 py-2 border-b border-gray-700">10 hours</td>

            <td class="px-3 py-2 border-b border-gray-700">8 hours</td>

            <td class="px-3 py-2 border-b border-gray-700">19.4s</td>

            <td class="px-3 py-2 border-b border-gray-700">83 GB</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">13 years</td>

            <td class="px-3 py-2 border-b border-gray-700">10 years</td>

            <td class="px-3 py-2 border-b border-gray-700">19.4s</td>

            <td class="px-3 py-2 border-b border-gray-700">1400 TB</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">VGG16wFC</td>

            <td class="px-3 py-2 border-b border-gray-700">2 days</td>

            <td class="px-3 py-2 border-b border-gray-700">2 days</td>

            <td class="px-3 py-2 border-b border-gray-700">19.4s</td>

            <td class="px-3 py-2 border-b border-gray-700">420 GB</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">13 years</td>

            <td class="px-3 py-2 border-b border-gray-700">10 years</td>

            <td class="px-3 py-2 border-b border-gray-700">19.4s</td>

            <td class="px-3 py-2 border-b border-gray-700">1400 TB</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">the proving time, and the CRS size are  <span class="math">291\\mathbf{x}</span>  faster and smaller in vCNN than Gro16 for LeNet-5. Similarly, they are  <span class="math">1200\\mathbf{x}</span>  faster and smaller than Gro16 for AlexNet;  <span class="math">18000\\mathbf{x}</span>  for VGG16;  <span class="math">3400\\mathbf{x}</span>  for VGG16 with FC. Note that Gro16 would require more than 10 years to generate a proof for VGG16. The verification time is equivalent for all applications in both vCNN and Gro16. Note that if the time to check the commitment to the input data is excluded then the verification time is less than 50ms for every application.</p>

    <p class="text-gray-300">In this paper, we propose a new efficient zk-SNARKs scheme called vCNN which can generate a proof rapidly for convolutional neural network models. We devise a new relation representation for convolutions, which reduces the computational complexity. The experimental results show that the proposed vCNN scheme reduces the proving time and the CRS size approximately 18,000x for the canonical CNN models on VGG16. The proposed scheme is proven to be perfectly zero-knowledge and computationally knowledge sound. Designing an efficient verifiable CNN training scheme will be our future work.</p>

    <p class="text-gray-300">[1] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing adversarial examples,” arXiv preprint arXiv:1412.6572, 2014. [2] B. Parno, J. Howell, C. Gentry, and M. Raykova, “Pinocchio: nearly practical verifiable computation,” Commun. ACM, vol. 59, no. 2, pp. 103–112, 2016. [Online]. Available: http://doi.acm.org/10.1145/2856449 [3] J. Groth, "On the size of pairing-based non-interactive arguments," in Advances in Cryptology - EUROCRYPT 2016 - 35th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Vienna, Austria, May 8-12, 2016, Proceedings, Part II, 2016, pp. 305-326. [Online]. Available: https://doi.org/10.1007/978-3-662-49896-5_11</p>

    <p class="text-gray-300">[4] R. Gennaro, C. Gentry, B. Parno, and M. Raykova, "Quadratic span programs and succinct nizks without pcps," in Advances in Cryptology - EUROCRYPT 2013, 32nd Annual International Conference on the Theory and Applications of Cryptographic Techniques, Athens, Greece, May 26-30, 2013. Proceedings, 2013, pp. 626-645. [Online]. Available: https://doi.org/10.1007/978-3-642-38348-9_37 [5] S. Goldwasser, G. N. Rothblum, and Y. T. Kalai, "Delegating computation: Interactive proofs for muggles," Electronic Colloquium on Computational Complexity (ECCC), vol. 24, p. 108, 2017. [Online]. Available: https://eccc.weizmann.ac.il/report/2017/108 [6] R. S. Wahby, I. Tzialla, A. Shelat, J. Thaler, and M. Walfish, "Doubly-efficient zksnarks without trusted setup," in 2018 IEEE Symposium on Security and Privacy, SP 2018, Proceedings, 21-23 May 2018, San Francisco, California, USA, 2018, pp. 926-943. [Online]. Available: https://doi.org/10.1109/SP.2018.00060 [7] S. Goldwasser, S. Micali, and C. Rackoff, “The knowledge complexity of interactive proof systems,” SIAM J. Comput., vol. 18, no. 1, pp. 186–208, 1989. [Online]. Available: https://doi.org/10.1137/0218012 [8] T. P. Pedersen, “Non-interactive and information-theoretic secure verifiable secret sharing,” in Advances in Cryptology - CRYPTO '91, 11th Annual International Cryptology Conference, Santa Barbara, California, USA, August 11-15, 1991, Proceedings, ser. Lecture Notes in Computer Science, J. Feigenbaum, Ed., vol. 576. Springer, 1991, pp. 129-140. [Online]. Available: https://doi.org/10.1007/3-540-46766-1_9 [9] K. Simonyan and A. Zisserman, “Very deep convolutional networks for large-scale image recognition,” arXiv preprint arXiv:1409.1556, 2014. [10] A. E. Kosba, D. Papadopoulos, C. Papamanthou, M. F. Sayed, E. Shi, and N. Triandopoulos, "TRUESET: faster verifiable set computations," in Proceedings of the 23rd USENIX Security Symposium, San Diego, CA, USA, August 20-22, 2014., 2014, pp. 765-780. [Online]. Available: https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/kosba [11] L. Cavallaro, J. Kinder, X. Wang, and J. Katz, Eds., Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, CCS 2019, London, UK, November 11-15, 2019. ACM, 2019. [Online]. Available: https://doi.org/10.1145/3319535 [12] R. Gilad-Bachrach, N. Dowlin, K. Laine, K. E. Lauter, M. Naehrig, and J. Wernsing, "Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy," in Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, 2016, pp. 201-210. [Online]. Available: http://proceedings.mlr.press/v48/gilad-bachrach16. [13] C. Juvekar, V. Vaikuntanathan, and A. Chandrakasan, “{GAZELLE}:</p>

    <p class="text-gray-300">!<a href="img-18.jpeg">img-18.jpeg</a> (a)</p>

    <p class="text-gray-300">!<a href="img-19.jpeg">img-19.jpeg</a> (b)</p>

    <p class="text-gray-300">!<a href="img-20.jpeg">img-20.jpeg</a> (c)</p>

    <p class="text-gray-300">!<a href="img-21.jpeg">img-21.jpeg</a> Fig. 10: Results when kernel size  <span class="math">= 3 \\times 3</span>  and kernel depth size  <span class="math">= 64</span> (a)</p>

    <p class="text-gray-300">!<a href="img-22.jpeg">img-22.jpeg</a> (b)</p>

    <p class="text-gray-300">!<a href="img-23.jpeg">img-23.jpeg</a> (c)</p>

    <p class="text-gray-300">!<a href="img-24.jpeg">img-24.jpeg</a> Fig. 11: MNIST CNN when kernel size is  <span class="math">3 \\times 3</span>  and kernel depths are 32, 64, and 128 for each convolution layer (a)</p>

    <p class="text-gray-300">!<a href="img-25.jpeg">img-25.jpeg</a> (b) Fig. 12: AlexNet in vCNN by varying the scale factor to the kernel depth and the input size</p>

    <p class="text-gray-300">!<a href="img-26.jpeg">img-26.jpeg</a> (c)</p>

    <p class="text-gray-300">A low latency framework for secure neural network inference," in 27th {USENIX} Security Symposium ( <span class="math">\\{\\text{USENIX}\\}</span>  Security 18), 2018, pp. 1651-1669. [14] X. Jiang, M. Kim, K. Lauter, and Y. Song, "Secure outsourced matrix computation and application to neural networks," in Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS '18. New York, NY, USA: Association for Computing Machinery, 2018, p. 1209-1222. [Online]. Available: https://doi.org/10.1145/3243734.3243837 [15] H. Chen, W. Dai, M. Kim, and Y. Song, "Efficient multi-key homomorphic encryption with packed ciphertexts with application to oblivious neural network inference," in Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS '19. New York, NY, USA: Association</p>

    <p class="text-gray-300">for Computing Machinery, 2019, p. 395-412. [Online]. Available: https://doi.org/10.1145/3319535.3363207 [16] Z. Ghodsi, T. Gu, and S. Garg, "Safetynets: Verifiable execution of deep neural networks on an untrusted cloud," in Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, 4-9 December 2017, Long Beach, CA, USA, 2017, pp. 4675-4684. [Online]. Available: http://papers.nips.cc/paper/7053-safetynets-verifiable-execution-of-deep-neural-networks-on-an-untrusted-cloud [17] L. Zhao, Q. Wang, C. Wang, Q. Li, C. Shen, X. Lin, S. Hu, and M. Du, "Veriml: Enabling integrity assurances and fair payments for machine learning as a service," CoRR, vol. abs/1909.06961, 2019. [Online]. Available: http://arxiv.org/abs/1909.06961 [18] J. Keuffer, R. Molva, and H. Chabanne, "Efficient proof composition</p>

    <p class="text-gray-300">!<a href="img-27.jpeg">img-27.jpeg</a> (a)</p>

    <p class="text-gray-300">!<a href="img-28.jpeg">img-28.jpeg</a> (b)</p>

    <p class="text-gray-300">!<a href="img-29.jpeg">img-29.jpeg</a> (c)</p>

    <p class="text-gray-300">!<a href="img-30.jpeg">img-30.jpeg</a> Fig. 13: VGG16 in vCNN by varying the scale factorvCNN to the kernel depth and the input size (a)</p>

    <p class="text-gray-300">!<a href="img-31.jpeg">img-31.jpeg</a> (b) Fig. 14: VGG16 with FC in vCNN by varying the scale factor to the kernel depth and the input size</p>

    <p class="text-gray-300">!<a href="img-32.jpeg">img-32.jpeg</a> (c)</p>

    <p class="text-gray-300">for verifiable computation," in Computer Security - 23rd European Symposium on Research in Computer Security, ESORICS 2018, Barcelona, Spain, September 3-7, 2018, Proceedings, Part I, ser. Lecture Notes in Computer Science, J. López, J. Zhou, and M. Soriano, Eds., vol. 11098. Springer, 2018, pp. 152-171. [Online]. Available: https://doi.org/10.1007/978-3-319-99073-6_8 [19] N. Bitansky, A. Chiesa, Y. Ishai, R. Ostrovsky, and O. Paneth, "Succinct non-interactive arguments via linear interactive proofs," in Theory of Cryptography - 10th Theory of Cryptography Conference, TCC 2013, Tokyo, Japan, March 3-6, 2013. Proceedings, 2013, pp. 315-333. [Online]. Available: https://doi.org/10.1007/978-3-642-36594-2_18 [20] G. Cormode, M. Mitzenmacher, and J. Thaler, "Practical verified computation with streaming interactive proofs," in Innovations in Theoretical Computer Science 2012, Cambridge, MA, USA, January 8-10, 2012, 2012, pp. 90-112. [Online]. Available: http://doi.acm.org/10.1145/2090236.2090245 [21] E. Ben-Sasson, A. Chiesa, D. Genkin, E. Tromer, and M. Virza, "Snarks for C: verifying program executions succinctly and in zero knowledge," in Advances in Cryptology - CRYPTO 2013 - 33rd Annual Cryptology Conference, Santa Barbara, CA, USA, August 18-22, 2013, Proceedings, Part II, ser. Lecture Notes in Computer Science, R. Canetti and J. A. Garay, Eds., vol. 8043. Springer, 2013, pp. 90-108. [Online]. Available: https://doi.org/10.1007/978-3-642-40084-1_6 [22] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza, "Succinct non-interactive zero knowledge for a von neumann architecture," in Proceedings of the 23rd USENIX Security Symposium, San Diego, CA, USA, August 20-22, 2014., 2014, pp. 781-796. [Online]. Available: https://www.usenix.org/conference/usenixsecurity14/technical</p>

    <p class="text-gray-300">sessions/presentation/ben-sasson [23] J. Thaler, "Time-optimal interactive proofs for circuit evaluation," in Advances in Cryptology - CRYPTO 2013 - 33rd Annual Cryptology Conference, Santa Barbara, CA, USA, August 18-22, 2013. Proceedings, Part II, ser. Lecture Notes in Computer Science, R. Canetti and J. A. Garay, Eds., vol. 8043. Springer, 2013, pp. 71-89. [Online]. Available: https://doi.org/10.1007/978-3-642-40084-1_5 [24] R. Canetti and J. A. Garay, Eds., Advances in Cryptology - CRYPTO 2013 - 33rd Annual Cryptology Conference, Santa Barbara, CA, USA, August 18-22, 2013. Proceedings, Part II, ser. Lecture Notes in Computer Science, vol. 8043. Springer, 2013. [Online]. Available: https://doi.org/10.1007/978-3-642-40084-1 [25] E. Ben-Sasson, A. Chiesa, C. Garman, M. Green, I. Miers, E. Tromer, and M. Virza, “Zerocash: Decentralized anonymous payments from bitcoin,” in 2014 IEEE Symposium on Security and Privacy, SP 2014, Berkeley, CA, USA, May 18-21, 2014. IEEE Computer Society, 2014, pp. 459-474. [Online]. Available: https://doi.org/10.1109/SP.2014.36 [26] J. Eberhardt and S. Tai, “Zokrates - scalable privacy-preserving off-chain computations,” in IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData), iThings/GreenCom/CPSCom/SmartData 2018, Halifax, NS, Canada, July 30 - August 3, 2018. IEEE, 2018, pp. 1084-1091. [Online]. Available: https://doi.org/10.1109/Cybermaths_2018.2018.00199 [27] “Zsl on quorum,” https://github.com/jpmorganchase/zsl-q. [28] "Jspark," https://github.com/akosba/jspark. [29] A. E. Kosba, C. Papamanthou, and E. Shi, "xjsnark: A framework</p>

    <p class="text-gray-300">for efficient verifiable computation,” in 2018 IEEE Symposium on Security and Privacy, SP 2018, Proceedings, 21-23 May 2018, San Francisco, California, USA, 2018, pp. 944–961. [Online]. Available: https://doi.org/10.1109/SP.2018.00018</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[30] F. Tramèr and D. Boneh, “Slalom: Fast, verifiable and private execution of neural networks in trusted hardware,” in 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019, 2019. [Online]. Available: https://openreview.net/forum?id=rJVorjCcKQ</li>

      <li>[31] R. Freivalds, “Probabilistic machines can use less running time,” in Information Processing, Proceedings of the 7th IFIP Congress 1977, Toronto, Canada, August 8-12, 1977, B. Gilchrist, Ed. North-Holland, 1977, pp. 839–842.</li>

      <li>[32] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,” Proceedings of the IEEE, vol. 86, no. 11, pp. 2278–2324, 1998.</li>

      <li>[33] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification with deep convolutional neural networks,” Commun. ACM, vol. 60, no. 6, pp. 84–90, 2017. [Online]. Available: http://doi.acm.org/10.1145/3065386</li>

      <li>[34] T. P. Pedersen, “Non-interactive and information-theoretic secure verifiable secret sharing,” in Annual international cryptology conference. Springer, 1991, pp. 129–140.</li>

    </ul>

    <h2 id="sec-29" class="text-2xl font-bold">Appendix A Proof of Theorem 1 and 2</h2>

    <h6 id="sec-30" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">We demonstrate the NILP scheme soundness for the proposed protocol as demonstrated in <em>[3]</em>. If the NILP scheme is proved, then soundness for proposed scheme is guaranteed in the Generic Group Model <em>[3]</em>. zk-SNARK and cc-SNARK are similar aside from the random parameter for the commitment. In the proof, zk-SNARK soundness(1) is the special case of cc-SNARK soundness(2) when <span class="math">\\nu=0</span>. Therefore we only prove Theorem 2 here.</p>

    <p class="text-gray-300">We first consider an affine adversary <span class="math">\\mathcal{A}</span> strategy with non-negligible success probability of extracting a witness. First, we set <span class="math">Z=X^{2d_{x}-1}</span> to reducing the variables. Then <span class="math">\\mathcal{A}</span> can generate a proof</p>

    <p class="text-gray-300"><span class="math">A=</span> <span class="math">A_{\\alpha}\\alpha+A_{\\beta}\\beta+A_{\\gamma}\\gamma+A_{\\delta}\\delta+A(x,x^{2d_{x}-1})</span> <span class="math">+\\sum_{i=0}^{l}\\sum_{j=0}^{d_{z}}A_{i,j}\\frac{\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x)}{\\gamma}x^{(2d_{x}-1)\\cdot j}</span> <span class="math">+\\sum_{i=l+1}^{m}\\sum_{j=0}^{d_{z}}A_{i,j}\\frac{\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x)}{\\delta}x^{(2d_{x}-1)\\cdot j}</span> <span class="math">+A_{h}(x,x^{2d_{x}-1})\\frac{t(x)}{\\delta}+A_{\\eta\\gamma}\\frac{\\eta}{\\gamma}+A_{\\eta\\delta}\\frac{\\eta}{\\delta}</span></p>

    <p class="text-gray-300">for known filed elements <span class="math">A_{\\alpha}</span>, <span class="math">A_{\\beta}</span>, <span class="math">A_{\\gamma}</span>, <span class="math">A_{\\delta}</span>, <span class="math">A_{i}</span> and polynomials <span class="math">A(x,z)</span>, <span class="math">A_{h}(x,z)</span>. we construct <span class="math">B</span> and <span class="math">C</span> similarly for the proof. In verification, the equation shows polynomials equality. From the Schwartz-Zippel lemma, verification holds the proof(<span class="math">A</span>, <span class="math">B</span>, and <span class="math">C</span>) for indeterminates <span class="math">\\alpha</span>, <span class="math">\\beta</span>, <span class="math">\\gamma</span>, <span class="math">\\delta</span>, and <span class="math">x</span> if verification succeed.</p>

    <p class="text-gray-300">Terms with indeterminates <span class="math">\\alpha^{2}</span> are <span class="math">A_{\\alpha}B_{\\alpha}\\alpha^{2}=0</span>, i.e., <span class="math">A_{\\alpha}=0</span> or <span class="math">B_{\\alpha}=0</span>. Since field operation is commutative, we can assume <span class="math">B_{\\alpha}=0</span>. Terms with indeterminate <span class="math">\\alpha\\beta</span> imply <span class="math">A_{\\alpha}B_{\\beta}+A_{\\beta}B_{\\alpha}=A_{\\alpha}B_{\\beta}=1</span>. Thus, <span class="math">AB=(AB_{\\beta})(A_{\\alpha}B)</span>, and we can assume <span class="math">A_{\\alpha}=B_{\\beta}=1</span>. Hence with indeterminate <span class="math">\\beta^{2}</span> now imply <span class="math">A_{\\beta}B_{\\beta}=A_{\\beta}=0</span>. This simplifies <span class="math">A</span> and <span class="math">B</span> constructed by the adversary to have the form</p>

    <p class="text-gray-300"><span class="math">A</span> <span class="math">=\\alpha+A_{\\gamma}\\gamma+A_{\\delta}\\delta+A(x,x^{2d_{x}-1})+\\cdots</span> <span class="math">B</span> <span class="math">=\\beta+B_{\\gamma}\\gamma+B_{\\delta}\\delta+B(x,x^{2d_{x}-1})+\\cdots</span></p>

    <p class="text-gray-300">Let us consider terms involving <span class="math">\\frac{1}{\\delta^{2}}</span>.</p>

    <p class="text-gray-300"><span class="math">\\left(\\sum_{i=l+1}^{m}A_{i,j}(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))\\cdot x^{(2d_{x}-1)\\cdot j}+A_{h}(x,x^{2d_{x}-1})t(x)\\right)</span> <span class="math">\\left(\\sum_{i=l+1}^{m}B_{i,j}(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))\\cdot x^{(2d_{x}-1)\\cdot j}+B_{h}(x,x^{2d_{x}-1})t(x)\\right)</span> <span class="math">=0</span></p>

    <p class="text-gray-300">Hence either left factor is <span class="math">0</span>. From symmetry, let us assume</p>

    <p class="text-gray-300"><span class="math">(\\Sigma_{i=l+1}^{m}A_{i}(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))+A_{h}(x,x^{2d_{x}-1})t(x))=0</span></p>

    <p class="text-gray-300">. Therefore, terms in</p>

    <p class="text-gray-300"><span class="math">\\alpha\\frac{\\Sigma_{i=l+1}^{m}B_{i}(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))+B_{h}(x,x^{2d_{x}-1})t(x)}{\\delta}=0</span></p>

    <p class="text-gray-300">imply that <span class="math">\\Sigma_{i=l+1}^{m}B_{i}(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))+B_{h}(x,x^{2d_{x}-1})t(x)=0</span>.</p>

    <p class="text-gray-300">Therefore, considering terms involving <span class="math">\\frac{1}{\\gamma}</span>,</p>

    <p class="text-gray-300"><span class="math">\\left(\\sum_{i=0}^{l}A_{i}(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))\\right)\\cdot\\left(\\sum_{i=0}^{l}B_{i}(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))\\right)</span></p>

    <p class="text-gray-300">hence either left or right factor is <span class="math">0</span>. From symmetry, let us assume <span class="math">(\\Sigma_{i=0}^{l}A_{i}(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x)))=0</span>. Thus, terms in</p>

    <p class="text-gray-300"><span class="math">\\beta\\frac{\\Sigma_{i=0}^{l}B_{i}(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))}{\\gamma}=0</span></p>

    <p class="text-gray-300">also imply <span class="math">\\Sigma_{i=0}^{l}B_{i}(\\beta u_{i}(x)+\\alpha v_{i}(x)+w_{i}(x))=0</span>.</p>

    <p class="text-gray-300">Thus, <span class="math">A_{\\gamma}\\beta\\gamma=0</span>, <span class="math">B_{\\gamma}\\alpha\\gamma=0</span>, and added terms involving <span class="math">\\eta</span> also <span class="math">(A_{\\eta\\gamma}\\frac{\\eta}{\\beta}+A_{\\eta\\delta}\\frac{\\eta}{\\delta})\\cdot\\beta=0</span>, hence <span class="math">A_{\\gamma}=0</span>, <span class="math">B_{\\gamma}=0</span>, <span class="math">A_{\\eta\\gamma}=0</span>, and <span class="math">A_{\\eta\\delta}=0</span>.</p>

    <p class="text-gray-300">Collecting these results,</p>

    <p class="text-gray-300"><span class="math">A=\\alpha+A(x,x^{2d_{x}-1})+A_{\\delta}\\delta\\quad B=\\beta+B(x,x^{2d_{x}-1})+B_{\\delta}\\delta</span></p>

    <p class="text-gray-300">Remaining terms in the verification equation that involve <span class="math">\\alpha</span> imply <span class="math">\\alpha B(x,x^{2d_{x}-1})=\\alpha\\sum_{i=0}^{l}a_{i}(x^{2d_{x}-1}v_{i}(x)+\\alpha\\sum_{i=l+1}^{m}\\sum_{j=0}^{d_{z}}C_{i,j}v_{i}(x)\\cdot x^{(2d_{x}-1)\\cdot j}</span>. Defining <span class="math">a_{i}(x^{2d_{x}-1})=C_{i}(x^{2d_{x}-1})=\\sum_{j=0}^{d_{z}}C_{i,j}\\cdot x^{(2d_{x}-1)\\cdot j}</span> for <span class="math">i=l+1,\\ldots,m</span>,</p>

    <p class="text-gray-300"><span class="math">\\begin{gathered}A(x,x^{2d_{x}-1})=\\sum_{i=0}^{m}a_{i}(x^{2d_{x}-1})u_{i}(x)\\quad B(x,x^{2d_{x}-1})=\\sum_{i=0}^{m}a_{i}(x^{2d_{x}-1})v_{i}(x)\\end{gathered}</span></p>

    <p class="text-gray-300">Finally, collecting terms involving powers of <span class="math">x</span>,</p>

    <p class="text-gray-300"><span class="math">\\sum_{i=0}^{m}a_{i}(x^{2d_{x}-1})u_{i}(x)</span> <span class="math">\\cdot\\sum_{i=0}^{m}a_{i}(x^{2d_{x}-1})v_{i}(x)</span> <span class="math">=\\sum_{i=0}^{m}a_{i}(x^{2d_{x}-1})w_{i}(x)+C_{h}(x,x^{2d_{x}-1})t(x)</span></p>

    <p class="text-gray-300">Since <span class="math">Z=X^{2d_{x}-1}</span>, <span class="math">Z</span> degree <span class="math">\\geq X</span> degree, and all terms are independent. Thus, <span class="math">a_{i}(X^{2d_{x}-1})</span> is irrelevant to <span class="math">u_{i}(X),v_{i}(X),w_{i}(X)</span> and <span class="math">t(X)</span>, and hence</p>

    <p class="text-gray-300"><span class="math">a_{l+1}(x^{2d_{x}-1}),\\ldots,a_{m}(x^{2d_{x}-1})=C_{l+1}(x^{2d_{x}-1}),\\ldots,C_{m}(x^{2d_{x}-1})</span></p>

    <p class="text-gray-300">is a witness for the statement <span class="math">(a_{1}(x^{2d_{x}-1}),\\ldots,a_{l}(x^{2d_{x}-1}))</span>.</p>

    <p class="text-gray-300">Proof. We first prove the perfect zero-knowledge. There are simulators for each scheme, and the commitment is the Pedersen [34] vector commitment which provides perfect hiding. Thus, proof has no information regarding witnesses, and hence the scheme supports perfect zero-knowledge.</p>

    <p class="text-gray-300">Next, we prove that the computational knowledge soundness error is negligible. We define the computational knowledge soundness errors for each scheme  <span class="math">\\Pi_{gap}</span> ,  <span class="math">\\Pi_{qpp}</span> , and  <span class="math">\\Pi_{cp}</span>  as  <span class="math">\\epsilon_{gap}</span> ,  <span class="math">\\epsilon_{qpp}</span> , and  <span class="math">\\epsilon_{cp}</span> , respectively, which are negligible; and the extractors for each scheme are  <span class="math">\\chi_{gap}</span> ,  <span class="math">\\chi_{qpp}</span> , and  <span class="math">\\chi_{cp}</span> , respectively, which must exist due to the knowledge soundness for each scheme. The extractor  <span class="math">\\chi</span>  for the proposed scheme can be composed of three extractors because each extractor can generate a witness and the collection of all the witnesses is the witness for the proposed scheme.</p>

    <p class="text-gray-300">Now, we compute the computation knowledge soundness error for the proposed scheme as follows:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Pr[</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Verify(crs,φ,π)=1 ∧(φ,w)∉R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(crs,td)←Setup(R), (φ,π,w)←(A</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">χA)(R,crs,z)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">=Pr[</td>

            <td class="px-3 py-2 border-b border-gray-700">Πgap.Verify(crsgap,φgap,πgap)=1 ∧Πgpp.Verify(crsgpp,φgpp,πgpp)=1 ∧Πcp.Verify(crscp,φcp,πcp)=1 ∧((φgap,wgap)∉RReLU+Pooling ∨(φgpp,wgpp)∉Rconvol ∨(φcp,wcp)∉Rcp)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">≤Pr[</td>

            <td class="px-3 py-2 border-b border-gray-700">Π.Verify(crsgap,φgap,πgap)=1 ∧Πgpp.Verify(crsgpp,φgpp,πgpp)=1 ∧Πcp.Verify(crscp,φcp,πcp)=1 ∧(φgap,wgap)∉RReLU+Pool</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">+Pr[</td>

            <td class="px-3 py-2 border-b border-gray-700">Πgap.Verify(crsgap,φgap,πgap)=1 ∧Πgpp.Verify(crsgpp,φgpp,πgpp)=1 ∧Πcp.Verify(crscp,φcp,πcp)=1 ∧(φgpp,wgpp)∉Rconvol</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">+Pr[</td>

            <td class="px-3 py-2 border-b border-gray-700">Πgap.Verify(crsgap,φgap,πgap)=1 ∧Πgpp.Verify(crsgpp,φgpp,πgpp)=1 ∧Πcp.Verify(crscp,φcp,πcp)=1 ∧(φcp,wcp)∉Rcp</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\leq \\epsilon_{gap} + \\epsilon_{qpp} + \\epsilon_{cp}</span></p>

    <p class="text-gray-300">where we used that  <span class="math">\\epsilon_{gap}</span> ,  <span class="math">\\epsilon_{qpp}</span> ,  <span class="math">\\epsilon_{cp}</span>  are negligible in the last two inequalities. Therefore the computational soundness error is negligible.</p>

    <p class="text-gray-300">□</p>`;
---

<BaseLayout title="vCNN: Verifiable Convolutional Neural Network based on zk-SN... (2020/584)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2020 &middot; eprint 2020/584
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
