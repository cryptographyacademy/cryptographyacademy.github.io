---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2011/273';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Memory Delegation';
const AUTHORS_HTML = 'Kai-Min Chung, Yael Tauman Kalai, Feng-Hao Liu, Ran Raz';

const CONTENT = `    <p class="text-gray-300">1</p>

    <p class="text-gray-300">Kai-Min Chung†  Yael Tauman Kalai‡  Feng-Hao Liu§  Ran Raz¶</p>

    <p class="text-gray-300">June 15, 2011</p>

    <h2 id="sec-2" class="text-2xl font-bold">Abstract</h2>

    <p class="text-gray-300">We consider the problem of delegating computation, where the delegator doesn't even know the input to the function being delegated, and runs in time significantly smaller than the input length.</p>

    <p class="text-gray-300">For example, consider the setting of memory delegation, where a delegator wishes to delegate her entire memory to the cloud. The delegator may want the cloud to compute functions on this memory, and prove that the functions were computed correctly. As another example, consider the setting of streaming delegation, where a stream of data goes by, and a delegator, who cannot store this data, delegates this task to the cloud. Later the delegator may ask the cloud to compute statistics on this streaming data, and prove the correctness of the computation. We note that in both settings the delegator must keep a (short) certificate of the data being delegated, in order to later verify the correctness of the computations. Moreover, in the streaming setting, this certificate should be computed in a streaming manner.</p>

    <p class="text-gray-300">We construct both memory and streaming delegation schemes. We present non-interactive constructions based on the (standard) delegation scheme of Goldwasser et. al. [GKR08]. These schemes allow the delegation of any function computable by an <span class="math">\\mathcal{L}</span>-uniform circuit of low depth (the complexity of the delegator depends linearly on the depth). For memory delegation, we rely on the existence of a polylog PIR scheme, and for streaming, we rely on the existence of a fully homomorphic encryption scheme.</p>

    <p class="text-gray-300">We also present constructions based on the CS-proofs of Micali. These schemes allow the delegation of any function in <span class="math">\\mathbf{P}</span>. However, they are interactive (i.e., consists of 4 messages), or are non-interactive in the Random Oracle Model.</p>

    <h2 id="sec-3" class="text-2xl font-bold">1 Introduction</h2>

    <p class="text-gray-300">The problem of delegating computation considers a scenario where one party, the delegator, wishes to delegate the computation of a function <span class="math">f</span> to another party, the worker. The challenge is that</p>

    <p class="text-gray-300">*An extend abstract of this paper will appear in Crypto '11 [CKLR11].</p>

    <p class="text-gray-300">†Department of Computer Science, Cornell University, Upson Hall 4108, Ithaca, NY 14850, USA. http://www.cs.cornell.edu/~chung/. chung@cs.cornell.edu. Supported by US-Israel BSF grant 2006060 and NSF grant CNS-0831289.</p>

    <p class="text-gray-300">‡Microsoft Research, One Memorial Drive, Cambridge MA, 02142, USA. http://research.microsoft.com/en-us/um/people/yael/. yael@microsoft.com.</p>

    <p class="text-gray-300">§Department of Computer Science, Brown University, Providence RI, 02912, USA. http://www.cs.brown.edu/people/fenghao/. fenghao@cs.brown.edu.</p>

    <p class="text-gray-300">¶Department of Mathematics and Computer Science, Weizmann Institute of Science, Ziskind 144, Rehovot 76100, Israel. http://www.wisdom.weizmann.ac.il/~ranraz/. ran.raz@weizmann.ac.il.</p>

    <p class="text-gray-300">the delegator may not trust the worker, and thus it is desirable to have the worker “prove” that the computation was done correctly. Obviously, verifying this proof should be easier than doing the computation.</p>

    <p class="text-gray-300">This concept of “outsourcing” computation received a lot of attention in recent years, partly due to the increasing interest in cloud computing, where the goal is to outsource all the computational resources to a (possibly untrusted) “cloud”. There are several reasons why the client (or delegator) may not trust the cloud, and thus would like to receive proofs for the correctness of the computation. For example, the cloud may have an incentive to return incorrect answers. Such an incentive may be a financial one, if the real computation requires a lot of work, whereas computing incorrect answers requires less work and is unlikely to be detected by the client. Moreover, in some cases, the applications outsourced to the cloud may be so critical that the delegator wishes to rule out accidental errors during the computation.</p>

    <p class="text-gray-300">In order to ensure that the worker (or the cloud) performed the computation correctly, we would like the worker to prove this to the delegator. Of course, it is essential that the time it takes to verify the proof is significantly smaller than the time needed to actually run the computation. At the same time, the running time of the worker carrying out the proof should also be reasonable — comparable to the time it takes to do the computation.</p>

    <p class="text-gray-300">The problem of delegating computation has been studied excessively (see Section 1.2 for an overview on previous work). However, most previous work on delegation allow the delegator to run in time polynomial in the input size, as long as this runtime is significantly smaller than the time it takes to do the computation. For example, when delegating the computation of a function <span class="math">f</span> that runs in time <span class="math">T</span> and has inputs of size <span class="math">n</span>, typically the desired runtime of the delegator is <span class="math">\\operatorname{poly}(n,\\log T)</span> and the desired runtime of the worker is <span class="math">\\operatorname{poly}(T)</span>.</p>

    <p class="text-gray-300">In this work, we want the delegator to run in time that is even smaller than the input size <span class="math">n</span>. Namely, we don’t allow the delegator even to read the input! At first, this requirement may seem unreasonable and unachievable. So, let us start by motivating this requirement with two examples.</p>

    <h4 id="sec-4" class="text-lg font-semibold mt-6">Memory delegation.</h4>

    <p class="text-gray-300">Suppose that Alice would like to store all her memory in the cloud. The size of her memory may be huge (for example, may include all the emails she ever received). Moreover, suppose she doesn’t trust the cloud. Then, every time she asks the cloud to carry out some computation (for example, compute how many emails she has received from Bob during the last year), she would like the answer to be accompanied by a proof that indeed the computation was done correctly. Note that the input to these delegated functions may be her entire memory, which can be huge. Therefore, it is highly undesirable that Alice runs in time that is proportional to this input size. More importantly, Alice doesn’t even hold on to this memory anymore, since she delegated it to the cloud.</p>

    <p class="text-gray-300">Thus, in a memory delegation scheme, a delegator delegates her entire memory to the cloud, and then may ask the could to compute functions of this memory, and expects the answers to be accompanied by a proof. Note that in order to verify the correctness of these proofs, the delegator must save some short certificate of her memory, say a certificate of size <span class="math">\\operatorname{polylog}(n)</span>, where <span class="math">n</span> is the memory size. The proofs should be verifiable very efficiently; say, in time <span class="math">\\operatorname{polylog}(n,T)</span>, where <span class="math">T</span> is the time it takes to compute the function. Moreover, Alice should be able to update her memory efficiently.</p>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">Streaming delegation.</p>

    <p class="text-gray-300">Suppose that there is some large amount of data that is streaming by, and suppose that a user, Alice, wishes to save this data, so that later on she will be able to compute statistics on this data. However, Alice’s memory is bounded and she cannot store this data. Instead, she wishes to delegate this to the cloud. Namely, she asks the cloud to store this streaming data for her, and then she asks the cloud to perform computation on this data. As in the case of memory delegation, in order to later verify the correctness of these computations, Alice must save some short certificate of this streaming data. As opposed to the setting of memory delegation, here the certificate should be computed (and updated) in a streaming manner.</p>

    <p class="text-gray-300">The settings of memory delegation and streaming delegation are quite similar. In both settings Alice asks the cloud to store a huge object (either her memory or the streaming data). There are two main differences between the two: (1) In the setting of streaming delegation, the certificates and updates must be computed in a streaming manner. Thus, in this sense, constructing streaming delegation schemes may be harder than constructing memory delegation schemes. Indeed, our streaming delegation scheme is more complicated than our memory delegation scheme, and proving soundness in the streaming setting is significantly harder than proving soundness in the memory setting. (2) In the setting of streaming delegation, the memory is updated by simply adding elements to it. This is in contrast to the setting of memory delegation, where the memory can be updated in arbitrary ways, depending on the user’s needs. However, in the memory setting, we allow the delegator to use the help of the worker when updating her certificate (or secret state), whereas in the streaming setting we require that the delegator updates her certificate on her own. The reason for this discrepancy, is that in the memory setting the delegator may not be able to update her certificate on her own, since she may want to update her memory in involved ways (such as, erase all emails from Bob). On the other hand, in the streaming setting, it seems essential that the delegator updates her certificate on her own, since in this setting the data may be streaming by very quickly, and there may not be enough time for the delegator and worker to interact during each update.</p>

    <h3 id="sec-5" class="text-xl font-semibold mt-8">1.1 Our Results</h3>

    <p class="text-gray-300">We construct both memory delegation and streaming delegation schemes. The memory delegation scheme consists of an offline phase, where the delegator D delegates her memory <span class="math">x\\in\\{0,1\\}^{n}</span> to a worker W. This phase is non-interactive, where the delegator sends a single message, which includes her memory content <span class="math">x</span> to the worker W. The runtime of both the delegator and the worker in the offline phase is <span class="math">\\operatorname{poly}(n)</span>, where <span class="math">n</span> is the memory size. At the end of this phase, the delegator saves a short certificate <span class="math">\\sigma</span> of her memory, which she will later use when verifying delegation proofs.</p>

    <p class="text-gray-300">The streaming delegation scheme, on the other hand, doesn’t have such an offline phase. In the streaming setting, we consider the scenario where at each time unit <span class="math">t</span> a bit <span class="math">x_{t}</span> is being streamed. The delegator starts with some secret state (or certificate) <span class="math">\\sigma_{0}</span>, and at time unit <span class="math">t+1</span> she uses her secret state <span class="math">\\sigma_{t}</span> and the current bit <span class="math">x_{t+1}</span> being streamed, to efficiently update her secret state from <span class="math">\\sigma_{t}</span> to <span class="math">\\sigma_{t+1}</span>.</p>

    <p class="text-gray-300">In both settings, each time the delegator D wants the worker W to compute a function <span class="math">f(x)</span>, they run a delegation protocol, which we denote by <span class="math">\\mathsf{Compute}(f)</span>. The memory delegation scheme also has an <span class="math">\\mathsf{Update}</span> protocol, where the delegator D asks the worker W to update her memory and to help her update her secret state <span class="math">\\sigma</span>. The latter can be thought of as a delegation request, and the guarantees (in term of runtime and communication complexity) are similar to the guarantees</p>

    <p class="text-gray-300">of the Compute protocol.</p>

    <p class="text-gray-300">In the streaming setting, the delegator updates her secret state on her own in time <span class="math">\\mathrm{polylog}(N)</span>, where <span class="math">N</span> is an upper bound on the length of the stream. Namely, the update function, that takes as input a certificate <span class="math">\\sigma_{t}</span> and a bit <span class="math">x_{t+1}</span>, and outputs a new certificate <span class="math">\\sigma_{t+1}</span>, can be computed in time <span class="math">\\mathrm{polylog}(N)</span>.</p>

    <p class="text-gray-300">We present two memory and streaming delegation protocols. The first are non-interactive (i.e, <span class="math">\\mathsf{Compute}(f)</span> consists of two messages, the first sent by the delegator and the second sent by the worker). They are based on the non-interactive version of the delegation protocol of Goldwasser et. al. <em>[x10, x16]</em>, denoted by GKR (though are significantly more complicated than merely running GKR). As in GKR, the efficiency of the delegator depends linearly on the depth of the circuit being delegated. Our second memory and streaming delegation protocols are interactive (i.e., <span class="math">\\mathsf{Compute}(f)</span> consists of four messages). These schemes are based on CS-proofs of Micali <em>[x22]</em>, and allow for efficient delegation of all functions in <span class="math">\\mathbf{P}</span>.</p>

    <p class="text-gray-300">In what follows we state our theorems formally. We refer the reader to Section 6 for the formal definition of a memory delegation scheme, and to Section 8 for the formal definition of a streaming delegation scheme.</p>

    <h6 id="sec-6" class="text-base font-medium mt-4">Theorem 1 (Memory Delegation)</h6>

    <p class="text-gray-300">Assume the existence of a poly-log PIR scheme(as defined in Definition 5), and assume the existence of a collision resistant hash family. Let <span class="math">\\mathcal{F}</span> be the class of all <span class="math">\\mathcal{L}</span>-uniform poly-size boolean circuits. Then there exists a non-interactive (2-message) memory delegation scheme <span class="math">\\mathsf{mDel}</span>, for delegating any function <span class="math">f\\in\\mathcal{F}</span>. The delegation scheme, <span class="math">\\mathsf{mDel}</span> has the following properties, for security parameter <span class="math">k</span>.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The scheme has perfect completeness and negligible (reusable) soundness error.</li>

      <li>The delegator and worker are efficient in the offline stage; i.e., both the delegator and the worker run in time <span class="math">\\mathrm{poly}(k,n)</span>.</li>

      <li>The worker is efficient in the online phase. More specifically, it runs in time <span class="math">\\mathrm{poly}(k,S)</span> during each <span class="math">\\mathsf{Compute}(f)</span> and <span class="math">\\mathsf{Update}(f)</span> operation, where <span class="math">S</span> is the size of the <span class="math">\\mathcal{L}</span>-uniform circuit computing <span class="math">f</span>. The delegator runs in time <span class="math">\\mathrm{poly}(k,d)</span> during each <span class="math">\\mathsf{Compute}(f)</span> and <span class="math">\\mathsf{Update}(f)</span> operation, where <span class="math">d</span> is the depth of the <span class="math">\\mathcal{L}</span>-uniform circuit computing <span class="math">f</span>.</li>

    </ul>

    <p class="text-gray-300">In particular, assuming the existence of a poly-logarithmic PIR scheme, and assuming the existence of a collision resistent hash family, we obtain a memory delegation scheme for <span class="math">\\mathcal{L}</span>-uniform <span class="math">\\mathbf{NC}</span> computations, where the delegator <span class="math">\\mathsf{D}</span> runs in time poly-logarithmic in the length of the memory.</p>

    <h6 id="sec-7" class="text-base font-medium mt-4">Theorem 2 (Streaming Delegation)</h6>

    <p class="text-gray-300">Let <span class="math">k</span> be a security parameter, and let <span class="math">N</span> be a parameter (an upper bound on the length of the stream). Let <span class="math">\\mathcal{F}</span> be the class of all <span class="math">\\mathcal{L}</span>-uniform poly-size boolean circuits. Assume the existence of a fully-homomorphic encryption scheme secure against <span class="math">\\mathrm{poly}(N)</span>-size adversaries. Then there exists a non-interactive (2-message) streaming delegation scheme <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> for <span class="math">\\mathcal{F}</span> with the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> has perfect completeness and negligible reusable soundness error.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>D updates her secret state in time <span class="math">\\operatorname{polylog}(N)</span>, per data item.</li>

      <li>In the delegation protocol, when delegating a function <span class="math">f\\in\\mathcal{F}</span> computable by an <span class="math">\\mathcal{L}</span>-uniform circuit of size <span class="math">S</span> and depth <span class="math">d</span>, the delegator D runs in time <span class="math">\\operatorname{poly}(k,d,\\log N)</span>, and the worker W runs in time <span class="math">\\operatorname{poly}(k,\\log N,S)</span>.</li>

    </ul>

    <p class="text-gray-300">In particular, assuming the existence of a fully-homomorphic encryption scheme secure against adversaries of size <span class="math">\\operatorname{poly}(N)</span>, we obtain a streaming delegation scheme for <span class="math">\\mathcal{L}</span>-uniform NC computations, where the delegator D runs in time poly-logarithmic in the length of data stream.</p>

    <h5 id="sec-8" class="text-base font-semibold mt-4">Remark.</h5>

    <p class="text-gray-300">We note that the property we needed from the GKR protocol is that the verifier does not need to read the entire input in order to verify, but rather only needs to access a single random point in the low-degree extension of the input. (We refer the reader to Section 3.3 for the definition and properties of a low-degree extension.) We note that the CS-proof delegation scheme of Micali <em>[x10]</em>, for delegating the computation of (uniform) Turing machines, also has the property that verification can be done by only accessing a few random points in the low-degree extension of the input, assuming the underlying PCP is a PCP of Proximity <em>[BSGH^{+}05, x4]</em>.</p>

    <p class="text-gray-300">Indeed using this delegation scheme, we get a memory delegation scheme and a streaming delegation scheme for all of <span class="math">\\mathbf{P}</span>. Using this scheme, the <span class="math">\\mathsf{Compute}(f)</span> protocol is interactive (i.e., it is a 4-message protocol). The runtime of the delegator is <span class="math">\\operatorname{polylog}(T)</span> and the runtime of the worker is <span class="math">\\operatorname{poly}(T)</span>, where <span class="math">T</span> is the runtime of the Turing machine computing the function <span class="math">f</span>. Furthermore, the memory delegation scheme relies only on the existence of a collision resistant hash family, without the need of a poly-log PIR scheme.</p>

    <h6 id="sec-9" class="text-base font-medium mt-4">Theorem 3 (Interactive Memory Delegation)</h6>

    <p class="text-gray-300">Assume the existence of a collision resistant hash family. Then there exists a memory delegation scheme mDel, for delegating any function computable by a polynomial-time Turning machine. The delegation scheme, mDel has the following properties, for security parameter <span class="math">k</span>.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The scheme has perfect completeness and negligible (reusable) soundness error.</li>

      <li>The delegator and worker are efficient in the offline stage; i.e., both the delegator and the worker run in time <span class="math">\\operatorname{poly}(k,n)</span>.</li>

      <li>The worker is efficient in the online phase. More specifically, it runs in time <span class="math">\\operatorname{poly}(k,T)</span> during each <span class="math">\\mathsf{Compute}(f)</span> and <span class="math">\\mathsf{Update}(f)</span> operation, where <span class="math">T</span> is an upper-bound on the running time of <span class="math">f</span>. The delegator runs in time <span class="math">\\operatorname{poly}(k,\\log T)</span> during each <span class="math">\\mathsf{Compute}(f)</span> and <span class="math">\\mathsf{Update}(f)</span> operation.</li>

      <li>Both <span class="math">\\mathsf{Compute}(f)</span> and <span class="math">\\mathsf{Update}(f)</span> operations consist of <span class="math">4</span> message exchanges.</li>

    </ul>

    <h6 id="sec-10" class="text-base font-medium mt-4">Theorem 4 (Interactive Streaming Delegation)</h6>

    <p class="text-gray-300">Let <span class="math">k</span> be a security parameter, and let <span class="math">N</span> be a parameter (an upper bound on the length of the stream). Let <span class="math">\\mathcal{F}</span> be the class of all functions computable by a polynomial-time Turning machine. Assume the existence of a fully-homomorphic encryption scheme secure against <span class="math">\\operatorname{poly}(N)</span>-size adversaries. Then there exists a streaming delegation scheme <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> for <span class="math">\\mathcal{F}</span> with the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>sDel_{F} has perfect completeness and negligible reusable soundness error.</li>

      <li>D updates her secret state in time <span class="math">\\operatorname{polylog}(N)</span>, per data item.</li>

      <li>In the delegation protocol, when delegating a function <span class="math">f\\in\\mathcal{F}</span> computable in time <span class="math">T</span>, the delegator D runs in time <span class="math">\\operatorname{poly}(k,\\log N,\\log T)</span>, and the worker W runs in time <span class="math">\\operatorname{poly}(k,\\log N,T)</span>. The delegation protocol consists of <span class="math">4</span> message exchanges.</li>

    </ul>

    <p class="text-gray-300">We note that in the Random Oracle Model (ROM) <em>[x1]</em>, the delegation scheme of Micali is non-interactive. This yields a non-interactive memory delegation scheme and a non-interactive streaming delegation scheme, for delegating all functions in <span class="math">\\mathbf{P}</span>, in the ROM.</p>

    <h3 id="sec-11" class="text-xl font-semibold mt-8">1.2 Previous Work</h3>

    <p class="text-gray-300">Various delegation protocols have been proposed in the literature. Some provide delegation protocols that are sound against any cheating worker, whereas others provide delegation protocols that are secure only against computationally bounded cheating worker (i.e., arguments as opposed to proofs). Some of these protocols are interactive, whereas others are non-interactive. We survey some of these results below, however, we emphasize that in all these solutions, the delegator runs in time that is (at least) linear in the input size, and thus do not apply to our settings of memory delegation or streaming delegation.</p>

    <h4 id="sec-12" class="text-lg font-semibold mt-6">Interactive proofs.</h4>

    <p class="text-gray-300">The celebrated IP=PSPACE Theorem <em>[x11, x24]</em> yields interactive proofs for any function <span class="math">f</span> computable in polynomial space, with a verifier (delegator) running in polynomial time. Thus, the IP=PSPACE protocol can be seen as a delegation protocol for languages in PSPACE. However, the complexity of the prover (worker) is only bounded by polynomial space (and hence exponential time). This theorem was refined and scaled down in <em>[x9]</em> to give verifier complexity <span class="math">\\operatorname{poly}(n,s)</span> and prover complexity <span class="math">2^{\\operatorname{poly}(s)}</span> for functions <span class="math">f</span> computable in time <span class="math">T</span> and space <span class="math">s</span>, on inputs of length <span class="math">n</span>. Note that the prover complexity is still super-polynomial in <span class="math">T</span>, even for computations that run in the smallest possible space, namely <span class="math">s=O(\\log T)</span>.</p>

    <p class="text-gray-300">The prover complexity was recently improved by Goldwasser et al. <em>[x12]</em> to <span class="math">\\operatorname{poly}(T,2^{s})</span>, which is <span class="math">\\operatorname{poly}(T)</span> when <span class="math">s=O(\\log T)</span>. More generally, Goldwasser et al. <em>[x12]</em> give interactive proofs for computations of small depth <span class="math">d</span> (i.e. parallel time). For these, they achieve prover complexity <span class="math">\\operatorname{poly}(T)</span> and verifier complexity <span class="math">\\operatorname{poly}(n,d,\\log T)</span>. (This implies the result for space-bounded computation because an algorithm that runs in time <span class="math">T</span> and space <span class="math">s</span> can be converted into one that runs in time <span class="math">\\operatorname{poly}(T,2^{s})</span> and depth <span class="math">d=O(s^{2})</span>.) However, if we do not restrict to computations of small space or depth, then we cannot use interactive proofs. Indeed, any language that has an interactive proof with verifier running time (and hence communication) <span class="math">T_{V}</span> can be decided in space <span class="math">\\operatorname{poly}(n,T_{V})</span>.</p>

    <h4 id="sec-13" class="text-lg font-semibold mt-6">Interactive arguments.</h4>

    <p class="text-gray-300">Interactive arguments <em>[x3]</em> (aka computationally sound proofs <em>[x16]</em>) relax the soundness condition to be computational. Namely, instead of requiring that no prover strategy whatsoever can convince the verifier of a false statement, we instead require that no computationally feasible prover strategy can convince the verifier of a false statement. In this model, Kilian <em>[x17]</em> and Micali <em>[x16]</em> gave constant-round protocols with prover complexity <span class="math">\\operatorname{poly}(T,k)</span> and verifier complexity <span class="math">\\operatorname{poly}(n,k,\\log T)</span> (where <span class="math">k</span> is the security parameter), assuming the existence of collision-resistant hash functions <em>[x2]</em>.</p>

    <p class="text-gray-300">##</p>

    <h4 id="sec-14" class="text-lg font-semibold mt-6">Toward non-interactive Solutions.</h4>

    <p class="text-gray-300">This possibility of efficient non-interactive arguments was suggested by Micali <em>[x19]</em>, who showed that non-interactive arguments with prover complexity <span class="math">\\operatorname{poly}(T,k)</span> and verifier complexity <span class="math">\\operatorname{poly}(n,k,\\log T)</span> are possible in the Random Oracle Model (the oracle is used to eliminate interaction a la Fiat–Shamir <em>[x10]</em>). Heuristically, one might hope that by instantiating the random oracle with an appropriate family of hash functions, we could obtain a non-interactive solution to delegating computation: first the delegator (or a trusted third party) chooses and publishes a random hash function from the family, and then, the proofs are completely non-interactive (just one message from the prover to the verifier). However, the Random Oracle Heuristic is known to be unsound in general <em>[x5]</em> and even in the context of Fiat–Shamir <em>[x2, x13]</em>. Thus, despite extensive effort, the existence of efficient non-interactive arguments remains a significant open problem in complexity and cryptography.</p>

    <p class="text-gray-300">There has been some recent progress in reducing the amount of interaction needed. Using a transformation of Kalai and Raz <em>[x16]</em>, the GKR delegation protocol <em>[x12]</em> can be converted into a 2-message argument (assuming the existence of single-server private-information retrieval (PIR) schemes). However, like the interactive proofs of <em>[x12]</em>, this solution applies only to small-depth computations, as the verifier’s complexity grows linearly with the depth.</p>

    <p class="text-gray-300">Very recently, Gennaro, Gentry, and Parno <em>[x11]</em>, and the followup work of Chung, Kalai, and Vadhan <em>[x7]</em>, gave a 2-message delegation scheme for arbitrary functions. However, these constructions have an offline phase, where the delegator invests time <span class="math">\\operatorname{poly}(T,k)</span> and computes a secret state (<span class="math">T</span> is the time it takes to compute the function, and <span class="math">k</span> is the security parameter). In the online phase, the delegator’s running time is reduced to <span class="math">\\operatorname{poly}(n,k,\\log T)</span> for an input of length <span class="math">n</span>, and the worker’s complexity is <span class="math">\\operatorname{poly}(T,k)</span>. Thus, the delegator’s large investment in the offline phase can be amortized over many executions of the online phase to delegate the computation of <span class="math">f</span> on many inputs. Their online phase is not completely non-interactive, but rather consists of two messages. However, in many applications, two messages will be necessary anyway, as the delegator may need to communicate the input <span class="math">x</span> to the worker.</p>

    <p class="text-gray-300">We remark that one main drawback of these works <em>[x11, x8]</em> is that soundness is only guaranteed as long as the adversarial worker does not learn whether the delegator accepted or rejected the proofs.</p>

    <p class="text-gray-300">In another followup work, Applebaum, Ishai, and Kushilevitz <em>[x1]</em> also consider the offline/online setting, but focus on efficient solutions for one-time delegation (i.e., the online phase can only be executed one time). They also consider the case when the delegation functions are represented as arithmetic circuits.</p>

    <h4 id="sec-15" class="text-lg font-semibold mt-6">PCPs and MIPs.</h4>

    <p class="text-gray-300">The MIP=NEXP Theorem <em>[x3]</em> and its scaled-down version by Babai et al. <em>[x4]</em> yield multi-prover interactive proofs and probabilistically checkable proofs for time <span class="math">T</span> computations with a prover running in time <span class="math">\\operatorname{poly}(T)</span> and a verifier running in time <span class="math">\\operatorname{poly}(n,\\log T)</span>, exactly as we want. However, using these for delegation require specialized communication models — either 2 non-communicating provers, or a mechanism for the prover to give the verifier random access to a long PCP (of length <span class="math">\\operatorname{poly}(T)</span>) that cannot be changed by the prover during the verification.</p>

    <h4 id="sec-16" class="text-lg font-semibold mt-6">Streaming Interactive Proofs.</h4>

    <p class="text-gray-300">Recently, Cormode, Thaler, and Yi <em>[x6]</em> considered streaming interactive proofs, which is a strengthening of interactive proofs where the input is given to the verifier in a streaming manner and the verifier is restricted to have sub-linear (ideally, poly</p>

    <p class="text-gray-300">logarithmic) space. They observed that both the GKR protocol <em>[x10]</em> and universal arguments <em>[x3]</em> can be modified to yield efficient streaming interactive proofs/arguments.</p>

    <p class="text-gray-300">Streaming interactive proofs are closely related to streaming delegation. The main difference is that streaming interactive proofs correspond to <em>one-time</em> streaming delegation, whereas in our streaming delegation model, the delegator is allowed to delegate as many computations to the worker as she want. Indeed, the GKR protocol is also the starting point of our construction of streaming delegation scheme, and the main effort is to make the scheme <em>reusable</em>.</p>

    <h2 id="sec-17" class="text-2xl font-bold">2 Overview of Our Constructions</h2>

    <p class="text-gray-300">In what follows we present the high-level overview of our constructions. For more elaborate overviews, we refer the reader to Section 7.1 for an overview of our memory delegation scheme, and to Section 9.1 for an overview of our streaming delegation scheme.</p>

    <h3 id="sec-18" class="text-xl font-semibold mt-8">2.1 Overview of our Memory Delegation Scheme</h3>

    <p class="text-gray-300">The starting point of this work is the observation of Goldwasswer <em>et. al.</em> <em>[x10]</em>, that their delegation protocol can be verified <em>very</em> efficiently (in time sub-linear in the input size), if the delegator has oracle access to the low-degree extension of the input <span class="math">x</span> (we refer the reader to Section 3.3 for the definition of a low-degree extension). Moreover, as observed by <em>[x10]</em>, the delegator needs to access this low-degree extension <span class="math">\\text{LDE}_{x}</span> at a single point <span class="math">z</span>, which depends only on the random coin tosses of the delegator.</p>

    <p class="text-gray-300">This observation immediately gives rise to a memory delegation scheme with <em>one-time</em> soundness: The delegator’s secret state will be <span class="math">(z,\\text{LDE}_{x}(z))</span>. Then, she will use this secret state in order to verify computation using the GKR protocol. As was argued by Goldwasswer <em>et. al.</em>, this indeed works if the delegator runs the delegation protocol <em>once</em>. However, the soundness crucially relies on the fact that the delegator’s secret state is indeed secret, and if the delegator uses this state more than once, then soundness breaks completely.</p>

    <p class="text-gray-300">One idea, following the idea of Gennaro <em>et. al.</em> <em>[x11]</em>, is to use a fully homomorphic encryption (FHE) scheme to encrypt all the communication, in order to hide the secret state. This indeed works if the worker does not learn whether the delegator accepts or rejects his proofs. However, if the worker does learn the verdict of the delegator, then there are known attacks that break soundness.</p>

    <p class="text-gray-300">In the streaming setting, we follow this approach, and we succeed in overcoming this problem, and construct a scheme that is sound even if the worker does learn the verdict of the delegator. We could follow this approach in the memory delegation setting as well. However, for several reasons, we choose to take a different approach. First, the approach above relies on the existence of an FHE scheme, whereas our memory delegation scheme relies on the existence of a poly-logarithmic PIR scheme (see Definition 5), arguably a more reasonable assumption. Second, the approach above results with the delegator having a secret state, whereas in our memory delegation scheme, the state of the delegator is public. Finally, the construction and proof of the memory delegation scheme is simpler.</p>

    <p class="text-gray-300">In our approach, instead of having <span class="math">(z,\\text{LDE}_{x}(z))</span> as the delegator’s secret state, the delegator keeps a tree-commitment of the entire <span class="math">\\text{LDE}_{x}</span> as her secret state (see Section 3.5 for the definition of a tree-commitment). Namely, she chooses a random hash function <span class="math">h</span> from a collision-resistant hash</p>

    <p class="text-gray-300">family, and keeps <span class="math">(h,T_{h}(\\mathrm{LDE}_{x}))</span> as her state. In addition to giving the worker her memory <span class="math">x</span>, she also gives him the hash function <span class="math">h</span>. We stress that her state is not secret, which makes the proof of security significantly simpler than that in the streaming setting (where the delegator’s state is secret).</p>

    <p class="text-gray-300">Very roughly speaking, when the delegator wishes to delegate the computation of a function <span class="math">f</span>, they execute <span class="math">\\mathsf{Compute}(f)</span> by simply running the (non-interactive) delegation protocol <span class="math">\\mathrm{GKR}(f)</span>. Recall that at the end of the GKR protocol the delegator needs to verify the value of <span class="math">\\mathrm{LDE}_{x}(r)</span> for a random <span class="math">r</span>. However, she doesn’t have <span class="math">x</span>, since it was delegated to the prover, and all she has is the state <span class="math">(h,T_{h}(\\mathrm{LDE}_{x}))</span>. So, rather than computing the value of <span class="math">\\mathrm{LDE}_{x}(r)</span> on her own, the worker will reveal this value, by sending the augmented path in the Merkle tree corresponding to the leaf <span class="math">r</span>.</p>

    <p class="text-gray-300">Unfortunately the high-level description given above is a gross oversimplification of our actual scheme, and there are several technical issues that complicate matters. We elaborate on these in Section 2.3.</p>

    <p class="text-gray-300">We mention that when the delegator wishes to update her memory from <span class="math">x</span> to <span class="math">g(x)</span>, she needs to update her secret state from <span class="math">(h,T_{h}(\\mathrm{LDE}_{x}))</span> to <span class="math">(h,T_{h}(\\mathrm{LDE}_{g(x)}))</span>. However, she cannot perform this operation on her own, since she does not have <span class="math">x</span>. Instead she will delegate this computation to the worker, by requesting a <span class="math">\\mathsf{Compute}(g^{\\prime})</span> operation, where <span class="math">g^{\\prime}(x)=T_{h}(\\mathrm{LDE}_{g(x)})</span>.</p>

    <h3 id="sec-19" class="text-xl font-semibold mt-8">2.2 Overview of our Streaming Delegation Scheme</h3>

    <p class="text-gray-300">Our streaming delegation scheme is similar to our memory delegation scheme described above, and the main difference is in the way the certificate is generated and updated, and in the way the worker reveals the value <span class="math">\\mathrm{LDE}_{x}(r)</span>.</p>

    <h4 id="sec-20" class="text-lg font-semibold mt-6">Generating and updating the certificate.</h4>

    <p class="text-gray-300">Recall that in the memory delegation scheme, the certificate of the delegator <span class="math">\\mathsf{D}</span> consists of a tree-commitment to the low-degree extension of her memory <span class="math">x</span>. Namely, her certificate is <span class="math">(h,T_{h}(\\mathrm{LDE}_{x}))</span>, where <span class="math">h</span> is a collision resistant hash function. Note that this certificate cannot be updated in a streaming manner, since any change to <span class="math">x</span> changes the low-degree extension <span class="math">\\mathrm{LDE}_{x}</span> almost everywhere.</p>

    <p class="text-gray-300">Instead, in the streaming setting, we replace the tree commitment with an “<em>algebraic commitment</em>”, which has the property that it can be updated efficiently when new data items arrive. The resulting certificate is a random point in the low-degree extension of the stream <span class="math">x</span>; i.e., <span class="math">(z,\\mathrm{LDE}_{x}(z))</span> for a random point <span class="math">z</span>. This certificate is efficiently updatable, if we assume some upper-bound <span class="math">N</span> on the size of the stream, and we take parameters <span class="math">\\mathbb{H},\\mathbb{F},m</span> of the low-degree extension, such that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\mathrm{polylog}(N),\\ m=\\theta\\left(\\frac{\\log N}{\\log\\log N}\\right),\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$ (1)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">(this follows from Proposition 6).</p>

    <p class="text-gray-300">As in the memory delegation scheme, at the end of each delegation protocol, the delegator needs to verify the value of <span class="math">\\mathrm{LDE}_{x}(r)</span> at a random point <span class="math">r</span>. In the memory delegation scheme this was done using a Reveal protocol where the worker reveals the augmented path of the leaf <span class="math">r</span> in the Merkle tree-commitment of <span class="math">\\mathrm{LDE}_{x}</span>. In the streaming setting, the Reveal protocol is totally different, since</p>

    <p class="text-gray-300">the delegator cannot compute the tree-commitment of  <span class="math">\\mathrm{LDE}_x</span> . Unfortunately, unlike in the memory delegation scheme, in the streaming setting constructing a reusable and sound reveal protocol is highly non-trivial.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The Reveal protocol. Our starting point is a basic reveal protocol  <span class="math">\\mathrm{Reveal}_1</span>  described in Figure 1. Note that the soundness of  <span class="math">\\mathrm{Reveal}_1</span>  relies on the secrecy of the certificate  <span class="math">\\sigma</span> . Namely, assuming that  <span class="math">\\mathsf{W}</span>  does not know the point  <span class="math">z</span> , it is not hard to see, by the Schwartz-Zippel Lemma, that an adversarial worker can cheat with probability at most  $d /</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> , where  </span>d<span class="math">  is the (total) degree of  </span>\\mathrm{LDE}_x$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Reveal1 protocol: D stores a secret state  <span class="math">\\sigma = (z, \\mathrm{LDE}_x(z))</span> , where  <span class="math">x \\in \\{0, 1\\}^N</span>  and  <span class="math">z</span>  is a random point in  <span class="math">\\mathbb{F}^m</span> , and wants to learn the value of  <span class="math">\\mathrm{LDE}_x(s)</span>  from W.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>D sends to W the line  <span class="math">\\ell_{sz}</span>  that passes through the points  <span class="math">s</span>  and  <span class="math">z</span> . More specifically, D chooses two random points  <span class="math">\\alpha_{1}, \\alpha_{2} \\gets \\mathbb{F}</span> , and defines  <span class="math">\\ell_{s,z}</span>  to be the line that satisfies  <span class="math">\\ell_{s,z}(\\alpha_{1}) = z</span>  and  <span class="math">\\ell_{s,z}(\\alpha_{2}) = s</span> .</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- W returns a univariate polynomial  <span class="math">p: \\mathbb{F} \\to \\mathbb{F}</span> , which is the polynomial  <span class="math">\\mathrm{LDE}_x</span>  restricted to the line  <span class="math">\\ell_{s,z}</span>  (i.e.,  $p = \\mathrm{LDE}_x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{\\ell_{s,z}}$ ).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>D checks whether  <span class="math">p(\\alpha_1) = \\mathrm{LDE}_x(z)</span> , and if so accepts the value  <span class="math">p(\\alpha_2) = \\mathrm{LDE}_x(s)</span> . Otherwise, she rejects.</li>

    </ul>

    <p class="text-gray-300">Figure 1: Reveal1 protocol</p>

    <p class="text-gray-300">However, note that the  <span class="math">\\mathrm{Reveal}_1</span>  protocol is not reusable. Suppose that  <span class="math">\\mathsf{D}</span>  uses the above reveal protocol to learn the value of  <span class="math">\\mathrm{LDE}_x</span>  on two random points  <span class="math">s, s&#x27; \\in \\mathbb{F}^m</span> . From the two executions, an adversarial worker  <span class="math">\\mathsf{W}^<em></span>  receives two lines  <span class="math">\\ell_{s,z}</span>  and  <span class="math">\\ell_{s&#x27;,z}</span> , and can learn the secret point  <span class="math">z</span>  by taking the intersection of the two lines. Once  <span class="math">\\mathsf{W}^</em></span>  learns  <span class="math">z</span> ,  <span class="math">\\mathsf{W}^<em></span>  can easily cheat by returning any polynomial  <span class="math">p^</em></span>  that agrees with  <span class="math">\\mathrm{LDE}_x</span>  only on point  <span class="math">z</span>  but disagrees on the remaining points.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">As observed by Gennaro et. al. [GGP10], a natural way to protect the secret point  <span class="math">z</span> , is to run the above Reveal protocol under a fully-homomorphic encryption (FHE) scheme. Namely, D generates a pair of keys  <span class="math">(\\mathsf{pk},\\mathsf{sk})</span>  for a FHE  <span class="math">(\\mathrm{Gen},\\mathrm{Enc},\\mathrm{Dec},\\mathrm{Eval})</span> , and sends  <span class="math">\\mathsf{pk}</span>  and an encrypted line  <span class="math">\\hat{\\ell}_{s,z} = \\mathrm{Enc}_{\\mathsf{pk}}(\\ell_{s,z})</span>  to  <span class="math">\\mathsf{W}</span> , who can compute the polynomial  $p = \\mathrm{LDE}_x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{\\ell_{s,z}}<span class="math">  homomorphically under the encryption. Indeed, by the semantic security of FHE, an adversarial worker  </span>\\mathsf{W}^<em><span class="math">  cannot learn any information from  </span>\\mathsf{D}<span class="math"> &#x27;s message  </span>\\hat{\\ell}_{s,z}<span class="math"> . This indeed makes the protocol reusable provided that  </span>\\mathsf{W}^</em><span class="math">  does not learn the decision bits of  </span>\\mathsf{D}$ , as proved in [GGP10, CKV10].</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">However, since the decision bit of  <span class="math">\\mathsf{D}</span>  can potentially contain one bit information about the secret point  <span class="math">z</span> , it is not clear that security holds if  <span class="math">\\mathsf{W}^*</span>  learns these decision bits. In fact, for both of the delegation schemes of [GGP10, CKV10], which use FHE to hide the delegator  <span class="math">\\mathsf{D}</span> 's secret state, there are known attacks that learn the whole secret state of  <span class="math">\\mathsf{D}</span>  bit-by-bit from  <span class="math">\\mathsf{D}</span> 's decision bits.</p>

    <p class="text-gray-300">Fortunately, we are able to show that a variant of the  <span class="math">\\mathrm{Reveal}_1</span>  protocol described in Figure 2 is reusable even if  <span class="math">\\mathsf{W}^*</span>  learns the decision bits of  <span class="math">\\mathsf{D}</span> . The main difference between  <span class="math">\\mathrm{Reveal}_1</span>  and  <span class="math">\\mathrm{Reveal}_2</span>  is that in  <span class="math">\\mathrm{Reveal}_2</span> , the delegator  <span class="math">\\mathsf{D}</span>  uses a random two-dimensional affine subspace instead of a line, and uses an FHE to mask the entire protocol.</p>

    <p class="text-gray-300">We prove that no efficient adversarial  <span class="math">\\mathsf{W}^*</span>  can learn useful information about the secret point  <span class="math">z</span>  from the  <span class="math">\\mathrm{Reveal}_2</span>  protocol. We note that the proof of the above statement is highly non-trivial,</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Figure 2: Protocol Reveal2</p>

    <p class="text-gray-300">and is one of the main technical difficulties in this work. Informally, the proof first uses Lemma 16, which claims that the ciphertext  <span class="math">\\hat{S}_{s,z}</span>  and the decision bit  <span class="math">b</span>  of D (which depend on the strategy of  <span class="math">W^{<em>}</span> ) do not give too much information about  <span class="math">S_{s,z}</span>  to  <span class="math">\\mathsf{W}^</em></span> . In other words, the random subspace  <span class="math">S_{s,z}</span>  still has high (pseudo-)entropy from the point of view of  <span class="math">\\mathsf{W}^<em></span> . Then it uses an information-theoretic argument to argue that a random point  <span class="math">z</span>  in a sufficiently random (with high entropy) subspace  <span class="math">S_{s,z}</span>  is statistically close to a random point in  <span class="math">\\mathbb{F}^m</span> , which implies that  <span class="math">\\mathsf{W}^</em></span>  does not learn useful information about  <span class="math">z</span> . We refer the reader to Section 4 for the techniques developed in order to prove the reusable soundness.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The Field Size. Recall that by Schwartz-Zippel Lemma, an adversarial worker can cheat with probability at most  $d /</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> , where  </span>d<span class="math">  is the (total) degree of  </span>\\mathrm{LDE}_x$ . Recall that in our setting of parameters:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\operatorname {p o l y l o g} (N), m = \\theta \\left(\\frac {\\log N}{\\log \\log N}\\right),</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\operatorname {p o l y} (</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Thus, a cheating worker can cheat (and more importantly, obtain information about the secret  <span class="math">z</span> ) with probability  $d /</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= O(1 / \\mathrm{polylog}(N))$ , which is not low enough.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The idea is to reduce the cheating probability to negligible by simply increasing the field size to be super-polynomial. However, we cannot increase the field size in the GKR protocol, since it will increase the complexity of the worker. Instead, we use an extension field  <span class="math">\\tilde{\\mathbb{F}}</span>  of  <span class="math">\\mathbb{F}</span> , of super-polynomial size, only in the certificate and the Reveal protocol, but run the GKR protocols as before. Namely, the secret state is  <span class="math">\\sigma = (z, \\mathrm{LDE}^{\\tilde{\\mathbb{F}},\\mathbb{H},m}(z))</span>  where  <span class="math">z \\gets \\tilde{\\mathbb{F}}^m</span> , The GKR protocol is run exactly as before with the parameters  <span class="math">(\\mathbb{H},\\mathbb{F},m)</span> .</p>

    <p class="text-gray-300">2.3 Additional Technicalities</p>

    <p class="text-gray-300">The high-level description given above (in Sections 2.1 and 2.2) is a gross oversimplification of our actual schemes, and there are several technical issues that complicate matters.</p>

    <p class="text-gray-300">Recall that in the overview above, we claimed that <span class="math">\\mathsf{Compute}(f)</span> merely runs GKR, in addition to a Reveal protocol which helps the delegator verify the GKR protocol. There are several technical reasons why this actually does not work. In what follows, we explain what are the main technical problems with this simple idea, and we give the highlevel idea of how to overcome these problems.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The first technicality (the easiest one to deal with), is that the GKR delegation scheme does not have a negligible soundness error. In our setting, especially in the setting of memory delegation, it is very important to have negligible soundness. The reason is that if the soundness is non-negligible, then a cheating worker may cheat in the update procedure of the memory delegation scheme (which is also being delegated). The problem is that if a worker cheats even once in an update procedure, all soundness guarantees are mute from that point on. So, we really need the soundness error to be negligible. In order to reduce the soundness error, we will run the GKR protocol in parallel <span class="math">u</span> times (for any parameter <span class="math">u</span> such that <span class="math">1/2^{u}=\\mathsf{ngl}(k)</span>, where <span class="math">k</span> is the security parameter). We denote the <span class="math">u</span>-fold parallel repetition of GKR by <span class="math">\\mathrm{GKR}^{(u)}</span>. As a result the worker will need to reveal to <span class="math">u</span> random points in the low-degree extension: <span class="math">\\mathrm{LDE}_{x}(r_{1}),\\ldots,\\mathrm{LDE}_{x}(r_{u})</span>.</li>

      <li>The second technical point is more subtle. In the offline stage, when the delegator computes the tree commitment <span class="math">T_{h}(\\mathrm{LDE}_{x})</span>, she needs to choose the parameters <span class="math">\\mathbb{H},\\mathbb{F},m</span> for the low-degree extension. The typical choice for these parameters is:</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\mathrm{polylog}(n),\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">),\\ m=O\\left(\\frac{\\log n}{\\log\\log n}\\right),$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where $n=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. When delegating the computation of a function </span>f<span class="math">, the worker and delegator run </span>\\mathrm{GKR}^{(u)}(f)<span class="math"> and need to verify </span>\\mathrm{LDE}_{x}(r_{i})=v_{i}<span class="math"> for random points </span>r_{1},\\ldots,r_{u}<span class="math">. However, here the parameters of the low-degree extension </span>\\mathrm{LDE}_{x}<span class="math"> depend on the depth </span>d<span class="math"> of the circuit computing </span>f$. Namely, looking at the parameters given in <em>[x10]</em> (see Theorem 8), the parameters of the low-degree extension are</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\theta(d\\cdot\\log n),\\ m^{\\prime}=\\theta\\left(\\frac{\\log n}{\\log d}\\right),\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">).$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Therefore, the worker cannot simply execute the Reveal protocols of the memory delegation or the streaming delegation. In the memory setting, the tree commitment is w.r.t. parameters <span class="math">\\mathbb{H},\\mathbb{F},m</span> whereas the delegator needs to verify <span class="math">\\mathrm{LDE}_{x}^{\\mathbb{F}^{\\prime},\\mathbb{H}^{\\prime},m^{\\prime}}(r_{i})=v_{i}</span>. In the streaming setting, the secret state of the delegator is <span class="math">(z,\\mathrm{LDE}_{x}^{\\mathbb{F},\\mathbb{H},m}(z))</span>, as opposed to <span class="math">(z,\\mathrm{LDE}_{x}^{\\mathbb{F}^{\\prime},\\mathbb{H}^{\\prime},m^{\\prime}}(z))</span>, thus the Reveal protocol described in Section 2.2 doesn’t work.</p>

    <p class="text-gray-300">We get around this technical problem by delegating the functions <span class="math">g_{r_{i}}(x)\\triangleq\\mathrm{LDE}_{x}^{\\mathbb{F}^{\\prime},\\mathbb{H}^{\\prime},m^{\\prime}}(r_{i})</span>. Luckily, these functions can be computed by a poly-size circuit of depth at most <span class="math">\\log^{2}n</span>, assuming the delegated function <span class="math">f</span> is of poly-size (see Proposition 6). We delegate the computation</p>

    <p class="text-gray-300">of each of these <span class="math">g_{r_i}</span> using <span class="math">\\mathrm{GKR}^{(u)}</span> to ensure negligible soundness. Thus, finally the worker will need to reveal to <span class="math">u^2</span> points in <span class="math">\\mathrm{LDE}_x</span> (<span class="math">u</span> points for each <span class="math">g_{r_i}</span>).</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The final technical difficulty is that all these algorithms need to run in parallel, since we want our final delegation schemes to be non-interactive (i.e., to consist of only two messages). Typically, there is no problem in running several two-message protocols in parallel [BIN97, CHS05]. However, in our case, the delegator uses a common secret input in these protocols. Namely, the delegator uses secret randomness <span class="math">r_1, \\ldots, r_u \\in (\\mathbb{F}&#x27;)^{m&#x27;}</span> in the parallel repetition of the delegation protocol <span class="math">\\mathrm{GKR}(f)</span> which ends with her needing to verify that <span class="math">\\mathrm{LDE}_x^{\\mathbb{F}&#x27;, \\mathbb{H}&#x27;, m&#x27;}(r_i) = v_i</span> for every <span class="math">i \\in [u]</span>. In addition she uses these same <span class="math">r_i</span>'s in the delegation protocols <span class="math">\\mathrm{GKR}(g_{r_i})</span>. Moreover, at the end of each of the <span class="math">\\mathrm{GKR}(g_{r_i})</span> protocols, the delegator needs to verify that <span class="math">\\mathrm{LDE}_x^{\\mathbb{F}, \\mathbb{H}, m}(z_{i,j}) = w_{i,j}</span> for random points <span class="math">z_{i,1}, \\ldots, z_{i,u} \\in \\mathbb{F}^m</span>. Finally, they also run a reveal protocol for each <span class="math">z_{i,j}</span>, denoted by <span class="math">\\mathrm{Reveal}(z_{i,j})</span>.</li>

    </ol>

    <p class="text-gray-300">We note that the protocol <span class="math">\\mathrm{GKR}(f)</span> (resp. <span class="math">\\mathrm{GKR}(g)</span>) is not sound if the <span class="math">r_i</span>'s (resp. <span class="math">z_{i,j}</span>'s) are a priori known to the worker. To ensure that soundness still holds even if we run all these algorithms in parallel, we mask parts of the delegator's message using a PIR scheme or an FHE scheme, and then we claim that the soundness error remains negligible. To this end, we use our parallel composition lemma (Lemma 24), which roughly states that if a set of protocols <span class="math">\\Pi_1, \\ldots, \\Pi_t</span> are executed in parallel, and the verifiers use the same common private randomness <span class="math">p</span> in all these protocols, then the soundness remains if the messages of the verifiers hide this common secret randomness <span class="math">p</span>. (We refer the reader to Section 5 for details.)</p>

    <h2 id="sec-21" class="text-2xl font-bold">3 Preliminaries</h2>

    <h3 id="sec-22" class="text-xl font-semibold mt-8">3.1 Computational Private Information Retrieval (PIR)</h3>

    <p class="text-gray-300"><strong>Definition 5</strong> Let <span class="math">k</span> be the security parameter and <span class="math">N</span> be the database size. Let <span class="math">Q^{\\mathrm{PIR}}</span> and <span class="math">D^{\\mathrm{PIR}}</span> be probabilistic circuits, and let <span class="math">R^{\\mathrm{PIR}}</span> be a deterministic circuit. We say that <span class="math">\\mathrm{PIR} = (Q^{\\mathrm{PIR}}, D^{\\mathrm{PIR}}, R^{\\mathrm{PIR}})</span> is a poly-logarithmic private information retrieval scheme if the following conditions are satisfied:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>(Size Restriction:) <span class="math">Q^{\\mathrm{PIR}}</span> and <span class="math">R^{\\mathrm{PIR}}</span> are of size <span class="math">\\leq \\mathrm{poly}(k, \\log N)</span>, and <span class="math">D^{\\mathrm{PIR}}</span> is of size <span class="math">\\leq \\mathrm{poly}(k, N)</span>. The output of <span class="math">Q^{\\mathrm{PIR}}</span> and <span class="math">D^{\\mathrm{PIR}}</span> is of size <span class="math">\\leq \\mathrm{poly}(k, \\log N)</span>.</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>(Perfect Correctness:) <span class="math">\\forall N, \\forall k, \\forall \\text{database } x = (x_1, x_2, \\ldots, x_N) \\in \\{0, 1\\}^N</span>, and <span class="math">\\forall i \\in [N]</span>,</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Pr \\left[ R ^ {\\mathrm {P I R}} (k, N, i, (q, s), a) = x _ {i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(q, s) \\leftarrow Q ^ {\\mathrm {P I R}} (k, N, i), a \\leftarrow D ^ {\\mathrm {P I R}} (k, x, q) \\right] = 1</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>(User Privacy:) <span class="math">\\forall N, \\forall k, \\forall i, j \\in [N]</span>, and <span class="math">\\forall</span> adversary <span class="math">\\mathcal{A}</span> of size at most <span class="math">2^{k^3}</span>,</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Pr [ \\mathcal {A} (k, N, q) = 1</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(q, s) \\leftarrow Q ^ {\\mathrm {P I R}} (k, N, i) ] - \\Pr [ \\mathcal {A} (k, N, q) = 1</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(q, s) \\leftarrow Q ^ {\\mathrm {P I R}} (k, N, j) ] \\right</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq 2 ^ {- k ^ {3}}.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">6We note that there are several ways to improve efficiency, such as thinking of <span class="math">(g_{r_1},\\ldots ,g_{r_u})</span> as one function. However, for the sake of simplicity of exposition, we focus on the simplest (rather than most efficient) solution.</p>

    <p class="text-gray-300">7For simplicity, we only define perfect correctness. However, usually a PIR scheme allows a negligible probability of error.</p>

    <p class="text-gray-300">13</p>

    <p class="text-gray-300">14</p>

    <h2 id="sec-23" class="text-2xl font-bold">3.2 Fully Homomorphic Encryption</h2>

    <p class="text-gray-300">A public-key encryption scheme <span class="math">\\mathbb{E} = (\\mathrm{KeyGen},\\mathrm{Enc},\\mathrm{Dec})</span> is said to be <em>fully homomorphic</em> if it is associated with an additional polynomial-time algorithm Eval, that takes as input a public key <span class="math">\\mathsf{pk}</span>, a ciphertext <span class="math">\\hat{x} = \\mathrm{Enc}_{\\mathsf{pk}}(x)</span> and a circuit <span class="math">C</span>, and outputs, a new ciphertext <span class="math">c = \\mathrm{Eval}_{\\mathsf{pk}}(\\hat{x},C)</span>, such that <span class="math">\\mathrm{Dec}_{\\mathsf{sk}}(c) = C(x)</span>, where <span class="math">\\mathsf{sk}</span> is the secret key corresponding to the public key <span class="math">\\mathsf{pk}</span>. It is required that the size of <span class="math">c = \\mathrm{Eval}_{\\mathsf{pk}}(\\mathrm{Enc}_{\\mathsf{pk}}(x),C)</span> depends polynomially on the security parameter and the length of <span class="math">C(x)</span>, but is otherwise independent of the size of the circuit <span class="math">C</span>. We also require that Eval is deterministic, and the scheme has perfect correctness (i.e. it always holds that <span class="math">\\mathrm{Dec}_{\\mathsf{sk}}(\\mathrm{Enc}_{\\mathsf{pk}}(x)) = x</span> and that <span class="math">\\mathrm{Dec}_{\\mathsf{sk}}(\\mathrm{Eval}_{\\mathsf{pk}}(\\mathrm{Enc}_{\\mathsf{pk}}(x),C)) = C(x)</span>). For security, we simply require that <span class="math">\\mathbb{E}</span> is semantically secure.</p>

    <p class="text-gray-300">In a recent breakthrough, Gentry [Gen09] proposed a fully homomorphic encryption scheme based on ideal lattices. Following this, Dijk, Gentry, Halevi and Vaikuntanathan [vDGHV10] proposed an alternative construction based on the extended GCD assumption. In these schemes, the complexity of the algorithms (KeyGen, Enc, Dec) depends linearly on the <em>depth</em> <span class="math">d</span> of the circuit <span class="math">C</span>, where <span class="math">d</span> is an upper bound on the depth of the circuit <span class="math">C</span> that are allowed as inputs to Eval. However, under the additional assumption that these schemes are circular secure (i.e., remain secure even given an encryption of the secret key), the complexity of these algorithms are independent of <span class="math">C</span>.</p>

    <p class="text-gray-300">Our streaming memory delegation scheme relies on the existence of a fully homomorphic scheme. For the sake of simplicity, we assume that the FHE scheme has perfect completeness. We note that the FHE schemes of both [Gen09] and [vDGHV10] indeed have perfect completeness.</p>

    <h2 id="sec-24" class="text-2xl font-bold">3.3 Low Degree Extension</h2>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">\\mathbb{H}</span> be an extension field of <span class="math">\\mathbb{GF}[2]</span>, and let <span class="math">\\mathbb{F}</span> be an extension field of <span class="math">\\mathbb{H}</span> (and in particular, an extension field of <span class="math">\\mathbb{GF}[2]</span>), where $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">. We always assume that field operations can be performed in time that is poly-logarithmic in the field size. Fix an integer </span>m \\in \\mathbb{N}<span class="math">. In what follows, we define the low degree extension of an </span>n<span class="math">-element string </span>(w_0, w_1, \\ldots, w_{n-1}) \\in \\mathbb{F}^n<span class="math"> with respect to </span>\\mathbb{F}, \\mathbb{H}, m<span class="math">, where </span>n \\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^m$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Fix $\\alpha : \\mathbb{H}^m \\to \\{0,1,\\ldots,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^m - 1\\}<span class="math"> to be any (efficiently computable) one-to-one function. In this paper, we take </span>\\alpha<span class="math"> to be the lexicographic order of </span>\\mathbb{H}^m<span class="math">. We can view </span>(w_0, w_1, \\ldots, w_{n-1})<span class="math"> as a function </span>W: \\mathbb{H}^m \\to \\mathbb{F}$, where</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">W(z) = \\begin{cases} w_{\\alpha(z)} &amp;amp; \\text{if } \\alpha(z) &amp;lt; n, \\\\ 0 &amp;amp; \\text{otherwise.} \\end{cases} \\tag{2}</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A basic fact is that there exists a unique extension of <span class="math">W</span> into a function <span class="math">\\tilde{W}: \\mathbb{F}^m \\to \\mathbb{F}</span> (which agrees with <span class="math">W</span> on <span class="math">\\mathbb{H}^m</span>; i.e., $\\tilde{W}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{\\mathbb{H}^m} \\equiv W<span class="math">), such that </span>\\tilde{W}<span class="math"> is an </span>m<span class="math">-variate polynomial of degree at most </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- 1<span class="math"> in each variable. Moreover, as is formally stated in the proposition below, the function </span>\\tilde{W}$ can be expressed as</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\tilde{W}(t_1, \\ldots, t_m) = \\sum_{i=0}^{n-1} \\tilde{\\beta}_i(t_1, \\ldots, t_m) \\cdot w_i,</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where each <span class="math">\\tilde{\\beta}_i:\\mathbb{F}^m\\to \\mathbb{F}</span> is an <span class="math">m</span>-variate polynomial, that depends only on the parameters <span class="math">\\mathbb{H},\\mathbb{F}</span>, and <span class="math">m</span> (and is independent of <span class="math">w</span>), of size $\\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,m)<span class="math"> and degree </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- 1$ in each variable.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The function <span class="math">\\tilde{W}</span> is called the low degree extension of <span class="math">w = (w_0, w_1, \\ldots, w_{n-1})</span> with respect to <span class="math">\\mathbb{F}, \\mathbb{H}, m</span>, and is denoted by <span class="math">\\mathrm{LDE}_w^{\\mathbb{F}, \\mathbb{H}, m}</span>. We omit the index of <span class="math">\\mathbb{F}, \\mathbb{H}, m</span> when the context is clear. Also, sometimes we use <span class="math">\\tilde{W}</span> for simplicity.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><strong>Proposition 6</strong> There exists a Turing machine that takes as input an extension field <span class="math">\\mathbb{H}</span> of <span class="math">\\mathbb{GF}[2]</span>, an extension field <span class="math">\\mathbb{F}</span> of <span class="math">\\mathbb{H}</span>, and integer <span class="math">m</span>. The machine runs in time $\\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, m, \\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> and outputs the unique </span>2m<span class="math">-variate polynomial </span>\\tilde{\\beta}: \\mathbb{F}^m \\times \\mathbb{F}^m \\to \\mathbb{F}<span class="math"> of degree </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- 1<span class="math"> in each variable (represented as an arithmetic circuit of degree </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- 1<span class="math"> in each variable), such that for every </span>w = (w_0, w_1, \\ldots, w_{n-1}) \\in \\mathbb{F}^n<span class="math">, where </span>n \\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^m<span class="math">, and for every </span>z \\in \\mathbb{F}^m$,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\tilde {W} (z) = \\sum_ {p \\in \\mathbb {H} ^ {m}} \\tilde {\\beta} (z, p) \\cdot W (p),</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where <span class="math">W: \\mathbb{H}^m \\to \\mathbb{F}</span> is the function corresponding to <span class="math">(w_0, w_1, \\ldots, w_{n-1})</span> as defined in Equation (2), and <span class="math">\\tilde{W}: \\mathbb{F}^m \\to \\mathbb{F}</span> is its low degree extension (i.e., the unique extension of <span class="math">W: \\mathbb{H}^m \\to \\mathbb{F}</span> of degree at most $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- 1$ in each variable).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Moreover, <span class="math">\\tilde{\\beta}</span> can be evaluated in time $\\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, m, \\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">. Namely, there exists a Turing machine that runs in time </span>\\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, m, \\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> that takes as input parameters </span>\\mathbb{H}, \\mathbb{F}, m<span class="math"> (as above), and a pair </span>(z, p) \\in \\mathbb{F}^m \\times \\mathbb{F}^m<span class="math">, and outputs </span>\\tilde{\\beta}(z, p)<span class="math">. Furthermore, there exists a circuit for evaluating </span>\\tilde{\\beta}<span class="math"> in the above sense with size </span>\\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, m, \\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> and depth </span>\\mathrm{poly}(m, \\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><strong>Corollary 7</strong> There exists a Turing machine that takes as input an extension field <span class="math">\\mathbb{H}</span> of <span class="math">\\mathbb{GF}[2]</span>, an extension field <span class="math">\\mathbb{F}</span> of <span class="math">\\mathbb{H}</span>, an integer <span class="math">m</span>, a sequence <span class="math">w = (w_0, w_1, \\ldots, w_{n-1}) \\in \\mathbb{F}^n</span> such that $n \\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^m<span class="math">, and a coordinate </span>z \\in \\mathbb{F}^m<span class="math">. It runs in time </span>n \\cdot \\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, m, \\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">, and outputs the value </span>\\tilde{W}(z)<span class="math">, where </span>\\tilde{W}<span class="math"> is the unique low-degree extension of </span>w<span class="math"> (with respect to </span>\\mathbb{H}, \\mathbb{F}, m<span class="math">). Furthermore, there exists a circuit for the same task with size </span>n \\cdot \\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, m, \\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> and depth </span>\\mathrm{poly}(m, \\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h2 id="sec-25" class="text-2xl font-bold">3.4 Delegation Schemes</h2>

    <p class="text-gray-300">In recent years, as cloud computing is gaining popularity, there have been many attempts to construct efficient delegation schemes. Loosely speaking, a delegation scheme is a protocol between a delegator <span class="math">\\mathsf{D}</span> and a worker <span class="math">\\mathsf{W}</span>, where the delegator asks the worker to do some computation, and prove that he indeed did the computation correctly. Typically, a delegation scheme is with respect to a class of functions <span class="math">\\mathcal{F}</span>, and the requirement is that on input <span class="math">(f,x)</span> where <span class="math">f\\in \\mathcal{F}</span> and <span class="math">x</span> is in the domain of <span class="math">f</span>, the worker outputs <span class="math">f(x)</span>, along with a proof (which may be interactive or non-interactive). The requirement is that the worker runs in time that is polynomial in the size of <span class="math">f</span> (when representing <span class="math">f</span> as a circuit), and the delegator runs in time that is significantly shorter than the size of <span class="math">f</span> (as otherwise, it would simply compute <span class="math">f(x)</span> on its own). In this work, we use the 2-message delegation protocol of [GKR08], which in turn uses a round reduction technique from [KR09]. The protocol has the following guarantees.</p>

    <p class="text-gray-300">9 Throughout this work, when we refer to a machine that takes as input a field, we mean that the machine is given a short (poly-logarithmic in the field size) description of the field, that permits field operations to be computed in time that is poly-logarithmic in the field size.</p>

    <p class="text-gray-300">15</p>

    <h6 id="sec-26" class="text-base font-medium mt-4">Theorem 8</h6>

    <p class="text-gray-300"><em>[x18, x20]</em> Assume the existence of a poly-logarithmic PIR scheme, as defined in Definition 5. Let <span class="math">k</span> be the security parameter, and let <span class="math">\\mathcal{F}</span> be the family of functions computable by <span class="math">\\mathcal{L}</span>-space uniform boolean circuits of size <span class="math">S</span> and depth <span class="math">d\\geq\\log S</span>. Then, there exists a delegation protocol for <span class="math">\\mathcal{F}</span> with the following properties.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The worker runs in time <span class="math">\\mathrm{poly}(S,k)</span> and the delegator runs in time <span class="math">n\\cdot\\mathrm{poly}(k,d)</span>, where <span class="math">n</span> is the length of the input.</li>

      <li>The protocol has perfect completeness and soundness <span class="math">s\\leq\\frac{1}{2}</span> (can be made arbitrarily small), where soundness is against any cheating worker of size <span class="math">\\leq 2^{k^{3}}</span>.</li>

      <li>The protocol consists of two messages, with communication complexity <span class="math">d\\cdot\\mathrm{poly}(k,\\log S)</span>. Moreover, the first message sent by the delegator depends only on her random coin tosses, and is independent of the statement being proved.</li>

      <li>If the delegator is given oracle access to the low-degree extension of <span class="math">x</span>, rather than being given the input <span class="math">x</span> itself, then it runs in time <span class="math">\\mathrm{poly}(k,d)</span>, and the protocol still has all the properties described above, assuming the parameters <span class="math">\\mathbb{H},\\mathbb{F},m</span> of the low-degree extension satisfy the following:</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\theta(d\\cdot\\log n),\\ m=\\theta\\left(\\frac{\\log n}{\\log d}\\right),\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where <span class="math">\\mathrm{poly}</span> is a large enough polynomial. Moreover, the delegator queries the low-degree extension of <span class="math">x</span> at a single point, which is uniformly random (over his coin tosses).</p>

    <p class="text-gray-300">Throughout this paper, we denote this protocol by GKR.</p>

    <h3 id="sec-27" class="text-xl font-semibold mt-8">3.5 Merkle Tree Commitments</h3>

    <h6 id="sec-28" class="text-base font-medium mt-4">Definition 9</h6>

    <p class="text-gray-300">Let <span class="math">h:\\{0,1\\}^{k}\\times\\{0,1\\}^{k}\\rightarrow\\{0,1\\}^{k}</span> be a hash function. A Merkle tree commitment of a sting <span class="math">x\\in\\{0,1\\}^{n}</span> w.r.t. <span class="math">h</span>, denoted by <span class="math">T_{h}(x)</span>, is a <span class="math">k</span>-bit string, computed as follows: The input <span class="math">x</span> is partitioned into <span class="math">m=\\lceil n/k\\rceil</span> blocks <span class="math">x=(B_{1},\\ldots,B_{m})</span>, each block of size <span class="math">k</span>. These blocks are partitioned into pairs <span class="math">(B_{2i-1},B_{2i})</span>, and the hash function <span class="math">h</span> is applied to each pair, resulting in <span class="math">m/2</span> blocks. Then, again these <span class="math">m/2</span> blocks are partitioned into pairs, and the hash function <span class="math">h</span> is applied to each of these pairs, resulting with <span class="math">m/4</span> blocks. This is repeated <span class="math">\\log m</span> times, resulting in a binary tree of hash values, until one block remains. This block is <span class="math">T_{h}(x)</span>.</p>

    <h2 id="sec-29" class="text-2xl font-bold">4 Our Leakage Lemma</h2>

    <p class="text-gray-300">In this section, we define some machinery that is needed in order to prove the soundness of our streaming delegation scheme in Section 9. The main contribution of this section is a leakage lemma (Lemma 22), which essentially says that given an encryption <span class="math">(\\mathsf{pk},\\mathrm{Enc}_{\\mathsf{pk}}(S))</span> of a random 2-dimensional subspace <span class="math">S\\leftarrow\\mathbb{F}^{m\\times 2}</span>, and given any additional arbitrary (not necessarily efficient) bit of leakage <span class="math">b=L(\\mathsf{pk},\\mathrm{Enc}_{\\mathsf{pk}}(S))</span>, then a random vector <span class="math">z\\leftarrow S</span> is computationally indistinguishable from a truly random vector <span class="math">u\\leftarrow\\mathbb{F}^{m}</span>. We formally state and prove this lemma in Section 4.2.</p>

    <p class="text-gray-300">This lemma plays a central role in analyzing the (reusable) soundness of our streaming delegation scheme. In this scheme, the delegator has a secret state, and we need to prove that a cheating worker cannot learn any information about her secret state, even after running several delegation protocols with the delegator, and learning the bit of whether she accepted or rejected. In the soundness proof, this verdict bit is thought of as a leakage bit.</p>

    <p class="text-gray-300">In the proof of Lemma 22, which is our main leakage lemma, we use another leakage lemma (Lemma 16), which is formally stated below and proved in Section 4.1. This leakage lemma roughly says that conditioning on a short leakage cannot decrease the conditional pseudo-entropy of a random variable too much.</p>

    <p class="text-gray-300">In order to even state these lemmas formally, we first need to define the notion of conditional pseudo-entropy. There are several possible notions of conditional pseudo-entropy with subtle differences. In the following, we present our definition along with discussions on other possible notions. We start with the information-theoretic notion of min-entropy and conditional min-entropy.</p>

    <p class="text-gray-300"><strong>Definition 10 (Min-Entropy)</strong> Let <span class="math">X</span> be a distribution over finite support. The min-entropy of <span class="math">X</span> is defined as</p>

    <div class="my-4 text-center"><span class="math-block">\\mathbf{H}_{\\infty}(X) = \\min_{x \\in \\operatorname{supp}(X)} \\log \\frac{1}{\\Pr[X = x]} = -\\log \\left(\\max_{x \\in \\operatorname{supp}(X)} \\Pr[X = x]\\right).</span></div>

    <p class="text-gray-300"><strong>Definition 11 (Conditional Min-Entropy)</strong> Let <span class="math">(X, C)</span> be a joint distribution over finite support. The (worst-case) conditional min-entropy of <span class="math">X</span> conditioned on <span class="math">C</span> is defined as</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{H}_{\\infty}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) = \\min_{(x, c) \\in \\operatorname{supp}(X, C)} \\log \\frac{1}{\\Pr[X = x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C = c]} = \\min_{c \\in \\operatorname{supp}(C)} \\mathbf{H}_{\\infty}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{C = c}).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The above worst-case definition may seem too stringent as it requires <span class="math">X</span> to have good min-entropy conditioned on every possible <span class="math">c \\in \\operatorname{supp}(C)</span>. Several relaxed definitions have been used. For example, Renner and Wolf [RW05] defined a smooth version of the above definition, where <span class="math">X</span> has <span class="math">\\varepsilon</span>-smooth conditional min-entropy <span class="math">n</span> conditioned on <span class="math">C</span> if <span class="math">(X, C)</span> is <span class="math">\\varepsilon</span>-close in statistical distance to a distribution <span class="math">(X&#x27;, C&#x27;)</span> with $\\mathbf{H}_{\\infty}(X'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C') = n<span class="math">. Such a slackness will be implicitly allowed in our definition of conditional pseudo-entropy. On the other hand, Dodis, Ostrovsky, Reyzin, and Smith [DORS08] defined an average-case version of conditional min-entropy, where </span>\\mathbf{H}_{\\infty}^{avg}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) = -\\log(\\mathrm{E}_{c \\leftarrow C}[\\max_x \\{\\Pr[X = x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C = c]\\}])$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In the computational setting, Hsiao, Lu, and Reyzin [HLR07] defined conditional HILL entropy. Informally, <span class="math">X</span> has high conditional HILL entropy conditioned on <span class="math">C</span> if there exists a random variable <span class="math">Y = Y(C)</span> such that (1) <span class="math">(X, C)</span> is computationally indistinguishable from <span class="math">(Y, C)</span>, and (2) <span class="math">Y</span> has high average conditional min-entropy conditioned on <span class="math">C</span> (a la [DORS08]). In this work, we use a slightly different definition. The only difference between our definition and the [HLR07] definition is that we use the worse-case version of conditional min-entropy, as opposed to the average-case version. We work with the worst-case definition since it is more convenient for our application and makes the analysis simpler. For convenience, we refer to our notion also as conditional HILL entropy.</p>

    <p class="text-gray-300">12We note that the two notions of [RW05] and [DORS08] are equivalent up to an additive <span class="math">\\log(1 / \\varepsilon)</span> term. A detailed discussion can be found in Appendix B of [DORS08].</p>

    <p class="text-gray-300">17</p>

    <p class="text-gray-300">18</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Definition 12 (Conditional HILL Entropy) Let <span class="math">(X, C)</span> be a joint distribution over a finite support, and let <span class="math">n, s \\in \\mathbb{N}</span> and <span class="math">\\varepsilon \\in (0,1)</span> be parameters. We say that <span class="math">X</span> conditioned on <span class="math">C</span> has conditional HILL entropy at least <span class="math">n</span> against circuits of size <span class="math">s</span> with advantage <span class="math">\\varepsilon</span>, denoted by $\\mathbf{H}_{\\varepsilon,s}^{\\mathrm{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n<span class="math">, if there exists a distribution </span>Y = Y(C)<span class="math"> jointly distributed with </span>C<span class="math"> such that (1) </span>\\mathbf{H}_{\\infty}(Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n<span class="math">, and (2) </span>(X, C)<span class="math"> and </span>(Y, C)<span class="math"> are computationally indistinguishable against circuits of size </span>s<span class="math"> with advantage </span>\\varepsilon$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In the asymptotic setting where there is a security parameter <span class="math">k</span>, we say $\\mathbf{H}^{\\mathrm{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n<span class="math">, if for every constant </span>c \\in \\mathbb{N}<span class="math">, </span>\\mathbf{H}_{k^{-c},k^c}^{\\mathrm{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Remark 13 Note that in the above definition, we only consider distributions <span class="math">(Y,C)</span> that are indistinguishable from <span class="math">(X,C)</span>, i.e., we do not allow modifying the distribution of <span class="math">C</span>. An alternative weaker definition is to consider all distributions <span class="math">(X&#x27;,C&#x27;)</span> that are indistinguishable from <span class="math">(X,C)</span>. The two definitions may not be equivalent in general.¹⁴ We emphasize that the more stringent definition seems more relevant for cryptographic applications, since <span class="math">C</span> is often some leakage information on <span class="math">X</span> learned by an adversary. We further emphasize that we do not claim that our definition is the "right" one, and we only use it as a tool to prove our main result.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Our goal is to show that if <span class="math">X</span> has high conditional HILL entropy conditioned on <span class="math">C</span> (say, $\\mathbf{H}^{\\mathrm{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n<span class="math">) and </span>B = B(X,C)<span class="math"> is an arbitrary, but short (say, one bit) leakage information on </span>X<span class="math">, then after further conditioning on </span>B<span class="math">, </span>X<span class="math"> still has high conditional HILL entropy (i.e., </span>\\mathbf{H}^{\\mathrm{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C,B) \\geq n - t<span class="math"> for some small </span>t<span class="math">). When </span>B<span class="math"> can be efficiently generated from </span>(X,C)<span class="math">, this is very easy to prove. However, proving this for general </span>B = B(X,C)$ is not trivial. Indeed, in order to prove this, we need to further strengthen our definition of conditional HILL entropy.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Definition 14 (Conditional HILL Entropy w.r.t. Samplable Distributions) Let <span class="math">k</span> be a security parameter. For a finite distribution <span class="math">(X, C)</span>, we say $\\mathbf{H}^{\\mathrm{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n<span class="math"> w.r.t. samplable distributions if there exists a distribution </span>Y = Y(C)$ such that the following holds.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">1. $\\mathbf{H}_{\\infty}(Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">(X,C)</span> and <span class="math">(Y,C)</span> are computationally indistinguishable.</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">3. There exists a <span class="math">\\mathrm{poly}(k)</span> time algorithm <span class="math">\\mathrm{Smp}</span> that on input <span class="math">c \\in \\operatorname{supp}(C)</span>, outputs a sample $y \\gets (Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{C=c})$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Remark 15 This definition differs from Definition 12 in two ways. First, we require the distributions $Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{C=c}<span class="math"> to be efficiently samplable for every </span>c<span class="math">. Second, we require a single distribution </span>Y = Y(C)<span class="math"> such that </span>(X, C)<span class="math"> and </span>(Y, C)<span class="math"> are indistinguishable for any </span>\\mathrm{poly}(k)<span class="math">-size distinguisher; whereas in Definition 12, we fix the size </span>k^c<span class="math"> of distinguisher first and require a distribution </span>Y = Y(C)<span class="math"> such that </span>(X, C)<span class="math"> and </span>(Y, C)<span class="math"> are indistinguishable for </span>k^c$-size distinguishers.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Lemma 16 Let <span class="math">k</span> be a security parameter and <span class="math">n, \\ell, t</span> be any parameters such that <span class="math">n \\leq \\mathrm{poly}(k)</span>, <span class="math">\\ell = O(\\log k)</span>, and <span class="math">t = \\omega (\\log k)</span>. Let <span class="math">(X, C)</span> be a joint distribution over <span class="math">\\{0,1\\}^<em> \\times \\{0,1\\}^</em></span> of <span class="math">\\mathrm{poly}(k)</span> length. If $\\mathbf{H}^{\\mathrm{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n<span class="math"> w.r.t. samplable distributions, then for any distribution </span>B = B(X, C)<span class="math"> over </span>\\{0,1\\}^\\ell$, we have</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{H}^{\\mathrm{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C,B) \\geq n - t.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">The lemma says that further conditioning on <span class="math">O(\\log k)</span> bits can only decrease the conditional HILL entropy by <span class="math">\\omega(\\log k)</span>. Note that an upper bound of <span class="math">O(\\log k)</span> on the length of <span class="math">B</span> is necessary, since the pseudo-entropy of <span class="math">X</span> could be generated from merely <span class="math">\\omega(\\log k)</span> bits of real entropy. For example, <span class="math">X</span> can be the output of a pseudo-random generator (PRG) with sub-exponential stretch, and <span class="math">B</span> can be the whole seed, if the length limit on <span class="math">B</span> is relaxed. On the other hand, we do not know whether the samplability assumption on <span class="math">Y(C)</span> is necessary or not. Moreover, we do not know whether we inherently need <span class="math">\\omega(\\log k)</span> entropy loss, or whether one can prove <span class="math">\\ell=O(\\log k)</span> entropy loss.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Before presenting the proof of the lemma, we first compare it with previous results of <em>[x10, x23]</em>. Dziembowski and Pietrzak <em>[x10]</em> (implicitly in Lemma 3), and Reingold, Trevisan, Tulsiani, and Vadhan <em>[x23]</em> (Theorem 1.3, phrased in a different language of “dense model theorem”) proved that if <span class="math">\\mathbf{H}^{\\mathsf{HILL}}(X)\\geq n</span> and <span class="math">E</span> is an event that occurs with probability <span class="math">p\\geq 1/\\mathrm{poly}(k)</span>, then after conditioning on the event <span class="math">E</span>, $\\mathbf{H}^{\\mathsf{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{E})\\geq n-\\log(1/p)<span class="math">. This implies a special case of our Lemma 16 where </span>C<span class="math"> is not present: Suppose </span>\\mathbf{H}^{\\mathsf{HILL}}(X)\\geq n<span class="math"> and </span>B=B(X)<span class="math"> is of length </span>O(\\log k)<span class="math">, then </span>\\mathbf{H}^{\\mathsf{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">B)\\geq n-\\omega(\\log k)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In contrast, we consider a more general setting where a (possibly long) prior leakage information <span class="math">C</span> is presented, which may information-theoretically determine <span class="math">X</span>. Indeed, in our setting, <span class="math">C</span> is an encryption of <span class="math">X</span> and hence determines <span class="math">X</span>.</p>

    <h3 id="sec-30" class="text-xl font-semibold mt-8">4.1 Proof of Lemma 16</h3>

    <h4 id="sec-31" class="text-lg font-semibold mt-6">4.1.1 Preliminaries</h4>

    <p class="text-gray-300">We proceed to present the proof of Lemma 16. The first part of our proof follows the same line as previous results <em>[x10, x23]</em>, where we convert (conditional) HILL-type entropy to (conditional) “metric-type” entropy, defined by Barak, Shaltiel, and Wigderson <em>[x6]</em>. On the other hand, the second part of our proof is more involved than previous results. We start by defining a conditional version of metric entropy.</p>

    <h5 id="sec-32" class="text-base font-semibold mt-4">Conditional Metric Entropy.</h5>

    <p class="text-gray-300">Loosely speaking, metric entropy is weaker than HILL entropy and is defined by switching the order of quantifiers in the definition of HILL entropy. Recall that the HILL definition says that <span class="math">X</span> has HILL entropy <span class="math">n</span> if there exists a random variable <span class="math">Y</span> with min-entropy <span class="math">n</span> such that every small distinguisher <span class="math">D</span> fails to distinguish between <span class="math">X</span> and <span class="math">Y</span>. In contrast, the definition of metric entropy requires that for every small distinguisher <span class="math">D</span>, there exists a random variable <span class="math">Y</span> (which may depend on <span class="math">D</span>) with min-entropy <span class="math">n</span> such that <span class="math">D</span> fails to distinguish between <span class="math">X</span> and <span class="math">Y</span>.</p>

    <h6 id="sec-33" class="text-base font-medium mt-4">Definition 17 (Conditional Metric Entropy)</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">(X,C)</span> be a joint distribution over a finite support. Let <span class="math">n,s\\in\\mathbb{N}</span> and <span class="math">\\varepsilon\\in(0,1)</span> be parameters. We say <span class="math">X</span> conditioned on <span class="math">C</span> has conditional metric entropy at least <span class="math">n</span> against <em>randomized circuits</em> of size <span class="math">s</span> with advantage <span class="math">\\varepsilon</span>, denoted by $\\mathbf{H}^{\\mathsf{metric}}_{\\varepsilon,s}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C)\\geq n<span class="math">, if for every <em>randomized circuit</em> </span>D<span class="math"> of size at most </span>s<span class="math">, there exists a distribution </span>Y=Y(C)<span class="math"> jointly distributed with </span>C<span class="math"> such that </span>\\mathbf{H}_{\\infty}(Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C)\\geq n$, and</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Pr[D(X,C)=1]-\\Pr[D(Y,C)=1]</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\varepsilon.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In the asymptotic setting where there is a security parameter <span class="math">k</span>, we say $\\mathbf{H}^{\\mathrm{metric}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n<span class="math">, if it holds that </span>\\mathbf{H}_{k^{-\\circ},k^{\\circ}}^{\\mathrm{metric}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n<span class="math"> for every constant </span>c \\in \\mathbb{N}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We emphasize that, except for the natural generalization to the conditional version, our definition differs from that of [BSW03] in that we allow the distinguishers to be randomized, as opposed to deterministic.¹⁶ The reason is that, as pointed out by Vadhan [Vad10] and Dziembowski and Pietrzak [DP08], the result of [BSW03] does not hold when deterministic distinguishers are considered, and randomized distinguishers should be used instead.¹⁷</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><strong>Lemma 18 (Theorem 5.2 of [BSW03], generalized)</strong> Let <span class="math">(X,C)</span> be a joint distribution over <span class="math">\\{0,1\\}^{m_1} \\times \\{0,1\\}^{m_2}</span>, and let <span class="math">\\varepsilon, \\delta &amp;gt; 0</span>, <span class="math">s, k \\in \\mathbb{N}</span> be parameters. If $\\mathbf{H}_{\\varepsilon,s}^{\\mathrm{metric}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n<span class="math">, then </span>\\mathbf{H}_{\\varepsilon+\\delta,s'}^{\\mathrm{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n<span class="math"> for </span>s' = s \\cdot O(\\delta^2/(m_1 + m_2))$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><strong>Lemma 18</strong> is proved in exactly the same way as the proof in [BSW03], where one uses von-Neuman’s min-max theorem [Neu28] to switch the order of quantifiers. For the sake of completeness, we give a proof sketch below.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><strong>Proof.</strong> (sketch) For the sake of contradiction, assume that $\\mathbf{H}_{\\varepsilon + \\delta, s'}^{\\mathrm{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) &lt; n<span class="math">. This means that for every distribution </span>Y = Y(C)<span class="math"> with </span>\\mathbf{H}_{\\infty}(Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n<span class="math">, there exists a size </span>s'<span class="math"> distinguisher </span>D<span class="math"> that distinguishes </span>(X, C)<span class="math"> from </span>(Y, C)<span class="math"> with advantage </span>\\geq \\varepsilon + \\delta<span class="math">. Applying min-max theorem, we obtain the following statement. There exists a distribution </span>\\mathcal{D}<span class="math"> over size-</span>s'<span class="math"> distinguishers such that for every </span>Y = Y(C)<span class="math"> with </span>\\mathbf{H}_{\\infty}(Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n$, we have</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\operatorname {E} _ {D \\leftarrow \\mathcal {D}} [ D (X, C) ] - \\operatorname {E} _ {D \\leftarrow \\mathcal {D}} [ D (Y, C) ] \\right</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq \\varepsilon + \\delta .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">Now, it can be shown by standard Chernoff and union bounds that there exists a set <span class="math">S = \\{D_1, \\ldots, D_{O((m_1 + m_2) / \\delta^2)}\\}</span> of circuits in <span class="math">\\operatorname{supp}(\\mathcal{D})</span> such that for every <span class="math">(z, c) \\in \\{0, 1\\}^{m_1} \\times \\{0, 1\\}^{m_2}</span>,</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\operatorname {E} _ {D \\leftarrow \\mathcal {D}} [ D (z, c) ] - \\operatorname {E} _ {D _ {i} \\leftarrow S} [ D _ {i} (z, c) ] \\right</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq \\delta / 2.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Since this holds point-wise, it follows that for every <span class="math">Y = Y(C)</span> with $\\mathbf{H}_{\\infty}(Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n$,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\operatorname {E} _ {D _ {i} \\leftarrow S} [ D _ {i} (X, C) ] - \\operatorname {E} _ {D _ {i} \\leftarrow S} [ D _ {i} (Y, C) ] \\right</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq \\varepsilon .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">We obtain a contradiction by observing that choosing a random circuit <span class="math">D_{i} \\gets S</span> and outputting <span class="math">D_{i}(z, c)</span> can be implemented by a size <span class="math">s = s&#x27; \\cdot O((m_1 + m_2) / \\delta^2)</span> randomized circuit.</p>

    <p class="text-gray-300">As a corollary, the lemma implies that conditional HILL entropy and conditional metric entropy are equivalent in the asymptotic setting.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><strong>Corollary 19</strong> Let <span class="math">k</span> be a security parameter. For every joint distribution <span class="math">(X, C)</span> of polynomially bounded length $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(X, C)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq \\mathrm{poly}(k)<span class="math">, we have </span>\\mathbf{H}^{\\mathrm{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) = \\mathbf{H}^{\\mathrm{metric}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">¹⁶ Note that, for HILL-type entropy, randomized distinguishers and deterministic distinguishers are essentially equivalent, since one can turn a randomized distinguisher to a deterministic one by fixing the “best” coins that preserves the advantage for distinguishing two distributions. In contrast, for the case of metric entropy, it is unclear whether randomized distinguishers can be converted into deterministic ones since the distinguisher needs to work for all distributions.</p>

    <p class="text-gray-300">¹⁷ [DP08], instead of using randomized distinguishers, use deterministic <span class="math">[0,1]</span>-valued distinguishers. We choose to use randomized circuit distinguishers since we find them to be more natural than circuits with <span class="math">[0,1]</span>-valued output.</p>

    <p class="text-gray-300">20</p>

    <p class="text-gray-300">21</p>

    <h2 id="sec-34" class="text-2xl font-bold">4.1.2 Formal Proof of Lemma 16</h2>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><strong>Proof.</strong> Suppose for contradiction that there exists a distribution <span class="math">B = B(X, C)</span> such that $\\mathbf{H}^{\\mathrm{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C, B) &lt; n - t<span class="math">. By Corollary 19, this implies that </span>\\mathbf{H}^{\\mathrm{metric}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C, B) &lt; n - t<span class="math">. Namely, there exists some constant </span>c_0 \\in \\mathbb{N}<span class="math"> and a <em>randomized</em> circuit </span>D<span class="math"> of size </span>k^{c_0}<span class="math"> such that for every distribution </span>Z = Z(C, B)<span class="math"> with </span>\\mathbf{H}_{\\infty}(Z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C, B) \\geq n - t$,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Pr \\left[ D (X, C, B) = 1 \\right] - \\Pr \\left[ D (Z, C, B) = 1 \\right] \\right</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">&gt; k ^ {- c _ {0}} \\stackrel {\\text {d e f}} {=} \\varepsilon . \\tag {3}</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">On the other hand, the fact that $\\mathbf{H}^{\\mathrm{HILL}}(X</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n<span class="math"> w.r.t. sampleable distributions implies that there exists a distribution </span>Y = Y(C)<span class="math"> such that (1) </span>\\mathbf{H}_{\\infty}(Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C) \\geq n<span class="math">, (2) </span>(X,C)<span class="math"> and </span>(Y,C)<span class="math"> are computationally indistinguishable, and (3) there exists a PPT algorithm Smp that on input </span>c \\in \\operatorname{supp}(C)<span class="math">, outputs a sample </span>y \\gets (Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{C=c})$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">For notational convenience, let</p>

    <div class="my-4 text-center"><span class="math-block">p _ {c, b} (z) \\triangleq \\Pr [ D (z, c, b) = 1 ].</span></div>

    <p class="text-gray-300">We construct a polynomial-size (randomized) circuit <span class="math">D&#x27;</span> that distinguishes between <span class="math">(X, C)</span> and <span class="math">(Y, C)</span>, as follows. On input <span class="math">(w, c)</span> which comes from either <span class="math">(X, C)</span> or <span class="math">(Y, C)</span>, <span class="math">D&#x27;</span> does the following:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">1. Use the sampling algorithm Smp to sample <span class="math">s = (4 \\cdot 2^{\\ell} / \\varepsilon)</span> independent samples of $y_{i} \\gets Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{C = c}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For every <span class="math">b \\in \\{0,1\\}^{\\ell}</span>, compute estimators for <span class="math">p_{c,b}(w)</span> and <span class="math">p_{c,b}(y_i)</span>, denoted by <span class="math">\\tilde{p}_{c,b}(w)</span> and <span class="math">\\tilde{p}_{c,b}(y_i)</span>, respectively. More specifically, run <span class="math">D(w,c,b)</span> (resp., <span class="math">D(y_i,c,b)</span>) with fresh randomness <span class="math">t \\triangleq \\Theta(\\ell(\\log^2 k)(\\log s)/\\varepsilon^2)</span> times, and let <span class="math">\\tilde{p}_{c,b}(w)</span> (resp., <span class="math">\\tilde{p}_{c,b}(y_i)</span>) be the average of the outputs.</li>

      <li>If there exists some <span class="math">b \\in \\{0,1\\}^{\\ell}</span> such that</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\tilde {p} _ {c, b} (w) \\geq \\max  _ {y _ {i}} \\left\\{\\tilde {p} _ {c, b} \\left(y _ {i}\\right) \\right\\} + \\varepsilon / 4,</span></div>

    <p class="text-gray-300">then output 1. Otherwise, output 0.</p>

    <p class="text-gray-300">Note that <span class="math">D&#x27;</span> can be implemented by a randomized circuit of size <span class="math">\\mathrm{poly}(k, 2^{\\ell}, 1 / \\varepsilon) = \\mathrm{poly}(k)</span>. We also note that the parameter <span class="math">t = \\Theta(\\ell(\\log^2 k)(\\log s) / \\varepsilon^2)</span> defined in Step 2 is chosen so that, with overwhelming probability, <em>all</em> estimators have error less than <span class="math">\\varepsilon / 8</span>, i.e.,</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\tilde {p} _ {c, b} (w) - p _ {c, b} (w) \\right</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">&lt;   \\varepsilon / 8, \\text { and } \\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\tilde {p} _ {c, b} \\left(y _ {i}\\right) - p _ {c, b} \\left(y _ {i}\\right) \\right</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">&lt;   \\varepsilon / 8. \\tag {4}</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">This follows from a standard Chernoff bound,<span class="math">^{18}</span> which says that a single estimator has error less than <span class="math">\\varepsilon / 8</span> with probability <span class="math">1 - e^{-\\Omega (t\\varepsilon^2)} = 1 - e^{-\\Omega (\\ell (\\log^2 k)(\\log s))}</span>. Since there are <span class="math">2^{\\ell} \\cdot (s + 1)</span> estimators, by a union bound, the probability that all estimators have error less than <span class="math">\\varepsilon / 8</span> is at least</p>

    <div class="my-4 text-center"><span class="math-block">1 - e ^ {- \\Omega (\\ell (\\log^ {2} k) (\\log s))} \\cdot 2 ^ {\\ell} \\cdot (s + 1) \\geq 1 - \\mathsf {n g l} (k).</span></div>

    <p class="text-gray-300">We proceed to prove the following two claims, which jointly imply that <span class="math">D&#x27;</span> distinguishes between <span class="math">(X, C)</span> and <span class="math">(Y, C)</span> with advantage <span class="math">\\varepsilon / 4 - \\mathsf{ngl}</span>, and thus completes the proof.</p>

    <p class="text-gray-300"><span class="math">^{18}</span>We use the following basic version of Chernoff bound: Let <span class="math">A_{1},\\ldots ,A_{n}</span> be i.i.d. boolean random variables with <span class="math">\\operatorname*{Pr}[A_i = 1] = p</span>, and let <span class="math">\\varepsilon \\in (0,1)</span> be a parameter. Then</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Pr \\left[ \\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\left(\\frac {1}{n} \\sum A _ {i}\\right) - p \\right</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq \\varepsilon \\right] \\leq e ^ {- \\Omega (n \\varepsilon^ {2})}.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">Claim 20 <span class="math">\\operatorname{Pr}[D&#x27;(Y, C) = 1] \\leq \\varepsilon / 4</span>.</p>

    <p class="text-gray-300">Claim 21 <span class="math">\\operatorname{Pr}[D&#x27;(X, C) = 1] \\geq \\varepsilon / 2 - \\mathrm{ngl}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Proof of Claim 20. Note that when <span class="math">(w, c) \\gets (Y, C)</span>, then <span class="math">w</span> and <span class="math">y_i</span>'s are i.i.d. copies of $(Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{C=c})<span class="math">. Hence, for every </span>b \\in \\{0,1\\}^\\ell$,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Pr}[p_{c,b}(w) &amp;gt; \\max_{y_i} \\{p_{c,b}(y_i)\\}] &amp;lt; 1 / s.</span></div>

    <p class="text-gray-300">By a union bound,</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Pr}[\\exists b^* \\in \\{0,1\\}^\\ell \\text{ s.t. } p_{c,b^*}(w) &amp;gt; \\max_{y_i} \\{p_{c,b^*}(y_i)\\}] &amp;lt; 2^\\ell / s = \\varepsilon / 4.</span></div>

    <p class="text-gray-300">Denote by <span class="math">E_{Good}</span> the event that Equation (4) holds; i.e., the event that all estimators have error less than <span class="math">\\varepsilon / 8</span>. Recall that we chose the parameter so that event <span class="math">E_{Good}</span> holds with overwhelming probability (i.e., probability <span class="math">1 - \\mathrm{ngl}(k)</span>). Note that if event <span class="math">E_{Good}</span> holds,</p>

    <div class="my-4 text-center"><span class="math-block">\\tilde{p}_{c,b}(w) \\geq \\max_{y_i} \\{\\tilde{p}_{c,b}(y_i)\\} + \\varepsilon / 4 \\quad \\Rightarrow \\quad p_{c,b}(w) &amp;gt; \\max_{y_i} \\{p_{c,b}(y_i)\\}</span></div>

    <p class="text-gray-300">Therefore,</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} \\operatorname{Pr}[D&#x27;(Y, C) = 1] \\\\ &amp;amp;= \\operatorname{Pr}\\left[\\exists b \\in \\{0,1\\}^\\ell \\text{ s.t. } \\tilde{p}_{c,b}(w) \\geq \\max_{y_i} \\{\\tilde{p}_{c,b}(y_i)\\} + \\varepsilon / 4\\right] \\\\ &amp;amp;\\leq \\operatorname{Pr}\\left[\\left(\\exists b \\in \\{0,1\\}^\\ell \\text{ s.t. } \\tilde{p}_{c,b}(w) \\geq \\max_{y_i} \\{\\tilde{p}_{c,b}(y_i)\\} + \\varepsilon / 4\\right) \\wedge E_{Good}\\right] + \\operatorname{Pr}[\\neg E_{Good}] \\\\ &amp;amp;\\leq \\operatorname{Pr}\\left[\\exists b \\in \\{0,1\\}^\\ell \\text{ s.t. } p_{c,b}(w) &amp;gt; \\max_{y_i} \\{p_{c,b}(y_i)\\}\\right] + \\mathrm{ngl}(k) \\\\ &amp;amp;\\leq \\varepsilon / 4 + \\mathrm{ngl}(k). \\end{aligned}</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Proof of Claim 21. We first argue that we can assume, without loss of generality, that for every <span class="math">Z</span> with $\\mathbf{H}_{\\infty}(Z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C,B) \\geq n - t$,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Pr}[D(X, C, B) = 1] - \\operatorname{Pr}[D(Z, C, B) = 1] &amp;gt; \\varepsilon. \\tag{5}</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The reason is the following: Suppose for the sake of contradiction that there exists some distribution <span class="math">Z</span> with $\\mathbf{H}_{\\infty}(Z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C,B) \\geq n - t$ such that</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Pr}[D(X, C, B) = 1] - \\operatorname{Pr}[D(Z, C, B) = 1] &amp;gt; \\varepsilon,</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">and yet there exists another distribution <span class="math">Z&#x27;</span> with $\\mathbf{H}_{\\infty}(Z'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C,B) \\geq n - t$ such that</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Pr}[D(Z&#x27;, C, B) = 1] - \\operatorname{Pr}[D(X, C, B) = 1] &amp;gt; \\varepsilon.</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Then one can construct a distribution <span class="math">Z&#x27;&#x27;</span>, by taking an appropriate convex combination of <span class="math">Z</span> and <span class="math">Z&#x27;</span>, such that $\\mathbf{H}_{\\infty}(Z''</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C,B) \\geq n - t<span class="math"> and </span>\\operatorname{Pr}[D(X,C,B) = 1] = \\operatorname{Pr}[D(Z'',C,B) = 1]$, contradicting</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Equation (3).</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">For every pair <span class="math">(c,b)\\in\\mathrm{supp}(C,B)</span>, let <span class="math">H_{cb}</span> be a set of the “heaviest” <span class="math">2^{n-t}</span> points <span class="math">w</span> that maximize <span class="math">p_{cb}(w)</span>. Consider the distribution <span class="math">Z^{+}=Z^{+}(C,B)</span> such that $Z^{+}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{(C,B)=(c,b)}<span class="math"> is the uniform distribution over </span>H_{c,b}<span class="math">. Note that </span>\\mathbf{H}_{\\infty}(Z^{+}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C,B)=n-t<span class="math">. For every </span>(c,b)\\in\\mathrm{supp}(C,B)$, define</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$p^{+}_{c,b}\\triangleq\\mathrm{Pr}[D(Z^{+}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{C=c,B=b},c,b)=1].$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Using these notations, Equation (5) implies that</p>

    <p class="text-gray-300"><span class="math">\\operatorname{E}_{(x,c,b)\\leftarrow(X,C,B)}[p_{c,b}(x)]-\\operatorname{E}_{(c,b)\\leftarrow(C,B)}[p^{+}_{c,b}]\\geq\\varepsilon.</span></p>

    <p class="text-gray-300">By a Markov argument, with probability at least <span class="math">\\varepsilon/2</span> over <span class="math">(x,c,b)\\leftarrow(X,C,B)</span>,</p>

    <p class="text-gray-300"><span class="math">p_{c,b}(x)-p^{+}_{c,b}\\geq\\varepsilon/2.</span></p>

    <p class="text-gray-300">We next prove that in this case, <span class="math">\\mathrm{Pr}[D^{\\prime}(x,c)=1]\\geq 1-\\mathsf{ngl}(k)</span>, which implies that</p>

    <p class="text-gray-300"><span class="math">\\mathrm{Pr}[D^{\\prime}(X,C)=1]\\geq(1-\\mathsf{ngl}(k))\\cdot(\\varepsilon/2)\\geq\\varepsilon/2-\\mathsf{ngl}(k).</span></p>

    <p class="text-gray-300">Fix any <span class="math">x,c,b</span> such that <span class="math">p_{c,b}(x)-p^{+}_{c,b}\\geq\\varepsilon/2</span>. It remains to prove that</p>

    <p class="text-gray-300"><span class="math">\\mathrm{Pr}[D^{\\prime}(x,c)=1]\\geq 1-\\mathsf{ngl}(k).</span></p>

    <p class="text-gray-300">Note that by definition, <span class="math">p_{cb}(w)\\leq p^{+}_{c,b}</span> for every <span class="math">w\\notin H_{cb}</span>. Recall that we choose the parameter so that with overwhelming probability, all estimators have error at most <span class="math">\\varepsilon/8</span>. As before, denote by <span class="math">E_{Good}</span> the event that indeed all estimators have error at most <span class="math">\\varepsilon/8</span>.</p>

    <p class="text-gray-300"><span class="math">\\mathrm{Pr}[D^{\\prime}(x,c)=1]</span> <span class="math">\\geq</span> <span class="math">\\mathrm{Pr}[\\tilde{p}_{cb}(x)\\geq\\max_{y_{i}}\\{\\tilde{p}_{cb}(y_{i})\\}+\\varepsilon/4]</span> <span class="math">\\geq</span> <span class="math">\\mathrm{Pr}[(\\tilde{p}_{cb}(x)\\geq\\max_{y_{i}}\\{\\tilde{p}_{cb}(y_{i})\\}+\\varepsilon/4)\\wedge E_{Good}]-\\mathrm{Pr}[\\neg E_{Good}]</span> <span class="math">\\geq</span> <span class="math">\\mathrm{Pr}[p_{cb}(x)\\geq\\max_{y_{i}}\\{p_{cb}(y_{i})\\}+\\varepsilon/2]-\\mathsf{ngl}(k)</span> <span class="math">\\geq</span> <span class="math">\\mathrm{Pr}[\\forall i,y_{i}\\notin H_{cb}]-\\mathsf{ngl}(k)</span> <span class="math">\\geq</span> <span class="math">(1-\\mathsf{ngl}(k))-\\mathsf{ngl}(k)</span> <span class="math">\\geq</span> <span class="math">1-\\mathsf{ngl}(k),</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where the second-to-last inequality follows from the fact that $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">H_{cb}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=2^{n-t}<span class="math"> and </span>\\mathbf{H}_{\\infty}(Y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{C=c})\\geq n$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\blacksquare</span></p>

    <h3 id="sec-35" class="text-xl font-semibold mt-8">4.2 Main Leakage Lemma</h3>

    <p class="text-gray-300">Throughout this section, we consider the following setting. Let <span class="math">k\\in\\mathbb{N}</span> be a security parameter. Let <span class="math">\\mathbb{F}</span> be a finite field of size <span class="math">q\\geq 2^{\\log^{2}k}</span>, and let <span class="math">E=(\\mathrm{Gen},\\mathrm{Enc},\\mathrm{Dec})</span> be any semantic secure public-key encryption scheme. Let <span class="math">m\\leq\\mathrm{poly}(k)</span> be a parameter. We define the following random variables.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let <span class="math">S\\in_{R}\\mathbb{F}^{m\\times 2}</span> be a random <span class="math">m</span>-by-2 matrix representing a random 2-dimensional linear subspace</li>

    </ol>

    <p class="text-gray-300"><span class="math">\\{a_{1}v_{1}+a_{2}v_{2}:a_{1},a_{2}\\in\\mathbb{F}\\},</span></p>

    <p class="text-gray-300">where <span class="math">v_{1},v_{2}</span> are columns of <span class="math">S</span>.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let <span class="math">(\\mathsf{pk},\\mathsf{sk})\\leftarrow\\mathrm{Gen}(1^{k})</span>, and let <span class="math">\\hat{S}=\\mathrm{Enc}_{\\mathsf{pk}}(S)</span>.</li>

      <li>Let <span class="math">L:\\{0,1\\}^{*}\\to\\{0,1\\}</span> be an arbitrary (randomized, not necessarily efficient) leakage function that maps <span class="math">(\\hat{S},\\mathsf{pk})</span> to one bit, and let <span class="math">b=L(\\hat{S},\\mathsf{pk})</span>.</li>

      <li>Let <span class="math">u\\leftarrow\\mathbb{F}^{m}</span> be a random point in <span class="math">\\mathbb{F}^{m}</span>, and <span class="math">z</span> be a random point in <span class="math">S</span>. Specifically, <span class="math">z=S\\cdot a=a_{1}v_{1}+a_{2}v_{2}</span> where <span class="math">a=(a_{1},a_{2})</span> is a uniformly random vector in <span class="math">\\mathbb{F}^{2}</span>.</li>

    </ol>

    <p class="text-gray-300">Our goal in this section is to prove the following lemma.</p>

    <h6 id="sec-36" class="text-base font-medium mt-4">Lemma 22</h6>

    <p class="text-gray-300">In the above setting, the distributions <span class="math">(z,\\hat{S},\\mathsf{pk},b)</span> and <span class="math">(u,\\hat{S},\\mathsf{pk},b)</span> are computationally indistinguishable.</p>

    <p class="text-gray-300">The lemma says that computationally, the encryption <span class="math">(\\hat{S},\\mathsf{pk})</span> together with an arbitrary leakage bit <span class="math">b</span> does not leak any information about <span class="math">z</span>. Note that information-theoretically, <span class="math">(\\hat{S},\\mathsf{pk})</span> does contain information about <span class="math">z</span>, since we know that <span class="math">z</span> is in <span class="math">S</span>. Also note that when <span class="math">b</span> is not present, semantic security readily implies that <span class="math">(z,\\hat{S},\\mathsf{pk})</span> and <span class="math">(u,\\hat{S},\\mathsf{pk})</span> are computationally indistinguishable. However, when the bit <span class="math">b</span> is present, the proof becomes highly non-trivial, and in particular, our proof makes use of Lemma 16.</p>

    <p class="text-gray-300">Proof. We first consider the distribution <span class="math">(S,\\hat{S},\\mathsf{pk})</span>. By the semantic security, <span class="math">(S,\\hat{S},\\mathsf{pk})</span> is computationally indistinguishable from <span class="math">(S^{\\prime},\\hat{S},\\mathsf{pk})</span>, where <span class="math">S^{\\prime}</span> is an i.i.d. copy of <span class="math">S</span>. Note that this implies</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\mathbf{H}^{\\mathsf{HILL}}(S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\hat{S},\\mathsf{pk})\\geq 2m\\cdot\\log q$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">w.r.t. sampleable distributions. By Lemma 16,</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\mathbf{H}^{\\mathsf{HILL}}(S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\hat{S},\\mathsf{pk},b)\\geq(2m\\cdot\\log q)-t,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where we set <span class="math">t=(\\log q)/4=\\omega(\\log k)</span>. Namely, for every constant <span class="math">c\\in\\mathbb{N}</span>, there exists a distribution <span class="math">T=T(\\hat{S},\\mathsf{pk},b)</span> such that:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">1. $\\mathbf{H}_{\\infty}(T</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\hat{S},\\mathsf{pk},b)\\geq(2m\\cdot\\log q)-t$, and</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">(S,\\hat{S},\\mathsf{pk},b)</span> and <span class="math">(T,\\hat{S},\\mathsf{pk},b)</span> are computationally indistinguishable against circuits of size <span class="math">k^{c}</span> with advantage <span class="math">k^{-c}</span>.</li>

    </ol>

    <p class="text-gray-300">Note that <span class="math">z\\leftarrow S</span> is efficiently sampleable, say, using a circuit of size <span class="math">m^{3}=\\mathrm{poly}(k)</span> . Therefore, the distributions <span class="math">(z_{S},S,\\hat{S},\\mathsf{pk},b)</span> and <span class="math">(z_{T},T,\\hat{S},\\mathsf{pk},b)</span>, where <span class="math">z_{S}\\leftarrow S</span> and <span class="math">z_{T}\\leftarrow T</span> are random points in <span class="math">S</span> and <span class="math">T</span> respectively, are computationally indistinguishable against circuits of size <span class="math">(k^{c}-m^{3})</span> with advantage <span class="math">k^{-c}</span>.</p>

    <p class="text-gray-300">Clearly, we can remove <span class="math">S</span> and <span class="math">T</span> from the distributions while preserving the indistinguishability. Namely, the distributions <span class="math">(z_{S},\\hat{S},\\mathsf{pk},b)</span> and <span class="math">(z_{T},\\hat{S},\\mathsf{pk},b)</span> are computationally indistinguishable against circuits of size <span class="math">(k^{c}-m^{3})</span> with advantage <span class="math">k^{-c}</span>.</p>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">We next claim that for any distribution <span class="math">T=T(\\hat{S},{\\sf pk},b)</span> over <span class="math">\\mathbb{F}^{m\\times 2}</span>, with</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\${\\bf H}_{\\infty}(T</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\hat{S},{\\sf pk},b)\\geq(2m\\cdot\\log q)-t,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">the distributions <span class="math">(z_{T},\\hat{S},{\\sf pk},b)</span> and <span class="math">(u,\\hat{S},{\\sf pk},b)</span> are statistically close (i.e., have distance <span class="math">{\\sf ngl}(k)</span>). This would imply that <span class="math">(z,\\hat{S},{\\sf pk},b)</span> and <span class="math">(u,\\hat{S},{\\sf pk},b)</span> are computationally indistinguishable against circuits of size <span class="math">(k^{c}-m^{3})</span> with advantage <span class="math">k^{-c}+{\\sf ngl}(k)</span>. Observing that the above argument holds for all constants <span class="math">c\\in\\mathbb{N}</span>, we conclude that <span class="math">(z,\\hat{S},{\\sf pk},b)</span> and <span class="math">(u,\\hat{S},{\\sf pk},b)</span> are computationally indistinguishable, as desired.</p>

    <p class="text-gray-300">Thus, it remains to prove that indeed <span class="math">(z_{T},\\hat{S},{\\sf pk},b)</span> and <span class="math">(u,\\hat{S},{\\sf pk},b)</span> are statistically close. To this end, we use Lemma 23 below, which states that if a distribution <span class="math">T</span> over <span class="math">\\mathbb{F}^{m\\times 2}</span> has min-entropy at least <span class="math">(2m\\cdot\\log q)-t</span> and <span class="math">a=(a_{1},a_{2})\\leftarrow\\mathbb{F}^{2}</span>, then <span class="math">z=T\\cdot a</span> is <span class="math">\\varepsilon</span>-close to uniform, where <span class="math">\\varepsilon\\leq 2m\\cdot q^{-1/4}={\\sf ngl}(k)</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Recall that according to our definition of conditional min-entropy (which is a worse-case definition), \${\\bf H}_{\\infty}(T</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\hat{S},{\\sf pk},b)\\geq(2m\\cdot\\log q)-t<span class="math"> implies that </span>{\\bf H}_{\\infty}(T</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{\\langle\\hat{S},{\\sf pk},b\\rangle=\\sigma})\\geq(2m\\cdot\\log q)-t<span class="math"> for every </span>\\sigma\\in{\\rm supp}(\\hat{S},{\\sf pk},b)<span class="math">. Thus, Lemma 23 implies that conditioned on any </span>(\\hat{S},{\\sf pk},b)=\\sigma<span class="math">, the random variable </span>z_{T}<span class="math"> is </span>{\\sf ngl}(k)<span class="math">-close to uniform. This clearly implies </span>(z_{T},\\hat{S},{\\sf pk},b)<span class="math"> and </span>(u,\\hat{S},{\\sf pk},b)$ are statistically close, as desired.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\blacksquare</span></p>

    <h6 id="sec-37" class="text-base font-medium mt-4">Lemma 23</h6>

    <p class="text-gray-300">Let <span class="math">X</span> be a distribution over <span class="math">\\mathbb{F}^{m\\times 2}</span> with <span class="math">{\\bf H}_{\\infty}(X)\\geq(2m\\cdot\\log q)-(\\log q)/4</span>, and <span class="math">a=(a_{1},a_{2})\\leftarrow\\mathbb{F}^{2}</span>. Then <span class="math">(X\\cdot a)\\in\\mathbb{F}^{m}</span> is <span class="math">\\varepsilon</span>-close to uniform with <span class="math">\\varepsilon\\leq 2m\\cdot q^{-1/4}</span>.</p>

    <p class="text-gray-300">We defer the proof of Lemma 23 to Appendix A.</p>

    <h2 id="sec-38" class="text-2xl font-bold">5 Parallel Composition Lemma</h2>

    <p class="text-gray-300">In this section we give soundness guarantees for a protocol <span class="math">\\Pi</span> that executes several protocols <span class="math">\\Pi_{1},\\ldots,\\Pi_{t}</span> in parallel, where in each <span class="math">\\Pi_{i}=\\langle P_{i},V_{i}\\rangle</span> the verifier <span class="math">V_{i}</span> uses the same private randomness <span class="math">p</span>. Such a parallel composition lemma will be used to prove soundness both of our memory delegation scheme (in Section 7) and the streaming delegation scheme (in Section 9). For the sake of simplicity, we focus on 2-message protocols, though our results hold for protocols with arbitrary number of messages.</p>

    <p class="text-gray-300">Let <span class="math">\\Pi_{1},\\Pi_{2},\\ldots,\\Pi_{t}</span> be protocols, where each <span class="math">\\Pi_{i}=\\langle P_{i},V_{i}\\rangle</span> is a 2-message protocol (where the first message is sent by the verifier <span class="math">V_{i}</span> and the second message is sent by the prover <span class="math">P_{i}</span>) for proving <span class="math">x_{i}\\in L_{i}</span>. Let <span class="math">\\Pi=\\langle P,V(p)\\rangle(x_{1},\\ldots,x_{t})</span> be the two-message protocol that runs the protocols <span class="math">\\Pi_{1},\\ldots,\\Pi_{t}</span> in parallel, where each <span class="math">\\Pi_{i}</span> is run with the input <span class="math">x_{i}</span>, and each verifier <span class="math">V_{i}</span> uses the same private random coin tosses <span class="math">p</span> (in addition to some independent private randomness which each <span class="math">V_{i}</span> may use). <span class="math">V</span> accepts <span class="math">(x_{1},\\ldots,x_{t})</span> if and only if at least one of the <span class="math">V_{i}</span>’s accepts <span class="math">x_{i}\\in L_{i}</span>. Thus, <span class="math">\\Pi(x_{1},\\ldots,x_{t})</span> should be thought of as a proof that there exists <span class="math">i\\in[t]</span> such that <span class="math">x_{i}\\in L_{i}</span>.</p>

    <p class="text-gray-300">We say that a protocol <span class="math">\\Pi_{i}</span> has soundness error <span class="math">s_{i}</span> if for every false statement <span class="math">x\\notin L_{i}</span>, and for every efficient cheating prover <span class="math">P^{*}</span>,</p>

    <p class="text-gray-300"><span class="math">\\Pr_{p}[V_{i}\\mbox{ accepts the interaction }\\langle P^{*},V_{i}(p)\\rangle(x)]\\leq s_{i},</span></p>

    <p class="text-gray-300">where the randomness is over <span class="math">p</span> and over any additional random coins that <span class="math">V_{i}</span> may use.</p>

    <p class="text-gray-300">In what follows we prove that if in each protocol <span class="math">\\Pi_{i}</span>, the verifier’s messages are computationally indistinguishable for all different <span class="math">p</span>’s (of length at most <span class="math">\\mathrm{poly}(k)</span>), then the soundness of all the <span class="math">\\Pi_{i}</span>’s implies the soundness of <span class="math">\\Pi</span>.</p>

    <h6 id="sec-39" class="text-base font-medium mt-4">Lemma 24</h6>

    <p class="text-gray-300">Let <span class="math">k</span> be the security parameter and <span class="math">t\\leq\\mathrm{poly}(k)</span>. Suppose that a protocol <span class="math">\\Pi</span> consists of a parallel composition of <span class="math">\\Pi_{1},\\Pi_{2},\\ldots,\\Pi_{t}</span> of the above form, and suppose that for each <span class="math">i</span> the following two properties hold:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\Pi_{i}</span> has soundness error <span class="math">s_{i}</span>.</li>

      <li>Let <span class="math">\\{M_{V_{i}(x_{i},p)}\\}</span> be the distribution of <span class="math">V_{i}</span>’s first message, where <span class="math">x_{i}</span> is the common input of <span class="math">V_{i}</span> and <span class="math">P_{i}</span>, and <span class="math">p</span> is the the common private random coins of <span class="math">V_{1},\\ldots,V_{t}</span>. Then, for all <span class="math">x_{i},p,p^{\\prime}</span> (of length bounded by <span class="math">\\mathrm{poly}(k)</span>), the distributions <span class="math">\\{M_{V_{i}(x_{i},p)}\\}</span> and <span class="math">\\{M_{V_{i}(x_{i},p^{\\prime})}\\}</span> are computationally indistinguishable.</li>

    </ol>

    <p class="text-gray-300">Then <span class="math">\\Pi</span> has soundness error at most <span class="math">\\sum_{i\\in[t]}s_{i}+\\mathsf{ngl}(k)</span>.</p>

    <p class="text-gray-300">Proof. Suppose for the sake of contradiction that there exists an efficient (parallel) cheating prover <span class="math">P^{<em>}</span> and a false input <span class="math">x=(x_{1},\\ldots,x_{t})</span> (i.e., an input <span class="math">x</span> such that for every <span class="math">i\\in[t]</span>, <span class="math">x_{i}\\notin L_{i}</span>) such that <span class="math">P^{</em>}</span> succeeds in convincing the verifier <span class="math">V</span> running <span class="math">\\Pi</span> to accept <span class="math">x</span> with probability</p>

    <p class="text-gray-300"><span class="math">\\varepsilon&gt;\\sum_{i\\in[t]}s_{i}+\\alpha(k),</span></p>

    <p class="text-gray-300">for some non-negligible function <span class="math">\\alpha</span>. We argue that there exists a coordinate <span class="math">i\\in[t]</span> and an efficient cheating prover <span class="math">P^{*}_{i}</span> for the protocol <span class="math">\\Pi_{i}</span> that succeed in convincing <span class="math">V_{i}</span> to accept the false <span class="math">x_{i}</span> with probability greater than <span class="math">s_{i}+\\alpha/t-\\mathsf{ngl}(k)</span>, which contradicts the assumption.</p>

    <p class="text-gray-300">For every <span class="math">i\\in[t]</span>, let <span class="math">W_{i}</span> be the event that <span class="math">P^{<em>}</span> successfully cheats on the <span class="math">i</span>’th coordinate in the protocol <span class="math">\\Pi(x)</span>, and define <span class="math">\\varepsilon_{i}\\triangleq\\mathrm{Pr}[W_{i}]</span>. By definition, if <span class="math">P^{</em>}</span> cheats on <span class="math">\\Pi</span> then at least one <span class="math">W_{i}</span> holds. Using the union bound, this implies that <span class="math">\\sum_{i\\in[t]}\\varepsilon_{i}\\geq\\varepsilon</span>.</p>

    <p class="text-gray-300">Now for each <span class="math">i\\in[t]</span> we define a cheating prover <span class="math">P^{<em>}_{i}</span> for the protocol <span class="math">\\Pi_{i}(x_{i})</span> with the following strategy. <span class="math">P^{</em>}_{i}</span>, upon receiving a message <span class="math">M_{V_{i}(x_{i},p)}</span> from <span class="math">V_{i}</span>, simulates the interaction between <span class="math">P^{<em>}</span> and <span class="math">V</span> by embedding the real message of <span class="math">V_{i}</span> into the <span class="math">i</span>-th coordinate, and setting the other <span class="math">V_{j}</span>’s messages to be <span class="math">M_{V_{j}(x_{j},0)}</span> for <span class="math">j\\neq i</span>. Then <span class="math">P^{</em>}_{i}</span> replies what <span class="math">P^{*}</span> does in the <span class="math">i</span>’th coordinate.</p>

    <p class="text-gray-300">Denote the success probability of <span class="math">P^{*}_{i}</span> by <span class="math">\\tilde{\\varepsilon}_{i}</span>. By the message indistinguishability of <span class="math">\\{M_{V_{j}(x_{j},0)}\\}</span> and <span class="math">\\{M_{V_{j}(x_{j},p)}\\}</span> for <span class="math">j\\neq i</span>, we know that <span class="math">\\tilde{\\varepsilon}_{i}&gt;\\varepsilon_{i}-\\mathsf{ngl}(k)</span>; otherwise there is a distinguisher that distinguishes between the distributions <span class="math">\\{M_{V_{k}(x_{k},0)}\\}</span> and <span class="math">\\{M_{V_{k}(x_{k},p)}\\}</span> for some <span class="math">k\\neq i</span> (by a standard hybrid argument).</p>

    <p class="text-gray-300">Thus,</p>

    <p class="text-gray-300"><span class="math">\\sum_{i\\in[t]}\\tilde{\\varepsilon}_{i}\\geq\\sum_{i\\in[t]}\\varepsilon_{i}-t\\cdot\\mathsf{ngl}(k)\\geq\\varepsilon-\\mathsf{ngl}(k)\\geq\\sum_{i\\in[t]}s_{i}+\\alpha(k)-\\mathsf{ngl}(k).</span></p>

    <p class="text-gray-300">This implies that there exists <span class="math">i</span> such that <span class="math">\\tilde{\\varepsilon}_{i}\\geq s_{i}+\\alpha/t-\\mathsf{ngl}(k)</span>, which contradicts the assumption. <span class="math">\\blacksquare</span></p>

    <p class="text-gray-300">We note that in the streaming delegation and memory delegation schemes, the delegator (verifier) uses an FHE scheme or a PIR scheme to achieve the property that <span class="math">\\{M_{V_{i}(x_{i},p)}\\}</span> and <span class="math">\\{M_{V_{i}(x_{i},p^{\\prime})}\\}</span> are computationally indistinguishable. This allows us to make use of Lemma 24.</p>

    <p class="text-gray-300">6 Memory Delegation Model</p>

    <p class="text-gray-300">In this section, we formally define our memory delegation model. We present our memory delegation scheme in Section 7.</p>

    <h6 id="sec-40" class="text-base font-medium mt-4">Definition 25 (Memory Delegation Scheme)</h6>

    <p class="text-gray-300">Let <span class="math">\\mathcal{F},\\mathcal{G}</span> be two sets of functions. A <em>memory delegation scheme</em> for functions in <span class="math">\\mathcal{F}</span> and updates in <span class="math">\\mathcal{G}</span>, is an interactive protocol <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}=\\langle\\mathsf{D},\\mathsf{W}\\rangle</span> between a delegator <span class="math">\\mathsf{D}</span> and a worker <span class="math">\\mathsf{W}</span>, of the following form:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The scheme <span class="math">\\mathsf{mDel}</span> consists of two stages: an offline/preprocessing stage and an online stage. The offline stage is executed only once before the online stage, whereas the online stage can be executed many times.</li>

      <li>In the offline stage, both the delegator <span class="math">\\mathsf{D}</span> and the worker <span class="math">\\mathsf{W}</span> receive a security parameter <span class="math">1^{k}</span> and an input <span class="math">x\\in\\{0,1\\}^{n}</span>.The worker stores <span class="math">x</span>, and the delegator computes a short (possibly secret) string <span class="math">\\sigma_{\\mathsf{D}}</span> and stores it for future use.</li>

      <li>In the online stage, the delegator can interact with the worker via the following two operations.</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>A computation operation <span class="math">\\mathsf{Compute}(f)</span> where both parties take as input a function <span class="math">f\\in\\mathcal{F}</span>. This input is in addition to the inputs that the parties store throughout the delegation protocol: the security parameter <span class="math">1^{k}</span>, the current memory content <span class="math">x\\in\\{0,1\\}^{n}</span> stored only by the worker <span class="math">\\mathsf{W}</span>, and the short (possibly secret) string <span class="math">\\sigma_{\\mathsf{D}}</span> stored only by the delegator <span class="math">\\mathsf{D}</span>. Then, <span class="math">\\mathsf{W}</span> proves to <span class="math">\\mathsf{D}</span> that <span class="math">y=f(x)</span>, for some <span class="math">y\\in\\{0,1\\}^{*}</span>.</li>

      <li>An update operation <span class="math">\\mathsf{Update}(g)</span> where both parties take as input a function <span class="math">g:\\{0,1\\}^{n}\\rightarrow\\{0,1\\}^{n^{\\prime}}\\in\\mathcal{G}</span>. This is in addition to the inputs that the parties store throughout the delegation protocol: the security parameters <span class="math">1^{k}</span>, the current memory content <span class="math">x\\in\\{0,1\\}^{n}</span> stored only by the worker <span class="math">\\mathsf{W}</span>, and the short (possibly secret) string <span class="math">\\sigma_{\\mathsf{D}}</span> stored only by the delegator <span class="math">\\mathsf{D}</span>. Then <span class="math">\\mathsf{W}</span> and <span class="math">\\mathsf{D}</span> interact, where <span class="math">\\mathsf{W}</span> “helps” <span class="math">\\mathsf{D}</span> update her secret <span class="math">\\sigma_{\\mathsf{D}}</span>. At the end of the interaction, if <span class="math">\\mathsf{D}</span> accepts, she updates her secret to some <span class="math">\\sigma_{\\mathsf{D}}^{\\prime}</span> and believes that the stored <span class="math">x</span> has been updated to <span class="math">g(x)</span>. Otherwise, she keeps her secret <span class="math">\\sigma_{\\mathsf{D}}</span> (and thinks of the previous <span class="math">x</span> as unchanged).</li>

    </ul>

    <p class="text-gray-300">At the end of each operation, <span class="math">\\mathsf{D}</span> sends <span class="math">\\mathsf{W}</span> a decision bit <span class="math">b\\in\\{0,1\\}</span> for her acceptance or rejection.</p>

    <p class="text-gray-300">For a delegation scheme to be meaningful, it needs to have efficiency, completeness and soundness properties, defined below.</p>

    <h6 id="sec-41" class="text-base font-medium mt-4">Definition 26 (Efficiency)</h6>

    <p class="text-gray-300">A delegation scheme <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}</span> has an efficient delegator in the offline stage if <span class="math">\\mathsf{D}</span> runs in time <span class="math">\\mathrm{poly}(k,n)</span> in the offline stage. It has an efficient delegator in the online stage if <span class="math">\\mathsf{D}</span> runs in time <span class="math">\\mathrm{poly}(k)</span> (independent of <span class="math">n</span>) during each operation in the online stage.</p>

    <p class="text-gray-300">A delegation scheme <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}</span> has an efficient worker if the runtime of <span class="math">\\mathsf{W}</span> is <span class="math">\\mathrm{poly}(k,n)</span> during both the offline stage and during each operation in the online stage, where <span class="math">n</span> is the length of the delegated memory.</p>

    <h6 id="sec-42" class="text-base font-medium mt-4">Definition 27 (Completeness)</h6>

    <p class="text-gray-300">For any sets of functions <span class="math">\\mathcal{F},\\mathcal{G}</span>, a delegation scheme <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}=\\langle\\mathsf{D},\\mathsf{W}\\rangle</span> has <em>perfect completeness</em> if for every <span class="math">k,n\\in\\mathbb{N}</span>, and for every <span class="math">x\\in\\{0,1\\}^{n}</span>, the following holds with probability <span class="math">1</span>: When <span class="math">\\mathsf{D}</span> and <span class="math">\\mathsf{W}</span> run the offline stage with input <span class="math">(1^{k},x)</span>, and then run the online</p>

    <p class="text-gray-300">stage polynomially many times with the operations <span class="math">\\mathsf{Update}(g)</span>, for any <span class="math">g\\in\\mathcal{G}</span>, and <span class="math">\\mathsf{Compute}(f)</span>, for any <span class="math">f\\in\\mathcal{F}</span>, the delegator <span class="math">\\mathsf{D}</span> always accepts (i.e., sends <span class="math">\\mathsf{W}</span> the decision bit 1).</p>

    <p class="text-gray-300">The definition of soundness is more elaborate, and requires defining the following security game. We emphasize that our soundness definition is <em>reusable</em> in the sense that we require that a (computationally bounded) cheating worker cannot convince the delegator to accept a wrong statement, even after interacting with the delegator polynomially many times, and each time learning whether the delegator accepted or rejected the proof.</p>

    <p class="text-gray-300">One could define security w.r.t. cheating workers of size <span class="math">T(k)</span> for any (possibly super-polynomial) function <span class="math">T</span>. However, for the sake of simplicity of notation, we define soundness w.r.t. poly-size cheating workers.</p>

    <h6 id="sec-43" class="text-base font-medium mt-4">Definition 28 (Reusable Security Game)</h6>

    <p class="text-gray-300">Let <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}=\\langle\\mathsf{D},\\mathsf{W}\\rangle</span> be a delegation scheme. For a security parameter <span class="math">k\\in\\mathbb{N}</span> and for a <span class="math">\\mathrm{PPT}</span> (cheating) worker <span class="math">\\mathsf{W}^{<em>}</span>, the </em>security game<em> <span class="math">\\mathsf{G}^{\\mathsf{W}^{</em>}}(k)</span> is defined as follows.</p>

    <p class="text-gray-300">The game starts with the offline stage of <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}</span>, and is followed by polynomially many rounds of the online stage.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>(Initial Phase) <span class="math">\\mathsf{W}^{<em>}(1^{k})</span> first chooses a parameter <span class="math">n=\\mathrm{poly}(k)</span> and an input <span class="math">x\\in\\{0,1\\}^{n}</span>. Then, <span class="math">\\mathsf{D}</span> and <span class="math">\\mathsf{W}^{</em>}(1^{k})</span> run the offline stage on inputs <span class="math">(1^{k},x)</span>.</li>

      <li>(Learning Phase) At the beginning of each round of the online stage, <span class="math">\\mathsf{W}^{*}</span> can do one of the following:</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Terminate this phase.</li>

      <li>Choose a function <span class="math">f\\in\\mathcal{F}</span> and interact with <span class="math">\\mathsf{D}</span> in the online stage with the operation <span class="math">\\mathsf{Compute}(f)</span>.</li>

      <li>Choose a function <span class="math">g\\in\\mathcal{G}</span> and interact with <span class="math">\\mathsf{D}</span> in the online stage with the operation <span class="math">\\mathsf{Update}(g)</span>.</li>

    </ol>

    <p class="text-gray-300">After each round, if <span class="math">\\mathsf{W}^{<em>}</span> did not terminate the phase, <span class="math">\\mathsf{D}</span> sends her decision bit to <span class="math">\\mathsf{W}^{</em>}</span>.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>(Challenge Phase) If the learning phase is terminated, <span class="math">\\mathsf{W}^{<em>}</span> chooses a function <span class="math">f^{\\prime}\\in\\mathcal{F}</span>, and <span class="math">\\mathsf{D}</span> and <span class="math">\\mathsf{W}^{</em>}</span> execute <span class="math">\\mathsf{Compute}(f^{\\prime})</span>.</li>

    </ol>

    <p class="text-gray-300"><span class="math">\\mathsf{W}^{<em>}</span> succeeds in the game <span class="math">\\mathsf{G}^{\\mathsf{W}^{</em>}}(k)</span> if <span class="math">\\mathsf{D}</span> accepts a wrong value <span class="math">y^{\\prime}\\neq f^{\\prime}(x)</span>, where <span class="math">x</span> is the latest updated memory.</p>

    <h6 id="sec-44" class="text-base font-medium mt-4">Definition 29 (Reusable Soundness)</h6>

    <p class="text-gray-300">A delegation scheme <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}=\\langle\\mathsf{D},\\mathsf{W}\\rangle</span> has reusable soundness error <span class="math">\\varepsilon</span> if for every <span class="math">k\\in\\mathbb{N}</span> and every <span class="math">\\mathrm{PPT}</span> worker strategy <span class="math">\\mathsf{W}^{*}</span>,</p>

    <p class="text-gray-300"><span class="math">\\mathrm{Pr}[\\mathsf{W}^{<em>}\\text{ succeeds in }\\mathsf{G}^{\\mathsf{W}^{</em>}}(k)]\\leq\\varepsilon(k),</span></p>

    <p class="text-gray-300">where <span class="math">\\mathsf{G}^{\\mathsf{W}^{*}}(k)</span> is the security game corresponding to <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}</span>, as defined above. We say that <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}</span> is sound if it has a negligible soundness error.</p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">Remark. We stress that in the soundness definition, we allow the adversary <span class="math">\\mathsf{W}^{<em>}</span> to learn the decision bit of the delegator <span class="math">\\mathsf{D}</span> after each execution of the delegation protocol. This is in contrast to the two delegation schemes of </em>[x10, x7]<em>, which are only sound if the adversary <span class="math">\\mathsf{W}^{</em>}</span> does not learn the decision bit of the delegator <span class="math">\\mathsf{D}</span>. We elaborate on this point when we discuss the streaming setting, in Section 8.</p>

    <p class="text-gray-300">In what follows we define the notion of one-time soundness. The reason we need this definition is that the soundness proof of our memory delegation scheme (in Section 7), consists of two parts. We first prove that our scheme has one-time soundness, i.e., it is sound assuming the delegation protocol is executed only once. Then, we argue that the fact that it is one-time sound, implies that it is also sound from multiple interactions (i.e., has reusable soundness.)</p>

    <h6 id="sec-45" class="text-base font-medium mt-4">Definition 30 (One-time Security Game and One-time Soundness)</h6>

    <p class="text-gray-300">Let <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}=\\langle\\mathsf{D},\\mathsf{W}\\rangle</span> be a delegation scheme. For a security parameter <span class="math">k\\in\\mathbb{N}</span> and for a (cheating) worker <span class="math">\\mathsf{W}^{<em>}</span>, the </em>one-time security game<em> <span class="math">\\mathsf{G}_{1}^{\\mathsf{W}^{</em>}}(k)</span> is defined similarly to the security game in Definition 37, except that they do not execute the learning phase, and just proceed to the challenge phase directly from the initial phase.</p>

    <p class="text-gray-300">We say <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}=\\langle\\mathsf{D},\\mathsf{W}\\rangle</span> has one-time soundness error <span class="math">\\varepsilon</span> if for every <span class="math">k\\in\\mathbb{N}</span> and every <em>PPT</em> worker strategy <span class="math">\\mathsf{W}^{*}</span>,</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mathsf{W}^{<em>}\\text{ succeeds in }\\mathsf{G}_{1}^{\\mathsf{W}^{</em>}}(k)]\\leq\\varepsilon(k).</span></p>

    <p class="text-gray-300">We say that <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}</span> is one-time sound if it has a negligible one-time soundness error.</p>

    <h6 id="sec-46" class="text-base font-medium mt-4">Theorem 31 (Memory Delegation)</h6>

    <p class="text-gray-300">Assume the existence of a poly-log PIR scheme (as defined in Definition 5) and a collision resistant hash function family. Then there exists a non-interactive (2-message) memory delegation scheme <span class="math">\\mathsf{mDel}</span>, for delegating any function computable by an <span class="math">\\mathcal{L}</span>-uniform poly-size circuit. The delegation scheme, <span class="math">\\mathsf{mDel}</span> has the following properties, for security parameter <span class="math">k</span>.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The scheme has perfect completeness and negligible (reusable) soundness error.</li>

      <li>The delegator and worker are efficient in the offline stage; i.e., both the delegator and the worker run in time <span class="math">\\mathrm{poly}(k,n)</span>.</li>

      <li>The worker is efficient in the online phase. More specifically, it runs in time <span class="math">\\mathrm{poly}(k,S)</span> during each <span class="math">\\mathsf{Compute}(f)</span> and <span class="math">\\mathsf{Update}(f)</span> operation, where <span class="math">S</span> is the size of the <span class="math">\\mathcal{L}</span>-uniform circuit computing <span class="math">f</span>. The delegator runs in time <span class="math">\\mathrm{poly}(k,d)</span> during each <span class="math">\\mathsf{Compute}(f)</span> and <span class="math">\\mathsf{Update}(f)</span> operation, where <span class="math">d</span> is the depth of the <span class="math">\\mathcal{L}</span>-uniform circuit computing <span class="math">f</span>.</li>

    </ul>

    <h2 id="sec-47" class="text-2xl font-bold">7 Memory Delegation Scheme</h2>

    <p class="text-gray-300">In this section, we prove Theorem 31, by constructing a non-interactive memory delegation scheme with the desired properties.</p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">7.1 Overview of our Memory Delegation Scheme</p>

    <p class="text-gray-300">The initial idea behind our memory delegation scheme, is the observation of Goldwasswer et. al. <em>[x10]</em>, that their delegation protocol can be verified very efficiently (in time sub-linear in the input size), if the delegator has oracle access to the low-degree extension of the input <span class="math">x</span> (we refer the reader to Section 3.3 for the definition of a low-degree extension). Moreover, as observed by <em>[x10]</em>, the delegator needs to access this low-degree extension <span class="math">\\text{LDE}_{x}</span> at a single point <span class="math">z</span>, which depends only on the random coin tosses of the delegator.</p>

    <p class="text-gray-300">This observation immediately gives rise to a memory delegation scheme with one-time soundness: The delegator’s secret state will be <span class="math">(z,\\text{LDE}_{x}(z))</span>. Then, she will use this secret state in order to verify computation using the GKR protocol. As was argued by Goldwasswer et. al., this indeed works if the delegator runs the delegation protocol once. However, the soundness crucially relies on the fact that the delegator’s secret state is indeed secret, and if the delegator uses this state more than once, then soundness breaks completely.</p>

    <p class="text-gray-300">One idea, following the idea of Gennaro et. al. <em>[x11]</em>, is to use a fully homomorphic encryption (FHE) scheme to encrypt all the communication, in order to hide the secret state. This indeed works if the worker does not learn whether the delegator accepts or rejects his proofs. However, if the worker does learn the verdict of the delegator, then there are known attacks that break soundness.</p>

    <p class="text-gray-300">In the streaming setting, we follow this approach, and we succeed in overcoming this problem, and construct a scheme that is sound even if the worker does learn the verdict of the delegator. We could follow this approach in the memory delegation setting as well. However, for several reasons, we choose to take a different approach. First, the approach above relies on the existence of an FHE scheme, whereas our memory delegation scheme relies on the existence of a poly-logarithmic PIR scheme, arguably a more reasonable assumption. Second, the approach above results with the delegator having a secret state, whereas in our memory delegation scheme, the state of the delegator is public. Finally, the construction and proof of the memory delegation scheme is simpler.</p>

    <p class="text-gray-300">In our approach, instead of having <span class="math">(z,\\text{LDE}_{x}(z))</span> as the delegator’s secret state, the delegator keeps a tree-commitment of the entire <span class="math">\\text{LDE}_{x}</span> as her secret state (recall the definition of a tree-commitment in Section 3.5). Namely, she chooses a random hash function <span class="math">h</span> from a collision-resistant hash family, and keeps <span class="math">(h,T_{h}(\\text{LDE}_{x}))</span> as her state. In addition to giving the worker her memory <span class="math">x</span>, she also gives him the hash function <span class="math">h</span>. Notice that her state is not secret, which makes the proof of security significantly simpler than that in the streaming setting (where the delegator’s state is secret).</p>

    <p class="text-gray-300">When the delegator wishes to delegate the computation of a function <span class="math">f</span>, they will execute <span class="math">\\mathsf{Compute}(f)</span>, by simply running the (non-interactive) delegation protocol <span class="math">\\text{GKR}(f)</span>. Recall that at the end of the GKR protocol the delegator needs to verify the value of <span class="math">\\text{LDE}_{x}(r)</span> for a random <span class="math">r</span>. However, she doesn’t have <span class="math">x</span>, since it was delegated to the prover, and all she has is the state <span class="math">(h,T_{h}(\\text{LDE}_{x}))</span>. So, rather than computing the value of <span class="math">\\text{LDE}_{x}(r)</span> on her own, she will ask the worker to reveal to this value, by sending the augmented path in the Merkle tree corresponding to the leaf <span class="math">r</span>.</p>

    <p class="text-gray-300">When the delegator wishes to update her memory from <span class="math">x</span> to <span class="math">g(x)</span>, she will need to update her secret state from <span class="math">(h,T_{h}(\\text{LDE}_{x}))</span> to <span class="math">(h,T_{h}(\\text{LDE}_{g(x)}))</span>. As before, she cannot perform this operation on her own, and instead she will delegate this computation to the worker, by requesting a</p>

    <p class="text-gray-300">Compute <span class="math">(g^{\\prime})</span> operation, where <span class="math">g^{\\prime}(x) = T_{h}(\\mathrm{LDE}_{g(x)})</span>.</p>

    <p class="text-gray-300">Unfortunately the high-level description given above is a gross oversimplification of our scheme, and there are several technical issues that complicate matters.</p>

    <p class="text-gray-300">The first technicality (the easiest one to deal with), is that the GKR delegation scheme does not have a negligible soundness error. In our setting, it is very important to have negligible soundness, since if the soundness is non-negligible, then a cheating worker may cheat in the update procedure (which is also being delegated). The problem is that if a worker cheats even once in an update procedure, all soundness guarantees are mute from that point on. So, we really need the soundness error to be negligible. In order to reduce the soundness error, we will run the GKR protocol in parallel <span class="math">u</span> times (for any parameter <span class="math">u</span> such that <span class="math">1/2^{u} = \\mathsf{ngl}(k)</span>). We denote the <span class="math">u</span>-fold parallel repetition of GKR by <span class="math">\\mathrm{GKR}^{(u)}</span>. As a result the worker will need to reveal to <span class="math">u</span> augmented paths of the Merkle tree.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The other technical point is more subtle. In the offline stage, when the delegator computes the tree commitment <span class="math">T_{h}(\\mathrm{LDE}_{x})</span>, she needs to choose the parameters <span class="math">\\mathbb{H},\\mathbb{F},m</span> for the low-degree extension. The typical choice for these parameters is: $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\mathrm{polylog}(n)<span class="math">, </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">, and </span>m = O\\left(\\frac{\\log n}{\\log \\log n}\\right)<span class="math">, where </span>n =</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. However, when delegating the computation of a function </span>f<span class="math">, the worker and delegator run </span>\\mathrm{GKR}^{(u)}(f)<span class="math"> and need to verify </span>\\mathrm{LDE}_x(r_i) = v_i<span class="math"> for random points </span>r_1,\\ldots ,r_u<span class="math">. However, here the parameters of the low-degree extension </span>\\mathrm{LDE}_x<span class="math"> depend on the depth </span>d<span class="math"> of the circuit computing </span>f$. Namely, looking at the parameters in Theorem 8, the parameters of the low-degree extension are</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {H} ^ {\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\theta (d \\cdot \\log n), m ^ {\\prime} = \\theta \\left(\\frac {\\log n}{\\log d}\\right),</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {F} ^ {\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\mathrm {p o l y} (</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {H} ^ {\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">Therefore, the worker cannot simply send the augmented path, since the tree commitment is w.r.t. parameters <span class="math">\\mathbb{H},\\mathbb{F},m</span> whereas the delegator needs to verify <span class="math">\\mathrm{LDE}_x(r_i) = v_i</span> w.r.t. the parameters <span class="math">\\mathbb{H}&#x27;,\\mathbb{F}&#x27;,m&#x27;</span>.</p>

    <p class="text-gray-300">We get around this technical problem by delegating the functions <span class="math">g_{r_i}(x) \\triangleq \\mathrm{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span>. Luckily, Corollary 7 implies that these functions can be computed by a poly-size circuit of depth <span class="math">\\log^c (n)</span> for some constant <span class="math">c</span> (assuming the delegated function <span class="math">f</span> is of poly-size). Again, we delegate the computation of each of these <span class="math">g_{r_i}</span> using <span class="math">\\mathrm{GKR}^{(u)}</span> to ensure negligible soundness. Thus, finally the worker will need to reveal the augmented paths of <span class="math">u^2</span> points in <span class="math">\\mathrm{LDE}_x</span> (<span class="math">u</span> points for each <span class="math">g_{r_i}</span>).</p>

    <p class="text-gray-300">The final technical difficulty is that all these algorithms need to run in parallel, since we want our final memory delegation scheme to be non-interactive (i.e., to consist of only two messages). Typically, there is no problem in running several two-message protocols in parallel. However, in our case, the delegator uses a common secret input in these protocols. Namely, the delegator uses secret randomness <span class="math">r_1,\\ldots ,r_u\\in (\\mathbb{F}&#x27;)^{m&#x27;}</span> in the parallel repetition of the delegation protocol <span class="math">\\mathrm{GKR}(f)</span> which ends with her needing to verify that <span class="math">\\mathrm{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i) = v_i</span> for every <span class="math">i\\in [u]</span>. In addition she uses these same <span class="math">r_i</span>'s in the delegation protocols <span class="math">\\mathrm{GKR}(g_{r_i})</span>. Moreover, at the end of each of the <span class="math">\\mathrm{GKR}(g_{r_i})</span> protocols, the delegator needs to verify that <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j}) = w_{i,j}</span> for random points <span class="math">z_{i,1},\\dots ,z_{i,u}\\in \\mathbb{F}^m</span>. Finally, they also run a reveal protocol for each <span class="math">z_{i,j}</span>, denoted by <span class="math">\\mathrm{Reveal}(z_{i,j})</span>, where the worker simply reveals to the augmented path of the leaf <span class="math">z_{i,j}</span> in the Merkle tree of <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}</span>.</p>

    <p class="text-gray-300">We note that the protocol <span class="math">\\mathrm{GKR}(f)</span> (resp. <span class="math">\\mathrm{GKR}(g)</span>) is not sound if the <span class="math">r_i</span>'s (resp. <span class="math">z_{i,j}</span>'s) are a priori known to the worker. To ensure that soundness still holds even if we run all these algorithms</p>

    <p class="text-gray-300">22We note that there are several ways to improve efficiency, such as thinking of <span class="math">(g_{r_1},\\ldots ,g_{r_u})</span> as one function. However, for the sake of simplicity of exposition, we focus on the simplest (rather than most efficient) solution.</p>

    <p class="text-gray-300">31</p>

    <p class="text-gray-300">in parallel, we mask parts of the delegator’s message using a PIR scheme, and then we use Lemma 24 to claim that the soundness error remains negligible.</p>

    <h3 id="sec-48" class="text-xl font-semibold mt-8">7.2 Formal Description of our Memory Delegation Scheme</h3>

    <p class="text-gray-300">Our construction uses the following building blocks</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>A collision resistant hash family <span class="math">\\mathcal{H}=\\{\\mathcal{H}_{k}\\}_{k\\in\\mathbb{N}}</span>, where every <span class="math">h\\in\\mathcal{H}_{k}</span> satisfies</li>

    </ol>

    <p class="text-gray-300"><span class="math">h:\\{0,1\\}^{k}\\times\\{0,1\\}^{k}\\to\\{0,1\\}^{k}.</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The delegation scheme <span class="math">\\mathrm{GKR}=\\langle\\mathsf{D}^{\\prime},\\mathsf{W}^{\\prime}\\rangle</span> from <em>[x13, x20]</em> (see Theorem 8 for the properties of this delegation scheme). The main property we use here, is that the delegator can verify proofs by accessing its input <span class="math">x</span> at a single random point in <span class="math">\\mathrm{LDE}_{x}</span>.</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- Parameters. Let <span class="math">k\\in\\mathbb{N}</span> be the security parameter, and let <span class="math">n\\in\\mathbb{N}</span> be the length of the (initial) memory being delegated. Let <span class="math">\\mathbb{H}</span> be an extension field of <span class="math">\\mathbb{GF}[2]</span>, and let <span class="math">m\\in\\mathbb{Z}</span> such that $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\mathrm{polylog}(n)<span class="math">, </span>m=\\theta\\left(\\frac{\\log n}{\\log\\log n}\\right)<span class="math">, and let </span>\\mathbb{F}<span class="math"> be an extension field of </span>\\mathbb{H}<span class="math"> of size </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\mathrm{poly}\\left(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\right)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Offline Phase. In the offline phase, both the delegator <span class="math">\\mathsf{D}</span> and the worker <span class="math">\\mathsf{W}</span> take as input the security parameter <span class="math">1^{k}</span> and a string <span class="math">x\\in\\{0,1\\}^{n}</span>. The worker <span class="math">\\mathsf{W}</span> simply saves <span class="math">x</span>. The delegator <span class="math">\\mathsf{D}</span> does the following.</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">1. Compute the low-degree extension of <span class="math">x</span> w.r.t. <span class="math">\\mathbb{H},\\mathbb{F},m</span>, denoted by <span class="math">\\mathrm{LDE}_{x}:\\mathbb{F}^{m}\\to\\mathbb{F}</span> (see Section 3.3 for the definition of a low-degree extension). She interprets <span class="math">\\mathrm{LDE}_{x}</span> as a vector in $\\mathbb{F}^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{m}}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Choose a random collision resistant hash-function <span class="math">h\\leftarrow\\mathcal{H}_{k}</span>, and sends <span class="math">h</span> to <span class="math">\\mathsf{W}</span>.</li>

      <li>Compute the root of the Merkle tree of <span class="math">\\mathrm{LDE}_{x}</span> with respect to the hash function <span class="math">h</span>. Namely, compute <span class="math">\\sigma=T_{h}(\\mathrm{LDE}_{x})</span>, which is the root of the Merkle tree corresponding to the hash function <span class="math">h</span> (we refer the reader to Section 3.5 for the definition of a Merkle tree).</li>

    </ol>

    <p class="text-gray-300">The delegator <span class="math">\\mathsf{D}</span> saves <span class="math">(h,\\sigma)</span> as a short certificate for <span class="math">x</span>.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Online-Phase.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{Compute}(f)</span>. When the delegator <span class="math">\\mathsf{D}</span> sends the worker <span class="math">\\mathsf{W}</span> a computation request <span class="math">\\mathsf{Compute}(f)</span>, they run the following three protocols in parallel.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run the underlying delegation protocol <span class="math">\\mathrm{GKR}=\\langle\\mathsf{D}^{\\prime},\\mathsf{W}^{\\prime}\\rangle</span> for delegating the computation of <span class="math">f(x)</span>. However, since the soundness of the GKR protocol is only <span class="math">1/2</span>, we amplify this soundness by repeating the GKR protocol <span class="math">u</span> times in parallel. Namely, <span class="math">\\mathsf{W}</span> and <span class="math">\\mathsf{D}</span> run <span class="math">\\mathrm{GKR}^{(u)}</span> which is a <span class="math">u</span>-fold parallel repetition of of the GKR protocol, and thus has soundness <span class="math">1/2^{u}+\\mathsf{ngl}(k)=\\mathsf{ngl}(k)</span> (assuming we take <span class="math">u</span> such that <span class="math">1/2^{u}=\\mathsf{ngl}(k)</span>).</li>

    </ol>

    <p class="text-gray-300">If <span class="math">\\mathsf{D}^{\\prime}</span> rejects, then <span class="math">\\mathsf{D}</span> rejects. Otherwise, at the end of this protocol the delegator <span class="math">\\mathsf{D}</span> needs to verify that <span class="math">\\mathrm{LDE}_{x}(r_{i})=v_{i}</span> for some random points <span class="math">r_{1},\\ldots,r_{u}</span>. Recall that</p>

    <p class="text-gray-300">these points depend only on the delegators random coin tosses, and can be efficiently computed by the delegator <span class="math">\\mathsf{D}</span> before the protocol execution begins (see Theorem 8).</p>

    <p class="text-gray-300">Recall that the low-degree extension <span class="math">\\mathrm{LDE}_x</span>, is not w.r.t. the parameters <span class="math">\\mathbb{H},\\mathbb{F},m</span>, but rather w.r.t. parameters <span class="math">\\mathbb{H}&#x27;,\\mathbb{F}&#x27;,m&#x27;</span> that depend on the depth <span class="math">d</span> of the <span class="math">\\mathcal{L}</span>-uniform circuit computing <span class="math">f</span> (see Theorem 8 and the discussion in Section 7.1). Thus, the delegator cannot verify that</p>

    <div class="my-4 text-center"><span class="math-block">\\mathrm{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i) = v_i</span></div>

    <p class="text-gray-300">by simply asking the worker to "decommit" to the leaves <span class="math">r_1, \\ldots, r_u</span> of the Merkle tree, by sending their augmented paths (since the tree commitment was on the low-degree extension of <span class="math">x</span> w.r.t. <span class="math">\\mathbb{H}, \\mathbb{F}, m</span>). Instead they will run the following additional protocol (in parallel).</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The idea is to run for every <span class="math">i \\in [u]</span>, the delegation protocol <span class="math">\\mathrm{GKR}^{(u)} = \\langle \\mathsf{D}&#x27;,\\mathsf{W}&#x27;\\rangle</span> for delegating the functions <span class="math">g_{r_i}</span>, where</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">g_{r_i}(x) = \\mathrm{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i).</span></div>

    <p class="text-gray-300">(As in Step 1, we use parallel repetition in order to reduce the soundness error to <span class="math">\\mathsf{ngl}(k)</span>). However, note that since these delegation protocols are running in parallel with the delegation protocol <span class="math">\\mathrm{GKR}^{(u)}</span> of Step 1, the <span class="math">r_i</span>'s (which are part of the description of <span class="math">g_{r_i}</span>) must be kept secret, to ensure the soundness of the <span class="math">\\mathrm{GKR}^{(u)}</span> protocol of Step 1.</p>

    <p class="text-gray-300">Thus, to ensure the secrecy of the <span class="math">r_i</span>'s, instead of running the <span class="math">\\mathrm{GKR}^{(u)}</span> protocols of Step 2 "in the clear", we mask them using a PIR scheme. In what follows, we explain what a single masked <span class="math">\\mathrm{GKR}^{(u)}</span> protocol for computing <span class="math">g_{r_i}</span> looks like, and this protocol will be repeated in parallel <span class="math">u</span> times (once for each <span class="math">i \\in [u]</span>).</p>

    <p class="text-gray-300">Recall that in the GKR protocol (and thus in the <span class="math">\\mathrm{GKR}^{(u)}</span> protocol), the message sent by the delegator <span class="math">\\mathsf{D}&#x27;</span> depends only on the parameters (and her random coin tosses), and is independent of the actual function being delegated (see Theorem 8). Thus, this message can be sent in the clear, as it reveals no information about the function <span class="math">g_{r_i}</span> being delegated (except for its size and depth), and thus reveals no information about the secret value <span class="math">r_i</span>. On the other hand, the message sent by the worker <span class="math">\\mathsf{W}&#x27;</span> obviously does depend on <span class="math">g_{r_i}</span>, and thus on <span class="math">r_i</span>. Since the <span class="math">r_i</span>'s should be kept secret, this message will be sent using a PIR scheme.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Namely, the worker <span class="math">\\mathsf{W}</span> prepares a database <span class="math">\\mathrm{DB}&#x27;</span> with $N' \\triangleq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{m'}<span class="math"> entries, where the entry </span>r \\in (\\mathbb{F}')^{m'}<span class="math"> contains the message he would have sent (in the parallel version </span>\\mathrm{GKR}^{(u)}<span class="math">) if the delegated function was </span>g_r(x) = \\mathrm{LDE}_x^{\\mathbb{F}',\\mathbb{H}',m'}(r)<span class="math">. The delegator </span>\\mathsf{D}<span class="math">, in addition to sending a </span>\\mathrm{GKR}^{(u)}<span class="math"> message, also sends a query </span>q_i' \\gets Q^{\\mathrm{PIR}}(k,r_i,N')<span class="math">. Then, the worker </span>\\mathsf{W}<span class="math"> answers the PIR query </span>q_i'<span class="math"> using the database </span>\\mathrm{DB}'<span class="math">; i.e., he sends </span>a_i' \\gets D^{\\mathrm{PIR}}(k,\\mathrm{DB}',q_i')<span class="math">. Finally, the delegator </span>\\mathsf{D}<span class="math"> retrieves the &quot;worker&#x27;s message&quot; using the Retrieve algorithm </span>R^{\\mathrm{PIR}}<span class="math">, and accepts this message if and only if </span>(\\mathsf{D}')^{(u)}<span class="math"> would have accepted it, and if it is consistent with Step 1; i.e., if the worker proved that indeed </span>g_{r_i}(x) = v_i<span class="math">, for the same value </span>v_i$ obtained in Step 1.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">As before, for every <span class="math">i \\in [u]</span>, to verify the <span class="math">i</span>'th delegation protocol <span class="math">\\mathrm{GKR}^{(u)}</span> for computing <span class="math">g_{r_i}(x) = \\mathrm{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span>, the delegator <span class="math">\\mathsf{D}&#x27;</span> needs to verify that <span class="math">\\mathrm{LDE}_x(z_{i,j}) = w_{i,j}</span>,</p>

    <p class="text-gray-300">for random values <span class="math">z_{i,1},\\ldots,z_{i,u}</span> that depend only on the parameters and on the delegator’s random coin tosses. However, here <span class="math">\\mathrm{LDE}_{x}</span> is w.r.t. the parameters <span class="math">\\mathbb{H},\\mathbb{F},m</span>, since the function <span class="math">g_{r_{i}}</span> is computable by <span class="math">\\mathcal{L}</span>-uniform circuit of depth <span class="math">\\mathrm{polylog}(n)</span> (follows from Corollary 7). In order to verify this, they run the following Reveal protocol <span class="math">u</span> times per each <span class="math">i\\in[u]</span>, and thus altogether they run the Reveal protocol <span class="math">u^{2}</span> times.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">3. The delegator and worker run a Reveal protocol <span class="math">u^{2}</span> times, where the delegator sends <span class="math">z_{i,j}\\in\\mathbb{F}^{m}</span> and the worker reveals the augmented path of the Merkle tree corresponding to the leaf <span class="math">z_{i,j}</span>, denoted by <span class="math">\\mathrm{aug}(z_{i,j})</span>. However, since <span class="math">z_{i,j}</span> needs to remain secret for the <span class="math">\\mathrm{GKR}^{(u)}</span> protocols in Step 2 to remain sound, this will be done using a PIR scheme. Namely, the worker <span class="math">\\mathsf{W}</span> does the following. He prepares a database DB of size $N\\triangleq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{m}<span class="math">, where for any </span>z\\in\\mathbb{F}^{m}<span class="math"> the </span>z<span class="math">’th entry contains </span>\\mathrm{aug}(z)<span class="math"> (i..e, the augmented path corresponding to the leaf </span>z<span class="math"> in the Merkle tree of </span>\\mathrm{LDE}_{x}<span class="math">). The delegator </span>\\mathsf{D}<span class="math"> sends a query </span>q_{i,j}\\leftarrow Q^{\\mathrm{PIR}}(k,z_{i,j},N)<span class="math">, and the worker </span>\\mathsf{W}<span class="math"> answers according to his database </span>a_{i,j}\\leftarrow D^{\\mathrm{PIR}}(k,\\mathrm{DB},q_{i,j})<span class="math">. Finally, the delegator </span>\\mathsf{D}<span class="math"> retrieves the answer using the retrieving algorithm </span>R^{\\mathrm{PIR}}<span class="math">, and accepts this answer if and only if the retrieved string is a valid augmented path of the Merkle tree corresponding to the leaf </span>z_{i,j}<span class="math">, and if the leaf value is </span>w_{i,j}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We denote the delegation protocol of Step 1 by</p>

    <p class="text-gray-300"><span class="math">\\mathrm{GKR}^{(u)}=\\langle\\mathsf{W}^{\\prime(u)},\\mathsf{D}^{\\prime(u)}(r_{1},\\ldots,r_{u})\\rangle(f).</span></p>

    <p class="text-gray-300">We denote the masked delegation protocols of Step 2 by</p>

    <p class="text-gray-300"><span class="math">\\mathrm{PIR}\\left(\\langle\\mathsf{W}^{\\prime(u)},\\mathsf{D}^{\\prime(u)}(z_{i,1},\\ldots,z_{i,u})\\rangle(g_{r_{i}})\\right).</span></p>

    <p class="text-gray-300">We denote the reveal protocols of Step 3 by <span class="math">\\mathrm{Reveal}(z_{i,j})</span>. Note that the memory <span class="math">x</span> is implicit in all these notations. We summarize the <span class="math">\\mathsf{Compute}(f)</span> protocol in Figure 3.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{Update}(g)</span>. When the delegator <span class="math">\\mathsf{D}</span> sends the worker <span class="math">\\mathsf{W}</span> an update request <span class="math">\\mathsf{Update}(g)</span> for some <span class="math">g\\in\\mathcal{G}</span>, indicating that she wishes to update her memory <span class="math">x</span> to <span class="math">g(x)</span>, the worker and delegator do the following.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The delegator <span class="math">\\mathsf{D}</span> uses the help of the worker <span class="math">\\mathsf{W}</span> in order to update her short certificate. Specifically, <span class="math">\\mathsf{D}</span> chooses a fresh hash function <span class="math">h^{\\prime}\\leftarrow\\mathcal{H}_{k}</span>, and sends <span class="math">h^{\\prime}</span> to <span class="math">\\mathsf{W}</span>. Then, she delegates to the worker <span class="math">\\mathsf{W}</span> the computation <span class="math">\\mathsf{Compute}(g^{\\prime})</span>, where</li>

    </ol>

    <p class="text-gray-300"><span class="math">g^{\\prime}(x)=T_{h^{\\prime}}(\\mathrm{LDE}_{g(x)}),</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where <span class="math">\\mathrm{LDE}_{g(x)}</span> is w.r.t. <span class="math">\\mathbb{H}^{\\prime},\\mathbb{F}^{\\prime},m^{\\prime}</span>, where letting $n^{\\prime}\\triangleq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">g(x)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, the field </span>\\mathbb{H}^{\\prime}<span class="math"> is an extension field of </span>\\mathbb{GF}[2]<span class="math"> of size </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\mathrm{polylog}(n^{\\prime})<span class="math">, </span>m^{\\prime}=\\theta\\left(\\frac{\\log n^{\\prime}}{\\log\\log n^{\\prime}}\\right)<span class="math">, and </span>\\mathbb{F}^{\\prime}<span class="math"> is an extension field of </span>\\mathbb{H}^{\\prime}<span class="math"> of size </span>\\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">. If she rejects this proof, then no update is performed. Otherwise, she updates her short certificate from </span>\\sigma<span class="math"> to </span>\\sigma^{\\prime}\\triangleq T_{h^{\\prime}}(\\mathrm{LDE}_{g(x)})$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The worker <span class="math">\\mathsf{W}</span> updates his state from <span class="math">x</span> to <span class="math">g(x)</span>.</li>

    </ol>

    <p class="text-gray-300">Note that if the function <span class="math">g</span> is computed by an <span class="math">\\mathcal{L}</span>-uniform circuit of depth <span class="math">d</span>, then the function <span class="math">g^{\\prime}</span> is computable by an <span class="math">\\mathcal{L}</span>-uniform circuit of depth <span class="math">d+\\mathrm{poly}(k)+\\mathrm{polylog}(n^{\\prime})\\leq\\mathrm{poly}(d,k)</span>.</p>

    <p class="text-gray-300">The delegator  <span class="math">\\mathsf{D}</span>  stores a state  <span class="math">(h,\\sigma)</span>  where  <span class="math">\\sigma = T_{h}(\\mathrm{LDE}_{x}^{\\mathbb{F},\\mathbb{H},m})</span>  and wants to learn the value of  <span class="math">f(x)</span>  from the worker  <span class="math">\\mathsf{W}</span> , who stores  <span class="math">x\\in \\{0,1\\} ^n</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>D and W run  <span class="math">\\mathrm{GKR}^{(u)} = \\langle \\mathsf{W}&#x27;^{(u)},\\mathsf{D}&#x27;^{(u)}(r_1,\\ldots ,r_u)\\rangle (f)</span></li>

    </ol>

    <p class="text-gray-300">(a) If  <span class="math">\\mathsf{D}&#x27;^{(u)}</span>  rejects, then the delegator  <span class="math">\\mathsf{D}</span>  outputs "reject". (b) At the end of this protocol, the delegator  <span class="math">\\mathsf{D}&#x27;</span>  needs to verify that  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i) = v_i</span>  for some values  <span class="math">v_{i}</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For every  <span class="math">i\\in [u]</span>  , run  <span class="math">\\mathrm{PIR}(\\langle \\mathsf{W}&#x27;^{(u)},\\mathsf{D}&#x27;^{(u)}(z_{i,1},\\ldots ,z_{i,u})\\rangle (g_{r_i}))</span></li>

    </ol>

    <p class="text-gray-300">(a) The delegator  <span class="math">\\mathsf{D}</span>  makes sure that in these protocols the worker still claims that indeed  <span class="math">g_{r_i}(x) = v_i</span> , where  <span class="math">g_{r_i}(x) = \\mathrm{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span> . If this is not the case, then the delegator  <span class="math">\\mathsf{D}</span>  outputs "reject". (b) If at any point  <span class="math">\\mathsf{D}&#x27;</span>  rejects, then the delegator  <span class="math">\\mathsf{D}</span>  outputs "reject". (c) In order to verify these protocols, the delegator  <span class="math">\\mathsf{D}</span>  needs to verify that  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j}) = w_{i,j}</span>  for some values  <span class="math">w_{i,j}</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For every  <span class="math">i,j\\in [u]</span>  , run  <span class="math">\\operatorname {Reveal}(z_{i,j})</span></li>

    </ol>

    <p class="text-gray-300">If for some  <span class="math">i,j\\in [u]</span> , the worker fails in revealing to  <span class="math">w_{i,j}</span> , then the delegator  <span class="math">\\mathsf{D}</span>  outputs "reject".</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The delegator  <span class="math">\\mathsf{D}</span>  outputs "accept", assuming he didn't output "reject" at any point.</li>

    </ol>

    <p class="text-gray-300">Figure 3: Compute(f)</p>

    <p class="text-gray-300">In this section, we prove that the construction above satisfies the properties of Theorem 31. The perfect completeness follows immediately from the completeness of the underlying delegation scheme GKR, the completeness of the PIR scheme, and the completeness of the Reveal protocol. The efficiency guarantees follow immediately from the efficiency guarantees of GKR and the efficiency guarantees of the underlying PIR scheme.</p>

    <p class="text-gray-300">The main difficulty is in proving soundness. We shall prove the one-time soundness of our memory delegation scheme in Lemma 32, and establish the reusable soundness in Lemma 33. At a very high level,</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>the one-time soundness of our scheme follows from the soundness of the GKR protocol, the security of tree commitments, and the parallel composition lemma (Lemma 24).</li>

      <li>the reusable soundness of our scheme follows from the one-time soundness, since the short certificate of the delegator is not secret, and the worker can compute this short certificate on his own.</li>

    </ul>

    <p class="text-gray-300">Lemma 32 The memory delegation scheme constructed in Section 7.2 is one-time sound, i.e., it has negligible one-time soundness error.</p>

    <p class="text-gray-300">Proof. Suppose for the sake of contradiction that there exists a PPT worker <span class="math">\\mathsf{W}^{*}</span> and a polynomial <span class="math">q</span> such that for infinitely many <span class="math">k</span>’s</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mathsf{W}^{<em>}\\text{ succeeds in }\\mathsf{G}_{1}^{\\mathsf{W}^{</em>}}(k)]\\geq\\frac{1}{q(k)},</span> (6)</p>

    <p class="text-gray-300">where <span class="math">\\mathsf{G}_{1}</span> is the one-time soundness game. Recall that in the game <span class="math">\\mathsf{G}_{1}</span>, the worker <span class="math">\\mathsf{W}^{<em>}(1^{k})</span> first chooses a parameter <span class="math">n=\\mathrm{poly}(k)</span> and a string <span class="math">x\\in\\{0,1\\}^{n}</span>. Then, <span class="math">\\mathsf{D}</span> and <span class="math">\\mathsf{W}^{</em>}</span> run the offline phase, where <span class="math">\\mathsf{D}</span> chooses a random hash function <span class="math">h\\leftarrow\\mathcal{H}_{k}</span>, computes <span class="math">\\sigma\\triangleq T_{h}(x)</span>, and sends <span class="math">h</span> to <span class="math">\\mathsf{W}^{<em>}</span>. Then, <span class="math">\\mathsf{W}^{</em>}</span> chooses a function <span class="math">f\\in\\mathcal{F}</span>, and <span class="math">\\mathsf{D}</span> and <span class="math">\\mathsf{W}^{*}</span> execute <span class="math">\\mathsf{Compute}(f)</span>.</p>

    <p class="text-gray-300">Suppose that <span class="math">\\mathsf{W}^{<em>}</span> succeeds in proving a false statement <span class="math">f(x)=y^{\\prime}</span>. Namely, <span class="math">\\mathsf{W}^{</em>}</span> and <span class="math">\\mathsf{D}</span> run the protocol <span class="math">\\mathsf{Compute}(f)</span> and at the end <span class="math">\\mathsf{D}</span> accepts a wrong statement <span class="math">f(x)=y^{\\prime}</span>.</p>

    <p class="text-gray-300">Recall that the <span class="math">\\mathsf{Compute}(f)</span> protocol consists of <span class="math">1+u+u^{2}</span> sub-protocols: an execution of</p>

    <p class="text-gray-300"><span class="math">\\Pi_{0}=\\mathrm{GKR}^{(u)}=\\langle\\mathsf{W}^{\\prime(u)},\\mathsf{D}^{\\prime(u)}(r_{1},\\ldots,r_{u})\\rangle(f),</span></p>

    <p class="text-gray-300">for every <span class="math">i\\in[u]</span>, an execution of</p>

    <p class="text-gray-300"><span class="math">\\Pi_{i}=\\mathrm{PIR}\\left(\\langle\\mathsf{W}^{\\prime(u)},\\mathsf{D}^{\\prime(u)}(z_{i,1},\\ldots,z_{i,u})\\rangle(g_{r_{i}})\\right),</span></p>

    <p class="text-gray-300">and for every <span class="math">i,j\\in[u]</span>, an execution of <span class="math">\\Pi_{i,j}=\\mathrm{Reveal}(z_{i,j})</span>.</p>

    <p class="text-gray-300">Suppose that in the <span class="math">\\mathsf{Compute}(f)</span> protocol, <span class="math">\\Pi_{0}</span> reduces verifying that <span class="math">f(x)=y^{\\prime}</span> to verifying the <span class="math">u</span> statements</p>

    <p class="text-gray-300"><span class="math">\\mathrm{LDE}^{\\mathbb{F}^{\\prime},\\mathbb{H}^{\\prime},m^{\\prime}}_{x}(r_{i})=v_{i},</span></p>

    <p class="text-gray-300">and each <span class="math">\\Pi_{i}</span> reduces verifying that <span class="math">\\mathrm{LDE}^{\\mathbb{F}^{\\prime},\\mathbb{H}^{\\prime},m^{\\prime}}_{x}(r_{i})=v_{i}</span> to verifying the <span class="math">u</span> statements</p>

    <p class="text-gray-300"><span class="math">\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m}_{x}(z_{i,j})=w_{i,j}.</span></p>

    <p class="text-gray-300">We note that for <span class="math">\\mathsf{W}^{<em>}</span> to succeed in <span class="math">\\mathsf{G}_{1}</span>, <span class="math">\\mathsf{W}^{</em>}</span> must successfully “cheat” in at least one of <span class="math">\\Pi_{0},\\Pi_{i}</span>, or <span class="math">\\Pi_{i,j}</span>. Namely, one of the following cases holds.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Case 1. <span class="math">y^{\\prime}\\neq f(x)</span>, and for every <span class="math">i\\in[u]</span>, <span class="math">v_{i}=\\mathrm{LDE}^{\\mathbb{F}^{\\prime},\\mathbb{H}^{\\prime},m^{\\prime}}_{x}(r_{i})</span>.</li>

      <li>Case 2. There exists <span class="math">i\\in[u]</span> such that <span class="math">v_{i}\\neq\\mathrm{LDE}^{\\mathbb{F}^{\\prime},\\mathbb{H}^{\\prime},m^{\\prime}}_{x}(r_{i})</span>, and for every <span class="math">j\\in[u]</span>, <span class="math">w_{i,j}=\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m}_{x}(z_{i,j})</span>.</li>

      <li>Case 3. There exists <span class="math">i,j\\in[u]</span> such that <span class="math">w_{i,j}\\neq\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m}_{x}(z_{i,j})</span>.</li>

    </ol>

    <p class="text-gray-300">Intuitively, each of the above cases should hold with only negligible probability. This is due to the soundness property of the GKR protocol and the security of the tree commitments.</p>

    <p class="text-gray-300">We next use Lemma 24 to claim that each of the above cases holds with negligible probability, even when <span class="math">\\Pi_{0},\\Pi_{i}</span>, or <span class="math">\\Pi_{i,j}</span> are executed in parallel, contradicting Equation (6).</p>

    <p class="text-gray-300">In order to make use of Lemma 24, we consider a slightly modified version of the protocols <span class="math">\\Pi_{0}</span>, <span class="math">\\Pi_{i}</span>, and <span class="math">\\Pi_{i,j}</span>, denoted by <span class="math">\\Pi_{0}^{\\prime}</span>, <span class="math">\\Pi_{i}^{\\prime}</span>, and <span class="math">\\Pi_{i,j}^{\\prime}</span>. The messages sent in these protocols are identical to the ones sent in the original <span class="math">\\Pi_{0},\\Pi_{i},\\Pi_{i,j}</span> protocols, and the only difference is in the verification procedure. Note that the protocols <span class="math">\\Pi_{0},\\Pi_{i},\\Pi_{i,j}</span> are interleaved in the sense that the verifier of <span class="math">\\Pi_{0}</span> doesn’t actually verify the correctness of <span class="math">\\Pi_{0}</span>, but rather uses the protocols <span class="math">\\Pi_{i}</span> to verify the correctness of <span class="math">\\Pi_{0}</span>. Similarly, the verifier uses the protocols <span class="math">\\Pi_{i,j}</span> to verify the correctness of <span class="math">\\Pi_{i}</span>.</p>

    <p class="text-gray-300">Instead, we define <span class="math">\\Pi_0&#x27;, \\Pi_i&#x27;, \\Pi_{i,j}&#x27;</span> to be stand-alone protocols (with their own verification procedures) for recognizing the empty language.</p>

    <p class="text-gray-300">Recall that <span class="math">\\Pi_0 = \\mathrm{GKR}^{(u)} = \\langle \\mathsf{W}&#x27;^{(u)}, \\mathsf{D}&#x27;^{(u)}(r_1, \\ldots, r_u) \\rangle(f)</span> is a <span class="math">u</span>-fold parallel repetition of GKR, where the delegator delegates the computation of <span class="math">f(x)</span> to the worker. In <span class="math">\\Pi_0&#x27;</span>, the verifier actually computes on her own (using <span class="math">x</span>) the correct values of <span class="math">y = f(x)</span> and <span class="math">v_i = \\mathrm{LDE}_x^{\\mathbb{F}&#x27;, \\mathbb{H}&#x27;, m&#x27;}(r_i)</span> for every <span class="math">i \\in [u]^{23}</span>, and the verifier accepts if and only if at the end of <span class="math">\\mathrm{GKR}^{(u)}</span>, the worker convinces the delegator to accept some incorrect <span class="math">y&#x27; \\neq f(x)</span>. Note that the soundness of <span class="math">\\mathrm{GKR}^{(u)}</span> implies that <span class="math">\\Pi_0&#x27;</span> has negligible soundness error.</p>

    <p class="text-gray-300">Recall that each <span class="math">\\Pi_i = \\mathrm{PIR}(\\langle \\mathsf{W}&#x27;^{(u)}, \\mathsf{D}&#x27;^{(u)}(z_{i,1}, \\ldots, z_{i,u}) \\rangle(g_{r_i}))</span> is a masked <span class="math">u</span>-fold parallel repetition of GKR, where the delegator delegates the computation of <span class="math">g_{r_i}(x) = \\mathrm{LDE}_x^{\\mathbb{F}&#x27;, \\mathbb{H}&#x27;, m&#x27;}(r_i)</span> to the worker, and <span class="math">r_i</span> is a random point masked by the PIR scheme. In each <span class="math">\\Pi_i&#x27;</span>, the verifier actually computes on her own (using <span class="math">x</span>) the correct value <span class="math">v_i = \\mathrm{LDE}_x^{\\mathbb{F}&#x27;, \\mathbb{H}&#x27;, m&#x27;}(r_i)</span> and the values <span class="math">w_{i,j} = \\mathrm{LDE}_x^{\\mathbb{F}, \\mathbb{H}, m}(z_{i,j})</span> for every <span class="math">j \\in [u]</span>, and the verifier accepts if and only if the worker convinces the delegator to accept some incorrect <span class="math">v_i&#x27; \\neq \\mathrm{LDE}_x^{\\mathbb{F}&#x27;, \\mathbb{H}&#x27;, m&#x27;}(r_i)</span>. Note that the soundness of <span class="math">\\mathrm{GKR}^{(u)}</span> implies that <span class="math">\\Pi_i&#x27;</span> has negligible soundness error.²⁴</p>

    <p class="text-gray-300">Finally, recall that each <span class="math">\\Pi_{i,j} = \\mathrm{Reveal}(z_{i,j})</span> is a masked tree commitment reveal protocol, where the delegator asks the worker to reveal the value of <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span> by giving a valid augmented path <span class="math">\\mathrm{aug}(z_{i,j})</span> of <span class="math">T_h(\\mathrm{LDE}_x)</span>, and <span class="math">z_{i,j}</span> is a random point masked by the PIR scheme. In each <span class="math">\\Pi_{i,j}&#x27;</span>, the verifier actually computes on her own (using <span class="math">x</span>) the correct values of <span class="math">w_{i,j} = \\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span>, and the verifier accepts iff the worker convinces the delegator to accept some incorrect <span class="math">w_{i,j} \\neq \\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span>. Note that the security of the tree commitments implies that <span class="math">\\Pi_{i,j}&#x27;</span> has negligible soundness error.</p>

    <p class="text-gray-300">In all the protocols <span class="math">\\Pi_0&#x27;</span>, <span class="math">\\Pi_i&#x27;</span>, and <span class="math">\\Pi_{i,j}&#x27;</span>, we think of <span class="math">x</span> as the common input, and we think of</p>

    <div class="my-4 text-center"><span class="math-block">p = \\left((r_i)_{i \\in [u]}, (z_{i,j})_{i, j \\in [u]}\\right)</span></div>

    <p class="text-gray-300">as the common private randomness.</p>

    <p class="text-gray-300">Let <span class="math">\\Pi&#x27;</span> be the corresponding parallel execution of <span class="math">\\Pi_0&#x27;, \\Pi_i&#x27;</span>, and <span class="math">\\Pi_{i,j}&#x27;</span>, where the verifier of <span class="math">\\Pi&#x27;</span> accepts if and only if any one of <span class="math">\\Pi_0&#x27;, \\Pi_i&#x27;</span>, and <span class="math">\\Pi_{i,j}&#x27;</span> accepts. Lemma 24 implies that the fact that each of the protocols <span class="math">\\Pi_0&#x27;, \\Pi_i&#x27;</span>, and <span class="math">\\Pi_{i,j}&#x27;</span> has negligible soundness error, implies that <span class="math">\\Pi&#x27;</span> has negligible soundness as well. Recall that whenever <span class="math">\\mathsf{W}^*</span> succeeds in <span class="math">\\mathsf{G}_1</span>, at least one of the above three cases holds. Namely, the verifier in <span class="math">\\Pi_0&#x27;</span> accepts when Case 1 holds, the verifier in <span class="math">\\Pi_i&#x27;</span> accepts when Case 2 holds, and the verifier in <span class="math">\\Pi_{i,j}&#x27;</span> accepts when Case 3 holds. Thus,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\mathsf{W}^* \\text{ succeeds in } \\mathsf{G}_1^{\\mathsf{W}^*}(k) \\right] \\leq \\Pr \\left[ \\mathsf{D} \\text{ accepts in } \\Pi&#x27; \\right] \\leq \\mathsf{ngl}(k),</span></div>

    <p class="text-gray-300">contradicting Equation (6).</p>

    <p class="text-gray-300"><strong>Lemma 33</strong> The memory delegation scheme constructed in Section 7.2 is sound, i.e., it has negligible reusable soundness error.</p>

    <p class="text-gray-300"><strong>Proof.</strong> Suppose for the sake of contradiction that there exists a PPT worker <span class="math">\\mathsf{W}^*</span> such that</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\mathsf{W}^* \\text{ succeeds in } \\mathsf{G}^{\\mathsf{W}^*}(k) \\right] \\geq \\alpha(k), \\tag{7}</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">²⁴ Note that the verifier in these protocols runs in time $\\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$, which is too long in our setting, but this is only in the analysis.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">²⁴ Note that we didn't use the soundness of the PIR scheme. Indeed, the PIR scheme is added only in order to later apply Lemma 24.</p>

    <p class="text-gray-300">for a non-negligible function <span class="math">\\alpha</span>, where <span class="math">\\mathsf{G}</span> is the reusable soundness game. We construct a PPT worker <span class="math">\\mathsf{W}_{1}^{<em>}</span> which succeeds in the one-time security game <span class="math">\\mathsf{G}_{1}^{\\mathsf{W}_{1}^{</em>}}(k)</span> with non-negligible probability.</p>

    <p class="text-gray-300">Recall that the game <span class="math">\\mathsf{G}</span> proceeds in three phases, as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In the initial phase, the worker <span class="math">\\mathsf{W}^{<em>}(1^{k})</span> first chooses a parameter <span class="math">n=\\mathrm{poly}(k)</span> and a string <span class="math">x\\in\\{0,1\\}^{n}</span>. Then, <span class="math">\\mathsf{D}</span> and <span class="math">\\mathsf{W}^{</em>}</span> run the offline phase, where <span class="math">\\mathsf{D}</span> chooses a random hash function <span class="math">h\\leftarrow\\mathcal{H}_{k}</span>, computes <span class="math">\\sigma\\triangleq T_{h}(x)</span>, and sends <span class="math">h</span> to <span class="math">\\mathsf{W}^{*}</span>.</li>

      <li>In the learning phase, <span class="math">\\mathsf{W}^{<em>}</span> and <span class="math">\\mathsf{D}</span> execute polynomially many <span class="math">\\mathsf{Compute}(f)</span> and <span class="math">\\mathsf{Update}(g)</span> operations, where each <span class="math">f\\in\\mathcal{F}</span> and <span class="math">g\\in\\mathcal{G}</span> are chosen by <span class="math">\\mathsf{W}^{</em>}</span>. In the <span class="math">\\mathsf{Update}(g)</span>, <span class="math">\\mathsf{D}</span> chooses a fresh hash function <span class="math">h^{\\prime}\\leftarrow\\mathcal{H}_{k}</span>, sends <span class="math">h^{\\prime}</span> to <span class="math">\\mathsf{W}^{<em>}</span>, and then <span class="math">\\mathsf{D}</span> and <span class="math">\\mathsf{W}^{</em>}</span> execute <span class="math">\\mathsf{Compute}(g^{\\prime})</span> where <span class="math">g^{\\prime}(x)=T_{h^{\\prime}}(\\mathrm{LDE}_{g(x)})</span>. If <span class="math">\\mathsf{D}</span> accepts, then the memory is updated to <span class="math">x^{\\prime}=g(x)</span>, and if <span class="math">\\mathsf{D}</span> rejects, then the memory <span class="math">x</span> remains unchanged.</li>

      <li>In the challenge phase, <span class="math">\\mathsf{W}^{<em>}</span> chooses <span class="math">f^{\\prime}\\in\\mathcal{F}</span>, and <span class="math">\\mathsf{D}</span> and <span class="math">\\mathsf{W}^{</em>}</span> execute <span class="math">\\mathsf{Compute}(f^{\\prime})</span>. <span class="math">\\mathsf{W}^{*}</span> succeeds if <span class="math">\\mathsf{D}</span> accepts a wrong value <span class="math">y^{\\prime}\\neq f^{\\prime}(x)</span>, where <span class="math">x</span> is the latest updated memory.</li>

    </ul>

    <p class="text-gray-300">Intuitively, noting that the short certificate of the delegator is public, one-time soundness seems to immediately imply reusable soundness, since in this case a (one-time) cheating worker <span class="math">\\mathsf{W}_{1}^{<em>}</span> can simulate the learning phase of <span class="math">\\langle\\mathsf{D},\\mathsf{W}^{</em>}\\rangle</span> on his own. However, this intuition is an oversimplification, since <span class="math">\\mathsf{W}^{<em>}</span> may cheat in one of the <span class="math">\\mathsf{Update}</span> computations, and thus convince the delegator <span class="math">\\mathsf{D}</span> to update her certificate to some incorrect value, which allows <span class="math">\\mathsf{W}^{</em>}</span> to cheat easily in the challenge phase. In this case, simulating the learning phase does not help <span class="math">\\mathsf{W}_{1}^{*}</span> cheat in the one-time security game <span class="math">\\mathsf{G}_{1}</span>.</p>

    <p class="text-gray-300">Therefore, instead of simply simulating the entire learning phase, roughly speaking, <span class="math">\\mathsf{W}_{1}^{*}</span> does the following.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Guess the <em>first time</em> that <span class="math">\\mathsf{W}^{*}</span> cheats successfully in either an update or a compute operation (we refer to this as the first cheating operation).</li>

      <li>Guess the <em>last</em> valid update operation (that <span class="math">\\mathsf{D}</span> accepts) before the cheating operation (we refer to this as the last update operation).</li>

      <li>Embed the one-time game <span class="math">\\mathsf{G}_{1}</span> into the reusable game <span class="math">\\mathsf{G}</span>, as follows: Simulate <span class="math">\\langle\\mathsf{D},\\mathsf{W}^{<em>}\\rangle</span> in <span class="math">\\mathsf{G}</span> up to the last update operation, and use the memory at that time to interact with <span class="math">\\mathsf{D}_{1}</span> in the initial phase of <span class="math">\\mathsf{G}_{1}</span>. Then, continue to simulate <span class="math">\\langle\\mathsf{D},\\mathsf{W}^{</em>}\\rangle</span> in <span class="math">\\mathsf{G}</span> up to the first cheating operation, and interact with <span class="math">\\mathsf{D}_{1}</span> in the challenge phase of <span class="math">\\mathsf{G}_{1}</span> by using <span class="math">\\mathsf{W}^{*}</span> in this first cheating operation in <span class="math">\\mathsf{G}</span>.</li>

    </ol>

    <p class="text-gray-300">In order to describe <span class="math">\\mathsf{W}_{1}^{<em>}</span> more formally, we use the following notation. Let <span class="math">L(k)\\leq\\mathrm{poly}(k)</span> be an upper bound on the total number of <span class="math">\\mathsf{Compute}</span> and <span class="math">\\mathsf{Update}</span> operations that <span class="math">\\mathsf{W}^{</em>}</span> makes in the (reusable) game <span class="math">\\mathsf{G}</span>. We call each such operation in <span class="math">\\mathsf{G}</span> a round. We refer to the initial phase as round <span class="math">0</span>, the learning phase starts at round <span class="math">1</span>, and the challenge phase is the last round. Denote by <span class="math">x_{i}</span> the memory content at the end of round <span class="math">i</span>, and let <span class="math">f_{i}</span> be the delegation function of the <span class="math">\\mathsf{Compute}(\\cdot)</span> operation in round <span class="math">i</span>. Recall that <span class="math">\\mathsf{Update}(g)</span> is implemented via a compute operation, so <span class="math">f_{i}</span> is defined for every round.</p>

    <p class="text-gray-300">Using this notation, we define <span class="math">\\mathsf{W}_{1}^{*}</span> more formally, as follows:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Choose at random <span class="math">j\\leftarrow[L]</span> and choose at random <span class="math">i\\leftarrow\\{0,1,\\ldots,j-1\\}</span>, where <span class="math">j</span> is a guess for the first cheating operation of <span class="math">\\mathsf{W}^{*}</span>, and <span class="math">i</span> is a guess for the last successful <span class="math">\\mathsf{Update}</span> operation</li>

    </ol>

    <p class="text-gray-300">of <span class="math">\\mathsf{W}^{<em>}</span> before round <span class="math">j</span>. (<span class="math">i=0</span> corresponds to the guess that <span class="math">\\mathsf{W}^{</em>}</span> doesn’t update successfully the initial input <span class="math">x_{0}</span> before round <span class="math">j</span>.)</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Simulate the interaction of <span class="math">\\langle\\mathsf{D},\\mathsf{W}^{*}\\rangle</span> in the reusable game <span class="math">\\mathsf{G}</span> up until the end of round <span class="math">i</span>. Denote by <span class="math">x_{i}</span> the memory at the end of round <span class="math">i</span> in the simulated game <span class="math">\\mathsf{G}</span>.</li>

      <li>Start the initial phase of <span class="math">\\mathsf{G}_{1}</span>, with the memory <span class="math">x_{i}</span>.</li>

      <li>Upon receiving a hash function <span class="math">h\\leftarrow\\mathcal{H}_{k}</span> from <span class="math">\\mathsf{D}_{1}</span> in the offline phase, view this <span class="math">h</span> as chosen by <span class="math">\\mathsf{D}</span> in round <span class="math">i</span> of the simulated (reusable game) <span class="math">\\mathsf{G}</span>, and continue the simulation of <span class="math">\\mathsf{G}</span> until the beginning of round <span class="math">j</span>.</li>

      <li>If at round <span class="math">j</span>, <span class="math">\\mathsf{W}^{<em>}</span> chooses to perform <span class="math">\\mathsf{Compute}(f_{j})</span>, then start the challenge phase of <span class="math">\\mathsf{G}_{1}</span> with the function <span class="math">f_{j}</span>, and interact with <span class="math">\\mathsf{D}_{1}</span> by simulating <span class="math">\\mathsf{W}^{</em>}</span> (who supposedly executes <span class="math">\\mathsf{Compute}(f_{j})</span> with <span class="math">\\mathsf{D}</span>).</li>

    </ol>

    <p class="text-gray-300">We next analyze the success probability of <span class="math">\\mathsf{W}_{1}^{<em>}</span>. To this end, for any <span class="math">j\\in[L]</span> and any <span class="math">i\\in\\{0,1,\\ldots,j-1\\}</span>, let <span class="math">W_{i,j}</span> be the event that (1) the </em>first time<em> that <span class="math">\\mathsf{W}^{</em>}</span> cheats successfully is in round <span class="math">j</span>, and (2) the <em>last</em> valid update operation (that <span class="math">\\mathsf{D}</span> accepts) before round <span class="math">j</span> is in round <span class="math">i</span>.</p>

    <p class="text-gray-300">Note that by definition, whenever <span class="math">\\mathsf{W}^{*}</span> succeeds in <span class="math">\\mathsf{G}</span>, there must exist some such <span class="math">i,j</span> such that event <span class="math">W_{i,j}</span> holds. Thus, a simple counting argument, together with Equation (7), implies that there exists some such <span class="math">i,j</span> such that</p>

    <p class="text-gray-300"><span class="math">\\Pr[W_{i,j}]\\geq\\frac{\\alpha}{L^{2}},</span></p>

    <p class="text-gray-300">which implies that</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mathsf{W}_{1}^{<em>}\\text{ succeeds in }\\mathsf{G}_{1}^{\\mathsf{W}_{1}^{</em>}}(k)]\\geq\\frac{\\alpha}{L^{2}},</span></p>

    <p class="text-gray-300">contradicting Lemma 32, which asserts that the scheme is one-time secure.</p>

    <p class="text-gray-300">∎</p>

    <h2 id="sec-51" class="text-2xl font-bold">8 Streaming Delegation Model</h2>

    <p class="text-gray-300">In this section, we formally define our streaming delegation model. We present our streaming delegation scheme in Section 9.</p>

    <h6 id="sec-52" class="text-base font-medium mt-4">Definition 34 (Streaming Delegation Scheme)</h6>

    <p class="text-gray-300">Let <span class="math">\\mathcal{F}</span> be a class of boolean functions. A <em>streaming delegation scheme</em> <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span>, for a function class <span class="math">\\mathcal{F}</span>, consists of a streaming generator <span class="math">\\mathsf{S}</span> and an interactive protocol <span class="math">\\langle\\mathsf{D},\\mathsf{W}\\rangle</span> between a delegator <span class="math">\\mathsf{D}</span> and a worker <span class="math">\\mathsf{W}</span> with the following structure.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The scheme <span class="math">\\mathsf{sDel}</span> starts at time <span class="math">0</span>, at which all parties receive a security parameter <span class="math">1^{k}</span> and a parameter <span class="math">N</span> (in binary) which specifies the maximum length of the data stream. On input <span class="math">(1^{k},N)</span>, <span class="math">\\mathsf{D}</span> generates some (possibly secret) state <span class="math">\\sigma_{0}</span>.</li>

      <li>At each time <span class="math">t\\in[N]</span>, <span class="math">\\mathsf{S}</span> generates a data item <span class="math">x_{t}\\in\\{0,1\\}</span>, which is received by both <span class="math">\\mathsf{D}</span> and <span class="math">\\mathsf{W}</span>. Upon receiving <span class="math">x_{t}</span>, <span class="math">\\mathsf{D}</span> updates her secret state from <span class="math">\\sigma_{t-1}</span> to <span class="math">\\sigma_{t}</span>, and <span class="math">\\mathsf{W}</span> simply stores <span class="math">x_{t}</span>. Let <span class="math">x^{t}=x^{t-1}\\circ x_{t}</span> denote the current received data items, where <span class="math">\\circ</span> represents a concatenation.</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>At any time <span class="math">t \\in [N]</span>, <span class="math">\\mathsf{D}</span> may choose a delegation function <span class="math">f: \\{0,1\\}^t \\to \\{0,1\\} \\in \\mathcal{F}</span> and run the delegation protocol <span class="math">\\langle \\mathsf{D}, \\mathsf{W} \\rangle</span> on input <span class="math">(f,t)</span>. In addition to the common input <span class="math">(f,t)</span>, the delegator <span class="math">D</span> takes as input her secret state <span class="math">\\sigma_t</span>, and the worker <span class="math">\\mathsf{W}</span> takes as input the data stream <span class="math">x^t</span>.</li>

    </ol>

    <p class="text-gray-300"><strong>Remark 1.</strong> For the sake of readability, we try to keep the definition of the model as simple as possible. For example, we assume that data items are bits and delegation functions are boolean functions, while it is natural to consider non-boolean data items and non-boolean delegation functions. Also, we implicitly assume that <span class="math">\\mathsf{D}</span> delegates at most one function of the current data stream at any given time <span class="math">t</span>, while it is natural to allow <span class="math">\\mathsf{D}</span> to delegate multiple functions at the same time. Nevertheless, it will be easy to see that our solution presented in Section 9 generalizes to these extensions readily.</p>

    <p class="text-gray-300"><strong>Remark 2.</strong> Note that in Definition 34, we require that <span class="math">\\mathsf{D}</span> updates her fingerprint of the data stream on her own efficiently (ideally, in time <span class="math">\\mathrm{polylog}(N)</span>; see Definition 35 below). The reason is that in the streaming setting, the data stream arrives constantly at a high rate. Thus, if the update function would be delegated at time <span class="math">t</span>, this delegation protocol may not end before time <span class="math">t + 1</span>. Hence, it may be infeasible and unreliable to ask the worker for his help in updating the delegator's fingerprint. We note that this is in contrast to the setting of memory delegation, where we do allow the update procedure to be delegated (see Section 6 for details).</p>

    <p class="text-gray-300"><strong>Definition 35 (Efficiency)</strong> A streaming delegation scheme <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> has an efficient delegator if the runtime of <span class="math">\\mathsf{D}</span> each time she updates her (secret) fingerprint is <span class="math">\\mathrm{polylog}(N)</span>, and her runtime during each execution of the protocol <span class="math">\\langle \\mathsf{D}, \\mathsf{W} \\rangle(f, t)</span> is <span class="math">\\mathrm{poly}(k, \\log N, \\log S)</span>, where <span class="math">S</span> is the size of the circuit computing <span class="math">f</span>. A streaming delegation scheme <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> has an efficient worker if the runtime of <span class="math">\\mathsf{W}</span> during an execution of <span class="math">\\langle \\mathsf{D}, \\mathsf{W} \\rangle(f, t)</span> is <span class="math">\\mathrm{poly}(k, \\log N, S)</span>, where <span class="math">S</span> is the size of the circuit computing <span class="math">f</span>.</p>

    <p class="text-gray-300">We proceed to define the completeness and soundness of a streaming delegation scheme.</p>

    <p class="text-gray-300"><strong>Definition 36 (Completeness)</strong> For any function class <span class="math">\\mathcal{F}</span>, a streaming delegation scheme <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> has perfect completeness if for every parameter <span class="math">k, N \\in \\mathbb{N}</span>, <span class="math">t \\in [N]</span>, every function <span class="math">f: \\{0,1\\}^t \\to \\{0,1\\} \\in \\mathcal{F}</span>, and every <span class="math">x^t \\in \\{0,1\\}^t</span> generated by <span class="math">\\mathsf{S}</span>, the following holds with probability 1: When <span class="math">\\mathsf{D}</span> and <span class="math">\\mathsf{W}</span> run the delegation protocol <span class="math">\\langle \\mathsf{D}, \\mathsf{W} \\rangle(f, t)</span>, <span class="math">\\mathsf{D}</span> always accepts and outputs <span class="math">y = f(x^t)</span>.</p>

    <p class="text-gray-300">The definition of the soundness property is more elaborate, since <span class="math">\\mathsf{D}</span> and <span class="math">\\mathsf{W}</span> may run the delegation protocol multiple times with different inputs. We provide the following game-based definition, where we allow the adversary <span class="math">\\mathsf{W}^<em></span> to choose the data stream and delegation functions, and <span class="math">\\mathsf{W}^</em></span> wins if he convinces <span class="math">\\mathsf{D}</span> to accept an incorrect function value.</p>

    <p class="text-gray-300"><strong>Definition 37 (Streaming Security Game)</strong> Let <span class="math">k</span> be a security parameter and <span class="math">N</span> be a parameter. Let <span class="math">\\mathcal{F}</span> be a function class and let <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> be a delegation scheme for <span class="math">\\mathcal{F}</span>. The corresponding streaming security game <span class="math">\\mathsf{G}^{\\mathsf{W}^<em>}(k, N)</span> played by an (adversarial) worker <span class="math">\\mathsf{W}^</em></span> is defined as follows.</p>

    <p class="text-gray-300">25For simplicity of presentation, we omit the security parameter when it is clear from the context.</p>

    <p class="text-gray-300">26It has completeness <span class="math">1 - \\epsilon</span> if the following holds with probability <span class="math">1 - \\epsilon</span>.</p>

    <p class="text-gray-300">40</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>At time <span class="math">0</span>, the delegator <span class="math">\\mathsf{D}</span>, on input <span class="math">(1^{k},N)</span>, generates her secret state <span class="math">\\sigma_{0}</span>.</li>

      <li>At each time <span class="math">t\\in[N]</span>, <span class="math">\\mathsf{W}^{<em>}</span> chooses a data item <span class="math">x^{t}\\in\\{0,1\\}</span> and sends it to <span class="math">\\mathsf{D}</span>, who then updates her secret state to <span class="math">\\sigma_{t}</span>. Furthermore, <span class="math">\\mathsf{W}^{</em>}</span> may choose a function <span class="math">f:\\{0,1\\}^{t}\\to\\{0,1\\}\\in\\mathcal{F}</span> and run with <span class="math">\\mathsf{D}</span> the delegation protocol <span class="math">\\langle\\mathsf{D},\\mathsf{W}^{*}\\rangle</span> on input <span class="math">(f,t)</span>.</li>

    </ol>

    <p class="text-gray-300">At the end of each delegation protocol, <span class="math">\\mathsf{W}^{*}</span> learns whether <span class="math">\\mathsf{D}</span> accepts or rejects.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{W}^{*}</span> may terminate the game at any time <span class="math">t\\in[N]</span>.</li>

    </ol>

    <p class="text-gray-300"><span class="math">\\mathsf{W}^{<em>}</span> succeeds in the game <span class="math">\\mathsf{G}^{\\mathsf{W}^{</em>}}(k,N)</span> if there exists a time <span class="math">t</span> such that <span class="math">\\mathsf{W}^{*}</span> chooses to run the delegation protocol on input <span class="math">(f,t)</span> for some function <span class="math">f\\in\\mathcal{F}</span>, and convinces <span class="math">\\mathsf{D}</span> to accept a wrong value <span class="math">y\\neq f(x^{t})</span>.</p>

    <h6 id="sec-53" class="text-base font-medium mt-4">Definition 38 (Soundness)</h6>

    <p class="text-gray-300">Let <span class="math">k</span> be a security parameter, and <span class="math">\\mathcal{F}</span> a (boolean) function class that is poly-time computable. A delegation scheme <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> has soundness error <span class="math">\\varepsilon</span> if for every worker strategy <span class="math">\\mathsf{W}^{*}</span> with runtime <span class="math">\\mathrm{poly}(N)</span>, where <span class="math">N=N(k)</span>,</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mathsf{W}^{<em>}\\text{ succeeds in }\\mathsf{G}^{\\mathsf{W}^{</em>}}(k)]\\leq\\varepsilon(N),</span></p>

    <p class="text-gray-300">where <span class="math">\\mathsf{G}^{\\mathsf{W}^{*}}(k)</span> is the security game corresponding to <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span>, as defined above. We say that <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> is sound if it has a negligible soundness error in the parameter <span class="math">N</span>.</p>

    <p class="text-gray-300">Remark. Note that in the above definition, we refer to <span class="math">k</span> as the security parameter, but require the soundness to hold against any <span class="math">\\mathrm{poly}(N)</span>-time adversaries as opposed to standard <span class="math">\\mathrm{poly}(k)</span>-time adversaries. This is because the honest worker needs to run in time <span class="math">\\mathrm{poly}(N)</span> even to evaluate the delegation function <span class="math">f</span>. One should think of <span class="math">k</span> as the security parameter of the cryptographic primitives used by <span class="math">\\mathsf{D}</span> in the delegation scheme, where the primitives are required to be secure against <span class="math">\\mathrm{poly}(N)</span>-time adversaries.</p>

    <p class="text-gray-300">Typically, one may assume that <span class="math">k</span> and <span class="math">N</span> are polynomially related. However, in the context of streaming algorithms, it is common to think of the data stream as having length super-polynomial in the computational resource of the streaming algorithms. For example, the space complexity of a streaming algorithm is typically limited to <span class="math">\\mathrm{polylog}(N)</span>, which usually implies the process time per data item is also <span class="math">\\mathrm{polylog}(N)</span>. We note that a stronger security assumption on the cryptographic primitives is necessary when the data stream is of length super-polynomial in the computational power of the delegator.</p>

    <p class="text-gray-300">Remark. Note that, as in the memory delegation model, in the soundness definition, we allow the adversary <span class="math">\\mathsf{W}^{<em>}</span> to learn the decision bit of the delegator <span class="math">\\mathsf{D}</span> after each execution of the delegation protocol. This is in contrast to the two delegation schemes of </em>[x10, x7]<em>, which are sound only if the adversary <span class="math">\\mathsf{W}^{</em>}</span> does not learn the decision bit of the delegator <span class="math">\\mathsf{D}</span>.</p>

    <p class="text-gray-300">We stress that our streaming delegation scheme (in Section 9) has the property that the state of the delegator must be secret, in order to ensure soundness. The only other delegation schemes that we are aware of which have this property, are <em>[x10, x7]</em>. However, these schemes are sound only if the adversary <span class="math">\\mathsf{W}^{*}</span> does not learn the decision bit of the delegator <span class="math">\\mathsf{D}</span>. The reason</p>

    <p class="text-gray-300">why in these schemes the decision bit needs to be kept secret is that the delegator uses her secret state to verify the worker’s answer, and thus, her decision bit can potentially reveal one bit of information about her secret state. Indeed, in both schemes of <em>[x10, x12]</em>, if D’s decision bits are revealed, then there are known attacks to learn the secret state of D bit by bit and break the soundness of the schemes.</p>

    <p class="text-gray-300">We didn’t have to deal with this issue in our memory delegation scheme mDel, since the state of the delegator in mDel is not secret. In contrast, the delegator of our streaming delegation scheme constructed in Section 9 does hold a secret state, and handling this reusability issue is one of the main technical challenges of this work. It is for this reason that we need all the machinery that was developed in Section 4.</p>

    <p class="text-gray-300">In what follows we define the notion of one-time soundness. The reason we need this definition, is that our soundness proof (for our streaming delegation scheme in Section 9), consists of two parts: We first prove that our scheme has one-time soundness, i.e., it is sound assuming the delegation protocol is executed only once. Then, we argue that the one-time soundness implies reusable soundness.</p>

    <h6 id="sec-54" class="text-base font-medium mt-4">Definition 39 (One-time Soundness)</h6>

    <p class="text-gray-300">Let <span class="math">k</span> be a security parameter and let <span class="math">N</span> be a parameter. Let <span class="math">\\mathcal{F}</span> be a function class and let <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> be a delegation scheme for <span class="math">\\mathcal{F}</span>. The corresponding one-time streaming security game <span class="math">\\mathsf{G}^{\\mathsf{W}^{<em>}}_{1}(k,N)</span> played by an (adversarial) worker <span class="math">\\mathsf{W}^{</em>}</span> is defined the same as <span class="math">\\mathsf{G}^{\\mathsf{W}^{<em>}}(k,N)</span>, except that the game is terminated after the first execution of the delegation protocol <span class="math">\\langle\\mathsf{D},\\mathsf{W}^{</em>}\\rangle</span>.</p>

    <p class="text-gray-300">We say that <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> has one-time soundness error <span class="math">\\varepsilon</span> if for every worker strategy <span class="math">\\mathsf{W}^{*}</span> with runtime <span class="math">\\mathrm{poly}(N)</span>, where <span class="math">N=N(k)</span>,</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mathsf{W}^{<em>}\\text{ succeeds in }\\mathsf{G}^{\\mathsf{W}^{</em>}}_{1}(k,N)]\\leq\\varepsilon(N).</span></p>

    <p class="text-gray-300"><span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> is one-time sound if it has a negligible one-time soundness error (in parameter <span class="math">N</span>).</p>

    <p class="text-gray-300">We proceed to state our main theorem for streaming delegation.</p>

    <h6 id="sec-55" class="text-base font-medium mt-4">Theorem 40 (Streaming Delegation)</h6>

    <p class="text-gray-300">Let <span class="math">k</span> be a security parameter, and let <span class="math">N</span> be a parameter. Let <span class="math">\\mathcal{F}</span> be the class of all <span class="math">\\mathcal{L}</span>-uniform poly-size boolean circuits. Assume the existence of a fully-homomorphic encryption scheme secure against <span class="math">\\mathrm{poly}(N)</span>-size adversaries. Then there exists a non-interactive (2-message) streaming delegation scheme <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> for <span class="math">\\mathcal{F}</span> with the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> has perfect completeness and negligible soundness error.</li>

      <li>D updates her secret state in time <span class="math">\\mathrm{polylog}(N)</span>, per data item.</li>

      <li>In the delegation protocol, when delegating a function <span class="math">f\\in\\mathcal{F}</span> computable by an <span class="math">\\mathcal{L}</span>-uniform circuit of size <span class="math">S</span> and depth <span class="math">d</span>, the delegator D runs in time <span class="math">\\mathrm{poly}(k,d,\\log N)</span>, and the worker W runs in time <span class="math">\\mathrm{poly}(k,S,\\log N)</span>.</li>

    </ul>

    <p class="text-gray-300">In particular, assuming the existence of a fully-homomorphic encryption scheme secure against adversaries of size <span class="math">\\mathrm{poly}(N)</span>, we obtain a streaming delegation scheme for <span class="math">\\mathcal{L}</span>-uniform NC computations, where the delegator D runs in time poly-logarithmic in the length of data stream.</p>

    <p class="text-gray-300">We proceed to present our streaming delegation scheme in the next section.</p>

    <p class="text-gray-300">9 Streaming Delegation Scheme</p>

    <p class="text-gray-300">In this section, we prove Theorem 40, by constructing a non-interactive streaming delegation scheme with the desired properties.</p>

    <h3 id="sec-56" class="text-xl font-semibold mt-8">9.1 Overview of our Streaming Delegation Scheme</h3>

    <p class="text-gray-300">Our streaming delegation scheme is similar to our memory delegation scheme mDel, presented in Section 7, and the main difference is in the way the certificate is generated and updated, and in the Reveal protocol of the Compute operation.</p>

    <h4 id="sec-57" class="text-lg font-semibold mt-6">Generating and updating the certificate.</h4>

    <p class="text-gray-300">Recall that in the memory delegation scheme, the certificate of the delegator D consists of a tree-commitment of the low-degree extension of her memory <span class="math">x</span>. Namely, her certificate is <span class="math">(h,T_{h}(\\mathrm{LDE}_{x}))</span>, where <span class="math">h</span> is a collision resistant hash function. Note that this certificate cannot be updated in a streaming manner, since any change to <span class="math">x</span> changes the low-degree extension <span class="math">\\mathrm{LDE}_{x}</span> almost everywhere.</p>

    <p class="text-gray-300">Instead, in the streaming setting, we replace the tree commitment with an “<em>algebraic commitment</em>”, which has the property that it can be updated efficiently when new data items arrive. The resulting certificate is a random point in the low-degree extension of the stream <span class="math">x</span>; i.e., <span class="math">(z,\\mathrm{LDE}_{x}(z))</span> for a random point <span class="math">z</span>. Proposition 6 implies that this certificate is efficiently updatable,if we assume some upper-bound <span class="math">N</span> on the size of the stream, and we take parameters <span class="math">\\mathbb{H},\\mathbb{F},m</span> such that <span class="math">\\mathbb{H}^{m}=\\theta(N)</span>. The parameters we take are</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\mathrm{polylog}(N),\\ m=\\theta\\left(\\frac{\\log N}{\\log\\log N}\\right),\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">).$ (8)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-58" class="text-lg font-semibold mt-6">The Compute operation.</h4>

    <p class="text-gray-300">The Compute operation of our streaming delegation scheme is very similar to the Compute operation of the memory delegation scheme mDel, and the main distinction is in the Reveal protocol. Namely, in <span class="math">\\mathsf{Compute}(f)</span> the delegator and worker run <span class="math">\\mathrm{GKR}^{(u)}(f)</span>, which is the <span class="math">u</span>-fold parallel repetition of <span class="math">\\mathrm{GKR}(f)</span> (the parallel repetition is in order to get negligible soundness). In order to verify correctness, the delegator needs to verify the value of <span class="math">\\mathrm{LDE}_{x}(r_{i})</span> for random <span class="math">r_{1},\\ldots,r_{u}</span>. Recall that this low-degree extension is w.r.t. the parameters <span class="math">\\mathbb{H}^{\\prime},\\mathbb{F}^{\\prime},m^{\\prime}</span> given in Theorem 8. Namely,</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\theta(d\\cdot\\log n),\\ m^{\\prime}=\\theta\\left(\\frac{\\log n}{\\log d}\\right),\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">).$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where <span class="math">d</span> is the depth of the circuit computing <span class="math">f</span>, and <span class="math">n</span> is the input length (i.e., the current size of the stream). Also, recall that the certificate of the delegator is of the form <span class="math">(z,\\mathrm{LDE}_{x}(z))</span>, where here the low-degree extension is w.r.t. the parameters <span class="math">\\mathbb{H},\\mathbb{F},m</span> as in Equation (8).</p>

    <p class="text-gray-300">In the memory delegation scheme we overcome this gap by delegating the computation of the functions <span class="math">g_{r_{i}}</span>, which are defined by</p>

    <p class="text-gray-300"><span class="math">g_{r_{i}}(x)\\triangleq\\mathrm{LDE}_{x}^{\\mathbb{F}^{\\prime},\\mathbb{H}^{\\prime},m^{\\prime}}(r_{i}),</span></p>

    <p class="text-gray-300">using <span class="math">\\mathrm{GKR}^{(u)}</span> with respect to <span class="math">(\\mathbb{H},\\mathbb{F},m)</span>. In order to verify the correctness of these <span class="math">u</span> protocols, the delegator needs to verify <span class="math">u^{2}</span> values <span class="math">\\mathrm{LDE}_{x}^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span>, where each <span class="math">z_{i,j}</span> is a random value in <span class="math">\\mathbb{F}^{m}</span>.</p>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">Remark.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In our setting this approach is too costly since the running time of the worker <span class="math">\\mathsf{W}</span> during the delegation protocols of <span class="math">g_{r_{i}}</span> is polynomial in <span class="math">N</span> (where <span class="math">N</span> is an upper bound on the stream size), as opposed to polynomial in <span class="math">n</span>, which is the actual stream size (see Theorem 8). However, it turns out that with a slight modification, we can ensure that <span class="math">\\mathsf{W}</span> runs in time <span class="math">\\mathrm{poly}(k,n,\\log N)</span> during these delegation protocols, where <span class="math">k</span> is the security parameter. The idea is the following: Let <span class="math">m^{\\prime\\prime}=\\lceil\\frac{\\log n}{\\log\\log N}\\rceil</span> so that $n\\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{m^{\\prime\\prime}}\\leq n\\cdot\\mathrm{polylog}(N)<span class="math">. The delegator will delegate the functions </span>g_{r_{i}}(x_{i})<span class="math"> by running </span>\\mathrm{GKR}^{(u)}<span class="math"> with respect to </span>(\\mathbb{H},\\mathbb{F},m^{\\prime\\prime})<span class="math">. Note that the runtime of </span>\\mathsf{W}<span class="math"> during these protocols is </span>\\mathrm{poly}(n,k,\\log N)<span class="math">, as desired. At the end of these protocols the delegator needs to verify </span>u^{2}<span class="math"> values </span>\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m^{\\prime\\prime}}_{x}(z^{\\prime\\prime}_{i,j})<span class="math">, where each </span>z^{\\prime\\prime}_{i,j}<span class="math"> is a random value in </span>\\mathbb{F}^{m^{\\prime\\prime}}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We next argue that for every <span class="math">z^{\\prime\\prime}\\in\\mathbb{F}^{m^{\\prime\\prime}}</span>,</p>

    <p class="text-gray-300"><span class="math">\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m^{\\prime\\prime}}_{x}(z^{\\prime\\prime})=\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m}_{x}(0^{m-m^{\\prime\\prime}},z^{\\prime\\prime}).</span></p>

    <p class="text-gray-300">To this end, recall (from Section 3.3) that</p>

    <p class="text-gray-300"><span class="math">\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m}_{x}(z)=\\sum_{p\\in\\mathbb{H}^{m}}\\tilde{B}(z,p)\\cdot x_{\\alpha(p)}</span> (9)</p>

    <p class="text-gray-300">and similarly</p>

    <p class="text-gray-300"><span class="math">\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m^{\\prime\\prime}}_{x}(z)=\\sum_{p\\in\\mathbb{H}^{m^{\\prime\\prime}}}\\tilde{B}(z,p)\\cdot x_{\\alpha^{\\prime\\prime}(p)}</span></p>

    <p class="text-gray-300">where for every <span class="math">z\\in\\mathbb{H}^{m}</span> (or <span class="math">z\\in\\mathbb{H}^{m^{\\prime\\prime}}</span> respectively) it holds that <span class="math">\\tilde{B}(z,p)=1</span> if <span class="math">z=p</span>, and <span class="math">\\tilde{B}(z,p)=0</span> otherwise. The functions <span class="math">\\alpha:\\mathbb{H}^{m}\\to\\{0,1,\\ldots,N-1\\}</span> and <span class="math">\\alpha^{\\prime\\prime}:\\mathbb{H}^{m^{\\prime\\prime}}\\to\\{0,1,\\ldots,n-1\\}</span> are the lexicographic order, and thus for every <span class="math">p\\in\\mathbb{H}^{m^{\\prime\\prime}}</span> it holds that <span class="math">\\alpha^{\\prime\\prime}(p)=\\alpha(0^{m-m^{\\prime\\prime}},p)</span>. Therefore, for every <span class="math">x\\in\\{0,1\\}^{n}</span> and for every <span class="math">z\\in\\mathbb{H}^{m^{\\prime\\prime}}</span>,</p>

    <p class="text-gray-300"><span class="math">\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m}_{x}(0^{m-m^{\\prime\\prime}},z)=\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m^{\\prime\\prime}}_{x}(z).</span> (10)</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">This, together with the Schwartz-Zippel lemma, and with the fact that both <span class="math">\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m}_{x}</span> and <span class="math">\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m^{\\prime\\prime}}_{x}</span> are polynomials of degree at most $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-1<span class="math"> in each variable, implies that for every </span>z\\in\\mathbb{F}^{m^{\\prime\\prime}}$ it holds that</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m}_{x}(0^{m-m^{\\prime\\prime}},z)=\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m^{\\prime\\prime}}_{x}(z).</span></p>

    <p class="text-gray-300">Therefore, it remains to verify the values of <span class="math">\\mathrm{LDE}^{\\mathbb{F},\\mathbb{H},m}_{x}(z_{i,j})</span>, where <span class="math">z_{i,j}\\triangleq(0^{m-m^{\\prime\\prime}},z^{\\prime\\prime}_{i,j})</span>. In the memory delegation scheme this was done using the <span class="math">\\mathrm{Reveal}(z_{i,j})</span> protocol where the worker reveals the augmented path of the leaf <span class="math">z_{i,j}</span> in the Merkle tree-commitment of <span class="math">\\mathrm{LDE}_{x}</span>. Here the Reveal protocol needs to be totally different, since the delegator cannot compute the tree-commitment of <span class="math">\\mathrm{LDE}_{x}</span>.</p>

    <p class="text-gray-300">Unfortunately, unlike in the memory delegation scheme, in the streaming setting constructing a <em>reusable</em> and <em>sound</em> reveal protocol is highly non-trivial.</p>

    <h4 id="sec-59" class="text-lg font-semibold mt-6">The Reveal protocol.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Our starting point is a basic reveal protocol <span class="math">\\mathrm{Reveal}_{1}</span> described in Figure 4. Note that the soundness of <span class="math">\\mathrm{Reveal}_{1}</span> relies on the secrecy of the certificate <span class="math">\\sigma</span>. Namely, assuming that <span class="math">\\mathsf{W}</span> does not know the point <span class="math">z</span>, it is not hard to see, by Schwartz-Zippel Lemma, that an adversarial worker can cheat with probability at most $d/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, where </span>d<span class="math"> is the (total) degree of </span>\\mathrm{LDE}_{x}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">However, note that the <span class="math">\\mathrm{Reveal}_{1}</span> protocol is not reusable. Suppose that <span class="math">\\mathsf{D}</span> uses the above reveal protocol to learn the value of <span class="math">\\mathrm{LDE}_{x}</span> on two random points <span class="math">s,s^{\\prime}\\in\\mathbb{F}^{m}</span>. From the two executions, an</p>

    <p class="text-gray-300"><span class="math">\\mathsf{D}</span> stores a <em>secret</em> state <span class="math">\\sigma=(z,\\mathrm{LDE}_{x}(z))</span>, where <span class="math">x\\in\\{0,1\\}^{N}</span> and <span class="math">z</span> is a random point in <span class="math">\\mathbb{F}^{m}</span>, and wants to learn the value of <span class="math">\\mathrm{LDE}_{x}(s)</span> from <span class="math">\\mathsf{W}</span>.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{D}</span> sends to <span class="math">\\mathsf{W}</span> the line <span class="math">\\ell_{sz}</span> that passes through the points <span class="math">s</span> and <span class="math">z</span>. More specifically, <span class="math">D</span> chooses two random points <span class="math">\\alpha_{1},\\alpha_{2}\\leftarrow\\mathbb{F}</span>, and defines <span class="math">\\ell_{s,z}</span> to be the line that satisfies <span class="math">\\ell_{s,z}(\\alpha_{1})=z</span> and <span class="math">\\ell_{s,z}(\\alpha_{2})=s</span>.</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- <span class="math">\\mathsf{W}</span> returns a univariate polynomial <span class="math">p:\\mathbb{F}\\to\\mathbb{F}</span>, which is the polynomial <span class="math">\\mathrm{LDE}_{x}</span> restricted to the line <span class="math">\\ell_{s,z}</span> (i.e., $p=\\mathrm{LDE}_{x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{\\ell_{s,z}}$).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{D}</span> checks whether <span class="math">p(\\alpha_{1})=\\mathrm{LDE}_{x}(z)</span>, and if so accepts the value <span class="math">p(\\alpha_{2})=\\mathrm{LDE}_{x}(s)</span>. Otherwise, she rejects.</li>

    </ul>

    <p class="text-gray-300">Figure 4: Reveal_{1} protocol</p>

    <p class="text-gray-300">adversarial worker <span class="math">\\mathsf{W}^{<em>}</span> receives two lines <span class="math">\\ell_{s,z}</span> and <span class="math">\\ell_{s^{\\prime},z}</span>, and can learn the secret point <span class="math">z</span> by taking the intersection of the two lines. Once <span class="math">\\mathsf{W}^{</em>}</span> learns <span class="math">z</span>, <span class="math">\\mathsf{W}^{<em>}</span> can easily cheat by returning any polynomial <span class="math">p^{</em>}</span> that agrees with <span class="math">\\mathrm{LDE}_{x}</span> only on point <span class="math">z</span> but disagrees on the remaining points.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">As observed by Gennaro <em>et. al.</em> <em>[x10]</em>, a natural way to protect the secret point <span class="math">z</span>, is to run the above Reveal protocol under a fully-homomorphic encryption (FHE) scheme. Namely, <span class="math">\\mathsf{D}</span> generates a pair of keys <span class="math">(\\mathsf{pk},\\mathsf{sk})</span> for a FHE <span class="math">(\\mathrm{Gen},\\mathrm{Enc},\\mathrm{Dec},\\mathrm{Eval})</span>, and sends <span class="math">\\mathsf{pk}</span> and an encrypted line <span class="math">\\hat{\\ell}_{s,z}=\\mathrm{Enc}_{\\mathsf{pk}}(\\ell_{s,z})</span> to <span class="math">\\mathsf{W}</span>, who can compute the polynomial $p=\\mathrm{LDE}_{x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{\\ell}<span class="math"> homomorphically under the encryption. Indeed, by the semantic security of FHE, an adversarial worker </span>\\mathsf{W}^{<em>}<span class="math"> cannot learn any information from </span>\\mathsf{D}<span class="math">’s message </span>\\hat{\\ell}_{s,z}<span class="math">. This indeed makes the protocol reusable provided that </span>\\mathsf{W}^{</em>}<span class="math"> does not learn the decision bits of </span>\\mathsf{D}$, as proved in <em>[x10, x7]</em>.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">However, since the decision bit of <span class="math">\\mathsf{D}</span> can potentially contain one bit information about the secret point <span class="math">z</span>, it is not clear that security holds if <span class="math">\\mathsf{W}^{<em>}</span> learns these decision bits. In fact, for both of the delegation schemes of </em>[x10, x7]*, which use FHE to hide the delegator <span class="math">\\mathsf{D}</span>’s secret state, there are known attacks that learn the whole secret state of <span class="math">\\mathsf{D}</span> bit-by-bit from <span class="math">\\mathsf{D}</span>’s decision bits.</p>

    <p class="text-gray-300">Fortunately, we are able to show that a variant of the Reveal_{1} protocol described in Figure 5 is reusable even if <span class="math">\\mathsf{W}^{<em>}</span> learns the decision bits of <span class="math">\\mathsf{D}</span>. The main difference between Reveal_{1} and Reveal_{2} is that in Reveal_{2}, the delegator <span class="math">\\mathsf{D}</span> uses a random </em>two-dimensional* affine subspace instead of a line, and uses an FHE to mask the entire protocol.</p>

    <p class="text-gray-300">Using our techniques developed in Section 4 (and in particular using Lemma 22), we show in Section 9.3 that no adversarial <span class="math">\\mathsf{W}^{<em>}</span> can learn useful information about the secret point <span class="math">z</span> from the Reveal_{2} protocol. We note that the proof of the above statement is highly non-trivial, and is one of the main technical difficulties in this work. Informally, the proof first uses Lemma 16, which claims that the ciphertext <span class="math">\\hat{S}_{sz}</span> and the decision bit <span class="math">b</span> of <span class="math">\\mathsf{D}</span> (which depend on the strategy of <span class="math">W^{</em>}</span>) do not give too much information about <span class="math">S_{sz}</span> to <span class="math">\\mathsf{W}^{<em>}</span>. In other words, the random subspace <span class="math">S_{s,z}</span> still has high (pseudo-)entropy from the point of view of <span class="math">\\mathsf{W}^{</em>}</span>. Then it uses an <em>information-theoretic</em> argument to argue that a random point <span class="math">z</span> in a sufficiently random (with high entropy) subspace <span class="math">S_{s,z}</span> is <em>statistically close</em> to a random point in <span class="math">\\mathbb{F}^{m}</span>, which implies that <span class="math">\\mathsf{W}^{*}</span> does not learn useful information about <span class="math">z</span>.</p>

    <h4 id="sec-60" class="text-lg font-semibold mt-6">The Field Size.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Recall that by Schwartz-Zippel Lemma, an adversarial worker can cheat with probability at most $d/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, where </span>d<span class="math"> is the (total) degree of </span>\\mathrm{LDE}_{x}$. Recall that in our setting of</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Reveal2 protocol: D stores a secret state  <span class="math">\\sigma = (z, \\mathrm{LDE}_x(z))</span> , where  <span class="math">x \\in \\{0, 1\\}^N</span>  and  <span class="math">z</span>  is a random point in  <span class="math">\\mathbb{F}^m</span> , and wants to learn the value of  <span class="math">\\mathrm{LDE}_x(s)</span>  from W.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>D does the following.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Generate a pair of keys  <span class="math">(\\mathsf{pk},\\mathsf{sk})\\gets \\mathrm{Gen}(1^k)</span>  for a fully homomorphic encryption scheme FHE.</li>

      <li>Choose a random two-dimensional affine subspace  <span class="math">S_{s,z} \\subset \\mathbb{F}^m</span>  that contains the points  <span class="math">s</span>  and  <span class="math">z</span> . More specifically, choose two random points  <span class="math">\\alpha_1, \\alpha_2 \\gets \\mathbb{F}^2</span>  and let  <span class="math">S_{s,z} \\subset \\mathbb{F}^m</span>  be a random two-dimensional affine subspace that satisfies  <span class="math">S_{s,z}(\\alpha_1) = z</span>  and  <span class="math">S_{s,z}(\\alpha_2) = s</span> .</li>

      <li>Send  <span class="math">\\hat{S}_{s,z} \\gets \\operatorname{Enc}_{\\mathsf{pk}}(S_{s,z})</span>  and  <span class="math">\\mathsf{pk}</span>  to  <span class="math">\\mathsf{W}</span> .</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- W homomorphically computes the two-variate polynomial  $p = \\mathrm{LDE}_x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{S_{s,z}}<span class="math">  under the FHE (denote the resulting ciphertext  </span>\\hat{p}<span class="math"> ), and sends  </span>\\hat{p}$  to D.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>D decrypts and checks whether  <span class="math">p(\\alpha_1) = \\mathrm{LDE}_x(z)</span> , and if so accepts the value  <span class="math">p(\\alpha_2) = \\mathrm{LDE}_x(s)</span> .</li>

    </ul>

    <p class="text-gray-300">Figure 5: Protocol Reveal2</p>

    <p class="text-gray-300">parameters:</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\operatorname {p o l y l o g} (N), m = O \\left(\\frac {\\log N}{\\log \\log N}\\right),</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\operatorname {p o l y} (</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Thus, a cheating worker can cheat with probability  $d /</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= O(1 / \\mathrm{polylog}(N))$ , which is not low enough.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The idea is to reduce the cheating probability to negligible by simply increasing the field size to be super-polynomial. However, we cannot increase the field size in the GKR protocol, since it will increase the complexity of the worker. Instead, we use an extension field  <span class="math">\\tilde{\\mathbb{F}}</span>  of  <span class="math">\\mathbb{F}</span> , of superpolynomial size, only in the certificate and the Reveal protocol, but run the GKR protocols as before. Namely, the secret state is  <span class="math">\\sigma = (z,\\mathrm{LDE}^{\\tilde{\\mathbb{F}},\\mathbb{H},m}(z))</span>  where  <span class="math">z\\gets \\tilde{\\mathbb{F}}^m</span> , The GKR protocols are run exactly as before (one  <span class="math">\\mathrm{GKR}^{(u)}</span>  protocol with the parameters  <span class="math">(\\mathbb{H}&#x27;,\\mathbb{F}&#x27;,m&#x27;)</span> , and  <span class="math">u</span> <span class="math">\\mathrm{GKR}^{(u)}</span>  protocols with the parameters  <span class="math">(\\mathbb{H},\\mathbb{F},m&#x27;&#x27;)</span> ). In the Reveal protocol, the worker reveals to a point  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(s)</span>  as follows: The delegator sends an encryption of a random two-dimensional subspace  <span class="math">S_{s,z}\\subset \\tilde{\\mathbb{F}}^m</span> , containing the points  <span class="math">s</span>  and  <span class="math">z</span> , and the worker sends an encryption of  $\\mathrm{LDE}_x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{S_{s,z}}<span class="math"> . The delegator verifies correctness exactly as in  </span>\\mathrm{Reveal}_2$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Reveal Multiple Points in Parallel. Finally, recall that in memory delegation, the reveal protocol is executed in parallel  <span class="math">u^2</span>  times to reveal  <span class="math">u^2</span>  random points  <span class="math">z_{i,j}</span> . However, if all reveal protocols use the same algebraic commitment  <span class="math">(z, \\mathrm{LDE}_x(z))</span> , then proving that  <span class="math">z</span>  remains secret after  <span class="math">\\mathsf{W}^*</span>  learns the decision bits of  <span class="math">\\mathsf{D}</span>  becomes somewhat tricky.[28] Instead, we could use  <span class="math">u^2</span>  independent commitments, one for each copy of the Reveal protocol. However, it blows up the size of  <span class="math">\\mathsf{D}</span> 's secret state as well as her runtime during the update procedure. It also makes the analysis somewhat more complicated.</p>

    <p class="text-gray-300">28We can make it work, but the analysis becomes more complicated. We decide to avoid this unnecessary complication.</p>

    <p class="text-gray-300">Therefore, instead of running multiple copies of the Reveal protocol in parallel, we use a classic “many-to-one” reduction to reduce the number of points to a single point, so that <span class="math">\\mathsf{D}</span> only needs to run a single copy of the Reveal protocol. Briefly, the idea is to let <span class="math">\\mathsf{D}</span> choose a random degree-<span class="math">u^2</span> curve <span class="math">\\ell</span>, passing through <span class="math">z_{i,j} \\in \\mathbb{F}^m</span> for <span class="math">i,j \\in [u]</span> and passing through an additional random point <span class="math">s \\gets \\tilde{\\mathbb{F}}^m</span>, and send <span class="math">\\ell</span> to <span class="math">\\mathsf{W}</span>. More specifically, <span class="math">\\mathsf{D}</span> will choose <span class="math">u^2 + 1</span> random points <span class="math">\\alpha_0, \\alpha_{i,j} \\gets \\tilde{\\mathbb{F}}</span> for <span class="math">i,j \\in [u]</span>, and let <span class="math">\\ell</span> be the <span class="math">u^2</span>-degree polynomial such that <span class="math">\\ell(\\alpha_0) = s</span> and <span class="math">\\ell(\\alpha_{i,j}) = z_{i,j}</span> for every <span class="math">i,j \\in [u]</span>. The worker <span class="math">\\mathsf{W}</span> returns a univariate polynomial <span class="math">p: \\tilde{\\mathbb{F}} \\to \\tilde{\\mathbb{F}}</span>, which is supposed to be <span class="math">\\mathrm{LDE}_x</span> restricted on the line <span class="math">\\ell</span>. If <span class="math">\\mathsf{W}</span> is honest, then <span class="math">\\mathsf{D}</span> learns the values <span class="math">\\mathrm{LDE}_x(z_{i,j}) = p(\\alpha_{i,j})</span> for <span class="math">i,j \\in [u]</span>, as desired. To verify that <span class="math">\\mathsf{W}</span> was indeed honest, <span class="math">\\mathsf{D}</span> and <span class="math">\\mathsf{W}</span> run the Reveal protocol on the point <span class="math">s</span>, to reveal to <span class="math">\\mathrm{LDE}_x(s)</span>, and <span class="math">\\mathsf{D}</span> checks whether indeed <span class="math">p(\\alpha_0) = \\mathrm{LDE}_x(s)</span>.</p>

    <p class="text-gray-300">To summarize, our <span class="math">\\mathsf{Compute}(f)</span> protocol runs the above many-to-one protocol and the Reveal protocol, in parallel, in order to reveal to <span class="math">\\{\\mathrm{LDE}_x(z_{i,j})\\}_{i,j\\in [u]}</span>.</p>

    <h2 id="sec-61" class="text-2xl font-bold">9.2 Formal Description of Our Streaming Delegation Scheme</h2>

    <p class="text-gray-300">In this section, we give a formal description of our streaming delegation scheme for delegating <span class="math">\\mathcal{L}</span>-uniform depth-<span class="math">d</span> circuits. Our construction uses the following building blocks</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>A fully homomorphic encryption scheme <span class="math">\\mathbf{E} = (\\mathrm{Gen}, \\mathrm{Enc}, \\mathrm{Dec}, \\mathrm{Eval})</span> where the semantic security holds against <span class="math">\\mathrm{poly}(N)</span>-time adversaries (with negligible advantage in <span class="math">N</span>).</li>

      <li>The delegation scheme <span class="math">\\mathrm{GKR} = \\langle \\mathsf{D}&#x27;, \\mathsf{W}&#x27; \\rangle</span> from [GKR08, KR09] (see Theorem 8 for the properties of this delegation scheme). The main property we use here, is that the delegator can verify proofs by accessing its input <span class="math">x</span> at a single random point in <span class="math">\\mathrm{LDE}_x</span>.</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- <strong>Parameters.</strong> Let <span class="math">k</span> be the security parameter, and let <span class="math">N</span> be an upper bound on the length of the data stream. Let <span class="math">\\mathbb{H}</span> be an extension field of <span class="math">\\mathbb{GF}[2]</span> of size $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\mathrm{polylog}(N)<span class="math">, let </span>m = \\theta \\left( \\frac{\\log N}{\\log \\log N} \\right)<span class="math">, and let </span>\\mathbb{F}<span class="math"> be an extension field of </span>\\mathbb{H}<span class="math"> of size </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\mathrm{poly}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">. Let </span>\\tilde{\\mathbb{F}}<span class="math"> be an extension field of </span>\\mathbb{F}<span class="math"> of size </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\tilde{\\mathbb{F}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= N^{\\log N}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><strong>Generating and updating the secret state.</strong></li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>At the initial time <span class="math">t = 0</span>, the delegator <span class="math">\\mathsf{D}</span> chooses a random point <span class="math">z \\gets \\tilde{\\mathbb{F}}^m</span>, and stores <span class="math">\\sigma_0 = (z, 0)</span> as her secret state.</li>

      <li>At each time <span class="math">t \\in [N]</span>, when a data item <span class="math">x_t \\in \\{0,1\\}</span> arrives, <span class="math">\\mathsf{D}</span> updates her secret state from <span class="math">\\sigma_{t-1} = (z, \\mathrm{LDE}_{x^{t-1}}(z))</span> to <span class="math">\\sigma_t = (z, \\mathrm{LDE}_{x^t}(z))</span>, by using Proposition 6.²⁹ (Recall that <span class="math">x^t = (x_1, \\ldots, x_t)</span> denotes the entire data stream up until time <span class="math">t</span>.)</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><strong>Compute}(f,t).</strong> At any time <span class="math">t \\in [N]</span> when the delegator wants the worker to compute some function <span class="math">f</span>, where <span class="math">f</span> is an <span class="math">\\mathcal{L}</span>-uniform depth-<span class="math">d</span> circuit, they run the following protocols in parallel.</li>

    </ul>

    <p class="text-gray-300">²⁹ More explicitly, the update is done using the following formula.</p>

    <div class="my-4 text-center"><span class="math-block">\\mathrm{LDE}_{x^t}(z) = \\mathrm{LDE}_{x^{t-1}}(z) + x_t \\cdot \\mathrm{LDE} e_t(z),</span></div>

    <p class="text-gray-300">where <span class="math">e_t \\in \\{0,1\\}^N</span> denotes the <span class="math">N</span>-bit string with 1 at the <span class="math">t</span>-th bit, and 0 otherwise. Note that <span class="math">\\mathrm{LDE}_{e_t}(z)</span> can be computed in <span class="math">\\mathrm{polylog}(N)</span> time by interpolation.</p>

    <p class="text-gray-300">47</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run <span class="math">\\mathrm{GKR}^{(u)}</span>, which is the <span class="math">u</span>-fold parallel repetition of the underlying delegation protocol GKR, for delegating the computation of <span class="math">f(x)</span>, where <span class="math">u</span> is any parameter such that <span class="math">1/2^u = \\mathsf{ngl}(N)</span>. If at any time the GKR delegator rejects, the delegator <span class="math">\\mathsf{D}</span> rejects.</li>

    </ol>

    <p class="text-gray-300">Let <span class="math">\\mathbb{F}&#x27;, \\mathbb{H}&#x27;, m&#x27;</span> be the parameters used by <span class="math">\\mathrm{GKR}^{(u)}</span>, and recall that at the end of the protocol, <span class="math">\\mathsf{D}</span> needs to verify the value of <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F}&#x27;, \\mathbb{H}&#x27;, m&#x27;}</span> at <span class="math">u</span> random points <span class="math">r_1, \\ldots, r_u \\in (\\mathbb{F}&#x27;)^{m&#x27;}</span>, i.e. it needs to check whether <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F}&#x27;, \\mathbb{H}&#x27;, m&#x27;}(r_i) = v_i</span> for some values <span class="math">v_i</span>.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For each <span class="math">i \\in [u]</span>, run <span class="math">\\mathrm{GKR}^{(u)}</span> for delegating the computation in <span class="math">g_{r_i}(x^t) \\triangleq \\mathrm{LDE}_{x^t}^{\\mathbb{F}&#x27;, \\mathbb{H}&#x27;, m&#x27;}(r_i)</span>. These <span class="math">\\mathrm{GKR}^{(u)}(g_{r_i})</span> protocols are done with respect to <span class="math">(\\mathbb{H}, \\mathbb{F}, m&#x27;&#x27;)</span>, where <span class="math">m&#x27;&#x27; = \\theta \\left( \\frac{\\log t}{\\log \\log N} \\right)</span>. Moreover, these protocols are masked using a PIR scheme to keep the secrecy of the <span class="math">r_i</span>'s, which is necessary to ensure the soundness of the <span class="math">\\mathrm{GKR}^{(u)}</span> protocol of Step 1.</li>

    </ol>

    <p class="text-gray-300">We note that Steps 1 and 2 above are almost identical to Steps 1 and 2 of the <span class="math">\\mathsf{Compute}(f)</span> operation of our memory delegation scheme, constructed in Section 7.2, and we refer the reader to Section 7.2 for a detailed description of the masked <span class="math">\\mathrm{GKR}^{(u)}(g_{r_i})</span> protocols. If the GKR delegator rejects at any point, then the delegator <span class="math">\\mathsf{D}</span> rejects. Otherwise, in order to verify these protocols, <span class="math">\\mathsf{D}</span> needs to check that <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z_{i,j}^{\\prime \\prime}) = w_{i,j}</span> for <span class="math">u^2</span> random points <span class="math">z_{i,j}^{\\prime \\prime}\\in \\mathbb{F}^{m^{\\prime \\prime}}</span>, and some values <span class="math">w_{i,j}\\in \\mathbb{F}</span>. However, as was argued above (see Equation (10)), <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z_{i,j}^{\\prime \\prime}) = \\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span> where <span class="math">z_{i,j} = (0^{m - m^{\\prime \\prime}},z_{i,j}^{\\prime \\prime})</span>. Thus, <span class="math">\\mathsf{D}</span> needs to check that <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m}(z_{i,j}) = w_{i,j}</span> for <span class="math">u^2</span> points <span class="math">z_{i,j}\\in \\mathbb{F}^m</span>.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run a many-to-one protocol to reduce computing <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span> for <span class="math">u^2</span> points <span class="math">z_{i,j} \\in \\mathbb{F}^m</span>, to computing <span class="math">\\mathrm{LDE}_{x^t}^{\\tilde{\\mathbb{F}},\\mathbb{H},m}(s)</span> for a single random point <span class="math">s \\gets \\tilde{\\mathbb{F}}^m</span>. Note that <span class="math">s</span> is a random point in the extension field <span class="math">\\tilde{\\mathbb{F}}^m</span>, as opposed to <span class="math">\\mathbb{F}^m</span>. As before, the points <span class="math">(z_{i,j})_{i,j \\in [u]}</span> must be kept secret to ensure the soundness of the <span class="math">\\mathrm{GKR}^{(u)}</span> protocols of Step 2. We ensure this secrecy by simply running the protocol under an FHE scheme.</li>

    </ol>

    <p class="text-gray-300">We note that we cannot use a PIR scheme here, since <span class="math">\\tilde{\\mathbb{F}}</span> is of super-poly size, and therefore the use of a PIR scheme will result with the worker running in super-polynomial time. Instead we use an FHE scheme, which keeps both the worker and the delegator efficient. More specifically, the delegator <span class="math">\\mathsf{D}</span> chooses a random <span class="math">s \\gets \\tilde{\\mathbb{F}}^m</span> and computes a canonical representation of the unique degree-<span class="math">u^2</span> curve <span class="math">\\ell_{\\vec{z},s}</span> passing through <span class="math">\\vec{z} = (z_{i,j})_{i,j \\in [u]}</span> and <span class="math">s</span>. Then <span class="math">\\mathsf{D}</span> generates <span class="math">(\\mathsf{pk}_1, \\mathsf{sk}_1) \\gets \\mathrm{Gen}(1^k)</span>, computes <span class="math">\\hat{\\ell}_{\\vec{z},s} = \\mathrm{Enc}_{\\mathsf{pk}_1}(\\ell_{\\vec{z},s})</span>, and sends <span class="math">(\\mathsf{pk}_1, \\hat{\\ell}_{\\vec{z},s})</span> to <span class="math">\\mathsf{W}</span>. The worker <span class="math">\\mathsf{W}</span> computes, homomorphically under encryption, a univariate polynomial <span class="math">p_1 \\triangleq \\mathrm{LDE}_{x^t}^{\\tilde{\\mathbb{F}},\\mathbb{H},m} \\circ \\ell_{\\vec{z},s}</span>, and returns the resulting ciphertext <span class="math">\\hat{p}_1</span> to <span class="math">\\mathsf{D}</span>, who decrypts to obtain the polynomial <span class="math">p_1</span>.</p>

    <p class="text-gray-300">Let <span class="math">\\alpha_0, \\alpha_{i,j} \\in \\tilde{\\mathbb{F}}</span> for <span class="math">i,j \\in [u]</span> be such that <span class="math">\\ell_{\\vec{z},s}(\\alpha_0) = s</span> and <span class="math">\\ell_{\\vec{z},s}(\\alpha_{i,j}) = z_{i,j}</span>. <span class="math">\\mathsf{D}</span> checks whether <span class="math">w_{i,j} = p_1(\\alpha_{i,j})</span> (which are supposed to be <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span>). If not, she rejects.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In order to verify that indeed <span class="math">p_1 = \\mathrm{LDE}_{x^t}^{\\tilde{\\mathbb{F}},\\mathbb{H},m} \\circ \\ell_{\\vec{z},s}</span>, the delegator <span class="math">\\mathsf{D}</span> checks whether <span class="math">\\mathrm{LDE}_{x^t}^{\\tilde{\\mathbb{F}},\\mathbb{H},m}(s) = p_1(\\alpha_0)</span>, using the Reveal protocol described in Figure 6, and using its certificate <span class="math">\\sigma_t = (z, \\mathrm{LDE}_{x^t}^{\\tilde{\\mathbb{F}},\\mathbb{H},m}(z))</span>.</li>

    </ol>

    <p class="text-gray-300">30Recall that since computing <span class="math">g_{r_i}(\\cdot)</span> can be done by a polylog(N)-depth poly-size circuit, this setting of parameters works for <span class="math">\\mathrm{GKR}^{(u)}</span>.</p>

    <p class="text-gray-300">31We mention that, we can also mask the <span class="math">\\mathrm{GKR}^{(u)}</span> protocol using an FHE scheme, as opposed to a polylog PIR scheme, which is what we do in Step 3.</p>

    <p class="text-gray-300">48</p>

    <p class="text-gray-300">Note that in the Reveal protocol, we are specific about the representation of the random affine space <span class="math">S_{s,z}</span>. This representation will be useful when we apply our main leakage lemma (Lemma 22), established in Section 4, to prove the reusable soundness of sDel in Section 9.3.</p>

    <p class="text-gray-300">If D rejects in the Reveal<span class="math">(s)</span> protocol, or if the accepted <span class="math">p_{2}(\\alpha_{s})</span> is not equal to the claimed value <span class="math">p_{1}(\\alpha_{0})</span>, then D rejects.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The delegator accepts the interaction if and only if she did not reject in any place above.</li>

    </ol>

    <p class="text-gray-300">Note that the first two steps are (almost) the same as that in our memory delegation scheme (Section 7.2). As before, we denote the delegation protocol of Step 1 by</p>

    <p class="text-gray-300"><span class="math">\\text{GKR}^{(u)}=\\langle\\mathsf{W}^{\\prime(u)},\\mathsf{D}^{\\prime(u)}(r_{1},\\ldots,r_{u})\\rangle(f).</span></p>

    <p class="text-gray-300">We denote the masked delegation protocols of Step 2 by</p>

    <p class="text-gray-300"><span class="math">\\text{PIR}\\left(\\langle\\mathsf{W}^{\\prime(u)},\\mathsf{D}^{\\prime(u)}(z_{i,1}^{\\prime\\prime},\\ldots,z_{i,u}^{\\prime\\prime})\\rangle(g_{r_{i}})\\right).</span></p>

    <p class="text-gray-300">We denote the masked many-to-one protocol of Step 3 by <span class="math">u^{2}</span>-to-<span class="math">1(\\vec{z},s)</span> and the reveal protocol of Step 4 by Reveal<span class="math">(s)</span>. Note that the streaming data <span class="math">x^{t}</span> is implicit in all these notations. We summarize the <span class="math">\\mathsf{Compute}(f)</span> protocol in Figure 7.</p>

    <h5 id="sec-62" class="text-base font-semibold mt-4">Remark.</h5>

    <p class="text-gray-300">We note that our streaming delegation scheme can also be used as a memory delegation scheme. Recall that the only component that a memory delegation scheme has, and a streaming delegation scheme does not have, is the Update operation. Also recall that in our memory delegation scheme, the delegator D delegates the update of her state (from <span class="math">(h,T_{h}(x))</span> to <span class="math">(h^{\\prime},T_{h^{\\prime}}(g(x)))</span>) to the worker W. The same idea can be applied to the streaming delegation scheme as well. As mentioned in Section 7.1, our memory delegation scheme has several advantages over the one that could be obtained from our streaming delegation scheme.</p>

    <h3 id="sec-63" class="text-xl font-semibold mt-8">9.3 Proof of Theorem 40.</h3>

    <p class="text-gray-300">In this section, we prove that the construction above satisfies the properties of Theorem 40.</p>

    <p class="text-gray-300">The perfect completeness follows immediately from the completeness of the underlying GKR delegation scheme, the completeness of the FHE scheme, and the completeness of the Reveal protocol. The fact that the delegator D can update her secret state in time <span class="math">\\text{polylog}(N)</span> follows from Proposition 6. The efficiency guarantees of the Compute protocol follow immediately from the efficiency guarantees of GKR, the efficiency guarantees of the underlying PIR scheme, and the efficiency of the <span class="math">u^{2}</span>-to-<span class="math">1</span> protocol and the Reveal protocol, under FHE.</p>

    <p class="text-gray-300">The main difficulty is in proving soundness. First we observe that the streaming delegation scheme is one-time sound. This proof is very similar to the proof that our memory delegation scheme is one-time sound (Lemma 32). However, it is at all not clear how to reduce one-time soundness to many-time soundness, since the delegator uses the same secret state in all the executions, and each decision bit of the delegator may leak one bit information about this secret state.</p>

    <p class="text-gray-300">Reveal(s):</p>

    <p class="text-gray-300">The delegator  <span class="math">\\mathsf{D}</span>  stores a secret algebraic commitment  <span class="math">\\sigma_{t} = (z, \\mathrm{LDE}_{x^{t}}^{\\widehat{\\mathbb{F}},\\mathbb{H},m}(z))</span>  and wants to learn the value of  <span class="math">\\mathrm{LDE}_{x^{t}}^{\\widehat{\\mathbb{F}},\\mathbb{H},m}(s)</span>  from the worker  <span class="math">\\mathsf{W}</span> , who stores  <span class="math">x \\in \\{0,1\\}^{N}</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>D does the following.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Choose a random two-dimensional affine subspace  <span class="math">S_{s,z} \\subset \\tilde{\\mathbb{F}}^m</span>  that contains the points  <span class="math">s</span>  and  <span class="math">z</span> .</li>

      <li>Let  <span class="math">X = S_{s,z} - s \\triangleq \\{v - s : v \\in S_{s,z}\\}</span> . Namely,  <span class="math">X</span>  is a random two-dimensional subspace that contains the point  <span class="math">z - s</span> .</li>

      <li>Choose a random representation for  <span class="math">X</span> , by choosing two random points  <span class="math">x_{1}, x_{2} \\gets X</span>  and represent  <span class="math">X</span>  as a matrix in  <span class="math">\\tilde{\\mathbb{F}}^{m \\times 2}</span>  where the first column is  <span class="math">x_{1}</span>  and the second column is  <span class="math">x_{2}</span> .</li>

    </ol>

    <p class="text-gray-300">Thus, every point  <span class="math">a \\in S_{s,z}</span>  is represented by  <span class="math">a = X \\cdot \\alpha + s</span>  for some  <span class="math">\\alpha \\in \\tilde{\\mathbb{F}}^2</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Generate a pair of keys  <span class="math">(\\mathsf{pk}_2,\\mathsf{sk}_2)\\gets \\mathrm{Gen}(1^k)</span>  and compute an encryption</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\hat {S} _ {s, z} \\triangleq (\\hat {X}, \\hat {s}) = (\\operatorname {E n c} _ {\\mathsf {p k} _ {2}} (X), \\operatorname {E n c} _ {\\mathsf {p k} _ {2}} (s)).</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Send  <span class="math">(\\mathsf{pk}_2,\\hat{S}_{s,z})</span>  to  <span class="math">\\mathsf{W}</span></li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>W homomorphically computes the two-variate polynomial  <span class="math">p_2 = \\mathrm{LDE}_x \\circ S_{s,z}</span>  under the FHE (denote the resulting ciphertext  <span class="math">\\hat{p}_2</span> ), and sends  <span class="math">\\hat{p}_2</span>  to  <span class="math">\\mathsf{D}</span> .</li>

      <li>D decrypts  <span class="math">\\hat{p}_2</span>  to obtain  <span class="math">p_2</span> . Let  <span class="math">\\alpha_s, \\alpha_z \\in \\tilde{\\mathbb{F}}^2</span>  be such that  <span class="math">S_{s,z}(\\alpha_s) = s</span>  and  <span class="math">S_{s,z}(\\alpha_z) = z</span> . D checks whether  <span class="math">p_2(\\alpha_z) = \\mathrm{LDE}_{x^t}^{\\hat{\\mathbb{F}},\\mathbb{H},m}(z)</span> . If so, D accepts the value  <span class="math">\\mathrm{LDE}_{x^t}^{\\hat{\\mathbb{F}},\\mathbb{H},m}(s) = p_2(\\alpha_s)</span> . Otherwise, D rejects.</li>

    </ul>

    <p class="text-gray-300">Figure 6: Formal description of the Reveal protocol.</p>

    <p class="text-gray-300">Soundness: high-level intuition. Intuitively, we would like to prove that in our construction, the decision bit of the delegator does not reveal any information about her secret state  <span class="math">z</span> , and thus this secret is "reusable", and hence the protocol is many-time sound.</p>

    <p class="text-gray-300">Recall that in our Compute protocol, the delegator  <span class="math">\\mathsf{D}</span>  uses her secret state  <span class="math">z</span>  only in the Reveal protocol, where she sends the worker an encryption of a random two-dimensional affine subspace  <span class="math">S_{s,z}</span>  that contains  <span class="math">z</span> . Intuitively, the idea is to use our main leakage lemma (Lemma 22 in section 4) to argue that in the Reveal protocol, any one-bit leakage about the subspace  <span class="math">S_{s,z}</span>  does not reveal information about  <span class="math">z</span>  (i.e.,  <span class="math">z</span>  looks totally random from the worker's view). While it is indeed true that any bit of leakage about  <span class="math">S_{s,z}</span>  does not reveal any information about  <span class="math">z</span> , note that the decision of the delegator in the Reveal protocol does depend on the actual point  <span class="math">z</span> , and not just on the subspace  <span class="math">S_{s,z}</span>  (as she checks the value of  <span class="math">p_2(\\alpha_z)</span> ).</p>

    <p class="text-gray-300">One way of going around this, is by considering another delegator  <span class="math">\\tilde{D}</span> , which is a "somewhat cautious" delegator, in the sense that she does not check the validity of the polynomial  <span class="math">p_2</span>  at the specific point  <span class="math">\\alpha_z</span> , as this depends on her secret point  <span class="math">z</span> . Instead,  <span class="math">\\tilde{D}</span>  is an inefficient delegator that holds the entire stream  <span class="math">x \\in \\{0,1\\}^t</span> , and checks that  <span class="math">p_2 = \\mathrm{LDE}_x \\circ S_{s,z}</span> . The point is that  <span class="math">\\tilde{D}</span>  does</p>

    <p class="text-gray-300">The delegator  <span class="math">\\mathsf{D}</span>  stores a secret state  <span class="math">\\sigma_{t} = (z,\\mathrm{LDE}_{x}^{\\tilde{\\mathbb{F}},H,m}(z))</span>  and wants to learn the value of  <span class="math">f(x)</span>  from the worker  <span class="math">\\mathsf{W}</span> , who stores  <span class="math">x\\in \\{0,1\\} ^N</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>D and W run  <span class="math">\\mathrm{GKR}^{(u)} = \\langle \\mathsf{W}&#x27;^{(u)},\\mathsf{D}&#x27;^{(u)}(r_1,\\ldots ,r_u)\\rangle (f)</span></li>

    </ol>

    <p class="text-gray-300">(a) If  <span class="math">\\mathsf{D}^{\\prime (u)}</span>  rejects, then the delegator D outputs "reject". (b) At the end of this protocol, the delegator  <span class="math">\\mathsf{D}&#x27;</span>  needs to verify that  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i) = v_i</span>  for some values  <span class="math">v_{i}</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For every  <span class="math">i \\in [u]</span> , run  <span class="math">\\mathrm{PIR}(\\langle \\mathsf{W}&#x27;^{(u)}, \\mathsf{D}&#x27;^{(u)}(z_{i,1}&#x27;&#x27;, \\ldots, z_{i,u}&#x27;&#x27;) \\rangle(g_{r_i}))</span>  with parameters  <span class="math">(\\mathbb{H}, \\mathbb{F}, m&#x27;&#x27;)</span>  where  <span class="math">m&#x27;&#x27; = \\theta \\left( \\frac{\\log t}{\\log \\log N} \\right)</span> .</li>

    </ol>

    <p class="text-gray-300">(a) The delegator  <span class="math">\\mathsf{D}</span>  makes sure that in these protocols the worker still claims that indeed  <span class="math">g_{r_i}(x) = v_i</span> , where  <span class="math">g_{r_i}(x) = \\mathrm{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span> . If this is not the case, then the delegator  <span class="math">\\mathsf{D}</span>  outputs "reject". (b) If at any point  <span class="math">\\mathsf{D}&#x27;</span>  rejects, then the delegator  <span class="math">\\mathsf{D}</span>  outputs "reject". (c) In order to verify these protocols, the delegator  <span class="math">\\mathsf{D}</span>  needs to verify that  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z_{i,j}^{\\prime \\prime}) = w_{i,j}</span>  for some values  <span class="math">w_{i,j}</span> , which is equivalent to verifying that  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j}) = w_{i,j}</span>  where  <span class="math">z_{i,j} = (0^{m - m^{\\prime \\prime}},z_{i,j}^{\\prime \\prime})\\in \\mathbb{F}^{m}</span>  (see Equation (10)).</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run  <span class="math">u^2</span> -to-1( <span class="math">\\vec{z}, s</span> ) where  <span class="math">\\vec{z} = (z_{i,j})</span> .</li>

    </ol>

    <p class="text-gray-300">Recall that in this protocol,  <span class="math">\\mathsf{D}</span>  sends  <span class="math">\\mathsf{W}</span>  a message  <span class="math">(\\mathsf{pk}_1,\\hat{\\ell}_{\\vec{z},s})</span> , where  <span class="math">\\ell_{\\vec{z},s}</span>  is a canonical representation of the  <span class="math">u^2</span> -degree curve that passes through the points  <span class="math">z_{i,j}</span>  and the point  <span class="math">s</span> ; namely,  <span class="math">\\ell_{\\vec{z},s}(\\alpha_{i,j}) = z_{i,j}</span>  and  <span class="math">\\ell_{\\vec{z},s}(\\alpha_0) = s</span> , for some  <span class="math">\\alpha_{i,j},\\alpha_0\\in \\tilde{\\mathbb{F}}</span> . Then,  <span class="math">\\mathsf{W}</span>  sends  <span class="math">\\hat{p}_1</span> , where supposedly,  <span class="math">p_1 = \\mathrm{LDE}_{x^i}^{\\tilde{\\mathbb{F}},\\mathbb{H},m}\\circ \\ell_{\\vec{z},s}</span></p>

    <p class="text-gray-300">The delegator  <span class="math">\\mathsf{D}</span>  verifies that  <span class="math">p_1(\\alpha_{i,j}) = w_{i,j}</span>  for every  <span class="math">i,j\\in [u]</span> . If this is not the case, then the delegator  <span class="math">\\mathsf{D}</span>  outputs "reject".</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The delegator  <span class="math">\\mathsf{D}</span>  verifies that  <span class="math">\\mathrm{LDE}_x^{\\tilde{\\mathbb{F}},\\mathbb{H},m}(s) = p_1(\\alpha_0)</span>  by running  <span class="math">\\operatorname{Reveal}(s)</span> .</li>

    </ol>

    <p class="text-gray-300">If  <span class="math">\\mathsf{D}</span>  rejects in the  <span class="math">\\operatorname{Reveal}(s)</span>  protocol, or if  <span class="math">p_1(\\alpha_0) \\neq p_2(\\alpha_s)</span>  (where  <span class="math">p_2</span>  and  <span class="math">\\alpha_s</span>  are defined in the  <span class="math">\\operatorname{Reveal}(s)</span>  protocol in Figure 6), then  <span class="math">\\mathsf{D}</span>  rejects.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The delegator  <span class="math">\\mathsf{D}</span>  outputs "accept", assuming she didn't output "reject" at any point.</li>

    </ol>

    <p class="text-gray-300">Figure 7: Compute(f)</p>

    <p class="text-gray-300">not use the actual point <span class="math">z</span>, but only the random subspace <span class="math">S_{s,z}</span>.</p>

    <p class="text-gray-300">Now we can try to use our main leakage lemma (Lemma 22) to claim that each execution of <span class="math">\\mathsf{Compute}</span> does not reveal any information about the delegator’s secret state <span class="math">z</span>, and thus she can safely use this secret state again. It still remains to argue that if a cheating worker could cheat when talking to a “somewhat cautious” delegator, then he could also cheat when talking to the real delegator. The idea here is to use the Schwartz-Zippel lemma (with a computationally hidden <span class="math">z</span>).</p>

    <h4 id="sec-65" class="text-lg font-semibold mt-6">Towards our formal proof.</h4>

    <p class="text-gray-300">In our formal proof, we take another route. We define a “cautious” delegator (as opposed to a “somewhat cautious”) to be one that each time uses a fresh new secret state <span class="math">z^{\\prime}</span>. As above, our cautious delegator is inefficient, and has the entire stream <span class="math">x\\in\\{0,1\\}^{t}</span>. The many-time soundness of this cautious scheme follows immediately from its one-time soundness.</p>

    <p class="text-gray-300">Next, we consider a sequence of <span class="math">N</span> hybrid games, <span class="math">\\mathsf{G}_{0},\\ldots,\\mathsf{G}_{N}</span>, where in <span class="math">\\mathsf{G}_{t}</span> the delegator is cautious during the first <span class="math">t</span> <span class="math">\\mathsf{Compute}</span> protocols, and runs the protocol of the original delegator <span class="math">\\mathsf{D}</span> from the <span class="math">t+1</span>’st execution onwards. Note that <span class="math">\\mathsf{G}_{0}</span> is the real soundness game (with the real delegator <span class="math">\\mathsf{D}</span>), as defined in Definition 37, whereas <span class="math">\\mathsf{G}_{N}</span> is the soundness game with the cautious delegator <span class="math">\\tilde{D}</span>. Thus, if there exists a cheating worker <span class="math">W^{<em>}</span> that cheats in the original game <span class="math">\\mathsf{G}_{0}</span>, by a standard hybrid argument, there must exist two games <span class="math">\\mathsf{G}_{t-1}</span> and <span class="math">\\mathsf{G}_{t}</span> where there is a noticeable gap between the success probability of <span class="math">W^{</em>}</span> in <span class="math">\\mathsf{G}_{t-1}</span> and its success probability in <span class="math">\\mathsf{G}_{t}</span>.</p>

    <p class="text-gray-300">The idea is to use this fact to contradict our main leakage lemma (Lemma 22), as follows. Simulate the first <span class="math">t-1</span> <span class="math">\\mathsf{Compute}</span> operations. Note that in both <span class="math">\\mathsf{G}_{t-1}</span> and in <span class="math">\\mathsf{G}_{t}</span> the delegator uses a fresh secret state in these executions. Then, in the <span class="math">t</span>’th <span class="math">\\mathsf{Compute}</span> operation, use the subspace given by the leakage lemma.</p>

    <p class="text-gray-300">Recall that the leakage lemma claims that it is hard to distinguish between <span class="math">(x,\\mathrm{Enc}_{\\mathsf{pk}}(X),\\mathsf{pk},b)</span> and <span class="math">(u,\\mathrm{Enc}_{\\mathsf{pk}}(X),\\mathsf{pk},b)</span>, where <span class="math">x\\leftarrow X</span> and <span class="math">u\\leftarrow\\widehat{\\mathbb{F}}^{m}</span>. So, the idea is to use <span class="math">\\mathsf{pk},\\mathrm{Enc}_{\\mathsf{pk}}(X)</span> in the <span class="math">\\mathrm{Reveal}(s)</span> protocol. Then continue the simulation of the rest of the <span class="math">\\mathsf{Compute}</span> operations using the secret state <span class="math">w+s</span>, where <span class="math">w</span> is either a random element in <span class="math">X</span> or a random element in <span class="math">\\widehat{\\mathbb{F}}^{m}</span>. However, as was noted above, we cannot use the leakage lemma, since the original delegator actually used the secret point to check the validity of the polynomial <span class="math">p_{2}</span> sent by the worker. This, slightly complicates matters.</p>

    <p class="text-gray-300">We define our “cautious” delegator to be <em>really cautious</em>, so that not only does he use a fresh secret state <span class="math">z^{\\prime}</span> for each round, but he also checks the validity of the polynomial <span class="math">p_{2}</span> sent by the worker, by actually checking that <span class="math">p_{2}\\equiv\\mathrm{LDE}_{x}\\circ S_{s,z^{\\prime}}</span> (as opposed to checking its validity at a single point). Then, assuming we have a gap between <span class="math">\\mathsf{G}_{t-1}</span> and <span class="math">\\mathsf{G}_{t}</span>, we consider another hybrid game between these two games, which we denote by <span class="math">\\mathsf{G}^{*}</span>. This game is similar to the game <span class="math">\\mathsf{G}_{t-1}</span>, in the sense that the delegator uses the real secret state <span class="math">z</span> in the <span class="math">t</span>’th round, but it differs from <span class="math">\\mathsf{G}_{t-1}</span> in that it checks the validity of <span class="math">p_{2}</span> by checking that <span class="math">p_{2}=\\mathrm{LDE}_{x}\\circ S_{s,z}</span>.</p>

    <p class="text-gray-300">We use the Schwartz-Zippel lemma to prove that <span class="math">\\mathsf{G}_{t-1}</span> and <span class="math">\\mathsf{G}^{<em>}</span> are statistically indistinguishable, and we use our main leakage lemma (Lemma 22) to prove that <span class="math">\\mathsf{G}^{</em>}</span> and <span class="math">\\mathsf{G}_{t}</span> are computationally indistinguishable. The latter is done by contradiction. If there exists a distinguisher between the games <span class="math">\\mathsf{G}^{*}</span> and <span class="math">\\mathsf{G}_{t}</span>, then we construct a distinguisher that distinguishes between the distributions given the leakage lemma. This is done by simply embedding the input given by the leakage lemma in the <span class="math">t</span>’th round of the Reveal protocol.</p>

    <h6 id="sec-66" class="text-base font-medium mt-4">Remark 41</h6>

    <p class="text-gray-300">We remark that the security reduction is inherently non-uniform, due to the use of the machinery developed in Section 4. Specifically, the proof of Lemma 16 uses the equivalence of HILL and Metric entropy, which only holds in the non-uniform setting. Therefore, the cryptographic</p>

    <p class="text-gray-300">primitives that we rely on need to be secure against non-uniform adversaries. In contrast, the security proof of our memory delegation scheme in Section 7 is uniform.</p>

    <p class="text-gray-300">In what follows we formally define the notion of a cautious delegator (or a cautious streaming delegation scheme), followed by a formal proof of the (reusable) soundness of our streaming delegation scheme.</p>

    <h4 id="sec-67" class="text-lg font-semibold mt-6">Cautious Streaming Delegation Scheme <span class="math">\\mathsf{sDel}=\\langle\\mathsf{W},\\tilde{\\mathsf{D}}\\rangle</span>.</h4>

    <p class="text-gray-300">For the purpose of our analysis, we consider a variant of <span class="math">\\mathsf{sDel}</span>, called <em>cautious streaming delegation scheme</em>, which we denote by <span class="math">\\mathsf{sDel}=\\langle\\mathsf{W},\\tilde{\\mathsf{D}}\\rangle</span>. In <span class="math">\\mathsf{sDel}</span> the worker is exactly the same as the worker in <span class="math">\\mathsf{sDel}</span>, but the delegator is “cautious.”</p>

    <p class="text-gray-300">More specifically, in <span class="math">\\mathsf{sDel}</span>, the delegator <span class="math">\\tilde{\\mathsf{D}}</span>, instead of maintaining a secret state <span class="math">\\sigma_{t}=(z,\\mathrm{LDE}_{x}(z))</span>, she stores the entire data stream <span class="math">x^{t}\\in\\{0,1\\}^{t}</span>. Recall that in the original <span class="math">\\mathsf{sDel}</span> scheme, during the Compute protocol, the delegator uses her secret state <span class="math">\\sigma_{t}</span> only in the Reveal protocol. In <span class="math">\\mathsf{sDel}</span>, the Compute protocol is exactly as in <span class="math">\\mathsf{sDel}</span>, except for the following modification to the Reveal<span class="math">(s)</span> protocol.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\tilde{\\mathsf{D}}</span> generates her message in the same way as <span class="math">\\mathsf{D}</span>, except that <span class="math">\\tilde{\\mathsf{D}}</span> chooses a random two-dimensional affine subspace <span class="math">S_{s}\\subset\\tilde{\\mathbb{F}}^{m}</span> containing <span class="math">s</span>, instead of choosing a random affine space <span class="math">S_{s,z}\\subset\\tilde{\\mathbb{F}}^{m}</span> containing both <span class="math">s</span> and <span class="math">z</span>.</li>

      <li>To verify the polynomial <span class="math">p_{2}</span> returned by <span class="math">\\mathsf{W}</span> (after decryption), <span class="math">\\tilde{\\mathsf{D}}</span> computes <span class="math">\\mathrm{LDE}_{x}\\circ S_{s}</span> on her own and checks if <span class="math">p_{2}=\\mathrm{LDE}_{x}\\circ S_{s}</span>, instead of checking its consistency with <span class="math">\\mathrm{LDE}_{x}\\circ S_{s}</span> on a single point.</li>

    </ul>

    <p class="text-gray-300">In other words, <span class="math">\\tilde{\\mathsf{D}}</span> is doubly-cautious in the Reveal protocol: First, <span class="math">\\tilde{\\mathsf{D}}</span> doesn’t reuse the same secret point <span class="math">z</span>, but rather chooses the affine subspace at random, with the only restriction that it contains <span class="math">s</span>. Second, she checks whether the polynomial <span class="math">p_{2}</span> returned by <span class="math">\\mathsf{W}</span> is correct, instead of only checking if <span class="math">p_{2}</span> is correct on a random point <span class="math">z</span>. Our analysis proceeds in the following two steps.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>We first show, that <span class="math">\\mathsf{sDel}</span> has negligible one-time soundness error, which immediately implies the (reusable) soundness of <span class="math">\\mathsf{sDel}</span>, since these executions are totally independent, as <span class="math">\\tilde{\\mathsf{D}}</span> does not use a secret state.</li>

    </ul>

    <p class="text-gray-300">The proof is very similar to the proof of the one-time soundness of our memory delegation scheme (Lemma 32).</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let <span class="math">\\mathsf{G}</span> and <span class="math">\\tilde{\\mathsf{G}}</span> be the (reusable) security games of <span class="math">\\mathsf{sDel}</span> and <span class="math">\\mathsf{sDel}</span>, respectively. We shall show, that the main-leakage lemma (Lemma 22), together with a hybrid argument, implies that no <span class="math">\\mathrm{poly}(N)</span>-size worker <span class="math">\\mathsf{W}^{*}</span> succeeds with noticeably higher probability in <span class="math">\\mathsf{G}</span> than in <span class="math">\\tilde{\\mathsf{G}}</span>. In other words, there is no need to be cautious!</li>

    </ul>

    <h6 id="sec-68" class="text-base font-medium mt-4">Lemma 42</h6>

    <p class="text-gray-300">The streaming delegation scheme <span class="math">\\mathsf{sDel}</span> constructed in Section 9.2 is one-time sound, i.e., it has negligible one-time soundness error.</p>

    <p class="text-gray-300">The proof of this lemma is essentially the same as the proof of Lemma 32, and is omitted.</p>

    <h6 id="sec-69" class="text-base font-medium mt-4">Lemma 43</h6>

    <p class="text-gray-300">The streaming delegation scheme sDel constructed in Section 9.2 is sound, i.e., it has negligible soundness error.</p>

    <p class="text-gray-300">Proof. Suppose for the sake of contradiction that there exists a poly<span class="math">(N)</span>-size worker <span class="math">\\mathsf{W}^{*}</span> such that</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mathsf{W}^{<em>}\\text{ succeeds in }\\mathsf{G}^{\\mathsf{W}^{</em>}}(k,N)]\\geq\\varepsilon(N),</span> (11)</p>

    <p class="text-gray-300">for some noticeable <span class="math">\\varepsilon(N)</span>. Lemma 42 implies that sD̃el has negligible soundness error. Namely</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mathsf{W}^{<em>}\\text{ succeeds in }\\tilde{\\mathsf{G}}^{\\mathsf{W}^{</em>}}(k,N)]\\leq\\mathsf{ngl}(N).</span> (12)</p>

    <p class="text-gray-300">From Equation (11) and (12), we derive a contradiction to Lemma 22, using the following hybrid argument. Consider the following hybrid games <span class="math">\\mathsf{G}_{t}</span> for every <span class="math">t\\in\\{0,\\ldots,N\\}</span>.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Hybrid Game <span class="math">\\mathsf{G}_{t}</span>: The reusable security game for the streaming delegation scheme with a hybrid delegator <span class="math">\\mathsf{D}_{t}</span>, who is cautious until (and including) time <span class="math">t</span>, and behaves as the original delegator <span class="math">\\mathsf{D}</span> after time <span class="math">t</span>. More precisely, for every time <span class="math">t^{\\prime}\\leq t</span>, the hybrid delegator <span class="math">\\mathsf{D}_{t}</span> stores the whole data stream <span class="math">x_{t^{\\prime}}</span> and behaves as the cautious delegator <span class="math">\\tilde{\\mathsf{D}}</span>. At the beginning of time <span class="math">t+1</span>, the hybrid delegator <span class="math">\\mathsf{D}_{t}</span> generates a secret state <span class="math">\\sigma_{t+1}=(z,\\mathrm{LDE}_{x^{t+1}}(z))</span> by choosing a random <span class="math">z\\leftarrow\\tilde{\\mathbb{F}}^{m}</span> and computing <span class="math">\\mathrm{LDE}_{x^{t+1}}(z)</span>. Then, for every time <span class="math">t^{\\prime}\\geq t+1</span>, the hybrid delegator <span class="math">\\mathsf{D}_{t}</span> behaves as the original delegator <span class="math">\\mathsf{D}</span>.</li>

    </ul>

    <p class="text-gray-300">By definition, the hybrid games <span class="math">\\mathsf{G}_{0}</span> and <span class="math">\\mathsf{G}_{N}</span> are simply <span class="math">\\mathsf{G}</span> and <span class="math">\\tilde{\\mathsf{G}}</span>, respectively. By a standard hybrid argument, Equations (11) and (12) imply that there exists some <span class="math">t\\in[N]</span> such that</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mathsf{W}^{<em>}\\text{ succeeds in }\\mathsf{G}_{t-1}^{\\mathsf{W}^{</em>}}]-\\Pr[\\mathsf{W}^{<em>}\\text{ succeeds in }\\mathsf{G}_{t}^{\\mathsf{W}^{</em>}}]\\geq\\varepsilon/N-\\mathsf{ngl}(N).</span> (13)</p>

    <p class="text-gray-300">Note that the only difference between <span class="math">\\mathsf{G}_{t-1}</span> and <span class="math">\\mathsf{G}_{t}</span> is at time <span class="math">t</span>, where <span class="math">\\mathsf{D}_{t-1}</span> behaves as the original delegator <span class="math">\\mathsf{D}</span>, but <span class="math">\\mathsf{D}_{t}</span> is still cautious. More precisely, at time <span class="math">t</span>, the two delegators behave differently in the Reveal<span class="math">(s)</span> protocol (if executed), as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{D}_{t-1}</span> sends <span class="math">(\\hat{S}_{s,z},\\mathsf{pk})=(\\hat{X},\\hat{s},\\mathsf{pk})</span> to <span class="math">\\mathsf{W}^{<em>}</span>, where <span class="math">S_{s,z}</span> is a random 2-dimensional affine space containing <span class="math">s</span> and <span class="math">z</span>, and <span class="math">X\\in\\tilde{\\mathbb{F}}^{m\\times 2}</span> is a random representation of the two-dimensional subspace <span class="math">S_{s,z}-s\\triangleq\\{v-x:v\\in S_{s,z}\\}</span>. Let <span class="math">\\alpha_{z}\\in\\tilde{\\mathbb{F}}^{2}</span> be such that <span class="math">z=X\\cdot\\alpha_{z}+s</span>. Then <span class="math">\\mathsf{D}_{t-1}</span> checks that <span class="math">p_{2}(\\alpha_{z})=\\mathrm{LDE}_{x^{t}}(z)</span>, where <span class="math">p_{2}</span> is the polynomial sent by <span class="math">\\mathsf{W}^{</em>}</span> (after decryption).</li>

      <li><span class="math">\\mathsf{D}_{t}</span> sends <span class="math">(\\hat{S}_{s},\\mathsf{pk})=(\\hat{X},\\hat{s},\\mathsf{pk})</span> to <span class="math">\\mathsf{W}^{<em>}</span>, where <span class="math">X\\in\\tilde{\\mathbb{F}}^{m\\times 2}</span> is a random two-dimensional subspace, and <span class="math">S=X+s</span>. Then <span class="math">\\mathsf{D}_{t}</span> checks that <span class="math">p_{2}=\\mathrm{LDE}_{x^{t}}\\circ S_{s}</span>, where <span class="math">p_{2}</span> is the polynomial sent by <span class="math">\\mathsf{W}^{</em>}</span> (after decryption).</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Note that <span class="math">\\mathsf{D}_{t-1}</span> continues to use <span class="math">z</span> as her secret state after time <span class="math">t</span>. Also note that in both cases, <span class="math">X\\in\\tilde{\\mathbb{F}}^{m\\times 2}</span> is a random representation of a random 2-dimensional linear subspace, so <span class="math">X</span> is statistically close to a uniformly random <span class="math">m</span>-by-2 matrix (with statistical distance $O(1/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\tilde{\\mathbb{F}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)=\\mathsf{ngl}(N)$).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Looking ahead, we want to use the noticeable gap between the success probability of <span class="math">\\mathsf{W}^{*}</span> in <span class="math">\\mathsf{G}_{t-1}</span> and <span class="math">\\mathsf{G}_{t}</span> (in Equation (13)) to contradict Lemma 22. To this end, we construct a distinguisher <span class="math">\\mathcal{A}</span> that distinguishes distributions <span class="math">(x,\\hat{X},\\mathsf{pk},b)\\leftarrow\\mathcal{D}_{1}</span> and <span class="math">(u,\\hat{X},\\mathsf{pk},b)\\leftarrow\\mathcal{D}_{2}</span>, where</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">X\\leftarrow\\tilde{\\mathbb{F}}^{m\\times 2}</span> is a random <span class="math">m</span>-by-2 matrix.</li>

    </ul>

    <p class="text-gray-300">-</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{pk}</span> is a public key generated by <span class="math">(\\mathsf{pk},\\mathsf{sk}) \\gets \\mathrm{Gen}(1^k)</span>, and <span class="math">\\hat{X} \\gets \\mathrm{Enc}_{\\mathsf{pk}}(X)</span>.</li>

      <li><span class="math">b = L(\\hat{X}, \\mathsf{pk})</span> is a leakage bit, where <span class="math">L: \\{0,1\\}^* \\to \\{0,1\\}</span> is a leakage function, to be specified later.</li>

      <li><span class="math">x \\gets X</span> and <span class="math">u \\gets \\tilde{\\mathbb{F}}^m</span>.</li>

    </ul>

    <p class="text-gray-300">To this end, the distinguisher <span class="math">\\mathcal{A}</span>, upon receiving <span class="math">(w, \\hat{X}, \\mathsf{pk}, b)</span>, distributed according to <span class="math">\\mathcal{D}_1</span> or <span class="math">\\mathcal{D}_2</span>, tries to simulate the game <span class="math">\\mathsf{G}_{t-1}</span> or <span class="math">\\mathsf{G}_t</span>, respectively, by embedding the received distribution <span class="math">(w, \\hat{X}, \\mathsf{pk}, b)</span> in the game. At a high level, we let <span class="math">\\mathcal{A}</span> embed the distribution in the Reveal protocol at time <span class="math">t</span> (if executed), where <span class="math">(\\hat{X}, \\mathsf{pk})</span> is (part of) the delegator's message, and <span class="math">b</span> is the decision bit indicating whether the delegator accepts or rejects in the Reveal protocol. However, note that (the original) <span class="math">\\mathsf{D}</span> and (the cautious) <span class="math">\\hat{\\mathsf{D}}</span> decide whether to accept in the Reveal protocol in a different way, and in particular, <span class="math">\\mathsf{D}</span>'s decision depends on the secret point <span class="math">z</span>.</p>

    <p class="text-gray-300">Therefore, in addition to <span class="math">\\mathsf{G}_{t-1}</span> and <span class="math">\\mathsf{G}_t</span>, we consider an intermediate hybrid game <span class="math">\\mathsf{G}^<em></span>, which is a hybrid of <span class="math">\\mathsf{G}_{t-1}</span> and <span class="math">\\mathsf{G}_t</span>: It is the same as <span class="math">\\mathsf{G}_{t-1}</span> and <span class="math">\\mathsf{G}_t</span> except in the <span class="math">t</span>'th protocol, where the delegator <span class="math">\\mathsf{D}^</em></span> sends the same message as <span class="math">\\mathsf{D}_{t-1}</span> (which is less cautious since she uses <span class="math">z</span>), but decide whether to accept in the same way as <span class="math">\\mathsf{D}_t</span> (which is cautious). Namely,</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{D}^<em></span> sends <span class="math">(\\hat{S}_{s,z}, \\mathsf{pk}) = (\\hat{X}, \\hat{s}, \\mathsf{pk})</span> to <span class="math">\\mathsf{W}^</em></span>, where <span class="math">S_{s,z}</span> is a random 2-dimensional affine space containing <span class="math">s</span> and <span class="math">z</span>, and <span class="math">X \\in \\tilde{\\mathbb{F}}^{m \\times 2}</span> is a random representation of <span class="math">S_{s,z} - s</span>. Then <span class="math">\\mathsf{D}^<em></span> checks the polynomial <span class="math">p_2</span> returned by <span class="math">\\mathsf{W}^</em></span> (after decryption) by checking whether <span class="math">p_2 = \\mathrm{LDE}_{x^t} \\circ S_{s,z}</span>.</li>

    </ul>

    <p class="text-gray-300">Note that both <span class="math">\\mathsf{D}_{t-1}</span> and <span class="math">\\mathsf{D}^*</span> continue to use <span class="math">z</span> in their secret state after time <span class="math">t</span>.</p>

    <p class="text-gray-300">We first argue that the hybrid games <span class="math">\\mathsf{G}_{t-1}</span> and <span class="math">\\mathsf{G}^<em></span> are statistically close. Recall that the only difference between them is in the Reveal(s) protocol at time <span class="math">t</span>, where <span class="math">\\mathsf{D}_{t-1}</span> (resp., <span class="math">\\mathsf{D}^</em></span>) checks the polynomial <span class="math">p_2</span> sent by <span class="math">\\mathsf{W}^<em></span> (after decryption) by checking whether <span class="math">p_2(\\alpha_z) = \\mathrm{LDE}_{x^t}(z)</span> (resp., <span class="math">p_2 = \\mathrm{LDE}_{x^t} \\circ S_{s,z}</span>). Note that <span class="math">\\mathsf{D}_{t-1}</span> and <span class="math">\\mathsf{D}^</em></span>, being cautious before time <span class="math">t</span>, use the (random) point <span class="math">z</span> for the very first time at time <span class="math">t</span>, so we can think of <span class="math">z</span> as being generated from <span class="math">z \\gets S_{s,z}</span> after they send the message <span class="math">(\\hat{S}_{s,z}, \\mathsf{pk})</span>. It follows by the Schwartz-Zipple lemma that</p>

    <p class="text-gray-300">$$ \\begin{array}{l} \\Pr \\left[ \\mathsf{D}_{t-1} \\text{ and } \\mathsf{D}^* \\text{ make a different decision} \\right] \\\\ \\leq \\Pr \\left[ \\left(p_2 \\neq \\mathrm{LDE}_{x^t} \\circ S_{s,z}\\right) \\wedge \\left(p_2(\\alpha_z) = \\mathrm{LDE}_{x^t}(z)\\right) \\right] \\\\</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq O(d /</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\tilde{\\mathbb{F}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">) \\leq \\mathsf{ngl}(N),</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">\\end{array} $$</p>

    <p class="text-gray-300">where <span class="math">d = \\mathrm{polylog}(N)</span> is the total degree of <span class="math">\\mathrm{LDE}_{x^t}</span>. Since this is the only difference between <span class="math">\\mathsf{G}_{t-1}</span> and <span class="math">\\mathsf{G}^*</span>, the statistical distance of the two hybrid is <span class="math">\\mathsf{ngl}(N)</span>.</p>

    <p class="text-gray-300">Now, since <span class="math">\\mathsf{G}_{t-1}</span> and <span class="math">\\mathsf{G}^*</span> are statistically close, Equation (13) implies</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\mathsf{W}^* \\text{ succeeds in } (\\mathsf{G}^*)^{\\mathsf{W}^*} \\right] - \\Pr \\left[ \\mathsf{W}^* \\text{ succeeds in } \\mathsf{G}_t^{\\mathsf{W}^*} \\right] \\geq (\\varepsilon / N) - \\mathsf{ngl}. \\tag{14}</span></div>

    <p class="text-gray-300">This time, we are able to use the noticeable gap between the success probability of <span class="math">\\mathsf{W}^<em></span> in <span class="math">\\mathsf{G}^</em></span> and <span class="math">\\mathsf{G}_t</span> in Equation (14), to contradict Lemma 22.</p>

    <p class="text-gray-300">Let us take a close look at the difference between <span class="math">\\mathsf{G}^<em></span> and <span class="math">\\mathsf{G}_t</span>. Again, the only difference is in the Reveal(s) protocol at time <span class="math">t</span>, where <span class="math">\\mathsf{D}^</em></span> (resp., <span class="math">\\mathsf{D}_t</span>) sends <span class="math">(\\hat{S}_{s,z}, \\mathsf{pk})</span> (resp., <span class="math">(\\hat{S}_s, \\mathsf{pk})</span>) to <span class="math">\\mathsf{W}^*</span>. Note,</p>

    <p class="text-gray-300">34 More precisely, first choosing a random <span class="math">z \\gets \\tilde{\\mathbb{F}}^m</span> and then choosing a random <span class="math">S_{s,z}</span> containing <span class="math">z</span> (and <span class="math">s</span>) is equivalent to first choosing a random <span class="math">S</span> containing <span class="math">s</span>, and then choosing <span class="math">z \\gets S</span>.</p>

    <p class="text-gray-300">55</p>

    <p class="text-gray-300">however, that the distribution of both <span class="math">S_{s,z}</span> and <span class="math">S_{s}</span> are actually the same, both being a random 2-dimensional affine space containing <span class="math">s</span>. The real difference is that, after time <span class="math">t</span>, <span class="math">\\hat{\\mathsf{D}}_{t-1}</span> (resp., <span class="math">\\mathsf{D}_{t}</span>) uses <span class="math">z \\leftarrow S_{s,z}</span> (resp., <span class="math">z \\leftarrow \\hat{\\mathbb{F}}^{m}</span>), in her secret state. Noting that this is exactly the difference between <span class="math">(z, \\hat{X}, \\mathsf{pk}, b) \\leftarrow \\mathcal{D}_{1}</span> and <span class="math">(u, \\hat{X}, \\mathsf{pk}, b) \\leftarrow \\mathcal{D}_{2}</span>, we are ready to define the distinguisher <span class="math">\\mathcal{A}</span>, as follows, from which the choice of leakage bit <span class="math">b = L(\\hat{X}, \\mathsf{pk})</span> would become clear.</p>

    <p class="text-gray-300">On input <span class="math">(w, \\hat{X}, \\mathsf{pk}, b)</span>, distributed either according to <span class="math">\\mathcal{D}_1</span> or according to <span class="math">\\mathcal{D}_2</span>, the distinguisher <span class="math">\\mathcal{A}</span> does the following.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Simulate the interaction between <span class="math">\\mathsf{W}^*</span> and <span class="math">\\hat{\\mathsf{D}}</span> until the end of time <span class="math">t - 1</span>.</li>

      <li>At time <span class="math">t</span>, if there is a Compute execution, then simulate the Compute operation as follows.</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Simulate for both parties all (sub-)protocols except the Reveal(s) protocol. This includes choosing <span class="math">s \\in \\hat{\\mathbb{F}}^m</span>.</li>

      <li>For the Reveal(s) protocol, simulate the delegator's message by <span class="math">(\\hat{X}, \\hat{s}, \\mathsf{pk})</span>, where <span class="math">(\\hat{X}, \\mathsf{pk})</span> is part of its input, and <span class="math">\\hat{s} \\gets \\operatorname{Enc}_{\\mathsf{pk}}(s)</span>. Then simulate <span class="math">\\mathsf{W}^*</span>'s message. Finally, use the bit <span class="math">b</span> (which is part of <span class="math">\\mathcal{A}</span>'s input) as the decision bit of the delegator. (Note that <span class="math">\\mathcal{A}</span> does not have a secret key sk and cannot compute the delegator's decision bit efficiently.)</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Compute <span class="math">\\sigma_t = (w + s, \\mathrm{LDE}_{x^t}(w + s))</span> and continue to simulate the interaction between <span class="math">\\mathsf{W}^*</span> and <span class="math">\\mathsf{D}</span> after time <span class="math">t</span> using <span class="math">\\sigma_t</span> as <span class="math">\\mathsf{D}</span>'s secret state.</li>

      <li>Output 1 if and only if <span class="math">\\mathsf{W}^*</span> ever cheats successfully during the interaction.</li>

    </ol>

    <p class="text-gray-300">We define the leakage function <span class="math">L(\\hat{X}, \\mathsf{pk})</span> to be the decision of <span class="math">\\mathsf{D}^*</span> and <span class="math">\\mathsf{D}_t</span> in the Reveal(s) protocol at time <span class="math">t</span>, if executed, and 0 otherwise. More precisely, let <span class="math">S = X + s</span>; <span class="math">L(\\hat{X}, \\mathsf{pk}) = 1</span> if and only if <span class="math">p_2 = \\mathrm{LDE}_{x^t} \\circ S</span>. Note that <span class="math">L</span> is a randomized function, which uses its randomness to simulate the game until the end of time <span class="math">t</span>, and determine the decision of the delegator in the Reveal(s) protocol. Also note that the secret key sk is missing from <span class="math">(\\hat{X}, \\mathsf{pk}, r)</span>, so <span class="math">L</span> cannot be computed in <span class="math">\\mathrm{poly}(N)</span> time.</p>

    <p class="text-gray-300">Note that when <span class="math">(z, \\hat{X}, \\mathsf{pk}, b) \\gets \\mathcal{D}_1</span>, the distinguisher <span class="math">\\mathcal{A}</span> perfectly simulates <span class="math">\\mathsf{G}^*</span>, and when <span class="math">(u, \\hat{X}, \\mathsf{pk}, b) \\gets \\mathcal{D}_2</span>, the distinguisher <span class="math">A</span> perfectly simulates <span class="math">\\mathsf{G}_t</span>. Therefore, Equation (14) implies</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\mathcal {A} (z, \\hat {X}, \\mathsf {p k}, b) = 1 \\right] - \\Pr \\left[ \\mathcal {A} (u, \\hat {X}, \\mathsf {p k}, b) = 1 \\right] \\geq \\varepsilon / N - \\mathsf {n g l} (N),</span></div>

    <p class="text-gray-300">contradicting Lemma 22. This completes the proof.</p>

    <p class="text-gray-300">In this section, we construct memory and streaming delegation schemes based on universal arguments of Barak and Goldreich [BG02]. This allows the delegator to delegate computation for all of <span class="math">\\mathbf{P}</span> rather than <span class="math">\\mathbf{NC}</span>, at the price that the <span class="math">\\mathsf{Compute}(f)</span> protocol becomes interactive with 4 message exchanges.</p>

    <p class="text-gray-300">Recall that when we constructed our memory and streaming delegation schemes in Sections 7 and 9, the key property we need from the GKR protocol is that the verifier does not need to read the entire input, but rather only needs to access a few random points in the low-degree extension of the input. The main observation is that, the same property also holds for universal</p>

    <p class="text-gray-300">56</p>

    <p class="text-gray-300">arguments, when the underlying PCP is substituted by an efficient PCP of Proximity (PCPP), a notion introduced by Ben-Sasson, Goldreich, Harsha, Sudan, and Vadhan <em>[BSGH^{+}05]</em> and Dinur and Reingold <em>[x10]</em>. (We remark that this observation has been made independently by Cormode, Thaler, and Yi <em>[x15]</em> in the context of “streaming interactive proofs.”) Therefore, we can use universal arguments with PCPP to construct memory and streaming delegation schemes for any (efficient) computation. In fact, the construction becomes simpler. Moreover, for memory delegation, we can avoid the use of poly-log PIR schemes, and only require the existence of collision-resistant hash functions.</p>

    <p class="text-gray-300">Formally, we obtain the following theorems. For the sake of simplicity, we state the theorems for delegating computation of polynomial time Turing machines. The theorems extend readily to non-uniform Turing machines, where the running time of the delegator and the worker in both the offline and the online stage depends polynomially on the length of the non-uniform advice.</p>

    <h6 id="sec-71" class="text-base font-medium mt-4">Theorem 44 (Interactive Memory Delegation)</h6>

    <p class="text-gray-300">Let <span class="math">k</span> be a security parameter, and let <span class="math">\\mathcal{F}</span> be the class of all functions computable by polynomial time Turning machines. Assume the existence of collision-resistance hash functions. Then there exists a memory delegation scheme <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> for <span class="math">\\mathcal{F}</span> with the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The scheme has perfect completeness and negligible (reusable) soundness error.</li>

      <li>The delegator and worker are efficient in the offline stage; i.e., both the delegator and the worker run in time <span class="math">\\mathrm{poly}(k,n)</span>, where <span class="math">n</span> is the size of the memory.</li>

      <li>The worker is efficient in the online stage. More specifically, it runs in time <span class="math">\\mathrm{poly}(k,T(n))</span> during each <span class="math">\\mathsf{Compute}(f)</span> and <span class="math">\\mathsf{Update}(f)</span> operation, where <span class="math">T(n)</span> is a time bound of the delegation function <span class="math">f</span> on inputs of length <span class="math">n</span>. The delegator runs in time <span class="math">\\mathrm{poly}(k,\\log T)</span> during each <span class="math">\\mathsf{Compute}(f)</span> and <span class="math">\\mathsf{Update}(f)</span> operation.</li>

      <li>Both <span class="math">\\mathsf{Compute}(f)</span> and <span class="math">\\mathsf{Update}(f)</span> consist of <span class="math">4</span> message exchanges.</li>

    </ul>

    <h6 id="sec-72" class="text-base font-medium mt-4">Theorem 45 (Interactive Streaming Delegation)</h6>

    <p class="text-gray-300">Let <span class="math">k</span> be a security parameter, and let <span class="math">N</span> be a parameter bounding the maximum length of the stream. Let <span class="math">\\mathcal{F}</span> be the class of all functions computable by polynomial time Turning machines. Assume the existence of a fully-homomorphic encryption scheme secure against <span class="math">\\mathrm{poly}(N)</span>-size adversaries. Then there exists a streaming delegation scheme <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> for <span class="math">\\mathcal{F}</span> with the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> has perfect completeness and negligible (reusable) soundness error.</li>

      <li><span class="math">\\mathsf{D}</span> updates her secret state in time <span class="math">\\mathrm{polylog}(N)</span>, per data item.</li>

      <li>In the delegation protocol, when delegating a function <span class="math">f\\in\\mathcal{F}</span> computable in time <span class="math">T(n)</span>, the delegator <span class="math">\\mathsf{D}</span> runs in time <span class="math">\\mathrm{poly}(k,\\log N,\\log T)</span>, and the worker <span class="math">\\mathsf{W}</span> runs in time <span class="math">\\mathrm{poly}(k,\\log N,T(n))</span>, where <span class="math">n</span> is the length of the stream.</li>

      <li>The delegation protocol <span class="math">\\mathsf{Compute}(f)</span> consists of <span class="math">4</span> message exchanges.</li>

    </ul>

    <p class="text-gray-300">In Section 10.1, we present some necessary preliminaries, where we briefly review how to construct a (standard) delegation scheme using universal arguments and define PCP of Proximity. We then present a (standard) delegation scheme with the key property we need in Section 10.2. Finally, we construct the memory and streaming delegation schemes described in Theorem 44 and 45 in Sections 10.3 and 10.4, respectively.</p>

    <p class="text-gray-300">10.1 Preliminaries</p>

    <h4 id="sec-73" class="text-lg font-semibold mt-6">10.1.1 Universal Arguments</h4>

    <p class="text-gray-300">In this section, we briefly review how to delegate computation using universal arguments <em>[x1]</em>, as presented implicitly in <em>[x10, Section 9]</em>.</p>

    <p class="text-gray-300">Let <span class="math">k</span> be the security parameter. To delegate the computation of a uniform function <span class="math">f</span> (specified by a Turing machine <span class="math">M</span> with a time bound <span class="math">T</span>) on input <span class="math">x\\in\\{0,1\\}^{n}</span>, the delegator <span class="math">\\mathsf{D}</span> sends <span class="math">f,x</span> to the worker <span class="math">\\mathsf{W}</span>, who returns the answer <span class="math">y=f(x)</span> to <span class="math">\\mathsf{D}</span>. Then they engage in a universal argument, where <span class="math">\\mathsf{W}</span> proves to <span class="math">\\mathsf{D}</span> that indeed <span class="math">y=f(x)</span>. More specifically, <span class="math">\\mathsf{W}</span> proves to <span class="math">\\mathsf{D}</span> that <span class="math">(M,x,y,T)</span> is in the following language <span class="math">L^{\\text{uni}}</span>.</p>

    <p class="text-gray-300"><span class="math">L^{\\text{uni}}\\triangleq\\{(M,x,y,T):M\\text{ is a Turing machine s.t. }M(x)\\text{ outputs }y\\text{ in }\\leq T\\text{ steps}\\}.</span></p>

    <p class="text-gray-300">In more detail, in the universal argument, the prover commits to a PCP proof <span class="math">\\pi</span> using a tree commitment <span class="math">T_{h}(\\pi)</span> with the hash function <span class="math">h\\leftarrow\\mathcal{H}</span> chosen by the verifier. Then the verifier plays the role of a PCP verifier, with the prover answering her PCP queries by revealing the corresponding bits <span class="math">\\pi_{i}</span>’s in the commitment <span class="math">T_{h}(\\pi)</span>.</p>

    <p class="text-gray-300">The universal argument consists of 4 message exchanges, so the delegation protocol as described above requires 6 message exchanges. However, as argued in <em>[x10]</em>, the first two message exchanges can be parallelized with the first two messages of the universal argument, which yields a 4-message delegation protocol.</p>

    <p class="text-gray-300">Clearly, the complexity of the delegation scheme depends on the complexity of the universal argument, which depends on the underlying PCPs. We note that the delegator needs to run in time <span class="math">\\Omega(n)</span> since the verification of the underlying PCP proof <span class="math">\\pi</span> using standard PCPs (as opposed to PCPs of proximity) depends on the whole input <span class="math">(M,x,y,T)</span>.</p>

    <p class="text-gray-300">In the following theorem, we state the delegation scheme obtained by using the universal argument of <em>[x1]</em>.</p>

    <h6 id="sec-74" class="text-base font-medium mt-4">Theorem 46 (<em>[x1]</em>)</h6>

    <p class="text-gray-300">Let <span class="math">k</span> be the security parameter. Let <span class="math">n</span> denote the input length, and let <span class="math">T</span> be a time bound such that <span class="math">T\\geq n\\geq k</span>. Let <span class="math">\\mathcal{F}</span> be the family of boolean functions computable by time <span class="math">T</span> Turing machines. Assume the existence of collision resistant hash functions secure against <span class="math">\\operatorname{poly}(T)</span>-time adversaries. Then, there exists a delegation protocol for <span class="math">\\mathcal{F}</span> with the following properties.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The protocol has perfect completeness and negligible soundness error.</li>

      <li>The worker runs in time <span class="math">\\operatorname{poly}(T)</span>, and the delegator runs in time <span class="math">\\operatorname{poly}(n,\\log T)</span>.</li>

      <li>The protocol consists of four messages, with communication complexity <span class="math">\\operatorname{poly}(k,\\log T)</span>. Moreover, the protocol is public-coin.</li>

    </ol>

    <h4 id="sec-75" class="text-lg font-semibold mt-6">10.1.2 PCPs of Proximity</h4>

    <p class="text-gray-300">In this section, we present necessary preliminaries on PCPs of proximity and state the PCPP theorem of <em>[BSGH^{+}05]</em>.</p>

    <p class="text-gray-300">####</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Definition 47 (Pair-language) A pair-language <span class="math">L</span> is simply a subset of the set of string pairs <span class="math">L \\subseteq \\{0,1\\}^<em> \\times \\{0,1\\}^</em></span>. For every <span class="math">a \\in \\{0,1\\}^<em></span>, we denote <span class="math">L_a = \\{b \\in \\{0,1\\}^</em> : (a,b) \\in L\\}</span>. We usually denote $\\ell =</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> and </span>K =</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The reader can think of <span class="math">a</span> as a Turing machine <span class="math">M</span>, and <span class="math">b</span> as an input encoding, and <span class="math">(a, b) \\in L</span> iff <span class="math">M</span> accepts the input encoded by <span class="math">b</span> within some time bound.</p>

    <p class="text-gray-300">Definition 48 (PCPP verifier [BSGH⁺05]) Let <span class="math">r, q: \\mathbb{N} \\to \\mathbb{N}</span> and <span class="math">t: \\mathbb{N} \\times \\mathbb{N} \\to \\mathbb{N}</span>. An <span class="math">(r, q, t)</span>-PCPP verifier <span class="math">V</span> is a probabilistic oracle machine with the following structure.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">V</span> receives as input a string <span class="math">a \\in \\{0,1\\}^<em></span> and a number <span class="math">K \\in \\mathbb{N}</span> (in binary), and has oracle access to two strings <span class="math">b \\in \\{0,1\\}^K</span>, and <span class="math">\\pi \\in \\{0,1\\}^</em></span>.</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- <span class="math">V</span> uses at most $r(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+ K)<span class="math"> coins, makes at most </span>q(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+ K)<span class="math"> non-adaptive queries to the two oracles (in total), runs in at most </span>t(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, K)$ time, and outputs a verdict bit, indicating her acceptance/rejection.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The parameters <span class="math">r, q, t</span> are the randomness, query, and time complexity of <span class="math">V</span>, respectively.</p>

    <p class="text-gray-300">The reader can think of <span class="math">r, q, t</span> as being sub-linear.</p>

    <p class="text-gray-300">Definition 49 (PCPP for Pair-language [BSGH⁺05]) Let <span class="math">r, q: \\mathbb{N} \\to \\mathbb{N}</span>, <span class="math">t: \\mathbb{N} \\times \\mathbb{N} \\to \\mathbb{N}</span>, and <span class="math">\\varepsilon, \\delta: \\mathbb{N} \\to [0,1]</span>. A pair-language <span class="math">L \\subseteq \\{0,1\\}^<em> \\times \\{0,1\\}^</em></span> is in <span class="math">\\mathrm{PCPP}_{\\varepsilon, \\delta}[r, q, t]</span> if there exists an <span class="math">(r, q, t)</span>-PCPP verifier <span class="math">V</span> with the following properties.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- (Completeness) If <span class="math">(a, b) \\in L</span>, then there exists a PCPP proof <span class="math">\\pi \\in \\{0, 1\\}^*</span> such that $V^{b, \\pi}(a,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$ accepts with probability 1.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Pr \\left[ V ^ {b, \\pi} (a,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">) = 1 \\right] \\leq \\varepsilon .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">The parameter <span class="math">\\delta</span> is called the proximity parameter.</p>

    <p class="text-gray-300">Theorem 50 (Efficient PCPP for Pair-language (Theorem 2.5 of [BSGH⁺05])) Let <span class="math">T: \\mathbb{N} \\to \\mathbb{N}</span> be a non-decreasing function, and let <span class="math">L = \\{(a,b)\\}</span> be a pair-language. If <span class="math">L</span> can be decided in time <span class="math">T</span>, then <span class="math">L \\in \\mathrm{PCPP}_{1/2,\\delta}[r,q,t]</span> with</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>proximity parameter <span class="math">\\delta = 1 / \\mathrm{polylog}(T)</span>,</li>

      <li>randomness complexity <span class="math">r = \\log_2 T + O(\\log \\log T)</span>,</li>

      <li>query complexity <span class="math">q = \\mathrm{polylog}(T)</span>, and</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- verification time complexity <span class="math">t(\\ell, K) = \\mathrm{poly}(\\ell, \\log K, \\log T)</span>, where $\\ell \\triangleq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, K \\triangleq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, and </span>T = T(\\ell + K)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">37A string <span class="math">b</span> is <span class="math">\\delta</span>-far from a set $S \\subset \\{0,1\\}^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math"> if for every </span>b' \\in S<span class="math">, the relative Hamming distance </span>\\Delta(b,b') \\geq \\delta<span class="math">, where the relative Hamming distance is defined by </span>\\Delta(b,b') \\triangleq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\{i : b_i \\neq b_i'}\\}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">38<span class="math">L</span> can be decided in time <span class="math">T</span> if there exists a Turing machine <span class="math">M</span> such that for every input <span class="math">(a,b) \\in \\{0,1\\}^<em> \\times \\{0,1\\}^</em></span>, <span class="math">M(a,b) = 1</span> iff <span class="math">(a,b) \\in L</span>, and <span class="math">M(a,b)</span> runs in time $T(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">59</p>

    <p class="text-gray-300">Furthermore, the PCPP proof <span class="math">\\pi</span> for inputs in <span class="math">L</span> (that makes <span class="math">V</span> accepts) can be computed in time <span class="math">\\mathrm{poly}(T)</span>, and has length at most <span class="math">q \\cdot 2^r = T \\cdot \\mathrm{polylog}(T)</span>.</p>

    <p class="text-gray-300">We mention that the result of [BSGH⁺⁰⁵] holds for languages decidable in non-deterministic time <span class="math">T</span>, but we are only interested in deterministic languages for the purpose of delegating computations. We also mention that [BSGH⁺⁰⁵] does not discuss the complexity of constructing the PCPP proof, but the efficiency follows by a close inspection of their construction [Vad10].</p>

    <p class="text-gray-300">We note that the soundness error <span class="math">1/2</span> can be reduced to <span class="math">1/2^u</span> by running <span class="math">V</span> with independent coins <span class="math">u</span> times. This blows up the randomness, query, and time complexity of <span class="math">V</span> by a (multiplicative) factor of <span class="math">u</span> (but does not increase the proof length).</p>

    <h2 id="sec-76" class="text-2xl font-bold">10.2 Delegation Scheme using Universal Arguments with PCPP</h2>

    <p class="text-gray-300">In this section, we present a 4-message (standard) delegation scheme for any (efficient) computation, that possesses the same key property we need from the GKR protocol for memory and streaming delegation. Namely, the delegation protocol can be verified <em>very</em> efficiently (in sub-linear time in the input size), if the delegator has oracle access to the low-degree extension of the input <span class="math">x</span>.</p>

    <p class="text-gray-300">The starting point is the 4-message delegation scheme using universal argument [BG02] presented in Section 10.1.1. Recall that the delegator runs in time <span class="math">\\Omega(n)</span> since the verification of the underlying PCP proof <span class="math">\\pi</span> depends on the whole input <span class="math">(M, x, y, T)</span>. To make the delegator run in sub-linear time in <span class="math">n</span>, we substitute the underlying PCP for the language <span class="math">L^{\\mathrm{uni}}</span> by the efficient PCPP of [BSGH⁺⁰⁵] from Theorem 50 for the following pair-language.</p>

    <div class="my-4 text-center"><span class="math-block">L^{\\mathrm{uni-pair}} \\triangleq \\{((M, y, T), \\mathrm{LDE}_x^{\\mathbb{F}, \\mathbb{H}, m}): M \\text{ is a Turing machine s.t. } M(x) \\text{ outputs } y \\text{ in } \\leq T \\text{ steps}\\},</span></div>

    <p class="text-gray-300">where the low-degree extension <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}</span> is a Reed-Muller code of <span class="math">x \\in \\{0,1\\}^n</span> with</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\log n, \\, m = \\theta \\left(\\frac{\\log n}{\\log \\log n}\\right), \\,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\log^2 n.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Since in Section 10.1.2, a language <span class="math">L</span> is always defined to contain bit strings, we think of the codeword <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}</span> as a bit string, parsing every field element in <span class="math">\\mathbb{F}</span> as $\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> bits. Thus, the length of the codeword is </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^m \\cdot \\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\tilde{O}(n^2)<span class="math">. The parameters </span>\\mathbb{H},\\mathbb{F},m$ are chosen so that the codewords have sufficient relative Hamming distance to each other, for establishing the soundness property (we discuss this later).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Note that there exists a Turing machine <span class="math">\\mathcal{M}</span> that on input <span class="math">((M,y,T),\\tilde{x})</span>, decides whether <span class="math">((M,y,T),\\tilde{x}) \\in L^{\\mathrm{uni-pair}}</span> in time <span class="math">\\mathrm{poly}(n,T)</span> as follows: check if <span class="math">\\tilde{x}</span> is a valid codeword (i.e., <span class="math">\\tilde{x} = \\mathrm{LDE}_x</span> for some <span class="math">x</span>), decode <span class="math">\\tilde{x}</span> to obtain <span class="math">x</span>, simulate <span class="math">M(x)</span> for <span class="math">T</span> steps, and check if <span class="math">M</span> outputs <span class="math">y</span>. Hence, Theorem 50 implies the existence of a PCPP system <span class="math">\\Pi_{pcpp}</span> for <span class="math">L^{\\mathrm{uni-pair}}</span> such that on instance <span class="math">((M,y,T),\\mathrm{LDE}_x)</span>, the PCPP verifier $V^{LDE_x,\\pi}(M,y,T;</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathrm{LDE}_x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> runs in time </span>\\mathrm{polylog}(T)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Therefore, when the underlying PCP of the delegation scheme in Section 10.1.1 is replaced by this PCPP system <span class="math">\\Pi_{pcpp}</span>, and when the delegator <span class="math">\\mathsf{D}</span> is given oracle access to the low-degree extension <span class="math">\\mathrm{LDE}_x</span> of <span class="math">x</span>, <span class="math">\\mathsf{D}</span> runs in time <span class="math">\\mathrm{poly}(k, \\log T)</span>, and makes at most <span class="math">\\mathrm{polylog}(T)</span> queries to the oracle <span class="math">\\mathrm{LDE}_x</span>. Furthermore, the queries to <span class="math">\\mathrm{LDE}_x</span> depend only on <span class="math">\\mathsf{D}</span>'s coin tosses. On the other hand, the worker <span class="math">\\mathsf{W}</span> runs in time <span class="math">\\mathrm{poly}(k, T)</span>, since the PCPP proof <span class="math">\\pi</span> can be computed in time <span class="math">\\mathrm{poly}(T)</span>. For the sake of completeness, a formal description of the modified protocol can be found in Figure 8.</p>

    <p class="text-gray-300">39Namely, to prove <span class="math">f(x) = y</span>, instead of proving <span class="math">(M,x,y,T)\\in L^{\\mathrm{uni}}</span> using PCP, the worker <span class="math">\\mathsf{W}</span> proves to <span class="math">\\mathsf{D}</span> that <span class="math">((M,y,T),\\mathrm{LDE}_x)\\in L^{\\mathrm{uni-pair}}</span> using universal argument with PCPPs.</p>

    <p class="text-gray-300">60</p>

    <p class="text-gray-300">Del = <D, W="">:</p>

    <p class="text-gray-300">D delegates the computation of a uniform function  <span class="math">f</span> , specified by a Turing machine  <span class="math">M</span>  and a time bound  <span class="math">T</span> , on input  <span class="math">x \\in \\{0,1\\}^n</span>  to  <span class="math">W</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>D has  <span class="math">(M, T)</span>  and  <span class="math">x</span>  as the input.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>D sends  <span class="math">(M,T)</span>  and  <span class="math">x</span>  to W.</li>

      <li>W computes and sends  <span class="math">y = M(x)</span>  to D.</li>

      <li>W and D engage in a universal argument with PCPP, where W proves to D that  <span class="math">((M,y,T),\\mathrm{LDE}_x)\\in L^{\\mathrm{uni - pair}}</span> .</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>D sends a collision-resistant hash function  <span class="math">h \\gets \\mathcal{H}</span>  to  <span class="math">\\mathsf{W}</span> .</li>

      <li>W computes a PCPP proof  <span class="math">\\pi</span>  of the statement  <span class="math">((M, y, T), \\operatorname{Enc}(x)) \\in L^{\\mathrm{uni-pair}}</span> , and sends the tree commitment  <span class="math">T_h(\\pi)</span>  to  <span class="math">\\mathsf{D}</span> .</li>

      <li>D runs the PCPP verifier  <span class="math">V</span>  to generate a PCPP query  <span class="math">q</span>  and sends it to  <span class="math">W</span> .</li>

      <li>W reveals the bits  <span class="math">\\pi_i</span> 's queried by  <span class="math">q</span>  from the commitment  <span class="math">T_h(\\pi)</span>  to  <span class="math">\\mathsf{D}</span> .</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- D checks if  <span class="math">\\pi_i</span> 's are revealed validly, and runs the PCPP verifier  $V^{\\mathrm{LDE}_x,\\pi}(M,y,T;</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathrm{LDE}_x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>D accepts  <span class="math">y = f(x)</span>  if D accepts in the universal argument.</li>

    </ol>

    <p class="text-gray-300">Figure 8: A (standard) delegation protocol Del for any (efficient) computation.</p>

    <p class="text-gray-300">We briefly check the completeness and soundness of Del. The completeness follows by the completeness of the PCPP. For the soundness, note that to convince the delegator D of an incorrect answer  <span class="math">y \\neq f(x)</span> , an adversarial worker  <span class="math">\\mathsf{W}^*</span>  needs to make D accept  <span class="math">((M,y,T),\\mathrm{LDE}_x) \\notin L^{\\mathrm{uni - pair}}</span>  in the universal argument. Note that by the choice of parameters  <span class="math">\\mathbb{F},\\mathbb{H},m</span>  and Schwartz-Zippel Lemma, the relative Hamming distance between any two codewords  <span class="math">\\mathrm{LDE}_x,\\mathrm{LDE}_{x&#x27;}</span>  is at least</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\frac {\\mathbb {F} - m \\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">} \\cdot \\frac {1}{\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">} = \\Omega \\left(\\frac {1}{\\log \\log n}\\right) \\geq \\frac {1}{\\mathrm {p o l y l o g} (T)}.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">Hence, the soundness property of the PCPP implies that for every  <span class="math">((M,y,T),\\mathrm{LDE}_x)\\notin L^{\\mathrm{uni - pair}}</span>  and for every  <span class="math">\\pi \\in \\{0,1\\}^{*}</span></p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Pr \\left[ V ^ {\\mathrm {L D E} _ {x}, \\pi} (M, y, T;</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathrm {L D E} _ {x}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">) = 1 \\right] \\leq 1 / 2.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">Since the soundness of the universal argument follows by the security of collision-resistance hash functions and the soundness of the underlying PCP / PCPP, the delegator  <span class="math">\\mathsf{D}</span>  would accept  <span class="math">y \\neq f(x)</span>  with probability at most  <span class="math">1/2 + \\mathsf{ngl}</span> . Namely, the delegation protocol has soundness error  <span class="math">1/2 + \\mathsf{ngl}</span> . The soundness error can be reduced to negligible if the soundness of the underlying PCPP is negligible, which as mentioned, can be achieved by repeating the PCPP verifier with fresh randomness  <span class="math">u</span>  times for some  <span class="math">u</span>  satisfying  <span class="math">1/2^u \\leq \\mathsf{ngl}</span> .</p>

    <p class="text-gray-300">As in Section 10.1.1, the protocol Del, as defined in Figure 8, consists of 6 message exchanges. However, note that the first message of D in the universal argument does not depend on the statement <span class="math">((M,y,T),\\mathrm{LDE}_{x})</span>, and hence the worker’s first message can be delayed to be sent together with the first prover’s message of the universal argument, which yields a 4-message delegation protocol.</p>

    <p class="text-gray-300">We summarize the properties of Del in the following theorem.</p>

    <h6 id="sec-77" class="text-base font-medium mt-4">Theorem 51 (Interactive Delegation Scheme for Any (Efficient) Computation)</h6>

    <p class="text-gray-300">Let <span class="math">k</span> be the security parameter. Let <span class="math">n</span> denote the input length, and let <span class="math">T</span> be a time bound such that <span class="math">T\\geq n\\geq k</span>. Let <span class="math">\\mathcal{F}</span> be the family of boolean functions computable by time <span class="math">T</span> Turing machines. Assume the existence of collision resistant hash functions secure against <span class="math">\\mathrm{poly}(T)</span>-time adversaries. Then, there exists a delegation protocol for <span class="math">\\mathcal{F}</span> with the following properties.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The protocol has perfect completeness and negligible soundness error.</li>

      <li>The worker runs in time <span class="math">\\mathrm{poly}(T)</span>, and the delegator runs in time <span class="math">\\mathrm{poly}(n,\\log T)</span>.</li>

      <li>The protocol consists of four messages, with communication complexity <span class="math">\\mathrm{poly}(k,\\log T)</span>. Moreover, the protocol is public-coin.</li>

      <li>If the delegator is given oracle access to the low-degree extension of <span class="math">x</span>, rather than being given the input <span class="math">x</span> itself, and if the worker is given <span class="math">x</span> as an input, then she runs in time <span class="math">\\mathrm{poly}(k,\\log T)</span>, and the protocol still has all the properties described above, for the following choice of parameters <span class="math">\\mathbb{H},\\mathbb{F},m</span> of the low-degree extension.</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\log n,\\ m=\\theta\\left(\\frac{\\log n}{\\log\\log n}\\right),\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\log^{2}n.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Moreover, the delegator queries the low-degree extension of <span class="math">x</span> at <span class="math">\\mathrm{polylog}(T)</span> points, depending only on her coin tosses.</p>

    <h6 id="sec-78" class="text-base font-medium mt-4">Remark 52</h6>

    <p class="text-gray-300">We remark that the parameters <span class="math">\\mathbb{F},\\mathbb{H},m</span> are chosen so that <span class="math">\\mathrm{LDE}_{x}</span> is a Reed-Muller code with good rate and minimum distance. Let <span class="math">N&gt;n</span> be a parameter. We can also set <span class="math">\\mathbb{F},\\mathbb{H},m</span> by</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\log N,\\ m=\\left\\lceil\\frac{\\log n}{\\log\\log N}\\right\\rceil,\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\log^{2}N,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Then <span class="math">\\mathrm{LDE}_{x}</span> has length at most <span class="math">\\mathrm{poly}(n,\\log N)</span> and (relative) minimum distance at least <span class="math">\\Omega(1/\\log\\log N)</span>. One can verify that the delegation scheme in Figure 8 is also sound with this setting of parameters (provided that <span class="math">T\\geq\\log N</span>, which can be assumed without loss of generality by padding dummy steps), and the runtime of the delegator and the work are <span class="math">\\mathrm{poly}(k,\\log N,\\log T)</span> and <span class="math">\\mathrm{poly}(k,\\log N,T)</span>, respectively. This will be useful for our streaming delegation scheme presented in Section 10.4.</p>

    <h3 id="sec-79" class="text-xl font-semibold mt-8">10.3 Memory Delegation Scheme Based on Theorem 51</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In this section, we outline how to construct the memory delegation scheme (Theorem 44) using the above delegation scheme (Theorem 51). Let <span class="math">x\\in\\{0,1\\}^{n}</span> be the memory being delegated. We observe that the delegator in Theorem 51 is efficient (<span class="math">\\mathrm{poly}(k,\\log T)</span>) if she is given the oracle access to the low-degree extension of <span class="math">x</span> with respect to some parameters $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\log^{2}n<span class="math">, </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\log n<span class="math">, and </span>m=\\theta(\\log n/\\log\\log n)$. Thus, we can use similar techniques to the once in Section 7.2 where the delegator can verify points on the low-degree extension oracle using a tree commitment.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The Construction.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- Offline Phase. The delegator chooses parameters <span class="math">\\mathbb{F},\\mathbb{H},m</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\log^{2}n<span class="math">, </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\log n<span class="math">, and </span>m=\\theta(\\log n/\\log\\log n)<span class="math">, and a random function </span>h<span class="math"> from a collision resistant hash family </span>\\mathcal{H}<span class="math">. Then the delegator computes the root of the Merkle tree of </span>\\mathrm{LDE}_{x}^{\\mathbb{F},\\mathbb{H},m}<span class="math">, namely </span>\\sigma=T_{h}(\\mathrm{LDE}_{x}^{\\mathbb{F},\\mathbb{H},m})<span class="math">, and saves </span>(h,\\sigma)<span class="math"> as a short certificate of </span>x$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Online Plase.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{Compute}(f)</span>: The worker and the delegator run the delegation scheme given by Theorem 51. In order to verify, the delegator needs to access poly <span class="math">\\log T</span> points in <span class="math">\\mathrm{LDE}_{x}^{\\mathbb{F},\\mathbb{H},m}</span>, and she can achieve this task by asking the worker to reveal the augmented paths corresponding to the Merkle tree. She accepts if and only if all the openings are accepted, and their corresponding values together with the answers to the PCPP queries are accepted in the verification of the delegation scheme.</li>

      <li><span class="math">\\mathsf{Update}(g)</span>: The delegator chooses a fresh collision resistant hash function <span class="math">h^{\\prime}\\leftarrow\\mathcal{H}</span>, then the delegator and the worker run <span class="math">\\mathsf{Compute}(T_{h^{\\prime}}(\\mathrm{LDE}_{g(x)}))</span>. Note that <span class="math">T_{h^{\\prime}}(\\mathrm{LDE}_{g(x)})</span> is polynomial time computable (in <span class="math">x</span>) given <span class="math">g</span>. Finally, the worker replaces the memory <span class="math">x</span> with <span class="math">g(x)</span>.</li>

    </ul>

    <p class="text-gray-300">Putting it together, we obtain Theorem 44. The proof is very similar to the proof of Theorem 31 in Section 7.3, and therefore is omitted. In what follows, we give a very high level overview of the proof.</p>

    <p class="text-gray-300">Proof Overview of Theorem 44.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The completeness follows from those of the delegation scheme from Theorem 51 and the tree commitment. The soundness can be proved in a similar way to the proof in Section 7.3.</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- Both parties are efficient in the offline stage, i.e. run in time <span class="math">\\mathrm{poly}(k,n)</span> since the computation of the root of the Merkle tree takes $\\mathrm{poly}(k,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{m})=\\mathrm{poly}(k,n)$ time.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In the online phase during each <span class="math">\\mathsf{Compute}(f)</span> operation, the worker runs in time <span class="math">\\mathrm{poly}(k,T)</span>, and the delegator runs in time <span class="math">\\mathrm{poly}(k,\\log T)</span>, where <span class="math">T</span> is the running time of <span class="math">f</span>. This follows from the efficiency of the delegation scheme from Theorem 51 and from the fact that only <span class="math">\\mathrm{poly}\\log T</span> leaves of the tree commitment need to be revealed.</li>

      <li>The protocol has 4 message exchanges, by running the delegation scheme from Theorem 51 and the Reveal protocols in parallel. Specifically, in the first two messages, the delegator sends a random hash function and the worker uses it to commit to a PCPP proof. Then in the third message, the delegator queries both the PCPP proof and points on the low degree extension of the memory. The worker answers the corresponding queries in the fourth message. An illustration of the protocol can be found in Figure 9.</li>

    </ul>

    <h3 id="sec-80" class="text-xl font-semibold mt-8">10.4 Streaming Delegation Scheme Based on Theorem 51</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In this section, we outline the construction of our streaming delegation scheme. Let <span class="math">N</span> be the bound of the stream, and we choose the following parameters: <span class="math">\\tilde{\\mathbb{F}},\\mathbb{F},\\mathbb{H},m</span> such that $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\log^{2}N<span class="math">, </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\log N<span class="math">, </span>m=\\theta(\\log N/\\log\\log N)<span class="math">, and </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\tilde{\\mathbb{F}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=N^{\\log N}<span class="math"> where </span>\\tilde{\\mathbb{F}}<span class="math"> is an extension field of </span>\\mathbb{F}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Figure 9:  <span class="math">\\mathsf{Compute}(f)</span>  protocol of our interactive memory delegation scheme:  <span class="math">h_{UA}</span>  is a collision resistant hash function chosen by the delegator in the universal argument.  <span class="math">T_{h_{UA}}(\\pi_{pcpp})</span>  is the tree commitment of the PCPP proof  <span class="math">\\pi_{pcpp}</span> .  <span class="math">q_{\\pi}</span>  and  <span class="math">q_{\\mathrm{LDE}}</span>  denote the queries that the delegator makes to the PCPP proof and the Reed-Muller encoding  <span class="math">\\mathrm{LDE}_x</span>  of the input  <span class="math">x</span> , respectively.  <span class="math">ans_{\\pi}</span>  and  <span class="math">ans_{\\mathrm{LDE}}</span>  denote the corresponding answers together with the corresponding augmented paths.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Generating and updating the secret state. At time 0, the delegator keeps a secret  <span class="math">\\sigma_0 = (z,0)</span> , where  <span class="math">z \\gets \\widehat{\\mathbb{F}}^m</span> . At each time  <span class="math">t \\in [N]</span> , when a data item  <span class="math">x_t \\in \\{0,1\\}</span>  arrives, the delegator updates her secret state from  <span class="math">\\sigma_{t-1} = (z, \\mathrm{LDE}_{x^{t-1}}^{\\widehat{\\mathbb{F}},\\mathbb{H},m}(z))</span>  to  <span class="math">\\sigma_t = (z, \\mathrm{LDE}_{x^t}^{\\widehat{\\mathbb{F}},\\mathbb{H},m}(z))</span> , by using Proposition 6. (Recall that  <span class="math">x^t = (x_1, \\ldots, x_t)</span>  denotes the entire data stream up until time  <span class="math">t</span> .)</li>

      <li>Compute  <span class="math">(f, t)</span> . At any time  <span class="math">t</span> , when the delegator wants to execute  <span class="math">\\mathsf{Compute}(f, t)</span> , both parties run the delegation scheme from Theorem 51 with a modified parameter setting</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {H}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\log N, m ^ {\\prime \\prime} = \\left\\lceil \\frac {\\log n}{\\log \\log N} \\right\\rceil ,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\log^ {2} N</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">as stated in Remark 52. Here in order to verify, the delegator needs to verify the value of  <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}</span>  on a few points  <span class="math">z_i&#x27;&#x27; \\in \\mathbb{F}^{m&#x27;&#x27;}</span> . As argued in Section 9.1 (see Equation (10)),  <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z_i&#x27;&#x27;) = \\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m}(z_i)</span>  where  <span class="math">z_i = (0^{m - m&#x27;&#x27;}, z_i)</span> . Hence, the delegator can instead verify the values  <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m}(z_i)</span> , which can be done by using a many-to-one protocol together with a Reveal protocol in exactly the same way as in Section 9.2 (see Steps 3 and 4 in Figure 7).</p>

    <p class="text-gray-300">This gives us a streaming delegation scheme satisfying Theorem 45. As in Section 10.3, the proof is very similar to the proof of Theorem 40 in Section 9, and is therefore omitted.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The completeness follows from that of the delegation scheme from Theorem 51, the many-to-one protocol, and the Reveal protocol of the algebraic commitments (see Section 9 for details). The soundness can be proved in a similar way to the proof in Section 9.3.</li>

      <li>The delegator runs in time polylog  <span class="math">N</span>  to update her secret per data item.</li>

      <li>The worker runs in time  <span class="math">\\mathrm{poly}(k, \\log N, T)</span>  for the delegation of a time  <span class="math">T</span>  computable function, and the delegator runs in time  <span class="math">\\mathrm{poly}(k, \\log N, \\log T)</span> . This follows from the efficiency of the underlying delegation scheme from Theorem 51, the many-to-one protocol, and the Reveal protocol of the algebraic commitments.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The protocol has 4 message exchanges, by running the the delegation scheme from Theorem 51, the many-to-one protocol, and the Reveal protocol in parallel, in a similar way to that of the memory delegation scheme described in Section 10.3. An illustration of the protocol can be found in Figure 10.</li>

    </ul>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a> Figure 10:  <span class="math">\\mathsf{Compute}(f)</span>  protocol of our interactive streaming delegation scheme, where  <span class="math">q_{\\mathrm{LDE}} = \\mathbf{z} = \\{z_i\\}</span>  is the queries that the delegator makes to the Reed-Muller encoding  <span class="math">\\mathrm{LDE}_x</span>  of the input  <span class="math">x</span> . In parallel to the universal argument, the delegator and the worker run a many-to-one protocol and a Reveal protocol in the same way as in Section 9.2 (see Steps 3 and 4 in Figure 7) to verify the values of  <span class="math">\\mathrm{LDE}_x</span>  on points  <span class="math">\\mathbf{z}</span> .</p>

    <p class="text-gray-300">We are very grateful to Shai Halevi for collaborating with us in the initial phase of this work, and to Salil Vadhan for several helpful discussions.</p>

    <p class="text-gray-300">[AIK10] Benny Applebaum, Yuval Ishai, and Eyal Kushilevitz. From secrecy to soundness: Efficient verification via secure computation. In ICALP (1), pages 152-163, 2010. [Bar01] Boaz Barak. How to go beyond the black-box simulation barrier. In FOCS, pages 106-115, 2001. [BCC88] Gilles Brassard, David Chaum, and Claude Crépeau. Minimum disclosure proofs of knowledge. Journal of Computer and System Sciences, 37(2):156-189, 1988. [BFL91] László Babai, Lance Fortnow, and Carsten Lund. Non-deterministic exponential time has two-prover interactive protocols. Computational Complexity, 1:3-40, 1991. [BFLS91] László Babai, Lance Fortnow, Leonid A. Levin, and Mario Szegedy. Checking computations in polylogarithmic time. In STOC, pages 21-31, 1991. [BG02] Boaz Barak and Oded Goldreich. Universal arguments and their applications. In Proceedings of the 17th Annual IEEE Conference on Computational Complexity, pages 194-203, 2002. [BIN97] Mihir Bellare, Russell Impagliazzo, and Moni Naor. Does parallel repetition lower the error in computationally sound protocols? In FOCS, pages 374-383, 1997.</p>

    <p class="text-gray-300">[BR97] Mihir Bellare and Phillip Rogaway. Minimizing the use of random oracles in authenticated encryption schemes. In ICICS, pages 1–16, 1997.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[BSGH^{+}05] Eli Ben-Sasson, Oded Goldreich, Prahladh Harsha, Madhu Sudan, and Salil P. Vadhan. Short pcps verifiable in polylogarithmic time. In IEEE Conference on Computational Complexity, pages 120–134, 2005.</li>

      <li>[BSW03] Boaz Barak, Ronen Shaltiel, and Avi Wigderson. Computational analogues of entropy. In RANDOM-APPROX, pages 200–215, 2003.</li>

      <li>[CGH04] Ran Canetti, Oded Goldreich, and Shai Halevi. The random oracle methodology, revisited. Journal of the ACM, 51(4):557–594, 2004.</li>

      <li>[CHS05] Ran Canetti, Shai Halevi, and Michael Steiner. Hardness amplification of weakly verifiable puzzles. In TCC, pages 17–33, 2005.</li>

      <li>[CKLR11] Kai-Min Chung, Yael Tauman Kalai, Feng-Hao Liu, and Ran Raz. Memory delegation. In CRYPTO, 2011.</li>

      <li>[CKV10] Kai-Min Chung, Yael Kalai, and Salil P. Vadhan. Improved delegation of computation using fully homomorphic encryption. In CRYPTO, pages 483–501, 2010.</li>

      <li>[CTY10] G. Cormode, J. Thaler, and K. Yi. Verifying computations with streaming interactive proofs. Technical Report TR10-159, ECCC Report, 2010.</li>

      <li>[DORS08] Yevgeniy Dodis, Rafail Ostrovsky, Leonid Reyzin, and Adam Smith. Fuzzy extractors: How to generate strong keys from biometrics and other noisy data. SIAM J. Comput., 38(1):97–139, 2008.</li>

      <li>[DP08] Stefan Dziembowski and Krzysztof Pietrzak. Leakage-resilient cryptography. In FOCS, pages 293–302, 2008.</li>

      <li>[DR06] Irit Dinur and Omer Reingold. Assignment testers: Towards a combinatorial proof of the pcp theorem. SIAM J. Comput., 36(4):975–1024, 2006.</li>

      <li>[FL93] Lance Fortnow and Carsten Lund. Interactive proof systems and alternating time-space complexity. Theoretical Computer Science, 113(1):55–73, 1993.</li>

      <li>[FR11] Benjamin Fuller and Leonid Reyzin. Computational entropy and information leakage. Manuscript., 2011.</li>

      <li>[FS86] Amos Fiat and Adi Shamir. How to prove yourself: Practical solutions to identification and signature problems. In CRYPTO, pages 186–194, 1986.</li>

      <li>[Gen09] Craig Gentry. Fully homomorphic encryption using ideal lattices. In STOC, pages 169–178, 2009.</li>

      <li>[GGP10] Rosario Gennaro, Craig Gentry, and Bryan Parno. Non-interactive verifiable computing: Outsourcing computation to untrusted workers. In CRYPTO, pages 465–482, 2010.</li>

    </ul>

    <p class="text-gray-300">[GK03] Shafi Goldwasser and Yael Tauman Kalai. On the (in)security of the fiat-shamir paradigm. pages 102–113, 2003.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[GKR08] Shafi Goldwasser, Yael Tauman Kalai, and Guy N. Rothblum. Delegating computation: interactive proofs for muggles. In STOC, pages 113–122, 2008.</li>

      <li>[HLR07] Chun-Yuan Hsiao, Chi-Jen Lu, and Leonid Reyzin. Conditional computational entropy, or toward separating pseudoentropy from compressibility. In EUROCRYPT, pages 169–186, 2007.</li>

      <li>[Kil92] Joe Kilian. A note on efficient zero-knowledge proofs and arguments (extended abstract). In STOC, pages 723–732, 1992.</li>

      <li>[KR09] Yael Tauman Kalai and Ran Raz. Probabilistically checkable arguments. In CRYPTO, 2009.</li>

      <li>[LFKN92] Carsten Lund, Lance Fortnow, Howard J. Karloff, and Noam Nisan. Algebraic methods for interactive proof systems. J. ACM, 39(4):859–868, 1992.</li>

      <li>[Mic94] Silvio Micali. Cs proofs (extended abstracts). In FOCS, pages 436–453, 1994.</li>

      <li>[Mic00] Silvio Micali. Computationally sound proofs. SIAM J. Comput., 30(4):1253–1298, 2000.</li>

      <li>[Neu28] John Von Neumann. Zur theorie der gesellschaftsspiele. Mathematische Annalen, 100(1):295–320, 1928.</li>

      <li>[RTTV08] Omer Reingold, Luca Trevisan, Madhur Tulsiani, and Salil P. Vadhan. Dense subsets of pseudorandom sets. In FOCS, pages 76–85, 2008.</li>

      <li>[RW05] Renato Renner and Stefan Wolf. Simple and tight bounds for information reconciliation and privacy amplification. In ASIACRYPT, pages 199–216, 2005.</li>

      <li>[Sha92] Adi Shamir. IP = PSPACE. Journal of the ACM, 39(4):869–877, 1992.</li>

      <li>[Vad10] Salil Vadhan. Psuedorandomness. Book draft, available at</li>

    </ul>

    <p class="text-gray-300">“http://people.seas.harvard.edu/~salil/pseudorandomness/pseudorandomness- Aug10.pdf”, 2010.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[vDGHV10] Marten van Dijk, Craig Gentry, Shai Halevi, and Vinod Vaikuntanathan. Fully homomorphic encryption over the integers. In EUROCRYPT, pages 24–43, 2010.</li>

    </ul>

    <h2 id="sec-85" class="text-2xl font-bold">Appendix A Proof of Lemma 23</h2>

    <h6 id="sec-86" class="text-base font-medium mt-4">Lemma 53 (Lemma 23 restated)</h6>

    <p class="text-gray-300">Let <span class="math">\\mathbb{F}</span> be a finite field of size <span class="math">q</span>, and let <span class="math">m\\in\\mathbb{N}</span> be a parameter. Let <span class="math">X</span> be a distribution over <span class="math">\\mathbb{F}^{m\\times 2}</span> with <span class="math">\\mathbf{H}_{\\infty}(X)\\geq(2m\\cdot\\log q)-(\\log q)/4</span>, and <span class="math">a=(a_{1},a_{2})\\leftarrow\\mathbb{F}^{2}</span>. Then <span class="math">(X\\cdot a)\\in\\mathbb{F}^{m}</span> is <span class="math">\\varepsilon</span>-close to uniform with <span class="math">\\varepsilon\\leq 2m\\cdot q^{-1/4}</span>.</p>

    <p class="text-gray-300">######</p>

    <p class="text-gray-300">Let <span class="math">x^{1},\\ldots,x^{m}\\in\\mathbb{F}^{2}</span> denote the <span class="math">m</span> rows of <span class="math">X</span>, and let <span class="math">\\mathcal{H}</span> be the following hash function family</p>

    <p class="text-gray-300"><span class="math">\\mathcal{H}=\\{h_{a}:\\mathbb{F}^{2}\\to\\mathbb{F}\\text{ s.t. }h_{a}(x)=a_{1}x_{1}+a_{2}x_{2}\\quad\\forall a\\in\\mathbb{F}^{2}\\}.</span></p>

    <p class="text-gray-300">In the above notation, <span class="math">X\\cdot a=(h_{a}(x^{1}),\\ldots,h_{a}(x^{m}))</span>. Loosely speaking, Lemma 23 holds for the following reasons:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>All rows of <span class="math">X</span> have high min-entropy. Note that there are only <span class="math">(\\log q)/4</span> bits of entropy missing from <span class="math">X</span>, so intuitively, all rows <span class="math">x^{i}</span> of <span class="math">X</span> have at least <span class="math">2\\log q-(\\log q)/4</span> bits of entropy.</li>

      <li><span class="math">\\mathcal{H}</span> is a 2-universal hash function family. By Leftover Hash Lemma (Lemma 57 below), <span class="math">h_{a}\\leftarrow\\mathcal{H}</span> can extract randomness from all rows <span class="math">x^{i}</span> of <span class="math">X</span>.</li>

    </ul>

    <p class="text-gray-300">We proceed to present necessary preliminaries for proving Lemma 23.</p>

    <h6 id="sec-87" class="text-base font-medium mt-4">Definition 54 (Block Source)</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">X=(X_{1},\\ldots,X_{m})</span> be a distribution, and let <span class="math">\\ell\\in\\mathbb{N}</span> be a parameter. We say that <span class="math">X</span> is a <em>block <span class="math">\\ell</span>-source</em> if for every <span class="math">i\\in[m]</span> and every <span class="math">(x_{1},\\ldots,x_{i-1})\\in\\mathrm{supp}(X_{1},\\ldots,X_{i-1})</span>, $\\mathbf{H}_{\\infty}(X_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{(X_{1},\\ldots,X_{i-1})=(x_{1},\\ldots,x_{i-1})})\\geq\\ell$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The following lemma says that if <span class="math">X=(X_{1},\\ldots,X_{m})</span> has sufficiently high min-entropy, then <span class="math">X</span> is (statistically close to) a block source.</p>

    <h6 id="sec-88" class="text-base font-medium mt-4">Lemma 55 (see, e.g., <em>[x10]</em>)</h6>

    <p class="text-gray-300">Let <span class="math">X=(X_{1},\\ldots,X_{m})</span> be a distribution over <span class="math">\\{0,1\\}^{m\\times n}</span>. Let <span class="math">\\Delta\\in\\mathbb{N}</span> and <span class="math">\\varepsilon\\in(0,1)</span> be parameters. If <span class="math">\\mathbf{H}_{\\infty}(X)\\geq mn-\\Delta</span>, then <span class="math">X</span> is <span class="math">(m\\varepsilon)</span>-close to a block <span class="math">k</span>-source with <span class="math">k=n-\\Delta-\\log(1/\\varepsilon)</span>.</p>

    <h6 id="sec-89" class="text-base font-medium mt-4">Definition 56 (2-universal)</h6>

    <p class="text-gray-300">A hash function family <span class="math">\\mathcal{H}=\\{h:\\{0,1\\}^{n_{1}}\\to\\{0,1\\}^{n_{2}}\\}</span> is <em>2-universal</em> if for every <span class="math">x\\neq x^{\\prime}\\in\\{0,1\\}^{n_{1}}</span>,</p>

    <p class="text-gray-300"><span class="math">\\Pr_{h\\leftarrow\\mathcal{H}}[h(x)=h(x^{\\prime})]\\leq 1/2^{n_{2}}.</span></p>

    <p class="text-gray-300">It is easy to verify that the hash function family <span class="math">\\mathcal{H}=\\{h_{a}:\\mathbb{F}^{2}\\to\\mathbb{F}\\}</span> defined above is 2-universal.</p>

    <h6 id="sec-90" class="text-base font-medium mt-4">Lemma 57 (Leftorver Hash Lemma (see, e.g., <em>[x10]</em>))</h6>

    <p class="text-gray-300">Let <span class="math">\\mathcal{H}=\\{h:\\{0,1\\}^{n_{1}}\\to\\{0,1\\}^{n_{2}}\\}</span> be a <span class="math">2</span>-universal family of hash functions. Let <span class="math">k\\in\\mathbb{N}</span> and <span class="math">\\varepsilon&gt;0</span> be parameters such that <span class="math">n_{2}\\leq k-2\\log(1/\\varepsilon)</span>. For any distribution <span class="math">X</span> with <span class="math">\\mathbf{H}_{\\infty}(X)\\geq k</span>, the distribution <span class="math">(h,h(X))</span> is <span class="math">\\varepsilon</span>-close to uniform in statistical distance.</p>

    <p class="text-gray-300">Moreover, if <span class="math">X=(X_{1},\\ldots,X_{m})</span> is a block <span class="math">k</span>-source, then the distribution <span class="math">(h,h(X_{1}),\\ldots,h(X_{m}))</span> is <span class="math">(m\\varepsilon)</span>-close to uniform.</p>

    <p class="text-gray-300">Lemma 23 follows readily by Lemma 55 and 57.</p>

    <p class="text-gray-300">Proof. (of Lemma 23) Let <span class="math">\\varepsilon=q^{-1/4}</span>, and <span class="math">k=1.5\\log q</span>. By Lemma 55, <span class="math">X=(x^{1},\\ldots,x^{m})</span> is <span class="math">m\\varepsilon</span>-close to a block <span class="math">k</span>-source. By Lemma 57, <span class="math">X\\cdot a=(h_{a}(x^{1}),\\ldots,h_{a}(x^{m}))</span> is <span class="math">(m\\varepsilon+m\\varepsilon)</span>-close to uniform. <span class="math">\\blacksquare</span></p>

    <p class="text-gray-300">##</p>`;
---

<BaseLayout title="Memory Delegation (2011/273)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2011 &middot; eprint 2011/273
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
