---
import BaseLayout from '../../layouts/BaseLayout.astro';
import PaperDisclaimer from '../../components/PaperDisclaimer.astro';
import PaperHistory from '../../components/PaperHistory.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2011/273';
const CRAWLER = 'modal-marker';
const CONVERTED_DATE = '2026-02-18';
const TITLE_HTML = 'Memory Delegation∗';
const AUTHORS_HTML = 'Kai-Min Chung† Yael Tauman Kalai‡ Feng-Hao Liu§ Ran Raz ¶ June 15, 2011';

const CONTENT = `    <p class="text-gray-300">Kai-Min Chung† Yael Tauman Kalai‡ Feng-Hao Liu§ Ran Raz ¶ June 15, 2011</p>

    <h4 id="sec-1" class="text-lg font-semibold mt-6">Abstract</h4>

    <p class="text-gray-300">We consider the problem of delegating computation, where the delegator doesn't even know the input to the function being delegated, and runs in time significantly smaller than the input length.</p>

    <p class="text-gray-300">For example, consider the setting of memory delegation, where a delegator wishes to delegate her entire memory to the cloud. The delegator may want the cloud to compute functions on this memory, and prove that the functions were computed correctly. As another example, consider the setting of streaming delegation, where a stream of data goes by, and a delegator, who cannot store this data, delegates this task to the cloud. Later the delegator may ask the cloud to compute statistics on this streaming data, and prove the correctness of the computation. We note that in both settings the delegator must keep a (short) certificate of the data being delegated, in order to later verify the correctness of the computations. Moreover, in the streaming setting, this certificate should be computed in a streaming manner.</p>

    <p class="text-gray-300">We construct both memory and streaming delegation schemes. We present non-interactive constructions based on the (standard) delegation scheme of Goldwasswer et. al. <a href="#page-66-0">[GKR08]</a>. These schemes allow the delegation of any function computable by an L-uniform circuit of low depth (the complexity of the delegator depends linearly on the depth). For memory delegation, we rely on the existence of a polylog PIR scheme, and for streaming, we rely on the existence of a fully homomorphic encryption scheme.</p>

    <p class="text-gray-300">We also present constructions based on the CS-proofs of Micali. These schemes allow the delegation of any function in P. However, they are interactive (i.e., consists of 4 messages), or are non-interactive in the Random Oracle Model.</p>

    <h2 id="sec-2" class="text-2xl font-bold">1 Introduction</h2>

    <p class="text-gray-300">The problem of delegating computation considers a scenario where one party, the delegator, wishes to delegate the computation of a function f to another party, the worker. The challenge is that</p>

    <p class="text-gray-300">&lt;sup&gt;∗&lt;/sup&gt;An extend abstract of this paper will appear in Crypto '11 <a href="#page-65-0">[CKLR11]</a>.</p>

    <p class="text-gray-300">&lt;sup&gt;†&lt;/sup&gt;Department of Computer Science, Cornell University, Upson Hall 4108, Ithaca, NY 14850, USA. <a href="http://www.cs.cornell.edu/~chung/">http://www.</a> <a href="http://www.cs.cornell.edu/~chung/">cs.cornell.edu/~chung/</a>. chung@cs.cornell.edu. Supported by US-Israel BSF grant 2006060 and NSF grant CNS-0831289.</p>

    <p class="text-gray-300">&lt;sup&gt;‡&lt;/sup&gt;Microsoft Research, One Memorial Drive, Cambridge MA, 02142, USA. <a href="http://research.microsoft.com/en-us/um/people/yael/">http://research.microsoft.com/</a> <a href="http://research.microsoft.com/en-us/um/people/yael/">en-us/um/people/yael/</a>. yael@microsoft.com.</p>

    <p class="text-gray-300">&lt;sup&gt;§&lt;/sup&gt;Department of Computer Science, Brown University, Providence RI, 02912, USA. <a href="http://www.cs.brown.edu/people/fenghao/">http://www.cs.brown.edu/</a> <a href="http://www.cs.brown.edu/people/fenghao/">people/fenghao/</a>. fenghao@cs.brown.edu.</p>

    <p class="text-gray-300">&lt;sup&gt;¶&lt;/sup&gt;Department of Mathematics and Computer Science, Weizmann Institute of Science, Ziskind 144, Rehovot 76100, Israel. <a href="http://www.wisdom.weizmann.ac.il/~ranraz/">http://www.wisdom.weizmann.ac.il/~ranraz/</a>. ran.raz@weizmann.ac.il.</p>

    <p class="text-gray-300">the delegator may not trust the worker, and thus it is desirable to have the worker &quot;prove&quot; that the computation was done correctly. Obviously, verifying this proof should be easier than doing the computation.</p>

    <p class="text-gray-300">This concept of &quot;outsourcing&quot; computation received a lot of attention in recent years, partly due to the increasing interest in cloud computing, where the goal is to outsource all the computational resources to a (possibly untrusted) &quot;cloud&quot;. There are several reasons why the client (or delegator) may not trust the cloud, and thus would like to receive proofs for the correctness of the computation. For example, the cloud may have an incentive to return incorrect answers. Such an incentive may be a financial one, if the real computation requires a lot of work, whereas computing incorrect answers requires less work and is unlikely to be detected by the client. Moreover, in some cases, the applications outsourced to the cloud may be so critical that the delegator wishes to rule out accidental errors during the computation.</p>

    <p class="text-gray-300">In order to ensure that the worker (or the cloud) performed the computation correctly, we would like the worker to prove this to the delegator. Of course, it is essential that the time it takes to verify the proof is significantly smaller than the time needed to actually run the computation. At the same time, the running time of the worker carrying out the proof should also be reasonable comparable to the time it takes to do the computation.</p>

    <p class="text-gray-300">The problem of delegating computation has been studied excessively (see Section <a href="#page-5-0">1.2</a> for an overview on previous work). However, most previous work on delegation allow the delegator to run in time polynomial in the input size, as long as this runtime is significantly smaller than the time it takes to do the computation. For example, when delegating the computation of a function f that runs in time T and has inputs of size n, typically the desired runtime of the delegator is poly(n, log T) and the desired runtime of the worker is poly(T).</p>

    <p class="text-gray-300">In this work, we want the delegator to run in time that is even smaller than the input size n. Namely, we don't allow the delegator even to read the input! At first, this requirement may seem unreasonable and unachievable. So, let us start by motivating this requirement with two examples.</p>

    <p class="text-gray-300">Memory delegation. Suppose that Alice would like to store all her memory in the cloud. The size of her memory may be huge (for example, may include all the emails she ever received). Moreover, suppose she doesn't trust the cloud. Then, every time she asks the cloud to carry out some computation (for example, compute how many emails she has received from Bob during the last year), she would like the answer to be accompanied by a proof that indeed the computation was done correctly. Note that the input to these delegated functions may be her entire memory, which can be huge. Therefore, it is highly undesirable that Alice runs in time that is proportional to this input size. More importantly, Alice doesn't even hold on to this memory anymore, since she delegated it to the cloud.</p>

    <p class="text-gray-300">Thus, in a memory delegation scheme, a delegator delegates her entire memory to the cloud, and then may ask the could to compute functions of this memory, and expects the answers to be accompanied by a proof. Note that in order to verify the correctness of these proofs, the delegator must save some short certificate of her memory, say a certificate of size polylog(n), where n is the memory size. The proofs should be verifiable very efficiently; say, in time polylog(n, T), where T is the time it takes to compute the function. Moreover, Alice should be able to update her memory efficiently.</p>

    <p class="text-gray-300">Streaming delegation. Suppose that there is some large amount of data that is streaming by, and suppose that a user, Alice, wishes to save this data, so that later on she will be able to compute statistics on this data. However, Alice's memory is bounded and she cannot store this data. Instead, she wishes to delegate this to the cloud. Namely, she asks the cloud to store this streaming data for her, and then she asks the cloud to perform computation on this data. As in the case of memory delegation, in order to later verify the correctness of these computations, Alice must save some short certificate of this streaming data. As opposed to the setting of memory delegation, here the certificate should be computed (and updated) in a streaming manner.</p>

    <p class="text-gray-300">The settings of memory delegation and streaming delegation are quite similar. In both settings Alice asks the cloud to store a huge object (either her memory or the streaming data). There are two main differences between the two: (1) In the setting of streaming delegation, the certificates and updates must be computed in a streaming manner. Thus, in this sense, constructing streaming delegation schemes may be harder than constructing memory delegation schemes. Indeed, our streaming delegation scheme is more complicated than our memory delegation scheme, and proving soundness in the streaming setting is significantly harder than proving soundness in the memory setting. (2) In the setting of streaming delegation, the memory is updated by simply adding elements to it. This is in contrast to the setting of memory delegation, where the memory can be updated in arbitrary ways, depending on the user's needs. However, in the memory setting, we allow the delegator to use the help of the worker when updating her certificate (or secret state), whereas in the streaming setting we require that the delegator updates her certificate on her own. The reason for this discrepancy, is that in the memory setting the delegator may not be able to update her certificate on her own, since she may want to update her memory in involved ways (such as, erase all emails from Bob). On the other hand, in the streaming setting, it seems essential that the delegator updates her certificate on her own, since in this setting the data may be streaming by very quickly, and there may not be enough time for the delegator and worker to interact during each update.</p>

    <h2 id="sec-3" class="text-2xl font-bold">1.1 Our Results</h2>

    <p class="text-gray-300">We construct both memory delegation and streaming delegation schemes. The memory delegation scheme consists of an offline phase, where the delegator D delegates her memory x ∈ {0, 1} n to a worker W. This phase is non-interactive, where the delegator sends a single message, which includes her memory content x to the worker W. The runtime of both the delegator and the worker in the offline phase is poly(n), where n is the memory size. At the end of this phase, the delegator saves a short certificate σ of her memory, which she will later use when verifying delegation proofs.</p>

    <p class="text-gray-300">The streaming delegation scheme, on the other hand, doesn't have such an offline phase. In the streaming setting, we consider the scenario where at each time unit t a bit x&lt;sup&gt;t&lt;/sup&gt; is being streamed. The delegator starts with some secret state (or certificate) σ0, and at time unit t + 1 she uses her secret state σ&lt;sup&gt;t&lt;/sup&gt; and the current bit xt+1 being streamed, to efficiently update her secret state from σ&lt;sup&gt;t&lt;/sup&gt; to σt+1.</p>

    <p class="text-gray-300">In both settings, each time the delegator D wants the worker W to compute a function f(x), they run a delegation protocol, which we denote by Compute(f). The memory delegation scheme also has an Update protocol, where the delegator D asks the worker W to update her memory and to help her update her secret state σ. The latter can be thought of as a delegation request, and the guarantees (in term of runtime and communication complexity) are similar to the guarantees of the Compute protocol.</p>

    <p class="text-gray-300">In the streaming setting, the delegator updates her secret state on her own in time polylog(N), where N is an upper bound on the length of the stream. Namely, the update function, that takes as input a certificate σ&lt;sup&gt;t&lt;/sup&gt; and a bit xt+1, and outputs a new certificate σt+1, can be computed in time polylog(N).</p>

    <p class="text-gray-300">We present two memory and streaming delegation protocols. The first are non-interactive (i.e, Compute(f) consists of two messages, the first sent by the delegator and the second sent by the worker). They are based on the non-interactive version of the delegation protocol of Goldwasser et. al. <a href="#page-66-0">[GKR08,</a> <a href="#page-66-1">KR09]</a>, denoted by GKR (though are significantly more complicated than merely running GKR). As in GKR, the efficiency of the delegator depends linearly on the depth of the circuit being delegated. Our second memory and streaming delegation protocols are interactive (i.e., Compute(f) consists of four messages). These schemes are based on CS-proofs of Micali <a href="#page-66-2">[Mic94]</a>, and allow for efficient delegation of all functions in P.</p>

    <p class="text-gray-300">In what follows we state our theorems formally. We refer the reader to Section <a href="#page-26-0">6</a> for the formal definition of a memory delegation scheme, and to Section <a href="#page-38-0">8</a> for the formal definition of a streaming delegation scheme.</p>

    <p class="text-gray-300">Theorem 1 (Memory Delegation) Assume the existence of a poly-log PIR scheme(as defined in Definition <a href="#page-12-0">5)</a>, and assume the existence of a collision resistant hash family. Let F be the class of all L-uniform poly-size boolean circuits. Then there exists a non-interactive (2-message) memory delegation scheme mDel, for delegating any function f ∈ F. The delegation scheme, mDel has the following properties, for security parameter k.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The scheme has perfect completeness and negligible (reusable) soundness error.</li>
      <li>The delegator and worker are efficient in the offline stage; i.e., both the delegator and the worker run in time poly(k, n).</li>
      <li>The worker is efficient in the online phase. More specifically, it runs in time poly(k, S) during each Compute(f) and Update(f) operation, where S is the size of the L-uniform circuit computing f. The delegator runs in time poly(k, d) during each Compute(f) and Update(f) operation, where d is the depth<a href="#page-3-0">1</a> of the L-uniform circuit computing f. <a href="#page-3-1">2</a></li>
    </ul>

    <p class="text-gray-300">In particular, assuming the existence of a poly-logarithmic PIR scheme, and assuming the existence of a collision resistent hash family, we obtain a memory delegation scheme for L-uniform NC computations, where the delegator D runs in time poly-logarithmic in the length of the memory.</p>

    <p class="text-gray-300">Theorem 2 (Streaming Delegation) Let k be a security parameter, and let N be a parameter (an upper bound on the length of the stream). Let F be the class of all L-uniform poly-size boolean circuits. Assume the existence of a fully-homomorphic encryption scheme secure against poly(N) size adversaries. Then there exists a non-interactive (2-message) streaming delegation scheme sDel&lt;sup&gt;F&lt;/sup&gt; for F with the following properties.</p>

    <p class="text-gray-300">• sDel&lt;sup&gt;F&lt;/sup&gt; has perfect completeness and negligible reusable soundness error.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-3-1&quot;&gt;&lt;/span&gt;&lt;span id=&quot;page-3-0&quot;&gt;&lt;/span&gt;&lt;sup&gt;1&lt;/sup&gt;We assume that d ≥ log n.</p>

    <p class="text-gray-300">&lt;sup&gt;2&lt;/sup&gt;Thus, for every constant c ∈ N, if we restrict the depth of f to be at most k c , then the delegator is considered efficient.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D updates her secret state in time polylog(N), per data item.</li>
      <li>In the delegation protocol, when delegating a function f ∈ F computable by an L-uniform circuit of size S and depth d, the delegator D runs in time poly(k, d, log N), and the worker W runs in time poly(k, log N, S).</li>
    </ul>

    <p class="text-gray-300">In particular, assuming the existence of a fully-homomorphic encryption scheme secure against adversaries of size poly(N), we obtain a streaming delegation scheme for L-uniform NC computations, where the delegator D runs in time poly-logarithmic in the length of data stream.</p>

    <p class="text-gray-300">Remark. We note that the property we needed from the GKR protocol is that the verifier does not need to read the entire input in order to verify, but rather only needs to access a single random point in the low-degree extension of the input. (We refer the reader to Section <a href="#page-13-0">3.3</a> for the definition and properties of a low-degree extension.) We note that the CS-proof delegation scheme of Micali <a href="#page-66-2">[Mic94]</a>, for delegating the computation of (uniform) Turing machines, also has the property that verification can be done by only accessing a few random points in the low-degree extension of the input, assuming the underlying PCP is a PCP of Proximity <a href="#page-65-1">[BSGH</a>+05, <a href="#page-65-2">DR06]</a>.</p>

    <p class="text-gray-300">Indeed using this delegation scheme, we get a memory delegation scheme and a streaming delegation scheme for all of P. Using this scheme, the Compute(f) protocol is interactive (i.e., it is a 4-message protocol). The runtime of the delegator is polylog(T) and the runtime of the worker is poly(T), where T is the runtime of the Turing machine computing the function f. <a href="#page-4-0">3</a> Furthermore, the memory delegation scheme relies only on the existence of a collision resistant hash family, without the need of a poly-log PIR scheme.</p>

    <p class="text-gray-300">Theorem 3 (Interactive Memory Delegation) Assume the existence of a collision resistant hash family. Then there exists a memory delegation scheme mDel, for delegating any function computable by a polynomial-time Turning machine. The delegation scheme, mDel has the following properties, for security parameter k.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The scheme has perfect completeness and negligible (reusable) soundness error.</li>
      <li>The delegator and worker are efficient in the offline stage; i.e., both the delegator and the worker run in time poly(k, n).</li>
      <li>The worker is efficient in the online phase. More specifically, it runs in time poly(k, T) during each Compute(f) and Update(f) operation, where T is an upper-bound on the running time of f. The delegator runs in time poly(k, log T) during each Compute(f) and Update(f) operation.</li>
      <li>Both Compute(f) and Update(f) operations consist of 4 message exchanges.</li>
    </ul>

    <p class="text-gray-300">Theorem 4 (Interactive Streaming Delegation) Let k be a security parameter, and let N be a parameter (an upper bound on the length of the stream). Let F be the class of all functions computable by a polynomial-time Turning machine. Assume the existence of a fully-homomorphic encryption scheme secure against poly(N)-size adversaries. Then there exists a streaming delegation scheme sDel&lt;sup&gt;F&lt;/sup&gt; for F with the following properties.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-4-0&quot;&gt;&lt;/span&gt;&lt;sup&gt;3&lt;/sup&gt;We assume that T ≥ n.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>sDel&lt;sup&gt;F&lt;/sup&gt; has perfect completeness and negligible reusable soundness error.</li>
      <li>D updates her secret state in time polylog(N), per data item.</li>
      <li>In the delegation protocol, when delegating a function f ∈ F computable in time T, the delegator D runs in time poly(k, log N, log T), and the worker W runs in time poly(k, log N, T). The delegation protocol consists of 4 message exchanges.</li>
    </ul>

    <p class="text-gray-300">We note that in the Random Oracle Model (ROM) <a href="#page-65-3">[BR97]</a>, the delegation scheme of Micali is non-interactive. This yields a non-interactive memory delegation scheme and a non-interactive streaming delegation scheme, for delegating all functions in P, in the ROM.</p>

    <h2 id="sec-4" class="text-2xl font-bold">&lt;span id=&quot;page-5-0&quot;&gt;&lt;/span&gt;1.2 Previous Work</h2>

    <p class="text-gray-300">Various delegation protocols have been proposed in the literature. Some provide delegation protocols that are sound against any cheating worker, whereas others provide delegation protocols that are secure only against computationally bounded cheating worker (i.e., arguments as opposed to proofs). Some of these protocols are interactive, whereas others are non-interactive. We survey some of these results below, however, we emphasize that in all these solutions, the delegator runs in time that is (at least) linear in the input size, and thus do not apply to our settings of memory delegation or streaming delegation.</p>

    <p class="text-gray-300">Interactive proofs. The celebrated IP=PSPACE Theorem <a href="#page-66-3">[LFKN92,</a> <a href="#page-66-4">Sha92]</a> yields interactive proofs for any function f computable in polynomial space, with a verifier (delegator) running in polynomial time. Thus, the IP=PSPACE protocol can be seen as a delegation protocol for languages in PSPACE. However, the complexity of the prover (worker) is only bounded by polynomial space (and hence exponential time). This theorem was refined and scaled down in <a href="#page-65-4">[FL93]</a> to give verifier complexity poly(n, s) and prover complexity 2poly(s) for functions f computable in time T and space s, on inputs of length n. Note that the prover complexity is still super-polynomial in T, even for computations that run in the smallest possible space, namely s = O(log T).</p>

    <p class="text-gray-300">The prover complexity was recently improved by Goldwasser et al. <a href="#page-66-0">[GKR08]</a> to poly(T, 2 s ), which is poly(T) when s = O(log T). More generally, Goldwasser et al. <a href="#page-66-0">[GKR08]</a> give interactive proofs for computations of small depth d (i.e. parallel time). For these, they achieve prover complexity poly(T) and verifier complexity poly(n, d, log T). (This implies the result for space-bounded computation because an algorithm that runs in time T and space s can be converted into one that runs in time poly(T, 2 s ) and depth d = O(s 2 ).) However, if we do not restrict to computations of small space or depth, then we cannot use interactive proofs. Indeed, any language that has an interactive proof with verifier running time (and hence communication) T&lt;sup&gt;V&lt;/sup&gt; can be decided in space poly(n, T&lt;sup&gt;V&lt;/sup&gt; ).</p>

    <p class="text-gray-300">Interactive arguments. Interactive arguments <a href="#page-64-0">[BCC88]</a> (aka computationally sound proofs <a href="#page-66-5">[Mic00]</a>) relax the soundness condition to be computational. Namely, instead of requiring that no prover strategy whatsoever can convince the verifier of a false statement, we instead require that no computationally feasible prover strategy can convince the verifier of a false statement. In this model, Kilian <a href="#page-66-6">[Kil92]</a> and Micali <a href="#page-66-5">[Mic00]</a> gave constant-round protocols with prover complexity poly(T, k) and verifier complexity poly(n, k, log T) (where k is the security parameter), assuming the existence of collision-resistant hash functions <a href="#page-64-1">[BG02]</a>.</p>

    <p class="text-gray-300">Toward non-interactive Solutions. This possibility of efficient non-interactive arguments was suggested by Micali <a href="#page-66-5">[Mic00]</a>, who showed that non-interactive arguments with prover complexity poly(T, k) and verifier complexity poly(n, k, log T) are possible in the Random Oracle Model (the oracle is used to eliminate interaction a la Fiat–Shamir <a href="#page-65-5">[FS86]</a>). Heuristically, one might hope that by instantiating the random oracle with an appropriate family of hash functions, we could obtain a non-interactive solution to delegating computation: first the delegator (or a trusted third party) chooses and publishes a random hash function from the family, and then, the proofs are completely non-interactive (just one message from the prover to the verifier). However, the Random Oracle Heuristic is known to be unsound in general <a href="#page-65-6">[CGH04]</a> and even in the context of Fiat– Shamir <a href="#page-64-2">[Bar01,</a> <a href="#page-66-7">GK03]</a>. Thus, despite extensive effort, the existence of efficient non-interactive arguments remains a significant open problem in complexity and cryptography.</p>

    <p class="text-gray-300">There has been some recent progress in reducing the amount of interaction needed. Using a transformation of Kalai and Raz <a href="#page-66-1">[KR09]</a>, the GKR delegation protocol <a href="#page-66-0">[GKR08]</a> can be converted into a 2-message argument (assuming the existence of single-server private-information retrieval (PIR) schemes). However, like the interactive proofs of <a href="#page-66-0">[GKR08]</a>, this solution applies only to small-depth computations, as the verifier's complexity grows linearly with the depth.</p>

    <p class="text-gray-300">Very recently, Gennaro, Gentry, and Parno <a href="#page-65-7">[GGP10]</a>, and the followup work of Chung, Kalai, and Vadhan <a href="#page-65-8">[CKV10]</a>, gave a 2-message delegation scheme for arbitrary functions. However, these constructions have an offline phase, where the delegator invests time poly(T, k) and computes a secret state (T is the time it takes to compute the function, and k is the security parameter). In the online phase, the delegator's running time is reduced to poly(n, k, log T) for an input of length n, and the worker's complexity is poly(T, k). Thus, the delegator's large investment in the offline phase can be amortized over many executions of the online phase to delegate the computation of f on many inputs. Their online phase is not completely non-interactive, but rather consists of two messages. However, in many applications, two messages will be necessary anyway, as the delegator may need to communicate the input x to the worker.</p>

    <p class="text-gray-300">We remark that one main drawback of these works <a href="#page-65-7">[GGP10,</a> <a href="#page-65-8">CKV10]</a> is that soundness is only guaranteed as long as the adversarial worker does not learn whether the delegator accepted or rejected the proofs.</p>

    <p class="text-gray-300">In another followup work, Applebaum, Ishai, and Kushilevitz <a href="#page-64-3">[AIK10]</a> also consider the offline/online setting, but focus on efficient solutions for one-time delegation (i.e., the online phase can only be executed one time). They also consider the case when the delegation functions are represented as arithmetic circuits.</p>

    <p class="text-gray-300">PCPs and MIPs. The MIP=NEXP Theorem <a href="#page-64-4">[BFL91]</a> and its scaled-down version by Babai et al. <a href="#page-64-5">[BFLS91]</a> yield multi-prover interactive proofs and probabilistically checkable proofs for time T computations with a prover running in time poly(T) and a verifier running in time poly(n, log T), exactly as we want. However, using these for delegation require specialized communication models — either 2 non-communicating provers, or a mechanism for the prover to give the verifier random access to a long PCP (of length poly(T)) that cannot be changed by the prover during the verification.</p>

    <p class="text-gray-300">Streaming Interactive Proofs. Recently, Cormode, Thaler, and Yi <a href="#page-65-9">[CTY10]</a> considered streaming interactive proofs, which is a strengthening of interactive proofs where the input is given to the verifier in a streaming manner and the verifier is restricted to have sub-linear (ideally, polylogarithmic) space. They observed that both the GKR protocol <a href="#page-66-0">[GKR08]</a> and universal arguments <a href="#page-64-1">[BG02]</a> can be modified to yield efficient streaming interactive proofs/arguments.</p>

    <p class="text-gray-300">Streaming interactive proofs are closely related to streaming delegation. The main difference is that streaming interactive proofs correspond to one-time streaming delegation, whereas in our streaming delegation model, the delegator is allowed to delegate as many computations to the worker as she want. Indeed, the GKR protocol is also the starting point of our construction of streaming delegation scheme, and the main effort is to make the scheme reusable.</p>

    <h2 id="sec-5" class="text-2xl font-bold">2 Overview of Our Constructions</h2>

    <p class="text-gray-300">In what follows we present the high-level overview of our constructions. For more elaborate overviews, we refer the reader to Section <a href="#page-29-0">7.1</a> for an overview of our memory delegation scheme, and to Section <a href="#page-42-0">9.1</a> for an overview of our streaming delegation scheme.</p>

    <h2 id="sec-6" class="text-2xl font-bold">&lt;span id=&quot;page-7-0&quot;&gt;&lt;/span&gt;2.1 Overview of our Memory Delegation Scheme</h2>

    <p class="text-gray-300">The starting point of this work is the observation of Goldwasswer et. al. <a href="#page-66-0">[GKR08]</a>, that their delegation protocol can be verified very efficiently (in time sub-linear in the input size), if the delegator has oracle access to the low-degree extension of the input x (we refer the reader to Section <a href="#page-13-0">3.3</a> for the definition of a low-degree extension). Moreover, as observed by <a href="#page-66-0">[GKR08]</a>, the delegator needs to access this low-degree extension LDE&lt;sup&gt;x&lt;/sup&gt; at a single point z, which depends only on the random coin tosses of the delegator.</p>

    <p class="text-gray-300">This observation immediately gives rise to a memory delegation scheme with one-time soundness: The delegator's secret state will be (z, LDEx(z)). Then, she will use this secret state in order to verify computation using the GKR protocol. As was argued by Goldwasswer et. al., this indeed works if the delegator runs the delegation protocol once. However, the soundness crucially relies on the fact that the delegator's secret state is indeed secret, and if the delegator uses this state more than once, then soundness breaks completely.</p>

    <p class="text-gray-300">One idea, following the idea of Gennaro et. al. <a href="#page-65-7">[GGP10]</a>, is to use a fully homomorphic encryption (FHE) scheme to encrypt all the communication, in order to hide the secret state. This indeed works if the worker does not learn whether the delegator accepts or rejects his proofs. However, if the worker does learn the verdict of the delegator, then there are known attacks that break soundness.</p>

    <p class="text-gray-300">In the streaming setting, we follow this approach, and we succeed in overcoming this problem, and construct a scheme that is sound even if the worker does learn the verdict of the delegator. We could follow this approach in the memory delegation setting as well. However, for several reasons, we choose to take a different approach. First, the approach above relies on the existence of an FHE scheme, whereas our memory delegation scheme relies on the existence of a poly-logarithmic PIR scheme (see Definition <a href="#page-12-0">5)</a>, arguably a more reasonable assumption. Second, the approach above results with the delegator having a secret state, whereas in our memory delegation scheme, the state of the delegator is public. Finally, the construction and proof of the memory delegation scheme is simpler.</p>

    <p class="text-gray-300">In our approach, instead of having (z, LDEx(z)) as the delegator's secret state, the delegator keeps a tree-commitment of the entire LDE&lt;sup&gt;x&lt;/sup&gt; as her secret state (see Section <a href="#page-15-0">3.5</a> for the definition of a tree-commitment). Namely, she chooses a random hash function h from a collision-resistant hash family, and keeps (h, Th(LDEx)) as her state. In addition to giving the worker her memory x, she also gives him the hash function h. We stress that her state is not secret, which makes the proof of security significantly simpler than that in the streaming setting (where the delegator's state is secret).</p>

    <p class="text-gray-300">Very roughly speaking, when the delegator wishes to delegate the computation of a function f, they execute Compute(f) by simply running the (non-interactive) delegation protocol GKR(f). Recall that at the end of the GKR protocol the delegator needs to verify the value of LDEx(r) for a random r. However, she doesn't have x, since it was delegated to the prover, and all she has is the state (h, Th(LDEx)). So, rather than computing the value of LDEx(r) on her own, the worker will reveal this value, by sending the augmented path in the Merkle tree corresponding to the leaf r.</p>

    <p class="text-gray-300">Unfortunately the high-level description given above is a gross oversimplification of our actual scheme, and there are several technical issues that complicate matters. We elaborate on these in Section <a href="#page-11-0">2.3.</a></p>

    <p class="text-gray-300">We mention that when the delegator wishes to update her memory from x to g(x), she needs to update her secret state from (h, Th(LDEx)) to (h, Th(LDEg(x) )).<a href="#page-8-0">4</a> However, she cannot perform this operation on her own, since she does not have x. Instead she will delegate this computation to the worker, by requesting a Compute(g 0 ) operation, where g 0 (x) = Th(LDEg(x) ).</p>

    <h2 id="sec-7" class="text-2xl font-bold">&lt;span id=&quot;page-8-1&quot;&gt;&lt;/span&gt;2.2 Overview of our Streaming Delegation Scheme</h2>

    <p class="text-gray-300">Our streaming delegation scheme is similar to our memory delegation scheme described above, and the main difference is in the way the certificate is generated and updated, and in the way the worker reveals the value LDEx(r).</p>

    <p class="text-gray-300">Generating and updating the certificate. Recall that in the memory delegation scheme, the certificate of the delegator D consists of a tree-commitment to the low-degree extension of her memory x. Namely, her certificate is (h, Th(LDEx)), where h is a collision resistant hash function. Note that this certificate cannot be updated in a streaming manner, since any change to x changes the low-degree extension LDE&lt;sup&gt;x&lt;/sup&gt; almost everywhere.</p>

    <p class="text-gray-300">Instead, in the streaming setting, we replace the tree commitment with an &quot;algebraic commitment&quot;, which has the property that it can be updated efficiently when new data items arrive. The resulting certificate is a random point in the low-degree extension of the stream x; i.e., (z, LDEx(z)) for a random point z. This certificate is efficiently updatable, if we assume some upper-bound N on the size of the stream, and we take parameters H, F, m of the low-degree extension, such that</p>

    <p class="text-gray-300"><span class="math">$|\\mathbb{H}| = \\text{polylog}(N), \\ m = \\theta\\left(\\frac{\\log N}{\\log\\log N}\\right), \\ |\\mathbb{F}| = \\text{poly}(|\\mathbb{H}|)</span>$
(1)</p>

    <p class="text-gray-300">(this follows from Proposition <a href="#page-14-0">6)</a>.</p>

    <p class="text-gray-300">As in the memory delegation scheme, at the end of each delegation protocol, the delegator needs to verify the value of LDEx(r) at a random point r. In the memory delegation scheme this was done using a Reveal protocol where the worker reveals the augmented path of the leaf r in the Merkle tree-commitment of LDEx. In the streaming setting, the Reveal protocol is totally different, since</p>

    <p class="text-gray-300">&lt;span id=&quot;page-8-0&quot;&gt;&lt;/span&gt;&lt;sup&gt;4&lt;/sup&gt;Actually, for technical reasons she will need to choose a fresh hash function h &lt;sup&gt;0&lt;/sup&gt; ← H during each Update. We discard this technical issue here.</p>

    <p class="text-gray-300">the delegator cannot compute the tree-commitment of  <span class="math">LDE_x</span> . Unfortunately, unlike in the memory delegation scheme, in the streaming setting constructing a <em>reusable</em> and <em>sound</em> reveal protocol is highly non-trivial.</p>

    <p class="text-gray-300">The Reveal protocol. Our starting point is a basic reveal protocol Reveal&lt;sub&gt;1&lt;/sub&gt; described in Figure 1. Note that the soundness of Reveal&lt;sub&gt;1&lt;/sub&gt; relies on the secrecy of the certificate  <span class="math">\\sigma</span> . Namely, assuming that W does not know the point z, it is not hard to see, by the Schwartz-Zippel Lemma, that an adversarial worker can cheat with probability at most  <span class="math">d/|\\mathbb{F}|</span> , where d is the (total) degree of LDE&lt;sub&gt;x&lt;/sub&gt;.</p>

    <p class="text-gray-300">Reveal&lt;sub&gt;1&lt;/sub&gt; protocol: D stores a secret state  <span class="math">\\sigma = (z, \\text{LDE}_x(z))</span> , where  <span class="math">x \\in \\{0, 1\\}^N</span>  and z is a random point in  <span class="math">\\mathbb{F}^m</span> , and wants to learn the value of  <span class="math">\\text{LDE}_x(s)</span>  from W.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D sends to W the line  <span class="math">\\ell_{sz}</span>  that passes through the points s and z. More specifically, D chooses two random points  <span class="math">\\alpha_1, \\alpha_2 \\leftarrow \\mathbb{F}</span> , and defines  <span class="math">\\ell_{s,z}</span>  to be the line that satisfies  <span class="math">\\ell_{s,z}(\\alpha_1) = z</span>  and  <span class="math">\\ell_{s,z}(\\alpha_2) = s</span> .</li>
      <li>W returns a univariate polynomial  <span class="math">p : \\mathbb{F} \\to \\mathbb{F}</span> , which is the polynomial LDE&lt;sub&gt;x&lt;/sub&gt; restricted to the line  <span class="math">\\ell_{s,z}</span>  (i.e.,  <span class="math">p = \\text{LDE}_x|_{\\ell_{s,z}}</span> ).</li>
      <li>D checks whether  <span class="math">p(\\alpha_1) = \\text{LDE}_x(z)</span> , and if so accepts the value  <span class="math">p(\\alpha_2) = \\text{LDE}_x(s)</span> . Otherwise, she rejects.</li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-9-0&quot;&gt;&lt;/span&gt;Figure 1: Reveal&lt;sub&gt;1&lt;/sub&gt; protocol</p>

    <p class="text-gray-300">However, note that the Reveal&lt;sub&gt;1&lt;/sub&gt; protocol is not reusable. Suppose that D uses the above reveal protocol to learn the value of  <span class="math">LDE_x</span>  on two random points  <span class="math">s, s&#x27; \\in \\mathbb{F}^m</span> . From the two executions, an adversarial worker W* receives two lines  <span class="math">\\ell_{s,z}</span>  and  <span class="math">\\ell_{s&#x27;,z}</span> , and can learn the secret point z by taking the intersection of the two lines. Once W* learns z, W* can easily cheat by returning any polynomial  <span class="math">p^*</span>  that agrees with  <span class="math">LDE_x</span>  only on point z but disagrees on the remaining points.</p>

    <p class="text-gray-300">As observed by Gennaro et. al. [GGP10], a natural way to protect the secret point z, is to run the above Reveal protocol under a fully-homomorphic encryption (FHE) scheme. Namely, D generates a pair of keys (pk, sk) for a FHE (Gen, Enc, Dec, Eval), and sends pk and an encrypted line  <span class="math">\\hat{\\ell}_{s,z} = \\text{Enc}_{pk}(\\ell_{s,z})</span>  to W, who can compute the polynomial  <span class="math">p = \\text{LDE}_x|_{\\ell_{s,z}}</span>  homomorphically under the encryption. Indeed, by the semantic security of FHE, an adversarial worker W* cannot learn any information from D's message  <span class="math">\\hat{\\ell}_{s,z}</span> . This indeed makes the protocol reusable provided that W* does not learn the decision bits of D, as proved in [GGP10, CKV10].</p>

    <p class="text-gray-300">However, since the decision bit of D can potentially contain one bit information about the secret point z, it is not clear that security holds if W* learns these decision bits. In fact, for both of the delegation schemes of [GGP10, CKV10], which use FHE to hide the delegator D's secret state, there are known attacks that learn the whole secret state of D bit-by-bit from D's decision bits.</p>

    <p class="text-gray-300">Fortunately, we are able to show that a variant of the Reveal&lt;sub&gt;1&lt;/sub&gt; protocol described in Figure 2 is reusable even if  <span class="math">W^*</span>  learns the decision bits of D. The main difference between Reveal&lt;sub&gt;1&lt;/sub&gt; and Reveal&lt;sub&gt;2&lt;/sub&gt; is that in Reveal&lt;sub&gt;2&lt;/sub&gt;, the delegator D uses a random two-dimensional affine subspace instead of a line, and uses an FHE to mask the entire protocol.</p>

    <p class="text-gray-300">We prove that no efficient adversarial  <span class="math">W^*</span>  can learn useful information about the secret point z from the Reveal&lt;sub&gt;2&lt;/sub&gt; protocol. We note that the proof of the above statement is highly non-trivial,</p>

    <p class="text-gray-300">Reveal&lt;sub&gt;2&lt;/sub&gt; protocol: D stores a secret state  <span class="math">\\sigma = (z, \\text{LDE}_x(z))</span> , where  <span class="math">x \\in \\{0, 1\\}^N</span>  and z is a random point in  <span class="math">\\mathbb{F}^m</span> , and wants to learn the value of  <span class="math">\\text{LDE}_x(s)</span>  from W.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D does the following.    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Generate a pair of keys  <span class="math">(pk, sk) \\leftarrow \\text{Gen}(1^k)</span>  for a fully homomorphic encryption scheme FHE.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Choose a random two-dimensional affine subspace  <span class="math">S_{s,z} \\subset \\mathbb{F}^m</span>  that contains the points s and z. More specifically, choose two random points  <span class="math">\\alpha_1, \\alpha_2 \\leftarrow \\mathbb{F}^2</span>  and let  <span class="math">S_{s,z} \\subset \\mathbb{F}^m</span>  be a random two-dimensional affine subspace that satisfies  <span class="math">S_{s,z}(\\alpha_1) = z</span>  and  <span class="math">S_{s,z}(\\alpha_2) = s</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Send  <span class="math">\\hat{S}_{s,z} \\leftarrow \\operatorname{Enc}_{\\mathsf{pk}}(S_{s,z})</span>  and  <span class="math">\\mathsf{pk}</span>  to  <span class="math">\\mathsf{W}</span> .</li>
    </ol></li>
    </ul></li>
      <li>W homomorphically computes the two-variate polynomial  <span class="math">p = \\text{LDE}_x|_{S_{s,z}}</span>  under the FHE (denote the resulting ciphertext  <span class="math">\\hat{p}</span> ), and sends  <span class="math">\\hat{p}</span>  to D.</li>
      <li>D decrypts and checks whether  <span class="math">p(\\alpha_1) = \\text{LDE}_x(z)</span> , and if so accepts the value  <span class="math">p(\\alpha_2) = \\text{LDE}_x(s)</span> .</li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-10-0&quot;&gt;&lt;/span&gt;Figure 2: Protocol Reveal&lt;sub&gt;2&lt;/sub&gt;</p>

    <p class="text-gray-300">and is one of the main technical difficulties in this work. Informally, the proof first uses Lemma 16, which claims that the ciphertext  <span class="math">\\hat{S}_{s,z}</span>  and the decision bit b of D (which depend on the strategy of  <span class="math">W^*</span> ) do not give too much information about  <span class="math">S_{s,z}</span>  to  <span class="math">W^*</span> . In other words, the random subspace  <span class="math">S_{s,z}</span>  still has high (pseudo-)entropy from the point of view of  <span class="math">W^*</span> . Then it uses an <em>information-theoretic</em> argument to argue that a random point z in a sufficiently random (with high entropy) subspace  <span class="math">S_{s,z}</span>  is statistically close to a random point in  <span class="math">\\mathbb{F}^m</span> , which implies that  <span class="math">W^*</span>  does not learn useful information about z. We refer the reader to Section 4 for the techniques developed in order to prove the reusable soundness.</p>

    <p class="text-gray-300"><strong>The Field Size.</strong> Recall that by Schwartz-Zippel Lemma, an adversarial worker can cheat with probability at most  <span class="math">d/|\\mathbb{F}|</span> , where d is the (total) degree of  <span class="math">LDE_x</span> . Recall that in our setting of parameters:</p>

    <p class="text-gray-300"><span class="math">$|\\mathbb{H}| = \\text{polylog}(N), \\ m = \\theta\\left(\\frac{\\log N}{\\log\\log N}\\right), \\ |\\mathbb{F}| = \\text{poly}(|\\mathbb{H}|).</span>$</p>

    <p class="text-gray-300">Thus, a cheating worker can cheat (and more importantly, obtain information about the secret z) with probability  <span class="math">d/|\\mathbb{F}| = O(1/\\text{polylog}(N))</span> , which is not low enough.</p>

    <p class="text-gray-300">The idea is to reduce the cheating probability to negligible by simply increasing the field size to be super-polynomial. However, we cannot increase the field size in the GKR protocol, since it will increase the complexity of the worker. Instead, we use an extension field  <span class="math">\\tilde{\\mathbb{F}}</span>  of  <span class="math">\\mathbb{F}</span> , of super-polynomial size, only in the certificate and the Reveal protocol, but run the GKR protocols as before. Namely, the secret state is  <span class="math">\\sigma = (z, \\text{LDE}^{\\tilde{\\mathbb{F}}, \\mathbb{H}, m}(z))</span>  where  <span class="math">z \\leftarrow \\tilde{\\mathbb{F}}^m</span> , The GKR protocol is run exactly as before with the parameters  <span class="math">(\\mathbb{H}, \\mathbb{F}, m)</span> .</p>

    <h4 id="sec-8" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-11-0&quot;&gt;&lt;/span&gt;2.3 Additional Technicalities</h4>

    <p class="text-gray-300">The high-level description given above (in Sections 2.1 and 2.2) is a gross oversimplification of our actual schemes, and there are several technical issues that complicate matters.</p>

    <p class="text-gray-300">Recall that in the overview above, we claimed that Compute(f) merely runs GKR, in addition to a Reveal protocol which helps the delegator verify the GKR protocol.&lt;sup&gt;5&lt;/sup&gt; There are several technical reasons why this actually does not work. In what follows, we explain what are the main technical problems with this simple idea, and we give the highlevel idea of how to overcome these problems.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The first technicality (the easiest one to deal with), is that the GKR delegation scheme does not have a negligible soundness error. In our setting, especially in the setting of memory delegation, it is very important to have negligible soundness. The reason is that if the soundness is non-negligible, then a cheating worker may cheat in the update procedure of the memory delegation scheme (which is also being delegated). The problem is that if a worker cheats even once in an update procedure, all soundness guarantees are mute from that point on. So, we really need the soundness error to be negligible. In order to reduce the soundness error, we will run the GKR protocol in parallel u times (for any parameter u such that  <span class="math">1/2^u = ngl(k)</span> , where k is the security parameter). We denote the u-fold parallel repetition of GKR by GKR&lt;sup&gt;(u)&lt;/sup&gt;. As a result the worker will need to reveal to u random points in the low-degree extension:  <span class="math">LDE_x(r_1), \\ldots, LDE_x(r_u)</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The second technical point is more subtle. In the offline stage, when the delegator computes the tree commitment  <span class="math">T_h(LDE_x)</span> , she needs to choose the parameters  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span>  for the low-degree extension. The typical choice for these parameters is:</li>
    </ol></li>
    </ul>

    <p class="text-gray-300"><span class="math">$|\\mathbb{H}| = \\text{polylog}(n), \\ |\\mathbb{F}| = \\text{poly}(|\\mathbb{H}|), \\ m = O\\left(\\frac{\\log n}{\\log \\log n}\\right),</span>$</p>

    <p class="text-gray-300">where n = |x|. When delegating the computation of a function f, the worker and delegator run  <span class="math">GKR^{(u)}(f)</span>  and need to verify  <span class="math">LDE_x(r_i) = v_i</span>  for random points  <span class="math">r_1, \\ldots, r_u</span> . However, here the parameters of the low-degree extension  <span class="math">LDE_x</span>  depend on the depth d of the circuit computing f. Namely, looking at the parameters given in [GKR08] (see Theorem 8), the parameters of the low-degree extension are</p>

    <p class="text-gray-300"><span class="math">$|\\mathbb{H}&#x27;| = \\theta(d \\cdot \\log n), \\ m&#x27; = \\theta\\left(\\frac{\\log n}{\\log d}\\right), \\ |\\mathbb{F}&#x27;| = \\text{poly}(|\\mathbb{H}&#x27;|).</span>$</p>

    <p class="text-gray-300">Therefore, the worker cannot simply execute the Reveal protocols of the memory delegation or the streaming delegation. In the memory setting, the tree commitment is w.r.t. parameters  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span>  whereas the delegator needs to verify  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i) = v_i</span> . In the streaming setting, the secret state of the delegator is  <span class="math">(z,\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z))</span> , as opposed to  <span class="math">(z,\\mathrm{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(z))</span> , thus the Reveal protocol described in Section 2.2 doesn't work.</p>

    <p class="text-gray-300">We get around this technical problem by delegating the functions  <span class="math">g_{r_i}(x) \\triangleq \\text{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span> . Luckily, these functions can be computed by a poly-size circuit of depth at most  <span class="math">\\log^2 n</span> , assuming the delegated function f is of poly-size (see Proposition 6). We delegate the computation</p>

    <p class="text-gray-300">&lt;span id=&quot;page-11-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;5&lt;/sup&gt;The Reveal protocol in the memory setting is totally different from the Reveal protocol in the streaming setting.</p>

    <p class="text-gray-300">of each of these  <span class="math">g_{r_i}</span>  using GKR&lt;sup&gt;(u)&lt;/sup&gt; to ensure negligible soundness. Thus, finally the worker will need to reveal to  <span class="math">u^2</span>  points in LDE&lt;sub&gt;x&lt;/sub&gt; (u points for each  <span class="math">g_{r_i}</span> ).&lt;sup&gt;6&lt;/sup&gt;</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The final technical difficulty is that all these algorithms need to run in parallel, since we want our final delegation schemes to be non-interactive (i.e., to consist of only two messages). Typically, there is no problem in running several two-message protocols in parallel [BIN97, CHS05]. However, in our case, the delegator uses a common secret input in these protocols. Namely, the delegator uses secret randomness  <span class="math">r_1, \\ldots, r_u \\in (\\mathbb{F}&#x27;)^{m&#x27;}</span>  in the parallel repetition of the delegation protocol GKR(f) which ends with her needing to verify that  <span class="math">LDE_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i) = v_i</span>  for every  <span class="math">i \\in [u]</span> . In addition she uses these same  <span class="math">r_i</span> 's in the delegation protocols  <span class="math">GKR(g_{r_i})</span> . Moreover, at the end of each of the  <span class="math">GKR(g_{r_i})</span>  protocols, the delegator needs to verify that  <span class="math">LDE_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j}) = w_{i,j}</span>  for random points  <span class="math">z_{i,1},\\ldots,z_{i,u} \\in \\mathbb{F}^m</span> . Finally, they also run a reveal protocol for each  <span class="math">z_{i,j}</span> , denoted by Reveal <span class="math">(z_{i,j})</span> .</li>
    </ol>

    <p class="text-gray-300">We note that the protocol GKR(f) (resp. GKR(g)) is not sound if the  <span class="math">r_i</span> 's (resp.  <span class="math">z_{i,j}</span> 's) are a priori known to the worker. To ensure that soundness still holds even if we run all these algorithms in parallel, we mask parts of the delegator's message using a PIR scheme or an FHE scheme, and then we claim that the soundness error remains negligible. To this end, we use our parallel composition lemma (Lemma 24), which roughly states that if a set of protocols  <span class="math">\\Pi_1, \\ldots \\Pi_t</span>  are executed in parallel, and the verifiers use the same common private randomness p in all these protocols, then the soundness remains if the messages of the verifiers hide this common secret randomness p. (We refer the reader to Section 5 for details.)</p>

    <h2 id="sec-9" class="text-2xl font-bold">3 Preliminaries</h2>

    <h2 id="sec-10" class="text-2xl font-bold">3.1 Computational Private Information Retrieval (PIR)</h2>

    <p class="text-gray-300">&lt;span id=&quot;page-12-0&quot;&gt;&lt;/span&gt;<strong>Definition 5</strong> Let k be the security parameter and N be the database size. Let  <span class="math">Q^{\\text{PIR}}</span>  and  <span class="math">D^{\\text{PIR}}</span>  be probabilistic circuits, and let  <span class="math">R^{\\text{PIR}}</span>  be a deterministic circuit. We say that  <span class="math">\\text{PIR} = (Q^{\\text{PIR}}, D^{\\text{PIR}}, R^{\\text{PIR}})</span>  is a poly-logarithmic private information retrieval scheme if the following conditions are satisfied:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(Size Restriction:)  <span class="math">Q^{\\text{PIR}}</span>  and  <span class="math">R^{\\text{PIR}}</span>  are of size  <span class="math">\\leq \\text{poly}(k, \\log N)</span> , and  <span class="math">D^{\\text{PIR}}</span>  is of size  <span class="math">\\leq \\text{poly}(k, N)</span> . The output of  <span class="math">Q^{\\text{PIR}}</span>  and  <span class="math">D^{\\text{PIR}}</span>  is of size  <span class="math">\\leq \\text{poly}(k, \\log N)</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(Perfect Correctness:)&lt;sup&gt;7&lt;/sup&gt;  <span class="math">\\forall N, \\forall k, \\forall database \\ x = (x_1, x_2, \\dots, x_N) \\in \\{0, 1\\}^N</span> , and  <span class="math">\\forall i \\in [N]</span> ,</li>
    </ol></li>
    </ul>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[R^{\\mathrm{PIR}}(k, N, i, (q, s), a) = x_i | (q, s) \\leftarrow Q^{\\mathrm{PIR}}(k, N, i), a \\leftarrow D^{\\mathrm{PIR}}(k, x, q)\\right] = 1</span>$</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(User Privacy:)  <span class="math">\\forall N, \\forall k, \\forall i, j \\in [N]</span> , and  <span class="math">\\forall adversary \\ \\mathcal{A}</span>  of size at most  <span class="math">2^{k^3}</span> ,</li>
    </ol>

    <p class="text-gray-300"><span class="math">$\\left|\\Pr[\\mathcal{A}(k,N,q) = 1 | (q,s) \\leftarrow Q^{\\mathrm{PIR}}(k,N,i)] - \\Pr[\\mathcal{A}(k,N,q) = 1 | (q,s) \\leftarrow Q^{\\mathrm{PIR}}(k,N,j)] \\right| \\leq 2^{-k^3}.</span>$</p>

    <p class="text-gray-300">&lt;span id=&quot;page-12-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;6&lt;/sup&gt;We note that there are several ways to improve efficiency, such as thinking of  <span class="math">(g_{r_1}, \\ldots, g_{r_u})</span>  as one function. However, for the sake of simplicity of exposition, we focus on the simplest (rather than most efficient) solution.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-12-2&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;7&lt;/sup&gt;For simplicity, we only define perfect correctness. However, usually a PIR scheme allows a negligible probability of error.</p>

    <h4 id="sec-11" class="text-lg font-semibold mt-6">3.2 Fully Homomorphic Encryption</h4>

    <p class="text-gray-300">A public-key encryption scheme E = (KeyGen, Enc, Dec) is said to be fully homomorphic if it is associated with an additional polynomial-time algorithm Eval, that takes as input a public key pk, a ciphertext  <span class="math">\\hat{x} = \\text{Enc}_{pk}(x)</span>  and a circuit C, and outputs, a new ciphertext  <span class="math">c = \\text{Eval}_{pk}(\\hat{x}, C)</span> , such that  <span class="math">\\text{Dec}_{sk}(c) = C(x)</span> , where sk is the secret key corresponding to the public key pk. It is required that the size of  <span class="math">c = \\text{Eval}_{pk}(\\text{Enc}_{pk}(x), C)</span>  depends polynomially on the security parameter and the length of C(x), but is otherwise independent of the size of the circuit C. We also require that Eval is deterministic, and the the scheme has perfect correctness (i.e. it always holds that  <span class="math">\\text{Dec}_{sk}(\\text{Enc}_{pk}(x)) = x</span>  and that  <span class="math">\\text{Dec}_{sk}(\\text{Eval}_{pk}(\\text{Enc}_{pk}(x), C)) = C(x)</span> ). For security, we simply require that E is semantically secure.</p>

    <p class="text-gray-300">In a recent breakthrough, Gentry [Gen09] proposed a fully homomorphic encryption scheme based on ideal lattices. Following this, Dijk, Gentry, Halevi and Vaikuntanathan [vDGHV10] proposed an alternative construction based on the extended GCD assumption. In these schemes, the complexity of the algorithms (KeyGen, Enc, Dec) depends linearly on the  <span class="math">depth\\ d</span>  of the circuit C, where d is an upper bound on the depth of the circuit C that are allowed as inputs to Eval. However, under the additional assumption that these schemes are circular secure (i.e., remain secure even given an encryption of the secret key), the complexity of these algorithms are independent of C.</p>

    <p class="text-gray-300">Our streaming memory delegation scheme relies on the existence of a fully homomorphic scheme. For the sake of simplicity, we assume that the FHE scheme has perfect completeness. We note that the FHE schemes of both [Gen09] and [vDGHV10] indeed have perfect completeness.</p>

    <h3 id="sec-12" class="text-xl font-semibold mt-8">&lt;span id=&quot;page-13-0&quot;&gt;&lt;/span&gt;3.3 Low Degree Extension</h3>

    <p class="text-gray-300">Let  <span class="math">\\mathbb{H}</span>  be an extension field of  <span class="math">\\mathbb{GF}[2]</span> , and let  <span class="math">\\mathbb{F}</span>  be an extension field of  <span class="math">\\mathbb{H}</span>  (and in particular, an extension field of  <span class="math">\\mathbb{GF}[2]</span> ), where  <span class="math">|\\mathbb{F}| = \\text{poly}(|\\mathbb{H}|)</span> . We always assume that field operations can be performed in time that is poly-logarithmic in the field size. Fix an integer  <span class="math">m \\in \\mathbb{N}</span> . In what follows, we define the low degree extension of an n-element string  <span class="math">(w_0, w_1, \\dots, w_{n-1}) \\in \\mathbb{F}^n</span>  with respect to  <span class="math">\\mathbb{F}, \\mathbb{H}, m</span> , where  <span class="math">n \\leq |\\mathbb{H}|^m</span> .</p>

    <p class="text-gray-300">Fix  <span class="math">\\alpha: \\mathbb{H}^m \\to \\{0, 1, \\dots, |\\mathbb{H}|^m - 1\\}</span>  to be any (efficiently computable) one-to-one function. In this paper, we take  <span class="math">\\alpha</span>  to be the lexicographic order of  <span class="math">\\mathbb{H}^m</span> . We can view  <span class="math">(w_0, w_1, \\dots, w_{n-1})</span>  as a function  <span class="math">W: \\mathbb{H}^m \\to \\mathbb{F}</span> , where</p>

    <p class="text-gray-300">&lt;span id=&quot;page-13-2&quot;&gt;&lt;/span&gt;
<span class="math">$W(z) = \\begin{cases} w_{\\alpha(z)} &amp; \\text{if } \\alpha(z) &lt; n, \\\\ 0 &amp; \\text{otherwise.} \\end{cases}</span>$
(2)</p>

    <p class="text-gray-300">A basic fact is that there exists a unique extension of W into a function  <span class="math">\\tilde{W}: \\mathbb{F}^m \\to \\mathbb{F}</span>  (which agrees with W on  <span class="math">\\mathbb{H}^m</span> ; i.e.,  <span class="math">\\tilde{W}|_{\\mathbb{H}^m} \\equiv W</span> ), such that  <span class="math">\\tilde{W}</span>  is an m-variate polynomial of degree at most  <span class="math">|\\mathbb{H}| - 1</span>  in each variable. Moreover, as is formally stated in the proposition below, the function  <span class="math">\\tilde{W}</span>  can be expressed as</p>

    <p class="text-gray-300"><span class="math">$\\widetilde{W}(t_1,\\ldots,t_m) = \\sum_{i=0}^{n-1} \\widetilde{\\beta}_i(t_1,\\ldots,t_m) \\cdot w_i,</span>$</p>

    <p class="text-gray-300">&lt;span id=&quot;page-13-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;8&lt;/sup&gt;Usually, when doing low degree extensions,  <span class="math">\\mathbb{F}</span>  is taken to be an extension field of  <span class="math">\\mathbb{GF}[2]</span> , and  <span class="math">\\mathbb{H}</span>  is simply a subset of  <span class="math">\\mathbb{F}</span>  (not necessarily a subfield). In this work, following the work of [GKR08], we take  <span class="math">\\mathbb{H}</span>  to be a subfield. However, all that is actually needed is that it is of size  <span class="math">2^{\\ell}</span>  for some  <span class="math">\\ell \\in \\mathbb{N}</span> .</p>

    <p class="text-gray-300">where each  <span class="math">\\tilde{\\beta}_i : \\mathbb{F}^m \\to \\mathbb{F}</span>  is an <em>m</em>-variate polynomial, that depends only on the parameters  <span class="math">\\mathbb{H}, \\mathbb{F}</span> , and m (and is independent of w), of size poly( <span class="math">|\\mathbb{H}|, m</span> ) and degree  <span class="math">|\\mathbb{H}| - 1</span>  in each variable.</p>

    <p class="text-gray-300">The function  <span class="math">\\tilde{W}</span>  is called the <em>low degree extension</em> of  <span class="math">w = (w_0, w_1, \\dots, w_{n-1})</span>  with respect to  <span class="math">\\mathbb{F}, \\mathbb{H}, m</span> , and is denoted by  <span class="math">\\mathrm{LDE}_w^{\\mathbb{F}, \\mathbb{H}, m}</span> . We omit the index of  <span class="math">\\mathbb{F}, \\mathbb{H}, m</span>  when the context is clear. Also, sometimes we use  <span class="math">\\tilde{W}</span>  for simplicity.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-14-0&quot;&gt;&lt;/span&gt;<strong>Proposition 6</strong> There exists a Turing machine that takes as input an extension field  <span class="math">\\mathbb{H}</span>  of  <span class="math">\\mathbb{GF}[2]</span> ,  <span class="math">^9</span>  an extension field  <span class="math">\\mathbb{F}</span>  of  <span class="math">\\mathbb{H}</span> , and integer m. The machine runs in time  <span class="math">\\operatorname{poly}(|\\mathbb{H}|, m, \\log |\\mathbb{F}|)</span>  and outputs the unique 2m-variate polynomial  <span class="math">\\tilde{\\beta}: \\mathbb{F}^m \\times \\mathbb{F}^m \\to \\mathbb{F}</span>  of degree  <span class="math">|\\mathbb{H}| - 1</span>  in each variable (represented as an arithmetic circuit of degree  <span class="math">|\\mathbb{H}| - 1</span>  in each variable), such that for every  <span class="math">w = (w_0, w_1, \\ldots, w_{n-1}) \\in \\mathbb{F}^n</span> , where  <span class="math">n \\leq |\\mathbb{H}|^m</span> , and for every  <span class="math">z \\in \\mathbb{F}^m</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\tilde{W}(z) = \\sum_{p \\in \\mathbb{H}^m} \\tilde{\\beta}(z, p) \\cdot W(p),</span>$</p>

    <p class="text-gray-300">where  <span class="math">W: \\mathbb{H}^m \\to \\mathbb{F}</span>  is the function corresponding to  <span class="math">(w_0, w_1, \\dots, w_{n-1})</span>  as defined in Equation (2), and  <span class="math">\\tilde{W}: \\mathbb{F}^m \\to \\mathbb{F}</span>  is its low degree extension (i.e., the unique extension of  <span class="math">W: \\mathbb{H}^m \\to \\mathbb{F}</span>  of degree at most  <span class="math">|\\mathbb{H}| - 1</span>  in each variable).</p>

    <p class="text-gray-300">Moreover,  <span class="math">\\tilde{\\beta}</span>  can be evaluated in time  <span class="math">\\operatorname{poly}(|\\mathbb{H}|, m, \\log |\\mathbb{F}|)</span> . Namely, there exists a Turing machine that runs in time  <span class="math">\\operatorname{poly}(|\\mathbb{H}|, m, \\log |\\mathbb{F}|)</span>  that takes as input parameters  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span>  (as above), and a pair  <span class="math">(z, p) \\in \\mathbb{F}^m \\times \\mathbb{F}^m</span> , and outputs  <span class="math">\\tilde{\\beta}(z, p)</span> . Furthermore, there exists a circuit for evaluating  <span class="math">\\tilde{\\beta}</span>  in the above sense with size  <span class="math">\\operatorname{poly}(|\\mathbb{H}|, m, \\log |\\mathbb{F}|)</span>  and depth  <span class="math">\\operatorname{poly}(m, \\log |\\mathbb{F}|)</span> .</p>

    <p class="text-gray-300">&lt;span id=&quot;page-14-3&quot;&gt;&lt;/span&gt;Corollary 7 There exists a Turing machine that takes as input an extension field  <span class="math">\\mathbb{H}</span>  of  <span class="math">\\mathbb{GF}[2]</span> , an extension field  <span class="math">\\mathbb{F}</span>  of  <span class="math">\\mathbb{H}</span> , an integer m, a sequence  <span class="math">w = (w_0, w_1, \\dots, w_{n-1}) \\in \\mathbb{F}^n</span>  such that  <span class="math">n \\leq |\\mathbb{H}|^m</span> , and a coordinate  <span class="math">z \\in \\mathbb{F}^m</span> . It runs in time  <span class="math">n \\cdot \\text{poly}(|\\mathbb{H}|, m, \\log |\\mathbb{F}|)</span> , and outputs the value  <span class="math">\\tilde{W}(z)</span> , where  <span class="math">\\tilde{W}</span>  is the unique low-degree extension of w (with respect to  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span> ). Furthermore, there exists a circuit for the same task with size  <span class="math">n \\cdot \\text{poly}(|\\mathbb{H}|, m, \\log |\\mathbb{F}|)</span>  and depth  <span class="math">\\text{poly}(m, \\log |\\mathbb{F}|)</span> .</p>

    <h4 id="sec-13" class="text-lg font-semibold mt-6">3.4 Delegation Schemes</h4>

    <p class="text-gray-300">In recent years, as cloud computing is gaining popularity, there have been many attempts to construct efficient delegation schemes. Loosely speaking, a delegation scheme is a protocol between a delegator D and a worker W, where the delegator asks the worker to do some computation, and prove that he indeed did the computation correctly. Typically, a delegation scheme is with respect to a class of functions  <span class="math">\\mathcal{F}</span> , and the requirement is that on input (f, x) where  <span class="math">f \\in \\mathcal{F}</span>  and x is in the domain of f, the worker outputs f(x), along with a proof (which may be interactive or non-interactive). The requirement is that the worker runs in time that is polynomial in the size of f (when representing f as a circuit), and the delegator runs in time that is significantly shorter than the size of f (as otherwise, it would simply compute f(x) on its own). In this work, we use the 2-message delegation protocol of [GKR08], which in turn uses a round reduction technique from [KR09]. The protocol has the following guarantees.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-14-2&quot;&gt;&lt;/span&gt;&lt;span id=&quot;page-14-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;9&lt;/sup&gt;Throughout this work, when we refer to a machine that takes as input a field, we mean that the machine is given a short (poly-logarithmic in the field size) description of the field, that permits field operations to be computed in time that is poly-logarithmic in the field size.</p>

    <p class="text-gray-300"><strong>Theorem 8</strong> [GKR08, KR09] Assume the existence of a poly-logarithmic PIR scheme, as defined in Definition 5. Let k be the security parameter, and let  <span class="math">\\mathcal{F}</span>  be the family of functions computable by  <span class="math">\\mathcal{L}</span> -space uniform boolean circuits of size S and depth  <span class="math">d \\geq \\log S</span> . Then, there exists a delegation protocol for  <span class="math">\\mathcal{F}</span>  with the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The worker runs in time poly(S, k) and the delegator runs in time  <span class="math">n \\cdot poly(k, d)</span> , where n is the length of the input.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The protocol has perfect completeness and soundness  <span class="math">s \\leq \\frac{1}{2}</span>  (can be made arbitrarily small), where soundness is against any cheating worker of size  <span class="math">\\leq 2^{k^3}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The protocol consists of two messages, with communication complexity  <span class="math">d \\cdot poly(k, \\log S)</span> . Moreover, the first message sent by the delegator depends only on her random coin tosses, and is independent of the statement being proved.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>If the delegator is given oracle access to the low-degree extension of x, rather than being given the input x itself, then it runs in time poly(k,d), and the protocol still has all the properties described above, assuming the parameters  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span>  of the low-degree extension satisfy the following:</li>
    </ol></li>
    </ul>

    <p class="text-gray-300"><span class="math">$|\\mathbb{H}| = \\theta(d \\cdot \\log n), \\ m = \\theta\\left(\\frac{\\log n}{\\log d}\\right), \\ |\\mathbb{F}| = \\text{poly}(|\\mathbb{H}|)</span>$</p>

    <p class="text-gray-300">where poly is a large enough polynomial.&lt;sup&gt;10&lt;/sup&gt; Moreover, the delegator queries the low-degree extension of x at a single point, which is uniformly random (over his coin tosses).</p>

    <p class="text-gray-300">Throughout this paper, we denote this protocol by GKR.</p>

    <h4 id="sec-14" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-15-0&quot;&gt;&lt;/span&gt;3.5 Merkle Tree Commitments</h4>

    <p class="text-gray-300"><strong>Definition 9</strong> Let  <span class="math">h: \\{0,1\\}^k \\times \\{0,1\\}^k \\to \\{0,1\\}^k</span>  be a hash function. A Merkle tree commitment of a sting  <span class="math">x \\in \\{0,1\\}^n</span>  w.r.t. h, denoted by  <span class="math">T_h(x)</span> , is a k-bit string, computed as follows: The input x is partitioned into  <span class="math">m = \\lceil n/k \\rceil</span>  blocks  <span class="math">x = (B_1, \\ldots, B_m)</span> , each block of size k.&lt;sup&gt;11&lt;/sup&gt; These blocks are partitioned into pairs  <span class="math">(B_{2i-1}, B_{2i})</span> , and the hash function h is applied to each pair, resulting in m/2 blocks. Then, again these m/2 blocks are partitioned into pairs, and the hash function h is applied to each of these pairs, resulting with m/4 blocks. This is repeated  <span class="math">\\log m</span>  times, resulting in a binary tree of hash values, until one block remains. This block is  <span class="math">T_h(x)</span> .</p>

    <h2 id="sec-15" class="text-2xl font-bold">&lt;span id=&quot;page-15-1&quot;&gt;&lt;/span&gt;4 Our Leakage Lemma</h2>

    <p class="text-gray-300">In this section, we define some machinery that is needed in order to prove the soundness of our streaming delegation scheme in Section 9. The main contribution of this section is a leakage lemma (Lemma 22), which essentially says that given an encryption (pk,  <span class="math">Enc_{pk}(S)</span> ) of a random 2-dimensional subspace  <span class="math">S \\leftarrow \\mathbb{F}^{m \\times 2}</span> , and given any additional arbitrary (not necessarily efficient) bit of leakage  <span class="math">b = L(pk, Enc_{pk}(S))</span> , then a random vector  <span class="math">z \\leftarrow S</span>  is computationally indistinguishable from a truly random vector  <span class="math">u \\leftarrow \\mathbb{F}^m</span> . We formally state and prove this lemma in Section 4.2.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-15-2&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;10&lt;/sup&gt;The larger poly is, the smaller the soundness becomes.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-15-3&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;11&lt;/sup&gt;For simplicity, we assume that m is a power of 2.</p>

    <p class="text-gray-300">This lemma plays a central role in analyzing the (reusable) soundness of our streaming delegation scheme. In this scheme, the delegator has a secret state, and we need to prove that a cheating worker cannot learn any information about her secret state, even after running several delegation protocols with the delegator, and learning the bit of whether she accepted or rejected. In the soundness proof, this verdict bit is thought of as a leakage bit.</p>

    <p class="text-gray-300">In the proof of Lemma 22, which is our main leakage lemma, we use another leakage lemma (Lemma 16), which is formally stated below and proved in Section 4.1. This leakage lemma roughly says that conditioning on a short leakage cannot decrease the conditional pseudo-entropy of a random variable too much.</p>

    <p class="text-gray-300">In order to even state these lemmas formally, we first need to define the notion of conditional pseudo-entropy. There are several possible notions of conditional pseudo-entropy with subtle differences. In the following, we present our definition along with discussions on other possible notions. We start with the information-theoretic notion of min-entropy and conditional min-entropy.</p>

    <p class="text-gray-300"><strong>Definition 10 (Min-Entropy)</strong> Let X be a distribution over finite support. The min-entropy of X is defined as</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{H}_{\\infty}(X) = \\min_{x \\in \\text{supp}(X)} \\log \\frac{1}{\\Pr[X = x]} = -\\log \\left( \\max_{x \\in \\text{supp}(X)} \\Pr[X = x] \\right).</span>$</p>

    <p class="text-gray-300"><strong>Definition 11 (Conditional Min-Entropy)</strong> Let (X,C) be a joint distribution over finite support. The (worst-case) conditional min-entropy of X conditioned on C is defined as</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{H}_{\\infty}(X|C) = \\min_{(x,c) \\in \\operatorname{supp}(X,C)} \\log \\frac{1}{\\Pr[X = x|C = c]} = \\min_{c \\in \\operatorname{supp}(C)} \\mathbf{H}_{\\infty}(X|_{C=c}).</span>$</p>

    <p class="text-gray-300">The above worst-case definition may seem too stringent as it requires X to have good minentropy conditioned on every possible  <span class="math">c \\in \\text{supp}(C)</span> . Several relaxed definitions have been used. For example, Renner and Wolf [RW05] defined a smooth version of the above definition, where X has  <span class="math">\\varepsilon</span> -smooth conditional min-entropy n conditioned on C if (X, C) is  <span class="math">\\varepsilon</span> -close in statistical distance to a distribution (X', C') with  <span class="math">\\mathbf{H}_{\\infty}(X&#x27;|C&#x27;) = n</span> . Such a slackness will be implicitly allowed in our definition of conditional pseudo-entropy. On the other hand, Dodis, Ostrovsky, Reyzin, and Smith [DORS08] defined an average-case version of conditional min-entropy, where  <span class="math">\\mathbf{H}_{\\infty}^{avg}(X|C) = -\\log(\\mathbf{E}_{C\\leftarrow C}[\\max_x \\{\\Pr[X=x|C=c]\\}])</span> .</p>

    <p class="text-gray-300">In the computational setting, Hsiao, Lu, and Reyzin [HLR07] defined conditional HILL entropy. Informally, X has high conditional HILL entropy conditioned on C if there exists a random variable Y = Y(C) such that (1) (X, C) is computationally indistinguishable from (Y, C), and (2) Y has high average conditional min-entropy conditioned on C (a la [DORS08]). In this work, we use a slightly different definition. The only difference between our definition and the [HLR07] definition is that we use the worse-case version of conditional min-entropy, as opposed to the average-case version. We work with the worst-case definition since it is more convenient for our application and makes the analysis simpler. For convenience, we refer to our notion also as conditional HILL entropy.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-16-1&quot;&gt;&lt;/span&gt;&lt;span id=&quot;page-16-0&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;12&lt;/sup&gt;We note that the two notions of [RW05] and [DORS08] are equivalent up to an additive  <span class="math">\\log(1/\\varepsilon)</span>  term. A detailed discussion can be found in Appendix B of [DORS08].</p>

    <p class="text-gray-300">Definition 12 (Conditional HILL Entropy) Let (X, C) be a joint distribution over a finite support, and let n, s ∈ N and ε ∈ (0, 1) be parameters. We say that X conditioned on C has conditional HILL entropy at least n against circuits of size s with advantage ε, denoted by HHILL ε,s (X|C) ≥ n, if there exists a distribution Y = Y (C) jointly distributed with C such that (1) H∞(Y |C) ≥ n, and (2) (X, C) and (Y, C) are computationally indistinguishable against circuits of size s with advantage ε. <a href="#page-17-1">13</a></p>

    <p class="text-gray-300">In the asymptotic setting where there is a security parameter k, we say HHILL(X|C) ≥ n, if for every constant c ∈ N, HHILL &lt;sup&gt;k&lt;/sup&gt;−c,k&lt;sup&gt;c&lt;/sup&gt; (X|C) ≥ n.</p>

    <p class="text-gray-300">Remark 13 Note that in the above definition, we only consider distributions (Y, C) that are indistinguishable from (X, C), i.e., we do not allow modifying the distribution of C. An alternative weaker definition is to consider all distributions (X&lt;sup&gt;0&lt;/sup&gt; , C&lt;sup&gt;0&lt;/sup&gt; ) that are indistinguishable from (X, C). The two definitions may not be equivalent in general.<a href="#page-17-2">14</a> We emphasize that the more stringent definition seems more relevant for cryptographic applications, since C is often some leakage information on X learned by an adversary. We further emphasize that we do not claim that our definition is the &quot;right&quot; one, and we only use it as a tool to prove our main result.</p>

    <p class="text-gray-300">Our goal is to show that if X has high conditional HILL entropy conditioned on C (say, HHILL(X|C) ≥ n) and B = B(X, C) is an arbitrary, but short (say, one bit) leakage information on X, then after further conditioning on B, X still has high conditional HILL entropy (i.e., HHILL(X|C, B) ≥ n − t for some small t). When B can be efficiently generated from (X, C), this is very easy to prove. However, proving this for general B = B(X, C) is not trivial. Indeed, in order to prove this, we need to further strengthen our definition of conditional HILL entropy.</p>

    <p class="text-gray-300">Definition 14 (Conditional HILL Entropy w.r.t. Samplable Distributions) Let k be a security parameter. For a finite distribution (X, C), we say HHILL(X|C) ≥ n w.r.t. samplable distributions if there exists a distribution Y = Y (C) such that the following holds.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>H∞(Y |C) ≥ n.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(X, C) and (Y, C) are computationally indistinguishable.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>There exists a poly(k) time algorithm Smp that on input c ∈ supp(C), outputs a sample y ← (Y |C=c).</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Remark 15 This definition differs from Definition <a href="#page-16-1">12</a> in two ways. First, we require the distributions Y |C=&lt;sup&gt;c&lt;/sup&gt; to be efficiently samplable for every c. Second, we require a single distribution Y = Y (C) such that (X, C) and (Y, C) are indistinguishable for any poly(k)-size distinguisher; whereas in Definition <a href="#page-16-1">12,</a> we fix the size k &lt;sup&gt;c&lt;/sup&gt; of distinguisher first and require a distribution Y = Y (C) such that (X, C) and (Y, C) are indistinguishable for k c -size distinguishers.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-17-0&quot;&gt;&lt;/span&gt;Lemma 16 Let k be a security parameter and n, <code>, t be any parameters such that n ≤ poly(k), </code> = O(log k), and t = ω(log k). Let (X, C) be a joint distribution over {0, 1} &lt;sup&gt;∗&lt;/sup&gt; × {0, 1} &lt;sup&gt;∗&lt;/sup&gt; of poly(k) length. If HHILL(X|C) ≥ n w.r.t. samplable distributions, then for any distribution B = B(X, C) over {0, 1} \` , we have</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{H}^{\\mathsf{HILL}}(X|C,B) \\ge n-t.</span>$</p>

    <p class="text-gray-300">&lt;span id=&quot;page-17-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;13&lt;/sup&gt;Note that the ε slackness is inherent in the above HILL-type definition.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-17-2&quot;&gt;&lt;/span&gt;&lt;sup&gt;14&lt;/sup&gt;We note that the two definitions are equivalent when the length of C is short (≤ O(log k)).</p>

    <p class="text-gray-300">The lemma says that further conditioning on O(log k) bits can only decrease the conditional HILL entropy by ω(log k). Note that an upper bound of O(log k) on the length of B is necessary, since the pseudo-entropy of X could be generated from merely ω(log k) bits of real entropy. For example, X can be the output of a pseudo-random generator (PRG) with sub-exponential stretch, and B can be the whole seed, if the length limit on B is relaxed. On the other hand, we do not know whether the samplability assumption on Y (C) is necessary or not. Moreover, we do not know whether we inherently need ω(log k) entropy loss, or whether one can prove \` = O(log k) entropy loss.</p>

    <p class="text-gray-300">Before presenting the proof of the lemma, we first compare it with previous results of <a href="#page-65-13">[DP08,</a> <a href="#page-66-11">RTTV08]</a>. Dziembowski and Pietrzak <a href="#page-65-13">[DP08]</a> (implicitly in Lemma 3), and Reingold, Trevisan, Tulsiani, and Vadhan <a href="#page-66-11">[RTTV08]</a> (Theorem 1.3, phrased in a different language of &quot;dense model theorem&quot;) proved that if HHILL(X) ≥ n and E is an event that occurs with probability p ≥ 1/poly(k), then after conditioning on the event E, HHILL(X|E) ≥ n − log(1/p).<a href="#page-18-1">15</a> This implies a special case of our Lemma <a href="#page-17-0">16</a> where C is not present: Suppose HHILL(X) ≥ n and B = B(X) is of length O(log k), then HHILL(X|B) ≥ n − ω(log k).</p>

    <p class="text-gray-300">In contrast, we consider a more general setting where a (possibly long) prior leakage information C is presented, which may information-theoretically determine X. Indeed, in our setting, C is an encryption of X and hence determines X.</p>

    <h2 id="sec-16" class="text-2xl font-bold">&lt;span id=&quot;page-18-0&quot;&gt;&lt;/span&gt;4.1 Proof of Lemma <a href="#page-17-0">16</a></h2>

    <h3 id="sec-17" class="text-xl font-semibold mt-8">4.1.1 Preliminaries</h3>

    <p class="text-gray-300">We proceed to present the proof of Lemma <a href="#page-17-0">16.</a> The first part of our proof follows the same line as previous results <a href="#page-65-13">[DP08,</a> <a href="#page-66-11">RTTV08]</a>, where we convert (conditional) HILL-type entropy to (conditional) &quot;metric-type&quot; entropy, defined by Barak, Shaltiel, and Wigderson <a href="#page-65-14">[BSW03]</a>. On the other hand, the second part of our proof is more involved than previous results. We start by defining a conditional version of metric entropy.</p>

    <p class="text-gray-300">Conditional Metric Entropy. Loosely speaking, metric entropy is weaker than HILL entropy and is defined by switching the order of quantifiers in the definition of HILL entropy. Recall that the HILL definition says that X has HILL entropy n if there exists a random variable Y with min-entropy n such that every small distinguisher D fails to distinguish between X and Y . In contrast, the definition of metric entropy requires that for every small distinguisher D, there exists a random variable Y (which may depend on D) with min-entropy n such that D fails to distinguish between X and Y .</p>

    <p class="text-gray-300">Definition 17 (Conditional Metric Entropy) Let (X, C) be a joint distribution over a finite support. Let n, s ∈ N and ε ∈ (0, 1) be parameters. We say X conditioned on C has conditional metric entropy at least n against randomized circuits of size s with advantage ε, denoted by Hmetric ε,s (X|C) ≥ n, if for every randomized circuit D of size at most s, there exists a distribution Y = Y (C) jointly distributed with C such that H∞(Y |C) ≥ n, and</p>

    <p class="text-gray-300"><span class="math">$|\\Pr[D(X,C)=1] - \\Pr[D(Y,C)=1]| \\le \\varepsilon.</span>$</p>

    <p class="text-gray-300">&lt;span id=&quot;page-18-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;15&lt;/sup&gt;This is also pointed out by Fuller and Reyzin <a href="#page-65-15">[FR11]</a>.</p>

    <p class="text-gray-300">In the asymptotic setting where there is a security parameter k, we say  <span class="math">\\mathbf{H}^{\\mathsf{metric}}(X|C) \\geq n</span> , if it holds that  <span class="math">\\mathbf{H}^{\\mathsf{metric}}_{k^{-c},k^{c}}(X|C) \\geq n</span>  for every constant  <span class="math">c \\in \\mathbb{N}</span> .</p>

    <p class="text-gray-300">We emphasize that, except for the natural generalization to the conditional version, our definition differs from that of [BSW03] in that we allow the distinguishers to be randomized, as opposed to deterministic. &lt;sup&gt;16&lt;/sup&gt; The reason is that, as pointed out by Vadhan [Vad10] and Dziembowski and Pietrzak [DP08], the result of [BSW03] does not hold when deterministic distinguishers are considered, and randomized distinguishers should be used instead. &lt;sup&gt;17&lt;/sup&gt;</p>

    <p class="text-gray-300">&lt;span id=&quot;page-19-2&quot;&gt;&lt;/span&gt;Lemma 18 (Theorem 5.2 of [BSW03], generalized) Let (X,C) be a joint distribution over  <span class="math">\\{0,1\\}^{m_1} \\times \\{0,1\\}^{m_2}</span> , and let  <span class="math">\\varepsilon, \\delta &gt; 0</span> ,  <span class="math">s,k \\in \\mathbb{N}</span>  be parameters. If  <span class="math">\\mathbf{H}^{\\mathsf{metric}}_{\\varepsilon,s}(X|C) \\geq n</span> , then  <span class="math">\\mathbf{H}^{\\mathsf{HILL}}_{\\varepsilon+\\delta,s&#x27;}(X|C) \\geq n</span>  for  <span class="math">s&#x27; = s \\cdot O(\\delta^2/(m_1 + m_2))</span> .</p>

    <p class="text-gray-300">Lemma 18 is proved in exactly the same way as the proof in [BSW03], where one uses von-Neuman's min-max theorem [Neu28] to switch the order of quantifiers. For the sake of completeness, we give a proof sketch below.</p>

    <p class="text-gray-300"><strong>Proof.</strong> (sketch) For the sake of contradiction, assume that  <span class="math">\\mathbf{H}_{\\varepsilon+\\delta,s&#x27;}^{\\mathsf{HILL}}(X|C) &lt; n</span> . This means that for every distribution Y = Y(C) with  <span class="math">\\mathbf{H}_{\\infty}(Y|C) \\geq n</span> , there exists a size s' distinguisher D that distinguishes (X,C) from (Y,C) with advantage  <span class="math">\\geq \\varepsilon + \\delta</span> . Applying min-max theorem, we obtain the following statement. There exists a distribution  <span class="math">\\mathcal{D}</span>  over size-s' distinguishers such that for every Y = Y(C) with  <span class="math">\\mathbf{H}_{\\infty}(Y|C) \\geq n</span> , we have</p>

    <p class="text-gray-300"><span class="math">$\\left| \\underset{D \\leftarrow \\mathcal{D}}{\\mathbb{E}} [D(X, C)] - \\underset{D \\leftarrow \\mathcal{D}}{\\mathbb{E}} [D(Y, C)] \\right| \\ge \\varepsilon + \\delta.</span>$</p>

    <p class="text-gray-300">Now, it can be shown by standard Chernoff and union bounds that there exists a set  <span class="math">S = \\{D_1, \\ldots, D_{O((m_1+m_2)/\\delta^2)}\\}</span>  of circuits in  <span class="math">\\text{supp}(\\mathcal{D})</span>  such that for every  <span class="math">(z, c) \\in \\{0, 1\\}^{m_1} \\times \\{0, 1\\}^{m_2}</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\left| \\underset{D \\leftarrow \\mathcal{D}}{\\mathbb{E}} [D(z, c)] - \\underset{D_i \\leftarrow S}{\\mathbb{E}} [D_i(z, c)] \\right| \\le \\delta/2.</span>$</p>

    <p class="text-gray-300">Since this holds point-wise, it follows that for every Y = Y(C) with  <span class="math">\\mathbf{H}_{\\infty}(Y|C) \\geq n</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\left| \\underset{D_i \\leftarrow S}{\\mathbb{E}} [D_i(X, C)] - \\underset{D_i \\leftarrow S}{\\mathbb{E}} [D_i(Y, C)] \\right| \\ge \\varepsilon.</span>$</p>

    <p class="text-gray-300">We obtain a contradiction by observing that choosing a random circuit  <span class="math">D_i \\leftarrow S</span>  and outputting  <span class="math">D_i(z,c)</span>  can be implemented by a size  <span class="math">s = s&#x27; \\cdot O((m_1 + m_2)/\\delta^2)</span>  randomized circuit.</p>

    <p class="text-gray-300">As a corollary, the lemma implies that conditional HILL entropy and conditional metric entropy are equivalent in the asymptotic setting.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-19-3&quot;&gt;&lt;/span&gt;<strong>Corollary 19</strong> Let k be a security parameter. For every joint distribution (X, C) of polynomially bounded length  <span class="math">|(X, C)| \\leq \\operatorname{poly}(k)</span> , we have  <span class="math">\\mathbf{H}^{\\mathsf{HILL}}(X|C) = \\mathbf{H}^{\\mathsf{metric}}(X|C)</span> .</p>

    <p class="text-gray-300">&lt;span id=&quot;page-19-0&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;16&lt;/sup&gt;Note that, for HILL-type entropy, randomized distinguishers and deterministic distinguishers are essentially equivalent, since one can turn a randomized distinguisher to a deterministic one by fixing the &quot;best&quot; coins that preserves the advantage for distinguishing two distributions. In contrast, for the case of metric entropy, it is unclear whether randomized distinguishers can be converted into deterministic ones since the distinguisher needs to work for all distributions.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-19-1&quot;&gt;&lt;/span&gt; <span class="math">&lt;sup&gt;^{17}&lt;/sup&gt;</span> [DP08], instead of using randomized distinguishers, use deterministic [0,1]-valued distinguishers. We choose to use randomized circuit distinguishers since we find them to be more natural than circuits with [0,1]-valued output.</p>

    <h4 id="sec-18" class="text-lg font-semibold mt-6">4.1.2 Formal Proof of Lemma 16</h4>

    <p class="text-gray-300"><strong>Proof.</strong> Suppose for contradiction that there exists a distribution B = B(X, C) such that  <span class="math">\\mathbf{H}^{\\mathsf{HILL}}(X|C,B) &lt; n-t</span> . By Corollary 19, this implies that  <span class="math">\\mathbf{H}^{\\mathsf{metric}}(X|C,B) &lt; n-t</span> . Namely, there exists some constant  <span class="math">c_0 \\in \\mathbb{N}</span>  and a randomized circuit D of size  <span class="math">k^{c_0}</span>  such that for every distribution Z = Z(C,B) with  <span class="math">\\mathbf{H}_{\\infty}(Z|C,B) \\geq n-t</span> ,</p>

    <p class="text-gray-300">&lt;span id=&quot;page-20-3&quot;&gt;&lt;/span&gt;
<span class="math">$|\\Pr[D(X, C, B) = 1] - \\Pr[D(Z, C, B) = 1]| &gt; k^{-c_0} \\stackrel{\\text{def}}{=} \\varepsilon.</span>$
(3)</p>

    <p class="text-gray-300">On the other hand, the fact that  <span class="math">\\mathbf{H}^{\\mathsf{HILL}}(X|C) \\geq n</span>  w.r.t. sampleable distributions implies that there exists a distribution Y = Y(C) such that (1)  <span class="math">\\mathbf{H}_{\\infty}(Y|C) \\geq n</span> , (2) (X,C) and (Y,C) are computationally indistinguishable, and (3) there exists a PPT algorithm Smp that on input  <span class="math">c \\in \\mathrm{supp}(C)</span> , outputs a sample  <span class="math">y \\leftarrow (Y|_{C=c})</span> .</p>

    <p class="text-gray-300">For notational convenience, let</p>

    <p class="text-gray-300"><span class="math">$p_{c,b}(z) \\triangleq \\Pr[D(z,c,b) = 1].</span>$</p>

    <p class="text-gray-300">We construct a polynomial-size (randomized) circuit D' that distinguishes between (X, C) and (Y, C), as follows. On input (w, c) which comes from either (X, C) or (Y, C), D' does the following:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Use the sampling algorithm Smp to sample  <span class="math">s = (4 \\cdot 2^{\\ell}/\\varepsilon)</span>  independent samples of  <span class="math">y_i \\leftarrow Y|_{C=c}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>For every  <span class="math">b \\in \\{0,1\\}^{\\ell}</span> , compute estimators for  <span class="math">p_{c,b}(w)</span>  and  <span class="math">p_{c,b}(y_i)</span> , denoted by  <span class="math">\\tilde{p}_{c,b}(w)</span>  and  <span class="math">\\tilde{p}_{c,b}(y_i)</span> , respectively. More specifically, run D(w,c,b) (resp.,  <span class="math">D(y_i,c,b)</span> ) with fresh randomness  <span class="math">t \\triangleq \\Theta(\\ell(\\log^2 k)(\\log s)/\\varepsilon^2)</span>  times, and let  <span class="math">\\tilde{p}_{c,b}(w)</span>  (resp.,  <span class="math">\\tilde{p}_{c,b}(y_i)</span> ) be the average of the outputs.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>If there exists some  <span class="math">b \\in \\{0,1\\}^{\\ell}</span>  such that</li>
    </ol></li>
    </ul>

    <p class="text-gray-300"><span class="math">$\\tilde{p}_{c,b}(w) \\ge \\max_{y_i} {\\{\\tilde{p}_{c,b}(y_i)\\}} + \\varepsilon/4,</span>$</p>

    <p class="text-gray-300">then output 1. Otherwise, output 0.</p>

    <p class="text-gray-300">Note that D' can be implemented by a randomized circuit of size  <span class="math">\\operatorname{poly}(k, 2^{\\ell}, 1/\\varepsilon) = \\operatorname{poly}(k)</span> . We also note that the parameter  <span class="math">t = \\Theta(\\ell(\\log^2 k)(\\log s)/\\varepsilon^2)</span>  defined in Step 2 is chosen so that, with overwhelming probability, <em>all</em> estimators have error less than  <span class="math">\\varepsilon/8</span> , i.e.,</p>

    <p class="text-gray-300">&lt;span id=&quot;page-20-2&quot;&gt;&lt;/span&gt;
<span class="math">$|\\tilde{p}_{c,b}(w) - p_{c,b}(w)| &lt; \\varepsilon/8</span>$
, and  <span class="math">|\\tilde{p}_{c,b}(y_i) - p_{c,b}(y_i)| &lt; \\varepsilon/8</span> . (4)</p>

    <p class="text-gray-300">This follows from a standard Chernoff bound, &lt;sup&gt;18&lt;/sup&gt; which says that a single estimator has error less than  <span class="math">\\varepsilon/8</span>  with probability  <span class="math">1 - e^{-\\Omega(t\\varepsilon^2)} = 1 - e^{-\\Omega(\\ell(\\log^2 k)(\\log s))}</span> . Since there are  <span class="math">2^{\\ell} \\cdot (s+1)</span>  estimators, by a union bound, the probability that all estimators have error less than  <span class="math">\\varepsilon/8</span>  is at least</p>

    <p class="text-gray-300"><span class="math">$1 - e^{-\\Omega(\\ell(\\log^2 k)(\\log s))} \\cdot 2^{\\ell} \\cdot (s+1) \\ge 1 - \\mathsf{ngl}(k).</span>$</p>

    <p class="text-gray-300">We proceed to prove the following two claims, which jointly imply that D' distinguishes between (X, C) and (Y, C) with advantage  <span class="math">\\varepsilon/4 - \\mathsf{ngl}</span> , and thus completes the proof.</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[\\left|\\left(\\frac{1}{n}\\sum A_i\\right) - p\\right| \\ge \\varepsilon\\right] \\le e^{-\\Omega(n\\varepsilon^2)}.</span>$</p>

    <p class="text-gray-300">&lt;span id=&quot;page-20-1&quot;&gt;&lt;/span&gt;&lt;span id=&quot;page-20-0&quot;&gt;&lt;/span&gt;&lt;sup&gt;18&lt;/sup&gt;We use the following basic version of Chernoff bound: Let  <span class="math">A_1, \\ldots, A_n</span>  be i.i.d. boolean random variables with  <span class="math">\\Pr[A_i = 1] = p</span> , and let  <span class="math">\\varepsilon \\in (0, 1)</span>  be a parameter. Then</p>

    <p class="text-gray-300">Claim 20 Pr[D&lt;sup&gt;0&lt;/sup&gt; (Y, C) = 1] ≤ ε/4.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-21-0&quot;&gt;&lt;/span&gt;Claim 21 Pr[D&lt;sup&gt;0&lt;/sup&gt; (X, C) = 1] ≥ ε/2 − ngl.</p>

    <p class="text-gray-300">Proof of Claim <a href="#page-20-1">20.</a> Note that when (w, c) ← (Y, C), then w and y&lt;sup&gt;i&lt;/sup&gt; 's are i.i.d. copies of (Y |C=c). Hence, for every b ∈ {0, 1} \` ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr[p_{c,b}(w) &gt; \\max_{y_i} \\{p_{c,b}(y_i)\\}] &lt; 1/s.</span>$</p>

    <p class="text-gray-300">By a union bound,</p>

    <p class="text-gray-300"><span class="math">$\\Pr[\\exists b^* \\in \\{0,1\\}^{\\ell} \\text{ s.t. } p_{c,b^*}(w) &gt; \\max_{y_i} \\{p_{c,b^*}(y_i)\\}] &lt; 2^{\\ell}/s = \\varepsilon/4.</span>$</p>

    <p class="text-gray-300">Denote by EGood the event that Equation <a href="#page-20-2">(4)</a> holds; i.e., the event that all estimators have error less than ε/8. Recall that we chose the parameter so that event EGood holds with overwhelming probability (i.e., probability 1 − ngl(k)). Note that if event EGood holds,</p>

    <p class="text-gray-300"><span class="math">$\\tilde{p}_{c,b}(w) \\ge \\max_{y_i} \\{ \\tilde{p}_{c,b}(y_i) \\} + \\varepsilon/4 \\quad \\Rightarrow \\quad p_{c,b}(w) &gt; \\max_{y_i} \\{ p_{c,b}(y_i) \\}</span>$</p>

    <p class="text-gray-300">Therefore,</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} &amp;\\Pr[D&#x27;(Y,C)=1]\\\\ &amp;= &amp;\\Pr\\left[\\exists b\\in\\{0,1\\}^{\\ell} \\text{ s.t. } \\tilde{p}_{c,b}(w) \\geq \\max_{y_i}\\{\\tilde{p}_{c,b}(y_i)\\} + \\varepsilon/4\\right]\\\\ &amp;\\leq &amp;\\Pr\\left[\\left(\\exists b\\in\\{0,1\\}^{\\ell} \\text{ s.t. } \\tilde{p}_{c,b}(w) \\geq \\max_{y_i}\\{\\tilde{p}_{c,b}(y_i)\\} + \\varepsilon/4\\right) \\wedge E_{Good}\\right] + \\Pr[\\neg E_{Good}]\\\\ &amp;\\leq &amp;\\Pr\\left[\\exists b\\in\\{0,1\\}^{\\ell} \\text{ s.t. } p_{c,b}(w) &gt; \\max_{y_i}\\{p_{c,b}(y_i)\\}\\right] + \\mathsf{ngl}(k)\\\\ &amp;\\leq &amp;\\varepsilon/4 + \\mathsf{ngl}(k). \\end{split}</span>$</p>

    <p class="text-gray-300">Proof of Claim <a href="#page-21-0">21.</a> We first argue that we can assume, without loss of generality, that for every Z with H∞(Z|C, B) ≥ n − t,</p>

    <p class="text-gray-300">&lt;span id=&quot;page-21-1&quot;&gt;&lt;/span&gt;
<span class="math">$\\Pr[D(X, C, B) = 1] - \\Pr[D(Z, C, B) = 1] &gt; \\varepsilon. \\tag{5}</span>$</p>

    <p class="text-gray-300">The reason is the following: Suppose for the sake of contradiction that there exists some distribution Z with H∞(Z|C, B) ≥ n − t such that</p>

    <p class="text-gray-300"><span class="math">$\\Pr[D(X, C, B) = 1] - \\Pr[D(Z, C, B) = 1] &gt; \\varepsilon,</span>$</p>

    <p class="text-gray-300">and yet there exists another distribution Z &lt;sup&gt;0&lt;/sup&gt; with H∞(Z 0 |C, B) ≥ n − t such that</p>

    <p class="text-gray-300"><span class="math">$\\Pr[D(Z&#x27;, C, B) = 1] - \\Pr[D(X, C, B) = 1] &gt; \\varepsilon.</span>$</p>

    <p class="text-gray-300">Then one can construct a distribution Z &lt;sup&gt;00&lt;/sup&gt;, by taking an appropriate convex combination of Z and Z 0 , such that H∞(Z &lt;sup&gt;00&lt;/sup&gt;|C, B) ≥ n − t and Pr[D(X, C, B) = 1] = Pr[D(Z &lt;sup&gt;00&lt;/sup&gt;, C, B) = 1], contradicting Equation (3).</p>

    <p class="text-gray-300">For every pair  <span class="math">(c, b) \\in \\text{supp}(C, B)</span> , let  <span class="math">H_{cb}</span>  be a set of the &quot;heaviest&quot;  <span class="math">2^{n-t}</span>  points w that maximize  <span class="math">p_{cb}(w)</span> . Consider the distribution  <span class="math">Z^+ = Z^+(C, B)</span>  such that  <span class="math">Z^+|_{(C,B)=(c,b)}</span>  is the uniform distribution over  <span class="math">H_{c,b}</span> . Note that  <span class="math">\\mathbf{H}_{\\infty}(Z^+|C,B) = n-t</span> . For every  <span class="math">(c,b) \\in \\text{supp}(C,B)</span> , define</p>

    <p class="text-gray-300"><span class="math">$p_{c,b}^{+} \\triangleq \\Pr[D(Z^{+}|_{C=c,B=b},c,b)=1].</span>$</p>

    <p class="text-gray-300">Using these notations, Equation (5) implies that</p>

    <p class="text-gray-300"><span class="math">$\\mathop{\\mathbf{E}}_{(x,c,b)\\leftarrow(X,C,B)}[p_{c,b}(x)] - \\mathop{\\mathbf{E}}_{(c,b)\\leftarrow(C,B)}[p_{c,b}^+] \\geq \\varepsilon.</span>$</p>

    <p class="text-gray-300">By a Markov argument, with probability at least  <span class="math">\\varepsilon/2</span>  over  <span class="math">(x,c,b) \\leftarrow (X,C,B)</span> ,</p>

    <p class="text-gray-300"><span class="math">$p_{c,b}(x) - p_{c,b}^+ \\ge \\varepsilon/2.</span>$</p>

    <p class="text-gray-300">We next prove that in this case,  <span class="math">\\Pr[D&#x27;(x,c)=1] \\geq 1 - \\mathsf{ngl}(k)</span> , which implies that</p>

    <p class="text-gray-300"><span class="math">$\\Pr[D&#x27;(X,C)=1] \\ge (1-\\mathsf{ngl}(k)) \\cdot (\\varepsilon/2) \\ge \\varepsilon/2 - \\mathsf{ngl}(k).</span>$</p>

    <p class="text-gray-300">Fix any x, c, b such that  <span class="math">p_{c,b}(x) - p_{c,b}^+ \\ge \\varepsilon/2</span> . It remains to prove that</p>

    <p class="text-gray-300"><span class="math">$\\Pr[D&#x27;(x,c) = 1] \\ge 1 - \\mathsf{ngl}(k).</span>$</p>

    <p class="text-gray-300">Note that by definition,  <span class="math">p_{cb}(w) \\leq p_{c,b}^+</span>  for every  <span class="math">w \\notin H_{cb}</span> . Recall that we choose the parameter so that with overwhelming probability, all estimators have error at most  <span class="math">\\varepsilon/8</span> . As before, denote by  <span class="math">E_{Good}</span>  the event that indeed all estimators have error at most  <span class="math">\\varepsilon/8</span> .</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} &amp;\\Pr[D&#x27;(x,c)=1] \\\\ &amp;\\geq &amp; \\Pr[\\tilde{p}_{cb}(x) \\geq \\max_{y_i} \\{\\tilde{p}_{cb}(y_i)\\} + \\varepsilon/4] \\\\ &amp;\\geq &amp; \\Pr[(\\tilde{p}_{cb}(x) \\geq \\max_{y_i} \\{\\tilde{p}_{cb}(y_i)\\} + \\varepsilon/4) \\wedge E_{Good}] - \\Pr[\\neg E_{Good}] \\\\ &amp;\\geq &amp; \\Pr[p_{cb}(x) \\geq \\max_{y_i} \\{p_{cb}(y_i)\\} + \\varepsilon/2] - \\mathsf{ngl}(k) \\\\ &amp;\\geq &amp; \\Pr[\\forall i, y_i \\notin H_{cb}] - \\mathsf{ngl}(k) \\\\ &amp;\\geq &amp; (1-\\mathsf{ngl}(k)) - \\mathsf{ngl}(k) \\\\ &amp;\\geq &amp; 1-\\mathsf{ngl}(k), \\end{split}</span>$</p>

    <p class="text-gray-300">where the second-to-last inequality follows from the fact that  <span class="math">|H_{cb}| = 2^{n-t}</span>  and  <span class="math">\\mathbf{H}_{\\infty}(Y|_{C=c}) \\geq n</span> .</p>

    <h4 id="sec-19" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-22-0&quot;&gt;&lt;/span&gt;4.2 Main Leakage Lemma</h4>

    <p class="text-gray-300">Throughout this section, we consider the following setting. Let  <span class="math">k \\in \\mathbb{N}</span>  be a security parameter. Let  <span class="math">\\mathbb{F}</span>  be a finite field of size  <span class="math">q \\geq 2^{\\log^2 k}</span> , and let E = (Gen, Enc, Dec) be any semantic secure public-key encryption scheme. Let  <span class="math">m \\leq \\text{poly}(k)</span>  be a parameter. We define the following random variables.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Let  <span class="math">S \\in_R \\mathbb{F}^{m \\times 2}</span>  be a random m-by-2 matrix representing a random 2-dimensional linear subspace</li>
    </ol>

    <p class="text-gray-300">&lt;span id=&quot;page-23-0&quot;&gt;&lt;/span&gt;
<span class="math">\${a_1v_1 + a_2v_2 : a_1, a_2 \\in \\mathbb{F}},</span>$</p>

    <p class="text-gray-300">where  <span class="math">v_1, v_2</span>  are columns of S.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Let  <span class="math">(pk, sk) \\leftarrow Gen(1^k)</span> , and let  <span class="math">\\hat{S} = Enc_{pk}(S)</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Let  <span class="math">L: \\{0,1\\}^* \\to \\{0,1\\}</span>  be an arbitrary (randomized, not necessarily efficient) leakage function that maps  <span class="math">(\\hat{S}, \\mathsf{pk})</span>  to one bit, and let  <span class="math">b = L(\\hat{S}, \\mathsf{pk})</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Let  <span class="math">u \\leftarrow \\mathbb{F}^m</span>  be a random point in  <span class="math">\\mathbb{F}^m</span> , and z be a random point in S. Specifically,  <span class="math">z = S \\cdot a = a_1 v_1 + a_2 v_2</span>  where  <span class="math">a = (a_1, a_2)</span>  is a uniformly random vector in  <span class="math">\\mathbb{F}^2</span> .</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Our goal in this section is to prove the following lemma.</p>

    <p class="text-gray-300"><strong>Lemma 22</strong> In the above setting, the distributions  <span class="math">(z, \\hat{S}, pk, b)</span>  and  <span class="math">(u, \\hat{S}, pk, b)</span>  are computationally indistinguishable.</p>

    <p class="text-gray-300">The lemma says that computationally, the encryption  <span class="math">(\\hat{S}, pk)</span>  together with an arbitrary leakage bit b does not leak any information about z. Note that information-theoretically,  <span class="math">(\\hat{S}, pk)</span>  does contain information about z, since we know that z is in S. Also note that when b is not present, semantic security readily implies that  <span class="math">(z, \\hat{S}, pk)</span>  and  <span class="math">(u, \\hat{S}, pk)</span>  are computationally indistinguishable. However, when the bit b is present, the proof becomes highly non-trivial, and in particular, our proof makes use of Lemma 16.</p>

    <p class="text-gray-300"><strong>Proof.</strong> We first consider the distribution  <span class="math">(S, \\hat{S}, pk)</span> . By the semantic security,  <span class="math">(S, \\hat{S}, pk)</span>  is computationally indistinguishable from  <span class="math">(S&#x27;, \\hat{S}, pk)</span> , where S' is an i.i.d. copy of S. Note that this implies</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{H}^{\\mathsf{HILL}}(S|\\hat{S},\\mathsf{pk}) \\geq 2m \\cdot \\log q</span>$</p>

    <p class="text-gray-300">w.r.t. sampleable distributions. By Lemma 16,</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{H}^{\\mathsf{HILL}}(S|\\hat{S},\\mathsf{pk},b) \\ge (2m \\cdot \\log q) - t,</span>$</p>

    <p class="text-gray-300">where we set  <span class="math">t = (\\log q)/4 = \\omega(\\log k)</span> . Namely, for every constant  <span class="math">c \\in \\mathbb{N}</span> , there exists a distribution  <span class="math">T = T(\\hat{S}, \\mathsf{pk}, b)</span>  such that:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathbf{H}_{\\infty}(T|\\hat{S},\\mathsf{pk},b) \\geq (2m \\cdot \\log q) t</span> , and</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">(S, \\hat{S}, \\mathsf{pk}, b)</span>  and  <span class="math">(T, \\hat{S}, \\mathsf{pk}, b)</span>  are computationally indistinguishable against circuits of size  <span class="math">k^c</span>  with advantage  <span class="math">k^{-c}</span> .</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Note that  <span class="math">z \\leftarrow S</span>  is efficiently sampleable, say, using a circuit of size  <span class="math">m^3 = \\text{poly}(k)</span> . Therefore, the distributions  <span class="math">(z_S, S, \\hat{S}, \\mathsf{pk}, b)</span>  and  <span class="math">(z_T, T, \\hat{S}, \\mathsf{pk}, b)</span> , where  <span class="math">z_S \\leftarrow S</span>  and  <span class="math">z_T \\leftarrow T</span>  are random points in S and T respectively, are computationally indistinguishable against circuits of size  <span class="math">(k^c - m^3)</span>  with advantage  <span class="math">k^{-c}</span> .</p>

    <p class="text-gray-300">Clearly, we can remove S and T from the distributions while preserving the indistinguishability. Namely, the distributions  <span class="math">(z_S, \\hat{S}, \\mathsf{pk}, b)</span>  and  <span class="math">(z_T, \\hat{S}, \\mathsf{pk}, b)</span>  are computationally indistinguishable against circuits of size  <span class="math">(k^c - m^3)</span>  with advantage  <span class="math">k^{-c}</span> .</p>

    <p class="text-gray-300">We next claim that for any distribution  <span class="math">T = T(\\hat{S}, pk, b)</span>  over  <span class="math">\\mathbb{F}^{m \\times 2}</span> , with</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{H}_{\\infty}(T|\\hat{S},\\mathsf{pk},b) \\geq (2m \\cdot \\log q) - t,</span>$</p>

    <p class="text-gray-300">the distributions  <span class="math">(z_T, \\hat{S}, \\mathsf{pk}, b)</span>  and  <span class="math">(u, \\hat{S}, \\mathsf{pk}, b)</span>  are statistically close (i.e., have distance  <span class="math">\\mathsf{ngl}(k)</span> ). This would imply that  <span class="math">(z, \\hat{S}, \\mathsf{pk}, b)</span>  and  <span class="math">(u, \\hat{S}, \\mathsf{pk}, b)</span>  are computationally indistinguishable against circuits of size  <span class="math">(k^c - m^3)</span>  with advantage  <span class="math">k^{-c} + \\mathsf{ngl}(k)</span> . Observing that the above argument holds for all constants  <span class="math">c \\in \\mathbb{N}</span> , we conclude that  <span class="math">(z, \\hat{S}, \\mathsf{pk}, b)</span>  and  <span class="math">(u, \\hat{S}, \\mathsf{pk}, b)</span>  are computationally indistinguishable, as desired.</p>

    <p class="text-gray-300">Thus, it remains to prove that indeed  <span class="math">(z_T, \\hat{S}, \\mathsf{pk}, b)</span>  and  <span class="math">(u, \\hat{S}, \\mathsf{pk}, b)</span>  are statistically close. To this end, we use Lemma 23 below, which states that if a distribution T over  <span class="math">\\mathbb{F}^{m \\times 2}</span>  has min-entropy at least  <span class="math">(2m \\cdot \\log q) - t</span>  and  <span class="math">a = (a_1, a_2) \\leftarrow \\mathbb{F}^2</span> , then  <span class="math">z = T \\cdot a</span>  is  <span class="math">\\varepsilon</span> -close to uniform, where  <span class="math">\\varepsilon \\leq 2m \\cdot q^{-1/4} = \\mathsf{ngl}(k)</span> .</p>

    <p class="text-gray-300">Recall that according to our definition of conditional min-entropy (which is a worse-case definition),  <span class="math">\\mathbf{H}_{\\infty}(T|\\hat{S},\\mathsf{pk},b) \\geq (2m \\cdot \\log q) - t</span>  implies that  <span class="math">\\mathbf{H}_{\\infty}(T|_{(\\hat{S},\\mathsf{pk},b)=\\sigma}) \\geq (2m \\cdot \\log q) - t</span>  for every  <span class="math">\\sigma \\in \\mathrm{supp}(\\hat{S},\\mathsf{pk},b)</span> . Thus, Lemma 23 implies that conditioned on any  <span class="math">(\\hat{S},\\mathsf{pk},b) = \\sigma</span> , the random variable  <span class="math">z_T</span>  is  <span class="math">\\mathsf{ngl}(k)</span> -close to uniform. This clearly implies  <span class="math">(z_T,\\hat{S},\\mathsf{pk},b)</span>  and  <span class="math">(u,\\hat{S},\\mathsf{pk},b)</span>  are statistically close, as desired.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-24-1&quot;&gt;&lt;/span&gt;<strong>Lemma 23</strong> Let X be a distribution over  <span class="math">\\mathbb{F}^{m\\times 2}</span>  with  <span class="math">\\mathbf{H}_{\\infty}(X) \\geq (2m \\cdot \\log q) - (\\log q)/4</span> , and  <span class="math">a = (a_1, a_2) \\leftarrow \\mathbb{F}^2</span> . Then  <span class="math">(X \\cdot a) \\in \\mathbb{F}^m</span>  is  <span class="math">\\varepsilon</span> -close to uniform with  <span class="math">\\varepsilon \\leq 2m \\cdot q^{-1/4}</span> .</p>

    <p class="text-gray-300">We defer the proof of Lemma 23 to Appendix A.</p>

    <h2 id="sec-20" class="text-2xl font-bold">&lt;span id=&quot;page-24-0&quot;&gt;&lt;/span&gt;5 Parallel Composition Lemma</h2>

    <p class="text-gray-300">In this section we give soundness guarantees for a protocol  <span class="math">\\Pi</span>  that executes several protocols  <span class="math">\\Pi_1, \\ldots, \\Pi_t</span>  in parallel, where in each  <span class="math">\\Pi_i = \\langle P_i, V_i \\rangle</span>  the verifier  <span class="math">V_i</span>  uses the same private randomness p. Such a parallel composition lemma will be used to prove soundness both of our memory delegation scheme (in Section 7) and the streaming delegation scheme (in Section 9). For the sake of simplicity, we focus on 2-message protocols, though our results hold for protocols with arbitrary number of messages.</p>

    <p class="text-gray-300">Let  <span class="math">\\Pi_1, \\Pi_2, \\ldots, \\Pi_t</span>  be protocols, where each  <span class="math">\\Pi_i = \\langle P_i, V_i \\rangle</span>  is a 2-message protocol (where the first message is sent by the verifier  <span class="math">V_i</span>  and the second message is sent by the prover  <span class="math">P_i</span> ) for proving  <span class="math">x_i \\in L_i</span> . Let  <span class="math">\\Pi = \\langle P, V(p) \\rangle (x_1, \\ldots, x_t)</span>  be the two-message protocol that runs the protocols  <span class="math">\\Pi_1, \\ldots, \\Pi_t</span>  in parallel, where each  <span class="math">\\Pi_i</span>  is run with the input  <span class="math">x_i</span> , and each verifier  <span class="math">V_i</span>  uses the <em>same</em> private random coin tosses p (in addition to some independent private randomness which each  <span class="math">V_i</span>  may use).  <span class="math">V_i</span>  accepts  <span class="math">V_i</span>  accepts  <span class="math">V_i</span>  if and only if at least one of the  <span class="math">V_i</span> 's accepts  <span class="math">V_i</span>  accepts  <span class="math">V_i</span>  and  <span class="math">V_i</span>  have  <span class="math">V_i</span>  should be thought of as a proof that there exists  <span class="math">V_i</span>  such that  <span class="math">V_i</span>  such that  <span class="math">V_i</span>  is a constant.</p>

    <p class="text-gray-300">We say that a protocol  <span class="math">\\Pi_i</span>  has soundness error  <span class="math">s_i</span>  if for every false statement  <span class="math">x \\notin L_i</span> , and for every efficient cheating prover  <span class="math">P^*</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{p}[V_{i} \\text{ accepts the interaction } \\langle P^{*}, V_{i}(p) \\rangle(x)] \\leq s_{i},</span>$</p>

    <p class="text-gray-300">where the randomness is over p and over any additional random coins that  <span class="math">V_i</span>  may use.</p>

    <p class="text-gray-300">In what follows we prove that if in each protocol  <span class="math">\\Pi_i</span> , the verifier's messages are computationally indistinguishable for all different p's (of length at most poly(k)), then the soundness of all the  <span class="math">\\Pi_i</span> 's implies the soundness of  <span class="math">\\Pi</span> .</p>

    <p class="text-gray-300">&lt;span id=&quot;page-25-0&quot;&gt;&lt;/span&gt;<strong>Lemma 24</strong> Let k be the security parameter and  <span class="math">t \\leq \\text{poly}(k)</span> . Suppose that a protocol  <span class="math">\\Pi</span>  consists of a parallel composition of  <span class="math">\\Pi_1, \\Pi_2, \\ldots, \\Pi_t</span>  of the above form, and suppose that for each i the following two properties hold:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\Pi_i</span>  has soundness error  <span class="math">s_i</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Let  <span class="math">\\{M_{V_i(x_i,p)}\\}</span>  be the distribution of  <span class="math">V_i</span> 's first message, where  <span class="math">x_i</span>  is the common input of  <span class="math">V_i</span>  and  <span class="math">P_i</span> , and p is the the common private random coins of  <span class="math">V_1, \\ldots, V_t</span> . Then, for all  <span class="math">x_i, p, p&#x27;</span>  (of length bounded by poly(k)), the distributions  <span class="math">\\{M_{V_i(x_i,p)}\\}</span>  and  <span class="math">\\{M_{V_i(x_i,p&#x27;)}\\}</span>  are computationally indistinguishable.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Then  <span class="math">\\Pi</span>  has soundness error at most  <span class="math">\\sum_{i \\in [t]} s_i + \\mathsf{ngl}(k)</span> .</p>

    <p class="text-gray-300"><strong>Proof.</strong> Suppose for the sake of contradiction that there exists an efficient (parallel) cheating prover  <span class="math">P^*</span>  and a false input  <span class="math">x = (x_1, \\ldots, x_t)</span>  (i.e., an input x such that for every  <span class="math">i \\in [t]</span> ,  <span class="math">x_i \\notin L_i</span> ) such that  <span class="math">P^*</span>  succeeds in convincing the verifier V running  <span class="math">\\Pi</span>  to accept x with probability</p>

    <p class="text-gray-300"><span class="math">$\\varepsilon &gt; \\sum_{i \\in [t]} s_i + \\alpha(k),</span>$</p>

    <p class="text-gray-300">for some non-negligible function  <span class="math">\\alpha</span> . We argue that there exists a coordinate  <span class="math">i \\in [t]</span>  and an efficient cheating prover  <span class="math">P_i^*</span>  for the protocol  <span class="math">\\Pi_i</span>  that succeed in convincing  <span class="math">V_i</span>  to accept the false  <span class="math">x_i</span>  with probability greater than  <span class="math">s_i + \\alpha/t - \\mathsf{ngl}(k)</span> , which contradicts the assumption.</p>

    <p class="text-gray-300">For every  <span class="math">i \\in [t]</span> , let  <span class="math">W_i</span>  be the event that  <span class="math">P^*</span>  successfully cheats on the <em>i</em>'th coordinate in the protocol  <span class="math">\\Pi(x)</span> , and define  <span class="math">\\varepsilon_i \\triangleq \\Pr[W_i]</span> . By definition, if  <span class="math">P^*</span>  cheats on  <span class="math">\\Pi</span>  then at least one  <span class="math">W_i</span>  holds. Using the union bound, this implies that  <span class="math">\\sum_{i \\in [t]} \\varepsilon_i \\geq \\varepsilon</span> .</p>

    <p class="text-gray-300">Now for each  <span class="math">i \\in [t]</span>  we define a cheating prover  <span class="math">P_i^*</span>  for the protocol  <span class="math">\\Pi_i(x_i)</span>  with the following strategy.  <span class="math">P_i^*</span> , upon receiving a message  <span class="math">M_{V_i(x_i,p)}</span>  from  <span class="math">V_i</span> , simulates the interaction between  <span class="math">P^*</span>  and V by embedding the real message of  <span class="math">V_i</span>  into the i-th coordinate, and setting the other  <span class="math">V_j</span> 's messages to be  <span class="math">M_{V_i(x_i,0)}</span>  for  <span class="math">j \\neq i</span> . Then  <span class="math">P_i^*</span>  replies what  <span class="math">P^*</span>  does in the i'th coordinate.</p>

    <p class="text-gray-300">Denote the success probability of  <span class="math">P_i^*</span>  by  <span class="math">\\tilde{\\varepsilon}_i</span> . By the message indistinguishability of  <span class="math">\\{M_{V_j(x_j,0)}\\}</span>  and  <span class="math">\\{M_{V_j(x_j,p)}\\}</span>  for  <span class="math">j \\neq i</span> , we know that  <span class="math">\\tilde{\\varepsilon}_i &gt; \\varepsilon_i - \\mathsf{ngl}(k)</span> ; otherwise there is a distinguisher that distinguishes between the distributions  <span class="math">\\{M_{V_k(x_k,0)}\\}</span>  and  <span class="math">\\{M_{V_k(x_k,p)}\\}</span>  for some  <span class="math">k \\neq i</span>  (by a standard hybrid argument).</p>

    <p class="text-gray-300">Thus,</p>

    <p class="text-gray-300"><span class="math">$\\sum_{i \\in [t]} \\tilde{\\varepsilon}_i \\geq \\sum_{i \\in [t]} \\varepsilon_i - t \\cdot \\mathsf{ngl}(k) \\geq \\varepsilon - \\mathsf{ngl}(k) \\geq \\sum_{i \\in [t]} s_i + \\alpha(k) - \\mathsf{ngl}(k).</span>$</p>

    <p class="text-gray-300">This implies that there exists i such that  <span class="math">\\tilde{\\epsilon}_i \\geq s_i + \\alpha/t - \\text{ngl}(k)</span> , which contradicts the assumption.</p>

    <p class="text-gray-300">We note that in the streaming delegation and memory delegation schemes, the delegator (verifier) uses an FHE scheme or a PIR scheme to achieve the property that  <span class="math">\\{M_{V_i(x_i,p)}\\}</span>  and  <span class="math">\\{M_{V_i(x_i,p&#x27;)}\\}</span>  are computationally indistinguishable. This allows us to make use of Lemma 24.</p>

    <h2 id="sec-21" class="text-2xl font-bold">&lt;span id=&quot;page-26-0&quot;&gt;&lt;/span&gt;6 Memory Delegation Model</h2>

    <p class="text-gray-300">In this section, we formally define our memory delegation model. We present our memory delegation scheme in Section 7.</p>

    <p class="text-gray-300"><strong>Definition 25 (Memory Delegation Scheme)</strong> Let  <span class="math">\\mathcal{F}, \\mathcal{G}</span>  be two sets of functions. A memory delegation scheme for functions in  <span class="math">\\mathcal{F}</span>  and updates in  <span class="math">\\mathcal{G}</span> , is an interactive protocol  <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}} = \\langle \\mathsf{D}, \\mathsf{W} \\rangle</span>  between a delegator  <span class="math">\\mathsf{D}</span>  and a worker  <span class="math">\\mathsf{W}</span> , of the following form:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The scheme mDel consists of two stages: an offline/preprocessing stage and an online stage. The offline stage is executed only once before the online stage, whereas the online stage can be executed many times.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>In the offline stage, both the delegator D and the worker W receive a security parameter  <span class="math">1^k</span>  and an input  <span class="math">x \\in \\{0,1\\}^n</span> . The worker stores x, and the delegator computes a short (possibly secret) string  <span class="math">\\sigma_D</span>  and stores it for future use.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>In the online stage, the delegator can interact with the worker via the following two operations.</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>A computation operation Compute(f) where both parties take as input a function f ∈ F.
This input is in addition to the inputs that the parties store throughout the delegation protocol: the security parameter 1&lt;sup&gt;k&lt;/sup&gt;, the current memory content x ∈ {0,1}&lt;sup&gt;n&lt;/sup&gt; stored only by the worker W, and the short (possibly secret) string σ&lt;sub&gt;D&lt;/sub&gt; stored only by the delegator D.
Then, W proves to D that y = f(x), for some y ∈ {0,1}*.</li>
      <li>An update operation Update(g) where both parties take as input a function g: {0,1}&lt;sup&gt;n&lt;/sup&gt; → {0,1}&lt;sup&gt;n'&lt;/sup&gt; ∈ G. This is in addition to the inputs that the parties store throughout the delegation protocol: the security parameters 1&lt;sup&gt;k&lt;/sup&gt;, the current memory content x ∈ {0,1}&lt;sup&gt;n&lt;/sup&gt; stored only by the worker W, and the short (possibly secret) string σ&lt;sub&gt;D&lt;/sub&gt; stored only by the delegator D. Then W and D interact, where W &quot;helps&quot; D update her secret σ&lt;sub&gt;D&lt;/sub&gt;. At the end of the interaction, if D accepts, she updates her secret to some σ'&lt;sub&gt;D&lt;/sub&gt; and believes that the stored x has been updated to g(x). Otherwise, she keeps her secret σ&lt;sub&gt;D&lt;/sub&gt; (and thinks of the previous x as unchanged).</li>
    </ul></li>
    </ul>

    <p class="text-gray-300">At the end of each operation, D sends W a decision bit  <span class="math">b \\in \\{0,1\\}</span>  for her acceptance or rejection.</p>

    <p class="text-gray-300">For a delegation scheme to be meaningful, it needs to have efficiency, completeness and soundness properties, defined below.</p>

    <p class="text-gray-300"><strong>Definition 26 (Efficiency)</strong> A delegation scheme  <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}</span>  has an efficient delegator in the offline stage if D runs in time  <span class="math">\\mathsf{poly}(k,n)</span>  in the offline stage. It has an efficient delegator in the online stage if D runs in time  <span class="math">\\mathsf{poly}(k)</span>  (independent of n) during each operation in the online stage.</p>

    <p class="text-gray-300">A delegation scheme  <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}</span>  has an efficient worker if the runtime of W is  <span class="math">\\mathsf{poly}(k,n)</span>  during both the offline stage and during each operation in the online stage, where n is the length of the delegated memory.</p>

    <p class="text-gray-300"><strong>Definition 27 (Completeness)</strong> For any sets of functions  <span class="math">\\mathcal{F}, \\mathcal{G}</span> , a delegation scheme  <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}} = \\langle \\mathsf{D}, \\mathsf{W} \\rangle</span>  has perfect completeness if for every  <span class="math">k, n \\in \\mathbb{N}</span> , and for every  <span class="math">x \\in \\{0,1\\}^n</span> , the following holds with probability 1:&lt;sup&gt;19&lt;/sup&gt; When D and W run the offline stage with input  <span class="math">(1^k, x)</span> , and then run the online</p>

    <p class="text-gray-300">&lt;span id=&quot;page-26-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;19&lt;/sup&gt;It has completeness  <span class="math">1 - \\epsilon</span>  if the following holds with probability  <span class="math">1 - \\epsilon</span> .</p>

    <p class="text-gray-300">stage polynomially many times with the operations Update(g), for any  <span class="math">g \\in \\mathcal{G}</span> , and Compute(f), for any  <span class="math">f \\in \\mathcal{F}</span> , the delegator D always accepts (i.e., sends W the decision bit 1).</p>

    <p class="text-gray-300">The definition of soundness is more elaborate, and requires defining the following security game. We emphasize that our soundness definition is <em>reusable</em> in the sense that we require that a (computationally bounded) cheating worker cannot convince the delegator to accept a wrong statement, even after interacting with the delegator polynomially many times, and each time learning whether the delegator accepted or rejected the proof.</p>

    <p class="text-gray-300">One could define security w.r.t. cheating workers of size T(k) for any (possibly super-polynomial) function T. However, for the sake of simplicity of notation, we define soundness w.r.t. poly-size cheating workers.</p>

    <p class="text-gray-300"><strong>Definition 28 (Reusable Security Game)</strong> Let  <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}} = \\langle \\mathsf{D},\\mathsf{W} \\rangle</span>  be a delegation scheme. For a security parameter  <span class="math">k \\in \\mathbb{N}</span>  and for a PPT (cheating) worker  <span class="math">\\mathsf{W}^*</span> , the security game  <span class="math">\\mathsf{G}^{\\mathsf{W}^*}(k)</span>  is defined as follows.</p>

    <p class="text-gray-300">The game starts with the offline stage of  <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}</span> , and is followed by polynomially many rounds of the online stage.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(Initial Phase)  <span class="math">W^*(1^k)</span>  first chooses a parameter n = poly(k) and an input  <span class="math">x \\in \\{0,1\\}^n</span> . Then, D and  <span class="math">W^*(1^k)</span>  run the offline stage on inputs  <span class="math">(1^k, x)</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(Learning Phase) At the beginning of each round of the online stage, W* can do one of the following:</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(a) Terminate this phase.</li>
      <li>(b) Choose a function  <span class="math">f \\in \\mathcal{F}</span>  and interact with D in the online stage with the operation Compute(f).</li>
      <li>(c) Choose a function  <span class="math">g \\in \\mathcal{G}</span>  and interact with D in the online stage with the operation  <span class="math">\\mathsf{Update}(g)</span> .</li>
    </ul></li>
    </ul>

    <p class="text-gray-300">After each round, if W* did not terminate the phase, D sends her decision bit to W*.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(Challenge Phase) If the learning phase is terminated, W* chooses a function  <span class="math">f&#x27; \\in \\mathcal{F}</span> , and D and W* execute Compute(f').</li>
    </ol>

    <p class="text-gray-300">W* succeeds in the game  <span class="math">G^{W^*}(k)</span>  if D accepts a wrong value  <span class="math">y&#x27; \\neq f&#x27;(x)</span> , where x is the latest updated memory.</p>

    <p class="text-gray-300"><strong>Definition 29 (Reusable Soundness)</strong> A delegation scheme  <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}} = \\langle \\mathsf{D},\\mathsf{W} \\rangle</span>  has <strong>reusable soundness error</strong>  <span class="math">\\varepsilon</span>  if for every  <span class="math">k \\in \\mathbb{N}</span>  and every PPT worker strategy  <span class="math">\\mathsf{W}^*</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr[\\mathsf{W}^* \\ succeeds \\ in \\ \\mathsf{G}^{\\mathsf{W}^*}(k)] \\le \\varepsilon(k),</span>$</p>

    <p class="text-gray-300">where  <span class="math">\\mathsf{G}^{\\mathsf{W}^*}(k)</span>  is the security game corresponding to  <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}</span> , as defined above. We say that  <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}}</span>  is sound if it has a negligible soundness error.</p>

    <p class="text-gray-300"><strong>Remark.</strong> We stress that in the soundness definition, we allow the adversary W* to learn the decision bit of the delegator D after each execution of the delegation protocol. This is in contrast to the two delegation schemes of [GGP10, CKV10], which are only sound if the adversary W* does not learn the decision bit of the delegator D. We elaborate on this point when we discuss the streaming setting, in Section 8.</p>

    <p class="text-gray-300">In what follows we define the notion of <em>one-time soundness</em>. The reason we need this definition is that the soundness proof of our memory delegation scheme (in Section 7), consists of two parts. We first prove that our scheme has one-time soundness, i.e., it is sound assuming the delegation protocol is executed only once. Then, we argue that the fact that it is one-time sound, implies that it is also sound from multiple interactions (i.e., has reusable soundness.)</p>

    <p class="text-gray-300"><strong>Definition 30 (One-time Security Game and One-time Soundness)</strong> Let  <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}} = \\langle \\mathsf{D}, \\mathsf{W} \\rangle</span>  be a delegation scheme. For a security parameter  <span class="math">k \\in \\mathbb{N}</span>  and for a (cheating) worker  <span class="math">\\mathsf{W}^*</span> , the one-time security game  <span class="math">\\mathsf{G}_1^{\\mathsf{W}^*}(k)</span>  is defined similarly to the security game in Definition 37, except that they do not execute the learning phase, and just proceed to the challenge phase directly from the initial phase.</p>

    <p class="text-gray-300">We say  <span class="math">\\mathsf{mDel}_{\\mathcal{F},\\mathcal{G}} = \\langle \\mathsf{D}, \\mathsf{W} \\rangle</span>  has <strong>one-time soundness error</strong>  <span class="math">\\varepsilon</span>  if for every  <span class="math">k \\in \\mathbb{N}</span>  and every PPT worker strategy  <span class="math">\\mathsf{W}^*</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr[\\mathsf{W}^* \\ succeeds \\ in \\ \\mathsf{G}_1^{\\mathsf{W}^*}(k)] \\le \\varepsilon(k).</span>$</p>

    <p class="text-gray-300">We say that  <span class="math">mDel_{\\mathcal{F},\\mathcal{G}}</span>  is <strong>one-time sound</strong> if it has a negligible one-time soundness error.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-28-2&quot;&gt;&lt;/span&gt;<strong>Theorem 31 (Memory Delegation)</strong> Assume the existence of a poly-log PIR scheme (as defined in Definition 5) and a collision resistant hash function family. Then there exists a non-interactive (2-message) memory delegation scheme mDel, for delegating any function computable by an  <span class="math">\\mathcal{L}</span> -uniform poly-size circuit. The delegation scheme, mDel has the following properties, for security parameter k.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The scheme has perfect completeness and negligible (reusable) soundness error.</li>
      <li>The delegator and worker are efficient in the offline stage; i.e., both the delegator and the worker run in time poly(k, n).</li>
      <li>The worker is efficient in the online phase. More specifically, it runs in time poly(k, S) during each Compute(f) and Update(f) operation, where S is the size of the  <span class="math">\\mathcal{L}</span> -uniform circuit computing f. The delegator runs in time poly(k, d) during each Compute(f) and Update(f) operation, where d is the depth of the  <span class="math">\\mathcal{L}</span> -uniform circuit computing f.&lt;sup&gt;20&lt;/sup&gt;</li>
    </ul>

    <h2 id="sec-22" class="text-2xl font-bold">&lt;span id=&quot;page-28-0&quot;&gt;&lt;/span&gt;7 Memory Delegation Scheme</h2>

    <p class="text-gray-300">In this section, we prove Theorem 31, by constructing a non-interactive memory delegation scheme with the desired properties.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-28-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;20&lt;/sup&gt;Thus, for every constant  <span class="math">c \\in \\mathbb{N}</span> , if we restrict the depth of f to be at most  <span class="math">k^c</span> , then the delegator is considered efficient.</p>

    <h2 id="sec-23" class="text-2xl font-bold">&lt;span id=&quot;page-29-0&quot;&gt;&lt;/span&gt;7.1 Overview of our Memory Delegation Scheme</h2>

    <p class="text-gray-300">The initial idea behind our memory delegation scheme, is the observation of Goldwasswer et. al. <a href="#page-66-0">[GKR08]</a>, that their delegation protocol can be verified very efficiently (in time sub-linear in the input size), if the delegator has oracle access to the low-degree extension of the input x (we refer the reader to Section <a href="#page-13-0">3.3</a> for the definition of a low-degree extension). Moreover, as observed by <a href="#page-66-0">[GKR08]</a>, the delegator needs to access this low-degree extension LDE&lt;sup&gt;x&lt;/sup&gt; at a single point z, which depends only on the random coin tosses of the delegator.</p>

    <p class="text-gray-300">This observation immediately gives rise to a memory delegation scheme with one-time soundness: The delegator's secret state will be (z, LDEx(z)). Then, she will use this secret state in order to verify computation using the GKR protocol. As was argued by Goldwasswer et. al., this indeed works if the delegator runs the delegation protocol once. However, the soundness crucially relies on the fact that the delegator's secret state is indeed secret, and if the delegator uses this state more than once, then soundness breaks completely.</p>

    <p class="text-gray-300">One idea, following the idea of Gennaro et. al. <a href="#page-65-7">[GGP10]</a>, is to use a fully homomorphic encryption (FHE) scheme to encrypt all the communication, in order to hide the secret state. This indeed works if the worker does not learn whether the delegator accepts or rejects his proofs. However, if the worker does learn the verdict of the delegator, then there are known attacks that break soundness.</p>

    <p class="text-gray-300">In the streaming setting, we follow this approach, and we succeed in overcoming this problem, and construct a scheme that is sound even if the worker does learn the verdict of the delegator. We could follow this approach in the memory delegation setting as well. However, for several reasons, we choose to take a different approach. First, the approach above relies on the existence of an FHE scheme, whereas our memory delegation scheme relies on the existence of a poly-logarithmic PIR scheme, arguably a more reasonable assumption. Second, the approach above results with the delegator having a secret state, whereas in our memory delegation scheme, the state of the delegator is public. Finally, the construction and proof of the memory delegation scheme is simpler.</p>

    <p class="text-gray-300">In our approach, instead of having (z, LDEx(z)) as the delegator's secret state, the delegator keeps a tree-commitment of the entire LDE&lt;sup&gt;x&lt;/sup&gt; as her secret state (recall the definition of a treecommitment in Section <a href="#page-15-0">3.5)</a>. Namely, she chooses a random hash function h from a collisionresistant hash family, and keeps (h, Th(LDEx)) as her state. In addition to giving the worker her memory x, she also gives him the hash function h. Notice that her state is not secret, which makes the proof of security significantly simpler than that in the streaming setting (where the delegator's state is secret).</p>

    <p class="text-gray-300">When the delegator wishes to delegate the computation of a function f, they will execute Compute(f), by simply running the (non-interactive) delegation protocol GKR(f). Recall that at the end of the GKR protocol the delegator needs to verify the value of LDEx(r) for a random r. However, she doesn't have x, since it was delegated to the prover, and all she has is the state (h, Th(LDEx)). So, rather than computing the value of LDEx(r) on her own, she will ask the worker to reveal to this value, by sending the augmented path in the Merkle tree corresponding to the leaf r. <a href="#page-29-1">21</a></p>

    <p class="text-gray-300">When the delegator wishes to update her memory from x to g(x), she will need to update her secret state from (h, Th(LDEx)) to (h, Th(LDEg(x) )). As before, she cannot perform this operation on her own, and instead she will delegate this computation to the worker, by requesting a</p>

    <p class="text-gray-300">&lt;span id=&quot;page-29-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;21&lt;/sup&gt;As we shall see in a few paragraphs, this is an oversimplification, and due to technical reasons, the actual protocol is more complicated.</p>

    <p class="text-gray-300">Compute(g') operation, where  <span class="math">g&#x27;(x) = T_h(LDE_{g(x)})</span> .</p>

    <p class="text-gray-300">Unfortunately the high-level description given above is a gross oversimplification of our scheme, and there are several technical issues that complicate matters.</p>

    <p class="text-gray-300">The first technicality (the easiest one to deal with), is that the GKR delegation scheme does not have a negligible soundness error. In our setting, it is very important to have negligible soundness, since if the soundness is non-negligible, then a cheating worker may cheat in the update procedure (which is also being delegated). The problem is that if a worker cheats even once in an update procedure, all soundness guarantees are mute from that point on. So, we really need the soundness error to be negligible. In order to reduce the soundness error, we will run the GKR protocol in parallel u times (for any parameter u such that  <span class="math">1/2^u = ngl(k)</span> ). We denote the u-fold parallel repetition of GKR by GKR&lt;sup&gt;(u)&lt;/sup&gt;. As a result the worker will need to reveal to u augmented paths of the Merkle tree.</p>

    <p class="text-gray-300">The other technical point is more subtle. In the offline stage, when the delegator computes the tree commitment  <span class="math">T_h(\\text{LDE}_x)</span> , she needs to choose the parameters  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span>  for the low-degree extension. The typical choice for these parameters is:  <span class="math">|\\mathbb{H}| = \\text{polylog}(n)</span> ,  <span class="math">|\\mathbb{F}| = \\text{poly}(|\\mathbb{H}|)</span> , and  <span class="math">m = O\\left(\\frac{\\log n}{\\log \\log n}\\right)</span> , where n = |x|. However, when delegating the computation of a function f, the worker and delegator run  <span class="math">GKR^{(u)}(f)</span>  and need to verify  <span class="math">LDE_x(r_i) = v_i</span>  for random points  <span class="math">r_1, \\ldots, r_u</span> . However, here the parameters of the low-degree extension  <span class="math">LDE_x</span>  depend on the depth d of the circuit computing f. Namely, looking at the parameters in Theorem 8, the parameters of the low-degree extension are</p>

    <p class="text-gray-300"><span class="math">$|\\mathbb{H}&#x27;| = \\theta(d \\cdot \\log n), \\ m&#x27; = \\theta\\left(\\frac{\\log n}{\\log d}\\right), \\ |\\mathbb{F}&#x27;| = \\text{poly}(|\\mathbb{H}&#x27;|).</span>$</p>

    <p class="text-gray-300">Therefore, the worker cannot simply send the augmented path, since the tree commitment is w.r.t. parameters  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span>  whereas the delegator needs to verify  <span class="math">LDE_x(r_i) = v_i</span>  w.r.t. the parameters  <span class="math">\\mathbb{H}&#x27;, \\mathbb{F}&#x27;, m&#x27;</span> .</p>

    <p class="text-gray-300">We get around this technical problem by delegating the functions  <span class="math">g_{r_i}(x) \\triangleq LDE_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span> . Luckily, Corollary 7 implies that these functions can be computed by a poly-size circuit of depth  <span class="math">\\log^c(n)</span>  for some constant c (assuming the delegated function f is of poly-size). Again, we delegate the computation of each of these  <span class="math">g_{r_i}</span>  using  <span class="math">GKR^{(u)}</span>  to ensure negligible soundness. Thus, finally the worker will need to reveal the augmented paths of  <span class="math">u^2</span>  points in  <span class="math">LDE_x</span>  (u points for each  <span class="math">g_{r_i}</span> ).</p>

    <p class="text-gray-300">The final technical difficulty is that all these algorithms need to run in parallel, since we want our final memory delegation scheme to be non-interactive (i.e., to consist of only two messages). Typically, there is no problem in running several two-message protocols in parallel. However, in our case, the delegator uses a common secret input in these protocols. Namely, the delegator uses secret randomness  <span class="math">r_1, \\ldots, r_u \\in (\\mathbb{F}&#x27;)^{m&#x27;}</span>  in the parallel repetition of the delegation protocol GKR(f) which ends with her needing to verify that  <span class="math">LDE_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i) = v_i</span>  for every  <span class="math">i \\in [u]</span> . In addition she uses these same  <span class="math">r_i</span> 's in the delegation protocols  <span class="math">GKR(g_{r_i})</span> . Moreover, at the end of each of the  <span class="math">GKR(g_{r_i})</span>  protocols, the delegator needs to verify that  <span class="math">LDE_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j}) = w_{i,j}</span>  for random points  <span class="math">z_{i,1}, \\ldots, z_{i,u} \\in \\mathbb{F}^m</span> . Finally, they also run a reveal protocol for each  <span class="math">z_{i,j}</span> , denoted by  <span class="math">Reveal(z_{i,j})</span> , where the worker simply reveals to the augmented path of the leaf  <span class="math">z_{i,j}</span>  in the Merkle tree of  <span class="math">LDE_x^{\\mathbb{F},\\mathbb{H},m}</span> .</p>

    <p class="text-gray-300">We note that the protocol GKR(f) (resp. GKR(g)) is not sound if the  <span class="math">r_i</span> 's (resp.  <span class="math">z_{i,j}</span> 's) are a priori known to the worker. To ensure that soundness still holds even if we run all these algorithms</p>

    <p class="text-gray-300">&lt;span id=&quot;page-30-0&quot;&gt;&lt;/span&gt;We note that there are several ways to improve efficiency, such as thinking of  <span class="math">(g_{r_1}, \\ldots, g_{r_u})</span>  as one function. However, for the sake of simplicity of exposition, we focus on the simplest (rather than most efficient) solution.</p>

    <p class="text-gray-300">in parallel, we mask parts of the delegator's message using a PIR scheme, and then we use Lemma 24 to claim that the soundness error remains negligible.</p>

    <h3 id="sec-24" class="text-xl font-semibold mt-8">&lt;span id=&quot;page-31-0&quot;&gt;&lt;/span&gt;7.2 Formal Description of our Memory Delegation Scheme</h3>

    <p class="text-gray-300">Our construction uses the following building blocks</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>A collision resistant hash family  <span class="math">\\mathcal{H} = \\{\\mathcal{H}_k\\}_{k \\in \\mathbb{N}}</span> , where every  <span class="math">h \\in \\mathcal{H}_k</span>  satisfies</li>
    </ol>

    <p class="text-gray-300"><span class="math">$h: \\{0,1\\}^k \\times \\{0,1\\}^k \\to \\{0,1\\}^k.</span>$</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The delegation scheme GKR =  <span class="math">\\langle D&#x27;, W&#x27; \\rangle</span>  from [GKR08, KR09] (see Theorem 8 for the properties of this delegation scheme). The main property we use here, is that the delegator can verify proofs by accessing its input x at a single random point in  <span class="math">LDE_x</span> .</li>
    </ol></li>
      <li>Parameters. Let  <span class="math">k \\in \\mathbb{N}</span>  be the security parameter, and let  <span class="math">n \\in \\mathbb{N}</span>  be the length of the (initial) memory being delegated. Let  <span class="math">\\mathbb{H}</span>  be an extension field of  <span class="math">\\mathbb{GF}[2]</span> , and let  <span class="math">m \\in \\mathbb{Z}</span>  such that  <span class="math">|\\mathbb{H}| = \\text{polylog}(n)</span> ,  <span class="math">m = \\theta\\left(\\frac{\\log n}{\\log\\log n}\\right)</span> , and let  <span class="math">\\mathbb{F}</span>  be an extension field of  <span class="math">\\mathbb{H}</span>  of size  <span class="math">|\\mathbb{F}| = \\text{poly}(|\\mathbb{H}|)</span> .</li>
      <li>Offline Phase. In the offline phase, both the delegator D and the worker W take as input the security parameter  <span class="math">1^k</span>  and a string  <span class="math">x \\in \\{0,1\\}^n</span> . The worker W simply saves x. The delegator D does the following.    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Compute the low-degree extension of x w.r.t.  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span> , denoted by  <span class="math">\\mathrm{LDE}_x : \\mathbb{F}^m \\to \\mathbb{F}</span>  (see Section 3.3 for the definition of a low-degree extension). She interprets  <span class="math">\\mathrm{LDE}_x</span>  as a vector in  <span class="math">\\mathbb{F}^{|\\mathbb{F}|^m}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Choose a random collision resistant hash-function  <span class="math">h \\leftarrow \\mathcal{H}_k</span> , and sends h to W.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Compute the root of the Merkle tree of  <span class="math">LDE_x</span>  with respect to the hash function h. Namely, compute  <span class="math">\\sigma = T_h(LDE_x)</span> , which is the root of the Merkle tree corresponding to the hash function h (we refer the reader to Section 3.5 for the definition of a Merkle tree).</li>
    </ol></li>
    </ul></li>
    </ul>

    <p class="text-gray-300">The delegator D saves  <span class="math">(h, \\sigma)</span>  as a short certificate for x.</p>

    <h4 id="sec-25" class="text-lg font-semibold mt-6">• Online-Phase.</h4>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Compute(f). When the delegator D sends the worker W a computation request Compute(f), they run the following three protocols in parallel.    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Run the underlying delegation protocol GKR =  <span class="math">\\langle D&#x27;, W&#x27; \\rangle</span>  for delegating the computation of f(x). However, since the soundness of the GKR protocol is only 1/2, we amplify this soundness by repeating the GKR protocol u times in parallel. Namely, W and D run GKR&lt;sup&gt;(u)&lt;/sup&gt; which is a u-fold parallel repetition of the GKR protocol, and thus has soundness  <span class="math">1/2^u + \\mathsf{ngl}(k) = \\mathsf{ngl}(k)</span>  (assuming we take u such that  <span class="math">1/2^u = \\mathsf{ngl}(k)</span> ).</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>If D' rejects, then D rejects. Otherwise, at the end of this protocol the delegator D needs to verify that  <span class="math">LDE_x(r_i) = v_i</span>  for some random points  <span class="math">r_1, \\ldots, r_u</span> . Recall that</li>
    </ul></li>
    </ul></li>
    </ul>

    <p class="text-gray-300">these points depend only on the delegators random coin tosses, and can be efficiently computed by the delegator D before the protocol execution begins (see Theorem 8).</p>

    <p class="text-gray-300">Recall that the low-degree extension  <span class="math">LDE_x</span> , is not w.r.t. the parameters  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span> , but rather w.r.t. parameters  <span class="math">\\mathbb{H}&#x27;, \\mathbb{F}&#x27;, m&#x27;</span>  that depend on the depth d of the  <span class="math">\\mathcal{L}</span> -uniform circuit computing f (see Theorem 8 and the discussion in Section 7.1). Thus, the delegator cannot verify that</p>

    <p class="text-gray-300"><span class="math">$LDE_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i) = v_i</span>$</p>

    <p class="text-gray-300">by simply asking the worker to &quot;decommit&quot; to the leaves  <span class="math">r_1, \\ldots, r_u</span>  of the Merkle tree, by sending their augmented paths (since the tree commitment was on the low-degree extension of x w.r.t.  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span> ). Instead they will run the following additional protocol (in parallel).</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The idea is to run for every  <span class="math">i \\in [u]</span> , the delegation protocol  <span class="math">GKR^{(u)} = \\langle D&#x27;, W&#x27; \\rangle</span>  for delegating the functions  <span class="math">g_{r_i}</span> , where</li>
    </ol>

    <p class="text-gray-300"><span class="math">$g_{r_i}(x) = LDE_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i).</span>$</p>

    <p class="text-gray-300">(As in Step 1, we use parallel repetition in order to reduce the soundness error to ngl(k)). However, note that since these delegation protocols are running in parallel with the delegation protocol  <span class="math">GKR^{(u)}</span>  of Step 1, the  <span class="math">r_i</span> 's (which are part of the description of  <span class="math">g_{r_i}</span> ) must be kept secret, to ensure the soundness of the  <span class="math">GKR^{(u)}</span>  protocol of Step 1.</p>

    <p class="text-gray-300">Thus, to ensure the secrecy of the  <span class="math">r_i</span> 's, instead of running the  <span class="math">GKR^{(u)}</span>  protocols of Step 2 &quot;in the clear&quot;, we mask them using a PIR scheme. In what follows, we explain what a single masked  <span class="math">GKR^{(u)}</span>  protocol for computing  <span class="math">g_{r_i}</span>  looks like, and this protocol will be repeated in parallel u times (once for each  <span class="math">i \\in [u]</span> ).</p>

    <p class="text-gray-300">Recall that in the GKR protocol (and thus in the GKR&lt;sup&gt;(u)&lt;/sup&gt; protocol), the message sent by the delegator D' depends only on the parameters (and her random coin tosses), and is independent of the actual function being delegated (see Theorem 8). Thus, this message can be sent in the clear, as it reveals no information about the function  <span class="math">g_{r_i}</span>  being delegated (except for its size and depth), and thus reveals no information about the secret value  <span class="math">r_i</span> . On the other hand, the message sent by the worker W' obviously does depend on  <span class="math">g_{r_i}</span> , and thus on  <span class="math">r_i</span> . Since the  <span class="math">r_i</span> 's should be kept secret, this message will be sent using a PIR scheme.</p>

    <p class="text-gray-300">Namely, the worker W prepares a database DB' with  <span class="math">N&#x27; \\triangleq |\\mathbb{F}&#x27;|^{m&#x27;}</span>  entries, where the entry  <span class="math">r \\in (\\mathbb{F}&#x27;)^{m&#x27;}</span>  contains the message he would have sent (in the parallel version  <span class="math">GKR^{(u)}</span> ) if the delegated function was  <span class="math">g_r(x) = LDE_x^{F&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r)</span> . The delegator D, in addition to sending a  <span class="math">GKR^{(u)}</span>  message, also sends a query  <span class="math">q&#x27;_i \\leftarrow Q^{PIR}(k, r_i, N&#x27;)</span> . Then, the worker W answers the PIR query  <span class="math">q&#x27;_i</span>  using the database DB'; i.e., he sends  <span class="math">a&#x27;_i \\leftarrow D^{PIR}(k, DB&#x27;, q&#x27;_i)</span> . Finally, the delegator D retrieves the &quot;worker's message&quot; using the Retrieve algorithm  <span class="math">R^{PIR}</span> , and accepts this message if and only if  <span class="math">(D&#x27;)^{(u)}</span>  would have accepted it, and if it is consistent with Step 1; i.e., if the worker proved that indeed  <span class="math">g_{r_i}(x) = v_i</span> , for the same value  <span class="math">v_i</span>  obtained in Step 1.</p>

    <p class="text-gray-300">As before, for every  <span class="math">i \\in [u]</span> , to verify the <em>i</em>'th delegation protocol GKR&lt;sup&gt;(u)&lt;/sup&gt; for computing  <span class="math">g_{r_i}(x) = \\text{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span> , the delegator D' needs to verify that  <span class="math">\\text{LDE}_x(z_{i,j}) = w_{i,j}</span> ,</p>

    <p class="text-gray-300">for random values  <span class="math">z_{i,1}, \\ldots, z_{i,u}</span>  that depend only on the parameters and on the delegator's random coin tosses. However, here  <span class="math">\\mathrm{LDE}_x</span>  is w.r.t. the parameters  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span> , since the function  <span class="math">g_{r_i}</span>  is computable by  <span class="math">\\mathcal{L}</span> -uniform circuit of depth polylog(n) (follows from Corollary 7). In order to verify this, they run the following Reveal protocol u times per each  <span class="math">i \\in [u]</span> , and thus altogether they run the Reveal protocol  <span class="math">u^2</span>  times.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The delegator and worker run a Reveal protocol  <span class="math">u^2</span>  times, where the delegator sends  <span class="math">z_{i,j} \\in \\mathbb{F}^m</span>  and the worker reveals the augmented path of the Merkle tree corresponding to the leaf  <span class="math">z_{i,j}</span> , denoted by  <span class="math">\\operatorname{aug}(z_{i,j})</span> . However, since  <span class="math">z_{i,j}</span>  needs to remain secret for the GKR&lt;sup&gt;(u)&lt;/sup&gt; protocols in Step 2 to remain sound, this will be done using a PIR scheme. Namely, the worker W does the following. He prepares a database DB of size  <span class="math">N \\triangleq |\\mathbb{F}|^m</span> , where for any  <span class="math">z \\in \\mathbb{F}^m</span>  the z'th entry contains  <span class="math">\\operatorname{aug}(z)</span>  (i..e, the augmented path corresponding to the leaf z in the Merkle tree of  <span class="math">\\operatorname{LDE}_x</span> ). The delegator D sends a query  <span class="math">q_{i,j} \\leftarrow Q^{\\operatorname{PIR}}(k, z_{i,j}, N)</span> , and the worker W answers according to his database  <span class="math">a_{i,j} \\leftarrow D^{\\operatorname{PIR}}(k, \\operatorname{DB}, q_{i,j})</span> . Finally, the delegator D retrieves the answer using the retrieving algorithm  <span class="math">R^{\\operatorname{PIR}}</span> , and accepts this answer if and only if the retrieved string is a valid augmented path of the Merkle tree corresponding to the leaf  <span class="math">z_{i,j}</span> , and if the leaf value is  <span class="math">w_{i,j}</span> .</li>
    </ol>

    <p class="text-gray-300">We denote the delegation protocol of Step 1 by</p>

    <p class="text-gray-300"><span class="math">$GKR^{(u)} = \\langle W&#x27;^{(u)}, D&#x27;^{(u)}(r_1, \\dots, r_u) \\rangle (f).</span>$</p>

    <p class="text-gray-300">We denote the masked delegation protocols of Step 2 by</p>

    <p class="text-gray-300">PIR
<span class="math">$\\left(\\langle \\mathsf{W}&#x27;^{(u)}, \\mathsf{D}&#x27;^{(u)}(z_{i,1},\\ldots,z_{i,u})\\rangle(g_{r_i})\\right)</span>$
.</p>

    <p class="text-gray-300">We denote the reveal protocols of Step 3 by  <span class="math">Reveal(z_{i,j})</span> . Note that the memory x is implicit in all these notations. We summarize the Compute(f) protocol in Figure 3.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Update(g). When the delegator D sends the worker W an update request Update(g) for some  <span class="math">g \\in \\mathcal{G}</span> , indicating that she wishes to update her memory x to g(x), the worker and delegator do the following.    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The delegator D uses the help of the worker W in order to update her short certificate. Specifically, D chooses a fresh hash function  <span class="math">h&#x27; \\leftarrow \\mathcal{H}_k</span> , and sends h' to W. Then, she delegates to the worker W the computation Compute(g'), where</li>
    </ol></li>
    </ul></li>
    </ul>

    <p class="text-gray-300"><span class="math">$g&#x27;(x) = T_{h&#x27;}(LDE_{g(x)}),</span>$</p>

    <p class="text-gray-300">where  <span class="math">\\mathrm{LDE}_{g(x)}</span>  is w.r.t.  <span class="math">\\mathbb{H}&#x27;, \\mathbb{F}&#x27;, m&#x27;</span> , where letting  <span class="math">n&#x27; \\triangleq |g(x)|</span> , the field  <span class="math">\\mathbb{H}&#x27;</span>  is an extension field of  <span class="math">\\mathbb{GF}[2]</span>  of size  <span class="math">|\\mathbb{H}&#x27;| = \\mathrm{polylog}(n&#x27;)</span> ,  <span class="math">m&#x27; = \\theta\\left(\\frac{\\log n&#x27;}{\\log \\log n&#x27;}\\right)</span> , and  <span class="math">\\mathbb{F}&#x27;</span>  is an extension field of  <span class="math">\\mathbb{H}&#x27;</span>  of size  <span class="math">\\mathrm{poly}(|\\mathbb{H}&#x27;|)</span> . If she rejects this proof, then no update is performed. Otherwise, she updates her short certificate from  <span class="math">\\sigma</span>  to  <span class="math">\\sigma&#x27; \\triangleq T_{h&#x27;}(\\mathrm{LDE}_{g(x)})</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The worker W updates his state from x to g(x).</li>
    </ol>

    <p class="text-gray-300">Note that if the function g is computed by an  <span class="math">\\mathcal{L}</span> -uniform circuit of depth d, then the function g' is computable by an  <span class="math">\\mathcal{L}</span> -uniform circuit of depth  <span class="math">d + \\text{poly}(k) + \\text{polylog}(n&#x27;) \\leq \\text{poly}(d, k)</span> .</p>

    <h3 id="sec-26" class="text-xl font-semibold mt-8">Compute(f):</h3>

    <p class="text-gray-300">The delegator D stores a state  <span class="math">(h, \\sigma)</span>  where  <span class="math">\\sigma = T_h(\\text{LDE}_x^{\\mathbb{F}, \\mathbb{H}, m})</span>  and wants to learn the value of f(x) from the worker W, who stores  <span class="math">x \\in \\{0, 1\\}^n</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D and W run GKR&lt;sup&gt;(u)&lt;/sup&gt; =  <span class="math">\\langle W&#x27;^{(u)}, D&#x27;^{(u)}(r_1, \\dots, r_u) \\rangle (f)</span> .</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(a) If  <span class="math">D&#x27;^{(u)}</span>  rejects, then the delegator D outputs &quot;reject&quot;.</li>
      <li>(b) At the end of this protocol, the delegator D' needs to verify that  <span class="math">LDE_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i) = v_i</span>  for some values  <span class="math">v_i</span> .</li>
    </ul></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>For every  <span class="math">i \\in [u]</span> , run PIR( <span class="math">\\langle W&#x27;^{(u)}, D&#x27;^{(u)}(z_{i,1}, \\ldots, z_{i,u}) \\rangle (g_{r_i})</span> ).</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(a) The delegator D makes sure that in these protocols the worker still claims that indeed  <span class="math">g_{r_i}(x) = v_i</span> , where  <span class="math">g_{r_i}(x) = \\text{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span> . If this is not the case, then the delegator D outputs &quot;reject&quot;.</li>
      <li>(b) If at any point D' rejects, then the delegator D outputs &quot;reject&quot;.</li>
      <li>(c) In order to verify these protocols, the delegator D needs to verify that  <span class="math">LDE_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j}) = w_{i,j}</span>  for some values  <span class="math">w_{i,j}</span> .</li>
    </ul></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>For every  <span class="math">i, j \\in [u]</span> , run Reveal <span class="math">(z_{i,j})</span> .</li>
    </ol>

If for some  <span class="math">i, j \\in [u]</span> , the worker fails in revealing to  <span class="math">w_{i,j}</span> , then the delegator D outputs &quot;reject&quot;.</li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The delegator D outputs &quot;accept&quot;, assuming he didn't output &quot;reject&quot; at any point.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-34-0&quot;&gt;&lt;/span&gt;Figure 3: Compute(f)</p>

    <h4 id="sec-27" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-34-2&quot;&gt;&lt;/span&gt;7.3 Proof of Theorem 31.</h4>

    <p class="text-gray-300">In this section, we prove that the construction above satisfies the properties of Theorem 31. The perfect completeness follows immediately from the completeness of the underlying delegation scheme GKR, the completeness of the PIR scheme, and the completeness of the Reveal protocol. The efficiency guarantees follow immediately from the efficiency guarantees of GKR and the efficiency guarantees of the underlying PIR scheme.</p>

    <p class="text-gray-300">The main difficulty is in proving soundness. We shall prove the one-time soundness of our memory delegation scheme in Lemma 32, and establish the reusable soundness in Lemma 33. At a very high level,</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>the one-time soundness of our scheme follows from the soundness of the GKR protocol, the security of tree commitments, and the parallel composition lemma (Lemma 24).</li>
      <li>the reusable soundness of our scheme follows from the one-time soundness, since the short certificate of the delegator is not secret, and the worker can compute this short certificate on his own.</li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-34-1&quot;&gt;&lt;/span&gt;<strong>Lemma 32</strong> The memory delegation scheme constructed in Section 7.2 is one-time sound, i.e., it has negligible one-time soundness error.</p>

    <p class="text-gray-300"><strong>Proof.</strong> Suppose for the sake of contradiction that there exists a PPT worker  <span class="math">W^*</span>  and a polynomial q such that for infinitely many k's</p>

    <p class="text-gray-300">&lt;span id=&quot;page-35-0&quot;&gt;&lt;/span&gt;
<span class="math">$\\Pr[\\mathsf{W}^* \\text{ succeeds in } \\mathsf{G}_1^{\\mathsf{W}^*}(k)] \\ge \\frac{1}{q(k)},\\tag{6}</span>$</p>

    <p class="text-gray-300">where  <span class="math">G_1</span>  is the one-time soundness game. Recall that in the game  <span class="math">G_1</span> , the worker  <span class="math">W^*(1^k)</span>  first chooses a parameter n = poly(k) and a string  <span class="math">x \\in \\{0,1\\}^n</span> . Then, D and W* run the offline phase, where D chooses a random hash function  <span class="math">h \\leftarrow \\mathcal{H}_k</span> , computes  <span class="math">\\sigma \\triangleq T_h(x)</span> , and sends h to W*. Then, W* chooses a function  <span class="math">f \\in \\mathcal{F}</span> , and D and W* execute Compute(f).</p>

    <p class="text-gray-300">Suppose that W* succeeds in proving a false statement f(x) = y'. Namely, W* and D run the protocol Compute(f) and at the end D accepts a wrong statement f(x) = y'.</p>

    <p class="text-gray-300">Recall that the Compute(f) protocol consists of  <span class="math">1 + u + u^2</span>  sub-protocols: an execution of</p>

    <p class="text-gray-300"><span class="math">$\\Pi_0 = GKR^{(u)} = \\langle \\mathsf{W}&#x27;^{(u)}, \\mathsf{D}&#x27;^{(u)}(r_1, \\dots, r_u) \\rangle (f),</span>$</p>

    <p class="text-gray-300">for every  <span class="math">i \\in [u]</span> , an execution of</p>

    <p class="text-gray-300"><span class="math">$\\Pi_i = \\operatorname{PIR}\\left(\\langle \\mathsf{W}&#x27;^{(u)}, \\mathsf{D}&#x27;^{(u)}(z_{i,1}, \\dots, z_{i,u})\\rangle(g_{r_i})\\right),</span>$</p>

    <p class="text-gray-300">and for every  <span class="math">i, j \\in [u]</span> , an execution of  <span class="math">\\Pi_{i,j} = \\text{Reveal}(z_{i,j})</span> .</p>

    <p class="text-gray-300">Suppose that in the Compute(f) protocol,  <span class="math">\\Pi_0</span>  reduces verifying that f(x) = y' to verifying the u statements</p>

    <p class="text-gray-300"><span class="math">$LDE_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i) = v_i,</span>$</p>

    <p class="text-gray-300">and each  <span class="math">\\Pi_i</span>  reduces verifying that  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i) = v_i</span>  to verifying the u statements</p>

    <p class="text-gray-300"><span class="math">$LDE_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j}) = w_{i,j}.</span>$</p>

    <p class="text-gray-300">We note that for W* to succeed in  <span class="math">G_1</span> , W* must successfully &quot;cheat&quot; in at least one of  <span class="math">\\Pi_0</span> ,  <span class="math">\\Pi_i</span> , or  <span class="math">\\Pi_{i,j}</span> . Namely, one of the following cases holds.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Case 1.  <span class="math">y&#x27; \\neq f(x)</span> , and for every  <span class="math">i \\in [u]</span> ,  <span class="math">v_i = LDE_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Case 2. There exists  <span class="math">i \\in [u]</span>  such that  <span class="math">v_i \\neq \\text{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span> , and for every  <span class="math">j \\in [u]</span> ,  <span class="math">w_{i,j} = \\text{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Case 3. There exists  <span class="math">i, j \\in [u]</span>  such that  <span class="math">w_{i,j} \\neq \\text{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span> .</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Intuitively, each of the above cases should hold with only negligible probability. This is due to the soundness property of the GKR protocol and the security of the tree commitments.</p>

    <p class="text-gray-300">We next use Lemma 24 to claim that each of the above cases holds with negligible probability, even when  <span class="math">\\Pi_0, \\Pi_i</span> , or  <span class="math">\\Pi_{i,j}</span>  are executed in parallel, contradicting Equation (6).</p>

    <p class="text-gray-300">In order to make use of Lemma 24, we consider a slightly modified version of the protocols  <span class="math">\\Pi_0</span> ,  <span class="math">\\Pi_i</span> , and  <span class="math">\\Pi_{i,j}</span> , denoted by  <span class="math">\\Pi&#x27;_0</span> ,  <span class="math">\\Pi&#x27;_i</span> , and  <span class="math">\\Pi&#x27;_{i,j}</span> . The messages sent in these protocols are identical to the ones sent in the original  <span class="math">\\Pi_0</span> ,  <span class="math">\\Pi_i</span> ,  <span class="math">\\Pi_{i,j}</span>  protocols, and the only difference is in the verification procedure. Note that the protocols  <span class="math">\\Pi_0</span> ,  <span class="math">\\Pi_i</span> ,  <span class="math">\\Pi_{i,j}</span>  are interleaved in the sense that the verifier of  <span class="math">\\Pi_0</span>  doesn't actually verify the correctness of  <span class="math">\\Pi_0</span> , but rather uses the protocols  <span class="math">\\Pi_i</span>  to verify the correctness of  <span class="math">\\Pi_i</span> . Similarly, the verifier uses the protocols  <span class="math">\\Pi_{i,j}</span>  to verify the correctness of  <span class="math">\\Pi_i</span> .</p>

    <p class="text-gray-300">Instead, we define  <span class="math">\\Pi&#x27;_0, \\Pi&#x27;_i, \\Pi&#x27;_{i,j}</span>  to be stand-alone protocols (with their own verification procedures) for recognizing the <em>empty</em> language.</p>

    <p class="text-gray-300">Recall that  <span class="math">\\Pi_0 = \\operatorname{GKR}^{(u)} = \\langle W&#x27;^{(u)}, D&#x27;^{(u)}(r_1, \\dots, r_u) \\rangle(f)</span>  is a u-fold parallel repetition of GKR, where the delegator delegates the computation of f(x) to the worker. In  <span class="math">\\Pi&#x27;_0</span> , the verifier actually computes on her own (using x) the correct values of y = f(x) and  <span class="math">v_i = \\operatorname{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span>  for every  <span class="math">i \\in [u]^{23}</span> , and the verifier accepts if and only if at the end of  <span class="math">\\operatorname{GKR}^{(u)}</span> , the worker convinces the delegator to accept some incorrect  <span class="math">y&#x27; \\neq f(x)</span> . Note that the soundness of  <span class="math">\\operatorname{GKR}^{(u)}</span>  implies that  <span class="math">\\Pi&#x27;_0</span>  has negligible soundness error.</p>

    <p class="text-gray-300">Recall that each  <span class="math">\\Pi_i = \\operatorname{PIR}(\\langle \\mathsf{W}&#x27;^{(u)}, \\mathsf{D}&#x27;^{(u)}(z_{i,1}, \\dots, z_{i,u}) \\rangle(g_{r_i}))</span>  is a masked u-fold parallel repetition of GKR, where the delegator delegates the computation of  <span class="math">g_{r_i}(x) = \\operatorname{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span>  to the worker, and  <span class="math">r_i</span>  is a random point masked by the PIR scheme. In each  <span class="math">\\Pi&#x27;_i</span> , the verifier actually computes on her own (using x) the correct value  <span class="math">v_i = \\operatorname{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span>  and the values  <span class="math">w_{i,j} = \\operatorname{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span>  for every  <span class="math">j \\in [u]</span> , and the verifier accepts if and only if the worker convinces the delegator to accept some incorrect  <span class="math">v&#x27;_i \\neq \\operatorname{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span> . Note that the soundness of GKR&lt;sup&gt;(u)&lt;/sup&gt; implies that  <span class="math">\\Pi&#x27;_i</span>  has negligible soundness error.&lt;sup&gt;24&lt;/sup&gt;</p>

    <p class="text-gray-300">Finally, recall that each  <span class="math">\\Pi_{i,j} = \\text{Reveal}(z_{i,j})</span>  is a masked tree commitment reveal protocol, where the delegator asks the worker to reveal the value of  <span class="math">\\text{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span>  by giving a valid augmented path  <span class="math">\\text{aug}(z_{i,j})</span>  of  <span class="math">T_h(\\text{LDE}_x)</span> , and  <span class="math">z_{i,j}</span>  is a random point masked by the PIR scheme. In each  <span class="math">\\Pi&#x27;_{i,j}</span> , the verifier actually computes on her own (using x) the correct values of  <span class="math">w_{i,j} = \\text{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span> , and the verifier accepts iff the worker convinces the delegator to accept some incorrect  <span class="math">w_{i,j} \\neq \\text{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span> . Note that the security of the tree commitments implies that  <span class="math">\\Pi&#x27;_{i,j}</span>  has negligible soundness error.</p>

    <p class="text-gray-300">In all the protocols  <span class="math">\\Pi&#x27;_0</span> ,  <span class="math">\\Pi&#x27;_i</span> , and  <span class="math">\\Pi&#x27;_{i,j}</span> , we think of x as the common input, and we think of</p>

    <p class="text-gray-300"><span class="math">$p = ((r_i)_{i \\in [u]}, (z_{i,j})_{i,j \\in [u]})</span>$</p>

    <p class="text-gray-300">as the common private randomness.</p>

    <p class="text-gray-300">Let  <span class="math">\\Pi&#x27;</span>  be the corresponding parallel execution of  <span class="math">\\Pi&#x27;_0, \\Pi&#x27;_i</span> , and  <span class="math">\\Pi&#x27;_{i,j}</span> , where the verifier of  <span class="math">\\Pi&#x27;</span>  accepts if and only if any one of  <span class="math">\\Pi&#x27;_0, \\Pi&#x27;_i</span> , and  <span class="math">\\Pi&#x27;_{i,j}</span>  accepts. Lemma 24 implies that the fact that each of the protocols  <span class="math">\\Pi&#x27;_0, \\Pi&#x27;_i</span> , and  <span class="math">\\Pi&#x27;_{i,j}</span>  has negligible soundness error, implies that  <span class="math">\\Pi&#x27;</span>  has negligible soundness as well. Recall that whenever  <span class="math">W^*</span>  succeed in  <span class="math">G_1</span> , at least one of the above three cases holds. Namely, the verifier in  <span class="math">\\Pi&#x27;_0</span>  accepts when Case 1 holds, the verifier in  <span class="math">\\Pi&#x27;_i</span>  accepts when Case 2 holds, and and the verifier in  <span class="math">\\Pi&#x27;_{i,j}</span>  accepts when Case 3 holds. Thus,</p>

    <p class="text-gray-300"><span class="math">$\\Pr[\\mathsf{W}^* \\text{ succeeds in } \\mathsf{G}_1^{\\mathsf{W}^*}(k)] \\leq \\Pr[\\mathsf{D} \\text{ accepts in } \\Pi&#x27;] \\leq \\mathsf{ngl}(k),</span>$</p>

    <p class="text-gray-300">contradicting Equation (6).</p>

    <p class="text-gray-300">&lt;span id=&quot;page-36-0&quot;&gt;&lt;/span&gt;<strong>Lemma 33</strong> The memory delegation scheme constructed in Section 7.2 is sound, i.e., it has negligible reusable soundness error.</p>

    <p class="text-gray-300"><strong>Proof.</strong> Suppose for the sake of contradiction that there exists a PPT worker W* such that</p>

    <p class="text-gray-300">&lt;span id=&quot;page-36-3&quot;&gt;&lt;/span&gt;
<span class="math">$\\Pr[\\mathsf{W}^* \\text{ succeeds in } \\mathsf{G}^{\\mathsf{W}^*}(k)] \\ge \\alpha(k),</span>$
(7)</p>

    <p class="text-gray-300">&lt;span id=&quot;page-36-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;23&lt;/sup&gt;Note that the verifier in these protocols runs in time poly(|x|), which is too long in our setting, but this is only in the analysis.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-36-2&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;24&lt;/sup&gt;Note that we didn't use the soundness of the PIR scheme. Indeed, the PIR scheme is added only in order to later apply Lemma 24.</p>

    <p class="text-gray-300">for a non-negligible function  <span class="math">\\alpha</span> , where G is the reusable soundness game. We construct a PPT worker W&lt;sub&gt;1&lt;/sub&gt;* which succeeds in the one-time security game  <span class="math">\\mathsf{G}_1^{\\mathsf{W}_1^*}(k)</span>  with non-negligible probability. Recall that the game G proceeds in three phases, as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>In the initial phase, the worker  <span class="math">W^*(1^k)</span>  first chooses a parameter n = poly(k) and a string  <span class="math">x \\in \\{0,1\\}^n</span> . Then, D and W* run the offline phase, where D chooses a random hash function  <span class="math">h \\leftarrow \\mathcal{H}_k</span> , computes  <span class="math">\\sigma \\triangleq T_h(x)</span> , and sends h to W*.</li>
      <li>In the learning phase, W* and D execute polynomially many Compute(f) and Update(g) operations, where each  <span class="math">f \\in \\mathcal{F}</span>  and  <span class="math">g \\in \\mathcal{G}</span>  are chosen by W*. In the Update(g), D chooses a fresh hash function  <span class="math">h&#x27; \\leftarrow \\mathcal{H}_k</span> , sends h' to W*, and then D and W* execute Compute(g') where  <span class="math">g&#x27;(x) = T_{h&#x27;}(\\text{LDE}_{g(x)})</span> . If D accepts, then the memory is updated to x' = g(x), and if D rejects, then the memory x remains unchanged.</li>
      <li>In the challenge phase, W* chooses  <span class="math">f&#x27; \\in \\mathcal{F}</span> , and D and W* execute Compute(f'). W* succeeds if D accepts a wrong value  <span class="math">y&#x27; \\neq f&#x27;(x)</span> , where x is the latest updated memory.</li>
    </ul>

    <p class="text-gray-300">Intuitively, noting that the short certificate of the delegator is public, one-time soundness seems to immediately imply reusable soundness, since in this case a (one-time) cheating worker  <span class="math">W_1^*</span>  can simulate the learning phase of  <span class="math">\\langle D, W^* \\rangle</span>  on his own. However, this intuition is an oversimplification, since  <span class="math">W^*</span>  may cheat in one of the Update computations, and thus convince the delegator D to update her certificate to some incorrect value, which allows  <span class="math">W^*</span>  to cheat easily in the challenge phase. In this case, simulating the learning phase does not help  <span class="math">W_1^*</span>  cheat in the one-time security game  <span class="math">G_1</span> .</p>

    <p class="text-gray-300">Therefore, instead of simply simulating the entire learning phase, roughly speaking,  <span class="math">W_1^*</span>  does the following.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Guess the <em>first time</em> that W* cheats successfully in either an update or a compute operation (we refer to this as the first cheating operation).</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Guess the <em>last</em> valid update operation (that D accepts) before the cheating operation (we refer to this as the last update operation).</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Embed the one-time game  <span class="math">G_1</span>  into the reusable game G, as follows: Simulate  <span class="math">\\langle D, W^* \\rangle</span>  in G up to the last update operation, and use the memory at that time to interact with  <span class="math">D_1</span>  in the initial phase of  <span class="math">G_1</span> . Then, continue to simulate  <span class="math">\\langle D, W^* \\rangle</span>  in G up to the first cheating operation, and interact with  <span class="math">D_1</span>  in the challenge phase of  <span class="math">G_1</span>  by using  <span class="math">W^*</span>  in this first cheating operation in G.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">In order to describe  <span class="math">W_1^*</span>  more formally, we use the following notation. Let  <span class="math">L(k) \\leq \\operatorname{poly}(k)</span>  be an upper bound on the total number of Compute and Update operations that  <span class="math">W^*</span>  makes in the (reusable) game G. We call each such operation in G a round. We refer to the initial phase as round 0, the learning phase starts at round 1, and the challenge phase is the last round. Denote by  <span class="math">x_i</span>  the memory content at the end of round i, and let  <span class="math">f_i</span>  be the delegation function of the Compute(·) operation in round i. Recall that  <span class="math">\\operatorname{Update}(g)</span>  is implemented via a compute operation, so  <span class="math">f_i</span>  is defined for every round.</p>

    <p class="text-gray-300">Using this notation, we define  <span class="math">W_1^*</span>  more formally, as follows:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Choose at random  <span class="math">j \\leftarrow [L]</span>  and choose at random  <span class="math">i \\leftarrow \\{0, 1, \\dots, j-1\\}</span> , where j is a guess for the first cheating operation of  <span class="math">W^*</span> , and i is a guess for the last successful Update operation</li>
    </ol>

    <p class="text-gray-300">of W* before round j. (i = 0 corresponds to the guess that W* doesn't update successfully the initial input  <span class="math">x_0</span>  before round j.)</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Simulate the interaction of  <span class="math">\\langle \\mathsf{D}, \\mathsf{W}^* \\rangle</span>  in the reusable game  <span class="math">\\mathsf{G}</span>  up until the end of round i. Denote by  <span class="math">x_i</span>  the memory at the end of round i in the simulated game  <span class="math">\\mathsf{G}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Start the initial phase of  <span class="math">G_1</span> , with the memory  <span class="math">x_i</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Upon receiving a hash function  <span class="math">h \\leftarrow \\mathcal{H}_k</span>  from  <span class="math">D_1</span>  in the offline phase, view this h as chosen by D in round i of the simulated (reusable game) G, and continue the simulation of G until the beginning of round j.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>If at round j,  <span class="math">W^*</span>  chooses to perform  <span class="math">Compute(f_j)</span> , then start the challenge phase of  <span class="math">G_1</span>  with the function  <span class="math">f_j</span> , and interact with  <span class="math">D_1</span>  by simulating  <span class="math">W^*</span>  (who supposedly executes  <span class="math">Compute(f_j)</span>  with D).</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">We next analyze the success probability of  <span class="math">W_1^*</span> . To this end, for any  <span class="math">j \\in [L]</span>  and any  <span class="math">i \\in \\{0, 1, \\ldots, j-1\\}</span> , let  <span class="math">W_{i,j}</span>  be the event that (1) the <em>first time</em> that  <span class="math">W^*</span>  cheats successfully is in round j, and (2) the <em>last</em> valid update operation (that D accepts) before round j is in round i.</p>

    <p class="text-gray-300">Note that by definition, whenever W* succeeds in G, there must exist some such i, j such that event  <span class="math">W_{i,j}</span>  holds. Thus, a simple counting argument, together with Equation (7), implies that there exists some such i, j such that</p>

    <p class="text-gray-300"><span class="math">$\\Pr[W_{i,j}] \\ge \\frac{\\alpha}{L^2},</span>$</p>

    <p class="text-gray-300">which implies that</p>

    <p class="text-gray-300"><span class="math">$\\Pr[\\mathsf{W}_1^* \\text{ succeeds in } \\mathsf{G}_1^{\\mathsf{W}_1^*}(k)] \\ge \\frac{\\alpha}{L^2},</span>$</p>

    <p class="text-gray-300">contradicting Lemma 32, which asserts that the scheme is one-time secure.</p>

    <h2 id="sec-28" class="text-2xl font-bold">&lt;span id=&quot;page-38-0&quot;&gt;&lt;/span&gt;8 Streaming Delegation Model</h2>

    <p class="text-gray-300">In this section, we formally define our streaming delegation model. We present our streaming delegation scheme in Section 9.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-38-1&quot;&gt;&lt;/span&gt;<strong>Definition 34 (Streaming Delegation Scheme)</strong> Let  <span class="math">\\mathcal{F}</span>  be a class of boolean functions. A streaming delegation scheme  <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span> , for a function class  <span class="math">\\mathcal{F}</span> , consists of a streaming generator  <span class="math">\\mathsf{S}</span>  and an interactive protocol  <span class="math">\\langle \\mathsf{D}, \\mathsf{W} \\rangle</span>  between a delegator  <span class="math">\\mathsf{D}</span>  and a worker  <span class="math">\\mathsf{W}</span>  with the following structure.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The scheme sDel starts at time 0, at which all parties receive a security parameter  <span class="math">1^k</span>  and a parameter N (in binary) which specifies the maximum length of the data stream. On input  <span class="math">(1^k, N)</span> , D generates some (possibly secret) state  <span class="math">\\sigma_0</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>At each time  <span class="math">t \\in [N]</span> , S generates a data item  <span class="math">x_t \\in \\{0,1\\}</span> , which is received by both D and W. Upon receiving  <span class="math">x_t</span> , D updates her secret state from  <span class="math">\\sigma_{t-1}</span>  to  <span class="math">\\sigma_t</span> , and W simply stores  <span class="math">x_t</span> . Let  <span class="math">x^t = x^{t-1} \\circ x_t</span>  denote the current received data items, where  <span class="math">\\circ</span>  represents a concatenation.</li>
    </ol></li>
    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>At any time  <span class="math">t \\in [N]</span> , D may choose a delegation function  <span class="math">f : \\{0,1\\}^t \\to \\{0,1\\} \\in \\mathcal{F}</span>  and run the delegation protocol  <span class="math">\\langle D, W \\rangle</span>  on input (f,t). In addition to the common input (f,t), the delegator D takes as input her secret state  <span class="math">\\sigma_t</span> , and the worker W takes as input the data stream  <span class="math">x^{t,25}</span></li>
    </ol>

    <p class="text-gray-300"><strong>Remark 1.</strong> For the sake of readability, we try to keep the definition of the model as simple as possible. For example, we assume that data items are bits and delegation functions are boolean functions, while it is natural to consider non-boolean data items and non-boolean delegation functions. Also, we implicitly assume that D delegates at most one function of the current data stream at any given time t, while it is natural to allow D to delegate multiple functions at the same time. Nevertheless, it will be easy to see that our solution presented in Section 9 generalizes to these extensions readily.</p>

    <p class="text-gray-300"><strong>Remark 2.</strong> Note that in Definition 34, we require that D updates her fingerprint of the data stream on her own efficiently (ideally, in time polylog(N); see Definition 35 below). The reason is that in the streaming setting, the data stream arrives constantly at a high rate. Thus, if the update function would be delegated at time t, this delegation protocol may not end before time t+1. Hence, it may be infeasible and unreliable to ask the worker for his help in updating the delegator's fingerprint. We note that this is in contrast to the setting of memory delegation, where we do allow the update procedure to be delegated (see Section 6 for details).</p>

    <p class="text-gray-300">&lt;span id=&quot;page-39-2&quot;&gt;&lt;/span&gt;<strong>Definition 35 (Efficiency)</strong> A streaming delegation scheme  <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span>  has an efficient delegator if the runtime of D each time she updates her (secret) fingerprint is  <span class="math">\\mathsf{polylog}(N)</span> , and her runtime during each execution of the protocol  <span class="math">\\langle \\mathsf{D}, \\mathsf{W} \\rangle (f,t)</span>  is  <span class="math">\\mathsf{poly}(k,\\log N,\\log S)</span> , where S is the size of the circuit computing f. A streaming delegation scheme  <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span>  has an efficient worker if the runtime of W during an execution of  <span class="math">\\langle \\mathsf{D}, \\mathsf{W} \\rangle (f,t)</span>  is  <span class="math">\\mathsf{poly}(k,\\log N,S)</span> , where S is the size of the circuit computing f.</p>

    <p class="text-gray-300">We proceed to define the completeness and soundness of a streaming delegation scheme.</p>

    <p class="text-gray-300"><strong>Definition 36 (Completeness)</strong> For any function class  <span class="math">\\mathcal{F}</span> , a streaming delegation scheme  <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span>  has perfect completeness if for every parameters  <span class="math">k, N \\in \\mathbb{N}</span> ,  <span class="math">t \\in [N]</span> , every function  <span class="math">f : \\{0, 1\\}^t \\to \\{0, 1\\} \\in \\mathcal{F}</span> , and every  <span class="math">x^t \\in \\{0, 1\\}^t</span>  generated by  <span class="math">\\mathsf{S}</span> , the following holds with probability  <span class="math">1:^{26}</span>  When  <span class="math">\\mathsf{D}</span>  and  <span class="math">\\mathsf{W}</span>  run the delegation protocol  <span class="math">\\langle \\mathsf{D}, \\mathsf{W} \\rangle (f, t)</span> ,  <span class="math">\\mathsf{D}</span>  always accepts and outputs  <span class="math">y = f(x^t)</span> .</p>

    <p class="text-gray-300">The definition of the soundness property is more elaborate, since D and W may run the delegation protocol multiple times with different inputs. We provide the following game-based definition, where we allow the adversary  <span class="math">W^*</span>  to choose the data stream and delegation functions, and  <span class="math">W^*</span>  wins if he convinces D to accept an incorrect function value.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-39-0&quot;&gt;&lt;/span&gt;<strong>Definition 37 (Streaming Security Game)</strong> Let k be a security parameter and N be a parameter. Let  <span class="math">\\mathcal{F}</span>  be a function class and let  <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span>  be a delegation scheme for  <span class="math">\\mathcal{F}</span> . The corresponding streaming security game  <span class="math">\\mathsf{G}^{\\mathsf{W}^*}(k,N)</span>  played by an (adversarial) worker  <span class="math">\\mathsf{W}^*</span>  is defined as follows.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-39-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;25&lt;/sup&gt;For simplicity of presentation, we omit the security parameter when it is clear from the context.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-39-3&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;26&lt;/sup&gt;It has completeness  <span class="math">1 - \\epsilon</span>  if the following holds with probability  <span class="math">1 - \\epsilon</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>At time 0, the delegator D, on input (1&lt;sup&gt;k&lt;/sup&gt; , N), generates her secret state σ0.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>At each time t ∈ [N], W&lt;sup&gt;∗&lt;/sup&gt; chooses a data item x &lt;sup&gt;t&lt;/sup&gt; ∈ {0, 1} and sends it to D, who then updates her secret state to σt. Furthermore, W&lt;sup&gt;∗&lt;/sup&gt; may choose a function f : {0, 1} &lt;sup&gt;t&lt;/sup&gt; → {0, 1} ∈ F and run with D the delegation protocol hD, W&lt;sup&gt;∗&lt;/sup&gt; i on input (f, t).</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">At the end of each delegation protocol, W&lt;sup&gt;∗&lt;/sup&gt; learns whether D accepts or rejects.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>W&lt;sup&gt;∗&lt;/sup&gt; may terminate the game at any time t ∈ [N].</li>
    </ol>

    <p class="text-gray-300">W&lt;sup&gt;∗&lt;/sup&gt; succeeds in the game GW&lt;sup&gt;∗&lt;/sup&gt; (k, N) if there exists a time t such that W&lt;sup&gt;∗&lt;/sup&gt; chooses to run the delegation protocol on input (f, t) for some function f ∈ F, and convinces D to accept a wrong value y 6= f(x t ).</p>

    <p class="text-gray-300">Definition 38 (Soundness) Let k be a security parameter, and F a (boolean) function class that is poly-time computable. A delegation scheme sDel&lt;sup&gt;F&lt;/sup&gt; has soundness error ε if for every worker strategy W&lt;sup&gt;∗&lt;/sup&gt; with runtime poly(N), where N = N(k),</p>

    <p class="text-gray-300"><span class="math">$\\Pr[\\mathsf{W}^* \\ succeeds \\ in \\ \\mathsf{G}^{\\mathsf{W}^*}(k)] \\le \\varepsilon(N),</span>$</p>

    <p class="text-gray-300">where GW&lt;sup&gt;∗&lt;/sup&gt; (k) is the security game corresponding to sDel&lt;sup&gt;F&lt;/sup&gt; , as defined above. We say that sDel&lt;sup&gt;F&lt;/sup&gt; is sound if it has a negligible soundness error in the parameter N.</p>

    <p class="text-gray-300">Remark. Note that in the above definition, we refer to k as the security parameter, but require the soundness to hold against any poly(N)-time adversaries as opposed to standard poly(k)-time adversaries. This is because the honest worker needs to run in time poly(N) even to evaluate the delegation function f. One should think of k as the security parameter of the cryptographic primitives used by D in the delegation scheme, where the primitives are required to be secure against poly(N)-time adversaries.</p>

    <p class="text-gray-300">Typically, one may assume that k and N are polynomially related. However, in the context of streaming algorithms, it is common to think of the data stream as having length super-polynomial in the computational resource of the streaming algorithms. For example, the space complexity of a streaming algorithm is typically limited to polylog(N), which usually implies the process time per data item is also polylog(N). We note that a stronger security assumption on the cryptographic primitives is necessary when the data stream is of length super-polynomial in the computational power of the delegator.</p>

    <p class="text-gray-300">Remark. Note that, as in the memory delegation model, in the soundness definition, we allow the adversary W&lt;sup&gt;∗&lt;/sup&gt; to learn the decision bit of the delegator D after each execution of the delegation protocol. This is in contrast to the two delegation schemes of <a href="#page-65-7">[GGP10,</a> <a href="#page-65-8">CKV10]</a>, which are sound only if the adversary W&lt;sup&gt;∗&lt;/sup&gt; does not learn the decision bit of the delegator D.</p>

    <p class="text-gray-300">We stress that our streaming delegation scheme (in Section <a href="#page-42-1">9)</a> has the property that the state of the delegator must be secret, in order to ensure soundness.<a href="#page-40-0">27</a> The only other delegation schemes that we are aware of which have this property, are <a href="#page-65-7">[GGP10,</a> <a href="#page-65-8">CKV10]</a>. However, these schemes are sound only if the adversary W&lt;sup&gt;∗&lt;/sup&gt; does not learn the decision bit of the delegator D. The reason</p>

    <p class="text-gray-300">&lt;span id=&quot;page-40-0&quot;&gt;&lt;/span&gt;&lt;sup&gt;27&lt;/sup&gt;This is in contrast to our memory delegation scheme (in Section <a href="#page-28-0">7)</a>, where the state of the delegator was not secret.</p>

    <p class="text-gray-300">why in these schemes the decision bit needs to be kept secret is that the delegator uses her secret state to verify the worker's answer, and thus, her decision bit can potentially reveal one bit of information about her secret state. Indeed, in both schemes of [GGP10, CKV10], if D's decision bits are revealed, then there are known attacks to learn the secret state of D bit by bit and break the soundness of the schemes.</p>

    <p class="text-gray-300">We didn't have to deal with this issue in our memory delegation scheme mDel, since the state of the delegator in mDel is not secret. In contrast, the delegator of our streaming delegation scheme constructed in Section 9 does hold a secret state, and handling this reusability issue is one of the main technical challenges of this work. It is for this reason that we need all the machinery that was developed in Section 4.</p>

    <p class="text-gray-300">In what follows we define the notion of <em>one-time soundness</em>. The reason we need this definition, is that our soundness proof (for our streaming delegation scheme in Section 9), consists of two parts: We first prove that our scheme has one-time soundness, i.e., it is sound assuming the delegation protocol is executed only once. Then, we argue that the one-time soundness implies reusable soundness.</p>

    <p class="text-gray-300"><strong>Definition 39 (One-time Soundness)</strong> Let k be a security parameter and let N be a parameter. Let  <span class="math">\\mathcal{F}</span>  be a function class and let  <span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span>  be a delegation scheme for  <span class="math">\\mathcal{F}</span> . The corresponding <strong>one-time streaming security game</strong>  <span class="math">\\mathsf{G}_1^{\\mathsf{W}^*}(k,N)</span>  played by an (adversarial) worker  <span class="math">\\mathsf{W}^*</span>  is defined the same as  <span class="math">\\mathsf{G}^{\\mathsf{W}^*}(k,N)</span> , except that the game is terminated after the first execution of the delegation protocol  <span class="math">\\langle \\mathsf{D}, \\mathsf{W}^* \\rangle</span> .</p>

    <p class="text-gray-300">We say that  <span class="math">sDel_{\\mathcal{F}}</span>  has one-time soundness error  <span class="math">\\varepsilon</span>  if for every worker strategy W* with runtime poly(N), where N = N(k),</p>

    <p class="text-gray-300"><span class="math">$\\Pr[\\mathsf{W}^* \\ succeeds \\ in \\ \\mathsf{G}_1^{\\mathsf{W}^*}(k,N)] \\le \\varepsilon(N).</span>$</p>

    <p class="text-gray-300"><span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span>  is one-time sound if it has a negligible one-time soundness error (in parameter N).</p>

    <p class="text-gray-300">We proceed to state our main theorem for streaming delegation.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-41-0&quot;&gt;&lt;/span&gt;<strong>Theorem 40 (Streaming Delegation)</strong> Let k be a security parameter, and let N be a parameter. Let  <span class="math">\\mathcal{F}</span>  be the class of all  <span class="math">\\mathcal{L}</span> -uniform poly-size boolean circuits. Assume the existence of a fully-homomorphic encryption scheme secure against  <span class="math">\\operatorname{poly}(N)</span> -size adversaries. Then there exists a non-interactive (2-message) streaming delegation scheme  <span class="math">\\operatorname{sDel}_{\\mathcal{F}}</span>  for  <span class="math">\\mathcal{F}</span>  with the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathsf{sDel}_{\\mathcal{F}}</span>  has perfect completeness and negligible soundness error.</li>
      <li>D updates her secret state in time polylog(N), per data item.</li>
      <li>In the delegation protocol, when delegating a function  <span class="math">f \\in \\mathcal{F}</span>  computable by an  <span class="math">\\mathcal{L}</span> -uniform circuit of size S and depth d, the delegator D runs in time poly(k, d, log N), and the worker W runs in time poly(k, S, log N).</li>
    </ul>

    <p class="text-gray-300">In particular, assuming the existence of a fully-homomorphic encryption scheme secure against adversaries of size poly(N), we obtain a streaming delegation scheme for  <span class="math">\\mathcal{L}</span> -uniform  <span class="math">\\mathbf{NC}</span>  computations, where the delegator  <span class="math">\\mathsf{D}</span>  runs in time poly-logarithmic in the length of data stream.</p>

    <p class="text-gray-300">We proceed to present our streaming delegation scheme in the next section.</p>

    <h2 id="sec-29" class="text-2xl font-bold">&lt;span id=&quot;page-42-1&quot;&gt;&lt;/span&gt;9 Streaming Delegation Scheme</h2>

    <p class="text-gray-300">In this section, we prove Theorem 40, by constructing a non-interactive streaming delegation scheme with the desired properties.</p>

    <h4 id="sec-30" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-42-0&quot;&gt;&lt;/span&gt;9.1 Overview of our Streaming Delegation Scheme</h4>

    <p class="text-gray-300">Our streaming delegation scheme is similar to our memory delegation scheme mDel, presented in Section 7, and the main difference is in the way the certificate is generated and updated, and in the Reveal protocol of the Compute operation.</p>

    <p class="text-gray-300">Generating and updating the certificate. Recall that in the memory delegation scheme, the certificate of the delegator D consists of a tree-commitment of the low-degree extension of her memory x. Namely, her certificate is  <span class="math">(h, T_h(\\text{LDE}_x))</span> , where h is a collision resistant hash function. Note that this certificate cannot be updated in a streaming manner, since any change to x changes the low-degree extension  <span class="math">\\text{LDE}_x</span>  almost everywhere.</p>

    <p class="text-gray-300">Instead, in the streaming setting, we replace the tree commitment with an &quot;algebraic commitment&quot;, which has the property that it can be updated efficiently when new data items arrive. The resulting certificate is a random point in the low-degree extension of the stream x; i.e.,  <span class="math">(z, \\text{LDE}_x(z))</span>  for a random point z. Proposition 6 implies that this certificate is efficiently updatable, if we assume some upper-bound N on the size of the stream, and we take parameters  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span>  such that  <span class="math">\\mathbb{H}^m = \\theta(N)</span> . The parameters we take are</p>

    <p class="text-gray-300">&lt;span id=&quot;page-42-2&quot;&gt;&lt;/span&gt;
<span class="math">$|\\mathbb{H}| = \\text{polylog}(N), \\ m = \\theta\\left(\\frac{\\log N}{\\log\\log N}\\right), \\ |\\mathbb{F}| = \\text{poly}(|\\mathbb{H}|).</span>$
(8)</p>

    <p class="text-gray-300">The Compute operation. The Compute operation of our streaming delegation scheme is very similar to the Compute operation of the memory delegation scheme mDel, and the main distinction is in the Reveal protocol. Namely, in Compute(f) the delegator and worker run  <span class="math">GKR^{(u)}(f)</span> , which is the u-fold parallel repetition of GKR(f) (the parallel repetition is in order to get negligible soundness). In order to verify correctness, the delegator needs to verify the value of  <span class="math">LDE_x(r_i)</span>  for random  <span class="math">r_1, \\ldots, r_u</span> . Recall that this low-degree extension is w.r.t. the parameters  <span class="math">\\mathbb{H}&#x27;, \\mathbb{F}&#x27;, m&#x27;</span>  given in Theorem 8. Namely,</p>

    <p class="text-gray-300"><span class="math">$|\\mathbb{H}&#x27;| = \\theta(d \\cdot \\log n), \\ m&#x27; = \\theta\\left(\\frac{\\log n}{\\log d}\\right), \\ |\\mathbb{F}&#x27;| = \\text{poly}(|\\mathbb{H}&#x27;|).</span>$</p>

    <p class="text-gray-300">where d is the depth of the circuit computing f, and n is the input length (i.e., the current size of the stream). Also, recall that the certificate of the delegator is of the form  <span class="math">(z, \\text{LDE}_x(z))</span> , where here the low-degree extension is w.r.t. the parameters  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span>  as in Equation (8).</p>

    <p class="text-gray-300">In the memory delegation scheme we overcome this gap by delegating the computation of the functions  <span class="math">g_{r_i}</span> , which are defined by</p>

    <p class="text-gray-300"><span class="math">$g_{r_i}(x) \\triangleq \\mathrm{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i),</span>$</p>

    <p class="text-gray-300">using  <span class="math">GKR^{(u)}</span>  with respect to  <span class="math">(\\mathbb{H}, \\mathbb{F}, m)</span> . In order to verify the correctness of these u protocols, the delegator needs to verify  <span class="math">u^2</span>  values  <span class="math">LDE_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span> , where each  <span class="math">z_{i,j}</span>  is a random value in  <span class="math">\\mathbb{F}^m</span> .</p>

    <p class="text-gray-300">Remark. In our setting this approach is too costly since the running time of the worker W during the delegation protocols of  <span class="math">g_{r_i}</span>  is polynomial in N (where N is an upper bound on the stream size), as opposed to polynomial in n, which is the actual stream size (see Theorem 8). However, it turns out that with a slight modification, we can ensure that W runs in time  <span class="math">\\operatorname{poly}(k, n, \\log N)</span>  during these delegation protocols, where k is the security parameter. The idea is the following: Let  <span class="math">m&#x27;&#x27; = \\lceil \\frac{\\log n}{\\log \\log N} \\rceil</span>  so that  <span class="math">n \\leq |\\mathbb{H}|^{m&#x27;&#x27;} \\leq n \\cdot \\operatorname{polylog}(N)</span> . The delegator will delegate the functions  <span class="math">g_{r_i}(x_i)</span>  by running  <span class="math">\\operatorname{GKR}^{(u)}</span>  with respect to  <span class="math">(\\mathbb{H}, \\mathbb{F}, m&#x27;&#x27;)</span> . Note that the runtime of W during these protocols is  <span class="math">\\operatorname{poly}(n, k, \\log N)</span> , as desired. At the end of these protocols the delegator needs to verify  <span class="math">u^2</span>  values  <span class="math">\\operatorname{LDE}_x^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z_{i,j}&#x27;&#x27;)</span> , where each  <span class="math">z_{i,j}&#x27;&#x27;</span>  is a random value in  <span class="math">\\mathbb{F}^{m&#x27;&#x27;}</span> .</p>

    <p class="text-gray-300">We next argue that for every  <span class="math">z&#x27;&#x27; \\in \\mathbb{F}^{m&#x27;&#x27;}</span> ,</p>

    <p class="text-gray-300"><span class="math">$LDE_x^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z&#x27;&#x27;) = LDE_x^{\\mathbb{F},\\mathbb{H},m}(0^{m-m&#x27;&#x27;},z&#x27;&#x27;).</span>$</p>

    <p class="text-gray-300">To this end, recall (from Section 3.3) that</p>

    <p class="text-gray-300"><span class="math">$LDE_x^{\\mathbb{F},\\mathbb{H},m}(z) = \\sum_{p \\in \\mathbb{H}^m} \\tilde{B}(z,p) \\cdot x_{\\alpha(p)}</span>$
(9)</p>

    <p class="text-gray-300">and similarly</p>

    <p class="text-gray-300"><span class="math">$LDE_x^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z) = \\sum_{p \\in \\mathbb{H}^{m&#x27;&#x27;}} \\tilde{B}(z,p) \\cdot x_{\\alpha&#x27;&#x27;(p)}</span>$</p>

    <p class="text-gray-300">where for every  <span class="math">z \\in \\mathbb{H}^m</span>  (or  <span class="math">z \\in \\mathbb{H}^{m&#x27;&#x27;}</span>  respectively) it holds that  <span class="math">\\tilde{B}(z,p) = 1</span>  if z = p, and  <span class="math">\\tilde{B}(z,p) = 0</span>  otherwise. The functions  <span class="math">\\alpha : \\mathbb{H}^m \\to \\{0,1,\\ldots,N-1\\}</span>  and  <span class="math">\\alpha&#x27;&#x27; : \\mathbb{H}^{m&#x27;&#x27;} \\to \\{0,1,\\ldots,n-1\\}</span>  are the lexicographic order, and thus for every  <span class="math">p \\in \\mathbb{H}^{m&#x27;&#x27;}</span>  it holds that  <span class="math">\\alpha&#x27;&#x27;(p) = \\alpha(0^{m-m&#x27;&#x27;},p)</span> . Therefore, for every  <span class="math">x \\in \\{0,1\\}^n</span>  and for every  <span class="math">z \\in \\mathbb{H}^{m&#x27;&#x27;}</span> ,</p>

    <p class="text-gray-300">&lt;span id=&quot;page-43-0&quot;&gt;&lt;/span&gt;
<span class="math">$LDE_x^{\\mathbb{F},\\mathbb{H},m}(0^{m-m&#x27;&#x27;},z) = LDE_x^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z). \\tag{10}</span>$</p>

    <p class="text-gray-300">This, together with the Schwartz-Zippel lemma, and with the fact that both  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}</span>  and  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}</span>  are polynomials of degree at most  <span class="math">|\\mathbb{H}|-1</span>  in each variable, implies that for every  <span class="math">z\\in\\mathbb{F}^{m&#x27;&#x27;}</span>  it holds that</p>

    <p class="text-gray-300"><span class="math">$LDE_x^{\\mathbb{F},\\mathbb{H},m}(0^{m-m&#x27;&#x27;},z) = LDE_x^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z).</span>$</p>

    <p class="text-gray-300">Therefore, it remains to verify the values of  <span class="math">LDE_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span> , where  <span class="math">z_{i,j} \\triangleq (0^{m-m&#x27;&#x27;}, z&#x27;&#x27;_{i,j})</span> . In the memory delegation scheme this was done using the Reveal <span class="math">(z_{i,j})</span>  protocol where the worker reveals the augmented path of the leaf  <span class="math">z_{i,j}</span>  in the Merkle tree-commitment of  <span class="math">LDE_x</span> . Here the Reveal protocol needs to be totally different, since the delegator cannot compute the tree-commitment of  <span class="math">LDE_x</span> .</p>

    <p class="text-gray-300">Unfortunately, unlike in the memory delegation scheme, in the streaming setting constructing a <em>reusable</em> and <em>sound</em> reveal protocol is highly non-trivial.</p>

    <p class="text-gray-300">The Reveal protocol. Our starting point is a basic reveal protocol Reveal&lt;sub&gt;1&lt;/sub&gt; described in Figure 4. Note that the soundness of Reveal&lt;sub&gt;1&lt;/sub&gt; relies on the secrecy of the certificate  <span class="math">\\sigma</span> . Namely, assuming that W does not know the point z, it is not hard to see, by Schwartz-Zippel Lemma, that an adversarial worker can cheat with probability at most  <span class="math">d/|\\mathbb{F}|</span> , where d is the (total) degree of  <span class="math">LDE_x</span> .</p>

    <p class="text-gray-300">However, note that the Reveal&lt;sub&gt;1&lt;/sub&gt; protocol is not reusable. Suppose that D uses the above reveal protocol to learn the value of  <span class="math">\\text{LDE}_x</span>  on two random points  <span class="math">s, s&#x27; \\in \\mathbb{F}^m</span> . From the two executions, an</p>

    <p class="text-gray-300">Reveal&lt;sub&gt;1&lt;/sub&gt; protocol: D stores a secret state  <span class="math">\\sigma = (z, \\text{LDE}_x(z))</span> , where  <span class="math">x \\in \\{0, 1\\}^N</span>  and z is a random point in  <span class="math">\\mathbb{F}^m</span> , and wants to learn the value of  <span class="math">\\text{LDE}_x(s)</span>  from W.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D sends to W the line  <span class="math">\\ell_{sz}</span>  that passes through the points s and z. More specifically, D chooses two random points  <span class="math">\\alpha_1, \\alpha_2 \\leftarrow \\mathbb{F}</span> , and defines  <span class="math">\\ell_{s,z}</span>  to be the line that satisfies  <span class="math">\\ell_{s,z}(\\alpha_1) = z</span>  and  <span class="math">\\ell_{s,z}(\\alpha_2) = s</span> .</li>
      <li>W returns a univariate polynomial  <span class="math">p : \\mathbb{F} \\to \\mathbb{F}</span> , which is the polynomial LDE&lt;sub&gt;x&lt;/sub&gt; restricted to the line  <span class="math">\\ell_{s,z}</span>  (i.e.,  <span class="math">p = \\text{LDE}_x|_{\\ell_{s,z}}</span> ).</li>
      <li>D checks whether  <span class="math">p(\\alpha_1) = \\text{LDE}_x(z)</span> , and if so accepts the value  <span class="math">p(\\alpha_2) = \\text{LDE}_x(s)</span> . Otherwise, she rejects.</li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-44-0&quot;&gt;&lt;/span&gt;Figure 4: Reveal&lt;sub&gt;1&lt;/sub&gt; protocol</p>

    <p class="text-gray-300">adversarial worker W* receives two lines  <span class="math">\\ell_{s,z}</span>  and  <span class="math">\\ell_{s&#x27;,z}</span> , and can learn the secret point z by taking the intersection of the two lines. Once W* learns z, W* can easily cheat by returning any polynomial  <span class="math">p^*</span>  that agrees with LDE&lt;sub&gt;x&lt;/sub&gt; only on point z but disagrees on the remaining points.</p>

    <p class="text-gray-300">As observed by Gennaro et. al. [GGP10], a natural way to protect the secret point z, is to run the above Reveal protocol under a fully-homomorphic encryption (FHE) scheme. Namely, D generates a pair of keys (pk, sk) for a FHE (Gen, Enc, Dec, Eval), and sends pk and an encrypted line  <span class="math">\\hat{\\ell}_{s,z} = \\operatorname{Enc}_{\\mathsf{pk}}(\\ell_{s,z})</span>  to W, who can compute the polynomial  <span class="math">p = \\operatorname{LDE}_x|_{\\ell}</span>  homomorphically under the encryption. Indeed, by the semantic security of FHE, an adversarial worker W* cannot learn any information from D's message  <span class="math">\\hat{\\ell}_{s,z}</span> . This indeed makes the protocol reusable provided that W* does not learn the decision bits of D, as proved in [GGP10, CKV10].</p>

    <p class="text-gray-300">However, since the decision bit of D can potentially contain one bit information about the secret point z, it is not clear that security holds if W* learns these decision bits. In fact, for both of the delegation schemes of [GGP10, CKV10], which use FHE to hide the delegator D's secret state, there are known attacks that learn the whole secret state of D bit-by-bit from D's decision bits.</p>

    <p class="text-gray-300">Fortunately, we are able to show that a variant of the Reveal&lt;sub&gt;1&lt;/sub&gt; protocol described in Figure 5 is reusable even if W* learns the decision bits of D. The main difference between Reveal&lt;sub&gt;1&lt;/sub&gt; and Reveal&lt;sub&gt;2&lt;/sub&gt; is that in Reveal&lt;sub&gt;2&lt;/sub&gt;, the delegator D uses a random <em>two-dimensional</em> affine subspace instead of a line, and uses an FHE to mask the entire protocol.</p>

    <p class="text-gray-300">Using our techniques developed in Section 4 (and in particular using Lemma 22), we show in Section 9.3 that no adversarial W* can learn useful information about the secret point z from the Reveal&lt;sub&gt;2&lt;/sub&gt; protocol. We note that the proof of the above statement is highly non-trivial, and is one of the main technical difficulties in this work. Informally, the proof first uses Lemma 16, which claims that the ciphertext  <span class="math">\\hat{S}_{sz}</span>  and the decision bit b of D (which depend on the strategy of  <span class="math">W^*</span> ) do not give too much information about  <span class="math">S_{sz}</span>  to W*. In other words, the random subspace  <span class="math">S_{s,z}</span>  still has high (pseudo-)entropy from the point of view of W*. Then it uses an information-theoretic argument to argue that a random point z in a sufficiently random (with high entropy) subspace  <span class="math">S_{s,z}</span>  is statistically close to a random point in  <span class="math">\\mathbb{F}^m</span> , which implies that W* does not learn useful information about z.</p>

    <p class="text-gray-300"><strong>The Field Size.</strong> Recall that by Schwartz-Zippel Lemma, an adversarial worker can cheat with probability at most  <span class="math">d/|\\mathbb{F}|</span> , where d is the (total) degree of LDE&lt;sub&gt;x&lt;/sub&gt;. Recall that in our setting of</p>

    <p class="text-gray-300">Reveal&lt;sub&gt;2&lt;/sub&gt; protocol: D stores a secret state  <span class="math">\\sigma = (z, \\text{LDE}_x(z))</span> , where  <span class="math">x \\in \\{0, 1\\}^N</span>  and z is a random point in  <span class="math">\\mathbb{F}^m</span> , and wants to learn the value of  <span class="math">\\text{LDE}_x(s)</span>  from W.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D does the following.    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Generate a pair of keys  <span class="math">(pk, sk) \\leftarrow \\text{Gen}(1^k)</span>  for a fully homomorphic encryption scheme FHE</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Choose a random two-dimensional affine subspace  <span class="math">S_{s,z} \\subset \\mathbb{F}^m</span>  that contains the points s and z. More specifically, choose two random points  <span class="math">\\alpha_1, \\alpha_2 \\leftarrow \\mathbb{F}^2</span>  and let  <span class="math">S_{s,z} \\subset \\mathbb{F}^m</span>  be a random two-dimensional affine subspace that satisfies  <span class="math">S_{s,z}(\\alpha_1) = z</span>  and  <span class="math">S_{s,z}(\\alpha_2) = s</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Send  <span class="math">\\hat{S}_{s,z} \\leftarrow \\operatorname{Enc}_{\\mathsf{pk}}(S_{s,z})</span>  and  <span class="math">\\mathsf{pk}</span>  to  <span class="math">\\mathsf{W}</span> .</li>
    </ol></li>
    </ul></li>
      <li>W homomorphically computes the two-variate polynomial  <span class="math">p = LDE_x|_{S_{s,z}}</span>  under the FHE (denote the resulting ciphertext  <span class="math">\\hat{p}</span> ), and sends  <span class="math">\\hat{p}</span>  to D.</li>
      <li>D decrypts and checks whether  <span class="math">p(\\alpha_1) = \\text{LDE}_x(z)</span> , and if so accepts the value  <span class="math">p(\\alpha_2) = \\text{LDE}_x(s)</span> .</li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-45-0&quot;&gt;&lt;/span&gt;Figure 5: Protocol Reveal&lt;sub&gt;2&lt;/sub&gt;</p>

    <p class="text-gray-300">parameters:</p>

    <p class="text-gray-300"><span class="math">$|\\mathbb{H}| = \\text{polylog}(N), \\ m = O\\left(\\frac{\\log N}{\\log \\log N}\\right), \\ |\\mathbb{F}| = \\text{poly}(|\\mathbb{H}|).</span>$</p>

    <p class="text-gray-300">Thus, a cheating worker can cheat with probability  <span class="math">d/|\\mathbb{F}| = O(1/\\text{polylog}(N))</span> , which is not low enough.</p>

    <p class="text-gray-300">The idea is to reduce the cheating probability to negligible by simply increasing the field size to be super-polynomial. However, we cannot increase the field size in the GKR protocol, since it will increase the complexity of the worker. Instead, we use an extension field  <span class="math">\\tilde{\\mathbb{F}}</span>  of  <span class="math">\\mathbb{F}</span> , of superpolynomial size, only in the certificate and the Reveal protocol, but run the GKR protocols as before. Namely, the secret state is  <span class="math">\\sigma = (z, \\mathrm{LDE}^{\\tilde{\\mathbb{F}}, \\mathbb{H}, m}(z))</span>  where  <span class="math">z \\leftarrow \\tilde{\\mathbb{F}}^m</span> , The GKR protocols are run exactly as before (one  <span class="math">\\mathrm{GKR}^{(u)}</span>  protocol with the parameters  <span class="math">(\\mathbb{H}&#x27;, \\mathbb{F}&#x27;, m&#x27;)</span> , and u  <span class="math">\\mathrm{GKR}^{(u)}</span>  protocols with the parameters  <span class="math">(\\mathbb{H}, \\mathbb{F}, m&#x27;&#x27;)</span> ). In the Reveal protocol, the worker reveals to a point  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F}, \\mathbb{H}, m}(s)</span>  as follows: The delegator sends an encryption of a random two-dimensional subspace  <span class="math">S_{s,z} \\subset \\tilde{\\mathbb{F}}^m</span> , containing the points s and s, and the worker sends an encryption of  <span class="math">\\mathrm{LDE}_x|_{S_{s,z}}</span> . The delegator verifies correctness exactly as in Reveal&lt;sub&gt;2&lt;/sub&gt;.</p>

    <p class="text-gray-300">Reveal Multiple Points in Parallel. Finally, recall that in memory delegation, the reveal protocol is executed in parallel  <span class="math">u^2</span>  times to reveal  <span class="math">u^2</span>  random points  <span class="math">z_{i,j}</span> . However, if all reveal protocols use the same algebraic commitment  <span class="math">(z, \\text{LDE}_x(z))</span> , then proving that z remains secret after W* learns the decision bits of D becomes somewhat tricky.&lt;sup&gt;28&lt;/sup&gt; Instead, we could use  <span class="math">u^2</span>  independent commitments, one for each copy of the Reveal protocol. However, it blows up the size of D's secret state as well as her runtime during the update procedure. It also makes the analysis somewhat more complicated.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-45-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;28&lt;/sup&gt;We can make it work, but the analysis becomes more complicated. We decide to avoid this unnecessary complication.</p>

    <p class="text-gray-300">Therefore, instead of running multiple copies of the Reveal protocol in parallel, we use a classic &quot;many-to-one&quot; reduction to reduce the number of points to a <em>single</em> point, so that D only needs to run a single copy of the Reveal protocol. Briefly, the idea is to let D choose a random degree- <span class="math">u^2</span>  curve  <span class="math">\\ell</span> , passing through  <span class="math">z_{i,j} \\in \\mathbb{F}^m</span>  for  <span class="math">i,j \\in [u]</span>  and passing through an additional random point  <span class="math">s \\leftarrow \\tilde{\\mathbb{F}}^m</span> , and send  <span class="math">\\ell</span>  to W. More specifically, D will choose  <span class="math">u^2 + 1</span>  random points  <span class="math">\\alpha_0, \\alpha_{i,j} \\leftarrow \\tilde{\\mathbb{F}}</span>  for  <span class="math">i,j \\in [u]</span> , and let  <span class="math">\\ell</span>  be the  <span class="math">u^2</span> -degree polynomial such that  <span class="math">\\ell(\\alpha_0) = s</span>  and  <span class="math">\\ell(\\alpha_{i,j}) = z_{i,j}</span>  for every  <span class="math">i,j \\in [u]</span> . The worker W returns a univariate polynomial  <span class="math">p: \\tilde{\\mathbb{F}} \\to \\tilde{\\mathbb{F}}</span> , which is supposed to be  <span class="math">\\mathrm{LDE}_x</span>  restricted on the line  <span class="math">\\ell</span> . If W is honest, then D learns the values  <span class="math">\\mathrm{LDE}_x(z_{i,j}) = p(\\alpha_{i,j})</span>  for  <span class="math">i,j \\in [u]</span> , as desired. To verify that W was indeed honest, D and W run the Reveal protocol on the point s, to reveal to  <span class="math">\\mathrm{LDE}_x(s)</span> , and D checks whether indeed  <span class="math">p(\\alpha_0) = \\mathrm{LDE}_x(s)</span> .</p>

    <p class="text-gray-300">To summarize, our Compute(f) protocol runs the above many-to-one protocol and the Reveal protocol, in parallel, in order to reveal to  <span class="math">\\{LDE_x(z_{i,j})\\}_{i,j\\in[u]}</span> .</p>

    <h4 id="sec-31" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-46-1&quot;&gt;&lt;/span&gt;9.2 Formal Description of Our Streaming Delegation Scheme</h4>

    <p class="text-gray-300">In this section, we give a formal description of our streaming delegation scheme for delegating  <span class="math">\\mathcal{L}</span> -uniform depth-d circuits. Our construction uses the following building blocks</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>A fully homomorphic encryption scheme E = (Gen, Enc, Dec, Eval) where the semantic security holds against poly(N)-time adversaries (with negligible advantage in N).</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The delegation scheme GKR =  <span class="math">\\langle D&#x27;, W&#x27; \\rangle</span>  from [GKR08, KR09] (see Theorem 8 for the properties of this delegation scheme). The main property we use here, is that the delegator can verify proofs by accessing its input x at a single random point in  <span class="math">LDE_x</span> .</li>
    </ol></li>
      <li>Parameters. Let k be the security parameter, and let N be an upper bound on the length of the data stream. Let  <span class="math">\\mathbb{H}</span>  be an extension field of  <span class="math">\\mathbb{GF}[2]</span>  of size  <span class="math">|\\mathbb{H}| = \\operatorname{polylog}(N)</span> , let  <span class="math">m = \\theta\\left(\\frac{\\log N}{\\log\\log N}\\right)</span> , and let  <span class="math">\\mathbb{F}</span>  be an extension field of  <span class="math">\\mathbb{H}</span>  of size  <span class="math">|\\mathbb{F}| = \\operatorname{poly}(|\\mathbb{H}|)</span> . Let  <span class="math">\\tilde{\\mathbb{F}}</span>  be an extension field of  <span class="math">\\mathbb{F}</span>  of size  <span class="math">|\\tilde{\\mathbb{F}}| = N^{\\log N}</span> .</li>
      <li>Generating and updating the secret state.    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>At the initial time t=0, the delegator D chooses a random point  <span class="math">z \\leftarrow \\tilde{\\mathbb{F}}^m</span> , and stores  <span class="math">\\sigma_0 = (z,0)</span>  as her secret state.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>At each time  <span class="math">t \\in [N]</span> , when a data item  <span class="math">x_t \\in \\{0,1\\}</span>  arrives, D updates her secret state from  <span class="math">\\sigma_{t-1} = (z, \\text{LDE}_{x^{t-1}}(z))</span>  to  <span class="math">\\sigma_t = (z, \\text{LDE}_{x^t}(z))</span> , by using Proposition 6.&lt;sup&gt;29&lt;/sup&gt; (Recall that  <span class="math">x^t = (x_1, \\dots, x_t)</span>  denotes the entire data stream up until time t.)</li>
    </ol></li>
    </ul></li>
      <li>Compute (f,t). At any time  <span class="math">t \\in [N]</span>  when the delegator wants the worker to compute some function f, where f is an  <span class="math">\\mathcal{L}</span> -uniform depth-d circuit, they run the following protocols in parallel.</li>
    </ul>

    <p class="text-gray-300"><span class="math">$LDE_{xt}(z) = LDE_{xt-1}(z) + x_t \\cdot LDEe_t(z),</span>$</p>

    <p class="text-gray-300">where  <span class="math">e_t \\in \\{0,1\\}^N</span>  denotes the N-bit string with 1 at the t-th bit, and 0 otherwise. Note that  <span class="math">LDE_{e_t}(z)</span>  can be computed in polylog(N) time by interpolation.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-46-0&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;29&lt;/sup&gt;More explicitly, the update is done using the following formula.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Run GKR&lt;sup&gt;(u)&lt;/sup&gt;, which is the u-fold parallel repetition of the underlying delegation protocol GKR, for delegating the computation of f(x), where u is any parameter such that  <span class="math">1/2^u = \\operatorname{ngl}(N)</span> . If at any time the GKR delegator rejects, the delegator D rejects. Let  <span class="math">\\mathbb{F}&#x27;, \\mathbb{H}&#x27;, m&#x27;</span>  be the parameters used by GKR&lt;sup&gt;(u)&lt;/sup&gt;, and recall that at the end of the protocol, D needs to verify the value of  <span class="math">\\operatorname{LDE}_{x^t}^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}</span>  at u random points  <span class="math">r_1,\\ldots,r_u\\in(\\mathbb{F}&#x27;)^{m&#x27;}</span> , i.e. it needs to check whether  <span class="math">\\operatorname{LDE}_{x^t}^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)=v_i</span>  for some values  <span class="math">v_i</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>For each  <span class="math">i \\in [u]</span> , run  <span class="math">GKR^{(u)}</span>  for delegating the computation in  <span class="math">g_{r_i}(x^t) \\triangleq LDE_{x^t}^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span> . These  <span class="math">GKR^{(u)}(g_{r_i})</span>  protocols are done with respect to  <span class="math">(\\mathbb{H}, \\mathbb{F}, m&#x27;&#x27;)</span> , where  <span class="math">m&#x27;&#x27; = \\theta\\left(\\frac{\\log t}{\\log \\log N}\\right)</span> . Moreover, these protocols are masked using a PIR scheme to keep the secrecy of the  <span class="math">r_i</span> 's, which is necessary to ensure the soundness of the  <span class="math">GKR^{(u)}</span>  protocol of Step 1. We note that Steps 1 and 2 above are almost identical to Steps 1 and 2 of the Compute(f) operation of our memory delegation scheme, constructed in Section 7.2, and we refer the reader to Section 7.2 for a detailed description of the masked  <span class="math">GKR^{(u)}(g_{r_i})</span>  protocols. If the GKR delegator rejects at any point, then the delegator D rejects. Otherwise, in order to verify these protocols, D needs to check that  <span class="math">LDE_{x^t}^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z&#x27;&#x27;_{i,j}) = w_{i,j}</span>  for  <span class="math">u^2</span>  random points  <span class="math">z&#x27;&#x27;_{i,j} \\in \\mathbb{F}^{m&#x27;&#x27;}</span> , and some values  <span class="math">w_{i,j} \\in \\mathbb{F}</span> . However, as was argued above (see Equation (10)),  <span class="math">LDE_{x^t}^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z&#x27;&#x27;_{i,j}) = LDE_{x^t}^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span>  where  <span class="math">z_{i,j} = (0^{m-m&#x27;&#x27;}, z&#x27;&#x27;_{i,j})</span> . Thus, D needs to check that  <span class="math">LDE_{x^t}^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z_{i,j}) = w_{i,j}</span>  for  <span class="math">u^2</span>  points  <span class="math">z_{i,j} \\in \\mathbb{F}^m</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Run a many-to-one protocol to reduce computing  <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span>  for  <span class="math">u^2</span>  points  <span class="math">z_{i,j} \\in \\mathbb{F}^m</span> , to computing  <span class="math">\\mathrm{LDE}_{x^t}^{\\tilde{\\mathbb{F}},\\mathbb{H},m}(s)</span>  for a single random point  <span class="math">s \\leftarrow \\tilde{\\mathbb{F}}^m</span> . Note that s is a random point in the extension field  <span class="math">\\tilde{\\mathbb{F}}^m</span> , as opposed to  <span class="math">\\mathbb{F}^m</span> . As before, the points  <span class="math">(z_{i,j})_{i,j\\in[u]}</span>  must be kept secret to ensure the soundness of the  <span class="math">\\mathrm{GKR}^{(u)}</span>  protocols of Step 2. We ensure this secrecy by simply running the protocol under an FHE scheme. We note that we cannot use a PIR scheme here, since  <span class="math">\\tilde{\\mathbb{F}}</span>  is of super-poly size, and therefore</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>We note that we cannot use a PIR scheme here, since  <span class="math">\\tilde{\\mathbb{F}}</span>  is of super-poly size, and therefore the use of a PIR scheme will result with the worker running in super-polynomial time. Instead we use an FHE scheme, which keeps both the worker and the delegator efficient. More specifically, the delegator D chooses a random  <span class="math">s \\leftarrow \\tilde{\\mathbb{F}}^m</span>  and computes a canonical representation of the unique degree- <span class="math">u^2</span>  curve  <span class="math">\\ell_{\\vec{z},s}</span>  passing through  <span class="math">\\vec{z} = (z_{i,j})_{i,j \\in [u]}</span>  and s. Then D generates  <span class="math">(\\mathsf{pk}_1, \\mathsf{sk}_1) \\leftarrow \\mathrm{Gen}(1^k)</span> , computes  <span class="math">\\hat{\\ell}_{\\vec{z},s} = \\mathrm{Enc}_{\\mathsf{pk}_1}(\\ell_{\\vec{z},s})</span> , and sends  <span class="math">(\\mathsf{pk}_1, \\hat{\\ell}_{\\vec{z},s})</span>  to W. The worker W computes, homomorphically under encryption, a univariate polynomial  <span class="math">p_1 \\triangleq \\mathrm{LDE}_{x^t}^{\\tilde{F},\\mathbb{H},m} \\circ \\ell_{\\vec{z},s}</span> , and returns the resulting ciphertext  <span class="math">\\hat{p}_1</span>  to D, who decrypts to obtain the polynomial  <span class="math">p_1</span> .</li>
      <li>Let  <span class="math">\\alpha_0, \\alpha_{i,j} \\in \\tilde{\\mathbb{F}}</span>  for  <span class="math">i, j \\in [u]</span>  be such that  <span class="math">\\ell_{\\vec{z},s}(\\alpha_0) = s</span>  and  <span class="math">\\ell_{\\vec{z},s}(\\alpha_{i,j}) = z_{i,j}</span> . D checks whether  <span class="math">w_{i,j} = p_1(\\alpha_{i,j})</span>  (which are supposed to be  <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})</span> ). If not, she rejects.</li>
    </ul></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>In order to verify that indeed  <span class="math">p_1 = \\mathrm{LDE}_{x^t}^{\\tilde{\\mathbb{F}}, \\mathbb{H}, m} \\circ \\ell_{\\vec{z}, s}</span> , the delegator D checks whether  <span class="math">\\mathrm{LDE}_{x^t}^{\\tilde{\\mathbb{F}}, \\mathbb{H}, m}(s) = p_1(\\alpha_0)</span> , using the Reveal protocol described in Figure 6, and using its certificate  <span class="math">\\sigma_t = (z, \\mathrm{LDE}_{x^t}^{\\tilde{\\mathbb{F}}, \\mathbb{H}, m}(z))</span> .</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-47-0&quot;&gt;&lt;/span&gt;Recall that since computing  <span class="math">g_{r_i}(\\cdot)</span>  can be done by a polylog(N)-depth poly-size circuit, this setting of parameters works for  <span class="math">GKR^{(u)}</span> .</p>

    <p class="text-gray-300">&lt;span id=&quot;page-47-1&quot;&gt;&lt;/span&gt; <span class="math">&lt;sup&gt;^{31}&lt;/sup&gt;</span> We mention that, we can also mask the GKR&lt;sup&gt;(u)&lt;/sup&gt; protocol using an FHE scheme, as opposed to a polylog PIR scheme, which is what we do in Step 3.</p>

    <p class="text-gray-300">Note that in the Reveal protocol, we are specific about the representation of the random affine space  <span class="math">S_{s,z}</span> . This representation will be useful when we apply our main leakage lemma (Lemma 22), established in Section 4, to prove the reusable soundness of sDel in Section 9.3.</p>

    <p class="text-gray-300">If D rejects in the Reveal(s) protocol, or if the accepted  <span class="math">p_2(\\alpha_s)</span>  is not equal to the claimed value  <span class="math">p_1(\\alpha_0)</span> , then D rejects.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The delegator accepts the interaction if and only if she did not reject in any place above.</li>
    </ol>

    <p class="text-gray-300">Note that the first two steps are (almost) the same as that in our memory delegation scheme (Section 7.2). As before, we denote the delegation protocol of Step 1 by</p>

    <p class="text-gray-300"><span class="math">$GKR^{(u)} = \\langle W&#x27;^{(u)}, D&#x27;^{(u)}(r_1, \\dots, r_u) \\rangle (f).</span>$</p>

    <p class="text-gray-300">We denote the masked delegation protocols of Step 2 by</p>

    <p class="text-gray-300">PIR
<span class="math">$\\left(\\langle \\mathsf{W}&#x27;^{(u)}, \\mathsf{D}&#x27;^{(u)}(z_{i,1}&#x27;&#x27;, \\ldots, z_{i,u}&#x27;&#x27;) \\rangle(g_{r_i})\\right)</span>$
.</p>

    <p class="text-gray-300">We denote the masked many-to-one protocol of Step 3 by  <span class="math">u^2</span> -to- <span class="math">1(\\vec{z}, s)</span>  and the reveal protocol of Step 4 by Reveal(s). Note that the streaming data  <span class="math">x^t</span>  is implicit in all these notations. We summarize the Compute(f) protocol in Figure 7.</p>

    <p class="text-gray-300"><strong>Remark.</strong> We note that our streaming delegation scheme can also be used as a memory delegation scheme. Recall that the only component that a memory delegation scheme has, and a streaming delegation scheme does not have, is the Update operation. Also recall that in our memory delegation scheme, the delegator D delegates the update of her state (from  <span class="math">(h, T_h(x))</span>  to  <span class="math">(h&#x27;, T_{h&#x27;}(g(x)))</span> ) to the worker W. The same idea can be applied to the streaming delegation scheme as well.&lt;sup&gt;32&lt;/sup&gt; As mentioned in Section 7.1, our memory delegation scheme has several advantages over the one that could be obtained from our streaming delegation scheme.</p>

    <h4 id="sec-32" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-48-0&quot;&gt;&lt;/span&gt;9.3 Proof of Theorem 40.</h4>

    <p class="text-gray-300">In this section, we prove that the construction above satisfies the properties of Theorem 40.</p>

    <p class="text-gray-300">The perfect completeness follows immediately from the completeness of the underlying GKR delegation scheme, the completeness of the FHE scheme, and the completeness of the Reveal protocol. The fact that the delegator D can update her secret state in time polylog(N) follows from Proposition 6. The efficiency guarantees of the Compute protocol follow immediately from the efficiency guarantees of GKR, the efficiency guarantees of the underlying PIR scheme, and the efficiency of the  <span class="math">u^2</span> -to-1 protocol and the Reveal protocol, under FHE.</p>

    <p class="text-gray-300">The main difficulty is in proving soundness. First we observe that the streaming delegation scheme is one-time sound. This proof is very similar to the proof that our memory delegation scheme is one-time sound (Lemma 32). However, it is at all not clear how to reduce one-time soundness to many-time soundness, since the delegator uses the same secret state in all the executions, and each decision bit of the delegator may leak one bit information about this secret state.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-48-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;32&lt;/sup&gt;We note that to ensure that D's secret state is kept secret from the worker W after the Update operation, we would need to run the Compute operation (for updating D' secret state) under FHE.</p>

    <p class="text-gray-300">Reveal(s):</p>

    <p class="text-gray-300">The delegator D stores a secret algebraic commitment  <span class="math">\\sigma_t = (z, \\text{LDE}_{x^t}^{\\tilde{\\mathbb{F}}, \\mathbb{H}, m}(z))</span>  and wants to learn the value of  <span class="math">\\text{LDE}_{x^t}^{\\tilde{\\mathbb{F}}, \\mathbb{H}, m}(s)</span>  from the worker W, who stores  <span class="math">x \\in \\{0, 1\\}^N</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D does the following.    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Choose a random two-dimensional affine subspace  <span class="math">S_{s,z} \\subset \\tilde{\\mathbb{F}}^m</span>  that contains the points s and z.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Let  <span class="math">X = S_{s,z} s \\triangleq \\{v s : v \\in S_{s,z}\\}</span> . Namely, X is a random two-dimensional subspace that contains the point z s.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Choose a random representation for X, by choosing two random points  <span class="math">x_1, x_2 \\leftarrow X</span> , and represent X as a matrix in  <span class="math">\\tilde{\\mathbb{F}}^{m \\times 2}</span>  where the first column is  <span class="math">x_1</span>  and the second column is  <span class="math">x_2</span> .</li>
    </ol></li>
    </ul></li>
    </ul>

    <p class="text-gray-300">Thus, every point  <span class="math">a \\in S_{s,z}</span>  is represented by  <span class="math">a = X \\cdot \\alpha + s</span>  for some  <span class="math">\\alpha \\in \\tilde{\\mathbb{F}}^2</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Generate a pair of keys  <span class="math">(\\mathsf{pk}_2, \\mathsf{sk}_2) \\leftarrow \\operatorname{Gen}(1^k)</span>  and compute an encryption</li>
    </ol>

    <p class="text-gray-300"><span class="math">$\\hat{S}_{s,z} \\triangleq (\\hat{X}, \\hat{s}) = (\\operatorname{Enc}_{\\mathsf{pk}_2}(X), \\operatorname{Enc}_{\\mathsf{pk}_2}(s)).</span>$</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Send  <span class="math">(pk_2, \\hat{S}_{s,z})</span>  to W.</li>
    </ol></li>
      <li>W homomorphically computes the two-variate polynomial  <span class="math">p_2 = \\text{LDE}_x \\circ S_{s,z}</span>  under the FHE (denote the resulting ciphertext  <span class="math">\\hat{p}_2</span> ), and sends  <span class="math">\\hat{p}_2</span>  to D.</li>
      <li>D decrypts  <span class="math">\\hat{p}_2</span>  to obtain  <span class="math">p_2</span> . Let  <span class="math">\\alpha_s, \\alpha_z \\in \\tilde{\\mathbb{F}}^2</span>  be such that  <span class="math">S_{s,z}(\\alpha_s) = s</span>  and  <span class="math">S_{s,z}(\\alpha_z) = z</span> . D checks whether  <span class="math">p_2(\\alpha_z) = \\mathrm{LDE}_{x^t}^{\\tilde{\\mathbb{F}},\\mathbb{H},m}(z)</span> . If so, D accepts the value  <span class="math">\\mathrm{LDE}_{x^t}^{\\tilde{\\mathbb{F}},\\mathbb{H},m}(s) = p_2(\\alpha_s)</span> . Otherwise, D rejects.</li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-49-0&quot;&gt;&lt;/span&gt;Figure 6: Formal description of the Reveal protocol.</p>

    <p class="text-gray-300">Soundness: high-level intuition. Intuitively, we would like to prove that in our construction, the decision bit of the delegator does not reveal any information about her secret state z, and thus this secret is &quot;reusable&quot;, and hence the protocol is many-time sound.</p>

    <p class="text-gray-300">Recall that in our Compute protocol, the delegator D uses her secret state z only in the Reveal protocol, where she sends the worker an encryption of a random two-dimensional affine subspace  <span class="math">S_{s,z}</span>  that contains z. Intuitively, the idea is to use our main leakage lemma (Lemma 22 in section 4) to argue that in the Reveal protocol, any one-bit leakage about the subspace  <span class="math">S_{s,z}</span>  does not reveal information about z (i.e., z looks totally random from the worker's view). While it is indeed true that any bit of leakage about  <span class="math">S_{s,z}</span>  does not reveal any information about z, note that the decision of the delegator in the Reveal protocol does depend on the actual point z, and not just on the subspace  <span class="math">S_{s,z}</span>  (as she checks the value of  <span class="math">p_2(\\alpha_z)</span> ).</p>

    <p class="text-gray-300">One way of going around this, is by considering another delegator  <span class="math">\\tilde{D}</span> , which is a &quot;somewhat cautious&quot; delegator, in the sense that she does not check the validity of the polynomial  <span class="math">p_2</span>  at the specific point  <span class="math">\\alpha_z</span> , as this depends on her secret point z. Instead,  <span class="math">\\tilde{D}</span>  is an inefficient delegator that holds the entire stream  <span class="math">x \\in \\{0,1\\}^t</span> , and checks that  <span class="math">p_2 = \\text{LDE}_x \\circ S_{s,z}</span> . The point is that  <span class="math">\\tilde{D}</span>  does</p>

    <h3 id="sec-33" class="text-xl font-semibold mt-8">Compute(f, t):</h3>

    <p class="text-gray-300">The delegator D stores a secret state  <span class="math">\\sigma_t = (z, \\text{LDE}_x^{\\tilde{\\mathbb{F}},H,m}(z))</span>  and wants to learn the value of f(x) from the worker W, who stores  <span class="math">x \\in \\{0,1\\}^N</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D and W run GKR&lt;sup&gt;(u)&lt;/sup&gt; =  <span class="math">\\langle W&#x27;^{(u)}, D&#x27;^{(u)}(r_1, \\dots, r_u) \\rangle (f)</span> .</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(a) If  <span class="math">D&#x27;^{(u)}</span>  rejects, then the delegator D outputs &quot;reject&quot;.</li>
      <li>(b) At the end of this protocol, the delegator D' needs to verify that  <span class="math">LDE_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i) = v_i</span>  for some values  <span class="math">v_i</span> .</li>
    </ul></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>For every  <span class="math">i \\in [u]</span> , run  <span class="math">PIR(\\langle W&#x27;^{(u)}, D&#x27;^{(u)}(z&#x27;&#x27;_{i,1}, \\ldots, z&#x27;&#x27;_{i,u})\\rangle(g_{r_i}))</span>  with parameters  <span class="math">(\\mathbb{H}, \\mathbb{F}, m&#x27;&#x27;)</span>  where  <span class="math">m&#x27;&#x27; = \\theta\\left(\\frac{\\log t}{\\log \\log N}\\right)</span> .</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(a) The delegator D makes sure that in these protocols the worker still claims that indeed  <span class="math">g_{r_i}(x) = v_i</span> , where  <span class="math">g_{r_i}(x) = \\text{LDE}_x^{\\mathbb{F}&#x27;,\\mathbb{H}&#x27;,m&#x27;}(r_i)</span> . If this is not the case, then the delegator D outputs &quot;reject&quot;.</li>
      <li>(b) If at any point D' rejects, then the delegator D outputs &quot;reject&quot;.</li>
      <li>(c) In order to verify these protocols, the delegator D needs to verify that  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z_{i,j}&#x27;&#x27;)=w_{i,j}</span>  for some values  <span class="math">w_{i,j}</span> , which is equivalent to verifying that  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}(z_{i,j})=w_{i,j}</span>  where  <span class="math">z_{i,j}=(0^{m-m&#x27;&#x27;},z_{i,j}&#x27;&#x27;)\\in\\mathbb{F}^m</span>  (see Equation (10)).</li>
    </ul></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Run  <span class="math">u^2</span> -to- <span class="math">1(\\vec{z}, s)</span>  where  <span class="math">\\vec{z} = (z_{i,j})</span> .</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Recall that in this protocol, D sends W a message  <span class="math">(\\mathsf{pk}_1, \\hat{\\ell}_{\\vec{z},s})</span> , where  <span class="math">\\ell_{\\vec{z},s}</span>  is a canonical representation of the  <span class="math">u^2</span> -degree curve that passes through the points  <span class="math">z_{i,j}</span>  and the point s; namely,  <span class="math">\\ell_{\\vec{z},s}(\\alpha_{i,j}) = z_{i,j}</span>  and  <span class="math">\\ell_{\\vec{z},s}(\\alpha_0) = s</span> , for some  <span class="math">\\alpha_{i,j}, \\alpha_0 \\in \\tilde{\\mathbb{F}}</span> . Then, W sends  <span class="math">\\hat{p}_1</span> , where supposedly,  <span class="math">p_1 = \\mathrm{LDE}_{x^t}^{\\tilde{\\mathbb{F}},\\mathbb{H},m} \\circ \\ell_{\\vec{z},s}</span></p>

    <p class="text-gray-300">The delegator D verifies that  <span class="math">p_1(\\alpha_{i,j}) = w_{i,j}</span>  for every  <span class="math">i, j \\in [u]</span> . If this is not the case, then the delegator D outputs &quot;reject&quot;.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The delegator D verifies that LDE&lt;sub&gt;x&lt;/sub&gt;&lt;sup&gt;F,H,m&lt;/sup&gt;(s) = p&lt;sub&gt;1&lt;/sub&gt;(α&lt;sub&gt;0&lt;/sub&gt;) by running Reveal(s).
If D rejects in the Reveal(s) protocol, or if p&lt;sub&gt;1&lt;/sub&gt;(α&lt;sub&gt;0&lt;/sub&gt;) ≠ p&lt;sub&gt;2&lt;/sub&gt;(α&lt;sub&gt;s&lt;/sub&gt;) (where p&lt;sub&gt;2&lt;/sub&gt; and α&lt;sub&gt;s&lt;/sub&gt; are defined in the Reveal(s) protocol in Figure 6), then D rejects.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The delegator D outputs &quot;accept&quot;, assuming she didn't output &quot;reject&quot; at any point.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-50-0&quot;&gt;&lt;/span&gt;Figure 7: Compute(f)</p>

    <p class="text-gray-300">not use the actual point z, but only the random subspace Ss,z.</p>

    <p class="text-gray-300">Now we can try to use our main leakage lemma (Lemma <a href="#page-23-0">22)</a> to claim that each execution of Compute does not reveal any information about the delegator's secret state z, and thus she can safely use this secret state again. It still remains to argue that if a cheating worker could cheat when talking to a &quot;somewhat cautious&quot; delegator, then he could also cheat when talking to the real delegator. The idea here is to use the Schwartz-Zippel lemma (with a computationally hidden z).</p>

    <p class="text-gray-300">Towards our formal proof. In our formal proof, we take another route. We define a &quot;cautious&quot; delegator (as opposed to a &quot;somewhat cautious&quot;) to be one that each time uses a fresh new secret state z 0 . As above, our cautious delegator is inefficient, and has the entire stream x ∈ {0, 1} t . The many-time soundness of this cautious scheme follows immediately from its one-time soundness.</p>

    <p class="text-gray-300">Next, we consider a sequence of N hybrid games, G0, . . . , G&lt;sup&gt;N&lt;/sup&gt; , where in G&lt;sup&gt;t&lt;/sup&gt; the delegator is cautious during the first t Compute protocols, and runs the protocol of the original delegator D from the t + 1'st execution onwards. Note that G&lt;sup&gt;0&lt;/sup&gt; is the real soundness game (with the real delegator D), as defined in Definition <a href="#page-39-0">37,</a> whereas G&lt;sup&gt;N&lt;/sup&gt; is the soundness game with the cautious delegator D˜. Thus, if there exists a cheating worker W&lt;sup&gt;∗&lt;/sup&gt; that cheats in the original game G0, by a standard hybrid argument, there must exist two games Gt−&lt;sup&gt;1&lt;/sup&gt; and G&lt;sup&gt;t&lt;/sup&gt; where there is a noticeable gap between the success probability of W&lt;sup&gt;∗&lt;/sup&gt; in Gt−&lt;sup&gt;1&lt;/sup&gt; and its success probability in G&lt;sup&gt;t&lt;/sup&gt; .</p>

    <p class="text-gray-300">The idea is to use this fact to contradict our main leakage lemma (Lemma <a href="#page-23-0">22)</a>, as follows. Simulate the first t − 1 Compute operations. Note that in both Gt−&lt;sup&gt;1&lt;/sup&gt; and in G&lt;sup&gt;t&lt;/sup&gt; the delegator uses a fresh secret state in these executions. Then, in the t'th Compute operation, use the subspace given by the leakage lemma.</p>

    <p class="text-gray-300">Recall that the leakage lemma claims that it is hard to distinguish between (x,Encpk(X), pk, b) and (u,Encpk(X), pk, b), where x ← X and u ← F˜m. So, the idea is to use pk,Encpk(X) in the Reveal(s) protocol. Then continue the simulation of the rest of the Compute operations using the secret state w + s, where w is either a random element in X or a random element in F˜m. However, as was noted above, we cannot use the leakage lemma, since the original delegator actually used the secret point to check the validity of the polynomial p&lt;sup&gt;2&lt;/sup&gt; sent by the worker. This, slightly complicates matters.</p>

    <p class="text-gray-300">We define our &quot;cautious&quot; delegator to be really cautious, so that not only does he use a fresh secret state z 0 for each round, but he also checks the validity of the polynomial p&lt;sup&gt;2&lt;/sup&gt; sent by the worker, by actually checking that p&lt;sup&gt;2&lt;/sup&gt; ≡ LDE&lt;sup&gt;x&lt;/sup&gt; ◦ Ss,z&lt;sup&gt;0&lt;/sup&gt; (as opposed to checking its validity at a single point). Then, assuming we have a gap between Gt−&lt;sup&gt;1&lt;/sup&gt; and G&lt;sup&gt;t&lt;/sup&gt; , we consider another hybrid game between these two games, which we denote by G ∗ . This game is similar to the game Gt−1, in the sense that the delegator uses the real secret state z in the t'th round, but it differs from Gt−&lt;sup&gt;1&lt;/sup&gt; in that it checks the validity of p&lt;sup&gt;2&lt;/sup&gt; by checking that p&lt;sup&gt;2&lt;/sup&gt; = LDE&lt;sup&gt;x&lt;/sup&gt; ◦ Ss,z.</p>

    <p class="text-gray-300">We use the Schwartz-Zippel lemma to prove that Gt−&lt;sup&gt;1&lt;/sup&gt; and G &lt;sup&gt;∗&lt;/sup&gt; are statistically indistinguishable, and we use our main leakage lemma (Lemma <a href="#page-23-0">22)</a> to prove that G &lt;sup&gt;∗&lt;/sup&gt; and G&lt;sup&gt;t&lt;/sup&gt; are computationally indistinguishable. The latter is done by contradiction. If there exists a distinguisher between the games G &lt;sup&gt;∗&lt;/sup&gt; and G&lt;sup&gt;t&lt;/sup&gt; , then we construct a distinguisher that distinguishes between the distributions given the leakage lemma. This is done by simply embedding the input given by the leakage lemma in the t'th round of the Reveal protocol.</p>

    <p class="text-gray-300">Remark 41 We remark that the security reduction is inherently non-uniform, due to the use of the machinery developed in Section <a href="#page-15-1">4.</a> Specifically, the proof of Lemma <a href="#page-17-0">16</a> uses the equivalence of HILL and Metric entropy, which only holds in the non-uniform setting. Therefore, the cryptographic primitives that we rely on need to be secure against non-uniform adversaries. In contrast, the security proof of our memory delegation scheme in Section 7 is uniform.</p>

    <p class="text-gray-300">In what follows we formally define the notion of a cautious delegator (or a cautious streaming delegation scheme), followed by a formal proof of the (reusable) soundness of our streaming delegation scheme.</p>

    <p class="text-gray-300">Cautious Streaming Delegation Scheme  <span class="math">s\\tilde{Del} = \\langle W, \\tilde{D} \\rangle</span> . For the purpose of our analysis, we consider a variant of sDel, called <em>cautious streaming delegation scheme</em>, which we denote by  <span class="math">s\\tilde{Del} = \\langle W, \\tilde{D} \\rangle</span> . In  <span class="math">s\\tilde{Del}</span>  the worker is exactly the same as the worker in sDel, but the delegator is &quot;cautious.&quot;</p>

    <p class="text-gray-300">More specifically, in  <span class="math">s\\tilde{\\mathsf{Del}}</span> , the delegator  <span class="math">\\tilde{\\mathsf{D}}</span> , instead of maintaining a secret state  <span class="math">\\sigma_t = (z, \\mathsf{LDE}_x(z))</span> , she stores the entire data stream  <span class="math">x^t \\in \\{0,1\\}^t</span> . Recall that in the original  <span class="math">\\mathsf{sDel}</span>  scheme, during the Compute protocol, the delegator uses her secret state  <span class="math">\\sigma_t</span>  only in the Reveal protocol. In  <span class="math">\\mathsf{s\\tilde{Del}}</span> , the Compute protocol is exactly as in  <span class="math">\\mathsf{sDel}</span> , except for the following modification to the Reveal(s) protocol.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\tilde{\\mathsf{D}}</span>  generates her message in the same way as  <span class="math">\\mathsf{D}</span> , except that  <span class="math">\\tilde{\\mathsf{D}}</span>  chooses a random twodimensional affine subspace  <span class="math">S_s \\subset \\tilde{\\mathbb{F}}^m</span>  containing s, instead of choosing a random affine space  <span class="math">S_{s,z} \\subset \\tilde{\\mathbb{F}}^m</span>  containing both s and z.</li>
      <li>To verify the polynomial  <span class="math">p_2</span>  returned by W (after decryption),  <span class="math">\\tilde{D}</span>  computes  <span class="math">LDE_x \\circ S_s</span>  on her own and checks if  <span class="math">p_2 = LDE_x \\circ S_s</span> , instead of checking its consistency with  <span class="math">LDE_x \\circ S_s</span>  on a single point.</li>
    </ul>

    <p class="text-gray-300">In other words,  <span class="math">\\tilde{D}</span>  is doubly-cautious in the Reveal protocol: First,  <span class="math">\\tilde{D}</span>  doesn't reuse the same secret point z, but rather chooses the affine subspace at random, with the only restriction that it contains s. Second, she checks whether the polynomial  <span class="math">p_2</span>  returned by W is correct, instead of only checking if  <span class="math">p_2</span>  is correct on a random point z.&lt;sup&gt;33&lt;/sup&gt; Our analysis proceeds in the following two steps.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\bullet</span>  We first show, that  <span class="math">s\\tilde{Del}</span>  has negligible one-time soundness error, which immediately implies the (reusable) soundness of  <span class="math">s\\tilde{Del}</span> , since these executions are totally independent, as  <span class="math">\\tilde{D}</span>  does not use a secret state.    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The proof is very similar to the proof of the one-time soundness of our memory delegation scheme (Lemma 32).</li>
    </ul></li>
      <li>Let G and  <span class="math">\\tilde{G}</span>  be the (reusable) security games of sDel and sDel, respectively. We shall show, that the main-leakage lemma (Lemma 22), together with a hybrid argument, implies that no poly(N)-size worker W* succeeds with noticeably higher probability in G than in  <span class="math">\\tilde{G}</span> . In other words, there is no need to be cautious!</li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-52-1&quot;&gt;&lt;/span&gt;<strong>Lemma 42</strong> The streaming delegation scheme sDel constructed in Section 9.2 is one-time sound, i.e., it has negligible one-time soundness error.</p>

    <p class="text-gray-300">The proof of this lemma is essentially the same as the proof of Lemma 32, and is omitted.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-52-0&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;33&lt;/sup&gt;Note that  <span class="math">\\tilde{D}</span>  runs in time poly(N), which is not efficient in our setting, but this is only for the sake of the analysis.</p>

    <p class="text-gray-300"><strong>Lemma 43</strong> The streaming delegation scheme sDel constructed in Section 9.2 is sound, i.e., it has negligible soundness error.</p>

    <p class="text-gray-300"><strong>Proof.</strong> Suppose for the sake of contradiction that there exists a poly(N)-size worker W* such that</p>

    <p class="text-gray-300">&lt;span id=&quot;page-53-0&quot;&gt;&lt;/span&gt;
<span class="math">$\\Pr[\\mathsf{W}^* \\text{ succeeds in } \\mathsf{G}^{\\mathsf{W}^*}(k,N)] \\ge \\varepsilon(N),</span>$
(11)</p>

    <p class="text-gray-300">for some noticeable  <span class="math">\\varepsilon(N)</span> . Lemma 42 implies that  <span class="math">\\tilde{\\mathsf{sDel}}</span>  has negligible soundness error. Namely</p>

    <p class="text-gray-300">&lt;span id=&quot;page-53-1&quot;&gt;&lt;/span&gt;
<span class="math">$\\Pr[\\mathsf{W}^* \\text{ succeeds in } \\tilde{\\mathsf{G}}^{\\mathsf{W}^*}(k, N)] \\le \\mathsf{ngl}(N). \\tag{12}</span>$</p>

    <p class="text-gray-300">From Equation (11) and (12), we derive a contradiction to Lemma 22, using the following hybrid argument. Consider the following hybrid games  <span class="math">G_t</span>  for every  <span class="math">t \\in \\{0, ..., N\\}</span> .</p>

    <p class="text-gray-300">• <strong>Hybrid Game</strong>  <span class="math">G_t</span> : The reusable security game for the streaming delegation scheme with a hybrid delegator  <span class="math">D_t</span> , who is cautious until (and including) time t, and behaves as the original delegator D after time t. More precisely, for every time  <span class="math">t&#x27; \\leq t</span> , the hybrid delegator  <span class="math">D_t</span>  stores the whole data stream  <span class="math">x_{t&#x27;}</span>  and behaves as the cautious delegator  <span class="math">\\tilde{D}</span> . At the beginning of time t+1, the hybrid delegator  <span class="math">D_t</span>  generates a secret state  <span class="math">\\sigma_{t+1} = (z, LDE_{x^{t+1}}(z))</span>  by choosing a random  <span class="math">z \\leftarrow \\tilde{\\mathbb{F}}^m</span>  and computing  <span class="math">LDE_{x^{t+1}}(z)</span> . Then, for every time  <span class="math">t&#x27; \\geq t+1</span> , the hybrid delegator  <span class="math">D_t</span>  behaves as the original delegator D.</p>

    <p class="text-gray-300">By definition, the hybrid games  <span class="math">G_0</span>  and  <span class="math">G_N</span>  are simply G and G, respectively. By a standard hybrid argument, Equations (11) and (12) imply that there exists some  <span class="math">t \\in [N]</span>  such that</p>

    <p class="text-gray-300">&lt;span id=&quot;page-53-2&quot;&gt;&lt;/span&gt;
<span class="math">$\\Pr[\\mathsf{W}^* \\text{ succeeds in } \\mathsf{G}_{t-1}^{\\mathsf{W}^*}] - \\Pr[\\mathsf{W}^* \\text{ succeeds in } \\mathsf{G}_t^{\\mathsf{W}^*}] \\ge \\varepsilon/N - \\mathsf{ngl}(N). \\tag{13}</span>$</p>

    <p class="text-gray-300">Note that the only difference between  <span class="math">G_{t-1}</span>  and  <span class="math">G_t</span>  is at time t, where  <span class="math">D_{t-1}</span>  behaves as the original delegator D, but  <span class="math">D_t</span>  is still cautious. More precisely, at time t, the two delegators behave differently in the Reveal(s) protocol (if executed), as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathsf{D}_{t-1}</span>  sends  <span class="math">(\\hat{S}_{s,z},\\mathsf{pk}) = (\\hat{X},\\hat{s},\\mathsf{pk})</span>  to  <span class="math">\\mathsf{W}^*</span> , where  <span class="math">S_{s,z}</span>  is a random 2-dimensional affine space containing s and z, and  <span class="math">X \\in \\tilde{\\mathbb{F}}^{m \\times 2}</span>  is a random representation of the two-dimensional subspace  <span class="math">S_{s,z} s \\triangleq \\{v x : v \\in S_{s,z}\\}</span> . Let  <span class="math">\\alpha_z \\in \\tilde{\\mathbb{F}}^2</span>  be such that  <span class="math">z = X \\cdot \\alpha_z + s</span> . Then  <span class="math">\\mathsf{D}_{t-1}</span>  checks that  <span class="math">p_2(\\alpha_z) = \\mathsf{LDE}_{x^t}(z)</span> , where  <span class="math">p_2</span>  is the polynomial sent by  <span class="math">\\mathsf{W}^*</span>  (after decryption).</li>
      <li><span class="math">\\mathsf{D}_t</span>  sends  <span class="math">(\\hat{S}_s, \\mathsf{pk}) = (\\hat{X}, \\hat{s}, \\mathsf{pk})</span>  to  <span class="math">\\mathsf{W}^*</span> , where  <span class="math">X \\in \\tilde{\\mathbb{F}}^{m \\times 2}</span>  is a random two-dimensional subspace, and S = X + s. Then  <span class="math">\\mathsf{D}_t</span>  checks that  <span class="math">p_2 = \\mathsf{LDE}_{x^t} \\circ S_s</span> , where  <span class="math">p_2</span>  is the polynomial sent by  <span class="math">\\mathsf{W}^*</span>  (after decryption).</li>
    </ul>

    <p class="text-gray-300">Note that  <span class="math">D_{t-1}</span>  continues to use z as her secret state after time t. Also note that in both cases,  <span class="math">X \\in \\tilde{\\mathbb{F}}^{m \\times 2}</span>  is a random representation of a random 2-dimensional linear subspace, so X is statistically close to a uniformly random m-by-2 matrix (with statistical distance  <span class="math">O(1/|\\tilde{\\mathbb{F}}|) = \\text{ngl}(N)</span> ).</p>

    <p class="text-gray-300">Looking ahead, we want to use the noticeable gap between the success probability of W* in  <span class="math">G_{t-1}</span>  and  <span class="math">G_t</span>  (in Equation (13)) to contradict Lemma 22. To this end, we construct a distinguisher  <span class="math">\\mathcal{A}</span>  that distinguishes distributions  <span class="math">(x, \\hat{X}, \\mathsf{pk}, b) \\leftarrow \\mathcal{D}_1</span>  and  <span class="math">(u, \\hat{X}, \\mathsf{pk}, b) \\leftarrow \\mathcal{D}_2</span> , where</p>

    <p class="text-gray-300">•  <span class="math">X \\leftarrow \\tilde{\\mathbb{F}}^{m \\times 2}</span>  is a random m-by-2 matrix.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>pk is a public key generated by  <span class="math">(pk, sk) \\leftarrow \\operatorname{Gen}(1^k)</span> , and  <span class="math">\\hat{X} \\leftarrow \\operatorname{Enc}_{pk}(X)</span> .</li>
      <li><span class="math">b = L(\\hat{X}, pk)</span>  is a leakage bit, where  <span class="math">L : \\{0, 1\\}^* \\to \\{0, 1\\}</span>  is a leakage function, to be specified later.</li>
      <li><span class="math">x \\leftarrow X</span>  and  <span class="math">u \\leftarrow \\tilde{\\mathbb{F}}^m</span> .</li>
    </ul>

    <p class="text-gray-300">To this end, the distinguisher  <span class="math">\\mathcal{A}</span> , upon receiving  <span class="math">(w, \\hat{X}, \\mathsf{pk}, b)</span> , distributed according to  <span class="math">\\mathcal{D}_1</span>  or  <span class="math">\\mathcal{D}_2</span> , tries to simulate the game  <span class="math">\\mathsf{G}_{t-1}</span>  or  <span class="math">\\mathsf{G}_t</span> , respectively, by embedding the received distribution  <span class="math">(w, \\hat{X}, \\mathsf{pk}, b)</span>  in the game. At a high level, we let  <span class="math">\\mathcal{A}</span>  embed the distribution in the Reveal protocol at time t (if executed), where  <span class="math">(\\hat{X}, \\mathsf{pk})</span>  is (part of) the delegator's message, and b is the decision bit indicating whether the delegator accepts or rejects in the Reveal protocol. However, note that (the original)  <span class="math">\\mathsf{D}</span>  and (the cautious)  <span class="math">\\tilde{\\mathsf{D}}</span>  decide whether to accept in the Reveal protocol in a different way, and in particular,  <span class="math">\\mathsf{D}</span> 's decision depends on the secret point z.</p>

    <p class="text-gray-300">Therefore, in addition to  <span class="math">G_{t-1}</span>  and  <span class="math">G_t</span> , we consider an intermediate hybrid game  <span class="math">G^*</span> , which is a hybrid of  <span class="math">G_{t-1}</span>  and  <span class="math">G_t</span> : It is the same as  <span class="math">G_{t-1}</span>  and  <span class="math">G_t</span>  except in the t'th protocol, where the delegator  <span class="math">D^*</span>  sends the same message as  <span class="math">D_{t-1}</span>  (which is less cautious since she uses z), but decide whether to accept in the same way as  <span class="math">D_t</span>  (which is cautious). Namely,</p>

    <p class="text-gray-300">• D* sends  <span class="math">(\\hat{S}_{s,z}, pk) = (\\hat{X}, \\hat{s}, pk)</span>  to W*, where  <span class="math">S_{s,z}</span>  is a random 2-dimensional affine space containing s and z, and  <span class="math">X \\in \\tilde{\\mathbb{F}}^{m \\times 2}</span>  is a random representation of  <span class="math">S_{s,z} - s</span> . Then D* checks the polynomial  <span class="math">p_2</span>  returned by W* (after decryption) by checking whether  <span class="math">p_2 = \\text{LDE}_{x^t} \\circ S_{s,z}</span> .</p>

    <p class="text-gray-300">Note that both  <span class="math">D_{t-1}</span>  and  <span class="math">D^*</span>  continue to use z in their secret state after time t.</p>

    <p class="text-gray-300">We first argue that the hybrid games  <span class="math">G_{t-1}</span>  and  <span class="math">G^*</span>  are statistically close. Recall that the only difference between them is in the Reveal(s) protocol at time t, where  <span class="math">D_{t-1}</span>  (resp.,  <span class="math">D^*</span> ) checks the polynomial  <span class="math">p_2</span>  sent by  <span class="math">W^*</span>  (after decryption) by checking whether  <span class="math">p_2(\\alpha_z) = \\mathrm{LDE}_{x^t}(z)</span>  (resp.,  <span class="math">p_2 = \\mathrm{LDE}_{x^t} \\circ S_{s,z}</span> ). Note that  <span class="math">D_{t-1}</span>  and  <span class="math">D^*</span> , being cautious before time t, use the (random) point z for the very first time at time t, so we can think of z as being generated from  <span class="math">z \\leftarrow S_{s,z}</span>  after they send the message  <span class="math">(\\hat{S}_{s,z}, \\mathsf{pk})</span> .&lt;sup&gt;34&lt;/sup&gt; It follows by the Schwartz-Zipple lemma that</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} &amp; \\text{Pr} \\big[ \\text{ D}_{t-1} \\text{ and D}^* \\text{ make a different decision } \\big] \\\\ &amp; \\leq &amp; \\text{Pr} \\big[ (p_2 \\neq \\text{LDE}_{x^t} \\circ S_{s,z}) \\wedge (p_2(\\alpha_z) = \\text{LDE}_{x^t}(z)) \\big] \\\\ &amp; \\leq &amp; O(d/|\\tilde{\\mathbb{F}}|) \\leq \\mathsf{ngl}(N), \\end{split}</span>$</p>

    <p class="text-gray-300">where d = polylog(N) is the total degree of  <span class="math">\\text{LDE}_{x^t}</span> . Since this is the only difference between  <span class="math">\\mathsf{G}_{t-1}</span>  and  <span class="math">\\mathsf{G}^*</span> , the statistical distance of the two hybrid is  <span class="math">\\mathsf{ngl}(N)</span> .</p>

    <p class="text-gray-300">Now, since  <span class="math">G_{t-1}</span>  and  <span class="math">G^*</span>  are statistically close, Equation (13) implies</p>

    <p class="text-gray-300">&lt;span id=&quot;page-54-1&quot;&gt;&lt;/span&gt;
<span class="math">$\\Pr[\\mathsf{W}^* \\text{ succeeds in } (\\mathsf{G}^*)^{\\mathsf{W}^*}] - \\Pr[\\mathsf{W}^* \\text{ succeeds in } \\mathsf{G}_t^{\\mathsf{W}^*}] \\ge (\\varepsilon/N) - \\mathsf{ngl}. \\tag{14}</span>$</p>

    <p class="text-gray-300">This time, we are able to use the noticeable gap between the success probability of  <span class="math">W^*</span>  in  <span class="math">G^*</span>  and  <span class="math">G_t</span>  in Equation (14), to contradict Lemma 22.</p>

    <p class="text-gray-300">Let us take a close look at the difference between  <span class="math">G^*</span>  and  <span class="math">G_t</span> . Again, the only difference is in the Reveal(s) protocol at time t, where  <span class="math">D^*</span>  (resp.,  <span class="math">D_t</span> ) sends  <span class="math">(\\hat{S}_{s,z}, pk)</span>  (resp.,  <span class="math">(\\hat{S}_s, pk)</span> ) to  <span class="math">W^*</span> . Note,</p>

    <p class="text-gray-300">&lt;span id=&quot;page-54-0&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;34&lt;/sup&gt;More precisely, first choosing a random  <span class="math">z \\leftarrow \\tilde{\\mathbb{F}}^m</span>  and then choosing a random  <span class="math">S_{s,z}</span>  containing z (and s) is equivalent to first choosing a random S containing s, and then choosing  <span class="math">z \\leftarrow S</span> .</p>

    <p class="text-gray-300">however, that the distribution of both  <span class="math">S_{s,z}</span>  and  <span class="math">S_s</span>  are actually the same, both being a random 2-dimensional affine space containing s. The real difference is that, after time t,  <span class="math">\\tilde{\\mathsf{D}}_{t-1}</span>  (resp.,  <span class="math">\\mathsf{D}_t</span> ) uses  <span class="math">z \\leftarrow S_{s,z}</span>  (resp.,  <span class="math">z \\leftarrow \\tilde{\\mathbb{F}}^m</span> ), in her secret state. Noting that this is exactly the difference between  <span class="math">(z, \\hat{X}, \\mathsf{pk}, b) \\leftarrow \\mathcal{D}_1</span>  and  <span class="math">(u, \\hat{X}, \\mathsf{pk}, b) \\leftarrow \\mathcal{D}_2</span> , we are ready to define the distinguisher  <span class="math">\\mathcal{A}</span> , as follows, from which the choice of leakage bit  <span class="math">b = L(\\hat{X}, \\mathsf{pk})</span>  would become clear.</p>

    <p class="text-gray-300">On input  <span class="math">(w, \\hat{X}, pk, b)</span> , distributed either according to  <span class="math">\\mathcal{D}_1</span>  or according to  <span class="math">\\mathcal{D}_2</span> , the distinguisher  <span class="math">\\mathcal{A}</span>  does the following.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Simulate the interaction between W* and  <span class="math">\\tilde{D}</span>  until the end of time t-1.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>At time t, if there is a Compute execution, then simulate the Compute operation as follows.</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Simulate for both parties all (sub-)protocols except the Reveal(s) protocol. This includes choosing  <span class="math">s \\in \\tilde{\\mathbb{F}}^m</span> .</li>
      <li>For the Reveal(s) protocol, simulate the delegator's message by  <span class="math">(\\hat{X}, \\hat{s}, pk)</span> , where  <span class="math">(\\hat{X}, pk)</span>  is part of its input, and  <span class="math">\\hat{s} \\leftarrow \\operatorname{Enc}_{pk}(s)</span> . Then simulate W*'s message. Finally, use the bit b (which is part of  <span class="math">\\mathcal{A}</span> 's input) as the decision bit of the delegator. (Note that  <span class="math">\\mathcal{A}</span>  does not have a secret key sk and cannot compute the delegator's decision bit efficiently.)</li>
    </ul></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Compute  <span class="math">\\sigma_t = (w + s, \\text{LDE}_{x^t}(w + s))</span>  and continue to simulate the interaction between W* and D after time t using  <span class="math">\\sigma_t</span>  as D's secret state.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Output 1 if and only if W* ever cheats successfully during the interaction.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">We define the leakage function  <span class="math">L(\\hat{X}, \\mathsf{pk})</span>  to be the decision of  <span class="math">\\mathsf{D}^*</span>  and  <span class="math">\\mathsf{D}_t</span>  in the Reveal(s) protocol at time t, if executed, and 0 otherwise. More precisely, let S = X + s;  <span class="math">L(\\hat{X}, \\mathsf{pk}) = 1</span>  if and only if  <span class="math">p_2 = \\mathsf{LDE}_{x^t} \\circ S</span> . Note that L is a randomized function, which uses its randomness to simulate the game until the end of time t, and determine the decision of the delegator in the Reveal(s) protocol. Also note that the secret key  <span class="math">\\mathsf{sk}</span>  is missing from  <span class="math">(\\hat{X}, \\mathsf{pk}, r)</span> , so L cannot be computed in  <span class="math">\\mathsf{poly}(N)</span>  time</p>

    <p class="text-gray-300">Note that when  <span class="math">(z, \\hat{X}, \\mathsf{pk}, b) \\leftarrow \\mathcal{D}_1</span> , the distinguisher  <span class="math">\\mathcal{A}</span>  perfectly simulates  <span class="math">\\mathsf{G}^*</span> , and when  <span class="math">(u, \\hat{X}, \\mathsf{pk}, b) \\leftarrow \\mathcal{D}_2</span> , the distinguisher A perfectly simulates  <span class="math">\\mathsf{G}_t</span> . Therefore, Equation (14) implies</p>

    <p class="text-gray-300"><span class="math">$\\Pr[\\mathcal{A}(z,\\hat{X},\\mathsf{pk},b)=1] - \\Pr[\\mathcal{A}(u,\\hat{X},\\mathsf{pk},b)=1] \\geq \\varepsilon/N - \\mathsf{ngl}(N),</span>$</p>

    <p class="text-gray-300">contradicting Lemma 22. This completes the proof.</p>

    <h2 id="sec-34" class="text-2xl font-bold">10 Interactive Delegation of Any (Efficient) Computation</h2>

    <p class="text-gray-300">In this section, we construct memory and streaming delegation schemes based on universal arguments of Barak and Goldreich [BG02]. This allows the delegator to delegate computation for all of  <span class="math">\\mathbf{P}</span>  rather than  <span class="math">\\mathbf{NC}</span> , at the price that the  <span class="math">\\mathsf{Compute}(f)</span>  protocol becomes interactive with 4 message exchanges.</p>

    <p class="text-gray-300">Recall that when we constructed our memory and streaming delegation schemes in Sections 7 and 9, the key property we need from the GKR protocol is that the verifier does not need to read the entire input, but rather only needs to access a few random points in the low-degree extension of the input. The main observation is that, the same property also holds for universal</p>

    <p class="text-gray-300">arguments, when the underlying PCP is substituted by an efficient PCP of Proximity (PCPP), a notion introduced by Ben-Sasson, Goldreich, Harsha, Sudan, and Vadhan <a href="#page-65-1">[BSGH</a>+05] and Dinur and Reingold <a href="#page-65-2">[DR06]</a>. (We remark that this observation has been made independently by Cormode, Thaler, and Yi <a href="#page-65-9">[CTY10]</a> in the context of &quot;streaming interactive proofs.&quot;) Therefore, we can use universal arguments with PCPP to construct memory and streaming delegation schemes for any (efficient) computation. In fact, the construction becomes simpler. Moreover, for memory delegation, we can avoid the use of poly-log PIR schemes, and only require the existence of collisionresistant hash functions.</p>

    <p class="text-gray-300">Formally, we obtain the following theorems. For the sake of simplicity, we state the theorems for delegating computation of polynomial time Turing machines. The theorems extend readily to non-uniform Turing machines, where the running time of the delegator and the worker in both the offline and the online stage depends polynomially on the length of the non-uniform advice.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-56-0&quot;&gt;&lt;/span&gt;Theorem 44 (Interactive Memory Delegation) Let k be a security parameter, and let F be the class of all functions computable by polynomial time Turning machines. Assume the existence of collision-resistance hash functions. Then there exists a memory delegation scheme sDel&lt;sup&gt;F&lt;/sup&gt; for F with the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The scheme has perfect completeness and negligible (reusable) soundness error.</li>
      <li>The delegator and worker are efficient in the offline stage; i.e., both the delegator and the worker run in time poly(k, n), where n is the size of the memory.</li>
      <li>The worker is efficient in the online stage. More specifically, it runs in time poly(k, T(n)) during each Compute(f) and Update(f) operation, where T(n) is a time bound of the delegation function f on inputs of length n. The delegator runs in time poly(k, log T) during each Compute(f) and Update(f) operation.</li>
      <li>Both Compute(f) and Update(f) consist of 4 message exchanges.</li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-56-1&quot;&gt;&lt;/span&gt;Theorem 45 (Interactive Streaming Delegation) Let k be a security parameter, and let N be a parameter bounding the maximum length of the stream. Let F be the class of all functions computable by polynomial time Turning machines. Assume the existence of a fully-homomorphic encryption scheme secure against poly(N)-size adversaries. Then there exists a streaming delegation scheme sDel&lt;sup&gt;F&lt;/sup&gt; for F with the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>sDel&lt;sup&gt;F&lt;/sup&gt; has perfect completeness and negligible (reusable) soundness error.</li>
      <li>D updates her secret state in time polylog(N), per data item.</li>
      <li>In the delegation protocol, when delegating a function f ∈ F computable in time T(n), the delegator D runs in time poly(k, log N, log T), and the worker W runs in time poly(k, log N, T(n)), where n is the length of the stream.</li>
      <li>The delegation protocol Compute(f) consists of 4 message exchanges.</li>
    </ul>

    <p class="text-gray-300">In Section <a href="#page-57-0">10.1,</a> we present some necessary preliminaries, where we briefly review how to construct a (standard) delegation scheme using universal arguments and define PCP of Proximity. We then present a (standard) delegation scheme with the key property we need in Section <a href="#page-59-0">10.2.</a> Finally, we construct the memory and streaming delegation schemes described in Theorem <a href="#page-56-0">44</a> and <a href="#page-56-1">45</a> in Sections <a href="#page-61-0">10.3</a> and <a href="#page-62-0">10.4,</a> respectively.</p>

    <h2 id="sec-35" class="text-2xl font-bold">&lt;span id=&quot;page-57-0&quot;&gt;&lt;/span&gt;10.1 Preliminaries</h2>

    <h3 id="sec-36" class="text-xl font-semibold mt-8">&lt;span id=&quot;page-57-3&quot;&gt;&lt;/span&gt;10.1.1 Universal Arguments</h3>

    <p class="text-gray-300">In this section, we briefly review how to delegate computation using universal arguments <a href="#page-64-1">[BG02]</a>, as presented implicitly in <a href="#page-65-8">[CKV10,</a> Section 9].</p>

    <p class="text-gray-300">Let k be the security parameter. To delegate the computation of a uniform function f (specified by a Turing machine M with a time bound T) on input x ∈ {0, 1} n , <a href="#page-57-1">35</a> the delegator D sends f, x to the worker W, who returns the answer y = f(x) to D. Then they engage in a universal argument, where W proves to D that indeed y = f(x). More specifically, W proves to D that (M, x, y, T) is in the following language L uni .</p>

    <p class="text-gray-300"><span class="math">$L^{\\text{uni}} \\triangleq \\{(M, x, y, T) : M \\text{ is a Turing machine s.t. } M(x) \\text{ outputs } y \\text{ in } \\leq T \\text{ steps}\\}.</span>$</p>

    <p class="text-gray-300">In more detail, in the universal argument, the prover commits to a PCP proof π using a tree commitment Th(π) with the hash function h ← H chosen by the verifier. Then the verifier plays the role of a PCP verifier, with the prover answering her PCP queries by revealing the corresponding bits π&lt;sup&gt;i&lt;/sup&gt; 's in the commitment Th(π).</p>

    <p class="text-gray-300">The universal argument consists of 4 message exchanges, so the delegation protocol as described above requires 6 message exchanges. However, as argued in <a href="#page-65-8">[CKV10]</a>, the first two message exchanges can be parallelized with the first two messages of the universal argument, which yields a 4-message delegation protocol.</p>

    <p class="text-gray-300">Clearly, the complexity of the delegation scheme depends on the complexity of the universal argument, which depends on the underlying PCPs. We note that the delegator needs to run in time Ω(n) since the verification of the underlying PCP proof π using standard PCPs (as opposed to PCPs of proximity) depends on the whole input (M, x, y, T).</p>

    <p class="text-gray-300">In the following theorem, we state the delegation scheme obtained by using the universal argument of <a href="#page-64-1">[BG02]</a>.</p>

    <p class="text-gray-300">Theorem 46 (<a href="#page-64-1">[BG02]</a>) <a href="#page-57-2">36</a> Let k be the security parameter. Let n denote the input length, and let T be a time bound such that T ≥ n ≥ k. Let F be the family of boolean functions computable by time T Turing machines. Assume the existence of collision resistant hash functions secure against poly(T)-time adversaries. Then, there exists a delegation protocol for F with the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The protocol has perfect completeness and negligible soundness error.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The worker runs in time poly(T), and the delegator runs in time poly(n, log T).</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The protocol consists of four messages, with communication complexity poly(k, log T). Moreover, the protocol is public-coin.</li>
    </ol></li>
    </ul>

    <h4 id="sec-37" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-57-4&quot;&gt;&lt;/span&gt;10.1.2 PCPs of Proximity</h4>

    <p class="text-gray-300">In this section, we present necessary preliminaries on PCPs of proximity and state the PCPP theorem of <a href="#page-65-1">[BSGH</a>+05].</p>

    <p class="text-gray-300">&lt;span id=&quot;page-57-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;35&lt;/sup&gt;Assume that T ≥ n.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-57-2&quot;&gt;&lt;/span&gt;&lt;sup&gt;36&lt;/sup&gt;The theorem statement slightly differs from the one given in <a href="#page-64-1">[BG02]</a> and is tailored to our application.</p>

    <p class="text-gray-300"><strong>Definition 47 (Pair-language)</strong> A pair-language L is simply a subset of the set of string pairs  <span class="math">L \\subseteq \\{0,1\\}^* \\times \\{0,1\\}^*</span> . For every  <span class="math">a \\in \\{0,1\\}^*</span> , we denote  <span class="math">L_a = \\{b \\in \\{0,1\\}^* : (a,b) \\in L\\}</span> . We usually denote  <span class="math">\\ell = |a|</span>  and K = |b|.</p>

    <p class="text-gray-300">The reader can think of a as a Turing machine M, and b as an input encoding, and  <span class="math">(a,b) \\in L</span>  iff M accepts the input encoded by b within some time bound.</p>

    <p class="text-gray-300"><strong>Definition 48</strong> (PCPP verifier [BSGH&lt;sup&gt;+&lt;/sup&gt;05]) Let  <span class="math">r, q : \\mathbb{N} \\to \\mathbb{N}</span>  and  <span class="math">t : \\mathbb{N} \\times \\mathbb{N} \\to \\mathbb{N}</span> . An (r, q, t)-PCPP verifier V is a probabilistic oracle machine with the following structure.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>V receives as input a string  <span class="math">a \\in \\{0,1\\}^*</span>  and a number  <span class="math">K \\in \\mathbb{N}</span>  (in binary), and has oracle access to two strings  <span class="math">b \\in \\{0,1\\}^K</span> , and  <span class="math">\\pi \\in \\{0,1\\}^*</span> .</li>
      <li>V uses at most r(|a|+K) coins, makes at most q(|a|+K) non-adaptive queries to the two oracles (in total), runs in at most t(|a|,K) time, and outputs a verdict bit, indicating her acceptance/rejection.</li>
    </ul>

    <p class="text-gray-300">The parameters r, q, t are the randomness, query, and time complexity of V, respectively.</p>

    <p class="text-gray-300">The reader can think of r, q, t as being sub-linear.</p>

    <p class="text-gray-300"><strong>Definition 49</strong> (PCPP for Pair-language [BSGH+05]) Let  <span class="math">r, q : \\mathbb{N} \\to \\mathbb{N}</span> ,  <span class="math">t : \\mathbb{N} \\times \\mathbb{N} \\to \\mathbb{N}</span> , and  <span class="math">\\varepsilon, \\delta : \\mathbb{N} \\to [0,1]</span> . A pair-language  <span class="math">L \\subseteq \\{0,1\\}^* \\times \\{0,1\\}^*</span>  is in PCPP&lt;sub&gt; <span class="math">\\varepsilon,\\delta</span> &lt;/sub&gt;[r,q,t] if there exists an (r,q,t)-PCPP verifier V with the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(Completeness) If  <span class="math">(a,b) \\in L</span> , then there exists a PCPP proof  <span class="math">\\pi \\in \\{0,1\\}^*</span>  such that  <span class="math">V^{b,\\pi}(a,|b|)</span>  accepts with probability 1.</li>
      <li>(Soundness) If (a, b) is such that b is  <span class="math">\\delta(|a| + |b|)</span> -far from  <span class="math">L_a \\cap \\{0, 1\\}^{|b|}</span> , 37 then for every  <span class="math">\\pi \\in \\{0, 1\\}^*</span> , it holds that</li>
    </ul>

    <p class="text-gray-300"><span class="math">$\\Pr[V^{b,\\pi}(a,|b|)=1] \\le \\varepsilon.</span>$</p>

    <p class="text-gray-300">The parameter  <span class="math">\\delta</span>  is called the proximity parameter.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-58-2&quot;&gt;&lt;/span&gt;Theorem 50 (Efficient PCPP for Pair-language (Theorem 2.5 of [BSGH&lt;sup&gt;+&lt;/sup&gt;05])) Let  <span class="math">T : \\mathbb{N} \\to \\mathbb{N}</span>  be a non-decreasing function, and let  <span class="math">L = \\{(a,b)\\}</span>  be a pair-language. If L can be decided in time T, trule 38, then trule 48 with</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>proximity parameter  <span class="math">\\delta = 1/\\text{polylog}(T)</span> ,</li>
      <li>randomness complexity  <span class="math">r = \\log_2 T + O(\\log \\log T)</span> ,</li>
      <li>query complexity q = polylog(T), and</li>
      <li>verification time complexity  <span class="math">t(\\ell, K) = \\text{poly}(\\ell, \\log K, \\log T)</span> , where  <span class="math">\\ell \\triangleq |a|, K \\triangleq |b|</span> , and  <span class="math">T = T(\\ell + K)</span> .</li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-58-0&quot;&gt;&lt;/span&gt;&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;37&lt;/sup&gt;A string b is  <span class="math">\\delta</span> -far from a set  <span class="math">S \\subset \\{0,1\\}^{|b|}</span>  if for every  <span class="math">b&#x27; \\in S</span> , the relative Hamming distance  <span class="math">\\Delta(b,b&#x27;) \\geq \\delta</span> , where the relative Hamming distance is defined by  <span class="math">\\Delta(b,b&#x27;) \\triangleq |\\{i:b_i \\neq b_i&#x27;\\}|/|b|</span> .</p>

    <p class="text-gray-300">&lt;span id=&quot;page-58-1&quot;&gt;&lt;/span&gt; <span class="math">&lt;sup&gt;^{38}&lt;/sup&gt;L</span>  can be decided in time T if there exists a Turing machine M such that for every input  <span class="math">(a,b) \\in \\{0,1\\}^* \\times \\{0,1\\}^*</span> , M(a,b) = 1 iff  <span class="math">(a,b) \\in L</span> , and M(a,b) runs in time T(|a| + |b|).</p>

    <p class="text-gray-300">Furthermore, the PCPP proof  <span class="math">\\pi</span>  for inputs in L (that makes V accepts) can be computed in time poly(T), and has length at most  <span class="math">q \\cdot 2^r = T \\cdot \\text{polylog}(T)</span> .</p>

    <p class="text-gray-300">We mention that the result of [BSGH&lt;sup&gt;+&lt;/sup&gt;05] holds for languages decidable in non-deterministic time T, but we are only interested in deterministic languages for the purpose of delegating computations. We also mention that [BSGH&lt;sup&gt;+&lt;/sup&gt;05] does not discuss the complexity of constructing the PCPP proof, but the efficiency follows by a close inspection of their construction [Vad10].</p>

    <p class="text-gray-300">We note that the soundness error 1/2 can be reduced to  <span class="math">1/2^u</span>  by running V with independent coins u times. This blows up the randomness, query, and time complexity of V by a (multiplicative) factor of u (but does not increase the proof length).</p>

    <h4 id="sec-38" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-59-0&quot;&gt;&lt;/span&gt;10.2 Delegation Scheme using Universal Arguments with PCPP</h4>

    <p class="text-gray-300">In this section, we present a 4-message (standard) delegation scheme for any (efficient) computation, that possesses the same key property we need from the GKR protocol for memory and streaming delegation. Namely, the delegation protocol can be verified very efficiently (in sub-linear time in the input size), if the delegator has oracle access to the low-degree extension of the input x.</p>

    <p class="text-gray-300">The starting point is the 4-message delegation scheme using universal argument [BG02] presented in Section 10.1.1. Recall that the delegator runs in time  <span class="math">\\Omega(n)</span>  since the verification of the underlying PCP proof  <span class="math">\\pi</span>  depends on the whole input (M, x, y, T). To make the delegator run in sub-linear time in n, we substitute the underlying PCP for the language  <span class="math">L^{\\text{uni}}</span>  by the efficient PCPP of [BSGH&lt;sup&gt;+&lt;/sup&gt;05] from Theorem 50 for the following pair-language.</p>

    <p class="text-gray-300"><span class="math">L^{\\mathrm{uni-pair}} \\triangleq \\{((M, y, T), \\mathrm{LDE}_x^{\\mathbb{F}, \\mathbb{H}, m}) : M \\text{ is a Turing machine s.t. } M(x) \\text{ outputs } y \\text{ in } \\leq T \\text{ steps}\\},</span> where the low-degree extension  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F}, \\mathbb{H}, m}</span>  is a Reed-Muller code of  <span class="math">x \\in \\{0, 1\\}^n</span>  with</p>

    <p class="text-gray-300"><span class="math">$|\\mathbb{H}| = \\log n, \\ m = \\theta\\left(\\frac{\\log n}{\\log\\log n}\\right), \\ |\\mathbb{F}| = \\log^2 n.</span>$</p>

    <p class="text-gray-300">Since in Section 10.1.2, a language L is always defined to contain bit strings, we think of the codeword  <span class="math">\\text{LDE}_x^{\\mathbb{F},\\mathbb{H},m}</span>  as a bit string, parsing every field element in  <span class="math">\\mathbb{F}</span>  as  <span class="math">\\log |\\mathbb{F}|</span>  bits. Thus, the length of the codeword is  <span class="math">|\\mathbb{F}|^m \\cdot \\log |\\mathbb{F}| = \\tilde{O}(n^2)</span> . The parameters  <span class="math">\\mathbb{H}, \\mathbb{F}, m</span>  are chosen so that the codewords have sufficient relative Hamming distance to each other, for establishing the soundness property (we discuss this later).</p>

    <p class="text-gray-300">Note that there exists a Turing machine  <span class="math">\\mathcal{M}</span>  that on input  <span class="math">((M, y, T), \\tilde{x})</span> , decides whether  <span class="math">((M, y, T), \\tilde{x}) \\in L^{\\mathrm{uni-pair}}</span>  in time  <span class="math">\\mathrm{poly}(n, T)</span>  as follows: check if  <span class="math">\\tilde{x}</span>  is a valid codeword (i.e.,  <span class="math">\\tilde{x} = \\mathrm{LDE}_x</span>  for some x), decode  <span class="math">\\tilde{x}</span>  to obtain x, simulate M(x) for T steps, and check if M outputs y. Hence, Theorem 50 implies the existence of a PCPP system  <span class="math">\\Pi_{pcpp}</span>  for  <span class="math">L^{\\mathrm{uni-pair}}</span>  such that on instance  <span class="math">((M, y, T), \\mathrm{LDE}_x)</span> , the PCPP verifier  <span class="math">V^{LDE_x, \\pi}(M, y, T; |\\mathrm{LDE}_x|)</span>  runs in time  <span class="math">\\mathrm{polylog}(T)</span> .</p>

    <p class="text-gray-300">Therefore, when the underlying PCP of the delegation scheme in Section 10.1.1 is replaced by this PCPP system  <span class="math">\\Pi_{pcpp}</span> ,&lt;sup&gt;39&lt;/sup&gt; and when the delegator D is given oracle access to the low-degree extension LDE&lt;sub&gt;x&lt;/sub&gt; of x, D runs in time poly(k, log T), and makes at most polylog(T) queries to the oracle LDE&lt;sub&gt;x&lt;/sub&gt;. Furthermore, the queries to LDE&lt;sub&gt;x&lt;/sub&gt; depend only on D's coin tosses. On the other hand, the worker W runs in time poly(k, T), since the PCPP proof  <span class="math">\\pi</span>  can be computed in time poly(T). For the sake of completeness, a formal description of the modified protocol can be found in Figure 8.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-59-1&quot;&gt;&lt;/span&gt;&lt;sup&gt;39&lt;/sup&gt;Namely, to prove f(x) = y, instead of proving  <span class="math">(M, x, y, T) \\in L^{\\text{uni}}</span>  using PCP, the worker W proves to D that  <span class="math">((M, y, T), \\text{LDE}_x) \\in L^{\\text{uni-pair}}</span>  using universal argument with PCPPs.</p>

    <p class="text-gray-300">Del = hD, Wi:</p>

    <p class="text-gray-300">D delegates the computation of a uniform function f, specified by a Turing machine M and a time bound T, on input x ∈ {0, 1} n to W.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D has (M, T) and x as the input.</li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D sends (M, T) and x to W.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>W computes and sends y = M(x) to D.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>W and D engage in a universal argument with PCPP, where W proves to D that ((M, y, T), LDEx) ∈ L uni−pair .</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D sends a collision-resistant hash function h ← H to W.</li>
      <li>W computes a PCPP proof π of the statement ((M, y, T),Enc(x)) ∈ L uni−pair, and sends the tree commitment Th(π) to D.</li>
      <li>D runs the PCPP verifier V to generate a PCPP query q and sends it to W.</li>
      <li>W reveals the bits π&lt;sup&gt;i&lt;/sup&gt; 's queried by q from the commitment Th(π) to D.</li>
      <li>D checks if π&lt;sup&gt;i&lt;/sup&gt; 's are revealed validly, and runs the PCPP verifier V LDEx,π(M, y, T; |LDEx|).</li>
    </ul></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>D accepts y = f(x) if D accepts in the universal argument.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-60-0&quot;&gt;&lt;/span&gt;Figure 8: A (standard) delegation protocol Del for any (efficient) computation.</p>

    <p class="text-gray-300">We briefly check the completeness and soundness of Del. The completeness follows by the completeness of the PCPP. For the soundness, note that to convince the delegator D of an incorrect answer y 6= f(x), an adversarial worker W&lt;sup&gt;∗&lt;/sup&gt; needs to make D accept ((M, y, T), LDEx) ∈/ L uni−pair in the universal argument. Note that by the choice of parameters F, H, m and Schwartz-Zippel Lemma, the relative Hamming distance between any two codewords LDEx, LDEx&lt;sup&gt;0&lt;/sup&gt; is at least</p>

    <p class="text-gray-300"><span class="math">$\\frac{\\mathbb{F} - m \\cdot |\\mathbb{H}|}{|\\mathbb{F}|} \\cdot \\frac{1}{\\log |\\mathbb{F}|} = \\Omega\\left(\\frac{1}{\\log \\log n}\\right) \\geq \\frac{1}{\\operatorname{polylog}(T)}.</span>$</p>

    <p class="text-gray-300">Hence, the soundness property of the PCPP implies that for every ((M, y, T), LDEx) ∈/ L uni−pair and for every π ∈ {0, 1} ∗ ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr[V^{\\mathrm{LDE}_x,\\pi}(M,y,T;|\\mathrm{LDE}_x|)=1] \\le 1/2.</span>$</p>

    <p class="text-gray-300">Since the soundness of the universal argument follows by the security of collision-resistance hash functions and the soundness of the underlying PCP / PCPP, the delegator D would accept y 6= f(x) with probability at most 1/2 + ngl. Namely, the delegation protocol has soundness error 1/2 + ngl. The soundness error can be reduced to negligible if the soundness of the underlying PCPP is negligible, which as mentioned, can be achieved by repeating the PCPP verifier with fresh randomness u times for some u satisfying 1/2 &lt;sup&gt;u&lt;/sup&gt; ≤ ngl.</p>

    <p class="text-gray-300">As in Section <a href="#page-57-3">10.1.1,</a> the protocol Del, as defined in Figure <a href="#page-60-0">8,</a> consists of 6 message exchanges. However, note that the first message of D in the universal argument does not depend on the statement ((M, y, T), LDEx), and hence the worker's first message can be delayed to be sent together with the first prover's message of the universal argument, which yields a 4-message delegation protocol.</p>

    <p class="text-gray-300">We summarize the properties of Del in the following theorem.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-61-1&quot;&gt;&lt;/span&gt;Theorem 51 (Interactive Delegation Scheme for Any (Efficient) Computation) Let k be the security parameter. Let n denote the input length, and let T be a time bound such that T ≥ n ≥ k. Let F be the family of boolean functions computable by time T Turing machines. Assume the existence of collision resistant hash functions secure against poly(T)-time adversaries. Then, there exists a delegation protocol for F with the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The protocol has perfect completeness and negligible soundness error.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The worker runs in time poly(T), and the delegator runs in time poly(n, log T).</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The protocol consists of four messages, with communication complexity poly(k, log T). Moreover, the protocol is public-coin.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>If the delegator is given oracle access to the low-degree extension of x, rather than being given the input x itself, and if the worker is given x as an input, then she runs in time poly(k, log T), and the protocol still has all the properties described above, for the following choice of parameters H, F, m of the low-degree extension.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300"><span class="math">$|\\mathbb{H}| = \\log n, \\ m = \\theta\\left(\\frac{\\log n}{\\log \\log n}\\right), \\ |\\mathbb{F}| = \\log^2 n.</span>$</p>

    <p class="text-gray-300">Moreover, the delegator queries the low-degree extension of x at polylog(T) points, depending only on her coin tosses.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-61-2&quot;&gt;&lt;/span&gt;Remark 52 We remark that the parameters F, H, m are chosen so that LDE&lt;sup&gt;x&lt;/sup&gt; is a Reed-Muller code with good rate and minimum distance. Let N &gt; n be a parameter. We can also set F, H, m by</p>

    <p class="text-gray-300"><span class="math">$|\\mathbb{H}| = \\log N, \\ m = \\left\\lceil \\frac{\\log n}{\\log \\log N} \\right\\rceil, \\ |\\mathbb{F}| = \\log^2 N,</span>$</p>

    <p class="text-gray-300">Then LDE&lt;sup&gt;x&lt;/sup&gt; has length at most poly(n, log N) and (relative) minimum distance at least Ω(1/ log log N). One can verify that the delegation scheme in Figure <a href="#page-60-0">8</a> is also sound with this setting of parameters (provided that T ≥ log N, which can be assumed without loss of generality by padding dummy steps), and the runtime of the delegator and the work are poly(k, log N, log T) and poly(k, log N, T), respectively. This will be useful for our streaming delegation scheme presented in Section <a href="#page-62-0">10.4.</a></p>

    <h2 id="sec-39" class="text-2xl font-bold">&lt;span id=&quot;page-61-0&quot;&gt;&lt;/span&gt;10.3 Memory Delegation Scheme Based on Theorem <a href="#page-61-1">51</a></h2>

    <p class="text-gray-300">In this section, we outline how to construct the memory delegation scheme (Theorem <a href="#page-56-0">44)</a> using the above delegation scheme (Theorem <a href="#page-61-1">51)</a>. Let x ∈ {0, 1} &lt;sup&gt;n&lt;/sup&gt; be the memory being delegated. We observe that the delegator in Theorem <a href="#page-61-1">51</a> is efficient (poly(k, log T)) if she is given the oracle access to the low-degree extension of x with respect to some parameters |F| = log&lt;sup&gt;2&lt;/sup&gt; n, |H| = log n, and m = θ(log n/ log log n). Thus, we can use similar techniques to the once in Section <a href="#page-31-0">7.2</a> where the delegator can verify points on the low-degree extension oracle using a tree commitment.</p>

    <h4 id="sec-40" class="text-lg font-semibold mt-6">The Construction.</h4>

    <p class="text-gray-300">• Offline Phase. The delegator chooses parameters  <span class="math">\\mathbb{F}, \\mathbb{H}, m</span>  with  <span class="math">|\\mathbb{F}| = \\log^2 n</span> ,  <span class="math">|\\mathbb{H}| = \\log n</span> , and  <span class="math">m = \\theta(\\log n / \\log \\log n)</span> , and a random function h from a collision resistant hash family  <span class="math">\\mathcal{H}</span> . Then the delegator computes the root of the Merkle tree of  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}</span> , namely  <span class="math">\\sigma = T_h(\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m})</span> , and saves  <span class="math">(h,\\sigma)</span>  as a short certificate of x.</p>

    <h4 id="sec-41" class="text-lg font-semibold mt-6">• Online Plase.</h4>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Compute(f): The worker and the delegator run the delegation scheme given by Theorem 51. In order to verify, the delegator needs to access poly  <span class="math">\\log T</span>  points in  <span class="math">\\mathrm{LDE}_x^{\\mathbb{F},\\mathbb{H},m}</span> , and she can achieve this task by asking the worker to reveal the augmented paths corresponding to the Merkle tree. She accepts if and only if all the openings are accepted, and their corresponding values together with the answers to the PCPP queries are accepted in the verification of the delegation scheme.</li>
      <li>Update(g): The delegator chooses a fresh collision resistant hash function  <span class="math">h&#x27; \\leftarrow \\mathcal{H}</span> , then the delegator and the worker run Compute( <span class="math">T_{h&#x27;}(LDE_{g(x)})</span> ). Note that  <span class="math">T_{h&#x27;}(LDE_{g(x)})</span>  is polynomial time computable (in x) given g. Finally, the worker replaces the memory x with g(x).</li>
    </ul>

    <p class="text-gray-300">Putting it together, we obtain Theorem 44. The proof is very similar to the proof of Theorem 31 in Section 7.3, and therefore is omitted. In what follows, we give a very high level overview of the proof.</p>

    <h4 id="sec-42" class="text-lg font-semibold mt-6">Proof Overview of Theorem 44.</h4>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The completeness follows from those of the delegation scheme from Theorem 51 and the tree commitment. The soundness can be proved in a similar way to the proof in Section 7.3.</li>
      <li>Both parties are efficient in the offline stage, i.e. run in time poly(k, n) since the computation of the root of the Merkle tree takes  <span class="math">poly(k, |\\mathbb{F}|^m) = poly(k, n)</span>  time.</li>
      <li>In the online phase during each  <span class="math">\\mathsf{Compute}(f)</span>  operation, the worker runs in time  <span class="math">\\mathsf{poly}(k,T)</span> , and the delegator runs in time  <span class="math">\\mathsf{poly}(k,\\log T)</span> , where T is the running time of f. This follows from the efficiency of the delegation scheme from Theorem 51 and from the fact that only  <span class="math">\\mathsf{poly}\\log T</span>  leaves of the tree commitment need to be revealed.</li>
      <li>The protocol has 4 message exchanges, by running the delegation scheme from Theorem 51 and the Reveal protocols in parallel. Specifically, in the first two messages, the delegator sends a random hash function and the worker uses it to commit to a PCPP proof. Then in the third message, the delegator queries both the PCPP proof and points on the low degree extension of the memory. The worker answers the corresponding queries in the fourth message. An illustration of the protocol can be found in Figure 9.</li>
    </ul>

    <h4 id="sec-43" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-62-0&quot;&gt;&lt;/span&gt;10.4 Streaming Delegation Scheme Based on Theorem 51</h4>

    <p class="text-gray-300">In this section, we outline the construction of our streaming delegation scheme. Let N be the bound of the stream, and we choose the following parameters:  <span class="math">\\tilde{\\mathbb{F}}, \\mathbb{F}, \\mathbb{H}, m</span>  such that  <span class="math">|\\mathbb{F}| = \\log^2 N</span> ,  <span class="math">|\\mathbb{H}| = \\log N</span> ,  <span class="math">m = \\theta(\\log N/\\log\\log N)</span> , and  <span class="math">|\\tilde{\\mathbb{F}}| = N^{\\log N}</span>  where  <span class="math">\\tilde{\\mathbb{F}}</span>  is an extension field of  <span class="math">\\mathbb{F}</span> .</p>

    <p class="text-gray-300">    <img src="_page_63_Picture_0.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Figure 9: Compute(f) protocol of our interactive memory delegation scheme:  <span class="math">h_{UA}</span>  is a collision resistant hash function chosen by the delegator in the universal argument.  <span class="math">T_{h_{UA}}(\\pi_{pcpp})</span>  is the tree commitment of the PCPP proof  <span class="math">\\pi_{pcpp}</span> .  <span class="math">q_{\\pi}</span>  and  <span class="math">q_{\\text{LDE}}</span>  denote the queries that the delegator makes to the PCPP proof and the Reed-Muller encoding LDE&lt;sub&gt;x&lt;/sub&gt; of the input x, respectively.  <span class="math">ans_{\\pi}</span>  and  <span class="math">ans_{\\text{LDE}}</span>  denote the corresponding answers together with the corresponding augmented paths.</p>

    <h4 id="sec-44" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-63-0&quot;&gt;&lt;/span&gt;The Construction.</h4>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Generating and updating the secret state. At time 0, the delegator keeps a secret  <span class="math">\\sigma_0 = (z,0)</span> , where  <span class="math">z \\leftarrow \\tilde{\\mathbb{F}}^m</span> . At each time  <span class="math">t \\in [N]</span> , when a data item  <span class="math">x_t \\in \\{0,1\\}</span>  arrives, the delegator updates her secret state from  <span class="math">\\sigma_{t-1} = (z, \\text{LDE}_{x^{t-1}}^{\\tilde{\\mathbb{F}}, \\mathbb{H}, m}(z))</span>  to  <span class="math">\\sigma_t = (z, \\text{LDE}_{x^t}^{\\tilde{\\mathbb{F}}, \\mathbb{H}, m}(z))</span> , by using Proposition 6. (Recall that  <span class="math">x^t = (x_1, \\dots, x_t)</span>  denotes the entire data stream up until time t.)</li>
      <li>Compute(f, t). At any time t, when the delegator wants to execute Compute(f, t), both parties run the delegation scheme from Theorem 51 with a modified parameter setting</li>
    </ul>

    <p class="text-gray-300"><span class="math">$|\\mathbb{H}| = \\log N, \\ m&#x27;&#x27; = \\left\\lceil \\frac{\\log n}{\\log \\log N} \\right\\rceil, \\ |\\mathbb{F}| = \\log^2 N</span>$</p>

    <p class="text-gray-300">as stated in Remark 52. Here in order to verify, the delegator needs to verify the value of  <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}</span>  on a few points  <span class="math">z_i&#x27;&#x27; \\in \\mathbb{F}^{m&#x27;&#x27;}</span> . As argued in Section 9.1 (see Equation (10)),  <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m&#x27;&#x27;}(z_i&#x27;&#x27;) = \\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m}(z_i)</span>  where  <span class="math">z_i = (0^{m-m&#x27;&#x27;},z_i)</span> . Hence, the delegator can instead verify the values  <span class="math">\\mathrm{LDE}_{x^t}^{\\mathbb{F},\\mathbb{H},m}(z_i)</span> , which can be done by using a many-to-one protocol together with a Reveal protocol in exactly the same way as in Section 9.2 (see Steps 3 and 4 in Figure 7).</p>

    <p class="text-gray-300">This gives us a streaming delegation scheme satisfying Theorem 45. As in Section 10.3, the proof is very similar to the proof of Theorem 40 in Section 9, and is therefore omitted.</p>

    <h4 id="sec-45" class="text-lg font-semibold mt-6">Proof Overview of Theorem 45.</h4>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The completeness follows from that of the delegation scheme from Theorem 51, the many-to-one protocol, and the Reveal protocol of the algebraic commitments (see Section 9 for details). The soundness can be proved in a similar way to the proof in Section 9.3.</li>
      <li>The delegator runs in time polylog N to update her secret per data item.</li>
      <li>The worker runs in time poly(k, log N, T) for the delegation of a time T computable function, and the delegator runs in time poly(k, log N, log T). This follows from the efficiency of the underlying delegation scheme from Theorem 51, the many-to-one protocol, and the Reveal protocol of the algebraic commitments.</li>
    </ul>

    <p class="text-gray-300">• The protocol has 4 message exchanges, by running the the delegation scheme from Theorem 51, the many-to-one protocol, and the Reveal protocol in parallel, in a similar way to that of the memory delegation scheme described in Section 10.3. An illustration of the protocol can be found in Figure 10.</p>

    <p class="text-gray-300">    <img src="_page_64_Figure_1.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">&lt;span id=&quot;page-64-7&quot;&gt;&lt;/span&gt;Figure 10: Compute(f) protocol of our interactive streaming delegation scheme, where  <span class="math">q_{\\text{LDE}} = \\mathbf{z} = \\{z_i\\}</span>  is the queries that the delegator makes to the Reed-Muller encoding LDE <span class="math">_x</span>  of the input x. In parallel to the universal argument, the delegator and the worker run a many-to-one protocol and a Reveal protocol in the same way as in Section 9.2 (see Steps 3 and 4 in Figure 7) to verify the values of LDE <span class="math">_x</span>  on points  <span class="math">\\mathbf{z}</span> .</p>

    <h2 id="sec-46" class="text-2xl font-bold">Acknowledgments</h2>

    <p class="text-gray-300">We are very grateful to Shai Halevi for collaborating with us in the initial phase of this work, and to Salil Vadhan for several helpful discussions.</p>

    <h2 id="sec-47" class="text-2xl font-bold">References</h2>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><p class="text-gray-300">&lt;span id=&quot;page-64-3&quot;&gt;&lt;/span&gt;[AIK10] Benny Applebaum, Yuval Ishai, and Eyal Kushilevitz. From secrecy to soundness: Efficient verification via secure computation. In <em>ICALP</em> (1), pages 152–163, 2010.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-64-2&quot;&gt;&lt;/span&gt;[Bar01] Boaz Barak. How to go beyond the black-box simulation barrier. In <em>FOCS</em>, pages 106–115, 2001.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-64-0&quot;&gt;&lt;/span&gt;[BCC88] Gilles Brassard, David Chaum, and Claude Crépeau. Minimum disclosure proofs of knowledge. <em>Journal of Computer and System Sciences</em>, 37(2):156–189, 1988.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-64-4&quot;&gt;&lt;/span&gt;[BFL91] László Babai, Lance Fortnow, and Carsten Lund. Non-deterministic exponential time has two-prover interactive protocols. <em>Computational Complexity</em>, 1:3–40, 1991.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-64-5&quot;&gt;&lt;/span&gt;[BFLS91] László Babai, Lance Fortnow, Leonid A. Levin, and Mario Szegedy. Checking computations in polylogarithmic time. In <em>STOC</em>, pages 21–31, 1991.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-64-1&quot;&gt;&lt;/span&gt;[BG02] Boaz Barak and Oded Goldreich. Universal arguments and their applications. In <em>Proceedings of the 17th Annual IEEE Conference on Computational Complexity</em>, pages 194–203, 2002.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-64-6&quot;&gt;&lt;/span&gt;[BIN97] Mihir Bellare, Russell Impagliazzo, and Moni Naor. Does parallel repetition lower the error in computationally sound protocols? In <em>FOCS</em>, pages 374–383, 1997.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-3&quot;&gt;&lt;/span&gt;[BR97] Mihir Bellare and Phillip Rogaway. Minimizing the use of random oracles in authenticated encryption schemes. In ICICS, pages 1–16, 1997.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-1&quot;&gt;&lt;/span&gt;[BSGH+05] Eli Ben-Sasson, Oded Goldreich, Prahladh Harsha, Madhu Sudan, and Salil P. Vadhan. Short pcps verifiable in polylogarithmic time. In IEEE Conference on Computational Complexity, pages 120–134, 2005.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-14&quot;&gt;&lt;/span&gt;[BSW03] Boaz Barak, Ronen Shaltiel, and Avi Wigderson. Computational analogues of entropy. In RANDOM-APPROX, pages 200–215, 2003.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-6&quot;&gt;&lt;/span&gt;[CGH04] Ran Canetti, Oded Goldreich, and Shai Halevi. The random oracle methodology, revisited. Journal of the ACM, 51(4):557–594, 2004.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-10&quot;&gt;&lt;/span&gt;[CHS05] Ran Canetti, Shai Halevi, and Michael Steiner. Hardness amplification of weakly verifiable puzzles. In TCC, pages 17–33, 2005.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-0&quot;&gt;&lt;/span&gt;[CKLR11] Kai-Min Chung, Yael Tauman Kalai, Feng-Hao Liu, and Ran Raz. Memory delegation. In CRYPTO, 2011.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-8&quot;&gt;&lt;/span&gt;[CKV10] Kai-Min Chung, Yael Kalai, and Salil P. Vadhan. Improved delegation of computation using fully homomorphic encryption. In CRYPTO, pages 483–501, 2010.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-9&quot;&gt;&lt;/span&gt;[CTY10] G. Cormode, J. Thaler, and K. Yi. Verifying computations with streaming interactive proofs. Technical Report TR10-159, ECCC Report, 2010.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-12&quot;&gt;&lt;/span&gt;[DORS08] Yevgeniy Dodis, Rafail Ostrovsky, Leonid Reyzin, and Adam Smith. Fuzzy extractors: How to generate strong keys from biometrics and other noisy data. SIAM J. Comput., 38(1):97–139, 2008.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-13&quot;&gt;&lt;/span&gt;[DP08] Stefan Dziembowski and Krzysztof Pietrzak. Leakage-resilient cryptography. In FOCS, pages 293–302, 2008.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-2&quot;&gt;&lt;/span&gt;[DR06] Irit Dinur and Omer Reingold. Assignment testers: Towards a combinatorial proof of the pcp theorem. SIAM J. Comput., 36(4):975–1024, 2006.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-4&quot;&gt;&lt;/span&gt;[FL93] Lance Fortnow and Carsten Lund. Interactive proof systems and alternating timespace complexity. Theoretical Computer Science, 113(1):55–73, 1993.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-15&quot;&gt;&lt;/span&gt;[FR11] Benjamin Fuller and Leonid Reyzin. Computational entropy and information leakage. Manuscript., 2011.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-5&quot;&gt;&lt;/span&gt;[FS86] Amos Fiat and Adi Shamir. How to prove yourself: Practical solutions to identification and signature problems. In CRYPTO, pages 186–194, 1986.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-11&quot;&gt;&lt;/span&gt;[Gen09] Craig Gentry. Fully homomorphic encryption using ideal lattices. In STOC, pages 169–178, 2009.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-65-7&quot;&gt;&lt;/span&gt;[GGP10] Rosario Gennaro, Craig Gentry, and Bryan Parno. Non-interactive verifiable computing: Outsourcing computation to untrusted workers. In CRYPTO, pages 465–482, 2010.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-7&quot;&gt;&lt;/span&gt;[GK03] Shafi Goldwasser and Yael Tauman Kalai. On the (in)security of the fiat-shamir paradigm. pages 102–113, 2003.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-0&quot;&gt;&lt;/span&gt;[GKR08] Shafi Goldwasser, Yael Tauman Kalai, and Guy N. Rothblum. Delegating computation: interactive proofs for muggles. In <em>STOC</em>, pages 113–122, 2008.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-10&quot;&gt;&lt;/span&gt;[HLR07] Chun-Yuan Hsiao, Chi-Jen Lu, and Leonid Reyzin. Conditional computational entropy, or toward separating pseudoentropy from compressibility. In <em>EUROCRYPT</em>, pages 169–186, 2007.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-6&quot;&gt;&lt;/span&gt;[Kil92] Joe Kilian. A note on efficient zero-knowledge proofs and arguments (extended abstract). In <em>STOC</em>, pages 723–732, 1992.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-1&quot;&gt;&lt;/span&gt;[KR09] Yael Tauman Kalai and Ran Raz. Probabilistically checkable arguments. In <em>CRYPTO</em>, 2009.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-3&quot;&gt;&lt;/span&gt;[LFKN92] Carsten Lund, Lance Fortnow, Howard J. Karloff, and Noam Nisan. Algebraic methods for interactive proof systems. <em>J. ACM</em>, 39(4):859–868, 1992.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-2&quot;&gt;&lt;/span&gt;[Mic94] Silvio Micali. Cs proofs (extended abstracts). In FOCS, pages 436–453, 1994.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-5&quot;&gt;&lt;/span&gt;[Mic00] Silvio Micali. Computationally sound proofs. SIAM J. Comput., 30(4):1253–1298, 2000.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-13&quot;&gt;&lt;/span&gt;[Neu28] John Von Neumann. Zur theorie der gesellschaftsspiele. <em>Mathematische Annalen</em>, 100(1):295–320, 1928.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-11&quot;&gt;&lt;/span&gt;[RTTV08] Omer Reingold, Luca Trevisan, Madhur Tulsiani, and Salil P. Vadhan. Dense subsets of pseudorandom sets. In <em>FOCS</em>, pages 76–85, 2008.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-9&quot;&gt;&lt;/span&gt;[RW05] Renato Renner and Stefan Wolf. Simple and tight bounds for information reconciliation and privacy amplification. In ASIACRYPT, pages 199–216, 2005.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-4&quot;&gt;&lt;/span&gt;[Sha92] Adi Shamir. IP = PSPACE. Journal of the ACM, 39(4):869–877, 1992.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-12&quot;&gt;&lt;/span&gt;[Vad10] Salil Vadhan. Psuedorandomness. Book draft, available at &quot;http://people.seas.harvard.edu/~salil/pseudorandomness/pseudorandomness-Aug10.pdf&quot;, 2010.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-66-8&quot;&gt;&lt;/span&gt;[vDGHV10] Marten van Dijk, Craig Gentry, Shai Halevi, and Vinod Vaikuntanathan. Fully homomorphic encryption over the integers. In <em>EUROCRYPT</em>, pages 24–43, 2010.</p></li>
    </ul>

    <h2 id="sec-48" class="text-2xl font-bold">&lt;span id=&quot;page-66-14&quot;&gt;&lt;/span&gt;A Proof of Lemma 23</h2>

    <p class="text-gray-300"><strong>Lemma 53 (Lemma 23 restated)</strong> Let  <span class="math">\\mathbb{F}</span>  be a finite field of size q, and let  <span class="math">m \\in \\mathbb{N}</span>  be a parameter. Let X be a distribution over  <span class="math">\\mathbb{F}^{m \\times 2}</span>  with  <span class="math">\\mathbf{H}_{\\infty}(X) \\geq (2m \\cdot \\log q) - (\\log q)/4</span> , and  <span class="math">a = (a_1, a_2) \\leftarrow \\mathbb{F}^2</span> . Then  <span class="math">(X \\cdot a) \\in \\mathbb{F}^m</span>  is  <span class="math">\\varepsilon</span> -close to uniform with  <span class="math">\\varepsilon \\leq 2m \\cdot q^{-1/4}</span> . Let x 1 , . . . , x&lt;sup&gt;m&lt;/sup&gt; ∈ F &lt;sup&gt;2&lt;/sup&gt; denote the m rows of X, and let H be the following hash function family</p>

    <p class="text-gray-300"><span class="math">$\\mathcal{H} = \\{ h_a : \\mathbb{F}^2 \\to \\mathbb{F} \\text{ s.t. } h_a(x) = a_1 x_1 + a_2 x_2 \\quad \\forall a \\in \\mathbb{F}^2 \\}.</span>$</p>

    <p class="text-gray-300">In the above notation, X · a = (ha(x 1 ), . . . , ha(x &lt;sup&gt;m&lt;/sup&gt;)). Loosely speaking, Lemma <a href="#page-24-1">23</a> holds for the following reasons:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>All rows of X have high min-entropy. Note that there are only (log q)/4 bits of entropy missing from X, so intuitively, all rows x &lt;sup&gt;i&lt;/sup&gt; of X have at least 2 log q −(log q)/4 bits of entropy.</li>
      <li>H is a 2-universal hash function family. By Leftover Hash Lemma (Lemma <a href="#page-67-0">57</a> below), h&lt;sup&gt;a&lt;/sup&gt; ← H can extract randomness from all rows x &lt;sup&gt;i&lt;/sup&gt; of X.</li>
    </ul>

    <p class="text-gray-300">We proceed to present necessary preliminaries for proving Lemma <a href="#page-24-1">23.</a></p>

    <p class="text-gray-300">Definition 54 (Block Source) Let X = (X1, . . . , Xm) be a distribution, and let <code>∈ N be a parameter. We say that X is a block</code>-source if for every i ∈ [m] and every (x1, . . . , xi−1) ∈ supp(X1, . . . , Xi−1), H∞(X&lt;sup&gt;i&lt;/sup&gt; |(X1,...,Xi−1)=(x1,...,xi−1) ) ≥ \`.</p>

    <p class="text-gray-300">The following lemma says that if X = (X1, . . . , Xm) has sufficiently high min-entropy, then X is (statistically close to) a block source.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-67-1&quot;&gt;&lt;/span&gt;Lemma 55 (see, e.g., <a href="#page-66-12">[Vad10]</a>) Let X = (X1, . . . , Xm) be a distribution over {0, 1} m×n . Let ∆ ∈ N and ε ∈ (0, 1) be parameters. If H∞(X) ≥ mn−∆, then X is (mε)-close to a block k-source with k = n − ∆ − log(1/ε).</p>

    <p class="text-gray-300">Definition 56 (2-universal) A hash function family H = {h : {0, 1} &lt;sup&gt;n&lt;/sup&gt;&lt;sup&gt;1&lt;/sup&gt; → {0, 1} &lt;sup&gt;n&lt;/sup&gt;&lt;sup&gt;2&lt;/sup&gt; } is 2-universal if for every x 6= x &lt;sup&gt;0&lt;/sup&gt; ∈ {0, 1} n&lt;sup&gt;1&lt;/sup&gt; ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{h \\leftarrow \\mathcal{H}}[h(x) = h(x&#x27;)] \\le 1/2^{n_2}.</span>$</p>

    <p class="text-gray-300">It is easy to verify that the hash function family H = {h&lt;sup&gt;a&lt;/sup&gt; : F &lt;sup&gt;2&lt;/sup&gt; → F} defined above is 2-universal.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-67-0&quot;&gt;&lt;/span&gt;Lemma 57 (Leftorver Hash Lemma (see, e.g., <a href="#page-66-12">[Vad10]</a>)) Let H = {h : {0, 1} &lt;sup&gt;n&lt;/sup&gt;&lt;sup&gt;1&lt;/sup&gt; → {0, 1} &lt;sup&gt;n&lt;/sup&gt;&lt;sup&gt;2&lt;/sup&gt; } be a 2-universal family of hash functions. Let k ∈ N and ε &gt; 0 be parameters such that n&lt;sup&gt;2&lt;/sup&gt; ≤ k − 2 log(1/ε). For any distribution X with H∞(X) ≥ k, the distribution (h, h(X)) is ε-close to uniform in statistical distance.</p>

    <p class="text-gray-300">Moreover, if X = (X1, . . . , Xm) is a block k-source, then the distribution (h, h(X1), . . . , h(Xm)) is (mε)-close to uniform.</p>

    <p class="text-gray-300">Lemma <a href="#page-24-1">23</a> follows readily by Lemma <a href="#page-67-1">55</a> and <a href="#page-67-0">57.</a></p>

    <p class="text-gray-300">Proof. (of Lemma <a href="#page-24-1">23)</a> Let ε = q −1/4 , and k = 1.5 log q. By Lemma <a href="#page-67-1">55,</a> X = (x 1 , . . . , xm) is mε-close to a block k-source. By Lemma <a href="#page-67-0">57,</a> X · a = (ha(x 1 ), . . . , ha(x &lt;sup&gt;m&lt;/sup&gt;)) is (mε + mε)-close to uniform.</p>

`;
---

<BaseLayout title="Memory Delegation∗ (2011/273)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2011 &middot; eprint 2011/273
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <PaperDisclaimer eprintUrl={EPRINT_URL} />
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

    <PaperHistory slug="memory-delegation-2011" />
  </article>
</BaseLayout>
