---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2022/1010';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Orion: Zero Knowledge Proof with Linear Prover Time';
const AUTHORS_HTML = 'Tiancheng Xie, Yupeng Zhang, Dawn Song';

const CONTENT = `    <p class="text-gray-300">Orion: Zero Knowledge Proof with Linear Prover Time\\*</p>

    <p class="text-gray-300">Tiancheng Xie<span class="math">^{1}</span>, Yupeng Zhang<span class="math">^{2}</span>, and Dawn Song<span class="math">^{1}</span></p>

    <p class="text-gray-300"><span class="math">^{1}</span> University of California, Berkeley {tianc.x,dawnsong}@berkeley.edu <span class="math">^{2}</span> Texas A&amp;M University zhangyp@tamu.edu</p>

    <p class="text-gray-300">Abstract. Zero-knowledge proof is a powerful cryptographic primitive that has found various applications in the real world. However, existing schemes with succinct proof size suffer from a high overhead on the proof generation time that is super-linear in the size of the statement represented as an arithmetic circuit, limiting their efficiency and scalability in practice. In this paper, we present Orion, a new zero-knowledge argument system that achieves <span class="math">O(N)</span> prover time of field operations and hash functions and <span class="math">O(\\log^2 N)</span> proof size. Orion is concretely efficient and our implementation shows that the prover time is 3.09s and the proof size is 1.5MB for a circuit with <span class="math">2^{20}</span> multiplication gates. The prover time is the fastest among all existing succinct proof systems, and the proof size is an order of magnitude smaller than a recent scheme proposed in Golovnev et al. 2021.</p>

    <p class="text-gray-300">In particular, we develop two new techniques leading to the efficiency improvement. (1) We propose a new algorithm to test whether a random bipartite graph is a lossless expander graph or not based on the small set expansion problem. It allows us to sample lossless expanders with an overwhelming probability. The technique improves the efficiency and/or security of all existing zero-knowledge argument schemes with a linear prover time. (2) We develop an efficient proof composition scheme, code switching, to reduce the proof size from square root to polylogarithmic in the size of the computation. The scheme is built on the encoding circuit of a linear code and shows that the witness of a second zero-knowledge argument is the same as the message in the linear code. The proof composition only introduces a small overhead on the prover time.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">* In the previous version, there was a mistake in the proof of the expander testing algorithm based on the densets sub-graph algorithm. In particular, in Case 2 of Theorem 2 in the original version, the density $\\frac{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+ c}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+ 1} &gt; \\frac{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math"> only holds when </span>c &gt; \\frac{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">, or </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">V'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">&gt;</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$, which was not the case for lossless expanders. In this version, we propose a different algorithm based on the small set expansion problem to identify losses expander graphs with a negligible soundness error in Section 3. We thank Quang Dao and Xifan Yu, Weijie Wang, Charalampos Papamanthou for pointing out the mistake.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">1 Introduction</p>

    <p class="text-gray-300">Zero-knowledge proof (ZKP) allows a <em>prover</em> to convince a <em>verifier</em> that a statement is valid, without revealing any additional information about the prover’s secret witness of the statement. Since it was first introduced in the seminal paper by Goldwasser, Micali and Rackoff <em>[x10]</em>, ZKP has evolved from a purely theoretical interest to a concretely efficient cryptographic primitive, leading to many real-world applications in practice. It has been widely used in blockchains and cryptocurrencies to achieve privacy (Zcash <em>[BCG^{+}14, x11]</em>) and to improve scalability (zkRollup <em>[x12]</em>). More recently, it also found applications in zero-knowledge machine learning <em>[x23, x16, x17, FQZ^{+}21, WYX^{+}21]</em>, zero-knowledge program analysis <em>[x7]</em>, and zero-knowledge middlebox <em>[GAZ^{+}22]</em>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">There are three major efficiency measures in ZKP: the overhead of the prover to generate the proof, which is referred to as the <em>prover time</em>; the total communication between the prover and the verifier, which is called the <em>proof size</em>; and the time to verify the proof, which is called the <em>verifier time</em>. Despite its recent progress, the efficiency of ZKP is still not good enough for many applications. In particular, the prover time is one of the major bottlenecks preventing existing ZKP schemes from scaling to large statements. As pointed out by Golovnev et al. in <em>[GLS^{+}]</em>, to prove a statement that can be modeled as an arithmetic circuit with <span class="math">N</span> gates, existing schemes with succinct proof size either perform a fast Fourier transform (FFT) due to the Reed-Solomon code encodings or polynomial interpolations, or a multi-scalar exponentiation due to the use of discrete-logarithm assumptions or bilinear maps, over a vector of size <span class="math">O(N)</span>. The former takes <span class="math">O(N\\log N)</span> field additions and multiplications and the latter takes $O(N\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> field multiplications, where </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> is the size of the finite field. With the Pippenger’s algorithm <em>[x20]</em>, the complexity of the multi-scalar exponentiation can be improved to </span>O(N\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">/\\log N)<span class="math">, which is still super-linear as </span>\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\omega(\\log N)$ to ensure security. These operations are indeed the dominating cost of the prover time both asymptotically and concretely. See Section 1.3 for more discussions about existing ZKP schemes categorized by the underlying cryptographic techniques.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The only exceptions in the literature are schemes in <em>[BCG^{+}17, x2, x3, GLS^{+}]</em>. Bootle et al. <em>[BCG^{+}17]</em> proposed the first ZKP scheme with a prover time of <span class="math">O(N)</span> field operations and a proof size of <span class="math">O(\\sqrt{N})</span> using a linear-time encodable error-correcting code. The proof size is later improved to <span class="math">O(N^{1/c})</span> for any constant <span class="math">c</span> via a tensor code in <em>[x2]</em>, and then to <span class="math">\\mathsf{polylog}(N)</span> via a generic proof composition with a probabilistic checkable proof (PCP) in <em>[x3]</em>. These schemes are mainly for theoretical interests and do not have implementations with good concrete efficiency. Recently, Golovnev et al. <em>[GLS^{+}]</em> proposed a ZKP scheme based on the techniques in <em>[x2]</em> by instantiating the linear-time encodable code with a randomized construction. However, the security guarantee (soundness error) is only inverse polynomial in the size of the circuit, instead of negligible. Moreover, the proof size of the implemented scheme is <span class="math">O(\\sqrt{N})</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Prover time</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Proof size</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Verifier time*</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Soundness error</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Concrete efficiency</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[BCG+17]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(√N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N)</td>

            <td class="px-3 py-2 border-b border-gray-700">negl(N)</td>

            <td class="px-3 py-2 border-b border-gray-700">X</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[BCG20]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N1/c)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N1/c)</td>

            <td class="px-3 py-2 border-b border-gray-700">negl(N)</td>

            <td class="px-3 py-2 border-b border-gray-700">X</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[BCL22]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N)</td>

            <td class="px-3 py-2 border-b border-gray-700">polylog(N)</td>

            <td class="px-3 py-2 border-b border-gray-700">polylog(N)</td>

            <td class="px-3 py-2 border-b border-gray-700">negl(N)</td>

            <td class="px-3 py-2 border-b border-gray-700">X</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[GLS+]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(√N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(√N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(1/poly(N))</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">our scheme</td>

            <td class="px-3 py-2 border-b border-gray-700">O(N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(log2N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(log2N)</td>

            <td class="px-3 py-2 border-b border-gray-700">negl(N)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 1: Comparison to existing ZKP schemes with linear prover time.  <span class="math">N</span>  is the size of the circuit/R1CS and  <span class="math">c \\geq 2</span>  is a constant. * The verifier time is achieved in the preprocessing setting. In addition, the scheme in  <span class="math">\\left[\\mathrm{GLS}^{+}\\right]</span>  achieves  <span class="math">O(\\sqrt{N})</span>  verifier for structured circuits in the non-preprocessing setting.</p>

    <p class="text-gray-300">(more details are presented in Section 1.3). Therefore, the following question still remains open:</p>

    <p class="text-gray-300">Can we construct a concretely efficient ZKP scheme with  <span class="math">O(N)</span>  prover time and polylog(N) proof size?</p>

    <p class="text-gray-300">We answer the question above positively in this paper by proposing a new ZKP scheme. In particular, our contributions include:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>First, we propose a random construction of the linear-time encodable code that has a constant relative distance with overwhelming probability. Such a code was used in all existing linear-time ZKP schemes [BCG+17, BCG20, BCL22, GLS+] and thus our new construction also improves their efficiency. The key technique is an algorithm to test whether a random graph is a good expander graph based on the small set expansion problem.</li>

      <li>Second, we propose a new reduction that achieves a proof size of  <span class="math">O(\\log^2 N)</span>  efficiently. Our technique is a proof composition named "code switching" proposed in [RR20]. We develop an efficient instantiation using the encoding circuit of the linear-time encodable code, which reduces the proof size of the schemes in [BCG20, GLS+] from  <span class="math">O(\\sqrt{N})</span>  to  <span class="math">O(\\log^2 N)</span>  with a small overhead on the prover time.</li>

      <li>Finally, we implement our new ZKP scheme, Orion, and evaluate it experimentally. On a circuit with  <span class="math">2^{20}</span>  gates (rank-1-constraint-system (R1CS) with  <span class="math">2^{20}</span>  constraints), the prover time is 3.09s, the proof size is 1.5 MBs and the verifier time is 70ms. Orion has the fastest prover time among all existing ZKP schemes in the literature. The proof size is  <span class="math">6.5 \\times</span>  smaller than the system in  <span class="math">\\left[\\mathrm{GLS}^{+}\\right]</span> . The scheme is plausibly post-quantum secure and can be made non-interactive via the Fiat-Shamir heuristic [FS86].</li>

    </ul>

    <p class="text-gray-300">Table 1 shows the comparison between our scheme and existing schemes with linear prover time and succinct proof size.</p>

    <p class="text-gray-300">Verifier time. The verifier time in Table 1 is achieved in the preprocessing setting (holographic proofs  <span class="math">\\left[\\mathrm{CHM}^{+}20\\right]</span> ). As all the schemes do not have a trusted setup, their verifier time is  <span class="math">O(N)</span>  in the worst case, as the verifier has to read the</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Fig. 1: An example of lossless expander.  <span class="math">k = 6, k&#x27; = 9, g = 3, \\delta = 1, \\epsilon = \\frac{1}{6}</span> .</p>

    <p class="text-gray-300">description of the circuit/R1CS. In the preprocessing setting, the verifier time becomes sublinear with the commitment of an indexer describing the circuit. This is the best that can be achieved, and our scheme has a  <span class="math">O(\\log^2 N)</span>  verifier time in this setting using the techniques in [Set20]. In addition, the scheme in  <span class="math">\\left[\\mathrm{GLS}^{+}\\right]</span>  can also achieve a verifier time of  <span class="math">O(\\sqrt{N})</span>  in the non-preprocessing setting if the circuit/R1CS is structured, i.e., the description of the circuit can be computed in sublinear time. Our scheme has an  <span class="math">O(\\sqrt{N})</span>  verifier in this case, but not  <span class="math">O(\\log^2 N)</span> . This is because the encoding circuit we use in the proof compositing is of size  <span class="math">O(\\sqrt{N})</span>  and is not structured.</p>

    <p class="text-gray-300">Testing expander graphs. All existing ZKP schemes with linear prover time and succinct proof size  <span class="math">\\left[\\mathrm{BCG}^{+}17, \\mathrm{BCG}20, \\mathrm{BCL}22, \\mathrm{GLS}^{+}\\right]</span>  use linear-time encodable codes with a constant relative distance proposed in [Spi96, DI14,  <span class="math">\\mathrm{GLS}^{+}</span> ], which in turn all rely on the existence of good expander graphs. In a good expander graph, any subset of vertices expands to a large number of neighbors. Figure 1 shows an example of a bipartite graph where any subset of vertices on the left of size 2 expands to at least 5 vertices on the right. See Section 2.1 for formal definitions and constructions. However, how to construct such good expanders remain unclear in practice. Explicit constructions [CRVW02] have large hidden constants in the complexity and thus are not practical. A random graph tends to have good expansion, but the probability that a random graph is not a good expander is inverse polynomial in the size of the graph. The code constructed from a non-expanding graph does not have a good minimum distance, making the ZKP scheme insecure. Therefore, a randomly sampled graph is not good for cryptographic applications.</p>

    <p class="text-gray-300">In this paper, we propose an algorithm to efficiently test whether a random graph is a good expander or not. With the new testing algorithm, we are able to re-sample the random graph until it passes the test, obtaining a good expander with an overwhelming probability and boosting the soundness error of the ZKP scheme to be negligible. The testing algorithm is based on the small set bipartite</p>

    <p class="text-gray-300">vertex expansion problem <em>[x10]</em>, which can be reduced to the Minimum <span class="math">s</span>-Union problem <em>[CDK^{+}18]</em>, finding <span class="math">s</span>-sets from <span class="math">k</span> sets minimizing the size of their union. The problem is NP-hard for <span class="math">s=O(k)</span>, but we observe that in order to achieve a negligible soundness error, it suffices to search for very small sets with <span class="math">s\\leq\\log\\log k</span>. In order to design a polynomial time algorithm, we rely on two observations of random bipartite graphs: (1) if there exist a non-expanding sub-graph, there has to be at least one that is connected (Lemma 4); (2) with high probability, a vertex in the right set <span class="math">R</span> has at most <span class="math">O(\\log k)</span> neighbors (Lemma 5). With these two observations, we are able to bound the search space of each vertex <span class="math">v\\in L</span>. That is, the total number of connected sub-graphs with <span class="math">\\leq\\log\\log k</span> vertices in <span class="math">L</span> containing <span class="math">v</span> is only <span class="math">O((\\log k)^{\\log\\log k})</span>. Therefore, we can enumerate all such sub-graphs for every vertex <span class="math">v\\in L</span> to see if there is a non-expanding one, and the complexity is <span class="math">o(k^{2}\\log\\log k)</span>. The formal algorithm, theorem and proofs are presented in Section 3.</p>

    <p class="text-gray-300">Proof composition via code-switching. With the expander graph sampled above and the corresponding linear code, we are able to build efficient ZKP schemes following the approaches in <em>[BCG^{+}17, x1, x11]</em>. However, the proof size is <span class="math">O(N^{1/c})</span> instead of <span class="math">\\mathsf{polylog}(N)</span>. To reduce the proof size, a common technique in the literature is proof composition. Instead of sending the proof directly to the verifier, the prover uses a second ZKP scheme to show that the proof of the first ZKP is indeed valid. In particular, in <em>[BCG^{+}17, x1, x11]</em>, the proof consists of several codewords of the linear-time encodable code, and the checks can be represented as inner products between the messages in the codewords and some public vectors.</p>

    <p class="text-gray-300">Unfortunately, we do not have a second ZKP scheme based on the linear-time encodable code with a <span class="math">\\mathsf{polylog}(N)</span> proof size to prove inner products. If we had it, we would already be able to build a ZKP scheme with <span class="math">\\mathsf{polylog}(N)</span> proof size in the first place. Instead, we rely on the fact that the proof consists of the codewords of the linear code and construct the second ZKP scheme as follows. One component of the second ZKP scheme is the <em>encoding circuit</em> of the linear-time encodable code. It takes the witness of the second ZKP scheme, encodes it and outputs several random locations of the codeword. The verifier checks that these random locations are the same as the proof of the first ZKP scheme, without receiving the entire proof. By the distance of the linear-time encodable code, we show that the witness of the second ZKP must be the same as the message in the proof of the first ZKP with overwhelming probability. After that, the other component of the second ZKP checks the inner product relationship modeled as an arithmetic circuit. A similar proof composition was also used in <em>[x26]</em>. We view our approach using the encoding circuit as a variant of the proof composition that is efficient in practice, and thus we inherit the name “code switching” from <em>[x26]</em>.</p>

    <p class="text-gray-300">With this idea, we can use any general-purpose ZKP scheme on arithmetic circuits with a <span class="math">\\mathsf{polylog}(N)</span> proof size as the second ZKP scheme in the proof composition. The size of this circuit is only <span class="math">O(\\sqrt{N})</span>, thus the second ZKP does not introduce any overhead on the prover time as long as its prover time is no</p>

    <p class="text-gray-300">more than quadratic. In our construction, we use the ZKP scheme in <em>[x22]</em> as the second ZKP. The scheme is based on the interactive oracle proofs (IOP) and the witness is encoded using the Reed-Solomon code. Therefore, the technique is called code switching. The formal protocols are presented in Section 4.</p>

    <h3 id="sec-3" class="text-xl font-semibold mt-8">1.3 Related Work</h3>

    <p class="text-gray-300">Zero-knowledge proof was introduced in <em>[x10]</em> and generic constructions based on PCPs were proposed by Kilian <em>[x15]</em> and Micali <em>[x16]</em> in the early days. Driven by various applications mentioned in the introduction, there has been significant progress in efficient ZKP protocols and systems. Categorized by their underlying techniques, there are ZKP systems based on bilinear maps <em>[x20, x1, BCG^{+}13, BFR^{+}13, x1, CFH^{+}15, WSR^{+}15, FFG^{+}16, GKM^{+}18, x1, x1, CHM^{+}20, x11, MPC-in-the-head, x12, x13, x14, x15, x16, x17, x18]</em>, interactive proofs <em>[x20, CDG^{+}17, x1, x17b, x18, x19, x20, x21]</em>, ZGK^{+}17b, WTS^{+}18, ZGK^{+}18, XZZ^{+}19, ZLW^{+}21]<em>, discrete logarithm </em>[BBB^{+}18, x2, x12, x13]<em>, interactive oracle proofs (IOP) </em>[BSCR^{+}19, x1, x1, x1, x13, x14, x15, x16]<em>, and lattices </em>[BBC^{+}18, x1, x1, x13, x14]*. As mentioned in the introduction, these schemes perform either an FFT (such as schemes based on MPC-in-the-head and IOP) or a multi-scalar exponentiation (such as schemes based on discrete-log and bilinear pairing), making the complexity of the prover time super-linear in the size of the circuit.</p>

    <p class="text-gray-300">With the techniques proposed in <em>[XZZ^{+}19, ZLW^{+}21]</em>, the prover time of the schemes based on the interactive proofs (the GKR protocol <em>[x12]</em>) is linear if the size of the input is significantly smaller than the size of the circuit. However, the goal of this paper is to make the prover time strictly linear without such a requirement, and our polynomial commitment scheme can also be plugged into these schemes to improve their efficiency.</p>

    <p class="text-gray-300">Schemes with linear prover time. As mentioned before, schemes in <em>[BCG^{+}17, x2, x1, x2, GLS^{+}]</em> are the only candidates in the literature with linear prover time and succinct proof size for arithmetic circuits. They all use linear-time encodable codes based on expander graphs and our first contribution applies to all of them. Moreover, our ZKP scheme is based on the polynomial commitment in <em>[GLS^{+}]</em> and the tensor IOP in <em>[x1]</em>, and we improve the proof size to <span class="math">O(\\log^{2}N)</span> through a proof composition. In fact, the scheme in <em>[x1]</em> also proposes a proof composition with the PCP in <em>[x18]</em>. However, the complexity of the PCP is polynomial time. That is why the scheme in <em>[x1]</em> has to be built on the scheme in <em>[x1]</em> with a proof size of <span class="math">O(N^{1/\\epsilon})</span> and is not concretely efficient, while our scheme can be built on top of the efficient scheme in <em>[GLS^{+}]</em> with a proof size of <span class="math">O(\\sqrt{N})</span>.</p>

    <p class="text-gray-300">Finally, the scheme in <em>[GLS^{+}]</em> samples a random graph to build the linear-time encodable code. The scheme achieves a soundness error of <span class="math">O(\\frac{1}{\\text{poly}(N)})</span> and the authors spent great efforts calculating parameters that achieve a concrete failure probability of <span class="math">2^{-100}</span> for large circuits in practice <em>[GLS^{+}, Claim 2 and Figure 2]</em>. Our sampling algorithm provides the provable security guarantee of a</p>

    <p class="text-gray-300">negligible soundness error for their scheme. Moreover, we improve the proof size from <span class="math">O(\\sqrt{N})</span> to <span class="math">O(\\log^{2}N)</span> efficiently, solving an open problem left in <em>[GLS+]</em>.</p>

    <p class="text-gray-300">There are two recent schemes that achieve linear prover time for Boolean circuits <em>[x29, x13]</em>. We mainly focus on arithmetic circuits in this paper, but our techniques may also apply to these schemes to obtain efficient instantiations.</p>

    <p class="text-gray-300">Schemes with linear proof size. Recently, there is a line of work constructing ZKP based on secure multiparty computation (MPC) techniques <em>[x35, x10, x1, x31, x32]</em> and these schemes have demonstrated fast prover time in practice. If one treats a block cipher (e.g., AES) as a constant-time operation because of the CPU instruction, these schemes indeed have a linear time prover (we are using a similar CPU instruction for the hash function SHA-256 in our scheme to achieve linear prover time). However, they have linear proof size in the size of the circuit, are inherently interactive, and are not publicly verifiable, which are not desirable in many applications. We mainly focus on non-interactive ZKP with succinct proof size and public verifiability in this paper.</p>

    <p class="text-gray-300">Expander testing. Testing the properties of expander graphs is a deeply explored area in computer science. Many works <em>[x26, x15, x12]</em> have proposed efficient testing algorithms without accessing the whole graph. However, these algorithms do not directly apply to our testing of lossless expander. For example, the algorithm in <em>[x26]</em> based on random walks can differentiate good expanders from graphs that are far from expanders, while our scheme can differentiate whether a graph is a lossless expander or not with overwhelming probability. Of course our algorithm accesses the entire graph, which is fine in our application of linear-time encodable code.</p>

    <p class="text-gray-300">There are also impossibility results on expander testing <em>[x18]</em>. Due to different definitions of expansion, our testing algorithm cannot distinguish the cases in <em>[x18, Theorem 1.1]</em> and thus it does not violate the impossibility results.</p>

    <h2 id="sec-4" class="text-2xl font-bold">2 Preliminary</h2>

    <p class="text-gray-300">We use <span class="math">[N]</span> to denote the set <span class="math">\\{0,1,2,...,N-1\\}</span>. <span class="math">\\mathsf{poly}(N)</span> means a function upper bounded by a polynomial in <span class="math">N</span> with a constant degree . We use <span class="math">\\lambda=\\omega(\\log N)</span> to denote the security parameter, and <span class="math">\\mathsf{negl}(N)</span> to denote the negligible function in <span class="math">N</span>, i.e. <span class="math">\\mathsf{negl}(N)\\leq\\frac{1}{\\mathsf{poly}(N)}</span> for all sufficiently large <span class="math">N</span> and any polynomial. Some papers define <span class="math">\\mathsf{negl}(\\lambda)</span> as the negligible function. As <span class="math">\\lambda</span> is a function of <span class="math">N</span>, they are essentially the same and <span class="math">\\mathsf{negl}(N)\\leq\\frac{1}{2^{N}}.</span> “PPT” stands for probabilistic polynomial time. <span class="math">\\langle A(x),B(y)\\rangle(z)</span> denotes an interactive protocol between algorithms <span class="math">A,B</span> with <span class="math">x</span> as the input of <span class="math">A</span>, <span class="math">y</span> as the input of <span class="math">B</span> and <span class="math">z</span> as the common input.</p>

    <h3 id="sec-5" class="text-xl font-semibold mt-8">2.1 Linear-Time Encodable Linear Code</h3>

    <h6 id="sec-6" class="text-base font-medium mt-4">Definition 1 (Linear Code)</h6>

    <p class="text-gray-300">A linear error-correcting code with message length <span class="math">k</span> and codeword length <span class="math">n</span> is a linear subspace <span class="math">C\\in\\mathbb{F}^{n}</span>, such that there exists an injective mapping from message to codeword <span class="math">E_{C}:\\mathbb{F}^{k}\\rightarrow C</span>, which is called</p>

    <p class="text-gray-300">the encoder of the code. Any linear combination of codewords is also a codeword. The rate of the code is defined as <span class="math">\\frac{k}{n}</span>. The distance between two codewords <span class="math">u,v</span> is the hamming distance denoted as <span class="math">\\Delta(u,v)</span>. The minimum distance is <span class="math">d=\\min_{u,v}\\Delta(u,v)</span>. Such a code is denoted as <span class="math">[n,k,d]</span> linear code, and we also refer to <span class="math">\\frac{d}{n}</span> as the relative distance of the code.</p>

    <p class="text-gray-300">Generalized Spielman code. In our construction, we use a family of linear codes that can be encoded in linear time and has a constant relative distance <em>[x21, x10, GLS^{+}]</em>. The code was first proposed by Daniel Spielman in <em>[x21]</em> over the Boolean alphabet. Druk and Ishai <em>[x10]</em> generalized it to a finite field <span class="math">\\mathbb{F}</span>, and introduced a distance boosting technique to achieve the Gilbert-Varshamov bound <em>[x13, x33]</em>. We only use the basic construction over <span class="math">\\mathbb{F}</span> without the distance boosting, and thus refer to it as the generalized Spielman code in this paper. The code relies on the existence of lossless expander graphs, which is defined below:</p>

    <h6 id="sec-7" class="text-base font-medium mt-4">Definition 2 (Lossless Expander <em>[x21]</em>).</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">G=(L,R,E)</span> be a bipartite graph. <span class="math">0&lt;\\epsilon&lt;1</span> and <span class="math">0&lt;\\delta</span> be some constants. The vertex set consists of <span class="math">L</span> and <span class="math">R</span>, two disjoint subsets, henceforth the left and right vertex set. Let <span class="math">\\Gamma(S)</span> be the neighbor set of some vertex set <span class="math">S</span>. We say <span class="math">G</span> is an <span class="math">(k,k^{\\prime};g)</span>-lossless expander if $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=k,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=k^{\\prime}=\\alpha k<span class="math"> for some constant </span>\\alpha$, and the following property hold:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Degree: The degree of every vertex in <span class="math">L</span> is <span class="math">g</span>.</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">2. Expansion: $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq(1-\\epsilon)g</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> for every </span>S\\subseteq L<span class="math"> with </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\frac{\\delta</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{g}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Intuitively speaking, a lossless expander has very strong expansion. As the degree of each left vertex is <span class="math">g</span>, a set of $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> left vertices have at most </span>g</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> neighbors, while the second condition requires that every set expands to at least </span>(1-\\epsilon)g</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> vertices for a small constant </span>\\epsilon<span class="math">. Meanwhile, as the right vertex set has </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\alpha k<span class="math"> vertices, such an expansion is not possible if </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">>\\frac{\\alpha k}{(1-\\epsilon)g}<span class="math">, thus there is a condition </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\frac{\\delta k}{g}<span class="math"> bounding the size of </span>S$. An example is shown in Figure 1.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Construction of generalized Spielman code. With the lossless expander, we give a brief description of the generalized Spielman code. Let <span class="math">G=(L,R,E)</span> be a lossless expander with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=2^{t},</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=2^{t-1}<span class="math">. Let </span>A_{t}<span class="math"> be a </span>2^{t}\\times 2^{t-1}<span class="math"> matrix where </span>A_{t}[i][j]=1<span class="math"> if there is an edge </span>i,j<span class="math"> in </span>G<span class="math"> for </span>i\\in[2^{t}],j\\in[2^{t-1}]<span class="math">; otherwise </span>A_{t}[i][j]=0$. The generalized Spielman code is constructed as follows:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">1. Let <span class="math">E^{t}_{C}(x)</span> be the encoder function of input length $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=2^{t}<span class="math">, and its output will be a codeword of size </span>2^{t+2}<span class="math">. We use </span>E_{C}$ to denote the encoder function when length is clear.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Compute <span class="math">m_{1}=xA_{t}</span>. Each entry of <span class="math">m_{1}</span> can be viewed as a vertex in <span class="math">R</span>, and value of each vertex is the summation of its neighbors in <span class="math">L</span>. The length of <span class="math">m_{1}</span> is <span class="math">2^{t-1}</span>.</li>

      <li>Recursively apply the encoder <span class="math">E^{t-1}_{C}</span> on <span class="math">m_{1}</span>, let <span class="math">c_{1}=E^{t-1}_{C}(m_{1})</span></li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Compute <span class="math">c_2 = c_1 A_{t+1}</span>.</li>

      <li>Output <span class="math">x \\odot c_1 \\odot c_2</span> as the codeword of size <span class="math">2^{t+2}</span>. <span class="math">\\odot</span> denotes concatenation.</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><strong>Lemma 1 (Generalized Spielman code, [DI14]).</strong> Given a family of lossless expander, that achieves $(1 - \\epsilon)g</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> expansion with </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq \\frac{\\delta</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{g}<span class="math">, for input size </span>k<span class="math">, the generalized Spielman code is a </span>[4k, k, \\frac{\\delta}{8g} k]<span class="math"> linear code over </span>\\mathbb{F}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The code in <span class="math">\\left[\\mathrm{GLS}^{+}\\right]</span> is a variant of generalized Spielman code. In their construction, random weights are assigned to each edge of lossless expander at line 3, 5. The output at line 6 is randomized as <span class="math">(x\\otimes r)\\odot c_1\\odot c_2</span>, where <span class="math">\\otimes</span> denotes element-wise multiplication and <span class="math">r</span> is a random vector.</p>

    <p class="text-gray-300"><strong>Definition 3 (Tensor code).</strong> Let <span class="math">C</span> be a <span class="math">[n, k, d]</span> linear code, the tensor code <span class="math">C^{\\otimes 2}</span> of dimension 2 is the linear code in <span class="math">\\mathbb{F}^{n^2}</span> with message length <span class="math">k^2</span>, codeword length <span class="math">n^2</span>, and distance <span class="math">nd</span>. We can view the codeword as a <span class="math">n \\times n</span> matrix. We define the encoding function below:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>A message of length <span class="math">k \\times k</span> is parsed as a <span class="math">k \\times k</span> matrix. Each row of the matrix is encoded using <span class="math">E_C</span>, resulting in a codeword <span class="math">C_1</span> of size <span class="math">k \\times n</span>.</li>

      <li>Each column of <span class="math">C_1</span> is then encoded again using <span class="math">E_C</span>. The result <span class="math">C_2</span> of size <span class="math">n \\times n</span> is the codeword of the tensor code.</li>

    </ol>

    <h2 id="sec-8" class="text-2xl font-bold">2.2 Collision-Resistant Hash Function and Merkle Tree</h2>

    <p class="text-gray-300"><strong>Definition 4.</strong> A commitment scheme is a tuple of algorithms <span class="math">\\operatorname{Setup}(1^{\\lambda}) \\to \\operatorname{ck}</span>, <span class="math">\\operatorname{Commit}(\\operatorname{ck}, m, r) \\to \\operatorname{com}</span>, <span class="math">\\operatorname{Open}(\\operatorname{ck}, \\operatorname{com}, m, r) \\to \\{0, 1\\}</span> such that:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><strong>Correctness.</strong> For any message <span class="math">m</span>,</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\operatorname{Setup}(1^{\\lambda}) \\rightarrow \\operatorname{ck}, \\operatorname{Commit}(\\operatorname{ck}, m, r) \\rightarrow \\operatorname{com}, \\operatorname{Open}(\\operatorname{ck}, \\operatorname{com}, m, r) \\rightarrow 1 \\right] = 1.</span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><strong>Binding.</strong> For any PPT adversary <span class="math">\\mathcal{A}</span>, the following probability is <span class="math">\\operatorname{negl}(N)</span>:</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} \\operatorname{Setup}(1^{\\lambda}) \\to \\operatorname{ck} &amp;amp; m \\neq m&#x27; \\\\ \\mathcal{A}(\\operatorname{ck} \\to (\\operatorname{com}, m, r, m&#x27;, r&#x27;) : &amp;amp; \\wedge \\operatorname{Open}(\\operatorname{ck}, \\operatorname{com}, m, r) \\to 1 \\\\ &amp;amp; \\wedge \\operatorname{Open}(\\operatorname{ck}, \\operatorname{com}, m&#x27;, r&#x27;) \\to 1) \\end{array} \\right]</span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><strong>Hiding.</strong> For any <span class="math">\\operatorname{Setup}(1^{\\lambda}) \\to \\operatorname{ck}</span>, for all <span class="math">m, m&#x27;</span>, the following two distributions are statistically close:</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Commit}(\\operatorname{ck}, m, r) \\approx \\operatorname{Commit}(\\operatorname{ck}, m&#x27;, r&#x27;)</span></div>

    <p class="text-gray-300">Let <span class="math">H: \\{0,1\\}^{2\\lambda} \\to \\{0,1\\}^{\\lambda}</span> be a hash function. A Merkle Tree is a data structure that allows one to commit to <span class="math">l = 2^{\\mathrm{dep}}</span> messages by a single hash value <span class="math">h</span>, such that revealing any bit of the message require <span class="math">\\mathrm{dep} + 1</span> hash values.</p>

    <p class="text-gray-300">A Merkle hash tree is represented by a binary tree of depth <span class="math">\\mathrm{dep}</span> where <span class="math">l</span> messages elements <span class="math">m_1, m_2, \\ldots, m_l</span> are assigned to the leaves of the tree. The values assigned to internal nodes are computed by hashing the value of its two child nodes. To reveal <span class="math">m_i</span>, we need to reveal <span class="math">m_i</span> together with the values on the path from <span class="math">m_i</span> to the root. We denote the algorithm as follows:</p>

    <p class="text-gray-300">9</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">h\\leftarrow\\text{ Merkle. Commit}(m_{1},...,m_{l})</span>.</li>

      <li><span class="math">(m_{i},\\pi_{\\text{i}})\\leftarrow\\text{ Merkle. Open}(m,i)</span>.</li>

      <li><span class="math">\\{\\text{accept},\\text{reject}\\}\\leftarrow\\text{ Merkle. Verify}(\\pi_{\\text{i}},m_{i},h)</span>.</li>

    </ol>

    <p class="text-gray-300">To achieve zero-knowledge, we requires the hash function to be hiding and we implicitly assumes for each hash function call on input <span class="math">x</span>, we will append a randomness <span class="math">r</span>.</p>

    <h3 id="sec-9" class="text-xl font-semibold mt-8">2.3 Zero-Knowledge Arguments</h3>

    <p class="text-gray-300">An argument system for an NP relation <span class="math">R</span> is a protocol between a computationally bounded prover <span class="math">\\mathcal{P}</span> and a verifier <span class="math">\\mathcal{V}</span>. At the end of the protocol <span class="math">\\mathcal{V}</span> will be convinced that there exits a witness <span class="math">w</span> such that <span class="math">(x,w)\\in R</span> for some public input <span class="math">x</span>. We focus on arguments of knowledge which require the prover know the witness <span class="math">w</span>. We formally define zero-knowledge as follows:</p>

    <h6 id="sec-10" class="text-base font-medium mt-4">Definition 5 (View).</h6>

    <p class="text-gray-300">We denote by <span class="math">\\textsf{View}(\\langle\\mathcal{P},\\mathcal{V}\\rangle(x))</span> the view of <span class="math">\\mathcal{V}</span> in an interactive protocol with <span class="math">\\mathcal{P}</span>. Namely, it is the random variable <span class="math">(r,b_{1},b_{2},...,b_{n},v_{1},v_{2},...,v_{m})</span> where <span class="math">r</span> is <span class="math">\\mathcal{V}</span>’s randomness, <span class="math">b_{1},...,b_{n}</span> are messages from <span class="math">\\mathcal{V}</span> to <span class="math">\\mathcal{P}</span>, and <span class="math">v_{1},...,v_{m}</span> are messages from <span class="math">\\mathcal{P}</span> to <span class="math">\\mathcal{V}</span>.</p>

    <h6 id="sec-11" class="text-base font-medium mt-4">Definition 6.</h6>

    <p class="text-gray-300">Let <span class="math">\\mathcal{R}</span> be an NP relation. A tuple of algorithm <span class="math">(\\mathcal{G},\\mathcal{P},\\mathcal{V})</span> is a zero-knowledge argument of knowledge for <span class="math">\\mathcal{R}</span> if the following holds.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Correctness. For every <span class="math">\\mathsf{pp}</span> output by <span class="math">\\mathcal{G}(1^{\\lambda})</span> and <span class="math">(x,w)\\in R</span>,</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\Pr[\\langle\\mathcal{P}(w),\\mathcal{V}()\\rangle(\\mathsf{pp},x)=\\mathsf{accept}]=1.</span></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Knowledge Soundness. For any PPT adversary <span class="math">\\mathcal{P}^{*}</span>, there exists a PPT extractor <span class="math">\\varepsilon</span> such that for every <span class="math">\\mathsf{pp}</span> output by <span class="math">\\mathcal{G}(1^{\\lambda})</span> and any <span class="math">x</span>, the following probability is <span class="math">\\mathsf{negl}(N)</span>:</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\Pr[\\langle\\mathcal{P}^{*}(),\\mathcal{V}()\\rangle(\\mathsf{pp},x)=\\mathsf{accept},(x,w)\\notin\\mathcal{R}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w\\leftarrow\\varepsilon(\\mathsf{pp},x,\\textsf{View}(\\langle\\mathcal{P}^{*}(),\\mathcal{V}()\\rangle(\\mathsf{pp},x)))]$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Zero knowledge. There exists a PPT simulator <span class="math">\\mathcal{S}</span> such that for any PPT algorithm <span class="math">\\mathcal{V}^{*}</span>, <span class="math">(x,w)\\in R</span>, <span class="math">\\mathsf{pp}</span> output by <span class="math">\\mathcal{G}(1^{\\lambda})</span>, it holds that</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\textsf{View}(\\langle\\mathcal{P}(w),\\mathcal{V}^{<em>}()\\rangle(x))\\approx\\mathcal{S}^{\\mathcal{V}^{</em>}}(\\mathsf{pp},x)</span></p>

    <p class="text-gray-300">Where <span class="math">\\mathcal{S}^{\\mathcal{V}^{<em>}}(x)</span> denotes that <span class="math">\\mathcal{S}</span> is given oracle accesses to <span class="math">\\mathcal{V}^{</em>}</span>’s random tape.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We say that <span class="math">(\\mathcal{G},\\mathcal{P},\\mathcal{V})</span> is a <em>succinct</em> argument system if the total communication between <span class="math">\\mathcal{P}</span> and <span class="math">\\mathcal{V}</span> (proof size) is $\\mathsf{poly}(\\lambda,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In addition, in our construction, we need a zero-knowledge argument that is a commit-and-prove SNARK (CP-SNARK) <em>[x1]</em> as a building block. Following the definition in <em>[x1]</em>, the relationship is represented by a pair <span class="math">\\mathbf{R}=(\\mathsf{ck},\\mathcal{R})</span> where <span class="math">\\mathsf{ck}</span> is the commitment key generated by <span class="math">\\mathsf{Setup}(1^{\\lambda})</span>. <span class="math">\\mathbf{R}</span> is over pairs <span class="math">(\\mathbf{x},\\mathbf{w})</span> where <span class="math">\\mathbf{x}=(x,\\mathsf{com}_{w})</span>, <span class="math">\\mathbf{w}=(w,r_{w})</span> and <span class="math">\\mathbf{R}</span> holds if and only if <span class="math">\\mathsf{Open}(\\mathsf{ck},\\mathsf{com}_{\\mathsf{w}},w,r_{w})=1\\wedge R(x,w)=1</span>.</p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">Definition 7 (Arithmetic circuit). An arithmetic circuit  <span class="math">\\mathsf{C}</span>  over  <span class="math">\\mathbb{F}</span>  and a set of variables  <span class="math">x_{1},\\ldots ,x_{N}</span>  is a directed acyclic graph as follows:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each vertex is called a "gate". A gate with in-degree zero is an input gate and is labeled as a variable  <span class="math">x_{i}</span>  or a constant field element in  <span class="math">\\mathbb{F}</span> .</li>

      <li>Other gates have 2 incoming edges. It calculates the addition or multiplication over the two inputs and output the result.</li>

      <li>The size of the circuit is defined as the number of gates  <span class="math">N</span> .</li>

    </ol>

    <p class="text-gray-300">A polynomial commitment consists of three algorithms:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>PC.Commit  <span class="math">(\\phi(\\cdot))</span> : the algorithm outputs a commitment  <span class="math">\\mathcal{R}</span>  of the polynomial  <span class="math">\\phi(\\cdot)</span> .</li>

      <li>PC.Prove  <span class="math">(\\phi, \\vec{x}, \\mathcal{R})</span> : given an evaluation point  <span class="math">\\phi(\\vec{x})</span> , the algorithm outputs a tuple  <span class="math">\\langle \\vec{x}, \\phi(\\vec{x}), \\pi_{\\vec{x}} \\rangle</span> , where  <span class="math">\\pi_{\\vec{x}}</span>  is the proof.</li>

      <li>PC.VerifyEval  <span class="math">(\\pi_{\\vec{x}},\\vec{x},\\phi (\\vec{x}),\\mathcal{R})</span>  : given  <span class="math">\\pi_{\\vec{x}},\\vec{x},\\phi (\\vec{x}),\\mathcal{R}</span>  , the algorithm checks if  <span class="math">\\phi (\\vec{x})</span>  is the correct evaluation. The algorithm outputs accept or reject.</li>

    </ul>

    <p class="text-gray-300">Definition 8 ((Multivariate) Polynomial commitment). A polynomial commitment scheme has the following properties:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Correctness. For every polynomial  <span class="math">\\phi</span>  and evaluation point  <span class="math">\\vec{x}</span> , the following probability holds:</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\operatorname * {P r} \\left( \\begin{array}{c} \\operatorname {P C . C o m m i t} (\\phi) \\to \\mathcal {R} \\\\ \\operatorname {P C . P r o v e} (\\phi , \\vec {x}, \\mathcal {R}) \\to \\vec {x}, y, \\pi \\\\ y = \\phi (\\vec {x}) \\\\ \\operatorname {P C . V e r i f y E v a l} (\\pi , \\vec {x}, y, \\mathcal {R}) \\to \\text {a c c e p t} \\end{array} \\right) = 1</span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Knowledge Soundness. For any PPT adversary  <span class="math">\\mathcal{P}^<em></span>  with PC.Commit</em>, PC.Prove*, there exists a PPT extractor  <span class="math">\\mathcal{E}</span>  such that the probability below is negligible:</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\operatorname * {P r} \\left( \\begin{array}{c} \\operatorname {P C . C o m m i t} ^ {*} (\\phi^ {*}) \\to \\mathcal {R} ^ {*} \\\\ \\operatorname {P C . P r o v e} ^ {*} (\\phi^ {*}, \\vec {x}, \\mathcal {R} ^ {*}) \\to \\vec {x}, y ^ {*}, \\pi^ {*}: \\phi^ {*} \\leftarrow \\mathcal {E} (\\mathcal {R} ^ {*}, \\vec {x}, \\pi^ {*}, y ^ {*}) \\wedge y ^ {*} \\neq \\phi^ {*} (\\vec {x}) \\\\ \\operatorname {P C . V e r i f y E v a l} (\\pi^ {*}, \\vec {x}, y ^ {*}, \\mathcal {R} ^ {*}) \\to \\text {a c c e p t} \\end{array} \\right)</span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Zero-knowledge. For security parameter  <span class="math">\\lambda</span> , polynomial  <span class="math">\\phi</span> , any PPT adversary  <span class="math">\\mathcal{A}</span> , there exists a simulator  <span class="math">\\mathcal{S} = [\\mathcal{S}_0, \\mathcal{S}_1]</span> , we consider following two experiments:</li>

    </ul>

    <p class="text-gray-300">RealA,φ(pp):</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{R}\\gets \\mathrm{Commit}(\\mathsf{pp},\\phi)</span></li>

      <li><span class="math">\\vec{x}\\gets \\mathcal{A}(\\mathcal{R},\\mathsf{pp})</span></li>

      <li><span class="math">(\\vec{x},y,\\pi)\\gets \\mathrm{Prove}(\\phi ,\\vec{x},\\mathcal{R})</span></li>

      <li><span class="math">b\\gets \\mathcal{A}(\\pi ,\\vec{x},y,\\mathcal{R})</span></li>

      <li>Output  <span class="math">b</span></li>

    </ol>

    <p class="text-gray-300">IdealA,SA(pp):</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{R}\\gets \\mathcal{S}_0(1^\\lambda ,\\mathsf{pp})</span></li>

      <li><span class="math">\\vec{x}\\gets \\mathcal{A}(\\mathcal{R},\\mathsf{pp})</span></li>

      <li><span class="math">(\\vec{x},y,\\pi)\\gets \\mathcal{S}_1^{\\mathcal{A}}(\\vec{x},\\mathsf{pp})</span>  , given oracle access to  <span class="math">y = \\phi (\\vec{x})</span></li>

      <li><span class="math">b\\gets \\mathcal{A}(\\pi ,\\vec{x},y,\\mathcal{R})</span></li>

      <li>Output  <span class="math">b</span></li>

    </ol>

    <p class="text-gray-300">For any PPT adversary <span class="math">\\mathcal{A}</span>, two experiments are identically distributed:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\Pr[</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathsf{Real}_{\\mathcal{A},f}(\\mathsf{pp})-\\mathsf{Ideal}_{\\mathcal{A},\\mathcal{S}^{\\mathcal{A}}}(\\mathsf{pp})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=1]\\leq\\mathsf{negl}(N)$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h2 id="sec-13" class="text-2xl font-bold">3 Testing Algorithm for Lossless Expander</h2>

    <p class="text-gray-300">As explained above, the generalized Spielman code relies on the existence of lossless expanders. On one hand, there are explicit constructions of lossless expanders in the literature <em>[x10]</em>. However, there are large hidden constants in the complexity and the constructions are not practical. On the other hand, a random bipartite graph is a lossless expander with a high probability of <span class="math">1-O(\\frac{1}{\\mathsf{poly}(k)})</span>, where <span class="math">k</span> is the size of the left vertex set in the bipartite graph. However, this is not good enough for cryptographic applications.</p>

    <p class="text-gray-300">In this section, we propose a new approach to sample a lossless expander with a negligible failure probability. The key ingredient of our approach is a new algorithm to test whether a randomly sampled bipartite graph is a lossless expander or not. We begin the section by introducing the classical randomized construction of a lossless expander and its analysis.</p>

    <h3 id="sec-14" class="text-xl font-semibold mt-8">3.1 Random Construction of Lossless Expander</h3>

    <p class="text-gray-300">As defined in Definition 2, a lossless expander graph is a <span class="math">g</span>-left-regular bipartite graph <span class="math">G=(L,R,E)</span>. Wigderson et al. <em>[x20, Lemma1.9]</em> showed that a random bipartite graph is a lossless expander with a high probability. In particular, we have the following lemma:</p>

    <h6 id="sec-15" class="text-base font-medium mt-4">Lemma 2 (<em>[x20]</em>)</h6>

    <p class="text-gray-300">For fixed constant parameters <span class="math">g,\\delta,\\alpha,\\epsilon</span>, a random <span class="math">g</span>-left-regular bipartite graph is a <span class="math">(k,k^{\\prime};g)</span>-lossless-expander with probability <span class="math">1-O(\\frac{1}{\\mathsf{poly}(k)})</span>.</p>

    <h6 id="sec-16" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Let <span class="math">G=(L,R,E)</span> be a random bipartite graph with <span class="math">k</span> vertices on the left and <span class="math">k^{\\prime}=O(k)</span> vertices on the right, where each left vertex connects to a randomly chosen set of <span class="math">g</span> vertices on the right.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let $s=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> be the cardinality of a left subset of vertices </span>S\\subseteq L<span class="math"> such that </span>s\\leq\\frac{\\delta k}{g}<span class="math">, and let </span>t=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> be the cardinality of a right subset of vertices </span>T\\subseteq R<span class="math"> such that </span>t\\leq(1-\\epsilon)gs<span class="math">. Let </span>X_{S,T}<span class="math"> be an indicator random variable for the event that all the edges from </span>S<span class="math"> connect to </span>T<span class="math">. Then for a particular </span>S<span class="math">, if </span>\\sum_{T\\in R}X_{S,T}=0<span class="math">, then the number of neighboring vertices of </span>S<span class="math"> must be larger than </span>(1-\\epsilon)gs<span class="math">. Otherwise, if there exists a </span>T\\in R<span class="math"> such that </span>X_{S,T}=1<span class="math">, i.e., all edges from </span>S<span class="math"> connect to </span>T<span class="math">, the graph is not a lossless expander. As the edges are sampled randomly, the probability of this non-expanding event is </span>(\\frac{t}{k^{\\prime}})^{sg}<span class="math">. Therefore, summing over all </span>S$ and by the union bound, the probability of a non-expanding graph is:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\operatorname{Pr}[(\\sum_{S,T} X_{S,T}) &amp;gt; 0] \\leq \\sum_{S,T} Pr[X_{S,T} = 1] = \\sum_{S,T} \\left(\\frac{t}{k&#x27;}\\right)^{sg} \\\\ \\leq \\sum_{s=2}^{\\frac{\\delta k}{s}} \\binom{k}{s} \\binom{k&#x27;}{t} \\left(\\frac{t}{k&#x27;}\\right)^{sg} \\leq \\sum_{s=2}^{\\frac{\\delta k}{s}} \\binom{k}{s} \\binom{k&#x27;}{(1-\\epsilon)gs} \\left(\\frac{(1-\\epsilon)gs}{k&#x27;}\\right)^{sg} \\end{array}</span></div>

    <p class="text-gray-300">Using the inequality <span class="math">\\binom{k}{s} \\leq \\left(\\frac{ke}{s}\\right)^s</span>, the probability above is</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\leq \\sum_{s=2}^{\\frac{\\delta k}{s}} \\left(\\frac{ke}{s}\\right)^s \\left(\\frac{k&#x27;e}{(1-\\epsilon)gs}\\right)^{(1-\\epsilon)gs} \\left(\\frac{(1-\\epsilon)gs}{k&#x27;}\\right)^{sg} \\\\ = \\sum_{s=2}^{\\frac{\\delta k}{s}} \\left(\\frac{ke}{s}\\right)^s e^{(1-\\epsilon)gs} \\left(\\frac{(1-\\epsilon)gs}{k&#x27;}\\right)^{\\epsilon gs} \\\\ = \\sum_{s=2}^{\\frac{\\delta k}{s}} e^{(1-\\epsilon)gs+s} \\cdot \\left(\\frac{k}{s}\\right)^s \\cdot \\left(\\frac{(1-\\epsilon)gs}{k&#x27;}\\right)^{\\epsilon gs} \\end{array} \\tag{1}</span></div>

    <p class="text-gray-300">When <span class="math">s, \\epsilon, g</span> are constants and <span class="math">k&#x27; = O(k)</span>, <span class="math">e^{(1-\\epsilon)gs+s}</span> is a constant, <span class="math">\\left(\\frac{k}{s}\\right)^s</span> is <span class="math">O(\\mathsf{poly}(k))</span>, and <span class="math">\\left(\\frac{(1-\\epsilon)gs}{k&#x27;}\\right)^{\\epsilon gs}</span> is <span class="math">O\\left(\\frac{1}{\\mathsf{poly}(k)}\\right)</span>. Therefore, the overall upper bound is at least <span class="math">O\\left(\\frac{1}{\\mathsf{poly}(k)}\\right)</span>.</p>

    <p class="text-gray-300">The derivation above shows that the probability that a random graph is not a lossless expander is upper-bounded by <span class="math">O\\left(\\frac{1}{\\mathrm{poly}(k)}\\right)</span>, which is not negligible. Furthermore, we show that the lower-bound of the non-expanding probability is also not negligible through a simple argument here.</p>

    <p class="text-gray-300">We focus on the case where <span class="math">s</span> is a constant. The number of all possible subgraphs induced by a left subset of vertices <span class="math">S</span> is at most <span class="math">k&#x27;^{sg} = O(\\mathsf{poly}(k))</span>. That is, the size of the entire probability space is bounded by a polynomial. The number of non-expanding graphs is at least 1 (e.g., all edges from <span class="math">S</span> connect to a single vertex in <span class="math">R</span>). Therefore, the non-expanding probability is at least <span class="math">O\\left(\\frac{1}{\\mathsf{poly}(k)}\\right)</span>.</p>

    <p class="text-gray-300"><strong>Lossless expander in [GLS⁺]</strong> As explained in Section 2.1, in [GLS⁺], the authors extended the generalized Spielman code by adding random weights to the edges in the bipartite graph. However, the graph still needs to be a lossless expander in order to achieve a constant relative distance, and the same issue above applies to their construction. In particular, as shown by [GLS⁺, Claim 2], the probability of not sampling a lossless expander is</p>

    <div class="my-4 text-center"><span class="math-block">2^{kH(15/k) + \\alpha kH(19.2/(\\alpha k)) - 15g \\log \\frac{\\alpha k}{19.2}},</span></div>

    <p class="text-gray-300"><span class="math">H(x)=-x\\log x-(1-x)\\log(1-x)</span>. We show that the probability above is not negligible. First, for any constant <span class="math">\\mathsf{const}</span>,</p>

    <p class="text-gray-300"><span class="math">xH(\\mathsf{const}/x)</span> <span class="math">=x(-\\frac{\\mathsf{const}}{x}\\log\\frac{\\mathsf{const}}{x}-(1-\\frac{\\mathsf{const}}{x})\\log(\\frac{x-\\mathsf{const}}{x})</span> <span class="math">=(\\mathsf{const}\\log(x)-\\mathsf{const}\\log\\mathsf{const})+(1-\\frac{\\mathsf{const}}{x})\\log(\\frac{x-\\mathsf{const}}{x}).</span></p>

    <p class="text-gray-300">By taking the limit, we have <span class="math">\\lim_{x\\to\\infty}xH(\\mathsf{const}/x)=(\\mathsf{const}\\log(x)-\\mathsf{const}\\log\\mathsf{const})+1\\times 0</span>. Therefore, <span class="math">xH(\\mathsf{const}/x)=O(\\log x)</span>. Applying this fact to the equation above, <span class="math">kH(15/k)+\\alpha kH(19.2/(\\alpha k))=O(\\log k)</span>, and <span class="math">-15g\\log\\frac{\\alpha k}{19.2}=-O(\\log k)</span>. Therefore, <span class="math">2^{kH(15/k)+\\alpha kH(19.2/(\\alpha k))-15g\\log\\frac{\\alpha k}{19.2}}</span> is at least <span class="math">2^{-O(\\log k)}=\\frac{1}{\\mathsf{poly}(k)}</span>. The failure probability is similar to the upper bound in Equation 1.</p>

    <h3 id="sec-17" class="text-xl font-semibold mt-8">3.2 Algorithm based on Small Set Expansion</h3>

    <p class="text-gray-300">To reduce the non-expanding probability of the random construction, we take a closer look at the equations above. Equation 1 shows that the probability that a random bipartite graph is a not lossless expander is upper bounded by <span class="math">\\frac{1}{\\mathsf{poly}(k)}</span>. However, we observe that within the summation, the probability is actually negligible when <span class="math">s</span> is large. In particular, if we decompose the summation in Equation 1 into two sums, one for <span class="math">2\\leq s\\leq\\log\\log k</span>, and the other for <span class="math">s\\geq\\log\\log k</span>, the second part is</p>

    <p class="text-gray-300"><span class="math">\\sum_{s=\\log\\log k}^{\\frac{\\delta k}{s}}e^{(1-\\epsilon)gs+s}\\cdot(\\frac{k}{s})^{s}\\cdot(\\frac{(1-\\epsilon)gs}{k^{\\prime}})^{\\epsilon gs}.</span> (2)</p>

    <h6 id="sec-18" class="text-base font-medium mt-4">Lemma 3.</h6>

    <p class="text-gray-300">Equation 2 is negligible if the following conditions are met:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">(1-\\epsilon)\\delta+\\frac{\\delta}{g}+\\frac{\\delta}{g}\\log(\\frac{g}{\\delta})+\\log(\\frac{\\delta}{\\alpha})\\epsilon\\delta&lt;-0.001</span>,</li>

      <li><span class="math">\\epsilon d&gt;2</span>.</li>

    </ol>

    <p class="text-gray-300">Here -0.001 is just any small constant that is less than 0. We give a proof in Appendix A. To provide an intuition on how these parameters are set, we give an example here: <span class="math">\\delta=\\frac{1}{11},\\epsilon=\\frac{7}{16},g=16,k^{\\prime}=\\frac{1}{2}k</span>. We can verify the condition:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\epsilon g=7&gt;2</span>.</li>

      <li><span class="math">(1-\\epsilon)\\delta+\\frac{\\delta}{g}+\\frac{\\delta}{g}\\log(\\frac{g}{\\delta})+\\log(\\frac{\\delta}{\\alpha})\\epsilon\\delta=-0.009&lt;-0.001</span>.</li>

    </ol>

    <p class="text-gray-300">Sampling lossless expander with negligible failure probability. The observation above shows that the non-expanding probability is dominated by small sub-graphs with size <span class="math">2\\leq s\\leq\\log\\log k</span>. This actually matches our lower bound in Section 3.1, as there are only polynomially many such sub-graphs and there exist ones that do not expand. Therefore, in order to reduce the non-expanding probability, we propose a new algorithm that detects small sub-graphs of size <span class="math">s\\leq\\log\\log k</span> that do not expand.</p>

    <p class="text-gray-300">The problem is related to the Small Set Bipartite Vertex Expansion problem <em>[x10]</em>, which can further be reduced to the Minimum <span class="math">s</span>-Union problem <em>[CDK^{+}18]</em>, finding <span class="math">s</span>-sets from <span class="math">k</span> sets minimizing the size of their union. The problem is NP-hard in general for <span class="math">s=O(k)</span>, but in our case we only consider very small sets with <span class="math">s\\leq\\log\\log k</span>, and thus it is possible to have an algorithm in polynomial time.</p>

    <h6 id="sec-19" class="text-base font-medium mt-4">Definition 9 (Very Small Set Expansion (VSSE)).</h6>

    <p class="text-gray-300">Let <span class="math">G=(L,R,E)</span> be a bipartite graph. We define the very small set expansion (VSSE) problem as distinguishing following two cases:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">1. Non-expanding case: there exists a subset <span class="math">S\\subset L</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\log\\log k<span class="math"> such that </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><(1-\\varepsilon)g</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We introduce an algorithm for finding such a non-expanding sub-graph. We first demonstrate that if a non-expanding sub-graph exists, then among all such non-expanding sub-graphs, there must be at least one that is both non-expanding and connected. We will then show that this connected sub-graph can be identified using a search algorithm. We say that a graph is connected if there is a path from any point to any other point in the graph.</p>

    <h6 id="sec-20" class="text-base font-medium mt-4">Lemma 4.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">G=(L,R,E)</span> be a bipartite graph. If there exists a subset <span class="math">S\\subset L</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\log\\log k<span class="math"> such that </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><(1-\\varepsilon)g</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, then there exists a connected sub-graph induced by </span>S^{\\prime}\\subset L<span class="math"> with </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\log\\log k<span class="math"> and </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S^{\\prime})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><(1-\\varepsilon)g</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-21" class="text-base font-medium mt-4">Proof.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">If <span class="math">S</span> itself is connected, then we have finished the proof. Otherwise, we divide <span class="math">S</span> into two disjoint parts <span class="math">S_{0},S_{1}</span> such that the induced sub-graphs <span class="math">S_{0}\\cup\\Gamma(S_{0}),S_{1}\\cup\\Gamma(S_{1})</span> are not connected. Let the expansion of <span class="math">S_{0}</span> be $e_{S_{0}}=\\frac{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S_{0})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{0}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">, the expansion of </span>S_{1}<span class="math"> be </span>e_{S_{1}}=\\frac{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S_{1})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{1}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">, then the expansion of </span>S<span class="math"> is </span>e_{S}=\\frac{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}=\\frac{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S_{0})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S_{1})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{0}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{1}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">, as the two sub-graphs are not connected. Next, we show that </span>e_{S_{0}}\\leq e_{S}<span class="math"> or </span>e_{S_{1}}\\leq e_{S}<span class="math"> by contradiction. Suppose both </span>e_{S_{0}}<span class="math"> and </span>e_{S_{1}}<span class="math"> are larger than </span>e_{S}$. Then we have</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$e_{S}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{0}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{1}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S_{0})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S_{1})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">By the assumption, $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S_{0})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=e_{S_{0}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{0}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">>e_{S}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{0}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, thus </span>e_{S}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{0}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S_{0})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><0<span class="math">. Similarly, </span>e_{S}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{1}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Gamma(S_{1})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><0<span class="math"> as well, and their sum cannot equal to </span>0<span class="math"> as in the equation above. Therefore, </span>e_{S_{0}}\\leq e_{S}<span class="math"> or </span>e_{S_{1}}\\leq e_{S}$, i.e., at least one of the sub-graph is non-expanding.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We can repeat this process on the non-expanding sub-graph until we find a connected one. ∎</p>

    <p class="text-gray-300">In order to find such a connected sub-graph that is non-expanding, we need to bound the size of such sub-graphs and thus the search space.</p>

    <p class="text-gray-300">1: Let  <span class="math">G = (L, R, E)</span>  be the random bipartite graph. If  <span class="math">\\exists v \\in R</span>  with degree larger than  <span class="math">\\frac{g}{\\alpha} + 10 \\ln k</span> , abort. 2: for each  <span class="math">v \\in L</span>  do 3: find set  <span class="math">D \\in L</span>  such that:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\forall u\\in D</span>  , the minimum distance between  <span class="math">u</span>  and  <span class="math">v</span>  is  <span class="math">\\leq 2\\log \\log k</span></li>

      <li><span class="math">\\forall u\\in L\\setminus D</span>  , the minimum distance between  <span class="math">u</span>  and  <span class="math">v</span>  is  <span class="math">&amp;gt;2\\log \\log k</span></li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">4: for All  <span class="math">S \\subseteq D</span>  and  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq \\log \\log k$  do</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">6: return Found 7: return Not Found</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Lemma 5. For a random  <span class="math">g</span> -left regular bipartite graph  <span class="math">G = (L, R, E)</span> , the degree of every vertex in  <span class="math">R</span>  is at most  <span class="math">10 \\ln k</span>  with high probability for constant  <span class="math">g</span> ,  $k =</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  and  </span>\\alpha k =</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Proof. Consider a vertex in  <span class="math">R</span> , let a sequence of random variables  <span class="math">X_{i}</span>  be indicator function of the edge between this vertex and the  <span class="math">i</span> -th vertex in  <span class="math">L</span> . Then for a random bipartite graph,  <span class="math">X_{i}</span>  is a Bernoulli random variable with probability  <span class="math">\\frac{g}{\\alpha k}</span> . Let  <span class="math">X = \\sum_{i=1}^{k} X_{i}</span> , by the Chernoff bound,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left(\\frac {X}{k} \\geq \\frac {g}{\\alpha k} + \\frac {1 0 \\ln k}{k}\\right) \\leq e ^ {- D \\left(\\frac {g}{\\alpha k} + \\frac {1 0 \\ln k}{k} \\mid \\mid \\frac {g}{\\alpha k}\\right) k},</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where  $D(x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y) = x\\ln \\frac{x}{y} + (1 - x)\\ln \\frac{1 - x}{1 - y}$  is the Kullback-Leibler (KL) divergence. By the inequality of the KL divergence, we have</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">D (\\frac {g}{\\alpha k} + \\frac {1 0 \\ln k}{k}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\frac {g}{\\alpha k}) \\geq \\frac {(\\frac {g}{\\alpha k} + \\frac {1 0 \\ln k}{k} - \\frac {g}{\\alpha k}) ^ {2}}{2 (\\frac {g}{\\alpha k} + \\frac {1 0 \\ln k}{k})} = \\frac {(\\frac {1 0 \\ln k}{k}) ^ {2}}{2 (\\frac {g}{\\alpha k} + \\frac {1 0 \\ln k}{k})} = \\frac {(1 0 \\ln k) ^ {2}}{2 (\\frac {g k}{\\alpha} + 1 0 k \\ln k)}</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">Therefore,</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\Pr \\left(\\frac {X}{k} \\geq \\frac {g}{\\alpha k} + \\frac {1 0 \\ln k}{k}\\right) \\leq e ^ {- D \\left(\\frac {g}{\\alpha k} + \\frac {1 0 \\ln k}{k} \\mid \\mid \\frac {g}{\\alpha k}\\right) k} \\\\ \\leq e ^ {- \\frac {(1 0 \\ln k) ^ {2}}{2 (\\frac {g}{\\alpha} + 1 0 \\ln k)}} \\leq e ^ {- \\frac {1 0}{2} \\ln k} = k ^ {- \\frac {1 0}{2}} \\\\ \\end{array}</span></div>

    <p class="text-gray-300">when  <span class="math">k</span>  is large, as  <span class="math">2\\left(\\frac{g}{\\alpha} + 10 \\ln k\\right) &amp;lt; 3 \\cdot 10 \\ln k</span> .</p>

    <p class="text-gray-300">Finally, by the union bound, the probability that there exists a vertex in  <span class="math">R</span>  with degree larger than  <span class="math">\\frac{g}{\\alpha} + 10 \\ln k</span>  is less than or equal to</p>

    <div class="my-4 text-center"><span class="math-block">\\alpha k \\cdot \\Pr [ X \\geq \\frac {g}{\\alpha} + 1 0 \\ln k ] = \\alpha k ^ {- \\frac {7}{3}}.</span></div>

    <p class="text-gray-300">□</p>

    <p class="text-gray-300">With these two lemmas, we present our search algorithm in Algorithm 1. In the algorithm, we use a search algorithm to find a non-expanding connected</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">component. First, we enumerate the vertex <span class="math">v\\in L</span>. Suppose <span class="math">v</span> is a vertex belonging to the non-expanding connected component. Then we find the subset <span class="math">D</span> that includes all vertices in <span class="math">L</span> within distance <span class="math">2\\log\\log k</span> of <span class="math">v</span>. The minimum distance between two vertices is defined as the number of edges in the shortest path between them. As we are trying to find non-expanding connected sub-graphs of size <span class="math">\\leq\\log\\log k</span>, any connected sub-graph <span class="math">G^{\\prime}=(L^{\\prime},R^{\\prime},E^{\\prime})</span> with size $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\log\\log k<span class="math"> containing </span>v<span class="math"> must be included in </span>D<span class="math">, as the minimum distance between any vertex in </span>L^{\\prime}<span class="math"> and </span>v<span class="math"> cannot be more than </span>2\\log\\log k<span class="math"> in a bipartite graph. Finally, we enumerate all possible subsets of size </span>\\leq\\log\\log k<span class="math"> in </span>D$ to find if there is a non-expanding sub-graph.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-23" class="text-base font-medium mt-4">Theorem 1.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Algorithm 1 is a polynomial time algorithm for the VSSE problem on a random <span class="math">g</span>-left regular bipartite graph with constant <span class="math">g</span>, $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=k<span class="math"> and </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\alpha k$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">To compute the complexity of the algorithm,</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The size of <span class="math">D</span> is at most <span class="math">(11g\\log k)^{\\log\\log k}</span>, as one vertex in <span class="math">L</span> can at most expand to <span class="math">g\\cdot(\\frac{g}{\\alpha}+10\\log k)&lt;11g\\log k</span> vertices in <span class="math">L</span> in two edges <span class="math">L\\to R\\to L</span>, and there are <span class="math">2\\log\\log k</span> edges.</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">2. By Stirling’s approximation, the number of possible subsets <span class="math">S\\subseteq D</span> and $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\log\\log k$ is at most</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\[ \\sum_{i=1}^{\\log\\log k}\\binom{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">D</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{i}\\leq\\log\\log k(\\frac{e(11g\\log k)^{\\log\\log k}}{\\log\\log k})^{\\log\\log k}=O(\\log k^{\\log\\log^{2}k})=o(k). \\]</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For each <span class="math">S</span>, finding its neighbor set takes at most <span class="math">O(\\log\\log k)</span> time.</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Therefore, the total running time for all $v\\in</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> is </span>o(k^{2}\\log\\log k)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Algorithm 1 gives a way to test whether a random graph is a lossless expander. As discussed in lemma 3, when <span class="math">s\\geq\\log\\log k</span>, the non-expanding probability is negligible. Thus, it suffices to test whether there is a sub-graph of size <span class="math">s&lt;\\log\\log k</span> that does not expand, which can be found by Algorithm 1 as long as the degree of vertices in <span class="math">R</span> is bounded. As shown by Lemma 5, it happens with high probability, thus the expected running time of the testing algorithm is polynomial as well. As long as the testing algorithm outputs Notfound, the graph is a lossless expander with an overwhleming probability by Lemma 3.</p>

    <h2 id="sec-24" class="text-2xl font-bold">4 Our new zero-knowledge argument</h2>

    <p class="text-gray-300">In this section, we present the construction of our zero-knowledge argument scheme. Many existing papers show that one can build zero-knowledge arguments from polynomial commitments <em>[WTS^{+}18, ZXZS20, CHM^{+}20, Set20, GWC19, BFS20, GLS^{+}]</em>. We adopt the same technique and focus on constructing a polynomial commitment because of its simplicity and efficiency, but our approach can be applied directly to the zero-knowledge arguments for R1CS in <em>[BCG20, BCL22]</em> to improve the prover time and the proof size. We start the section by describing the polynomial commitment scheme in <em>[GLS^{+}]</em> based on the tensor IOP protocol in <em>[BCG20]</em> with a proof size of <span class="math">O(\\sqrt{N})</span>.</p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">4.1 Polynomial commitment from tensor query</p>

    <p class="text-gray-300">In <em>[GLS+]</em>, Golovnev et al. observed that a polynomial evaluation can be expressed as a tensor product. Here we only consider multilinear polynomial commitments, which can be used to construct zero-knowledge arguments based on the approaches in <em>[ZGK+17b, WTS+18, XZZ+19, ZXZS20, Set20]</em>, but our scheme can be extended to univariate polynomials. In particular, given a multilinear polynomial <span class="math">\\phi</span>, its evaluation on input vector <span class="math">x_{0},x_{1},...,x_{\\log N-1}</span> is:</p>

    <p class="text-gray-300"><span class="math">\\phi(x_{0},x_{1},...,x_{\\log N-1})=\\sum_{i_{0}=0}^{1}\\sum_{i_{1}=0}^{1}...\\sum_{i_{\\log N-1}=0}^{1}w_{i_{0}i_{1}...i_{\\log N-1}}x_{0}^{i_{0}}x_{1}^{i_{1}}...x_{\\log N-1}^{i_{\\log N-1}}.</span></p>

    <p class="text-gray-300">The degree of each variable is either <span class="math">0</span> or <span class="math">1</span> by the definition of a multilinear polynomial, and thus there are <span class="math">N</span> monomials and coefficients with <span class="math">\\log N</span> variables. We let <span class="math">i=\\sum_{j=0}^{\\log N-1}2^{j}i_{j}</span>, that is, <span class="math">i_{0}i_{1}...i_{\\log N-1}</span> is the binary representation of number <span class="math">i</span>. We use <span class="math">w</span> to denote the coefficients where <span class="math">w[i]=w_{i_{0}i_{1}...i_{\\log N-1}}</span>. Similarly we define <span class="math">X_{i}=x_{0}^{i_{0}}x_{1}^{i_{1}}...x_{\\log N-1}^{i_{\\log N-1}}</span>. Let <span class="math">k=\\sqrt{N}</span>, <span class="math">r_{0}=\\{X_{0},X_{1},...,X_{k-1}\\},r_{1}=\\{X_{0\\times k},X_{1\\times k},X_{2\\times k},...,X_{(k-1)\\times k}\\}</span>. Then we have <span class="math">X=r_{0}\\otimes r_{1}</span>. The polynomial evaluation is reduced to a tensor product <span class="math">\\phi(x_{0},x_{1},...,x_{\\log N-1})=\\langle w,r_{0}\\otimes r_{1}\\rangle</span>. Using the tensor IOP protocol in <em>[BCG20]</em>, one can build a polynomial commitment <em>[GLS+]</em> and we present the protocol in Protocol 2 for completeness. Here we reuse the notation <span class="math">k</span> as it is exactly the message length of the linear code.</p>

    <p class="text-gray-300">As shown in the protocol, to commit to a polynomial, PC.Commit parses the coefficients <span class="math">w</span> as a <span class="math">k\\times k</span> matrix and encodes it using the tensor code with dimension <span class="math">2</span> as defined in Definition 3. Then the algorithm constructs a Merkle tree commitment for every column <span class="math">\\mathsf{C}_{2}[:,i]</span> of the <span class="math">n\\times n</span> codeword <span class="math">\\mathsf{C}_{2}</span>, and finally builds another Merkle tree on top of their roots as the final commitment.</p>

    <p class="text-gray-300">To answer the tensor query, there are two checks in the protocol: a proximity check and a consistency check. The proximity check ensures that the matrix in the commitment is indeed close to a codeword of the tensor code. The consistency check ensures that <span class="math">y=\\langle r_{0}\\otimes r_{1},w\\rangle</span> assuming <span class="math">\\mathcal{R}</span> is a commitment of a codeword.</p>

    <p class="text-gray-300"><em>Proximity check.</em> The proximity check has two steps. First, the verifier sends a random vector <span class="math">\\gamma_{0}</span> to the prover, and the prover computes the linear combination of all rows of <span class="math">\\mathsf{C}_{1}</span> and <span class="math">w</span> with <span class="math">\\gamma_{0}</span>, as in Step 8 in Protocol 2. Because of the property of a linear code, <span class="math">c_{\\gamma_{0}}</span> is a codeword with message <span class="math">y_{\\gamma_{0}}</span>, and this step is referred to as the “fold” operation in <em>[BCG20]</em>. Second, the prover shows that <span class="math">c_{\\gamma_{0}}</span> is indeed computed from the committed tensor codeword. To do so, the verifier randomly selects <span class="math">t</span> columns and the prover opens them with their Merkle tree proofs. The verifier checks that the inner product between each column and the random vector <span class="math">\\gamma_{0}</span> is equal to the corresponding element of <span class="math">c_{\\gamma_{0}}</span> (Step 15). As shown in <em>[BCG+17, BCG20]</em>, if the linear code has a constant relative distance, the committed matrix is close to a tensor codeword with overwhelming probability.</p>

    <p class="text-gray-300"><em>Consistency check.</em> The consistency check follows exactly the same steps of the proximity check. Instead of using a random vector from the verifier, the linear combination is done with <span class="math">r_{0}</span> of the tensor query <span class="math">r_{0}\\otimes r_{1}</span>. Similarly, <span class="math">c_{1}</span> is a codeword</p>

    <p class="text-gray-300">Protocol 2 Polynomial commitment from [BCG20, GLS+] Public input: The evaluation point <span class="math">\\vec{x}</span>, parsed as a tensor product <span class="math">r = r_0 \\otimes r_1</span>; Private input: the polynomial <span class="math">\\phi</span>, the coefficient of <span class="math">\\phi</span> is denoted by <span class="math">w</span>. Let <span class="math">C</span> be the <span class="math">[n, k, d]</span>-linear code, <span class="math">E_C : \\mathbb{F}^k \\to \\mathbb{F}^n</span> be the encoding function, <span class="math">N = k \\times k</span>. If <span class="math">N</span> is not a perfect square, we can pad it to the next perfect square. We use a python style notation to select the <span class="math">i</span>-th column of a matrix <span class="math">\\mathsf{mat}[:, i]</span>. 1: function PC.COMMIT(<span class="math">\\phi</span>) 2: Parse <span class="math">w</span> as a <span class="math">k \\times k</span> matrix. The prover computes the tensor code encoding <span class="math">C_1, C_2</span> locally as defined in Definition 3. Here <span class="math">C_1</span> is a <span class="math">k \\times n</span> matrix and <span class="math">C_2</span> is a <span class="math">n \\times n</span> matrix. 3: for <span class="math">i \\in [n]</span> do 4: Compute the Merkle tree root <span class="math">\\mathsf{Root}_i = \\mathsf{Merkle.Commit}(C_2[:, i])</span>. 5: Compute a Merkle tree root <span class="math">\\mathcal{R} = \\mathsf{Merkle.Commit}([\\mathsf{Root}_0, ..., \\mathsf{Root}_{n-1}])</span> and output <span class="math">\\mathcal{R}</span> as the commitment. 6: function PC.PROVE(<span class="math">\\phi, \\vec{x}, \\mathcal{R}</span>) 7: The prover receives a random vector <span class="math">\\gamma_0 \\in \\mathbb{F}^k</span> from the verifier. 8: <span class="math">c_{\\gamma_0} = \\sum_{i=0}^{k-1} \\gamma_0[i] C_1[i], y_{\\gamma_0} = \\sum_{i=0}^{k-1} \\gamma_0[i] w[i]</span>. ▷ Proximity 9: <span class="math">c_1 = \\sum_{i=0}^{k-1} r_0[i] C_1[i], y_1 = \\sum_{i=0}^{k-1} r_0[i] w[i]</span>. ▷ Consistency 10: Prover sends <span class="math">c_1, y_1, c_{\\gamma_0}, y_{\\gamma_0}</span> to the verifier. 11: Verifier randomly samples <span class="math">t \\in [n]</span> indexes as an array <span class="math">\\hat{I}</span> and send it to prover. 12: for <span class="math">\\mathrm{idx} \\in \\hat{I}</span> do 13: Prover sends <span class="math">C_1[:, \\mathrm{idx}]</span> and the Merkle tree proof of <span class="math">\\mathsf{Root}_{\\mathrm{idx}}</span> for <span class="math">C_2[:, \\mathrm{idx}]</span> under <span class="math">\\mathcal{R}</span> to verifier 14: function PC.VERIFYEVAL(<span class="math">\\pi_{\\vec{x}}, \\vec{x}, y = \\phi(\\vec{x}), \\mathcal{R}</span>) 15: <span class="math">\\forall \\mathrm{idx} \\in \\hat{I}, c_{\\gamma_0}[\\mathrm{idx}] == \\langle \\gamma_0, C_1[:, \\mathrm{idx}] \\rangle</span> and <span class="math">E_C(y_{\\gamma_0}) == c_{\\gamma_0}</span>. ▷ Proximity 16: <span class="math">\\forall \\mathrm{idx} \\in \\hat{I}, c_1[\\mathrm{idx}] == \\langle r_0, C_1[:, \\mathrm{idx}] \\rangle</span> and <span class="math">E_C(y_1) == c_1</span>. ▷ Consistency 17: <span class="math">y == \\langle r_1, y_1 \\rangle</span>. ▷ Tensor product 18: <span class="math">\\forall \\mathrm{idx} \\in \\hat{I}, E_C(C_1[:, \\mathrm{idx}])</span> is consistent with <span class="math">\\mathsf{Root}_{\\mathrm{idx}}</span>, and <span class="math">\\mathsf{Root}_{\\mathrm{idx}}</span>'s Merkle tree proof is valid. 19: Output accept if all conditions above holds. Otherwise output reject.</p>

    <p class="text-gray-300">of the linear code with message <span class="math">y_{1}</span>, and <span class="math">\\phi(x) = \\langle y_{1}, r_{1} \\rangle</span> by the definition of tensor product and polynomial evaluation. As shown in [BCG20], by the check in Step 16, if the committed matrix in <span class="math">\\mathcal{R}</span> is close to a tensor codeword, then <span class="math">y = \\phi(x)</span> with overwhelming probability. In particular, there exist an extractor to extract a polynomial <span class="math">\\phi</span> from the commitment such that <span class="math">y = \\phi(x)</span>.</p>

    <p class="text-gray-300">Theorem 2 (Polynomial commitment [BCG20, GLS+]). Protocol 2 is a polynomial commitment that is correct and sound as defined in Definition 8.</p>

    <p class="text-gray-300">Efficiency. The prover's computation is dominated by encoding the tensor code, which takes <span class="math">O(N)</span> time using a linear-time encodable code such as the generalized Spielman code. The proof size is <span class="math">O(t\\sqrt{N})</span>, as the prover opens <span class="math">t</span> random columns of size <span class="math">\\sqrt{N}</span> to the verifier. The verifier time is also <span class="math">O(t\\sqrt{N})</span> to check the inner products and to encode <span class="math">t</span> columns.</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Fig. 2: An illustration of code switching. The circuit on the right for Check 1,2 and Check 3,4 are the same.</p>

    <p class="text-gray-300">The proof size of the polynomial commitment in Protocol 2 is  <span class="math">O(\\sqrt{N})</span>  (the complexity hides a security parameter  <span class="math">t</span> ). There are three steps that incur  <span class="math">O(\\sqrt{N})</span>  proof size in Protocol 2: Step 8, 9, and 13. In this section, we present a new protocol that reduces the proof size to  <span class="math">O(\\log^2 N)</span>  via the technique of proof composition. The idea is to use a second proof system to prove that the checks of these three steps are satisfied, without sending the proofs of these steps to the verifier directly.</p>

    <p class="text-gray-300">To design the second proof system efficiently, our key observation is that the values sent by the prover in these three steps are messages of the linear-time encodable code. That is,  <span class="math">y_{\\gamma_0}</span>  is the message of  <span class="math">c_{\\gamma_0}</span>  in Step 8,  <span class="math">y_1</span>  is the message of  <span class="math">c_1</span>  in Step 9 and  <span class="math">C_1[:, \\mathrm{idx}]</span>  is the message of  <span class="math">C_2[:, \\mathrm{idx}]</span>  for every  <span class="math">\\mathrm{idx}</span>  in Step 13. Therefore, the second proof system takes  <span class="math">y_{\\gamma_0}, y_1</span>  and  <span class="math">C_1[:, \\mathrm{idx}]</span>  for  <span class="math">\\mathrm{idx} \\in I</span>  as the witness, and performs the following computations:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>It encodes the witness using the encoding circuit of the linear-time encodable code.</li>

      <li>It outputs a subset of random indices of the codewords chosen by the verifier. By checking whether the values of these indices are consistent with the commitments by the prover via the Merkle tree, it guarantees that the witness is indeed the same as the messages specified above with overwhelming probability because of the minimum distance property of the code.</li>

      <li>Finally, it checks that these messages and their codewords satisfy the conditions in line 15, 16 and 17 of Protocol 2.</li>

    </ol>

    <p class="text-gray-300">Protocol 3 Code Switching Statement  <span class="math">C_{\\mathrm{CS}}</span></p>

    <pre><code class="language-txt">Witness:  $y_{\\gamma_0},y_1,\\mathsf{C}_1[:,i\\mathsf{dx}]\\forall i\\mathsf{dx}\\in \\hat{I}$  in Protocol 2. Public input:  $\\gamma_0,r_0,r_1,y$  . Public information:  $\\hat{I}$  and  $I$  chosen by the verifier.
1: Encode  $c_{\\gamma_0}\\coloneqq E_C(y_{\\gamma_0})$ $c_{1}\\coloneqq E_{C}(y_{1})$
2: for  $\\mathsf{idx}\\in \\hat{I}$  do
3: Encode  $\\mathsf{C}_2[:,i\\mathsf{dx}]\\coloneqq E_C(\\mathsf{C}_1[:,i\\mathsf{dx})$
4: for  $\\mathsf{idx}\\in \\hat{I}$  do
5: Check if  $c_{\\gamma_0}[\\mathsf{idx}] = = \\langle \\gamma_0,\\mathsf{C}_1[:,i\\mathsf{dx}]\\rangle .$  ▷Proximity
6: Check if  $c_{1}[\\mathsf{idx}] = = \\langle r_{0},\\mathsf{C}_{1[:,i\\mathsf{dx}]}\\rangle .$  ▷Consistency
7: Check if  $\\langle r_1,y_1\\rangle = = y.$  ▷Tensor product
8: for  $\\mathsf{idx}\\in \\hat{I}$  do ▷Encoder check
9: Output  $c_{1}[\\mathsf{idx}]$ $c_{\\gamma_0}[\\mathsf{idx}]$
10: for  $0\\leq j &amp;lt;   |I|$  do
11: Output  $\\mathsf{C}_2[I[j],i\\mathsf{dx}]$</code></pre>

    <p class="text-gray-300">The idea is illustrated in Figure 2, and we formally present the statement of the second proof system in Protocol 3. Note that  <span class="math">\\hat{I}</span>  is the random set chosen by the verifier in Protocol 2, and is only used as a notation for the subscripts in Protocol 3.  <span class="math">I</span>  is the random set chosen by the verifier for the code switching. In this way, we switch the message encoded using the linear-time encodable code to the witness of the second proof system. In our implementation, we are using an IOP-based zero-knowledge argument with the Reed-Solomon code, thus this can be viewed as an efficient instantiation of the "code switching" technique in [RR20].</p>

    <p class="text-gray-300">We apply any CP-SNARK  <span class="math">\\mathcal{Z}\\mathcal{K}</span>  on the statement and then check the consistency between the output and the Merkle tree commitment  <span class="math">\\mathcal{R}</span>  of the codeword of the linear-time encodable code. The use of CP-SNARK was first proposed in [CBBZ23]. We present the new protocol in Protocol 4 and highlight the differences from Protocol 2 in blue. As shown in the protocol, instead of sending  <span class="math">c_{1},y_{1},c_{\\gamma_{0}},y_{\\gamma_{0}}</span> , the prover commits to  <span class="math">c_{1}</span>  and  <span class="math">c_{\\gamma_0}</span>  in Step 8 and 9. The codeword  <span class="math">\\mathsf{C}_2</span>  was already committed column-wise in  <span class="math">\\mathcal{R}</span> . The prover then proves the constraints of  <span class="math">c_{1},y_{1},c_{\\gamma_{0}},y_{\\gamma_{0}}</span>  and  <span class="math">\\mathsf{C}_1[:,i\\mathsf{dx}]</span>  using the code switching technique in Step 14. In this way, we are able to reduce the proof size of Protocol 2 to  <span class="math">O(\\log^2 N)</span> .</p>

    <p class="text-gray-300">Theorem 3. Protocol 4 is a polynomial commitment that is correct and sound, as defined in Definition 8 without zero-knowledge property.</p>

    <p class="text-gray-300">The proof is presented in Appendix B.</p>

    <p class="text-gray-300">Complexity of Protocol 4. The prover time remains  <span class="math">O(N)</span> . This is because in Step 8 and 9, the prover additionally commits to  <span class="math">c_{1}, c_{\\gamma_{0}}</span> , which only takes  <span class="math">O(n) = O(\\sqrt{N})</span>  time. In Step 14, the prover invokes another CP-SNARK on  <span class="math">C_{\\mathsf{CS}}</span> .  <span class="math">C_{\\mathsf{CS}}</span>  consists of  <span class="math">t + 2</span>  encoding circuits  <span class="math">E_{C}</span>  of the linear-time encodable code and  <span class="math">t + 2</span>  inner products. In Appendix C, we show that the encoding circuit of the generalized Spielman code is of size  <span class="math">O(k)</span> . The circuit to compute an inner</p>

    <p class="text-gray-300">Protocol 4 Polynomial commitment with code-switching Public input: The evaluation point <span class="math">\\vec{x}</span>, parsed as a tensor product <span class="math">r = r_0 \\otimes r_1</span>; Private input: the polynomial <span class="math">\\phi</span> with coefficients <span class="math">w</span>. 1: function COMMIT(<span class="math">\\phi</span>) 2: Parse <span class="math">w</span> as a <span class="math">k \\times k</span> matrix. The prover computes the tensor code encoding <span class="math">C_1, C_2</span> locally as defined in Definition 3. 3: for <span class="math">i \\in [n]</span> do 4: Compute the Merkle tree root Root<span class="math">_i</span> = Merkle.Commit(<span class="math">C_2[:, i]</span>). 5: Compute a Merkle tree root <span class="math">\\mathcal{R}</span> = Merkle.Commit(<span class="math">[\\text{Root}_0, ..., \\text{Root}_{n-1}]</span>) and output <span class="math">\\mathcal{R}</span> as the commitment. 6: function PROVE(<span class="math">\\phi, \\vec{x}, \\mathcal{R}</span>) 7: The prover receives a random vector <span class="math">\\gamma_0 \\in \\mathbb{F}^k</span> from the verifier. 8: <span class="math">c_1 = \\sum_{i=0}^{k-1} r_0[i] C_1[i], y_1 = \\sum_{i=0}^{k-1} r_0[i] w[i], \\mathcal{R}_{c_1} = \\text{Merkle.Commit}(c_1)</span> 9: <span class="math">c_{\\gamma_0} = \\sum_{i=0}^{k-1} \\gamma_0[i] C_1[i], y_{\\gamma_0} = \\sum_{i=0}^{k-1} \\gamma_0[i] w[i], \\mathcal{R}_{\\gamma_0} = \\text{Merkle.Commit}(c_{\\gamma_0})</span> 10: The prover computes the answer <span class="math">y := \\langle y_1, r_1 \\rangle</span>. Prover sends <span class="math">\\mathcal{R}_{c_1}, \\mathcal{R}_{\\gamma_0}, y</span> to the verifier. 11: The verifier randomly samples <span class="math">t \\in [n]</span> indexes as an array <span class="math">\\hat{I}</span> and sends it to prover. 12: The prover commits to the witness of the relationship <span class="math">C_{\\mathbb{C}S}</span> using the CP-SNARK <span class="math">\\mathcal{ZK}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">13: The verifier randomly samples another index set $I \\subseteq [n],</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">I</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= t$ and sends it to the prover.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">14: The prover calls the zero-knowledge argument protocol <span class="math">\\mathcal{ZK.P}</span> on <span class="math">C_{\\mathbb{C}S}</span>. Let <span class="math">\\pi_{zk}</span> be the proof of the zero-knowledge argument. The prover sends the output of <span class="math">C_{\\mathbb{C}S}</span>: <span class="math">C_2[I[j], \\mathrm{idx}], c_1[\\mathrm{idx}], c_{\\gamma_0}[\\mathrm{idx}] \\ \\forall \\mathrm{idx} \\in \\hat{I}, j \\in I</span> and <span class="math">\\pi_{zk}</span> to the verifier. 15: The prover sends the Merkle tree proofs of <span class="math">C_2[I[j], \\mathrm{idx}] \\ \\forall \\mathrm{idx} \\in \\hat{I}</span> under Rootidx. 16: The prover sends the Merkle tree proofs of Rootidx <span class="math">\\forall \\mathrm{idx} \\in \\hat{I}</span> under <span class="math">\\mathcal{R}</span>. 17: The prover sends the Merkle tree proofs of <span class="math">c_1[\\mathrm{idx}], c_{\\gamma_0}[\\mathrm{idx}]</span> under <span class="math">\\mathcal{R}_{c_1}, \\mathcal{R}_{c_{\\gamma_0}}</span>. 18: function VERIFYEval(<span class="math">\\pi_{\\vec{x}}, \\vec{x}, y = \\phi(\\vec{x}), \\mathcal{R}</span>) 19: The verifier calls the zero-knowledge argument protocol <span class="math">\\mathcal{ZK.V}</span> on <span class="math">C_{\\mathbb{C}S}</span>. 20: The verifier checks the Merkle tree proofs of <span class="math">C_2[I[j], \\mathrm{idx}] \\ \\forall \\mathrm{idx} \\in \\hat{I}</span>. 21: The verifier checks the Merkle tree proofs of Rootidx <span class="math">\\forall \\mathrm{idx} \\in \\hat{I}</span> using <span class="math">\\mathcal{R}</span>. 22: The verifier checks the Merkle tree proofs of <span class="math">c_1[\\mathrm{idx}], c_{\\gamma_0}[\\mathrm{idx}]</span> using <span class="math">\\mathcal{R}_{c_1}, \\mathcal{R}_{c_{\\gamma_0}}</span>. 23: Output accept if all checks pass. Otherwise output reject.</p>

    <p class="text-gray-300">product is of size <span class="math">O(k)</span>, thus the overall circuit size is <span class="math">O(t \\cdot k)</span>. By using any CP-SNARK scheme with a quasi-linear prover time, the prover time of this step is <span class="math">O(t \\cdot k \\log k)</span>. Since <span class="math">k = \\sqrt{N}</span>, the prover time is still <span class="math">O(N)</span> dominated by the encoding and the commitment of the <span class="math">k \\times k</span> matrix. With the code switching technique, the proof size and becomes <span class="math">O(t \\log^2 N)</span>.</p>

    <p class="text-gray-300">Since we apply <span class="math">\\mathcal{ZK}</span> in a black-box way, the verification time of the protocol will be <span class="math">O(\\sqrt{N})</span> due to the size of recursive circuit.</p>

    <p class="text-gray-300">22</p>

    <p class="text-gray-300">4.3 Putting Everything Together</p>

    <p class="text-gray-300">In this section, we show how to achieve zero-knowledge on top of our new polynomial commitment in Protocol 4, and sketch how to build a zero-knowledge argument using the polynomial commitment.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Achieving zero-knowledge. We apply a masking technique similar to the one in <em>[BCG^{+}17]</em>. The codeword <span class="math">\\mathsf{C}_{1}</span> is replaced by a randomized encoding by setting $\\mathsf{C^{\\prime}}_{1}[i]=(E_{C}(w[i])+\\mathbf{r}_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{r}_{i})<span class="math"> for </span>i\\in[k]<span class="math">, where </span>\\mathbf{r_{i}}<span class="math"> is a random vector of size </span>n<span class="math"> chosen by the prover and </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> denotes concatenation. Now each codeword is of length </span>2n<span class="math"> and a value at index </span>j<span class="math"> looks uniformly random if the value at </span>j+n<span class="math"> is not revealed. Therefore, the verifier now samples the opening set </span>\\hat{I}\\subset[2n]<span class="math"> such that </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\hat{I}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=2t,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\hat{I}\\cap[n]</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=t,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\hat{I}\\setminus[n]</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=t<span class="math"> and there is no </span>i\\in\\hat{I}<span class="math"> such that </span>i+n\\in\\hat{I}<span class="math">. In addition, to compute the randomized encoding, we revise the statement of the second ZKP in Protocol 6. The rest of the protocol remains mostly the same. We present the protocol in Protocol 5 and the differences from the polynomial commitment scheme without ZK are highlighted in blue. Note that in <em>[BCG^{+}17]</em>, the prover also needs to add a random row to </span>\\mathsf{C^{\\prime}}_{1}<span class="math"> in order to eliminate the leakage of </span>c_{\\gamma_{0}}<span class="math">, the linear combination in the proximity test. Our protocol is even simpler without this random row, as </span>c_{\\gamma_{0}}$ is not sent to the verifier at all, but is computed in the second ZKP.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-26" class="text-base font-medium mt-4">Theorem 4.</h6>

    <p class="text-gray-300">Protocol 5 is a zero-knowledge polynomial commitment scheme by definition 8.</p>

    <p class="text-gray-300">We present the proof in Appendix D.</p>

    <p class="text-gray-300">Zero-knowledge argument. Finally, we build our zero-knowledge argument system by combining the multivariate polynomial commitment with the sumcheck protocol as in <em>[x23, x13]</em>. We state the theorem here and refer the readers to <em>[x23, x13]</em> for the construction and the proof.</p>

    <h6 id="sec-27" class="text-base font-medium mt-4">Theorem 5.</h6>

    <p class="text-gray-300">There exists a zero-knowledge argument scheme by definition 6 with <span class="math">O(N)</span> prover time, <span class="math">O(\\log^{2}N)</span> proof size and <span class="math">O(N)</span> verifier time.</p>

    <p class="text-gray-300">As we are using the IOP-based scheme in <em>[x29]</em> as the second zero-knowledge argument in the proof composition, our scheme is an IOP with a linear proof size and logarithmic query complexity. The scheme can be made non-interactive via the Fiat-Shamir <em>[x12]</em> heuristic, and has plausible post-quantum security.</p>

    <h2 id="sec-28" class="text-2xl font-bold">5 Experiments</h2>

    <p class="text-gray-300">We have implemented our scheme, Orion, and we present the evaluations of the system and the comparions to existing ZKP schemes in this section.</p>

    <p class="text-gray-300">Protocol 5 zk-Polynomial commitment</p>

    <p class="text-gray-300">Public input: The evaluation point <span class="math">\\vec{x}</span>, parsed as a tensor product <span class="math">r = r_0 \\otimes r_1</span>; Private input: the polynomial <span class="math">\\phi</span> with coefficients <span class="math">w</span>.</p>

    <p class="text-gray-300">1: function COMMIT(<span class="math">\\phi</span>)</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">2: Parse <span class="math">w</span> as a <span class="math">k \\times k</span> matrix. The prover computes the randomized encoding <span class="math">C_1&#x27;</span> as $C_1'[i] = (E_C(w[i]) + r_i)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">r_i<span class="math"> for </span>i \\in [k]<span class="math">, where each </span>r_i<span class="math"> is a random vector of size </span>n<span class="math"> chosen by the prover and the size of </span>C_1'<span class="math"> is </span>k \\times 2n<span class="math">. The prover computes </span>C_2<span class="math"> by encoding each column of </span>C_1'<span class="math"> and the size is </span>n \\times 2n$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">3: for <span class="math">i \\in [2n]</span> do</p>

    <p class="text-gray-300">4: Compute the Merkle tree root <span class="math">\\mathsf{Root}_i = \\mathsf{Merkle.Commit}(C_2[:,i])</span>.</p>

    <p class="text-gray-300">5: Compute a Merkle tree root <span class="math">\\mathcal{R} = \\text{Merkle.Commit}([Root_0, ..., Root_{2n-1}])</span> and output <span class="math">\\mathcal{R}</span> as the commitment.</p>

    <p class="text-gray-300">6: function PROVE(<span class="math">\\phi, \\vec{x}, \\mathcal{R}</span>)</p>

    <p class="text-gray-300">7: The prover receives a random vector <span class="math">\\gamma_0 \\in \\mathbb{F}^k</span> from the verifier.</p>

    <p class="text-gray-300">8: <span class="math">c_1 = \\sum_{i=0}^{k-1} r_0[i] C_1&#x27;[i], y_1 = \\sum_{i=0}^{k-1} r_0[i] w[i], \\mathcal{R}_{c_1} = \\text{Merkle.Commit}(c_1)</span></p>

    <p class="text-gray-300">9: <span class="math">c_{\\gamma_0} = \\sum_{i=0}^{k-1} \\gamma_0[i] C_1&#x27;[i], y_{\\gamma_0} = \\sum_{i=0}^{k-1} \\gamma_0[i] w[i], \\mathcal{R}_{\\gamma_0} = \\text{Merkle.Commit}(c_{\\gamma_0})</span></p>

    <p class="text-gray-300">10: The prover computes the answer <span class="math">y := \\langle y_1, r_1 \\rangle</span>. Prover sends <span class="math">\\mathcal{R}_{c_1}, \\mathcal{R}_{\\gamma_0}, y</span> to the verifier.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">11: The verifier randomly samples <span class="math">\\hat{I} \\subset [2n]</span> indexes such that $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\hat{I}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= 2t,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\hat{I} \\cap [n]</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= t,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\hat{I} \\setminus [n]</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= t<span class="math"> and there is no </span>i \\in \\hat{I}<span class="math"> such that </span>i + n \\in \\hat{I}<span class="math">. The verifier sends </span>\\hat{I}$ to the prover.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">12: The prover commits to the witness of the relationship <span class="math">C_{\\mathsf{CS}}</span> using the CP-SNARK <span class="math">\\mathcal{ZK}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">13: The verifier randomly samples another index set $I \\subseteq [n],</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">I</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= t$ and sends it to the prover.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">14: The prover calls the zero-knowledge argument protocol <span class="math">\\mathcal{ZK.P}</span> on <span class="math">C_{\\mathsf{CS}}</span>. In line 1 of Protocol 6, in order to compute the randomized encoding of <span class="math">y_{\\gamma_0}</span> and <span class="math">y_1</span>, the prover provides <span class="math">\\sum_{i=0}^{k-1} r_0[i] \\mathbf{r}_i</span> and <span class="math">\\sum_{i=0}^{k-1} \\gamma_0[i] \\mathbf{r}_i</span> as witness as well. Let <span class="math">\\pi_{zk}</span> be the proof of the zero-knowledge argument. The prover sends the output of <span class="math">C_{\\mathsf{CS}}</span>: <span class="math">\\mathsf{C}_2[I[j], \\mathsf{idx}], c_1[\\mathsf{idx}], c_{\\gamma_0}[\\mathsf{idx}] \\ \\forall \\mathsf{idx} \\in \\hat{I}, j \\in I</span> and <span class="math">\\pi_{zk}</span> to the verifier.</p>

    <p class="text-gray-300">15: The prover sends the Merkle tree proofs of <span class="math">\\mathsf{C}_2[I[j], \\mathrm{idx}] \\ \\forall \\mathrm{idx} \\in \\hat{I}</span> under <span class="math">\\mathsf{Root}_{\\mathrm{idx}}</span>.</p>

    <p class="text-gray-300">16: The prover sends the Merkle tree proofs of <span class="math">\\mathsf{Root}_{\\mathrm{idx}} \\ \\forall \\mathrm{idx} \\in \\hat{I}</span> under <span class="math">\\mathcal{R}</span>.</p>

    <p class="text-gray-300">17: The prover sends the Merkle tree proofs of <span class="math">c_1[\\mathrm{idx}], c_{\\gamma_0}[\\mathrm{idx}]</span> under <span class="math">\\mathcal{R}_{c_1}, \\mathcal{R}_{c_{\\gamma_0}}</span>.</p>

    <p class="text-gray-300">18: function VERIFYEVAL(<span class="math">\\pi_{\\vec{x}}, \\vec{x}, y = \\phi(\\vec{x}), \\mathcal{R}</span>)</p>

    <p class="text-gray-300">19: The verifier calls the zero-knowledge argument protocol <span class="math">\\mathcal{ZK.V}</span> on <span class="math">C_{\\mathsf{CS}}</span>.</p>

    <p class="text-gray-300">20: The verifier checks the Merkle tree proofs of <span class="math">\\mathsf{C}_2[I[j], \\mathrm{idx}] \\ \\forall \\mathrm{idx} \\in \\hat{I}</span>.</p>

    <p class="text-gray-300">21: The verifier checks the Merkle tree proofs of <span class="math">\\mathsf{Root}_{\\mathrm{idx}} \\ \\forall \\mathrm{idx} \\in \\hat{I}</span> using <span class="math">\\mathcal{R}</span>.</p>

    <p class="text-gray-300">22: The verifier checks the Merkle tree proofs of <span class="math">c_1[\\mathrm{idx}], c_{\\gamma_0}[\\mathrm{idx}]</span> using <span class="math">\\mathcal{R}_{c_1}, \\mathcal{R}_{c_{\\gamma_0}}</span>.</p>

    <p class="text-gray-300">23: Output accept if all checks pass. Otherwise output reject.</p>

    <p class="text-gray-300">Settings and parameters. Our polynomial commitment scheme is implemented in C++ with 6000 lines of code. The proof composition uses Virgo in [ZXZS20] and its open-source implementation. We combine the polynomial commitment with a sumcheck protocol to get our zero-knowledge argument following the approach in [Set20] and we implement our own code for this part.</p>

    <p class="text-gray-300">Protocol 6 Code Switching Statement  <span class="math">C_{\\mathrm{CS}}</span>  with ZK</p>

    <pre><code class="language-txt">Witness:  $y_{\\gamma_0},y_1,\\mathsf{C}_1[:,i\\mathrm{dx}]\\forall i\\mathrm{dx}\\in \\hat{I},\\mathbf{r}_{r_0} = \\sum_{i = 1}^{k}r_0[i]\\mathbf{r}_i$  and  $\\mathbf{r}_{\\gamma_0} = \\sum_{i = 1}^{k}\\gamma_{0}[i]\\mathbf{r}_{i}$  Public input:  $\\gamma_0,r_0,r_1,y$  Public information:  $\\hat{I}$  and  $I$  chosen by the verifier.
1: Encode  $c_{\\gamma_0}\\coloneqq E_C(y_{\\gamma_0}) + \\mathbf{r}_{\\gamma_0}||\\mathbf{r}_{\\gamma_0},c_1\\coloneqq E_C(y_1) + \\mathbf{r}_{r_0}||\\mathbf{r}_{r_0}.$
2: for  $\\mathrm{idx}\\in \\hat{I}$  do
3: Encode  $\\mathsf{C}_2[:,i\\mathrm{dx}]\\coloneqq E_C(\\mathsf{C}_1[:,i\\mathrm{dx})$
4: for  $\\mathrm{idx}\\in \\hat{I}$  do
5: Check if  $c_{\\gamma_0}[\\mathrm{idx}] = = \\langle \\gamma_0,\\mathsf{C}_1[:,i\\mathrm{dx}]\\rangle .$  ▷Proximity
6: Check if  $c_{1}[\\mathrm{idx}] = = \\langle r_{0},\\mathsf{C}_{1[:,i\\mathrm{dx}]}\\rangle .$  ▷Consistency
7: Check if  $\\langle r_1,y_1\\rangle = = y.$  ▷Tensor product
8: for  $\\mathrm{idx}\\in \\hat{I}$  do ▷Encoder check
9: Output  $c_{1}[\\mathrm{idx}],c_{\\gamma_{0}}[\\mathrm{idx}].$
10: for  $0\\leq j &amp;lt;   |I|$  do
11: Output  $\\mathsf{C}_2[I[j],i\\mathrm{dx}]$</code></pre>

    <p class="text-gray-300">Expander graph used in our implementation We use a modified version of generalized Spielman code in  <span class="math">\\left[\\mathrm{GLS}^{+}\\right]</span> . The code assigns a random weight to each edge of the expander graph, achieving a better minimum distance. We take a step further and fine-tune the dimensions more aggressively. With our testing algorithm, the failure probability of the expander sampling remains negligible. There are two types of expander graph used in our construction and the parameters are  <span class="math">G_{1}</span> :  <span class="math">\\alpha = 0.33</span> ,  <span class="math">\\delta = 0.6</span> ,  <span class="math">\\epsilon = 0.78</span> ,  <span class="math">g = 6</span> ;  <span class="math">G_{2}</span> :  <span class="math">\\alpha = 0.337</span> ,  <span class="math">g = 6</span> ,  <span class="math">\\delta = g</span> ,  <span class="math">\\epsilon = 0.88</span> .</p>

    <p class="text-gray-300">Parameters of our linear code. With expanders above, the final relative distance is 0.055. We set the security parameter  <span class="math">\\lambda = 128</span> . This leads to opening  <span class="math">t = \\frac{-128}{\\log(1 - 0.055)} = 1568</span>  columns and locations in Protocol 4.</p>

    <p class="text-gray-300">Hash function and finite field. We use the SHA-256 hash function implemented by [arm]. We use the extension field of  <span class="math">\\mathrm{GF}((2^{61} - 1)^2)</span>  as our underlying field to be compatible with the zero-knowledge argument in [ZXZS20].</p>

    <p class="text-gray-300">Environment and method. We use an AWS m6i-32xlarge instance with Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz CPU and 512GB memory to execute all of our experiments. However, the largest instance in our experiment only utilize 16 GB of memory. All experiments are using a single thread except the expander testing algorithm. For each data point, we run the experiments 10 times and report the average.</p>

    <p class="text-gray-300">In this section, we report the performance of our polynomial commitment scheme and compare it with the scheme Brakedown in  <span class="math">\\left[\\mathrm{GLS}^{+}\\right]</span> , which is the only implemented polynomial commitment scheme with a linear prover time. We use the open-source implementation of Brakedown at [Wla] in the comparison. Our current implementation is for the plain version of the polynomial commitment without zero-knowledge, which is the same as Brakedown.</p>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a></p>

    <p class="text-gray-300">!<a href="img-3.jpeg">img-3.jpeg</a></p>

    <p class="text-gray-300">!<a href="img-4.jpeg">img-4.jpeg</a> Fig. 3: Performance of polynomial commitments.</p>

    <p class="text-gray-300">Figure 3 shows the performance of our polynomial commitment and the polynomial commitment in Brakedown. We vary the size of the polynomials from  <span class="math">2^{15}</span>  to  <span class="math">2^{29}</span>  and measure the prover time, the proof size and the verifier time. As shown in the figure, our prover time is even slightly faster than Brakedown. It only takes 115 seconds for a polynomial with  <span class="math">2^{27}</span>  coefficients, while it is 132 seconds in Brakedown. This is because we use more aggressive parameters of the expander code, while still achieving 128-bit of security thanks to our expander testing algorithm. Moreover, the additional proof composition in our scheme involves a second zero-knowledge argument on a circuit of size  <span class="math">O(\\sqrt{N})</span> . In our experiments, this extra zero-knowledge argument takes less than  <span class="math">20\\%</span>  of the total prover time, justifying that our code switching technique only introduces a small overhead on the prover time.</p>

    <p class="text-gray-300">Our proof size and verifier time is significantly smaller than Brakedown. The proof size is only 6 MBs for a polynomial of size  <span class="math">2^{27}</span> ,  <span class="math">16 \\times</span>  smaller than Brakedown. The verifier time is 70ms for  <span class="math">N = 2^{27}</span> ,  <span class="math">33 \\times</span>  faster than Brakedown. The result demonstrates the improvement of the  <span class="math">O(\\log^2 N)</span>  proof size and verifier time in our scheme.</p>

    <p class="text-gray-300">Note that there is a jump from  <span class="math">N = 2^{21}</span>  to  <span class="math">N = 2^{23}</span>  in the proof size and verifier time. This is because in our implementation, instead of directly parsing the coefficients into  <span class="math">\\sqrt{N} \\times \\sqrt{N}</span>  matrix, we optimize the dimensions for better performance. When  <span class="math">N &amp;lt; 2^{23}</span> , it is not meaningful to do code-switching on the columns. The prover only does the code-switching on the row (Protocol 4 Step 8 and 9), but opens the columns directly. We observe that this gives the best prover time and the proof size. When  <span class="math">N \\geq 2^{23}</span> , the prover does the code-switching for</p>

    <p class="text-gray-300">!<a href="img-5.jpeg">img-5.jpeg</a></p>

    <p class="text-gray-300">!<a href="img-6.jpeg">img-6.jpeg</a></p>

    <p class="text-gray-300">!<a href="img-7.jpeg">img-7.jpeg</a> Fig. 4: Performance of zero-knowledge arguments on R1CS.</p>

    <p class="text-gray-300">both the row and the columns (Protocol 4, Step 8-14). Therefore, the proof size and the verifier time have a big increase because of the larger column size and the additional code-switching protocol.</p>

    <p class="text-gray-300">Finally, we present the performance of our zero-knowledge argument scheme for R1CS as a whole in this section. We focus the comparison to existing schemes that work on R1CS and have transparent setup and plausible post-quantum security. They include Brakedown  <span class="math">\\left[\\mathrm{GLS}^{+}\\right]</span> , Aurora  <span class="math">\\left[\\mathrm{BSCR}^{+}19\\right]</span>  and Ligero [AHIV17]. We use the implementation of Brakedown at [Wla], and the open-source code of Ligero and Aurora at [aur] in the experiments.</p>

    <p class="text-gray-300">We randomly generate the R1CS instances and vary the number of constraints from  <span class="math">2^{15}</span>  to  <span class="math">2^{20}</span> . As shown in Figure 4, Orion has the fastest prover among all schemes. It only takes 3.09 seconds to generate the proof for  <span class="math">N = 2^{20}</span> . This is slightly faster than Brakedown for the same reason as explained in Section 5.1. It is  <span class="math">20 \\times</span>  faster than Ligero and  <span class="math">142 \\times</span>  faster than Aurora because of the linear prover time and the simplified reduction via polynomial commitments.</p>

    <p class="text-gray-300">The proof size of Orion is significantly smaller than Brakedown and Ligero. It is only  <span class="math">1.5\\mathrm{MB}</span>  for  <span class="math">N = 2^{20}</span> ,  <span class="math">6.5\\times</span>  smaller than Brakedown and  <span class="math">12.5\\times</span>  smaller than Ligero. The proof size is even comparable to Aurora, which has  <span class="math">O(\\log^2 N)</span>  proof size and uses the Reed-Solomon code with a much better minimum distance than our linear code. The result justifies the improvement of our code switching.</p>

    <p class="text-gray-300">We only implemented and compared with the variants of the protocols with a linear verifier time. As explained in the introduction, the verifier time of all schemes grow linearly with <span class="math">N</span> in the worst case, and the comparisons are similar to the prover time. One can reduce the verifier time to sublinear in the holographic setting using the techniques in <em>[CHM^{+}20, x11, x26]</em>.</p>

    <p class="text-gray-300">Other related schemes. There are several other existing transparent zero-knowledge argument schemes. Hyrax <em>[WTS^{+}18]</em>, Virgo <em>[x27]</em> and Virgo++ <em>[ZLW^{+}21]</em> work on layered arithmetic circuits and STARK <em>[x10]</em> works on an algebraic intermediate representation that is close to a RAM program. It is hard to compare directly to R1CS, but we expect our prover time to be faster than these systems for similar computations based on the results shown in prior papers <em>[x27, ZLW^{+}21]</em>. Spartan and schemes in <em>[x28]</em> are using the same framework of polynomial commitment and sumcheck as in our scheme. However, they are based on discrete-log and bilinear pairing and thus are not post-quantum secure. As shown in <em>[GLS^{+}]</em>, their prover time is slower than Brakedown while the proof size is better (tens of KBs). Finally, Bulletproofs <em>[BBB^{+}18]</em> and Supersonic <em>[x3]</em> are based on discrete-log and group of unknown order. Their prover time is orders of magnitude slower than schemes mentioned above, while providing the smallest proof size (1-2 KBs) because of the underlying cryptographic techniques.</p>

    <h2 id="sec-31" class="text-2xl font-bold">Acknowledgements</h2>

    <p class="text-gray-300">We thank Yuval Ishai for helpful discussions and valuable feedback on the paper. The material is supported by DARPA under Contract No. HR001120C0087, the NSF award #2144625 and the Center for Long-Term Cybersecurity (CLTC). Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of DARPA, NSF or CLTC. We thank Dao Quang, Xifan Yu, Weijie Wang and Charalampos Papamanthou for pointing out a mistake in the expander testing algorithm, Jonathan Bootle for pointing out a mistake in the zero-knowledge variant, and Benedikt Bünz and Bingyi Chen for pointing out a bug in the soundness proof and a solution using CP-SNARK in an earlier version.</p>

    <h2 id="sec-32" class="text-2xl font-bold">References</h2>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>AHIV [17] Scott Ames, Carmit Hazay, Yuval Ishai, and Muthuramakrishnan Venkita-subramaniam. Ligero: Lightweight sublinear arguments without a trusted setup. In CCS, 2017.</li>

      <li>arm [18] armfazh. flo-shani-aesni. https://github.com/armfazh/flo-shani-aesni.</li>

      <li>aur [19] libIOP. https://github.com/scipr-lab/libiop.</li>

      <li>BBB^{+} [18] B. Bünz, J. Bootle, D. Boneh, A. Poelstra, P. Wuille, and G. Maxwell. Bulletproofs: Short proofs for confidential transactions and more. In IEEE S&P, 2018.</li>

    </ul>

    <p class="text-gray-300">-</p>

    <p class="text-gray-300">BBC^{+}18. Carsten Baum, Jonathan Bootle, Andrea Cerulli, Rafaël Del Pino, Jens Groth, and Vadim Lyubashevsky. Sub-linear lattice-based zero-knowledge arguments for arithmetic circuits. In CRYPTO, 2018. BCG^{+}14. Eli Ben-Sasson, Alessandro Chiesa, Christina Garman, Matthew Green, Ian Miers, Eran Tromer, and Madars Virza. Zerocash: Decentralized anonymous payments from bitcoin. In IEEE S&P, 2014. BCG^{+}17. Jonathan Bootle, Andrea Cerulli, Essam Ghadafi, Jens Groth, Mohammad Hajiabadi, and Sune K Jakobsen. Linear-time zero-knowledge proofs for arithmetic circuit satisfiability. In ASIACRYPT, 2017. BCG20. Jonathan Bootle, Alessandro Chiesa, and Jens Groth. Linear-time arguments with sublinear verification from tensor codes. TCC, 2020. BCL22. Jonathan Bootle, Alessandro Chiesa, and Siqi Liu. Zero-knowledge iops with linear-time prover and polylogarithmic-time verifier. EUROCRYPT, 2022. BDFG20. Dan Boneh, Justin Drake, Ben Fisch, and Ariel Gabizon. Halo infinite: Recursive zk-SNARKs from any additive polynomial commitment scheme. Cryptology ePrint Archive, Report 2020/1536, 2020. BFH^{+}20. Rishabh Bhadauria, Zhiyong Fang, Carmit Hazay, Muthuramakrishnan Venkitasubramaniam, Tiancheng Xie, and Yupeng Zhang. Ligero++: A new optimized sublinear IOP. In CCS, 2020. BFR^{+}13. Benjamin Braun, Ariel J. Feldman, Zuocheng Ren, Srinath T. V. Setty, Andrew J. Blumberg, and Michael Walfish. Verifying computations with state. In SOSP, 2013. BFS20. Benedikt Bünz, Ben Fisch, and Alan Szepieniec. Transparent SNARKs from DARK compilers. In Eurocrypt, 2020. BLNS20. Jonathan Bootle, Vadim Lyubashevsky, Ngoc Khanh Nguyen, and Gregor Seiler. A non-PCP approach to succinct quantum-safe zero-knowledge. In CRYPTO, 2020. BMRS21. Carsten Baum, Alex J. Malozemoff, Marc Rosen, and Peter Scholl. Mac’n’cheese: Zero-knowledge proofs for arithmetic circuits with nested disjunctions. In CRYPTO, 2021. BSBHR19. Eli Ben-Sasson, Iddo Bentov, Yinon Horesh, and Michael Riabzev. Scalable zero knowledge with no trusted setup. In CRYPTO, 2019. BSCG^{+}13. Eli Ben-Sasson, Alessandro Chiesa, Daniel Genkin, Eran Tromer, and Madars Virza. SNARKs for C: Verifying program executions succinctly and in zero knowledge. In CRYPTO. 2013. BSCR^{+}19. Eli Ben-Sasson, Alessandro Chiesa, Michael Riabzev, Nicholas Spooner, Madars Virza, and Nicholas P Ward. Aurora: Transparent succinct arguments for R1CS. In Eurocrypt, 2019. BSCTV14. Eli Ben-Sasson, Alessandro Chiesa, Eran Tromer, and Madars Virza. Scalable zero knowledge via cycles of elliptic curves. In CRYPTO, 2014. CBBZ23. Binyi Chen, Benedikt Bünz, Dan Boneh, and Zhenfei Zhang. Hyperplonk: Plonk with linear-time prover and high-degree custom gates. In Annual International Conference on the Theory and Applications of Cryptographic Techniques, pages 499–530. Springer, 2023. CDG^{+}17. Melissa Chase, David Derler, Steven Goldfeder, Claudio Orlandi, Sebastian Ramacher, Christian Rechberger, Daniel Slamanig, and Greg Zaverucha. Post-quantum zero-knowledge and signatures from symmetric-key primitives. In CCS, 2017.</p>

    <p class="text-gray-300">CDK^{+}18. Eden Chlamtác, Michael Dinitz, Christian Konrad, Guy Kortsarz, and George Rabanca. The densest k-subhypergraph problem. SIAM Journal on Discrete Mathematics, 32(2):1458–1477, 2018.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[20] Eden Chlamtác, Michael Dinitz, and Yury Makarychev. Minimizing the union: Tight approximations for small set bipartite vertex expansion. In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 881–899. SIAM, 2017.</li>

      <li>[30] CFH^{+}15. Craig Costello, Cédric Fournet, Jon Howell, Markulf Kohlweiss, Benjamin Kreuter, Michael Naehrig, Bryan Parno, and Samee Zahur. Geppetto: Versatile verifiable computation. In IEEE S&P, 2015.</li>

      <li>[31] CFQ19. Matteo Campanelli, Dario Fiore, and Anaïs Querol. LegoSNARK: Modular design and composition of succinct zero-knowledge proofs. In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS), 2019.</li>

      <li>[32] CHM^{+}20. Alessandro Chiesa, Yuncong Hu, Mary Maller, Pratyush Mishra, Noah Vesely, and Nicholas Ward. Marlin: Preprocessing zksnarks with universal and updatable srs. In Eurocrypt, 2020.</li>

      <li>[33] COS20. Alessandro Chiesa, Dev Ojha, and Nicholas Spooner. Fractal: Post-quantum and transparent recursive proofs from holography. In Eurocrypt, 2020.</li>

      <li>[34] CRVW02. Michael Capalbo, Omer Reingold, Salil Vadhan, and Avi Wigderson. Randomness conductors and constant-degree lossless expanders. STOC, 2002.</li>

      <li>[35] CS07. Artur Czumaj and Christian Sohler. Testing expansion in bounded-degree graphs. In IEEE FOCS, 2007.</li>

      <li>[36] DI14. Erez Druk and Yuval Ishai. Linear-time encodable codes meeting the Gilbert-Varshamov bound and their cryptographic applications. In ITCS, 2014.</li>

      <li>[37] DIO21. Samuel Dittmer, Yuval Ishai, and Rafail Ostrovsky. Line-point zero knowledge and its applications. In ITC, 2021.</li>

      <li>[38] ESLL19. Muhammed F Esgin, Ron Steinfeld, Joseph K Liu, and Dongxi Liu. Lattice-based zero-knowledge proofs: new techniques for shorter and faster constructions and applications. In CRYPTO, 2019.</li>

      <li>[39] FDNZ21. Zhiyong Fang, David Darais, Joseph Near, and Yupeng Zhang. Zero knowledge static program analysis. In CCS, 2021.</li>

      <li>[40] FFG^{+}16. Dario Fiore, Cédric Fournet, Esha Ghosh, Markulf Kohlweiss, Olga Ohrimenko, and Bryan Parno. Hash first, argue later: Adaptive verifiable computations on outsourced data. In CCS, 2016.</li>

      <li>[41] FQZ^{+}21. Boyuan Feng, Lianke Qin, Zhenfei Zhang, Yufei Ding, and Shumo Chu. ZEN: Efficient zero-knowledge proofs for neural networks. Cryptology ePrint Archive, Report 2021/087, 2021.</li>

      <li>[42] FS86. Amos Fiat and Adi Shamir. How to prove yourself: Practical solutions to identification and signature problems. In CRYPTO, 1986.</li>

      <li>[43] GAZ^{+}22. Paul Grubbs, Arasu Arun, Ye Zhang, Joseph Bonneau, and Michael Walfish. Zero-knowledge middleboxes. In USENIX Security, 2022.</li>

      <li>[44] Gil52. Edgar N Gilbert. A comparison of signalling alphabets. The Bell system technical journal, 31(3):504–522, 1952.</li>

      <li>[45] GKM^{+}18. Jens Groth, Markulf Kohlweiss, Mary Maller, Sarah Meiklejohn, and Ian Miers. Updatable and universal common reference strings with applications to zk-SNARKS. In CRYPTO, 2018.</li>

      <li>[46] GKR08. Shafi Goldwasser, Yael Tauman Kalai, and Guy Rothblum. Delegating computation: interactive proofs for muggles. In STOC, 2008.</li>

    </ul>

    <p class="text-gray-300">GLS^{+}. Alexander Golovnev, Jonathan Lee, Srinath Setty, Justin Thaler, and Riad S. Wahby. Brakedown: Linear-time and post-quantum snarks for r1cs. Cryptology ePrint Archive. https://ia.cr/2021/1043.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[10] Irene Giacomelli, Jesper Madsen, and Claudio Orlandi. ZKBoo: Faster zero-knowledge for boolean circuits. In USENIX Security, 2016.</li>

      <li>[11] Shafi Goldwasser, Silvio Micali, and Charles Rackoff. The knowledge complexity of interactive proof systems. SIAM Journal on computing, 1989.</li>

      <li>[12] Oded Goldreich and Dana Ron. On Testing Expansion in Bounded-Degree Graphs, pages 68–75. Springer Berlin Heidelberg, Berlin, Heidelberg, 2011.</li>

      <li>[13] Ariel Gabizon, Zachary J. Williamson, and Oana Ciobotaru. Plonk: Permutations over Lagrange-bases for oecumenical noninteractive arguments of knowledge. Cryptology ePrint Archive, Report 2019/953, 2019.</li>

      <li>[14] Shlomo Hoory, Nathan Linial, and Avi Wigderson. Expander graphs and their applications. BULL. AMER. MATH. SOC., 43(4):439–561, 2006.</li>

      <li>[15] Justin Holmgren and Ron Rothblum. Faster sounder succinct arguments and iops. 2022.</li>

      <li>[16] Yuval Ishai, Hang Su, and David J Wu. Shorter and faster post-quantum designated-verifier zksnarks from lattices. In CCS, 2021.</li>

      <li>[17] Joe Kilian. A note on efficient zero-knowledge proofs and arguments (extended abstract). In STOC, 1992.</li>

      <li>[18] Jonathan Katz, Vladimir Kolesnikov, and Xiao Wang. Improved noninteractive zero knowledge with applications to post-quantum signatures. In CCS, 2018.</li>

      <li>[19] Ahmed E. Kosba, Dimitrios Papadopoulos, Charalampos Papamanthou, and Dawn Song. MIRAGE: Succinct arguments for randomized algorithms with applications to universal zk-SNARKs. In USENIX Security, 2020.</li>

      <li>[20] Subhash Khot and Rishi Saket. Hardness of Bipartite Expansion. In ESA, 2016.</li>

      <li>[21] Seunghwa Lee, Hankyung Ko, Jihye Kim, and Hyunok Oh. vCNN: Verifiable convolutional neural network based on zk-snarks. Cryptology ePrint Archive, Report 2020/584, 2020.</li>

      <li>[22] Tianyi Liu, Xiang Xie, and Yupeng Zhang. zkCNN: Zero knowledge proofs for convolutional neural network predictions and accuracy. In CCS, 2021.</li>

      <li>[23] Mary Maller, Sean Bowe, Markulf Kohlweiss, and Sarah Meiklejohn. Sonic: Zero-knowledge snarks from linear-size universal and updatable structured reference strings. In CCS, 2019.</li>

      <li>[24] Silvio Micali. Computationally sound proofs. SIAM J. Comput., 2000.</li>

      <li>[25] Thilo Mie. Short pcpps verifiable in polylogarithmic time with o (1) queries. Annals of Mathematics and Artificial Intelligence, 2009.</li>

      <li>[26] Asaf Nachmias and Asaf Shapira. Testing the expansion of a graph. Electronic Colloquium on Computational Complexity (ECCC), 14, 01 2007.</li>

      <li>[27] Bryan Parno, Jon Howell, Craig Gentry, and Mariana Raykova. Pinocchio: Nearly practical verifiable computation. In IEEE S&P, 2013.</li>

      <li>[28] Nicholas Pippenger. On the evaluation of powers and related problems. In SFCS 1976. IEEE Computer Society, 1976.</li>

      <li>[29] Noga Ron-Zewi and Ron D. Rothblum. Local proofs approaching the witness length. In FOCS, 2020.</li>

      <li>[30] Noga Ron-Zewi and Ron D Rothblum. Proving as fast as computing: Succinct arguments with constant prover overhead. In STOC, 2022.</li>

      <li>[31] Srinath Setty. Spartan: Efficient and general-purpose zksnarks without trusted setup. In CRYPTO, 2020.</li>

    </ul>

    <p class="text-gray-300">SL20. Srinath Setty and Jonathan Lee. Quarks: Quadruple-efficient transparent zkSNARKs. Cryptology ePrint Archive, Report 2020/1275, 2020. Spi96. Daniel A Spielman. Linear-time encodable and decodable error-correcting codes. IEEE Transactions on Information Theory, 42(6):1723–1731, 1996. Var57. Rom Rubenovich Varshamov. Estimate of the number of signals in error correcting codes. Docklady Akad. Nauk, SSSR, 117:739–741, 1957. Wla. Riad S. Wahby and lcpc authors. lcpc. https://github.com/conroi/lcpc. WSR^{+}15. Riad S Wahby, Srinath TV Setty, Zuocheng Ren, Andrew J Blumberg, and Michael Walfish. Efficient RAM and control flow in verifiable outsourced computation. In NDSS, 2015. WTS^{+}18. Riad S Wahby, Ioanna Tzialla, Abhi Shelat, Justin Thaler, and Michael Walfish. Doubly-efficient zkSNARKs without trusted setup. In S&P, 2018. WYKW20. Chenkai Weng, Kang Yang, Jonathan Katz, and Xiao Wang. Wolverine: Fast, scalable, and communication-efficient zero-knowledge proofs for boolean and arithmetic circuits. In S&P, 2020. WYX^{+}21. Chenkai Weng, Kang Yang, Xiang Xie, Jonathan Katz, and Xiao Wang. Mystique: Efficient conversions for zero-knowledge proofs with applications to machine learning. USENIX Security, 2021. XZZ^{+}19. Tiacheng Xie, Jiaheng Zhang, Yupeng Zhang, Charalampos Papamanthou, and Dawn Song. Libra: Succinct zero-knowledge proofs with optimal prover computation. In CRYPTO, 2019. YSWW21. Kang Yang, Pratik Sarkar, Chenkai Weng, and Xiao Wang. Quicksilver: Efficient and affordable zero-knowledge proofs for circuits and polynomials over any field. In CCS, 2021. zca. Zcash. https://z.cash/. ZFZS20. Jiaheng Zhang, Zhiyong Fang, Yupeng Zhang, and Dawn Song. Zero knowledge proofs for decision tree predictions and accuracy. In CCS, 2020. ZGK^{+}17a. Yupeng Zhang, Daniel Genkin, Jonathan Katz, Dimitrios Papadopoulos, and Charalampos Papamanthou. vSQL: Verifying arbitrary SQL queries over dynamic outsourced databases. In S&P, 2017. ZGK^{+}17b. Yupeng Zhang, Daniel Genkin, Jonathan Katz, Dimitrios Papadopoulos, and Charalampos Papamanthou. A Zero-Knowledge version of vSQL. Cryptology ePrint Archive: Report 2017/1146, 2017. ZGK^{+}18. Yupeng Zhang, Daniel Genkin, Jonathan Katz, Dimitrios Papadopoulos, and Charalampos Papamanthou. vRAM: Faster verifiable RAM with program-independent preprocessing. In S&P, 2018. zkr. An incomplete guide to rollups. https://vitalik.ca/general/2021/01/05/rollup.html. ZLW^{+}21. Jiaheng Zhang, Tianyi Liu, Weijie Wang, Yinuo Zhang, Dawn Song, Xiang Xie, and Yupeng Zhang. Doubly efficient interactive proofs for general arithmetic circuits with linear prover time. In CCS, 2021. ZXZS20. Jiaheng Zhang, Tiancheng Xie, Yupeng Zhang, and Dawn Song. Transparent polynomial delegation and its applications to zero knowledge proof. In S&P. IEEE, 2020.</p>

    <p class="text-gray-300">A Proof of Lemma 3</p>

    <h6 id="sec-33" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">When <span class="math">s\\geq\\log\\log k</span>, we have following:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">e^{(1-\\epsilon)gs+s}=e^{O(s)}=e^{c_{0}s}</span> for some constant <span class="math">c_{0}</span>.</li>

      <li><span class="math">(\\frac{(1-\\epsilon)gs}{k^{\\prime}})^{\\epsilon gs}\\leq(\\frac{gs}{k^{\\prime}})^{\\epsilon gs}</span></li>

    </ol>

    <p class="text-gray-300">We take the expression in the summation and simplify it:</p>

    <p class="text-gray-300"><span class="math">e^{(1-\\epsilon)gs+s}\\cdot(\\frac{k}{s})^{s}\\cdot(\\frac{(1-\\epsilon)gs}{k^{\\prime}})^{\\epsilon gs}\\leq e^{c_{0}s}(\\frac{k}{s})^{s}(\\frac{gs}{k^{\\prime}})^{\\epsilon gs}</span></p>

    <p class="text-gray-300">Let <span class="math">f(x)=e^{c_{0}x}(\\frac{k}{x})^{x}(\\frac{gx}{k^{\\prime}})^{\\epsilon gx}</span>, then its derivative <span class="math">f^{\\prime}(x)=e^{c_{0}x}(\\frac{k}{x})^{x}(\\frac{gx}{k^{\\prime}})^{\\epsilon gx}\\cdot(c_{0}+\\epsilon g\\log\\frac{gx}{k^{\\prime}}+\\epsilon g+\\log\\frac{k}{x}-1)</span>. Let <span class="math">g(x)=(c_{0}+\\epsilon g\\log\\frac{gx}{k^{\\prime}}+\\epsilon g+\\log\\frac{k}{x}-1)</span>, we know that when <span class="math">x&gt;2</span>, <span class="math">f^{\\prime}(x)</span> is positive (negative or zero) if and only if <span class="math">g(x)</span> is positive (negative or zero). Taking the derivative of <span class="math">g(x)</span>, <span class="math">g^{\\prime}(x)=\\frac{\\epsilon g-1}{x}&gt;0</span> so <span class="math">f(x)</span> is a convex function. Therefore, the maximum of <span class="math">f(x)</span> is <span class="math">\\max_{x\\in[\\log\\log k,\\frac{\\delta k}{g}]}(f(x))=\\max(f(\\log\\log k),f(\\frac{\\delta k}{g}))</span>.</p>

    <p class="text-gray-300">We then compute these two values at the boundaries:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">f(\\log\\log k)=\\log^{c_{0}}(k)(\\frac{k}{\\log\\log k})^{\\log\\log k}(\\frac{g\\log\\log k}{k^{\\prime}})^{\\epsilon g\\log\\log k}</span>, since <span class="math">k^{\\prime}=\\alpha k,\\epsilon g&gt;2</span>, the equation is</li>

    </ol>

    <p class="text-gray-300"><span class="math">\\leq\\log^{c_{0}}(k)(\\frac{k}{\\log\\log k})^{\\log\\log k}(\\frac{g}{\\alpha}\\frac{\\log\\log k}{k})^{2\\log\\log k}=\\tilde{O}((\\frac{\\log\\log k}{k})^{\\log\\log k}),</span></p>

    <p class="text-gray-300">which is negligible.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">f(\\frac{\\delta k}{g})=e^{c_{0}\\frac{\\delta k}{g}}(\\frac{g}{\\delta})^{\\frac{\\delta}{g}k}(\\frac{\\delta k}{k^{\\prime}})^{\\epsilon\\delta k}=e^{(\\frac{c_{0}\\delta}{g}+\\frac{\\delta}{g}\\log(\\frac{g}{\\delta}))k+\\log(\\frac{\\delta}{\\alpha})\\epsilon\\delta k}</span>. It is negligible if <span class="math">\\frac{c_{0}\\delta}{g}+\\frac{\\delta}{g}\\log(\\frac{g}{\\delta})+\\log(\\frac{\\delta}{\\alpha})\\epsilon\\delta&lt;-0.01</span>. Therefore, we set <span class="math">c_{0}=(1-\\epsilon)g+1</span>, and we have <span class="math">\\frac{c_{0}\\delta}{g}+\\frac{\\delta}{g}\\log(\\frac{g}{\\delta})+\\log(\\frac{\\delta}{\\alpha})\\epsilon\\delta=(1-\\epsilon)\\delta+\\frac{\\delta}{g}+\\frac{\\delta}{g}\\log(\\frac{g}{\\delta})+\\log(\\frac{\\delta}{\\alpha})\\epsilon\\delta&lt;-0.001</span></li>

    </ol>

    <p class="text-gray-300">The reasoning above shows that every single value in the summation is negligible as the maximum is negligible, and there are linear number of values in the summation, so the summation is negligible.</p>

    <p class="text-gray-300">∎</p>

    <h2 id="sec-34" class="text-2xl font-bold">Appendix B Proof of Theorem 3</h2>

    <h6 id="sec-35" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Correctness. It follows the correctness of Protocol 2, the zero-knowledge argument <span class="math">\\mathcal{ZK}</span> on <span class="math">C_{\\mathsf{CS}}</span>, and the Merkle trees.</p>

    <p class="text-gray-300">Soundness. By Step 19 of Protocol 4, <span class="math">\\mathcal{E}</span> first extracts the witness <span class="math">w^{<em>}\\in\\mathbb{F}^{(t+2)k}</span> of <span class="math">\\mathcal{ZK}</span> on <span class="math">C_{\\mathsf{CS}}</span> using <span class="math">\\mathcal{E}_{\\mathcal{ZK}}</span>. Parse <span class="math">w^{</em>}</span> as <span class="math">y^{<em>}_{\\gamma_{0}},y^{</em>}_{1}</span> and <span class="math">\\mathsf{C}^{*}[\\cdot,\\mathsf{idx}]</span> for <span class="math">\\mathsf{idx}\\in\\hat{I}</span>, each of length <span class="math">k</span>. Let <span class="math">c_{\\gamma_{0}},c_{1}</span> and <span class="math">\\mathsf{C}_{2}[\\cdot,\\mathsf{idx}]</span> for <span class="math">\\mathsf{idx}\\in\\hat{I}</span> be vectors committed by <span class="math">\\mathcal{P}</span> under <span class="math">\\mathcal{R}_{\\gamma_{0}},\\mathcal{R}_{c_{1}},\\mathsf{Root}_{\\mathsf{idx}}</span> in Step 8, 9 and 4 in Protocol 4. By the check in Step 22, we have</p>

    <p class="text-gray-300"><span class="math">\\Pr\\left(\\Delta(c_{1},E_{C}(y^{*}_{1}))&gt;\\frac{d}{2}\\right)\\leq\\mathsf{negl}(N).</span></p>

    <p class="text-gray-300">To see this, since the minimum distance of the code is <span class="math">d=O(k)</span>, if the vector in <span class="math">\\mathcal{R}_{c_{1}}</span> is at least <span class="math">\\frac{d}{2}</span>-far from the codeword of <span class="math">y_{1}^{<em>}</span>, then the probability that <span class="math">c_{1}</span> and <span class="math">E_{C}(y_{1}^{</em>})</span> agrees on any <span class="math">\\mathsf{idx}</span> is <span class="math">\\frac{d}{2n}</span>. Therefore, as <span class="math">I</span> is chosen by the verifier after the prover committing to the witness in Step 12, the probability to pass all <span class="math">t=O(\\lambda)</span> checks in <span class="math">I</span> in Step 22 is at most <span class="math">(1-\\frac{d}{2n})^{t}</span>, which is <span class="math">\\mathsf{negl}(N)</span>. Similarly,</p>

    <p class="text-gray-300"><span class="math">\\Pr\\left(\\Delta(c_{\\gamma_{0}},E_{C}(y_{\\gamma_{0}}^{*}))&gt;\\frac{d}{2}\\right)\\leq\\mathsf{negl}(N),</span></p>

    <p class="text-gray-300">and</p>

    <p class="text-gray-300"><span class="math">\\Pr\\left(\\Delta(\\mathsf{C}_{2}[:,{\\mathsf{idx}}],E_{C}(\\mathsf{C}_{1}^{*}[:,{\\mathsf{idx}}]))&gt;\\frac{d}{2}\\right)\\leq\\mathsf{negl}(N),\\forall{\\mathsf{idx}}\\in\\hat{I}.</span></p>

    <p class="text-gray-300">This technique is exactly the proximity check. Therefore, <span class="math">y_{\\gamma_{0}}^{<em>},y_{1}^{</em>}</span> and <span class="math">\\mathsf{C}_{1}^{*}[:,{\\mathsf{idx}}]</span> for <span class="math">{\\mathsf{idx}}\\in\\hat{I}</span> are indeed the only messages within the distance of <span class="math">\\frac{d}{2}</span> of <span class="math">c_{\\gamma_{0}},c_{1}</span> and <span class="math">\\mathsf{C}_{2}[:,{\\mathsf{idx}}]</span> for <span class="math">{\\mathsf{idx}}\\in\\hat{I}</span> respectively, except for <span class="math">\\mathsf{negl}(N)</span> probability.</p>

    <p class="text-gray-300">Moreover, by the soundness of <span class="math">\\mathcal{ZK}</span> on <span class="math">C_{\\mathsf{CS}}</span>,</p>

    <p class="text-gray-300"><span class="math">\\Pr\\left(y\\neq\\langle y_{1}^{<em>},r_{0}\\rangle\\right)\\leq\\mathsf{negl}(N),</span> <span class="math">\\Pr\\left(E_{C}(y_{\\gamma_{0}}^{</em>})[{\\mathsf{idx}}]\\neq\\langle\\mathsf{C}_{1}^{*}[:,{\\mathsf{idx}}],\\gamma_{0}\\rangle\\right)\\leq\\mathsf{negl}(N),\\forall{\\mathsf{idx}}\\in\\hat{I}.</span></p>

    <p class="text-gray-300">and</p>

    <p class="text-gray-300"><span class="math">\\Pr\\left(E_{C}(y_{1}^{<em>})[{\\mathsf{idx}}]\\neq\\langle\\mathsf{C}_{1}^{</em>}[:,{\\mathsf{idx}}],r_{0}\\rangle\\right)\\leq\\mathsf{negl}(N),\\forall{\\mathsf{idx}}\\in\\hat{I}.</span></p>

    <p class="text-gray-300">Therefore, <span class="math">w=y_{1}^{<em>},y_{\\gamma_{0}}^{</em>},(\\mathsf{C}_{1}^{<em>}[:,{\\mathsf{idx}}]\\forall{\\mathsf{idx}}\\in\\hat{I})</span>, and <span class="math">E_{C}(y_{1}^{</em>}),E_{C}(y_{\\gamma_{0}}^{*})</span> passes the PC.VerifyEval in Protocol 2 with an overwhleming probability. When PC.VerifyEval outputs accept, by Theorem 2, <span class="math">\\mathcal{E}</span> calls the extractor <span class="math">\\mathcal{E}_{PC}</span> to extract the coefficients of a polynomial <span class="math">\\phi</span> such that <span class="math">\\phi(\\vec{x})=y</span>, where <span class="math">x=r_{0}\\otimes r_{1}</span>, except with negligible probability. This completes the proof of knowledge soundness. <span class="math">\\Box</span></p>

    <h2 id="sec-36" class="text-2xl font-bold">Appendix C Encoding circuit</h2>

    <p class="text-gray-300">Recall the construction of generalized Spielman code in Preliminary section 2.1, we prove the following:</p>

    <h6 id="sec-37" class="text-base font-medium mt-4">Lemma 6 (Size of the encoder circuit)</h6>

    <p class="text-gray-300">The size of the encoder circuit for input size <span class="math">k=2^{t}</span>, is at most <span class="math">8dk</span>. And the circuit depth is <span class="math">O(\\log N)</span></p>

    <h6 id="sec-38" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">We prove by induction:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>If <span class="math">k\\leq n_{0}</span>, the lemma holds.</li>

      <li>Assume for all <span class="math">k^{*}\\leq 2^{t-1}</span> the lemma holds, we prove for <span class="math">k=2^{t}</span> the lemma holds:</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The step <span class="math">m_{1}=xA_{t}</span> can be done in <span class="math">dk</span> steps, since <span class="math">A_{t}</span> represents an expander graph with <span class="math">dk</span> edges, so <span class="math">A_{t}</span> is sparse and have only <span class="math">dk</span> non-zeros.</li>

      <li>The step <span class="math">c_{1}=E_{C}^{t-1}(m_{1})</span> costs at most <span class="math">8d\\frac{k}{2}=4dk</span> by induction.</li>

      <li>The step <span class="math">c_{2}=c_{1}B_{t+1}</span> costs at most <span class="math">2dk</span> since <span class="math">B_{t+1}</span> represents an expander with <span class="math">2dk</span> edges.</li>

      <li>In total the cost is <span class="math">7dk\\leq 8dk</span>.</li>

    </ol>

    <p class="text-gray-300">The circuit depth is <span class="math">O(t)=O(\\log N)</span> from the construction.</p>

    <p class="text-gray-300">D Proof of Theorem 4</p>

    <h6 id="sec-39" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">The correctness is straight-forward and we omit the proof here.</p>

    <p class="text-gray-300">Knowledge Soundness. By Step 19 of Protocol 5, <span class="math">\\mathcal{E}</span> first extracts the witness <span class="math">w^{<em>}\\in\\mathbb{F}^{(t+2)k+2n}</span> of <span class="math">\\mathcal{ZK}</span> on <span class="math">C_{\\mathsf{CS}}</span> using <span class="math">\\mathcal{E}_{\\mathcal{ZK}}</span>. Parse <span class="math">w^{</em>}</span> as <span class="math">y^{<em>}_{\\gamma_{0}},y^{</em>}_{1}</span>, <span class="math">\\mathsf{C}^{<em>}_{1}[:,{\\mathsf{id}}\\mathsf{x}]</span> for <span class="math">{\\mathsf{id}}\\mathsf{x}\\in\\hat{I}</span>, each of length <span class="math">k</span> and <span class="math">\\mathbf{r}^{</em>}_{r_{0}},\\mathbf{r}^{*}_{\\gamma_{0}}</span> of length <span class="math">n</span>. Let <span class="math">c_{\\gamma_{0}},c_{1}</span> and <span class="math">\\mathsf{C}_{2}[:,{\\mathsf{id}}\\mathsf{x}]</span> for <span class="math">{\\mathsf{id}}\\mathsf{x}\\in\\hat{I}</span> be vectors committed by <span class="math">\\mathcal{P}</span> under <span class="math">\\mathcal{R}_{\\gamma_{0}},\\mathcal{R}_{c_{1}},\\mathsf{Root}_{\\mathsf{id}}\\mathsf{x}</span> in Step 8, 9 and 4 in Protocol 5.</p>

    <p class="text-gray-300">As in Theorem 3, by Step 20, 21,</p>

    <p class="text-gray-300"><span class="math">\\Pr\\left(\\Delta(\\mathsf{C}_{2}[:,{\\mathsf{id}}\\mathsf{x}],E_{C}(\\mathsf{C}^{*}_{1}[:,{\\mathsf{id}}\\mathsf{x}]))&gt;\\frac{d}{2}\\right)\\leq\\mathsf{negl}(N),\\forall{\\mathsf{id}}\\mathsf{x}\\in\\hat{I}.</span></p>

    <p class="text-gray-300">thus, <span class="math">\\mathsf{C}^{*}_{1}[:,{\\mathsf{id}}\\mathsf{x}]</span> for <span class="math">{\\mathsf{id}}\\mathsf{x}\\in\\hat{I}</span> are the only messages within the distance of <span class="math">\\frac{d}{2}</span> of <span class="math">\\mathsf{C}_{2}[:,{\\mathsf{id}}\\mathsf{x}]</span> for <span class="math">{\\mathsf{id}}\\mathsf{x}\\in\\hat{I}</span> as well, except with <span class="math">\\mathsf{negl}(N)</span> probability.</p>

    <p class="text-gray-300">By the check in Step 22 and the soundness of <span class="math">\\mathcal{ZK}</span> on Statement 6 (Step 5,6, and 9), we have</p>

    <p class="text-gray-300"><span class="math">c_{\\gamma_{0}}[{\\mathsf{id}}\\mathsf{x}]=\\langle\\gamma_{0},\\mathsf{C}^{*}_{1}[:,{\\mathsf{id}}\\mathsf{x}]\\rangle,</span></p>

    <p class="text-gray-300">and</p>

    <p class="text-gray-300"><span class="math">c_{1}[{\\mathsf{id}}\\mathsf{x}]=\\langle r_{0},\\mathsf{C}^{*}_{1}[:,{\\mathsf{id}}\\mathsf{x}]\\rangle,</span></p>

    <p class="text-gray-300">except with probability <span class="math">\\mathsf{negl}(N)</span>.</p>

    <p class="text-gray-300">Therefore, the commitment <span class="math">\\mathsf{Root}_{i},\\mathcal{R}</span>, <span class="math">\\mathsf{C}^{<em>}_{1}[:,{\\mathsf{id}}\\mathsf{x}],c_{\\gamma_{0}}</span> and <span class="math">c_{1}</span> form the instantiation of the ideal linear commitment (ILC) in </em>[BCG^{+}17, Section 4]<em>, with <span class="math">w[i]</span> for <span class="math">i\\in[k]</span> as the prover’s vectors and <span class="math">r_{0}</span> being the verifier’s query. By Theorem 4 in </em>[BCG^{+}17]<em>, there exist an extractor to extract <span class="math">w</span> such that <span class="math">y^{</em>}_{1}=w\\times r_{0}</span>.</p>

    <p class="text-gray-300">Finally, by the soundness of <span class="math">\\mathcal{ZK}</span>, <span class="math">y=\\langle y^{*}_{1},r_{1}\\rangle</span> except with probability <span class="math">\\mathsf{negl}(N)</span>, which completes the proof.</p>

    <p class="text-gray-300">Zero-knowledge. The simulator <span class="math">\\mathcal{S}</span> is constructed in Protocol 7. Note that in order to make the commitment indistinguishable, we use the randmized version of Merkle tree commitment that is hiding as defined in Section 2.2, and we omit the randomness in the protocol and the simulator.</p>

    <p class="text-gray-300">Next we prove that every message sent by the simulator is indistinguishable from the real-world execution as follows:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In the commitment phase, the verifier receives a single Merkle tree root in both worlds, which are indistinguishable because of the hiding property of Merkle trees.</li>

      <li>In Step 14, <span class="math">\\mathcal{S}</span> sends two hashes and the result <span class="math">y</span> from the oracle access. By the hiding property of the Merkle tree, they are indistinguishable from the real-world execution (Step 8,9,10 of Protocol 5).</li>

      <li>In Step 16, <span class="math">\\mathcal{S}</span> calls the simulator of <span class="math">\\mathcal{ZK}</span>, making <span class="math">\\pi_{\\mathcal{ZK}}</span> indistinguishable from the real world without knowing the witness of the zero-knowledge argument.</li>

      <li>In Step 16, <span class="math">c_{1}[{\\mathsf{id}}\\mathsf{x}],c_{\\gamma_{0}}[{\\mathsf{id}}\\mathsf{x}]</span> <span class="math">\\forall{\\mathsf{id}}\\mathsf{x}\\in\\hat{I}</span> are uniformly distributed, subject to the condition that <span class="math">c_{\\gamma_{0}}[{\\mathsf{id}}\\mathsf{x}]=\\langle\\gamma_{0},\\mathsf{C}_{1}[:,{\\mathsf{id}}\\mathsf{x}]\\rangle</span> and <span class="math">c_{1}[{\\mathsf{id}}\\mathsf{x}]=\\langle r_{0},\\mathsf{C}_{1}[:,{\\mathsf{id}}\\mathsf{x}]\\rangle</span>. This is the same as the real world.</li>

    </ol>

    <p class="text-gray-300">1: function  <span class="math">S_{0}^{\\mathcal{V}}(\\mathsf{pp})</span> 2: With access to  <span class="math">\\mathcal{V}</span> 's random tape,  <span class="math">\\mathcal{S}</span>  learns the random challenge  <span class="math">\\gamma_0</span> , query  <span class="math">r_0</span>  and the random set  <span class="math">\\hat{I}</span> . 3:  <span class="math">S</span>  picks  <span class="math">y_{\\gamma_0}, y_1</span>  randomly. 4: For each  <span class="math">\\mathrm{idx} \\in \\hat{I}</span> ,  <span class="math">S</span>  picks  <span class="math">C_1[:, \\mathrm{idx}]</span>  randomly. 5: For each  <span class="math">i \\notin \\hat{I}</span>  and  <span class="math">i + n \\notin \\hat{I}</span> ,  <span class="math">S</span>  picks a random  <span class="math">\\mathbf{r}_{\\gamma_0}[i], \\mathbf{r}_{r_0}[i]</span>  and  <span class="math">\\mathbf{r}_j[i]</span>  for all  <span class="math">j \\in [k]</span> .</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">6: For each  <span class="math">i \\in \\hat{I}</span>  or  <span class="math">i + n \\in \\hat{I}</span> ,  <span class="math">S</span>  computes the unique  <span class="math">\\mathbf{r}_{\\gamma_0}[i], \\mathbf{r}_{r_0}[i]</span>  and  <span class="math">\\mathbf{r}_j[i]</span>  for all  <span class="math">j \\in [k]</span>  such that  $(E_C(y_{\\gamma_0}) + \\mathbf{r}_{\\gamma_0}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{r}_{\\gamma_0})<span class="math">  agrees with  </span>\\langle \\gamma_0, C_1[:, i] \\rangle<span class="math">  and  </span>(E_C(y_1) + \\mathbf{r}_{r_0}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{r}_{r_0})<span class="math">  agrees with  </span>\\langle r_0, C_1[:, i] \\rangle<span class="math">  for all  </span>i$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">7: Finally,  <span class="math">S</span>  sets all other  <span class="math">C_1[:,i] = \\vec{0}</span>  for  <span class="math">i\\notin \\hat{I}</span> 8:  <span class="math">S</span>  computes  <span class="math">\\mathsf{C}_2</span>  by encoding each column of  <span class="math">\\mathsf{C}_1</span> . 9:  <span class="math">S</span>  computes the Merkle tree root  <span class="math">\\mathsf{Root}_i = \\mathsf{Merkle}.\\mathsf{Commit}(\\mathsf{C}_2[:,i])</span> 10: Compute a Merkle tree root  <span class="math">\\mathcal{R} = \\text{Merkle. Commit}([\\text{Root}_0, \\dots, \\text{Root}_{2n-1}])</span>  and output  <span class="math">\\mathcal{R}</span>  as the commitment. 11: function  <span class="math">S_{1}(y, r_{0}, \\mathsf{pp})</span> 12: To generate a proof,  <span class="math">S</span>  computes  <span class="math">c_{1} = \\sum_{i=0}^{k-1} r_{0}[i]C_{1}[i]</span> ,  <span class="math">\\mathcal{R}_{c_{1}} = \\text{Merkle. Commit}(c_{1})</span> 13:  <span class="math">c_{\\gamma_0} = \\sum_{i=0}^{k-1} \\gamma_0[i] C_1[i]</span> ,  <span class="math">\\mathcal{R}_{\\gamma_0} = \\text{Merkle. Commit}(c_{\\gamma_0})</span> 14:  <span class="math">S</span>  sends  <span class="math">\\mathcal{R}_{c_1},\\mathcal{R}_{\\gamma_0},y</span>  to the verifier.  <span class="math">S</span>  calls the simulator  <span class="math">\\mathcal{Z}\\mathcal{K}.S</span>  to generate the commitment of the witness of the CP-SNARK. 15:  <span class="math">S</span>  reads  <span class="math">\\mathcal{V}</span> 's random tape to learn  <span class="math">I</span> . 16:  <span class="math">S</span>  calls the simulator  <span class="math">\\mathcal{Z}\\mathcal{K}.S</span>  with public input  <span class="math">\\gamma_0, r_0, r_1, y</span>  to generate a proof  <span class="math">\\pi_{\\mathcal{Z}\\mathcal{K}}</span> .  <span class="math">S</span>  sends  <span class="math">\\pi_{\\mathcal{Z}\\mathcal{K}}</span>  together with  <span class="math">\\mathsf{C}_2[I[j], \\mathsf{idx}], c_1[\\mathsf{idx}], c_{\\gamma_0}[\\mathsf{idx}] \\forall \\mathsf{idx} \\in \\hat{I}, j \\in I</span>  to the verifier. 17:  <span class="math">S</span>  sends the Merkle tree proofs of  <span class="math">\\mathsf{C}_2[I[j],\\mathrm{idx}]\\forall \\mathrm{idx}\\in \\hat{I}</span>  under  <span class="math">\\mathsf{Root}_{\\mathrm{idx}}</span> 18:  <span class="math">S</span>  sends the Merkle tree proofs of  <span class="math">\\mathsf{Root}_{\\mathsf{idx}}\\forall \\mathsf{idx}\\in \\hat{I}</span>  under  <span class="math">\\mathcal{R}</span> 19:  <span class="math">S</span>  sends the Merkle tree proofs of  <span class="math">c_{1}[\\mathrm{idx}], c_{\\gamma_{0}}[\\mathrm{idx}]</span>  under  <span class="math">\\mathcal{R}_{c_1},\\mathcal{R}_{c_{\\gamma_0}}</span></p>`;
---

<BaseLayout title="Orion: Zero Knowledge Proof with Linear Prover Time (2022/1010)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2022 &middot; eprint 2022/1010
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
