---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2024/940';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Scalable Collaborative zk-SNARK and Its Application to Fully Distributed Proof Delegation';
const AUTHORS_HTML = 'Xuanming Liu, Zhelei Zhou, Yinghao Wang, Yanxin Pang, Jinye He, Bingsheng Zhang, Xiaohu Yang, Jiaheng Zhang';

const CONTENT = `    <p class="text-gray-300">Xuanming Liu<span class="math">^{1,<em>,\\dagger}</span>, Zhelei Zhou<span class="math">^{1,\\dagger}</span>, Yinghao Wang<span class="math">^{1,\\dagger}</span>, Yanxin Pang<span class="math">^{3,</em>}</span>, Jinye He<span class="math">^{4,*}</span>, Bingsheng Zhang<span class="math">^{1,\\dagger,\\mathrm{rs}}</span>, Xiaohu Yang<span class="math">^{1,\\dagger,\\mathrm{rs}}</span>, and Jiaheng Zhang<span class="math">^{2}</span></p>

    <p class="text-gray-300"><span class="math">^{1}</span>Zhejiang University <span class="math">^{2}</span>National University of Singapore <span class="math">^{3}</span>Tsinghua University <span class="math">^{4}</span>University of Virginia</p>

    <p class="text-gray-300">June 1, 2025</p>

    <h2 id="sec-2" class="text-2xl font-bold">Abstract</h2>

    <p class="text-gray-300">Collaborative zk-SNARK (USENIX'22) allows multiple parties to compute a proof over distributed witness. It offers a promising application called proof delegation (USENIX'23), where a client delegates the tedious proof generation to many servers while ensuring no one can learn the witness. Unfortunately, existing works suffer from significant efficiency issues and face challenges when scaling to complex applications.</p>

    <p class="text-gray-300">In this work, we introduce the first scalable collaborative zk-SNARK for general circuits, built upon HyperPlonk (Eurocrypt'23). Our result overcomes existing barriers, offering fully distributed workload and small communication. For data-parallel circuits, the communication overhead is even sublinear. We propose several efficient collaborative and distributed protocols for multivariate primitives, which form the main building blocks of our results and may be of independent interest. In addition, we design a new permutation check protocol for Plonk arithmetization, which is MPC-friendly and suitable for collaborative zk-SNARKs.</p>

    <p class="text-gray-300">With 128 servers jointly generating a proof for a circuit of size <span class="math">2^{21}</span> gates, the experiment demonstrates over <span class="math">30\\times</span> speedup and reduced RAM requirements compared to a local prover, while the witness is still private. Previous works were unable to achieve such savings in both time and memory efficiency. Moreover, our protocol performs well under various network conditions, making it practical for real-world applications.</p>

    <p class="text-gray-300">*Part of the work was done when Xuanming, Yanxin and Jinye were visiting the National University of Singapore. †The authors are with the State Key Laboratory of Blockchain and Data Security &amp; Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security, Hangzhou, China. <span class="math">^{1}</span>Emails: {hinsliu, zl.zhou, asternight, bingsheng, yangxh}@zju.edu.cn, jhzhang@nus.edu.sg, pangyx21@mails.tsinghua.edu.cn, qfn5bh@virginia.edu.</p>

    <p class="text-gray-300">2</p>

    <p class="text-gray-300">1  Introduction  1 1.1 Our contributions  1 1.2 Related works  2</p>

    <p class="text-gray-300">2  Preliminary  3 2.1 Packed (Shamir's) secret sharing  3 2.2 Collaborative zk-SNARK  4</p>

    <p class="text-gray-300">3  Technical Overview  4 3.1 Background of this work  4 3.2 Collaborative protocols with PSS  5 3.3 Collaborative proof for HyperPlonk  6</p>

    <p class="text-gray-300">4  Collaborative Multivariate Primitives  8 4.1 Collaborative sumcheck  8 4.2 Collaborative multilinear PCS  9 4.3 Collaborative prodcheck  10</p>

    <p class="text-gray-300">5  Scalable Collaborative zk-SNARK  11 5.1 MPC-friendly permcheck  11 5.2 Collaborative proof for general circuit  12 5.3 Collaborative proof for data-parallel circuit  13</p>

    <p class="text-gray-300">6  Experimental Evaluation  14 6.1 Experimental setup  14 6.2 Evaluation for general circuits  14 6.3 Evaluation for data-parallel circuits  17</p>

    <p class="text-gray-300">7  Conclusion &amp; Discussion  17</p>

    <p class="text-gray-300">Acknowledgement  18</p>

    <p class="text-gray-300">References  18</p>

    <p class="text-gray-300">A  Additional Preliminary  22 A.1 Interactive argument of knowledge  22 A.2 Collaborative zk-SNARK  22 A.3 Multiparty computation  23 A.4 Multivariate polynomial commitment  23</p>

    <p class="text-gray-300">B  Helper Functionalities  23 B.1 Generating double random shares  23 B.2 PSS multiplication  24 B.3 Converting PSS to SSS  24 B.4 Collaborative MSM  25</p>

    <p class="text-gray-300">C  Multivariate Primitives  25 C.1 Multilinear PCS  26 C.2 Sumcheck  26 C.3 Zerocheck  27 C.4 Prodcheck  27 C.5 Permcheck  27</p>

    <p class="text-gray-300">3</p>

    <p class="text-gray-300">D Distributed Protocols 27 D.1 Distributed multilinear PCS 27 D.2 Distributed sumcheck 27 D.3 Distributed zerocheck 28 D.4 Our distributed prodcheck 28 D.5 Our distributed permcheck 31</p>

    <p class="text-gray-300">E Collaborative Protocols 31 E.1 Our collaborative multilinear PCS 31 E.2 Our collaborative sumcheck 32 E.3 Our collaborative zerocheck 33 E.4 Our collaborative prodcheck 33 E.5 Our collaborative permcheck 34</p>

    <p class="text-gray-300">F Collaborative Proof for HyperPlonk++ 34 F.1 HyperPlonk++ 34 F.2 Collaborative HyperPlonk++ 35</p>

    <p class="text-gray-300">G USENIX Security 25 Artifact Appendix 35</p>

    <p class="text-gray-300">1 Introduction</p>

    <p class="text-gray-300">Given the arithmetic circuit <span class="math">\\mathcal{C}</span> and some public inputs <span class="math">x</span>, a zero-knowledge Succinct Non-interactive ARgument of Knowledge (zk-SNARK) allows a prover <span class="math">\\mathcal{P}</span> to generate a concise proof that convinces a verifier <span class="math">\\mathcal{V}</span> that <span class="math">\\mathcal{P}</span>’s private witness <span class="math">w</span> satisfies <span class="math">\\mathcal{C}(x,w)=1</span>, without revealing any information about <span class="math">w</span>. This technique enables trustworthy applications while preserving sensitive information, such as blockchain <em>[61, 39]</em>, machine learning <em>[64, 40, 42, 49]</em>, and program execution <em>[2, 7]</em>. Collaborative zk-SNARK, introduced by Ozdemir and Boneh <em>[45]</em>, allows multiple parties, each holding a secret-shared <span class="math">w</span>, to collaboratively generate the proof via multiparty computation (MPC), while preserving the privacy of <span class="math">w</span>. Some representative applications include verifiable aggregate statistics <em>[45]</em> and publicly auditable MPC <em>[5]</em>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Application to proof delegation. Recently, another promising application of collaborative zk-SNARK is explored by Garg et al. <em>[27]</em>, introducing the concept of proof delegation: Although with various technical breakthroughs and improvements <em>[33, 8, 41, 34]</em>, currently, proof generation still remains prohibitively expensive for ordinary clients. For example, experiments showcase that even with HyperPlonk <em>[13]</em>, a prover-efficient zk-SNARK, it still takes several hours and over <span class="math">300</span> GB of RAM to generate a proof for a general-purpose virtual machine <em>[9]</em> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\approx 2^{27}<span class="math">. Handling such burdens is even challenging for a powerful server, let alone lightweight clients. To address this issue, in <em>[27]</em>, the authors propose a framework called zkSaaS, allowing the client to delegate this task to a group of untrusted servers, each of which only holds a secret-shared </span>w<span class="math"> and runs a collaborative zk-SNARK together to generate a proof for the client. A highlight of this scheme is that the client does not need to involve in the collaborative proof, and no server is able to access the client’s private information </span>w$. For instance, consider a client who wants to generate a proof for the integrity of her machine learning inference <em>[64]</em>, but the device is resource-constrained. As a use case of collaborative zk-SNARKs, she can delegate the task to service providers without leaking her private input.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Scalability. However, not all collaborative zk-SNARKs are suitable for proof delegation, primarily because many of them have significant scalability limitations. We posit that if a collaborative zk-SNARK satisfies all of the following efficiency properties, it is considered well-suited for proof delegation:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[leftmargin=*]</li>

      <li>Fully distributed workload: First, during the collaborative zk-SNARK, as the number of parties increases, the time complexity for each party should decrease accordingly, so that proof delegation becomes meaningful, as it can generate proofs more quickly than the client would locally. Moreover, the space complexity also tends to improve linearly with the number of parties. As a result, memory will not become the key bottleneck for handling complex applications. This is crucial: while it is possibly tolerable to wait longer during the collaborative proof, we cannot always add more RAM to support larger circuits.</li>

      <li>Small communication: Finally, the communication should stay as small as possible, so as not to affect the efficiency.</li>

    </ul>

    <p class="text-gray-300">We note these properties also benefit other previously mentioned applications of collaborative zk-SNARKs <em>[45, 5]</em>.</p>

    <p class="text-gray-300">Unfortunately, existing collaborative zk-SNARKs <em>[45, 27]</em> are not scalable. Specifically, in <em>[45]</em>, each party has the same time and space complexity as the local prover, making the collaborative proof very costly; zkSaaS <em>[27]</em> partially addresses this issue: most servers in their protocols achieve the desired properties, but a leader server still incurs the same time and space complexity as the local prover, along with significant communication overhead. Our experiment (Tab. 4) showcases that their efficiency improvement is limited due to the leader server becoming a new bottleneck. Additionally, some previous work, such as <em>[39, 50]</em>, also attempts to achieve these properties, but their approaches sacrifice the privacy of witness and therefore do not meet the desired requirements. Therefore, in this work, we ask the following question:</p>

    <p class="text-gray-300">Can we construct a collaborative zk-SNARK that has (i) fully distributed workload, and (ii) concretely small communication?</p>

    <h3 id="sec-4" class="text-xl font-semibold mt-8">1.1 Our contributions</h3>

    <p class="text-gray-300">We provide affirmative answer to the above question, and our contributions are summarized as follows:</p>

    <p class="text-gray-300">Collaborative multivariate primitives. Firstly, we identify the problems hindering <em>[45, 27]</em> from achieving scalability (§3.1), one of the most important being the use of univariate SNARKs like Plonk <em>[25]</em>. In contrast, we turn to multivariate SNARKs, such as HyperPlonk <em>[13]</em>. As shown before, while the prover is already efficient, large circuits still face time and space bottlenecks, which is the main focus of proof delegation. This motivates us to improve proof delegation efficiency for them. Based on packed secret sharing (PSS) <em>[23]</em>, we design a toolbox of highly-efficient collaborative protocols (§4), allowing servers, each with secret-shared polynomials, to compute key</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">System</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Comp. Model</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Scheme</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Time per Party</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Space per Party</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Comm. per Party</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Privacy?</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">S0</td>

            <td class="px-3 py-2 border-b border-gray-700">Si</td>

            <td class="px-3 py-2 border-b border-gray-700">S0</td>

            <td class="px-3 py-2 border-b border-gray-700">Si</td>

            <td class="px-3 py-2 border-b border-gray-700">S0</td>

            <td class="px-3 py-2 border-b border-gray-700">Si</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">zkBridge [61]</td>

            <td class="px-3 py-2 border-b border-gray-700">Data-parallel</td>

            <td class="px-3 py-2 border-b border-gray-700">Virgo [66]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(Tp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">O(Sp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">O(</td>

            <td class="px-3 py-2 border-b border-gray-700">C</td>

            <td class="px-3 py-2 border-b border-gray-700">/N)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">X</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Pianist [39]</td>

            <td class="px-3 py-2 border-b border-gray-700">General</td>

            <td class="px-3 py-2 border-b border-gray-700">Plonk [25]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(Tp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">O(Sp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">O(1)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">X</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Hekaton [50]</td>

            <td class="px-3 py-2 border-b border-gray-700">General</td>

            <td class="px-3 py-2 border-b border-gray-700">Mirage [38]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(Tp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">O(Sp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">O(1)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">X</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">DFS [36]</td>

            <td class="px-3 py-2 border-b border-gray-700">R1CS</td>

            <td class="px-3 py-2 border-b border-gray-700">DFS [36]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(TP)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">O(SP)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">O(log</td>

            <td class="px-3 py-2 border-b border-gray-700">C</td>

            <td class="px-3 py-2 border-b border-gray-700">)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">zkSaaS [27]</td>

            <td class="px-3 py-2 border-b border-gray-700">R1CS</td>

            <td class="px-3 py-2 border-b border-gray-700">Groth16 [33]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(TP)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(Tp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(SP)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(Sp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(</td>

            <td class="px-3 py-2 border-b border-gray-700">C</td>

            <td class="px-3 py-2 border-b border-gray-700">)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(</td>

            <td class="px-3 py-2 border-b border-gray-700">C</td>

            <td class="px-3 py-2 border-b border-gray-700">/N)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">General</td>

            <td class="px-3 py-2 border-b border-gray-700">Plonk [25]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(TP)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(Tp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(SP)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(Sp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(</td>

            <td class="px-3 py-2 border-b border-gray-700">C</td>

            <td class="px-3 py-2 border-b border-gray-700">)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(</td>

            <td class="px-3 py-2 border-b border-gray-700">C</td>

            <td class="px-3 py-2 border-b border-gray-700">/N)</td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">This work</td>

            <td class="px-3 py-2 border-b border-gray-700">Data-parallel</td>

            <td class="px-3 py-2 border-b border-gray-700">HyperPlonk [13]</td>

            <td class="px-3 py-2 border-b border-gray-700">O(Tp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">O(Sp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">O(log</td>

            <td class="px-3 py-2 border-b border-gray-700">C</td>

            <td class="px-3 py-2 border-b border-gray-700">)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">General</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">O(Tp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">O(Sp/N)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">O(</td>

            <td class="px-3 py-2 border-b border-gray-700">C</td>

            <td class="px-3 py-2 border-b border-gray-700">/N)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">✓</td>

          </tr>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Table 1: Comparisons of leading systems aiming to distribute zk-SNARK workload. Schemes represent the targeted underlying zk-SNARKs of these systems.  <span class="math">T_{\\mathcal{P}}</span> ,  <span class="math">S_{\\mathcal{P}}</span>  denote the time complexity and space complexity of a local prover  <span class="math">\\mathcal{P}</span> .  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  represents the size of the circuit.  </span>S_0<span class="math"> ,  </span>S_i$  denote the leader server and other servers in [27] which have different properties.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">primitives of these SNARKs, such as sumcheck and polynomial commitment. Notably, to the best of our knowledge, we are the first to study these multivariate primitives over secret-shared witness. This toolbox may serve as independent interests.</p>

    <p class="text-gray-300">MPC-friendly permcheck. For Plonk arithmetization [25], a most common circuit representation, permcheck is another key primitive. We analyze the difficulties of computing this with an MPC protocol, deeming it MPC-unfriendly. Instead, we propose a new MPC-friendly permcheck scheme (§5.1) that transforms the check on secret-shared polynomials to public inputs, significantly improving the efficiency of collaborative proof. Replacing the original component with this, we obtain HyperPlonk++, an MPC-friendly variant of [13].</p>

    <p class="text-gray-300">Mixed-mode collaborative proofs. With the above construction, we design an efficient distributed protocol for permcheck (§5.2). Hence, the final collaborative proof is a mixed-mode of two protocol categories, offering faster computation and lower communication than the purely PSS-based protocols in [27]. The distributed permcheck combines two new constructions, layered distributed sumcheck and polynomial commitment, achieving speed-up without increasing the proof size.</p>

    <p class="text-gray-300">Implementation and evaluation. Combining everything, we make a significant advance in this field, obtaining scalable collaborative zk-SNARK for HyperPlonk++ (§5.2). In a collaborative proof for a circuit  <span class="math">\\mathcal{C}</span> , with  <span class="math">N</span>  low-memory servers:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- If  <span class="math">\\mathcal{C}</span>  is a general circuit with arbitrary form, (i) the workload is fully distributed, with each server having the same time and space complexity; (ii) the communication per server is  $O\\left(\\frac{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}{N}\\right)<span class="math"> . Concretely, with  </span>N = 128<span class="math"> , the collaborative proof can handle  </span>16 \\times<span class="math">  larger circuits compared to a local prover, and achieve over  </span>30 \\times<span class="math">  speedup for large circuits. The communication is not a bottleneck even in a WAN: for  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= 2^{21}, N = 128<span class="math"> , the cost per server is under  </span>50\\mathrm{MB}$ . In addition, we eliminate significant pre-processing needs.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">There is a line of work that focuses on distributing a local prover  <span class="math">\\mathcal{P}</span> 's workload among machines or parties, thereby efficiently scaling the corresponding SNARKs to larger circuits. Tab. 1 summarizes the properties of leading related works.</p>

    <p class="text-gray-300">Witness is exposed. Distributed zk-SNARKs [59, 61, 39, 50] demonstrate how to enable several machines to work in tandem to generate a proof. For instance, [61, 39, 50] design distributed zk-SNARKs for Plonk [25], Mirage [38] and Virgo [66], respectively. These works effectively divide the workload, and [39, 50] even achieve sublinear communication relative to the circuit size. However, as they assume machines are honest and directly expose the witness in plain, they are unsuitable for our purposes where the witness is sensitive.</p>

    <p class="text-gray-300">Witness is secret-shared. Recently, works such as <em>[51, 18, 45, 14, 27, 63, 36, 60]</em> explore using MPC to compute proofs without revealing the witness, with <em>[45]</em> formalizing the collaborative zk-SNARK framework. Note that, many of them (e.g., <em>[45, 60]</em>, EOS and its follow-ups <em>[14, 63]</em>) fail to achieve scalability, as each party retains <span class="math">\\mathcal{P}</span>’s complexity and incurs large communication cost. While we work in a semi-honest setting, some works <em>[45, 14, 63]</em> consider malicious security.</p>

    <p class="text-gray-300">In <em>[27]</em>, Garg et al. introduce zkSaaS and design customized collaborative proofs for <em>[33, 25]</em>, using PSS to <em>distribute <span class="math">\\mathcal{P}</span>’</em>s workload among parties. However, their work relies heavily on a powerful leader with high complexity and communication cost, limiting its scalability. Our goal is to eliminate this bottleneck. See §3.1 for detailed analysis of <em>[27]</em>.</p>

    <p class="text-gray-300">More recently, in a concurrent and independent work, Hu et al. <em>[36]</em> improve upon EOS <em>[14]</em> and explore faster proof delegation. Their model differs significantly from ours: each party in their protocol still undertakes the <em>same</em> complexity as <span class="math">\\mathcal{P}</span>, but they additionally assume that each party has multiple machines and achieve acceleration through parallel computing; In contrast, we do not make such assumptions. Furthermore, the techniques differ a lot, for instance, their focus is a customized SNARK for R1CS <em>[52]</em> called DFS, while our goal is collaborative SNARK for general circuits <em>[13]</em>. Nevertheless, we note both works share some similar observations, such as the suitability of multivariate SNARKs for proof delegation.</p>

    <h2 id="sec-6" class="text-2xl font-bold">2 Preliminary</h2>

    <p class="text-gray-300">We provide additional preliminaries, including the definitions for argument of knowledge, Polynomial Commitment Scheme (PCS) and Multi-Party Computation (MPC), in Appx. A. We use the term <em>collaborative</em> to describe protocols that operate on inputs that are secret-shared, and <em>distributed</em> to describe computations performed on inputs that are all public.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Notations. We use <span class="math">\\lambda</span> to denote the security parameter, and <span class="math">\\mathsf{negl}(\\lambda)</span> to denote a negligible function in <span class="math">\\lambda</span>. Let <span class="math">\\mathbb{F}</span> be a finite field with prime order such that $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{-1}=\\mathsf{negl}(\\lambda)<span class="math">. Let </span>(\\mathbb{G},\\mathbb{G}_{T})<span class="math"> be multiplicative cyclic groups. “PPT” stands for probabilistic polynomial time. Bold letters, e.g., </span>\\bm{x}<span class="math">, are used to denote vectors and bit-strings. For a positive integer </span>n>1<span class="math">, we use </span>[n]<span class="math"> to denote the set </span>\\{1,\\ldots,n\\}<span class="math">. For positive integers </span>a,b<span class="math"> such that </span>a\\leq b<span class="math">, we use </span>[a,b]<span class="math"> to denote the set </span>\\{a,\\ldots,b\\}<span class="math">, and </span>\\bm{x}[a:b]<span class="math"> to denote </span>\\{x_{a},\\ldots,x_{b}\\}<span class="math">. Let </span>\\mathds{1}_{j}<span class="math"> denote </span>j<span class="math"> consecutive </span>1$’s.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Multilinear extension (MLE). A polynomial <span class="math">f</span> is <em>multilinear</em> if it is a multivariate polynomial whose degree in each variable is at most one. An <span class="math">\\ell</span>-variate multilinear polynomial <span class="math">f</span>’s evaluations on <span class="math">\\{0,1\\}^{\\ell}</span> can be represented as a hypercube <span class="math">\\mathsf{A}_{f}</span>, and we use <span class="math">\\mathsf{A}_{f}[\\bm{b}]</span> to denote the element in <span class="math">\\mathsf{A}_{f}</span> indexed by <span class="math">\\bm{b}\\in\\{0,1\\}^{\\ell}</span>. On the other hand, the MLE of a hypercube <span class="math">\\mathsf{A}_{f}</span> of size <span class="math">2^{\\ell}</span> is defined as <span class="math">f:\\mathbb{F}^{\\ell}\\to\\mathbb{F}</span>, where <span class="math">f(\\bm{x})=\\mathsf{A}_{f}[\\bm{x}]</span> for any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>. Specifically, <span class="math">f</span> can be expressed as:</p>

    <p class="text-gray-300"><span class="math">f(\\bm{x})=\\sum_{\\bm{b}\\in\\{0,1\\}^{\\ell}}\\hat{\\mathsf{eq}}(\\bm{x},\\bm{b})\\cdot f(\\bm{b}),</span> (1)</p>

    <p class="text-gray-300">where <span class="math">\\hat{\\mathsf{eq}}(\\bm{x},\\bm{b})=\\prod_{i=1}^{\\ell}\\big{(}(1-x_{i})(1-b_{i})+x_{i}b_{i}\\big{)}</span>, <span class="math">b_{i}</span> is <span class="math">\\bm{b}</span>’s <span class="math">i</span>-th bit. For any <span class="math">\\bm{r}\\in\\mathbb{F}^{\\ell}</span>, <span class="math">f(\\bm{r})</span> can be computed in <span class="math">O(2^{\\ell})</span> time <em>[58]</em>.</p>

    <h3 id="sec-7" class="text-xl font-semibold mt-8">2.1 Packed (Shamir’s) secret sharing</h3>

    <p class="text-gray-300">In this work, we use the packed secret sharing (PSS) scheme introduced by Franklin and Yung <em>[23]</em>, which is a generalization of Shamir’s secret sharing (SSS) scheme <em>[56]</em> . Suppose <span class="math">\\bm{x}=\\{x_{1},\\ldots,x_{k}\\}</span> is a vector of <span class="math">k</span> secrets, where <span class="math">k</span> is called the packing factor. The dealer selects a degree-<span class="math">d</span> polynomial <span class="math">f_{\\bm{x}}</span> (where <span class="math">d\\geq k-1</span>) such that <span class="math">f_{\\bm{x}}(-i)=x_{i}</span> for <span class="math">i\\in[k]</span>. Each share is then calculated as <span class="math">f_{\\bm{x}}(i)</span> and sent to the <span class="math">i</span>-th party <span class="math">\\mathsf{S}_{i}</span> for <span class="math">i\\in[0,N-1]</span>. Any <span class="math">d+1</span> parties can reconstruct <span class="math">\\bm{x}</span> by Lagrange interpolation. We call <span class="math">f_{\\bm{x}}</span> the <em>secret polynomial</em> of <span class="math">\\bm{x}</span>, and use <span class="math">\\llbracket\\bm{x}\\rrbracket_{d}</span> to denote a degree-<span class="math">d</span> PSS of <span class="math">\\bm{x}</span> (may omit the subscript <span class="math">d</span> when the context is clear). Accordingly, we use <span class="math">\\langle x\\rangle</span> to denote a regular Shamir’s secret sharing. Recall two properties of PSS: for any <span class="math">\\bm{x},\\bm{y}\\in\\mathbb{F}^{k}</span> and <span class="math">d\\geq k-1</span>:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Linear homomorphism: <span class="math">\\llbracket\\bm{x+\\bm{y}}\\rrbracket_{d}=\\llbracket\\bm{x}\\rrbracket_{d}+\\llbracket\\bm{y}\\rrbracket_{d}</span>.</li>

      <li>Multiplicative: For all <span class="math">d_{1},d_{2}\\geq k-1</span> subject to <span class="math">d_{1}+d_{2}&lt;N</span>, <span class="math">\\llbracket\\bm{x<em>\\bm{y}}\\rrbracket_{d_{1}+d_{2}}=\\llbracket\\bm{x}\\rrbracket_{d_{1}}\\cdot\\llbracket\\bm{y}\\rrbracket_{d_{2}}</span>, where <span class="math"></em></span> denotes coordinate-wise multiplication.</li>

    </ul>

    <p class="text-gray-300">Recall that any <span class="math">d-k+1</span> shares are independent of the secret <span class="math">\\bm{x}</span>. If we denote by <span class="math">t</span> the number of corrupted parties, the PSS scheme is secure against <span class="math">t\\leq d-k+1</span> corrupted parties.</p>

    <p class="text-gray-300">Collaborative MSM. We recall the collaborative MSM introduced by <em>[27]</em>. Suppose <span class="math">\\mathsf{A}_{1},\\ldots,\\mathsf{A}_{n}\\in\\mathbb{G}^{n}</span> and <span class="math">b_{1},\\ldots,b_{n}\\in\\mathbb{F}^{n}</span>, and each party holds the PSS <span class="math">\\{\\llbracket\\bm{A_{j}}\\rrbracket\\}_{j\\in\\left[\\frac{n}{k}\\right]}</span> of <span class="math">\\bm{A}_{j}=\\{\\mathsf{A}_{(j-1)k+i}\\}_{i\\in[k]}</span> and <span class="math">\\{\\llbracket\\bm{b_{j}}\\rrbracket\\}_{j\\in\\left[\\frac{n}{k}\\right]}</span> of <span class="math">\\bm{b}_{j}=\\{b_{(j-1)k+i}\\}_{i\\in[k]}</span>. The</p>

    <p class="text-gray-300">protocol allows <span class="math">N</span> parties to compute the multi-scalar multiplication (MSM) <span class="math">\\prod_{i=1}^{n}\\mathsf{A}_{i}^{\\ b_{i}}</span>. Each server incurs <span class="math">O\\left(\\frac{n}{k}\\right)</span> time and space complexity, and the total communication is <span class="math">O(N)</span>. The protocol needs to pre-processing <span class="math">O(N)</span> randomness. We provide the formal functionality and protocol in Appx. B.4.</p>

    <h3 id="sec-8" class="text-xl font-semibold mt-8">2.2 Collaborative zk-SNARK</h3>

    <p class="text-gray-300">We present the definition of collaborative zk-SNARK introduced by Ozdemir and Boneh, adapted from <em>[45, 27]</em>.</p>

    <h6 id="sec-9" class="text-base font-medium mt-4">Definition 1 (Collaborative zk-SNARK).</h6>

    <p class="text-gray-300">Let <span class="math">\\mathsf{S}_{0},\\ldots,\\mathsf{S}_{N-1}</span> be <span class="math">N</span> servers, and <span class="math">(\\mathsf{Setup},\\mathsf{Prove},\\mathsf{Verify})</span> be a zk-SNARK for some NP relation <span class="math">\\mathcal{R}</span> with public input <span class="math">x</span> and witness <span class="math">\\bm{w}</span>. For each server, let <span class="math">\\bm{w}_{i}</span> be the PSS of <span class="math">\\bm{w}</span> held by <span class="math">\\mathsf{S}_{i}</span>. A collaborative zk-SNARK for <span class="math">\\mathcal{R}</span> is <span class="math">(\\mathsf{Setup},\\Pi,\\mathsf{Verify})</span>, where:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{pp}\\leftarrow\\mathsf{Setup}(1^{\\lambda},\\mathcal{R})</span>: The same as the setup algorithm of the underlying zk-SNARK.</li>

      <li><span class="math">\\pi\\leftarrow\\Pi(\\mathsf{pp},x,\\bm{w}_{0},...,\\bm{w}_{N-1})</span>: <span class="math">\\Pi</span> is an MPC protocol among <span class="math">N</span> servers, which securely computes the prover algorithm <span class="math">\\mathsf{Prove}</span> of the underlying zk-SNARK.</li>

      <li><span class="math">0/1\\leftarrow\\mathsf{Verify}(\\mathsf{pp},x,\\pi)</span>: The same as the verification algorithm of the underlying zk-SNARK.</li>

    </ul>

    <p class="text-gray-300">A collaborative zk-SNARK satisfies completeness, knowledge soundness, zero-knowledge, succinctness, and <em><span class="math">t</span>-zero-knowledge</em>. The first four properties are commonly used as in traditional zk-SNARKs, with formal definitions provided in Appx. A, while the last property is described as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><em><span class="math">t</span>-zero-knowledge</em>: For all PPT adversaries <span class="math">\\mathcal{A}</span> controlling at most <span class="math">t</span> servers, denoted as <span class="math">\\mathcal{C}orr</span>, and <span class="math">\\mathsf{pp}\\leftarrow\\mathsf{Setup}(1^{\\lambda},\\mathcal{R})</span>, there exists a simulator <span class="math">\\mathcal{S}</span> such that for all <span class="math">x,\\bm{w}</span> (where <span class="math">b\\leftarrow\\mathcal{R}(x,\\bm{w})\\in\\{0,1\\}</span>), the following relation holds:</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\mathsf{View}_{\\Pi}^{\\mathcal{A}}(x,\\bm{w})\\approx\\mathcal{S}(\\mathsf{pp},x,b,\\{\\bm{w}_{i}\\}_{i\\,\\text{s.t.}\\,\\,\\mathsf{S}_{i}\\in\\mathcal{C}orr})</span></p>

    <p class="text-gray-300"><span class="math">\\mathsf{View}_{\\Pi}^{\\mathcal{A}}(x,\\bm{w})</span> denotes <span class="math">\\mathcal{A}</span>’s view from the real-world execution of <span class="math">\\Pi</span> and <span class="math">\\mathcal{S}(\\mathsf{pp},x,b,\\{\\bm{w}_{i}\\}_{i\\in\\mathcal{C}orr})</span> is the view generated by <span class="math">\\mathcal{S}</span> given <span class="math">x</span> and inputs from corrupted parties. <span class="math">\\approx</span> denotes the two distributions are computationally indistinguishable.</p>

    <p class="text-gray-300">Previous work has shown that if there exists an MPC protocol <span class="math">\\Pi</span> that computes <span class="math">\\mathsf{Prove}</span> of the underlying zk-SNARK against up to <span class="math">t</span> corruptions, then a corresponding collaborative zk-SNARK <span class="math">(\\mathsf{Setup},\\Pi,\\mathsf{Verify})</span> follows immediately <em>[45]</em>. Due to this, we primarily focus on the design of such a protocol <span class="math">\\Pi</span>.</p>

    <h2 id="sec-10" class="text-2xl font-bold">3 Technical Overview</h2>

    <h3 id="sec-11" class="text-xl font-semibold mt-8">3.1 Background of this work</h3>

    <p class="text-gray-300">Similar to zkSaaS <em>[27]</em>, we present this work in a proof delegation scenario, though the results can be extended to other applications <em>[45, 5]</em>. A client delegates proof generation to <span class="math">N</span> servers <span class="math">\\mathsf{S}_{0},\\ldots,\\mathsf{S}_{N-1}</span> with a certain price. But unlike <em>[27]</em>, we impose no resource requirements on servers, allowing low-end devices to participate. The process has two phases:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Assume that the circuit <span class="math">\\mathcal{C}</span> is public. The client first computes the (extended) witness <span class="math">\\bm{w}</span> from the inputs and then uses a PSS scheme to share <span class="math">\\bm{w}</span> among the servers, where each server <span class="math">\\mathsf{S}_{i}</span> receives its share <span class="math">\\bm{w}_{i}</span>. This step is relatively inexpensive, as it does not involve costly cryptographic operations. Moreover, the client can process these operations in a streaming manner <em>[27]</em>, avoiding high space complexity. After this distribution, the client no longer needs to participate in the proof generation.</li>

      <li>The servers then execute the MPC protocol <span class="math">\\Pi</span> for a collaborative zk-SNARK to generate the proof <span class="math">\\pi</span>, which is subsequently returned to the client.</li>

    </ul>

    <p class="text-gray-300">Intuitively, the <em><span class="math">t</span>-zero-knowledge</em> property of the collaborative zk-SNARK ensures that no server can gain any information about <span class="math">\\bm{w}</span> under the given security model.</p>

    <p class="text-gray-300">Security model. We assume an honest-majority setting where an adversary can only corrupt a minority of the servers. Concretely, let <span class="math">k=O(N)</span> be the packing factor, our work is proven to be secure against at most <span class="math">t=\\frac{N}{2}-2k</span> corrupted servers. Aligning with <em>[27]</em>, we consider a semi-honest adversary. In §7, we briefly discuss how to extend our work to achieve malicious security, i.e., to defend against adversaries who may arbitrarily deviate from the protocol.</p>

    <p class="text-gray-300">Efficiency goals. For a given circuit <span class="math">\\mathcal{C}</span>, let <span class="math">T_{\\mathcal{P}}</span> and <span class="math">S_{\\mathcal{P}}</span> denote the time and space complexity of <span class="math">\\mathsf{Prove}</span> for a local zk-SNARK prover, respectively. We define a target scalable collaborative zk-SNARK as <em>fully distributed</em> if each server</p>

    <p class="text-gray-300">in <span class="math">\\Pi</span> incurs the same time and space complexity of <span class="math">O\\left(\\frac{T_{\\mathcal{P}}}{N}\\right)</span> and <span class="math">O\\left(\\frac{S_{\\mathcal{P}}}{N}\\right)</span>, respectively. Additionally, we require that each server bears a similar communication cost, and the total communication is expected to be as small as possible.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Pre-processing. In this work, we design MPC protocols in the pre-processing model, where input-independent randomness is prepared prior to online execution. We require the total pre-processing cost to be sublinear in the circuit size $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, ensuring that the cost of randomness preparation remains slight compared to proof generation. In proof delegation, the client can directly provide the randomness, as this is inexpensive. Given the low pre-processing cost, our efficiency analysis and experimental evaluation focus solely on online complexity. Note that, this contrasts with previous works <em>[45, 27]</em>, which require costly </span>O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$ randomness preparation.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Pros and cons of PSS. Recent research <em>[32, 20, 21, 27]</em> proposes PSS as a general weapon for improving the efficiency of MPC protocols, primarily because it enables parties to perform Single Instruction Multiple Data (SIMD) operations on a secret-shared vector. Thanks to this property, PSS achieves a <span class="math">k=O(N)</span> improvement in both time and space complexity. Building on this insight, we also aim to leverage PSS to enhance the efficiency of collaborative zk-SNARKs.</p>

    <p class="text-gray-300">Challenges from <em>[27]</em>. However, we emphasize that even with this weapon, achieving ideal efficiency remains non-trivial. <em>[27]</em> attempts to adapt Plonk <em>[25]</em> and Groth16 <em>[33]</em> into collaborative zk-SNARKs with PSS. However, several issues force them to rely on a leader server to handle most of the workload and communication, ultimately becoming the system’s bottleneck. Below, we analyze the challenges they face:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[leftmargin=*]</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- The biggest challenge is that Plonk and Groth16 are constructed using univariate polynomials (hereafter referred to as univariate SNARKs), and <em>[27]</em> requires an MPC sub-protocol that enables servers to compute FFT collaboratively. However, the authors find it highly challenging to design an efficient MPC protocol for FFT. As a result, they only manage to develop a protocol for partially distributing FFT, where a powerful server handles the majority of the workload, which is undesirable. Another building block, the univariate KZG PCS <em>[37]</em>, faces similar issues. Moreover, the univariate prodcheck <em>[25]</em> introduces significant communication overhead and requires $O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$ randomness, which is difficult to achieve in practice, especially when the randomness is expected to be provided by the client.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Another problem is that if we model the Prove algorithms of zk-SNARKs as a <em>prover circuit</em> <span class="math">\\mathcal{C}_{\\mathcal{P}}</span>, it contains many multiplication gates. For collaborative zk-SNARKs in <em>[27]</em>, this implies the need to handle numerous multiplications between PSS. However, it is well known that successfully recovering secrets after PSS multiplication requires an expensive procedure called <em>degree reduction</em> <em>[16]</em> to lower the degree of the PSS’s secret polynomial, which again introduces significant communication overhead.</li>

    </ul>

    <p class="text-gray-300">Obs. I: Multivariate SNARKs without FFT. Due to the above analysis, our first observation is that univariate SNARKs, such as Plonk and Groth16, are not suitable for MPC and are therefore difficult to align with our goals. On the other hand, there exist multivariate SNARKs, such as Libra <em>[62]</em>, HyperPlonk <em>[13]</em>, and Spartan <em>[52]</em>, which do not rely on FFT and are more suitable for exploring how to make them satisfy our purpose. Hence, in this work, we choose to study how to make these multivariate zk-SNARKs “collaborative”.</p>

    <p class="text-gray-300">Obs. II: Multiplicative depth of SNARKs. The second crucial observation is that for most SNARKs, including the aforementioned univariate and multivariate ones, the prover circuit <span class="math">\\mathcal{C}_{\\mathcal{P}}</span> actually has a <em>shallow multiplicative depth</em>. More specifically, <span class="math">\\mathcal{C}_{\\mathcal{P}}</span> requires <em>only one inevitable</em> multiplication between private witness due to the need to check the correctness of multiplication gates in a given application. Beyond this, <span class="math">\\mathcal{C}_{\\mathcal{P}}</span> only needs to perform <em>several</em> multiplications between public inputs and private witness. Therefore, it is feasible to adjust the PSS setting to support a limited number of PSS multiplications, thereby avoiding <em>any</em> costly degree reduction.</p>

    <h3 id="sec-12" class="text-xl font-semibold mt-8">3.2 Collaborative protocols with PSS</h3>

    <p class="text-gray-300">We first provide a collaborative protocol toolbox for conveniently lifting multivariate SNARKs into collaborative zk-SNARKs. There are two important basic building blocks: (i) <em>Sumcheck</em> <em>[43]</em>, which, given an <span class="math">\\ell</span>-variate polynomial <span class="math">f</span> and a claim <span class="math">H</span>, allows <span class="math">\\mathcal{P}</span> to convince that <span class="math">H=\\sum_{\\bm{x}\\in\\{0,1\\}^{\\ell}}f(\\bm{x})</span>, and (ii) <em>Multilinear PCS</em> <em>[46]</em>, which allows <span class="math">\\mathcal{P}</span> to commit to a multilinear polynomial and later evaluate it at some point. The first task is to enable the servers to compute <span class="math">\\mathcal{P}</span> of these primitives without learning the underlying polynomial <span class="math">f</span>.</p>

    <p class="text-gray-300">Collaborative sumcheck. The first construction is a collaborative protocol that allows <span class="math">N</span> servers to generate a proof for sumcheck. First, let us consider a case where <span class="math">f</span> is <em>multilinear</em>.</p>

    <p class="text-gray-300">Collaboratively compute bookkeeping table. In <em>[57]</em>, Thaler proposes a linear-time algorithm for <span class="math">\\mathcal{P}</span>, the core of which involves <span class="math">\\mathcal{P}</span> computes a <em>bookkeeping table</em>. This table consists of <span class="math">\\ell</span> rows, where the <span class="math">n=2^{\\ell}</span> entries in the first row are initialized with the hypercube <span class="math">\\mathsf{A}_{f}</span>, and the <span class="math">i</span>-th row contains <span class="math">2^{\\ell-i+1}</span> entries, computed as follows, for <span class="math">\\bm{b}\\in\\{0,1\\}^{\\ell}</span></p>

    <p class="text-gray-300"><span class="math">\\{0,1\\}^{\\ell-i+1}</span>:</p>

    <p class="text-gray-300"><span class="math">f(r_{1},\\ldots,r_{i-1},r_{i},\\bm{b})=(1-r_{i})\\cdot f(r_{1},\\ldots,r_{i-1},0,\\bm{b})+r_{i}\\cdot f(r_{1},\\ldots,r_{i-1},1,\\bm{b})</span> (2)</p>

    <p class="text-gray-300">where <span class="math">r_{i}\\in\\mathbb{F}</span> are random challenges from previous rounds. In our setting, to maintain privacy, each server initially only obtains the PSS of <span class="math">\\mathsf{A}_{f}</span>. To achieve efficiency goals, we note that it is possible to fully distribute the workload among <span class="math">N</span> servers with PSS. More specifically, <span class="math">\\mathsf{A}_{f}</span> is split into <span class="math">\\frac{n}{k}</span> vectors, where <span class="math">k</span> is the packing factor. Assuming the PSS of these vectors are provided, then Eq. (2) can be rewritten as:</p>

    <p class="text-gray-300"><span class="math">\\llbracket\\bm{x_{i+1,j}}\\rrbracket=(1-r_{i})\\cdot\\llbracket\\bm{x_{i,j}}\\rrbracket+r_{i}\\cdot\\llbracket\\bm{x_{i,j+\\frac{n_{i}}{2k}}}\\rrbracket,\\quad j\\in\\left[\\frac{n_{i}}{2k}\\right]</span> (3)</p>

    <p class="text-gray-300">where <span class="math">\\bm{x}_{i}</span> denotes the <span class="math">n_{i}=\\frac{n}{2^{i-1}}</span> entries in the <span class="math">i</span>-th row. However, one problem is that the above computation will get stuck in the <span class="math">\\log\\frac{2n}{k}</span>-th row, where each server only holds one share, making Eq. (3) infeasible to proceed further. To address this issue, here we allow the servers to convert the single PSS into regular Shamir’s secret sharing (SSS). Hereafter, the remaining work can be completed on the shares locally again.</p>

    <p class="text-gray-300">High-degree problem. However, when <span class="math">f</span> has a higher degree <span class="math">D&gt;1</span>, the above protocol encounters a significant problem: This is because a high-degree <span class="math">f</span> can be viewed as the evaluation of an arithmetic circuit containing <span class="math">O(D)</span> multiplication gates, taking multiple multilinear polynomials as inputs. Therefore, during the sumcheck, in each round the servers need to compute several multiplications between PSS, which precisely leads to the second challenge mentioned earlier.</p>

    <p class="text-gray-300">Optimal <span class="math">(t,k)</span>. Our solution comes from the earlier observation: We find that throughout the proof generation of most multivariate SNARKs <em>[62, 52, 13]</em>, <span class="math">D</span> is at most 4, requiring products of four polynomials: two of which encode private witness and the other two encode public inputs. Therefore, by appropriately configuring <span class="math">t</span> and <span class="math">k</span> in PSS, we can ensure that the degree of PSS’s secret polynomial does not exceed <span class="math">N</span>, allowing the secrets to be recovered. More precisely, the multiplicative property (§2.1) implies that, for PSS <span class="math">\\llbracket\\bm{x_{1}}\\rrbracket_{d},\\llbracket\\bm{x_{2}}\\rrbracket_{d}</span> of two witness vectors and <span class="math">\\llbracket\\bm{c_{1}}\\rrbracket_{k-1},\\llbracket\\bm{c_{2}}\\rrbracket_{k-1}</span> of two public vectors, all servers can locally compute their product <span class="math">\\llbracket\\bm{x_{1}<em>x_{2}</em>c_{1}*c_{2}}\\rrbracket_{2d+2k-2}</span>. Therefore, by arranging <span class="math">(t,k)</span> to satisfy both <span class="math">N&gt;2d+2k-2</span> and <span class="math">d\\geq t+k-1</span> (§2.1), we conclude that our protocol is secure when <span class="math">N\\geq 2t+4k</span>.</p>

    <p class="text-gray-300">Collaborative multilinear PCS. As mentioned earlier, <em>[27]</em> uses collaborative KZG <em>[37]</em> as their PCS for univariate polynomials, and the evaluation of KZG requires polynomial division. However, they find that performing long division of univariate polynomials with PSS is inefficient. Therefore, they turn to using collaborative FFT for polynomial divisions, which is known to impose a significant burden. In contrast, we instantiate multilinear PCS with PST <em>[46]</em>, and we observe that this scheme can be made fully distributed via PSS.</p>

    <p class="text-gray-300">Collaboratively compute polynomial division. Given an evaluation point <span class="math">\\bm{u}\\in\\mathbb{F}^{\\ell}</span> and the evaluation <span class="math">z\\in\\mathbb{F}</span>, <span class="math">\\mathcal{P}</span> generates a proof showing <span class="math">z=f(\\bm{u})</span>. In the PST scheme, this involves performing polynomial divisions by <span class="math">(x_{i}-u_{i})</span> to obtain a series of quotient and remainder polynomials <span class="math">\\{Q_{i},R_{i}\\}_{i\\in[\\ell]}</span>. Our observation is, unlike KZG which is PSS-unfriendly, in PST, when <span class="math">f</span> is multilinear, the evaluations of <span class="math">Q_{i},R_{i}</span> on <span class="math">\\{0,1\\}^{\\ell-i}</span> satisfy:</p>

    <p class="text-gray-300"><span class="math">Q_{i}(\\bm{b})</span> <span class="math">=R_{i-1}(1,\\bm{b})-R_{i-1}(0,\\bm{b})\\enspace,</span> (4) <span class="math">R_{i}(\\bm{b})</span> <span class="math">=(1-u_{i})\\cdot R_{i-1}(0,\\bm{b})+u_{i}\\cdot R_{i-1}(1,\\bm{b})</span></p>

    <p class="text-gray-300">where <span class="math">R_{0}:=f</span>. This formula is similar to Eq. (2). Thus, when the hypercube <span class="math">\\mathsf{A}_{f}</span> is secret-shared in PSS, the servers can compute the PSS of <span class="math">\\{\\mathsf{A}_{Q_{i}},\\mathsf{A}_{R_{i}}\\}_{i\\in[\\ell]}</span> in a similar way, evenly distributing the workload. Finally, the servers can invoke the collaborative MSM protocol (§2.1) to obtain the proof.</p>

    <h3 id="sec-13" class="text-xl font-semibold mt-8">3.3 Collaborative proof for HyperPlonk</h3>

    <p class="text-gray-300">We instantiate collaborative multivariate zk-SNARKs with HyperPlonk <em>[13]</em>, which is widely used in industry due to its use of Plonk arithmetization <em>[25, 13]</em>, a highly expressive framework for real-world applications. Meanwhile, our constructions have the potential to make other SNARKs <em>[62, 66, 52, 65, 10]</em> “collaborative”, as they have similar building blocks.</p>

    <p class="text-gray-300">Problem of classic permcheck. The arithmetization introduces the Permcheck problem: it encodes <span class="math">n=2^{\\ell}</span> wires in a circuit as an <span class="math">\\ell</span>-variate witness polynomial <span class="math">V</span>, with the wiring pattern defined by a public permutation <span class="math">\\sigma:\\{0,1\\}^{\\ell}\\rightarrow\\{0,1\\}^{\\ell}</span> determined by the circuit structure. It needs to check the correct wiring through the relation: <span class="math">V(\\bm{x})=V(\\sigma(\\bm{x}))</span> for all <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>. A classic approach reduces this to a Prodcheck, where <span class="math">\\mathcal{P}</span> convinces that <span class="math">H=\\prod_{\\bm{x}\\in\\{0,1\\}^{\\ell}}f(\\bm{x})</span>.</p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Figure 1: Illustration of an 8-input product tree with 2 servers. Here,  <span class="math">\\mathsf{A}_{v,i}</span>  denotes the  <span class="math">i</span> -th entry in  <span class="math">\\mathsf{A}_v</span> , and  <span class="math">\\mathsf{A}_{v,15} = 0</span> .</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Figure 2: Illustration of reducing a permutation check on (private) witness to a permutation check on public inputs.</p>

    <p class="text-gray-300">A novel view of prodcheck. Quark [54] provides an argument where  <span class="math">\\mathcal{P}</span>  first constructs an  <span class="math">(\\ell + 1)</span> -variate polynomial  <span class="math">v</span>  such that  <span class="math">v(0, \\boldsymbol{x}) = f(\\boldsymbol{x})</span>  and  <span class="math">v(1, \\boldsymbol{x}) = v(\\boldsymbol{x}, 0) \\cdot v(\\boldsymbol{x}, 1)</span>  for any  <span class="math">\\boldsymbol{x} \\in \\{0, 1\\}^{\\ell}</span> . Now, the key step is to allow the servers to compute  <span class="math">v</span> 's hypercube  <span class="math">\\mathsf{A}_v</span>  without learning  <span class="math">f</span> . One of our important findings is that this computation can be viewed as building a depth- <span class="math">\\ell</span>  product tree, where the  <span class="math">n = 2^{\\ell}</span>  leaves correspond to  <span class="math">\\mathsf{A}_f</span> , and each internal node is the product of its two children. This tree-like formulation provides a novel view for computing  <span class="math">\\mathsf{A}_v</span>  in a distributed manner: we split the  <span class="math">n</span>  leaves into  <span class="math">N</span>  subtrees, and each server is responsible for computing  <span class="math">\\frac{N}{N} - 1</span>  nodes in its subtree. Finally,  <span class="math">\\mathsf{S}_0</span>  integrates the roots of the  <span class="math">N</span>  subtrees and computes the last  <span class="math">N - 1</span>  nodes. Refer to Fig. 1 for an example. Unfortunately, this approach does not seem to be friendly for MPC: Since each server only has  <span class="math">\\mathsf{A}_f</span> 's PSS, the above process involves performing  <span class="math">O(\\ell)</span>  consecutive multiplications on shares, which is infeasible.</p>

    <p class="text-gray-300">Attempt I: collaborative prodcheck. We note that [45, 27] encounter a similar issue when dealing with univariate prodcheck. They resolve the problem by adopting the idea of computing unbounded multiplications from [4], but ultimately obtain an MPC protocol with large communication costs and the need for pre-processing  <span class="math">O(2^{\\ell})</span>  randomness. Back to our case, the first attempt is to convert shared secrets into masked value to avoid too many multiplications on PSS. In this way, we obtain a collaborative prodcheck, but it also inevitably has two drawbacks: (i) It requires performing several PSS multiplications and degree reductions, leading to about  <span class="math">10 \\cdot \\frac{N}{k} \\cdot 2^{\\ell}</span>  communication; (ii) It also requires pre-processing  <span class="math">O(2^{\\ell})</span>  randomness. This protocol is provided in §4.3 for comparison purposes. In summary, we find it very challenging to directly perform permcheck and prodcheck on secret-shared witness.</p>

    <p class="text-gray-300">Attempt II: a novel permcheck. The second attempt aims to avoid permcheck on secret-shared witness: Instead of directly reducing to a prodcheck, we introduce a permutation matrix  <span class="math">\\mathsf{M} \\in \\{0,1\\}^{n \\times n}</span> , determined by  <span class="math">\\sigma</span> . More specifically,  <span class="math">\\mathsf{M}(i,j) = 1</span>  iff  <span class="math">\\sigma(\\tilde{i}) = \\tilde{j}</span> , and equals 0 otherwise, where  <span class="math">\\tilde{x}</span>  is the bit-decomposition of an integer  <span class="math">x</span> . Now, it suffices to check whether  <span class="math">\\mathsf{M} \\cdot \\mathsf{A}_V^\\top = \\mathsf{A}_V^\\top</span>  holds, where  <span class="math">\\mathsf{A}_V</span>  is the hypercube of  <span class="math">V</span> . We note that this is exactly a matrix multiplication [57]: It suffices to check  <span class="math">V(\\boldsymbol{r_1}) = \\sum_{\\boldsymbol{b} \\in \\{0,1\\}^\\ell} M(\\boldsymbol{r_1}, \\boldsymbol{b}) \\cdot V(\\boldsymbol{b})</span> , where  <span class="math">\\boldsymbol{r_1}</span>  is a challenge from  <span class="math">\\mathcal{V}</span> , and  <span class="math">M</span>  is the MLE of  <span class="math">\\mathsf{M}</span> . This can be handled by invoking the collaborative sumcheck, which ultimately reduces to the evaluations of  <span class="math">M(\\boldsymbol{r_1}, \\boldsymbol{r_2})</span> ,  <span class="math">V(\\boldsymbol{r_1})</span> , and  <span class="math">V(\\boldsymbol{r_2})</span> , where  <span class="math">\\boldsymbol{r_2}</span>  is also a random challenge. Note that the latter two terms can be checked by invoking the collaborative multilinear PCS, while the first term is more tricky, as direct evaluation would result in an undesirable cost of  <span class="math">O(2^{2\\ell})</span> .</p>

    <p class="text-gray-300">Reducing to public checks. Inspired by the idea of handling sparse polynomial evaluation in [52], we note the task could be done in  <span class="math">O(2^{\\ell})</span>  time. However, previous work introduces additional techniques, such as memory-checking [53] and lookup arguments [55, 35], which are costly. This is because they must handle sparse polynomials whose hypercube may contain many randomly arranged non-zero entries. Instead, in our case, the permutation matrix  <span class="math">M</span>  is not only sparse, but more importantly, each row and column has exactly one entry  <span class="math">M(i,j)</span>  equals 1, according to</p>

    <p class="text-gray-300">the definition of <span class="math">\\sigma</span>. Therefore, we admit a more efficient solution: For any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>,</p>

    <p class="text-gray-300"><span class="math">M(\\bm{r_{1}},\\bm{x})=\\sum_{\\bm{b}\\in\\{0,1\\}^{\\ell}}\\tilde{\\bm{\\mathrm{eq}}}(\\bm{r_{1}},\\bm{b})\\cdot M(\\bm{b},\\bm{x})=\\tilde{\\bm{\\mathrm{eq}}}(\\bm{r_{1}},\\sigma(\\bm{x}))</span></p>

    <p class="text-gray-300">Therefore, <span class="math">\\mathcal{P}</span> only needs to: (i) commit and evaluate <span class="math">M(\\bm{r_{1}},\\bm{x})</span>, and (ii) convince that <span class="math">M(\\bm{r_{1}},\\bm{x})=\\tilde{\\bm{\\mathrm{eq}}}(\\bm{r_{1}},\\sigma(\\bm{x}))</span> for any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>. We observe that task (ii) is precisely a “classic” permcheck. However, note that, unlike the previous situation where the checks were performed over secret-shared witness, now <span class="math">M</span>, <span class="math">\\sigma</span>, and <span class="math">\\tilde{\\bm{\\mathrm{eq}}}</span> are public, which enables distributed computation. The above idea is summarized in Fig. 2.</p>

    <p class="text-gray-300">Distributed permcheck & prodcheck. In §5, we provide novel distributed protocols for the final classic permcheck and prodcheck, allowing the servers to compute with only corresponding partial polynomials. Note that in this mixed-mode, distributed protocols are concretely more efficient than the collaborative ones, but can only be applied to public inputs.</p>

    <p class="text-gray-300">One problem arises when generating a proof for the correctness of the product tree: in our situation, each server only holds non-contiguous segments of <span class="math">\\mathsf{A}_{c}</span>, making the distributed sumcheck from previous work <em>[61]</em> infeasible. An alternative idea is to have each server employ a sub-prodcheck to prove the correctness of its subtree, and <span class="math">\\mathsf{S}_{0}</span> finally generates a proof for the remaining nodes. However, this approach increases the proof size to <span class="math">O(N(\\ell-\\log N))</span> instead of <span class="math">O(\\ell)</span>. Instead, we dive into this problem and design a layered distributed sumcheck protocol (§5.2), which enables distributed computation when each server only possesses a subtree, rather than contiguous segments, without increasing the proof size.</p>

    <p class="text-gray-300">Computing the PSS of permuted <span class="math">\\mathsf{A}_{\\tilde{\\bm{\\mathrm{eq}}}}</span>. The collaborative proof needs one more critical step, requiring the servers to compute the PSS of <span class="math">\\tilde{\\bm{\\mathrm{eq}}}(\\bm{r_{1}},\\sigma(\\bm{x}))</span>’s hypercube, based on the permutation <span class="math">\\sigma</span>. Unfortunately, this computation does not have good SIMD property and thus cannot leverage PSS to improve efficiency. One idea is to have each server compute the entire hypercube and its PSS, but this would introduce <span class="math">O(2^{\\ell})</span> time complexity per server, which is undesirable. It appears that if no assumptions are made about the circuit structure, i.e., <span class="math">\\sigma</span> is arbitrary, we cannot achieve a fully distributed workload and zero communication between servers at the same time. Therefore, for a general circuit, we propose having each server compute <span class="math">\\frac{1}{N}</span> part of the hypercube and share it with other servers. This step incurs <span class="math">\\frac{N}{k}\\cdot 2^{\\ell}</span> communication in total, and this overhead is evenly divided among the servers. In addition, we provide an analysis showing that the communication is concretely small compared to Attempt I and does not become a bottleneck in practice, according to the experiments.</p>

    <p class="text-gray-300">Data-parallel case. We further explore the impact of circuit structure: If the circuit is data-parallel, we can achieve zero communication for the above step. Our idea is to use a new packing strategy to improve efficiency, leveraging the SIMD structure of data-parallel circuits: specifically, instead of sequentially packing and sharing the hypercube in the most straightforward manner, we choose to pack the elements at the same position of each sub-circuit into a single PSS. With this improvement, we find that the collaborative proof can be completed with a fully distributed workload and sub-linear communication cost simultaneously. See more details in §5.3.</p>

    <h2 id="sec-14" class="text-2xl font-bold">4 Collaborative Multivariate Primitives</h2>

    <p class="text-gray-300">This section provides collaborative protocols for multivariate primitives, with preliminary for these primitives provided in Appx. C. In the collaborative mode, we assume that each server only receives a secret-shared <span class="math">\\ell</span>-variate polynomial <span class="math">f</span>. If it is multilinear, each server only holds the PSS of <span class="math">\\mathsf{A}_{f}</span>, i.e., <span class="math">\\{\\llbracket\\bm{x_{j}}\\rrbracket\\}_{j\\in[\\frac{n}{k}]}</span>, where <span class="math">n:=2^{\\ell}</span>. Additionally, we denote <span class="math">k:=2^{s}</span> as the packing factor of the PSS, and <span class="math">n_{i}:=\\frac{n}{2^{i}}</span>.</p>

    <h3 id="sec-15" class="text-xl font-semibold mt-8">4.1 Collaborative sumcheck</h3>

    <p class="text-gray-300">The sumcheck protocol (Appx. C.2) allows <span class="math">\\mathcal{P}</span> to convince that <span class="math">H=\\sum_{\\bm{x}\\in\\{0,1\\}^{\\ell}}f(\\bm{x})</span>. We first consider the case where the target polynomial <span class="math">f</span> is multilinear. In this case, each server holds only the PSS of <span class="math">\\mathsf{A}_{f}</span>. As discussed in the overview, the core task is to collaboratively compute the bookkeeping table. At first, each server holds the PSS <span class="math">\\{\\llbracket\\bm{x_{0,j}}\\rrbracket\\}_{j\\in[\\frac{n}{k}]}</span> of entries in the first row of the table, and they operate in three phases:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In the <span class="math">i</span>-th round (<span class="math">i\\in[\\ell-s]</span>), with the random challenge <span class="math">r_{i}\\in\\mathbb{F}</span> from <span class="math">\\mathcal{V}</span>, the PSS <span class="math">\\{\\llbracket\\bm{x_{i,j}}\\rrbracket\\}_{j\\in[\\frac{n_{i}}{k}]}</span> of entries in the <span class="math">(i+1)</span>-th row is locally computed by each server through the linear combination according to Eq. (3).</li>

      <li>In the <span class="math">(\\ell-s)</span>-th round, the servers invoke <span class="math">\\mathcal{F}_{\\mathsf{PS52SSS}}</span> to convert the single PSS <span class="math">\\llbracket\\bm{x_{\\ell-s}}\\rrbracket</span> into <span class="math">k</span> Shamir’s secret sharings (SSS) <span class="math">\\langle x_{\\ell-s,1}\\rangle,\\ldots,\\langle x_{\\ell-s,k}\\rangle</span>.</li>

      <li>In the <span class="math">i</span>-th round (<span class="math">i\\in[\\ell-s]</span>), each server locally computes the SSS of needed entries like in the original sumcheck.</li>

    </ol>

    <p class="text-gray-300">Note that, in the second step, the servers invoke a standard procedure to convert a PSS to <span class="math">k</span> SSS to facilitate the remaining computation, when a server only holds a single PSS, which introduces a slight <span class="math">O(N)</span> communication overhead. We provide a detailed description of this procedure in Appx. B.3. In each round, since <span class="math">f</span> is multilinear, the sumcheck round polynomial <span class="math">f_{i}</span> can be fixed by two points, <span class="math">f_{i}(0)</span> and <span class="math">f_{i}(1)</span>, which are determined by two PSS as the sum of the first half of the secrets in this round and the sum of the second half of the secrets, respectively. Since <span class="math">k=O(N)</span>, each server holds only <span class="math">O\\left(\\frac{2^{\\ell}}{N}\\right)</span> PSS. Consequently, the workload is fully distributed, and the communication cost is sublinear with respect to <span class="math">n</span>.</p>

    <p class="text-gray-300">High-degree case. Consider a degree-<span class="math">D</span> polynomial <span class="math">f</span>, expressed as <span class="math">f(\\bm{x}):=h(g_{1}(\\bm{x}),\\ldots,g_{c}(\\bm{x}))</span>, where <span class="math">g_{1},\\ldots,g_{c}</span> are multilinear, and <span class="math">h</span> is a degree-<span class="math">D</span> arithmetic circuit for polynomials. Since <span class="math">\\mathcal{P}</span> needs <span class="math">D+1</span> points <span class="math">f_{i}(0),\\ldots,f_{i}(D)</span> to fix each round polynomial <span class="math">f_{i}</span>, leveraging the dynamic programming technique from <em>[57, 62]</em>, in the <span class="math">i</span>-th round (<span class="math">i\\in[\\ell-s]</span>),</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For each <span class="math">l\\in[c]</span>, each server computes <span class="math">T_{j}^{(l)}(u)=(1-u)\\cdot\\llbracket\\bm{x_{i-1,j}^{(l)}}\\rrbracket+u\\cdot\\llbracket\\bm{x_{i-1,j+\\frac{n_{i}}{k}}}^{(l)}}\\rrbracket</span> for <span class="math">u\\in[0,D]</span> and <span class="math">j\\in[\\frac{n_{i}}{k}]</span>,</li>

      <li>For each <span class="math">u\\in[0,D]</span>, each server computes the PSS <span class="math">T_{j}(u)=h(T_{j}^{(1)}(u),\\ldots,T_{j}^{(c)}(u))</span> for each <span class="math">j\\in\\left[\\frac{n_{i}}{k}\\right]</span>, and then sums these <span class="math">\\left\\{T_{j}(u)\\right\\}_{j\\in\\left[\\frac{n_{i}}{k}\\right]}</span> together to determine a PSS for <span class="math">f_{i}(u)</span>.</li>

    </ol>

    <p class="text-gray-300">The remaining <span class="math">s</span> rounds follow a similar pattern.</p>

    <p class="text-gray-300"><em>Requirement for <span class="math">h</span>.</em> Here, one specific challenge is that the second step requires evaluating PSS through the degree-<span class="math">\\overline{D}</span> circuit <span class="math">h</span>, which introduces the aforementioned degree reduction problem. Fortunately, as discussed in the overview, most multivariate SNARKs <em>[62, 52, 13]</em> have a low <em>multiplicative depth</em>, making it still safe to evaluate <span class="math">h</span> on PSS under such conditions. More precisely, in these SNARK’s Prove algorithm, <span class="math">h</span> has at most a degree <span class="math">D\\leq 4</span>, where the most complex term in <span class="math">h</span> involves the product of 4 polynomials: 2 of which encode private witness, and the other encode public inputs. In this case, the output of <span class="math">h</span> is a PSS of degree <span class="math">(2d+2k-2)</span>, which is smaller than <span class="math">N</span> under the security model of this work. Therefore, the PSS can still be recovered correctly after the computation, which guarantees the correctness.</p>

    <p class="text-gray-300">For better understanding, in Appx. E.2, we provide the complete construction of collaborative sumcheck on such a polynomial <span class="math">f</span> (Fig. 19), along with the security analysis.</p>

    <p class="text-gray-300"><em>Efficiency.</em> The total prover complexity is <span class="math">O(2^{\\ell})</span>, while the per-server workload is <span class="math">O\\left(\\frac{2^{\\ell}}{N}\\right)</span>. The single round of <span class="math">\\mathcal{F}_{\\textsf{PSS2SSS}}</span> introduces <span class="math">O(N)</span> communication. The total round complexity is <span class="math">O(\\ell)</span> and the total communication is <span class="math">O(N\\ell)</span>.</p>

    <p class="text-gray-300">Collaborative zerocheck. A zerocheck (Appx. C.3) allows <span class="math">\\mathcal{P}</span> to convince that <span class="math">f(\\bm{x})=0</span> for any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>. Since it can be reduced to a sumcheck on <span class="math">f^{\\prime}(\\bm{x}):=\\mathfrak{Eq}(\\bm{r},\\bm{x})\\cdot f(\\bm{x})</span> <em>[52]</em>, where <span class="math">\\bm{r}</span> is a challenge from <span class="math">\\mathcal{V}</span>, the collaborative zerocheck is accordingly reduced to a collaborative sumcheck on <span class="math">f^{\\prime}</span>. We show the servers can locally get the PSS of <span class="math">\\mathfrak{Eq}</span>’s hypercube:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each server computes <span class="math">\\bm{y}:=\\{\\mathfrak{Eq}(\\bm{r}[\\ell-s+1,\\ell],\\bm{b})\\}_{\\bm{b}\\in\\{0,1\\}^{\\epsilon}}</span> locally and converts it into PSS <span class="math">\\llbracket\\bm{y}\\rrbracket_{k-1}</span> <em>[23]</em>.</li>

      <li>Each server computes <span class="math">\\mathfrak{Eq}(\\bm{r}[1:\\ell-s],\\bm{b})\\cdot\\llbracket\\bm{y}\\rrbracket</span> for any <span class="math">\\bm{b}\\in\\{0,1\\}^{\\ell-s}</span> to get <span class="math">\\frac{n}{k}</span> degree-<span class="math">(k-1)</span> PSS as the result.</li>

    </ol>

    <p class="text-gray-300">These steps take <span class="math">O\\left(\\frac{2^{\\ell}}{N}\\right)</span> workload. Therefore, it has a similar efficiency analysis as the collaborative sumcheck.</p>

    <h3 id="sec-16" class="text-xl font-semibold mt-8">4.2 Collaborative multilinear PCS</h3>

    <p class="text-gray-300">In multivariate zk-SNARKs, <span class="math">\\mathcal{P}</span> uses a multilinear PCS mlPC to commit to <span class="math">f</span> and later opens it at some evaluation point. In this work, we instantiate it with the PST scheme <em>[46]</em>. We refer to Appx. C.1 for the introduction to it. In the collaborative multilinear PCS, the task is two-fold: (i) generating the commitment, and (ii) generating the evaluation proof.</p>

    <p class="text-gray-300">Generate <span class="math">\\mathsf{com}_{f}</span>. Leveraging Eq. (1), the commitment is computed as <span class="math">\\mathsf{com}_{f}=g^{f(\\bm{\\alpha})}=g^{\\sum_{\\bm{b}\\in\\{0,1\\}^{\\ell}}\\mathfrak{Eq}(\\bm{\\alpha},\\bm{b})\\cdot f(\\bm{b})}</span>, where <span class="math">\\bm{\\alpha}\\in\\mathbb{F}^{\\ell}</span> is the trapdoor. Note that this is essentially an MSM between the field elements <span class="math">\\{f(\\bm{b})\\}_{\\bm{b}\\in\\{0,1\\}^{\\ell}}</span> and the group elements <span class="math">\\{g^{\\mathfrak{Eq}(\\bm{\\alpha},\\bm{b})}\\}_{\\bm{b}\\in\\{0,1\\}^{\\ell}}</span>, where the latter are from a trusted setup. Therefore, we propose to prepare the group elements in PSS form during the setup. Since each server holds the PSS of <span class="math">\\mathsf{A}_{f}</span>, the computation can be completed by directly invoking the collaborative MSM (§2.1).</p>

    <p class="text-gray-300">Generate evaluation proof. During the PST evaluation, <span class="math">\\mathcal{P}</span> needs to generate a proof for <span class="math">z=f(\\bm{u})</span>, where <span class="math">\\bm{u}\\in\\mathbb{F}^{\\ell}</span> is an evaluation point. This involves <span class="math">\\mathcal{P}</span> performing <span class="math">\\ell</span> polynomial divisions to obtain a sequence of quotient polynomials <span class="math">\\{Q_{i}\\}_{i\\in[\\ell]}</span> and remainder polynomials <span class="math">\\{R_{i}\\}_{i\\in[\\ell]}</span>. Specifically, let <span class="math">R_{0}:=f</span> denote the original polynomial. In the <span class="math">i</span>-th division, the division is performed on <span class="math">R_{i-1}</span> with respect to the divisor <span class="math">(x_{i}-u_{i})</span>. After obtaining the polynomials, <span class="math">\\mathcal{P}</span> computes the proof as <span class="math">\\{g^{Q_{i}(\\bm{\\alpha})}\\}_{i\\in[\\ell]}</span>, which are MSMs similar to the commitment.</p>

    <p class="text-gray-300">Now we discuss how to make it “collaborative”. We leverage the algebraic property of <span class="math">f</span> when it is multilinear, which allows the hypercube of the quotient polynomials <span class="math">\\{Q_{i}\\}_{i\\in[\\ell]}</span> to be calculated using a formula Eq. (4). This calculation also exhibits a SIMD property that can be exploited:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For <span class="math">i\\in[\\ell-s]</span>, the PSS of <span class="math">\\mathsf{A}_{Q_{i}}</span> (<span class="math">\\{\\llbracket\\bm{x_{i,j}}\\rrbracket\\}_{j\\in[\\frac{n_{i}}{k}]}</span>) is locally computed by subtracting the first half of <span class="math">\\{\\llbracket\\bm{x_{i-1,j}}\\rrbracket\\}_{j\\in[\\frac{n_{i-1}}{k}]}</span> from the second half. Similarly, <span class="math">\\mathsf{A}_{R_{i}}</span>’s PSS is determined by linear combinations of <span class="math">\\{\\llbracket\\bm{x_{i-1,j}}\\rrbracket\\}_{j\\in[\\frac{n_{i-1}}{k}]}</span>.</li>

      <li>When <span class="math">i=\\ell-s</span>, the servers invoke <span class="math">\\mathcal{F}_{\\mathsf{PSS2SSS}}</span> to convert the <em>single</em> PSS <span class="math">\\llbracket\\bm{x_{\\ell-s}}\\rrbracket</span> into <span class="math">k</span> SSS <span class="math">\\langle x_{\\ell-s,1}\\rangle,\\ldots,\\langle x_{\\ell-s,k}\\rangle</span>.</li>

      <li>For <span class="math">i&gt;\\ell-s</span>, each server continues to locally computes the SSS of <span class="math">\\{\\mathsf{A}_{Q_{i}}\\}_{i\\in[\\ell-s+1,\\ell]}</span> as in the original PST evaluation.</li>

    </ol>

    <p class="text-gray-300">With the PSS and SSS of quotient polynomials, the servers execute collaborative MSM in batch to compute the final proof. We defer the complete construction of collaborative multilinear PCS (Fig. 18) and its security analysis to Appx. E.1.</p>

    <p class="text-gray-300">Efficiency. The total prover complexity is <span class="math">O(2^{\\ell})</span>, while the per-server workload is <span class="math">O\\left(\\frac{2^{\\ell}}{N}\\right)</span>. Due to the single round of <span class="math">\\mathcal{F}_{\\mathsf{PSS2SSS}}</span> and the batched <span class="math">\\mathcal{F}_{\\mathsf{co}\\text{-}\\mathsf{MSM}}</span>, the round complexity is <span class="math">O(1)</span>, and the total communication is <span class="math">O(N\\ell)</span>. Due to the use of <span class="math">\\mathcal{F}_{\\mathsf{co}\\text{-}\\mathsf{MSM}}</span>, it needs to pre-processing <span class="math">O(N\\ell)</span> randomness.</p>

    <h3 id="sec-17" class="text-xl font-semibold mt-8">4.3 Collaborative prodcheck</h3>

    <p class="text-gray-300">The prodcheck (Appx. C.4) is yet another important building block for many zk-SNARKs <em>[25, 13, 54, 24]</em>, allowing <span class="math">\\mathcal{P}</span> to convince <span class="math">H=\\prod_{\\bm{x}\\in\\{0,1\\}^{\\ell}}f(\\bm{x})</span>. This subsection presents a “less-efficient” collaborative protocol for prodcheck, with an idea also adopted by <em>[45, 27]</em> when designing collaborative prodcheck for univariate polynomials. Since the idea is similar, it shares the drawbacks of previous works: (i) requiring concretely large communication, and (ii) requiring expensive pre-processing. Jumping ahead, in the final collaborative proof (§5), there is a method to avoid prodcheck on secret-shared polynomials, thereby circumventing the issues.</p>

    <p class="text-gray-300">As discussed in the overview, <span class="math">\\mathcal{P}</span> first constructs a <span class="math">(\\ell+1)</span>-variate polynomial <span class="math">v</span> such that <span class="math">v(0,\\bm{x})=f(\\bm{x})</span> and <span class="math">v(1,\\bm{x})=v(\\bm{x},0)\\cdot v(\\bm{x},1)</span> for any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>. Then, <span class="math">\\mathcal{P}</span> convinces the correctness of <span class="math">v</span> and that <span class="math">H=v(1,\\ldots,1,0)</span> through zerocheck and multilinear PCS. In the collaborative case, these translate to the servers computing <span class="math">\\mathsf{A}_{v}</span> and using the protocols in §4.1 and §4.2 to generate the proof. The major problem here is the former: Leveraging the tree-like formulation in Fig. 1 can distribute the workload easily, but this computation involves <span class="math">O(\\ell)</span> multiplications on shares, which is not feasible. To address this, we refer to the unbounded multiplication idea from <em>[4]</em>, which is also leveraged by <em>[45, 27]</em>, allowing servers to compute the product tree within constant rounds. Specifically, in the offline phase, the PSS of randomness <span class="math">r_{1},\\ldots,r_{n}</span> and <span class="math">r_{1}^{-1},\\ldots,r_{n}^{-1}</span> is prepared through pre-processing. Then, given the PSS of the input layer of the tree, denoted as <span class="math">\\bm{x}</span>,</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The servers first mask the leaves into the form <span class="math">r_{j}x_{j}r_{j+1}^{-1}</span> through multiplications between the PSS of <span class="math">\\bm{x}</span> and the randomness, and reveal the “masked” leaves to each server.</li>

      <li>With the “masked” leaves, the servers compute other nodes inside the tree (i.e., the hypercube of <span class="math">v(1,\\bm{x})</span>) through a <em>distributed</em> computation, and packed shares the “masked” hypercube of <span class="math">v(1,\\bm{x})</span>, <span class="math">v(\\bm{x},0)</span> and <span class="math">v(\\bm{x},1)</span> with others.</li>

      <li>Finally, the servers invoke PSS multiplications <span class="math">\\mathcal{F}_{\\mathsf{PSSMult}}</span> to “unmask” the shares separately and get the PSS of “unmasked” hypercube of the three polynomials.</li>

    </ol>

    <p class="text-gray-300">The product of “masked” nodes inside the tree is always in the form <span class="math">r^{\\prime}xr^{-1}</span>. Therefore, by appropriately preparing the “unmasks”, the randomness will ultimately be removed through PSS multiplication. A standard procedure <span class="math">\\mathcal{F}_{\\mathsf{PSSMult}}</span> is needed for PSS multiplication and degree reduction, which incurs <span class="math">O(2^{\\ell})</span> communication per execution. The description of it is provided in Appx. B.2. With the PSS of <span class="math">\\mathsf{A}_{v}</span>, it is sufficient for the servers to generate proofs for remaining checks.</p>

    <p class="text-gray-300">Discussion. In Appx. E.4, we provide the complete construction of the collaborative prodcheck along with its security analysis. The total prover complexity is <span class="math">O(2^{\\ell})</span>, while the per-server workload is <span class="math">O\\left(\\frac{2^{\\ell}}{N}\\right)</span>. The total communication is <span class="math">O(2^{\\ell})</span>, and this is concretely large: if we take <span class="math">N\\ll 2^{\\ell}</span>, the total concrete communication is nearly <span class="math">(10\\epsilon+1)\\cdot 2^{\\ell}</span>, where <span class="math">\\epsilon:=\\frac{N}{k}</span>. Additionally, this protocol requires pre-processing <span class="math">O(2^{\\ell})</span> randomness. We refer readers to the detailed efficiency analysis in Appx. E.4. It is also noted that <em>[45, 27]</em> have similar issues when handling collaborative prodcheck for univariate polynomials. Finally, we conclude that it is less-efficient to directly run prodcheck over secret-shared polynomials.</p>

    <p class="text-gray-300">5 Scalable Collaborative zk-SNARK</p>

    <p class="text-gray-300">This section provides constructions of scalable collaborative zk-SNARKs for both data-parallel and general circuits.</p>

    <p class="text-gray-300">Preliminary. Consider a circuit comprising <span class="math">m</span> gates performing addition or multiplication. The arithmetization in <em>[13]</em> captures the computation trace with <span class="math">m</span> triples <span class="math">\\{(L_{i},R_{i},O_{i})\\in\\mathbb{F}^{3}\\}_{i\\in[m]}</span>, where each triple represents the left, right and output wires of the <span class="math">i</span>-th gate. <span class="math">\\mathcal{P}</span> defines an <span class="math">\\ell</span>-variate polynomial <span class="math">V</span> as the MLE of the triples (the witness), where <span class="math">2^{\\ell}=4m=n</span>. <span class="math">\\mathcal{P}</span> needs to prove both the gate identity and the wiring identity:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Gate identity: For any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\log m}</span>, <span class="math">S_{1}(\\bm{x})\\cdot(V(0,0,\\bm{x})+V(0,1,\\bm{x}))+S_{2}(\\bm{x})\\cdot V(0,0,\\bm{x})\\cdot V(0,1,\\bm{x})-V(1,0,\\bm{x})=0</span>, where <span class="math">S_{1},S_{2}</span> are two public selector polynomials.</li>

      <li>Wiring identity: For any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>, <span class="math">V(\\bm{x})=V(\\sigma(\\bm{x}))</span>, where <span class="math">\\sigma:\\{0,1\\}^{\\ell}\\rightarrow\\{0,1\\}^{\\ell}</span> is a public permutation.</li>

    </ul>

    <p class="text-gray-300">Zero-knowledge. In this section, we discuss <em>[13]</em> without the zero-knowledge property. But notice that, this property can be incorporated using randomized polynomial masking method outlined in <em>[12, Appendix A]</em> with minimal effort.</p>

    <p class="text-gray-300">Non-interactive. Since the multivariate building blocks are public-coin, both the construction in <em>[13]</em> and our proposed constructions can be made non-interactive via the Fiat-Shamir transformation <em>[22]</em>. For collaborative zk-SNARKs, this is done by having the servers reconstruct the proof transcript and query a random oracle to derive the same challenges as <span class="math">\\mathcal{V}</span>’s messages. Thus, no corrupted parties can access the private witness as long as the proof maintains zero-knowledge.</p>

    <p class="text-gray-300">Straw-man collaborative proof. To generate a collaborative proof for the above circuit <span class="math">\\mathcal{C}</span>, a straw-man approach will fully rely on the existing collaborative protocols from §4:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The gate identity is checked through a zerocheck, which results in a sumcheck on a degree-<span class="math">4</span> polynomial. The most complex term here involves the product of two public polynomials, <span class="math">\\tilde{\\text{\\rm eq}}</span> and <span class="math">S_{2}</span>, along with two polynomials from <span class="math">V</span> that encode the witness. Therefore, it satisfies the requirement of collaborative sumcheck described in §4.1.</li>

      <li>The wiring identity is checked through a permcheck. A straw-man approach can directly extend the collaborative prodcheck in §4.3 to a collaborative permcheck (refer to Appx. E.5 for details of this protocol) and generate a proof.</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">However, as noted in §4.3, the collaborative permcheck does not appear to be the perfect solution for wiring identity. This is two-fold: (i) it introduces concretely large communication, and (ii) it requires $O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$ randomness. If all the randomness is provided by the client, this overhead is unacceptable in practice. In conclusion, we think the original permcheck from <em>[13]</em> is not MPC-friendly, and propose a transformation for it.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-18" class="text-xl font-semibold mt-8">5.1 MPC-friendly permcheck</h3>

    <p class="text-gray-300">Consider the permutation relation <span class="math">\\mathcal{R}_{perm}(\\ell,\\sigma;f,g)=1</span> iff <span class="math">f(\\bm{x})=g(\\sigma(\\bm{x}))</span> for any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>, where <span class="math">f,g</span> are two multilinear polynomials encoding the witness, and <span class="math">\\sigma:\\{0,1\\}^{\\ell}\\rightarrow\\{0,1\\}^{\\ell}</span> is a public permutation. We present a transformation to make the permcheck MPC-friendly. <span class="math">\\mathcal{P},\\mathcal{V}</span> run the following:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let <span class="math">\\mathsf{M}\\in\\{0,1\\}^{n\\times n}</span> be a public permutation matrix such that <span class="math">\\mathsf{M}(i,j)=1</span> iff <span class="math">\\sigma(\\tilde{i})=\\tilde{j}</span>, and <span class="math">0</span> otherwise, where <span class="math">\\tilde{x}</span> is the bit-decomposition of an <span class="math">x\\in\\mathbb{F}</span>. <span class="math">\\mathcal{P}</span> invokes Commit of mlPC to compute <span class="math">\\mathsf{com}_{f},\\mathsf{com}_{g}</span> and sends to <span class="math">\\mathcal{V}</span>.</li>

      <li>Let <span class="math">M</span> denotes the MLE of <span class="math">\\mathsf{M}</span>. According to the classic interactive matrix multiplication protocol <em>[57]</em>, <span class="math">\\mathcal{P}</span> and <span class="math">\\mathcal{V}</span> run the following to check <span class="math">\\mathsf{M}\\cdot\\mathsf{A}_{f}^{\\top}=\\mathsf{A}_{g}^{\\top}</span>:</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}</span> sends <span class="math">\\bm{r_{1}}\\stackrel{{\\scriptstyle\\bm{r}}}{{\\leftarrow}}\\mathbb{F}^{\\ell}</span> to <span class="math">\\mathcal{P}</span>.</li>

      <li>Let <span class="math">M^{\\prime}(\\bm{x}):=M(\\bm{r_{1}},\\bm{x})</span>. <span class="math">\\mathcal{P}</span> sends <span class="math">\\mathsf{com}_{M^{\\prime}}</span> to <span class="math">\\mathcal{V}</span>.</li>

      <li><span class="math">\\mathcal{P}</span>, <span class="math">\\mathcal{V}</span> run a sumcheck on <span class="math">g(\\bm{r_{1}})=\\sum_{\\bm{b}\\in\\{0,1\\}^{\\ell}}M^{\\prime}(\\bm{b})\\cdot f(\\bm{b})</span>, reducing to the claims <span class="math">H_{1}=g(\\bm{r_{1}})</span>, <span class="math">H_{2}=f(\\bm{r_{2}})</span>, and <span class="math">H_{3}=M^{\\prime}(\\bm{r_{2}})=M(\\bm{r_{1}},\\bm{r_{2}})</span>, where <span class="math">\\bm{r_{2}}\\in\\mathbb{F}^{\\ell}</span> is the random challenge from <span class="math">\\mathcal{V}</span> during the sumcheck.</li>

      <li><span class="math">\\mathcal{P}</span> and <span class="math">\\mathcal{V}</span> run mlPC.Open to check <span class="math">H_{1}</span>, <span class="math">H_{2}</span>, and <span class="math">H_{3}</span>, and run the classic permcheck protocol <em>[13, Sec. 3.5]</em> to check <span class="math">\\mathcal{R}_{perm}(\\ell,\\sigma;\\tilde{\\text{\\rm eq}}(\\bm{r_{1}},\\bm{x}),M^{\\prime}(\\bm{x}))=1</span>.</li>

    </ol>

    <p class="text-gray-300">Step 3 contains an invocation of the classic permcheck protocol, whose description is provided in Appx. C.5. One important observation is that, since <span class="math">M</span> is the unique permutation matrix according to <span class="math">\\sigma</span>, we have <span class="math">M^{\\prime}(\\bm{x})=\\tilde{\\text{\\rm eq}}(\\bm{r_{1}},\\sigma(\\bm{x}))</span> for any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>. Consequently, it transforms a permcheck on the private witness (i.e., <span class="math">f</span> and <span class="math">g</span> above) into a permcheck on public inputs. As a result, we avoid the use of the collaborative permcheck and</p>

    <p class="text-gray-300">the associated issues. In addition, since the final permcheck operates on public inputs, we can use a <em>distributed</em> protocol to divide its workload, which has concretely better efficiency. For instance, since <span class="math">M^{\\prime}</span> is public, the servers can use the <em>distributed</em> multilinear PCS (Appx. D.1) to commit to it, rather than a <em>collaborative</em> multilinear PCS. As the former provides a near <span class="math">N</span> times concrete improvement, while the latter only achieves <span class="math">k</span> times, the former is more efficient. For these reasons, we refer to this new construction as “MPC-friendly”. Its security analysis is deferred to Appx. F.1.</p>

    <p class="text-gray-300"><em>Efficiency.</em> Compared to the classic permcheck, the new protocol does not change the asymptotic analysis of <span class="math">\\mathcal{P}</span> and <span class="math">\\widetilde{\\mathcal{V}}</span>. <span class="math">\\mathcal{P}^{\\prime}</span>s time remains <span class="math">O(2^{\\ell})</span>. <span class="math">\\mathcal{V}^{\\prime}</span>s time and proof size are <span class="math">O(\\ell)</span>. Concretely, it adds the cost of a sumcheck and a commitment for <span class="math">M^{\\prime}</span>, as well as several multilinear polynomial evaluations.</p>

    <h3 id="sec-19" class="text-xl font-semibold mt-8">5.2 Collaborative proof for general circuit</h3>

    <p class="text-gray-300">We aim to use the new permcheck in §5.1 for wiring identity check, hence avoiding the issues from the straw-man protocol. Now, in the collaborative setting, most steps can be handled using existing collaborative and distributed protocols: With the PSS of <span class="math">\\mathsf{A}_{V}</span>, (i) In Step 1, the servers use the collaborative multilinear PCS to compute <span class="math">\\mathsf{com}_{V}</span>; (ii) In Step 2-b, they use the distributed multilinear PCS to compute <span class="math">\\mathsf{com}_{M^{\\prime}}</span>; and (iii) Step 2-c is precisely an invoke of the collaborative sumcheck. However, there are still two insufficiencies: (i) Computing the PSS of <span class="math">\\mathsf{A}_{M^{\\prime}}</span> in Step 2-b, which is needed for the sumcheck; and (ii) Distributing the classic permcheck in Step 3.</p>

    <p class="text-gray-300">Computing <span class="math">\\mathsf{A}_{M^{\\prime}}</span>’s PSS. To run the collaborative sumcheck with <span class="math">M^{\\prime}</span>, the servers need to first obtain the PSS of <span class="math">\\mathsf{A}_{M^{\\prime}}</span>, i.e., the evaluations of <span class="math">M^{\\prime}</span> on <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>. Note that <span class="math">M^{\\prime}(\\bm{x})=\\widehat{\\mathsf{eq}}(\\bm{r_{1}},\\sigma(\\bm{x}))</span> for any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>; therefore, the task is to compute the PSS of <span class="math">\\mathsf{A}_{\\widehat{\\mathsf{eq}}}</span> permuted by <span class="math">\\sigma</span>. However, since for a general circuit, the permutation <span class="math">\\sigma</span> does not follow any specific pattern, this computation cannot leverage SIMD property to improve efficiency. To meet our efficiency goal, we let each server compute and distribute <span class="math">\\frac{1}{N}</span> of the hypercube through one round of communication to resolve this issue.</p>

    <p class="text-gray-300">Specifically, each server <span class="math">\\mathsf{S}_{i}</span> is responsible for computing <span class="math">\\widehat{\\mathsf{eq}}(\\bm{r_{1}},\\sigma(\\widetilde{i},\\bm{x}))</span> for any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell-s}</span>, where <span class="math">N=2^{s}</span>. Each server then packs and shares this part of the hypercube with the other servers. During this process, each server completes its task with <span class="math">O\\left(\\frac{2^{\\ell}}{N}\\right)</span> time and space complexity, while incurring a communication cost of <span class="math">O\\left(\\frac{2^{\\ell}}{N}\\right)</span>. Concretely, let <span class="math">\\epsilon:=\\frac{N}{k}</span>, the total communication cost is <span class="math">(\\frac{2^{\\ell}}{Nk}\\cdot N)\\cdot N=\\epsilon\\cdot 2^{\\ell}</span>. We also conjecture that there is no way to compute these PSS with both fully distributed time complexity and sublinear communication if the circuit structure has an arbitrary pattern.</p>

    <p class="text-gray-300">Distributed permcheck & prodcheck. Next, we present a solution enabling <span class="math">N</span> servers to compute <span class="math">\\mathcal{P}</span> of the classic permcheck (Appx. C.5), which is then reduced to a prodcheck (Appx. C.4), in a distributed manner without increasing the proof size. Note that this can be done with a <em>distributed</em> protocol since the involved polynomials are now public.</p>

    <p class="text-gray-300">Similar to the previous collaborative prodcheck in §4.3, the first task is to compute the <span class="math">(\\ell+1)</span>-variate polynomial <span class="math">v</span> such that: (i) <span class="math">v(0,\\bm{b})=f(\\bm{b})</span>, and (ii) <span class="math">v(1,\\bm{b})=v(\\bm{b},0)\\cdot v(\\bm{b},1)</span>, for any <span class="math">\\bm{b}\\in\\{0,1\\}^{\\ell}</span>. In the distributed protocol, the servers can leverage the tree-like formulation idea in Fig. 1 directly to distribute the workload of computing <span class="math">\\mathsf{A}_{v}</span> among <span class="math">N</span> servers.</p>

    <p class="text-gray-300">Subsequently, the servers generate a proof for the correctness of the product tree, i.e., conditions (i) and (ii) above. Both checks can be reduced to sumcheck, which is reminiscent of the well-known distributed sumcheck protocol from <em>[61]</em> (also provided in Appx. D.2). Unfortunately, we cannot <em>directly</em> apply or adapt this protocol, as it requires each server to hold a contiguous segment of the hypercube, e.g., <span class="math">\\mathsf{S}_{i}</span> holds <span class="math">f(\\widetilde{i},\\bm{x})</span>. In contrast, as in Fig. 1, for the polynomials in (ii), each server only holds <em>non-contiguous</em> segments derived from its subtree.</p>

    <p class="text-gray-300"><em>Layered distributed sumcheck.</em> Actually, the problem can be generalized as follows: Let <span class="math">N=2^{s}</span>. To compute <span class="math">\\mathcal{P}</span> of sumcheck on an <span class="math">(\\ell+1)</span>-variate polynomial <span class="math">f</span>, while each server <span class="math">\\mathsf{S}_{i}</span> only has access to <span class="math">f_{j}^{(i)}(\\bm{x}):=f(\\mathds{1}_{\\ell-s-j},0,\\widetilde{i},\\bm{x})</span> for any <span class="math">j\\in[\\ell-s]</span>, while <span class="math">\\mathsf{S}_{0}</span> additionally has a <span class="math">(s+1)</span>-variate polynomial <span class="math">f^{\\prime}(\\bm{x}):=f(\\mathds{1}_{\\ell-s-1},1,\\bm{x})</span>. We leverage the following observation to design a distributed protocol:</p>

    <p class="text-gray-300"><span class="math">H=\\sum_{\\bm{x}\\in\\{0,1\\}^{\\ell+1}}f(\\bm{x})=\\sum_{j=1}^{\\ell-s}\\sum_{\\bm{x}\\in\\{0,1\\}^{s+j}}f(\\mathds{1}_{\\ell-s-j},0,\\bm{x})+\\sum_{\\bm{x}\\in\\{0,1\\}^{s+1}}f(\\mathds{1}_{\\ell-s-1},1,\\bm{x})</span> (5)</p>

    <p class="text-gray-300">Eq. (5) indicates that the sumcheck on <span class="math">f</span> can be interpreted as the sumcheck on the sum of <span class="math">\\ell-s+1</span> sub-polynomials <span class="math">\\{f_{j}\\}_{j\\in[\\ell-s]},f^{\\prime}</span>. For each of <span class="math">\\{f_{j}\\}_{j\\in[\\ell-s]}</span>, each <span class="math">\\mathsf{S}_{i}</span> precisely holds the required partial polynomial for distributed sumcheck. Hence, the servers can run <span class="math">\\ell-s</span> distributed sumchecks in parallel. Finally, in each round <span class="math">\\mathsf{S}_{0}</span> aggregates the partial proofs along with the last instance. Specifically,</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In the <span class="math">l</span>-th round (<span class="math">l\\in[\\ell-s]</span>),</li>

      <li><span class="math">\\mathsf{S}_{i}</span> runs the sumcheck on <span class="math">f_{l}^{(i)},...,f_{\\ell-s}^{(i)}</span> to get <span class="math">\\ell-s-l+1</span> round polynomials, and sends a univariate polynomial <span class="math">g_{l}^{(i)}</span> to <span class="math">\\mathsf{S}_{0}</span>, as the sum of the round polynomials. <span class="math">\\mathsf{S}_{0}</span> additionally runs the sumcheck on <span class="math">f^{\\prime}</span> and obtains the round polynomial <span class="math">g_{l}^{\\prime}</span>. <span class="math">\\mathsf{S}_{0}</span> aggregates these <span class="math">\\{g_{l}^{(i)}\\}_{i\\in[0,N-1]}</span> and <span class="math">g_{l}^{\\prime}</span> by summing them up, and sends the aggregated univariate polynomial as the final round polynomial.</li>

      <li>In this round, <span class="math">f_{l}^{(i)}</span> is folded to an evaluation on <span class="math">\\bm{r}[1:l]</span>, where <span class="math">\\bm{r}[1:l]</span> are random challenges from <span class="math">\\mathcal{V}</span> in previous rounds. Each <span class="math">\\mathsf{S}_{i}</span> sends its point to <span class="math">\\mathsf{S}_{0}</span>. <span class="math">\\mathsf{S}_{0}</span> uses these <span class="math">N</span> points to construct a <span class="math">s</span>-variate polynomial <span class="math">\\hat{f}_{l}</span>. Meanwhile, <span class="math">f^{\\prime}</span> is folded to a <span class="math">s</span>-variate polynomial <span class="math">\\hat{f}^{\\prime}</span>. <span class="math">\\mathsf{S}_{0}</span> updates <span class="math">f^{\\prime}</span> such that <span class="math">f^{\\prime}(0,\\bm{x})=\\hat{f}_{l}(\\bm{x})</span> and <span class="math">f^{\\prime}(1,\\bm{x})=\\hat{f}^{\\prime}(\\bm{x})</span>.</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>After the round <span class="math">(\\ell-s)</span>, <span class="math">\\mathsf{S}_{0}</span> continues to run the sumcheck on <span class="math">(s+1)</span>-variate polynomial <span class="math">f^{\\prime}</span> in last <span class="math">s</span> rounds.</li>

    </ol>

    <p class="text-gray-300">We refer to the above as a <em>layered</em> distributed sumcheck. Intuitively, for condition (ii) mentioned above, the <span class="math">j</span>-th sub-sumcheck checks the correctness of the multiplication gates at the <span class="math">j</span>-th layer of the product tree (Refer to Fig. 1).</p>

    <p class="text-gray-300">Additionally, at the end of the sumcheck, the servers need to generate a proof for the evaluation of <span class="math">f</span> at a random point using a multilinear PCS. We note that when the PCS is instantiated with PST <em>[46]</em>, this evaluation can also be performed in a <em>layered</em> distributed manner. The formal constructions for the layered distributed protocols, along with the complete distributed prodcheck and permcheck protocols, are provided in Appx. D.4 and Appx. D.5 for interested readers.</p>

    <p class="text-gray-300"><em>Efficiency.</em> During the layered distributed sumcheck and multilinear PCS, the workload for each server is <span class="math">O\\left(\\frac{2^{\\ell}}{N}\\right)</span>, with <span class="math">\\mathsf{S}_{0}</span> performing an additional <span class="math">O(N\\ell)</span> work. The total communication is <span class="math">O(N\\ell)</span>. The round complexity of the former is <span class="math">O(\\ell)</span>, and the latter is <span class="math">O(1)</span>. Complexities in distributed prodcheck and permcheck follows the same bound. Note that both the proof size and the verifier time remain <span class="math">O(\\ell)</span>.</p>

    <p class="text-gray-300">Collaborative proof. By replacing the original classic permcheck in HyperPlonk <em>[13]</em> with the newly-designed permcheck in §5.1, we obtain a zk-SNARK for general circuits. We refer to this modified protocol as HyperPlonk++, an MPC-friendly variant of the former. Now, it is straightforward to put the building blocks together to generate collaborative proof for HyperPlonk++. We have the following theorem:</p>

    <h6 id="sec-20" class="text-base font-medium mt-4">Theorem 1.</h6>

    <p class="text-gray-300">Let <span class="math">(\\mathsf{Setup},\\mathsf{Prove},\\mathsf{Verify})</span> be the algorithms of HyperPlonk++, a zk-SNARK for general circuits. There exists a collaborative zk-SNARK <span class="math">(\\mathsf{Setup},\\mathsf{II},\\mathsf{Verify})</span>, where <span class="math">\\Pi</span> is an MPC protocol that securely computes <span class="math">\\mathsf{Prove}</span> in the <span class="math">\\{\\mathcal{F}_{\\mathsf{co}\\text{-}\\mathsf{MSM}},\\mathcal{F}_{\\mathsf{PSS2SSS}}\\}</span>-hybrid world against a semi-honest adversary who corrupts at most <span class="math">t</span> servers.</p>

    <p class="text-gray-300">The full constructions of HyperPlonk++ and its collaborative proof are provided in Appx. F.1, and the security analysis of the above theorem is detailed in Appx. F.2.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><em>Efficiency.</em> For a general circuit <span class="math">\\mathcal{C}</span> where $n:=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, the asymptotic complexity of the prover time, verifier time, and proof size in HyperPlonk++ remains unchanged compared to <em>[13]</em>. In the collaborative proof, each server incurs </span>O\\left(\\frac{n}{N}\\right)<span class="math"> time and space complexity. The communication for each server is </span>O\\left(\\frac{n}{N}\\right)<span class="math">. The round complexity is </span>O(\\log n)<span class="math">. Specifically, when </span>n\\gg N<span class="math">, the total communication is approximately </span>\\epsilon\\cdot n<span class="math">, where </span>\\epsilon:=\\frac{N}{k}<span class="math">. In the pre-processing model, the protocol requires only </span>O(N\\log n)$ randomness due to the collaborative MSM.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-21" class="text-xl font-semibold mt-8">5.3 Collaborative proof for data-parallel circuit</h3>

    <p class="text-gray-300">In this subsection, we focus on data-parallel circuits, where our protocol achieves sublinear communication costs, offering greater efficiency compared to the general circuit case.</p>

    <p class="text-gray-300">The improvement arises from computing the PSS of <span class="math">\\mathsf{A}_{M^{\\prime}}</span>, which introduces a linear total communication for general circuits. Recall that in the permcheck protocol from §5.1, <span class="math">\\mathsf{A}_{M^{\\prime}}</span> corresponds precisely to the hypercube of <span class="math">\\widehat{\\mathsf{eq}}(\\bm{r_{1}},\\sigma(\\bm{x}))</span>. However, for general circuits, due to the arbitrary nature of <span class="math">\\sigma</span>, each server cannot compute the PSS of this hypercube with both <span class="math">O\\left(\\frac{2^{\\ell}}{N}\\right)</span> time complexity and sublinear communication simultaneously. In contrast, for data-parallel circuits, we demonstrate that this is actually feasible. Suppose a data-parallel circuit <span class="math">\\mathcal{C}</span> consists of <span class="math">2^{s^{\\prime}}</span> identical sub-circuits, <span class="math">\\mathcal{C}_{0},\\ldots,\\mathcal{C}_{2^{s^{\\prime}}-1}</span>, and assume <span class="math">k=2^{s^{\\prime}}</span> without loss of generality, where <span class="math">k</span> is the packing factor of the PSS. Hence, each sub-circuit shares the same permutation function <span class="math">\\sigma^{\\prime}:\\{0,1\\}^{\\ell-s^{\\prime}}\\to\\{0,1\\}^{\\ell-s^{\\prime}}</span>.</p>

    <p class="text-gray-300">Our packing strategy. For data-parallel circuits, instead of packing elements in <span class="math">\\mathsf{A}_{M^{\\prime}}</span> <em>one-by-one</em> as usual, we adopt a new packing strategy: we pack the <span class="math">k=2^{s^{\\prime}}</span> elements at the <em>same position</em> of each sub-circuit into one vector and try to compute its PSS. Specifically, for any <span class="math">\\bm{b_{2}}\\in\\{0,1\\}^{\\ell-s^{\\prime}}</span>, each server needs to compute the PSS of the vector <span class="math">\\bm{x}_{\\bm{b_{2}}}:=\\left\\{M^{\\prime}(\\bm{b_{1}},\\bm{b_{2}})\\right\\}_{\\bm{b_{1}}\\in\\{0,1\\}^{s^{\\prime}}}</span>. We show each server can perform this computation locally:</p>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a> Figure 3: Performance comparison between the local provers of HyperPlonk and HyperPlonk++.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each server computes  <span class="math">\\pmb{y} \\coloneqq \\{\\widehat{\\mathbf{eq}}(\\pmb{r}_1[1:s&#x27;], \\pmb{b}_1)\\}_{b_1 \\in \\{0,1\\}^{s&#x27;}}</span>  and locally converts it into PSS  <span class="math">\\llbracket \\pmb{y} \\rrbracket_{k-1}</span> .</li>

      <li>Each server computes  <span class="math">c_{b_2} \\coloneqq \\widehat{\\mathbf{eq}}(\\boldsymbol{r}_1[s&#x27; + 1 : \\ell], \\sigma&#x27;(\\boldsymbol{b}_2))</span>  and  <span class="math">\\boldsymbol{x}_{b_2} = c_{b_2} \\cdot [[\\boldsymbol{y}]]</span> , for any  <span class="math">b_2 \\in \\{0,1\\}^{\\ell - s&#x27;}</span> .</li>

    </ol>

    <p class="text-gray-300">The above computation can be completed by each server within  <span class="math">O\\left(\\frac{2^{\\ell}}{k}\\right)</span>  time and space complexity, without any need for communication. Furthermore, when the circuit is data-parallel, this packing strategy can also be extended to other polynomials involved in the protocol, without compromising the correctness of the collaborative proof.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Efficiency. For a data-parallel circuit  <span class="math">\\mathcal{C}</span>  where  $n\\coloneqq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> , in the collaborative proof, each server incurs  </span>O\\left(\\frac{n}{N}\\right)<span class="math">  time and space complexity. Due to the above improvement, the total communication is only  </span>O(N\\log n)<span class="math">  from the collaborative and distributed protocols. The round complexity is  </span>O(\\log n)$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We implement our protocols, along with the prototypes of monolithic HyperPlonk [13] and HyperPlonk++. The codebase is built upon the mpc-net library [44] and the arkworks library [1]. Our implementation involves about 5000 lines of Rust code. We provide our codebase publicly <span class="math">^3</span> .</p>

    <p class="text-gray-300">Hardware. Our protocols are evaluated with up to 256 machines of instance type c7. large, each being consumer-level with 4 GB of RAM. In comparison, zkSaaS [27] is evaluated in a cluster with a powerful leader, which is a g7.8xlarge instance with 256 GB RAM, and other c7. large workers.</p>

    <p class="text-gray-300">PSS setting. The PSS packing factor is set to  <span class="math">k = \\frac{N}{8}</span>  for both our protocols and [27]. Due to the security model we adopt (§3), our protocols are secure against at most  <span class="math">t = \\frac{N}{4}</span>  corrupted servers. One can adapt this according to different scenarios.</p>

    <p class="text-gray-300">Network. For testing the adaptability of MPC protocols, we consider three different network settings: (i) Local network with 10 Gbps bandwidth and 0.1 ms latency, (ii) LAN network with 1 Gbps bandwidth and 2 ms latency, and (iii) WAN network with 50 Mbps bandwidth and 50 ms latency.</p>

    <p class="text-gray-300">According to discussion in §3, all experiments only evaluate the online execution time of the corresponding protocols.</p>

    <p class="text-gray-300">We first evaluate the protocols and conclusions presented in §5.1 and §5.2, where the circuits are general.</p>

    <p class="text-gray-300">Evaluations for permcheck. We conduct two experiments to demonstrate that our new permcheck (§5.1) is more MPC-friendly than the classic permcheck (Appx. C.5). The experimental results are as follows: (i) the new permcheck introduces a slight increase in prover time for the monolithic HyperPlonk++ compared to HyperPlonk; as</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Scheme</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Setting</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Time</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Comm. per server</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">New Classic</td>

            <td class="px-3 py-2 border-b border-gray-700">n = 221, N = 128, Local</td>

            <td class="px-3 py-2 border-b border-gray-700">62.8s</td>

            <td class="px-3 py-2 border-b border-gray-700">40.9 MB</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">271.5s</td>

            <td class="px-3 py-2 border-b border-gray-700">656 MB</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">New Classic</td>

            <td class="px-3 py-2 border-b border-gray-700">n = 218, N = 128, Local</td>

            <td class="px-3 py-2 border-b border-gray-700">15.6s</td>

            <td class="px-3 py-2 border-b border-gray-700">10.5 MB</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">49.9s</td>

            <td class="px-3 py-2 border-b border-gray-700">100 MB</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">New Classic</td>

            <td class="px-3 py-2 border-b border-gray-700">n = 221, N = 256, Local</td>

            <td class="px-3 py-2 border-b border-gray-700">51.0s</td>

            <td class="px-3 py-2 border-b border-gray-700">33.0 MB</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">173.8s</td>

            <td class="px-3 py-2 border-b border-gray-700">397.6 MB</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">New Classic</td>

            <td class="px-3 py-2 border-b border-gray-700">n = 221, N = 128, WAN</td>

            <td class="px-3 py-2 border-b border-gray-700">71.5s</td>

            <td class="px-3 py-2 border-b border-gray-700">40.9 MB</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">378.0s</td>

            <td class="px-3 py-2 border-b border-gray-700">656 MB</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 2: Performance comparison between collaborative proofs for the new permcheck and the classic permcheck in four settings, where the first can be taken as the baseline.</p>

    <p class="text-gray-300">!<a href="img-3.jpeg">img-3.jpeg</a> Figure 4: Performance of the collaborative proof vs. the local prover across various circuit sizes and server counts. The slash lines indicate estimated data due to memory limits.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a reward, (ii) compared to the collaborative classic permcheck (Appx. E.5), the collaborative proof for the new permcheck has significantly lower communication cost (approximately  <span class="math">\\frac{1}{10}</span> ) and achieves faster proof generation. Compare HyperPlonk++ with HyperPlonk. HyperPlonk++ is derived by replacing the classic permcheck in the original HyperPlonk [13] (Appx. C.5) with the construction presented in §5.1. Therefore, we compare the performance of HyperPlonk++ against the original HyperPlonk to assess the impact of the new permcheck on the prover time. The results are summarized in Fig. 3. HyperPlonk++ retains the property of linear prover time; however, due to the new permcheck introducing several additional calls to the sumcheck and multilinear PCS, the concrete prover time slightly increases. Specifically, for a circuit of size  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= 2^{19}<span class="math"> , HyperPlonk takes 516s to generate the proof, while HyperPlonk++ takes 634s, resulting in approximately a  </span>20\\%$  increase in time. However, considering that HyperPlonk++ achieves better performance in collaborative proofs, this trade-off is worthwhile.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Compare collaborative proofs for two permchecks. We conduct a microbenchmark to compare the performance of the collaborative proof for our new permcheck (Step 2 in Fig. 21) against the collaborative proof for the classic permcheck  <span class="math">(\\Pi_{\\mathrm{co-permcheck}}</span>  in Appx. E.5). The evaluation results are summarized in Tab. 2. In the experiment, we conduct comparison tests in four different settings. Taking the first setting as a baseline, the results indicate that: (i) under the same settings, the collaborative proof for the classic permcheck incurs approximately 10 times more per server communication cost compared to the new permcheck, which aligns with our analysis of the concrete communication cost (roughly  <span class="math">10\\epsilon \\cdot n</span>  for the former and  <span class="math">\\epsilon \\cdot n</span>  for the latter); (ii) moreover, the collaborative proof for the classic permcheck also has significantly higher computational cost. In summary, we conclude that the new permcheck is more MPC-friendly than the classic permcheck.</p>

    <p class="text-gray-300">Compare with local prover. We compare the performance of the collaborative HyperPlonk++ (Fig. 21) against its corresponding local prover, focusing on the following two aspects:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">N</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Si's comm.</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Local</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">LAN</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">WAN</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">218</td>

            <td class="px-3 py-2 border-b border-gray-700">32</td>

            <td class="px-3 py-2 border-b border-gray-700">18 MB</td>

            <td class="px-3 py-2 border-b border-gray-700">32.2s (10.2×)</td>

            <td class="px-3 py-2 border-b border-gray-700">32.4s (10.1×)</td>

            <td class="px-3 py-2 border-b border-gray-700">36.8s (8.9×)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">64</td>

            <td class="px-3 py-2 border-b border-gray-700">12 MB</td>

            <td class="px-3 py-2 border-b border-gray-700">24.9s (13.2×)</td>

            <td class="px-3 py-2 border-b border-gray-700">25.0s (13.1×)</td>

            <td class="px-3 py-2 border-b border-gray-700">28.6s (11.5×)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">128</td>

            <td class="px-3 py-2 border-b border-gray-700">12 MB</td>

            <td class="px-3 py-2 border-b border-gray-700">19.8s (16.6×)</td>

            <td class="px-3 py-2 border-b border-gray-700">19.9s (16.5×)</td>

            <td class="px-3 py-2 border-b border-gray-700">23.5s (13.9×)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">256</td>

            <td class="px-3 py-2 border-b border-gray-700">19 MB</td>

            <td class="px-3 py-2 border-b border-gray-700">15.6s (21.1×)</td>

            <td class="px-3 py-2 border-b border-gray-700">15.8s (20.8×)</td>

            <td class="px-3 py-2 border-b border-gray-700">20.4s (16.0×)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">221</td>

            <td class="px-3 py-2 border-b border-gray-700">32</td>

            <td class="px-3 py-2 border-b border-gray-700">127 MB</td>

            <td class="px-3 py-2 border-b border-gray-700">184.1s (13.8×)</td>

            <td class="px-3 py-2 border-b border-gray-700">185.1s (13.7×)</td>

            <td class="px-3 py-2 border-b border-gray-700">206.5s (12.3×)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">64</td>

            <td class="px-3 py-2 border-b border-gray-700">69 MB</td>

            <td class="px-3 py-2 border-b border-gray-700">111.0s (22.9×)</td>

            <td class="px-3 py-2 border-b border-gray-700">111.6s (22.8×)</td>

            <td class="px-3 py-2 border-b border-gray-700">124.0s (20.5×)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">128</td>

            <td class="px-3 py-2 border-b border-gray-700">43 MB</td>

            <td class="px-3 py-2 border-b border-gray-700">90.8s (28.0×)</td>

            <td class="px-3 py-2 border-b border-gray-700">91.2s (27.8×)</td>

            <td class="px-3 py-2 border-b border-gray-700">99.8s (25.5×)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">256</td>

            <td class="px-3 py-2 border-b border-gray-700">39 MB</td>

            <td class="px-3 py-2 border-b border-gray-700">67.4s (37.7×)</td>

            <td class="px-3 py-2 border-b border-gray-700">67.7s (37.5×)</td>

            <td class="px-3 py-2 border-b border-gray-700">75.7s (33.6×)</td>

          </tr>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Table 3: Performance of collaborative proof (speedup) under different network settings. Communication is measured per server. When  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= 2^{18}<span class="math"> , the local prover time is 328 seconds; when  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= 2^{21}$ , the (estimated) time is 2400 seconds.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Scheme</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Time in Local</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Time in WAN</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Space</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Comm.</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Ours</td>

            <td class="px-3 py-2 border-b border-gray-700">Si</td>

            <td class="px-3 py-2 border-b border-gray-700">28.0×</td>

            <td class="px-3 py-2 border-b border-gray-700">25.5×</td>

            <td class="px-3 py-2 border-b border-gray-700">11.8×</td>

            <td class="px-3 py-2 border-b border-gray-700">43 MB</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[27]</td>

            <td class="px-3 py-2 border-b border-gray-700">S0</td>

            <td class="px-3 py-2 border-b border-gray-700">0.9×</td>

            <td class="px-3 py-2 border-b border-gray-700">0.1×</td>

            <td class="px-3 py-2 border-b border-gray-700">0.86×</td>

            <td class="px-3 py-2 border-b border-gray-700">90 GB</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">Si</td>

            <td class="px-3 py-2 border-b border-gray-700">0.9×</td>

            <td class="px-3 py-2 border-b border-gray-700">0.1×</td>

            <td class="px-3 py-2 border-b border-gray-700">16.8×</td>

            <td class="px-3 py-2 border-b border-gray-700">718 MB</td>

          </tr>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Table 4: Performance comparison with [27],  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= 2^{21}, N = 128<span class="math"> . Time and space savings are measured as  </span>\\frac{T_{\\mathcal{P}}}{T}<span class="math">  and  </span>\\frac{S_{\\mathcal{P}}}{S}<span class="math"> , where  </span>T, S<span class="math">  and  </span>T_{\\mathcal{P}}, S_{\\mathcal{P}}<span class="math">  are the time and space usage of the collaborative protocols and local prover, respectively. Communication is per server.  </span>S_0$  denotes the leader in [27].</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Scalability. To evaluate scalability, we first vary the number of gates from  <span class="math">2^{16}</span>  to  <span class="math">2^{24}</span> , representing circuits of different scales in real-world applications. For the collaborative proof, the number of servers is adjusted from 32 to 256, with the servers connected through a Local network. For the monolithic prover, a c7. large machine simulates a low-specification client PC. Fig. 4 presents the results. Two points highlight the protocol's good scalability: (i) The client cannot handle circuits when  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">&gt; 2^{19}<span class="math"> , while the collaborative proof can handle circuits up to  </span>k = \\frac{N}{8}<span class="math">  times larger; (ii) The collaborative proof exhibits a linear time improvement with  </span>N<span class="math"> , and the efficiency gain becomes more significant for larger circuits. Specifically, the time improvement factor lies between  </span>N<span class="math">  and  </span>k<span class="math"> , as the collaborative proof is a mixed-mode of distributed and collaborative protocols. For instance, when  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= 2^{24}<span class="math"> ,  </span>N = 256<span class="math"> , and  </span>k = 32<span class="math"> , the improvement is approximately  </span>60 \\times$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Network adaptability. To demonstrate the adaptability of our protocol under different network environments, we fix the circuit sizes at  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= 2^{18}<span class="math">  and  </span>2^{21}$  separately, and run experiments under various network configurations to measure the corresponding speedup relative to the monolithic prover. The results are presented in Tab. 3. Two points worth noting: (i) Communication per server increases as the circuit size grows, but the overhead remains concretely small, due to the MPC-friendly permcheck we design; (ii) A worse network leads to fewer efficiency gains, because the communication takes longer time; however, this loss is slight, as significant improvements are still observed even under a WAN environment.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Compare with [27]. To demonstrate the advantages of collaborative proof for multivariate SNARKs compared to univariate SNARKs in our setting, we further compare the performance of our protocol (Fig. 21) with collaborative Plonk from [27].</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Methodology. We evaluate the time and space savings, as well as the per-server communication cost, for each protocol when generating a proof for the same circuit  $(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= 2^{21})$  using 128 servers. The implementations of collaborative Plonk and the corresponding monolithic prover are from their open-source codebase [48]. Note that provers of multivariate SNARKs like HyperPlonk and univariate SNARKs like Plonk inherently have different properties: the former achieves linear time complexity, whereas the latter has quasi-linear time complexity; both have similar linear space complexity. We justify the fairness of the experiment based on two key points: (i) both HyperPlonk [13] and Plonk [25] use arithmetic circuits as the computation model, and (ii) the experiment measures the time and space savings relative to a monolithic prover as a baseline. Finally, we note that in [27], the reported running time is divided by the leader's thread count, while here we do not consider any multi-thread optimization in the report.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Scheme</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Time in WAN</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Comm. per server</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Total comm.</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">L=8</td>

            <td class="px-3 py-2 border-b border-gray-700">Local P</td>

            <td class="px-3 py-2 border-b border-gray-700">4800s*</td>

            <td class="px-3 py-2 border-b border-gray-700">\\</td>

            <td class="px-3 py-2 border-b border-gray-700">\\</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">w/o P.S.</td>

            <td class="px-3 py-2 border-b border-gray-700">165.8s (28.9×)</td>

            <td class="px-3 py-2 border-b border-gray-700">75.7 MB</td>

            <td class="px-3 py-2 border-b border-gray-700">9.5 GB</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">w/ P.S.</td>

            <td class="px-3 py-2 border-b border-gray-700">147.8s (32.5×)</td>

            <td class="px-3 py-2 border-b border-gray-700">12.2 MB</td>

            <td class="px-3 py-2 border-b border-gray-700">1.5 GB</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">L=16</td>

            <td class="px-3 py-2 border-b border-gray-700">Local P</td>

            <td class="px-3 py-2 border-b border-gray-700">9600s*</td>

            <td class="px-3 py-2 border-b border-gray-700">\\</td>

            <td class="px-3 py-2 border-b border-gray-700">\\</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">w/o P.S.</td>

            <td class="px-3 py-2 border-b border-gray-700">305.0s (31.5×)</td>

            <td class="px-3 py-2 border-b border-gray-700">140.3 MB</td>

            <td class="px-3 py-2 border-b border-gray-700">17.5 GB</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">w/ P.S.</td>

            <td class="px-3 py-2 border-b border-gray-700">256.8s (37.4×)</td>

            <td class="px-3 py-2 border-b border-gray-700">13.3 MB</td>

            <td class="px-3 py-2 border-b border-gray-700">1.7 GB</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 5: Performance comparison of collaborative proof for a data-parallel circuit of the Merkle tree, w/ or w/o the packing strategy (P.S.) in §5.3. * denotes the estimated data.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Tab. 4 reports the results. It is observed that the collaborative Plonk incurs significant communication overhead for the leader  <span class="math">S_0</span> , and across both Local and WAN networks, the protocol fails to achieve time and space efficiency gains without additional hardware optimization on the leader. Our protocol avoids these issues. We also note that the advantage of our protocol remains prominent across varying circuit sizes  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{C}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ . Therefore, we conclude that, in our setting, multivariate SNARK is the better choice.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">§5.3 achieves sublinear communication for data-parallel circuits. We demonstrate this feature through a specific application: a client wants to convince that she knows the leaves of a Merkle tree with respect to a public Merkle root, where the hash function applied is SHA-256. The circuit size of each SHA-256 circuit is roughly  <span class="math">2^{18}</span>  gates. For a Merkle tree with  <span class="math">L</span>  leaves, the client needs to deal with a circuit consisting of  <span class="math">2L - 1</span>  SHA-256 hashes, which is data-parallel. She uses the strategy in §5.3 to pack and share PSS ( <span class="math">k \\geq 2L</span> ), thereby the collaborative proof can avoid linear communication.</p>

    <p class="text-gray-300">We demonstrate the advantage of reduced communication through an experiment with  <span class="math">N = 128</span>  servers linked in a WAN, generating a collaborative proof for the  <span class="math">L = 8, 16</span>  Merkle trees, where the total circuit scales are approximately  <span class="math">2^{22}</span>  and  <span class="math">2^{23}</span> , respectively. The results are summarized in Tab. 5. Note that with the optimization, the collaborative proof achieves better time efficiency, while the communication cost remains almost unchanged as the instance size increases. This feature is particularly beneficial for bandwidth-sensitive scenarios. We also note that this implies our protocol achieves better performance on data-parallel circuits compared to previous works (e.g., [27]), as we incorporate specific optimizations for such circuits, which they do not.</p>

    <p class="text-gray-300">Our main contribution is the first scalable collaborative zk-SNARK, applicable to proof delegation and other applications of collaborative zk-SNARK. Our collaborative proof features excellent scalability, low communication, and eliminates the need for expensive pre-processing. Experiments provide evidences. Along the way to our main contribution, we propose many efficient constructions for multivariate primitives, which have the potential to make other zk-SNARKs "collaborative".</p>

    <p class="text-gray-300">Achieving malicious security. In this work, our primary goal is to improve the efficiency and scalability of collaborative zk-SNARKs; therefore, semi-honest security serves as a valuable stepping stone toward this objective. However, we note that in practical applications, malicious security is often a requirement. Below, we make two remarks in this regard.</p>

    <p class="text-gray-300">First, as discussed in [27, Sec. 1.1], the proof output by a collaborative zk-SNARK remains sound even if all servers are corrupted by a malicious adversary. In other words, a malicious adversary in the proof delegation cannot compromise the soundness of the proof, which is crucial for zk-SNARKs. Nevertheless, we emphasize that a malicious adversary may still compromise the privacy of witness: as observed by [14], the adversary may deviate from the protocol and adopt strategies such as selective failure attacks to infer partial information about the witness. Thus, it is interesting to explore how to achieve privacy in the presence of a malicious adversary.</p>

    <p class="text-gray-300">Moreover, we conjecture that our semi-honest protocol can be extended to provide malicious security (with abort) by incorporating lightweight verification mechanisms, as demonstrated in prior works [29, 28, 31, 32, 20, 21]. Notably, recent works [32, 20] focus on designing general malicious-secure MPC protocols for arithmetic</p>

    <p class="text-gray-300">circuits and similarly adopt PSS as their primary tool. According to <em>[32]</em>, malicious security can be achieved by using <em>information-theoretic MACs</em> <em>[17]</em> to authenticate PSS. These standard techniques are sufficient to verify the correctness of computation over secret shares and typically incur an overhead of at most <span class="math">2\\times</span>. Since our work also employs PSS as the main building block, we conjecture these techniques can be directly adapted. We leave the concrete instantiation of such an extension as future work.</p>

    <h2 id="sec-27" class="text-2xl font-bold">Acknowledgement</h2>

    <p class="text-gray-300">The authors thank Alex Ozdemir for his helpful discussions and comments on an earlier version of this work. We also thank Guru-Vamsi Policharla for valuable advice on understanding the details of zkSaaS and its implementation. Additionally, we thank the anonymous reviewers for their insightful comments, which helped improve the quality of this paper.</p>

    <p class="text-gray-300">This work is funded by the National Key Research and Development Project (Grant No: 2022YFB2703100), the “Leading Goose” R&D Program of Zhejiang (Grant No. 2022C01126), the National Natural Science Foundation of China (Grant No. 62232002) and Input Output (iohk.io).</p>

    <h2 id="sec-28" class="text-2xl font-bold">References</h2>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[1] arkworks contributors. arkworks zksnark ecosystem. https://arkworks.rs, 2022.</li>

      <li>[2] Arasu Arun, Srinath T. V. Setty, and Justin Thaler. Jolt: SNARKs for virtual machines via lookups. In Marc Joye and Gregor Leander, editors, EUROCRYPT 2024, Part VI, volume 14656 of LNCS, pages 3–33. Springer, Cham, May 2024.</li>

      <li>[3] David Balbás, Dario Fiore, María Isabel González Vasco, Damien Robissout, and Claudio Soriente. Modular sumcheck proofs with applications to machine learning and image processing. In Weizhi Meng, Christian Damsgaard Jensen, Cas Cremers, and Engin Kirda, editors, ACM CCS 2023, pages 1437–1451. ACM Press, November 2023.</li>

      <li>[4] J. Bar-Ilan and D. Beaver. Non-cryptographic fault-tolerant computing in constant number of rounds of interaction. In Proceedings of the Eighth Annual ACM Symposium on Principles of Distributed Computing, PODC ’89, page 201–209, New York, NY, USA, 1989. Association for Computing Machinery.</li>

      <li>[5] Carsten Baum, Ivan Damgård, and Claudio Orlandi. Publicly auditable secure multi-party computation. In Michel Abdalla and Roberto De Prisco, editors, SCN 14, volume 8642 of LNCS, pages 175–196. Springer, Cham, September 2014.</li>

      <li>[6] Rishabh Bhadauria, Zhiyong Fang, Carmit Hazay, Muthuramakrishnan Venkitasubramaniam, Tiancheng Xie, and Yupeng Zhang. Ligero++: A new optimized sublinear IOP. In Jay Ligatti, Xinming Ou, Jonathan Katz, and Giovanni Vigna, editors, ACM CCS 2020, pages 2025–2038. ACM Press, November 2020.</li>

      <li>[7] Jonathan Bootle, Andrea Cerulli, Jens Groth, Sune K. Jakobsen, and Mary Maller. Arya: Nearly linear-time zero-knowledge proofs for correct program execution. In Thomas Peyrin and Steven Galbraith, editors, ASIACRYPT 2018, Part I, volume 11272 of LNCS, pages 595–626. Springer, Cham, December 2018.</li>

      <li>[8] Benedikt Bünz, Jonathan Bootle, Dan Boneh, Andrew Poelstra, Pieter Wuille, and Greg Maxwell. Bulletproofs: Short proofs for confidential transactions and more. In 2018 IEEE Symposium on Security and Privacy, pages 315–334. IEEE Computer Society Press, May 2018.</li>

      <li>[9] Vitalik Buterin. The different types of zk-evms. https://vitalik.eth.limo/general/2022/08/04/zkevm.html, Aug 2022.</li>

      <li>[10] Matteo Campanelli, Nicolas Gailly, Rosario Gennaro, Philipp Jovanovic, Mara Mihali, and Justin Thaler. Testudo: Linear time prover SNARKs with constant size proofs and square root size universal setup. In Abdelrahaman Aly and Mehdi Tibouchi, editors, LATINCRYPT 2023, volume 14168 of LNCS, pages 331–351. Springer, Cham, October 2023.</li>

      <li>[11] Ran Canetti. Security and composition of multiparty cryptographic protocols. Journal of Cryptology, 13(1):143–202, January 2000.</li>

    </ul>

    <p class="text-gray-300">-</p>

    <p class="text-gray-300">[12] Binyi Chen, Benedikt Bünz, Dan Boneh, and Zhenfei Zhang. HyperPlonk: Plonk with linear-time prover and high-degree custom gates. Cryptology ePrint Archive, Report 2022/1355, 2022.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[13] Binyi Chen, Benedikt Bünz, Dan Boneh, and Zhenfei Zhang. HyperPlonk: Plonk with linear-time prover and high-degree custom gates. In Carmit Hazay and Martijn Stam, editors, EUROCRYPT 2023, Part II, volume 14005 of LNCS, pages 499–530. Springer, Cham, April 2023.</li>

      <li>[14] Alessandro Chiesa, Ryan Lehmkuhl, Pratyush Mishra, and Yinuo Zhang. Eos: Efficient private delegation of zkSNARK provers. In Joseph A. Calandrino and Carmela Troncoso, editors, USENIX Security 2023, pages 6453–6469. USENIX Association, August 2023.</li>

      <li>[15] Ivan Damgård, Yuval Ishai, and Mikkel Krøigaard. Perfectly secure multiparty computation and the computational overhead of cryptography. In Henri Gilbert, editor, EUROCRYPT 2010, volume 6110 of LNCS, pages 445–465. Springer, Berlin, Heidelberg, May / June 2010.</li>

      <li>[16] Ivan Damgård and Jesper Buus Nielsen. Scalable and unconditionally secure multiparty computation. In Alfred Menezes, editor, CRYPTO 2007, volume 4622 of LNCS, pages 572–590. Springer, Berlin, Heidelberg, August 2007.</li>

      <li>[17] Ivan Damgård, Valerio Pastro, Nigel P. Smart, and Sarah Zakarias. Multiparty computation from somewhat homomorphic encryption. In Reihaneh Safavi-Naini and Ran Canetti, editors, CRYPTO 2012, volume 7417 of LNCS, pages 643–662. Springer, Berlin, Heidelberg, August 2012.</li>

      <li>[18] Pankaj Dayama, Arpita Patra, Protik Paul, Nitin Singh, and Dhinakaran Vinayagamurthy. How to prove any NP statement jointly? Efficient distributed-prover zero-knowledge protocols. PoPETs, 2022(2):517–556, April 2022.</li>

      <li>[19] Changchang Ding and Yan Huang. Dubhe: Succinct zero-knowledge proofs for standard AES and related applications. In Joseph A. Calandrino and Carmela Troncoso, editors, USENIX Security 2023, pages 4373–4390. USENIX Association, August 2023.</li>

      <li>[20] Daniel Escudero, Vipul Goyal, Antigoni Polychroniadou, and Yifan Song. TurboPack: Honest majority MPC with constant online communication. In Heng Yin, Angelos Stavrou, Cas Cremers, and Elaine Shi, editors, ACM CCS 2022, pages 951–964. ACM Press, November 2022.</li>

      <li>[21] Daniel Escudero, Vipul Goyal, Antigoni Polychroniadou, Yifan Song, and Chenkai Weng. SuperPack: Dishonest majority MPC with constant online communication. In Carmit Hazay and Martijn Stam, editors, EUROCRYPT 2023, Part II, volume 14005 of LNCS, pages 220–250. Springer, Cham, April 2023.</li>

      <li>[22] Amos Fiat and Adi Shamir. How to prove yourself: Practical solutions to identification and signature problems. In Andrew M. Odlyzko, editor, CRYPTO’86, volume 263 of LNCS, pages 186–194. Springer, Berlin, Heidelberg, August 1987.</li>

      <li>[23] Matthew K. Franklin and Moti Yung. Communication complexity of secure computation (extended abstract). In 24th ACM STOC, pages 699–710. ACM Press, May 1992.</li>

      <li>[24] Ariel Gabizon and Zachary J. Williamson. plookup: A simplified polynomial protocol for lookup tables. Cryptology ePrint Archive, Report 2020/315, 2020.</li>

      <li>[25] Ariel Gabizon, Zachary J. Williamson, and Oana Ciobotaru. PLONK: Permutations over Lagrange-bases for oecumenical noninteractive arguments of knowledge. Cryptology ePrint Archive, Report 2019/953, 2019.</li>

      <li>[26] Sanjam Garg, Aarushi Goel, Abhishek Jain, Guru-Vamsi Policharla, and Sruthi Sekar. zkSaaS: Zero-knowledge SNARKs as a service. Cryptology ePrint Archive, Report 2023/905, 2023.</li>

      <li>[27] Sanjam Garg, Aarushi Goel, Abhishek Jain, Guru-Vamsi Policharla, and Sruthi Sekar. zkSaaS: Zero-knowledge SNARKs as a service. In Joseph A. Calandrino and Carmela Troncoso, editors, USENIX Security 2023, pages 4427–4444. USENIX Association, August 2023.</li>

      <li>[28] Daniel Genkin, Yuval Ishai, and Antigoni Polychroniadou. Efficient multi-party computation: From passive to active security via secure SIMD circuits. In Rosario Gennaro and Matthew J. B. Robshaw, editors, CRYPTO 2015, Part II, volume 9216 of LNCS, pages 721–741. Springer, Berlin, Heidelberg, August 2015.</li>

    </ul>

    <p class="text-gray-300">[29] Daniel Genkin, Yuval Ishai, Manoj Prabhakaran, Amit Sahai, and Eran Tromer. Circuits resilient to additive attacks with applications to secure computation. In David B. Shmoys, editor, 46th ACM STOC, pages 495–504. ACM Press, May / June 2014.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[30] Alexander Golovnev, Jonathan Lee, Srinath T. V. Setty, Justin Thaler, and Riad S. Wahby. Brakedown: Linear-time and field-agnostic SNARKs for R1CS. In Helena Handschuh and Anna Lysyanskaya, editors, CRYPTO 2023, Part II, volume 14082 of LNCS, pages 193–226. Springer, Cham, August 2023.</li>

      <li>[31] Vipul Goyal, Antigoni Polychroniadou, and Yifan Song. Unconditional communication-efficient MPC via hall’s marriage theorem. In Tal Malkin and Chris Peikert, editors, CRYPTO 2021, Part II, volume 12826 of LNCS, pages 275–304, Virtual Event, August 2021. Springer, Cham.</li>

      <li>[32] Vipul Goyal, Antigoni Polychroniadou, and Yifan Song. Sharing transformation and dishonest majority MPC with packed secret sharing. In Yevgeniy Dodis and Thomas Shrimpton, editors, CRYPTO 2022, Part IV, volume 13510 of LNCS, pages 3–32. Springer, Cham, August 2022.</li>

      <li>[33] Jens Groth. On the size of pairing-based non-interactive arguments. In Marc Fischlin and Jean-Sébastien Coron, editors, EUROCRYPT 2016, Part II, volume 9666 of LNCS, pages 305–326. Springer, Berlin, Heidelberg, May 2016.</li>

      <li>[34] Yanpei Guo, Xuanming Liu, Kexi Huang, Wenjie Qu, Tianyang Tao, and Jiaheng Zhang. DeepFold: Efficient multilinear polynomial commitment from reed-solomon code and its application to zero-knowledge proofs. In 34th USENIX Security Symposium (USENIX Security 25), 2025.</li>

      <li>[35] Ulrich Haböck. Multivariate lookups based on logarithmic derivatives. Cryptology ePrint Archive, Report 2022/1530, 2022.</li>

      <li>[36] Yuncong Hu, Pratyush Mishra, Xiao Wang, Jie Xie, Kang Yang, Yu Yu, and Yuwen Zhang. Dfs: Delegation-friendly zksnark and private delegation of provers. USENIX Security, 2025.</li>

      <li>[37] Aniket Kate, Gregory M. Zaverucha, and Ian Goldberg. Constant-size commitments to polynomials and their applications. In Masayuki Abe, editor, ASIACRYPT 2010, volume 6477 of LNCS, pages 177–194. Springer, Berlin, Heidelberg, December 2010.</li>

      <li>[38] Ahmed E. Kosba, Dimitrios Papadopoulos, Charalampos Papamanthou, and Dawn Song. MIRAGE: Succinct arguments for randomized algorithms with applications to universal zk-SNARKs. In Srdjan Capkun and Franziska Roesner, editors, USENIX Security 2020, pages 2129–2146. USENIX Association, August 2020.</li>

      <li>[39] Tianyi Liu, Tiancheng Xie, Jiaheng Zhang, Dawn Song, and Yupeng Zhang. Pianist: Scalable zkRollups via fully distributed zero-knowledge proofs. In 2024 IEEE Symposium on Security and Privacy, pages 1777–1793. IEEE Computer Society Press, May 2024.</li>

      <li>[40] Tianyi Liu, Xiang Xie, and Yupeng Zhang. zkCNN: Zero knowledge proofs for convolutional neural network predictions and accuracy. In Giovanni Vigna and Elaine Shi, editors, ACM CCS 2021, pages 2968–2985. ACM Press, November 2021.</li>

      <li>[41] Tao Lu, Yuxun Chen, Zonghui Wang, Xiaohang Wang, Wenzhi Chen, and Jiaheng Zhang. Batchzk: A fully pipelined gpu-accelerated system for batch generation of zero-knowledge proofs. In Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1, ASPLOS ’25, page 100–115, New York, NY, USA, 2025. Association for Computing Machinery.</li>

      <li>[42] Tao Lu, Haoyu Wang, Wenjie Qu, Zonghui Wang, Jinye He, Tianyang Tao, Wenzhi Chen, and Jiaheng Zhang. An efficient and extensible zero-knowledge proof framework for neural networks. Cryptology ePrint Archive, Report 2024/703, 2024.</li>

      <li>[43] Carsten Lund, Lance Fortnow, Howard J. Karloff, and Noam Nisan. Algebraic methods for interactive proof systems. In 31st FOCS, pages 2–10. IEEE Computer Society Press, October 1990.</li>

      <li>[44] Alex Ozdemir. collaborative-zkSNARK implementation. https://github.com/alex-ozdemir/collaborative-zksnark, 2022.</li>

    </ul>

    <p class="text-gray-300">[45] Alex Ozdemir and Dan Boneh. Experimenting with collaborative zk-SNARKs: Zero-knowledge proofs for distributed secrets. In Kevin R. B. Butler and Kurt Thomas, editors, USENIX Security 2022, pages 4291–4308. USENIX Association, August 2022.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[46] Charalampos Papamanthou, Elaine Shi, and Roberto Tamassia. Signatures of correct computation. In Amit Sahai, editor, TCC 2013, volume 7785 of LNCS, pages 222–242. Springer, Berlin, Heidelberg, March 2013.</li>

      <li>[47] Christodoulos Pappas and Dimitrios Papadopoulos. Sparrow: Space-efficient zksnark for data-parallel circuits and applications to zero-knowledge decision trees. In Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security, CCS ’24, page 3110–3124, New York, NY, USA, 2024. Association for Computing Machinery.</li>

      <li>[48] Guru-Vamsi Policharla. zkSaaS implementation. https://github.com/guruvamsi-policharla/zksaas, 2023.</li>

      <li>[49] Wenjie Qu, Yijun Sun, Xuanming Liu, Tao Lu, Yanpei Guo, Kai Chen, and Jiaheng Zhang. zkgpt: An efficient non-interactive zero-knowledge proof framework for llm inference. In 34th USENIX Security Symposium (USENIX Security 25), 2025.</li>

      <li>[50] Michael Rosenberg, Tushar Mopuri, Hossein Hafezi, Ian Miers, and Pratyush Mishra. Hekaton: Horizontally-scalable zksnarks via proof aggregation. In Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security, CCS ’24, page 929–940, New York, NY, USA, 2024. Association for Computing Machinery.</li>

      <li>[51] Berry Schoenmakers, Meilof Veeningen, and Niels de Vreede. Trinocchio: Privacy-preserving outsourcing by distributed verifiable computation. In Mark Manulis, Ahmad-Reza Sadeghi, and Steve Schneider, editors, ACNS 2016, volume 9696 of LNCS, pages 346–366, June 2016.</li>

      <li>[52] Srinath Setty. Spartan: Efficient and general-purpose zkSNARKs without trusted setup. In Daniele Micciancio and Thomas Ristenpart, editors, CRYPTO 2020, Part III, volume 12172 of LNCS, pages 704–737. Springer, Cham, August 2020.</li>

      <li>[53] Srinath Setty, Sebastian Angel, Trinabh Gupta, and Jonathan Lee. Proving the correct execution of concurrent services in zero-knowledge. In 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18), pages 339–356, Carlsbad, CA, October 2018. USENIX Association.</li>

      <li>[54] Srinath Setty and Jonathan Lee. Quarks: Quadruple-efficient transparent zkSNARKs. Cryptology ePrint Archive, Report 2020/1275, 2020.</li>

      <li>[55] Srinath T. V. Setty, Justin Thaler, and Riad S. Wahby. Unlocking the lookup singularity with Lasso. In Marc Joye and Gregor Leander, editors, EUROCRYPT 2024, Part VI, volume 14656 of LNCS, pages 180–209. Springer, Cham, May 2024.</li>

      <li>[56] Adi Shamir. How to share a secret. Communications of the Association for Computing Machinery, 22(11):612–613, November 1979.</li>

      <li>[57] Justin Thaler. Time-optimal interactive proofs for circuit evaluation. In Ran Canetti and Juan A. Garay, editors, CRYPTO 2013, Part II, volume 8043 of LNCS, pages 71–89. Springer, Berlin, Heidelberg, August 2013.</li>

      <li>[58] Victor Vu, Srinath T. V. Setty, Andrew J. Blumberg, and Michael Walfish. A hybrid architecture for interactive verifiable computation. In 2013 IEEE Symposium on Security and Privacy, pages 223–237. IEEE Computer Society Press, May 2013.</li>

      <li>[59] Howard Wu, Wenting Zheng, Alessandro Chiesa, Raluca Ada Popa, and Ion Stoica. DIZK: A distributed zero knowledge proof system. In William Enck and Adrienne Porter Felt, editors, USENIX Security 2018, pages 675–692. USENIX Association, August 2018.</li>

      <li>[60] Wenxuan Wu, Soamar Homsi, and Yupeng Zhang. Confidential and verifiable machine learning delegations on the cloud. In European Symposium on Research in Computer Security, pages 182–201. Springer, 2024.</li>

      <li>[61] Tiancheng Xie, Jiaheng Zhang, Zerui Cheng, Fan Zhang, Yupeng Zhang, Yongzheng Jia, Dan Boneh, and Dawn Song. zkBridge: Trustless cross-chain bridges made practical. In Heng Yin, Angelos Stavrou, Cas Cremers, and Elaine Shi, editors, ACM CCS 2022, pages 3003–3017. ACM Press, November 2022.</li>

    </ul>

    <p class="text-gray-300">[62] Tiancheng Xie, Jiaheng Zhang, Yupeng Zhang, Charalampos Papamanthou, and Dawn Song. Libra: Succinct zero-knowledge proofs with optimal prover computation. In Alexandra Boldyreva and Daniele Micciancio, editors, CRYPTO 2019, Part III, volume 11694 of LNCS, pages 733–764. Springer, Cham, August 2019.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[63] Yunbo Yang, Yuejia Cheng, Kailun Wang, Xiaoguo Li, Jianfei Sun, Jiachen Shen, Xiaolei Dong, Zhenfu Cao, Guomin Yang, and Robert H. Deng. Siniel: Distributed privacy-preserving zkSNARK. NDSS, 2025.</li>

      <li>[64] Jiaheng Zhang, Zhiyong Fang, Yupeng Zhang, and Dawn Song. Zero knowledge proofs for decision tree predictions and accuracy. In Jay Ligatti, Xinming Ou, Jonathan Katz, and Giovanni Vigna, editors, ACM CCS 2020, pages 2039–2053. ACM Press, November 2020.</li>

      <li>[65] Jiaheng Zhang, Tianyi Liu, Weijie Wang, Yinuo Zhang, Dawn Song, Xiang Xie, and Yupeng Zhang. Doubly efficient interactive proofs for general arithmetic circuits with linear prover time. In Giovanni Vigna and Elaine Shi, editors, ACM CCS 2021, pages 159–177. ACM Press, November 2021.</li>

      <li>[66] Jiaheng Zhang, Tiancheng Xie, Yupeng Zhang, and Dawn Song. Transparent polynomial delegation and its applications to zero knowledge proof. In 2020 IEEE Symposium on Security and Privacy, pages 859–876. IEEE Computer Society Press, May 2020.</li>

    </ul>

    <h2 id="sec-29" class="text-2xl font-bold">Appendix A Additional Preliminary</h2>

    <h3 id="sec-30" class="text-xl font-semibold mt-8">A.1 Interactive argument of knowledge</h3>

    <p class="text-gray-300">An interactive argument for an NP relation <span class="math">\\mathcal{R}</span> allows <span class="math">\\mathcal{P}</span> to convince <span class="math">\\mathcal{V}</span> that there exists a statement-witness pair <span class="math">(x,w)\\in\\mathcal{R}</span>. To qualify as an interactive Argument of Knowledge (AoK), we require <span class="math">w</span> can be efficiently extracted by an extractor <span class="math">\\mathcal{E}</span>.</p>

    <h6 id="sec-31" class="text-base font-medium mt-4">Definition 2.</h6>

    <p class="text-gray-300">(<span class="math">\\mathcal{G}</span>, <span class="math">\\mathcal{P}</span>, <span class="math">\\mathcal{V}</span>) is an interactive argument of knowledge for <span class="math">\\mathcal{R}</span> if it satisfies the following properties:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[leftmargin=*]</li>

      <li>Completeness. For every <span class="math">\\mathsf{pp}</span> output by <span class="math">\\mathcal{G}(1^{\\lambda})</span>, a statement-witness pair <span class="math">(x,w)</span> such that <span class="math">\\mathcal{R}(x,w)=1</span>, we have</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\Pr\\left[\\langle\\mathcal{P}(w),\\mathcal{V}\\rangle(x,\\mathsf{pp})=1\\right]=1</span></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Knowledge soundness. For any PPT prover <span class="math">\\mathcal{P}^{<em>}</span>, there exists a PPT extractor <span class="math">\\mathcal{E}</span> such that for every <span class="math">\\mathsf{pp}</span> output by <span class="math">\\mathcal{G}(1^{\\lambda})</span>, any input <span class="math">x</span>, and the extractor’s output <span class="math">w^{</em>}\\leftarrow\\mathcal{E}^{\\mathcal{P}^{*}}(\\mathsf{pp},x)</span>, the following probability is <span class="math">\\mathsf{negl}(\\lambda)</span>:</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\Pr\\left[\\langle\\mathcal{P}^{<em>},\\mathcal{V}\\rangle(x,\\mathsf{pp})=1\\wedge\\mathcal{R}(x,w^{</em>})\\neq 1\\right]</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We say it is <em>succinct</em> if the running time of the verifier and the total proof size are both $\\mathsf{poly}(\\lambda,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">. The AoK is <em>zero-knowledge</em> if it does not leak any information about </span>w$:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[leftmargin=*]</li>

      <li>Zero-knowledge. There exists a PPT simulator <span class="math">\\mathcal{S}</span> that for any PPT <span class="math">\\mathcal{V}^{*}</span>, <span class="math">\\mathcal{R}(x,w)=1</span>, <span class="math">\\mathsf{pp}</span> output by <span class="math">\\mathcal{G}(1^{\\lambda})</span>, we have</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\mathsf{View}^{\\mathcal{V}^{<em>}}(\\langle\\mathcal{P}(w),\\mathcal{V}^{</em>}\\rangle(x,\\mathsf{pp}))\\approx\\mathcal{S}^{\\mathcal{V}^{*}}(x)</span></p>

    <p class="text-gray-300">where <span class="math">\\mathsf{View}^{\\mathcal{V}^{<em>}}(\\langle\\mathcal{P}(w),\\mathcal{V}^{</em>}\\rangle(x,\\mathsf{pp}))</span> is the view of <span class="math">\\mathcal{V}^{<em>}</span> in the real protocol, and <span class="math">\\mathcal{S}^{\\mathcal{V}^{</em>}}(x)</span> is the view generated by <span class="math">\\mathcal{S}</span> given <span class="math">x</span> and the transcript of <span class="math">\\mathcal{V}^{*}</span>. <span class="math">\\approx</span> denotes the two distributions are computationally indistinguishable.</p>

    <p class="text-gray-300">zk-SNARK. A public-coin zero-knowledge succinct interactive AoK can be made non-interactive by applying the Fiat-Shamir transformation <em>[22]</em>, thereby obtaining a zk-SNARK, which includes the following algorithms:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[leftmargin=*]</li>

      <li><span class="math">\\mathsf{Setup}(1^{\\lambda},\\mathcal{R})\\to\\mathsf{pp}</span>: It takes the NP relation <span class="math">\\mathcal{R}</span> as inputs, and outputs the public parameter <span class="math">\\mathsf{pp}</span>.</li>

      <li><span class="math">\\mathsf{Prove}(\\mathsf{pp},x,w)\\to\\pi</span>: It takes <span class="math">\\mathsf{pp}</span> and a statement-witness pair <span class="math">x,w</span> as inputs, and outputs a proof <span class="math">\\pi</span>.</li>

      <li><span class="math">\\mathsf{Verify}(\\mathsf{pp},x,\\pi)\\to 0/1</span>: It takes <span class="math">\\mathsf{pp}</span>, the statement <span class="math">x</span>, and the proof <span class="math">\\pi</span> as inputs, and outputs a bit <span class="math">b</span> indicating acceptance <span class="math">(b=1)</span> or rejection <span class="math">(b=0)</span>.</li>

    </ul>

    <h3 id="sec-32" class="text-xl font-semibold mt-8">A.2 Collaborative zk-SNARK</h3>

    <p class="text-gray-300">The definitions of the zero-knowledge and succinctness properties are the same as those for a zk-SNARK. Below, we provide the formal definitions for completeness and knowledge soundness for a collaborative zk-SNARK (<span class="math">\\mathsf{Setup},\\Pi</span>, <span class="math">\\mathsf{Verify}</span>).</p>

    <p class="text-gray-300">####</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Completeness: For all <span class="math">(x,\\bm{w})\\in\\mathcal{R}</span>, the following holds:</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\Pr\\left[\\begin{matrix}\\mathsf{pp}\\leftarrow\\mathsf{Setup}(1^{\\lambda},\\mathcal{R}),\\\\ \\pi\\leftarrow\\Pi(\\mathsf{pp},x,\\bm{w}_{1},...,\\bm{w}_{N}):\\mathsf{Verify}(\\mathsf{pp},x,\\pi)=1\\end{matrix}\\right]=1</span></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Knowledge Soundness: For all <span class="math">x</span> and all sets of PPT algorithms <span class="math">\\vec{\\mathsf{S}}=\\{\\mathsf{S}_{0}^{<em>},...,\\mathsf{S}_{N-1}^{</em>}\\}</span>, there exists a PPT extractor <span class="math">\\mathcal{E}</span> such that,</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\Pr\\left[\\begin{matrix}\\mathsf{pp}\\leftarrow\\mathsf{Setup}(1^{\\lambda},\\mathcal{R}),\\\\ \\pi^{<em>}\\leftarrow\\vec{\\mathsf{S}}(\\mathsf{pp},x),&amp;:\\mathsf{Verify}(\\mathsf{pp},x,\\pi^{</em>})=1,\\\\ \\bm{w}^{<em>}\\leftarrow\\mathcal{E}^{\\vec{\\mathsf{S}}}(\\mathsf{pp},x)&amp;(x,\\bm{w}^{</em>})\\notin\\mathcal{R}\\end{matrix}\\right]\\leq\\mathsf{negl}(\\lambda)</span></p>

    <h3 id="sec-33" class="text-xl font-semibold mt-8">A.3 Multiparty computation</h3>

    <p class="text-gray-300">Let <span class="math">\\mathcal{C}_{\\Pi}:\\{0,1\\}^{N\\times\\lambda}\\rightarrow\\{0,1\\}^{N\\times\\lambda}</span> be a circuit, and <span class="math">\\mathsf{P}_{0},\\ldots,\\mathsf{P}_{N-1}</span> be the parties in an MPC protocol <span class="math">\\Pi</span> for <span class="math">\\mathcal{C}_{\\Pi}</span>. During the execution of <span class="math">\\Pi</span>, assume that each party <span class="math">\\mathsf{P}_{i}</span> has a private input <span class="math">x_{i}\\in\\{0,1\\}^{\\lambda}</span>, and wants to receive <span class="math">y_{i}\\in\\{0,1\\}^{\\lambda}</span> as output, where <span class="math">(y_{1},\\ldots,y_{N})=\\mathcal{C}_{\\Pi}(x_{1},\\ldots,x_{N})</span>, without revealing <span class="math">x_{i}</span>.</p>

    <p class="text-gray-300">We analyze the security of the MPC protocol <span class="math">\\Pi</span> in the real-world/ideal-world paradigm <em>[11]</em>. Below, we provide a high-level description of this paradigm. In the real-world execution, the real parties <span class="math">\\mathsf{P}_{0},\\ldots,\\mathsf{P}_{N-1}</span> communicate with each other to execute <span class="math">\\Pi</span>, and there is an adversary <span class="math">\\mathcal{A}</span> who can choose a set of parties, <span class="math">\\mathcal{C}orr</span>, to corrupt. In the ideal-world execution, there are dummy parties <span class="math">\\tilde{\\mathsf{P}}_{0},\\ldots,\\tilde{\\mathsf{P}}_{N-1}</span>, an ideal-world adversary (a.k.a. the simulator) <span class="math">\\mathcal{S}</span> who can corrupt the same set <span class="math">\\mathcal{C}orr</span>, and a trusted entity called the ideal functionality <span class="math">\\mathcal{F}</span>. The ideal functionality <span class="math">\\mathcal{F}</span> receives inputs from the dummy parties and <span class="math">\\mathcal{S}</span>, computes <span class="math">\\mathcal{C}_{\\Pi}</span>, and delivers the outputs to the parties. We say the protocol <span class="math">\\Pi</span> securely realizes <span class="math">\\mathcal{F}</span> if the outputs of the parties in the real-world execution are computationally indistinguishable from those in the ideal-world execution. Notice that we also use the term “hybrid world”. When we say a protocol is in the <span class="math">\\mathcal{G}</span>-hybrid world, it means that the parties have oracle access to an ideal functionality <span class="math">\\mathcal{G}</span>.</p>

    <p class="text-gray-300">For the ease of presentation, when we say that <span class="math">\\Pi</span> is an MPC protocol that <em>computes</em> an algorithm <span class="math">\\mathsf{Alg}</span>, we mean that <span class="math">\\mathsf{Alg}</span> can be represented as a circuit <span class="math">\\mathcal{C}_{\\Pi}</span>, and <span class="math">\\Pi</span> securely realizes an ideal functionality which computes this circuit. Similar treatments can be found in <em>[45, 27]</em>.</p>

    <h3 id="sec-34" class="text-xl font-semibold mt-8">A.4 Multivariate polynomial commitment</h3>

    <p class="text-gray-300">Polynomial Commitment Scheme (PCS) allows <span class="math">\\mathcal{P}</span> to commit to a polynomial <span class="math">f</span> and later evaluate <span class="math">f</span> at a given point. In this work, we focus on multivariate PCS, where <span class="math">f</span> is a multivariate polynomial. The definition of a multivariate PCS is as follows:</p>

    <h6 id="sec-35" class="text-base font-medium mt-4">Definition 3.</h6>

    <p class="text-gray-300">A PCS for <span class="math">\\ell</span>-variate polynomials has a tuple of algorithms <span class="math">(\\mathsf{PC}.{\\mathsf{Setup}},\\mathsf{PC}.{\\mathsf{Commit}},\\mathsf{PC}.{\\mathsf{Open}},\\mathsf{PC}.{\\mathsf{Verify}})</span>:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{PC}.{\\mathsf{Setup}}(1^{\\lambda})\\rightarrow\\mathsf{pp}</span>: It outputs a public parameter <span class="math">\\mathsf{pp}</span>.</li>

      <li><span class="math">\\mathsf{PC}.{\\mathsf{Commit}}(f,\\mathsf{pp})\\rightarrow\\mathsf{com}_{f}</span>: It takes as input a <span class="math">\\ell</span>-variates polynomial <span class="math">f</span> and outputs a commitment <span class="math">\\mathsf{com}_{f}</span>.</li>

      <li><span class="math">\\mathsf{PC}.{\\mathsf{Open}}(f,\\bm{u},\\mathsf{pp})\\rightarrow(z,\\pi)</span>: It outputs <span class="math">z:=f(\\bm{u})</span> for a given evaluation point <span class="math">\\bm{u}</span> and a corresponding proof <span class="math">\\pi</span>.</li>

      <li><span class="math">\\mathsf{PC}.{\\mathsf{Verify}}(\\mathsf{com}_{f},\\bm{u},z,\\pi,\\mathsf{pp})\\rightarrow 0/1</span>: It verifies the proof <span class="math">\\pi</span> using <span class="math">\\mathsf{pp},\\mathsf{com}_{f},z</span> and outputs <span class="math">1</span> if the proof is valid.</li>

    </ul>

    <p class="text-gray-300">The PCS should satisfy completeness, binding, and knowledge soundness. It can also be made hiding with additional randomization. We refer readers to <em>[30]</em> for the formal definitions of these properties.</p>

    <h2 id="sec-36" class="text-2xl font-bold">Appendix B Helper Functionalities</h2>

    <h3 id="sec-37" class="text-xl font-semibold mt-8">B.1 Generating double random shares</h3>

    <p class="text-gray-300">Figs. 5 and 6 provide the functionality and protocol for generating degree-<span class="math">d</span> and <span class="math">2d</span> PSS of random vectors. We refer readers to <em>[26, 16]</em> for security proof. The computation and communication cost for a single instance of double random share is <span class="math">O(N)</span>, where <span class="math">N</span> is the number of parties</p>

    <p class="text-gray-300">It interacts with a set of the servers  <span class="math">S_0, \\ldots, S_{N-1}</span>  and an adversary  <span class="math">S</span> . Corr denotes the set of corrupted servers. Upon receiving (DOUBLERAND) from all servers, do:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Receive shares  <span class="math">\\{u_i, v_i\\}_{i \\in \\text{Corr}}</span>  from  <span class="math">S</span> .</li>

      <li>Choose a random vector  <span class="math">\\boldsymbol{r} \\in \\mathbb{F}^k</span>  and sample random degree- <span class="math">d</span>  and degree- <span class="math">2d</span>  packed secret sharing  <span class="math">[\\boldsymbol{r}]_d</span>  and  <span class="math">[\\boldsymbol{r}]_{2d}</span>  s.t. the shares of the corrupted parties are identical to those received from  <span class="math">S</span> , i.e.,  <span class="math">\\{u_i, v_i\\}_{i \\in \\text{Corr}}</span> .</li>

      <li>Send the shares  <span class="math">\\llbracket r\\rrbracket_d</span>  and  <span class="math">\\llbracket r\\rrbracket_{2d}</span>  to all parties.</li>

    </ul>

    <p class="text-gray-300">Figure 5: The functionality  <span class="math">\\mathcal{F}_{\\mathrm{Double - Rand}}</span></p>

    <p class="text-gray-300">Let  <span class="math">\\mathbf{V}_{N,N - t}</span>  be a public Vandermonde matrix over  <span class="math">\\mathbb{F}</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For  <span class="math">i \\in [N]</span> : server  <span class="math">S_i</span>  samples a uniform  <span class="math">\\pmb{u}_i \\gets \\mathbb{F}^k</span>  and uses PSS to share  <span class="math">\\pmb{u}_i</span>  using degree- <span class="math">d</span>  and degree- <span class="math">2d</span>  polynomials respectively, so the servers can receive  <span class="math">[[\\pmb{u}_i]]_d, [[\\pmb{u}_i]]_{2d}</span> .</li>

      <li>For  <span class="math">i \\in [N]</span> : server  <span class="math">S_i</span>  locally compute  <span class="math">([\\mathbf{r}_1]_d, \\ldots, [\\mathbf{r}_{N - t}]_d) \\gets \\mathbf{V}_{N,N - t}^\\top \\cdot ([\\mathbf{u}_1]_d, \\ldots, [\\mathbf{u}_N]_d)</span>  and  <span class="math">([\\mathbf{r}_1]_2d, \\ldots, [\\mathbf{r}_{N - t}]_2d) \\gets \\mathbf{V}_{N,N - t}^\\top \\cdot ([\\mathbf{u}_1]_2d, \\ldots, [\\mathbf{u}_N]_2d)</span> .</li>

      <li>Each server  <span class="math">S_{i}</span>  outputs  <span class="math">\\{\\llbracket r_i\\rrbracket_d,\\llbracket r_i\\rrbracket_{2d}\\}_{i\\in [N - t]}</span> .</li>

    </ol>

    <p class="text-gray-300">Figure 6: The Protocol  <span class="math">\\Pi_{\\mathrm{Double - Rand}}</span></p>

    <p class="text-gray-300">It interacts with a set of the servers  <span class="math">S_0, \\ldots, S_{N-1}</span>  and an adversary  <span class="math">S</span> . Corr denotes the set of corrupted servers. Upon receiving (PSSMULT,  <span class="math">[[\\pmb{a}]], [[\\pmb{b}]])</span>  from all servers, do:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Receive a set of shares  <span class="math">\\{u_i\\}_{i \\in \\text{Corr}}</span>  from the adversary  <span class="math">S</span> .</li>

      <li>Reconstruct  <span class="math">\\mathbf{a}</span>  and  <span class="math">\\mathbf{b}</span>  from  <span class="math">[\\mathbf{a}], [\\mathbf{b}]</span> .</li>

      <li>Compute  <span class="math">\\pmb{c} = \\pmb{a} * \\pmb{b}</span> , i.e.,  <span class="math">c_{i} = a_{i} \\cdot b_{i}</span>  for  <span class="math">i \\in [k]</span> .</li>

      <li>Sample random sharing  <span class="math">\\llbracket c\\rrbracket</span>  of  <span class="math">c</span> , such that the shares of the corrupted servers are identical to those received from  <span class="math">S</span> , i.e.,  <span class="math">\\{u_i\\}_{i, \\text{s.t. } S_i \\in \\text{Corr}}</span> .</li>

      <li>Distribute  <span class="math">\\llbracket c\\rrbracket</span>  to all servers.</li>

    </ul>

    <p class="text-gray-300">Figure 7: The functionality  <span class="math">\\mathcal{F}_{\\mathrm{PSSMult}}</span></p>

    <p class="text-gray-300">Inputs: The servers hold  <span class="math">\\llbracket a\\rrbracket_d</span>  and  <span class="math">\\llbracket b\\rrbracket_d</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Servers invoke  <span class="math">\\mathcal{F}_{\\mathrm{Double - Rand}}</span>  to receive  <span class="math">([\\mathbf{r}]_d, [\\mathbf{r}]_{2d})</span> .</li>

      <li>Servers compute  <span class="math">\\llbracket c\\rrbracket_{2d} = \\llbracket a\\rrbracket_d\\cdot \\llbracket b\\rrbracket_d</span>  and  <span class="math">\\llbracket e\\rrbracket_{2d} = \\llbracket c\\rrbracket_{2d} + \\llbracket r\\rrbracket_{2d}</span> , and send  <span class="math">\\llbracket e\\rrbracket_{2d}</span>  to  <span class="math">S_0</span> .</li>

      <li><span class="math">S_0</span>  reconstructs  <span class="math">\\pmb{e}</span>  and re-shares it to other parties, i.e., other servers will receive  <span class="math">\\llbracket e\\rrbracket_d</span> .</li>

      <li>Servers output  <span class="math">\\llbracket c\\rrbracket_d = \\llbracket e\\rrbracket_d - \\llbracket r\\rrbracket_d</span></li>

    </ol>

    <p class="text-gray-300">Figure 8: The Protocol  <span class="math">\\Pi_{\\mathrm{PSSMult}}</span></p>

    <p class="text-gray-300">Figs. 7 and 8 provide the functionality and protocol for multiplying two degree- <span class="math">d</span>  PSS and reducing the degree of the product back to  <span class="math">d</span> . For the security proof, we refer readers to [26, 15]. The concrete communication cost for multiplying two PSS is  <span class="math">2N</span> . Denote  <span class="math">\\epsilon := \\frac{N}{k}</span> . To multiply  <span class="math">\\frac{n}{k}</span>  groups of PSS, the concrete communication cost is  <span class="math">\\frac{n}{k} \\cdot 2N = 2\\epsilon n</span> .</p>

    <p class="text-gray-300">It interacts with a set of the servers  <span class="math">S_0, \\ldots, S_{N-1}</span>  and an adversary  <span class="math">S</span> . Corr denotes the set of corrupted servers.</p>

    <p class="text-gray-300">Upon receiving (CONVERT,  <span class="math">\\llbracket x\\rrbracket</span>  ) from all servers, do:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For each  <span class="math">j \\in [k]</span> , receive shares  <span class="math">\\{u_{j,i}\\}_{i \\in \\mathcal{C}orr}</span>  from  <span class="math">S</span> .</li>

      <li>Reconstruct  <span class="math">\\pmb{x} = (x_{1},\\dots,x_{k})</span>  from  <span class="math">\\llbracket \\pmb{x}\\rrbracket</span> .</li>

      <li>For each  <span class="math">j \\in [k]</span> , computes a random sharing of  <span class="math">x_{j}</span>  such that the shares of the corrupted servers are identical to those received from  <span class="math">S</span> , i.e.,  <span class="math">\\{u_{j,i}\\}_{i \\in \\mathcal{C}orr}</span> .</li>

      <li>For each  <span class="math">j \\in [k]</span> , distribute  <span class="math">\\langle x_j \\rangle</span>  to all servers.</li>

    </ul>

    <p class="text-gray-300">Figure 9: The functionality  <span class="math">\\mathcal{F}_{\\mathrm{PSS2SSS}}</span></p>

    <p class="text-gray-300">Let  <span class="math">\\mathbf{V}_{N,N - t}</span>  be a public Vandermonde matrix over  <span class="math">\\mathbb{F}</span> .</p>

    <p class="text-gray-300">Inputs: The servers hold  <span class="math">\\llbracket x\\rrbracket</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For  <span class="math">i \\in [N]</span> : server  <span class="math">S_i</span>  samples a uniform  <span class="math">\\pmb{u}_i = (\\pmb{u}_i[1], \\dots, \\pmb{u}_i[k]) \\stackrel{\\mathbb{S}}{\\leftarrow} \\mathbb{F}^k</span>  and uses PSS and SSS to share  <span class="math">\\pmb{u}_i</span>  respectively, so the servers can receive  <span class="math">\\llbracket \\pmb{u}_i\\rrbracket</span>  and  <span class="math">\\langle \\pmb{u}_i[1]\\rangle, \\dots, \\langle \\pmb{u}_i[k]\\rangle</span> .</li>

      <li>For  <span class="math">i \\in [N]</span> : server  <span class="math">\\mathsf{S}_i</span>  locally compute  <span class="math">([\\pmb{r_1}], \\dots, [\\pmb{r_{N - t}}]) \\gets \\mathbf{V}_{N,N - t}^{\\top} \\cdot ([\\pmb{u_1}], \\dots, [\\pmb{u_N}])</span>  and  <span class="math">\\forall j \\in [k] : (\\langle \\pmb{r_1}[j] \\rangle, \\dots, \\langle \\pmb{r_{N - t}}[j] \\rangle) \\gets \\mathbf{V}_{N,N - t}^{\\top} \\cdot (\\langle \\pmb{u_1}[j] \\rangle, \\dots, \\langle \\pmb{u_N}[j] \\rangle)</span> .</li>

      <li>Servers compute  <span class="math">\\llbracket \\pmb{y}\\rrbracket \\gets \\llbracket \\pmb{x}\\rrbracket -\\llbracket \\pmb{r}_1\\rrbracket</span>  and send  <span class="math">\\llbracket \\pmb{y}\\rrbracket</span>  to  <span class="math">S_0</span></li>

      <li><span class="math">S_0</span>  reconstructs  <span class="math">\\pmb{y}</span>  and sends  <span class="math">\\pmb{y}</span>  to other servers.</li>

      <li>For  <span class="math">j \\in [k]</span> : servers compute  <span class="math">\\langle x_j \\rangle \\gets \\langle r_1[j] \\rangle + y_j</span> .</li>

      <li>Servers output  <span class="math">\\langle x_1\\rangle ,\\ldots ,\\langle x_k\\rangle</span></li>

    </ol>

    <p class="text-gray-300">Figure 10: The Protocol  <span class="math">\\Pi_{\\mathrm{PSS2SSS}}</span></p>

    <p class="text-gray-300">The functionality interacts with servers  <span class="math">S_0, \\ldots, S_{N-1}</span>  and an adversary  <span class="math">S</span> . Let  <span class="math">\\mathcal{C}orr</span>  be the corrupted servers. It does:</p>

    <p class="text-gray-300">Upon receiving  <span class="math">(\\mathsf{MULT},m,\\llbracket \\mathbf{A}_1\\rrbracket ,\\ldots ,\\llbracket \\mathbf{A}_m\\rrbracket ,\\llbracket b_1\\rrbracket ,\\ldots ,\\llbracket b_m\\rrbracket)</span>  from the servers, where  <span class="math">m</span>  is the number of pairs:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For  <span class="math">i \\in [m]</span> , reconstruct  <span class="math">(\\mathsf{A}_{(i-1)k+1}, \\dots, \\mathsf{A}_{ik})</span>  from  <span class="math">[\\mathbf{A}_i]</span>  and reconstruct  <span class="math">(b_{(i-1)k+1}, \\dots, b_{ik})</span>  from  <span class="math">[\\mathbf{b}_i]</span> .</li>

      <li>Receive a set of shares  <span class="math">\\{u_i\\}_{i\\in \\mathcal{C}orr}</span>  from the adversary.</li>

      <li>Compute out  <span class="math">= \\prod_{i\\in [m\\cdot k]}\\mathsf{A}_i^{b_i}</span></li>

      <li>Sample a random sharing  <span class="math">\\langle \\mathrm{out}\\rangle</span>  of out, such that the shares of the corrupted parties are identical to those received from the adversary  <span class="math">\\{u_i\\}_{i\\in \\mathcal{C}orr}</span> .</li>

      <li>Distribute the shares  <span class="math">\\langle \\mathrm{out}\\rangle</span>  to all servers.</li>

    </ol>

    <p class="text-gray-300">Figure 11: Collaborative MSM functionality.</p>

    <p class="text-gray-300">Figs. 9 and 10 provide the functionality and protocol for converting PSS to regular SSS. We refer readers to [26] for security proof. The amortized computation and communication cost for converting PSS to SSS is  <span class="math">O(N)</span> .</p>

    <p class="text-gray-300">Figs. 11 and 12 provide the functionality and protocol of collaborative MSM. We refer readers to [27] for security proof. Each server incurs  <span class="math">O\\left(\\frac{N}{N}\\right)</span>  time and space complexity, and the total communication is  <span class="math">O(N)</span> . Due to the need of preparing double random shares  <span class="math">(\\mathcal{F}_{\\mathrm{Double - Rand}})</span> , the pre-processing needs  <span class="math">O(N)</span>  randomness.</p>

    <p class="text-gray-300">Let  <span class="math">\\mathsf{A}_1,\\ldots ,\\mathsf{A}_n</span>  be  <span class="math">n</span>  group elements in  <span class="math">\\mathbb{G}</span>  and  <span class="math">b_{1},\\ldots ,b_{n}</span>  be  <span class="math">n</span>  field elements in  <span class="math">\\mathbb{F}</span> , let  <span class="math">m\\coloneqq n / k</span></p>

    <p class="text-gray-300">Inputs: Each server holds the PSS of  <span class="math">\\mathbf{A}_j\\coloneqq \\{\\mathsf{A}_{(j - 1)k + i}\\}_{i\\in [k]}</span>  and  <span class="math">\\pmb {b}_j\\coloneqq \\{b_{(j - 1)k + i}\\}_{i\\in [k]}</span> , for each  <span class="math">j\\in [m]</span> , respectively.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The servers invoke  <span class="math">\\mathcal{F}_{\\mathrm{Double - Rand}}</span>  to prepare a pair of random shares  <span class="math">\\llbracket r\\rrbracket_d,\\llbracket r\\rrbracket_{2d}</span> , where  <span class="math">r\\in \\mathbb{F}^k</span>  is a random vector unknown to any server  <span class="math">S_{i}</span> .</li>

      <li>The servers send  <span class="math">\\llbracket r\\rrbracket_d</span>  to  <span class="math">\\mathcal{F}_{\\mathrm{PSS2SSS}}</span> , which returns  <span class="math">\\langle r_1\\rangle, \\dots, \\langle r_k\\rangle</span>  to the servers.</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each server  <span class="math">S_{i}</span>  computes  <span class="math">\\llbracket C\\rrbracket_{2d} = \\prod_{j\\in [\\frac{n}{k}]}[\\mathbf{A}_j]_{d}^{\\llbracket b_j\\rrbracket_d}</span> .</li>

      <li>Each server  <span class="math">S_{i}</span>  computes  <span class="math">\\llbracket D\\rrbracket_{2d} = \\llbracket C\\rrbracket_{2d}\\cdot g^{\\llbracket r\\rrbracket_{2d}}</span>  and sends it to  <span class="math">S_0</span> .</li>

      <li><span class="math">S_0</span>  reconstructs  <span class="math">\\mathbf{D} = (D_1, \\dots, D_k)</span> .</li>

      <li><span class="math">S_0</span>  computes  <span class="math">\\mathsf{E} = \\prod_{j\\in [k]}D_j</span>  and sends it to each server.</li>

      <li>Each server computes  <span class="math">\\langle \\mathrm{out}\\rangle \\coloneqq \\frac{\\mathsf{E}}{\\prod_{j\\in[k]}g^{\\langle r_j\\rangle}}</span>  as output.</li>

    </ol>

    <p class="text-gray-300">Figure 12: Collaborative MSM protocol.</p>

    <p class="text-gray-300">We list the definitions of a series of multivariate primitives: sumcheck, zerocheck, prodcheck, permcheck, and multilinear PCS, along with their classical protocols. Please refer to [13] for detailed security proofs of these constructions.</p>

    <p class="text-gray-300">We instantiate the multilinear PCS (mlPC) using the PST scheme [46]. It requires a trusted setup:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>mlPC.Setup  <span class="math">(1^{\\lambda})\\to \\mathsf{pp}</span> : It samples  <span class="math">\\alpha \\stackrel{\\mathrm{s}}{\\leftarrow} \\mathbb{F}^{\\ell}</span>  as a trapdoor and outputs parameters  <span class="math">\\mathsf{pp} := \\{g^{\\theta_{\\mathfrak{q}}(\\alpha, b)}\\}_{\\mathbf{b} \\in \\{0, 1\\}^{\\ell}}</span>  where  <span class="math">g</span>  is a generator of the group  <span class="math">\\mathbb{G}</span> .</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\mathcal{P}</span>  and  <span class="math">\\mathcal{V}</span>  run the following to commit to and check the evaluation of an  <span class="math">\\ell</span> -variate multilinear polynomial  <span class="math">f</span> :</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>mlPC.Commit  <span class="math">(f, \\mathsf{pp}) \\to \\mathsf{com}_f</span> :  <span class="math">\\mathcal{P}</span>  outputs  <span class="math">\\mathsf{com}_f := g^{f(\\alpha)}</span> . Note that the evaluation on the power of  <span class="math">g</span>  can be computed with the aid of prepared parameters efficiently.</li>

      <li>mlPC.Open  <span class="math">(f, \\mathbf{u}, \\mathsf{pp}) \\to (z, \\pi)</span> :  <span class="math">\\mathcal{P}</span>  evaluates  <span class="math">f</span>  at a given point  <span class="math">\\mathbf{u}</span>  as  <span class="math">z := f(\\mathbf{u})</span> .  <span class="math">\\mathcal{P}</span>  computes polynomials  <span class="math">\\{Q_i\\}_{i \\in [\\ell]}</span>  that satisfy  <span class="math">f(\\mathbf{x}) - z = \\sum_{i=1}^{\\ell} (x_i - u_i) \\cdot Q_i(x_{i+1}, \\ldots, x_\\ell)</span> , and outputs a proof  <span class="math">\\pi := \\{\\pi_i\\}_{i \\in [\\ell]}</span> , where  <span class="math">\\pi_i := g^{Q_i(s_{i+1}, \\ldots, s_\\ell)}</span> .</li>

      <li>mlPC.Verify  <span class="math">(\\mathsf{com}_f, z, \\mathbf{u}, \\pi) \\to 0/1</span> :  <span class="math">\\mathcal{V}</span>  parses the proof as  <span class="math">\\pi = \\{\\pi_i\\}_{i \\in [\\ell]}</span> , then checks  <span class="math">e\\left(\\frac{\\mathsf{com}_f}{g^s}, g\\right) \\stackrel{?}{=} \\prod_{i=1}^{\\ell} e(g^{s_i - a_i}, \\pi_i)</span> . If it passes,  <span class="math">\\mathcal{V}</span>  outputs 1; 0 otherwise.</li>

    </ul>

    <p class="text-gray-300">Efficiency. The prover time is  <span class="math">O(2^{\\ell})</span>  group operations, the verifier time is  <span class="math">O(\\ell)</span>  bilinear pairings operations, and the proof size is  <span class="math">O(\\ell)</span>  group elements.</p>

    <p class="text-gray-300">Consider a sumcheck relation  <span class="math">\\mathcal{R}_{sum}(\\ell, H, \\mathsf{com}_f; f) = 1</span>  iff  <span class="math">H = \\sum_{\\boldsymbol{x} \\in \\{0,1\\}^{\\ell}} f(\\boldsymbol{x})</span> , where  <span class="math">f</span>  is a degree- <span class="math">D</span> <span class="math">\\ell</span> -variate polynomial,  <span class="math">H \\in \\mathbb{F}</span>  is a sum claim and  <span class="math">\\mathsf{com}_f</span>  is the multivariate polynomial committment of  <span class="math">f</span> .  <span class="math">\\mathcal{P}</span>  and  <span class="math">\\mathcal{V}</span>  run the following:</p>

    <p class="text-gray-300">1: In the  <span class="math">i</span> -th round, where  <span class="math">1 \\leq i \\leq \\ell</span> ,</p>

    <p class="text-gray-300">a.  <span class="math">\\mathcal{P}</span>  computes  <span class="math">f_{i}(x)\\coloneqq \\sum_{\\pmb {b}\\in \\{0,1\\}^{\\ell -i}}f(r_{1},\\dots r_{i - 1},x,\\pmb {b})</span>  and sends it  <span class="math">\\nu</span> b.  <span class="math">\\mathcal{V}</span>  checks  <span class="math">f_{i}(0) + f_{i}(1)\\stackrel {?}{=}H</span>  . If passes,  <span class="math">\\mathcal{V}</span>  samples  <span class="math">r_i\\stackrel {k}{\\leftarrow}\\mathbb{F}</span>  and updates  <span class="math">H\\gets f_{i}(r_{i})</span>  . If  <span class="math">i &amp;lt;   \\ell ,\\mathcal{V}</span>  sends back  <span class="math">r_i</span> 2:  <span class="math">\\mathcal{V}</span>  checks the correctness of  <span class="math">f(r_{1},\\dots,r_{\\ell})</span></p>

    <p class="text-gray-300">In the last step,  <span class="math">\\mathcal{V}</span>  checks the correctness of  <span class="math">f(\\boldsymbol{r})</span>  for a multilinear  <span class="math">f</span>  using mlPC.Open of a multilinear PCS. For a high-degree polynomial  <span class="math">f</span> , we treat  <span class="math">f</span>  as the output of an arithmetic circuit of multiple multilinear polynomials evaluations.</p>

    <p class="text-gray-300">Efficiency.</p>

    <p class="text-gray-300">In this work, we only consider the low-degree case where <span class="math">D\\leq 4</span>, and assume the PCS is instantiated by the PST scheme <em>[46]</em>. The prover time is <span class="math">O(2^{\\ell})</span>, the verifier time and proof size are both <span class="math">O(\\ell)</span>, and the round complexity is <span class="math">O(\\ell)</span>.</p>

    <h3 id="sec-57" class="text-xl font-semibold mt-8">C.3 Zerocheck</h3>

    <p class="text-gray-300">Consider a zerocheck relation <span class="math">\\mathcal{R}_{zero}(\\ell,\\mathsf{com}_{f};f)=1</span> iff for any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>, <span class="math">f(\\bm{x})=0</span>, where <span class="math">f</span> is a degree-<span class="math">D</span> <span class="math">\\ell</span>-variate polynomial. <span class="math">\\mathcal{P}</span> and <span class="math">\\mathcal{V}</span> run the following:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}</span> sends <span class="math">\\mathcal{P}</span> a random challenge <span class="math">\\bm{r}_{2}\\stackrel{{\\scriptstyle\\mathsf{s}}}{{\\leftarrow}}\\mathbb{F}^{\\ell}</span>.</li>

      <li><span class="math">\\mathcal{P}</span>, <span class="math">\\mathcal{V}</span> run a sumcheck on <span class="math">\\sum_{\\bm{x}\\in\\{0,1\\}^{\\ell}}f(\\bm{x})\\cdot\\bm{\\mathrm{\\acute{e}q}}(\\bm{x},\\bm{r_{2}})=0</span>.</li>

    </ol>

    <p class="text-gray-300">Efficiency. <span class="math">\\mathcal{V}</span> can evaluate <span class="math">\\bm{\\mathrm{\\acute{e}q}}(\\bm{r_{1}},\\bm{r_{2}})</span> locally in <span class="math">O(\\ell)</span> time, where <span class="math">\\bm{r}_{1}</span> is the randomness used in the sumcheck protocol. Since zerocheck can be reduced to a degree-<span class="math">(D+1)</span> sumcheck, the efficiency metrics are analogous.</p>

    <h3 id="sec-58" class="text-xl font-semibold mt-8">C.4 Prodcheck</h3>

    <p class="text-gray-300">Consider a prodcheck relation <span class="math">\\mathcal{R}_{prod}(\\ell,H,\\mathsf{com}_{f};f)=1</span> iff <span class="math">H=\\prod_{\\bm{x}\\in\\{0,1\\}^{\\ell}}f(\\bm{x})</span>, where <span class="math">f</span> is a <span class="math">\\ell</span>-variate polynomial and <span class="math">H\\in\\mathbb{F}</span> is a product claim. <span class="math">\\mathcal{P}</span> and <span class="math">\\mathcal{V}</span> run the following:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let <span class="math">v</span> denote an <span class="math">(\\ell+1)</span>-variate polynomial such that <span class="math">v(0,\\bm{x})=f(\\bm{x})</span> and <span class="math">v(1,\\bm{x})=v(\\bm{x},0)\\cdot v(\\bm{x},1)</span>, for any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>. <span class="math">\\mathcal{P}</span> computes <span class="math">v</span> by Alg. 1 and sends <span class="math">\\mathsf{com}_{v}</span> to <span class="math">\\mathcal{V}</span>.</li>

      <li><span class="math">\\mathcal{P}</span> and <span class="math">\\mathcal{V}</span> run zerocheck on <span class="math">p(\\bm{x}):=v(0,\\bm{x})-f(\\bm{x})</span> and <span class="math">q(\\bm{x}):=v(1,\\bm{x})-v(\\bm{x},0)\\cdot v(\\bm{x},1)</span>.</li>

      <li><span class="math">\\mathcal{P}</span> and <span class="math">\\mathcal{V}</span> run mlPC.Open on <span class="math">v(1,...,1,0)=H</span>.</li>

    </ol>

    <p class="text-gray-300">Efficiency. Since it is reduced to zerocheck, and computing <span class="math">v</span> requires <span class="math">O(2^{\\ell})</span> time, the efficiency metrics are analogous.</p>

    <h3 id="sec-59" class="text-xl font-semibold mt-8">C.5 Permcheck</h3>

    <p class="text-gray-300">Consider a permcheck relation <span class="math">\\mathcal{R}_{perm}(\\ell,\\sigma;f,g)=1</span> iff for any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>, <span class="math">f(\\bm{x})=g(\\sigma(\\bm{x}))</span>, where <span class="math">f,g</span> are two <span class="math">\\ell</span>-variate linear polynomials, and <span class="math">\\sigma:\\{0,1\\}^{\\ell}\\rightarrow\\{0,1\\}^{\\ell}</span> is a public permutation. In a classical percheck protocol <em>[13]</em>, <span class="math">\\mathcal{P}</span> and <span class="math">\\mathcal{V}</span> run the following:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let <span class="math">s_{id},s_{\\sigma}</span> denote <span class="math">\\ell</span>-variate linear polynomials such that for any <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>, <span class="math">s_{id}(\\bm{x}):=[\\bm{x}],s_{\\sigma}(\\bm{x}):=[\\sigma(\\bm{x})]</span>, where we abuse <span class="math">[\\bm{x}]</span> to represent the integer form of <span class="math">\\bm{x}\\in\\{0,1\\}^{\\ell}</span>. <span class="math">\\mathcal{P}</span> sends <span class="math">\\mathsf{com}_{f},\\mathsf{com}_{g},\\mathsf{com}_{s_{id}},\\mathsf{com}_{s_{\\sigma}}</span> to <span class="math">\\mathcal{V}</span>.</li>

      <li><span class="math">\\mathcal{V}</span> samples <span class="math">\\alpha,\\beta\\stackrel{{\\scriptstyle\\mathsf{s}}}{{\\leftarrow}}\\mathbb{F}</span> and sends them to <span class="math">\\mathcal{P}</span>.</li>

      <li><span class="math">\\mathcal{P}</span>, <span class="math">\\mathcal{V}</span> run a prodcheck on <span class="math">\\prod_{\\bm{x}\\in\\{0,1\\}^{\\ell}}h(\\bm{x})=1</span>, where <span class="math">h(\\bm{x}):=\\frac{f(\\bm{x})+\\alpha s_{id}(\\bm{x})+\\beta}{g(\\bm{x})+\\alpha s_{\\sigma}(\\bm{x})+\\beta}</span> and a zerocheck on <span class="math">q(\\bm{x}):=h(\\bm{x})\\cdot(g(\\bm{x})+\\alpha s_{\\sigma}(\\bm{x})+\\beta)-(f(\\bm{x})+\\alpha s_{id}(\\bm{x})+\\beta)</span>.</li>

    </ol>

    <p class="text-gray-300">Efficiency. Since the permcheck can be reduced to the prodcheck, the efficiency metrics are analogous.</p>

    <h2 id="sec-60" class="text-2xl font-bold">Appendix D Distributed Protocols</h2>

    <p class="text-gray-300">We list the distributed version of the multivariate primitives in Appx. C, allowing <span class="math">N</span> servers to distribute <span class="math">\\mathcal{P}</span>’s work.</p>

    <h3 id="sec-61" class="text-xl font-semibold mt-8">D.1 Distributed multilinear PCS</h3>

    <p class="text-gray-300">Fig. 13 provides the full protocol for the distributed multilinear PCS, denoted as <span class="math">\\Pi_{\\mathsf{di-mlPC}}</span>, computes <span class="math">\\mathcal{P}</span> of PST multilinear PCS (Appx. C.1) where <span class="math">f</span> is public.</p>

    <p class="text-gray-300">Efficiency. The prover work for each server is <span class="math">O\\left(\\frac{2^{\\ell}}{N}\\right)</span>. The communication between <span class="math">N</span> servers is <span class="math">O(N\\ell)</span>.</p>

    <h3 id="sec-62" class="text-xl font-semibold mt-8">D.2 Distributed sumcheck</h3>

    <p class="text-gray-300">Fig. 14 provides the full protocol of the distributed sumcheck protocol, denoted as <span class="math">\\Pi_{\\mathsf{di-sumcheck}}</span>, computes <span class="math">\\mathcal{P}</span> of sumcheck (Appx. C.2) where <span class="math">f</span> is public. This is adapted from <em>[61]</em>.</p>

    <p class="text-gray-300">Efficiency. The prover work for each server is <span class="math">O\\left(\\frac{2^{\\ell}}{N}\\right)</span>. The communication between <span class="math">N</span> servers is <span class="math">O(N\\ell)</span>. The round complexity, proof size, and verifier time are all <span class="math">O(\\ell)</span>.</p>

    <h2 id="sec-63" class="text-2xl font-bold">Appendix</h2>

    <p class="text-gray-300">Let  <span class="math">N = 2^s</span> ,  <span class="math">n = 2^\\ell</span> , and  <span class="math">f</span>  be an  <span class="math">\\ell</span> -variate linear polynomial.</p>

    <p class="text-gray-300">Inputs: Each server holds a  <span class="math">(\\ell - s)</span> -variate linear polynomial  <span class="math">f^{(i)}(\\pmb{x}) = f(\\tilde{i}, \\pmb{x})</span>  for any  <span class="math">i \\in [0, N-1]</span> .</p>

    <p class="text-gray-300">Procedure di-mIPC.Setup:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Sample  <span class="math">\\alpha \\coloneqq \\{\\alpha_{1},\\dots,\\alpha_{\\ell}\\} \\stackrel{\\mathrm{b}}{\\leftarrow}\\mathbb{F}^{\\ell}</span>  as a trapdoor.</li>

      <li><span class="math">S_0</span>  receives  <span class="math">\\mathsf{pp}^{(0)}\\coloneqq \\{g^{\\tilde{\\mathbf{q}} (\\alpha [1:s],b)}\\}_{b\\in \\{0,1\\} ^s}</span></li>

      <li>Each server receives  <span class="math">\\mathsf{pp}^{(i)}\\coloneqq \\{g^{\\tilde{\\mathbf{q}} (\\alpha ,\\tilde{i},\\mathbf{b})}\\}_{b\\in \\{0,1\\}^{\\ell -s}}</span>  for any  <span class="math">i\\in [0,N - 1]</span></li>

    </ol>

    <p class="text-gray-300">Procedure di-mIPC.Commit:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each server computes  <span class="math">\\mathsf{com}_f^{(i)}\\coloneqq g^{f^{(i)}(\\alpha)}</span>  using  <span class="math">f^{(i)}</span>  and  <span class="math">\\mathsf{pp}^{(i)}</span> , and sends it to  <span class="math">\\mathsf{S}_0</span> .</li>

      <li><span class="math">S_0</span>  outputs  <span class="math">\\mathsf{com}_f\\coloneqq \\prod_{i = 0}^{N - 1}\\mathsf{com}_f^{(i)}</span></li>

    </ol>

    <p class="text-gray-300">Procedure di-mIPC.Open:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each server computes  <span class="math">z^{(i)}</span>  and  <span class="math">\\left\\{Q_j^{(i)}\\right\\}_{j\\in [s + 1,\\ell ]}</span>  such that  <span class="math">f^{(i)}(\\pmb {x}) - z^{(i)} = \\sum_{j = s + 1}^{\\ell}(x_j - u_j)\\cdot Q_j^{(i)}(x_{j + 1},\\ldots ,x_\\ell)</span>  and  <span class="math">\\pi_j^{(i)}\\coloneqq g^{\\tilde{\\mathbf{q}} (\\alpha [1:s],\\tilde{i})\\cdot Q_j^{(i)}(\\alpha_{j + 1},\\dots,\\alpha_\\ell)}</span></li>

      <li>Each server sends  <span class="math">z^{(i)}</span> ,  <span class="math">\\pi^{(i)} \\coloneqq \\left\\{\\pi_j^{(i)}\\right\\}_{j \\in [s + 1, \\ell]}</span>  to  <span class="math">S_0</span> .</li>

      <li><span class="math">S_0</span>  parses  <span class="math">\\pi^{(i)} = \\left\\{\\pi_j^{(i)}\\right\\}_{j\\in [s + 1,\\ell ]}</span>  for  <span class="math">i\\in [0,N - 1]</span> , and computes  <span class="math">\\pi_{j}\\coloneqq \\prod_{i = 0}^{N - 1}\\pi_{j}^{(i)}</span>  for any  <span class="math">j\\in [s + 1,\\ell ]</span></li>

      <li><span class="math">S_0</span>  computes  <span class="math">\\hat{f}(\\pmb{x}) \\coloneqq \\sum_{i \\in [0, N-1]} \\tilde{\\mathbf{q}}(\\hat{i}, \\pmb{x}) \\cdot z^{(i)}</span>  and runs  <span class="math">z, \\{\\pi_j\\}_{j \\in [s]} \\gets \\mathsf{mIPC}</span> . Open  <span class="math">(\\hat{f}, \\pmb{u}[1, s], \\mathsf{pp}^{(0)})</span> .</li>

      <li><span class="math">S_0</span>  outputs  <span class="math">(z,\\pi \\coloneqq (\\pi_1,\\dots ,\\pi_\\ell))</span></li>

    </ol>

    <p class="text-gray-300">Figure 13: Distributed multilinear PCS protocol.</p>

    <p class="text-gray-300">Let  <span class="math">N = 2^s</span> ,  <span class="math">n = 2^\\ell</span> , and  <span class="math">f</span>  be an  <span class="math">\\ell</span> -variate polynomial.</p>

    <p class="text-gray-300">Inputs: Each server  <span class="math">S_{i}</span>  holds a  <span class="math">(\\ell - s)</span> -variate polynomial  <span class="math">f^{(i)}(\\pmb{x}) \\coloneqq f(\\tilde{i}, \\pmb{x})</span>  for any  <span class="math">i \\in [0, N - 1]</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In the  <span class="math">j</span> -th round, where  <span class="math">1 \\leq j \\leq \\ell - s</span> ,</li>

    </ol>

    <p class="text-gray-300">(a) Each server sends  <span class="math">S_0</span>  a univariate polynomial  <span class="math">f_j^{(i)}(x_j) \\coloneqq \\sum_{b \\in \\{0,1\\}^{\\ell - s - j}} f^{(i)}(r_1, \\ldots, r_{j-1}, x_j, b)</span> . (b)  <span class="math">S_0</span>  computes  <span class="math">f_{j}(x_{j})\\coloneqq \\sum_{i = 0}^{N - 1}f_{j}^{(i)}(x_{j}).</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In the  <span class="math">(\\ell - s)</span> -th round, each server computes  <span class="math">z^{(i)} \\coloneqq f^{(i)}(r_1, \\ldots, r_{\\ell - s})</span>  and sends it to  <span class="math">\\mathsf{S}_0</span> .  <span class="math">\\mathsf{S}_0</span>  computes  <span class="math">\\hat{f}(\\pmb{x}) \\coloneqq \\sum_{i \\in [0, N-1]} \\tilde{\\mathbf{q}}(\\hat{i}, \\pmb{x}) \\cdot z^{(i)}</span> .</li>

      <li>In the  <span class="math">j</span> -th round, where  <span class="math">\\ell - s &amp;lt; j \\leq \\ell</span> ,  <span class="math">S_0</span>  runs the prover of sumcheck on  <span class="math">H&#x27; = \\sum_{b \\in \\{0,1\\}^s} \\hat{f}(b)</span> , where  <span class="math">H&#x27; := \\sum_{i \\in [0,N-1]} z^{(i)}</span> .</li>

    </ol>

    <p class="text-gray-300">Figure 14: Distributed sumcheck protocol adapted from [61].</p>

    <p class="text-gray-300">The distributed zerocheck protocol, denoted as  <span class="math">\\Pi_{\\mathrm{di - zerocheck}}</span> , computes  <span class="math">\\mathcal{P}</span>  of zerocheck (Appx. C.3) where  <span class="math">f</span>  is public. It can be reduced to a distributed sumcheck protocol.</p>

    <p class="text-gray-300">Efficiency. Each server computes the segment of  <span class="math">\\tilde{\\mathbf{q}}</span>  with  <span class="math">O\\left(\\frac{n}{N}\\right)</span>  workload. Since the protocol is reduced to a distributed sumcheck, the efficiency metrics are analogous.</p>

    <p class="text-gray-300">First, we present the formal construction of the layered distributed sumcheck and layered distributed multilinear PCS. Subsequently, we provide the distributed prodcheck protocol, which relies on these constructions.</p>

    <p class="text-gray-300">Layered distributed sumcheck. We denote the layered distributed sumcheck as  <span class="math">\\Pi_{\\text{Layered-di-sumcheck}}</span>  and present its full protocol in Fig. 15. The protocol addresses the scenario where each server holds only a subtree, while  <span class="math">S_0</span>  additionally holds the top-tree, making the standard distributed sumcheck protocol infeasible. Instead, the protocol executes  <span class="math">\\ell - s + 1</span>  distributed sumchecks in parallel, where, for each instance, the random challenge from</p>

    <p class="text-gray-300">Let  <span class="math">N = 2^s</span> ,  <span class="math">n = 2^\\ell</span> , and  <span class="math">f</span>  be an  <span class="math">(\\ell + 1)</span> -variate polynomial.</p>

    <p class="text-gray-300">Inputs: Each server has access to  <span class="math">f_{j}^{(i)}(\\pmb{x}) \\coloneqq f(\\mathbb{1}_{\\ell - s - j}, 0, \\tilde{i}, \\pmb{x})</span>  for any  <span class="math">j \\in [\\ell - s]</span> , and  <span class="math">S_0</span>  additionally has a  <span class="math">(s + 1)</span> -variate polynomial  <span class="math">f&#x27;(x) \\coloneqq f(\\mathbb{1}_{\\ell - s - 1}, 1, x)</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In the  <span class="math">l</span> -th round, where  <span class="math">1 \\leq l \\leq \\ell - s</span> ,</li>

    </ol>

    <p class="text-gray-300">(a) Each server computes the univariate round polynomial  <span class="math">g_{j,l}^{(i)}</span>  for  <span class="math">f_{j}^{(i)}</span> , for any  <span class="math">j \\in [l, \\ell - s]</span> , and sends a univariate polynomial  <span class="math">g_{l}^{(i)}(x) := \\sum_{j \\in [l, \\ell - s]} g_{j,l}^{(i)}(x)</span>  to  <span class="math">S_0</span> . (b)  <span class="math">S_0</span>  computes the univariate round polynomial  <span class="math">g_l^i</span>  for  <span class="math">f&#x27;</span> , and computes  <span class="math">g_l(x) \\coloneqq g_l^i(x) + \\sum_{i \\in [0, N-1]} g_l^{(i)}(x)</span>  as the overall sumcheck round polynomial. (c) Upon receiving  <span class="math">r_l</span>  from  <span class="math">\\mathcal{V}</span> , each server sends  <span class="math">z_l^{(i)} \\coloneqq f_l^{(i)}(r_l, \\dots, r_1)</span>  to  <span class="math">\\mathsf{S}_0</span> .  <span class="math">\\mathsf{S}_0</span>  computes  <span class="math">\\hat{f}_l(\\pmb{x}) \\coloneqq \\sum_{i \\in [0, N-1]} \\hat{\\mathbf{eq}}(\\tilde{i}, \\pmb{x}) \\cdot z_l^{(i)}</span> . Meanwhile,  <span class="math">\\mathsf{S}_0</span>  folds  <span class="math">f&#x27;</span>  to  <span class="math">\\hat{f}&#x27;(\\pmb{x}) \\coloneqq f&#x27;(\\pmb{x}, r_l)</span> .  <span class="math">\\mathsf{S}_0</span>  updates  <span class="math">f&#x27;</span>  such that  <span class="math">f&#x27;(0, \\pmb{x}) = \\hat{f}_l(\\pmb{x})</span>  and  <span class="math">f&#x27;(1, \\pmb{x}) = \\hat{f}_l&#x27;(\\pmb{x})</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In the  <span class="math">l</span> -th round, where  <span class="math">\\ell - s &amp;lt; l \\leq \\ell</span> ,  <span class="math">\\mathsf{S}_0</span>  runs the prover of sumcheck on  <span class="math">H&#x27; = \\sum_{b \\in \\{0,1\\}^s} f&#x27;(b)</span> , where  <span class="math">H&#x27; := \\sum_{i \\in [0,N-1]} z_{\\ell-s}^{(i)}</span> .</li>

    </ol>

    <p class="text-gray-300">Figure 15: Layered distributed sumcheck protocol.</p>

    <p class="text-gray-300">Let  <span class="math">N = 2^s</span> ,  <span class="math">n = 2^\\ell</span> , and  <span class="math">f</span>  be an  <span class="math">(\\ell + 1)</span> -variate linear polynomial.</p>

    <p class="text-gray-300">Inputs: Each server has access to  <span class="math">f_{j}^{(i)} \\coloneqq f(\\mathbb{1}_{\\ell - s - j}, 0, \\tilde{i}, \\boldsymbol{x})</span>  for any  <span class="math">j \\in [\\ell - s]</span> , and  <span class="math">S_0</span>  additionally has a  <span class="math">(s + 1)</span> -variate polynomial  <span class="math">f&#x27;(\\boldsymbol{x}) \\coloneqq f(\\mathbb{1}_{\\ell - s - 1}, 1, \\boldsymbol{x})</span> .</p>

    <p class="text-gray-300">Procedure Layered-di-mlPC.Setup:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Sample  <span class="math">\\alpha \\coloneqq \\{\\alpha_{1},\\dots,\\alpha_{\\ell}\\} \\stackrel{\\mathbf{s}}{\\leftarrow}\\mathbb{F}^{\\ell}</span>  as a trapdoor.</li>

      <li><span class="math">S_0</span>  receives  <span class="math">\\mathsf{pp}_j^{(0)}\\coloneqq \\left\\{g^{\\hat{\\mathbf{eq}} (\\pmb {\\alpha}[1:\\ell +1 - j],(\\mathbb{1}_{\\ell -s - j},1,\\pmb {b}))}\\right\\}_{\\pmb {b}\\in \\{0,1\\} ^s}</span>  for all  <span class="math">j\\in [\\ell -s]</span></li>

      <li>Each server receives  <span class="math">\\mathsf{pp}_j^{(i)}\\coloneqq \\left\\{g^{\\hat{\\mathbf{eq}} (\\pmb {\\alpha},(\\mathbb{1}_{\\ell -s - j},0,\\tilde{i},\\pmb {b}))}\\right\\}_{\\pmb {b}\\in \\{0,1\\} ^j}</span>  for any  <span class="math">j\\in [\\ell -s]</span></li>

    </ol>

    <p class="text-gray-300">Procedure Layered-di-mlPC.Commit:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each server computes  <span class="math">\\mathsf{com}_f^{(i)}\\coloneqq \\prod_{j\\in [\\ell -s]}g_{f_j}^{(i)}(\\pmb {\\alpha})</span>  using  <span class="math">f_{j}^{(i)}</span>  and  <span class="math">\\mathsf{pp}_j^{(i)}</span> , for  <span class="math">j\\in [\\ell -s]</span> , and sends it to  <span class="math">\\mathsf{S}_0</span> .</li>

      <li><span class="math">S_0</span>  outputs  <span class="math">\\mathsf{com}_f\\coloneqq g^{f&#x27;(\\pmb {\\alpha})}\\cdot \\prod_{i = 0}^{N - 1}\\mathsf{com}_f^{(i)}</span></li>

    </ol>

    <p class="text-gray-300">Procedure Layered-di-mlPC.Open:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let  <span class="math">R_{j}^{(i)} \\coloneqq f_{j}^{(i)}</span> . For  <span class="math">l \\in [\\ell - s]</span> ,</li>

    </ol>

    <p class="text-gray-300">(a) Each server computes  <span class="math">Q_{j,\\ell -l + 2}^{(i)}, R_{j,\\ell -l + 2}^{(i)}</span> , for any  <span class="math">j \\in [l,\\ell -s]</span>  such that  <span class="math">R_{j}^{(i)} = Q_{j,\\ell -l + 2}^{(i)}(x_{\\ell -l + 2} - u_{\\ell -l + 2}) + R_{j,\\ell -l + 2}^{(i)}</span> , and updates  <span class="math">R_{j}^{(i)} \\gets R_{j,\\ell -l + 2}^{(i)}</span> . (b) Each server computes  <span class="math">\\pi_{\\ell -l + 2}^{(i)}\\coloneqq \\prod_{j = l}^{\\ell -s}g^{\\hat{\\mathbf{eq}} (\\pmb {\\alpha}[1:\\ell -j + 1],(\\mathbb{1}_{\\ell -s - j},0,\\tilde{i}))}\\cdot Q_{j,\\ell -l + 2}^{(i)}(\\pmb {\\alpha}[\\ell -j + 2:\\ell -l + 1])</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each server obtains a single evaluation  <span class="math">z_{l}^{(i)} \\coloneqq R_{l}^{(i)}</span>  for  <span class="math">l \\in [\\ell - s]</span> .</li>

      <li>Each server sends  <span class="math">\\{\\pi_l^{(i)}\\}_{l\\in [s + 2,\\ell +1]}</span> ,  <span class="math">\\{z_{l}^{(i)}\\}_{l\\in [\\ell -s]}</span>  to  <span class="math">\\mathsf{S}_0</span></li>

      <li>For  <span class="math">l \\in [\\ell - s]</span> ,</li>

    </ol>

    <p class="text-gray-300">(a)  <span class="math">S_0</span>  computes  <span class="math">Q_{\\ell -l + 2}^{\\prime},R_{\\ell -l + 2}^{\\prime}</span>  such that  <span class="math">f^{\\prime} = Q_{\\ell -l + 2}^{\\prime}(x_{\\ell -l + 2} - u_{\\ell -l + 2}) + R_{\\ell -l + 2}^{\\prime}</span> (b)  <span class="math">S_0</span>  outputs  <span class="math">\\pi_{\\ell -l + 2}\\coloneqq (\\prod_{i\\in [0,N - 1]}\\pi_{\\ell -l + 2}^{(i)})\\cdot g^{\\hat{\\mathbf{eq}} (\\pmb {\\alpha}[1:\\ell -s - l + 1],\\mathbb{1}_{\\ell -s - l + 1})\\cdot Q_{\\ell -l + 2}^{\\prime}(\\pmb {\\alpha}[\\ell -s - l + 2,\\ell -l + 1])}</span> (c)  <span class="math">S_0</span>  computes  <span class="math">\\hat{f}_l(\\pmb{x}) \\coloneqq \\sum_{i \\in [0, N-1]} \\hat{\\mathbf{eq}}(\\tilde{i}, \\pmb{x}) \\cdot z_l^{(i)}</span> , and updates  <span class="math">f&#x27;</span>  s.t.  <span class="math">f&#x27;(0, \\pmb{x}) = \\hat{f}_l(\\pmb{x})</span> ,  <span class="math">f&#x27;(1, \\pmb{x}) = R_{\\ell - l + 2}&#x27;(\\pmb{x})</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">S_0</span>  runs mlPC.Open on  <span class="math">f&#x27;</span>  to compute  <span class="math">z</span>  and  <span class="math">\\pi_1, \\ldots, \\pi_{s+1}</span> , outputs  <span class="math">(z, \\pi := (\\pi_1, \\ldots, \\pi_{\\ell+1}))</span> .</li>

    </ol>

    <p class="text-gray-300">Figure 16: Layered distributed multilinear PCS protocol.</p>

    <p class="text-gray-300"><span class="math">\\mathcal{V}</span>  is determined in a backward manner. The correctness of this protocol follows from Eq. (5).</p>

    <p class="text-gray-300">Layered distributed multilinear PCS. We denote the layered distributed sumcheck as  <span class="math">\\Pi_{\\text{Layered-di-mlPC}}</span>  and present its full protocol in Fig. 16. It addresses a similar scenario to the layered distributed sumcheck, where the dis</p>

    <p class="text-gray-300">Algorithm 1 Computing an input- <span class="math">n</span>  Prodtree // Assume  <span class="math">n = 2^{\\ell}</span>  for some positive integer  <span class="math">\\ell</span> function PROD-TREE  <span class="math">(x_{1}\\in \\mathbb{F}^{n})</span>  for  <span class="math">i = 1</span>  to  <span class="math">\\ell</span>  do  <span class="math">x_{i + 1,j}\\gets x_{i,2j - 1}\\cdot x_{i,2j},\\forall j\\in [2^{\\ell -i}]</span> <span class="math">x_{i + 1}\\coloneqq \\{x_{i + 1,j}\\}_{j\\in [2^{\\ell -i}]} / / x_{\\ell +1}\\coloneqq \\{r\\}</span>  is the root. end for return  <span class="math">(x_{1},\\ldots ,x_{l + 1})\\in \\mathbb{F}^{2n - 1}</span> end function</p>

    <p class="text-gray-300">Let  <span class="math">N = 2^s</span> ,  <span class="math">n = 2^\\ell</span> ,  <span class="math">f</span>  be an  <span class="math">\\ell</span> -variate polynomial,  <span class="math">p(\\pmb{x}) \\coloneqq f(\\pmb{x}) - v(0,\\pmb{x})</span> ,  <span class="math">q(\\pmb{x}) \\coloneqq v(1,\\pmb{x}) - v(\\pmb{x},0) \\cdot v(\\pmb{x},1)</span> .</p>

    <p class="text-gray-300">Inputs: Each server holds a  <span class="math">(\\ell - s)</span> -variate polynomial  <span class="math">f^{(i)}(\\pmb{x}) = f(\\tilde{i}, \\pmb{x})</span>  for any  <span class="math">i \\in [0, N-1]</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each server invokes PROD-TREE  <span class="math">(\\mathsf{A}_{f^{(i)}})</span>  (Alg. 1) to compute  <span class="math">\\frac{2n}{N} - 1</span>  elements in the subtree, and sends the last element  <span class="math">r^{(i)}</span>  to  <span class="math">\\mathsf{S}_0</span> .</li>

      <li><span class="math">S_0</span>  invokes PROD-TREE  <span class="math">\\{r_i\\}_{i\\in [0,N - 1]}</span>  (Alg. 1) to compute  <span class="math">2N - 1</span>  elements.</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The servers invoke Commit of  <span class="math">\\Pi_{\\text{Layered-di-mlPC}}</span>  (Fig. 16) on  <span class="math">v</span>  to compute  <span class="math">\\operatorname{com}_v</span> .</li>

      <li>The servers invoke  <span class="math">\\Pi_{\\mathrm{di - zerocheck}}</span>  (Appx. D.3) on  <span class="math">p(\\pmb {x})</span></li>

      <li>The servers run the following to zerocheck on  <span class="math">q(\\pmb {x})</span>  ..</li>

    </ol>

    <p class="text-gray-300">(a) Upon receiving  <span class="math">\\pmb{r}_1</span> , the servers invoke  <span class="math">\\Pi_{\\text{Layered-di-mlPC}}</span>  (Fig. 15) on  <span class="math">u(\\pmb{x}) \\coloneqq \\widehat{\\operatorname{eq}}(\\pmb{r}_1, \\pmb{x}) \\cdot q(\\pmb{x})</span> . (b) The servers invoke Open of  <span class="math">\\Pi_{\\text{Layered-di-mlPC}}</span>  (Fig. 16) on  <span class="math">v(1, \\boldsymbol{u}), v(\\boldsymbol{u}, 0), v(\\boldsymbol{u}, 1)</span>  to finalize the sumcheck, where  <span class="math">\\boldsymbol{r}_2</span>  is the challenges from sumcheck.</p>

    <p class="text-gray-300">Figure 17: Distributed prodcheck protocol.</p>

    <p class="text-gray-300">tributed multilinear PCS becomes infeasible. Intuitively, the protocol executes  <span class="math">\\ell - s + 1</span>  distributed multilinear PCS instances in parallel. The correctness is based on the following equation:</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} f (x _ {1}, \\dots , x _ {\\ell + 1}) \\\\ = \\sum_ {j = 1} ^ {\\ell - s} x _ {1} \\dots x _ {\\ell - s - j} \\left(1 - x _ {\\ell - s - j + 1}\\right) \\cdot f \\left(\\mathbb {1} _ {\\ell - s - j}, 0, x _ {\\ell - s - j + 2}, \\dots , x _ {\\ell + 1}\\right) \\tag {6} \\\\ + x _ {1} \\dots x _ {\\ell - s} \\cdot f \\left(\\mathbb {1} _ {\\ell - s - 1}, 1, x _ {\\ell - s + 1}, \\dots , x _ {\\ell + 1}\\right) \\\\ \\end{array}</span></div>

    <p class="text-gray-300">Distributed prodcheck. Fig. 17 provides the full protocol of the distributed prodcheck protocol, denoted as  <span class="math">\\Pi_{\\mathrm{di - prodcheck}}</span> , computes  <span class="math">\\mathcal{P}</span>  of prodcheck (Appx. C.4) where  <span class="math">f</span>  is public and the servers need to generate a proof for  <span class="math">H = \\prod_{b\\in \\{0,1\\}^{\\ell}}f(b)</span> .</p>

    <p class="text-gray-300">Below is a further explanation of this protocol: Initially, each server holds only  <span class="math">f(\\tilde{i}, \\boldsymbol{x})</span> . The first procedure enables the servers to compute  <span class="math">A_v</span> , i.e., a product tree, in a distributed manner, following the idea in Fig. 1. Next, the servers collectively compute a proof on the well-formedness of the product tree. Specifically, this involves two distributed zerochecks for</p>

    <div class="my-4 text-center"><span class="math-block">p (\\boldsymbol {x}) := f (\\boldsymbol {x}) - v (0, \\boldsymbol {x}), q (\\boldsymbol {x}) := v (1, \\boldsymbol {x}) - v (\\boldsymbol {x}, 0) \\cdot v (\\boldsymbol {x}, 1)</span></div>

    <p class="text-gray-300">respectively. The first zerocheck is performed directly by the servers invoking the existing distributed zerocheck protocol. For the second zerocheck, note that it is exactly a "layered" case, making direct distributed zerocheck infeasible. Therefore, we leverage the above two layered distributed protocols for assistance. More precisely, in this case, we have  <span class="math">u(\\pmb{x}) \\coloneqq \\widehat{\\operatorname{eq}}(\\pmb{r}, \\pmb{x}) \\cdot q(\\pmb{x})</span> , and each server holds the non-contiguous segments of the hypercube required for the layered distributed protocol. Consequently, the second check can also be performed in a distributed manner.</p>

    <p class="text-gray-300">Efficiency. In the first procedure, the prover work for each server is  <span class="math">O\\left(\\frac{2^{\\ell}}{N}\\right)</span> , with  <span class="math">S_0</span>  additionally performing  <span class="math">O(N)</span>  work. The communication between  <span class="math">N</span>  servers is  <span class="math">O(N)</span> . In the second procedure, the prover work for each server is  <span class="math">O\\left(\\frac{2^{\\ell}}{N}\\right)</span> , with  <span class="math">S_0</span>  additionally performing  <span class="math">O(N\\ell)</span>  work. and the communication between  <span class="math">N</span>  servers is  <span class="math">O(N\\ell)</span> . The round complexity is  <span class="math">O(\\ell)</span> . The proof size and verifier time both remain  <span class="math">O(\\ell)</span> .</p>

    <p class="text-gray-300">Let  <span class="math">k = 2^s</span>  and  <span class="math">n_i = 2^{\\ell - i}</span>  for  <span class="math">i \\in [0, \\ell]</span> . Let  <span class="math">f</span>  be an  <span class="math">\\ell</span> -variate linear polynomial.</p>

    <p class="text-gray-300">Inputs: Each server holds the PSS of  <span class="math">\\mathsf{A}_f</span> , denoted as  <span class="math">\\llbracket x_{0,j}\\rrbracket</span> , for  <span class="math">j\\in \\left[\\frac{n_0}{k}\\right]</span> .</p>

    <p class="text-gray-300">Procedure co-mIPC.Setup:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Sample  <span class="math">\\alpha \\coloneqq \\{\\alpha_{1},\\dots,\\alpha_{\\ell}\\} \\stackrel{\\mathrm{s}}{\\leftarrow}\\mathbb{F}^{\\ell}</span>  as a trapdoor.</li>

      <li>For  <span class="math">i\\in [0,\\ell ]</span>  , compute  <span class="math">g^{\\prod_{j = i + 1}^{t}(1 - b_{j})(1 - \\alpha_{j}) + b_{j}\\alpha_{j}}</span>  for any  <span class="math">b_{i + 1},\\ldots b_{\\ell}\\in \\{0,1\\}^{\\ell -i}</span>  , resulting in  <span class="math">n_i</span>  group elements  <span class="math">\\mathsf{P}_i</span></li>

      <li>For  <span class="math">i\\in [0,\\ell -s]</span>  , pack  <span class="math">n_i</span>  group elements from Step 2 as  <span class="math">\\mathbf{P}_{i,1},\\dots,\\mathbf{P}_{i,\\frac{n_i}{k}}</span>  . Each server receives  <span class="math">\\mathsf{pp}_i\\coloneqq \\{\\llbracket \\mathbf{P}_{i,j}\\rrbracket \\}_{j\\in [\\frac{n_i}{k} ]}</span></li>

      <li>For  <span class="math">i\\in (\\ell -s,\\ell ]</span>  , each server receives  <span class="math">\\mathsf{pp}_i\\coloneqq \\{\\mathsf{P}_{i,j}\\}_{j\\in [n_i]}</span></li>

    </ol>

    <p class="text-gray-300">Procedure co-mIPC.Commit:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each server parse  <span class="math">\\mathsf{pp}_0</span>  as  <span class="math">\\{\\llbracket \\mathbf{P}_{0,j}\\rrbracket \\}_{j\\in [\\frac{n_0}{k}]}</span> , and the servers invoke  <span class="math">\\mathcal{F}_{\\mathrm{co - MSM}}</span>  on  <span class="math">\\{\\llbracket x_{0,j}\\rrbracket \\}_{j\\in [\\frac{n_0}{k}]}</span> ,  <span class="math">\\{\\llbracket \\mathbf{P}_{0,j}\\rrbracket \\}_{j\\in [\\frac{n_0}{k}]}</span>  to compute  <span class="math">\\langle \\mathrm{com}_f\\rangle</span> .</li>

    </ol>

    <p class="text-gray-300">Procedure co-mIPC.Open:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For  <span class="math">1 \\leq i \\leq \\ell - s</span> ,</li>

    </ol>

    <p class="text-gray-300">(a) Each server computes  <span class="math">\\llbracket q_{i,j}\\rrbracket = \\llbracket x_{i - 1,j + \\frac{n_i}{k}}\\rrbracket -\\llbracket x_{i - 1,j}\\rrbracket</span>  and  <span class="math">\\llbracket x_{i,j}\\rrbracket = (1 - u_i)\\cdot \\llbracket x_{i - 1,j}\\rrbracket +u_i\\cdot \\llbracket x_{i - 1,j + \\frac{n_i}{k}}\\rrbracket</span>  for  <span class="math">j\\in [\\frac{n_i}{k} ]</span> (b) Each server parses  <span class="math">\\mathsf{pp}_i</span>  as  <span class="math">\\{\\llbracket \\mathbf{P}_{i,j}\\rrbracket \\}_{j\\in [\\frac{n_i}{k}]}</span> , and the servers invoke  <span class="math">\\mathcal{F}_{\\mathrm{co - MSM}}</span>  on  <span class="math">\\{\\llbracket q_{i,j}\\rrbracket \\}_{j\\in [\\frac{n_i}{k}]}</span> ,  <span class="math">\\{\\llbracket \\mathbf{P}_{i,j}\\rrbracket \\}_{j\\in [\\frac{n_i}{k}]}</span>  to compute  <span class="math">\\langle \\pi_i\\rangle</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The servers invoke  <span class="math">\\mathcal{F}_{\\mathrm{PSS2SSS}}</span>  to convert  <span class="math">\\llbracket x_{l - s}\\rrbracket</span>  to  <span class="math">\\langle x_{l - s,1}\\rangle ,\\ldots ,\\langle x_{l - s,k}\\rangle</span></li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For  <span class="math">\\ell - s + 1 \\leq i \\leq \\ell</span> ,</li>

    </ol>

    <p class="text-gray-300">(a) Each server computes  <span class="math">\\langle q_{i,j}\\rangle = \\langle x_{i - 1,j + n_i}\\rangle -\\langle x_{i - 1,j}\\rangle</span>  and  <span class="math">\\langle x_{i,j}\\rangle = (1 - u_i)\\cdot \\langle x_{i - 1,j}\\rangle +u_i\\cdot \\langle x_{i - 1,j + n_i}\\rangle</span>  for  <span class="math">j\\in [n_i]</span> (b) Each server parses  <span class="math">\\mathsf{pp}_i</span>  as  <span class="math">\\{\\mathsf{P}_{i,j}\\}_{j\\in [n_i]}</span> , and computes  <span class="math">\\langle \\pi_i\\rangle = \\prod_{j\\in [n_i]}\\mathsf{P}_{i,j}^{(q_{i,j})}</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The servers output  <span class="math">\\langle \\pi \\rangle = (\\langle \\pi_1\\rangle ,\\dots,\\langle \\pi_\\ell \\rangle)</span></li>

    </ol>

    <p class="text-gray-300">Figure 18: Collaborative multilinear PCS.</p>

    <p class="text-gray-300">The distributed permcheck protocol, denoted as  <span class="math">\\Pi_{\\mathrm{di-permcheck}}</span> , computes  <span class="math">\\mathcal{P}</span>  of permcheck (Appx. C.5), where involved polynomials are public. It is reduced to a distributed prodcheck.</p>

    <p class="text-gray-300">Each server holds an  <span class="math">(\\ell - s)</span> -variate polynomial  <span class="math">f^{(i)}(\\pmb{x}) = f(\\hat{i}, \\pmb{x})</span> , and the same partition is applied to  <span class="math">g</span> ,  <span class="math">s_{id}</span> , and  <span class="math">s_{\\sigma}</span>  as well. Using these slices, it suffices for each server to compute the required sub-polynomial of  <span class="math">\\mathsf{A}_h</span> , where  <span class="math">h(\\pmb{x}) := \\frac{f(\\pmb{x}) + \\alpha s_{id}(\\pmb{x}) + \\beta}{g(\\pmb{x}) + \\alpha s_{\\sigma}(\\pmb{x}) + \\beta}</span> . The servers then invoke Commit of  <span class="math">\\Pi_{\\mathrm{di-mIPC}}</span>  (Appx. D.1) to compute  <span class="math">\\mathrm{com}_f</span> ,  <span class="math">\\mathrm{com}_g</span> ,  <span class="math">\\mathrm{com}_{s_{id}}</span> , and  <span class="math">\\mathrm{com}_{s_\\sigma}</span> . Finally, the servers invoke  <span class="math">\\Pi_{\\mathrm{di-prodcheck}}</span>  to check that  <span class="math">\\prod_{\\pmb{x} \\in \\{0,1\\}^\\ell} h(\\pmb{x}) = 1</span> , where  <span class="math">h(\\pmb{x}) := \\frac{f(\\pmb{x}) + \\alpha s_{id}(\\pmb{x}) + \\beta}{g(\\pmb{x}) + \\alpha s_{\\sigma}(\\pmb{x}) + \\beta}</span> , and invoke  <span class="math">\\Pi_{\\mathrm{di-zerocheck}}</span>  on  <span class="math">q(\\pmb{x}) := h(\\pmb{x}) \\cdot (g(\\pmb{x}) + \\alpha s_{\\sigma}(\\pmb{x}) + \\beta) - (f(\\pmb{x}) + \\alpha s_{id}(\\pmb{x}) + \\beta)</span> .</p>

    <p class="text-gray-300">Efficiency. Since it is reduced to the distributed prodcheck and zerocheck, the efficiency metrics are analogous.</p>

    <p class="text-gray-300">We list the collaborative versions of the multivariate primitives in Appx. C, allowing  <span class="math">N</span>  servers to collaboratively compute  <span class="math">\\mathcal{P}</span> 's work with only secret-shared polynomials.</p>

    <p class="text-gray-300">Fig. 18 provides the full protocol for the collaborative multilinear PCS, denoted as  <span class="math">\\Pi_{\\mathrm{co - mIPC}}</span> , computes  <span class="math">\\mathcal{P}</span>  of PST multilinear PCS (Appx. C.1) where each server only holds a secret-shared hypercube of  <span class="math">f</span> .</p>

    <p class="text-gray-300">The security comes from the following lemma:</p>

    <p class="text-gray-300">Lemma 1. The collaborative multilinear PCS in Fig. 18 is an MPC protocol that securely computes mIPC.Commit and mIPC.Open in  <span class="math">\\{\\mathcal{F}_{\\mathrm{co - MSM}},\\mathcal{F}_{\\mathrm{PSS2SSS}}\\}</span> -hybrid world against a semi-honest adversary who corrupts at most  <span class="math">t</span>  servers.</p>

    <p class="text-gray-300">Proof. The correctness follows the construction directly. For security, except for invoking  <span class="math">\\mathcal{F}_{\\mathrm{co - MSM}}</span>  and  <span class="math">\\mathcal{F}_{\\mathrm{PSS2SSS}}</span> , the servers only perform local computations during co-mIPC.Commit and co-mIPC.Open. In other words, no corrupted parties have the chance to learn other parties' private input. Therefore, the security is guaranteed.</p>

    <p class="text-gray-300">Let  <span class="math">k = 2^s</span>  and  <span class="math">n_i = 2^{\\ell - i}</span>  for  <span class="math">i \\in [0, \\ell]</span> . Let  <span class="math">f(\\pmb{x}) \\coloneqq h(g_1(\\pmb{x}), \\dots, g_c(\\pmb{x}))</span>  be an  <span class="math">\\ell</span> -variate degree- <span class="math">D</span>  polynomial.</p>

    <p class="text-gray-300">Inputs: Each server holds the PSS of  <span class="math">\\mathsf{A}_{g_1},\\dots,\\mathsf{A}_{g_c}</span> , denoted as  <span class="math">\\llbracket x_{0,j}^{(l)}\\rrbracket</span> , for  <span class="math">l\\in [c]</span>  and  <span class="math">j\\in \\left[\\frac{n_0}{k}\\right]</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In the  <span class="math">i</span> -th round, where  <span class="math">1 \\leq i \\leq \\ell - s</span> ,</li>

    </ol>

    <p class="text-gray-300">(a) Define  <span class="math">T_{j}^{(l)}(X) \\coloneqq (1 - X) \\cdot [[\\pmb{x}_{i-1,j}^{(l)}]] + X \\cdot [[\\pmb{x}_{i-1,j+\\frac{n_i}{k}}^{(l)}]]</span> . Each server computes  <span class="math">T_{j}^{(l)}(u)</span>  and subsequently  <span class="math">T_{j}(u) = h(T_{j}^{(1)}(u), \\ldots, T_{j}^{(c)}(u))</span> , for  <span class="math">u \\in [0, D]</span> ,  <span class="math">l \\in [c]</span> , and  <span class="math">j \\in \\left[\\frac{n_i}{k}\\right]</span> . Each server computes  <span class="math">[[a_{i,u}]] = \\sum_{j=1}^{n_i} T_j(u)</span>  for  <span class="math">u \\in [0, D]</span> . (b) Upon receiving  <span class="math">r_i</span>  from  <span class="math">\\mathcal{V}</span> , each server computes  <span class="math">[\\pmb{x}_{i,j}^{(l)}]</span>  by Eq. (3), for  <span class="math">l\\in [c]</span>  and  <span class="math">j\\in [\\frac{n_i}{k}]</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For  <span class="math">l \\in [c]</span> , the servers invoke  <span class="math">\\mathcal{F}_{\\mathrm{PSS2SSS}}</span>  to convert  <span class="math">[\\pmb{x}_{l - s}^{(l)}]</span>  to  <span class="math">\\langle x_{l - s,1}^{(l)}\\rangle, \\dots, \\langle x_{l - s,k}^{(l)}\\rangle</span> .</li>

      <li>In the  <span class="math">i</span> -th round, where  <span class="math">\\ell - s + 1 \\leq i &amp;lt; \\ell</span> ,</li>

    </ol>

    <p class="text-gray-300">(a) Define  <span class="math">T_{j}^{(l)}(X) \\coloneqq (1 - X) \\cdot \\langle x_{i-1,j}^{(l)} \\rangle + X \\cdot \\langle x_{i-1,j+n_{i}}^{(l)} \\rangle</span> . Each server computes  <span class="math">T_{j}^{(l)}(u)</span>  and subsequently  <span class="math">T_{j}(u) = h(T_{j}^{(1)}(u), \\ldots, T_{j}^{(c)}(u))</span> , for  <span class="math">u \\in [0,D]</span> ,  <span class="math">l \\in [c]</span> , and  <span class="math">j \\in [n_{i}]</span> . Each server computes  <span class="math">\\langle a_{i,u} \\rangle = \\sum_{j=1}^{n_{i}} T_{j}(u)</span>  for  <span class="math">u \\in [0,D]</span> . (b) Upon receiving  <span class="math">r_i</span>  from  <span class="math">\\mathcal{V}</span> , each server computes  <span class="math">\\langle x_{i,j}^{(l)}\\rangle = T_j^{(l)}(r_i)</span> , for  <span class="math">l\\in [c],j\\in [n_i]</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The servers output  <span class="math">\\{\\llbracket a_{i,u}\\rrbracket \\}_{i\\in [1,\\ell -s],u\\in [0,D]}</span>  and  <span class="math">\\{\\langle a_{i,u}\\rangle \\}_{i\\in [\\ell -s + 1,\\ell ],u\\in [0,D]}</span> .</li>

    </ol>

    <p class="text-gray-300">Figure 19: Collaborative sumcheck protocol.</p>

    <p class="text-gray-300">Let  <span class="math">k = 2^s</span> ,  <span class="math">n = 2^\\ell \\geq N^2</span> ,  <span class="math">f</span>  be an  <span class="math">\\ell</span> -variate polynomial and  <span class="math">p(\\pmb{x}) \\coloneqq f(\\pmb{x}) - v(0, \\pmb{x})</span> ,  <span class="math">q(\\pmb{x}) \\coloneqq v(1, \\pmb{x}) - v(\\pmb{x}, 0) \\cdot v(\\pmb{x}, 1)</span> .</p>

    <p class="text-gray-300">Inputs: Each server holds the PSS of  <span class="math">f</span> 's evaluation on  <span class="math">\\{0,1\\}^\\ell</span> , denoted as  <span class="math">[\\pmb{x}_j]</span> , for  <span class="math">j \\in \\left[\\frac{n}{k}\\right]</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each server receives the PSS of masks  <span class="math">\\{\\llbracket m_j\\rrbracket \\}_{j\\in [\\frac{n}{k} ]}</span>  and unmasks  <span class="math">\\{\\llbracket u_{1,j}\\rrbracket ,\\llbracket u_{2,j}\\rrbracket ,\\llbracket u_{3,j}\\rrbracket \\}_{j\\in [\\frac{n}{k} ]}</span> .</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each server computes  <span class="math">\\llbracket \\pmb {y}_j\\rrbracket \\coloneqq \\llbracket \\pmb {x}_j\\rrbracket \\cdot \\llbracket \\pmb {m}_j\\rrbracket</span>  for  <span class="math">j\\in [\\frac{n}{k} ]</span></li>

      <li>The servers reveal  <span class="math">\\pmb{y}_i \\coloneqq (y_{\\frac{n_i}{N} + 1}, \\dots, y_{\\frac{n_i + 1}{N}})</span>  to  <span class="math">\\mathsf{S}_i</span> , for  <span class="math">i \\in [0, N - 1]</span> .</li>

      <li>The servers compute "masked" product tree as follows:</li>

    </ol>

    <p class="text-gray-300">(a) Each server invokes PROD-TREE  <span class="math">(\\pmb{y}_i)</span>  (Alg. 1) to get  <span class="math">\\frac{2n}{N} - 1</span>  elements  <span class="math">\\pmb{z}_i</span>  in the subtree, and sends the last  <span class="math">2k - 1</span>  elements of  <span class="math">\\pmb{z}_i</span>  to  <span class="math">\\mathsf{S}_0</span> . Denote the root as  <span class="math">r_i</span> . (b)  <span class="math">\\mathsf{S}_0</span>  collects  <span class="math">N(2k - 1)</span>  elements and invokes PROD-TREE  <span class="math">(\\{r_i\\}_{i\\in [0,N - 1]})</span>  (Alg. 1) to get  <span class="math">N - 1</span>  elements and 0. It constructs  <span class="math">\\pmb{z}^{\\prime}</span>  with  <span class="math">2Nk</span>  elements.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each server shares  <span class="math">\\mathbf{z}_{i,1} \\coloneqq \\mathbf{z}_i[\\mathbf{b}, 0]</span> ,  <span class="math">\\mathbf{z}_{i,2} \\coloneqq \\mathbf{z}_i[\\mathbf{b}, 1]</span> ,  <span class="math">\\mathbf{z}_{i,3} \\coloneqq \\mathbf{z}_i[1, \\mathbf{b}]</span>  to others.  <span class="math">S_0</span>  additionally shares  <span class="math">\\mathbf{z}&#x27;</span> . Finally, each server holds  <span class="math">\\{\\llbracket \\mathbf{z}_{1,j}\\rrbracket, \\llbracket \\mathbf{z}_{2,j}\\rrbracket, \\llbracket \\mathbf{z}_{3,j}\\rrbracket\\}_{j \\in [\\frac{n}{k}]}</span> .</li>

      <li>The servers invoke  <span class="math">\\mathcal{F}_{\\mathrm{PSSMult}}</span>  to compute  <span class="math">\\llbracket \\pmb {v}_{l,j}\\rrbracket \\coloneqq \\llbracket \\pmb {z}_{l,j}\\rrbracket \\cdot \\llbracket \\pmb {u}_{l,j}\\rrbracket</span> , for  <span class="math">j\\in [\\frac{n}{k} ]</span>  and  <span class="math">l = 1,2,3</span></li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The servers invoke Commit of  <span class="math">\\Pi_{\\mathrm{co - mIPC}}</span>  (Fig. 18) to compute  <span class="math">\\mathsf{com}_v</span> , and  <span class="math">\\Pi_{\\mathrm{co - zerocheck}}</span>  (Appx. E.3) on  <span class="math">p(\\pmb {x}),q(\\pmb {x})</span></li>

    </ol>

    <p class="text-gray-300">Figure 20: Collaborative prodcheck protocol.</p>

    <p class="text-gray-300">Fig. 19 provides the full protocol for the collaborative sumcheck protocol, denoted as  <span class="math">\\Pi_{\\mathrm{co-sumcheck}}</span> , computes  <span class="math">\\mathcal{P}</span>  of sumcheck (Appx. C.2) where  <span class="math">f(\\pmb{x}) \\coloneqq h(g_1(\\pmb{x}), \\dots, g_c(\\pmb{x}))</span> . Here,  <span class="math">h</span>  is a degree- <span class="math">D</span>  arithmetic circuit for multivariate polynomials, and  <span class="math">\\{g_i\\}</span>  are witness or public polynomials. In this work, we require that  <span class="math">h</span>  satisfies the condition that  <span class="math">D \\leq 4</span> , and the most complex term in  <span class="math">h</span>  contains only the product of four polynomials: two of which encode private witness, and the other encode public inputs.</p>

    <p class="text-gray-300">The security comes from the following lemma:</p>

    <p class="text-gray-300">Lemma 2. The collaborative sumcheck in Fig. 19 is an MPC protocol that securely computes  <span class="math">\\mathcal{P}</span>  of sumcheck in the  <span class="math">\\mathcal{F}_{\\mathrm{PSS2SSS}}</span> -hybrid world against a semi-honest adversary who corrupts at most  <span class="math">t</span>  servers.</p>

    <p class="text-gray-300">Proof. In the  <span class="math">i</span> -th round  <span class="math">(i \\in [1, \\ell - s])</span> , the sums of elements inside  <span class="math">\\pmb{a}_{i,\\pmb{u}}</span>  are used to form the degree- <span class="math">D</span>  round</p>

    <p class="text-gray-300">polynomial. In the <span class="math">i</span>-th round (<span class="math">i\\in[\\ell-s+1,\\ell]</span>), <span class="math">\\{a_{i,u}\\}_{u\\in[0,D]}</span> are used to form the round polynomial. Therefore, the correctness of the protocol follows straightforwardly from the construction. For security, due to the definition of <span class="math">h</span>, in Step 1.a, <span class="math">T_{j}(u)</span> is a PSS whose secret polynomial degree satisfies <span class="math">4k+2t&lt;N</span> under the security model of this work. Therefore, it is secure for the servers to recover the secret from the PSS. Except for invoking <span class="math">\\mathcal{F}_{\\textsc{PSS2SSS}}</span>, the servers only perform local computations during the execution. In other words, no corrupted parties have the opportunity to learn other parties’ private inputs. In conclusion, the security is guaranteed. ∎</p>

    <h3 id="sec-86" class="text-xl font-semibold mt-8">E.3 Our collaborative zerocheck</h3>

    <p class="text-gray-300">The collaborative zerocheck protocol, denoted as <span class="math">\\Pi_{\\text{co-zerocheck}}</span>, computes <span class="math">\\mathcal{P}</span> of zerocheck (Appx. C.3) where <span class="math">f</span> is secret-shared. According to §4.1, it can be reduced to a collaborative sumcheck protocol.</p>

    <p class="text-gray-300">Efficiency. As discussed in §4.1, each server computes the PSS of <span class="math">\\hat{\\mathbf{eq}}</span> with <span class="math">O\\left(\\frac{n}{N}\\right)</span> workload. Since it can be reduced to a collaborative sumcheck, the efficiency metrics are analogous.</p>

    <h3 id="sec-87" class="text-xl font-semibold mt-8">E.4 Our collaborative prodcheck</h3>

    <p class="text-gray-300">Fig. 20 provides the full protocol for the collaborative prodcheck protocol, denoted as <span class="math">\\Pi_{\\text{co-prodcheck}}</span>, computes <span class="math">\\mathcal{P}</span> of prodcheck (Appx. C.1) where each server only holds a secret-shared <span class="math">f</span>. Note that the protocol needs to prepare appropriate masks and unmasks <span class="math">m,u_{1},u_{2},u_{3}</span> in PSS form during the offline phase. In the proof delegation scenario, these <span class="math">O(2^{\\ell})</span> randomness can be directly provided by the client. We treat the subscript in a modular <span class="math">n</span> fashion. The masks <span class="math">\\{\\llbracket\\bm{m_{j}}\\rrbracket\\}_{j\\in[\\frac{n}{k}]}</span> and unmasks <span class="math">\\{\\llbracket\\bm{u_{1,j}}\\rrbracket,\\llbracket\\bm{u_{2,j}}\\rrbracket,\\llbracket\\bm{u_{3,j}}\\rrbracket\\}_{j\\in[\\frac{n}{k}]}</span> are prepared as follows:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Sample <span class="math">n</span> randomness <span class="math">r_{1},...,r_{n}\\stackrel{{\\scriptstyle\\sharp}}{{\\leftarrow}}\\mathbb{F}</span>, and denote <span class="math">\\bm{r}=(r_{1},...,r_{n}),\\bm{r}^{\\prime}=(r_{2},...,r_{n+1})</span>. Compute the inverse of <span class="math">\\bm{r},\\bm{r}^{\\prime}</span> as <span class="math">\\bm{r}^{-1},\\bm{r}^{{}^{\\prime}-1}</span>.</li>

      <li>The masks <span class="math">\\bm{m}</span> is computed as <span class="math">\\bm{r}\\cdot\\bm{r}^{{}^{\\prime}-1}</span>.</li>

      <li>Invoke <span class="math">\\textsc{Prod-Tree}(\\bm{r^{\\prime}}\\cdot\\bm{r}^{-1})</span> to get <span class="math">2n-1</span> elements. <span class="math">\\bm{u}</span> is constructed from these elements and <span class="math">0</span>.</li>

      <li>Share <span class="math">\\bm{m},\\bm{u}_{1}:=\\bm{u}[\\bm{b},0]</span>, <span class="math">\\bm{u}_{2}:=\\bm{u}[\\bm{b},1]</span>, <span class="math">\\bm{u}_{3}:=\\bm{u}[1,\\bm{b}]</span> for any <span class="math">\\bm{b}\\in\\{0,1\\}^{\\ell}</span> to the servers.</li>

    </ol>

    <p class="text-gray-300">The security comes from the following lemma:</p>

    <h6 id="sec-88" class="text-base font-medium mt-4">Lemma 3.</h6>

    <p class="text-gray-300">The collaborative prodcheck in Fig. 20 is an MPC protocol that computes <span class="math">\\mathcal{P}</span> of prodcheck in the <span class="math">\\{\\mathcal{F}_{\\textsc{PSSMult}},\\mathcal{F}_{\\textsc{PSS2SSS}},\\mathcal{F}_{\\text{co-MSM}}\\}</span>-hybrid world, secure against a semi-honest adversary who corrupts at most <span class="math">t</span> servers.</p>

    <h6 id="sec-89" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">For <span class="math">x_{j}\\in\\bm{x}</span>, the mask <span class="math">m_{j}</span> is prepared in the form <span class="math">r_{j}r_{j+1}^{-1}</span> where <span class="math">r_{j},r_{j+1}</span> are uniform randomness to hide <span class="math">x_{j}</span>. Taking the root of an input-<span class="math">n</span> product tree as an example: the root <span class="math">z=\\prod_{j=1}^{n}m_{j}\\cdot x_{j}=r_{1}r_{n+1}^{-1}\\prod_{j=1}^{n}x_{j}</span>. The corresponding unmask is prepared as <span class="math">r_{1}^{-1}r_{n+1}</span>. This ensures the unmasked output <span class="math">v=z\\cdot r_{1}^{-1}\\cdot r_{n+1}=\\prod_{j=1}^{n}x_{j}</span> is computed properly. Similarly, all unmasks <span class="math">\\{\\llbracket\\bm{u_{1,j}}\\rrbracket,\\llbracket\\bm{u_{2,j}}\\rrbracket,\\llbracket\\bm{u_{3,j}}\\rrbracket\\}_{j\\in[\\frac{n}{k}]}</span> are prepared correctly to ensure that the randomness applied to <span class="math">\\{\\llbracket\\bm{z_{1,j}}\\rrbracket,\\llbracket\\bm{z_{2,j}}\\rrbracket,\\llbracket\\bm{z_{3,j}}\\rrbracket\\}_{j\\in[\\frac{n}{k}]}</span> is removed. For security, it is easy to conclude from the protocol that the servers only perform local computations, except for invoking <span class="math">\\mathcal{F}_{\\textsc{PSSMult}}</span>, <span class="math">\\mathcal{F}_{\\textsc{PSS2SSS}}</span>, <span class="math">\\mathcal{F}_{\\textsc{co-MSM}}</span> during the collaborative protocols and distributing the shares to others; therefore, the corrupted servers cannot learn others’ private input. This ensures the security. ∎</p>

    <p class="text-gray-300">Efficiency. Here, we discuss the communication cost of this protocol, and we mainly focus on the procedure for computing the product tree since it takes up most of the cost. Let <span class="math">\\epsilon:=\\frac{N}{k}</span>, and the communication costs are as follows: In Step 2, revealing the “masked” leaves incurs <span class="math">N\\cdot\\frac{2^{\\ell}}{k}=\\epsilon\\cdot 2^{\\ell}</span> communication, and distributing the leaves incurs an additional <span class="math">2^{\\ell}</span> cost. In Step 3, to distributed the PSS smoothly, the communication is <span class="math">N(2k-1)</span>. In Step 4, distributing the PSS of <span class="math">v(1,\\bm{x})</span>, <span class="math">v(\\bm{x},0)</span>, and <span class="math">v(\\bm{x},1)</span> incurs <span class="math">3\\epsilon\\cdot 2^{\\ell}</span> cost. Finally, the three PSS multiplications incur <span class="math">3\\cdot 2\\epsilon\\cdot 2^{\\ell}=6\\epsilon\\cdot 2^{\\ell}</span> cost. Therefore, the total communication cost is <span class="math">(10\\epsilon+1)\\cdot 2^{\\ell}+N\\left(\\frac{2N}{\\epsilon}-1\\right)</span>, which is a relatively large concrete overhead.</p>

    <h3 id="sec-90" class="text-xl font-semibold mt-8">E.5 Our collaborative permcheck</h3>

    <p class="text-gray-300">The collaborative prodcheck protocol in E.4 can be extended to construct the collaborative permcheck protocol, denoted as <span class="math">\\Pi_{\\text{co-permcheck}}</span>. This protocol computes <span class="math">\\mathcal{P}</span> of permcheck (Appx. C.5), where all polynomials are secret-shared.</p>

    <p class="text-gray-300">Each server holds the PSS of <span class="math">f</span>, <span class="math">g</span>, <span class="math">s_{id}</span>, and <span class="math">s_{\\sigma}</span>. Using these PSS, each server can compute the required PSS of <span class="math">h_{1}(\\bm{x}):=f(\\bm{x})+\\alpha s_{id}(\\bm{x})+\\beta</span> and <span class="math">h_{2}(\\bm{x}):=g(\\bm{x})+\\alpha s_{\\sigma}(\\bm{x})+\\beta</span>. Then, the servers invoke Commit of <span class="math">\\Pi_{\\text{co-mlPC}}</span></p>

    <p class="text-gray-300">Let  <span class="math">n = 2^{\\ell}</span> ,  <span class="math">\\mathsf{M} \\in \\{0,1\\}^{n \\times n}</span>  be a public matrix such that  <span class="math">\\mathsf{M}(i,j) = 1</span>  if and only if  <span class="math">\\sigma(\\tilde{i}) = \\tilde{j}</span> , and 0 otherwise.</p>

    <p class="text-gray-300">Inputs: Each server holds the PSS of  <span class="math">\\mathsf{A}_V, \\mathsf{A}_{S_1}, \\mathsf{A}_{S_2}, \\mathsf{A}_I</span>  and  <span class="math">S_{1}(\\tilde{i},\\pmb {x}), S_{2}(\\tilde{i},\\pmb {x}), I(\\tilde{i},\\pmb {x})</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The servers invoke Commit of  <span class="math">\\Pi_{\\mathrm{co - mIPC}}</span>  (Fig. 18) to compute  <span class="math">\\mathsf{com}_V</span> , and Commit of  <span class="math">\\Pi_{\\mathrm{di - mIPC}}</span>  (Fig. 13) to compute  <span class="math">\\mathsf{com}_{S_1}, \\mathsf{com}_{S_2}, \\mathsf{com}_I</span> .</li>

      <li>The servers run  <span class="math">\\mathcal{P}</span>  of permcheck from §5.1 as follows:</li>

    </ol>

    <p class="text-gray-300">(a) Upon receiving  <span class="math">\\pmb{r_1}</span> , each server  <span class="math">S_{i}</span>  computes the PSS of  <span class="math">\\mathsf{A}_{M&#x27;}</span> , where  <span class="math">M&#x27;(x) := M(r_1, x)</span> . (b) The servers invoke Commit of  <span class="math">\\Pi_{\\mathrm{di - mIPC}}</span>  (Fig. 13) to compute  <span class="math">\\mathsf{com}_{M&#x27;}</span> . (c) The servers invoke  <span class="math">\\Pi_{\\mathrm{co - sumcheck}}</span>  (Fig. 19) on  <span class="math">V(\\boldsymbol{r_1}) = \\sum_{\\boldsymbol{b} \\in \\{0,1\\}^\\ell} M&#x27;(\\boldsymbol{b}) \\cdot V(\\boldsymbol{b})</span> , during which each server receives  <span class="math">\\boldsymbol{r_2}</span> . (d) The servers invoke Open of  <span class="math">\\Pi_{\\mathrm{co - mIPC}}</span>  (Fig. 18) for  <span class="math">H_{1} = V(\\boldsymbol{r}_{1})</span> ,  <span class="math">H_{2} = V(\\boldsymbol{r}_{2})</span> , and Open of  <span class="math">\\Pi_{\\mathrm{di - mIPC}}</span>  (Fig. 13) for  <span class="math">H_{3} = M^{\\prime}(\\boldsymbol{r}_{2})</span> . (e) The servers invoke  <span class="math">\\Pi_{\\mathrm{di - permcheck}}</span>  (Appx. D.5) on  <span class="math">\\mathcal{R}_{perm}(\\ell, \\sigma; M&#x27;, \\widehat{\\mathbf{e}}_{\\mathbf{l}}(\\boldsymbol{r}_1, \\boldsymbol{x})) = 1</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The servers invoke  <span class="math">\\Pi_{\\mathrm{co - zerocheck}}</span>  (Appx. E.3) on  <span class="math">F</span> .</li>

      <li>The servers invoke Open of  <span class="math">\\Pi_{\\mathrm{co - mIPC}}</span>  (Fig. 18) and  <span class="math">\\Pi_{\\mathrm{di - mIPC}}</span>  (Fig. 13) to finalize the above checks.</li>

    </ol>

    <p class="text-gray-300">(Appx. E.1) to compute  <span class="math">\\mathsf{com}_f</span> ,  <span class="math">\\mathsf{com}_g</span> ,  <span class="math">\\mathsf{com}_{s_{id}}</span> , and  <span class="math">\\mathsf{com}_{s_\\sigma}</span> . Finally, the servers invoke  <span class="math">\\Pi_{\\mathrm{co - prodcheck}}</span>  to check that  <span class="math">H_1 = \\prod_{\\boldsymbol{x} \\in \\{0,1\\}^\\ell} h_1(\\boldsymbol{x})</span>  and  <span class="math">H_2 = \\prod_{\\boldsymbol{x} \\in \\{0,1\\}^\\ell} h_2(\\boldsymbol{x})</span>  such that  <span class="math">H = \\frac{H_1}{H_2}</span> .</p>

    <p class="text-gray-300">Efficiency. Since it is reduced to the collaborative prodcheck, the efficiency metrics are analogous.</p>

    <p class="text-gray-300">Arithmetization. Consider a circuit  <span class="math">\\mathcal{C}</span>  comprising  <span class="math">l</span>  public inputs,  <span class="math">m</span>  gates performing either addition or multiplication, and an output. Let  <span class="math">2^{\\mu} = m + l + 1</span> . The computation trace is captured with  <span class="math">2^{\\mu}</span>  triples  <span class="math">\\{(L_i,R_i,O_i)\\in \\mathbb{F}^3\\}_{i\\in [2^\\mu ]}</span> , where each triple represents the left, right and output wires of the  <span class="math">i</span> -th gate.  <span class="math">\\mathcal{P}</span>  defines an  <span class="math">\\ell</span> -variate polynomial  <span class="math">V</span>  as the MLE of the triples, where  <span class="math">2^{\\ell} = 2^{\\mu +2} = n</span> , such that for all  <span class="math">i\\in [0,2^{\\mu} - 1]</span> ,</p>

    <div class="my-4 text-center"><span class="math-block">V (0, 0, \\tilde {\\boldsymbol {i}}) = L _ {i}, \\quad V (0, 1, \\tilde {\\boldsymbol {i}}) = R _ {i}, \\quad V (1, 0, \\tilde {\\boldsymbol {i}}) = O _ {i}</span></div>

    <p class="text-gray-300"><span class="math">\\mathcal{P}</span>  needs to prove the following constraints:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Gate identity: For any  <span class="math">\\pmb{x} \\in \\{0,1\\}^{\\mu}</span> ,</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">F (\\boldsymbol {x}) = S _ {1} (\\boldsymbol {x}) \\cdot (V (0, 0, \\boldsymbol {x}) + V (0, 1, \\boldsymbol {x})) + S _ {2} (\\boldsymbol {x}) \\cdot V (0, 0, \\boldsymbol {x}) \\cdot</span></div>

    <div class="my-4 text-center"><span class="math-block">V (0, 1, \\boldsymbol {x}) - V (1, 0, \\boldsymbol {x}) + I (\\boldsymbol {x}) = 0,</span></div>

    <p class="text-gray-300">where  <span class="math">S_{1}, S_{2}, I</span>  are three public polynomials encoding the circuit and input information.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Wiring identity: For any  <span class="math">\\pmb{x} \\in \\{0,1\\}^{\\ell}</span> ,  <span class="math">V(\\pmb{x}) = V(\\sigma(\\pmb{x}))</span> , where  <span class="math">\\sigma</span>  is a public permutation.</li>

    </ul>

    <p class="text-gray-300">HyperPlonk++.  <span class="math">\\mathcal{P}</span>  and  <span class="math">\\nu</span>  run the following:</p>

    <p class="text-gray-300">1:  <span class="math">\\mathcal{P}</span>  invokes mIPC.Commit (Appx. C.1) to compute  <span class="math">\\mathsf{com}_V</span> ,  <span class="math">\\mathsf{com}_{S_1}</span> ,  <span class="math">\\mathsf{com}_{S_2}</span>  and  <span class="math">\\mathsf{com}_I</span> , and sends them to  <span class="math">\\nu</span> . 2:  <span class="math">\\mathcal{P}</span> ,  <span class="math">\\mathcal{V}</span>  run the permcheck protocol in §5.1 to check the relation  <span class="math">\\mathcal{R}_{perm}(\\ell, \\sigma; V, V) = 1</span> , ensuring the wiring identity. 3:  <span class="math">\\mathcal{P},\\mathcal{V}</span>  run a zerocheck (Appx. C.3) to check  <span class="math">F(\\pmb {x}) = 0</span>  for any  <span class="math">\\pmb {x}\\in \\{0,1\\}^{\\ell}</span> , ensuring the gate identity. 4:  <span class="math">\\mathcal{P},\\mathcal{V}</span>  run mIPC.Open (Appx. C.1) to finalize the above checks.</p>

    <p class="text-gray-300">Security analysis of our permcheck. We provide the security analysis of our permcheck scheme with the following lemma:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Lemma 4. The scheme in §5.1 for  <span class="math">\\mathcal{R}_{perm}</span>  is perfect complete and has knowledge soundness error  $O\\left(\\frac{2^{\\ell}}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\right)$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Proof. The completeness follows the construction directly. Note that  <span class="math">\\mathsf{M} \\cdot \\mathsf{A}_f^\\top = \\mathsf{A}_g^\\top</span>  iff  <span class="math">g(\\pmb{x}) = \\sum_{\\pmb{y} \\in \\{0,1\\}^\\ell} M(\\pmb{x},\\pmb{y}) \\cdot f(\\pmb{y})</span>  for every  <span class="math">\\pmb{x} \\in \\{0,1\\}^\\ell</span> . Based on this observation, the second step is essentially the zerocheck protocol, which</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">results in a knowledge soundness error of $O\\left(\\frac{\\ell}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\right)<span class="math"> (<em>[13, Theorem 3.2]</em>). The final step introduces a knowledge soundness error of </span>O\\left(\\frac{2^{\\ell}}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\right)<span class="math"> (<em>[13, Theorem 3.6]</em>). Combining these, we conclude that the total knowledge soundness error is </span>O\\left(\\frac{2^{\\ell}}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\right)$. ∎</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Security analysis of HyperPlonk++. The security of HyperPlonk++ is established through the following lemma:</p>

    <h6 id="sec-95" class="text-base font-medium mt-4">Lemma 5.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">HyperPlonk++ is perfectly complete and has a knowledge soundness error of $O\\left(\\frac{2^{\\ell}}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\right)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-96" class="text-base font-medium mt-4">Proof.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The completeness directly follows from the protocol. For any <span class="math">(x;w)\\notin\\mathcal{R}</span>, at least one of the following conditions holds: (i) <span class="math">\\mathcal{R}_{perm}(\\ell,\\sigma;V,V)=0</span>, or (ii) <span class="math">\\mathcal{R}_{zero}(\\ell,\\mathsf{com}_{F};F)=0</span>. Based on the knowledge soundness error analysis of zerocheck <em>[13, Theorem 3.2]</em> and Lemma 4, we conclude that the probability of the <span class="math">\\mathcal{V}</span> accepting is at most $O\\left(\\frac{2^{\\ell}}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\right)$. ∎</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-97" class="text-xl font-semibold mt-8">F.2 Collaborative HyperPlonk++</h3>

    <p class="text-gray-300">The full protocol of collaborative HyperPlonk++ is presented in Fig. 21. In the protocol, each multivariate primitive is replaced with its distributed or collaborative counterparts from Appx. D and Appx. E. Note that Step 2-a introduces <span class="math">O\\left(\\frac{n}{N}\\right)</span> communication cost per server if the circuit has an arbitrary form. However, this cost can be eliminated if the circuit is data-parallel, as discussed in §5.3.</p>

    <p class="text-gray-300">Proof of Theorem 1. The security of HyperPlonk++ is proven through Lemma 5. We provide the security analysis of collaborative HyperPlonk++ in the following:</p>

    <h6 id="sec-98" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">The collaborative proof in Fig. 21 can be divided into two components: (i) local computations and the invocation of sub-protocols for multivariate polynomial primitives, which have already been proven secure in the <span class="math">\\{\\mathcal{F}_{\\mathsf{co}\\text{-}\\mathsf{MSM}},\\mathcal{F}_{\\mathsf{PSS2SSS}}\\}</span>-hybrid world through Lemmas 1 and 2; (ii) collaboratively accomplishing the Fiat-Shamir transform. In the latter component, the servers reconstruct the proof transcript and make queries to the random oracle. By the zero-knowledge property of the underlying zk-SNARK, the corrupted servers gain no information from the obtained proof transcript. ∎</p>

    <h2 id="sec-99" class="text-2xl font-bold">Appendix G USENIX Security <span class="math">\\acute{\\mathsf{2}}</span>5 Artifact Appendix</h2>

    <p class="text-gray-300">ARTIFACT EVALUATED U S E N I X S A T I F A C T E V A L U A T E D U S E N I X S P R E D I C E S U B E N I E S P R E D I C E YUNCTIONAU ARTIFACT EVALUATED U S E N I X S P R E D I C E</p>

    <p class="text-gray-300">Xuanming Liu<span class="math">^{1}</span>, Zhelei Zhou<span class="math">^{1}</span>, Yinghao Wang<span class="math">^{1}</span>, Yanxin Pang<span class="math">^{3}</span>, Jinye He<span class="math">^{4}</span>, Bingsheng Zhang<span class="math">^{1}</span>, Xiaohu Yang<span class="math">^{1}</span>, Jiaheng Zhang<span class="math">^{2}</span></p>

    <p class="text-gray-300"><span class="math">^{1}</span>Zhejiang University  <span class="math">^{2}</span>National University of Singapore  <span class="math">^{3}</span>Tsinghua University  <span class="math">^{4}</span>University of Virginia {hinsliu, zl_zhou, asternight, bingsheng, yangxh}@zju.edu.cn, jhzhang@nus.edu.sg, pangyx21@mails.tsinghua.edu.cn, qfn5bh@virginia.edu</p>

    <h2 id="sec-101" class="text-2xl font-bold">A Artifact Appendix</h2>

    <h3 id="sec-102" class="text-xl font-semibold mt-8">A.1 Abstract</h3>

    <p class="text-gray-300">In a nutshell, this work enables many low-resource servers to jointly execute a multiparty computation (MPC) protocol for zk-SNARK proof generation. During the proof generation, the servers collaboratively compute a zk-SNARK proof for a large circuit while keeping their secret inputs—known as the witness in zk-SNARK terminology—hidden from each other. A key feature of our design is its scalability: each server incurs less computational and memory overhead compared to the original monolithic prover.</p>

    <p class="text-gray-300">This artifact provides a proof-of-concept implementation. It includes a Rust-based prototype, supporting collaborative proof generation. The artifact includes implementations of collaborative primitives, the packed secret sharing scheme, and the complete collaborative zk-SNARK (HyperPlonk), which are introduced in the paper. Moreover, it provides two modes of execution: (i) Local mode and (ii) Distributed mode, allowing users to simulate the protocol either on a single machine or in a distributed network across multiple machines. Refer to the README.md file for detailed instructions on how to run the artifact. It also includes scripts to benchmark performance under various deployment configurations.</p>

    <h3 id="sec-103" class="text-xl font-semibold mt-8">A.2 Description &amp; Requirements</h3>

    <h4 id="sec-104" class="text-lg font-semibold mt-6">A.2.1 Security, privacy, and ethical concerns</h4>

    <p class="text-gray-300">This artifact is an academic prototype and is not suitable for production uses. It has not undergone formal reviews.</p>

    <p class="text-gray-300">Although it involves cryptographic protocols and peer-to-peer communication, it does not perform any destructive or malicious operations on developers' machines. However, since the artifact requires network-based interactions between multiple parties, we recommend running it in a controlled environment, virtual machine or sandbox to mitigate potential risks related to system security or data privacy during testing.</p>

    <h4 id="sec-105" class="text-lg font-semibold mt-6">A.2.2 How to access</h4>

    <p class="text-gray-300">The artifact is maintained at GitHub. A branch named artifact-eval, containing the code and docs specifically prepared for AE, is available at: https://github.com/LBruyne/Scalable-Collaborative-zkSNARK/tree/artifact-eval.</p>

    <p class="text-gray-300">For artifact evaluation, we also provide a stable reference to the evaluated version. The direct link to this version is available on Zenodo: https://doi.org/10.5281/zenodo.16722573. We recommend reviewers download the artifact from the Zenodo link, as it includes additional documentation and detailed instructions for usage.</p>

    <h4 id="sec-106" class="text-lg font-semibold mt-6">A.2.3 Hardware dependencies</h4>

    <p class="text-gray-300">This artifact does not require special hardware features.</p>

    <p class="text-gray-300">As detailed in the README.md file, the artifact supports two modes of execution. Reviewer/User could choose the mode that best fits their testing environment and available resources.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Distributed execution mode (Benchmark): This mode really runs a distributed network and supports large-scale deployment across 16-128 virtual or physical machines to run the collaborative proof generation. Each peer can be a low-resource instance with only 4GB of memory. All peers must be connected over a LAN or WAN network.</li>

      <li>Local execution mode (Local/Leader): (Recommended for its simplicity) Suitable for small-scale testing, this mode runs on a single machine. It does not require any special hardware beyond a standard system with sufficient computational resources. For reproducibility concerns, we recommend a machine with at least 1TB of RAM.</li>

    </ul>

    <h4 id="sec-107" class="text-lg font-semibold mt-6">A.2.4 Software dependencies</h4>

    <p class="text-gray-300">This artifact is developed using the Rust nightly toolchain. The following specific versions were used for development and evaluation (but other versions may also work):</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>rustup 1.27.1 (54dd3d00f 2024-04-24)</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>cargo 1.80.0-nightly (05364cb2f 2024-05-03)</li>

    </ul>

    <p class="text-gray-300">For convenience, we recommend installing the utility tool just, which simplifies execution and scripting. It can be installed from https://github.com/casey/just.</p>

    <p class="text-gray-300">A Linux-based operating system is recommended. All development and testing were conducted on Ubuntu 22.04 LTS.</p>

    <h4 id="sec-108" class="text-lg font-semibold mt-6">A.2.5 Benchmarks</h4>

    <p class="text-gray-300">None.</p>

    <h3 id="sec-109" class="text-xl font-semibold mt-8">A.3 Set-up</h3>

    <h4 id="sec-110" class="text-lg font-semibold mt-6">A.3.1 Installation</h4>

    <p class="text-gray-300">First, download the artifact and install the required Rust nightly toolchain. We also recommend installing the just tool to simplify command execution.</p>

    <p class="text-gray-300">Then, set up the environment with the following command:</p>

    <p class="text-gray-300">⬇ rustup default nightly-2024-05-03 # You can use a different nightly version, but this is the one we used for development.</p>

    <p class="text-gray-300">Next, build the artifact using:</p>

    <p class="text-gray-300">⬇ cargo build --release</p>

    <p class="text-gray-300">This command compiles the Rust code and prepares the executable files for use.</p>

    <p class="text-gray-300">Finally, run a basic test to ensure the artifact is set up correctly:</p>

    <p class="text-gray-300">⬇ just run --release --example sumcheck -F leader -- --l 4 --n 10</p>

    <p class="text-gray-300">If you do not have just installed, you can run the following command instead:</p>

    <p class="text-gray-300">⬇ RUSTFLAGS="-Ctarget-cpu=native -Awarnings" cargo + nightly run --release --example <example_name> <args></p>

    <p class="text-gray-300">where <example_name> is the name of the example (e.g., sumcheck), and <args> are the relevant command-line arguments (e.g., -F leader - -l 4 -n 10).</p>

    <p class="text-gray-300">You may need to use the following commands to allow the user’s shell to run the artifact properly:</p>

    <p class="text-gray-300">⬇ ulimit -HSn 65536</p>

    <p class="text-gray-300">This command runs a simple example of the collaborative sumcheck with input size <span class="math">2^{10}</span> in leader mode (refer to the README.md file), verifying that the main components of the artifact are functioning correctly. The output looks like this:</p>

    <p class="text-gray-300">⬇ Start: Local Sumcheck (thread ThreadId(1)) End: Local Sumcheck (thread ThreadId(1)) ...s Start: Collaborative Sumcheck Leader (thread ThreadId(1)) ... End: Collaborative SumcheckProduct Leader (thread ThreadId(1)) ...s Comm: (...)</p>

    <h4 id="sec-111" class="text-lg font-semibold mt-6">A.3.2 Basic Test</h4>

    <p class="text-gray-300">To test the artifact’s functionality, run:</p>

    <p class="text-gray-300">⬇ just run --release --example hyperplonk -F local ----l 8 --n 16</p>

    <p class="text-gray-300">This command executes a moderate-size example of the collaborative HyperPlonk protocol in local mode (refer to the README.md file), verifying that the artifact is functioning correctly. This simulates the workload of <span class="math">64=8\\times l</span> parties on a <span class="math">2^{16}=2^{n}</span>-gate circuit one-party-by-one-party using a single thread. The full network is emulated locally.</p>

    <p class="text-gray-300">The expected output should resemble:</p>

    <p class="text-gray-300">⬇ Start: Local HyperPlonk (thread ThreadId(1)) ... End: Local HyperPlonk (thread ThreadId(1)) ...s Start: Local HyperPlonk++ (thread ThreadId(1)) ... End: Local HyperPlonk++ (thread ThreadId(1)) ...s Start: Simulate Collaborative Hyperplonk++ (thread ThreadId(1)) ... Comm: (...) Comm: (...) End: Simulate Collaborative Hyperplonk++ (thread ThreadId(1)) ...s</p>

    <p class="text-gray-300">This command typically takes around 8 minutes to complete. You can notice that according to the log file, there are actually three instances being run: local HyperPlonk, local HyperPlonk++, and collaborative HyperPlonk++. The runtime duration is the runtime sum of these three instances. If it does not run successfully, please refer to the README.md file for troubleshooting. A common issue is insufficient memory allocation for virtual machines—try a smaller value of <span class="math">n</span>, or use a machine with more memory.</p>

    <h3 id="sec-112" class="text-xl font-semibold mt-8">A.4 Evaluation workflow</h3>

    <h4 id="sec-113" class="text-lg font-semibold mt-6">A.4.1 Major Claims</h4>

    <p class="text-gray-300">The protocol enables scalable collaborative zk-SNARK:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Each peer in the collaborative zk-SNARK (in this paper, HyperPlonk) incurs only a fraction (<span class="math">O(\\frac{1}{N})</span>, where <span class="math">N</span> is the number of servers) of the time and memory overhead compared to the monolithic prover. The communication is small. This is demonstrated in experiment (E1), corresponding to Section 5.2, 6.2, Figure 3, and Table 2, 3 of the paper.</li>

    </ol>

    <p class="text-gray-300">A.4.2 Experiments</p>

    <p class="text-gray-300">First, we introduce (this can also be found in the README.md file) that the artifact provides two modes of execution:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Distributed execution mode: The Rust feature Benchmark, enabled by -F benchmark in the command, specifies the protocol is run in a real distributed network. When benchmarking using this mode (this is what we do in the experiments), you need sufficient servers or machines connected over a LAN/WAN network. In the README.md file, we provide very detailed scripts to set up such a network and run the benchmarks. Especially note that there are many files and paths needed to by renamed, which are listed in the README.md file.</li>

      <li>Local execution mode: However, we understand reviewers may not have access to a distributed network or sufficient machines. Therefore, we also provide a local execution mode, which simulates the protocol in a single machine. The Rust feature Local, specifies the protocol is simulated locally. In this mode, A single thread will run each peer’s workload one-by-one in circulation. This mode does not require a network connection.</li>

    </ul>

    <p class="text-gray-300">Next, we describe the recommended experiments:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[Collaborative vs. Monolithic Prover] [30 human-minutes + 24 compute-hours]: This experiment compares the performance of collaborative HyperPlonk against the monolithic prover on general circuits.</li>

    </ol>

    <p class="text-gray-300">If you are running the benchmark in the distributed mode:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Provision 128 virtual machines, each with 2 vCPUs and 4GB RAM, connected over a LAN or WAN network. Additionally, set up a separate machine as a jump server that can access all 128 VMs via SSH. Ensure the network connectivity is functional.</li>

      <li>Follow the instructions in the benchmark section of the README.md file. The script we prepared will automatically handle the setup and execution.</li>

    </ol>

    <p class="text-gray-300">Note that to run this experiment, you only need the first three lines in the run_all.sh file.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The results for each cases will be written to the ./output directory. Use the provided Jupyter notebook (./hack/read_data.ipynb) to convert logs into CSV for performance comparisons. We expect to observe that the data reflect the Figure 3 and Table 2 in the paper. Note that in different runs, the computation time may vary slightly due to the non-deterministic nature of the network and system load. However, the overall linear trends should remain consistent.</li>

    </ol>

    <p class="text-gray-300">If you are running the benchmark in the local mode:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Prepare a single machine with at least 1TB of memory. This machine will run all the peers’ workloads in a single thread, simulating the distributed network locally.</li>

      <li>Run bash ./hack/bench_hyperplonk.sh. This script will automatically run the collaborative HyperPlonk and the monolithic prover in local mode, simulating the workload of 8<span class="math">l</span> peers on a 2^{n}-gate circuit using a single thread locally.</li>

      <li>The output will be written to the output directory. The expected results are similar to the Figure 3 and Table 2 in the paper. Remember that in local mode, the actual computation time should be divided by <span class="math">N=8l</span> where <span class="math">N</span> is the number of peers, to obtain the average time per peer. After this division, the results should be similar to the distributed mode. For example, in the case of <span class="math">l=4</span> and <span class="math">n=16</span>, the output should be similar to the following:</li>

    </ol>

    <p class="text-gray-300">⬇ Start: Local HyperPlonk (thread ThreadId(1)) ... End: Local HyperPlonk (thread ThreadId(1)) 52.132s Start: Local HyperPlonk++ (thread ThreadId(1)) ... End: Local HyperPlonk++ (thread ThreadId(1)) 65.256s Start: Simulate Collaborative Hyperplonk++ (thread ThreadId(1)) ... Comm: (2298526, 3666742) Comm: (2298526, 3666742) End: Simulate Collaborative Hyperplonk++ (thread ThreadId(1)) 190.622s</p>

    <p class="text-gray-300">Then each peer’s average time is <span class="math">\\frac{190.6s}{4\\times 8}=5.9s</span>, while the monolithic prover’s time is <span class="math">65.3s</span>. Therefore, the simulated speedup is <span class="math">\\frac{65.3s}{5.9s}\\approx 11</span>, which is consistent with the claims in the paper.</p>

    <h3 id="sec-114" class="text-xl font-semibold mt-8">A.5 Version</h3>

    <p class="text-gray-300">Based on the LaTeX template for Artifact Evaluation V20231005. Submission, reviewing and badging methodology followed for the evaluation of this artifact can be found at https://secartifacts.github.io/usenixsec2025/.</p>`;
---

<BaseLayout title="Scalable Collaborative zk-SNARK and Its Application to Fully... (2024/940)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2024 &middot; eprint 2024/940
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
