---
import BaseLayout from '../../layouts/BaseLayout.astro';
import PaperDisclaimer from '../../components/PaperDisclaimer.astro';
import PaperHistory from '../../components/PaperHistory.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2024/504';
const CRAWLER = 'marker';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Polylogarithmic Proofs for Multilinears over Binary Towers';
const AUTHORS_HTML = 'Benjamin E. Diamond, Jim Posen';

const CONTENT = `    <section id="abstract" class="mb-10">
      <h2 class="text-2xl font-bold">Abstract</h2>
      <p class="text-gray-300">The use of small fields has come to typify the design of modern, production-oriented SNARKs. In this work, we treat multilinear polynomial commitment over tiny fields. A tiny-field polynomial&mdash;in the nomenclature of Diamond and Posen (EUROCRYPT &#x27;25)&mdash;is defined over a field that has fewer elements than the polynomial itself has coefficients. We focus on multilinears over the field with just two elements.

In this work, we generically reduce the problem of tiny-field commitment to that of large-field commitment. We introduce a sumcheck-based compiler&mdash;called &quot;ring-switching&quot;&mdash;which, upon being fed a multilinear polynomial commitment scheme over some large extension field, yields a further scheme over that field&#x27;s ground field. The resulting scheme lacks embedding overhead, in that its commitment cost, on each input, equals that of the large-field scheme on each input of identical size (in bits). Its evaluation protocol&#x27;s overhead is linear for the prover and logarithmic for the verifier, and is essentially optimal.

Instantiating our ring-switching reduction on the BaseFold (CRYPTO &#x27;24) large-field multilinear polynomial commitment scheme&mdash;or more precisely on a characteristic-2 adaptation of that scheme that we develop at length&mdash;we obtain an extremely fast polynomial commitment scheme for bit-valued multilinears. Our scheme outperforms its state-of-the-art peers, a fact we demonstrate experimentally.</p>
      <p class="text-gray-300"><strong>Keywords:</strong> binary fields &middot; succinct arguments &middot; proximity testing</p>
    </section>

    <section id="sec-1" class="mb-10">
      <h2 class="text-2xl font-bold">1 Introduction</h2>

    <p class="text-gray-300">Today's fastest, production-oriented SNARKs universally use small fields. Before 2022, virtually all SNARKs operated over just one&mdash;cryptographically large&mdash;field. The small-field revolution began in earnest with <a href="https://github.com/starkware-libs/ethSTARK" target="_blank" rel="noopener noreferrer">ethSTARK</a> and <a href="https://github.com/0xPolygonZero/plonky2/blob/main/plonky2/plonky2.pdf" target="_blank" rel="noopener noreferrer">Plonky2</a> . Those systems decouple the respective fields used within their arithmetization and cryptography portions. That is, they use small fields&mdash;sized roughly like a 64-bit register&mdash;for their arithmetizations; each, during its security-critical portions, passes to a cryptographically large field extension of its arithmetization field. Subsequent production-oriented SNARKs like <a href="https://github.com/Plonky3/Plonky3" target="_blank" rel="noopener noreferrer">Plonky3</a> and <a href="https://github.com/risc0/risc0" target="_blank" rel="noopener noreferrer">RISC Zero</a> have embraced similar designs, based on 32-bit prime fields; <a href="https://github.com/starkware-libs/stwo" target="_blank" rel="noopener noreferrer">S-two</a> has adopted a related architecture based on Hab&uml;ock, Levit and Papini's Circle STARK <a href="#page-48-0">[HLP24]</a>. By using small fields, these systems have managed to deliver industry-leading provers, which outperform those grounded in elliptic-curve-based SNARKs (like Sonic <a href="#page-49-0">[MBKM19]</a>, PlonK <a href="#page-48-1">[GWC19]</a> and Marlin <a href="#page-47-0">[Chi+20]</a>).</p>

    <p class="text-gray-300">These SNARKs all use arithmetization fields which, though relatively small, are nonetheless at least as large as the statements they're capable of proving. This fact is not a coincidence. Indeed, all of them operate by, roughly, arranging their witness data into a trace table, Reed&ndash;Solomon-encoding that table's columns, and finally invoking a low-degree test based on FRI <a href="#page-47-1">[BBHR18a]</a>. Reed&ndash;Solomon codes demand alphabets that are at least as large as their block lengths are.</p>

    <p class="text-gray-300">A recent work of Diamond and Posen <a href="#page-48-2">[DP25]</a> breaks this trace-length barrier, in that it treats even polynomials over tiny fields&mdash;fields smaller than the statement's trace length. Crucially, that work does so without embedding overhead, a phenomenon we now recall. One might trivially attempt to commit to a tinyfield multilinear simply by embedding its coefficients into an extension, before blackbox-invoking a standard scheme on the resulting object. That approach would face at least two deficiencies. On the efficiency front, it would secure no gain from the tininess of its input's coefficients. Instead, it would impose an artificial penalty proportional to the ratio between its input's original coefficient bitwidth and the scheme's native field's bitwidth. On the security front, it would fail to guarantee the tininess of the prover's input, a security desideratum which, in practice, turns out to be essential. As Diamond and Posen <a href="#page-48-2">[DP25]</a> argue, most production-oriented SNARKs deployed today face embedding overhead in some form.</p>

    <p class="text-gray-300">In this work, we introduce a generic reduction from the problem of tiny-field multilinear polynomial commitment to that of large-field multilinear commitment. Our techniques are rather different from those of Diamond&ndash;Posen <a href="#page-48-2">[DP25]</a>. Our reduction, applied to any large-field scheme, yields a corresponding tiny-field scheme, which moreover lacks embedding overhead. It is agnostic to the large-field scheme used. In fact, our reduction works even on recently introduced, state-of-the-art large-field schemes like Blaze <a href="#page-47-2">[Bre+25]</a> and WHIR <a href="#page-47-3">[ACFY25]</a>, and even on large-field schemes that haven't been created yet. Its overhead over the underlying large-field scheme given to it is essentially optimal, and beats that associated with alternative constructions, like Hashcaster (we explain this further in Subsection <a href="#page-3-0">1.3</a> below).</p>

      <h3 id="sec-1.1" class="text-xl font-semibold mt-8">1.1 Some Historical Remarks</h3>

    <p class="text-gray-300">Diamond and Posen <a href="#page-48-2">[DP25]</a> break the trace-length barrier by further decoupling two fields which, in all of the small-field schemes noted above, coincide: the arithmetization field and the alphabet field. All of those schemes use just one prime field&mdash;again, sized just under 32 or 64 bits&mdash;both as the coefficient field of the polynomials committed and as the alphabet of the Reed&ndash;Solomon code used to encode them. The scheme <a href="#page-48-2">[DP25]</a> makes possible the simultaneous use of a tiny arithmetization field and a small alphabet field. Separately, that work reintroduces the use of binary fields, fields of characteristic 2; these fields have figured in various previous works, like FRI <a href="#page-47-1">[BBHR18a]</a> and STARK <a href="#page-47-4">[BBHR18b]</a>. Finally, that work treats exclusively multilinear polynomials; in this capacity, it extends an important line of work which includes Libra <a href="#page-49-1">[Xie+19]</a>, Virgo <a href="#page-49-2">[ZXZS20]</a>, Spartan <a href="#page-49-3">[Set20]</a>, Brakedown <a href="#page-48-3">[Gol+23]</a>, and HyperPlonk <a href="#page-47-5">[CBBZ23]</a>.</p>

    <p class="text-gray-300">To make their technique work, Diamond and Posen <a href="#page-48-2">[DP25]</a> tie together these various threads. They introduce a data-casting operation&mdash;which they call packing, and which is based on field extensions&mdash;which serves to recast a witness defined over F2, say, into a shorter witness over the larger field F<sup>2</sup> <sup>32</sup> . They then apply a Brakedown-like multilinear commitment procedure to the resulting witness, whose coefficient field, crucially, is large enough to be used as a Reed&ndash;Solomon alphabet. Using various mathematical techniques, those authors manage to make that scheme work (using Brakedown in a na&uml;&#305;ve, fire-and-forget manner on the packed, F<sup>2</sup> <sup>32</sup> -witness would lead to information loss). That work, therefore, treats three generally distinct fields at once: the tiny coefficient field, the small alphabet field, and the huge cryptographic field.</p>

    <p class="text-gray-300">We mention a further observation essential to that work. In those small-field schemes above&mdash;which are themselves based on the DEEP-ALI <a href="#page-47-6">[BGKS19]</a> paradigm&mdash;the Reed&ndash;Solomon code plays two separate roles at once. On the one hand, it plays the role of an error-correcting linear block code, a mathematical object that amplifies errors and corruptions and makes them efficiently detectable. On the other hand, it serves the distinct end of polynomial extrapolation. It is essential to those DEEP-ALI-based schemes that the Reed&ndash;Solomon codewords that arise within them be, semantically, evaluations of polynomials. In particular, those constraint polynomials which, if the prover is honest, must vanish identically over its witnesses must likewise vanish identically over the Reed&ndash;Solomon encodings of those witnesses.</p>

    <p class="text-gray-300">As Diamond and Posen <a href="#page-48-2">[DP25]</a> implicitly observe, unlike DEEP-ALI <a href="#page-47-6">[BGKS19]</a>, Brakedown <a href="#page-48-3">[Gol+23]</a> like its predecessor works Bootle, Chiesa and Groth <a href="#page-47-7">[BCG20]</a> and Ron-Zewi and Rothblum <a href="#page-49-4">[RR24]</a> do decouples the coding-theoretic specifications of its code from the semantics of its code. That is, Brakedown's Ligero-inspired <a href="#page-47-8">[AHIV23]</a> polynomial commitment scheme uses its code only for error-amplification; the semantics of that code are irrelevant to it. (That protocol could freely substitute in place of its code an otherwise-arbitrary code of identical alphabet, message length, block length, and distance, to no effect.) This decoupling makes Diamond and Posen's packing procedure coherent, since that procedure garbles the semantics of Reed&ndash;Solomon extrapolation.</p>

    <p class="text-gray-300">On the other hand, most transparent, hash-based proofs that achieve polylogarithmic verifiers&mdash;like Fractal <a href="#page-48-4">[COS20]</a>, or those based on DEEP-ALI <a href="#page-47-6">[BGKS19]</a>&mdash;use univariate quotienting. (We refer also to Hab&uml;ock <a href="#page-48-5">[Hab22]</a> for a useful survey of these techniques.) As Diamond and Posen <a href="#page-48-2">[DP25]</a> note, quotienting seems incompatible with their packing technique.</p>

    <p class="text-gray-300">Zeilberger, Chen and Fisch's BaseFold PCS <a href="#page-49-5">[ZCF24,</a> &sect; 5] seems to be the first multilinear polynomial commitment scheme with a polylogarithmic verifier that doesn't use quotienting. That work proves Reed&ndash; Solomon codes foldable just in the odd-characteristic, multiplicative case. BaseFold is simple, elegant, and efficient, and is a compelling candidate for adaptation to the binary case.</p>

    <p class="text-gray-300">This work's small-field PCS works in a drop-in way with the PIOP of <a href="#page-48-2">[DP25]</a>. By combining this work's PCS with that work's PIOP, one stands to obtain an efficient, full-blown SNARK for binary witnesses.</p>

      <h3 id="sec-1.2" class="text-xl font-semibold mt-8">1.2 Our Contributions</h3>

    <p class="text-gray-300">We sketch our contributions here; in Subsections 1.3 and 1.4 below, we explain them in more detail.</p>

    <p class="text-gray-300">A reduction from tiny-field commitment to huge-field commitment. Ring-switching is a generic compiler, which, on input a multilinear polynomial commitment scheme over some large extension field L/K, yields a new multilinear polynomial commitment scheme over the ground field K. Here, L can be of any characteristic, including 2. Each scheme our compiler outputs lacks embedding overhead, in that its commitment cost on each K-multilinear equals the original scheme's commitment cost on an L-multilinear of equal size in bits.</p>

    <p class="text-gray-300">We write  <span class="math">2^{\\kappa}</span>  for the degree of L over K, which we assume is a power of 2. Diamond and Posen's [DP25, &sect; 4] packing procedure takes in an  <span class="math">\\ell</span> -variate multilinear  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell-\\kappa-1})</span>  over L. (Packing works by interpreting each  <span class="math">2^{\\kappa}</span> -element chunk of  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span> 's Lagrange coefficient vector as an L-element, by basis-combination.) The multilinears  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span>  and  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell-\\kappa-1})</span>  are of the same size in bits; they contain &quot;the same amount of information&quot;. Our K-scheme's commitment procedure, on the input  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span> , simply packs  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span>  and invokes the underlying L-scheme's commitment procedure on  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell-\\kappa-1})</span> , the result. The hard part is relating an evaluation claim on  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span>  to one on  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell-\\kappa-1})</span> . To do this, we devise an unusual matrix-transposition trick, and write down an  <span class="math">\\ell - \\kappa</span> -round sumcheck between  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell-\\kappa-1})</span>  and a new sort of polynomial we call a ring-switch equality indicator. Polynomials of this latter sort can be evaluated succinctly by the verifier, but showing that they can is tricky. The evaluation algorithm at issue again entails matrix-transposition, this time carried out  <span class="math">\\ell - \\kappa</span>  times, in alternation with L-scaling operations. The idea is that a list of  <span class="math">2^{\\kappa}</span>  L-elements amounts to a  <span class="math">2^{\\kappa} \\times 2^{\\kappa}</span>  matrix of K-elements. By transposing this matrix, we obtain a &quot;dual&quot; list of L-elements, again of length  <span class="math">2^{\\kappa}</span> . We record further details in Subsection 1.3.</p>

    <p class="text-gray-300">An improved multilinear PCS for large binary fields, based on BaseFold. Zeilberger, Chen and Fisch's BaseFold PCS [ZCF24, &sect; 5] is an important multilinear polynomial commitment scheme for large prime fields. In order to spin up a target for our ring-switching reduction, we develop a characteristic-2 variant of BaseFold PCS, i.e. for large binary fields. We also improve that scheme by incorporating into it higher-arity folding, an optimization that reduces its proof sizes by more than half. The incompatibility of BaseFold&mdash;as written&mdash;with higher-arity folding has been noted by previous authors (see e.g. Arnon, Chiesa, Fenzi and Yogev's WHIR [ACFY25, &sect; 1.1]).</p>

    <p class="text-gray-300">To make higher-arity folding work with BaseFold, we introduce oracle-skipping, a new higher-arity folding mechanism. In contrast with FRI's original approach [BBHR18a, &sect; 3.2] to higher-arity folding&mdash;based on univariate polynomials&mdash;oracle-skipping simply carries out the usual, 2-to-1 folding procedure repeatedly, skipping intermediate oracles. Our security proof necessitates a different sort of proximity gap than FRI's approach does, one pertaining not to low-degree curves but instead to tensor combinations. Precisely this kind of proximity gap is established in recent work of Diamond and Gruen [DG25], which we leverage.</p>

    <p class="text-gray-300">Oracle-skipping narrows the proof-size gap between BaseFold and WHIR in the proven-security, unique decoding regime. For example, at the 100-bit security level and using the rate  <span class="math">\\rho=\\frac{1}{2}</span> , we obtain a proof size of 488 KiB for <em>large-field</em> multilinears on  <span class="math">\\ell=24</span>  variables, compared to WHIR-UD's 390 KiB. In the  <span class="math">\\ell=26</span>  <em>large-field</em> case, we obtain 563 KiB, while WHIR-UD reports 441 KiB [ACFY25, &sect; 6.3.1]. We discuss our techniques further in Subsection 1.4.</p>

    <p class="text-gray-300">A state-of-the-art PCS for multilinears over tiny binary fields. Putting the two parts above together, we obtain an extremely fast PCS for tiny-field multilinears. We outline our combined scheme in Section 5 below. We benchmark our scheme against Plonky3, a state-of-the-art competitor, using Binius, an open-source SNARK that implements this work's PCS. On a 28-variate multilinear over  <span class="math">\\mathbb{F}_2</span> , our scheme achieves singlethreaded commitment and opening times of just 144 and 160 milliseconds, respectively; our multithreaded commitment and opening times are 44 and 71 milliseconds, respectively (see Table 2). Our proofs for polynomials of this size are 0.351 MiB, and our verifier runs in under a milliseconds.</p>

    <p class="text-gray-300">Our measurements beat Plonky3's by between one and two orders of magnitude. Plonky3 takes 25 and 13 seconds, respectively, to commit a comparable amount of data, in the singlethreaded setting, and 4 and 2 seconds in multithreaded mode. Its proofs are also larger, and its verifier is around 20 milliseconds.</p>

      <h3 id="sec-1.3" class="text-xl font-semibold mt-8">1.3 Ring-Switching</h3>

    <p class="text-gray-300">In this subsection, we gently introduce ring-switching, prioritizing technical simplicity and accuracy. We fix a field extension L/K of power-of-2 degree  <span class="math">2^{\\kappa}</span> . Though ring-switching works for any such field extension, of any characteristic, the special case  <span class="math">K = \\mathbb{F}_2</span>  and  <span class="math">L = \\mathbb{F}_{2^{128}}</span>  is especially important and exemplary. We write  <span class="math">\\mathcal{B}_{\\kappa} := \\{0,1\\}^{\\kappa}</span>  for the  <span class="math">\\kappa</span> -dimensional unit cube.</p>

    <p class="text-gray-300"><strong>The problem.</strong> We assume access to a large-field multilinear polynomial commitment scheme for multilinears over L. How might we obtain a small-field commitment scheme for multilinears over K, assuming access to that large-field scheme?</p>

    <p class="text-gray-300">We begin with a small-field multilinear, say  <span class="math">t(X_0, \\ldots, X_{\\ell-1}) \\in K[X_0, \\ldots, X_{\\ell-1}]^{\\leq 1}</span> , that we'd like to commit to. Following Diamond and Posen [DP25], we fix a basis  <span class="math">(\\beta_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  of L over K, write  <span class="math">\\ell&#x27; := \\ell - \\kappa</span> , and define the packed multilinear:</p>

    <p class="text-gray-300">
<span class="math">$t&#x27;(X_0, \\dots, X_{\\ell&#x27;-1}) := \\sum_{v \\in \\mathcal{B}_{\\kappa}} t(v_0, \\dots, v_{\\kappa-1}, X_0, \\dots, X_{\\ell&#x27;-1}) \\cdot \\beta_v. \\tag{1}</span>$</p>

    <p class="text-gray-300">The multilinear  <span class="math">t&#x27;(X_0,\\ldots,X_{\\ell&#x27;-1})</span>  is the packing of  <span class="math">t(X_0,\\ldots,X_{\\ell-1})</span> , as Diamond and Posen explain. This relationship is easiest to see at the level of Lagrange coefficient vectors. For each  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span> , the  <span class="math">w^{\\text{th}}</span>  Lagrange coefficient t'(w) is the basis-combination, over  <span class="math">(\\beta_v)_{v \\in \\mathcal{B}_\\kappa}</span> , of the  <span class="math">w^{\\text{th}}</span>   <span class="math">2^\\kappa</span> -element chunk of  <span class="math">t(X_0,\\ldots,X_{\\ell-1})</span> 's Lagrange coefficient vector; that is,  <span class="math">t&#x27;(w) = \\sum_{v \\in \\mathcal{B}_\\kappa} t(v_0,\\ldots,v_{\\kappa-1},w_0,\\ldots,w_{\\ell&#x27;-1}) \\cdot \\beta_v</span> .</p>

    <p class="text-gray-300">How should we commit to  <span class="math">t(X_0,\\ldots,X_{\\ell-1})</span> ? Our commitment procedure is simple: it just packs</p>

    <p class="text-gray-300">How should we commit to  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span> ? Our commitment procedure is simple: it just packs  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span>  and invokes the underlying large-field scheme's commitment procedure on  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell&#x27;-1})</span> , the result. This procedure lacks embedding overhead, since  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span>  and  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell&#x27;-1})</span>  are of the same size (in bits).</p>

    <p class="text-gray-300">To check an evaluation claim on  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span> , we must reduce it to one on  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell&#x27;-1})</span> . We fix a point  <span class="math">(r_0, \\ldots, r_{\\ell-1})</span>  and an evaluation claim  <span class="math">s \\stackrel{?}{=} t(r_0, \\ldots, r_{\\ell-1})</span> . We emphasize that the evaluation point r is defined over L, and not over K (we refer to [DP25, &sect; 3.2], as well as to Subsection 2.7 below, for security definitions).</p>

    <p class="text-gray-300"><strong>A strawman approach.</strong> We begin with a tempting &quot;strawman&quot; approach, which exhibits the difficulty of the problem. This first approach, though correct, is insecure. On the other hand, it prefigures a few of our techniques, and serves as a jumping-off point.</p>

    <p class="text-gray-300">This simple technique proceeds in the following way. First, the prover sends values  <span class="math">(\\hat{s}_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  which&mdash;it claims&mdash;respectively satisfy</p>

    <p class="text-gray-300">
<span class="math">$\\hat{s}_v \\stackrel{?}{=} t(v_0, \\dots, v_{\\kappa-1}, r_{\\kappa}, \\dots, r_{\\ell-1}), \\tag{2}</span>$</p>

    <p class="text-gray-300">for each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> . The verifier begins by checking whether</p>

    <p class="text-gray-300">
<span class="math">$s \\stackrel{?}{=} \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\widetilde{eq}(v_0, \\dots, v_{\\kappa-1}, r_0, \\dots, r_{\\kappa-1}) \\cdot \\hat{s}_v</span>$
(3)</p>

    <p class="text-gray-300">holds. This equality will certainly hold if the prover is honest, since</p>

    <p class="text-gray-300"><span class="math">$t(r_0,\\ldots,r_{\\ell-1}) = \\sum_{v \\in \\mathcal{B}_\\kappa} \\widetilde{\\operatorname{eq}}(v_0,\\ldots,v_{\\kappa-1},r_0,\\ldots,r_{\\kappa-1}) \\cdot t(v_0,\\ldots,v_{\\kappa-1},r_\\kappa,\\ldots,r_{\\ell-1}).</span>$</p>

    <p class="text-gray-300">On the other hand, if  <span class="math">s \\neq t(r_0, \\ldots, r_{\\ell-1})</span> , then the prover can cause (3) to pass only by sending claims  <span class="math">(\\hat{s}_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  for which at least one of the equalities (2) does <em>not</em> hold.</p>

    <p class="text-gray-300">The linear combination, over the basis  <span class="math">(\\beta_v)_{v \\in \\mathcal{B}_{\\kappa}}</span> , of all  <span class="math">2^{\\kappa}</span>  instances of (2) is:</p>

    <p class="text-gray-300">
<span class="math">$\\sum_{v \\in \\mathcal{B}_{\\kappa}} \\hat{s}_v \\cdot \\beta_v \\stackrel{?}{=} \\sum_{v \\in \\mathcal{B}_{\\kappa}} t(v_0, \\dots, v_{\\kappa - 1}, r_{\\kappa}, \\dots, r_{\\ell - 1}) \\cdot \\beta_v. \\tag{4}</span>$</p>

    <p class="text-gray-300">On the other hand, by (1), the right-hand side of (4) is simply  <span class="math">t&#x27;(r_{\\kappa}, \\ldots, r_{\\ell-1})</span> , which the verifier has direct access to. The verifier may thus use the underlying large-field scheme to compare  <span class="math">\\sum_{v \\in \\mathcal{B}_{\\kappa}} \\beta_v \\cdot \\hat{s}_v</span>  to  <span class="math">t&#x27;(r_{\\kappa}, \\ldots, r_{\\ell-1})</span> . We summarize this approach in Figure 1 below.</p>

    <p class="text-gray-300">
<span class="math">$\\frac{\\mathcal{P}(r,s;t)}{\\text{for each }v\\in\\mathcal{B}_{\\kappa},\\text{ set }\\hat{s}_{v}\\coloneqq t(v_{0},\\ldots,v_{\\kappa-1},r_{\\kappa},\\ldots,r_{\\ell-1}).} \\xrightarrow{\\qquad \\qquad } \\underbrace{\\begin{array}{c} \\mathcal{V}(r,s)\\\\ \\\\ (\\hat{s}_{v})_{v\\in\\mathcal{B}_{\\kappa}} \\end{array}}_{\\text{check }s} \\stackrel{?}{=} \\sum_{v\\in\\mathcal{B}_{\\kappa}} \\tilde{\\mathsf{eq}}(v_{0},\\ldots,v_{\\kappa-1},r_{0},\\ldots,r_{\\kappa-1}) \\cdot \\hat{s}_{v}.</span>$</p>

    <p class="text-gray-300"><span class="math">$\\text{set }s&#x27;\\coloneqq\\sum_{v\\in\\mathcal{B}_{\\kappa}} \\hat{s}_{v}\\cdot\\beta_{v}.</span>$</p>

    <p class="text-gray-300"><span class="math">$\\text{check }s&#x27;\\stackrel{?}{=}t&#x27;(r_{\\kappa},\\ldots,r_{\\ell-1}) \\text{ using large-field scheme.}</span>$</p>

    <p class="text-gray-300">Figure 1: A simple&mdash;but insecure&mdash;strawman variant of ring-switching.</p>

    <p class="text-gray-300">While this protocol is complete, it's not secure. The problem is the linear combination (4) of (2). The set  <span class="math">(\\beta_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  is a basis of L over K. This means that unequal K-vectors yield unequal combinations. This only works, though, for coefficient vectors over K. In other words,  <span class="math">(\\beta_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  is linearly independent over K, but not over L. It's easy to write down two unequal L-vectors whose combinations with  <span class="math">(\\beta_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  yield the same L-element. Put differently,  <span class="math">(\\beta_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  induces an injection from  <span class="math">K^{2^{\\kappa}} \\to L</span> , but not from  <span class="math">L^{2^{\\kappa}} \\to L</span> .</p>

    <p class="text-gray-300">The problem is that the individual equations (2) are defined over L, and not K. Thus, combining them is not secure. In particular, the prover can easily contrive to construct values  <span class="math">(\\hat{s}_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  that don't <em>individually</em> equal  <span class="math">(t(v_0, \\ldots, v_{\\kappa-1}, r_{\\kappa}, \\ldots, r_{\\ell-1}))_{v \\in \\mathcal{B}_{\\kappa}}</span> , but for which  <span class="math">\\sum_{v \\in \\mathcal{B}_{\\kappa}} \\hat{s}_v \\cdot \\beta_v = t&#x27;(r_{\\kappa}, \\ldots, r_{\\ell-1})</span>  nonetheless holds.</p>

    <p class="text-gray-300">Our solution. Our idea is&mdash;very roughly&mdash;to further decompose the claims (2), until they are defined over K. We may then apply the &quot;tempting&quot; linear combination (4) to the resulting decomposed claims, proceeding &quot;slice-wise&quot;. We explain the details now.</p>

    <p class="text-gray-300">For each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> , the verifier can freely basis-decompose the prover's quantity  <span class="math">\\hat{s}_v</span> , writing</p>

    <p class="text-gray-300">
<span class="math">$\\hat{s}_v = \\sum_{u \\in \\mathcal{B}_\\kappa} \\hat{s}_{u,v} \\cdot \\beta_u \\tag{5}</span>$</p>

    <p class="text-gray-300">for appropriate K-elements  <span class="math">(\\hat{s}_{u,v})_{u \\in \\mathcal{B}_{\\kappa}}</span> . Moreover, for each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> ,</p>

    <p class="text-gray-300">
<span class="math">$t(v_0, \\dots, v_{\\kappa-1}, r_{\\kappa}, \\dots, r_{\\ell-1}) = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{eq}(r_{\\kappa}, \\dots, r_{\\ell-1}, w_0, \\dots, w_{\\ell&#x27;-1}) \\cdot t(v_0, \\dots, v_{\\kappa-1}, w_0, \\dots, w_{\\ell&#x27;-1}).</span>$
(6)</p>

    <p class="text-gray-300">Combining (5) and (6), we basis-decompose (2) as follows. For each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> , we have the claim:</p>

    <p class="text-gray-300">
<span class="math">$\\sum_{u \\in \\mathcal{B}_{\\kappa}} \\hat{s}_{u,v} \\cdot \\beta_u \\stackrel{?}{=} \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{\\operatorname{eq}}(r_{\\kappa}, \\dots, r_{\\ell-1}, w_0, \\dots, w_{\\ell&#x27;-1}) \\cdot t(v_0, \\dots, v_{\\kappa-1}, w_0, \\dots, w_{\\ell&#x27;-1}). \\tag{7}</span>$</p>

    <p class="text-gray-300">We're not quite done. While, for each  <span class="math">w \\in \\mathcal{B}_{\\kappa}</span> ,  <span class="math">t(v_0, \\ldots, v_{\\kappa-1}, w_0, \\ldots, w_{\\ell&#x27;-1})</span>  is of course a K-element,  <span class="math">\\widetilde{\\text{eq}}(r_{\\kappa}, \\ldots, r_{\\ell-1}, w_0, \\ldots, w_{\\ell&#x27;-1})</span>  is not. On the other hand, we can basis-decompose these latter quantities too. For each  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span> , we can freely write down K-elements  <span class="math">(A_{w,u})_{u \\in \\mathcal{B}_{\\kappa}}</span>  for which</p>

    <p class="text-gray-300">
<span class="math">$\\widetilde{\\operatorname{eq}}(r_{\\kappa}, \\dots, r_{\\ell-1}, w_0, \\dots, w_{\\ell&#x27;-1}) = \\sum_{u \\in \\mathcal{B}_{\\kappa}} A_{w,u} \\cdot \\beta_u.</span>$
(8)</p>

    <p class="text-gray-300">Using these, we further re-express (7) in the following way. For each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> , we obtain the claim:</p>

    <p class="text-gray-300"><span class="math">$\\sum_{u \\in \\mathcal{B}_{\\kappa}} \\hat{s}_{u,v} \\cdot \\beta_{u} \\stackrel{?}{=} \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{\\operatorname{eq}}(r_{\\kappa}, \\dots, r_{\\ell-1}, w_{0}, \\dots, w_{\\ell&#x27;-1}) \\cdot t(v_{0}, \\dots, v_{\\kappa-1}, w_{0}, \\dots, w_{\\ell&#x27;-1}) \\quad \\text{(this is (7).)}</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\left( \\sum_{u \\in \\mathcal{B}_{\\kappa}} A_{w,u} \\cdot \\beta_{u} \\right) \\cdot t(v_{0}, \\dots, v_{\\kappa-1}, w_{0}, \\dots, w_{\\ell&#x27;-1}) \\quad \\text{(by definition of } (A_{w,u})_{u \\in \\mathcal{B}_{\\kappa}} \\quad \\text{(8).)}</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\left( \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A_{w,u} \\cdot t(v_{0}, \\dots, v_{\\kappa-1}, w_{0}, \\dots, w_{\\ell&#x27;-1}) \\right) \\cdot \\beta_{u}. \\quad \\text{(rearrange the sum.)}</span>$</p>

    <p class="text-gray-300">We've finally reached something we can basis-decompose!</p>

    <p class="text-gray-300">Indeed, everything in the leftmost and rightmost sides of the above identity is defined over K, except for the basis-elements  <span class="math">(\\beta_u)_{u \\in \\mathcal{B}_{\\kappa}}</span> . To check the claim just above for each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> , it's thus equivalent for the verifier to check whether, for each  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span>  and each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> ,</p>

    <p class="text-gray-300">
<span class="math">$\\hat{s}_{u,v} \\stackrel{?}{=} \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A_{w,u} \\cdot t(v_0, \\dots, v_{\\kappa-1}, w_0, \\dots, w_{\\ell&#x27;-1}). \\tag{9}</span>$</p>

    <p class="text-gray-300">Here is the key point: unlike (2), the claims (9) are purely defined over K. We can thus basis-combine the claims (9) using  <span class="math">(\\beta_v)_{v \\in \\mathcal{B}_{\\kappa}}</span> , as opposed to the claims (2). We do exactly this. For each  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span> , combining (9) over  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> , we obtain the claim:</p>

    <p class="text-gray-300"><span class="math">$\\sum_{v \\in \\mathcal{B}_{\\kappa}} \\hat{s}_{u,v} \\cdot \\beta_{v} \\stackrel{?}{=} \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\left( \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A_{w,u} \\cdot t(v_{0}, \\dots, v_{\\kappa-1}, w_{0}, \\dots, w_{\\ell&#x27;-1}) \\right) \\cdot \\beta_{v} \\qquad \\text{(combine (9) over } (\\beta_{v})_{v \\in \\mathcal{B}_{\\kappa}}.)</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A_{w,u} \\cdot \\left( \\sum_{v \\in \\mathcal{B}_{\\kappa}} t(v_{0}, \\dots, v_{\\kappa-1}, w_{0}, \\dots, w_{\\ell&#x27;-1}) \\cdot \\beta_{v} \\right) \\qquad \\text{(rearrange the sum.)}</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A_{w,u} \\cdot t&#x27;(w_{0}, \\dots, w_{\\ell&#x27;-1}). \\qquad \\text{(by the definition (1).)}</span>$</p>

    <p class="text-gray-300">Up to defining</p>

    <p class="text-gray-300">
<span class="math">$\\hat{s}_u := \\sum_{v \\in \\mathcal{B}_r} \\hat{s}_{u,v} \\cdot \\beta_v, \\tag{10}</span>$</p>

    <p class="text-gray-300">we thus have the claims</p>

    <p class="text-gray-300">
<span class="math">$\\hat{s}_u \\stackrel{?}{=} \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A_{w,u} \\cdot t&#x27;(w_0, \\dots, w_{\\ell&#x27;-1}) \\tag{11}</span>$</p>

    <p class="text-gray-300">for each  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span> . This combination is secure. Moreover, its right-hand side depends only on  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell&#x27;-1})</span> , as well as on  <span class="math">(A_{w,u})_{w \\in \\mathcal{B}_{d&#x27;}}</span> . We're getting close to something that we can run the sumcheck on.</p>

    <p class="text-gray-300">The verifier must check (11) for each  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span> . In light of standard sumcheck batching techniques, though, this fact presents no obstacle. In practice, up to a soundness error of just  <span class="math">\\frac{\\kappa}{|L|}</span> , the verifier can simply sample further random scalars  <span class="math">(r&#x27;&#x27;_0, \\ldots, r&#x27;&#x27;_{\\kappa-1})</span> , and batch both sides of (11) by the L-vector  <span class="math">(\\widetilde{\\text{eq}}(u_0, \\ldots, u_{\\kappa-1}, r&#x27;&#x27;_0, \\ldots, r&#x27;&#x27;_{\\kappa-1}))_{u \\in \\mathcal{B}_{\\kappa}}</span> , over varying  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span> . That is, the verifier may check whether</p>

    <p class="text-gray-300">
<span class="math">$\\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(u, r&#x27;&#x27;) \\cdot \\hat{s}_u \\stackrel{?}{=} \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\left( \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(u, r&#x27;&#x27;) \\cdot A_{w, u} \\right) \\cdot t&#x27;(w) \\tag{12}</span>$</p>

    <p class="text-gray-300">holds. We summarize our amended protocol in Figure 2 below.</p>

    <p class="text-gray-300">
<span class="math">$\\frac{\\mathcal{P}(r,s;t)}{\\text{for each } v \\in \\mathcal{B}_{\\kappa}, \\text{ set } \\hat{s}_{v} \\coloneqq t(v_{0},\\ldots,v_{\\kappa-1},r_{\\kappa},\\ldots,r_{\\ell-1}). \\xrightarrow{(\\hat{s}_{v})_{v \\in \\mathcal{B}_{\\kappa}}} \\xrightarrow{\\mathcal{V}(r,s)} \\text{check } s \\stackrel{?}{=} \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\tilde{eq}(v_{0},\\ldots,v_{\\kappa-1},r_{0},\\ldots,r_{\\kappa-1}) \\cdot \\hat{s}_{v}.</span>$</p>

    <p class="text-gray-300"><span class="math">$\\text{for each } v \\in \\mathcal{B}_{\\kappa}, \\text{ decompose } \\hat{s}_{v} = \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\hat{s}_{u,v} \\cdot \\beta_{u}.</span>$</p>

    <p class="text-gray-300"><span class="math">$\\text{for each } u \\in \\mathcal{B}_{\\kappa}, \\text{ combine } \\hat{s}_{u} \\coloneqq \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\hat{s}_{u,v} \\cdot \\beta_{v}.</span>$</p>

    <p class="text-gray-300"><span class="math">$\\underbrace{(r&#x27;&#x27;_{0},\\ldots,r&#x27;&#x27;_{\\kappa-1})}_{\\text{many } \\text{multiple of the sumcheck } (12).</span>$</p>

    <p class="text-gray-300"><span class="math">$\\text{at the end of the sumcheck, evaluate}</span>$</p>

    <p class="text-gray-300"><span class="math">$\\sum_{u \\in \\mathcal{B}_{\\kappa}} \\tilde{eq}(u,r&#x27;&#x27;) \\cdot A_{u}(r&#x27;) \\text{ and } t&#x27;(r&#x27;),</span>$</p>

    <p class="text-gray-300"><span class="math">$\\text{where } r = (r&#x27;_{0},\\ldots,r&#x27;_{\\ell&#x27;-1}) \\text{ is the sumcheck challenge.}</span>$</p>

    <p class="text-gray-300">Figure 2: A rough sketch of our full ring-switching protocol.</p>

    <p class="text-gray-300">There is one, final issue that we've glossed over. In Figure 2 above, for each  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span> , we abbreviate  <span class="math">A_u(X_0,\\ldots,X_{\\ell&#x27;-1})</span>  for the multilinear extension of the function  <span class="math">A_u: w \\mapsto A_{w,u}</span>  on  <span class="math">\\mathcal{B}_{\\ell&#x27;}</span> . At the end of the sumcheck, the verifier may learn  <span class="math">t&#x27;(r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1})</span>  by invoking the underlying large-field scheme's evaluation protocol once. How might the verifier locally&mdash;and efficiently&mdash;obtain the evaluations  <span class="math">(A_u(r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1}))_{u\\in\\mathcal{B}_u}</span> ?</p>

    <p class="text-gray-300">This issue brings us to the trickiest part of our theory. We claim that the multilinears  <span class="math">(A_u(X_0,\\ldots,X_{\\ell&#x27;-1}))_{u\\in\\mathcal{B}_{\\kappa}}</span>  are <em>succinct</em>. In fact, the verifier may learn the whole list  <span class="math">(A_u(r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1}))_{u\\in\\mathcal{B}_{\\kappa}}</span> , in one shot, by expending just  <span class="math">2\\cdot 2^{\\kappa}\\cdot \\ell&#x27;</span>  <em>L</em>-multiplications. This fact is non-obvious; we sketch it now.</p>

    <p class="text-gray-300">To do this, we recall how the multilinears  <span class="math">A_u(X_0, \\ldots, X_{\\ell&#x27;-1})</span>  are defined. Indeed, for each  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span> ,  <span class="math">A_u(X_0, \\ldots, X_{\\ell&#x27;-1})</span>  is defined, in the Lagrange basis, as the  <span class="math">u^{\\text{th}}</span>  &quot;coordinate slice&quot; of the partially-specialized equality indicator  <span class="math">\\widetilde{\\text{eq}}(r_{\\kappa}, \\ldots, r_{\\ell-1}, X_0, \\ldots, X_{\\ell&#x27;-1})</span> . Moreover, for each  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span> ,</p>

    <p class="text-gray-300">
<span class="math">$A_{u}(r&#x27;_{0}, \\dots, r&#x27;_{\\ell&#x27;-1}) = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A_{w,u} \\cdot \\widetilde{\\mathsf{eq}}(w_{0}, \\dots, w_{\\ell&#x27;-1}, r&#x27;_{0}, \\dots, r&#x27;_{\\ell&#x27;-1})</span>$
(13)</p>

    <p class="text-gray-300">obviously holds. Writing all  <span class="math">2^{\\kappa}</span>  copies&mdash;i.e., over varying  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span> &mdash;of the sum (13) into the rows of a square,  <span class="math">2^{\\kappa} \\times 2^{\\kappa}</span>  matrix, we obtain the sum expression depicted in Figure 3 below.</p>

    <p class="text-gray-300">    <img src="_page_6_Figure_5.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Figure 3: Vertically stacking (13), we express  <span class="math">(A_u(r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1}))_{u\\in\\mathcal{B}_{\\kappa}}</span>  as the rows of an unusual sum.</p>

    <p class="text-gray-300">In Figure 3, for each  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span> , we've drawn a square in which  <span class="math">\\widetilde{\\operatorname{eq}}(r_{\\kappa},\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell&#x27;-1})</span>  is written vertically and  <span class="math">\\widetilde{\\operatorname{eq}}(w_0,\\ldots,w_{\\ell&#x27;-1},r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1})</span>  horizontally. By each such square, we mean the  <span class="math">2^{\\kappa} \\times 2^{\\kappa}</span>  K-matrix whose cells are the &quot;exterior product&quot; of  <span class="math">\\widetilde{\\operatorname{eq}}(r_{\\kappa}\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell&#x27;-1})</span>  and  <span class="math">\\widetilde{\\operatorname{eq}}(w_0,\\ldots,w_{\\ell&#x27;-1},r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1})</span> . I.e., we basis-decompose both L-elements, and take all cross-products between the resulting two K-vectors.</p>

    <p class="text-gray-300">Why did we do such a thing? Because this is simply the definition of (13)! Indeed, if we &quot;zoom into&quot; a single row  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span>  of Figure 3, then we obtain (13) on the nose (we recall that  <span class="math">A_{w,u}</span>  is defined to be the  <span class="math">u^{\\text{th}}</span>  coordinate slice of  <span class="math">\\widetilde{\\text{eq}}(r_{\\kappa}, \\ldots, r_{\\ell-1}, w_0, \\ldots, w_{\\ell&#x27;-1})</span> ).</p>

    <p class="text-gray-300">The point of Figure 3 is that it lets us explain our succinct algorithm for  <span class="math">(A_u(r&#x27;_0, \\ldots, r&#x27;_{\\ell&#x27;-1}))_{u \\in \\mathcal{B}_{\\kappa}}</span> . If we write  <span class="math">\\star</span>  for the &quot;exterior product&quot; operation between K-vectors, then Figure 3 shows us that:</p>

    <p class="text-gray-300">
<span class="math">$(A_u(r&#x27;_0, \\dots, r&#x27;_{\\ell&#x27;-1}))_{u \\in \\mathcal{B}_{\\kappa}} = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{eq}(r_{\\kappa} \\dots, r_{\\ell-1}, w_0, \\dots, w_{\\ell&#x27;-1}) \\star \\widetilde{eq}(w_0, \\dots, w_{\\ell&#x27;-1}, r&#x27;_0, \\dots, r&#x27;_{\\ell&#x27;-1}).</span>$
(14)</p>

    <p class="text-gray-300">The right-hand side of (14) almost looks like the equality indicator expression  <span class="math">\\widetilde{eq}(r_{\\kappa}, \\dots, r_{\\ell-1}, r&#x27;_0, \\dots, r&#x27;_{\\ell&#x27;-1})</span> , which we know is succinct. The problem is the  <span class="math">\\star</span>  operation.</p>

    <p class="text-gray-300">We state without proof (though see Section 3) that, in characteristic 2, the following efficient procedure yields  <span class="math">(A_u(r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1}))_{u\\in\\mathcal{B}_\\kappa}</span> . The verifier should maintain a  <span class="math">2^\\kappa\\times 2^\\kappa</span>  K-matrix, initialized to be 1 in the top-left cell and 0 elsewhere. For each  <span class="math">i\\in\\{0,\\ldots,\\ell&#x27;-1\\}</span> , the verifier should L-multiply each column of this matrix by  <span class="math">r_{\\kappa+i}</span>  and each row of it by  <span class="math">r&#x27;_i</span> , and update its running matrix by adding to it these two scalings. We interpret rows and columns as L-elements by basis-combination. The result of this procedure will be  <span class="math">(A_u(r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1}))_{u\\in\\mathcal{B}_\\kappa}</span> . To explain why this works, we must get into a bit of algebra. Everything hinges on  <span class="math">L\\otimes_K L</span> , the tensor product of L with itself over its own subfield K, an object we call the &quot;tensor algebra&quot;.</p>

    <p class="text-gray-300"><strong>Hashcaster.</strong> We compare ring-switching in detail to Hashcaster. Soukhanov's Hashcaster [Sou24] is a SNARK for binary (i.e., specifically  <span class="math">\\mathbb{F}_2</span> -valued) witnesses. At the PIOP level, that work introduces a number of innovations, including an efficient &quot;ternary&quot; sumcheck for domains of power-of-3 size. For the purposes of this work, we survey just that work's ideas at the PCS level, which are also important. Indeed, that work yields an alternative reduction from the problem of evaluating the K-multilinear  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span>  to that of evaluating its packed L-multilinear  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell&#x27;-1})</span> . For self-containedness, we reproduce that work's technique here in some detail; we then compare it to ring-switching, the approach of this work.</p>

    <p class="text-gray-300">We again fix a degree- <span class="math">2^{\\kappa}</span>  field extension L/K, and write  <span class="math">(\\beta_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  for a basis of L over K. We write  <span class="math">\\sigma \\in \\operatorname{Gal}(L/K)</span>  for the <em>Frobenius automorphism</em> of L over K. As a notational device, for each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> , we write  <span class="math">\\{v\\} := \\sum_{i=0}^{\\kappa-1} 2^i \\cdot v_i</span> .</p>

    <p class="text-gray-300">Hashcaster begins with the same observation as Subsection 1.3 does. That is, for the verifier to assess the evaluation claim  <span class="math">s \\stackrel{?}{=} t(r_0, \\dots, r_{\\ell-1})</span> , it suffices for the prover to send it quantities  <span class="math">(\\hat{s}_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  respectively claimed to equal  <span class="math">(t(v_0, \\dots, v_{\\kappa-1}, r_{\\kappa}, \\dots, r_{\\ell-1}))_{v \\in \\mathcal{B}_{\\kappa}}</span>  (recall (2)). Indeed, given these, the verifier can check</p>

    <p class="text-gray-300">
<span class="math">$s \\stackrel{?}{=} \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\text{eq}}(v_0, \\dots, v_{\\kappa-1}, r_0, \\dots, r_{\\kappa-1}) \\cdot \\hat{s}_v, \\tag{15}</span>$</p>

    <p class="text-gray-300">as usual (just as in (3)).</p>

    <p class="text-gray-300">At this point, Hashcaster diverges. Hashcaster's idea is to relate the claimed partial evaluations  <span class="math">(\\hat{s}_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  to the respective evaluations of the packed multilinear  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell&#x27;-1})</span>  at  <span class="math">(\\sigma^{\\{v\\}}(r_{\\kappa}), \\ldots, \\sigma^{\\{v\\}}(r_{\\ell-1}))_{v \\in \\mathcal{B}_{\\kappa}}</span> , the componentwise Galois orbit of the suffix  <span class="math">(r_{\\kappa}, \\ldots, r_{\\ell-1})</span> .</p>

    <p class="text-gray-300">There are various ways to make this task precise. Hashcaster's approach hinges on the following matrix identity:</p>

    <p class="text-gray-300">
$$\\begin{bmatrix}
\\sigma^{{u}}(\\beta_v) &amp; \\vdots &amp; \\vdots \\
\\hat{s}<em>v &amp; \\vdots &amp; \\vdots \\
\\vdots &amp; \\vdots &amp; \\vdots \\
\\end{bmatrix} \\stackrel{?}{=} \\begin{bmatrix} \\sigma^{{u}}(t')(r</em>{\\kappa}, \\dots, r_{\\ell-1}) \\
\\vdots &amp; \\vdots &amp; \\vdots \\
\\end{bmatrix}.$$
(16)</p>

    <p class="text-gray-300">On the left, we have the  <span class="math">2^{\\kappa} \\times 2^{\\kappa}</span>  matrix whose  <span class="math">(\\{u\\}, \\{v\\})^{\\text{th}}</span>  entry is  <span class="math">\\sigma^{\\{u\\}}(\\beta_v)</span> , the  <span class="math">\\{u\\}^{\\text{th}}</span>  Galois image of the  <span class="math">v^{\\text{th}}</span>  basis vector. On the right-hand side, we have the vector containing the respective evaluations at  <span class="math">(r_{\\kappa}, \\ldots, r_{\\ell-1})</span>  of  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell&#x27;-1})</span> 's various &quot;Galois twists&quot;. Indeed, for each  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span> , we define  <span class="math">\\sigma^{\\{u\\}}(t&#x27;)(X_0, \\ldots, X_{\\ell&#x27;-1})</span>  by the Lagrange basis prescription  <span class="math">\\sigma^{\\{u\\}}: w \\mapsto \\sigma^{\\{u\\}}(t&#x27;(w))</span> , for each  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span> . It is a nontrivial fact of field theory that the matrix  <span class="math">\\left[\\sigma^{\\{u\\}}(\\beta_v)\\right]</span>  is nonsingular; we refer to Lidl and Niederreiter [LN96, Lem. 3.51]. Assuming this fact, it's not too hard to show that (16) holds if and only if the prover is honest (i.e., if each of its claims  <span class="math">\\hat{s}_v \\stackrel{?}{=} t(v_0, \\ldots, v_{\\kappa-1}, r_{\\kappa}, \\ldots, r_{\\ell-1})</span> , for  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> , is true).</p>

    <p class="text-gray-300">Upon receiving the prover's vector of claims  <span class="math">(\\hat{s}_v)_{v \\in \\mathcal{B}_{\\kappa}}</span> , the verifier could thus compute the matrix transformation (16) on that vector. By moreover &quot;peeling off&quot; the twists  <span class="math">\\sigma^{\\{u\\}}</span> , for each  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span> , the verifier could thereby obtain a further vector supposedly equal to  <span class="math">(t&#x27;(\\sigma^{\\{-u\\}}(r_{\\kappa}),\\ldots,\\sigma^{\\{-u\\}}(r_{\\ell-1})))_{u\\in\\mathcal{B}_{\\kappa}}</span> , the vector of evaluations of  <span class="math">t&#x27;(X_0,\\ldots,X_{\\ell&#x27;-1})</span>  on the Galois orbit of  <span class="math">(r_{\\kappa},\\ldots,r_{\\ell-1})</span> .</p>

    <p class="text-gray-300">In fact, we will do Hashcaster one better. We claim that, up to performing a transposition of the sort already discussed above in the context of ring-switching, the verifier may simplify its job; specifically, it might directly relate  <span class="math">(\\hat{s}_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  to  <span class="math">(t&#x27;(\\sigma^{\\{v\\}}(r_{\\kappa}), \\ldots, \\sigma^{\\{v\\}}(r_{\\ell-1})))_{v \\in \\mathcal{B}_{\\kappa}}</span>  (with no twists necessary). Indeed, given  <span class="math">(\\hat{s}_v)_{v \\in \\mathcal{B}_{\\kappa}}</span> , the verifier may freely, as before, decompose  <span class="math">\\hat{s}_v = \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\hat{s}_{u,v} \\cdot \\beta_u</span>  (just as in (5)), and write  <span class="math">\\hat{s}_u := \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\hat{s}_{u,v} \\cdot \\beta_v</span>  (just as in (10)). In this setting, we obtain the further identity:</p>

    <p class="text-gray-300">
<span class="math">$\\underbrace{\\begin{bmatrix} - \\hat{s}_{u} - \\hat{s}_{v} - \\hat{s}_{v} - \\hat{s}_{v} - \\hat{s}_{v} \\end{bmatrix}}_{u \\in \\mathcal{B}_{\\kappa} \\text{ varying}} \\cdot \\begin{bmatrix} \\sigma^{\\{v\\}}(\\beta_{u}) \\end{bmatrix} \\stackrel{?}{=} \\underbrace{\\begin{bmatrix} - t&#x27;(\\sigma^{\\{v\\}}(r_{\\kappa}), \\dots, \\sigma^{\\{v\\}}(r_{\\ell-1})) - \\dots \\end{bmatrix}}_{v \\in \\mathcal{B}_{\\kappa} \\text{ varying}}. (17)</span>$</p>

    <p class="text-gray-300">We claim that (17) also holds if and only if the prover is honest (i.e., if  <span class="math">\\hat{s}_v \\stackrel{?}{=} t(v_0, \\dots, v_{\\kappa-1}, r_{\\kappa}, \\dots, r_{\\ell-1})</span>  for each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> ). Importantly, the right-hand side of (17) directly yields the evaluations of  <span class="math">t&#x27;(X_0, \\dots, X_{\\ell&#x27;-1})</span>  over  <span class="math">(r_{\\kappa}, \\dots, r_{\\ell-1})</span> 's Galois orbit, with no &quot;twisting&quot; or &quot;peeling off&quot; necessary.</p>

    <p class="text-gray-300">To check the validity of the prover's claim, then, it's thus enough for the verifier to compute</p>

    <p class="text-gray-300">
<span class="math">$\\underbrace{\\left[ \\underbrace{\\overline{s}_{v}} \\right]}_{v \\in \\mathcal{B}_{\\kappa} \\text{ varying}} := \\underbrace{\\left[ \\underbrace{\\hat{s}_{u}} \\right]}_{u \\in \\mathcal{B}_{\\kappa} \\text{ varying}} \\cdot \\left[ \\sigma^{\\{v\\}}(\\beta_{u}) \\right], \\tag{18}</span>$</p>

    <p class="text-gray-300">i.e. the left-hand side of (17), and then check whether, for each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> ,</p>

    <p class="text-gray-300">
<span class="math">$\\overline{s}_v \\stackrel{?}{=} t&#x27; \\Big( \\sigma^{\\{v\\}}(r_\\kappa), \\dots, \\sigma^{\\{v\\}}(r_{\\ell-1}) \\Big)</span>$</p>

    <p class="text-gray-300"><span class="math">$\\tag{19}</span>$</p>

    <p class="text-gray-300">holds.</p>

    <p class="text-gray-300">We've made progress, since each right-hand side of (19) (for  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> ) is an evaluation of  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell&#x27;-1})</span> . On the other hand, we'd prefer to evaluate  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell&#x27;-1})</span>  at just one place, as opposed to over the entire orbit  <span class="math">(\\sigma^{\\{v\\}}(r_{\\kappa}), \\ldots, \\sigma^{\\{v\\}}(r_{\\ell-1}))_{v \\in \\mathcal{B}_{\\kappa}}</span> . To this end, we again apply a sumcheck-based batching technique, due this time to Ron-Zewi and Rothblum [RR24, Fig. 3]. Indeed, we note that, for each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> , (19) is equivalent to the sum claim:</p>

    <p class="text-gray-300">
<span class="math">$\\overline{s}_v \\stackrel{?}{=} \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{\\operatorname{eq}} \\left( \\sigma^{\\{v\\}}(r_{\\kappa}), \\dots, \\sigma^{\\{v\\}}(r_{\\ell-1}), w_0, \\dots, w_{\\ell&#x27;-1} \\right) \\cdot t&#x27;(w). \\tag{20}</span>$</p>

    <p class="text-gray-300">After sampling batching scalars  <span class="math">(r_0&#x27;&#x27;, \\ldots, r_{\\kappa-1}&#x27;&#x27;)</span> , the verifier may batch both sides of (20) by the vector  <span class="math">(\\widetilde{\\operatorname{eq}}(v_0, \\ldots, v_{\\kappa-1}, r_0&#x27;&#x27;, \\ldots, r_{\\kappa-1}&#x27;&#x27;))_{v \\in \\mathcal{B}_{\\kappa}}</span> , and in this way obtain the batched sum claim:</p>

    <p class="text-gray-300">
<span class="math">$\\sum_{v \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(v, r&#x27;&#x27;) \\cdot \\overline{s}_{v} \\stackrel{?}{=} \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\left( \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(v, r&#x27;&#x27;) \\cdot \\widetilde{\\operatorname{eq}} \\left( \\sigma^{\\{v\\}}(r_{\\kappa}), \\dots, \\sigma^{\\{v\\}}(r_{\\ell-1}), w_{0}, \\dots, w_{\\ell&#x27;-1} \\right) \\right) \\cdot t&#x27;(w). \\tag{21}</span>$</p>

    <p class="text-gray-300">This is finally something we can run the sumcheck on. Combining these observations, we obtain the protocol sketched in Figure 4.</p>

    <p class="text-gray-300">
<span class="math">$\\begin{array}{c} \\underline{\\mathcal{P}(r,s;t)} \\\\ \\text{for each } v \\in \\mathcal{B}_{\\kappa}, \\text{ set } \\hat{s}_{v} \\coloneqq t(v_{0},\\ldots,v_{\\kappa-1},r_{\\kappa},\\ldots,r_{\\ell-1}). \\\\ \\hline \\\\ &amp; \\underbrace{(\\hat{s}_{v})_{v \\in \\mathcal{B}_{\\kappa}}}_{} \\\\ \\text{for each } v \\in \\mathcal{B}_{\\kappa}, \\text{ set } \\hat{s}_{v} \\coloneqq t(v_{0},\\ldots,v_{\\kappa-1},r_{\\kappa},\\ldots,r_{\\ell-1}). \\\\ \\hline \\\\ &amp; \\underbrace{(\\hat{s}_{v})_{v \\in \\mathcal{B}_{\\kappa}}}_{} \\\\ \\text{for each } v \\in \\mathcal{B}_{\\kappa}, \\text{ decompose } \\hat{s}_{v} = \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\hat{s}_{u,v} \\cdot \\beta_{u}. \\\\ \\\\ \\text{for each } u \\in \\mathcal{B}_{\\kappa}, \\text{ combine } \\hat{s}_{u} \\coloneqq \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\hat{s}_{u,v} \\cdot \\beta_{v}. \\\\ \\\\ \\text{set } [-\\overline{s}_{v}-] \\coloneqq [-\\hat{s}_{u}-] \\cdot \\left[\\sigma^{\\{v\\}}(\\beta_{u})\\right] \\text{ as in (18)} \\\\ \\\\ \\underbrace{(r&#x27;&#x27;_{0},\\ldots,r&#x27;&#x27;_{\\kappa-1})}_{} \\\\ \\text{sample batching scalars } (r&#x27;&#x27;_{0},\\ldots,r&#x27;&#x27;_{\\kappa-1}) \\leftarrow L^{\\kappa}. \\\\ \\\\ \\\\ \\text{otherwise } \\mathcal{P} \\text{ and } \\mathcal{V} \\text{ run the sumcheck (21)}. \\\\ \\\\ \\text{at the end of the sumcheck, evaluate} \\\\ \\\\ \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\widehat{\\mathsf{eq}}(v,r&#x27;&#x27;) \\cdot \\widehat{\\mathsf{eq}}\\left(\\sigma^{\\{v\\}}(r),r&#x27;\\right) \\text{ and } t&#x27;(r&#x27;), \\\\ \\\\ \\text{where } r = (r&#x27;_{0},\\ldots,r&#x27;_{\\ell&#x27;-1}) \\text{ is the sumcheck challenge,} \\\\ \\\\ \\text{and we set } \\sigma^{\\{v\\}}(r) \\coloneqq \\left(\\sigma^{\\{v\\}}(r_{\\kappa}),\\ldots,\\sigma^{\\{v\\}}(r_{\\ell-1})\\right). \\\\ \\end{array}</span>$</p>

    <p class="text-gray-300">Figure 4: A sketch of the Hashcaster [Sou24] protocol.</p>

    <p class="text-gray-300">This is a perfectly correct and sound protocol, which moreover wards off the tensor-algebraic complexities of ring-switching (cf. Figure 3). But what about its efficiency? We claim that ring-switching is more efficient than Hashcaster for both the prover and the verifier. We note that the comparison we undertake below pits ring-switching against our <em>improved</em> variant of Hashcaster (explained above). The &quot;original&quot; version of Hashcaster is still worse, albeit just by a bit. (We expand this analysis further in Subsection 3.2 below.)</p>

    <p class="text-gray-300">We begin with our protocols' verifiers. The verifier complexities of Figures 2 and 4 turn out to be almost identical, except for the Hashcaster verifier's matrix transformation (18). Hashcaster's verifier must compute this matrix product; ours has no analogue of this task. This transformation entails a quadratic number of L-multiplications in the extension degree  <span class="math">2^{\\kappa}</span> . (There might be an &quot;NTT analogue&quot; for this matrix; we haven't investigated this thoroughly.) Thus Hashcaster's verifier's number of L-multiplications grows quadratically in the extension degree  <span class="math">2^{\\kappa}</span> ; ours grows only linearly. We do not know how to modify Hashcaster so as to make its verifier complexity match ours (other than by replacing it entirely with ring-switching).</p>

    <p class="text-gray-300">Our protocols' provers tell a similar story. To calculate  <span class="math">(\\hat{s}_v)_{v \\in \\mathcal{B}_\\kappa}</span> , both provers must begin by tensor-expanding  <span class="math">(r_\\kappa, \\dots, r_{\\ell-1})</span> , which takes  <span class="math">2^{\\ell&#x27;}</span>  L-by-L multiplications, and then performing  <span class="math">2^{\\ell}</span>  L-by-K multiplications and just under  <span class="math">2^{\\ell}</span>  L-additions. To prepare the sumcheck (12), our prover must further basis-decompose this tensor, and row-combine the resulting  <span class="math">2^{\\kappa} \\times 2^{\\ell&#x27;}</span>  K-matrix by the L-vector  <span class="math">(\\widetilde{\\text{eq}}(u, r&#x27;&#x27;))_{u \\in \\mathcal{B}_\\kappa}</span> . We thus further obtain again  <span class="math">2^{\\ell}</span>  L-by-K multiplications and just under  <span class="math">2^{\\ell}</span>  L-additions. To prepare the analogous sumcheck (21), Hashcaster's prover must do something more complex. It must first obtain the respective tensor-expansions of each of the elements of the Galois orbit  <span class="math">(\\sigma^{\\{v\\}}(r_\\kappa), \\dots, \\sigma^{\\{v\\}}(r_{\\ell-1}))_{v \\in \\mathcal{B}_\\kappa}</span> . This task entails  <span class="math">2^{\\ell&#x27;}</span>  L-by-L multiplications and  <span class="math">2^{\\ell}</span>  Frobenius applications. Finally, it must multiply the row-combination vector  <span class="math">(\\widetilde{\\text{eq}}(u, r&#x27;&#x27;))_{u \\in \\mathcal{B}_\\kappa}</span>  by the  <span class="math">2^{\\kappa} \\times 2^{\\ell&#x27;}</span>  L-matrix it obtains in this way, thereby expending  <span class="math">2^{\\ell}</span>  L-by-L multiplications. Hashcaster's prover, if implemented naively, is thus about  <span class="math">2^{\\kappa}</span> -fold more costly than ours.</p>

    <p class="text-gray-300">On the other hand, Hashcaster develops various concrete optimizations, which serve to make its prover more efficient. These all have the same flavor, however; to explain it, we need to develop a bit more theory. For each Galois extension L/K, the L-algebras</p>

    <p class="text-gray-300">
<span class="math">$L \\otimes_K L \\cong \\prod_{\\rho \\in Gal(L/K)} L \\tag{22}</span>$</p>

    <p class="text-gray-300">are isomorphic. This fact is classical and important in arithmetic geometry (see e.g. Waterhouse [Wat79]). We record a proof here, valid in case both K and L are finite. The left-hand ring is exactly our &quot;tensor algebra&quot;. We understand that ring as an L-algebra by letting L act on the right-hand tensor factor; that is, we define  <span class="math">\\alpha \\cdot (a_0 \\otimes a_1) := (a_0 \\otimes (\\alpha \\cdot a_1))</span>  on simple tensors (we refer to Subsection 2.5 below for more details on the tensor algebra). We understand the right-hand ring as an L-algebra via the standard componentwise action. As for the actual isomorphism, we map simple tensors in the following way:</p>

    <p class="text-gray-300">
<span class="math">$(a_0 \\otimes a_1) \\mapsto \\left(\\sigma^0(a_0) \\cdot a_1, \\dots, \\sigma^{2^{\\kappa} - 1}(a_0) \\cdot a_1\\right). \\tag{23}</span>$</p>

    <p class="text-gray-300">To describe this isomorphism in coordinates, we must pick bases for both algebras in (22). In the left-hand ring, we pick the L-basis  <span class="math">(\\beta_u \\otimes 1)_{u \\in \\mathcal{B}_{\\kappa}}</span> ; as for the right, we use the standard basis.</p>

    <p class="text-gray-300">It's not hard to show that the matrix of the map (23)&mdash;once expressed in coordinates with respect to these bases (and under the multiply-on-the-right convention)&mdash;is nothing other than the matrix</p>

    <p class="text-gray-300">
<span class="math">$\\sigma^{\\{v\\}}(\\beta_u) \\tag{24}</span>$</p>

    <p class="text-gray-300">of (17); that is, the isomorphism (22) and the transformation (17) are one and the same map. Of course, since we already know that (24) is nonsingular (see again [LN96, Lem. 3.51]), (22) is sure enough an isomorphism.</p>

    <p class="text-gray-300">Hashcaster turns out to be a parallel instantiation of ring-switching that takes place on the right-hand ring of (22), as opposed to on the left. (Hashcaster's various &quot;optimizations&quot; serve to move certain among its steps to the left.) In this dictionary, (11) and (20) correspond, (12) and (21) correspond, and finally the final evaluations  <span class="math">(A_u(r&#x27;_0, \\ldots, r&#x27;_{\\ell&#x27;-1}))_{u \\in \\mathcal{B}_{\\kappa}}</span>  and  <span class="math">(\\widetilde{eq}(\\sigma^{\\{v\\}}(r_{\\kappa}), \\ldots, \\sigma^{\\{v\\}}(r_{\\ell-1}), r&#x27;_0, \\ldots, r&#x27;_{\\ell&#x27;-1}))_{v \\in \\mathcal{B}_{\\kappa}}</span>  correspond. These &quot;correspondences&quot; are not merely suggestive, but are rather entirely rigorous! In each, the relevant quantities differ exactly by the isomorphism (22). On the other hand, the check (15) (see also (3)) can only be performed in the left-hand side of (22). That isomorphism's left-hand side is thus the most natural side within which to remain throughout. By failing to stay there, Hashcaster imposes upon its prover and verifier the costs&mdash;which are ultimately artificial&mdash;of traversing the isomorphism (22). The hard part, of course, is to find out an analogue on the left-hand side of (22) of the verifier's final check, and to remain on the left for good. This is what we've done by surfacing the tensor algebra, and by developing the theory of this work.</p>

      <h3 id="sec-1.4" class="text-xl font-semibold mt-8">1.4 Binary BaseFold</h3>

    <p class="text-gray-300">In order to apply ring-switching, we need a large-field scheme to invoke it on. To this end, we adapt BaseFold PCS [ZCF24, &sect; 5] to the characteristic 2 setting. To achieve this, we must re-examine the classic <em>additive NTT</em> of Lin, Chung and Han [LCH14]. We show that that NTT fits into a framework articulated by Hab&ouml;ck, Levit and Papini [HLP24], though it predates that latter work.</p>

    <p class="text-gray-300">It is essentially folklore&mdash;see e.g. Hab&ouml;ck, Levit and Papini [HLP24, &sect; 4.1], Li and Xing [LX24], and Hab&ouml;ck [Hab24]&mdash;that from <em>any</em> sequence of two-to-one collapsing maps, &quot;an&quot; FFT arises. The resulting FFTs are ad-hoc, &quot;exotic&quot; FFTs; a new one arises <em>for each</em> system of collapsing maps. (See Hab&ouml;ck, Levit and Papini [HLP24, &sect; 1], who write &quot;this polynomial basis is not the standard monomial one, and there is no known efficient conversion between the two.&quot;)</p>

    <p class="text-gray-300">FRI's original, binary rendition [BBHR18a, &sect; 3.2] consumes&mdash;as a global parameter&mdash;just such a decreasing chain of  <span class="math">\\mathbb{F}_2</span> -linear subspaces. It stands to reason that, by using some arbitrary sequence of collapsing maps together with its associated exotic FFT, one might make something like binary BaseFold work.</p>

    <p class="text-gray-300">It is much more interesting that one need not turn to nonstandard FFTs in order to make binary BaseFold work. In fact, a perfectly suitable one is sitting under our proverbial noses: Lin, Chung and Han's additive NTT [LCH14]. (Though it's not essential for us, their NTT's basis-conversion problem is very well-studied; Lin, Al-Naffouri and Han [LAH16] report an  <span class="math">O(n \\cdot \\log n \\cdot \\log \\log n)</span> -time algorithm for the task, reproduced also in Li et al. [Li+18, &sect; 2.5].) Importantly, Lin, Chung and Han's NTT [LCH14, &sect; III.] is not expressed&mdash;as written&mdash;as that which results from an explicit system of collapsing maps. We show below that it can be made to arise in that way. The collapsing maps we devise, then, are those that we use in our binary FRI specialization, and also in our binary adaptation of BaseFold PCS. Our choice lets us use Lin, Chung and Han's additive NTT&mdash;by far the most standard option&mdash;in our BaseFold adaptation, as opposed to an &quot;exotic&quot; FFT.</p>

    <p class="text-gray-300"><strong>The problem.</strong> BaseFold PCS identifies a new collection between FRI and <em>multilinear evaluation</em>. To explain this connection, we go &quot;back to the basics&quot;. We explain, by example, the phenomenon that BaseFold PCS identifies. We also explain what &quot;goes wrong&quot; if one tries to make things work in characteristic 2 without setting things up right.</p>

    <p class="text-gray-300">Each honest FRI prover begins with the evaluation of some polynomial  <span class="math">P(X) := \\sum_{j=0}^{2^{\\ell}-1} a_j \\cdot X^j</span>  over its initial domain  <span class="math">S^{(0)}</span> . During the course of the protocol, the prover repeatedly &quot;folds&quot; its initial word. In FRI's simplest configurations, the prover's <em>last</em> oracle will be identically constant. In fact, the prover will send the verifier this latter constant in the clear, at the very end of its &quot;commit phase&quot;. What will the <em>value</em> of this constant be, as a function of P(X) and of the verifier's folding challenges?</p>

    <p class="text-gray-300">The answer to this question depends on which &quot;collapsing maps&quot; we choose to use in FRI. In the smooth, prime-field case, there is a canonical choice: we let  <span class="math">S^{(0)}</span>  be a large, power-of-2-order multiplicative subgroup of our field. For our collapsing maps, we repeatedly apply the squaring map  <span class="math">X \\mapsto X^2</span> .</p>

    <p class="text-gray-300">In the characteristic 2 setting, this choice isn't available. (The squaring map is actually an automorphism, the <em>Frobenius</em>.) We must instead let our domains  <span class="math">S^{(i)} \\subset L</span> , for  <span class="math">i \\in \\{0, \\ldots, \\ell\\}</span> , be  <span class="math">\\mathbb{F}_2</span> -linear subspaces of our large binary field L. Our two-to-one collapsing maps  <span class="math">q^{(i)}: S^{(i)} \\to S^{(i+1)}</span>  must be  <span class="math">\\mathbb{F}_2</span> -linear maps.</p>

    <p class="text-gray-300">As we show now, if we choose these maps <em>abitrarily</em>, then BaseFold's key observation doesn't go through. The point is that the initial Reed&ndash;Solomon encoding and the subsequent collapsing maps must &quot;correspond&quot;.</p>

    <p class="text-gray-300">For the sake of our illustration, we work in a toy-sized, 8-bit field: the AES field. That is, we work in the field</p>

    <p class="text-gray-300"><span class="math">$\\mathbb{F}_2[X] / (x^8 + x^4 + x^3 + x + 1) \\cong \\mathbb{F}_{2^8}.</span>$</p>

    <p class="text-gray-300">This field's elements correspond in a one-to-one way with bytes. We set  <span class="math">\\ell=2</span>  and  <span class="math">\\mathcal{R}=1</span> . We fix the 2-variate input multilinear</p>

    <p class="text-gray-300"><span class="math">$t(X_0,X_1) \\coloneqq \\mathtt{Oxde} \\cdot 1 + \\mathtt{Oxad} \\cdot X_0 + \\mathtt{Oxbe} \\cdot X_1 + \\mathtt{Oxef} \\cdot X_0 \\cdot X_1.</span>$</p>

    <p class="text-gray-300">We finally fix the evaluation point</p>

    <p class="text-gray-300"><span class="math">$(r_0, r_1) \\coloneqq (0xab, 0xcd).</span>$</p>

    <p class="text-gray-300">We note that</p>

    <p class="text-gray-300">
<span class="math">$t(r_0, r_1) = 0x89. (25)</span>$</p>

    <p class="text-gray-300">In order to set up FRI, we need a Reed&ndash;Solomon domain S (0) &sub; L of dimension &#8467;+ R = 3, together with a system of collapsing maps.</p>

    <p class="text-gray-300">    <img src="_page_11_Figure_1.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Figure 5: A possible system of domains and collapsing maps in the AES field.</p>

    <p class="text-gray-300">In Figure <a href="#page-11-0">5,</a> we sketch a plausible choice for these maps in the 8-bit AES field. We initialize S (0) := &#10216;0x01, 0x02, 0x04&#10217;. For our first collapsing map q (0) : S (0) &rarr; S (1), we use X 7&rarr; X2+X; this map annihilates the one-dimensional subspace of S (0) generated by 0x01. For our next map, we annihilate the image in S (1) (namely 0x06) of the next basis vector of S (0) (namely 0x02).</p>

    <p class="text-gray-300">Figure <a href="#page-11-0">5'</a>s parameterization, while coherent&mdash;and perfectly suitable for FRI&mdash;fails to work for binary BaseFold. To show why, we give the thing a try. As prescribed by BaseFold PCS, we begin by &quot;flattening&quot; the input multilinear t(X0, X1) into a univariate polynomial of degree less than 2<sup>&#8467;</sup> . In this way, we obtain</p>

    <p class="text-gray-300"><span class="math">$P(X) = \\mathtt{Oxde} \\cdot 1 + \\mathtt{Oxad} \\cdot X + \\mathtt{Oxbe} \\cdot X^2 + \\mathtt{Oxef} \\cdot X^3.</span>$</p>

    <p class="text-gray-300">We next Reed&ndash;Solomon-encode&mdash;that is, we evaluate&mdash;P(X) on the domain S (0); finally, we FRI-fold the resulting codeword using the challenges r<sup>0</sup> = 0xab and r<sup>1</sup> = 0xcd. This process appears in Figure <a href="#page-11-1">6</a> below.</p>

    <p class="text-gray-300">    <img src="_page_11_Figure_7.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Figure 6: If we don't choose our domains carefully, then FRI-folding fails to capture multilinear evaluation.</p>

    <p class="text-gray-300">The final FRI oracle in Figure <a href="#page-11-1">6</a> is constant, as is liable to hold generically in FRI. On the other hand, its value is wrong. We already agreed in <a href="#page-10-1">(25)</a> that t(r0, r1) = 0x89; on the other hand, we obtained 0x36 above. BaseFold depends crucially on these values' being equal.</p>

    <p class="text-gray-300">Our solution. In Figure <a href="#page-12-0">7,</a> we reveal our domains S (0) , S (1) and S (2) and folding maps q (0) and q (1) .</p>

    <p class="text-gray-300">    <img src="_page_12_Figure_1.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Figure 7: A further binary FRI configuration, this time BaseFold-compatible.</p>

    <p class="text-gray-300">The choice procedure underlying Figure <a href="#page-12-0">7</a> is given rigorously in Subsection <a href="#page-32-0">4.1</a> below (see Definition <a href="#page-32-1">4.1)</a>. Actually, the method is not hard to describe. At each stage i, we begin with the simple map q (i) : X 7&rarr; X2+X, which annihilates the subspace of S (i) generated by 1. Then, however, we &quot;twist&quot; the map q (i) , so as to make the first element of its image 1. This choice guarantees to boot that 1 will be in S (i+1) = q (i) S (i) , so that the initial choice q (i+1) : X 7&rarr; X<sup>2</sup> + X makes sense (that map too, though, will need to be twisted).</p>

    <p class="text-gray-300">This process can be seen in Figure <a href="#page-12-0">7</a> above. Under the map X 7&rarr; X<sup>2</sup> + X, 0x02 maps to 0x06, whose inverse is the scaling factor 0x7b. Similarly, under X 7&rarr; X<sup>2</sup> + X, 0x06 maps to 0x12, whose inverse is 0xaa.</p>

    <p class="text-gray-300">The point of our theory is that, if we choose our collapsing maps in the right way&mdash;that is, as Figure <a href="#page-12-0">7</a> does&mdash;then we recover multilinear evaluation after all. Crucially, we must also replace our initial Reed&ndash; Solomon encoding with Lin&ndash;Chung&ndash;Han's variant. We depict this &quot;happy path&quot; in Figure <a href="#page-12-1">8.</a></p>

    <p class="text-gray-300">    <img src="_page_12_Figure_6.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Figure 8: Upon parameterizing FRI carefully, we recover that protocol's built-in multilinear evaluator.</p>

    <p class="text-gray-300">In Section <a href="#page-30-0">4</a> below, we prove that our collapsing maps work out this way, in general. To carry out that proof, we must study Lin, Chung and Han's additive NTT in some detail (the key result is Theorem <a href="#page-36-0">4.13)</a>. In fact, we further enrich our binary BaseFold variant in various interesting ways. For example, using an &quot;oracle-skipping&quot; optimization&mdash;which itself exploits a recent tensor-style proximity gap, due to Diamond and Gruen <a href="#page-48-6">[DG25]</a>&mdash;we shrink that scheme's proofs by over half. We explain these ideas in full in Section <a href="#page-30-0">4.</a></p>

      <h3 id="sec-1.5" class="text-xl font-semibold mt-8">1.5 Concurrent and Subsequent Works</h3>

    <p class="text-gray-300">In this subsection, we discuss Brehm et al.'s Blaze <a href="#page-47-2">[Bre+25]</a>.</p>

    <p class="text-gray-300">Blaze. Blaze <a href="#page-47-2">[Bre+25]</a> is a polynomial commitment scheme for multilinears large large binary fields.</p>

    <p class="text-gray-300">We fix an &#8467;-variate multilinear t(X0, . . . , X&#8467;&minus;1) over a large binary field L. Using a technique grounded in code-switching <a href="#page-49-4">[RR24]</a>, Blaze obtains a strictly linear-time commitment procedure, a linear-time prover, and a polylogarithmic verifier; we sketch its approach. Blaze begins as Brakedown does, except with a wide matrix&mdash;shaped something like 2<sup>a</sup> &times; 2 &#8467;&minus;a , where the matrix height 2<sup>a</sup> is just polynomial in &#8467;. That is, Blaze inscribes t(X0, . . . , X&#8467;&minus;1)'s Lagrange coefficients, in row-major order, into that wide matrix. Its prover encodes that matrix row-wise under a RAA (repeat, accumulate accumulate) code&mdash;or under a &quot;packed&quot; variant of that code&mdash;and commits to the resulting matrix, which we presently call M.</p>

    <p class="text-gray-300">Beginning as Brakedown <a href="#page-48-3">[Gol+23]</a> does, Blaze reduces the problem of evaluating t(X0, . . . , X&#8467;&minus;1) at some point (z0, . . . , z&#8467;&minus;1) to that of evaluating the message underneath r &middot; M&mdash;whatever it may be&mdash;at the suffix (za, . . . , z&#8467;&minus;1); here, r is a length-2<sup>a</sup> random vector sampled by the verifier.</p>

    <p class="text-gray-300">As of this point, Blaze has shrunk its problem size by a polylogarithmic factor, and so can freely begin using &quot;heavier&quot;&mdash;i.e., quasilinear-time&mdash;techniques. The overhead to the verifier of this reduction is proportional to 2<sup>a</sup> , which is just polylogarithmic in 2<sup>&#8467;</sup> . (This is code-switching in action.) Blaze, indeed, must now securely evaluate a multilinear whose coefficients are themselves encoded underneath the RAA code. To this end, it introduces a further protocol, which is based on BaseFold (and in fact on this work's binary variant). That is, it commits using binary BaseFold to the claimed RAA codeword r T &middot; M, to the message supposedly underneath that codeword, and finally to all of the intermediate RAA encoding steps which intervene between those two quantities. It then uses sumcheck-based techniques, as well as the native evaluation procedure of BaseFold PCS, to check the validity of the RAA encoding and evaluate the committed message.</p>

    <p class="text-gray-300">The Blaze PCS is functionally an alternative to the large-field, binary BaseFold PCS construction we present in Section <a href="#page-30-0">4.</a> Operating over F<sup>2</sup> <sup>128</sup> throughout, Blaze <a href="#page-47-2">[Bre+25,</a> &sect; 8] reports commitment and proving times that improve upon binary BaseFold's by roughly threefold at the &#8467; = 28 problem size, though its proofs are larger. The key point is that though Blaze's RAA code is very fast to encode, its relative distance is middling (e.g., just 0.19 at the rate &rho; = 1 4 ). Blaze reports a proof of 2.5 MiB in the &#8467; = 28 case, compared with 1.4 MiB for their binary BaseFold benchmark. In this work, we develop a binary BaseFold variant that further reduces proof sizes, using the nontrivial enhancement whereby we skip FRI round oracles (see Section <a href="#page-30-0">4)</a>. Incorporating our oracle-skipping technique, as well as various further concrete proof size optimizations (described in Subsection <a href="#page-45-0">5.2)</a>, we obtain a proof size of 0.436 MiB in the &#8467; = 28 case. Our enhancements could be used to improve Blaze's proof sizes too.</p>

    <p class="text-gray-300">Blaze's RAA code depends on a randomized, transparent setup, which involves an expensive verification procedure, itself necessary to bound that setup's probability of failure. That test must be independently rerun by each of the protocol's users; it requires more than a day of computation on a laptop <a href="#page-47-2">[Bre+25,</a> &sect; 1.1]. The outcome of that test could, in theory, be attested to by a further SNARK, or else checked more quickly with the aid of a GPU-accelerated implementation. Blaze's RAA setup procedure must be carried out independently for each instance size and each code rate.</p>

    <p class="text-gray-300">Blaze's failure analysis assumes that its sampler's coins are uniform. In order to make that analysis applicable in practice, Blaze's sampler must use public, nothing-up-my-sleeve randomness. The security guarantees of Blaze&mdash;i.e., of each of that protocol's deployments&mdash;demand that its sampler do exactly this, and cease to hold otherwise.</p>

    <p class="text-gray-300">While Blaze supports only cryptographically large fields, its authors note that Blaze PCS is compatible with this work's ring-switching compiler. Upon instantiating our ring-switching reduction on Blaze's largefield PCS&mdash;i.e., as opposed to on our binary BaseFold variant&mdash;one would obtain an interesting small-field scheme, an alternative to that which we present in Section <a href="#page-43-0">5.</a></p>

    <p class="text-gray-300">Acknowledgements. We would like to acknowledge our colleagues at Irreducible for their insights and contributions to the Binius implementation of these techniques. We would like to gratefully thank Benedikt B&uml;unz, Giacomo Fenzi, Angus Gruen, Ulrich Hab&uml;ock, Joseph Johnston, Raju Krishnamoorthy, Eugene Rabinovich, Justin Thaler and Benjamin Wilson, whose collective comments and suggestions contributed significantly to this work. We thank Ron Rothblum for patiently explaining code-switching to us.</p>

    </section>

    <section id="sec-2" class="mb-10">
      <h2 class="text-2xl font-bold">2 Background and Notation</h2>

    <p class="text-gray-300">We write  <span class="math">\\mathbb N</span>  for the nonnegative integers. All fields in this work are finite. We fix a binary field L. For each  <span class="math">\\ell \\in \\mathbb N</span> , we write  <span class="math">\\mathcal B_\\ell</span>  for the  <span class="math">\\ell</span> -dimensional boolean hypercube  <span class="math">\\{0,1\\}^\\ell \\subset L^\\ell</span> . We occasionally identify  <span class="math">\\mathcal B_\\ell</span>  with the integer range  <span class="math">\\{0,\\dots 2^\\ell-1\\}</span>  by mapping  <span class="math">v\\mapsto \\{v\\}\\coloneqq \\sum_{i=0}^{\\ell-1} 2^i\\cdot v_i</span> . The rings we treat are nonzero and commutative with unit. For us, an algebra A over a field L is a commutative ring A together with an embedding of rings  <span class="math">L\\hookrightarrow A</span> . For L a field and  <span class="math">R\\subset L^\\vartheta</span>  a subset, we write  <span class="math">\\mu(R)\\coloneqq \\frac{|R|}{|L|^\\vartheta}</span> .</p>

      <h3 id="sec-2.1" class="text-xl font-semibold mt-8">2.1 Multilinear Polynomials</h3>

    <p class="text-gray-300">We review various normal forms for multilinear polynomials, following [DP25, &sect; 2.1]. An  <span class="math">\\ell</span> -variate polynomial in  <span class="math">L[X_0,\\ldots,X_{\\ell-1}]</span>  is multilinear if each of its indeterminates appears with individual degree at most 1; we write  <span class="math">L[X_0,\\ldots,X_{\\ell-1}]^{\\leq 1}</span>  for the set of multilinear polynomials over L in  <span class="math">\\ell</span>  indeterminates. Clearly, the set of monomials  <span class="math">(1,X_0,X_1,X_0\\cdot X_1,\\ldots,X_0\\cdot \\cdots \\cdot X_{\\ell-1})</span>  yields a L-basis for  <span class="math">L[X_0,\\ldots,X_{\\ell-1}]^{\\leq 1}</span> ; we call this basis the multilinear monomial basis in  <span class="math">\\ell</span>  variables.</p>

    <p class="text-gray-300">We introduce the  <span class="math">2 \\cdot \\ell</span> -variate polynomial</p>

    <p class="text-gray-300"><span class="math">$\\widetilde{\\operatorname{eq}}(X_0,\\dots,X_{\\ell-1},Y_0,\\dots,Y_{\\ell-1})\\coloneqq \\prod_{i=0}^{\\ell-1}(1-X_i)\\cdot (1-Y_i) + X_i\\cdot Y_i.</span>$</p>

    <p class="text-gray-300">It is essentially the content of Thaler [Tha22, Fact. 3.5]) that the set  <span class="math">(\\widetilde{eq}(X_0, \\dots, X_{\\ell-1}, w_0, \\dots, w_{\\ell-1}))_{w \\in \\mathcal{B}_{\\ell}}</span>  yields a further L-basis of the space  <span class="math">L[X_0, \\dots, X_{\\ell-1}]^{\\leq 1}</span> .</p>

    <p class="text-gray-300">For each fixed  <span class="math">(r_0, \\ldots, r_{\\ell-1}) \\in L^{\\ell}</span> , the vector  <span class="math">(\\widetilde{eq}(r_0, \\ldots, r_{\\ell-1}, w_0, \\ldots, w_{\\ell-1}))_{w \\in \\mathcal{B}_{\\ell}}</span>  takes the form</p>

    <p class="text-gray-300"><span class="math">$\\left(\\prod_{i=0}^{\\ell-1} r_i \\cdot w_i + (1-r_i) \\cdot (1-w_i)\\right)_{w \\in \\mathcal{B}_{\\ell}} = ((1-r_0) \\cdot \\dots \\cdot (1-r_{\\ell-1}), \\dots, r_0 \\cdot \\dots \\cdot r_{\\ell-1}).</span>$</p>

    <p class="text-gray-300">We call this vector the tensor product expansion of  <span class="math">(r_0, \\ldots, r_{\\ell-1}) \\in L^{\\ell}</span> , and denote it by  <span class="math">\\bigotimes_{i=0}^{\\ell-1} (1 - r_i, r_i)</span> . We note that it can be computed in  <span class="math">2^{\\ell}</span>  L-additions and  <span class="math">2^{\\ell}</span>  L-multiplications (see e.g. [Tha22, Lem. 3.8]). As a notational device, we introduce the further  <span class="math">2 \\cdot \\ell</span> -variate polynomial:</p>

    <p class="text-gray-300"><span class="math">$\\widetilde{\\mathrm{mon}}(X_0,\\ldots,X_{\\ell-1},Y_0,\\ldots,Y_{\\ell-1})\\coloneqq \\prod_{i=0}^{\\ell-1}1+(X_i-1)\\cdot Y_i;</span>$</p>

    <p class="text-gray-300">we note that  <span class="math">(\\widetilde{\\mathtt{mon}}(X_0,\\ldots,X_{\\ell-1},w_0,\\ldots,w_{\\ell-1}))_{w\\in\\mathcal{B}_\\ell}</span>  is the multilinear monomial basis in  <span class="math">\\ell</span>  indeterminates.</p>

      <h3 id="sec-2.2" class="text-xl font-semibold mt-8">2.2 Error-Correcting Codes</h3>

    <p class="text-gray-300">We recall details on codes, referring throughout to Guruswami [Gur06]. A code of block length n over the alphabet  <span class="math">\\Sigma</span>  is a subset of  <span class="math">\\Sigma^n</span> . In  <span class="math">\\Sigma^n</span> , we write d for the Hamming distance between two vectors (i.e., the number of components at which they differ). We fix a field L. A linear [n,k,d]-code over L is a k-dimensional linear subspace  <span class="math">C \\subset L^n</span>  for which  <span class="math">d(v_0,v_1) \\geq d</span>  holds for each unequal pair of elements  <span class="math">v_0</span>  and  <span class="math">v_1</span>  of C. The unique decoding radius of the [n,k,d]-code  <span class="math">C \\subset L^n</span>  is  <span class="math">\\left\\lfloor \\frac{d-1}{2} \\right\\rfloor</span> ; indeed, we note that, for each word  <span class="math">u \\in L^n</span> , at most one codeword  <span class="math">v \\in C</span>  satisfies  <span class="math">d(u,v) &lt; \\frac{d}{2}</span>  (this fact is a direct consequence of the triangle inequality). For  <span class="math">u \\in L^n</span>  arbitrary, we write  <span class="math">d(u,C) := \\min_{v \\in C} d(u,v)</span>  for the distance between u and the code C.</p>

    <p class="text-gray-300">For each linear code  <span class="math">C \\subset L^n</span>  and each integer  <span class="math">m \\geq 1</span> , we define C's m-fold interleaved code as the subset  <span class="math">C^m \\subset (L^n)^m \\cong (L^m)^n</span> . We understand this latter set as a length-n block code over the alphabet  <span class="math">L^m</span> . In particular, its elements are essentially matrices in  <span class="math">L^{m \\times n}</span>  each of whose rows is a C-element. We write matrices  <span class="math">(u_i)_{i=0}^{m-1} \\in L^{m \\times n}</span>  row-wise. By definition of  <span class="math">C^m</span> , two matrices in  <span class="math">L^{m \\times n}</span>  differ at a column if they differ at any of that column's components. That a matrix  <span class="math">(u_i)_{i=0}^{m-1} \\in L^{m \\times n}</span>  is within distance e to the code  <span class="math">C^m</span> &mdash;in which event we write  <span class="math">d^m \\left( (u_i)_{i=0}^{m-1}, C^m \\right) \\leq e</span> &mdash;thus entails precisely that there exists a subset  <span class="math">D := \\Delta^m \\left( (u_i)_{i=0}^{m-1}, C^m \\right)</span> , say, of  <span class="math">\\{0, \\dots, n-1\\}</span> , of size at most e, for which, for each  <span class="math">i \\in \\{0, \\dots, m-1\\}</span> , the row  <span class="math">u_i</span>  admits a codeword  <span class="math">v_i \\in C</span>  for which  <span class="math">u_i|_{\\{0,\\dots,n-1\\}\\setminus D} = v_i|_{\\{0,\\dots,n-1\\}\\setminus D}</span> .</p>

    <p class="text-gray-300">We recall Reed&ndash;Solomon codes (see [Gur06, Def. 2.3]). For notational convenience, we consider only Reed&ndash;Solomon codes whose message and block lengths are powers of two. We fix nonnegative message length and rate parameters  <span class="math">\\ell</span>  and  <span class="math">\\mathcal{R}</span> , as well as a subset  <span class="math">S \\subset L</span>  of size  <span class="math">2^{\\ell+\\mathcal{R}}</span> . We write  <span class="math">C \\subset L^{2^{\\ell+\\mathcal{R}}}</span>  for the Reed&ndash;Solomon code  <span class="math">\\mathsf{RS}_{L,S}[2^{\\ell+\\mathcal{R}},2^\\ell]</span> , defined to be the set  <span class="math">\\left\\{(P(x))_{x\\in S} \\middle| P(X) \\in L[X]^{\\prec 2^\\ell}\\right\\}</span> . That is,  <span class="math">\\mathsf{RS}_{L,S}[2^{\\ell+\\mathcal{R}},2^\\ell]</span>  is the set of  <span class="math">2^{\\ell+\\mathcal{R}}</span> -vectors that arise as the vector of respective values of a polynomial of degree less than  <span class="math">2^\\ell</span>  over S. The distance of  <span class="math">\\mathsf{RS}_{L,S}[2^{\\ell+\\mathcal{R}},2^\\ell]</span>  is  <span class="math">d=2^{\\ell+\\mathcal{R}}-2^\\ell+1</span> . We write  <span class="math">\\mathsf{Enc}:L[X]^{\\prec 2^\\ell}\\to L^S</span>  for the code's encoding function; it maps each polynomial P(X) to its tuple of evaluations over S.</p>

    <p class="text-gray-300">We recall the Berlekamp-Welch algorithm for Reed&ndash;Solomon decoding within the unique decoding radius (see [Gur06, Rem. 4]).</p>

    <h3 id="sec-misc-1" class="text-xl font-semibold mt-8">Algorithm 1 (Berlekamp-Welch [Gur06, Rem. 4].)</h3>

    <pre><code class="language-text">1: procedure Decodered Solomon (f(x))_{x \\in S}

2: allocate A(X) and B(X) of degrees \\lfloor \\frac{d-1}{2} \\rfloor and 2^{\\ell+\\mathcal{R}} - \\lfloor \\frac{d-1}{2} \\rfloor - 1; write Q(X,Y) \\coloneqq A(X) \\cdot Y + B(X).

3: interpret the equalities Q(x,f(x)) = 0, for x \\in S, as a system of 2^{\\ell+\\mathcal{R}} equations in 2^{\\ell+\\mathcal{R}} + 1 unknowns.
</code></pre>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>4: by finding a nonzero solution of this linear system, obtain values for the polynomials A(X) and B(X).</li>
      <li>5: <strong>if</strong>  <span class="math">A(X) \\nmid B(X)</span>  <strong>then return</strong>  <span class="math">\\perp</span> .</li>
      <li>6: write P(X) := -B(X)/A(X).</li>
      <li>7: if  <span class="math">deg(P(X)) \\ge 2^{\\ell}</span>  then return  <span class="math">\\perp</span> .</li>
      <li>8: return P(X).</li>
    </ul>

    <p class="text-gray-300">We note that the unknown polynomial Q(X,Y) above indeed has  <span class="math">\\left\\lfloor \\frac{d-1}{2} \\right\\rfloor + 1 + 2^{\\ell+\\mathcal{R}} - \\left\\lfloor \\frac{d-1}{2} \\right\\rfloor = 2^{\\ell+\\mathcal{R}} + 1</span>  coefficients, as required.</p>

    <p class="text-gray-300">On input a word  <span class="math">f: S \\to L</span>  for which  <span class="math">d(f,C) &lt; \\frac{d}{2}</span> , Algorithm 1 necessarily returns the unique polynomial P(X) of degree less than  <span class="math">2^{\\ell}</span>  for which  <span class="math">d(f,\\operatorname{Enc}(P(X))) &lt; \\frac{d}{2}</span>  holds. Indeed, this is just the correctness of Berlekamp&ndash;Welch algorithm on input assumed to reside within the unique decoding radius (we refer to [Gur06, Rem. 4] for a thorough treatment of this result).</p>

    <p class="text-gray-300">Interestingly, our above variant of this classical algorithm&mdash;the supplementary degree check 7 is atypical&mdash;serves moreover to <em>detect</em> whether its input is in the unique decoding radius. We prove this fact below.</p>

    <p class="text-gray-300"><strong>Lemma 2.1.</strong> If  <span class="math">d(f,C) \\geq \\frac{d}{2}</span> , then Algorithm 1 outputs  <span class="math">\\perp</span> .</p>

    <p class="text-gray-300">Proof. We fix a map  <span class="math">f: S \\to L</span>  for which  <span class="math">d(f,C) \\geq \\frac{d}{2}</span> ; we suppose for contradiction that Algorithm 1, on the input f, nonetheless successfully outputs a polynomial P(X) (necessarily of degree less than  <span class="math">2^{\\ell}</span> ). We first note that the relation P(X) = -B(X)/A(X) implies the factorization  <span class="math">Q(X,Y) = A(X) \\cdot (Y-P(X))</span> . Separately, since  <span class="math">\\deg(P(X)) &lt; 2^{\\ell}</span> ,  <span class="math">\\operatorname{Enc}(P(X))</span>  is a codeword; our hypothesis on f thus implies that  <span class="math">d(f,\\operatorname{Enc}(P(X))) \\geq \\frac{d}{2}</span> . On the other hand, by its degree, A(X) can have at most  <span class="math">\\left\\lfloor \\frac{d-1}{2} \\right\\rfloor &lt; \\frac{d}{2}</span>  roots. We conclude that there necessarily exists some element  <span class="math">x^* \\in S</span>  for which  <span class="math">P(x^*) \\neq f(x^*)</span>  and  <span class="math">A(x^*) \\neq 0</span>  simultaneously hold. Finally, by its construction, Q(x,f(x))=0 necessarily holds for each  <span class="math">x \\in S</span> . Putting these facts together, we see that  <span class="math">0=Q(x^*,f(x^*))=A(x^*)\\cdot (f(x^*)-P(x^*))\\neq 0</span> , a contradiction.</p>

      <h3 id="sec-2.3" class="text-xl font-semibold mt-8">2.3 The Novel Polynomial Basis</h3>

    <p class="text-gray-300">We recall in detail the <em>novel polynomial basis</em> of Lin, Chung and Han [LCH14, &sect; II. C.]. We fix again a binary field L, of degree r, say, over  <span class="math">\\mathbb{F}_2</span> . For our purposes, a <em>subspace polynomial</em> over L is a polynomial  <span class="math">W(X) \\in L[X]</span>  which splits completely over L, and whose roots, each of multiplicity 1, form an  <span class="math">\\mathbb{F}_2</span> -linear subspace of L. For a detailed treatment of subspace polynomials, we refer to Lidl and Niederreiter [LN96, Ch. 3. &sect; 4.]. For each subspace polynomial  <span class="math">W(X) \\in L[X]</span> , the evaluation map  <span class="math">W: L \\to L</span>  is  <span class="math">\\mathbb{F}_2</span> -linear.</p>

    <p class="text-gray-300">For each fixed  <span class="math">\\ell \\in \\{0, \\dots, r-1\\}</span> , the set  <span class="math">L[X]^{\\prec 2^{\\ell}}</span>  of polynomials of degree less than  <span class="math">2^{\\ell}</span>  is a  <span class="math">2^{\\ell}</span> -dimensional vector space over L. Of course, the set  <span class="math">(1, X, X^2, \\dots, X^{2^{\\ell}-1})</span>  yields a natural L-basis of  <span class="math">L[X]^{\\prec 2^{\\ell}}</span> . Lin, Chung and Han define a further L-basis of  <span class="math">L[X]^{\\prec 2^{\\ell}}</span> &mdash;called the <em>novel polynomial basis</em>&mdash;in the following way. We fix once and for all an  <span class="math">\\mathbb{F}_2</span> -basis  <span class="math">(\\beta_0, \\dots, \\beta_{r-1})</span>  of L (which we view as an r-dimensional vector space over its subfield  <span class="math">\\mathbb{F}_2</span> ). For each  <span class="math">i \\in \\{0, \\dots, \\ell\\}</span> , we write  <span class="math">U_i := \\langle \\beta_0, \\dots, \\beta_{i-1} \\rangle</span>  for the  <span class="math">\\mathbb{F}_2</span> -linear span of</p>

    <p class="text-gray-300">the prefix  <span class="math">(\\beta_0,\\ldots,\\beta_{i-1})</span> , and define the subspace vanishing polynomial  <span class="math">W_i(X)\\coloneqq\\prod_{u\\in U_i}(X-u)</span> , as well as its normalized variant  <span class="math">\\widehat{W}_i(X)\\coloneqq\\frac{W_i(X)}{W_i(\\beta_i)}</span>  (we note that  <span class="math">\\beta_i\\not\\in U_i</span> , so that  <span class="math">W_i(\\beta_i)\\not=0</span> ). In words, for each  <span class="math">i\\in\\{0,\\ldots,\\ell\\}</span> ,  <span class="math">W_i(X)</span>  vanishes precisely on  <span class="math">U_i\\subset L</span> ;  <span class="math">\\widehat{W}_i(X)</span>  moreover satisfies  <span class="math">\\widehat{W}_i(X)(\\beta_i)=1</span> . Finally, for each  <span class="math">j\\in\\{0,\\ldots,2^\\ell-1\\}</span> , we write  <span class="math">(j_0,\\ldots,j_{\\ell-1})</span>  for the bits of j&mdash;so that  <span class="math">j=\\sum_{k=0}^{\\ell-1}2^k\\cdot j_k</span>  holds&mdash;and set  <span class="math">X_j(X)\\coloneqq\\prod_{i=0}^{\\ell-1}\\widehat{W}_i(X)^{j_i}</span> . We note that, for each  <span class="math">j\\in\\{0,\\ldots,2^\\ell-1\\}</span> ,  <span class="math">X_j(X)</span>  is of degree j. We conclude that the change-of-basis matrix from  <span class="math">(1,X,\\ldots,X^{2^\\ell-1})</span>  to  <span class="math">(X_0(X),X_1(X),\\ldots,X_{2^\\ell-1}(X))</span>  is triangular (with an everywhere-nonzero diagonal), so that this latter list indeed yields a L-basis of  <span class="math">L[X]^{\\prec 2^\\ell}</span> .</p>

    <p class="text-gray-300">We now fix moreover a rate parameter  <span class="math">\\mathcal{R} \\in \\{1, \\dots, r-\\ell\\}</span>  and a union  <span class="math">S \\subset L</span>  of  <span class="math">2^{\\mathcal{R}}</span>  distinct cosets of  <span class="math">U_{\\ell} = \\langle \\beta_0, \\dots, \\beta_{\\ell-1} \\rangle</span> . For example, we may take as  <span class="math">S \\subset L</span>  any affine translate of the  <span class="math">\\ell + \\mathcal{R}</span> -dimensional subspace  <span class="math">\\langle \\beta_0, \\dots, \\beta_{\\ell+\\mathcal{R}-1} \\rangle</span> . For each  <span class="math">S \\subset L</span>  of this form, Lin, Chung and Han [LCH14, &sect; III. B.]'s  <span class="math">O(2^{\\ell+\\mathcal{R}} \\cdot \\ell)</span> -time algorithm serves to compute, on input the polynomial  <span class="math">P(X) := \\sum_{j=0}^{2^{\\ell}-1} a_j \\cdot X_j(X)</span>  (expressed in coordinates with respect to the novel polynomial basis), its encoding  <span class="math">(P(x))_{x \\in S}</span> . In fact, that algorithm takes exactly  <span class="math">2^{\\ell+\\mathcal{R}} \\cdot \\ell</span>  L-additions and  <span class="math">2^{\\ell+\\mathcal{R}-1} \\cdot \\ell</span>  L-multiplications [LCH14, &sect; III. D.].</p>

    <p class="text-gray-300">In Remark 4.15 below, we suggest a new interpretation of Lin, Chung and Han's algorithm [LCH14, &sect; III.] based on the techniques of this paper. For now, for self-containedness, we record here the key algorithm in full, in our notation. We note that Algorithm 2's equivalence with [LCH14, &sect; III.] is not obvious; we explain the correctness of our description in Remark 4.15 below. In what follows, we fix as above the degree and rate parameters  <span class="math">\\ell</span>  and  <span class="math">\\mathcal{R}</span> . We finally fix a polynomial  <span class="math">P(X) = \\sum_{j=0}^{2^{\\ell}-1} a_j \\cdot X_j(X)</span> ; we write  <span class="math">b: \\mathcal{B}_{\\ell+\\mathcal{R}} \\to L</span>  for  <span class="math">(a_j)_{j=0}^{2^{\\ell}-1}</span> 's  <span class="math">2^{\\mathcal{R}}</span> -fold tiling; in other words, for each  <span class="math">v \\in \\mathcal{B}_{\\ell+\\mathcal{R}}</span> , we set  <span class="math">b(v_0, \\ldots, v_{\\ell+\\mathcal{R}-1}) \\coloneqq a_{\\{(v_0, \\ldots, v_{\\ell-1})\\}}</span> .</p>

    <h3 id="sec-misc-2" class="text-xl font-semibold mt-8">Algorithm 2 (Lin-Chung-Han [LCH14, &sect; III.].)</h3>

    <pre><code class="language-text">1: procedure ADDITIVENTT (b(v))_{v \\in \\mathcal{B}_{\\ell+\\mathcal{R}}})

2: for i \\in \\{\\ell-1,\\ldots,0\\} (i.e., in downward order) do

3: for (u,v) \\in \\mathcal{B}_{\\ell+\\mathcal{R}-i-1} \\times \\mathcal{B}_i do

4: define the twiddle factor t := \\sum_{k=0}^{\\ell+\\mathcal{R}-i-2} u_k \\cdot \\widehat{W}_i(\\beta_{i+1+k}).

5: overwrite first b(u \\parallel 0 \\parallel v) += t \\cdot b(u \\parallel 1 \\parallel v) and then b(u \\parallel 1 \\parallel v) += b(u \\parallel 0 \\parallel v).

6: return (b(v))_{v \\in \\mathcal{B}_{\\ell+\\mathcal{R}}}.
</code></pre>

    <p class="text-gray-300">We note that the twiddle factor t above depends only on u, and not on v, and can be reused accordingly. Finally, in the final return statement above, we implicitly identify  <span class="math">\\mathcal{B}_{\\ell+\\mathcal{R}} \\cong S</span>  using the standard basis  <span class="math">\\beta_0, \\ldots, \\beta_{\\ell+\\mathcal{R}-1}</span>  of the latter space (see also Subsection 4.1 below).</p>

      <h3 id="sec-2.4" class="text-xl font-semibold mt-8">2.4 FRI</h3>

    <p class="text-gray-300">We recall Ben-Sasson, Bentov, Horesh and Riabzev's [BBHR18a] Fast Reed&ndash;Solomon Interactive Oracle Proof of Proximity (FRI). For L a binary field, and size and rate parameters  <span class="math">\\ell</span>  and  <span class="math">\\mathcal{R}</span>  fixed, FRI yields an IOP of proximity for the Reed&ndash;Solomon code  <span class="math">\\mathsf{RS}_{L,S}[2^{\\ell+\\mathcal{R}},2^\\ell]</span> ; here, we require that  <span class="math">S\\subset L</span>  be an affine,  <span class="math">\\mathbb{F}_2</span> -linear subspace (of dimension  <span class="math">\\ell+\\mathcal{R}</span> , of course). That is, FRI yields an IOP for the claim whereby some oracle [f]&mdash;i.e., representing a function  <span class="math">f:S\\to L</span> &mdash;is close to a codeword  <span class="math">(P(x))_{x\\in S}</span>  (here,  <span class="math">P(X)\\in L[X]^{\\prec 2^\\ell}</span>  represents a polynomial of degree less than  <span class="math">2^\\ell</span> ). FRI's verifier complexity is polylogarithmic in  <span class="math">2^\\ell</span> . We abbreviate  <span class="math">\\rho:=2^{-\\mathcal{R}}</span> , so that  <span class="math">\\mathsf{RS}_{L,S}[2^{\\ell+\\mathcal{R}},2^\\ell]</span>  is of rate  <span class="math">\\rho</span> .</p>

    <p class="text-gray-300">Internally, FRI makes use of a folding constant  <span class="math">\\eta</span> &mdash;which we fix to be 1&mdash;as well as a fixed, global sequence of subspaces and maps of the form:</p>

    <p class="text-gray-300"><span class="math">$S = S^{(0)} \\xrightarrow{q^{(0)}} S^{(1)} \\xrightarrow{q^{(1)}} S^{(2)} \\xrightarrow{q^{(2)}} \\cdots \\xrightarrow{q^{(\\ell-1)}} S^{(\\ell)}.</span>$
(26)</p>

    <p class="text-gray-300">For each  <span class="math">i \\in \\{0, ..., \\ell-1\\}</span> ,  <span class="math">q^{(i)}</span>  is a subspace polynomial of degree  <span class="math">2^{\\eta} = 2</span> , whose kernel, which is 1-dimensional, is contained in  <span class="math">S^{(i)}</span> . By linear-algebraic considerations,  <span class="math">S^{(i+1)}</span> 's  <span class="math">\\mathbb{F}_2</span> -dimension is 1 less than  <span class="math">S^{(i)}</span> 's is; inductively, we see that each  <span class="math">S^{(i)}</span>  is of dimension  <span class="math">\\ell + \\mathcal{R} - i</span> . In particular,  <span class="math">S^{(\\ell)}</span>  is of dimension  <span class="math">\\mathcal{R}</span> .</p>

      <h3 id="sec-2.5" class="text-xl font-semibold mt-8">2.5 Tensor Products of Fields</h3>

    <p class="text-gray-300">We record algebraic preliminaries, referring throughout to Lang [Lan02, Ch. XVI]. We fix a field extension L/K. We define the tensor product  <span class="math">A := L \\otimes_K L</span>  of L with itself over K as in [Lan02, Ch. XVI &sect; 6]. Here, we view L as a K-algebra; the resulting object  <span class="math">A := L \\otimes_K L</span>  is likewise a K-algebra. We would like to sincerely thank Benjamin Wilson for first suggesting to us this tensor-theoretic perspective on the tower algebra of [DP25, &sect; 3.4].</p>

    <p class="text-gray-300">We recall from [Lan02, Ch. XVI, &sect; 1] the natural K-bilinear mapping  <span class="math">\\varphi: L \\times L \\to L \\otimes_K L</span>  which sends  <span class="math">\\varphi: (\\alpha_0, \\alpha_1) \\mapsto \\alpha_0 \\otimes \\alpha_1</span> . We write  <span class="math">\\varphi_0</span>  and  <span class="math">\\varphi_1</span>  for  <span class="math">\\varphi</span> 's restrictions to the subsets  <span class="math">L \\times \\{1\\}</span>  and  <span class="math">\\{1\\} \\times L</span>  of  <span class="math">L \\times L</span> , and moreover identify these latter subsets with L. That is, we write  <span class="math">\\varphi_0: \\alpha \\mapsto \\alpha \\otimes 1</span>  and  <span class="math">\\varphi_1: \\alpha \\mapsto 1 \\otimes \\alpha</span> , both understood as maps  <span class="math">L \\to A</span> . We claim that these maps are injective (i.e., that they're not identically zero). We follow Lang [Lan02, Ch. XVI, &sect; 2, Prop. 2.3]. The mapping  <span class="math">f: L \\times L \\to L</span>  sending  <span class="math">f: (\\alpha_0, \\alpha_1) \\mapsto \\alpha_0 \\cdot \\alpha_1</span>  is K-bilinear; by the universal property of the tensor product, f induces a K-linear map  <span class="math">h: L \\otimes_K L \\to L</span> , for which, for each  <span class="math">\\alpha \\in L</span> ,  <span class="math">h(\\alpha \\otimes 1) = f(\\alpha, 1) = \\alpha \\cdot 1 = \\alpha</span>  holds; we see that  <span class="math">\\alpha \\otimes 1 = 0</span>  if and only if  <span class="math">\\alpha = 0</span> .</p>

    <p class="text-gray-300">We assume once and for all that  <span class="math">\\deg(L / K)</span>  is a power of 2, say  <span class="math">2^{\\kappa}</span> . We fix a K-basis  <span class="math">(\\beta_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  of L. We moreover impose the simplifying assumption whereby  <span class="math">\\beta_{(0,\\dots,0)} = 1</span> . By [Lan02, Ch. XVI, &sect; 2, Cor. 2.4], the set  <span class="math">(\\beta_u \\otimes \\beta_v)_{(u,v) \\in \\mathcal{B}_{\\kappa} \\times \\mathcal{B}_{\\kappa}}</span>  yields a K-basis of A. We thus see that each A-element is, concretely, a  <span class="math">2^{\\kappa} \\times 2^{\\kappa}</span>  array of K-elements. For each  <span class="math">a \\in A</span>  given, there is a unique  <span class="math">2^{\\kappa}</span> -tuple of L-elements  <span class="math">(a_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  for which  <span class="math">a = \\sum_{v \\in \\mathcal{B}_{\\kappa}} a_v \\otimes \\beta_v</span>  holds. (Indeed, this is just [Lan02, Ch. XVI, &sect; 2, Prop. 2.3].) Similarly, there is a unique  <span class="math">2^{\\kappa}</span> -tuple of L-elements  <span class="math">(a_u)_{u \\in \\mathcal{B}_{\\kappa}}</span>  for which  <span class="math">a = \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes a_u</span>  holds. We call the tuples  <span class="math">(a_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  and  <span class="math">(a_u)_{u \\in \\mathcal{B}_{\\kappa}}</span>  a's column and row representations, respectively. We depict the tensor algebra in Figure 9 below.</p>

    <p class="text-gray-300">    <img src="_page_17_Figure_4.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Figure 9: A schematic representation of our tensor algebra.</p>

    <p class="text-gray-300">The maps  <span class="math">\\varphi_0</span>  and  <span class="math">\\varphi_1</span>  respectively embed L into A's left-hand column and top row. That is, the image of  <span class="math">\\varphi_0: L \\hookrightarrow A</span>  is the set of K-arrays which are 0 except in their respective left-most columns; the image of  <span class="math">\\varphi_1: L \\hookrightarrow A</span>  is the set of K-arrays which are 0 outside of their top rows. We finally characterize concretely the products  <span class="math">\\varphi_0(\\alpha) \\cdot a</span>  and  <span class="math">\\varphi_1(\\alpha) \\cdot a</span> , for elements  <span class="math">\\alpha \\in L</span>  and  <span class="math">a \\in A</span>  arbitrary. It is a straightforward to show that  <span class="math">\\varphi_0(\\alpha) \\cdot a = \\sum_{v \\in \\mathcal{B}_\\kappa} (\\alpha \\cdot a_v) \\otimes \\beta_v</span>  and  <span class="math">\\varphi_1(\\alpha) \\cdot a = \\sum_{u \\in \\mathcal{B}_\\kappa} \\beta_u \\otimes (\\alpha \\cdot a_u)</span>  both hold; here, we again write  <span class="math">(a_v)_{v \\in \\mathcal{B}_\\kappa}</span>  and  <span class="math">(a_u)_{u \\in \\mathcal{B}_\\kappa}</span>  for a's column and row representations. That is,  <span class="math">\\varphi_0(\\alpha) \\cdot a</span>  differs from a by column-wise multiplication by  <span class="math">\\alpha</span> ;  <span class="math">\\varphi_1(\\alpha) \\cdot a</span>  differs from a by row-wise multiplication by  <span class="math">\\alpha</span> . In short,  <span class="math">\\varphi_0</span>  operates on columns;  <span class="math">\\varphi_1</span>  operates on rows.</p>

    <p class="text-gray-300">We now record a simple polynomial-packing operation, which is implicit in [DP25, &sect; 3.4]. The basis-combination procedure  <span class="math">(\\alpha_v)_{v \\in \\mathcal{B}_{\\kappa}} \\mapsto \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\alpha_v \\cdot \\beta_v</span>  induces a K-isomorphism  <span class="math">K^{2^{\\kappa}} \\to L</span> . By applying this map in chunks, we get a procedure that associates to each  <span class="math">\\ell</span> -variate K-multilinear an  <span class="math">\\ell - \\kappa</span> -variate L-multilinear.</p>

    <p class="text-gray-300"><strong>Definition 2.2.</strong> For each extension L/K, with K-basis  <span class="math">(\\beta_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  say, and each multilinear  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span>  over K, we write  <span class="math">\\ell&#x27; := \\ell - \\kappa</span> , and define the <em>packed polynomial</em></p>

    <p class="text-gray-300"><span class="math">$t&#x27;(X_0,\\ldots,X_{\\ell&#x27;-1})\\coloneqq \\sum_{v\\in\\mathcal{B}_\\kappa} t(v_0,\\ldots,v_{\\kappa-1},X_0,\\ldots,X_{\\ell&#x27;-1})\\cdot\\beta_v.</span>$</p>

    <p class="text-gray-300">The effect of Definition 2.2, in the Lagrange basis, is to replace each  <span class="math">2^{\\kappa}</span> -element chunk of  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span> 's Lagrange coefficient vector with a single L-element, by basis-combining that chunk.</p>

    <p class="text-gray-300">We emphasize that Definition 2.2's packing procedure is reversible (see also [DP25, Thm. 3.9]); that is,  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell&#x27;-1})</span>  can be &quot;unpacked&quot;. We note that Definition 2.2 is essentially the same as [DP25, &sect; 4.3].</p>

    <p class="text-gray-300">We finally write  <span class="math">\\varphi_1(t&#x27;)(X_0,\\ldots,X_{\\ell&#x27;-1}) \\in A[X_0,\\ldots,X_{\\ell&#x27;-1}]</span>  for the result of embedding  <span class="math">t&#x27;(X_0,\\ldots,X_{\\ell&#x27;-1})</span>  componentwise along the inclusion  <span class="math">\\varphi_1:L\\hookrightarrow A</span> .</p>

    <p class="text-gray-300">A conceptual predecessor of our tensor algebra A appears in Diamond and Posen [DP25, &sect; 3.4]. That work's &quot;tower algebra&quot;  <span class="math">A_{\\iota,\\kappa,\\tau}</span>  turns out to be isomorphic, as an algebra, to  <span class="math">\\mathcal{T}_{\\tau} \\otimes_{\\mathcal{T}_{\\iota}} \\mathcal{T}_{\\iota+\\kappa}</span> ; here,  <span class="math">\\mathcal{T}_{\\tau}</span> ,  <span class="math">\\mathcal{T}_{\\iota}</span> , and  <span class="math">\\mathcal{T}_{\\iota+\\kappa}</span>  are certain binary fields introduced in that work (&quot;tower fields&quot; of characteristic 2). That work's &quot;constant&quot; and &quot;synthetic&quot; embeddings correspond to our embeddings  <span class="math">\\varphi_0</span>  and  <span class="math">\\varphi_1</span> , respectively.</p>

      <h3 id="sec-2.6" class="text-xl font-semibold mt-8">2.6 Proximity Gaps</h3>

    <p class="text-gray-300">We turn to proximity gaps, following Ben-Sasson, et al., [Ben+23], Diamond and Posen [DP24], and Diamond and Gruen [DG25]. Throughout this subsection, we again fix a Reed&ndash;Solomon code  <span class="math">C := \\mathsf{RS}_{L,S}[2^{\\ell+\\mathcal{R}}, 2^\\ell]</span> ; we moreover write  <span class="math">d := 2^{\\ell+\\mathcal{R}} - 2^\\ell + 1</span>  for C's distance. In the following results, for notational convenience, we abbreviate  <span class="math">n := 2^{\\ell+\\mathcal{R}}</span>  for the Reed&ndash;Solomon code C's block length.</p>

    <p class="text-gray-300">We recall the notion of <em>proximity gaps</em>, both over affine lines [DG25, Def. 1] and over tensor combinations [DG25, Def. 2]. The following key result entails that Reed&ndash;Solomon codes exhibit proximity gaps for affine lines, for each proximity parameter  <span class="math">e \\in \\{0, \\dots, \\left\\lfloor \\frac{d-1}{2} \\right\\rfloor\\}</span>  within the unique decoding radius.</p>

    <p class="text-gray-300"><strong>Theorem 2.3</strong> (Ben-Sasson, et al. [Ben+23, Thm. 4.1]). For each proximity parameter  <span class="math">e \\in \\{0, \\ldots, \\lfloor \\frac{d-1}{2} \\rfloor\\}</span>  and each pair of words  <span class="math">u_0</span>  and  <span class="math">u_1</span>  in  <span class="math">L^{2^{\\ell+\\mathcal{R}}}</span> , if</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{r \\in L}[d((1-r) \\cdot u_0 + r \\cdot u_1, C) \\le e] &gt; \\frac{n}{|L|},</span>$</p>

    <p class="text-gray-300">then
<span class="math">$d^2((u_i)_{i=0}^1, C^2) \\le e</span>$
.</p>

    <p class="text-gray-300">Our formulation above of [Ben+23, Thm. 4.1] uses a slightly different parameterization; that is, our line is of the form  <span class="math">(1-r_0) \\cdot u_0 + r_0 \\cdot u_1</span> , while that result considers lines of the form  <span class="math">u_0&#x27; + r_0 \\cdot u_1&#x27;</span> . The difference between these conventions is immaterial, up to the reparameterization which sets  <span class="math">u_0&#x27; := u_0</span>  and  <span class="math">u_1&#x27; := u_1 - u_0</span>  (this reparameterization moreover doesn't affect the conclusion).</p>

    <p class="text-gray-300">Diamond and Gruen [DG25, Thm. 2], making use of a result of Angeris, Evans and Roh [AER24] (see also [DG25, Thm. 3]), show that each code C for which the conclusion of Theorem 2.3 holds also exhibits tensor-style proximity gaps in the sense of Diamond and Posen [DP24, Thm. 2] (although they sharpen by a factor of two that result's false witness probability). Applying their result to Theorem 2.3, those authors obtain:</p>

    <p class="text-gray-300"><strong>Theorem 2.4</strong> (Diamond&ndash;Gruen [DG25, Cor. 1]). For each proximity parameter  <span class="math">e \\in \\{0, \\dots, \\left\\lfloor \\frac{d-1}{2} \\right\\rfloor \\}</span> , each tensor arity  <span class="math">\\vartheta \\geq 1</span> , and each list of words  <span class="math">u_0, \\dots, u_{2^{\\vartheta}-1}</span>  in  <span class="math">L^{2^{\\ell+\\mathcal{R}}}</span> , if</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{(r_0,\\dots,r_{\\vartheta-1})\\in L^\\vartheta}\\left[d\\left(\\begin{bmatrix}\\dots&amp;\\otimes_{i=0}^{\\vartheta-1}(1-r_i,r_i)&amp;-\\end{bmatrix}\\cdot\\begin{bmatrix}\\dots&amp;u_0&amp;-\\dots\\\\&amp;&amp;\\vdots\\\\&amp;&amp;&amp;\\vdots\\\\&amp;&amp;&amp;u_{2^\\vartheta-1}&amp;-\\dots\\end{bmatrix},C\\right)\\leq e\\right]&gt;\\vartheta\\cdot\\frac{n}{|L|},</span>$</p>

    <p class="text-gray-300">then
<span class="math">$d^{2^{\\vartheta}}((u_i)_{i=0}^{2^{\\vartheta}-1}, C^{2^{\\vartheta}}) \\leq e.</span>$</p>

      <h3 id="sec-2.7" class="text-xl font-semibold mt-8">2.7 Security Definitions</h3>

    <p class="text-gray-300">We record security definitions. We begin by defining various abstract oracles, following [DP25, &sect; 4.1].</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Upon receiving (submit, m, f) from  <span class="math">\\mathcal{P}</span> , where  <span class="math">m \\in \\mathbb{N}</span>  and  <span class="math">f \\in L^{\\mathcal{B}_m}</span> , output (receipt, L, [f]) to all parties, where [f] is some unique handle onto the vector f.</li>
      <li>Upon receiving (query, [f], v) from  <span class="math">\\mathcal{V}</span> , where  <span class="math">v \\in \\mathcal{B}_m</span> , send  <span class="math">\\mathcal{V}</span>  (result, f(v)).</li>
    </ul>

    <p class="text-gray-300"><strong>FUNCTIONALITY 2.6</strong> ( <span class="math">\\mathcal{F}_{\\mathsf{Poly}}^{\\lambda,\\ell}</span> &mdash;polynomial oracle). A security parameter  <span class="math">\\lambda \\in \\mathbb{N}</span>  and a number-of-variables parameter  <span class="math">\\ell \\in \\mathbb{N}</span>  are given. The functionality constructs and fixes a field L (allowed to depend on  <span class="math">\\lambda</span>  and  <span class="math">\\ell</span> ).</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Upon receiving (submit, t) from  <span class="math">\\mathcal{P}</span> , where  <span class="math">t(X_0,\\ldots,X_{\\ell-1}) \\in L[X_0,\\ldots,X_{\\ell-1}]^{\\leq 1}</span> , output (receipt, [t]) to all parties, where [t] is some unique handle onto the polynomial t.</li>
      <li>On input (query, [t], r) from  <span class="math">\\mathcal{V}</span> , where  <span class="math">r \\in L^{\\ell}</span> , send  <span class="math">\\mathcal{V}</span>  (result,  <span class="math">t(r_0, \\ldots, r_{\\ell-1})</span> ).</li>
    </ul>

    <p class="text-gray-300">FUNCTIONALITY 2.7 ( <span class="math">\\mathcal{F}_{\\mathsf{SFPoly}}^{\\lambda,K,\\ell}</span> &mdash;small-field polynomial oracle). A security parameter  <span class="math">\\lambda \\in \\mathbb{N}</span> , a number-of-variables parameter  <span class="math">\\ell \\in \\mathbb{N}</span> , and a ground field K are given. The functionality constructs and fixes a field extension L/K (allowed to depend on  <span class="math">\\lambda</span> ,  <span class="math">\\ell</span>  and K).</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Upon receiving (submit, t) from  <span class="math">\\mathcal{P}</span> , where  <span class="math">t(X_0, \\ldots, X_{\\ell-1}) \\in K[X_0, \\ldots, X_{\\ell-1}]^{\\leq 1}</span> , output (receipt, [t]) to all parties, where [t] is some unique handle onto the polynomial t.</li>
      <li>On input (query, [t], r) from  <span class="math">\\mathcal{V}</span> , where  <span class="math">r \\in L^{\\ell}</span> , send  <span class="math">\\mathcal{V}</span>  (result,  <span class="math">t(r_0, \\ldots, r_{\\ell-1})</span> ).</li>
    </ul>

    <p class="text-gray-300">An IOP, by definition, is a protocol in which  <span class="math">\\mathcal{P}</span>  and  <span class="math">\\mathcal{V}</span>  may make free use of the abstract Functionality 2.5; in a PIOP, the parties may instead use Functionality 2.6. Interactive oracle polynomial commitment schemes (IOPCSs) serve to bridge these two models. They're IOPs; that is, they operate within the abstract computational model in which Functionality 2.5 is assumed to exist. On the other hand, they &quot;emulate&quot; the more-powerful Functionality 2.6, in the sense that each given PIOP&mdash;by inlining in place of each of its calls to Functionality 2.6 an execution of the IOPCS&mdash;stands to yield an equivalently secure IOP.</p>

    <p class="text-gray-300">Departing from previous treatments, we define polynomial commitment in the IOP model. For our purposes, a &quot;polynomial commitment scheme&quot; is an IOP (i.e., a protocol in which the vector oracle is available to both parties) which captures the commitment, and subsequently the evaluation, of a polynomial. Our approach contrasts with that taken by various previous works (we note e.g. Setty [Set20] and Diamond and Posen [DP25]). Those works opt to define polynomial commitment schemes in the plain (random oracle) model, noting that a plain PCS, upon being inlined into a secure PIOP, yields a sound argument. That approach absorbs the Merklization process both into the PCS and into the composition theorem. Our approach bypasses this technicality, and separates these concerns. Indeed, given a PIOP, we may first inline our IOPCS into it; on the resulting IOP, we may finally invoke generically the compiler of Ben-Sasson, Chiesa and Spooner [BCS16]. This &quot;two-step&quot; compilation process serves to transform any secure PIOP into a secure argument in the random oracle model.</p>

    <p class="text-gray-300">We also define the security of IOPCSs differently than do [Set20, Def. 2.11] and [DP25, &sect; 3.5]. Our definition below requires that  <span class="math">\\mathcal{E}</span>  extract  <span class="math">t(X_0,\\ldots,X_{\\ell-1})</span>  immediately after seeing  <span class="math">\\mathcal{A}</span> 's commitment (that is, before seeing r, or observing any evaluation proofs on the part of A). This work's IOPCS constructions indeed meet this stricter requirement, owing essentially to their use of Reed-Solomon codes, which are efficiently decodable. (In the setting of general&mdash;that is, not-necessarily-decodable&mdash;codes, extraction becomes much more complicated, and requires rewinding.) On the other hand, our strict rendition of the IOPCS notion makes its key composability property&mdash;that is, the fact whereby a secure IOPCS, upon being inlined into a secure PIOP, yields a secure IOP&mdash;easier to prove. (We believe that this composability property should, on the other hand, nonetheless hold even under various weakenings of Definition 2.9.)</p>

    <p class="text-gray-300"><strong>Definition 2.8.</strong> An interactive oracle polynomial commitment scheme (IOPCS) is a tuple of algorithms  <span class="math">\\Pi = (\\mathsf{Setup}, \\mathsf{Commit}, \\mathcal{P}, \\mathcal{V})</span>  with the following syntax:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>params  <span class="math">\\leftarrow \\Pi.\\mathsf{Setup}(1^{\\lambda}, \\ell)</span> . On input the security parameter  <span class="math">\\lambda \\in \\mathbb{N}</span>  and a number-of-variables parameter  <span class="math">\\ell \\in \\mathbb{N}</span> , outputs params, which includes, among other things, a field L.</li>
      <li><span class="math">[f] \\leftarrow \\Pi.\\mathsf{Commit}(\\mathsf{params},t)</span> . On input params and a multilinear polynomial  <span class="math">t(X_0,\\ldots,X_{\\ell-1}) \\in L[X_0,\\ldots,X_{\\ell-1}]^{\\leq 1}</span> , outputs a handle [f] to a vector.</li>
      <li><span class="math">b \\leftarrow \\langle \\mathcal{P}([f], s, r; t), \\mathcal{V}([f], s, r) \\rangle</span>  is an IOP, in which the parties may jointly leverage the machine  <span class="math">\\mathcal{F}^L_{\\text{Vec}}</span> . The parties have as common input a vector handle [f], an evaluation point  <span class="math">(r_0, \\ldots, r_{\\ell-1}) \\in L^{\\ell}</span> , and a claimed evaluation  <span class="math">s \\in L</span> .  <span class="math">\\mathcal{P}</span>  has as further input a multilinear polynomial  <span class="math">t(X_0, \\ldots, X_{\\ell-1}) \\in L[X_0, \\ldots, X_{\\ell-1}]^{\\leq 1}</span> .  <span class="math">\\mathcal{V}</span>  outputs a success bit  <span class="math">b \\in \\{0, 1\\}</span> .</li>
    </ul>

    <p class="text-gray-300">The IOPCS  <span class="math">\\Pi</span>  is <em>complete</em> if the obvious correctness property holds. That is, for each multilinear polynomial  <span class="math">t(X_0,\\ldots,X_{\\ell-1})\\in L[X_0,\\ldots,X_{\\ell-1}]^{\\leq 1}</span>  and each honestly generated commitment  <span class="math">[f]\\leftarrow\\Pi</span> .Commit(params, t), it should hold that, for each  <span class="math">t\\in L^\\ell</span> , and for  <span class="math">t\\in L^\\ell</span> , and for  <span class="math">t\\in L^\\ell</span> , the honest prover algorithm induces the verifier to accept with probability 1, so that  <span class="math">\\langle \\mathcal{P}([f],s,r;t),\\mathcal{V}([f],s,r)\\rangle=1</span> .</p>

    <p class="text-gray-300">We now define the security of IOPCSs.</p>

    <p class="text-gray-300"><strong>Definition 2.9.</strong> For each interactive oracle polynomial commitment scheme  <span class="math">\\Pi</span> , security parameter  <span class="math">\\lambda \\in \\mathbb{N}</span> , number-of-variables parameter  <span class="math">\\ell \\in \\mathbb{N}</span> , PPT adversary  <span class="math">\\mathcal{A}</span> , and PPT emulator  <span class="math">\\mathcal{E}</span> , we define the following experiment:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The experimenter samples params  <span class="math">\\leftarrow \\Pi.\\mathsf{Setup}(1^{\\lambda}, \\ell)</span> , and gives params, including L, to  <span class="math">\\mathcal{A}</span>  and  <span class="math">\\mathcal{E}</span> .</li>
      <li>The adversary, after interacting arbitrarily with the vector oracle, outputs a handle  <span class="math">[f] \\leftarrow \\mathcal{A}(\\mathsf{params})</span> .</li>
      <li>On input  <span class="math">\\mathcal{A}</span> 's record of interactions with the oracle,  <span class="math">\\mathcal{E}</span>  outputs  <span class="math">t(X_0, \\dots, X_{\\ell-1}) \\in L[X_0, \\dots, X_{\\ell-1}]^{\\leq 1}</span> .</li>
      <li>The verifier outputs  <span class="math">(r_0, \\ldots, r_{\\ell-1}) \\leftarrow \\mathcal{V}(\\mathsf{params}, [f])</span> ;  <span class="math">\\mathcal{A}</span>  responds with an evaluation claim  <span class="math">s \\leftarrow \\mathcal{A}(r)</span> .</li>
      <li>By running the evaluation IOP with  <span class="math">\\mathcal{A}</span>  as  <span class="math">\\mathcal{V}</span> , the experimenter obtains the bit  <span class="math">b \\leftarrow \\langle \\mathcal{A}(s,r), \\mathcal{V}([f],s,r) \\rangle</span> .</li>
      <li>The experimenter defines two quantities:    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathsf{Real}_{\\mathcal{A}}^{\\Pi,\\ell}(\\lambda)</span> : is defined to be s if b=1, and  <span class="math">\\bot</span>  otherwise.</li>
      <li><span class="math">\\mathsf{Ideal}_{\\mathcal{E},\\mathcal{A}}^{\\Pi,\\ell}(\\lambda)</span> : is defined to be  <span class="math">t(r_0,\\ldots,r_{\\ell-1})</span>  if  <span class="math">t(X_0,\\ldots,X_{\\ell-1})\\neq \\bot</span>  and b=1, and  <span class="math">\\bot</span>  otherwise.</li>
    </ul></li>
    </ul>

    <p class="text-gray-300">The IOPCS  <span class="math">\\Pi</span>  is said to be <em>secure</em> if, for each PPT adversary  <span class="math">\\mathcal{A}</span> , there exists a PPT emulator  <span class="math">\\mathcal{E}</span>  and a negligible function negl such that, for each  <span class="math">\\lambda \\in \\mathbb{N}</span>  and each  <span class="math">\\ell \\in \\mathbb{N}</span> ,  <span class="math">\\Pr\\left[\\mathsf{Real}_{\\mathcal{A}}^{\\Pi,\\ell}(\\lambda) \\neq \\mathsf{Ideal}_{\\mathcal{E},\\mathcal{A}}^{\\Pi,\\ell}(\\lambda)\\right] \\leq \\mathsf{negl}(\\lambda)</span> .</p>

    <p class="text-gray-300">We finally record a variant of Definition 2.8 in which the parties may fix a small coefficient field K.</p>

    <p class="text-gray-300"><strong>Definition 2.10.</strong> A small-field interactive oracle polynomial commitment scheme (small-field IOPCS) is a tuple of algorithms  <span class="math">\\Pi = (\\mathsf{Setup}, \\mathsf{Commit}, \\mathcal{P}, \\mathcal{V})</span>  with the following syntax:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>params  <span class="math">\\leftarrow \\Pi.\\mathsf{Setup}(1^{\\lambda}, \\ell, K)</span> . On input the security parameter  <span class="math">\\lambda \\in \\mathbb{N}</span> , a number-of-variables parameter  <span class="math">\\ell \\in \\mathbb{N}</span>  and a field K, outputs params, which includes, among other things, a field extension L / K.</li>
      <li><span class="math">[f] \\leftarrow \\Pi.\\mathsf{Commit}(\\mathsf{params},t)</span> . On input params and a multilinear polynomial  <span class="math">t(X_0,\\ldots,X_{\\ell-1}) \\in K[X_0,\\ldots,X_{\\ell-1}]^{\\leq 1}</span> , outputs a handle [f] to a vector.</li>
      <li><span class="math">b \\leftarrow \\langle \\mathcal{P}([f], s, r; t), \\mathcal{V}([f], s, r) \\rangle</span>  is an IOP, in which the parties may jointly leverage the machine  <span class="math">\\mathcal{F}^{L}_{\\text{Vec}}</span> . The parties have as common input a vector handle [f], an evaluation point  <span class="math">(r_0, \\ldots, r_{\\ell-1}) \\in L^{\\ell}</span> , and a claimed evaluation  <span class="math">s \\in L</span> .  <span class="math">\\mathcal{P}</span>  has as further input a multilinear polynomial  <span class="math">t(X_0, \\ldots, X_{\\ell-1}) \\in K[X_0, \\ldots, X_{\\ell-1}]^{\\leq 1}</span> .  <span class="math">\\mathcal{V}</span>  outputs a success bit  <span class="math">b \\in \\{0, 1\\}</span> .</li>
    </ul>

    <p class="text-gray-300">We define the <em>security</em> of small-field IOPCSs  <span class="math">\\Pi</span>  exactly as in Definition 2.9, except that we require that  <span class="math">\\mathcal{E}</span>  output a polynomial  <span class="math">t(X_0, \\ldots, X_{\\ell-1}) \\in K[X_0, \\ldots, X_{\\ell-1}]^{\\leq 1}</span> .</p>

    </section>

    <section id="sec-3" class="mb-10">
      <h2 class="text-2xl font-bold">3 Ring-Switching</h2>

    <p class="text-gray-300">In this section, we formally present ring-switching. First, we review in a bit more detail the material of Subsection 1.3. Our main goal is to reframe that subsection's content tensor-theoretically.</p>

    <p class="text-gray-300">As usual, we fix a field extension L/K and a basis  <span class="math">(\\beta_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  of L over K. We moreover fix a K-multilinear  <span class="math">t(X_0,\\ldots,X_{\\ell-1})</span>  and an evaluation point  <span class="math">(r_0,\\ldots,r_{\\ell-1})</span>  over L. Finally, we again write  <span class="math">t&#x27;(X_0,\\ldots,X_{\\ell&#x27;-1})</span>  for  <span class="math">t(X_0,\\ldots,X_{\\ell-1})</span> 's packed multilinear (see (1)). Above, we argued that, in order for the verifier to assess the claim  <span class="math">t(r_0,\\ldots,r_{\\ell-1})\\stackrel{?}{=} s</span> , it's enough for the prover to send values  <span class="math">(\\hat{s}_v)_{v\\in\\mathcal{B}_{\\kappa}}</span>  respectively claimed to equal  <span class="math">(t(v_0,\\ldots,v_{\\kappa-1},r_{\\kappa},\\ldots,r_{\\ell-1}))_{v\\in\\mathcal{B}_{\\kappa}}</span> . Provided it can verify these latter claims, the verifier must just check (3).</p>

    <p class="text-gray-300">We begin with the following basic fact about the partial evaluations  <span class="math">(t(v_0, \\ldots, v_{\\kappa-1}, r_{\\kappa}, \\ldots, r_{\\ell-1}))_{v \\in \\mathcal{B}_{\\kappa}}</span> . For each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> :</p>

    <p class="text-gray-300">
<span class="math">$t(v_0, \\dots, v_{\\kappa-1}, r_{\\kappa}, \\dots, r_{\\ell-1}) = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{eq}(r_{\\kappa}, \\dots, r_{\\ell-1}, w_0, \\dots, w_{\\ell&#x27;-1}) \\cdot t(v_0, \\dots, v_{\\kappa-1}, w_0, \\dots, w_{\\ell&#x27;-1})</span>$
(27)</p>

    <p class="text-gray-300">holds, essentially by multilinear extension. In other words, to get  <span class="math">t(v_0,\\ldots,v_{\\kappa-1},r_\\kappa,\\ldots,r_{\\ell-1})</span> , we should take the weighted sum over  <span class="math">w\\in\\mathcal{B}_{\\ell&#x27;}</span> &mdash;with weights  <span class="math">(\\widetilde{\\operatorname{eq}}(r_\\kappa,\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell&#x27;-1}))_{w\\in\\mathcal{B}_{\\ell&#x27;}}</span> &mdash;of the &quot;slice components&quot;  <span class="math">t(v_0,\\ldots,v_{\\kappa-1},w_0,\\ldots,w_{\\ell&#x27;-1})</span> . That is, as the chunk index  <span class="math">w\\in\\mathcal{B}_{\\ell&#x27;}</span>  varies, we take, in each case, the  <span class="math">v^{\\operatorname{th}}</span>  component of the  <span class="math">w^{\\operatorname{th}}</span>  chunk of  <span class="math">t(X_0,\\ldots,X_{\\ell-1})</span> 's Lagrange coefficient vector.</p>

    <p class="text-gray-300">Figure 10 below&mdash;in which we horizontally &quot;stack&quot; all  <span class="math">2^{\\kappa}</span>  instances of the relationship (27) (i.e., for  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span>  varying)&mdash;reveals something interesting.</p>

    <p class="text-gray-300">    <img src="_page_21_Figure_7.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Figure 10: A graphical depiction of  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span> 's partial evaluations.</p>

    <p class="text-gray-300">For each column index  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> , the  <span class="math">v^{\\text{th}}</span>  &quot;column slice&quot; of Figure 10 is simply (27). The point is that, for each column index  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span>  and each summand index  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span> , slice component  <span class="math">t(v_0, \\ldots, v_{\\kappa-1}, w_0, \\ldots, w_{\\ell&#x27;-1})</span>  we want is exactly the  <span class="math">v^{\\text{th}}</span>  horizontal component of t'(w) (this is just the definition of packing, i.e. (1)).</p>

    <p class="text-gray-300">In Figure 10's right-hand side, we have the sum, over varying  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span> , of the matrices  <span class="math">\\widetilde{\\text{eq}}(r_{\\kappa},\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell&#x27;-1})\\star t&#x27;(w)</span> . Here, we again use the  <span class="math">\\star</span>  symbol to denote the &quot;exterior product&quot; between two <em>L</em>-elements (recall Subsection 1.3). That is, we basis-decompose both operands into <em>K</em>-vectors, and then take the  <span class="math">2^{\\kappa} \\times 2^{\\kappa}</span>  <em>K</em>-matrix of cross-products between these vectors.</p>

    <p class="text-gray-300">On the other hand, by taking the exact same picture and viewing it row-wise, we obtain relationships that we can sumcheck. As in Subsection 1.3, for each  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span> , we write  <span class="math">(A_{w,u})_{u \\in \\mathcal{B}_{\\kappa}}</span>  for the basis-decomposition of  <span class="math">\\widetilde{eq}(r_{\\kappa}, \\ldots, r_{\\ell-1}, w_0, \\ldots, w_{\\ell&#x27;-1})</span> ; that is, for each  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span> , we define these elements so that</p>

    <p class="text-gray-300">
<span class="math">$\\widetilde{\\operatorname{eq}}(r_{\\kappa}, \\dots, r_{\\ell-1}, w_0, \\dots, w_{\\ell&#x27;-1}) = \\sum_{u \\in \\mathcal{B}_{\\kappa}} A_{w,u} \\cdot \\beta_u \\tag{28}</span>$</p>

    <p class="text-gray-300">holds (recall also (8)). Interpreting Figure 10 row-wise, we obtain Figure 11 below, which, again, is true essentially by definition. Indeed, &quot;zooming into&quot; some row  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span>  of Figure 11, we note that that Figure 11's right-hand side sums the slice-product  <span class="math">A_{w,u} \\cdot t&#x27;(w)</span>  over  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span> .</p>

    <p class="text-gray-300">    <img src="_page_22_Figure_0.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Figure 11: A row-wise viewpoint into the same exact expression.</p>

    <p class="text-gray-300">The point is that the rows of Figure 11 are amenable to the sumcheck protocol&mdash;provided, that is, that the verifier can efficiently evaluate  <span class="math">(A_u(r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1}))_{u\\in\\mathcal{B}_\\kappa}</span> , for some random point  <span class="math">(r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1})</span>  that arises during the sumcheck. Here, for each  <span class="math">u\\in\\mathcal{B}_\\kappa</span> , we define  <span class="math">A_u(X_0,\\ldots,X_{\\ell&#x27;-1})</span>  to be the multilinear extension of the map  <span class="math">A_u:w\\mapsto A_{w,u}</span> , for  <span class="math">w\\in\\mathcal{B}_{\\ell&#x27;}</span>  varying. This gets us to where we left off in Subsection 1.3, i.e. to Figure 3.</p>

    <p class="text-gray-300">In fact, Figures 3, 10 and 11 all arise naturally as tensor-algebraic expressions. We recall the tensor algebra  <span class="math">A := L \\otimes_K L</span>  from Subsection 2.5. Each element of the tensor algebra looks, concretely, like a  <span class="math">2^{\\kappa} \\times 2^{\\kappa}</span>  array of K-elements. We may freely interpret each such element, say  <span class="math">\\hat{s} \\in A</span> , both column-wise and row-wise. That is, we can interpret each of  <span class="math">\\hat{s}</span> 's columns as an L-element, and so obtain a list  <span class="math">(\\hat{s}_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  of L-elements; alternatively, we can interpret each of  <span class="math">\\hat{s}</span> 's rows as an L-element, thereby obtaining a further list  <span class="math">(\\hat{s}_u)_{u \\in \\mathcal{B}_{\\kappa}}</span> . As should be clear by now, our theory hinges on a viewpoint that maintains both of these perspectives at once. The tensor algebra furnishes the arena within which we might best do this.</p>

    <p class="text-gray-300">The important thing about the tensor algebra is its multiplication operation, and in particular how that operation handles columns and rows. Given some L-element  <span class="math">\\alpha</span> , we can obtain an A-element by inscribing  <span class="math">\\alpha</span> 's K-decomposition into the left-hand column of a  <span class="math">2^{\\kappa} \\times 2^{\\kappa}</span>  array. The resulting A-element is  <span class="math">\\varphi_0(\\alpha)</span> . Similarly, we may equally inscribe  <span class="math">\\alpha</span> 's K-decomposition into the top row of a  <span class="math">2^{\\kappa} \\times 2^{\\kappa}</span>  K-array; this operation yields  <span class="math">\\varphi_1(\\alpha)</span> . (We again recall Subsection 2.5.) The important thing about the tensor algebra's multiplication structure is that it captures the  <span class="math">\\star</span>  operation. In fact, for each pair of L-elements  <span class="math">\\alpha_0</span>  and  <span class="math">\\alpha_1</span> ,</p>

    <p class="text-gray-300">
<span class="math">$\\alpha_0 \\star \\alpha_1 = \\varphi_0(\\alpha_0) \\cdot \\varphi_1(\\alpha_1). \\tag{29}</span>$</p>

    <p class="text-gray-300">In (29), the left-hand product is of course the exterior product, whereas the right-hand product is the ambient multiplication operation in the tensor algebra.</p>

    <p class="text-gray-300">Figures 10 and 11 represent the tensor-algebraic identity</p>

    <p class="text-gray-300">
<span class="math">$\\varphi_1(t&#x27;)(\\varphi_0(r_{\\kappa}),\\ldots,\\varphi_0(r_{\\ell-1})) = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\varphi_0(\\widetilde{\\operatorname{eq}}(r_{\\kappa},\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell&#x27;-1})) \\cdot \\varphi_1(t&#x27;(w_0,\\ldots,w_{\\ell&#x27;-1})). \\tag{30}</span>$</p>

    <p class="text-gray-300">The identity (30) captures, in just one expression, &quot;both views&quot; (i.e., the views respectively expressed by Figures 10 and 11). Here, we write  <span class="math">\\varphi_1(t&#x27;)(X_0, \\ldots, X_{\\ell&#x27;-1})</span>  for the A-valued multilinear defined by the Lagrange prescription  <span class="math">w \\mapsto \\varphi_1(t&#x27;(w))</span>  (i.e., for  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span>  varying).</p>

    <p class="text-gray-300">Our key claim is that the right-hand side of Figure 3 is simply</p>

    <p class="text-gray-300">
<span class="math">$\\widetilde{\\operatorname{eq}}(\\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1}), \\varphi_1(r&#x27;_0), \\dots, \\varphi_1(r&#x27;_{\\ell&#x27;-1}))</span>$
(31)</p>

    <p class="text-gray-300">(recall also (14)). This nontrivial fact is key to our theory; it implies that the verifier may locally compute the right-hand side of Figure 3 succinctly, by operating in the algebra A itself. In more concrete terms, the verifier may compute (31) concretely in just  <span class="math">2 \\cdot \\ell&#x27; \\cdot 2^{\\kappa}</span>  L-multiplications, a fact we explain rigorously in Remark 3.4 below. In Subsection 3.2 below, we argue that ring-switching is concretely and asymptotically efficient for both the prover and the verifier, and is essentially optimal.</p>

      <h3 id="sec-3.1" class="text-xl font-semibold mt-8">3.1 Ring-Switching Protocol</h3>

    <p class="text-gray-300">We now record our ring-switching reduction.</p>

    <h3 id="sec-misc-3" class="text-xl font-semibold mt-8">CONSTRUCTION 3.1 (Ring-Switching Compiler).</h3>

    <p class="text-gray-300">A large-field scheme  <span class="math">\\Pi&#x27; = (\\mathsf{Setup}&#x27;, \\mathsf{Commit}&#x27;, \\mathcal{P}&#x27;, \\mathcal{V}&#x27;)</span>  is given as input. We define the small-field scheme  <span class="math">\\Pi = (\\mathsf{Setup}, \\mathsf{Commit}, \\mathcal{P}, \\mathcal{V})</span>  in the following way.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>params  <span class="math">\\leftarrow \\Pi</span> . Setup <span class="math">(1^{\\lambda}, \\ell, K)</span> . On input  <span class="math">1^{\\lambda}, \\ell</span> , and K, run and output  <span class="math">\\Pi&#x27;</span> . Setup <span class="math">&#x27;(1^{\\lambda}, \\ell&#x27;)</span> , where  <span class="math">\\ell&#x27;</span>  is such that the field L/K returned by that routine, of degree  <span class="math">2^{\\kappa}</span>  over K say, satisfies  <span class="math">\\ell&#x27; = \\ell - \\kappa</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">[f] \\leftarrow \\Pi.\\mathsf{Commit}(\\mathsf{params},t)</span> . On input  <span class="math">t(X_0,\\ldots,X_{\\ell-1}) \\in K[X_0,\\ldots,X_{\\ell-1}]^{\\leq 1}</span> , fix the packed polynomial  <span class="math">t&#x27;(X_0,\\ldots,X_{\\ell&#x27;-1})\\in L[X_0,\\ldots,X_{\\ell&#x27;-1}]^{\\leq 1}</span>  as in Definition 2.2; output  <span class="math">\\Pi&#x27;</span> . Commit'(params, t').</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">We define  <span class="math">(\\mathcal{P}, \\mathcal{V})</span>  as the following IOP, in which both parties have the common input [f],  <span class="math">s \\in L</span> , and  <span class="math">(r_0,\\ldots,r_{\\ell-1})\\in L^{\\ell}</span> , and  <span class="math">\\mathcal{P}</span>  has the further input  <span class="math">t(X_0,\\ldots,X_{\\ell-1})\\in K[X_0,\\ldots,X_{\\ell-1}]^{\\leq 1}</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>1.  <span class="math">\\mathcal{P}</span>  computes  <span class="math">\\hat{s} := \\varphi_1(t&#x27;)(\\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1}))</span>  and sends  <span class="math">\\mathcal{V}</span>  the A-element  <span class="math">\\hat{s}</span> .</li>
      <li>2.  <span class="math">\\mathcal{V}</span>  decomposes  <span class="math">\\hat{s} =: \\sum_{v \\in \\mathcal{B}_u} \\hat{s}_v \\otimes \\beta_v</span> .  <span class="math">\\mathcal{V}</span>  requires  <span class="math">s \\stackrel{?}{=} \\sum_{v \\in \\mathcal{B}_u} \\widetilde{eq}(v_0, \\dots, v_{\\kappa-1}, r_0, \\dots, r_{\\kappa-1}) \\cdot \\hat{s}_v</span> .</li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{V}</span>  samples batching scalars  <span class="math">(r&#x27;&#x27;_0, \\ldots, r&#x27;&#x27;_{\\kappa-1}) \\leftarrow L^{\\kappa}</span>  and sends them to  <span class="math">\\mathcal{P}</span> .</li>
    </ol></li>
      <li>4. For each  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span> ,  <span class="math">\\mathcal{P}</span>  decomposes  <span class="math">\\widetilde{\\operatorname{eq}}(r_{\\kappa}, \\dots, r_{\\ell-1}, w_0, \\dots, w_{\\ell&#x27;-1}) =: \\sum_{u \\in \\mathcal{B}_{\\kappa}} A_{w,u} \\cdot \\beta_u</span> .  <span class="math">\\mathcal{P}</span>  defines the function  <span class="math">A: w \\mapsto \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(u_0, \\dots, u_{\\kappa-1}, r_0&#x27;&#x27;, \\dots, r_{\\kappa-1}&#x27;&#x27;) \\cdot A_{w,u}</span>  on  <span class="math">\\mathcal{B}_{\\ell&#x27;}</span>  and writes  <span class="math">A(X_0, \\dots, X_{\\ell&#x27;-1})</span>  for its multilinear extension.  <span class="math">\\mathcal{P}</span>  defines  <span class="math">h(X_0, \\dots, X_{\\ell&#x27;-1}) \\coloneqq A(X_0, \\dots, X_{\\ell&#x27;-1}) \\cdot t&#x27;(X_0, \\dots, X_{\\ell&#x27;-1})</span> .</li>
      <li>5.  <span class="math">\\mathcal{V}</span>  decomposes  <span class="math">\\hat{s} =: \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes \\hat{s}_u</span> , and sets  <span class="math">s_0 := \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{eq}(u_0, \\dots, u_{\\kappa-1}, r_0&#x27;&#x27;, \\dots, r_{\\kappa-1}&#x27;&#x27;) \\cdot \\hat{s}_u</span> .</li>
      <li>6.  <span class="math">\\mathcal{P}</span>  and  <span class="math">\\mathcal{V}</span>  execute the following standard sumcheck loop:    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>1: <strong>for</strong>  <span class="math">i \\in \\{0, \\dots, \\ell&#x27; 1\\}</span>  <strong>do</strong></li>
      <li><span class="math">\\mathcal{P}</span>  sends  <span class="math">\\mathcal{V}</span>  the polynomial  <span class="math">h_i(X) := \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} h(r&#x27;_0, \\dots, r&#x27;_{i-1}, X, w_0, \\dots, w_{\\ell&#x27;-i-2}).</span></li>
      <li><span class="math">\\mathcal{V}</span>  requires  <span class="math">s_i \\stackrel{?}{=} h_i(0) + h_i(1)</span> .  <span class="math">\\mathcal{V}</span>  samples  <span class="math">r_i&#x27; \\leftarrow L</span> , sets  <span class="math">s_{i+1} \\coloneqq h_i(r_i&#x27;)</span> , and sends  <span class="math">\\mathcal{P}</span>   <span class="math">r_i&#x27;</span> .</li>
    </ul></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{P}</span>  computes  <span class="math">s&#x27; := t&#x27;(r&#x27;_0, \\dots, r&#x27;_{\\ell&#x27;-1})</span>  and sends  <span class="math">\\mathcal{V}</span>  s'.</li>
    </ol></li>
      <li>8. V sets  <span class="math">e := \\widetilde{\\text{eq}}(\\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1}), \\varphi_1(r&#x27;_0), \\dots, \\varphi_1(r&#x27;_{\\ell&#x27;-1}))</span>  and decomposes  <span class="math">e := \\sum_{u \\in \\mathcal{B}_u} \\beta_u \\otimes e_u</span> .</li>
      <li>9.  <span class="math">\\mathcal{V}</span>  requires  <span class="math">s_{\\ell&#x27;} \\stackrel{?}{=} \\left( \\sum_{u \\in \\mathcal{B}_{+}} \\widetilde{\\mathsf{eq}}(u_0, \\dots, u_{\\kappa-1}, r_0&#x27;&#x27;, \\dots, r_{\\kappa-1}&#x27;&#x27;) \\cdot e_u \\right) \\cdot s&#x27;</span> .</li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{P}</span>  and  <span class="math">\\mathcal{V}</span>  engage in the evaluation protocol  <span class="math">b&#x27; \\leftarrow \\langle \\mathcal{P}&#x27;([f], s&#x27;, r&#x27;; t&#x27;), \\mathcal{V}&#x27;([f], s&#x27;, r&#x27;) \\rangle</span> ;  <span class="math">\\mathcal{V}</span>  outputs b := b'.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300"><strong>Theorem 3.2.</strong> If  <span class="math">\\Pi&#x27; = (\\mathsf{Setup}&#x27;, \\mathsf{Commit}&#x27;, \\mathcal{P}&#x27;, \\mathcal{V}&#x27;)</span>  is complete, then  <span class="math">\\Pi = (\\mathsf{Setup}, \\mathsf{Commit}, \\mathcal{P}, \\mathcal{V})</span>  also is.</p>

    <p class="text-gray-300"><em>Proof.</em> We must prove three main things. First, we must show that, if  <span class="math">\\mathcal{P}</span>  constructs  <span class="math">\\hat{s} \\in A</span>  honestly, then  <span class="math">\\mathcal{V}</span> 's check  <span class="math">s \\stackrel{?}{=} \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(r_0, \\dots, r_{\\kappa-1}, v_0, \\dots, v_{\\kappa-1}) \\cdot \\hat{s}_v</span>  will pass. Further, we must show that  <span class="math">\\mathcal{V}</span> 's quantity  <span class="math">s_0 \\coloneqq</span>  <span class="math">\\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(u_0, \\dots, u_{\\kappa-1}, r_0&#x27;&#x27;, \\dots, r_{\\kappa-1}&#x27;&#x27;) \\cdot \\hat{s}_u</span>  will satisfy  <span class="math">s_0 = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} h(w)</span> , so that  <span class="math">\\mathcal{V}</span>  will accept throughout its sumcheck. Finally, we must show that  <span class="math">\\mathcal{V}</span> 's final check will pass; this task amounts to showing that e's rowrepresentation  <span class="math">e = \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes e_u</span>  will satisfy  <span class="math">A(r&#x27;_0, \\dots, r&#x27;_{\\ell&#x27;-1}) = \\sum_{u \\in \\mathcal{B}_{\\kappa}} e_u \\cdot \\widetilde{eq}(u_0, \\dots, u_{\\kappa-1}, r&#x27;&#x27;_0, \\dots, r&#x27;&#x27;_{\\kappa-1})</span> . We begin with the first fact above. If  <span class="math">\\mathcal{P}</span>  operates as prescribed, then its initial message  <span class="math">\\hat{s} \\in A</span>  will satisfy:</p>

    <p class="text-gray-300">
<span class="math">$\\hat{s} := \\varphi_1(t&#x27;)(\\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1})) = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{\\text{eq}}(\\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1}), w_0, \\dots, w_{\\ell&#x27;-1}) \\cdot \\varphi_1(t&#x27;)(w). \\tag{32}</span>$</p>

    <p class="text-gray-300">By the definition of  <span class="math">\\varphi_1(t&#x27;)(X_0,\\ldots,X_{\\ell&#x27;-1})</span> , for each  <span class="math">w\\in\\mathcal{B}_{\\ell&#x27;}</span> , we have the column decomposition  <span class="math">\\varphi_1(t&#x27;)(w)=</span>  <span class="math">\\sum_{v \\in \\mathcal{B}_{\\kappa}} t(v_0, \\dots, v_{\\kappa-1}, w_0, \\dots, w_{\\ell&#x27;-1}) \\otimes \\beta_v. \\quad \\text{On the other hand, } \\widetilde{\\mathsf{eq}}(\\varphi_0(r_\\kappa), \\dots, \\varphi_0(r_{\\ell-1}), w_0, \\dots, w_{\\ell&#x27;-1}) = 0</span>  <span class="math">\\varphi_0(\\widehat{eq}(r_{\\kappa},\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell&#x27;-1}))</span> . Using the column-multiplication rule, we obtain, for each summand  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span>  of the sum (32) above, the column decomposition  <span class="math">\\varphi_0(\\widetilde{\\operatorname{eq}}(r_{\\kappa},\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell&#x27;-1})) \\cdot \\varphi_1(t&#x27;)(w) = \\sum_{v \\in \\mathcal{B}_{\\kappa}} (\\widetilde{\\operatorname{eq}}(r_{\\kappa},\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell&#x27;-1}) \\cdot t(v_0,\\ldots,v_{\\kappa-1},w_0,\\ldots,w_{\\ell&#x27;-1})) \\otimes \\beta_v</span> . Inlining this expression into the sum (32) above, we obtain:</p>

    <p class="text-gray-300"><span class="math">$\\hat{s} = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{eq}(\\varphi_0(r_\\kappa), \\dots, \\varphi_0(r_{\\ell-1}), w_0, \\dots, w_{\\ell&#x27;-1}) \\cdot \\varphi_1(t&#x27;)(w)</span>$
(by (32).)</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\left( \\sum_{v \\in \\mathcal{B}_{\\kappa}} (\\widetilde{\\mathsf{eq}}(r_{\\kappa}, \\dots, r_{\\ell-1}, w_0, \\dots, w_{\\ell&#x27;-1}) \\cdot t(v_0, \\dots, v_{\\kappa-1}, w_0, \\dots, w_{\\ell&#x27;-1})) \\otimes \\beta_v \\right)</span>$
(column values.)</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\left( \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{eq}(r_{\\kappa}, \\dots, r_{\\ell-1}, w_0, \\dots, w_{\\ell&#x27;-1}) \\cdot t(v_0, \\dots, v_{\\kappa-1}, w_0, \\dots, w_{\\ell&#x27;-1}) \\right) \\otimes \\beta_v \\quad \\text{(rearranging sums.)}</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{v \\in \\mathcal{B}_{\\kappa}} t(v_0, \\dots, v_{\\kappa-1}, r_{\\kappa}, \\dots, r_{\\ell-1}) \\otimes \\beta_v.</span>$
(fundamental property of multilinears.)</p>

    <p class="text-gray-300">That is,  <span class="math">\\mathcal{V}</span> 's column-decomposition  <span class="math">\\hat{s} = \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\hat{s}_v \\otimes \\beta_v</span>  will satisfy  <span class="math">\\hat{s}_v = t(v_0, \\dots, v_{\\kappa-1}, r_{\\kappa}, \\dots, r_{\\ell-1})</span>  for each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> . Assuming now that  <span class="math">\\mathcal{P}</span> 's initial claim  <span class="math">s \\stackrel{?}{=} t(r_0, \\dots, r_{\\ell-1})</span>  is true, we obtain:</p>

    <p class="text-gray-300"><span class="math">$s = t(r_0, \\dots, r_{\\ell-1})</span>$
(by the truth of  <span class="math">\\mathcal{P}</span> 's claim.)
<span class="math">$= \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\text{eq}}(v_0, \\dots, v_{\\kappa-1}, r_0, \\dots, r_{\\kappa-1}) \\cdot t(v_0, \\dots, v_{\\kappa-1}, r_{\\kappa}, \\dots, r_{\\ell-1})</span>$
(partial multilinear expansion.)
<span class="math">$= \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\text{eq}}(v_0, \\dots, v_{\\kappa-1}, r_0, \\dots, r_{\\kappa-1}) \\cdot \\hat{s}_v.</span>$
(by the calculation just carried out.)</p>

    <p class="text-gray-300">In particular,  <span class="math">\\mathcal{V}</span>  will accept its first check  <span class="math">s \\stackrel{?}{=} \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\widetilde{eq}(v_0, \\dots, v_{\\kappa-1}, r_0, \\dots, r_{\\kappa-1}) \\cdot \\hat{s}_v</span> . We turn to the sumcheck. As a notational device, we define the A-valued polynomial:</p>

    <p class="text-gray-300"><span class="math">$\\hat{h}(X_0,\\ldots,X_{\\ell&#x27;-1}) \\coloneqq \\widetilde{\\operatorname{eq}}(\\varphi_0(r_\\kappa),\\ldots,\\varphi_0(r_{\\ell-1}),X_0,\\ldots,X_{\\ell&#x27;-1})) \\cdot \\varphi_1(t&#x27;)(X_0,\\ldots,X_{\\ell&#x27;-1}).</span>$</p>

    <p class="text-gray-300">Informally, we must show that  <span class="math">\\mathcal{P}</span> 's polynomial  <span class="math">h(X_0,\\ldots,X_{\\ell&#x27;-1})</span>  above is a &quot;row-combination&quot; of  <span class="math">\\hat{h}(X_0,\\ldots,X_{\\ell&#x27;-1})</span>  by the vector  <span class="math">(\\widetilde{\\operatorname{eq}}(u_0,\\ldots,u_{\\kappa-1},r_0&#x27;&#x27;,\\ldots,r_{\\kappa-1}&#x27;&#x27;))_{u\\in\\mathcal{B}_{\\kappa}}</span> .</p>

    <p class="text-gray-300">On the one hand, we note immediately that</p>

    <p class="text-gray-300"><span class="math">$\\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\hat{h}(w) = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{\\operatorname{eq}}(\\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1}), w_0, \\dots, w_{\\ell&#x27;-1}) \\cdot \\varphi_1(t&#x27;)(w) = \\varphi_1(t&#x27;)(\\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1})) = \\hat{s};</span>$</p>

    <p class="text-gray-300">the last equality holds precisely when  <span class="math">\\mathcal{P}</span>  constructs  <span class="math">\\hat{s}</span>  honestly.</p>

    <p class="text-gray-300">On the other hand, for each  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span> :</p>

    <p class="text-gray-300"><span class="math">$\\hat{h}(w) = \\widetilde{\\operatorname{eq}}(\\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1}), w_0, \\dots, w_{\\ell&#x27;-1}) \\cdot \\varphi_1(t&#x27;)(w) \\qquad \\text{(by definition of } \\hat{h}.)</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\left(\\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes A_{w,u}\\right) \\cdot (1 \\otimes t&#x27;(w)) \\qquad \\text{(by the definitions of } \\varphi_1(t&#x27;) \\text{ and of } A_{w,u}.)</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes (A_{w,u} \\cdot t&#x27;(w)). \\qquad \\text{(distributing and using the multiplicative structure of } A.)</span>$</p>

    <p class="text-gray-300">We explain in slightly further detail the second equality above. Indeed, we use first the fact&mdash;already noted above&mdash;whereby  <span class="math">\\widetilde{\\operatorname{eq}}(\\varphi_0(r_{\\kappa}),\\ldots,\\varphi_0(r_{\\ell-1}),w_0,\\ldots,w_{\\ell&#x27;-1})=\\varphi_0(\\widetilde{\\operatorname{eq}}(r_{\\kappa},\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell&#x27;-1}))</span> . On the other hand, since the basis decomposition  <span class="math">\\widetilde{\\operatorname{eq}}(r_{\\kappa},\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell&#x27;-1})=\\sum_{u\\in\\mathcal{B}_{\\kappa}}A_{w,u}\\cdot\\beta_u</span>  holds by definition of the elements  <span class="math">A_{w,u}</span> , the row representation of this quantity's image under  <span class="math">\\varphi_0</span>  can be none other than  <span class="math">\\sum_{u\\in\\mathcal{B}_{\\kappa}}\\beta_u\\otimes A_{w,u}</span> , which is what appears above.</p>

    <p class="text-gray-300">Combining the above two calculations, we conclude that, if  <span class="math">\\mathcal{P}</span>  is honest, then</p>

    <p class="text-gray-300">
<span class="math">$\\hat{s} = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\hat{h}(w) = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\left( \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes (t&#x27;(w) \\cdot A_{w,u}) \\right) = \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes \\left( \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A_{w,u} \\cdot t&#x27;(w) \\right)</span>$
(33)</p>

    <p class="text-gray-300">will hold, so that  <span class="math">\\mathcal{V}</span> 's row decomposition  <span class="math">\\hat{s} = \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes \\hat{s}_u</span>  will satisfy  <span class="math">\\hat{s}_u = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A_{w,u} \\cdot t&#x27;(w)</span>  for each  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span> . We conclude that, if  <span class="math">\\mathcal{P}</span>  constructs  <span class="math">\\hat{s}</span>  correctly, then</p>

    <p class="text-gray-300"><span class="math">$\\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} h(w) = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A(w) \\cdot t&#x27;(w) \\qquad \\text{(by definition of } h(X_0, \\dots, X_{\\ell&#x27;-1}).)</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\left( \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\text{eq}}(u_0, \\dots, u_{\\kappa-1}, r&#x27;&#x27;_0, \\dots, r&#x27;&#x27;_{\\kappa-1}) \\cdot A_{w,u} \\right) \\cdot t&#x27;(w) \\quad \\text{(by definition of } A(X_0, \\dots, X_{\\ell&#x27;-1}).)</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\text{eq}}(u_0, \\dots, u_{\\kappa-1}, r&#x27;&#x27;_0, \\dots, r&#x27;&#x27;_{\\kappa-1}) \\cdot \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A_{w,u} \\cdot t&#x27;(w) \\quad \\text{(interchanging the above sums.)}</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\text{eq}}(u_0, \\dots, u_{\\kappa-1}, r&#x27;&#x27;_0, \\dots, r&#x27;&#x27;_{\\kappa-1}) \\cdot \\hat{s}_u \\quad \\text{(by (33) and the remarks below it.)}</span>$</p>

    <p class="text-gray-300"><span class="math">$= s_0 \\quad \\text{(by definition of the verifier.)}</span>$</p>

    <p class="text-gray-300">will hold, so that  <span class="math">\\mathcal{P}</span> 's sumcheck claim  <span class="math">s_0 = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} h(w)</span>  will be valid, and  <span class="math">\\mathcal{V}</span>  will accept throughout the course of its sumcheck, by the completeness of that latter protocol.</p>

    <p class="text-gray-300">We turn to  <span class="math">\\mathcal{V}</span> 's final check. If  <span class="math">\\mathcal{P}</span>  is honest, then  <span class="math">s&#x27;=t&#x27;(r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1})</span>  will hold; moreover, by definition of the sumcheck, we will have  <span class="math">s_{\\ell&#x27;}=h(r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1})</span> . To treat  <span class="math">\\mathcal{V}</span> 's final check, it thus suffices to argue that  <span class="math">h(r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1})=t&#x27;(r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1})\\cdot\\sum_{u\\in\\mathcal{B}_\\kappa}\\widetilde{\\mathrm{eq}}(u_0,\\ldots,u_{\\kappa-1},r&#x27;&#x27;_0,\\ldots,r&#x27;&#x27;_{\\kappa-1})\\cdot e_u</span>  will hold; to show this, it in turn suffices, by definition of  <span class="math">h(X_0,\\ldots,X_{\\ell&#x27;-1})</span> , to prove that</p>

    <p class="text-gray-300"><span class="math">$A(r&#x27;_0,\\ldots,r&#x27;_{\\ell&#x27;-1}) = \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(u_0,\\ldots,u_{\\kappa-1},r&#x27;&#x27;_0,\\ldots,r&#x27;&#x27;_{\\kappa-1}) \\cdot e_u.</span>$</p>

    <p class="text-gray-300">We proceed as follows. We note first that:</p>

    <p class="text-gray-300"><span class="math">$e = \\widetilde{\\operatorname{eq}} \\left( \\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1}), \\varphi_1(r&#x27;_0), \\dots, \\varphi_1(r&#x27;_{\\ell&#x27;-1}) \\right)</span>$
(by definition.)
<span class="math">$= \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{\\operatorname{eq}} \\left( \\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1}), w_0, \\dots, w_{\\ell&#x27;-1} \\right) \\cdot \\widetilde{\\operatorname{eq}} \\left( \\varphi_1(r&#x27;_0), \\dots, \\varphi_1(r&#x27;_{\\ell&#x27;-1}), w_0, \\dots, w_{\\ell&#x27;-1} \\right)</span>$
(see below.)
<span class="math">$= \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\varphi_0(\\widetilde{\\operatorname{eq}}(r_{\\kappa}, \\dots, r_{\\ell-1}, w_0, \\dots, w_{\\ell&#x27;-1})) \\cdot \\varphi_1\\left(\\widetilde{\\operatorname{eq}}(w_0, \\dots, w_{\\ell&#x27;-1}, r&#x27;_0, \\dots, r&#x27;_{\\ell&#x27;-1})\\right)</span>$
(pulling out  <span class="math">\\varphi_0</span>  and  <span class="math">\\varphi_1</span> .)
<span class="math">$= \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\left( \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes A_{w,u} \\right) \\cdot \\left( 1 \\otimes \\widetilde{\\operatorname{eq}}(w_0, \\dots, w_{\\ell&#x27;-1}, r&#x27;_0, \\dots, r&#x27;_{\\ell&#x27;-1}) \\right)</span>$
(again by definition of the  <span class="math">A_{w,u}</span> .)
<span class="math">$= \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes \\left( \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A_{w,u} \\cdot \\widetilde{\\operatorname{eq}}(w_0, \\dots, w_{\\ell&#x27;-1}, r&#x27;_0, \\dots, r&#x27;_{\\ell&#x27;-1}) \\right).</span>$
(multiplying in  <span class="math">A</span>  and rearranging.)</p>

    <p class="text-gray-300">To achieve the second equality above, we note that the multilinears  <span class="math">\\widetilde{\\operatorname{eq}}(X_0,\\ldots,X_{\\ell&#x27;-1},Y_0,\\ldots,Y_{\\ell&#x27;-1})</span>  and  <span class="math">\\sum_{w\\in\\mathcal{B}_{\\ell&#x27;}}\\widetilde{\\operatorname{eq}}(X_0,\\ldots,X_{\\ell&#x27;-1},w_0,\\ldots,w_{\\ell&#x27;-1})\\cdot\\widetilde{\\operatorname{eq}}(w_0,\\ldots,w_{\\ell&#x27;-1},Y_0,\\ldots,Y_{\\ell&#x27;-1})</span>  are necessarily identical, since they agree identically on the cube  <span class="math">\\mathcal{B}_{2\\cdot\\ell&#x27;}</span> .</p>

    <p class="text-gray-300">We see that the verifier's row-decomposition  <span class="math">e = \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes e_u</span>  will satisfy  <span class="math">e_u = \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A_{w,u} \\cdot \\widetilde{eq}(w_0, \\dots, w_{\\ell&#x27;-1}, r&#x27;_0, \\dots, r&#x27;_{\\ell&#x27;-1})</span>  for each  <span class="math">u \\in \\mathcal{B}_{\\kappa}</span> . We conclude finally  <span class="math">\\mathcal V</span>  will have</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(r&#x27;&#x27;, u) \\cdot e_{u} &amp;= \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(u_{0}, \\dots, u_{\\kappa-1}, r&#x27;&#x27;_{0}, \\dots, r&#x27;&#x27;_{\\kappa-1}) \\cdot \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A_{w, u} \\cdot \\widetilde{\\operatorname{eq}}(w_{0}, \\dots, w_{\\ell&#x27;-1}, r&#x27;_{0}, \\dots, r&#x27;_{\\ell&#x27;-1}) \\\\ &amp;= \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\left( \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(u_{0}, \\dots, u_{\\kappa-1}, r&#x27;&#x27;_{0}, \\dots, r&#x27;&#x27;_{\\kappa-1}) \\cdot A_{w, u} \\right) \\cdot \\widetilde{\\operatorname{eq}}(w_{0}, \\dots, w_{\\ell&#x27;-1}, r&#x27;_{0}, \\dots, r&#x27;_{\\ell&#x27;-1}) \\\\ &amp;= \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} A(w_{0}, \\dots, w_{\\ell&#x27;-1}) \\cdot \\widetilde{\\operatorname{eq}}(w_{0}, \\dots, w_{\\ell&#x27;-1}, r&#x27;_{0}, \\dots, r&#x27;_{\\ell&#x27;-1}) \\\\ &amp;= A(r&#x27;_{0}, \\dots, r&#x27;_{\\ell&#x27;-1}), \\end{split}</span>$</p>

    <p class="text-gray-300">which is exactly what we needed to show. This completes the proof of completeness.</p>

    <p class="text-gray-300"><strong>Remark 3.3.</strong> We explain in slightly more rigorous terms the &quot;information loss&quot; which would result if the parties <em>merely</em> evaluated  <span class="math">t&#x27;(r_{\\kappa}, \\ldots, r_{\\ell-1})</span> , as opposed to using the tensor algebra. During Theorem 3.2's proof, we show that  <span class="math">\\hat{s}_v = t(v_0, \\ldots, v_{\\kappa-1}, r_{\\kappa}, \\ldots, r_{\\ell-1})</span>  holds for each  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span> . On the other hand,</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} t&#x27;(r_{\\kappa},\\ldots,r_{\\ell-1}) &amp;= \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{\\operatorname{eq}}(r_{\\kappa},\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell&#x27;-1}) \\cdot t&#x27;(w) \\\\ &amp;= \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{\\operatorname{eq}}(r_{\\kappa},\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell&#x27;-1}) \\cdot \\sum_{v \\in \\mathcal{B}_{\\kappa}} t(v_0,\\ldots,v_{\\kappa-1},w_0,\\ldots,w_{\\ell&#x27;-1}) \\cdot \\beta_v \\\\ &amp;= \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\left( \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} \\widetilde{\\operatorname{eq}}(r_{\\kappa},\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell&#x27;-1}) \\cdot t(v_0,\\ldots,v_{\\kappa-1},w_0,\\ldots,w_{\\ell&#x27;-1}) \\right) \\cdot \\beta_v \\\\ &amp;= \\sum_{v \\in \\mathcal{B}_{\\kappa}} t(v_0,\\ldots,v_{\\kappa-1},r_{\\kappa},\\ldots,r_{\\ell-1}) \\cdot \\beta_v \\\\ &amp;= \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\hat{s}_v \\cdot \\beta_v. \\end{split}</span>$</p>

    <p class="text-gray-300">We see that, while the information contained in  <span class="math">\\hat{s} = \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\hat{s}_v \\otimes \\beta_v</span>  suffices to recover  <span class="math">t(r_0, \\dots, r_{\\ell-1})</span>  (as the proof of Theorem 3.2 above shows), the datum  <span class="math">t(r_{\\kappa}, \\dots, r_{\\ell-1})</span>  would yield, rather, the basis-combination  <span class="math">\\sum_{v \\in \\mathcal{B}_{\\kappa}} \\hat{s}_v \\cdot \\beta_v</span>  of  <span class="math">\\hat{s}</span> 's columns. Since the K-basis  <span class="math">(\\beta_v)_{v \\in \\mathcal{B}_{\\kappa}}</span>  is certainly not linearly independent over L, this latter combination reflects  <span class="math">\\hat{s}</span>  only &quot;lossfully&quot;. We note that, interestingly,  <span class="math">\\sum_{v \\in \\mathcal{B}_{\\kappa}} \\hat{s} \\cdot \\beta_v = h(\\hat{s})</span>  holds; here,  <span class="math">h: L \\otimes_K L \\to L</span>  is the canonical K-linear map defined on simple tensors by multiplication (we recall Subsection 2.5 above). That is,  <span class="math">t(r_{\\kappa}, \\dots, r_{\\ell-1})</span>  relates to  <span class="math">\\varphi_1(t&#x27;)(\\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1}))</span>  exactly by the map h, which is of course not injective. We would like to thank Raju Krishnamoorthy for explaining this fact to us.</p>

    <p class="text-gray-300"><strong>Remark 3.4.</strong> We discuss the verifier's computation of  <span class="math">e := \\widetilde{\\operatorname{eq}}(\\varphi_0(r_{\\kappa}), \\ldots, \\varphi_0(r_{\\ell-1}), \\varphi_1(r&#x27;_0), \\ldots, \\varphi_1(r&#x27;_{\\ell&#x27;-1}))</span> . Clearly, this computation amounts to  <span class="math">O(\\ell&#x27;)</span>  arithmetic operations in the algebra A, and so can be carried out in polylogarithmic time for the verifier in the worst case. Here, we discuss a concretely efficient procedure by whose aid the verifier may compute e, at least in the characteristic 2 case. Indeed, we note first the following identity, valid only in characteristic 2:</p>

    <p class="text-gray-300"><span class="math">$\\widetilde{\\text{eq}}(X_0, \\dots, X_{\\ell&#x27;-1}, Y_0, \\dots, Y_{\\ell&#x27;-1}) \\coloneqq \\prod_{i=0}^{\\ell&#x27;-1} (1-X_i) \\cdot (1-Y_i) + X_i \\cdot Y_i = \\prod_{i=0}^{\\ell&#x27;-1} 1 - X_i - Y_i.</span>$</p>

    <p class="text-gray-300">This identity suggests the correctness of the following algorithm:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>1: initialize the A-element e := 1.</li>
      <li>2: <strong>for</strong>  <span class="math">i \\in \\{0, ..., \\ell&#x27; 1\\}</span>  <strong>do</strong> update  <span class="math">e -= e \\cdot \\varphi_0(r_{\\kappa+i}) + e \\cdot \\varphi_1(r&#x27;_i)</span> .</li>
      <li>3: return e.</li>
    </ul>

    <p class="text-gray-300">Concretely,  <span class="math">e \\cdot \\varphi_0(r_{\\kappa+i})</span>  means &quot;scale each column of e by  <span class="math">r_{\\kappa+i}</span> &quot;. Similarly,  <span class="math">e \\cdot \\varphi_1(r_i&#x27;)</span>  means &quot;scale each row of e by  <span class="math">r_i&#x27;&#x27;</span> &quot;. In practical implementations, e will reside at rest in column form (i.e., as a list of  <span class="math">2^{\\kappa}</span>  column L-elements). Column-scaling will be achieved by componentwise multiplication. Row-scaling will amount to a transposition, a componentwise multiplication, and a further transposition.</p>

    <p class="text-gray-300">The total cost of this procedure is thus  <span class="math">2 \\cdot \\ell&#x27; \\cdot 2^{\\kappa}</span>  L-by-L multiplications, as well as  <span class="math">2 \\cdot \\ell&#x27;</span>  transpositions.</p>

    <p class="text-gray-300">We now prove the security of ring-switching.</p>

    <p class="text-gray-300"><strong>Theorem 3.5.</strong> If  <span class="math">\\Pi&#x27; = (\\mathsf{Setup}&#x27;, \\mathsf{Commit}&#x27;, \\mathcal{P}&#x27;, \\mathcal{V}&#x27;)</span>  is secure, then  <span class="math">\\Pi = (\\mathsf{Setup}, \\mathsf{Commit}, \\mathcal{P}, \\mathcal{V})</span>  also is.</p>

    <p class="text-gray-300"><em>Proof.</em> We write  <span class="math">\\mathcal{E}&#x27;</span>  for the emulator for  <span class="math">\\Pi&#x27;</span> . We define an emulator  <span class="math">\\mathcal{E}</span>  for  <span class="math">\\Pi</span>  as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>On input  <span class="math">\\mathcal{A}</span> 's record of interactions with the vector oracle,  <span class="math">\\mathcal{E}</span>  internally runs  <span class="math">t&#x27;(X_0,\\ldots,X_{\\ell&#x27;-1})\\leftarrow\\mathcal{E}&#x27;</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>If  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell&#x27;-1}) = \\bot</span> , then  <span class="math">\\mathcal{E}</span>  outputs  <span class="math">\\bot</span>  and aborts.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>By reversing Definition 2.2,  <span class="math">\\mathcal{E}</span>  obtains  <span class="math">t(X_0, \\dots, X_{\\ell-1}) \\in K[X_0, \\dots, X_{\\ell-1}]^{\\leq 1}</span> , which it outputs.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">We argue that the emulator  <span class="math">\\mathcal{E}</span>  defined in this way is secure. If  <span class="math">\\mathcal{V}&#x27;</span>  rejects, then  <span class="math">\\mathcal{V}</span>  also does. The probability with which  <span class="math">\\mathcal{E}&#x27;</span>  outputs  <span class="math">\\bot</span>  and  <span class="math">\\mathcal{V}&#x27;</span>  accepts is negligible, by the security of  <span class="math">\\Pi&#x27;</span> . So too, therefore, is the probability with which  <span class="math">\\mathcal{E}</span>  outputs  <span class="math">\\bot</span>  and  <span class="math">\\mathcal{V}</span>  accepts. We thus fix our attention on those executions of the experiment for which  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell&#x27;-1}) \\neq \\bot</span> ; in particular, we assume that  <span class="math">t(X_0, \\ldots, X_{\\ell-1}) \\neq \\bot</span> . Similarly, the probability with which  <span class="math">t&#x27;(X_0, \\ldots, X_{\\ell&#x27;-1}) \\neq \\bot</span> ,  <span class="math">t&#x27;(r&#x27;) \\neq s&#x27;</span> , and b' = 1 all hold is negligible, by the security of  <span class="math">\\Pi&#x27;</span> . We thus focus our attention on those executions for which t'(r') = s'. We must show that the probability with which  <span class="math">t(r) \\neq s</span>  and  <span class="math">\\mathcal{V}</span>  accepts is negligible. We assume now that  <span class="math">t(r) \\neq s</span> .</p>

    <p class="text-gray-300">We may further restrict our considerations to the set of executions within which  <span class="math">\\mathcal{P}</span>  computes its first message  <span class="math">\\hat{s} \\neq \\varphi_1(t&#x27;)(\\varphi_0(r_{\\kappa}), \\ldots, \\varphi_0(r_{\\ell-1}))</span>  incorrectly. Indeed, it is shown directly in the course of our proof of Theorem 3.2 above that, if  <span class="math">\\hat{s} = \\varphi_1(t&#x27;)(\\varphi_0(r_{\\kappa}), \\ldots, \\varphi_0(r_{\\ell-1}))</span>  holds, then  <span class="math">\\sum_{v \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\text{eq}}(v_0, \\ldots, v_{\\kappa-1}, r_0, \\ldots, r_{\\kappa-1}) \\cdot \\hat{s}_v = t(r_0, \\ldots, r_{\\ell-1})</span>  also will. In this latter setting,</p>

    <p class="text-gray-300"><span class="math">$s \\neq t(r_0, \\dots, r_{\\ell-1})</span>$
(by our initial assumption above whereby  <span class="math">\\mathcal{P}</span> 's claim is false.)
<span class="math">$= \\sum_{v \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(v_0, \\dots, v_{\\kappa-1}, r_0, \\dots, r_{\\kappa-1}) \\cdot \\hat{s}_v</span>$
(a consequence of  <span class="math">\\hat{s} = \\varphi_1(t&#x27;)(\\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1}))</span> .)</p>

    <p class="text-gray-300">will hold, so that  <span class="math">\\mathcal{V}</span>  will reject and we're done. We thus assume that  <span class="math">\\hat{s} \\neq \\varphi_1(t&#x27;)(\\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1}))</span> . For the sake of notation, we abbreviate  <span class="math">\\overline{s} := \\varphi_1(t&#x27;)(\\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1}))</span>  for this latter quantity, and write  <span class="math">\\overline{s} := \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes \\overline{s}_u</span>  for its row-decomposition.</p>

    <p class="text-gray-300">Our hypothesis whereby  <span class="math">\\hat{s} \\neq \\bar{s}</span>  entails that the  <span class="math">\\kappa</span> -variate polynomial over L</p>

    <p class="text-gray-300"><span class="math">$S(X_0,\\ldots,X_{\\kappa-1})\\coloneqq \\sum_{u\\in\\mathcal{B}_\\kappa} (\\hat{s}_u-\\overline{s}_u)\\cdot \\widetilde{\\operatorname{eq}}(u_0,\\ldots,u_{\\kappa-1},X_0,\\ldots,X_{\\kappa-1})</span>$</p>

    <p class="text-gray-300">is not identically zero. Applying Schwartz&ndash;Zippel to  <span class="math">S(X_0,\\ldots,X_{\\kappa-1})</span> , we conclude that the probability, over  <span class="math">\\mathcal{V}</span> 's choice of  <span class="math">(r_0&#x27;&#x27;,\\ldots,r_{\\kappa-1}&#x27;&#x27;)\\leftarrow L^{\\kappa}</span> , that  <span class="math">S(r_0&#x27;&#x27;,\\ldots,r_{\\kappa-1}&#x27;&#x27;)=0</span>  will hold is at most  <span class="math">\\frac{\\kappa}{|L|}</span> , which is negligible. We thus assume that  <span class="math">S(r_0&#x27;&#x27;,\\ldots,r_{\\kappa-1}&#x27;&#x27;)\\neq 0</span> , which itself immediately entails that:</p>

    <p class="text-gray-300"><span class="math">$s_0 \\coloneqq \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\hat{s}_u \\cdot \\widetilde{\\operatorname{eq}}(u_0, \\dots, u_{\\kappa-1}, r_0&#x27;&#x27;, \\dots, r_{\\kappa-1}&#x27;&#x27;) \\neq \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\overline{s}_u \\cdot \\widetilde{\\operatorname{eq}}(u_0, \\dots, u_{\\kappa-1}, r_0&#x27;&#x27;, \\dots, r_{\\kappa-1}&#x27;&#x27;)</span>$</p>

    <p class="text-gray-300">will hold. On the other hand, by an argument identical to one already given during the proof of Theorem 3.2 above, we have that:</p>

    <p class="text-gray-300"><span class="math">$\\sum_{w \\in \\mathcal{B}_{\\ell&#x27;}} h(w) = \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(u_0, \\dots, u_{\\kappa-1}, r_0&#x27;&#x27;, \\dots, r_{\\kappa-1}&#x27;&#x27;) \\cdot \\overline{s}_u;</span>$</p>

    <p class="text-gray-300">we again write  <span class="math">h(X_0,\\ldots,X_{\\ell&#x27;-1}) \\coloneqq A(X_0,\\ldots,X_{\\ell&#x27;-1}) \\cdot t&#x27;(X_0,\\ldots,X_{\\ell&#x27;-1})</span>  (as usual,  <span class="math">t(X_0,\\ldots,X_{\\ell-1})</span>  here refers to what  <span class="math">\\mathcal E</span>  extracted). Combining the above two equations, we conclude&mdash;again under our hypothesis whereby  <span class="math">S(r_0&#x27;&#x27;,\\ldots,r_{\\kappa-1}&#x27;&#x27;) \\neq 0</span> &mdash;that  <span class="math">s_0 \\neq \\sum_{w \\in \\mathcal B_{\\ell&#x27;}} h(w)</span> . By the soundness of the sumcheck, we conclude that the probability with which  <span class="math">\\mathcal V</span>  accepts throughout that protocol and  <span class="math">s_{\\ell&#x27;} = h(r_0&#x27;,\\ldots,r_{\\ell&#x27;-1}&#x27;)</span>  holds is at most  <span class="math">\\frac{2 \\cdot \\ell&#x27;}{|\\mathcal L|}</span> , which is negligible. We thus assume that  <span class="math">s_{\\ell&#x27;} \\neq h(r_0&#x27;,\\ldots,r_{\\ell&#x27;-1}&#x27;)</span> , or in other words that:</p>

    <p class="text-gray-300"><span class="math">$s_{\\ell&#x27;} \\neq A(r&#x27;_0, \\dots, r&#x27;_{\\ell&#x27;-1}) \\cdot t(r&#x27;_0, \\dots, r&#x27;_{\\ell&#x27;-1}).</span>$</p>

    <p class="text-gray-300">The proof of Theorem 3.2 already shows that  <span class="math">A(r&#x27;_0, \\ldots, r&#x27;_{\\ell&#x27;-1}) = \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(u_0, \\ldots, u_{\\kappa-1}, r&#x27;&#x27;_0, \\ldots, r&#x27;&#x27;_{\\kappa-1}) \\cdot e_u</span> . On the other hand, we've already justified our consideration just of those executions within which  <span class="math">s&#x27; = t&#x27;(r&#x27;_0, \\ldots, r&#x27;_{\\ell&#x27;-1})</span>  holds. Under exactly this latter condition, therefore, the verifier will obtain:</p>

    <p class="text-gray-300"><span class="math">$s_{\\ell&#x27;} \\neq A(r_0&#x27;, \\dots, r_{\\ell&#x27;-1}&#x27;) \\cdot t(r_0&#x27;, \\dots, r_{\\ell&#x27;-1}&#x27;) = \\left(\\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(u_0, \\dots, u_{\\kappa-1}, r_0&#x27;&#x27;, \\dots, r_{\\kappa-1}&#x27;&#x27;) \\cdot e_u\\right) \\cdot s&#x27;,</span>$</p>

    <p class="text-gray-300">and so will once again reject. This completes the proof.</p>

      <h3 id="sec-3.2" class="text-xl font-semibold mt-8">3.2 Efficiency</h3>

    <p class="text-gray-300">We examine the efficiency of Protocol 3.1. Throughout, we count K-operations. We view the ground field K as constant in both  <span class="math">\\lambda</span>  and  <span class="math">\\ell</span> . We must first clarify how L relates to K. The soundness error of Protocol 3.1 is  <span class="math">\\frac{2 \\cdot \\ell&#x27; + \\kappa}{|L|}</span> . In order for this quantity to be negligible, it's enough that  <span class="math">|L| \\geq 2^{\\omega(\\log \\lambda)}</span>  hold (we note that  <span class="math">\\ell = O(\\log \\lambda)</span>  must hold, lest the prover's input length  <span class="math">2^{\\ell}</span>  fail to be polynomial in the security parameter). For simplicity, we assume that  <span class="math">\\deg(L/K) = \\lambda</span> . In this case,  <span class="math">|L| = |K|^{\\lambda} \\geq 2^{\\lambda}</span> , so that Protocol 3.1 in fact becomes exponentially secure. We moreover obtain  <span class="math">2^{\\kappa} = \\lambda</span>  and  <span class="math">2^{\\ell&#x27;} = \\frac{2^{\\ell}}{\\lambda}</span> .</p>

    <p class="text-gray-300">We refer to von zur Gathen and Gerhard for [GG13] for complexity-theoretic background. For the purposes of this subsection, we understand L as a univariate extension of K (see [GG13, &sect; 25.4]). Following [GG13, Def. 8.26], we write  <span class="math">\\mathsf{M}(\\lambda)</span>  for the complexity&mdash;measured in K-operations&mdash;of multiplying two polynomials in K[X] of degree at most  <span class="math">\\lambda</span> . It is known [GG13, Thm. 8.23] that we may take  <span class="math">\\mathsf{M}(\\lambda) = \\widetilde{O}(\\lambda)</span> . Multiplication in L can be carried out in  <span class="math">6 \\cdot \\mathsf{M}(\\lambda) + O(\\lambda) = \\widetilde{O}(\\lambda)</span>  K-operations [GG13, Cor. 11.11]. We write  <span class="math">\\mathsf{Q}(\\lambda) = O(\\mathsf{M}(\\lambda)) = \\widetilde{O}(\\lambda)</span>  for the cost, in K-operations, of L-multiplication. We note that each K-by-L multiplication takes exactly  <span class="math">\\lambda</span>  K-multiplications; each L-addition costs exactly  <span class="math">\\lambda</span>  K-additions.</p>

    <p class="text-gray-300">Prover cost. The prover's main cost is that of computing the tensor-expansion</p>

    <p class="text-gray-300">
<span class="math">$\\underbrace{\\begin{bmatrix} \\underbrace{-1} \\\\ \\underbrace{ \\sum_{i=\\kappa}^{\\ell-1} (1 - r_i, r_i)} \\end{bmatrix}}_{2^{\\ell&#x27;} \\text{ elements}}.</span>$
(34)</p>

    <p class="text-gray-300">In view of the standard algorithm for it (see Subsection 2.1), this task takes  <span class="math">2^{\\ell&#x27;}</span>  L-multiplications and  <span class="math">2^{\\ell&#x27;}</span>  L-additions. We see that the total number of K-operations associated with this task is</p>

    <p class="text-gray-300"><span class="math">$O\\Big(2^{\\ell&#x27;}\\Big) \\cdot \\mathsf{Q}(\\lambda) = O\\bigg(\\frac{2^\\ell}{\\lambda}\\bigg) \\cdot \\mathsf{Q}(\\lambda) = O(2^\\ell) \\cdot \\frac{\\mathsf{Q}(\\lambda)}{\\lambda} = O(2^\\ell) \\cdot \\widetilde{O}(1),</span>$</p>

    <p class="text-gray-300">which is linear in the input length and polylogarithmic in  <span class="math">\\lambda</span> .</p>

    <p class="text-gray-300">Having computed (34), the prover must use it in two places. First, to compute  <span class="math">\\hat{s}</span>  in step 1, the prover must compute all  <span class="math">2^{\\kappa}</span>  partial evaluations  <span class="math">\\hat{s}_v = t(v_0, \\ldots, v_{\\kappa-1}, r_{\\kappa}, \\ldots, r_{\\ell-1})</span> ; i.e., it must compute all  <span class="math">2^{\\kappa}</span>  dot-products</p>

    <p class="text-gray-300">
<span class="math">$\\hat{s}_{v} := \\left\\langle \\left[ \\underbrace{------------------------------------</span>$</p>

    <p class="text-gray-300">for  <span class="math">v \\in \\mathcal{B}_{\\kappa}</span>  varying. Each dot-product (35) takes  <span class="math">2^{\\ell&#x27;}</span>  L-by-K multiplications and  <span class="math">2^{\\ell&#x27;}</span>  L-additions. The total cost associated with the dot-products (35) is thus</p>

    <p class="text-gray-300"><span class="math">$2^{\\kappa} \\cdot O(2^{\\ell&#x27;}) \\cdot \\lambda = O(2^{\\ell}) \\cdot \\lambda</span>$</p>

    <p class="text-gray-300">K-operations.</p>

    <p class="text-gray-300">Finally, to prepare its sumcheck in step 4, the prover must first tensor-expand  <span class="math">\\bigotimes_{i=0}^{\\kappa-1} (1-r_i&#x27;&#x27;, r_i&#x27;&#x27;)</span> &mdash;a task whose cost is polynomial in  <span class="math">\\lambda</span>  alone, and which we ignore&mdash;and then compute the L-by-K matrix product:</p>

    <p class="text-gray-300">
<span class="math">$\\left[ \\underbrace{---} \\bigotimes_{i=0}^{\\kappa-1} (1 - r_i&#x27;&#x27;, r_i&#x27;&#x27;) ---- \\right] \\cdot \\begin{bmatrix} A_{(0,\\dots,0),u} &amp; \\cdots &amp; A_{(1,\\dots,1),u} \\end{bmatrix} \\begin{pmatrix} a_{(0,\\dots,0),u} &amp; \\cdots &amp; A_{(1,\\dots,1),u} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp; \\vdots \\\\ a_{i} &amp; \\vdots &amp;</span>$</p>

    <p class="text-gray-300">The product (36) yields exactly the table of values of  <span class="math">A(X_0, \\ldots, X_{\\ell&#x27;-1})</span>  on the cube  <span class="math">\\mathcal{B}_{\\ell&#x27;}</span> .</p>

    <p class="text-gray-300">To obtain the  <span class="math">2^{\\kappa} \\times 2^{\\ell&#x27;}</span>  matrix in the right-hand side of (36), the prover must use (34) again; specifically, it must simply basis-decompose each component of that tensor. This task is simply a rewiring operation, and is free (recall also (28)). To compute the matrix product (36), the prover must again perform  <span class="math">2^{\\kappa} \\cdot 2^{\\ell&#x27;} = 2^{\\ell}</span>  L-by-K multiplications and  <span class="math">2^{\\ell}</span>  L-additions; the total cost of (36) is thus again  <span class="math">O(2^{\\ell}) \\cdot \\lambda</span>  K-operations.</p>

    <p class="text-gray-300">The sumcheck 6 is  <span class="math">\\ell&#x27;</span> -dimensional over L. In view of standard algorithms for this task (we recall the treatment of Thaler [Tha22, &sect; 4.1]), the prover can carry it out in  <span class="math">O(2^{\\ell&#x27;})</span>  total L-operations. Just as in (34) above, the prover's total cost during the sumcheck is therefore again  <span class="math">O(2^{\\ell}) \\cdot \\widetilde{O}(1)</span>  total K-operations.</p>

    <p class="text-gray-300">In sum, we see that our prover's cost is  <span class="math">O(2^{\\ell}) \\cdot \\lambda</span>  K-operations. Our prover is thus linear (in both the statement size and the security parameter). Interestingly, our prover is asymptotically dominated by the respective costs of K-by-L multiplication and L-addition. These tasks are, in practice, cheaper than L-multiplication is. Upon ignoring these former costs&mdash;and considering only the cost of L-multiplication&mdash;we would in fact obtain a prover costing just  <span class="math">O(2^{\\ell}) \\cdot \\widetilde{O}(1)</span>  K-multiplications (that is, with just a polylogarithmic, and not a linear, multiplicative dependence on the security parameter  <span class="math">\\lambda</span> ).</p>

    <p class="text-gray-300"><strong>Verifier cost.</strong> To receive  <span class="math">\\hat{s}</span> , the verifier must receive  <span class="math">2^{\\kappa}</span>  <em>L</em>-elements, whose total size is that of  <span class="math">2^{2 \\cdot \\kappa} = \\lambda^2</span>  <em>K</em>-elements. In its step 2 above, the verifier must compute the tensor-expansion  <span class="math">\\bigotimes_{i=0}^{\\kappa-1} (1-r_i, r_i)</span> , as well as dot the resulting tensor with  <span class="math">(\\hat{s}_v)_{v \\in \\mathcal{B}_{\\kappa}}</span> . These tasks, together, amount to  <span class="math">O(2^{\\kappa})</span>  <em>L</em>-operations, and so cost in total</p>

    <p class="text-gray-300"><span class="math">$O(2^{\\kappa}) \\cdot \\mathsf{Q}(\\lambda) = O(\\lambda) \\cdot \\mathsf{Q}(\\lambda) = \\widetilde{O}(\\lambda^2)</span>$</p>

    <p class="text-gray-300">K-operations. The verifier's respective combination tasks 5 and 9 are structurally identical to 2, and have identical costs; we skip our analyses of them.</p>

    <p class="text-gray-300">During the sumcheck 6, the verifier must expend  <span class="math">O(\\ell&#x27;)</span>  L-operations; these cost in total  <span class="math">O(\\ell&#x27;) \\cdot \\mathsf{Q}(\\lambda) \\leq O(\\ell) \\cdot \\mathsf{Q}(\\lambda)</span>  K-operations. To compute e in step 8, the verifier must perform  <span class="math">2 \\cdot 2^{\\kappa} \\cdot \\ell&#x27;</span>  L-operations (recall Remark 3.4). These in total cost</p>

    <p class="text-gray-300"><span class="math">$O(\\ell&#x27;) \\cdot 2^{\\kappa} \\cdot \\mathsf{Q}(\\lambda) \\le O(\\ell) \\cdot \\widetilde{O}(\\lambda^2)</span>$</p>

    <p class="text-gray-300">K-operations. Our verifier is thus logarithmic in the statement size and quadratic in  <span class="math">\\lambda</span>  (up to a polylogarithmic multiplicative factor).</p>

    <p class="text-gray-300">Other costs. Protocol 3.1's prover must invoke  <span class="math">\\Pi&#x27;</span> 's commitment procedure exactly once. During Protocol 3.1's evaluation phase, the prover and the verifier must jointly invoke the underlying large-field commitment scheme  <span class="math">\\Pi&#x27;</span> 's evaluation procedure exactly once. We ignore all of these costs in this subsection, and only measure the efficiency of Protocol 3.1 over and above them.</p>

    <p class="text-gray-300">Comparison to Hashcaster. To prepare the sumcheck (21) naively, Hashcaster [Sou24]'s prover would need to compute the matrix product</p>

    <p class="text-gray-300"><span class="math">$\\left[ \\underbrace{---\\bigotimes_{i=\\kappa}^{\\kappa-1} (1-\\sigma^{0}(r_{i}),\\sigma^{0}(r_{i}))}_{i=\\kappa} \\right] \\cdot \\left[ \\underbrace{----\\bigotimes_{i=\\kappa}^{\\kappa-1} (1-\\sigma^{0}(r_{i}),\\sigma^{0}(r_{i}))}_{\\vdots} \\right]</span>$</p>

    <p class="text-gray-300"><span class="math">$\\vdots</span>$</p>

    <p class="text-gray-300"><span class="math">$------------------------------------</span>$</p>

    <p class="text-gray-300">To compute that matrix product, Hashcaster's prover would need to expend  <span class="math">\\Theta(2^{\\ell})</span>  <em>L</em>-multiplications, thereby incurring  <span class="math">\\Theta(2^{\\ell}) \\cdot \\mathbb{Q}(\\lambda)</span>  <em>K</em>-operations. That prover's cost would thus be worse than ours by a polylogarithmic factor in  <span class="math">\\lambda</span> , at least. As it turns out, by nontrivially using the Galois transformation (22), Hashcaster is able to bring its prover cost closer to ours, albeit with various <em>additive</em> polylogarithmic penalties in  <span class="math">\\lambda</span> . Its prover, on the other hand, is much more complicated, and runs the sumcheck using a non-blackbox algorithm.</p>

    <p class="text-gray-300">To compute the Galois transformation (18), Hashcaster's verifier must expend  <span class="math">2^{2 \\cdot \\kappa}</span>  L-multiplications, for a total cost of</p>

    <p class="text-gray-300"><span class="math">$2^{2 \\cdot \\kappa} \\cdot \\mathsf{Q}(\\lambda) = \\lambda^2 \\cdot \\mathsf{Q}(\\lambda) = \\widetilde{O}(\\lambda^3)</span>$</p>

    <p class="text-gray-300">K-operations. We thus see that Hashcaster's verifier's dependence on  <span class="math">\\lambda</span>  is cubic, as opposed to quadratic.</p>

    </section>

    <section id="sec-4" class="mb-10">
      <h2 class="text-2xl font-bold">4 Binary BaseFold</h2>

    <p class="text-gray-300">In this section, we present our large-field PCS. We have already sketched the main problem in Subsection 1.4 above; here, we record a few further details.</p>

    <p class="text-gray-300">The additive NTT. The additive NTT is the problem of evaluating a polynomial  <span class="math">P(X) = \\sum_{j=0}^{2^{\\ell}-1} a_j \\cdot X^j</span>  with coefficients in a binary field L, of degree less than  <span class="math">2^{\\ell}</span>  say, on some  <span class="math">\\ell</span> -dimensional  <span class="math">\\mathbb{F}_2</span> -linear subspace  <span class="math">S \\subset L</span> . In a classic and farsighted work, Cantor [Can89] introduces the additive NTT and devises an  <span class="math">O(2^{\\ell} \\cdot \\ell^{\\log_2(3)})</span> -time algorithm for it. In the specific case of  <span class="math">\\ell</span>  a power of 2, Gao and Mateer [GM10] further achieve the complexity  <span class="math">O(2^{\\ell} \\cdot \\ell \\cdot \\log \\ell)</span> .</p>

    <p class="text-gray-300">For some time, it was not known whether the characteristic  <span class="math">O(2^{\\ell} \\cdot \\ell)</span>  time complexity of the Cooley&ndash;Tukey algorithm could be attained in the additive case. In a key work, Lin, Chung and Han [LCH14] achieve exactly this feat, with a caveat: their algorithm interprets its input vector as P(X)'s coefficients not in the standard monomial basis, but in a novel polynomial basis that those authors introduce. That is, on the input  <span class="math">(a_0,\\ldots,a_{2^{\\ell}-1})</span> , their algorithm evaluates not  <span class="math">\\sum_{j=0}^{2^{\\ell}-1}a_j\\cdot X^j</span> , but rather  <span class="math">\\sum_{j=0}^{2^{\\ell}-1}a_j\\cdot X_j(X)</span> , over the domain  <span class="math">S\\subset L</span> ; here, for each  <span class="math">j\\in\\{0,\\ldots,2^{\\ell}-1\\}</span> ,  <span class="math">X_j(X)</span>  is an alternate basis polynomial&mdash;of degree j&mdash;that those authors describe. (The polynomials  <span class="math">(X_j(X))_{j=0}^{2^{\\ell}-1}</span>  span the L-vector space  <span class="math">L[X]^{\\prec 2^{\\ell}}</span> , so the &quot;space&quot; of polynomials that Lin, Chung and Han's algorithm serves to encode is the same as that of Cantor's.) Lin, Chung and Han [LCH14] build their basis polynomials  <span class="math">(X_j(X))_{j=0}^{2^{\\ell}-1}</span>  out of subspace vanishing polynomials. These are polynomials  <span class="math">\\widehat{W}_i(X)</span> , for  <span class="math">i\\in\\{0,\\ldots,\\ell\\}</span> , which respectively vanish identically on an ascending chain of  <span class="math">\\mathbb{F}_2</span> -subspaces  <span class="math">U_0\\subset\\cdots\\subset U_\\ell</span>  of L.</p>

    <p class="text-gray-300">Our binary adaptation of BaseFold PCS ties together two disparate threads: Lin, Chung and Han [LCH14]'s additive NTT and FRI [BBHR18a]. We recall that binary-field FRI works with the aid of a sequence of  <span class="math">\\mathbb{F}_2</span> -subspaces  <span class="math">S^{(0)}, \\ldots, S^{(\\ell)}</span>  of L, themselves connected by linear subspace polynomials:</p>

    <p class="text-gray-300"><span class="math">$S^{(0)} \\xrightarrow{q^{(0)}} S^{(1)} \\xrightarrow{q^{(1)}} S^{(2)} \\xrightarrow{q^{(2)}} \\cdots \\xrightarrow{q^{(\\ell-1)}} S^{(\\ell)}.</span>$</p>

    <p class="text-gray-300">Here, the maps  <span class="math">q^{(0)}, \\dots, q^{(\\ell-1)}</span>  are linear subspace polynomials of degree 2.</p>

    <p class="text-gray-300">Hab&ouml;ck, Levit and Papini [HLP24, &sect; 4.1] implicitly argue that, from <em>any</em> such chain of subspaces, &quot;an&quot; FFT arises. Our goal is to show that, for an appropriately chosen chain, Lin, Chung and Han's additive NTT can itself be made to arise.</p>

    <p class="text-gray-300">Choosing the folding maps. To use BaseFold PCS in characteristic 2, we must use the additive NTT instead of the standard one, and use binary-field FRI instead of prime-field FRI. Simple enough, but which domains  <span class="math">S^{(0)}, \\ldots, S^{(\\ell)}</span>  and which maps  <span class="math">q^{(0)}, \\ldots, q^{(\\ell-1)}</span>  should we use in the latter protocol? FRI [BBHR18a] does not suggest a canonical choice; each choice there works as well as any other. But BaseFold's FRI subprotocol is not just a proximity test; it's also a built-in multilinear evaluator (see Subsection 1.4). BaseFold PCS relies on the fact whereby a FRI execution which begins on the Reed&ndash;Solomon encoding of  <span class="math">(a_0, \\ldots, a_{2^{\\ell}-1})</span>  will end on the constant polynomial whose value on  <span class="math">S^{(\\ell)}</span>  is identically</p>

    <p class="text-gray-300">
<span class="math">$a_0 + a_1 \\cdot r_0&#x27; + a_2 \\cdot r_1&#x27; + a_3 \\cdot r_0&#x27; \\cdot r_1&#x27; + \\dots + a_{2\\ell-1} \\cdot r_0&#x27; \\cdot \\dots \\cdot r_{\\ell-1}&#x27;, \\tag{38}</span>$</p>

    <p class="text-gray-300">where  <span class="math">(r&#x27;_0, \\ldots, r&#x27;_{\\ell-1})</span>  are the verifier's FRI challenges. For maps  <span class="math">q^{(0)}, \\ldots, q^{(\\ell-1)}</span>  generically chosen, this fact will fail to hold.</p>

    <p class="text-gray-300">We recover BaseFold PCS in characteristic 2 by introducing a specialization of binary FRI that works compatibly with [LCH14]. That is, we introduce a particular choice of the maps  <span class="math">q^{(0)}, \\ldots, q^{(\\ell-1)}</span>  which causes the equality (38) to re-emerge. Interestingly, the right choice of  <span class="math">q^{(0)}, \\ldots, q^{(\\ell-1)}</span>  turns out to be that for which, for each  <span class="math">i \\in \\{0, \\ldots, \\ell\\}</span> , the composition identity</p>

    <p class="text-gray-300"><span class="math">$\\widehat{W}_i = q^{(i-1)} \\circ \\dots \\circ q^{(0)}</span>$</p>

    <p class="text-gray-300">holds. That is, we choose our FRI folding maps  <span class="math">q^{(0)}, \\ldots, q^{(\\ell-1)}</span>  so that they &quot;factor&quot; Lin, Chung and Han [LCH14]'s subspace vanishing polynomials.</p>

    <p class="text-gray-300">Oracle-skipping. Standard FRI [BBHR18a, &sect; 3.2] supports arbitrary-arity folding, controlled by a folding arity parameter  <span class="math">\\eta \\geq 1</span> . The parameter  <span class="math">\\eta</span>  mediates a tradeoff between the number of oracles committed (which grows like  <span class="math">\\frac{\\ell}{\\eta}</span> ) and the size of each Merkle leaf (which grows like  <span class="math">2^{\\eta}</span> ). The &quot;sweet spot&quot; tends to be around  <span class="math">\\eta = 4</span> , in practical deployments. The effect on proof size at stake&mdash;i.e., which one stands to induce, upon changing  <span class="math">\\eta</span>  from 1 to something better&mdash;is significant (amounting to a halving at least, if not better). In rough terms, FRI stipulates that, to fold a given oracle using the parameter  <span class="math">\\eta</span> , the prover interpolate a univariate polynomial of degree less than  <span class="math">2^{\\eta}</span>  on each coset of the relevant oracle, and finally evaluate the resulting univariate polynomials collectively at the verifier's challenge point.</p>

    <p class="text-gray-300">BaseFold PCS does not support the use of univariate higher-arity folding. BaseFold, instantiated using a FRI folding arity parameter  <span class="math">\\eta &gt; 1</span> , would break (38) in essentially two ways. For one, the number of challenges  <span class="math">r&#x27;_i</span>  available would become too few (something like  <span class="math">\\frac{\\ell}{\\eta}</span> , as opposed to  <span class="math">\\ell</span> ). Moreover, the relationship between the list  <span class="math">(a_0, \\ldots, a_{2^{\\ell}-1})</span>  and the value of the final constant FRI oracle would become that of a multivariate evaluation&mdash;of individual degree less than  <span class="math">2^{\\eta}</span> &mdash;over the challenges  <span class="math">r&#x27;_i</span> , as opposed to of a multilinear one. For this reason, BaseFold as written remains unable to draw on the proof-size gains available at the hands of higher-arity folding, which are significant. This fact is noted by WHIR [ACFY25, &sect; 1.1].</p>

    <p class="text-gray-300">We introduce a new, multilinear style of many-to-one FRI folding, different from FRI's univariate approach [BBHR18a, &sect; 3.2]. We describe our FRI folding variant in Subsection 4.2 below (see in particular Definitions 4.6 and 4.8). We parameterize our method by a constant  <span class="math">\\vartheta</span>  that plays a role analogous to  <span class="math">\\eta</span> 's. Informally, we stipulate that the verifier send  <span class="math">\\vartheta</span>  folding challenges, and that the prover fold its oracle, again coset-wise, using a length- <span class="math">2^{\\vartheta}</span>  tensor combination of the verifier's challenges over each coset. Equivalently, we insist that the prover perform standard, 2-to-1 folding  <span class="math">\\vartheta</span>  times in succession&mdash;consuming  <span class="math">\\vartheta</span>  challenges in the process, as opposed to 1&mdash;and commit only to the last among the oracles it obtains in this way. (For this reason, we call our technique oracle-skipping.) Our folding technique makes necessary a sort of proximity gap different from that invoked by the standard FRI protocol. Indeed, while the soundness proof [Ben+23, &sect; 8.2] of FRI uses the proximity gap [Ben+23, Thm. 1.5] for low-degree parameterized curves, our security treatment below uses a tensor-folding proximity gap of the sort recently established by Diamond and Posen [DP24, Thm. 2]. In fact, we use a sharpening of that result due to Diamond and Gruen [DG25, Cor. 1]. Oracle-skipping&mdash;understood as a FRI variant, leave aside BaseFold&mdash;is simpler, easier to implement and more sound than higher-arity univariate folding is; on the other hand, its proof of security depends on the new work [DG25]. We refer to Diamond and Gruen [DG25, &sect; 1.5] for more remarks on these matters.</p>

    <h3 id="sec-misc-4" class="text-xl font-semibold mt-8"><strong>Practical matters.</strong> We examine various further aspects of binary-field FRI.</h3>

    <p class="text-gray-300">We first opt to modify FRI itself, so as to induce a Lagrange-style, as opposed to a monomial-style, 2-to-1 folding pattern in the coefficient domain. In our FRI variant, the value of the prover's final oracle becomes rather</p>

    <p class="text-gray-300"><span class="math">$a_0 \\cdot (1 - r_0) \\cdot \\cdots \\cdot (1 - r_{\\ell-1}) + \\cdots + a_{2^{\\ell} - 1} \\cdot r_0 \\cdot \\cdots \\cdot r_{\\ell-1},</span>$</p>

    <p class="text-gray-300">the evaluation at  <span class="math">(r_0, \\ldots, r_{\\ell-1})</span>  of the polynomial whose coefficients in the <em>multilinear Lagrange basis</em>&mdash;as opposed to in the multilinear monomial basis&mdash;are  <span class="math">(a_0, \\ldots, a_{2\\ell-1})</span> . (We explain this further in Remark 4.7.)</p>

    <p class="text-gray-300">Separately, even in the abstract IOP model, we must fix  <span class="math">\\mathbb{F}_2</span> -bases of the respective Reed&ndash;Solomon domains  <span class="math">S^{(i)}</span> , in order to interpret our committed functions  <span class="math">f^{(i)}: S^{(i)} \\to L</span>  as L-valued strings. That is, we must implicitly lexicographically flatten each domain  <span class="math">S^{(i)}</span> , using some ordered  <span class="math">\\mathbb{F}_2</span> -bases of it, known to both the prover and the verifier. The choice of these bases matters. Indeed, for  <span class="math">\\mathbb{F}_2</span> -bases of  <span class="math">S^{(i)}</span>  and  <span class="math">S^{(i+1)}</span>  chosen arbitrarily, the fundamental operation which associates to each  <span class="math">y \\in S^{(i+1)}</span>  its fiber  <span class="math">q^{(i)^{-1}}(\\{y\\}) \\subset S^{(i)}</span> &mdash;which both the prover and the verifier must perform repeatedly&mdash;could come to assume complexity on the order of  <span class="math">\\dim(S^{(i)})^2</span>  bit-operations, even after a linear-algebraic preprocessing phase.</p>

    <p class="text-gray-300">We suggest a family of bases for the respective domains  <span class="math">S^{(i)}</span>  with respect to which the maps  <span class="math">q^{(i)}</span>  come to act simply by projecting away their first coordinate. In particular, the application of each map  <span class="math">q^{(i)}</span> &mdash;in coordinates&mdash;becomes free; the preimage operation  <span class="math">q^{(i)^{-1}}(\\{y\\})</span>  comes to amount simply to that of prepending an arbitrary boolean coordinate to y's coordinate representation. While bases with these properties can of course be constructed in FRI even for maps  <span class="math">q^{(i)}</span>  chosen arbitrarily, our procedure moreover yields a basis of the initial domain  <span class="math">S^{(0)}</span>  which coincides with that expected by the additive NTT [LCH14]. In particular, our prover may use as is the output of the additive NTT as its  <span class="math">0^{th}</span>  FRI oracle, without first subjecting that output to the permutation induced by an appropriate change-of-basis transformation on  <span class="math">S^{(0)}</span> .</p>

      <h3 id="sec-4.1" class="text-xl font-semibold mt-8">4.1 Using FRI in Novel Polynomial Basis</h3>

    <p class="text-gray-300">We begin by proposing a specific construction of those subspace polynomials  <span class="math">q^{(0)}, \\ldots, q^{(\\ell-1)}</span>  invoked internally by FRI. Throughout this section, we fix a binary field L, with  <span class="math">\\mathbb{F}_2</span> -basis  <span class="math">(\\beta_0, \\ldots, \\beta_{r-1})</span> . Throughout the remainder of this subsection&mdash;and in fact, the entire paper&mdash;we impose the simplifying assumption whereby  <span class="math">\\beta_0 = 1</span> . We fix moreover a size parameter  <span class="math">\\ell \\in \\{0, \\ldots, r-1\\}</span>  and a rate parameter  <span class="math">\\mathcal{R} \\in \\{1, \\ldots, r-\\ell\\}</span> . We finally recall the subspace vanishing polynomials  <span class="math">\\widehat{W}_i(X) \\in L[X]</span> , for  <span class="math">i \\in \\{0, \\ldots, \\ell\\}</span> , which we now view as  <span class="math">\\mathbb{F}_2</span> -linear maps  <span class="math">\\widehat{W}_i : L \\to L</span> , as well as their non-normalized counterparts  <span class="math">W_i : L \\to L</span>  (see Subsection 2.3). We begin by defining our FRI domains and folding maps.</p>

    <p class="text-gray-300"><strong>Definition 4.1.</strong> For each  <span class="math">i \\in \\{0, ..., \\ell\\}</span> , we define the domain</p>

    <p class="text-gray-300"><span class="math">$S^{(i)} := \\widehat{W}_i(\\langle \\beta_0, \\dots, \\beta_{\\ell+\\mathcal{R}-1} \\rangle).</span>$</p>

    <p class="text-gray-300">Moreover, for each  <span class="math">i \\in \\{0, \\dots, \\ell - 1\\}</span> , we define</p>

    <p class="text-gray-300"><span class="math">$q^{(i)}(X) := \\frac{W_i(\\beta_i)^2}{W_{i+1}(\\beta_{i+1})} \\cdot X \\cdot (X+1).</span>$</p>

    <p class="text-gray-300">For each  <span class="math">i \\in \\{0, \\dots, \\ell-1\\}</span> , the map  <span class="math">q^{(i)}(X)</span>  is a linear subspace polynomial of degree 2. A priori, this map's kernel could relate arbitrarily to the domain  <span class="math">S^{(i)} \\subset L</span> ; moreover, the image of its restriction to  <span class="math">S^{(i)}</span>  could relate arbitrarily to  <span class="math">S^{(i+1)}</span> . In the following sequence of results, we prove that in fact  <span class="math">q^{(i)}(S^{(i)}) = S^{(i+1)}</span>  holds for each  <span class="math">i \\in \\{0, \\dots, \\ell-1\\}</span> . In particular, the chain of maps  <span class="math">q^{(0)}, \\dots, q^{(\\ell-1)}</span>  and the spaces  <span class="math">S^{(0)}, \\dots, S^{(\\ell)}</span>  yield a valid global parameterization of the FRI protocol (in the sense of Subsection 2.4).</p>

    <p class="text-gray-300"><strong>Lemma 4.2.</strong> For each  <span class="math">i \\in \\{0, ..., \\ell-1\\}</span> , we have the equality  <span class="math">q^{(i)} \\circ \\widehat{W}_i = \\widehat{W}_{i+1}</span>  of polynomials.</p>

    <p class="text-gray-300"><em>Proof.</em> We invoke the following direct calculation:</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\Big(q^{(i)} \\circ \\widehat{W}_i\\Big)(X) &amp;= \\frac{W_i(\\beta_i)^2}{W_{i+1}(\\beta_{i+1})} \\cdot \\widehat{W}_i(X) \\cdot \\Big(\\widehat{W}_i(X) + 1\\Big) &amp; \\text{(by definition of } q^{(i)}.) \\\\ &amp;= \\frac{W_i(\\beta_i)^2}{W_{i+1}(\\beta_{i+1})} \\cdot \\frac{W_i(X)}{W_i(\\beta_i)} \\cdot \\frac{W_i(X) + W_i(\\beta_i)}{W_i(\\beta_i)} &amp; \\text{(by definition of } \\widehat{W}_i.) \\\\ &amp;= \\frac{W_i(X) \\cdot (W_i(X) + W_i(\\beta_i))}{W_{i+1}(\\beta_{i+1})} &amp; \\text{(cancellation of } W_i(\\beta_i)^2.) \\\\ &amp;= \\frac{W_{i+1}(X)}{W_{i+1}(\\beta_{i+1})} &amp; \\text{(recursive characterization of } W_{i+1}(X).) \\\\ &amp;= \\widehat{W}_{i+1}(X). &amp; \\text{(by definition of } \\widehat{W}_{i+1}(X).) \\end{split}</span>$</p>

    <p class="text-gray-300">In the second-to-last step, we exploit the recursive identity  <span class="math">W_{i+1}(X) = W_i(X) \\cdot (W_i(X) + W_i(\\beta_i))</span> , itself a basic consequence of the definitions of  <span class="math">W_{i+1}</span>  and  <span class="math">W_i</span>  and of the linearity of  <span class="math">W_i</span> .</p>

    <p class="text-gray-300"><strong>Theorem 4.3.</strong> For each  <span class="math">i \\in \\{0, ..., \\ell - 1\\}</span> ,  <span class="math">q^{(i)}(S^{(i)}) = S^{(i+1)}</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> Using Lemma 4.2, we obtain:</p>

    <p class="text-gray-300"><span class="math">$q^{(i)}\\left(S^{(i)}\\right) = q^{(i)}\\left(\\widehat{W}_i(\\langle \\beta_0, \\dots, \\beta_{\\ell+\\mathcal{R}-1}\\rangle)\\right)</span>$
(by definition of  <span class="math">S^{(i)}</span> .)
<span class="math">$= \\widehat{W}_{i+1}(\\langle \\beta_0, \\dots, \\beta_{\\ell+\\mathcal{R}-1}\\rangle)</span>$
(by Lemma 4.2.)
<span class="math">$= S^{(i+1)}.</span>$
(again by definition of  <span class="math">S^{(i+1)}</span> .)</p>

    <p class="text-gray-300">This completes the proof.</p>

    <p class="text-gray-300">In the following further corollary of Lemma 4.2, we argue that the polynomials  <span class="math">q^{(0)}, \\ldots, q^{(\\ell-1)}</span>  collectively &quot;factor&quot; the normalized subspace polynomials  <span class="math">\\widehat{W}_0, \\ldots, \\widehat{W}_\\ell</span> , at least provided we assume  <span class="math">\\beta_0 = 1</span> .</p>

    <p class="text-gray-300">Corollary 4.4. For each  <span class="math">i \\in \\{0, \\dots, \\ell\\}</span> ,  <span class="math">\\widehat{W}_i = q^{(i-1)} \\circ \\dots \\circ q^{(0)}</span>  holds.</p>

    <p class="text-gray-300"><em>Proof.</em> In the base case i = 0, we must show that  <span class="math">\\widehat{W}_0</span>  equals the empty composition (namely X itself). To show this, we recall first that  <span class="math">W_0(X) = X</span> . Moreover:</p>

    <p class="text-gray-300"><span class="math">$\\widehat{W}_0(X) = \\frac{X}{W_0(\\beta_0)} = \\frac{X}{\\beta_0} = X;</span>$</p>

    <p class="text-gray-300">in the last step, we use our global assumption whereby  <span class="math">\\beta_0 = 1</span> .</p>

    <p class="text-gray-300">For  <span class="math">i \\in \\{1, \\dots, \\ell\\}</span>  arbitrary, Lemma 4.2 shows that  <span class="math">\\widehat{W}_i = q^{(i-1)} \\circ \\widehat{W}_{i-1}</span> . Applying this corollary inductively to to  <span class="math">\\widehat{W}_{i-1}</span> , we conclude that this latter map in turn equals  <span class="math">q^{(i-1)} \\circ q^{(i-2)} \\circ \\cdots \\circ q^{(0)}</span> .</p>

    <p class="text-gray-300">We note finally the following result.</p>

    <p class="text-gray-300">Corollary 4.5. For each
<span class="math">$i \\in \\{0, ..., \\ell\\}</span>$
, the set  <span class="math">\\left(\\widehat{W}_i(\\beta_i), ..., \\widehat{W}_i(\\beta_{\\ell+R-1})\\right)</span>  is an  <span class="math">\\mathbb{F}_2</span> -basis of the space  <span class="math">S^{(i)}</span> .</p>

    <p class="text-gray-300">Proof. Indeed, the subspace  <span class="math">V_i := \\langle \\beta_i, \\dots, \\beta_{\\ell+\\mathcal{R}-1} \\rangle</span>  is clearly a subspace of  <span class="math">\\langle \\beta_0, \\dots, \\beta_{\\ell+\\mathcal{R}-1} \\rangle</span> , so that in turn  <span class="math">\\widehat{W}_i(V_i) \\subset \\widehat{W}_i(\\langle \\beta_0, \\dots, \\beta_{\\ell+\\mathcal{R}-1} \\rangle)</span> , which itself equals  <span class="math">S^{(i)}</span>  (by Definition 4.1). On the other hand, the restriction of  <span class="math">\\widehat{W}_i</span>  to  <span class="math">V_i</span>  is necessarily injective, since  <span class="math">\\widehat{W}_i</span> 's kernel  <span class="math">\\langle \\beta_0, \\dots, \\beta_{i-1} \\rangle</span>  intersects  <span class="math">V_i</span>  trivially. Since  <span class="math">S^{(i)}</span>  is  <span class="math">\\ell + \\mathcal{R} - i</span> -dimensional, we conclude by a dimension count that  <span class="math">(\\widehat{W}_i(\\beta_i), \\dots, \\widehat{W}_i(\\beta_{\\ell+\\mathcal{R}-1}))</span>  spans  <span class="math">S^{(i)}</span> .  <span class="math">\\square</span></p>

    <p class="text-gray-300">The bases  <span class="math">\\left\\langle \\widehat{W}_i(\\beta_i), \\ldots, \\widehat{W}_i(\\beta_{\\ell+\\mathcal{R}-1}) \\right\\rangle = S^{(i)}</span> , for  <span class="math">i \\in \\{0, \\ldots, \\ell\\}</span> , simplify various aspects of our protocol's implementation. For example, expressed in coordinates with respect to these bases, each map  <span class="math">q^{(i)}: S^{(i)} \\to S^{(i+1)}</span>  acts simply by projecting away its  <span class="math">0^{\\text{th}}</span> -indexed component (indeed, for each  <span class="math">i \\in \\{0, \\ldots, \\ell-1\\}</span> ,  <span class="math">q^{(i)}</span>  maps  <span class="math">(\\widehat{W}_i(\\beta_i), \\ldots, \\widehat{W}_i(\\beta_{\\ell+\\mathcal{R}-1}))</span>  to  <span class="math">(0, \\widehat{W}_{i+1}(\\beta_{i+1}), \\ldots, \\widehat{W}_{i+1}(\\beta_{\\ell+\\mathcal{R}-1})))</span> . Similarly, for each  <span class="math">i \\in \\{0, \\ldots, \\ell-1\\}</span>  and each  <span class="math">y \\in S^{(i+1)}</span> , the two L-elements  <span class="math">x \\in S^{(i)}</span>  for which  <span class="math">q^{(i)}(x) = y</span>  differ precisely at their  <span class="math">0^{\\text{th}}</span>  components, and elsewhere agree with y's coordinate representation. Below, we often identify  <span class="math">S^{(i)} \\cong \\mathcal{B}_{\\ell+\\mathcal{R}-i}</span>  as sets, using these bases; moreover, where possible, we eliminate altogether the maps  <span class="math">q^{(0)}, \\ldots, q^{(\\ell-1)}</span>  from our descriptions. These measures make our protocol's description and implementation more transparent.</p>

      <h3 id="sec-4.2" class="text-xl font-semibold mt-8">4.2 FRI Folding, Revisited</h3>

    <p class="text-gray-300">We now introduce a new FRI-like folding mechanism. Below, we again write L for a binary field.</p>

    <p class="text-gray-300"><strong>Definition 4.6.</strong> We fix an index  <span class="math">i \\in \\{0, \\dots, \\ell-1\\}</span>  and a map  <span class="math">f^{(i)}: S^{(i)} \\to L</span> . For each  <span class="math">r \\in L</span> , we define the map fold  <span class="math">(f^{(i)}, r): S^{(i+1)} \\to L</span>  by setting, for each  <span class="math">y \\in S^{(i+1)}</span> :</p>

    <p class="text-gray-300"><span class="math">$\\operatorname{fold} \\Big( f^{(i)}, r \\Big) : y \\mapsto \\begin{bmatrix} 1 - r &amp; r \\end{bmatrix} \\cdot \\begin{bmatrix} x_1 &amp; -x_0 \\\\ -1 &amp; 1 \\end{bmatrix} \\cdot \\begin{bmatrix} f^{(i)}(x_0) \\\\ f^{(i)}(x_1) \\end{bmatrix},</span>$</p>

    <p class="text-gray-300">where we write  <span class="math">(x_0, x_1) \\coloneqq q^{(i)^{-1}}(\\{y\\})</span>  for the fiber of  <span class="math">q^{(i)}</span>  over  <span class="math">y \\in S^{(i+1)}</span> .</p>

    <p class="text-gray-300">Remark 4.7. Definition 4.6's quantity  <span class="math">\\operatorname{fold}(f^{(i)},r)(y)</span>  is similar&mdash;and yet not equivalent&mdash;to FRI's interpolant  <span class="math">\\left(f^{(i)}\\big|_{q^{(i)^{-1}}(\\{y\\})}\\right)(r)</span> . (FRI's variant, on the other hand, admits a similar matrix-based characterization.) The essential point is that FRI's variant induces a <em>monomial</em> fold, as opposed to a <em>Lagrange</em> fold, in the coefficient domain. If we used FRI's variant instead of our own, then something like our Lemma 4.14 would stay true, albeit rather with the conclusion  <span class="math">P^{(i+1)}(X) = \\sum_{j=0}^{2^{\\ell-i-1}-1} (a_{2j} + r&#x27;_i \\cdot a_{2j+1}) \\cdot X_j^{(i+1)}(X)</span> . Our entire theory can be carried out in that &quot;parallel&quot; setting, though further complications arise there.</p>

    <p class="text-gray-300">We finally record the following iterated extension of Definition 4.6.</p>

    <p class="text-gray-300"><strong>Definition 4.8.</strong> We fix a positive folding factor  <span class="math">\\vartheta</span> , an index  <span class="math">i \\in \\{0, \\dots, \\ell - \\vartheta\\}</span> , and a map  <span class="math">f^{(i)}: S^{(i)} \\to L</span> . For each tuple  <span class="math">(r_0, \\dots, r_{\\vartheta-1}) \\in L^{\\vartheta}</span> , we abbreviate  <span class="math">\\mathsf{fold}(f^{(i)}, r_0, \\dots, r_{\\vartheta-1}) \\coloneqq \\mathsf{fold}(\\dots \\mathsf{fold}(f^{(i)}, r_0), \\dots, r_{\\vartheta-1})</span> .</p>

    <p class="text-gray-300">We have the following mathematical characterization of this iterated folding operation:</p>

    <p class="text-gray-300"><strong>Lemma 4.9.</strong> For each positive folding factor  <span class="math">\\vartheta</span> , each index  <span class="math">i \\in \\{0, \\dots, \\ell - \\vartheta\\}</span> , and each  <span class="math">y \\in S^{(i+\\vartheta)}</span> , there is a  <span class="math">2^{\\vartheta} \\times 2^{\\vartheta}</span>  invertible matrix  <span class="math">M_y</span> , which depends only on  <span class="math">y \\in S^{(i+\\vartheta)}</span> , such that, for each function  <span class="math">f^{(i)}: S^{(i)} \\to L</span>  and each tuple  <span class="math">(r_0, \\dots, r_{\\vartheta-1}) \\in L^{\\vartheta}</span>  of folding challenges, we have the matrix identity:</p>

    <p class="text-gray-300"><span class="math">$\\operatorname{fold}\\Bigl(f^{(i)},r_0,\\ldots,r_{\\vartheta-1}\\Bigr)(y) = \\left[ \\quad \\bigotimes_{j=0}^{\\vartheta-1}(1-r_j,r_j) \\quad \\right] \\cdot \\left[ \\qquad M_y \\qquad \\right] \\cdot \\left[ \\begin{matrix} f^{(i)}(x_0) \\\\ \\vdots \\\\ f^{(i)}(x_{2^\\vartheta-1}) \\end{matrix} \\right],</span>$</p>

    <p class="text-gray-300">where the right-hand vector's values  <span class="math">(x_0, \\ldots, x_{2^{\\vartheta}-1})</span>  represent the fiber  <span class="math">(q^{(i+\\vartheta-1)} \\circ \\cdots \\circ q^{(i)})^{-1}(\\{y\\}) \\subset S^{(i)}</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> We prove the result by induction on  <span class="math">\\vartheta</span> . In the base case  <span class="math">\\vartheta = 1</span> , the claim is a tautology, in view of</p>

    <p class="text-gray-300">Definition 4.6. We note that that definition's matrix  <span class="math">\\begin{bmatrix} x_1 &amp; -x_0 \\\\ -1 &amp; 1 \\end{bmatrix}</span>  is invertible, since its determinant  <span class="math">x_1 - x_0</span></p>

    <p class="text-gray-300">is nonzero (and in fact equals 1, a fact we shall use below).</p>

    <p class="text-gray-300">We thus fix a folding factor  <span class="math">\\vartheta &gt; 1</span> , and suppose that the claim holds for  <span class="math">\\vartheta - 1</span> . We write  <span class="math">(z_0, z_1) := q^{(i+\\vartheta-1)^{-1}}(\\{y\\})</span> , as well as  <span class="math">(x_0, \\ldots, x_{2^\\vartheta-1}) := \\left(q^{(i+\\vartheta-1)} \\circ \\cdots \\circ q^{(i)}\\right)^{-1}(\\{y\\})</span> . Unwinding Definition 4.8, we recursively express the relevant quantity  <span class="math">\\operatorname{fold}(f^{(i)}, r_0, \\ldots, r_{\\vartheta-1})(y)</span> &mdash;which, for typographical reasons, we call  <span class="math">\\mathfrak{f}</span> &mdash;in the following way:</p>

    <p class="text-gray-300"><span class="math">$\\mathfrak{f} = \\begin{bmatrix} 1 - r_{\\vartheta - 1} &amp; r_{\\vartheta - 1} \\end{bmatrix} \\cdot \\begin{bmatrix} z_1 &amp; -z_0 \\\\ -1 &amp; 1 \\end{bmatrix} \\cdot \\begin{bmatrix} \\operatorname{fold} \\left( f^{(i)}, r_0, \\dots, r_{\\vartheta - 2} \\right) (z_0) \\\\ \\operatorname{fold} \\left( f^{(i)}, r_0, \\dots, r_{\\vartheta - 2} \\right) (z_1) \\end{bmatrix}</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\begin{bmatrix} 1 - r_{\\vartheta - 1} &amp; r_{\\vartheta - 1} \\end{bmatrix} \\cdot \\underbrace{\\begin{bmatrix} z_1 &amp; -z_0 \\\\ -1 &amp; 1 \\end{bmatrix} \\cdot \\begin{bmatrix} \\bigotimes_{j=0}^{\\vartheta - 2} (1 - r_j, r_j) &amp; \\\\ &amp; \\bigotimes_{j=0}^{\\vartheta - 2} (1 - r_j, r_j) \\end{bmatrix}}_{\\text{these matrices may be interchanged.}} \\cdot \\begin{bmatrix} M_{z_0} &amp; \\\\ &amp; &amp; \\\\ &amp; &amp; \\end{bmatrix} \\cdot \\begin{bmatrix} f^{(i)}(x_0) &amp; \\\\ \\vdots &amp; \\\\ f^{(i)}(x_{2^{\\vartheta} - 1}) \\end{bmatrix}.</span>$</p>

    <p class="text-gray-300">In the second step above, we apply the inductive hypothesis on both  <span class="math">z_0</span>  and  <span class="math">z_1</span> . That hypothesis furnishes the nonsingular,  <span class="math">2^{\\vartheta-1} \\times 2^{\\vartheta-1}</span>  matrices  <span class="math">M_{z_0}</span>  and  <span class="math">M_{z_1}</span> ; we note moreover that the union of the fibers  <span class="math">\\left(q^{(i+\\vartheta-2)} \\circ \\cdots \\circ q^{(i)}\\right)^{-1}(\\{z_0\\})</span>  and  <span class="math">\\left(q^{(i+\\vartheta-2)} \\circ \\cdots \\circ q^{(i)}\\right)^{-1}(\\{z_1\\})</span>  is precisely  <span class="math">\\left(q^{(i+\\vartheta-1)} \\circ \\cdots \\circ q^{(i)}\\right)^{-1}(\\{y\\})</span> . Interchanging the two matrices bracketed above, we further reexpress this quantity as:</p>

    <p class="text-gray-300"><span class="math">$= \\begin{bmatrix} 1 - r_{\\vartheta-1} &amp; r_{\\vartheta-1} \\end{bmatrix} \\cdot \\begin{bmatrix} \\underbrace{\\bigotimes_{j=0}^{\\vartheta-2} (1 - r_j, r_j)}^{\\vartheta-2} \\\\ &amp; \\underbrace{\\bigotimes_{j=0}^{\\vartheta-2} (1 - r_j, r_j)} \\end{bmatrix} \\cdot \\begin{bmatrix} \\underbrace{\\deg(z_1) &amp; \\deg(z_2)}^{\\operatorname{diag}(z_1)} \\\\ &amp; \\underbrace{\\deg(z_1)}^{\\operatorname{diag}(z_2)} \\end{bmatrix} \\cdot \\begin{bmatrix} \\underbrace{M_{z_0}} \\\\ &amp; \\underbrace{M_{z_1}} \\end{bmatrix} \\cdot \\begin{bmatrix} f^{(i)}(x_0) \\\\ \\vdots \\\\ f^{(i)}(x_{2^{\\vartheta}-1}) \\end{bmatrix}.</span>$</p>

    <p class="text-gray-300">By the standard recursive substructure of the tensor product, the product of the left-hand two matrices equals exactly  <span class="math">\\bigotimes_{j=0}^{\\vartheta-1}(1-r_j,r_j)</span> . On the other hand, the product of the two  <span class="math">2^{\\vartheta}\\times 2^{\\vartheta}</span>  nonsingular matrices above is itself nonsingular, and supplies the required  <span class="math">2^{\\vartheta}\\times 2^{\\vartheta}</span>  matrix  <span class="math">M_y</span> .</p>

    <p class="text-gray-300">We emphasize that, in Lemma 4.9, the matrix  <span class="math">M_y</span>  depends only on  <span class="math">y \\in S^{(i+\\vartheta)}</span> &mdash;and of course on  <span class="math">\\vartheta</span>  and  <span class="math">i \\in \\{0, \\ldots, \\ell - \\vartheta\\}</span> &mdash;and not on the map  <span class="math">f^{(i)}</span>  or the folding challenges  <span class="math">(r_0, \\ldots, r_{\\vartheta-1}) \\in L^{\\vartheta}</span> .</p>

    <p class="text-gray-300"><strong>Remark 4.10.</strong> Interestingly, the matrix  <span class="math">M_y</span>  of Lemma 4.9 is nothing other than that of the <em>inverse additive</em> NTT [LCH14, &sect; III. C.] on the coset  <span class="math">(x_0, \\ldots, x_{2^{\\vartheta}-1})</span> ; i.e., it's the matrix which, on input the evaluations of some polynomial of degree less than  <span class="math">2^{\\vartheta}</span>  on the set of elements  <span class="math">(x_0, \\ldots, x_{2^{\\vartheta}-1})</span> , returns the coefficients&mdash;with respect to the  <span class="math">i^{\\text{th}}</span> -order novel basis (see Remark 4.16 below)&mdash;of that polynomial.</p>

    <p class="text-gray-300"><strong>Remark 4.11.</strong> On input some map  <span class="math">f^{(i)}: S^{(i)} \\to L</span> &mdash;expressed as a list of values let's say, via the identification  <span class="math">S^{(i)} \\cong \\mathcal{B}_{\\ell+\\mathcal{R}-i}</span>  discussed above&mdash;and a tuple  <span class="math">(r_0,\\ldots,r_{\\vartheta-1})</span>  of folding challenges, one can efficiently compute the table of values of  <span class="math">\\mathsf{fold}(f^{(i)},r_0,\\ldots,r_{\\vartheta-1}):S^{(i+\\vartheta)}\\to L</span> . Indeed, Definitions 4.6 and 4.8 directly suggest a  <span class="math">\\vartheta</span> -pass,  <span class="math">\\Theta(|S^{(i)}|)</span> -time algorithm for this task. Lemma 4.9 is not interesting algorithmically, but mathematically; it appears in our security proof below (see Theorem 4.17, and in particular Proposition 4.21).</p>

      <h3 id="sec-4.3" class="text-xl font-semibold mt-8">4.3 Our Large-Field IOPCS</h3>

    <p class="text-gray-300">We now present our binary adaptation of BaseFold's IOPCS [ZCF24, &sect; 5], itself based on the material of our Subsections 4.1 and 4.2 above. In order to present a notationally simpler variant of our protocol, we assume below that  <span class="math">\\vartheta \\mid \\ell</span> ; this requirement is not necessary.</p>

    <h3 id="sec-misc-5" class="text-xl font-semibold mt-8">CONSTRUCTION 4.12 (Binary BaseFold IOPCS).</h3>

    <p class="text-gray-300">We define  <span class="math">\\Pi = (\\mathsf{Setup}, \\mathsf{Commit}, \\mathcal{P}, \\mathcal{V})</span>  as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>params  <span class="math">\\leftarrow \\Pi.\\mathsf{Setup}(1^{\\lambda},\\ell)</span> . On input  <span class="math">1^{\\lambda}</span>  and  <span class="math">\\ell</span> , choose a constant, positive rate parameter  <span class="math">\\mathcal{R} \\in \\mathbb{N}</span> and a binary field  <span class="math">L/\\mathbb{F}_2</span>  whose degree r (say) over  <span class="math">\\mathbb{F}_2</span>  satisfies  <span class="math">r = \\omega(\\log \\lambda)</span>  and  <span class="math">r \\ge \\ell + \\mathcal{R}</span> . Initialize the vector oracle  <span class="math">\\mathcal{F}_{\\text{Vec}}^L</span> . Fix a folding factor  <span class="math">\\vartheta \\mid \\ell</span>  and a repetition parameter  <span class="math">\\gamma = \\omega(\\log \\lambda)</span> . Fix an arbitrary  <span class="math">\\mathbb{F}_2</span> -basis  <span class="math">(\\beta_0,\\ldots,\\beta_{r-1})</span>  of L. Write  <span class="math">(X_0(X),\\ldots,X_{2^{\\ell}-1}(X))</span>  for the resulting novel L-basis of  <span class="math">L[X]^{\\prec 2^{\\ell}}</span> , and fix the domains  <span class="math">S^{(0)}, \\ldots, S^{(\\ell)}</span>  and the polynomials  <span class="math">q^{(0)}, \\ldots, q^{(\\ell-1)}</span>  as in Subsection 4.1. Write  <span class="math">C^{(0)} \\subset L^{2^{\\ell+\\mathcal{R}}}</span>  for the Reed&ndash;Solomon code  <span class="math">\\mathsf{RS}_{L,S^{(0)}}[2^{\\ell+\\mathcal{R}},2^{\\ell}]</span> .</li>
    </ol></li>
      <li>2.  <span class="math">[f] \\leftarrow \\Pi.\\mathsf{Commit}(\\mathsf{params},t)</span> . On input  <span class="math">t(X_0,\\ldots,X_{\\ell-1}) \\in L[X_0,\\ldots,X_{\\ell-1}]^{\\leq 1}</span> , use t's Lagrange coefficients  <span class="math">(t(w))_{w \\in \\mathcal{B}_{\\ell}}</span>  as the coefficients, in the novel polynomial basis, of a univariate polynomial  <span class="math">P(X) := \\sum_{w \\in \\mathcal{B}_{\\ell}} t(w) \\cdot X_{\\{w\\}}(X)</span> , say. Using Algorithm 2, compute the Reed&ndash;Solomon codeword  <span class="math">f: S^{(0)} \\to L</span>  defined by  <span class="math">f: x \\mapsto P(x)</span> . Submit (submit,  <span class="math">\\ell + \\mathcal{R}, f</span> ) to the vector oracle  <span class="math">\\mathcal{F}^L_{\\mathsf{Vec}}</span> . Upon receiving (receipt,  <span class="math">\\ell + \\mathcal{R}, [f]</span> ) from  <span class="math">\\mathcal{F}^L_{\\mathsf{Vec}}</span> , output the handle [f].</li>
    </ul>

    <p class="text-gray-300">We define  <span class="math">(\\mathcal{P}, \\mathcal{V})</span>  as the following IOP, in which both parties have the common input [f],  <span class="math">s \\in L</span> , and  <span class="math">(r_0,\\ldots,r_{\\ell-1})\\in L^\\ell</span> , and  <span class="math">\\mathcal{P}</span>  has the further input  <span class="math">t(X_0,\\ldots,X_{\\ell-1})\\in L[X_0,\\ldots,X_{\\ell-1}]^{\\leq 1}</span> .</p>

    <pre><code class="language-text">1. \\mathcal{P} writes h(X_0, \\dots, X_{\\ell-1}) := \\widetilde{eq}(r_0, \\dots, r_{\\ell-1}, X_0, \\dots, X_{\\ell-1}) \\cdot t(X_0, \\dots, X_{\\ell-1}).
</code></pre>

    <p class="text-gray-300">2.  <span class="math">\\mathcal{P}</span>  and  <span class="math">\\mathcal{V}</span>  both abbreviate  <span class="math">f^{(0)} := f</span>  and  <span class="math">s_0 := s</span> , and execute the following loop:</p>

    <pre><code class="language-text">1: for i \\in \\{0, \\dots, \\ell - 1\\} do
</code></pre>

    <pre><code class="language-text">\\mathcal{P} sends \\mathcal{V} the polynomial h_i(X) \\coloneqq \\sum_{w \\in \\mathcal{B}_{\\ell-i-1}} h(r&#x27;_0, \\dots, r&#x27;_{i-1}, X, w_0, \\dots, w_{\\ell-i-2}).
</code></pre>

    <p class="text-gray-300">3:
<span class="math">$\\mathcal{V}</span>$
requires  <span class="math">s_i \\stackrel{?}{=} h_i(0) + h_i(1)</span> .  <span class="math">\\mathcal{V}</span>  samples  <span class="math">r_i&#x27; \\leftarrow L</span> , sets  <span class="math">s_{i+1} \\coloneqq h_i(r_i&#x27;)</span> , and sends  <span class="math">\\mathcal{P}</span>   <span class="math">r_i&#x27;</span> .
4:  <span class="math">\\mathcal{P}</span>  defines  <span class="math">f^{(i+1)}: S^{(i+1)} \\to L</span>  as the function fold  <span class="math">(f^{(i)}, r_i&#x27;)</span>  of Definition 4.6.</p>

    <pre><code class="language-text">if i+1=\\ell then \\mathcal{P} sends c:=f^{(\\ell)}(0,\\ldots,0) to \\mathcal{V}.
</code></pre>

    <p class="text-gray-300">else if  <span class="math">\\vartheta \\mid i+1</span>  then  <span class="math">\\mathcal{P}</span>  submits (submit,  <span class="math">\\ell + \\mathcal{R} - i - 1, f^{(i+1)}</span> ) to the oracle  <span class="math">\\mathcal{F}_{\\mathsf{Vec}}^L</span> .</p>

    <pre><code class="language-text">3. \\mathcal{V} requires s_{\\ell} \\stackrel{?}{=} \\widetilde{\\mathsf{eq}}(r_0, \\dots, r_{\\ell-1}, r&#x27;_0, \\dots, r&#x27;_{\\ell-1}) \\cdot c.
</code></pre>

    <p class="text-gray-300">4.  <span class="math">\\mathcal{V}</span>  carries out the following FRI-querying procedure:</p>

    <pre><code class="language-text">1: for \\gamma repetitions do
</code></pre>

    <pre><code class="language-text">\\mathcal{V} samples v \\leftarrow \\mathcal{B}_{\\ell+\\mathcal{R}} randomly.
2:
</code></pre>

    <p class="text-gray-300">3: <strong>for</strong>
<span class="math">$i \\in \\{0, \\vartheta, \\dots, \\ell - \\vartheta\\}</span>$
(i.e., taking  <span class="math">\\vartheta</span> -sized steps) <strong>do</strong></p>

    <p class="text-gray-300">4: for each
<span class="math">$u \\in \\mathcal{B}_{\\vartheta}</span>$
,  <span class="math">\\mathcal{V}</span>  sends (query,  <span class="math">[f^{(i)}], (u_0, \\dots, u_{\\vartheta-1}, v_{i+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1})</span> ) to the oracle.</p>

    <pre><code class="language-text">if i &gt; 0 then \\mathcal{V} requires c_i \\stackrel{?}{=} f^{(i)}(v_i, \\dots, v_{\\ell+\\mathcal{R}-1}).
</code></pre>

    <p class="text-gray-300">6:
<span class="math">$\\mathcal{V}</span>$
defines  <span class="math">c_{i+\\vartheta} := \\text{fold}(f^{(i)}, r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1})(v_{i+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1}).</span></p>

    <p class="text-gray-300"><span class="math">\\mathcal{V}</span>  requires  <span class="math">c_{\\ell} \\stackrel{?}{=} c</span> . 7:</p>

    <p class="text-gray-300">In our commitment procedure above, we make sense of the prover's commitment of f by identifying  <span class="math">S^{(0)} \\cong \\mathcal{B}_{\\ell+\\mathcal{R}}</span>  as sets (as we discussed above); similarly, in the prover's line 6 above, we identify  <span class="math">\\mathcal{B}_{\\ell+\\mathcal{R}-i-1} \\cong S^{(i+1)}</span> . Conversely, in its lines 4 and 6 above, the verifier must identify the  <span class="math">\\mathcal{B}_{\\ell+\\mathcal{R}-i}</span> -elements  <span class="math">(u_0, \\dots, u_{\\vartheta-1}, v_{i+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1})_{u \\in \\mathcal{B}_{\\vartheta}}</span>  with  <span class="math">S^{(i)}</span> -elements&mdash;and the  <span class="math">\\mathcal{B}_{\\ell+\\mathcal{R}-i-\\vartheta}</span> -element  <span class="math">(v_{i+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1})</span> with an  <span class="math">S^{(i+\\vartheta)}</span> -element&mdash;in order to apply Definition 4.8. We note that, in line 6,  <span class="math">\\mathcal{V}</span>  has precisely the information it needs to compute  <span class="math">\\operatorname{fold}(\\hat{f^{(i)}}, r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1})(v_{i+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1})</span>  (namely, the values of  <span class="math">f^{(i)}</span>  on the fiber  <span class="math">(u_0, \\ldots, u_{\\vartheta-1}, v_{i+\\vartheta}, \\ldots, v_{\\ell+\\mathcal{R}-1})_{u \\in \\mathcal{B}_{\\vartheta}} \\cong (q^{(i+\\vartheta-1)} \\circ \\cdots \\circ q^{(i)})^{-1} (\\{(v_{i+\\vartheta}, \\ldots, v_{\\ell+\\mathcal{R}-1})\\})).</span></p>

    <p class="text-gray-300">The completness of Construction 4.12's evaluation IOP is not straightforward. For instance, it is simply not obvious what the folding operation of line 4 does to the coefficients of the low-degree polynomial  <span class="math">P^{(i)}(X)</span>  underlying  <span class="math">f^{(i)}</span> . (Though our folding operation departs slightly from FRI's&mdash;we refer to Remark 4.7 for a discussion of this fact&mdash;the conceptual obstacle is essentially the same.) Indeed, the completeness proof of generic FRI [BBHR18a, &sect; 4.1.1] establishes that the folded function  <span class="math">f^{(i+1)}</span>  captures the evaluations of some polynomial  <span class="math">P^{(i+1)}(X)</span>  of appropriate degree on the domain  <span class="math">S^{(i+1)}</span> . But which one? The proof of [BBHR18a, &sect; 4.1.1] fails to constructively answer this question, in that it invokes the generic characteristics of the multivariate reduction&mdash;called  <span class="math">Q^{(i)}(X,Y)</span> &mdash;of  <span class="math">P^{(i)}(X)</span>  by  <span class="math">Y-q^{(i)}(X)</span> . (We refer to e.g. von zur Gathen and Gerhard [GG13, Alg. 21.11] for a thorough treatment of multivariate division.) It seems infeasible to analyze by hand the execution of the multivariate division algorithm with sufficient fidelity as to determine with any precision the result  <span class="math">P^{(i+1)}(Y) = Q^{(i)}(r&#x27;_i,Y)</span>  (though we don't rule out the prospect whereby a proof could in principle be achieved in this way).</p>

    <p class="text-gray-300">Instead, we introduce new, carefully-selected L-bases of the spaces  <span class="math">L[X]^{\\prec 2^{\\ell-i}}</span> , for  <span class="math">i \\in \\{0, \\dots, \\ell\\}</span>  (the so-called &quot;higher-order&quot; novel polynomial bases). As it turns out, the respective coefficients of  <span class="math">P^{(i)}(X)</span>  and  <span class="math">P^{(i+1)}(X)</span>  with respect to these bases bear a relationship more disposed to yield to our scrutiny (i.e., just that which results from folding by  <span class="math">r&#x27;_i</span> ). Proceeding by induction, we obtain the characterization of c we need.</p>

    <p class="text-gray-300"><strong>Theorem 4.13.</strong> The IOPCS  <span class="math">\\Pi = (\\mathsf{Setup}, \\mathsf{Commit}, \\mathcal{P}, \\mathcal{V})</span>  of Construction 4.12 is complete.</p>

    <p class="text-gray-300">Proof. Provided that  <span class="math">\\mathcal{P}</span>  is honest,  <span class="math">s=t(r_0,\\ldots,r_{\\ell-1})</span>  will hold. Since  <span class="math">t(r_0\\ldots,r_{\\ell-1})=\\sum_{w\\in\\mathcal{B}_\\ell}h(w)</span> , this guarantee implies that  <span class="math">s=s_0=\\sum_{w\\in\\mathcal{B}_\\ell}h(w)</span>  will hold, so that, by the completeness of the sumcheck,  <span class="math">\\mathcal{V}</span> 's checks  <span class="math">s_i\\stackrel{?}{=}h_i(0)+h_i(1)</span>  will pass. Finally,  <span class="math">s_\\ell=h(r_0&#x27;,\\ldots,r_{\\ell-1}&#x27;)=\\widetilde{\\operatorname{eq}}(r_0,\\ldots,r_{\\ell-1},r_0&#x27;,\\ldots,r_{\\ell-1}&#x27;)\\cdot t(r_0&#x27;,\\ldots,r_{\\ell-1}&#x27;)</span>  too will hold. To argue the completeness of  <span class="math">\\mathcal{V}</span> 's check  <span class="math">s_\\ell\\stackrel{?}{=}\\widetilde{\\operatorname{eq}}(r_0,\\ldots,r_{\\ell-1},r_0&#x27;,\\ldots,r_{\\ell-1}&#x27;)\\cdot c</span>  above, it thus suffices to argue that, for  <span class="math">\\mathcal{P}</span>  honest,  <span class="math">c=t(r_0&#x27;,\\ldots,r_{\\ell-1}&#x27;)</span>  will hold.</p>

    <p class="text-gray-300">We introduce a family of further polynomial bases. For each  <span class="math">i \\in \\{0,\\dots,\\ell-1\\}</span> , we define the  <span class="math">i^{th}</span> -order subspace vanishing polynomials  <span class="math">\\widehat{W}_0^{(i)},\\dots,\\widehat{W}_{\\ell-i-1}^{(i)}</span>  as the polynomials  <span class="math">X,q^{(i)},q^{(i+1)}\\circ q^{(i)},\\dots,q^{(\\ell-2)}\\circ \\dots \\circ q^{(i)}</span> , respectively (that is,  <span class="math">\\widehat{W}_k^{(i)} \\coloneqq q^{(i+k-1)}\\circ \\dots \\circ q^{(i)}</span> , for each  <span class="math">k \\in \\{0,\\dots,\\ell-i-1\\}</span> ). Finally, we define the  <span class="math">i^{th}</span> -order novel polynomial basis by setting  <span class="math">X_j^{(i)} \\coloneqq \\prod_{k=0}^{\\ell-i-1}\\widehat{W}_k^{(i)^{jk}}</span> , for each  <span class="math">j \\in \\{0,\\dots,2^{\\ell-i}-1\\}</span>  (here, again, we write  <span class="math">(j_0,\\dots,j_{\\ell-i-1})</span>  for the bits of j). We adopt the notational convention whereby the  <span class="math">\\ell^{th}</span> -order basis consists simply of the constant polynomial  <span class="math">X_0^{(\\ell)}(X) = 1</span> . Below, we use a certain inductive relationship between the bases  <span class="math">\\left(X_j^{(i)}(X)\\right)_{j=0}^{2^{\\ell-i-1}}</span>  and  <span class="math">\\left(X_j^{(i+1)}(X)\\right)_{j=0}^{2^{\\ell-i-1}-1}</span> ; that is, for each  <span class="math">j \\in \\{0,\\dots,2^{\\ell-i-1}-1\\}</span> , the polynomials  <span class="math">X_{2j}^{(i)}(X)</span>  and  <span class="math">X_{2j+1}^{(i)}(X)</span>  respectively equal  <span class="math">X_j^{(i+1)}(q^{(i)}(X))</span>  and  <span class="math">X \\cdot X_j^{(i+1)}(q^{(i)}(X))</span> .</p>

    <p class="text-gray-300"><strong>Lemma 4.14.</strong> Fix an index  <span class="math">i \\in \\{0, \\dots, \\ell-1\\}</span> . If  <span class="math">f^{(i)}: S^{(i)} \\to L</span>  is exactly the evaluation over  <span class="math">S^{(i)}</span>  of the polynomial  <span class="math">P^{(i)}(X) = \\sum_{j=0}^{2^{\\ell-i}-1} a_j \\cdot X_j^{(i)}(X)</span> , then, under honest prover behavior,  <span class="math">f^{(i+1)}: S^{(i+1)} \\to L</span>  is exactly the evaluation over  <span class="math">S^{(i+1)}</span>  of the polynomial  <span class="math">P^{(i+1)}(X) = \\sum_{j=0}^{2^{\\ell-i-1}-1} ((1-r_i&#x27;) \\cdot a_{2j} + r_i&#x27; \\cdot a_{2j+1}) \\cdot X_j^{(i+1)}(X)</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> Given  <span class="math">P^{(i)}(X)</span>  as in the hypothesis of the lemma, we introduce the <em>even and odd refinements</em>  <span class="math">P_0^{(i+1)}(X) \\coloneqq \\sum_{j=0}^{2^{\\ell-i-1}-1} a_{2j} \\cdot X_j^{(i+1)}(X)</span>  and  <span class="math">P_1^{(i+1)}(X) \\coloneqq \\sum_{j=0}^{2^{\\ell-i-1}-1} a_{2j+1} \\cdot X_j^{(i+1)}(X)</span>  of  <span class="math">P^{(i)}(X)</span> . We note the following key polynomial identity:</p>

    <p class="text-gray-300">
<span class="math">$P^{(i)}(X) = P_0^{(i+1)}(q^{(i)}(X)) + X \\cdot P_1^{(i+1)}(q^{(i)}(X)); \\tag{39}</span>$</p>

    <p class="text-gray-300">This identity is a direct consequence of the definitions of the higher-order novel polynomial bases.</p>

    <p class="text-gray-300">We turn to the proof of the lemma. We claim that  <span class="math">f^{(i+1)}(y) = P^{(i+1)}(y)</span>  holds for each  <span class="math">y \\in S^{(i+1)}</span> , where  <span class="math">P^{(i+1)}(X)</span>  is as in the lemma's hypothesis. To this end, we let  <span class="math">y \\in S^{(i+1)}</span>  be arbitrary; we moreover write  <span class="math">(x_0, x_1) := q^{(i)^{-1}}(\\{y\\})</span>  for the fiber of  <span class="math">q^{(i)}</span>  over y. We begin by examining the values  <span class="math">P^{(i)}(x_0)</span>  and  <span class="math">P^{(i)}(x_1)</span> . For each  <span class="math">b \\in \\{0, 1\\}</span>  we have:</p>

    <p class="text-gray-300"><span class="math">$P^{(i)}(x_b) = P_0^{(i+1)} \\left( q^{(i)}(x_b) \\right) + x_b \\cdot P_1^{(i+1)} \\left( q^{(i)}(x_b) \\right)</span>$
(by the identity (39).)
<span class="math">$= P_0^{(i+1)}(y) + x_b \\cdot P_1^{(i+1)}(y).</span>$
(using  <span class="math">q^{(i)}(x_b) = y</span> .)</p>

    <p class="text-gray-300">Using now our assumption whereby  <span class="math">f^{(i)}(x_b) = P^{(i)}(x_b)</span>  for each  <span class="math">b \\in \\{0,1\\}</span> , and unwinding the prescription of Definition 4.6, we obtain:</p>

    <p class="text-gray-300"><span class="math">$f^{(i+1)}(y) = \\begin{bmatrix} 1 - r_i&#x27; &amp; r_i&#x27; \\end{bmatrix} \\cdot \\begin{bmatrix} x_1 &amp; -x_0 \\\\ -1 &amp; 1 \\end{bmatrix} \\cdot \\begin{bmatrix} P^{(i)}(x_0) \\\\ P^{(i)}(x_1) \\end{bmatrix}</span>$
(by our hypothesis on  <span class="math">f^{(i)}</span> , and by Definition 4.6.)
<span class="math">$= \\begin{bmatrix} 1 - r_i&#x27; &amp; r_i&#x27; \\end{bmatrix} \\cdot \\begin{bmatrix} x_1 &amp; -x_0 \\\\ -1 &amp; 1 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 &amp; x_0 \\\\ 1 &amp; x_1 \\end{bmatrix} \\cdot \\begin{bmatrix} P^{(i+1)}(y) \\\\ P^{(i+1)}(y) \\end{bmatrix}</span>$
(by the calculation just performed above.)
<span class="math">$= \\begin{bmatrix} 1 - r_i&#x27; &amp; r_i&#x27; \\end{bmatrix} \\cdot \\begin{bmatrix} P^{(i+1)}(y) \\\\ P^{(i+1)}(y) \\end{bmatrix}</span>$
(cancellation of inverse matrices.)
<span class="math">$= P^{(i+1)}(y).</span>$
(by the definitions of  <span class="math">P^{(i+1)}(X)</span> ,  <span class="math">P^{(i+1)}(X)</span> , and  <span class="math">P^{(i+1)}(X)</span> .)</p>

    <p class="text-gray-300">To achieve the third equality above, we note that the matrices  <span class="math">\\begin{bmatrix} x_1 &amp; -x_0 \\\\ -1 &amp; 1 \\end{bmatrix}</span>  and  <span class="math">\\begin{bmatrix} 1 &amp; x_0 \\\\ 1 &amp; x_1 \\end{bmatrix}</span>  are inverses; there, we use the guarantee  <span class="math">x_1 - x_0 = 1</span> , a basic consequence of Definition 4.1 (or rather of  <span class="math">\\ker(q^{(i)}) = \\{0,1\\}</span> ).  <span class="math">\\square</span></p>

    <p class="text-gray-300">Applying Corollary 4.4, we note finally that  <span class="math">\\left(\\widehat{W}_k^{(0)}\\right)_{k=0}^{\\ell-1}</span>  and  <span class="math">\\left(X_j^{(0)}\\right)_{j=0}^{2^\\ell-1}</span>  themselves equal precisely the standard subspace vanishing and novel basis polynomials, respectively. It follows that in the base case i=0 of Lemma 4.14&mdash;and again assuming honest behavior by the prover&mdash;we have that  <span class="math">f^{(0)}</span>  will equal the evaluation over  <span class="math">S^{(0)}</span>  of  <span class="math">P^{(0)}(X) \\coloneqq P(X) = \\sum_{w \\in \\mathcal{B}_\\ell} t(w) \\cdot X_{\\{w\\}}^{(0)}(X)</span> . Applying Lemma 4.14 repeatedly, we conclude by induction that  <span class="math">f^{(\\ell)}</span>  will equal the evaluation over  <span class="math">S^{(\\ell)}</span>  of the constant polynomial  <span class="math">\\sum_{w \\in \\mathcal{B}_\\ell} \\widetilde{\\operatorname{eq}}(w_0, \\dots, w_{\\ell-1}, r&#x27;_0, \\dots, r&#x27;_{\\ell-1}) \\cdot t(w) = t(r&#x27;_0, \\dots, r&#x27;_{\\ell-1})</span> , so that  <span class="math">c = t(r&#x27;_0, \\dots, r&#x27;_{\\ell-1})</span>  will hold, as desired. The completeness of the verifier's query phase is self-evident (and is just as in [BBHR18a, &sect; 4.1.1]); we</p>

    <p class="text-gray-300">note that  <span class="math">\\mathcal{V}</span>  applies to each oracle  <span class="math">f^{(i)}</span>  the same folding procedure that  <span class="math">\\mathcal{P}</span>  does. This completes the proof of completeness.</p>

    <p class="text-gray-300">Remark 4.15. Using the techniques of Subsection 4.1 and of Theorem 4.13 above, we are able to suggest a new explanation of the additive NTT algorithm of Lin, Chung and Han [LCH14, &sect; III.], and of its correctness; we note also our Algorithm 2 above. (Li et al. [Li+18, Alg. 2] present yet a further&mdash;and very interesting&mdash;perspective, which differs both from ours and from Lin&ndash;Chung&ndash;Han's.) We fix an index  <span class="math">i \\in \\{0, \\ldots, \\ell-1\\}</span>  and a polynomial  <span class="math">P^{(i)}(X) := \\sum_{j=0}^{2^{\\ell-i}-1} a_j \\cdot X_j^{(i)}(X)</span>  expressed with respect to the  <span class="math">i^{\\text{th}}</span> -order novel basis. The key idea is that the values of  <span class="math">P^{(i)}(X)</span>  on the domain  <span class="math">S^{(i)}</span>  can be derived&mdash;using only  <span class="math">O(2^{\\ell+\\mathcal{R}-i})</span>  L-operations&mdash;given the values of  <span class="math">P^{(i)}(X)</span> 's even and odd refinements  <span class="math">P^{(i+1)}_0(X)</span>  and  <span class="math">P^{(i+1)}_1(X)</span>  (as in the proof of Lemma 4.14) over the domain  <span class="math">S^{(i+1)}</span> . This is a direct consequence of the identity (39) above. Indeed, applying that identity, we see that, for  <span class="math">y \\in S^{(i+1)}</span>  arbitrary, with fiber  <span class="math">(x_0, x_1) := q^{(i)}(y)</span> , say, we have the equalities  <span class="math">P^{(i)}(x_0) := P^{(i+1)}_0(y) + x_0 \\cdot P^{(i+1)}_1(y)</span>  and  <span class="math">P^{(i)}(x_1) := P^{(i+1)}_0(y) + x_1 \\cdot P^{(i+1)}_1(y)</span> . Since  <span class="math">x_0</span>  and  <span class="math">x_1</span>  in fact differ by exactly 1, we see that  <span class="math">P^{(i)}(x_1)</span>  can be computed from  <span class="math">P^{(i)}(x_0)</span>  using a single further L-addition. We recover the key butterfly diagram of [LCH14, Fig. 1. (a)] (see also Algorithm 2 above) upon carrying out this procedure recursively, with the convention whereby we flatten (using the space's canonical basis) and interleave the two copies of  <span class="math">S^{(i+1)}</span>  at each instance. The base case of the recursion consists of the  <span class="math">2^\\ell</span> -fold interleaving of the domain  <span class="math">S^{(\\ell)}</span> , into which  <span class="math">P^{(0)}</span> 's coefficients are tiled  <span class="math">2^\\mathcal{R}</span>  times. The final stage of the butterfly diagram yields the desired evaluation of  <span class="math">P^{(0)}(X)</span>  on  <span class="math">S^{(0)}</span> . Algorithm 2's twiddle factors in its  <span class="math">i^{\\text{th}}</span>  stage, then, are nothing other than the respective first lifts  <span class="math">x_0</span>  of y, as the image  <span class="math">y = q^{(i)}(x_0)</span>  varies throughout  <span class="math">S^{(i+1)}</span> . These latt</p>

    <p class="text-gray-300">Remark 4.16. Though it seems inessential to the proof of Theorem 4.13, it is interesting to note that, for each  <span class="math">i \\in \\{0,\\dots,\\ell-1\\}</span> , the  <span class="math">i^{\\text{th}}</span> -order basis  <span class="math">\\left(X_j^{(i)}\\right)_{j=0}^{2^{\\ell-i}-1}</span>  is itself a novel polynomial basis in its own right, namely that attached to the set of vectors  <span class="math">\\left(\\widehat{W}_i(\\beta_i),\\dots,\\widehat{W}_i(\\beta_{\\ell-1})\\right)</span> . Equivalently, the  <span class="math">i^{\\text{th}}</span> -order subspace vanishing polynomials  <span class="math">\\left(\\widehat{W}_k^{(i)}\\right)_{k=0}^{\\ell-i-1}</span>  are simply the subspace vanishing polynomials attached to this latter set of vectors. Indeed, for each  <span class="math">k \\in \\{0,\\dots,\\ell-i-1\\}</span> ,  <span class="math">\\left\\langle\\widehat{W}_i(\\beta_i),\\dots,\\widehat{W}_i(\\beta_{i+k-1})\\right\\rangle \\subset \\ker\\left(\\widehat{W}_k^{(i)}\\right)</span>  certainly holds, since  <span class="math">\\widehat{W}_k^{(i)} \\circ \\widehat{W}_i = q^{(i+k-1)} \\circ \\cdots \\circ q^{(i)} \\circ \\widehat{W}_i = \\widehat{W}_{i+k}</span> , which annihilates  <span class="math">\\langle \\beta_0,\\dots,\\beta_{i+k-1}\\rangle</span>  (here, we use the definition of  <span class="math">\\widehat{W}_k^{(i)}</span>  and Lemma 4.2). On the other hand,  <span class="math">\\widehat{W}_k^{(i)} = q^{(i+k-1)} \\circ \\cdots \\circ q^{(i)}</span> 's kernel can be of dimension at most k (say by degree considerations), while the vectors  <span class="math">\\widehat{W}_i(\\beta_i),\\dots,\\widehat{W}_i(\\beta_{i+k-1})</span>  are linearly independent (a consequence of Corollary 4.5). We conclude that the above containment is an equality. Finally, the subspace polynomials  <span class="math">\\left(\\widehat{W}_k^{(i)}\\right)_{k=0}^{\\ell-i-1}</span>  are normalized. Indeed, using Lemma 4.2 again, we see that, for each  <span class="math">k \\in \\{0,\\dots,\\ell-i-1\\}</span> ,  <span class="math">\\widehat{W}_k^{(i)}\\left(\\widehat{W}_i(\\beta_{i+k})\\right) = \\left(q^{(i+k-1)} \\circ \\cdots \\circ q^{(i)} \\circ \\widehat{W}_i\\right)(\\beta_{i+k}) = \\widehat{W}_{i+k}(\\beta_{i+k}) = 1</span>  holds.</p>

    <p class="text-gray-300">We now prove the security of Construction 4.12. Our key technical results below (see Propositions 4.21 and 4.24), essentially, jointly constitute a variant of FRI's soundness statement [BBHR18a,  <span class="math">\\S</span>  4.2.2]. Our proofs of these results incorporate&mdash;albeit in an attenuated way&mdash;various ideas present in [BBHR18a,  <span class="math">\\S</span>  4.2.2] and [Ben+23,  <span class="math">\\S</span>  8.2]. We also introduce a number of new ideas, which, by and large, pertain to our new folding technique (see Subsection 4.2).</p>

    <p class="text-gray-300">We note that our protocol seems not to admit a security proof which invokes that of FRI in a strictly blackbox manner. Rather, our security argument&mdash;and, it would seem, any conceivable analysis of Construction 4.12&mdash;must inevitably concern itself not merely with the distance from the code of  <span class="math">\\mathcal{A}</span> 's initial committed word, but moreover with the consistency of its oracles, and in particular with whether its final oracle value c relates as it should to its initial oracle.</p>

    <p class="text-gray-300"><strong>Theorem 4.17.</strong> The IOPCS  <span class="math">\\Pi = (\\mathsf{Setup}, \\mathsf{Commit}, \\mathcal{P}, \\mathcal{V})</span>  of Construction 4.12 is secure.</p>

    <p class="text-gray-300"><em>Proof.</em> We define a straight-line emulator  <span class="math">\\mathcal{E}</span>  as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>By inspecting  <span class="math">\\mathcal{A}</span> 's messages to the vector oracle,  <span class="math">\\mathcal{E}</span>  immediately recovers the function  <span class="math">f: S^{(0)} \\to L</span>  underlying the handle [f] output by  <span class="math">\\mathcal{A}</span> .</li>
    </ol></li>
      <li>2.  <span class="math">\\mathcal{E}</span>  runs the Berlekamp&ndash;Welch decoder (i.e., Algorithm 1) on the word  <span class="math">f: S^{(0)} \\to L</span> . If that algorithm outputs  <span class="math">P(X) = \\bot</span> , then  <span class="math">\\mathcal{E}</span>  outputs  <span class="math">\\bot</span>  and aborts.</li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Otherwise,  <span class="math">\\mathcal{E}</span>  re-expresses the Berlekamp-Welch output polymomial  <span class="math">P(X) = \\sum_{w \\in \\mathcal{B}_{\\ell}} t_w \\cdot X_{\\{w\\}}(X)</span>  in coordinates with respect to the novel polynomial basis.  <span class="math">\\mathcal{E}</span>  writes  <span class="math">t(X_0, \\dots, X_{\\ell-1}) \\in L[X_0, \\dots, X_{\\ell-1}]^{\\leq 1}</span>  for the multilinear whose Lagrange coordinates are  <span class="math">(t_w)_{w \\in \\mathcal{B}_{\\ell}}</span> .  <span class="math">\\mathcal{E}</span>  outputs  <span class="math">t(X_0, \\dots, X_{\\ell-1})</span>  and halts.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">We begin by defining various notions, adapting [BBHR18a, &sect; 4.2.1]. For each  <span class="math">i \\in \\{0, \\vartheta, \\dots, \\ell\\}</span>  (i.e., ascending in  <span class="math">\\vartheta</span> -sized steps), we write  <span class="math">C^{(i)} \\subset L^{2^{\\ell+\\mathcal{R}-i}}</span>  for the Reed&ndash;Solomon code  <span class="math">\\mathsf{RS}_{L,S^{(i)}}[2^{\\ell+\\mathcal{R}-i},2^{\\ell-i}]</span> . We recall that  <span class="math">C^{(i)}</span>  is of distance  <span class="math">d_i \\coloneqq 2^{\\ell+\\mathcal{R}-i} - 2^{\\ell-i} + 1</span> . We write  <span class="math">f^{(0)}, f^{(\\vartheta)}, \\dots, f^{(\\ell-\\vartheta)}</span>  for the oracles committed by  <span class="math">\\mathcal{A}</span> ; we moreover write  <span class="math">f^{(\\ell)}: S^{(\\ell)} \\to L</span>  for the identically-c function (here,  <span class="math">c \\in L</span>  is  <span class="math">\\mathcal{A}</span> 's final FRI message). For each  <span class="math">i \\in \\{0, \\vartheta, \\dots, \\ell-\\vartheta\\}</span> , we write  <span class="math">\\Delta(f^{(i+\\vartheta)}, g^{(i+\\vartheta)}) \\subset S^{(i+\\vartheta)}</span>  for the disagreement set between the elements  <span class="math">f^{(i+\\vartheta)}</span>  and  <span class="math">g^{(i+\\vartheta)}</span>  of  <span class="math">L^{2^{\\ell+\\mathcal{R}-i-\\vartheta}}</span> ; that is,  <span class="math">\\Delta(f^{(i+\\vartheta)}, g^{(i+\\vartheta)})</span>  is the set of elements  <span class="math">y \\in S^{(i+\\vartheta)}</span>  for which  <span class="math">f^{(i+\\vartheta)}(y) \\neq g^{(i+\\vartheta)}(y)</span> . We moreover write  <span class="math">\\Delta^{(i)}(f^{(i)}, g^{(i)}) \\subset S^{(i+\\vartheta)}</span>  for the fiber-wise disagreement set of the elements  <span class="math">f^{(i)}</span>  and  <span class="math">f^{(i)}</span>  of  <span class="math">f^{(i+\\vartheta)}</span>  and  <span class="math">f^{(i)}</span>  of  <span class="math">f^{(i+\\vartheta)}</span>  denotes the set of elements  <span class="math">f^{(i)}</span>  for which the respective restrictions of  <span class="math">f^{(i)}</span>  and  <span class="math">f^{(i)}</span>  to the fiber  <span class="math">f^{(i+\\vartheta)}(f^{(i)}, f^{(i)}) \\subset f^{(i+\\vartheta)}(f^{(i)}, f^{(i)}) \\subset f^{(i+\\vartheta)}(f^{(i)}, f^{(i)}) \\subset f^{(i+\\vartheta)}(f^{(i)}, f^{(i)})</span> . We note that, if  <span class="math">f^{(i)}(f^{(i)}, f^{(i)}) \\in f^{(i+\\vartheta)}(f^{(i)}, f^{(i)}) \\subset f^{(i+\\vartheta)}(f^{(i)}, f^{(i)}) \\subset f^{(i+\\vartheta)}(f^{(i)}, f^{(i)}) \\subset f^{(i+\\vartheta)}(f^{(i)}, f^{(i)})</span> . In any case, in case the oracle  <span class="math">f^{(i)}: f^{(i)} \\to f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)})</span> . The angle  <span class="math">f^{(i)}(f^{(i)}, f^{(i)}) \\to f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)})</span> . We note that, if  <span class="math">f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}, f^{(i)}) \\subset f^{(i)}(f^{(i)}</span></p>

    <p class="text-gray-300">We record the following key compliance condition:</p>

    <p class="text-gray-300"><strong>Definition 4.18.</strong> For each index  <span class="math">i \\in \\{0, \\vartheta, \\dots, \\ell - \\vartheta\\}</span> , we say that  <span class="math">\\mathcal{A}</span> 's  <span class="math">i^{\\text{th}}</span>  oracle  <span class="math">f^{(i)}</span>  is compliant if the conditions  <span class="math">d^{(i)}\\left(f^{(i)}, C^{(i)}\\right) &lt; \\frac{d_i}{2}, \\ d\\left(f^{(i+\\vartheta)}, C^{(i+\\vartheta)}\\right) &lt; \\frac{d_{i+\\vartheta}}{2}, \\ \\text{and} \\ \\overline{f}^{(i+\\vartheta)} = \\text{fold}\\left(\\overline{f}^{(i)}, r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1}\\right) \\ \\text{all hold.}</span></p>

    <p class="text-gray-300">We first argue that if any among  <span class="math">\\mathcal{A}</span> 's oracles  <span class="math">i \\in \\{0, \\vartheta, \\dots, \\ell - \\vartheta\\}</span>  is not compliant, then  <span class="math">\\mathcal{V}</span>  will accept with negligible probability at most. This is exactly Proposition 4.24 below. In order to prepare for that proposition, we record a sequence of lemmas. We begin with the following elementary fact.</p>

    <p class="text-gray-300"><strong>Lemma 4.19.</strong> For each  <span class="math">i \\in \\{0, \\vartheta, \\dots, \\ell - \\vartheta\\}</span> , if  <span class="math">d(f^{(i)}, C^{(i)}) &lt; \\frac{d_i}{2}</span> , then, for each tuple of folding challenges  <span class="math">(r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1}) \\in L^\\vartheta</span> , we have that  <span class="math">\\Delta(\\operatorname{fold}(f^{(i)}, r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1}), \\operatorname{fold}(\\overline{f}^{(i)}, r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1})) \\subset \\Delta^{(i)}(f^{(i)}, \\overline{f}^{(i)})</span> .</p>

    <p class="text-gray-300">Proof. We proceed by contraposition; we fix an element  <span class="math">y \\notin \\Delta^{(i)}(f^{(i)}, \\overline{f}^{(i)})</span> . By definition of that latter set, we conclude immediately that the restrictions  <span class="math">f^{(i)}|_{(q^{(i+\\vartheta-1)}\\circ\\cdots\\circ q^{(i)})^{-1}(\\{y\\})} = \\overline{f}^{(i)}|_{(q^{(i+\\vartheta-1)}\\circ\\cdots\\circ q^{(i)})^{-1}(\\{y\\})}</span>  are identically equal. Applying Definition 4.8, we see under this guarantee that, regardless of the challenges  <span class="math">(r&#x27;_i,\\ldots,r&#x27;_{i+\\vartheta-1})</span> , fold  <span class="math">(f^{(i)},r&#x27;_i,\\ldots,r&#x27;_{i+\\vartheta-1})(y)</span>  = fold  <span class="math">(\\overline{f}^{(i)},r&#x27;_i,\\ldots,r&#x27;_{i+\\vartheta-1})(y)</span>  necessarily also holds.</p>

    <p class="text-gray-300">We now define a sequence of bad folding events. Our definition of  <span class="math">E_i</span>  is case-based, and depends on the status of  <span class="math">f^{(i)}</span> . If  <span class="math">f^{(i)}</span>  is within the (fiber-wise) unique decoding radius, then  <span class="math">E_i</span>  captures the event whereby the generic inclusion of Lemma 4.19 becomes strict. Otherwise,  <span class="math">E_i</span>  captures the &quot;bad batching&quot; event whereby fold( <span class="math">f^{(i)}, r&#x27;_i, \\ldots, r&#x27;_{i+\\vartheta-1}</span> ) becomes close to  <span class="math">C^{(i+\\vartheta)}</span> .</p>

    <p class="text-gray-300"><strong>Definition 4.20.</strong> For each  <span class="math">i \\in \\{0, \\vartheta, \\dots, \\ell - \\vartheta\\}</span> , we define the <em>bad subset</em>  <span class="math">E_i \\subset L^{\\vartheta}</span>  as the set of tuples  <span class="math">(r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1}) \\in L^{\\vartheta}</span>  for which, as the case may be:</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} &amp;\\text{in case } d^{(i)}\\big(f^{(i)},C^{(i)}\\big) &lt; \\frac{d_{i+\\vartheta}}{2}: \\ \\Delta^{(i)}\\big(f^{(i)},\\overline{f}^{(i)}\\big) \\not\\subset \\Delta\\big(\\mathsf{fold}\\big(f^{(i)},r_i&#x27;,\\ldots,r_{i+\\vartheta-1}&#x27;\\big),\\mathsf{fold}\\big(\\overline{f}^{(i)},r_i&#x27;,\\ldots,r_{i+\\vartheta-1}&#x27;\\big)\\big). \\\\ &amp;\\text{in case } d^{(i)}\\big(f^{(i)},C^{(i)}\\big) \\geq \\frac{d_{i+\\vartheta}}{2}: \\ d\\big(\\mathsf{fold}\\big(f^{(i)},r_i&#x27;,\\ldots,r_{i+\\vartheta-1}&#x27;\\big),C^{(i+\\vartheta)}\\big) &lt; \\frac{d_{i+\\vartheta}}{2}. \\end{split}</span>$</p>

    <p class="text-gray-300">We now bound the bad subsets  <span class="math">E_i</span>  of Definition 4.20. We recall that  <span class="math">\\mu(E_i) := \\frac{|E_i|}{|L|^{\\vartheta}}</span>  denotes the probability mass of the set  <span class="math">E_i \\subset L^{\\vartheta}</span> .</p>

    <p class="text-gray-300"><strong>Proposition 4.21.</strong> For each
<span class="math">$i \\in \\{0, \\vartheta, \\dots, \\ell - \\vartheta\\}</span>$
,  <span class="math">\\mu(E_i) \\leq \\vartheta \\cdot \\frac{\\left|S^{(i+\\vartheta)}\\right|}{|L|}</span>  holds.</p>

    <p class="text-gray-300"><em>Proof.</em> We treat separately the two cases of Definition 4.20.</p>

    <p class="text-gray-300">We begin with the first case. We fix an element  <span class="math">y \\in \\Delta^{(i)} \\left( f^{(i)}, \\overline{f}^{(i)} \\right)</span> , we moreover write  <span class="math">E_i^y \\subset L^\\vartheta</span>  for the set of tuples  <span class="math">(r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1}) \\in L^\\vartheta</span>  for which  <span class="math">y \\not\\in \\Delta(\\operatorname{fold}(f^{(i)}, r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1}), \\operatorname{fold}(\\overline{f}^{(i)}, r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1}))</span> . We argue that  <span class="math">\\mu(E_i^y) \\leq \\frac{\\vartheta}{|L|}</span> . This latter claim suffices to complete the proof of the first case; indeed, since  <span class="math">E_i = \\bigcup_{y \\in \\Delta^{(i)} \\left( f^{(i)}, \\overline{f}^{(i)} \\right)} E_i^y</span> , assuming the claim, we conclude that  <span class="math">\\mu(E_i) \\leq \\left| \\Delta^{(i)} \\left( f^{(i)}, \\overline{f}^{(i)} \\right) \\right| \\cdot \\frac{\\vartheta}{|L|} \\leq |S^{(i+\\vartheta)}| \\cdot \\frac{\\vartheta}{|L|}</span> . For  <span class="math">y \\in \\Delta^{(i)} \\left( f^{(i)}, \\overline{f}^{(i)} \\right)</span>  chosen as above, we apply Lemma 4.9 to the words  <span class="math">f^{(i)}</span>  and  <span class="math">\\overline{f}^{(i)}</span> . Applying that lemma, we see that  <span class="math">(r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1}) \\in E_i^y</span>  holds if and only if we have the following matrix identity:</p>

    <p class="text-gray-300">
<span class="math">$0 = \\begin{bmatrix} \\bigotimes_{j=0}^{\\vartheta-1} (1 - r&#x27;_{i+j}, r&#x27;_{i+j}) \\end{bmatrix} \\cdot \\begin{bmatrix} M_y \\end{bmatrix} \\cdot \\begin{bmatrix} f^{(i)}(x_0) - \\overline{f}^{(i)}(x_0) \\\\ \\vdots \\\\ f^{(i)}(x_{2^{\\vartheta}-1}) - \\overline{f}^{(i)}(x_{2^{\\vartheta}-1}) \\end{bmatrix}, \\tag{40}</span>$</p>

    <p class="text-gray-300">where we again write  <span class="math">(x_0,\\ldots,x_{2^\\vartheta-1})\\coloneqq \\left(q^{(i+\\vartheta-1)}\\circ\\cdots\\circ q^{(i)}\\right)^{-1}(\\{y\\})</span> . Our hypothesis  <span class="math">y\\in\\Delta^{(i)}\\left(f^{(i)},\\overline{f}^{(i)}\\right)</span>  entails precisely that the right-hand vector of (40) is not identically zero. By Lemma 4.9,  <span class="math">M_y</span>  is non-singular; we conclude that the image of the right-hand vector of (40) under  <span class="math">M_y</span>  is likewise not identically zero. Writing  <span class="math">(a_0,\\ldots,a_{2^\\vartheta-1})</span>  for this latter vector&mdash;which, we repeat, is not zero&mdash;we conclude that  <span class="math">E_i^y\\subset L^\\vartheta</span>  is precisely the vanishing locus in  <span class="math">L^\\vartheta</span>  of the  <span class="math">\\vartheta</span> -variate polynomial  <span class="math">s(X_0,\\ldots,X_{\\vartheta-1}):=\\sum_{v\\in\\mathcal{B}_\\vartheta}a_{\\{v\\}}\\cdot\\widetilde{\\operatorname{eq}}(X_0,\\ldots,X_{\\vartheta-1},v_0,\\ldots,v_{\\vartheta-1})</span>  over L. Since  <span class="math">s(X_0,\\ldots,X_{\\vartheta-1})</span> 's values on the cube  <span class="math">\\{0,1\\}^\\vartheta\\subset L^\\vartheta</span>  are exactly  <span class="math">(a_0,\\ldots,a_{2^\\vartheta-1}),\\,s(X_0,\\ldots,X_{\\vartheta-1})</span>  is certainly not zero. Applying the Schwartz&ndash;Zippel lemma to  <span class="math">s(X_0,\\ldots,X_{\\vartheta-1})</span> , we conclude that the relevant locus  <span class="math">E_i^y\\subset L^\\vartheta</span>  is of mass at most  <span class="math">\\mu(E_i^y)\\leq\\frac{\\vartheta}{|L|}</span> , as required.</p>

    <p class="text-gray-300">We turn to the second case of Definition 4.20; in particular, we assume that  <span class="math">d^{(i)}(f^{(i)}, C^{(i)}) \\geq \\frac{d_{i+\\vartheta}}{2}</span> . We define an interleaved word  <span class="math">\\left(f_j^{(i+\\vartheta)}\\right)_{j=0}^{2^{\\vartheta}-1}</span> &mdash;i.e., a  <span class="math">2^{\\vartheta} \\times 2^{\\ell+\\mathcal{R}-i-\\vartheta}</span>  matrix, with entries in L&mdash;in the following way. For each  <span class="math">y \\in S^{(i+\\vartheta)}</span> , writing  <span class="math">M_y</span>  for the matrix guaranteed to exist by Lemma 4.9, we define the column:</p>

    <p class="text-gray-300">
$$\\begin{bmatrix}
f_0^{(i+\\vartheta)}(y) \\
\\vdots \\
f_{2^\\vartheta-1}^{(i+\\vartheta)}(y)
\\end{bmatrix} := \\begin{bmatrix}
M_y \\
\\vdots \\
f^{(i)}(x_0) \\
\\vdots \\
f^{(i)}(x_{2^\\vartheta-1})
\\end{bmatrix}.$$
(41)</p>

    <p class="text-gray-300">We note that the resulting  <span class="math">2^{\\vartheta} \\times 2^{\\ell+\\mathcal{R}-i-\\vartheta}</span>  matrix  <span class="math">\\left(f_j^{(i+\\vartheta)}\\right)_{j=0}^{2^{\\vartheta}-1}</span> &mdash;i.e., that whose columns are given by the respective left-hand sides of (41), for  <span class="math">y \\in S^{(i+\\vartheta)}</span>  varying&mdash;satisfies, for each  <span class="math">(r_i&#x27;, \\dots, r_{i+\\vartheta-1}&#x27;) \\in L^{\\vartheta}</span> ,</p>

    <p class="text-gray-300">
<span class="math">$\\operatorname{fold}\\left(f^{(i)},r_i&#x27;,\\ldots,r_{i+\\vartheta-1}&#x27;\\right) = \\begin{bmatrix} &amp; &amp; \\\\ &amp; &amp; \\\\ \\end{pmatrix}_{j=i}^{i+\\vartheta-1}(1-r_j&#x27;,r_j&#x27;) \\quad -- \\end{bmatrix} \\cdot \\begin{bmatrix} &amp; &amp; &amp; \\\\ &amp; &amp; \\\\ &amp; &amp; \\\\ &amp; &amp; \\\\ &amp; &amp; \\end{bmatrix}. \\tag{42}</span>$</p>

    <p class="text-gray-300">Indeed, this is essentially the content of Lemma 4.9, which we apply here jointly to all elements  <span class="math">y \\in S^{(i+\\vartheta)}</span> . We claim that the interleaved word  <span class="math">\\left(f_j^{(i+\\vartheta)}\\right)_{j=0}^{2^\\vartheta-1}</span>  constructed in this way is far from the interleaved code  <span class="math">C^{(i+\\vartheta)}^{2^\\vartheta}</span> .</p>

    <p class="text-gray-300"><strong>Lemma 4.22.</strong> Under our hypothesis
<span class="math">$d^{(i)}(f^{(i)}, C^{(i)}) \\geq \\frac{d_{i+\\vartheta}}{2}</span>$
, we have  <span class="math">d^{2^{\\vartheta}}\\left(\\left(f_j^{(i+\\vartheta)}\\right)_{j=0}^{2^{\\vartheta}-1}, C^{(i+\\vartheta)^{2^{\\vartheta}}}\\right) \\geq \\frac{d_{i+\\vartheta}}{2}</span> .</p>

    <p class="text-gray-300">Proof. We fix an arbitrary interleaved codeword  <span class="math">\\left(g_j^{(i+\\vartheta)}\\right)_{j=0}^{2^\\vartheta-1} \\in C^{(i+\\vartheta)^{2^\\vartheta}}</span> . We define a &quot;lift&quot;  <span class="math">g^{(i)} \\in C^{(i)}</span>  of  <span class="math">\\left(g_j^{(i+\\vartheta)}\\right)_{j=0}^{2^\\vartheta-1}</span>  in the following way. Writing, for each  <span class="math">j \\in \\{0,\\dots,2^\\vartheta-1\\}</span> ,  <span class="math">P_j^{(i+\\vartheta)}(X) \\coloneqq \\sum_{k=0}^{2^{\\ell-i-\\vartheta}-1} a_{j,k} \\cdot X_k^{(i+\\vartheta)}(X)</span>  for the polynomial&mdash;expressed in coordinates with respect to the  <span class="math">i+\\vartheta^{\\text{th}}</span> -order novel polynomial basis&mdash;for which  <span class="math">g_j^{(i+\\vartheta)} = \\text{Enc}(P_j^{(i+\\vartheta)})</span>  holds, we define</p>

    <p class="text-gray-300"><span class="math">$P^{(i)}(X) \\coloneqq \\sum_{j=0}^{2^{\\vartheta}-1} \\sum_{k=0}^{2^{\\ell-i-\\vartheta}-1} a_{j,k} \\cdot X_{k \\cdot 2^{\\vartheta}+j}^{(i)};</span>$</p>

    <p class="text-gray-300">that is,  <span class="math">P^{(i)}</span> 's list of  <span class="math">i^{\\text{th}}</span> -order coefficients is precisely the  <span class="math">2^{\\vartheta}</span> -fold interleaving of the polynomials  <span class="math">P^{(i+\\vartheta)}_0(X),\\dots,P^{(i+\\vartheta)}_{2^{\\vartheta}-1}(X)</span> 's respective lists of  <span class="math">i+\\vartheta^{\\text{th}}</span> -order coefficients. Finally, we define  <span class="math">g^{(i)}\\coloneqq \\mathsf{Enc}(P^{(i)})</span> .</p>

    <p class="text-gray-300">We argue that the codeword  <span class="math">g^{(i)} \\in C^{(i)}</span>  constructed in this way stands in relation to  <span class="math">\\left(g_j^{(i+\\vartheta)}\\right)_{j=0}^{2^\\vartheta-1}</span>  just as  <span class="math">f^{(i)}</span>  does to  <span class="math">\\left(f_j^{(i+\\vartheta)}\\right)_{j=0}^{2^\\vartheta-1}</span>  (i.e., it also satisfies a matrix identity analogous to (41) for each  <span class="math">y \\in S^{(i+\\vartheta)}</span> ). To prove this, we fix an arbitrary element  <span class="math">y \\in S^{(i+\\vartheta)}</span> ; we moreover fix a row-index  <span class="math">j \\in \\{0,\\dots,2^\\vartheta-1\\}</span> . We write  <span class="math">(j_0,\\dots,j_{\\vartheta-1})</span>  for the bits of j (i.e., so that  <span class="math">j=\\sum_{k=0}^{\\vartheta-1}2^k\\cdot j_k</span>  holds). We first note that the functions  <span class="math">g_j^{(i+\\vartheta)}</span>  and  <span class="math">\\operatorname{fold}(g^{(i)},j_0,\\dots,j_{\\vartheta-1})</span>  agree identically over the domain  <span class="math">S^{(i+\\vartheta)}</span> . Indeed, this is a direct consequence of Lemma 4.14 and of the construction of  <span class="math">g^{(i)}</span>  ( <span class="math">g_j^{(i+\\vartheta)}(y)</span> 's underlying polynomial's coefficients are the  <span class="math">j^{\\text{th}}</span>  refinement of  <span class="math">g^{(i)}</span> 's underlying polynomial's). On the other hand, applying Lemma 4.9 to  <span class="math">y \\in S^{(i+\\vartheta)}</span>  and  <span class="math">g^{(i)}</span> , with the folding tuple  <span class="math">(j_0,\\dots,j_{\\vartheta-1})</span> , we see that the dot product between  <span class="math">M_y</span> 's  <span class="math">j^{\\text{th}}</span>  row and  <span class="math">\\left(g^{(i)}(x_0),\\dots,g^{(i)}(x_{2^\\vartheta-1})\\right)</span>  is exactly  <span class="math">\\operatorname{fold}(g^{(i)},j_0,\\dots,j_{\\vartheta-1})(y)=g_j^{(i+\\vartheta)}(y)</span> , where the latter equality was just argued.</p>

    <p class="text-gray-300">Since  <span class="math">g^{(i)} \\in C^{(i)}</span>  is a codeword, our hypothesis  <span class="math">d^{(i)}(f^{(i)},C^{(i)}) \\geq \\frac{d_{i+\\vartheta}}{2}</span>  applies to it. That hypothesis entails precisely that, for at least  <span class="math">\\frac{d_{i+\\vartheta}}{2}</span>  elements  <span class="math">y \\in S^{(i+\\vartheta)}</span> , the restrictions  <span class="math">f^{(i)}|_{(q^{(i+\\vartheta-1)}\\circ\\cdots\\circ q^{(i)})^{-1}(\\{y\\})}</span>  and  <span class="math">g^{(i)}|_{(q^{(i+\\vartheta-1)}\\circ\\cdots\\circ q^{(i)})^{-1}(\\{y\\})}</span>  are not identically equal. For each such  <span class="math">y \\in S^{(i+\\vartheta)}</span> , since  <span class="math">M_y</span>  is nonsingular (and since both  <span class="math">f^{(i)}</span>  and  <span class="math">g^{(i)}</span>  satisfy (41)), we conclude that the columns  <span class="math">\\left(f_j^{(i+\\vartheta)}(y)\\right)_{j=0}^{2^\\vartheta-1}</span>  and  <span class="math">\\left(g_j^{(i+\\vartheta)}(y)\\right)_{j=0}^{2^\\vartheta-1}</span>  are in turn unequal. Since  <span class="math">\\left(g_j^{(i+\\vartheta)}\\right)_{j=0}^{2^\\vartheta-1}</span>  was arbitrary, we conclude that  <span class="math">d^{2^\\vartheta}\\left(\\left(f_j^{(i+\\vartheta)}\\right)_{j=0}^{2^\\vartheta-1},C^{(i+\\vartheta)^{2^\\vartheta}}\\right) \\geq \\frac{d_{i+\\vartheta}}{2}</span> .</p>

    <p class="text-gray-300">Applying Lemma 4.22, we conclude directly that the contraposition of Theorem 2.4 is fulfilled with respect to the code  <span class="math">C^{(i+\\vartheta)} \\subset L^{2^{\\ell+\\mathcal{R}-i-\\vartheta}}</span> , the proximity parameter  <span class="math">e \\coloneqq \\left\\lfloor \\frac{d_{i+\\vartheta}-1}{2} \\right\\rfloor</span> , and the interleaved word  <span class="math">\\left(f_j^{(i+\\vartheta)}\\right)_{j=0}^{2^\\vartheta-1}</span> . That theorem's contraposition immediately implies that the set  <span class="math">E_i \\subset L^\\vartheta</span>  consisting of those tuples  <span class="math">(r_i&#x27;,\\ldots,r_{i+\\vartheta-1}&#x27;) \\in L^\\vartheta</span>  for which  <span class="math">d\\left(\\operatorname{fold}\\left(f^{(i)},r_i&#x27;,\\ldots,r_{i+\\vartheta-1}&#x27;\\right),C^{(i+\\vartheta)}\\right) &lt; \\frac{d_{i+\\vartheta}}{2}</span>  holds&mdash;and here, we use (42)&mdash;is of mass at most  <span class="math">\\mu(E_i) \\leq \\vartheta \\cdot \\frac{2^{\\ell+\\mathcal{R}-i-\\vartheta}}{|L|} = \\vartheta \\cdot \\frac{|S^{(i+\\vartheta)}|}{|L|}</span> , as required. This completes the proof of the proposition.</p>

    <p class="text-gray-300"><strong>Proposition 4.23.</strong> The probability that any among the bad events  <span class="math">E_0, E_{\\vartheta}, \\dots, E_{\\ell-\\vartheta}</span>  occurs is at most  <span class="math">\\frac{2^{\\ell+\\mathcal{R}}}{|L|}</span> . <em>Proof.</em> Applying Proposition 4.21, we upper-bound the quantity of interest as:</p>

    <p class="text-gray-300"><span class="math">$\\frac{\\vartheta}{|L|} \\cdot (|S_{\\vartheta}| + \\dots + |S_{\\ell}|) = \\frac{\\vartheta}{|L|} \\cdot \\left(2^{\\ell + \\mathcal{R} - \\vartheta} + \\dots + 2^{\\mathcal{R}}\\right) \\leq \\frac{\\vartheta}{|L|} \\cdot \\frac{2^{\\vartheta}}{2^{\\vartheta} - 1} \\cdot 2^{\\ell + \\mathcal{R} - \\vartheta} \\leq \\frac{2^{\\ell + \\mathcal{R}}}{|L|},</span>$</p>

    <p class="text-gray-300">which completes the proof. In the last two steps, we use the geometric series formula and the inequality  <span class="math">\\frac{\\vartheta}{2^{\\vartheta}-1} \\leq 1</span>  (which holds for each  <span class="math">\\vartheta \\geq 1</span> ), respectively.</p>

    <p class="text-gray-300">In light of Proposition 4.23, we freely assume that none of the events  <span class="math">E_0, E_{\\vartheta}, \\dots, E_{\\ell-\\vartheta}</span>  occurs. Under this assumption, we finally turn to the following key proposition.</p>

    <p class="text-gray-300"><strong>Proposition 4.24.</strong> If any of A's oracles is not compliant, then V accepts with at most negligible probability.</p>

    <p class="text-gray-300"><em>Proof.</em> We suppose that at least one of  <span class="math">\\mathcal{A}</span> 's oracles is not compliant; we write  <span class="math">i^* \\in \\{0, \\vartheta, \\dots, \\ell - \\vartheta\\}</span>  for the index of  <span class="math">\\mathcal{A}</span> 's highest-indexed noncompliant oracle.</p>

    <p class="text-gray-300">
<span class="math">$\\textbf{Lemma 4.25. For } i^* \\in \\{0,\\vartheta,\\dots,\\ell-\\vartheta\\} \\ \\ \\textit{as above, we have} \\ d\\big(\\mathsf{fold}\\big(f^{(i^*)},r&#x27;_{i^*},\\dots,r&#x27;_{i^*+\\vartheta-1}\\big),\\overline{f}^{(i^*+\\vartheta)}\\big) \\geq \\frac{d_{i^*+\\vartheta}}{2}.</span>$</p>

    <p class="text-gray-300">Proof. Assuming first that  <span class="math">d^{(i^*)}\\left(f^{(i^*)},C^{(i^*)}\\right)&lt;\\frac{d_{i^*+\\vartheta}}{2}</span> , we write  <span class="math">\\overline{f}^{(i^*)}\\in C^{(i^*)}</span>  for the codeword for which  <span class="math">\\left|\\Delta^{(i^*)}\\left(f^{(i^*)},\\overline{f}^{(i^*)}\\right)\\right|&lt;\\frac{d_{i^*+\\vartheta}}{2}</span> . We note that  <span class="math">d\\left(f^{(i^*)},\\overline{f}^{(i^*)}\\right)&lt;\\frac{d_{i^*}}{2}</span>  a fortiori holds; by Definition 4.18 and our choice of  <span class="math">i^*</span> , we thus must have in turn  <span class="math">\\overline{f}^{(i^*+\\vartheta)}\\neq \\operatorname{fold}\\left(\\overline{f}^{(i^*)},r&#x27;_{i^*},\\ldots,r&#x27;_{i^*+\\vartheta-1}\\right)</span> . On the other hand, by Lemma 4.19,  <span class="math">\\left|\\Delta^{(i^*)}\\left(f^{(i^*)},\\overline{f}^{(i^*)}\\right)\\right|&lt;\\frac{d_{i^*+\\vartheta}}{2}</span>  implies that  <span class="math">d\\left(\\operatorname{fold}\\left(f^{(i^*)},r&#x27;_{i^*},\\ldots,r&#x27;_{i^*+\\vartheta-1}\\right),\\operatorname{fold}\\left(\\overline{f}^{(i^*)},r&#x27;_{i^*},\\ldots,r&#x27;_{i^*+\\vartheta-1}\\right)\\right)&lt;\\frac{d_{i^*+\\vartheta}}{2}</span> . Finally, by the reverse triangle inequality,  <span class="math">d\\left(\\operatorname{fold}\\left(f^{(i^*)},r&#x27;_{i^*},\\ldots,r&#x27;_{i^*+\\vartheta-1}\\right),\\overline{f}^{(i^*+\\vartheta)}\\right)</span>  is at least:</p>

    <p class="text-gray-300"><span class="math">$d\\Big(\\overline{f}^{(i^*+\\vartheta)}, \\operatorname{fold}\\Big(\\overline{f}^{(i^*)}, r&#x27;_{i^*}, \\dots, r&#x27;_{i^*+\\vartheta-1}\\Big)\\Big) - d\\Big(\\operatorname{fold}\\Big(f^{(i^*)}, r&#x27;_{i^*}, \\dots, r&#x27;_{i^*+\\vartheta-1}\\Big), \\operatorname{fold}\\Big(\\overline{f}^{(i^*)}, r&#x27;_{i^*}, \\dots, r&#x27;_{i^*+\\vartheta-1}\\Big)\\Big).</span>$</p>

    <p class="text-gray-300">Since  <span class="math">\\overline{f}^{(i^*+\\vartheta)}</span>  and  <span class="math">\\operatorname{fold}(\\overline{f}^{(i^*)},r&#x27;_{i^*},\\ldots,r&#x27;_{i^*+\\vartheta-1})</span>  are unequal codewords in  <span class="math">C^{(i^*+\\vartheta)}</span> , this quantity in turn is greater than or equal to  <span class="math">d_{i^*+\\vartheta}-\\frac{d_{i^*+\\vartheta}}{2}\\geq \\frac{d_{i^*+\\vartheta}}{2}</span> , and the proof of the first case is complete.</p>

    <p class="text-gray-300">In the case  <span class="math">d^{(i^*)}(f^{(i^*)},C^{(i^*)})\\geq \\frac{d_{i^*+\\vartheta}}{2}</span> , our assumption whereby  <span class="math">E_{i^*}</span>  didn't occur implies, by def-</p>

    <p class="text-gray-300">In the case  <span class="math">d^{(i^*)}(f^{(i^*)}, C^{(i^*)}) \\geq \\frac{d_{i^*+\\vartheta}}{2}</span> , our assumption whereby  <span class="math">E_{i^*}</span>  didn't occur implies, by definition, that  <span class="math">d(\\mathsf{fold}(f^{(i^*)}, r&#x27;_{i^*}, \\dots, r&#x27;_{i^*+\\vartheta-1}), C^{(i^*+\\vartheta)}) \\geq \\frac{d_{i^*+\\vartheta}}{2}</span> . Since  <span class="math">\\overline{f}^{(i^*+\\vartheta)} \\in C^{(i^*+\\vartheta)}</span>  is a codeword,  <span class="math">d(\\mathsf{fold}(f^{(i^*)}, r&#x27;_{i^*}, \\dots, r&#x27;_{i^*+\\vartheta-1}), \\overline{f}^{(i^*+\\vartheta)}) \\geq \\frac{d_{i^*+\\vartheta}}{2}</span>  in particular holds, and the proof is again complete.</p>

    <p class="text-gray-300"> <span class="math">\\textbf{Lemma 4.26.} \\ \\textit{Whenever its suffix} \\ (v_{i^*+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1}) \\in \\Delta \\big( \\mathsf{fold} \\big( f^{(i^*)}, r&#x27;_{i^*}, \\dots, r&#x27;_{i+\\vartheta-1} \\big), \\overline{f}^{(i^*+\\vartheta)} \\big), \\ \\mathcal{V} \\ \\textit{rejects}.</span></p>

    <p class="text-gray-300"><em>Proof.</em> We fix an iteration of the query phase's outer loop for which the lemma's hypothesis holds. We fix an arbitrary index  <span class="math">i \\in \\{i^*, i^* + \\vartheta, \\dots, \\ell - \\vartheta\\}</span> . If  <span class="math">\\mathcal{V}</span>  rejects before finishing the inner loop 3's  <span class="math">i^{\\text{th}}</span>  iteration, then there's nothing to prove. We argue that, conditioned on  <span class="math">\\mathcal{V}</span>  reaching the end of its  <span class="math">i^{\\text{th}}</span>  iteration, we have the inductive conclusion  <span class="math">c_{i+\\vartheta} \\neq \\overline{f}^{(i+\\vartheta)}(v_{i+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1})</span>  as of the end of that iteration.</p>

    <p class="text-gray-300">inductive conclusion  <span class="math">c_{i+\\vartheta} \\neq \\overline{f}^{(i+\\vartheta)}(v_{i+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1})</span>  as of the end of that iteration. In the base case  <span class="math">i=i^*</span> ,  <span class="math">\\mathcal{V}</span>  assigns  <span class="math">c_{i^*+\\vartheta} \\coloneqq \\operatorname{fold}\\left(f^{(i^*)}, r&#x27;_{i^*}, \\dots, r&#x27;_{i^*+\\vartheta-1}\\right)(v_{i^*+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1})</span>  inline on line 6. On the other hand, the hypothesis of the lemma is precisely  <span class="math">\\operatorname{fold}\\left(f^{(i^*)}, r&#x27;_{i^*}, \\dots, r&#x27;_{i+\\vartheta-1}\\right)(v_{i^*+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1}) \\neq \\overline{f}^{(i^*+\\vartheta)}(v_{i^*+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1})</span> ; we conclude immediately that  <span class="math">c_{i^*+\\vartheta} \\neq \\overline{f}^{(i^*+\\vartheta)}(v_{i^*+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1})</span>  will hold as of the end of the  <span class="math">i^*</span> th iteration, as desired.</p>

    <p class="text-gray-300">We fix an index  <span class="math">i \\in \\{i^* + \\vartheta, \\dots, \\ell - \\vartheta\\}</span> . As of the beginning of the  <span class="math">i^{\\text{th}}</span>  iteration, by induction, we have the hypothesis  <span class="math">c_i \\neq \\overline{f}^{(i)}(v_i, \\dots, v_{\\ell+\\mathcal{R}-1})</span> . If  <span class="math">\\overline{f}^{(i)}(v_i, \\dots, v_{\\ell+\\mathcal{R}-1}) = f^{(i)}(v_i, \\dots, v_{\\ell+\\mathcal{R}-1})</span>  moreover holds, then we see immediately that  <span class="math">\\mathcal{V}</span>  will reject on line 5; indeed, in this case  <span class="math">c_i \\neq \\overline{f}^{(i)}(v_i, \\dots, v_{\\ell+\\mathcal{R}-1}) = f^{(i)}(v_i, \\dots, v_{\\ell+\\mathcal{R}-1})</span>  will hold. We conclude that, conditioned on  <span class="math">\\mathcal{V}</span>  reaching the end of its  <span class="math">i^{\\text{th}}</span>  iteration, we necessarily have  <span class="math">\\overline{f}^{(i)}(v_i, \\dots, v_{\\ell+\\mathcal{R}-1}) \\neq f^{(i)}(v_i, \\dots, v_{\\ell+\\mathcal{R}-1})</span> , or in other words  <span class="math">(v_i, \\dots, v_{\\ell+\\mathcal{R}-1}) \\in \\Delta(f^{(i)}, \\overline{f}^{(i)})</span> . This guarantee implies a fortiori that  <span class="math">(v_{i+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1}) \\in \\Delta^{(i)}(f^{(i)}, \\overline{f}^{(i)})</span> , by definition of this latter set. Using our assumption whereby the event  <span class="math">E_i</span>  didn't occur, we conclude in turn that  <span class="math">(v_{i+\\vartheta}, \\dots, v_{\\ell-1}) \\in \\Delta(f \\text{old}(f^{(i)}, r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1}), \\text{fold}(\\overline{f}^{(i)}, r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1})</span> . Since  <span class="math">\\overline{f}^{(i+\\vartheta)} = \\text{fold}(\\overline{f}^{(i)}, r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1})</span>  (a consequence of the maximality of  <span class="math">i^*</span> ), this latter set itself equals  <span class="math">\\Delta(f \\text{old}(f^{(i)}, r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1}), \\overline{f}^{(i+\\vartheta)})</span> . We conclude that  <span class="math">f \\text{old}(f^{(i)}, r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1})</span>  ( <span class="math">v_{i+\\vartheta}, \\dots, v_{\\ell+\\mathcal{R}-1}</span> )  <span class="math">v_{\\ell+\\mathcal{R}-1}</span> ), thereby preserving the inductive hypothesis.</p>

    <p class="text-gray-300">Carrying through the induction, we see finally that either  <span class="math">\\mathcal{V}</span>  will abort before finishing its inner loop 3, or else it will have  <span class="math">c_{\\ell} \\neq \\overline{f}^{(\\ell)}(v_{\\ell}, \\dots, v_{\\ell+\\mathcal{R}-1})</span>  as of its final check 7. Since  <span class="math">c = \\overline{f}^{(\\ell)}(v_{\\ell}, \\dots, v_{\\ell+\\mathcal{R}-1})</span>  holds identically for each  <span class="math">v \\in \\mathcal{B}_{\\mathcal{R}}</span>  (by definition of this latter oracle), we see that  <span class="math">\\mathcal{V}</span>  will reject its check  <span class="math">c_{\\ell} \\stackrel{?}{=} c</span> .  <span class="math">\\square</span></p>

    <p class="text-gray-300">We return to the proposition. Lemma 4.25 guarantees (i.e., assuming  <span class="math">E_{i^*}</span>  doesn't occur) that  <span class="math">c_{i^*+\\vartheta} \\in \\Delta(\\operatorname{fold}(f^{(i^*)}, r&#x27;_{i^*}, \\dots, r&#x27;_{i^*+\\vartheta-1}), \\overline{f}^{(i^*+\\vartheta)})</span>  will hold with probability at least  <span class="math">\\frac{1}{|S^{(i^*+\\vartheta)}|} \\cdot \\frac{d_{i^*+\\vartheta}}{2} \\geq \\frac{1}{2} - \\frac{1}{2 \\cdot 2^{\\mathcal{R}}}</span>  in each of the verifier's query iterations. By Lemma 4.26, the verifier will reject in each such iteration (i.e., assuming none of the events  <span class="math">E_{i^*+\\vartheta}, \\dots, E_{\\ell-\\vartheta}</span>  occurs). We see that  <span class="math">\\mathcal{V}</span>  will accept with probability at most  <span class="math">(\\frac{1}{2} + \\frac{1}{2 \\cdot 2^{\\mathcal{R}}})^{\\gamma}</span> , which is negligible (we recall that  <span class="math">\\mathcal{R}</span>  is a positive constant). This completes the proof of the proposition.  <span class="math">\\square</span></p>

    <p class="text-gray-300">In light of Proposition 4.24, we assume that all of  <span class="math">\\mathcal{A}</span> 's oracles are compliant. Under this assumption, we note first that  <span class="math">d(f^{(0)}, C^{(0)}) &lt; \\frac{d_0}{2}</span>  will hold. We see that Algorithm 1 will terminate successfully in step 2 above. We write  <span class="math">t(X_0, \\ldots, X_{\\ell-1}) \\in L[X_0, \\ldots, X_{\\ell-1}]^{\\leq 1}</span>  for the polynomial output by  <span class="math">\\mathcal{E}</span>  in that step.</p>

    <p class="text-gray-300">We now argue that  <span class="math">c=t(r&#x27;_0,\\ldots,r&#x27;_{\\ell-1})</span>  will hold. To this end, we apply Definition 4.18 repeatedly. In the base case i=0, we note that  <span class="math">\\overline{f}^{(0)}</span>  will be the encoding of  <span class="math">P^{(0)}(X)=\\sum_{w\\in\\mathcal{B}_\\ell}t(w)\\cdot X^{(0)}_{\\{w\\}}(X)</span> , precisely by  <span class="math">\\mathcal{E}</span> 's construction of  <span class="math">(t(w))_{w\\in\\mathcal{B}_\\ell}</span> . On the other hand, for each  <span class="math">i\\in\\{0,\\vartheta,\\ldots,\\ell-\\vartheta\\}</span> , writing  <span class="math">P^{(i)}(X)\\in L[X]^{\\prec 2^{\\ell-i}}</span>  for the polynomial for which  <span class="math">\\operatorname{Enc}(P^{(i)})=\\overline{f}^{(i)}</span>  holds, and using our assumption  <span class="math">\\overline{f}^{(i+\\vartheta)}=\\operatorname{fold}(\\overline{f}^{(i)},r&#x27;_i,\\ldots,r&#x27;_{i+\\vartheta-1})</span> , we conclude that  <span class="math">\\overline{f}^{(i+\\vartheta)}</span>  will be exactly the encoding of that polynomial  <span class="math">P^{(i+\\vartheta)}(X)\\in L[X]^{\\prec 2^{\\ell-i-\\vartheta}}</span>  which results from repeatedly applying to  <span class="math">P^{(i)}(X)</span>  the conclusion of Lemma 4.14 (with the folding challenges  <span class="math">r&#x27;_i,\\ldots,r&#x27;_{i+\\vartheta-1}</span> ). Carrying out the induction, we see that  <span class="math">\\overline{f}^{(\\ell)}</span>  will itself be identically equal to  <span class="math">\\sum_{w\\in\\mathcal{B}_\\ell}\\widetilde{\\operatorname{eq}}(w_0,\\ldots,w_{\\ell-1},r&#x27;_0,\\ldots,r&#x27;_{\\ell-1})\\cdot t(w)=t(r&#x27;_0,\\ldots,r&#x27;_{\\ell-1})</span> , so that  <span class="math">c=t(r&#x27;_0,\\ldots,r&#x27;_{\\ell-1})</span>  indeed will hold.</p>

    <p class="text-gray-300">We write  <span class="math">(r_0, \\ldots, r_{\\ell-1}) \\in L^{\\ell}</span>  for the evaluation point output by  <span class="math">\\mathcal{V}</span>  and  <span class="math">s \\in L</span>  for  <span class="math">\\mathcal{A}</span> 's response. To finish the proof, we argue that the probability with which  <span class="math">s \\neq t(r_0, \\ldots, r_{\\ell-1})</span>  and  <span class="math">\\mathcal{V}</span>  accepts is negligible. We assume that  <span class="math">s \\neq t(r_0, \\ldots, r_{\\ell-1})</span> .</p>

    <p class="text-gray-300">As in Construction 4.12, we write  <span class="math">h(X_0,\\ldots,X_{\\ell-1}) \\coloneqq \\widetilde{\\operatorname{eq}}(r_0,\\ldots,r_{\\ell-1},X_0,\\ldots,X_{\\ell-1}) \\cdot t(X_0,\\ldots,X_{\\ell-1})</span>  (here,  <span class="math">t(X_0,\\ldots,X_{\\ell-1})</span>  refers to what  <span class="math">\\mathcal E</span>  extracted). Since  <span class="math">t(r_0,\\ldots,r_{\\ell-1}) = \\sum_{w \\in \\mathcal B_\\ell} h(w)</span> , our assumption  <span class="math">s \\neq t(r_0,\\ldots,r_{\\ell-1})</span>  amounts to the condition  <span class="math">s \\neq \\sum_{w \\in \\mathcal B_\\ell} h(w)</span> . The soundness analysis of the sumcheck (we refer to Thaler [Tha22, &sect; 4.1]) states that, under this very assumption, the probability that the verifier accepts its checks  <span class="math">s_i \\stackrel{?}{=} h_i(0) + h_i(1)</span>  and  <span class="math">s_\\ell = h(r&#x27;_0,\\ldots,r&#x27;_{\\ell-1})</span>  holds is at most  <span class="math">\\frac{2 \\cdot \\ell}{|\\mathcal L|}</span>  over  <span class="math">\\mathcal V</span> 's choice of its folding challenges  <span class="math">(r&#x27;_0,\\ldots,r&#x27;_{\\ell-1})</span> . We thus assume that  <span class="math">s_\\ell \\neq h(r&#x27;_0,\\ldots,r&#x27;_{\\ell-\\kappa-1}) = \\widetilde{\\operatorname{eq}}(r_0,\\ldots,r_{\\ell-1},r&#x27;_0,\\ldots,r&#x27;_{\\ell-1}) \\cdot t(r&#x27;_0,\\ldots,r&#x27;_{\\ell-1})</span> . Our conclusion whereby  <span class="math">c = t(r&#x27;_0,\\ldots,r&#x27;_{\\ell-1})</span> , established above, thus implies that  <span class="math">\\mathcal V</span>  will reject its check</p>

    <p class="text-gray-300"><span class="math">s_{\\ell} \\stackrel{?}{=} \\widetilde{\\mathsf{eq}}(r_0, \\dots, r_{\\ell-1}, r&#x27;_0, \\dots, r&#x27;_{\\ell-1}) \\cdot c</span> . This completes the proof of the theorem.</p>

    <p class="text-gray-300">Remark 4.27. In our proof of Theorem 4.17 above, our emulator  <span class="math">\\mathcal E</span>  runs the Berlekamp&ndash;Welch decoder on the adversary-supplied word  <span class="math">f:S^{(0)}\\to L</span>  (see its step 2). Most analyses of that algorithm (see e.g. [Gur06, Rem. 4]) assume input guaranteed to reside within the unique decoding radius, and implicitly leave undefined the algorithm's behavior on arbitrary words. The behavior of Algorithm 1 on a general word  <span class="math">f:S^{(0)}\\to L</span>  is not obvious. As far as our proof of Theorem 4.17 is concerned, we need merely the guarantee whereby, regardless of its input, Algorithm 1&mdash;and hence also  <span class="math">\\mathcal E</span> &mdash;will run in strict polynomial time. (This guarantee follows self-evidently from Algorithm 1's description.) Indeed, if  <span class="math">\\mathcal A</span>  submits a word f outside of the unique decoding radius, then&mdash;as our Propositions 4.23 and 4.24 above show&mdash; <span class="math">\\mathcal V</span>  will reject with overwhelming probability in any case, so that  <span class="math">\\mathcal E</span> 's output ultimately doesn't matter. As it happens&mdash;and as we show in Lemma 2.1 above&mdash;on input f outside of the unique decoding radius, Algorithm 1 will return  <span class="math">\\bot</span> .</p>

      <h3 id="sec-4.4" class="text-xl font-semibold mt-8">4.4 Efficiency</h3>

    <p class="text-gray-300">We discuss the efficiency of Construction 4.12. We count L-operations throughout. Though the choices  <span class="math">\\deg(L/\\mathbb{F}_2) = \\omega(\\log \\lambda)</span>  and  <span class="math">\\gamma = \\omega(\\log \\lambda)</span>  suffice to make that construction's soundness error negligible, we in fact set  <span class="math">\\deg(L/\\mathbb{F}_2) = \\lambda</span>  and  <span class="math">\\gamma = \\lambda</span> . These latter choices make Construction 4.12 exponentially secure, and make its efficiency easier to analyze. As usual, we understand the positive integers  <span class="math">\\mathcal{R}</span>  and  <span class="math">\\vartheta</span>  as constants.</p>

    <p class="text-gray-300"><strong>Prover cost.</strong> In its commitment phase 2, our prover must use Lin, Chung and Han's additive NTT [LCH14] to encode its length- <span class="math">2^{\\ell}</span>  vector  <span class="math">(t(w))_{w \\in \\mathcal{B}_{\\ell}}</span>  onto  <span class="math">S^{(0)}</span>  (see also Algorithm 2 above). For this task,  <span class="math">2^{\\ell+\\mathcal{R}-1} \\cdot \\ell</span>  L-multiplications and  <span class="math">2^{\\ell+\\mathcal{R}} \\cdot \\ell</span>  L-additions suffice (see also Subsection 2.3).</p>

    <p class="text-gray-300">To prepare its sumcheck 2, the prover must tensor-expand  <span class="math">(\\widetilde{\\operatorname{eq}}(r_0,\\ldots,r_{\\ell-1},w_0,\\ldots,w_{\\ell-1}))_{w\\in\\mathcal{B}_\\ell}</span> ; this task takes  <span class="math">2^\\ell</span>  L-additions and  <span class="math">2^\\ell</span>  L-multiplications (recall Subsection 2.1). Our prover can carry out that sumcheck itself also in  <span class="math">O(2^\\ell)</span>  time (we refer to Thaler [Tha22, &sect; 4.1]). Our prover is thus linear-time.</p>

    <p class="text-gray-300">Verifier cost. To carry out the sumcheck 2, Construction 4.12's verifier must expend just  <span class="math">O(\\ell)</span>  L-operations. It can compute  <span class="math">\\widetilde{\\operatorname{eq}}(r_0,\\ldots,r_{\\ell-1},r&#x27;_0,\\ldots,r&#x27;_{\\ell-1})</span>  in step 3 in again  <span class="math">O(\\ell)</span>  L-operations. During its querying phase 4, the verifier must finally, for  <span class="math">\\gamma=\\lambda</span>  repetitions, make  <span class="math">2^{\\vartheta} \\cdot \\frac{\\ell}{\\vartheta} = O(\\ell)</span>  queries to the IOP oracle and perform  <span class="math">O\\left(2^{\\vartheta} \\cdot \\frac{\\ell}{\\vartheta}\\right) = O(\\ell)</span>  L-operations. Its total cost during that phase is thus  <span class="math">O(\\lambda \\cdot \\ell)</span>  L-operations.</p>

    <p class="text-gray-300">The BCS transform. In practice, we must use Ben-Sasson, Chiesa and Spooner's transformation [BCS16] to turn Construction 4.12 into an interactive protocol in the random oracle model. The resulting compiled protocol imposes further costs on both parties, as we now explain. First, its prover must moreover Merklehash both  <span class="math">f^{(0)}</span>  during its commitment phase and the positive-indexed oracles  <span class="math">f^{(\\vartheta)}, \\ldots, f^{(\\ell-\\vartheta)}</span>  during its evaluation phase; these commitments represent total work on the order of  <span class="math">O(2^{\\ell+\\mathcal{R}}) = O(2^{\\ell})</span>  hash invocations.</p>

    <p class="text-gray-300">During the querying phase, both parties must handle Merkle paths. During each query repetition, the total length of all Merkle paths sent (measured in digests) is on the order of  <span class="math">O((\\ell + \\mathcal{R})^2) = O(\\ell^2)</span> . Since there are  <span class="math">\\gamma = \\lambda</span>  total repetitions, the total cost for both parties during the querying phase is thus  <span class="math">O(\\lambda \\cdot \\ell^2)</span>  hash operations.</p>

    </section>

    <section id="sec-5" class="mb-10">
      <h2 class="text-2xl font-bold">5 Unrolled Small-Field IOPCS</h2>

    <p class="text-gray-300">In this section, we describe a one-shot small-field IOPCS construction. This construction inlines the large-field IOPCS of Section 4 into the ring-switching reduction of Section 3. We moreover streamline the resulting combination, by applying a few optimizations. That is, we unify Construction 4.12's sumcheck with that already required within Construction 3.1.</p>

      <h3 id="sec-5.1" class="text-xl font-semibold mt-8">5.1 Combined Small-Field Protocol</h3>

    <p class="text-gray-300">We present our full combined protocol below. Our protocol directly instantiates the generic small-field template of Definition 2.10, though we insist below that the small field K supplied to that template be binary.</p>

    <h3 id="sec-misc-6" class="text-xl font-semibold mt-8">CONSTRUCTION 5.1 (Combined Small-Field IOPCS).</h3>

    <p class="text-gray-300">We define  <span class="math">\\Pi = (\\mathsf{Setup}, \\mathsf{Commit}, \\mathcal{P}, \\mathcal{V})</span>  as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>params  <span class="math">\\leftarrow \\Pi.\\mathsf{Setup}(1^{\\lambda}, \\ell, K)</span> . On input  <span class="math">1^{\\lambda}</span> ,  <span class="math">\\ell</span> , and K, choose a constant, positive rate parameter  <span class="math">\\mathcal{R} \\in \\mathbb{N}</span>  and an extension field L/K of power-of-two degree  <span class="math">2^{\\kappa}</span>  (say) over K, whose degree, say r, over  <span class="math">\\mathbb{F}_2</span>  satisfies  <span class="math">r = \\omega(\\log \\lambda)</span>  and  <span class="math">r \\geq \\ell + \\mathcal{R}</span> . Write  <span class="math">\\ell&#x27; \\coloneqq \\ell - \\kappa</span>  and  <span class="math">A \\coloneqq L \\otimes_K L</span> . Initialize the oracle  <span class="math">\\mathcal{F}_{\\mathsf{Vec}}^L</span> . Fix a folding factor  <span class="math">\\vartheta \\mid \\ell&#x27;</span>  and a repetition parameter  <span class="math">\\gamma = \\omega(\\log \\lambda)</span> . Write  <span class="math">(X_0(X), \\ldots, X_{2\\ell&#x27;-1}(X))</span> for the novel L-basis of  <span class="math">L[X]^{\\prec 2^{\\ell&#x27;}}</span> , and fix  <span class="math">S^{(0)}, \\ldots, S^{(\\ell&#x27;)}</span>  and  <span class="math">q^{(0)}, \\ldots, q^{(\\ell&#x27;-1)}</span>  as in Subsection 4.1. Write  <span class="math">C^{(0)} \\subset L^{2^{\\ell&#x27;+\\mathcal{R}}}</span>  for the Reed&ndash;Solomon code  <span class="math">\\mathsf{RS}_{L,S^{(0)}}[2^{\\ell&#x27;+\\mathcal{R}},2^{\\ell&#x27;}].</span></li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">[f] \\leftarrow \\Pi.\\mathsf{Commit}(\\mathsf{params},t)</span> . On input  <span class="math">t(X_0,\\ldots,X_{\\ell-1}) \\in K[X_0,\\ldots,X_{\\ell-1}]^{\\preceq 1}</span> , construct as in Definition 2.2 the packed polynomial  <span class="math">t&#x27;(X_0,\\ldots,X_{\\ell&#x27;-1}) \\in L[X_0,\\ldots,X_{\\ell&#x27;-1}]^{\\preceq 1}</span> . Write  <span class="math">P(X) \\coloneqq</span>  <span class="math">\\sum_{v \\in \\mathcal{B}_{gl}} t&#x27;(v) \\cdot X_{\\{v\\}}(X)</span>  for its univariate flattening. Using Algorithm 2, compute the Reed&ndash;Solomon codeword  <span class="math">f: S^{(0)} \\to L</span>  defined by  <span class="math">f: x \\mapsto P(x)</span> . Submit (submit,  <span class="math">\\ell&#x27; + \\mathcal{R}, f</span> ) to the vector oracle  <span class="math">\\mathcal{F}_{\\text{Vec}}^{L}</span> . Upon receiving (receipt,  <span class="math">\\ell&#x27; + \\mathcal{R}</span> , [f]) from the oracle, output the commitment [f].</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">We define  <span class="math">(\\mathcal{P}, \\mathcal{V})</span>  as the following IOP, in which both parties have the common input [f],  <span class="math">s \\in L</span> , and  <span class="math">(r_0,\\ldots,r_{\\ell-1})\\in L^\\ell</span> , and  <span class="math">\\mathcal{P}</span>  has the further input  <span class="math">t(X_0,\\ldots,X_{\\ell-1})\\in L[X_0,\\ldots,X_{\\ell-1}]^{\\leq 1}</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{P}</span>  computes  <span class="math">\\hat{s} := \\varphi_1(t&#x27;)(\\varphi_0(r_{\\kappa}), \\ldots, \\varphi_0(r_{\\ell-1}))</span>  and sends  <span class="math">\\mathcal{V}</span>  the A-element  <span class="math">\\hat{s}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{V}</span>  decomposes  <span class="math">\\hat{s} =: \\sum_{v \\in \\mathcal{B}_u} \\hat{s}_v \\otimes \\beta_v</span> .  <span class="math">\\mathcal{V}</span>  requires  <span class="math">s \\stackrel{?}{=} \\sum_{v \\in \\mathcal{B}_u} \\widetilde{\\text{eq}}(v_0, \\dots, v_{\\kappa-1}, r_0, \\dots, r_{\\kappa-1}) \\cdot \\hat{s}_v</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{V}</span>  samples batching scalars  <span class="math">(r&#x27;&#x27;_0, \\ldots, r&#x27;&#x27;_{\\kappa-1}) \\leftarrow L^{\\kappa}</span>  and sends them to  <span class="math">\\mathcal{P}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>For each  <span class="math">w \\in \\mathcal{B}_{\\ell&#x27;}</span> ,  <span class="math">\\mathcal{P}</span>  decomposes  <span class="math">\\widetilde{\\operatorname{eq}}(r_{\\kappa}, \\dots, r_{\\ell-1}, w_0, \\dots, w_{\\ell&#x27;-1}) =: \\sum_{u \\in \\mathcal{B}_{\\kappa}} A_{w,u} \\cdot \\beta_u</span> .  <span class="math">\\mathcal{P}</span>  defines the function  <span class="math">A: w \\mapsto \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{\\operatorname{eq}}(u_0, \\dots, u_{\\kappa-1}, r_0&#x27;&#x27;, \\dots, r_{\\kappa-1}&#x27;&#x27;) \\cdot A_{w,u}</span>  on  <span class="math">\\mathcal{B}_{\\ell&#x27;}</span>  and writes  <span class="math">A(X_0, \\dots, X_{\\ell&#x27;-1})</span>  for its multilinear extension.  <span class="math">\\mathcal{P}</span>  defines  <span class="math">h(X_0, \\dots, X_{\\ell&#x27;-1}) := A(X_0, \\dots, X_{\\ell&#x27;-1}) \\cdot t&#x27;(X_0, \\dots, X_{\\ell&#x27;-1})</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{V}</span>  decomposes  <span class="math">\\hat{s} =: \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes \\hat{s}_u</span> , and sets  <span class="math">s_0 := \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{eq}(u_0, \\dots, u_{\\kappa-1}, r_0&#x27;&#x27;, \\dots, r_{\\kappa-1}&#x27;&#x27;) \\cdot \\hat{s}_u</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{P}</span>  and  <span class="math">\\mathcal{V}</span>  both abbreviate  <span class="math">f^{(0)} := f</span> , and execute the following loop:</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><p class="text-gray-300">1: <strong>for</strong>  <span class="math">i \\in \\{0, \\dots, \\ell&#x27; 1\\}</span>  <strong>do</strong></p></li>
      <li><p class="text-gray-300"><span class="math">\\mathcal{P}</span>  sends  <span class="math">\\mathcal{V}</span>  the polynomial  <span class="math">h_i(X) := \\sum_{w \\in \\mathcal{B}_{\\ell&#x27;-i-1}} h(r&#x27;_0, \\dots, r&#x27;_{i-1}, X, w_0, \\dots, w_{\\ell&#x27;-i-2}).</span></p></li>
      <li><p class="text-gray-300"><span class="math">\\mathcal{V}</span>  requires  <span class="math">s_i \\stackrel{?}{=} h_i(0) + h_i(1)</span> .  <span class="math">\\mathcal{V}</span>  samples  <span class="math">r_i&#x27; \\leftarrow L</span> , sets  <span class="math">s_{i+1} \\coloneqq h_i(r_i&#x27;)</span> , and sends  <span class="math">\\mathcal{P}</span>   <span class="math">r_i&#x27;</span> .  <span class="math">\\mathcal{P}</span>  defines  <span class="math">f^{(i+1)}: S^{(i+1)} \\to L</span>  as the function  <span class="math">\\mathsf{fold}(f^{(i)}, r_i&#x27;)</span>  of Definition 4.6.</p></li>
      <li><p class="text-gray-300">if  <span class="math">i+1=\\ell&#x27;</span>  then  <span class="math">\\mathcal{P}</span>  sends  <span class="math">c \\coloneqq f^{(\\ell&#x27;)}(0,\\ldots,0)</span>  to  <span class="math">\\mathcal{V}</span> . 5:</p></li>
      <li><p class="text-gray-300">else if  <span class="math">\\vartheta \\mid i+1</span>  then  <span class="math">\\mathcal{P}</span>  submits (submit,  <span class="math">\\ell&#x27; + \\mathcal{R} i 1, f^{(i+1)}</span> ) to the oracle.</p></li>
    </ul></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{V}</span>  sets  <span class="math">e := \\widetilde{\\text{eq}}(\\varphi_0(r_{\\kappa}), \\dots, \\varphi_0(r_{\\ell-1}), \\varphi_1(r&#x27;_0), \\dots, \\varphi_1(r&#x27;_{\\ell&#x27;-1}))</span>  and decomposes  <span class="math">e := \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\beta_u \\otimes e_u</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{V}</span>  requires  <span class="math">s_{\\ell&#x27;} \\stackrel{?}{=} \\left( \\sum_{u \\in \\mathcal{B}_{\\kappa}} \\widetilde{eq}(u_0, \\dots, u_{\\kappa-1}, r_0&#x27;&#x27;, \\dots, r_{\\kappa-1}&#x27;&#x27;) \\cdot e_u \\right) \\cdot c</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{V}</span>  executes the following querying procedure:</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>1: <strong>for</strong>  <span class="math">\\gamma</span>  repetitions <strong>do</strong></li>
      <li><span class="math">\\mathcal{V}</span>  samples  <span class="math">v \\leftarrow \\mathcal{B}_{\\ell&#x27; + \\mathcal{R}}</span>  randomly.</li>
      <li>for  <span class="math">i \\in \\{0, \\vartheta, \\dots, \\ell&#x27; \\vartheta\\}</span>  (i.e., taking  <span class="math">\\vartheta</span> -sized steps) do 3:</li>
      <li>for each  <span class="math">u \\in \\mathcal{B}_{\\vartheta}</span> ,  <span class="math">\\mathcal{V}</span>  sends (query,  <span class="math">[f^{(i)}], (u_0, \\dots, u_{\\vartheta-1}, v_{i+\\vartheta}, \\dots, v_{\\ell&#x27;+\\mathcal{R}-1})</span> ) to the oracle. 4:</li>
      <li>if i &gt; 0 then  <span class="math">\\mathcal{V}</span>  requires  <span class="math">c_i \\stackrel{?}{=} f^{(i)}(v_i, \\dots, v_{\\ell&#x27; + \\mathcal{R} 1})</span> .</li>
      <li><span class="math">\\mathcal{V}</span>  defines  <span class="math">c_{i+\\vartheta} := \\mathsf{fold}(f^{(i)}, r&#x27;_i, \\dots, r&#x27;_{i+\\vartheta-1})(v_{i+\\vartheta}, \\dots, v_{\\ell&#x27;+\\mathcal{R}-1}).</span> 6:</li>
      <li><span class="math">\\mathcal{V}</span>  requires  <span class="math">c_{\\ell&#x27;} \\stackrel{?}{=} c</span> . 7:</li>
    </ul></li>
    </ul>

    <p class="text-gray-300">The completeness and security of Construction 5.1 are a consequence of techniques that we've already expounded in Sections 3 and 4 above.</p>

      <h3 id="sec-5.2" class="text-xl font-semibold mt-8">5.2 Efficiency</h3>

    <p class="text-gray-300">In this subsection, we discuss the concrete efficiency of our combined Construction 5.1.</p>

    <p class="text-gray-300">We make use of various concrete proof size optimizations in our implementation. For example, for each oracle  <span class="math">i \\in \\{0, \\vartheta, \\dots, \\ell&#x27; - \\vartheta\\}</span> , we opt to send the entire  <span class="math">j^{\\text{th}}</span>  layer of the Merkle tree&mdash;as opposed to just its root&mdash;for an appropriately chosen constant  <span class="math">j \\geq 0</span> . This optimization is a fixed-cost-variable-cost tradeoff. As j grows, the size of each Merkle commitment grows (exponentially); on the other hand, each of the  <span class="math">\\gamma</span>  subsequently sent paths becomes shorter. The optimal truncation height turns out to be  <span class="math">j := \\lceil \\log_2(\\gamma) \\rceil</span> . Each path ultimately sent is of size  <span class="math">\\ell&#x27; + \\mathcal{R} - i - \\vartheta - j</span> .</p>

    <p class="text-gray-300">As soon as  <span class="math">i \\in \\{0, \\vartheta, \\dots, \\ell&#x27; - \\vartheta\\}</span>  becomes so large that  <span class="math">j &gt; \\ell&#x27; + \\mathcal{R} - i - \\vartheta</span>  holds, this optimization becomes nonsensical; at this point, we instruct our prover rather to terminate FRI early and send its entire message to the verifier in the clear. (This measure further allows us to drop our assumption  <span class="math">\\vartheta \\mid \\ell&#x27;</span> , which we picked up merely for notational convenience in the first place.) It can be shown that this termination strategy outperforms&mdash;i.e., yields smaller proofs than&mdash;each strategy that terminates strictly after it. On the other hand, terminating even earlier can do good in some settings. The optimal termination point seems complicated to predict in general, i.e. as a function of  <span class="math">\\theta</span> ,  <span class="math">\\ell&#x27;</span> ,  <span class="math">\\mathcal{R}</span> ,  <span class="math">\\gamma</span>  and j (as well as of global parameters like L, K, and the hash digest width).</p>

    <p class="text-gray-300">Concrete soundness. In order to select the query repetition parameter  <span class="math">\\gamma</span> , we have to understand the concrete security of our protocol. It follows essentially from the proofs of Theorems 3.5 and 4.17 that Construction 5.1's concrete soundness error is bounded from above by</p>

    <p class="text-gray-300">
<span class="math">$\\frac{\\kappa + 2 \\cdot \\ell&#x27;}{|L|} + \\frac{2\\ell&#x27; + \\mathcal{R}}{|L|} + \\left(\\frac{1}{2} + \\frac{1}{2 \\cdot 2\\mathcal{R}}\\right)^{\\gamma}.\\tag{43}</span>$</p>

    <p class="text-gray-300">Above, the first summand comes from ring-switching and the sumcheck; the latter two reflect Propositions 4.23 and 4.24, respectively. For each desired <em>concrete security</em> level  <span class="math">\\Xi</span> , we thus set  <span class="math">\\gamma</span>  minimally so that (43) becomes bounded from above by  <span class="math">\\Xi</span> . (Clearly, this is possible only when L is sufficiently large that  <span class="math">\\Xi &gt; \\frac{\\kappa + 2 \\cdot \\ell&#x27;}{|L|} + \\frac{2^{\\ell&#x27; + \\mathcal{R}}}{|L|}</span>  holds.) We say in this case that Construction 5.1 attains  <span class="math">-\\log_2(\\Xi)</span>  bits of security.</p>

    <p class="text-gray-300"><strong>Proof sizes.</strong> In Table 1 below, we tabulate various proof sizes. We compare [DP25, Cons. 3.11] and Construction 5.1 on input polynomials  <span class="math">t(X_0, \\ldots, X_{\\ell-1})</span>  over  <span class="math">\\mathbb{F}_2</span> . In each case, we process evaluation claims over  <span class="math">\\mathbb{F}_{2^{128}}</span> , and attain 100 bits of provable security. We vary both the number of variables  <span class="math">\\ell</span>  and the rate parameter  <span class="math">\\mathcal{R}</span> . We recall that  <span class="math">\\rho = \\frac{1}{2^{\\mathcal{R}}}</span> ; we thus test the rates  <span class="math">\\rho = \\frac{1}{2}</span> ,  <span class="math">\\rho = \\frac{1}{4}</span> , and  <span class="math">\\rho = \\frac{1}{8}</span>  in each case.</p>

    <p class="text-gray-300">In our benchmarks of Construction 5.1, we use the folding factor  <span class="math">\\vartheta := 4</span>  and the Merkle cap height j := 8.</p>

    <p class="text-gray-300"></p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Num. Variables <span class="math">\\ell</span></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Log Inverse Rate <span class="math">\\mathcal{R}</span></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">[DP25, Cons. 3.11]</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Construction 5.1</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">24 (2 MiB)</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">0.922~\\mathrm{MiB}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.202 MiB</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.758 MiB</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.143 MiB</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.681 MiB</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.129 MiB</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">28 (32 MiB)</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">3.562 MiB</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.342 MiB</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2.935 MiB</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.237 MiB</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">2.629~\\mathrm{MiB}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.210 MiB</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">32 (512 MiB)</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">14.050 MiB</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.514 MiB</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">11.598 MiB</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.351 MiB</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">14.376 MiB</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.336 MiB</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">Table 1: Proof sizes of polynomial commitment schemes for  <span class="math">\\mathbb{F}_2</span> -multilinears.</p>

    <p class="text-gray-300"><strong>Concrete performance.</strong> We concretely benchmark this work's Construction 5.1, as well as the univariate-FRI-based scheme <em>Plonky3</em>. Our benchmarks of our scheme use <em>Binius</em>, an open-source SNARK that uses this work as its PCS.</p>

    <p class="text-gray-300">In each of our performance benchmarks below, we use a 128-bit field. In this work, we use the <em>GHASH</em> [GLL19] field  <span class="math">\\mathbb{F}_2[X] / (X^{128} + X^7 + X^2 + X + 1) \\cong \\mathbb{F}_{2^{128}}</span> . In Plonky3, we use the quartic extension  <span class="math">\\mathbb{F}_p[X] / (X^4 - 11) \\cong \\mathbb{F}_{p^4}</span>  of the <em>Baby Bear</em> prime field  <span class="math">\\mathbb{F}_p</span> , where  <span class="math">p := 2^{31} - 2^{27} + 1</span> .</p>

    <p class="text-gray-300">Throughout our concrete benchmarks, we use the code rate  <span class="math">\\rho = \\frac{1}{2}</span>  and attain 100 bits of provable security. We work exclusively in the unique-decoding regime. Both [DP25, Cons. 3.11] and this work have been proven secure only in that regime (thus far). As for Plonky3, we note that it's impossible to obtain 100 bits of provable security in the <em>list-decoding regime</em> over a field of merely 128 bits. The best available proximity gap in that regime, namely [Ben+23, Thm. 5.1], has a batching error [Ben+23, (5.3)] whose numerator grows quadratically in the problem size. On each reasonably large problem instance, that result will yield an error term greater than or equal to  <span class="math">2^{-100}</span> , thus making the protocol's total error greater than  <span class="math">2^{-100}</span>  regardless of the number of queries made. Our benchmarks below thus reflect the best-possible proof size attainable in Plonky3, conditioned on the 100-bit security level and the use of a 128-bit field.</p>

    <p class="text-gray-300">We benchmark this work's Construction 5.1 on 28-variate polynomials over  <span class="math">\\mathbb{F}_2</span> . We benchmark Plonky3's performance on <em>batches</em> consisting of 16 polynomials over Baby Bear, each of degree  <span class="math">2^{24}</span> . The <em>total</em> number of coefficients is thus the same&mdash;i.e.,  <span class="math">2^{28}</span> &mdash;in all benchmarks.</p>

    <p class="text-gray-300">We explain this methodology further. The most natural benchmark would have compared our scheme's performance on 28-variate multilinear polynomials to Plonky3's on single, degree-2<sup>28</sup> univariate polynomials. On the other hand, Plonky3's FRI-PCS implementation is heavily optimized towards the batched case. In order to be more fair to Plonky3, we run that work in the batched setting. As it happens, in our own (non-batched) scheme, we incorporate a straightforward <em>interleaving optimization</em> that serves to reduce by 4 the number of butterfly stages our commitment phase must carry out. In sum, both our scheme (operating on single multilinear polynomials) and Plonky3's (operating on size-16 batches of univariate polynomials) must perform NTTs of essentially the same shape and size. This fact makes our benchmarks comparable.</p>

    <p class="text-gray-300">Plonky3 does not implement the higher-arity FRI folding or Merkle-caps optimizations. In order to make it easier to make apples-to-apples comparisons between our work and theirs, we benchmark our scheme both with and without these optimizations enabled. We note that these optimizations are free wins, and yield a monotonically superior protocol. There is no reason&mdash;in any practical deployment&mdash;that we would voluntarily switch them off; the purpose is just for comparison. We emphasize that our proofs become much larger when these optimizations are disabled. We write &quot;Cons. 5.1*&quot; for the unoptimized version of our scheme, i.e. for which Merkle caps and oracle-skipping are both switched off (in the language used above, we set  <span class="math">\\vartheta=1</span>  and also j=0).</p>

    <p class="text-gray-300">In our benchmarks, we use an AWS machine of type c7i.8xlarge, with a 4<sup>th</sup>-generation Intel <em>Xeon Scalable</em> processor, 32 virtual cores, and 64 GiB of memory. Both the Binius and Plonky3 implementations leverage AVX-512 accelerated instructions; Binius moreover uses the Intel <em>Carry-less Multiplication</em> (CLMUL) instruction set extension. In all schemes, we use SHA-256 for Merklization. We present both singlethreaded (ST) and multithreaded (MT) benchmarks. We present our results in Table 2 below.</p>

    <p class="text-gray-300"></p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Protocol</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Proof Size</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Commit (ST)</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Commit (MT)</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Prove (ST)</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Prove (MT)</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Verify (ST)</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Plonky3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.931 MiB</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">24{,}893~\\mathrm{ms}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">3,991  ms</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">13{,}257~\\mathrm{ms}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">1{,}794~\\mathrm{ms}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">18.2 ms</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Cons. 5.1</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">0.351~\\mathrm{MiB}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">144 ms</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">44 ms</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">160 ms</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">71 ms</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">0.7~\\mathrm{ms}</span></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Cons. 5.1*</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.930 MiB</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">143 ms</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">44 ms</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">181 ms</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">75 ms</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.8 ms</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">Table 2: Concrete performance benchmarks.</p>

    <p class="text-gray-300">Our scheme outperforms the state-of-the-art scheme Plonky3 by between one and two orders of magnitude, across all computational performance metrics. Our proofs are also smaller than theirs, by more than fivefold.</p>

    </section>

    <section id="references" class="mb-10">
      <h2 class="text-2xl font-bold">References</h2>

    <ul class="space-y-2 text-gray-400 text-sm list-none">
      <li><p class="text-gray-300">[ACFY25] Gal Arnon, Alessandro Chiesa, Giacomo Fenzi, and Eylon Yogev. &quot;WHIR: Reed-Solomon Proximity Testing with Super-Fast Verification&quot;. In: Advances in Cryptology &ndash; EUROCRYPT 2025. Ed. by Serge Fehr and Pierre-Alain Fouque. Cham: Springer Nature Switzerland, 2025, pp. 214&ndash;243. ISBN: 978-3-031-91134-7.</p></li>
      <li><p class="text-gray-300">[AER24] Guillermo Angeris, Alex Evans, and Gyumin Roh. A Note on Ligero and Logarithmic Randomness. Cryptology ePrint Archive, Paper 2024/1399. 2024. URL: https://eprint.iacr.org/2024/1399.</p></li>
      <li><p class="text-gray-300">[AHIV23] Scott Ames, Carmit Hazay, Yuval Ishai, and Muthuramakrishnan Venkitasubramaniam. &quot;Ligero: lightweight sublinear arguments without a trusted setup&quot;. In: <em>Designs, Codes and Cryptography</em> (2023). DOI: 10.1007/s10623-023-01222-8.</p></li>
      <li><p class="text-gray-300">[BBHR18a] Eli Ben-Sasson, Iddo Bentov, Yinon Horesh, and Michael Riabzev. &quot;Fast Reed-Solomon Interactive Oracle Proofs of Proximity&quot;. In: International Colloquium on Automata, Languages, and Programming. Ed. by Ioannis Chatzigiannakis, Christos Kaklamanis, D&aacute;niel Marx, and Donald Sannella. Vol. 107. Leibniz International Proceedings in Informatics. Dagstuhl, Germany: Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2018, 14:1&ndash;14:17. DOI: 10.4230/LIPIcs.ICALP.2018.14.</p></li>
      <li><p class="text-gray-300">[BBHR18b] Eli Ben-Sasson, Iddo Bentov, Yinon Horesh, and Michael Riabzev. Scalable, transparent, and post-quantum secure computational integrity. Cryptology ePrint Archive, Paper 2018/046. 2018. URL: https://eprint.iacr.org/2018/046.</p></li>
      <li><p class="text-gray-300">[BCG20] Jonathan Bootle, Alessandro Chiesa, and Jens Groth. &quot;Linear-Time Arguments with Sublinear Verification from Tensor Codes&quot;. In: <em>Theory of Cryptography</em>. Ed. by Rafael Pass and Krzysztof Pietrzak. Cham: Springer International Publishing, 2020, pp. 19&ndash;46. ISBN: 978-3-030-64378-2. DOI: 10.1007/978-3-030-64378-2_2.</p></li>
      <li><p class="text-gray-300">[BCS16] Eli Ben-Sasson, Alessandro Chiesa, and Nicholas Spooner. &quot;Interactive Oracle Proofs&quot;. In: International Conference on Theory of Cryptography. Vol. 9986. Berlin, Heidelberg: Springer-Verlag, 2016, pp. 31&ndash;60. ISBN: 978-3-662-53644-5. DOI: 10.1007/978-3-662-53644-5_2.</p></li>
      <li><p class="text-gray-300">[Ben+23] Eli Ben-Sasson, Dan Carmon, Yuval Ishai, Swastik Kopparty, and Shubhangi Saraf. &quot;Proximity Gaps for Reed&ndash;Solomon Codes&quot;. In: <em>Journal of the ACM</em> 70.5 (Oct. 2023). DOI: 10.1145/3614423.</p></li>
      <li><p class="text-gray-300">[BGKS19] Eli Ben-Sasson, Lior Goldberg, Swastik Kopparty, and Shubhangi Saraf. <em>DEEP-FRI: Sampling Outside the Box Improves Soundness</em>. Cryptology ePrint Archive, Paper 2019/336. 2019. URL: https://eprint.iacr.org/2019/336.</p></li>
      <li><p class="text-gray-300">[Bre+25] Martijn Brehm, Binyi Chen, Ben Fisch, Nicolas Resch, Ron D. Rothblum, and Hadas Zeilberger. &quot;Blaze: Fast SNARKs from Interleaved RAA Codes&quot;. In: <em>Advances in Cryptology &ndash; EUROCRYPT 2025</em>. Ed. by Serge Fehr and Pierre-Alain Fouque. Cham: Springer Nature Switzerland, 2025, pp. 123&ndash;152. ISBN: 978-3-031-91134-7.</p></li>
      <li><p class="text-gray-300">[Can89] David G Cantor. &quot;On arithmetical algorithms over finite fields&quot;. In: <em>Journal of Combinatorial Theory, Series A</em> 50.2 (1989), pp. 285&ndash;300. DOI: https://doi.org/10.1016/0097-3165(89) 90020-4.</p></li>
      <li><p class="text-gray-300">[CBBZ23] Binyi Chen, Benedikt B&uuml;nz, Dan Boneh, and Zhenfei Zhang. &quot;HyperPlonk: Plonk with Linear-Time Prover and High-Degree Custom Gates&quot;. In: <em>Advances in Cryptology &ndash; EUROCRYPT 2023</em>. Ed. by Carmit Hazay and Martijn Stam. Vol. 14005. Lecture Notes in Computer Science. Cham: Springer Nature Switzerland, 2023.</p></li>
      <li><p class="text-gray-300">[Chi+20] Alessandro Chiesa, Yuncong Hu, Mary Maller, Pratyush Mishra, Noah Vesely, and Nicholas Ward. &quot;Marlin: Preprocessing zkSNARKs with Universal and Updatable SRS&quot;. In: <em>Advances in Cryptology &ndash; EUROCRYPT 2020</em>. Ed. by Anne Canteaut and Yuval Ishai. Lecture Notes in Computer Science. Full version. Cham: Springer International Publishing, 2020, pp. 738&ndash;768. ISBN: 978-3-030-45721-1. DOI: 10.1007/978-3-030-45721-1_26.</p></li>
      <li><p class="text-gray-300">[COS20] Alessandro Chiesa, Dev Ojha, and Nicholas Spooner. &quot;Fractal: Post-quantum and Transparent Recursive Proofs from Holography&quot;. In: Advances in Cryptology &ndash; EUROCRYPT 2020. Ed. by Anne Canteaut and Yuval Ishai. Cham: Springer International Publishing, 2020, pp. 769&ndash;793. isbn: 978-3-030-45721-1. doi: <a href="https://doi.org/10.1007/978-3-030-45721-1%7B_%7D27" target="_blank" rel="noopener noreferrer">10.1007/978-3-030-45721-1{\\_}27</a>.</p></li>
      <li><p class="text-gray-300">[DG25] Benjamin E. Diamond and Angus Gruen. &quot;Proximity Gaps in Interleaved Codes&quot;. In: IACR Communications in Cryptology 1.4 (Jan. 13, 2025). issn: 3006-5496. doi: <a href="https://doi.org/10.62056/a0ljbkrz" target="_blank" rel="noopener noreferrer">10.62056/a0ljbkrz</a>.</p></li>
      <li><p class="text-gray-300">[DP24] Benjamin E. Diamond and Jim Posen. &quot;Proximity Testing with Logarithmic Randomness&quot;. In: IACR Communications in Cryptology 1.1 (2024). issn: 3006-5496. doi: <a href="https://doi.org/10.62056/aksdkp10" target="_blank" rel="noopener noreferrer">10.62056/aksdkp10</a>.</p></li>
      <li><p class="text-gray-300">[DP25] Benjamin E. Diamond and Jim Posen. &quot;Succinct Arguments over Towers of Binary Fields&quot;. In: Advances in Cryptology &ndash; EUROCRYPT 2025. Ed. by Serge Fehr and Pierre-Alain Fouque. Cham: Springer Nature Switzerland, 2025, pp. 93&ndash;122. isbn: 978-3-031-91134-7.</p></li>
      <li><p class="text-gray-300">[GG13] Joachim von zur Gathen and J&uml;urgen Gerhard. Modern Computer Algebra. 3rd Edition. Cambridge University Press, 2013.</p></li>
      <li><p class="text-gray-300">[GLL19] Shay Gueron, Adam Langley, and Yehuda Lindell. AES-GCM-SIV: Nonce Misuse-Resistant Authenticated Encryption. RFC 8452. Apr. 2019.</p></li>
      <li><p class="text-gray-300">[GM10] Shuhong Gao and Todd Mateer. &quot;Additive Fast Fourier Transforms Over Finite Fields&quot;. In: IEEE Transactions on Information Theory 56.12 (2010), pp. 6265&ndash;6272. doi: <a href="https://doi.org/10.1109/TIT.2010.2079016" target="_blank" rel="noopener noreferrer">10.1109/TIT.</a> <a href="https://doi.org/10.1109/TIT.2010.2079016" target="_blank" rel="noopener noreferrer">2010.2079016</a>.</p></li>
      <li><p class="text-gray-300">[Gol+23] Alexander Golovnev, Jonathan Lee, Srinath Setty, Justin Thaler, and Riad S. Wahby. &quot;Brakedown: Linear-Time and Field-Agnostic SNARKs for R1CS&quot;. In: Advances in Cryptology &ndash; CRYPTO 2023. Ed. by Helena Handschuh and Anna Lysyanskaya. Cham: Springer Nature Switzerland, 2023, pp. 193&ndash;226. doi: <a href="https://doi.org/10.1007/978-3-031-38545-2_7" target="_blank" rel="noopener noreferrer">10.1007/978-3-031-38545-2\\_7</a>.</p></li>
      <li><p class="text-gray-300">[Gur06] Venkatesan Guruswami. Algorithmic Results in List Decoding. Vol. 2. Foundations and Trends in Theoretical Computer Science 2. now publishers, 2006. doi: <a href="https://doi.org/10.1561/0400000007" target="_blank" rel="noopener noreferrer">10.1561/0400000007</a>.</p></li>
      <li><p class="text-gray-300">[GWC19] Ariel Gabizon, Zachary J. Williamson, and Oana Ciobotaru. PLONK: Permutations over Lagrange-bases for Oecumenical Noninteractive arguments of Knowledge. Cryptology ePrint Archive, Paper 2019/953. 2019. url: <a href="https://eprint.iacr.org/2019/953" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2019/953</a>.</p></li>
      <li><p class="text-gray-300">[Hab22] Ulrich Hab&uml;ock. A summary on the FRI low degree test. Cryptology ePrint Archive, Paper 2022/1216. 2022. url: <a href="https://eprint.iacr.org/2022/1216" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2022/1216</a>.</p></li>
      <li><p class="text-gray-300">[Hab24] Ulrich Hab&uml;ock. A note on the G-FFT. Cryptology ePrint Archive, Paper 2024/1036. 2024. url: <a href="https://eprint.iacr.org/2024/1036" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2024/1036</a>.</p></li>
      <li><p class="text-gray-300">[HLP24] Ulrich Hab&uml;ock, David Levit, and Shahar Papini. Circle STARKs. Cryptology ePrint Archive, Paper 2024/278. 2024. url: <a href="https://eprint.iacr.org/2024/278" target="_blank" rel="noopener noreferrer">https://eprint.iacr.org/2024/278</a>.</p></li>
      <li><p class="text-gray-300">[LAH16] S. -J. Lin, T. Y. Al-Naffouri, and Y. S. Han. &quot;FFT Algorithm for Binary Extension Finite Fields and Its Application to Reed&ndash;Solomon Codes&quot;. In: IEEE Transactions on Information Theory 62.10 (2016), pp. 5343&ndash;5358. doi: <a href="https://doi.org/10.1109/TIT.2016.2600417" target="_blank" rel="noopener noreferrer">10.1109/TIT.2016.2600417</a>.</p></li>
      <li><p class="text-gray-300">[Lan02] Serge Lang. Algebra. Revised Third Edition. Vol. 211. Graduate Texts in Mathematics. Springer, 2002.</p></li>
      <li><p class="text-gray-300">[LCH14] Sian-Jheng Lin, Wei-Ho Chung, and Yunghsiang S. Han. &quot;Novel Polynomial Basis and Its Application to Reed&ndash;Solomon Erasure Codes&quot;. In: IEEE 55th Annual Symposium on Foundations of Computer Science. 2014, pp. 316&ndash;325. doi: <a href="https://doi.org/10.1109/FOCS.2014.41" target="_blank" rel="noopener noreferrer">10.1109/FOCS.2014.41</a>.</p></li>
      <li><p class="text-gray-300">[Li+18] Wen-Ding Li, Ming-Shing Chen, Po-Chun Kuo, Chen-Mou Cheng, and Bo-Yin Yang. &quot;Frobenius Additive Fast Fourier Transform&quot;. In: ACM International Symposium on Symbolic and Algebraic Computation. 2018. isbn: 9781450355506. doi: <a href="https://doi.org/10.1145/3208976.3208998" target="_blank" rel="noopener noreferrer">10.1145/3208976.3208998</a>.</p></li>
      <li><p class="text-gray-300">[LN96] Rudolf Lidl and Harald Niederreiter. Finite Fields. Ed. by G.-C. Rota. 2nd. Vol. 20. Encyclopedia of Mathematics and its Applications. Cambridge University Press, 1996. doi: <a href="https://doi.org/10.1017/CBO9780511525926" target="_blank" rel="noopener noreferrer">10.1017/</a> <a href="https://doi.org/10.1017/CBO9780511525926" target="_blank" rel="noopener noreferrer">CBO9780511525926</a>.</p></li>
      <li><p class="text-gray-300">[LX24] Songsong Li and Chaoping Xing. &quot;Fast Fourier transform via automorphism groups of rational function fields&quot;. In: ACM-SIAM Symposium on Discrete Algorithms. 2024, pp. 3836-3859. DOI: 10.1137/1.9781611977912.135. URL: https://epubs.siam.org/doi/abs/10.1137/1.9781611977912.135.</p></li>
      <li><p class="text-gray-300">[MBKM19] Mary Maller, Sean Bowe, Markulf Kohlweiss, and Sarah Meiklejohn. &quot;Sonic: Zero-Knowledge SNARKs from Linear-Size Universal and Updatable Structured Reference Strings&quot;. In: <em>Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security</em>. 2019, pp. 2111&ndash;2128. ISBN: 9781450367479. DOI: 10.1145/3319535.3339817.</p></li>
      <li><p class="text-gray-300">[RR24] Noga Ron-Zewi and Ron Rothblum. &quot;Local Proofs Approaching the Witness Length&quot;. In: Journal of the ACM 71.3 (June 2024). DOI: 10.1145/3661483. URL: https://doi.org/10.1145/3661483.</p></li>
      <li><p class="text-gray-300">[Set20] Srinath Setty. &quot;Spartan: Efficient and General-Purpose zkSNARKs Without Trusted Setup&quot;. In: Advances in Cryptology &ndash; CRYPTO 2020. Ed. by Daniele Micciancio and Thomas Ristenpart. Cham: Springer International Publishing, 2020, pp. 704&ndash;737. ISBN: 978-3-030-56877-1. DOI: 10.1007/978-3-030-56877-1_25.</p></li>
      <li><p class="text-gray-300">[Sou24] Lev Soukhanov. &quot;Hashcaster&quot;. Unpublished report. Sept. 2024. URL: https://hackmd.io/ @levs57/SJ4fuZMD0#Hashcaster.</p></li>
      <li><p class="text-gray-300">[Tha22] Justin Thaler. <em>Proofs, Arguments and Zero-Knowledge</em>. Vol. 4. Foundations and Trends in Privacy and Security 2&ndash;4. now publishers, 2022.</p></li>
      <li><p class="text-gray-300">[Wat79] William C. Waterhouse. &quot;The Normal Basis Theorem&quot;. In: <em>The American Mathematical Monthly</em> 86.3 (1979), pp. 212&ndash;212. URL: http://www.jstor.org/stable/2321527.</p></li>
      <li><p class="text-gray-300">[Xie+19] Tiacheng Xie, Jiaheng Zhang, Yupeng Zhang, Charalampos Papamanthou, and Dawn Song. &quot;Libra: Succinct Zero-Knowledge Proofs with Optimal Prover Computation&quot;. In: <em>Advances in Cryptology - CRYPTO 2019</em>. Berlin, Heidelberg: Springer-Verlag, 2019, pp. 733&ndash;764. ISBN: 978-3-030-26953-1. DOI: 10.1007/978-3-030-26954-8_24.</p></li>
      <li><p class="text-gray-300">[ZCF24] Hadas Zeilberger, Binyi Chen, and Ben Fisch. &quot;BaseFold: Efficient Field-Agnostic Polynomial Commitment Schemes from Foldable Codes&quot;. In: <em>Advances in Cryptology - CRYPTO 2024</em>. Berlin, Heidelberg: Springer-Verlag, 2024, pp. 138&ndash;169. ISBN: 978-3-031-68402-9. DOI: 10.1007/978-3-031-68403-6_5.</p></li>
      <li><p class="text-gray-300">[ZXZS20] Jiaheng Zhang, Tiancheng Xie, Yupeng Zhang, and Dawn Song. &quot;Transparent Polynomial Delegation and Its Applications to Zero Knowledge Proof&quot;. In: <em>IEEE Symposium on Security and Privacy.</em> 2020, pp. 859&ndash;876. ISBN: 2375-1207. DOI: 10.1109/SP40000.2020.00052.</p></li>
    </ul>

    </section>
`;
---

<BaseLayout title="Polylogarithmic Proofs for Multilinears over Binary Towers (2024/504)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2024 &middot; eprint 2024/504
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <PaperDisclaimer eprintUrl={EPRINT_URL} />
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <nav id="toc" class="mb-10 p-6 rounded-lg" style="background: rgba(255,255,255,0.03); border: 1px solid rgba(255,255,255,0.06);">
      <h2 class="text-lg font-bold mb-4">Table of Contents</h2>
      <ol class="space-y-1 text-sm text-gray-300
        list-decimal list-inside">
        <li><a href="#abstract" class="hover:text-white">Abstract</a></li>
        <li>
          <a href="#sec-1" class="hover:text-white">Introduction</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-1.1" class="hover:text-white">Some Historical Remarks</a></li>
            <li><a href="#sec-1.2" class="hover:text-white">Our Contributions</a></li>
            <li><a href="#sec-1.3" class="hover:text-white">Ring-Switching</a></li>
            <li><a href="#sec-1.4" class="hover:text-white">Binary BaseFold</a></li>
            <li><a href="#sec-1.5" class="hover:text-white">Concurrent and Subsequent Works</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-2" class="hover:text-white">Background and Notation</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-2.1" class="hover:text-white">Multilinear Polynomials</a></li>
            <li><a href="#sec-2.2" class="hover:text-white">Error-Correcting Codes</a></li>
            <li><a href="#sec-2.3" class="hover:text-white">The Novel Polynomial Basis</a></li>
            <li><a href="#sec-2.4" class="hover:text-white">FRI</a></li>
            <li><a href="#sec-2.5" class="hover:text-white">Tensor Products of Fields</a></li>
            <li><a href="#sec-2.6" class="hover:text-white">Proximity Gaps</a></li>
            <li><a href="#sec-2.7" class="hover:text-white">Security Definitions</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-3" class="hover:text-white">Ring-Switching</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-3.1" class="hover:text-white">Ring-Switching Protocol</a></li>
            <li><a href="#sec-3.2" class="hover:text-white">Efficiency</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-4" class="hover:text-white">Binary BaseFold</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-4.1" class="hover:text-white">Using FRI in Novel Polynomial Basis</a></li>
            <li><a href="#sec-4.2" class="hover:text-white">FRI Folding, Revisited</a></li>
            <li><a href="#sec-4.3" class="hover:text-white">Our Large-Field IOPCS</a></li>
            <li><a href="#sec-4.4" class="hover:text-white">Efficiency</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-5" class="hover:text-white">Unrolled Small-Field IOPCS</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-5.1" class="hover:text-white">Combined Small-Field Protocol</a></li>
            <li><a href="#sec-5.2" class="hover:text-white">Efficiency</a></li>
          </ol>
        </li>
      </ol>
      <p class="text-xs text-gray-500 mt-4 mb-1 font-semibold">
        Additional
      </p>
      <ul class="space-y-1 text-sm text-gray-400
        list-disc list-inside">
        <li><a href="#references" class="hover:text-white">References</a></li>
      </ul>
    </nav>


    <Fragment set:html={CONTENT} />

    <PaperHistory slug="polylogarithmic-proofs-for-multilinears-over-binary-towers-2024" />
  </article>
</BaseLayout>
