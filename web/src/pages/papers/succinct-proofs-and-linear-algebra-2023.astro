---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2023/1478';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Succinct Proofs and Linear Algebra';
const AUTHORS_HTML = 'Alex Evans, Guillermo Angeris';

const CONTENT = `    <p class="text-gray-300">Alex Evans aevans@baincapital.com Guillermo Angeris gangeris@baincapital.com</p>

    <h6 id="sec-2" class="text-base font-medium mt-4">Abstract</h6>

    <p class="text-gray-300">The intuitions behind succinct proof systems are often difficult to separate from some of the deep cryptographic techniques that are used in their construction. In this paper, we show that, using some simple abstractions, a number of commonly-used tools used in the construction of succinct proof systems may be viewed as basic consequences of linear algebra over finite fields. We introduce notation which considerably simplifies these constructions and slowly build a toolkit of useful techniques that can be combined to create different protocols. We also show a simple ‘probabilistic calculus’ which specifies how to combine these tools and bounds on their resulting security. To show the power of these abstractions and toolkit, we give a short proof of the security of the FRI protocol. Along the way, we discuss some natural generalizations of protocols in the literature and propose a conjecture related to proximity testing using linear error-correcting codes that is of independent interest.</p>

    <h2 id="sec-3" class="text-2xl font-bold">Introduction</h2>

    <p class="text-gray-300">Succinct proofs and arguments play an important role in ensuring privacy and integrity of computation, with many applications in blockchains among other fields. To understand succinct proofs, we may contrast them with ‘traditional’ computational proofs; i.e., providing a witness for a given statement. Traditional computational proofs may be viewed as a certificate that a certain computation was performed correctly. Succinct proofs, compared to computational ones, make the following tradeoff: they allow some very small probability of error that the proof incorrectly verifies (that is, the proof is accepted as good, even though the computation was done incorrectly) in exchange for a short, easy to verify certificate—often much shorter and faster to verify than the corresponding traditional proof would be.</p>

    <p class="text-gray-300">Historically, succinct proofs leverage interaction and randomness to achieve their stated goal. Related to this idea of succinct proofs are the succinct noninteractive arguments of knowledge (SNARKs, for short), which are of growing practical interest <em>[BCCT13, BSCG^{+}13, BBB^{+}18, Nit20, Tha22]</em>. Common to both of these approaches is the use of randomness to reduce complicated statements to simpler ones, which is the focus of this work. Note</p>

    <p class="text-gray-300">that practical implementations of these protocols often involve careful considerations around communication models or cryptographic assumptions, which we elide here.</p>

    <p class="text-gray-300">Our goal in this paper is to provide a minimal framework for understanding the tools used in many protocols involving random reductions. To do this, we mostly limit ourselves to linear algebra over finite fields and some basic probability theory. These tools are sufficient to explain a surprising number of results and checks used throughout much of the literature.</p>

    <h4 id="sec-4" class="text-lg font-semibold mt-6">Other work.</h4>

    <p class="text-gray-300">Other authors have noted that, indeed, some of the reductions may be generalized to any number of other domains. For example, a recent line of work, exemplified by <em>[x1]</em>, <em>[x29]</em>, and <em>[x23]</em> provided a number of frameworks for thinking about some of the reductions used in succinct proofs. The papers <em>[x1]</em> and <em>[x23]</em> are probably the closest in spirit to this work. Each paper shows that some reductions used in the literature may be understood from the perspective of module theory and focus mostly on the sumcheck protocol and its generalizations over spaces with tensor structure. Many of the statements we present in this paper similarly have natural module-theoretic generalizations which may be of possible interest, but we do not expand on this here.</p>

    <h4 id="sec-5" class="text-lg font-semibold mt-6">This work.</h4>

    <p class="text-gray-300">In this paper we show that many of the tools and ‘checks’ used in succinct proofs can be viewed as a consequence of basic facts from linear algebra over finite fields. This perspective also suggests some generalizations. For example, one common operation in succinct proof systems is to check if a number of vectors all lie in some subspace, say <span class="math">V</span>. It is possible to show that, with high probability, all vectors lie in this subspace <span class="math">V</span> only when a uniformly random linear combination of the vectors lies in <span class="math">V</span>. In this sense, we have reduced a potentially ‘very large’ problem (of checking that each vector lies in <span class="math">V</span>) to a much smaller problem (of checking a single vector lying in <span class="math">V</span>) using randomness; many protocols rely on this (and similar) reductions. We show that the ‘uniform random linear combination’ may be replaced with a more general construction: a uniformly chosen random row of a generator matrix for a linear code of large distance.</p>

    <h2 id="sec-6" class="text-2xl font-bold">1 Preliminaries and notation</h2>

    <p class="text-gray-300">In this section, we discuss some basic facts from linear algebra, error correcting codes, and the conventions used in this paper. A reader that is very comfortable with linear algebra and the basics of error correcting codes should feel free to skim this material to understand the notation used in this paper and proceed directly to §1.4.</p>

    <h3 id="sec-7" class="text-xl font-semibold mt-8">1.1 Linear algebra</h3>

    <p class="text-gray-300">In this paper, we will take the linear-algebraic standard for notation (versus, e.g., some standards in coding theory). In particular, all vectors are column vectors (unless otherwise specified) and matrix-vector products are written in that order. (We can then interpret matrix-vector products as linear combinations of the <em>columns</em> of the matrix, rather than the</p>

    <p class="text-gray-300">rows.) The presentation here is not intended to be an introduction to linear algebra—for that, we refer the reader to, e.g., <em>[x1]</em>—but is simply meant to be a refresher.</p>

    <h4 id="sec-8" class="text-lg font-semibold mt-6">Vectors and matrices.</h4>

    <p class="text-gray-300">Given a finite field <span class="math">\\mathbf{F}</span> we write <span class="math">\\mathbf{F}^{n}</span> for the set of <span class="math">n</span>-vectors with elements in <span class="math">\\mathbf{F}</span> and write <span class="math">\\mathbf{F}^{m\\times n}</span> for the set of matrices with <span class="math">m</span> rows and <span class="math">n</span> columns with elements in <span class="math">\\mathbf{F}</span>. For example, we may have <span class="math">x\\in\\mathbf{F}^{n}</span> and <span class="math">A\\in\\mathbf{F}^{m\\times n}</span>, then</p>

    <p class="text-gray-300"><span class="math">Ax=\\sum_{j=1}^{n}x_{j}a_{j},</span></p>

    <p class="text-gray-300">where <span class="math">a_{j}\\in\\mathbf{F}^{m}</span> is the <span class="math">j</span>th column of <span class="math">A</span>, which means that <span class="math">Ax</span> is an <span class="math">m</span>-vector. A common view will be to look at one specific element of the resulting vector <span class="math">Ax</span>. For example, we may write the <span class="math">i</span>th element as</p>

    <p class="text-gray-300"><span class="math">(Ax)_{i}=\\tilde{a}_{i}^{T}x,</span></p>

    <p class="text-gray-300">where <span class="math">\\tilde{a}_{i}</span> denotes the <span class="math">i</span>th row of <span class="math">A</span> (viewed as a column vector) and <span class="math">\\tilde{a}_{i}^{T}</span> is the transpose of <span class="math">\\tilde{a}_{i}</span> (which is a row vector). We will identify the <span class="math">n</span>-by-<span class="math">1</span> matrices with the <span class="math">n</span>-vectors, when the meaning is clear.</p>

    <h4 id="sec-9" class="text-lg font-semibold mt-6">Vector spaces and subspaces.</h4>

    <p class="text-gray-300">Any subset <span class="math">V\\subseteq\\mathbf{F}^{n}</span> which is itself a vector space (i.e., <span class="math">V</span> is closed under linear combinations of its elements) is called a subspace. (If <span class="math">V^{\\prime}\\subseteq V</span> and <span class="math">V^{\\prime}</span> is a vector space, we say that <span class="math">V^{\\prime}</span> is a subspace of <span class="math">V</span>.) Examples of vector subspaces are, of course, <span class="math">\\mathbf{F}^{n}</span> or the singleton <span class="math">\\{0\\}</span>. Another important example is, given a vector <span class="math">x\\in\\mathbf{F}^{n}</span>, the ray</p>

    <p class="text-gray-300"><span class="math">\\{\\alpha x\\mid\\alpha\\in\\mathbf{F}\\}</span></p>

    <p class="text-gray-300">is a subspace. Some useful and important operations on vector spaces are sums and intersections. In particular, if <span class="math">U,V\\subseteq\\mathbf{F}^{n}</span> are both subspaces, then their sum (sometimes called their Minkowski sum), defined</p>

    <p class="text-gray-300"><span class="math">U+V=\\{u+v\\mid u\\in U,\\;v\\in V\\},</span> (1)</p>

    <p class="text-gray-300">is also a subspace. (We purposefully overload the <span class="math">+</span> operation for convenience.) Additionally, their intersection <span class="math">U\\cap V</span> is also a subspace.</p>

    <h4 id="sec-10" class="text-lg font-semibold mt-6">Range and nullspace.</h4>

    <p class="text-gray-300">Every matrix <span class="math">A\\in\\mathbf{F}^{m\\times n}</span> defines two vector subspaces. The first is its range (sometimes called the image of <span class="math">A</span>) defined as</p>

    <p class="text-gray-300"><span class="math">\\mathcal{R}(A)=\\{Ax\\mid x\\in\\mathbf{F}^{n}\\}.</span></p>

    <p class="text-gray-300">From its definition, <span class="math">\\mathcal{R}(A)\\subseteq\\mathbf{F}^{m}</span>. In English: the range of a matrix <span class="math">A</span> is the set of all vectors that are linear combinations of the columns of <span class="math">A</span>. The second vector space is its nullspace (sometimes called its kernel) written</p>

    <p class="text-gray-300"><span class="math">\\mathcal{N}(A)=\\{x\\in\\mathbf{F}^{n}\\mid Ax=0\\}.</span></p>

    <p class="text-gray-300">is is the set of vectors which are mapped to zero under the action of <span class="math">A</span>. It is not hard to verify that both <span class="math">\\mathcal{R}(A)</span> and <span class="math">\\mathcal{N}(A)</span> are vector spaces (subspaces of <span class="math">\\mathbf{F}^{m}</span>). A matrix <span class="math">A</span> is said to be <em>injective</em> if <span class="math">\\mathcal{N}(A)=\\{0\\}</span> since, if <span class="math">y=Ax</span> for some <span class="math">x\\in\\mathbf{F}^{n}</span>, then this vector <span class="math">x</span> is unique. Similarly, we say that a set of <span class="math">n</span>-vectors <span class="math">\\{a_{i}\\}</span> is <em>linearly independent</em> if, viewed as the columns of a matrix</p>

    <p class="text-gray-300"><span class="math">A=\\begin{bmatrix}a_{1}&amp;a_{2}&amp;\\ldots&amp;a_{n}\\end{bmatrix},</span></p>

    <p class="text-gray-300">then the nullspace of <span class="math">A</span> is only the zero vector. In other words, we say the <span class="math">\\{a_{i}\\}</span> are linearly independent if every nonzero linear combination of the vectors <span class="math">a_{i}</span> is nonzero.</p>

    <h4 id="sec-11" class="text-lg font-semibold mt-6">Representations of subspaces.</h4>

    <p class="text-gray-300">A basic fact from linear algebra is that every subspace <span class="math">V\\subseteq\\mathbf{F}^{m}</span> can be written as the range of some injective matrix <span class="math">A\\in\\mathbf{F}^{m\\times n}</span>,</p>

    <p class="text-gray-300"><span class="math">V=\\mathcal{R}(A),</span></p>

    <p class="text-gray-300">where <span class="math">n</span> is called the <em>dimension</em> of the subspace <span class="math">V</span>. (The columns of <span class="math">A</span> are called a <em>basis</em> for <span class="math">V</span>.) Since <span class="math">A</span> is injective, we have that <span class="math">m\\geq n</span>. Similarly, the subspace <span class="math">V</span> can be written as the nullspace of some matrix <span class="math">C\\in\\mathbf{F}^{k\\times m}</span> such that</p>

    <p class="text-gray-300"><span class="math">V=\\mathcal{N}(C),</span></p>

    <p class="text-gray-300">and <span class="math">k=m-n</span>. This matrix is sometimes called the <em>parity check matrix</em>, which is the terminology we adopt here. Another way of stating this definition of <span class="math">C</span> is:</p>

    <p class="text-gray-300"><span class="math">x\\in V\\quad\\text{if, and only if,}\\quad Cx=0.</span> (2)</p>

    <h4 id="sec-12" class="text-lg font-semibold mt-6">Polynomial evaluations.</h4>

    <p class="text-gray-300">One particular example we will use constantly is the vector space consisting of the evaluations of a polynomial of small degree. In particular, let <span class="math">\\{\\alpha_{i}\\}\\subseteq\\mathbf{F}</span>, for <span class="math">i=1,\\ldots,m</span>, be some evaluation points and <span class="math">n\\geq 1</span> be some given number, then the set of polynomials of degree less than or equal to <span class="math">n-1</span>, evaluated at the points <span class="math">\\alpha_{i}</span>, forms a vector space <span class="math">V</span> since it can be written as the range of the matrix</p>

    <p class="text-gray-300">\\[ A=\\begin{bmatrix}1&\\alpha_{1}&\\alpha_{1}^{2}&\\ldots&\\alpha_{1}^{n-1}\\\\ 1&\\alpha_{2}&\\alpha_{2}^{2}&\\ldots&\\alpha_{2}^{n-1}\\\\ \\vdots&\\vdots&\\vdots&\\ddots&\\vdots\\\\ 1&\\alpha_{m}&\\alpha_{m}^{2}&\\ldots&\\alpha_{m}^{n-1}\\end{bmatrix}. \\] (3)</p>

    <p class="text-gray-300">(This matrix is called the <em>Vandermonde matrix</em> of degree <span class="math">n-1</span> for the evaluation points <span class="math">\\alpha_{i}</span>.) To see this, note that every polynomial of degree at most <span class="math">n-1</span>, say <span class="math">f:\\mathbf{F}\\to\\mathbf{F}</span>, can be written as</p>

    <p class="text-gray-300"><span class="math">f(\\beta)=x_{1}+x_{2}\\beta+x_{3}\\beta^{2}+\\cdots+x_{n}\\beta^{n-1},</span></p>

    <p class="text-gray-300">where <span class="math">x\\in\\mathbf{F}^{n}</span>. So, we may write</p>

    <p class="text-gray-300"><span class="math">f(\\alpha_{i})=x_{1}+x_{2}\\alpha_{i}+\\cdots+x_{n}\\alpha_{i}^{n-1}=(Ax)_{i},</span></p>

    <p class="text-gray-300">for any polynomial of degree at most <span class="math">n-1</span>. Because of this, the set of evaluations of all possible low-degree polynomials <span class="math">f</span>, written as vectors <span class="math">(f(\\alpha_{1}),\\ldots,f(\\alpha_{m}))</span>, is just</p>

    <p class="text-gray-300"><span class="math">V=\\mathcal{R}(A).</span></p>

    <p class="text-gray-300">Finally, because we know that the range of any matrix is a subspace and since <span class="math">V</span> is the range of the matrix <span class="math">A</span>, then the set <span class="math">V</span> must also be a subspace.</p>

    <h4 id="sec-13" class="text-lg font-semibold mt-6">Direct sums.</h4>

    <p class="text-gray-300">If <span class="math">V\\subseteq\\mathbf{F}^{n}</span> is a subspace and <span class="math">T,U\\subseteq V</span> are subspaces of <span class="math">V</span> satisfying the property that <span class="math">T\\cap U=\\{0\\}</span> and <span class="math">V=T+U</span>, where</p>

    <p class="text-gray-300"><span class="math">T+U=\\{y+z\\mid y\\in T,\\ z\\in U\\},</span></p>

    <p class="text-gray-300">then we say that <span class="math">V</span> is the <em>direct sum</em> <em>[x1, §1]</em> of <span class="math">T</span> and <span class="math">U</span>. We write this as <span class="math">V=T\\oplus U</span>, for shorthand. The interpretation of this is that, if <span class="math">x\\in V</span>, then it can be written uniquely as</p>

    <p class="text-gray-300"><span class="math">x=y+z,</span></p>

    <p class="text-gray-300">where <span class="math">y\\in T</span> and <span class="math">z\\in U</span>. We may extend this definition to any number of subspaces, <span class="math">V_{k}\\subseteq V</span> with <span class="math">k=1,\\ldots,s</span>, and in this case we write</p>

    <p class="text-gray-300"><span class="math">V=V_{1}\\oplus V_{2}\\oplus\\cdots\\oplus V_{s},</span></p>

    <p class="text-gray-300">if <span class="math">V=V_{1}+\\cdots+V_{s}</span> and <span class="math">V_{k}\\cap V_{l}=\\{0\\}</span> for every <span class="math">k\\neq l</span> with <span class="math">k,l=1,\\ldots,s</span>.</p>

    <h3 id="sec-14" class="text-xl font-semibold mt-8">1.2 Linear error correcting codes</h3>

    <p class="text-gray-300">In this section, we introduce some basic definitions from linear error correcting codes, along with some examples of codes that we use throughout. Though we will not use any deep results from error correcting codes, other than the definition of distance, we refer readers to the excellent series of lecture notes <em>[x27]</em> for more.</p>

    <h4 id="sec-15" class="text-lg font-semibold mt-6">1.2.1 Weight and distance</h4>

    <p class="text-gray-300">The <em>weight</em> of a vector <span class="math">x\\in\\mathbf{F}^{n}</span>, defined</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\{i\\mid x_{i}\\neq 0\\}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">is the number of nonzero entries of a vector <span class="math">x</span>. (This is often referred to as the Hamming weight, but we simply use the term weight for this paper.) We write this as $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\cdot\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}<span class="math">, as this is sometimes called the </span>\\ell_{0}$-‘norm’, since it satisfies the triangle inequality</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x+y\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}+\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">for any <span class="math">y\\in\\mathbf{F}^{n}</span>. It also satisfies definiteness in that $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=0<span class="math"> if and only if </span>x=0<span class="math">, and satisfies </span>0<span class="math">-homogeneity in that, for any </span>\\alpha\\in\\mathbf{F}<span class="math"> with </span>\\alpha\\neq 0$,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\alpha x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(This ‘norm’ is not a true norm as norms must usually be <span class="math">1</span>-homogeneous.) Using this ‘norm’, the <em>distance</em> between two vectors <span class="math">x</span> and <span class="math">y</span> can then be written as $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x-y\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">####</p>

    <p class="text-gray-300">Notation.</p>

    <p class="text-gray-300">We overload this norm notation for convenience to also work over sets: given a set <span class="math">S\\subseteq\\mathbf{F}^{n}</span>, we write</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=\\min_{x\\in S}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">such that the weight of a set <span class="math">S</span> is the minimum weight of any vector in the set. This notation is quite convenient: writing, as in (1),</p>

    <p class="text-gray-300"><span class="math">x-S=\\{x-y\\mid y\\in S\\},</span></p>

    <p class="text-gray-300">we may then view</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x-S\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=\\min_{y\\in S}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x-y\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">as the minimum distance between <span class="math">x</span> and any vector in the set <span class="math">S</span>.</p>

    <h4 id="sec-16" class="text-lg font-semibold mt-6">1.2.2 Linear codes</h4>

    <p class="text-gray-300">A <em>linear code</em> is defined as a matrix <span class="math">G\\in\\mathbf{F}^{m\\times n}</span>. (Technically, many matrices <span class="math">G</span> may generate the same code, which is usually defined as <span class="math">\\mathcal{R}(G)</span>, but we ignore the distinction here.) We say that <span class="math">n</span> is the <em>message length</em> and <span class="math">m</span> is the <em>block length</em> of the code given by <span class="math">G</span>. This is called a linear code since we can take a message <span class="math">x\\in\\mathbf{F}^{n}</span>, which is simply an <span class="math">n</span>-vector over the field <span class="math">\\mathbf{F}</span>, and <em>encode</em> it by applying the matrix <span class="math">G</span> to get a length <span class="math">m</span> codeword, <span class="math">Gx</span>. It is linear since the codeword corresponding to any linear combination of messages is just the same linear combination of the individual codewords.</p>

    <h5 id="sec-17" class="text-base font-semibold mt-4">Distance.</h5>

    <p class="text-gray-300">The main definition that we will use throughout this paper is the <em>distance</em> of the code <span class="math">G</span>, defined</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$d=\\min_{x\\in\\mathbf{F}^{n}\\setminus\\{0\\}}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Gx\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}<span class="math"> denotes the number of nonzero entries in </span>z\\in\\mathbf{F}^{m}<span class="math">. This is called the distance since any two distinct messages </span>x,y\\in\\mathbf{F}^{n}<span class="math"> with </span>x\\neq y<span class="math"> will differ in at least </span>d$ places after being encoded; <em>i.e.</em>,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Gx-Gy\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G(x-y)\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\geq d,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">since <span class="math">x-y\\neq 0</span>.</p>

    <p class="text-gray-300">Note that <span class="math">G</span> has linearly dependent columns (<em>i.e.</em>, nontrivial nullspace) if, and only if, the distance <span class="math">d=0</span>. In other words, if the distance <span class="math">d&gt;0</span> then <span class="math">G</span> is injective; this implies that the distance <span class="math">d</span> can be positive only when <span class="math">m\\geq n</span>.</p>

    <h5 id="sec-18" class="text-base font-semibold mt-4">Discussion.</h5>

    <p class="text-gray-300">At the highest level, we may view codes with large distance <span class="math">d</span> as those which encode ‘errors’ in the original message in many places. More specifically, if we have some expected message, say <span class="math">x\\in\\mathbf{F}^{n}</span>, but, instead, receive a corrupted message <span class="math">x+\\delta</span> where <span class="math">\\delta\\in\\mathbf{F}^{n}</span> has a small (but nonzero) number of corruptions, we know that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G(x+\\delta)-Gx\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G\\delta\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\geq d.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">So if <span class="math">d</span> is roughly of the size of <span class="math">m</span> (where <span class="math">m</span> is the size of the codeword) then, if we expect message <span class="math">x</span>, but instead receive <span class="math">\\tilde{x}=x+\\delta</span>, it only suffices to check that <span class="math">Gx</span> (the encoded expected message) differs from <span class="math">G\\tilde{x}</span> (the encoded received message) in a few entries, to ‘catch’ the fact that <span class="math">\\tilde{x}\\neq x</span>. This rather simple fact, and its consequences, will be the basis for the entire remainder of the paper.</p>

    <h3 id="sec-19" class="text-xl font-semibold mt-8">1.3 Examples of linear codes</h3>

    <p class="text-gray-300">There are a number of important linear codes that are used in the broader literature. We show a few examples, along with some properties, here.</p>

    <h4 id="sec-20" class="text-lg font-semibold mt-6">1.3.1 Repeated code</h4>

    <p class="text-gray-300">A very simple (and silly) family of codes are the <span class="math">k</span>-repeated codes, given by the matrix <span class="math">G\\in\\mathbf{F}^{kn\\times n}</span>, defined</p>

    <p class="text-gray-300">\\[ G=\\begin{bmatrix}I_{n}\\\\ \\vdots\\\\ I_{n}\\end{bmatrix}, \\]</p>

    <p class="text-gray-300">where <span class="math">I_{n}\\in\\mathbf{F}^{n\\times n}</span> is the identity matrix of size <span class="math">n\\times n</span>. This code simply takes some message <span class="math">x</span> of length <span class="math">n</span>, repeats it <span class="math">k</span> times, and stacks the result into a vector of size <span class="math">kn</span>; i.e., given some vector <span class="math">x\\in\\mathbf{F}^{n}</span>:</p>

    <p class="text-gray-300">\\[ Gx=\\begin{bmatrix}x\\\\ \\vdots\\\\ x\\end{bmatrix}, \\]</p>

    <p class="text-gray-300">where the vector <span class="math">x</span> is stacked <span class="math">k</span> times</p>

    <h5 id="sec-21" class="text-base font-semibold mt-4">Distance.</h5>

    <p class="text-gray-300">This code has distance <span class="math">d=k</span>, which is easy to see from its definition.</p>

    <h4 id="sec-22" class="text-lg font-semibold mt-6">1.3.2 Reed–Solomon codes</h4>

    <p class="text-gray-300">A more interesting (and common) choice of codes are the <em>Reed–Solomon codes</em>. Assuming a message of length <span class="math">n</span> and given some block size <span class="math">m\\geq n</span>, we may pick any subset of evaluation points <span class="math">\\{\\alpha_{1},\\ldots,\\alpha_{m}\\}\\subseteq\\mathbf{F}</span>. We can then define the matrix as <span class="math">G\\in\\mathbf{F}^{m\\times n}</span> in the following way:</p>

    <p class="text-gray-300"><span class="math">G_{ij}=\\alpha_{i}^{j-1},</span></p>

    <p class="text-gray-300">for <span class="math">i=1,\\ldots,m</span>, and <span class="math">j=1,\\ldots,n</span>. (The definition here is exactly the definition of the Vandemonde matrix given in (3), written in index notation.)</p>

    <p class="text-gray-300">.</p>

    <h4 id="sec-23" class="text-lg font-semibold mt-6">Distance.</h4>

    <p class="text-gray-300">Since a nonzero degree <span class="math">d</span> polynomial has at most <span class="math">d</span> roots (over any field <span class="math">\\mathbf{F}</span>) then the distance of this code is at least <span class="math">m-n+1</span> since</p>

    <p class="text-gray-300"><span class="math">(Gx)_{i}=\\sum_{j=1}^{n}x_{j}\\alpha_{i}^{j-1},</span></p>

    <p class="text-gray-300">is a degree at most <span class="math">n-1</span> polynomial with coefficients <span class="math">x_{j}</span>, evaluated at each of the <span class="math">\\alpha_{i}</span>. It is not hard to construct a polynomial of degree <span class="math">n-1</span> which has exactly <span class="math">m-n+1</span> zeros when evaluated over the points <span class="math">\\alpha_{1},\\ldots,\\alpha_{m}</span>, which makes the distance of this code exactly equal to <span class="math">m-n+1</span>.</p>

    <h4 id="sec-24" class="text-lg font-semibold mt-6">1.3.3 Hadamard code</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Another common code is the Hadamard code, which is defined by a matrix <span class="math">G\\in\\mathbf{F}^{m\\times n}</span> whose rows contain all possible tuples from <span class="math">\\mathbf{F}^{n}</span>. (Here, then, $m=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{n}<span class="math">.) Drawing a row uniformly at random corresponds to drawing a uniformly random tuple from </span>\\mathbf{F}^{n}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-25" class="text-lg font-semibold mt-6">Distance.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The distance of this code is $d=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{n}-</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{n-1}<span class="math">. To see this, consider any row </span>i<span class="math"> of </span>G<span class="math">, which we write as </span>y<span class="math">. Then, given a message </span>x\\neq 0<span class="math">, we have that at least one index, say </span>j<span class="math">, has </span>x_{j}\\neq 0<span class="math">. So, if the </span>i<span class="math">th symbol of </span>Gx$ is zero, we have</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">(Gx)_{i}=y^{T}x=y_{j}x_{j}+\\tilde{y}^{T}\\tilde{x}=0,</span></p>

    <p class="text-gray-300">where <span class="math">\\tilde{x}</span> is the vector <span class="math">x</span> with entry <span class="math">j</span> removed, and similarly for <span class="math">y</span>. We can write this as</p>

    <p class="text-gray-300"><span class="math">y_{j}=-x_{j}^{-1}(\\tilde{y}^{T}\\tilde{x}).</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Note that any choice of <span class="math">\\tilde{y}</span> fixes <span class="math">y_{j}</span> from the above equation. Since there are $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{n-1}<span class="math"> possible options for </span>\\tilde{y}<span class="math"> satisfying this condition, then there are at most </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{n-1}<span class="math"> possible symbols of </span>Gx<span class="math"> that are zero, or, equivalently, at least </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{n}-</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{n-1}<span class="math"> symbols that are nonzero in </span>Gx<span class="math">, whenever </span>x\\neq 0$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-26" class="text-xl font-semibold mt-8">1.4 Probabilistic implications</h3>

    <p class="text-gray-300">It will be useful to define some basic notation which will clean up the proofs that follow. In particular, this notation can be seen as compact way of expressing logical statements (such as implications) in a probabilistic setting, where there is some probability that a statement is not true. Even in this case, we will show that analogues of the basic rules of logic still hold.</p>

    <h4 id="sec-27" class="text-lg font-semibold mt-6">Implications.</h4>

    <p class="text-gray-300">Given two statements <span class="math">P_{r}</span> and <span class="math">Q_{r^{\\prime}}</span> (in other words, two Boolean functions taking on values <span class="math">0</span> or <span class="math">1</span>) that depend on random variables <span class="math">r</span> and <span class="math">r^{\\prime}</span> drawn from some set, we write</p>

    <p class="text-gray-300"><span class="math">P_{r}\\implies Q_{r^{\\prime}},</span></p>

    <p class="text-gray-300">where</p>

    <p class="text-gray-300"><span class="math">\\Pr(P_{r}\\wedge\\neg Q_{r^{\\prime}})\\leq p</span> over randomness <span class="math">r</span> and <span class="math">r^{\\prime}</span>; i.e., if the probability that <span class="math">P_{r}</span> is true, yet <span class="math">Q_{r^{\\prime}}</span> is not, is no larger than some value <span class="math">p</span>. In general, we make no assumptions about the distribution of <span class="math">r</span> and <span class="math">r^{\\prime}</span> except that it should be explicit in the text. Almost universally, in the remainder of this work, we will either have <span class="math">r=r^{\\prime}</span> or <span class="math">r</span> and <span class="math">r^{\\prime}</span> independently and uniformly drawn from some set. When it is clear from context what the randomness is over, we will sometimes write this as <span class="math">P_{r}</span> implies <span class="math">Q_{r^{\\prime}}</span> with error (at most) <span class="math">p</span>.</p>

    <p class="text-gray-300">The basic idea behind this notation is to think of <span class="math">p</span> as the probability that the statement is ‘wrong’. If <span class="math">p=0</span>, then this reduces exactly to the usual definition in propositional logic, while, if <span class="math">p</span> is very small, we can think of the statements as being ‘almost equivalent’ under the randomness. In general, this relation will satisfy many similar rules to those of propositional logic, with additional ‘error’ terms that satisfy some basic rules we discuss below.</p>

    <h4 id="sec-28" class="text-lg font-semibold mt-6">Chaining implications.</h4>

    <p class="text-gray-300">Given three statements with</p>

    <p class="text-gray-300"><span class="math">P_{r}\\underset{p}{\\Longrightarrow}\\ Q_{r^{\\prime}},\\quad\\text{and}\\quad Q_{r^{\\prime}}\\underset{p^{\\prime}}{\\Longrightarrow}\\ T_{r^{\\prime\\prime}},</span></p>

    <p class="text-gray-300">over randomness <span class="math">r</span>, <span class="math">r^{\\prime}</span>, and <span class="math">r^{\\prime\\prime}</span>, then</p>

    <p class="text-gray-300"><span class="math">P_{r}\\underset{p+p^{\\prime}}{\\Longrightarrow}\\ T_{r^{\\prime\\prime}}.</span></p>

    <p class="text-gray-300">This is not hard to see from the union bound, but we provide the easy (if verbose) proof in appendix A. Note that, since ‘normal’ implication can be written as <span class="math">\\underset{0}{\\Longrightarrow}</span>, then this bound says, if</p>

    <p class="text-gray-300"><span class="math">P_{r}\\underset{p}{\\Longrightarrow}\\ Q_{r^{\\prime}},\\quad\\text{and}\\quad Q_{r^{\\prime}}\\ \\ \\text{implies}\\ \\ T_{r^{\\prime\\prime}},</span></p>

    <p class="text-gray-300">then <span class="math">P_{r}\\underset{p}{\\Longrightarrow}\\ T_{r^{\\prime\\prime}}</span>. (In the ‘usual’ logical implications, we will have that <span class="math">r^{\\prime}=r^{\\prime\\prime}</span>.)</p>

    <h4 id="sec-29" class="text-lg font-semibold mt-6">Contrapositives.</h4>

    <p class="text-gray-300">It is also similarly easy to see that, if</p>

    <p class="text-gray-300"><span class="math">P_{r}\\underset{p}{\\Longrightarrow}\\ Q_{r},</span></p>

    <p class="text-gray-300">then</p>

    <p class="text-gray-300"><span class="math">\\neg Q_{r}\\underset{p}{\\Longrightarrow}\\ \\neg P_{r},</span></p>

    <p class="text-gray-300">from the definition.</p>

    <h4 id="sec-30" class="text-lg font-semibold mt-6">Conjunctions.</h4>

    <p class="text-gray-300">Another interesting point is, given some ‘deterministic’ claim <span class="math">Q</span> (that does not depend on randomness; it is either true or false), and the following implications</p>

    <p class="text-gray-300"><span class="math">P_{r}\\underset{p}{\\Longrightarrow}\\ Q,\\quad\\text{and}\\quad T_{r^{\\prime}}\\underset{p^{\\prime}}{\\Longrightarrow}\\ Q,</span></p>

    <p class="text-gray-300">then, if <span class="math">r</span> and <span class="math">r^{\\prime}</span> are independent, we have</p>

    <p class="text-gray-300"><span class="math">P_{r},\\ T_{r^{\\prime}}\\underset{pp^{\\prime}}{\\Longrightarrow}\\ Q.</span></p>

    <p class="text-gray-300">This follows essentially from the definition of independence and the probabilistic implications above. In English: if we have two claims we can independently verify, each of which implies <span class="math">Q</span> with low probability of error <span class="math">p</span> and <span class="math">p^{\\prime}</span>, then verifying both (with independent randomness) must imply <span class="math">Q</span> with much lower probability of error <span class="math">pp^{\\prime}</span>. A special case of this is: repeating a check with independent and identical randomness decreases the probability of failure of the check from <span class="math">p</span> to <span class="math">p^{2}</span>.</p>

    <h4 id="sec-31" class="text-lg font-semibold mt-6">Discussion.</h4>

    <p class="text-gray-300">While the notation (and some of the basic implications) described here look simple, they will reduce the complexity of the discussions by allowing us to talk about, and compose, statements in a very compact way, without requiring additional overhead. We will make constant use of the rules described here throughout the remainder of this paper. Interestingly, as far as the authors know, this subject has only been explored in the context of data analysis and inference, as a special case of fuzzy logic implications <em>[x1]</em>, but, to the authors’ knowledge, little of it has been used in the general proof setting (along with its implications).</p>

    <h2 id="sec-32" class="text-2xl font-bold">2 The structure of checks</h2>

    <p class="text-gray-300">This section explains the general model and assumptions that go into many of the tools used in succinct proof systems, along with explaining how randomness is useful in making these tools practical. Those familiar with the structure of succinct proof systems should feel free to skim this section and proceed to the next section directly.</p>

    <p class="text-gray-300">We will start this section with a very simple example, known as the zero check and its variation, the sparsity check, both of which we analyze later in more detail. This will then help motivate the remainder of the section and show how claims that are expensive to verify may be successively ‘reduced’ to smaller claims that are cheaper to verify.</p>

    <h3 id="sec-33" class="text-xl font-semibold mt-8">2.1 The zero check</h3>

    <p class="text-gray-300">In the examples that follow, we seek to answer the following question: given two vectors <span class="math">x</span> and <span class="math">y</span> (say, in <span class="math">\\mathbf{F}^{n}</span>), are the two vectors equal? Of course, we may verify whether <span class="math">x=y</span> by checking if each of their <span class="math">n</span> elements are equal. Indeed, this is the best we can hope to do if we must be absolutely certain whether <span class="math">x=y</span>, yet only have access to <span class="math">x</span> and <span class="math">y</span> by querying individual entries of each vector. If <span class="math">n</span> is large—in many practical cases, <span class="math">n</span> is on the order of <span class="math">2^{20}</span> or so—this could prove to be an expensive procedure if fetching each element incurs some reasonable cost.</p>

    <h4 id="sec-34" class="text-lg font-semibold mt-6">2.1.1 Sparse checks</h4>

    <p class="text-gray-300">One ‘relaxation’ of the above question is to check if, instead, <span class="math">x</span> is ‘close to’ <span class="math">y</span>. That is, we would like to guarantee that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x-y\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$ (4)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">for some threshold <span class="math">q\\geq 0</span>, set ahead of time. From before, if we must be absolutely certain that <span class="math">x</span> and <span class="math">y</span> are no more than <span class="math">q</span> apart from each other, we must check that at least <span class="math">n-q</span> entries of <span class="math">x</span> and <span class="math">y</span> are equal. (We recommend the reader convince themselves of this before proceeding.)</p>

    <p class="text-gray-300">In practice, though, we rarely care that a statement is perfectly true. For example, if a statement is false with probability no more than <span class="math">2^{-100}</span>, it might as well be true for all intents and purposes. Of course, this assumes that the probability is measured over some ‘reasonable’ notion of randomness, but we will see that this can be achieved in what follows.</p>

    <h4 id="sec-35" class="text-lg font-semibold mt-6">Probabilistic sparse checks.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Perhaps the simplest ‘check’ is to uniformly randomly draw indices <span class="math">r\\sim\\{1,\\ldots,n\\}</span> and verify that <span class="math">x_{r}=y_{r}</span> at each of these indices. If the desired condition (4) is not true, that is, if $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x-y\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\geq q+1<span class="math">, then the probability that a uniformly randomly chosen index lands on one of the entries with </span>x_{r}\\neq y_{r}$ is at least</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">1-\\frac{q+1}{n}.</span></p>

    <p class="text-gray-300">If we repeat this procedure <span class="math">\\ell</span> times, uniformly and independently drawing indices from <span class="math">1,\\ldots,n</span>, the probability that we never ‘catch’ at least one of the indices for which <span class="math">x_{r}\\neq y_{r}</span> is easily bounded from above by</p>

    <p class="text-gray-300"><span class="math">\\left(1-\\frac{q+1}{n}\\right)^{\\ell}.</span></p>

    <p class="text-gray-300">To guarantee a probability of failure no more than <span class="math">p</span>, then, it suffices to repeat the experiment</p>

    <p class="text-gray-300"><span class="math">\\ell\\geq\\frac{n}{q+1}\\log\\left(\\frac{1}{p}\\right)</span></p>

    <p class="text-gray-300">times. (We have used the fact that <span class="math">\\log(1-x)\\leq-x</span> in this bound.) If <span class="math">n</span> is large (say <span class="math">n=2^{20}</span>) and <span class="math">q=n/10</span>, yet we wish the probability of failure to be no more than <span class="math">2^{-100}</span> then, repeating the experiment</p>

    <p class="text-gray-300"><span class="math">\\ell\\approx 700</span></p>

    <p class="text-gray-300">times suffices. In other words, only about <span class="math">700</span> queries to elements of <span class="math">x</span> and <span class="math">y</span> are needed to verify the claim. On the other hand, checking that this condition holds exactly requires checking that <span class="math">n-q</span> entries are equal, which is still on the order of about a million queries. While this particular observation is not ‘deep’ in any meaningful sense, the basic idea is generalized to a much broader setting in §3.2.</p>

    <h4 id="sec-36" class="text-lg font-semibold mt-6">2.1.2 Models and the ‘exact’ zero check</h4>

    <p class="text-gray-300">In the second setting, we wish to check whether <span class="math">x</span> is exactly equal to <span class="math">y</span> with high probability. Checking exact equality with high probability using the procedure described previously essentially boils down to setting the threshold <span class="math">q=0</span>, which means that the number of queries is roughly <span class="math">n</span>. (Indeed, a simple argument shows that, to guarantee any probability of failure</p>

    <p class="text-gray-300">smaller than 1, <span class="math">p&lt;1</span>, we always need on the order of <span class="math">n</span> queries.) This means that a new interaction model is required if we want to do better than <span class="math">n</span> queries, which we cover in a brief aside below.</p>

    <h4 id="sec-37" class="text-lg font-semibold mt-6">Direct access model.</h4>

    <p class="text-gray-300">As a baseline, we can view the communication model discussed up until this point as a simple direct access model. In that model, <span class="math">x</span> and <span class="math">y</span> are vectors stored in some drive handed to us, say. We then pay some fixed cost for each query, which accesses a single element of <span class="math">x</span> or <span class="math">y</span>. The drive is assumed to be ‘truthful’ in that it simply relays information about <span class="math">x</span> and <span class="math">y</span> as queried. (Such a guarantee is not obvious: for example, one could easily imagine a malicious ‘smart’ drive that attempts to adapt its responses based on the previous queries we made.)</p>

    <h4 id="sec-38" class="text-lg font-semibold mt-6">Coding model.</h4>

    <p class="text-gray-300">We can propose a different model by slightly generalizing the direct access model, which we call the coding model. In this model, instead, we are handed a black box. This black box has a fixed code matrix <span class="math">G\\in\\mathbf{F}^{m\\times n}</span>, known to us, along with some message <span class="math">x\\in\\mathbf{F}^{n}</span>, unknown to us. We then are allowed to query some index <span class="math">i</span> for symbol <span class="math">(Gx)_{i}</span> from the encoded message <span class="math">Gx</span>, paying a fixed cost for each query performed. The direct access model is the special case where the code matrix <span class="math">G</span> is the identity <span class="math">G=I</span>, such that querying the <span class="math">i</span>th symbol of <span class="math">Gx</span> is the same as querying the <span class="math">i</span>th symbol from the message <span class="math">x</span>.</p>

    <h4 id="sec-39" class="text-lg font-semibold mt-6">Model discussion.</h4>

    <p class="text-gray-300">We note that these models assume that the queries are answered truthfully; i.e., that the black boxes being handed to us answer queries in a way consistent with their definitions above. This, of course, seems like a very difficult restriction. Indeed, if a stranger (or, more specifically, a paper author) hands us such a black box on the street with a promise that it satisfies these definitions, we should be extremely skeptical of these promises and the authors more generally. Luckily, in many practical cases, we can replace black boxes with cryptographic protocols that have certain guarantees. For example, the direct access model can be replaced with a Merkle commitment <em>[x13, §6.6.2]</em>, while the coding model can be replaced with any number of possible polynomial commitments <em>[x15]</em> (when the matrix <span class="math">G</span> corresponds to a Reed–Solomon code), inner product commitments <em>[BCC^{+}16]</em> (for general matrices <span class="math">G</span>), among many others.</p>

    <h4 id="sec-40" class="text-lg font-semibold mt-6">Probabilistic zero check.</h4>

    <p class="text-gray-300">Now that we have defined the coding model, we will show that, surprisingly, we can construct a simple procedure in this model to check if <span class="math">x\\in\\mathbf{F}^{n}</span> is equal to <span class="math">y\\in\\mathbf{F}^{n}</span> that succeeds with high probability, assuming that the code matrix <span class="math">G</span> has relatively large distance, using only a single query.</p>

    <p class="text-gray-300">To see this, let <span class="math">G\\in\\mathbf{F}^{m\\times n}</span> be a <span class="math">m</span>-by-<span class="math">n</span> matrix with distance <span class="math">d</span>. The procedure is as follows:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Uniformly randomly sample an index <span class="math">r</span> from <span class="math">1,\\ldots,m</span></li>

      <li>Query the <span class="math">r</span>th symbol of <span class="math">Gx</span> and <span class="math">Gy</span> to receive <span class="math">(Gx)_{r}</span> and <span class="math">(Gy)_{r}</span></li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Verify that <span class="math">(Gx)_{r}=(Gy)_{r}</span></li>

    </ol>

    <p class="text-gray-300">If <span class="math">x=y</span>, then this procedure correctly verifies this fact. On the other hand, if <span class="math">x\\neq y</span>, the probability that <span class="math">(Gx)_{r}=(Gy)_{r}</span> is very small. Since</p>

    <p class="text-gray-300"><span class="math">(Gx)_{r}-(Gy)_{r}=(G(x-y))_{r},</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">and <span class="math">x-y\\neq 0</span>, then <span class="math">G(x-y)</span> has at least <span class="math">d</span> nonzero entries, by the definition of distance. The probability that a uniformly randomly chosen index <span class="math">r</span> lands in one of those entries is at least <span class="math">d/m</span>, or, conversely, the probability that <span class="math">r</span> ‘misses’ one of these nonzero entries is at most <span class="math">1-d/m</span>. If <span class="math">d</span> is very close to <span class="math">m</span>, then this probability is nearly zero. To make concrete what ‘nearly zero’ means, consider a Reed–Solomon code matrix (see §1.3.2) whose subset of evaluations is every element of <span class="math">\\mathbf{F}</span> (such that $m=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">). If </span>n=2^{20}<span class="math"> (as our previous example) and </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=2^{255}-19<span class="math"> (as in some standard protocols <em>[x1, §15.3.3]</em>), then </span>d=m-n+1$, so the probability that this procedure errs is no more than</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">1-\\frac{d}{m}\\approx 2^{-235},</span></p>

    <p class="text-gray-300">which is effectively zero for all practical purposes.</p>

    <h3 id="sec-41" class="text-xl font-semibold mt-8">2.2 Succinctness and zero knowledge</h3>

    <p class="text-gray-300">The procedures above have two interesting properties. First, in a very general sense, we started with the task of checking whether two potentially very long vectors, <span class="math">x</span> and <span class="math">y</span>, are equal. By using some randomness, we have reduced this task to a much smaller one: checking whether a small number of values are equal to one another. This latter ‘simple’ claim, if true, lets us claim the ‘global’ statement that the two vectors <span class="math">x</span> and <span class="math">y</span>, each composed of many field elements (in fact, <span class="math">n</span> of them), must be equal or ‘close’. The second interesting point is that, in a certain sense, we learn very little about the vectors <span class="math">x</span> and <span class="math">y</span> (with a small modification, it is possible to ensure we actually learn practically nothing) other than the original fact we wished to verify.</p>

    <p class="text-gray-300">We will focus almost universally on the first part: taking a large claim and reducing it to a much smaller one, such that it suffices only to verify the smaller claim, which, in turn, implies the original one with high probability. The second part, while interesting in its own right, is mostly avoided in the remainder of this text. We refer the reader to <em>[x17]</em> for (much) more.</p>

    <h5 id="sec-42" class="text-base font-semibold mt-4">Reductions.</h5>

    <p class="text-gray-300">In a certain sense, we may view the above procedures in §2.1 as a type of ‘lossy’ reduction. The procedures begin with a certain very large claim, and this claim is reduced to a much simpler one that is easier to verify, but in doing so, we accept some probability of failure. (This probability of failure cannot be avoided <em>[x1, §20]</em> and is essential in making the reduction ‘easier’ than the original problem.) Indeed, any reduction we present here can be split into three steps: first, we are handed some black box, we then</p>

    <p class="text-gray-300">query the black box, and finally we verify that its result is consistent with some statement. Ideally, verifying the result in the last step is much easier than the original claim we wished to show; in some cases, though, it is only marginally easier. In these cases, we can then replace this last step with another reduction (and accept some additional error for doing so) that is also marginally easier, and so on, until the claim has been reduced to a very simple one, which also has a very small probability of error. This is the basic structure of a number of succinct proof systems, a few of which we generalize here.</p>

    <h5 id="sec-43" class="text-base font-semibold mt-4">Size of the generator.</h5>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Another important point that could be raised is that, for example, the matrix in §2.1.2 is very large: the number of rows of <span class="math">G</span> is $m=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, which is on the order of </span>2^{255}<span class="math">, far too large to fit in any computer. The important thing to keep in mind is that the whole matrix should never be constructed. The only way that the matrix </span>G<span class="math"> is ‘accessed’ is in finding a specific symbol, say </span>r<span class="math"> of the encoding, </span>(Gx)_{r}<span class="math">, which means that it suffices to only construct the </span>r<span class="math">th row of </span>G<span class="math">, written </span>\\tilde{g}_{r}^{T}$, which we can use to compute the symbol by noting that</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">(Gx)_{r}=\\tilde{g}_{r}^{T}x.</span></p>

    <p class="text-gray-300">Indeed, in many of the checks that follow, we only need the ability to query the inner product of the message <span class="math">x</span> with a single row of the matrix <span class="math">G</span>, even when this matrix is very large.</p>

    <h2 id="sec-44" class="text-2xl font-bold">3 Standard checks</h2>

    <p class="text-gray-300">In the remainder of this paper, we will build up a library of such ‘checks’, beginning with the zero checks presented above. Using the probabilistic implications presented in §1.4, it will then be possible to compose these checks in a variety of ways to achieve certain outcomes. Along the way, we will give natural linear-algebraic generalizations of many checks and tools commonly used in succinct proof systems, along with some conjectures that greatly generalize a number of standard protocols.</p>

    <h3 id="sec-45" class="text-xl font-semibold mt-8">3.1 Classic checks</h3>

    <p class="text-gray-300">In this section we focus on what we call the ‘classic’ checks: those which check exact inclusion, exact equality, and so on. This should be compared to the ‘sparse checks’ presented later in this section, which only seek to verify that vectors are ‘close enough’ to others. This is presented first as some of the tools used in the checks here are used in the later section.</p>

    <p class="text-gray-300">For the remainder of the section, <span class="math">G\\in\\mathbf{F}^{m\\times n}</span> will be a matrix representing a linear code with message length <span class="math">n</span> and block length <span class="math">m</span>. We will assume that the distance of this code is <span class="math">d\\geq 0</span>. It will sometimes be convenient to consider the rows of <span class="math">G</span>, which we write as <span class="math">\\tilde{g}_{r}^{T}</span> for the <span class="math">r</span>th row.</p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">3.1.1 Zero check</p>

    <p class="text-gray-300">This is a rewriting of the zero check presented in §2.1.2, using the notation defined in §1.4. One particular reduction of interest is to note that checking that two vectors are equal is, roughly speaking, the same as checking if a single vector is nonzero. In particular, checking that <span class="math">x=y</span> is identical to checking that <span class="math">x-y=0</span>, and, using the linearity of <span class="math">G</span>, as in the proof given in §2.1.2, it suffices only to check this latter claim.</p>

    <h4 id="sec-46" class="text-lg font-semibold mt-6">Check.</h4>

    <p class="text-gray-300">Given a linear code with generator <span class="math">G\\in\\mathbf{F}^{m\\times n}</span> and distance <span class="math">d</span>, we wish to show that <span class="math">x=0</span> with high probability, by checking a much smaller claim. We can write the procedure specified in §2.1.2 compactly using this notation. For any <span class="math">x\\in\\mathbf{F}^{n}</span>, the following is true</p>

    <p class="text-gray-300"><span class="math">(Gx)_{r}=0\\quad\\implies\\quad x=0,</span> (5)</p>

    <p class="text-gray-300">where the randomness is over <span class="math">r</span>, uniformly sampled from <span class="math">\\{1,\\ldots,m\\}</span>, and <span class="math">p\\leq 1-d/m</span>. (The reverse direction is obviously always true.) Parsing the symbols in expression (5) carefully, it may be read as: if <span class="math">(Gx)_{r}=0</span>, for a uniformly randomly chosen <span class="math">r</span> in <span class="math">1,\\ldots,m</span>, then the probability that <span class="math">x\\neq 0</span> is no more than <span class="math">p</span>. In other words, it suffices to check that a single random symbol of the encoding of <span class="math">x</span> is zero to conclude that <span class="math">x</span> is the zero vector, with high probability (at least <span class="math">1-p</span>). Note that this is exactly the claim we showed in §2.1.2, but the notation here is considerably more compact. As a useful exercise, note that the check (5) can also be written</p>

    <p class="text-gray-300"><span class="math">\\tilde{g}^{T}_{r}x=0\\quad\\implies\\quad x=0,</span> (6)</p>

    <p class="text-gray-300">where <span class="math">\\tilde{g}^{T}_{r}</span> denotes the <span class="math">r</span>th row of <span class="math">G</span>.</p>

    <h4 id="sec-47" class="text-lg font-semibold mt-6">Example.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A special case of this relation, used in a number of zero knowledge protocols, is known as the <em>polynomial zero check</em> <em>[x11, §2.2]</em>. This check says that, given a polynomial <span class="math">f:\\mathbf{F}\\to\\mathbf{F}</span> of degree no more than <span class="math">n-1</span>, if we uniformly randomly sample a point <span class="math">r\\in\\mathbf{F}</span> and find that <span class="math">f(r)=0</span>, then, with probability at least $1-(n-1)/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, we know that </span>f=0$ everywhere. We may write this in the above notation as:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">f(r)=0\\quad\\implies\\quad f=0,</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where $p\\leq(n-1)/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. Note that this is the special case of the check provided in (5), where the coefficients of the polynomial </span>f<span class="math"> are represented as a vector </span>x\\in\\mathbf{F}^{n}$ such that</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">f(\\beta)=x_{1}+x_{2}\\beta+\\cdots+x_{n}\\beta^{n-1},</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">for <span class="math">\\beta\\in\\mathbf{F}</span>, and the matrix <span class="math">G\\in\\mathbf{F}^{m\\times n}</span> is the Reed–Solomon code matrix §1.3.2 where every field element in <span class="math">\\mathbf{F}</span> is an evaluation point. This means that $m=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$, and, using the probability bound in (5) we find</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$p\\leq 1-\\frac{d}{m}=1-\\frac{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-n+1}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}=\\frac{n-1}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where the first equality uses the distance of a Reed–Solomon code <span class="math">d=m-n+1</span>. This matches the bound of the original polynomial zero check (cf., <em>[x21, §2.1]</em>) exactly, as expected.</p>

    <h4 id="sec-48" class="text-lg font-semibold mt-6">3.1.2 Matrix zero check</h4>

    <p class="text-gray-300">We may check that a matrix <span class="math">X\\in{\\bf F}^{k\\times n}</span> is zero by reducing the claim to checking that a single <span class="math">k</span>-vector is zero.</p>

    <h5 id="sec-49" class="text-base font-semibold mt-4">Check.</h5>

    <p class="text-gray-300">Let <span class="math">X</span> be an <span class="math">k\\times n</span> matrix, with columns <span class="math">x_{1},\\ldots,x_{k}</span>. We may then check that <span class="math">X</span> is zero by noting that</p>

    <p class="text-gray-300"><span class="math">G_{r1}x_{1}+\\cdots+G_{rn}x_{n}=0\\quad\\underset{p}{\\Longrightarrow}\\quad\\ X=0,</span> (7)</p>

    <p class="text-gray-300">where the randomness is again over <span class="math">r</span>, uniformly sampled from <span class="math">\\{1,\\ldots,m\\}</span>, and we have that <span class="math">p=1-d/m</span>. We may view the check (7) as uniformly randomly drawing a row of <span class="math">G</span>, say <span class="math">\\tilde{g}_{r}^{T}</span>, using this row to take a linear combination of the columns of <span class="math">X</span>, and checking that the result is zero; we may write this as,</p>

    <p class="text-gray-300"><span class="math">X\\tilde{g}_{r}=0\\quad\\underset{p}{\\Longrightarrow}\\quad\\ X=0,</span> (8)</p>

    <p class="text-gray-300">where, again, <span class="math">\\tilde{g}_{r}</span> is a uniformly randomly selected row of <span class="math">G</span>, viewed as a column vector, and <span class="math">p\\leq 1-d/m</span>.</p>

    <h5 id="sec-50" class="text-base font-semibold mt-4">Proof.</h5>

    <p class="text-gray-300">The proof follows by reducing this case to the previously presented zero check. Let <span class="math">\\tilde{x}_{1}^{T},\\ldots,\\tilde{x}_{k}^{T}</span> be the <span class="math">k</span> rows of the matrix <span class="math">X</span>:</p>

    <p class="text-gray-300">\\[ X=\\begin{bmatrix}\\tilde{x}_{1}^{T}\\\\ \\vdots\\\\ \\tilde{x}_{k}^{T}\\end{bmatrix}. \\]</p>

    <p class="text-gray-300">Now, let’s say that for uniformly randomly chosen <span class="math">r</span> from <span class="math">1,\\ldots,m</span>, we have that the left-hand-side of the claim (7) is true,</p>

    <p class="text-gray-300"><span class="math">G_{r1}x_{1}+\\cdots+G_{rn}x_{n}=0,</span> (9)</p>

    <p class="text-gray-300">then, this is the same as saying that</p>

    <p class="text-gray-300"><span class="math">(G\\tilde{x}_{1})_{r}=0,\\ \\ldots,\\ (G\\tilde{x}_{k})_{r}=0.</span></p>

    <p class="text-gray-300">(All we have done is reinterpret the sum (9) in terms of the rows of <span class="math">X</span>, as opposed to the columns.) From before, we know that each of these has</p>

    <p class="text-gray-300"><span class="math">(G\\tilde{x}_{j})_{r}=0\\quad\\underset{p}{\\Longrightarrow}\\quad\\ \\tilde{x}_{j}=0,</span></p>

    <p class="text-gray-300"><span class="math">p\\leq 1-d/m</span>, for <span class="math">j=1,\\ldots,k</span>. But then, if every row of <span class="math">X</span> is zero, <span class="math">\\tilde{x}_{j}=0</span>, this implies <span class="math">X=0</span>, which gives the result that</p>

    <p class="text-gray-300"><span class="math">G_{r1}x_{1}+\\cdots+G_{rn}x_{n}=0\\quad\\implies\\quad X=0,</span></p>

    <p class="text-gray-300">with the same <span class="math">p</span> as above, <span class="math">p\\leq 1-d/m</span>.</p>

    <h4 id="sec-51" class="text-lg font-semibold mt-6">Example.</h4>

    <p class="text-gray-300">This reduction is very similar to a number of ‘common’ checks: for example, to check that a list of vectors is zero, many protocols <em>[x1, x13]</em> will take a uniformly random linear combination of these vectors and check that the result of this linear combination is zero. We note that this is exactly the special case of the check (7) when the matrix <span class="math">G</span> is a Hadamard code matrix (see §1.3.3), in which case randomly drawing a row of <span class="math">G</span> corresponds exactly to randomly drawing a uniform vector in <span class="math">\\mathbf{F}^{n}</span> and so the check (7) corresponds to taking a uniformly random linear combination of the columns of <span class="math">X</span>. In this case, we recover the ‘standard’ error bound:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$p\\leq 1-\\frac{d}{m}=1-\\frac{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{n}-</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{n-1}}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{n}}=\\frac{1}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where we have used the fact that the Hadamard code of message length <span class="math">n</span> with field <span class="math">\\mathbf{F}</span> has block size $m=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{n}<span class="math"> and distance </span>d=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{n}-</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{n-1}$, as shown in §1.3.3.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-52" class="text-lg font-semibold mt-6">3.1.3 Reduced matrix zero check</h4>

    <p class="text-gray-300">The previous section §3.1.2 showed that we can reduce checking that a matrix is zero to checking that a single vector is zero. We also have, from §3.1.1, a way to reduce checking that a vector is zero to checking that a single field element is zero. The natural next step is to join the two checks together and therefore reduce checking that a matrix is zero to checking that a single field element is zero, with some additional error. Recalling the previous set up, we assume that we are interested in checking that some matrix <span class="math">X\\in\\mathbf{F}^{k\\times n}</span> is zero.</p>

    <h4 id="sec-53" class="text-lg font-semibold mt-6">Check.</h4>

    <p class="text-gray-300">For this check, we introduce a second code matrix <span class="math">G^{\\prime}\\in\\mathbf{F}^{m^{\\prime}\\times k}</span> (which will serve as our second check’s code matrix) with distance <span class="math">d^{\\prime}\\geq 0</span>. The check can then be written:</p>

    <p class="text-gray-300"><span class="math">\\left(G^{\\prime}\\left(\\sum_{i=1}^{k}G_{ri}x_{i}\\right)\\right)_{r^{\\prime}}=0\\quad\\implies\\quad X=0,</span></p>

    <p class="text-gray-300">where <span class="math">x_{i}</span> denotes the <span class="math">i</span>th column of <span class="math">X</span>, while <span class="math">r</span> is uniformly randomly drawn from <span class="math">1,\\ldots,m</span> and <span class="math">r^{\\prime}</span> is uniformly randomly drawn from <span class="math">1,\\ldots,m^{\\prime}</span>. Here, <span class="math">p\\leq 1-d/m</span> and <span class="math">p^{\\prime}\\leq 1-d^{\\prime}/m^{\\prime}</span> Another way of writing this check is, letting <span class="math">\\tilde{g}_{r}^{T}</span> denote the <span class="math">r</span>th row of <span class="math">G</span> and <span class="math">\\bar{g}_{r^{\\prime}}^{T}</span> denote the <span class="math">r^{\\prime}</span>th row of <span class="math">G^{\\prime}</span>,</p>

    <p class="text-gray-300"><span class="math">\\tilde{g}_{r^{\\prime}}^{T}X\\tilde{g}_{r}=0\\quad\\implies\\quad X=0.</span> (10)</p>

    <p class="text-gray-300">We will use this more compact statement to prove the claim.</p>

    <p class="text-gray-300">Proof. The check is essentially also the proof of its correctness, using the notation and implications of §1.4, along with the proofs presented previously. Starting with the left hand side of (10)</p>

    <p class="text-gray-300"><span class="math">\\tilde{g}^{\\prime T}_{r^{\\prime}}(X\\tilde{g}_{r})=0\\quad\\underset{p^{\\prime}}{\\Longrightarrow}\\quad\\ X\\tilde{g}_{r}=0,</span></p>

    <p class="text-gray-300">using the basic zero check (6), where <span class="math">p^{\\prime}\\leq 1-d^{\\prime}/m^{\\prime}</span> and <span class="math">r^{\\prime}</span> uniformly randomly selected from <span class="math">1,\\ldots,m^{\\prime}</span>. Note that this statement is true for any <span class="math">r</span>. Now, from the matrix check (8), we know that</p>

    <p class="text-gray-300"><span class="math">X\\tilde{g}_{r}=0\\quad\\underset{p}{\\Longrightarrow}\\quad\\ X=0,</span></p>

    <p class="text-gray-300">where <span class="math">r</span> is uniformly randomly selected from <span class="math">1,\\ldots,m</span>. Using the chained implications of §1.4, we therefore have that</p>

    <p class="text-gray-300"><span class="math">\\tilde{g}^{\\prime T}_{r^{\\prime}}(X\\tilde{g}_{r})=0\\quad\\underset{p+p^{\\prime}}{\\Longrightarrow}\\quad\\ X=0.</span></p>

    <p class="text-gray-300">where <span class="math">r</span> and <span class="math">r^{\\prime}</span> are uniformly and independently chosen from <span class="math">1,\\ldots,m</span> and <span class="math">1,\\ldots,m^{\\prime}</span>, respectively, while <span class="math">p</span> and <span class="math">p^{\\prime}</span> are as defined above, which is what we wished to prove.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Discussion. We may view the check above as a type of ‘generalized Schwartz–Zippel’ lemma <em>[x23, §3.4]</em>, for arbitrary linear codes. Indeed, when the matrices <span class="math">G</span> and <span class="math">G^{\\prime}</span> are Reed–Solomon code matrices and every field element is an evaluation point, we may interpret the check as exactly evaluating a bivariate polynomial, with coefficients <span class="math">X</span>, at two uniformly randomly chosen points in <span class="math">\\mathbf{F}</span>. In this case, $m=m^{\\prime}=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, and, since the matrix </span>X\\in\\mathbf{F}^{k\\times n}<span class="math">, then this means that </span>n-1<span class="math"> is the max degree of the first variable and </span>k-1<span class="math"> is the max degree of the second. The bound here then says that, if the polynomial is nonzero (i.e., if </span>X\\neq 0<span class="math">) then the probability that the polynomial, evaluated at a uniformly randomly chosen point in </span>\\mathbf{F}^{2}$, evaluates to zero is no more than</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$p+p^{\\prime}\\leq\\left(1-\\frac{d}{m}\\right)+\\left(1-\\frac{d^{\\prime}}{m^{\\prime}}\\right)=\\frac{(n-1)+(k-1)}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">exactly matching the bound of Schwartz–Zippel. Here, we have used the fact that <span class="math">d=m-n+1</span> for Reed–Solomon codes (and similarly for <span class="math">d^{\\prime}</span>). Surprisingly, it is not hard to show that this bound is loose (and therefore Schwartz–Zippel is, as well) except when the codes are trivial, and it is possible to do better by using the fact that the codes are linear. In this case, the bound can be improved by an additive factor of around <span class="math">(1-d/m)(1-d^{\\prime}/m^{\\prime})</span> which is very small when <span class="math">d/m</span> and <span class="math">d^{\\prime}/m^{\\prime}</span> are very close to <span class="math">1</span>. (See appendix B.3.)</p>

    <p class="text-gray-300">Generalization. A natural question is, of course, can we generalize this procedure from vectors and matrices to some sort of higher-order mathematical structure? A natural idea would be to introduce tensors and so on, but there is a slightly simpler approach which we can explore via the Kronecker product. (See appendix B.1 for a definition.) In particular, we may identify the <span class="math">k\\times n</span> matrix <span class="math">X</span> with a (long) vector <span class="math">x\\in\\mathbf{F}^{kn}</span> by stacking the columns</p>

    <p class="text-gray-300">of <span class="math">X</span>. The procedure above, performed over <span class="math">X</span>, is equivalent to running the following check over the vector <span class="math">x</span>,</p>

    <p class="text-gray-300"><span class="math">((G^{\\prime}\\otimes G)x)_{r^{\\prime\\prime}}=0\\quad\\implies\\quad x=0,</span></p>

    <p class="text-gray-300">where <span class="math">G^{\\prime}\\otimes G</span> is the Kronecker product of <span class="math">G</span> and <span class="math">G^{\\prime}</span>, and <span class="math">r^{\\prime\\prime}</span> is uniformly randomly chosen from <span class="math">1,\\ldots,mm^{\\prime}</span>, while <span class="math">p\\leq 1-dd^{\\prime}/mm^{\\prime}</span>. Indeed, this ‘equivalence’ gives us a tighter bound, which we show in appendix B.2, than the one derived above. Of course, given any higher order tensor of <span class="math">s</span> dimensions, say, <span class="math">(n_{j})</span> for <span class="math">j=1,\\ldots,s</span>, we may always ‘stack’ the tensor into a vector <span class="math">x</span> of size <span class="math">\\prod_{j}n_{j}</span> and apply a similar procedure, given codes <span class="math">G_{j}</span> of dimension <span class="math">{\\bf F}^{m_{j}\\times n_{j}}</span> for each <span class="math">j=1,\\ldots,s</span>. This leads to a ‘general check’</p>

    <p class="text-gray-300"><span class="math">((G_{1}\\otimes G_{2}\\otimes\\cdots\\otimes G_{s})x)_{r}=0\\implies x=0,</span></p>

    <p class="text-gray-300">where <span class="math">r</span> is uniformly sampled from <span class="math">1,\\ldots,\\prod_{j}m_{j}</span>, while</p>

    <p class="text-gray-300"><span class="math">p\\leq 1-\\prod_{j=1}^{s}\\frac{d_{j}}{m_{j}}.</span></p>

    <p class="text-gray-300">If the matrices <span class="math">G_{j}</span> are Vandemonde matrices, where every element in the field <span class="math">{\\bf F}</span> is an evaluation point, then Schwartz–Zippel would imply that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$p\\leq\\sum_{j=1}^{s}\\left(1-\\frac{d_{j}}{m_{j}}\\right)=\\frac{\\sum_{j=1}^{s}(n_{j}-1)}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">{\\bf F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Note that <span class="math">n_{j}-1</span> denotes the degree of the <span class="math">j</span>th variable, so the sum can be recognized as the total degree of the <span class="math">s</span>-variate polynomial. On the other hand, this bound would imply,</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$p\\leq 1-\\frac{\\prod_{j=1}^{s}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">{\\bf F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-n_{j}+1)}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">{\\bf F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">^{s}}=1-\\prod_{j=1}^{s}\\left(1-\\frac{n_{j}-1}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">{\\bf F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\right).$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">These two values are, of course, very close if $n_{j}\\ll</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">{\\bf F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, but the latter is always a better bound unless </span>n_{j}=1<span class="math"> for all but one index </span>j$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-54" class="text-lg font-semibold mt-6">3.1.4 Vector subspace check</h4>

    <p class="text-gray-300">Finally, we can construct the most general form of the above checks by strengthening the procedures slightly. We may verify that the columns of a matrix <span class="math">X\\in{\\bf F}^{k\\times n}</span> all belong to some vector subspace <span class="math">V\\subseteq{\\bf F}^{k}</span> by verifying that only one vector belongs in such a subspace.</p>

    <h5 id="sec-55" class="text-base font-semibold mt-4">Check.</h5>

    <p class="text-gray-300">Using the same set up as the matrix zero check §3.1.2, let <span class="math">x_{i}\\in{\\bf F}^{k}</span> denote the <span class="math">i</span>th column of the matrix <span class="math">X</span>. The subspace check may be written as follows:</p>

    <p class="text-gray-300"><span class="math">G_{r1}x_{1}+\\cdots+G_{rn}x_{n}\\in V\\quad\\implies\\quad x_{i}\\in V\\ \\ \\mbox{for}\\ \\ i=1,\\ldots,n,</span> (11)</p>

    <p class="text-gray-300">where</p>

    <p class="text-gray-300"><span class="math">r</span> is chosen uniformly at random from <span class="math">1,\\ldots,m</span>, and <span class="math">p\\leq 1-d/m</span>. In a similar way to the previous, we may interpret this check as picking a random row of <span class="math">G</span>, say <span class="math">\\tilde{g}_{r}^{T}</span>, uniformly over all rows, and then using this row as the coefficients of a linear combination of the columns of <span class="math">X</span>. We may equivalently write this statement as</p>

    <p class="text-gray-300"><span class="math">X\\tilde{g}_{r}\\in V\\quad\\implies\\quad\\quad X\\in V_{n},</span> (12)</p>

    <p class="text-gray-300">where <span class="math">V_{n}</span> is the set of <span class="math">k\\times n</span> matrices whose columns lie in the vector space <span class="math">V</span>.</p>

    <p class="text-gray-300">Proof. The proof follows nearly immediately from the original matrix zero check. Since <span class="math">V</span> is a vector space, we know there exists a parity check matrix <span class="math">C\\in{\\bf F}^{s\\times n}</span> such that <span class="math">y\\in V</span> if, and only if, <span class="math">Cy=0</span>, from (2). Given this, consider the left hand side of (11). If this is true, then</p>

    <p class="text-gray-300"><span class="math">G_{r1}x_{1}+\\cdots+G_{rn}x_{n}\\in V\\quad\\mbox{implies}\\quad C(G_{r1}x_{1}+\\cdots+G_{rn}x_{n})=0.</span></p>

    <p class="text-gray-300">We may rewrite the right hand side of this expression to:</p>

    <p class="text-gray-300"><span class="math">G_{r1}(Cx_{1})+\\cdots+G_{rn}(Cx_{n})=0,</span></p>

    <p class="text-gray-300">for any <span class="math">r</span>. But, note that, if <span class="math">r</span> is chosen uniformly at random from <span class="math">1,\\ldots,m</span>, then, from the matrix zero check §3.1.2, we know</p>

    <p class="text-gray-300"><span class="math">G_{r1}(Cx_{1})+\\cdots+G_{rn}(Cx_{n})=0\\quad\\implies\\quad\\quad Cx_{i}=0,\\mbox{ for }i=1,\\ldots,n,</span></p>

    <p class="text-gray-300">where <span class="math">p\\leq 1-d/m</span>. By definition of the parity check matrix <span class="math">C</span>, the right hand side of this expression can be written</p>

    <p class="text-gray-300"><span class="math">Cx_{i}=0\\quad\\mbox{implies}\\quad x_{i}\\in V,</span></p>

    <p class="text-gray-300">for each <span class="math">i=1,\\ldots,n</span>. Putting it all together gives the final result:</p>

    <p class="text-gray-300"><span class="math">G_{r1}x_{1}+\\cdots+G_{rn}x_{n}\\in V\\quad\\implies\\quad\\quad x_{i}\\in V\\ \\mbox{ for }\\ i=1,\\ldots,n.</span></p>

    <p class="text-gray-300">Discussion and extensions. We may view this check as a generalization of the matrix zero check, which is the special case of this check when the subspace <span class="math">V=\\{0\\}</span> (and therefore one possible parity check matrix for this subspace would be <span class="math">C=I</span>). We may also ask if it is possible to extend the above check in a similar way to the reduced matrix zero check §3.1.3. Indeed, using the check (12) and the definition of the parity check matrix <span class="math">C</span>, we can write the left hand side as</p>

    <p class="text-gray-300"><span class="math">X\\tilde{g}_{r}\\in V\\quad\\mbox{if, and only if,}\\quad CX\\tilde{g}_{r}=0,</span></p>

    <p class="text-gray-300">where <span class="math">\\tilde{g}_{r}</span> is the <span class="math">r</span>th row of <span class="math">G</span>, viewed as a column vector. Given a second code matrix <span class="math">G^{\\prime}\\in{\\bf F}^{m^{\\prime}\\times s}</span> with distance <span class="math">d^{\\prime}</span>, we can reduce checking the right hand side of this statement, whether <span class="math">CXg_{r}=0</span>, to a ‘simpler’ check over a single field element, since:</p>

    <p class="text-gray-300"><span class="math">\\tilde{g}_{r^{\\prime}}^{T}CX\\tilde{g}_{r}=0\\quad\\implies\\quad\\quad\\quad CXg_{r}=0,</span></p>

    <p class="text-gray-300"><span class="math">p^{\\prime}\\leq 1-d^{\\prime}/m^{\\prime}</span> and <span class="math">\\tilde{g}_{r^{\\prime}}^{T}</span> is a uniformly randomly sampled row of <span class="math">G^{\\prime}</span>. (This follows from the zero check (6), using the code generated by <span class="math">G^{\\prime}</span>.) The remainder of the check proceeds in the same way as (11) and has total error no more than <span class="math">p+p^{\\prime}</span>. If it is easy to efficiently compute the matrix vector product <span class="math">C^{T}\\tilde{g}_{r^{\\prime}}^{\\prime}</span> (it need not be, as this product may be large), then this check may be achieved with an inner product commitment.</p>

    <h3 id="sec-56" class="text-xl font-semibold mt-8">3.2 Sparse checks</h3>

    <p class="text-gray-300">In this section, we present what we call the <em>sparse checks</em>. In comparison to the previous section §3.1, which mostly dealt with whether a vector is, say, all zero, or included in some vector space, this section deals with notions related to the sparsity of a vector or the distance from a vector to a vector space.</p>

    <p class="text-gray-300">As in the previous section, we assume that <span class="math">G\\in\\mathbf{F}^{m\\times n}</span> is a matrix generating a code with block size <span class="math">m</span>, for messages of size <span class="math">n</span>. We let <span class="math">d\\geq 0</span> be the distance of this code, as defined previously. As before, this definition will be used for the remainder of the section.</p>

    <h4 id="sec-57" class="text-lg font-semibold mt-6">3.2.1 Sparsity check</h4>

    <p class="text-gray-300">The first useful tool is the fact that we can check whether a given vector <span class="math">x\\in\\mathbf{F}^{k}</span> is <em>sparse</em>, that is, if most of its entries are equal to zero.</p>

    <h5 id="sec-58" class="text-base font-semibold mt-4">Check and proof.</h5>

    <p class="text-gray-300">The simplest idea is to check that a randomly chosen entry of <span class="math">x\\in\\mathbf{F}^{k}</span> is zero: if this is true, then, with some probability, the vector <span class="math">x</span> must be somewhat sparse. Writing this out, we have,</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$x_{r}=0\\quad\\implies\\ \\ \\ \\ \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">with probability <span class="math">p\\leq 1-(q+1)/k</span>, where <span class="math">r</span> is uniformly randomly sampled from <span class="math">1,\\ldots,k</span>. To see this, note that if <span class="math">x_{r}=0</span> yet, $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}>q<span class="math">, then </span>x<span class="math"> has at least </span>q+1<span class="math"> nonzero entries. The probability we land on one of these is at least </span>(q+1)/k<span class="math"> so the probability we land on none is no more than </span>1-(q+1)/k$, as given above.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">If the vector <span class="math">x</span> is very sparse, then <span class="math">q</span> is much smaller than <span class="math">k</span> and this check is unlikely to succeed with high probability. Of course, we can simply repeat the check over a number of uniformly randomly-chosen indices <span class="math">S\\subseteq\\{1,\\ldots,k\\}</span> of some fixed size, then</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$x_{S}=0\\quad\\implies\\ \\ \\ \\ \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">with $p\\leq(1-(q+1)/k)^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">, by a nearly identical argument. (The analysis can be made slightly tighter by noting that </span>S<span class="math"> does not have repeated indices, but we usually assume that </span>q\\ll k$.)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h5 id="sec-59" class="text-base font-semibold mt-4">Discussion.</h5>

    <p class="text-gray-300">This is the same argument as the one presented in §2.1.1 except with the notation of §1.4. The main idea here is that we may take a check that succeeds with</p>

    <p class="text-gray-300">relatively small probability and repeat it. Assuming that the samples are uniformly random and independent, this, of course, decreases the probability that the check fails.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Additionally, and for fun, we may combine this check with the previous zero check of §3.1.1. If $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=n<span class="math">, then, using the definition of </span>G$ at the beginning of this subsection,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$(Gx_{S})_{r}=0\\quad\\implies\\quad x_{S}=0\\quad\\implies\\quad\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">with <span class="math">p^{\\prime}\\leq 1-d/m</span> over a uniformly chosen <span class="math">r</span> from <span class="math">1,\\ldots,m</span>, and <span class="math">S</span> a uniform random subset of <span class="math">\\{1,\\ldots,k\\}</span> and <span class="math">p</span> is the same as above. This means that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$(Gx_{S})_{r}=0\\quad\\implies\\quad\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where <span class="math">r</span> is chosen from <span class="math">1,\\ldots,m</span> and <span class="math">S\\subseteq\\{1,\\ldots n\\}</span> are both uniformly randomly chosen.</p>

    <h4 id="sec-60" class="text-lg font-semibold mt-6">3.2.2 Matrix sparsity check</h4>

    <p class="text-gray-300">Another simple idea is to note that we can reduce the sparsity check for a list of vectors into a single sparsity check for a single vector. In particular, given a matrix <span class="math">X\\in\\mathbf{F}^{k\\times n}</span>, whose columns are vectors <span class="math">x_{i}\\in\\mathbf{F}^{k}</span> for <span class="math">i=1,\\ldots,n</span>, the following check holds:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{k}G_{ri}x_{i}\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\quad\\implies\\quad X\\text{ has at most }q\\text{ nonzero rows,}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where <span class="math">p=(q+1)(1-d/m)</span> . Note that this implies that each vector has $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x_{i}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q<span class="math"> for </span>i=1,\\ldots,k$, but is, in general, a stronger statement. For example, this implies something roughly like: either all vectors are extremely sparse, or their nonzero entries are aligned.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Proof. We will give a simple bound on the probability that the inequality fails. In particular, given some <span class="math">X</span> with at least <span class="math">q+1</span> nonzero rows, we need to show that the probability that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{k}G_{ri}x_{i}\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q$ (13)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">is small, for a uniformly randomly chosen <span class="math">r</span> (from <span class="math">1,\\ldots,m</span>). To see this, we will reduce the matrix sparsity check to the zero check provided in §3.1.1.</p>

    <p class="text-gray-300">First, consider the expression in (13). We may remove rows of <span class="math">X</span> to get some shorter matrix <span class="math">\\hat{X}</span>. Note that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{k}G_{ri}\\hat{x}_{i}\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{k}G_{ri}x_{i}\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">for any choice of <span class="math">r</span>, where <span class="math">\\hat{x}_{i}</span> denotes the <span class="math">i</span>th column of the shorter matrix <span class="math">\\hat{X}</span>. So, the probability that the event (13) happens is at most the probability that the event</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{k}G_{ri}\\hat{x}_{i}\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">appens over a uniform choice of <span class="math">r</span> from <span class="math">1,\\ldots,m</span>.</p>

    <p class="text-gray-300">Now, let <span class="math">X</span> have more than <span class="math">q</span> nonzero rows. We may pick any <span class="math">q+1</span> nonzero rows of <span class="math">X</span> to get the matrix <span class="math">\\hat{X}\\in\\mathbf{F}^{(q+1)\\times k}</span>. Since every row of <span class="math">\\hat{X}</span> is nonzero, if</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{k}G_{ri}\\tilde{x}_{i}\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">then there is at least one row of <span class="math">\\hat{X}</span>, say <span class="math">\\tilde{x}_{j}^{T}</span>, which satisfies</p>

    <p class="text-gray-300"><span class="math">(G\\tilde{x}_{j})_{r}=0.</span></p>

    <p class="text-gray-300">Of course, this happens with probability at most <span class="math">1-d/m</span> by the zero check in (5). Finally, since there are <span class="math">q+1</span> possible choices of rows, we have that</p>

    <p class="text-gray-300"><span class="math">p\\leq(q+1)\\left(1-\\frac{d}{m}\\right),</span></p>

    <p class="text-gray-300">by the union bound, as required.</p>

    <h4 id="sec-61" class="text-lg font-semibold mt-6">Discussion.</h4>

    <p class="text-gray-300">While likely not very useful by itself, we can think of this particular check as a type of ‘lemma’ which we can strengthen slightly to be part of the following check: the subspace distance check.</p>

    <h4 id="sec-62" class="text-lg font-semibold mt-6">3.2.3 Subspace distance check</h4>

    <p class="text-gray-300">An important consequence of the sparsity check above is the ability to check that a matrix <span class="math">X\\in\\mathbf{F}^{k\\times n}</span> has columns close to a vector subspace <span class="math">V\\subseteq\\mathbf{F}^{k}</span>, by reducing this to checking only that a single vector is close to the subspace <span class="math">V</span>.</p>

    <h4 id="sec-63" class="text-lg font-semibold mt-6">Definitions.</h4>

    <p class="text-gray-300">For this check, we have to introduce a few more definitions, similar in spirit to the previous ones. First, we will define the <em>distance</em> of a subspace <span class="math">V</span> as</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$d^{\\prime}=\\min_{x\\in V\\setminus\\{0\\}}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">(Note that this is the definition of distance of a code <span class="math">G</span> whenever <span class="math">V=\\mathcal{R}(G)</span> and <span class="math">G</span> is injective.) Now, we define what it means for a matrix <span class="math">X</span> to be <span class="math">q</span>-close to a vector subspace <span class="math">V</span>. Let <span class="math">Y</span> be any matrix whose columns lie in <span class="math">V</span>, then we say <span class="math">X</span> is <em><span class="math">q</span>-close to <span class="math">V</span></em> if there exists some matrix <span class="math">Y</span>, meeting the above conditions, such that <span class="math">X-Y</span> has at most <span class="math">q</span> nonzero rows. Conversely, we say <span class="math">X</span> is <em><span class="math">q</span>-far</em> from <span class="math">V</span> if, for every matrix <span class="math">Y</span> with columns in <span class="math">V</span>, the difference <span class="math">X-Y</span> has at least <span class="math">q</span> nonzero rows.</p>

    <p class="text-gray-300">####</p>

    <h4 id="sec-64" class="text-lg font-semibold mt-6">Check.</h4>

    <p class="text-gray-300">We can now state the subspace distance check: let <span class="math">q&lt;d^{\\prime}/2</span> then</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{n}G_{ri}x_{i}-V\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\quad\\implies\\quad X\\text{ is <span class="math">q</span>-close to <span class="math">V</span>},$ (14)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where <span class="math">p\\leq(q+1)(1-d/m)</span>. We leave the general case of this check as an open conjecture, proving only the special case of <span class="math">n=2</span> and <span class="math">q&lt;d^{\\prime}/4</span> below, which we use later in this paper.</p>

    <p class="text-gray-300">We note that this conjecture, in particular, generalizes some of the work from <em>[x1]</em>, which shows the special case where <span class="math">G</span> is the Hadamard code (see §1.3.3) and <span class="math">q&lt;d^{\\prime}/3</span>, with the same probability of error. (This work was extended for a different code <span class="math">G</span>, with slightly higher error probability, in <em>[x12]</em>.) In the special case that <span class="math">V</span> is the subspace generated by Reed–Solomon codes, the bound is slightly improved to <span class="math">q&lt;d^{\\prime}/2</span>, but the probability <span class="math">p</span> is slightly different <em>[BCI^{+}23]</em>. We show the ‘easy’ part of the general proof in appendix C.1, but leave the second part of this proof as an open conjecture we call the distance-preserving encoding conjecture. See the appendix C.2 for more details.</p>

    <h4 id="sec-65" class="text-lg font-semibold mt-6">Proof outline.</h4>

    <p class="text-gray-300">As mentioned previously, we provide a proof of the special case where <span class="math">n=2</span> and <span class="math">q&lt;d^{\\prime}/4</span>, which we use in the next section to generalize the FRI protocol and provide a simple proof of its security. Let</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$R=\\{r\\in\\{1,\\ldots,m\\}\\mid\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Xg_{r}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In other words, <span class="math">R</span> is the set of indices at which the left hand side of the check (14) passes, and $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">/m<span class="math"> is the probability that the check indeed passes (independent of whether </span>X<span class="math"> is </span>q<span class="math">-close to </span>V<span class="math">). We will break the proof up into two cases. First, we will show that, if </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">>m-d<span class="math"> (equivalently, if the probability that the left hand side of the check is true is greater than </span>1-d/m<span class="math">), then for all </span>z\\in\\mathbf{F}^{2}$ we have</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Xz-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq 2q<d^{\\prime}/2.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">That is, there is no linear combination of columns of <span class="math">X</span> which can certify that the matrix <span class="math">X</span> is more than <span class="math">d^{\\prime}/2</span>-far from <span class="math">V</span>. (The remaining case, if $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq m-d$, would mean we are done by definition.) We will then show that, if this is true, then the check given in (14) is correct with high probability. It is interesting that, at a very high level, the structure of the proof given here is similar to that of <em>[x1]</em>, but the mechanics of the actual proof are surprisingly different. We share more notes on the similarities (and differences) in appendix C.2.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-66" class="text-lg font-semibold mt-6">Proof, part one.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Since, by assumption, $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">>m-d<span class="math">, this means that at least two rows with indices </span>r,r^{\\prime}\\in R<span class="math">, are linearly independent. To see this, assume the contrary. Let </span>\\tilde{g}_{r}<span class="math"> be a nonzero row of </span>G<span class="math"> for </span>r\\in R<span class="math">, and, by assumption, for each other row, </span>\\tilde{g}_{r^{\\prime}}<span class="math"> with </span>r^{\\prime}\\in R<span class="math">, there exists some </span>\\alpha,\\beta<span class="math">, not both zero, such that </span>\\alpha\\tilde{g}_{r}+\\beta\\tilde{g}_{r^{\\prime}}=0<span class="math">. Let </span>x\\in\\mathbf{F}^{2}<span class="math"> be a nonzero vector satisfying </span>\\tilde{g}_{r}^{T}x=0<span class="math">, then we also have that </span>\\tilde{g}_{r^{\\prime}}^{T}x=0<span class="math">. This would, in turn, imply that </span>Gx$ is</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">zero at more than <span class="math">m-d</span> indices, so the distance of <span class="math">G</span> must be smaller than <span class="math">d</span>, contradicting the assumption. Now, let <span class="math">\\tilde{g}_{r}</span> and <span class="math">\\tilde{g}^{\\prime}_{r}</span> be two linearly independent rows, with <span class="math">r,r^{\\prime}\\in R</span>, then</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">X(\\alpha\\tilde{g}_{r}+\\beta\\tilde{g}_{r^{\\prime}})-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">X\\tilde{g}_{r}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}+\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">X\\tilde{g}_{r^{\\prime}}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq 2q.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">But since <span class="math">\\tilde{g}_{r}</span> and <span class="math">\\tilde{g}_{r^{\\prime}}</span> are linearly independent, then every vector <span class="math">z\\in{\\bf F}^{2}</span> can be written as a linear combination of these two vectors, <span class="math">z=\\alpha g_{r}+\\beta g_{r^{\\prime}}</span>. This means that every vector <span class="math">z\\in{\\bf F}^{2}</span> has</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Xz-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq 2q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">whenever $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">>m-d$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-67" class="text-lg font-semibold mt-6">Proof, part two.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Now, if $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">>m-d<span class="math">, we will show that the current check reduces to the matrix sparsity check, which would show that </span>p\\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">/m\\leq(q+1)(1-d/m)<span class="math"> if </span>X<span class="math"> is more than </span>q<span class="math">-far from </span>V<span class="math">, as required. From the assumption that </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">>m-d<span class="math"> and part one of the proof, we know that for any </span>z\\in{\\bf F}^{2}$, we have</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Xz-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq 2q.$ (15)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Since we know that <span class="math">q&lt;d^{\\prime}/4</span>, then we may write the columns of <span class="math">X</span>, <span class="math">x_{1}</span> and <span class="math">x_{2}</span>, uniquely as</p>

    <p class="text-gray-300"><span class="math">x_{i}=y_{i}+\\xi_{i},</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where <span class="math">y_{i}\\in V</span> and $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\xi_{i}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq 2q<span class="math">, using the fact any linear combination of the columns of </span>X<span class="math"> is a distance of at most </span>2q<span class="math"> from </span>V<span class="math">, see (15), and </span>2q<d^{\\prime}/2<span class="math">, so we are in the unique decoding radius; i.e., there is only one possible </span>y_{i}\\in V<span class="math"> and </span>\\xi_{i}<span class="math"> which satisfy this property. Of course, note that, since </span>y_{i}\\in V<span class="math">, then any linear combination of these vectors is also in </span>V$. This means:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Xz-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z_{1}(y_{1}+\\xi_{1})+z_{2}(y_{2}+\\xi_{2})-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z_{1}\\xi_{1}+z_{2}\\xi_{2}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">So it suffices to consider only the latter quantity.</p>

    <p class="text-gray-300">As before, let <span class="math">R</span> denote the set of indices <span class="math">1,\\ldots,m</span> over which the left hand side of the check (14) is true (independent of the right hand side). Using the above, this is the same as defining <span class="math">R</span> as</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$R=\\{r\\in\\{1,\\ldots,m\\}\\mid\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r1}\\xi_{1}+G_{r2}\\xi_{2}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">For each <span class="math">r</span>, we have a corresponding unique <span class="math">\\bar{y}_{r}\\in V</span> such that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r1}\\xi_{1}+G_{r2}\\xi_{2}-\\bar{y}_{r}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$ (16)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">as <span class="math">q&lt;d^{\\prime}/4</span>. Now, consider any pair <span class="math">r,r^{\\prime}\\in R</span> and note that, by definition</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r1}\\xi_{1}+G_{r2}\\xi_{2}-\\bar{y}_{r}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\quad\\mbox{and}\\quad\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r^{\\prime}1}\\xi_{1}+G_{r^{\\prime}2}\\xi_{2}-\\bar{y}_{r^{\\prime}}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Since scaling any vector by any constant does not increase the distance, we scale the first term by <span class="math">G_{r^{\\prime}1}</span> and the second by <span class="math">G_{r1}</span> respectively. This gives:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r^{\\prime}1}(G_{r1}\\xi_{1}+G_{r2}\\xi_{2}-\\bar{y}_{r})\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\quad\\mbox{and}\\quad\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r1}(G_{r^{\\prime}1}\\xi_{1}+G_{r^{\\prime}2}\\xi_{2}-\\bar{y}_{r^{\\prime}})\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Adding both of these terms and using the triangle inequality gives:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(G_{r^{\\prime}1}G_{r2}-G_{r1}G_{r^{\\prime}2})\\xi_{2}-(G_{r^{\\prime}1}\\bar{y}_{r}-G_{r1}\\bar{y}_{r^{\\prime}})\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq 2q.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Applying the reverse triangle inequality to the terms above gives the following claim about <span class="math">\\bar{y}_{r}</span> and <span class="math">\\bar{y}_{r^{\\prime}}</span>,</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r^{\\prime}1}\\bar{y}_{r}-G_{r1}\\bar{y}_{r^{\\prime}}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq 2q+\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(G_{r^{\\prime}1}G_{r2}-G_{r1}G_{r^{\\prime}2})\\xi_{2}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq 4q<d^{\\prime}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">So, since <span class="math">V</span> has distance <span class="math">d^{\\prime}</span> we must have that the two vectors are equal; i.e.,</p>

    <p class="text-gray-300"><span class="math">G_{r^{\\prime}1}\\bar{y}_{r}=G_{r1}\\bar{y}_{r^{\\prime}}.</span></p>

    <p class="text-gray-300">Repeating this argument, but multiplying the inequalities with <span class="math">G_{r2}</span> and <span class="math">G_{r^{\\prime}2}</span> instead, gives</p>

    <p class="text-gray-300"><span class="math">G_{r^{\\prime}2}\\bar{y}_{r}=G_{r2}\\bar{y}_{r^{\\prime}}.</span></p>

    <p class="text-gray-300">so, in particular, we may take a linear combination of these two equalities; i.e., for any <span class="math">s\\in\\mathbf{F}</span> we have</p>

    <p class="text-gray-300"><span class="math">(G_{r^{\\prime}1}+sG_{r^{\\prime}2})\\bar{y}_{r}=(G_{r1}+sG_{r2})\\bar{y}_{r^{\\prime}}.</span> (17)</p>

    <p class="text-gray-300">Now, either for all <span class="math">r\\in R</span> we have that <span class="math">\\bar{y}_{r}=0</span> or there is at least one <span class="math">\\hat{r}\\in R</span> such that <span class="math">\\bar{y}_{\\hat{r}}\\neq 0</span>. In the former case, this is the same as saying, from (16),</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r1}\\xi_{1}+G_{r2}\\xi_{2}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">for all <span class="math">r\\in R</span>. From the matrix sparsity check presented in §3.2.2, if this is true, then, since <span class="math">\\xi_{i}=x_{i}-y_{i}</span>,</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r1}\\xi_{1}+G_{r2}\\xi_{2}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\quad\\underset{p}{\\Longrightarrow}\\quad\\ X-Y\\text{ has at most <span class="math">q</span> nonzero rows,}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where <span class="math">Y\\in\\mathbf{F}^{k\\times 2}</span> is the matrix with columns <span class="math">y_{1}</span> and <span class="math">y_{2}</span>. Equivalently, if <span class="math">X-Y</span> has more than <span class="math">q</span> nonzero rows, then $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">/m\\leq(q+1)(1-d/m)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We will show that the remaining case, where some <span class="math">\\bar{y}_{\\hat{r}}\\neq 0</span>, is impossible. Let <span class="math">\\hat{r}\\in R</span> be an index such that <span class="math">\\bar{y}_{\\hat{r}}\\neq 0</span>, and let <span class="math">r\\in R</span> be any other index. Set <span class="math">s\\in\\mathbf{F}</span> in (17) such that</p>

    <p class="text-gray-300"><span class="math">G_{\\hat{r}1}+sG_{\\hat{r}2}=0.</span></p>

    <p class="text-gray-300">Using the equality (17), every <span class="math">r\\in R</span> must satisfy</p>

    <p class="text-gray-300"><span class="math">(G_{r1}+sG_{r2})\\bar{y}_{\\hat{r}}=(G_{\\hat{r}1}+sG_{\\hat{r}2})\\bar{y}_{r}=0,</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">but, since <span class="math">\\bar{y}_{\\hat{r}}\\neq 0</span>, then <span class="math">G_{r1}+sG_{r2}=0</span> for every <span class="math">r\\in R</span>. But, from the beginning of this section, we have assumed that $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">>m-d<span class="math">, so the distance of </span>G<span class="math"> is at most </span>m-</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><d<span class="math">, which contradicts our assumption on the distance of </span>G$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">4 A distance check protocol</p>

    <p class="text-gray-300">We will use some of the checks presented above to present a protocol that successively reduces checking that some (potentially very large) vector is close to a subspace, to checking that an appropriately-chosen smaller vector is close to a vector subspace. This construction is essentially a linear-algebraic generalization of the Fast Reed–Solomon Interactive Oracle Proof of Proximity <em>[x1]</em> (also called FRI) to vector spaces with certain recursive substructure. Along the way, we will give basic bounds on its probability of error and give a way of practically implementing the protocol, along with some basic query complexity bounds.</p>

    <h3 id="sec-68" class="text-xl font-semibold mt-8">4.1 A basic reduction</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In the simple protocol, we would like to reduce checking that a particular vector <span class="math">y</span> is close to some vector subspace <span class="math">V\\subseteq\\mathbf{F}^{n}</span> to the fact that it is close to a (smaller) vector subspace <span class="math">V^{\\prime}\\subseteq\\mathbf{F}^{k}</span>. We will start first with the ‘exact inclusion’ case (i.e., checking that <span class="math">y\\in V</span>), which is easier to write, and then develop the ‘distance check’ (i.e., whether $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}$ is not too large) as a generalization.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-69" class="text-lg font-semibold mt-6">Set up.</h4>

    <p class="text-gray-300">We will assume that the vector space <span class="math">V</span> has the following recursive substructure:</p>

    <p class="text-gray-300"><span class="math">V=T_{1}V^{\\prime}\\oplus T_{2}V^{\\prime}\\oplus\\cdots\\oplus T_{\\ell}V^{\\prime},</span></p>

    <p class="text-gray-300">where <span class="math">T_{i}\\in\\mathbf{F}^{n\\times k}</span> are some given matrices. Here, <span class="math">\\oplus</span> denotes the fact that <span class="math">V</span> is a direct sum of the indicated subspaces (as defined in §1.1), and we have defined, for <span class="math">i=1,\\ldots,\\ell</span>,</p>

    <p class="text-gray-300"><span class="math">T_{i}V^{\\prime}=\\{T_{i}x\\mid x\\in V^{\\prime}\\},</span></p>

    <p class="text-gray-300">which will be very convenient notation in what follows. This implies that any vector <span class="math">y\\in V</span> can be written uniquely as</p>

    <p class="text-gray-300"><span class="math">y=\\sum_{i=1}^{\\ell}T_{i}x_{i},</span></p>

    <p class="text-gray-300">where <span class="math">x_{i}\\in V^{\\prime}</span>. (This is, roughly speaking, saying that <span class="math">V</span> has some sort of recursive substructure; examples include the fact that <span class="math">\\mathbf{F}^{2k}\\sim\\mathbf{F}^{k}\\times\\mathbf{F}^{k}</span> among others.) Similar to the previous section, we will assume that we are given some matrix <span class="math">G\\in\\mathbf{F}^{m\\times n}</span> that generates a code with distance <span class="math">d</span>, and a matrix <span class="math">G^{\\prime}\\in\\mathbf{F}^{m^{\\prime}\\times k}</span> that generates a code with distance <span class="math">d^{\\prime}</span>.</p>

    <h4 id="sec-70" class="text-lg font-semibold mt-6">Aside.</h4>

    <p class="text-gray-300">While this substructure may seem like a very strong requirement, we note that it always exists for any vector space <span class="math">V</span>. If, for example, <span class="math">V</span> is of even dimension, say <span class="math">2k</span> for some <span class="math">k</span>, then there exists a matrix <span class="math">A\\in\\mathbf{F}^{n\\times 2k}</span> such that <span class="math">\\mathcal{R}(A)=V</span>. In this case, we define the matrices <span class="math">T_{1},T_{2}\\in\\mathbf{F}^{n\\times k}</span> such that</p>

    <p class="text-gray-300"><span class="math">A=\\begin{bmatrix}T_{1}&amp;T_{2}\\end{bmatrix},</span></p>

    <p class="text-gray-300">and <span class="math">V^{\\prime}=\\mathbf{F}^{k}</span>. (That is, the matrix <span class="math">T_{1}</span> contains the first <span class="math">k</span> columns of <span class="math">A</span>, while the matrix <span class="math">T_{2}</span> contains the last <span class="math">k</span> columns.) This would then show that</p>

    <p class="text-gray-300"><span class="math">V=T_{1}V^{\\prime}\\oplus T_{2}V^{\\prime}.</span></p>

    <p class="text-gray-300">Note that we do not require the matrices <span class="math">T_{i}</span> to be injective, so a similar argument would work for cases where the dimension of <span class="math">V</span> is odd. Of course, in many cases, much more structure can be exploited, but this varies on a case-by-case basis.</p>

    <h4 id="sec-71" class="text-lg font-semibold mt-6">4.1.1 Exact inclusion reduction</h4>

    <p class="text-gray-300">Indeed, we may reduce the claim of checking that <span class="math">y\\in V</span> to the (hopefully easier) single claim of checking that a single element is in the smaller vector space <span class="math">V^{\\prime}</span>. To do this, note that <span class="math">y\\in V</span> if, and only if, there exist <span class="math">x_{i}\\in V^{\\prime}</span> such that</p>

    <p class="text-gray-300"><span class="math">y=\\sum_{i=1}^{\\ell}T_{i}x_{i}.</span> (18)</p>

    <p class="text-gray-300">In other words, to verify that <span class="math">y\\in V</span>, it suffices to be given <span class="math">x_{i}\\in\\mathbf{F}^{k}</span>, verify that <span class="math">x_{i}\\in V^{\\prime}</span> for each <span class="math">i=1,\\ldots,\\ell</span>, and verify that (18) holds. Consider the claims in reverse order. Claim (18) can be verified by using a zero check (§3.1.1); i.e., letting <span class="math">\\tilde{g}_{r}^{T}</span> denote a uniformly chosen random row of <span class="math">G</span>,</p>

    <p class="text-gray-300"><span class="math">\\tilde{g}_{r}^{T}y=\\sum_{i=1}^{\\ell}\\tilde{g}_{r}^{T}T_{i}x_{i}\\quad\\implies\\quad y=\\sum_{i=1}^{\\ell}T_{i}x_{i},</span></p>

    <p class="text-gray-300">where <span class="math">p\\leq 1-d/m</span>. Similarly, we may reduce the first claim of verifying that <span class="math">x_{i}\\in V^{\\prime}</span> for each <span class="math">i</span> to verifying a single inclusion via the vector subspace check of §3.1.4:</p>

    <p class="text-gray-300"><span class="math">\\sum_{i=1}^{\\ell}G^{\\prime}_{r^{\\prime}i}x_{i}\\in V^{\\prime}\\quad\\implies\\quad x_{i}\\in V^{\\prime},\\text{ for }i=1,\\ldots,\\ell.</span></p>

    <p class="text-gray-300">Here, as shown in the check, <span class="math">p^{\\prime}\\leq 1-d^{\\prime}/m^{\\prime}</span> and <span class="math">r^{\\prime}</span> is uniformly randomly chosen from <span class="math">1,\\ldots,m^{\\prime}</span>. Combining these two statements gives the final result.</p>

    <h5 id="sec-72" class="text-base font-semibold mt-4">Discussion.</h5>

    <p class="text-gray-300">In a sense, all we are doing is exploiting the structure we assumed about the space <span class="math">V</span> to reduce checking whether <span class="math">y\\in V</span>, to (a) checking whether <span class="math">y</span> is equal to some linear combination of vectors, and (b) checking whether these individual vectors are each in the smaller subspace <span class="math">V^{\\prime}</span>. The former we may perform via a zero check, while the latter we may perform via a vector subspace check. If both of these checks are cheaper to perform than the original, then, in a sense, we have reduced the problem to a simpler one.</p>

    <p class="text-gray-300">On the other hand, unless we have some interesting cryptographic primitives (such as homomorphic inner product commitments <em>[BCC^{+}16]</em>, e.g.), it is not immediately clear how to make this protocol practically useful. To this end, we generalize this basic building block to the distance check, which will, in turn, yield a practical protocol.</p>

    <p class="text-gray-300">4.1.2 Distance reduction</p>

    <p class="text-gray-300">In this check, we will attempt to show that the provided vector <span class="math">y</span> is not too far away from <span class="math">V\\subseteq\\mathbf{F}^{n}</span>. Because of this, the exact choice of basis <span class="math">T_{i}\\in\\mathbf{F}^{n\\times k}</span> matters.</p>

    <h5 id="sec-73" class="text-base font-semibold mt-4">Basis alignment.</h5>

    <p class="text-gray-300">To this end, we will define a notion of alignment for the basis <span class="math">T_{1},\\ldots,T_{\\ell}</span>, as follows. We say the <span class="math">T_{i}</span> are <em>basis aligned</em> if, given any <span class="math">X\\in\\mathbf{F}^{k\\times\\ell}</span>, a matrix with columns <span class="math">x_{i}</span>, that is <span class="math">q</span>-close to <span class="math">V</span>, we have that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}x_{1}+\\cdots+T_{\\ell}x_{\\ell}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q^{\\prime},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">for some fixed <span class="math">q^{\\prime}</span>. (We must specify the <span class="math">q</span> and <span class="math">q^{\\prime}</span> in the definition, of course.) The interpretation of this statement is that, if the at-most-<span class="math">q</span> ‘errors’ in the columns of <span class="math">X</span> are aligned (where ‘errors’ are the number of indices where at least one column of <span class="math">X</span> differs from any closest vector in <span class="math">V^{\\prime}</span>), then the total number of errors over the larger vector space must be similarly small; i.e., at most <span class="math">q^{\\prime}</span>.</p>

    <p class="text-gray-300">While this seems like a strong restriction, we note that just the sparsity of the matrices <span class="math">T_{i}</span> would imply this claim. For example, if the matrices <span class="math">T_{i}</span> are diagonal, we would have that <span class="math">q^{\\prime}\\leq q</span>, or, if each <span class="math">T_{i}</span> is nonzero in at most two rows, and the <span class="math">T_{i}</span> all have the same sparsity pattern, we would have that <span class="math">q^{\\prime}\\leq 2q</span>, and so on. We use this fact in the protocol presented below and provide a simple proof along with some basic conditions in appendix D.</p>

    <h5 id="sec-74" class="text-base font-semibold mt-4">Reduction.</h5>

    <p class="text-gray-300">Given a set of matrices <span class="math">T_{i}</span> which are basis aligned in the sense above (and using the same notation <span class="math">q</span> and <span class="math">q^{\\prime}</span> as defined above), then note that, if <span class="math">X</span> is <span class="math">q</span>-close to <span class="math">V</span>, and</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y-(T_{1}x_{1}+\\cdots+T_{\\ell}x_{\\ell})\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q^{\\prime\\prime},$ (19)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">then</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q^{\\prime}+q^{\\prime\\prime},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">via the triangle inequality. To test the first claim (that <span class="math">X</span> is <span class="math">q</span>-close to <span class="math">V</span>), we may apply the subspace distance check of §3.2.3, while the second (19), can be tested via the sparsity check of §3.2.1; both combined imply that the original vector <span class="math">y</span> is indeed close to <span class="math">V</span>. To write this out explicitly, first set</p>

    <p class="text-gray-300"><span class="math">\\tilde{y}=T_{1}x_{1}+\\cdots+T_{\\ell}x_{\\ell},</span> (20)</p>

    <p class="text-gray-300">for notational convenience. Then, assuming the conjecture of §3.2.3 holds for general codes <span class="math">G\\in\\mathbf{F}^{m\\times\\ell}</span> with distance <span class="math">d</span>, we have</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r1}x_{1}+\\cdots+G_{r\\ell}x_{\\ell}-V^{\\prime}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\quad\\underset{p}{\\Longrightarrow}\\quad\\ X\\text{ is }q\\text{-close to }V^{\\prime},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where <span class="math">p\\leq(q+1)(1-d/m)</span> and <span class="math">r</span> is uniformly sampled from <span class="math">1,\\ldots,m</span>. We also have that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$y_{S}=\\tilde{y}_{S}\\quad\\underset{p^{\\prime}}{\\Longrightarrow}\\quad\\ \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y-\\tilde{y}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q^{\\prime\\prime},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where <span class="math">S\\subseteq\\{1,\\ldots,n\\}</span> is uniformly randomly sampled, while $p^{\\prime}\\leq(1-(q^{\\prime\\prime}+1)/n)^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}$. Combining these two statements, we have that</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$y_{S}=\\tilde{y}_{S}\\ \\ \\text{and}\\ \\ \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r1}x_{1}+\\cdots+G_{r\\ell}x_{\\ell}-V^{\\prime}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\quad\\underset{p+p^{\\prime}}{\\Longrightarrow}\\ \\ \\ \\ \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q^{\\prime}+q^{\\prime\\prime}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Here, as before, we have that <span class="math">S\\subseteq\\{1,\\ldots,n\\}</span> is uniformly randomly sampled, <span class="math">r</span> is uniformly sampled from <span class="math">1,\\ldots,m</span>, and <span class="math">\\tilde{y}</span> is as defined in (20), while <span class="math">p\\leq(q+1)(1-d/m)</span> and $p^{\\prime}\\leq(1-(q^{\\prime\\prime}+1)/n)^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}$. Note, again, that this is just the natural generalization of the reduction presented previously in §4.1.1, except where we care about proximity rather than exact inclusion into the vector space.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-75" class="text-lg font-semibold mt-6">Discussion.</h4>

    <p class="text-gray-300">At a high level, we have just reduced checking that a potentially very large vector <span class="math">y</span> is close to a vector space to checking that (a) two vectors are close to each other (via random sampling) and (b) that a linear combination of much smaller vectors is close to some subspace <span class="math">V^{\\prime}</span>. If this subspace also has a similar recursive substructure; i.e., if there exist matrices <span class="math">T^{\\prime}_{i}</span> and a subspace <span class="math">V^{\\prime\\prime}</span> such that</p>

    <p class="text-gray-300"><span class="math">V^{\\prime}=T^{\\prime}_{1}V^{\\prime\\prime}\\oplus\\cdots\\oplus T^{\\prime}_{s}V^{\\prime\\prime},</span></p>

    <p class="text-gray-300">then, instead of directly checking that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r1}x_{1}+\\cdots+G_{r\\ell}x_{\\ell}-V^{\\prime}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">we may set <span class="math">y^{\\prime}=G_{r1}x_{1}+\\cdots+G_{r\\ell}x_{\\ell}</span> and repeat the above procedure again, except over <span class="math">y^{\\prime}</span> and <span class="math">V^{\\prime}</span>, making the appropriate replacements.</p>

    <p class="text-gray-300">Unfortunately, the general reduction presented prior to this discussion paragraph depends on the unsolved conjecture of §3.2.3 (though special cases have been solved). In what follows, we will use the special case where <span class="math">\\ell=2</span>, shown earlier, to construct a linear-algebraic generalization of the FRI protocol, along with its security proof.</p>

    <h3 id="sec-76" class="text-xl font-semibold mt-8">4.2 The FRI protocol</h3>

    <p class="text-gray-300">In this section we will, using the statements above, present a small generalization of the FRI protocol along with a proof of its security.</p>

    <h4 id="sec-77" class="text-lg font-semibold mt-6">Set up.</h4>

    <p class="text-gray-300">In FRI, we have the following construction: <span class="math">\\ell=2</span> and the matrices <span class="math">T_{1},T_{2}\\in\\mathbf{F}^{n\\times n}</span> are the identity (<span class="math">T_{1}=I</span>) and diagonal, respectively. (We will define <span class="math">T_{2}</span> in what follows.)</p>

    <p class="text-gray-300">In this scenario, the vector space <span class="math">V</span> is the set of evaluations of polynomials of degree <span class="math">\\leq s</span> at some fixed set of points <span class="math">\\{\\alpha_{1},\\ldots,\\alpha_{n}\\}\\subseteq\\mathbf{F}^{n}</span>. (This forms a vector space by the same reasoning as §1.1.) The ‘smaller’ vector space <span class="math">V^{\\prime}</span> is the set of evaluations of polynomials of degree <span class="math">\\leq s</span> with only even-degree terms, over the same set of fixed points. (This is a</p>

    <p class="text-gray-300">vector space, as summing two polynomials with only even-degree terms results in another polynomial with terms of only even degree, as does scaling these polynomials.) Setting</p>

    <p class="text-gray-300">\\[ T_{2}=\\begin{bmatrix}\\alpha_{1}&0&\\ldots&0\\\\ 0&\\alpha_{2}&\\ldots&0\\\\ \\vdots&\\vdots&\\ddots&\\vdots\\\\ 0&0&\\ldots&\\alpha_{n}\\end{bmatrix}, \\]</p>

    <p class="text-gray-300">we may then write</p>

    <p class="text-gray-300"><span class="math">V=T_{1}V^{\\prime}\\oplus T_{2}V^{\\prime}.</span></p>

    <p class="text-gray-300">This decomposition has the following interpretation: we may decompose the vector space of polynomials of degree <span class="math">\\leq s</span> into two parts: the set of polynomials of degree <span class="math">\\leq s</span> with only even-degree terms, and the set of polynomials of degree <span class="math">\\leq s</span> with only odd-degree terms. (The latter, of course, is just the set of polynomials with only even-degree terms, multiplied pointwise by the polynomial <span class="math">f(\\beta)=\\beta</span>.)</p>

    <h4 id="sec-78" class="text-lg font-semibold mt-6">Squared evaluations.</h4>

    <p class="text-gray-300">It is worth noticing that, since <span class="math">\\beta^{2}=(-\\beta)^{2}</span> for any <span class="math">\\beta\\in\\mathbf{F}</span>, in many cases, the set of squared evaluation points, <span class="math">\\{\\alpha_{i}^{2}\\}</span>, is much smaller than the set of all evaluation points <span class="math">\\{\\alpha_{i}\\}</span>. (If the <span class="math">\\{\\alpha_{i}\\}</span> form a subfield of <span class="math">\\mathbf{F}</span>, it is about half, unless <span class="math">\\mathbf{F}</span> is a binary field.) In fact, if the evaluation points are chosen such that <span class="math">\\alpha_{i+n/2}=-\\alpha_{i}</span> for <span class="math">i=1,\\ldots,n/2</span>, then the number of unique evaluation points is halved, and we may assume that <span class="math">V^{\\prime}\\subseteq\\mathbf{F}^{n/2}</span>. In this case, we may write the decomposition with the following matrices:</p>

    <p class="text-gray-300">\\[ T_{1}=\\begin{bmatrix}I\\\\ I\\end{bmatrix},\\quad T_{2}=\\begin{bmatrix}D\\\\ -D\\end{bmatrix}, \\]</p>

    <p class="text-gray-300">where <span class="math">D=\\mathbf{diag}(\\alpha_{1},\\ldots,\\alpha_{n/2})</span> and <span class="math">T_{1},T_{2}\\in\\mathbf{F}^{n\\times(n/2)}</span>, where <span class="math">V^{\\prime}</span> is the set of all evaluations of polynomials (of degree <span class="math">\\leq s</span>) at the points <span class="math">\\{\\alpha_{i}^{2}\\}</span> for <span class="math">i=1,\\ldots,n/2</span>. This gives yet another way of writing</p>

    <p class="text-gray-300"><span class="math">V=T_{1}V^{\\prime}\\oplus T_{2}V^{\\prime}.</span></p>

    <p class="text-gray-300">Note that these matrices are aligned in that, letting the matrix <span class="math">[x_{1}\\;x_{2}]</span> be <span class="math">q</span>-close to <span class="math">V^{\\prime}</span>, then</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}x_{1}+T_{2}x_{2}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq 2q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">so, in the notation above, we have <span class="math">q^{\\prime}=2q</span>.</p>

    <h4 id="sec-79" class="text-lg font-semibold mt-6">Reduction step.</h4>

    <p class="text-gray-300">From here it is easy to (a) read off the algorithm for reducing the queries to a smaller subspace, given the prior discussion, and (b) to read off its probability of error. From the previous discussion in §4.1.2, we know</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r1}x_{1}+G_{r2}x_{2}-V^{\\prime}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\;\\mbox{ and }\\;y_{S}=(T_{1}x_{1}+T_{2}x_{2})_{S}\\quad\\underset{p+p^{\\prime}}{\\Longrightarrow}\\quad\\ \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq 3q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">over uniformly randomly chosen <span class="math">r=1,\\ldots,m</span> and <span class="math">S\\subseteq\\{1,\\ldots,n\\}</span>, where <span class="math">p\\leq(q+1)(1-d/m)</span> and $p^{\\prime}\\leq(1-(q+1)/n)^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math">, and we have used the fact that </span>q^{\\prime}=2q<span class="math">, so </span>q+q^{\\prime}=3q$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">Complete reduction. At a high level, we may view the above check as: we begin by wishing to check that some vector is <span class="math">q</span>-close to a subspace (of whatever dimension) embedded in <span class="math">\\mathbf{F}^{n}</span>. We then reduce this to checking that some other vector is in a subspace of <span class="math">\\mathbf{F}^{n/2}</span>, while incurring some additional error term <span class="math">p+p^{\\prime}</span> (as given above) by doing so. We may continue to perform this procedure, say, <span class="math">k</span> times, until we are left with verifying that some vector, embedded in <span class="math">\\mathbf{F}^{n/2^{k}}</span>, lies in a subspace. (We assume <span class="math">n</span> is divisible by <span class="math">2^{k}</span> in what follows.) If <span class="math">n/2^{k}</span> is small, then every subspace must be similarly ‘small’, and it suffices to simply directly verify that this last vector is part of the subspace directly. If so, this will imply that the original vector (embedded in the ‘large’ vector space <span class="math">\\mathbf{F}^{n}</span>) must be similarly close to the original vector space <span class="math">V</span> with high probability, controlled by the above terms, which is what we desired to check in the first place.</p>

    <p class="text-gray-300">Now, consider the first ‘step’ of the protocol. In order to have that <span class="math">y</span> is <span class="math">3q</span>-close to <span class="math">V</span>, we must have that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r1}x_{1}+G_{r2}x_{2}-V^{\\prime}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\ \\ \\text{and}\\ \\ \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y-(T_{1}x_{1}+T_{2}x_{2})\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">with high probability. If we then set</p>

    <p class="text-gray-300"><span class="math">y^{\\prime}=G_{r1}x_{1}+G_{r2}x_{2},</span></p>

    <p class="text-gray-300">then, to guarantee that <span class="math">y^{\\prime}</span> is <span class="math">q</span>-close to <span class="math">V^{\\prime}=T_{1}^{\\prime}V^{\\prime\\prime}\\oplus T_{2}^{\\prime}V^{\\prime\\prime}</span> (i.e., to guarantee the left hand side of the first step) we must have that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">G_{r1}x_{1}^{\\prime}+G_{r2}x_{2}^{\\prime}-V^{\\prime\\prime}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q/3\\ \\ \\text{and}\\ \\ \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y^{\\prime}-(T_{1}^{\\prime}x_{1}^{\\prime}+T_{2}^{\\prime}x_{2}^{\\prime})\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq q/3,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">with high probability. Repeating this process, we see that at the <span class="math">k</span>th round, we must have that both queries must ensure that the respective vectors are no more than <span class="math">q/3^{k}</span>-far from the vector space. By some basic accounting, using the implications of §1.4, it is not hard to show that the probability of error is at most</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\sum_{i=1}^{k}\\left(\\frac{q}{3^{i}}+1\\right)\\left(1-\\frac{d}{m}\\right)+\\sum_{i=1}^{k}\\left(1-\\frac{q/3^{i}+1}{n/2^{i}}\\right)^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> is the size of the randomly drawn subset for round </span>i$. The first term in this sum is easily bounded from above since</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\sum_{i=1}^{k}\\left(\\frac{q}{3^{i}}+1\\right)\\leq\\frac{3}{2}q+k.</span></p>

    <p class="text-gray-300">The second term is slightly trickier, but, since <span class="math">\\log(1-\\lambda)\\leq-\\lambda</span> for <span class="math">0\\leq\\lambda&lt;1</span>, then for any nonnegative <span class="math">\\gamma</span>,</p>

    <p class="text-gray-300"><span class="math">(1-\\lambda)^{\\gamma}\\leq\\exp(-\\gamma\\lambda),</span></p>

    <p class="text-gray-300">which means that the right-hand-term, inside of the sum, is bounded above by</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left(1-\\frac{q/3^{i}+1}{n/2^{i}}\\right)^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\leq\\exp\\left(-\\frac{q}{n}\\left(\\frac{2}{3}\\right)^{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\right).$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{i}\\right</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\eta(3/2)^{i}<span class="math">, for some </span>\\eta\\geq 0$ to be established, simplifies the expression slightly to</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\sum_{i=1}^{k}\\left(1-\\frac{q/3^{i}+1}{n/2^{i}}\\right)^{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\leq k\\exp\\left(-\\eta\\frac{q}{n}\\right),$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">which means the probability of error is bounded above by</p>

    <p class="text-gray-300"><span class="math">\\left(\\frac{3}{2}q+k\\right)\\left(1-\\frac{d}{m}\\right)+k\\exp\\left(-\\eta\\frac{q}{n}\\right).</span></p>

    <h4 id="sec-80" class="text-lg font-semibold mt-6">Concrete instance.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The parameters presented above are relatively abstract. If we set <span class="math">G</span> to be the matrix whose rows are all of the pairs <span class="math">(1,\\alpha)</span> for each <span class="math">\\alpha\\in\\mathbf{F}</span> (as in the original FRI protocol <em>[x1]</em>) we know that $1-d/m=1/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, from §1.3.2. We may similarly choose </span>q<span class="math"> to be, say, </span>q=n/8<span class="math">. If the field size is relatively large compared to </span>n<span class="math"> (we will say that </span>n=2^{32}<span class="math"> for this instance and the field size is, say </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\approx 2^{128}<span class="math">) then, to have an error of around </span>2^{-80}<span class="math"> after </span>k=28$ rounds, we must have</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">k\\exp\\left(-\\frac{\\eta}{8}\\right)\\leq 2^{-80},</span></p>

    <p class="text-gray-300">which means that we may set <span class="math">\\eta=470</span>. This gives a total error probability of slightly above <span class="math">2^{-80}</span>.</p>

    <h4 id="sec-81" class="text-lg font-semibold mt-6">Query complexity.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In this model, the number of queries that must be made to either the vector <span class="math">y</span> or its constituents <span class="math">x_{1}</span> or <span class="math">x_{2}</span> at round <span class="math">i</span> is given by $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\eta(3/2)^{i}$. This means that the total number of queries is</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\sum_{i=1}^{k}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S_{i}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=2\\eta\\left(\\left(\\frac{3}{2}\\right)^{k+1}-1\\right).$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">With the provided parameters, the total number of queries is then <span class="math">\\sim 2^{26}</span>, which is much smaller than naïvely querying all <span class="math">n-q\\approx 2^{32}</span> possible entries to verify the claim. Indeed, it is not hard to show that, if <span class="math">n/2^{k}</span> remains constant, along with all of the other parameters, then, as <span class="math">n</span> grows, this difference becomes arbitrarily large. (This is easy to see: the query complexity grows as <span class="math">(3/2)^{k\\log(k)}</span> whereas the message size grows as <span class="math">2^{k}</span>, which marks an exponential(!) gap between the two as <span class="math">k</span>, or, equivalently, <span class="math">n</span>, becomes large. Some care has to be taken as <span class="math">n</span> becomes roughly the size of the field, but we usually assume $n\\ll</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$.)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-82" class="text-lg font-semibold mt-6">Optimizing constants.</h4>

    <p class="text-gray-300">Note that, in the above construction, we did not make use of the freedom that many parameters, such as the distances between different elements, could be arbitrarily chosen. Indeed, we did not optimize for any constants at all, and, using the bounds presented here, the proof system would be unlikely to be useful for practical applications. We suspect that using the framework presented here, but with much more careful accounting, it is possible to achieve similar constants as those derived by directly analyzing the protocols <em>[x1]</em>.</p>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">5 Conclusion</p>

    <p class="text-gray-300">In this paper, we have shown that a number of the basic tools used in succinct proof systems may be recast, almost entirely, in terms of linear algebra and error correcting codes. This continues a long line of tradition in the cryptography space which attempts to separate out and individually consider the components which make up a succinct proof system. For example, it was possible to mostly elide the use of cryptography by pushing most of the cryptographic complexity into the models of §2.1.2. Focusing on just the reductions used here then leads to a clean abstraction which may be considered in its own right. Indeed, an interesting consequence of this line of work is that it suggests natural generalizations of known statements, leading to, say, the conjecture provided in §3.2.3. In a certain sense, this work also suggests the following high level idea: one may, in many cases, replace a very specific notion of randomness (such as, say, random linear combinations) with the much more structured ‘randomness’ coming from rows of the generator matrix for an error correcting code of large distance. In many ways, the main point of this paper is to show that even this notion of randomness not only preserves most ‘natural’ properties of objects in vector spaces, but indeed serves as a way of verifying these properties.</p>

    <h2 id="sec-83" class="text-2xl font-bold">Acknowledgements</h2>

    <p class="text-gray-300">The authors would like to thank Tarun Chitra and Kobi Gurkan for their comments and suggestions, many of which we have incorporated.</p>

    <h2 id="sec-84" class="text-2xl font-bold">References</h2>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[AHIV17] Scott Ames, Carmit Hazay, Yuval Ishai, and Muthuramakrishnan Venkitasubramaniam. Ligero: Lightweight sublinear arguments without a trusted setup. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pages 2087–2104, Dallas Texas USA, October 2017. ACM.</li>

      <li>[Axl14] Sheldon Axler. Linear Algebra Done Right. Springer, New York, 2014.</li>

      <li>[BBB^{+}18] Benedikt Bünz, Jonathan Bootle, Dan Boneh, Andrew Poelstra, Pieter Wuille, and Greg Maxwell. Bulletproofs: Short proofs for confidential transactions and more. In 2018 IEEE Symposium on Security and Privacy (SP), pages 315–334, 2018.</li>

      <li>[BBHR18] Eli Ben-Sasson, Iddo Bentov, Yinon Horesh, and Michael Riabzev. Fast Reed-Solomon Interactive Oracle Proofs of Proximity. pages 1–17, 2018.</li>

      <li>[BCC^{+}16] Jonathan Bootle, Andrea Cerulli, Pyrros Chaidos, Jens Groth, and Christophe Petit. Efficient zero-knowledge arguments for arithmetic circuits in the discrete log setting. In Marc Fischlin and Jean-Sébastien Coron, editors, Advances in</li>

    </ul>

    <p class="text-gray-300">Cryptology – EUROCRYPT 2016, volume 9666, pages 327–357. Springer Berlin Heidelberg, Berlin, Heidelberg, 2016.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[BCCT13] Nir Bitansky, Ran Canetti, Alessandro Chiesa, and Elan Tromer. Recursive Composition and Bootstrapping for SNARKs and Proof–Carrying Data. In STOC’13: Proceedings of the Forty-Fifth Annual ACM Symposium on Theory of Computing, June 2013.</li>

      <li>[BCI^{+}23] Eli Ben-Sasson, Dan Carmon, Yuval Ishai, Swastik Kopparty, and Shubhangi Saraf. Proximity Gaps for Reed–Solomon Codes. Journal of the ACM, page 3614423, August 2023.</li>

      <li>[BCMS20] Benedikt Bünz, Alessandro Chiesa, Pratyush Mishra, and Nicholas Spooner. Recursive Proof Composition from Accumulation Schemes. In Rafael Pass and Krzysztof Pietrzak, editors, Theory of Cryptography, volume 12551, pages 1–18. Springer International Publishing, Cham, 2020.</li>

      <li>[BCS21] Jonathan Bootle, Alessandro Chiesa, and Katerina Sotiraki. Sumcheck arguments and their applications. In Advances in Cryptology – CRYPTO 2021: 41st Annual International Cryptology Conference, CRYPTO 2021, Virtual Event, August 16–20, 2021, Proceedings, Part I, page 742–773, Berlin, Heidelberg, 2021. Springer-Verlag.</li>

      <li>[BF23] Benedikt Bunz and Ben Fisch. Multilinear Schwartz-Zippel mod N and Lattice-Based Succinct Arguments. 2023.</li>

      <li>[BJ08] Michał Baczyński and Balasubramaniam Jayaram. Fuzzy Implications, volume 231 of Studies in Fuzziness and Soft Computing. Springer Berlin Heidelberg, Berlin, Heidelberg, 2008.</li>

      <li>[BS23] Dan Boneh and Victor Shoup. A Graduate Course in Applied Cryptography. 2023.</li>

      <li>[BSCG^{+}13] Eli Ben-Sasson, Alessandro Chiesa, Daniel Genkin, Eran Tromer, and Madars Virza. Snarks for c: Verifying program executions succinctly and in zero knowledge. In Advances in Cryptology–CRYPTO 2013: 33rd Annual Cryptology Conference, Santa Barbara, CA, USA, August 18-22, 2013. Proceedings, Part II, pages 90–108. Springer, 2013.</li>

      <li>[DP23] Benjamin E. Diamond and Jim Posen. Proximity testing with logarithmic randomness. Cryptology ePrint Archive, Paper 2023/630, 2023. https://eprint.iacr.org/2023/630.</li>

      <li>[KL21] Jonathan Katz and Yehuda Lindell. Introduction to Modern Cryptography. Chapman & Hall/CRC Cryptography and Network Security Series. CRC Press Taylor & Francis Group, Boca Raton London New York, third edition edition, 2021.</li>

    </ul>

    <p class="text-gray-300">[KP22] Abhiram Kothapalli and Bryan Parno. Algebraic Reductions of Knowledge. 2022.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[KST22] Abhiram Kothapalli, Srinath Setty, and Ioanna Tzialla. Nova: Recursive Zero-Knowledge Arguments from Folding Schemes. In Yevgeniy Dodis and Thomas Shrimpton, editors, Advances in Cryptology – CRYPTO 2022, volume 13510, pages 359–388. Springer Nature Switzerland, Cham, 2022.</li>

      <li>[KZG10] Aniket Kate, Gregory Zaverucha, and Ian Goldberg. Constant-size commitments to polynomials and their applications. In Advances in Cryptology–ASIACRYPT 2010: 16th International Conference on the Theory and Application of Cryptology and Information Security, Singapore, December 5-9, 2010. Proceedings 16, pages 177–194. Springer, 2010.</li>

      <li>[Nit20] Anca Nitulescu. Zk-SNARKs: A Gentle Introduction. 2020.</li>

      <li>[RZ21] Carla Ràfols and Arantxa Zapico. An Algebraic Framework for Universal and Updatable SNARKs. In Tal Malkin and Chris Peikert, editors, Advances in Cryptology – CRYPTO 2021, volume 12825, pages 774–804. Springer International Publishing, Cham, 2021.</li>

      <li>[Tha22] Justin Thaler. Proofs, Arguments, and Zero-Knowledge. Foundations and Trends® in Privacy and Security, 4(2–4):117–660, 2022.</li>

      <li>[Woo22] Mary Wootters. CS250/EE387 Lecture Notes. Stanford University, 2022. Online.</li>

      <li>[Woo23] Mary Wootters. Personal communication, 2023.</li>

    </ul>

    <p class="text-gray-300">A Chaining probabilistic implications</p>

    <p class="text-gray-300">Given two statements <span class="math">P_{r}\\underset{p}{\\Longrightarrow}Q_{r^{\\prime}}</span> and <span class="math">Q_{r^{\\prime}}\\underset{p^{\\prime}}{\\Longrightarrow}T_{r^{\\prime\\prime}}</span>, we will show that</p>

    <p class="text-gray-300"><span class="math">P_{r}\\underset{p+p^{\\prime}}{\\Longrightarrow}T_{r^{\\prime\\prime}}.</span></p>

    <p class="text-gray-300">where the randomness is, as before, over <span class="math">r</span>, <span class="math">r^{\\prime}</span>, and <span class="math">r^{\\prime\\prime}</span>, with no assumptions on their dependence. Using the definitions for the given notation, this claim may be written as, knowing</p>

    <p class="text-gray-300"><span class="math">\\Pr(P_{r}\\wedge\\neg Q_{r^{\\prime}})\\leq p,\\quad\\text{and}\\quad\\Pr(Q_{r^{\\prime}}\\wedge\\neg T_{r^{\\prime\\prime}})\\leq p^{\\prime}</span></p>

    <p class="text-gray-300">implies that</p>

    <p class="text-gray-300"><span class="math">\\Pr(P_{r}\\wedge\\neg T_{r^{\\prime\\prime}})\\leq p+p^{\\prime}.</span></p>

    <p class="text-gray-300">Proof. To see this, we may use basic logical implications. Note that, for any <span class="math">r</span>, <span class="math">r^{\\prime}</span>, and <span class="math">r^{\\prime\\prime}</span>, the following implications are true</p>

    <p class="text-gray-300"><span class="math">P_{r}\\wedge\\neg T_{r^{\\prime\\prime}}\\quad\\text{implies}\\quad(P_{r}\\wedge\\neg Q_{r^{\\prime}})\\vee(Q_{r^{\\prime}}\\wedge\\neg T_{r^{\\prime\\prime}}).</span></p>

    <p class="text-gray-300">This follows from the fact that <span class="math">P_{r}</span> and <span class="math">\\neg T_{r^{\\prime\\prime}}</span>. Since <span class="math">Q_{r^{\\prime}}</span> is either true or false, and both of the previous statements are true, then, necessarily, one of the statements in the disjunction must be true. Since this is true for any <span class="math">r</span>, <span class="math">r^{\\prime}</span>, and <span class="math">r^{\\prime\\prime}</span>, we then have that</p>

    <p class="text-gray-300"><span class="math">\\Pr(P_{r}\\wedge\\neg T_{r^{\\prime\\prime}})\\leq\\Pr((P_{r}\\wedge\\neg Q_{r^{\\prime}})\\vee(Q_{r^{\\prime}}\\wedge\\neg T_{r^{\\prime\\prime}}))\\leq\\Pr(P_{r}\\wedge\\neg Q_{r^{\\prime}})+\\Pr(Q_{r^{\\prime}}\\wedge\\neg T_{r^{\\prime\\prime}}),</span></p>

    <p class="text-gray-300">where the last inequality follows from the union bound. Using the definitions in the statement of the claim above gives the result.</p>

    <h2 id="sec-85" class="text-2xl font-bold">Appendix B Kronecker product of codes</h2>

    <h3 id="sec-86" class="text-xl font-semibold mt-8">B.1 Kronecker product</h3>

    <p class="text-gray-300">Given two matrices <span class="math">G\\in\\mathbf{F}^{m\\times n}</span> and <span class="math">G^{\\prime}\\in\\mathbf{F}^{m^{\\prime}\\times k}</span>, we define their Kronecker product, written <span class="math">G^{\\prime}\\otimes G\\in\\mathbf{F}^{mm^{\\prime}\\times nk}</span>, as</p>

    <p class="text-gray-300">\\[ G^{\\prime}\\otimes G=\\begin{bmatrix}G^{\\prime}_{11}G&\\ldots&G^{\\prime}_{1k}G\\\\ \\vdots&\\ddots&\\vdots\\\\ G^{\\prime}_{m^{\\prime}1}G&\\ldots&G^{\\prime}_{m^{\\prime}k}G\\end{bmatrix}. \\]</p>

    <p class="text-gray-300">This definition may be interpreted in a number of ways. The simplest, perhaps, is to note that, for a list of vectors <span class="math">x_{1},\\ldots,x_{k}\\in\\mathbf{F}^{n}</span>, not all zero, then</p>

    <p class="text-gray-300">\\[ (G^{\\prime}\\otimes G)\\begin{bmatrix}x_{1}\\\\ \\vdots\\\\ x_{k}\\end{bmatrix}=\\mathbf{vec}(G^{\\prime}X^{T}G^{T}), \\] (21)</p>

    <p class="text-gray-300">where</p>

    <p class="text-gray-300"><span class="math">\\mathbf{vec}(G^{\\prime}X^{T}G^{T})</span> is a vector corresponding to stacking the columns of <span class="math">G^{\\prime}X^{T}G^{T}</span> into one large vector, while</p>

    <p class="text-gray-300"><span class="math">X=\\begin{bmatrix}x_{1}&amp;x_{2}&amp;\\ldots&amp;x_{k}\\end{bmatrix},</span></p>

    <p class="text-gray-300">is a matrix with columns <span class="math">x_{i}</span> for <span class="math">i=1,\\ldots,k</span>. If the matrices <span class="math">G</span> and <span class="math">G^{\\prime}</span> define codes, we may view the right hand side of (21) as performing the following series of steps. First, we encode the columns of <span class="math">X</span> using <span class="math">G</span>, giving a big matrix <span class="math">GX</span>. Then, we take the transpose of this matrix and encode its columns, using <span class="math">G^{\\prime}</span>, i.e., <span class="math">G^{\\prime}(GX)^{T}=G^{\\prime}X^{T}G</span>. (Equivalently, this is just encoding the rows of <span class="math">GX</span> to get a new matrix <span class="math">(GX)G^{\\prime T}</span> and taking the transpose of the result.) Finally, we stack the columns of the resulting matrix <span class="math">G^{\\prime}X^{T}G^{T}</span> into one large vector, which gives the final result.</p>

    <h5 id="sec-87" class="text-base font-semibold mt-4">Tensor interpretation.</h5>

    <p class="text-gray-300">In a certain sense, this may be viewed as the natural ‘structure preserving map’ which takes operations on tensors and maps them to corresponding operations on vectors. Specifically, given a matrix <span class="math">X\\in\\mathbf{F}^{n\\times k}</span>, which may be viewed as a rank 2 tensor, there is an invertible linear map <span class="math">X\\to\\mathbf{vec}(X)</span> which gives a ‘vector’ element <span class="math">\\mathbf{F}^{nk}</span>. (There are many such maps; here, we take a simple one, which is just stacking the columns of <span class="math">X</span> into one large vector.) Applying linear operations to the matrix <span class="math">X</span> then corresponds to a linear operation on <span class="math">\\mathbf{vec}(X)</span>. In the case that these operations are ‘axis’ aligned, i.e., that these linear operations only apply column-wise or row-wise on <span class="math">X</span>, then the Kronecker product of the operators (in the tensor space, which deals with the matrix <span class="math">X</span>) is the corresponding linear operator in the vector representation (which deals with the vector <span class="math">\\mathbf{vec}(X)</span>). It is not hard to see that this generalizes to arbitrary-rank tensors, though we do not show this here.</p>

    <h3 id="sec-88" class="text-xl font-semibold mt-8">B.2 Kronecker product distance</h3>

    <p class="text-gray-300">Given two codes <span class="math">G\\in\\mathbf{F}^{m\\times n}</span> and <span class="math">G^{\\prime}\\in\\mathbf{F}^{m^{\\prime}\\times k}</span> with distance <span class="math">d</span> and <span class="math">d^{\\prime}</span>, respectively, we will show that the distance of the Kronecker product <span class="math">G^{\\prime}\\otimes G\\in\\mathbf{F}^{mm^{\\prime}\\times nk}</span> is at least <span class="math">dd^{\\prime}</span>. To see this, we will use a simple counting argument. Consider a list of vectors <span class="math">x_{1},\\ldots,x_{k}\\in\\mathbf{F}^{n}</span>, not all zero, then</p>

    <p class="text-gray-300">\\[ (G^{\\prime}\\otimes G)\\begin{bmatrix}x_{1}\\\\ \\vdots\\\\ x_{k}\\end{bmatrix}=\\mathbf{vec}(G^{\\prime}X^{T}G^{T}), \\] (22)</p>

    <p class="text-gray-300">where <span class="math">\\mathbf{vec}(G^{\\prime}X^{T}G^{T})</span> is a vector corresponding to stacking the columns of <span class="math">G^{\\prime}X^{T}G^{T}</span>, while</p>

    <p class="text-gray-300"><span class="math">X=\\begin{bmatrix}x_{1}&amp;x_{2}&amp;\\ldots&amp;x_{k}\\end{bmatrix},</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">is a matrix with columns <span class="math">x_{i}</span> for <span class="math">i=1,\\ldots,k</span>. Since $\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{vec}(G^{\\prime}X^{T}G^{T})\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}<span class="math"> is just the number of nonzero entries of the matrix </span>G^{\\prime}X^{T}G^{T}$, we will only consider the latter object. Defining</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\tilde{X}=X^{T}G^{T}</span>, we can then rewrite <span class="math">G^{\\prime}X^{T}G^{T}</span> as</p>

    <p class="text-gray-300">\\[ G^{\\prime}X^{T}G^{T}=G^{\\prime}\\tilde{X}=G^{\\prime}\\begin{bmatrix}(Gx_{1})^{T}\\\\ \\vdots\\\\ (Gx_{k})^{T}\\end{bmatrix}. \\]</p>

    <p class="text-gray-300">Since at least one index <span class="math">i</span> has <span class="math">x_{i}\\neq 0</span>, then, at least <span class="math">d</span> columns of <span class="math">\\tilde{X}</span> will be nonzero, since the distance of <span class="math">G</span> is <span class="math">d</span> by assumption. This implies that each of the (at least) <span class="math">d</span> nonzero columns of <span class="math">\\tilde{X}</span> will be encoded into a vector of weight at least <span class="math">d^{\\prime}</span>, since <span class="math">G^{\\prime}</span> has distance <span class="math">d^{\\prime}</span>, which means that we have at least <span class="math">dd^{\\prime}</span> nonzero entries in <span class="math">G^{\\prime}X^{T}G^{T}</span>; or, in other words, that the distance of <span class="math">G^{\\prime}\\otimes G</span> is at least <span class="math">dd^{\\prime}</span>.</p>

    <h3 id="sec-89" class="text-xl font-semibold mt-8">B.3 Tightness</h3>

    <p class="text-gray-300">The derivation presented in the reduced matrix zero check §3.1.3 is strictly weaker than the one above as it does not use the linearity properties of the encoding. We show that the bound on the probability of failure derived there, which is</p>

    <p class="text-gray-300"><span class="math">1-\\frac{d}{m}+1-\\frac{d^{\\prime}}{m^{\\prime}},</span></p>

    <p class="text-gray-300">(using the same <span class="math">m</span> and <span class="math">m^{\\prime}</span> and <span class="math">d</span>, <span class="math">d^{\\prime}</span> as above) is essentially always worse than the bound derived here, of</p>

    <p class="text-gray-300"><span class="math">1-\\frac{dd^{\\prime}}{mm^{\\prime}}.</span> (23)</p>

    <p class="text-gray-300">To see this, note that</p>

    <p class="text-gray-300"><span class="math">\\left(1-\\frac{d}{m}\\right)\\left(1-\\frac{d^{\\prime}}{m^{\\prime}}\\right)\\geq 0,</span> (24)</p>

    <p class="text-gray-300">which, after rearranging, implies that</p>

    <p class="text-gray-300"><span class="math">1-\\frac{d}{m}+1-\\frac{d^{\\prime}}{m^{\\prime}}\\geq 1-\\frac{dd^{\\prime}}{mm^{\\prime}}.</span></p>

    <p class="text-gray-300">Whenever the quantity in the left hand side of (24) is positive, which always true unless <span class="math">d=m</span> or <span class="math">d=m^{\\prime}</span>, the latter quantity holds strictly. In general, we find that chained implications yield much simpler proofs at the expense of some potential error. (Roughly speaking: chained implications assume that the worst-case errors are disjoint, since the argument used is a union-bound one. This is not true, e.g., in the case of linear codes, from the proof above.) It is of course, not hard to show that (23) is the best we can hope for since, given <span class="math">x\\in\\mathbf{F}^{n}</span> which has <span class="math">Gx</span> with weight <span class="math">d</span> and <span class="math">x^{\\prime}\\in\\mathbf{F}^{k}</span> which has <span class="math">G^{\\prime}x^{\\prime}</span> with weight <span class="math">d^{\\prime}</span>, then <span class="math">x^{\\prime}\\otimes x\\in\\mathbf{F}^{nk}</span> will result in a codeword</p>

    <p class="text-gray-300"><span class="math">(G^{\\prime}\\otimes G)(x^{\\prime}\\otimes x)=(G^{\\prime}x^{\\prime})\\otimes(Gx),</span></p>

    <p class="text-gray-300">with weight <span class="math">dd^{\\prime}</span>. (The equality follows from the definition (22), as does the weight.) It is not hard to show that the matrix <span class="math">X</span> with <span class="math">\\mathbf{vec}(X)=x^{\\prime}\\otimes x</span> is given by</p>

    <p class="text-gray-300"><span class="math">X=xx^{\\prime T},</span></p>

    <p class="text-gray-300">which gives the result.</p>

    <h2 id="sec-90" class="text-2xl font-bold">Appendix C Subspace distance check</h2>

    <p class="text-gray-300">This appendix section contains some notes on the subspace distance check and the associated distance-preserving encoding conjecture. We use the same definitions and notation as §3.2.3 for the remainder of this appendix section. As a reminder, we are attempting to check if some matrix <span class="math">X\\in\\mathbf{F}^{k\\times n}</span> has columns that are <span class="math">q</span>-close to some vector subspace <span class="math">V\\subseteq\\mathbf{F}^{k}</span> whose distance is at least <span class="math">d^{\\prime}</span>, given some code matrix <span class="math">G\\in\\mathbf{F}^{m\\times n}</span> with distance at least <span class="math">d</span>. We assume that <span class="math">q&lt;d^{\\prime}/2</span> and rewrite the check below for convenience:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{n}G_{ri}x_{i}-V\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\quad\\implies\\quad X\\text{ is <span class="math">q</span>-close to <span class="math">V</span>},$ (25)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where the randomness is over <span class="math">r</span> uniformly randomly chosen from <span class="math">1,\\ldots,m</span>, and the error probability <span class="math">p\\leq(q+1)(1-d/m)</span>. This, as before, may be viewed as a generalization of the Ligero distance check <em>[x1]</em> to the case where the randomness is not provided by a uniformly random vector in <span class="math">\\mathbf{F}^{n}</span>, but is instead a uniformly randomly chosen row of a code generator matrix <span class="math">G</span>.</p>

    <h3 id="sec-91" class="text-xl font-semibold mt-8">C.1 Easy case</h3>

    <p class="text-gray-300">We may split the proof of the check presented in the paper into two cases. In the first, we assume that <span class="math">X</span> is less than <span class="math">d^{\\prime}/2</span>-far from the vector space <span class="math">V</span>; that is, there exists a matrix <span class="math">Y\\in\\mathbf{F}^{k\\times n}</span>, with columns in <span class="math">V</span> such that <span class="math">X-Y</span> has less than <span class="math">d^{\\prime}/2</span> nonzero rows. (This is the part of the proof we present below.) In the second case, we assume that <span class="math">X</span> is at least <span class="math">d^{\\prime}/2</span>-far from <span class="math">V</span>. This means that, for any matrix <span class="math">Y</span> whose columns lie in <span class="math">V</span>, the matrix <span class="math">X-Y</span> has at least <span class="math">d^{\\prime}/2</span> nonzero rows. (In a certain sense, that the columns of <span class="math">X</span> are ‘far’ from the vector space <span class="math">V</span>.)</p>

    <h4 id="sec-92" class="text-lg font-semibold mt-6">First case proof.</h4>

    <p class="text-gray-300">This part assumes that <span class="math">X</span> is less than <span class="math">d^{\\prime}/2</span>-far from <span class="math">V</span>. This means that there exists a matrix <span class="math">Y</span> such that its columns <span class="math">y_{i}</span> lie in <span class="math">V</span>, <span class="math">y_{i}\\in V</span>, and <span class="math">X-Y</span> has less than <span class="math">d^{\\prime}/2</span> nonzero rows. First, set</p>

    <p class="text-gray-300"><span class="math">\\bar{y}_{r}=\\sum_{i=1}^{n}G_{ri}y_{i},</span> (26)</p>

    <p class="text-gray-300">where</p>

    <p class="text-gray-300">for each <span class="math">r=1,\\ldots,m</span>. We will show that this is the unique closest vector in the subspace <span class="math">V</span> to the left hand side of the claim (25):</p>

    <p class="text-gray-300"><span class="math">\\bar{x}_{r}=\\sum_{i=1}^{m}G_{ri}x_{i},</span> (27)</p>

    <p class="text-gray-300">where <span class="math">x_{i}</span> is the <span class="math">i</span>th column of <span class="math">X</span>. This is not hard to see: since <span class="math">X-Y</span> has less than <span class="math">d^{\\prime}/2</span> nonzero rows, then any linear combination of the columns of <span class="math">X-Y</span> must have less than <span class="math">d^{\\prime}/2</span> nonzero entries; i.e.,</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{m}G_{ri}(x_{i}-y_{i})\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}<d^{\\prime}/2,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">but the term inside of the norm can be split into</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{m}G_{ri}x_{i}-\\sum_{i=1}^{m}G_{ri}y_{i}\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}<d^{\\prime}/2,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where the second sum can be recognized as <span class="math">\\bar{y}_{r}\\in V</span>. Since the distance of <span class="math">V</span> is at least <span class="math">d^{\\prime}</span>, then this vector is within the unique decoding radius and is therefore the unique vector in <span class="math">V</span> closest to <span class="math">\\bar{x}_{r}</span>; i.e., for any choice of <span class="math">r</span>,</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{m}G_{ri}x_{i}-V\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{m}G_{ri}(x_{i}-y_{i})\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Armed with this fact, if</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{m}G_{ri}x_{i}-V\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">then</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{m}G_{ri}(x_{i}-y_{i})\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{m}G_{ri}x_{i}-V\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">But, from the folded sparsity check above, we have that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{m}G_{ri}(x_{i}-y_{i})\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\quad\\implies\\quad X-Y\\text{ has at most }q\\text{ nonzero rows,}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">with <span class="math">p\\leq(q+1)(1-d/m)</span> when <span class="math">r</span> is uniformly randomly selected from <span class="math">1,\\ldots,m</span>. In other words, that <span class="math">X-Y</span> have at most <span class="math">q</span> nonzero rows, or, alternatively that <span class="math">X</span> is <span class="math">q</span>-close to <span class="math">V</span>, as required.</p>

    <p class="text-gray-300">##</p>

    <h3 id="sec-93" class="text-xl font-semibold mt-8">Strengthening this proof.</h3>

    <p class="text-gray-300">Wootters <em>[x21]</em> proved a slightly stronger version of this case in private communication: instead of assuming that <span class="math">X</span> is less than <span class="math">d^{\\prime}/2</span>-far from <span class="math">V</span>, it suffices to assume that <span class="math">X</span> is less than <span class="math">(d^{\\prime}-q)</span>-far from <span class="math">V</span>, which is at least as good (and often much better) than the original proof, as <span class="math">q&lt;d^{\\prime}/2</span> by assumption. Similar to the previous, we let <span class="math">Y</span> be a matrix whose columns lie in <span class="math">V</span> and <span class="math">X-Y</span> has at most <span class="math">d^{\\prime}-q</span> nonzero rows. The proof is very similar to the above and we reproduce it here for completeness, using the same notation and definitions given above.</p>

    <p class="text-gray-300">Let the left hand side of (25) be satisfied, i.e.,</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{n}G_{ri}x_{i}-V\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">then we will show that the unique vector closest to the linear combination of the columns of <span class="math">X</span> above is <span class="math">\\bar{y}_{r}</span>, as defined in (26). To see this, let <span class="math">y\\in V</span> be any vector in the subspace, then, if <span class="math">y\\neq\\bar{y}_{r}</span>, we have</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\bar{x}_{r}-y\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\geq\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y-\\bar{y}_{r}\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}-\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\bar{x}_{r}-\\bar{y}_{r}\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}>d^{\\prime}-(d^{\\prime}-q)\\geq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where <span class="math">\\bar{x}_{r}</span> is also as defined previously in (27), so no other <span class="math">y\\in V</span> is closer to <span class="math">\\bar{x}_{r}</span> than <span class="math">\\bar{y}_{r}</span>. The first inequality follows from the reverse triangle inequality, while the second follows from the fact that <span class="math">V</span> has distance <span class="math">d^{\\prime}</span>, so $\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y-\\bar{y}_{r}\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq d^{\\prime}<span class="math">, and the fact that </span>X-Y<span class="math"> has less than </span>d^{\\prime}-q<span class="math"> nonzero entries, by assumption on </span>X$. So:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{n}G_{ri}(x_{i}-y_{i})\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{n}G_{ri}x_{i}-V\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">but, from the matrix sparsity check, we know that this implies</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{m}G_{ri}(x_{i}-y_{i})\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\quad\\implies\\quad X-Y\\text{ has at most }q\\text{ nonzero rows,}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">when <span class="math">r</span> is uniformly randomly drawn from <span class="math">1,\\ldots,m</span>, and where <span class="math">p\\leq(q+1)(1-d/m)</span>. In English, this simply says that <span class="math">X</span> is <span class="math">q</span>-close to <span class="math">V</span>, as required.</p>

    <h3 id="sec-94" class="text-xl font-semibold mt-8">C.2 Distance-preserving encoding conjecture</h3>

    <p class="text-gray-300">The remaining case then, is to prove that, if <span class="math">X</span> is at least <span class="math">(d^{\\prime}-q)</span>-far from <span class="math">V</span>, then the probability that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{n}G_{ri}x_{i}-V\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">with respect to a uniformly randomly drawn <span class="math">r</span> from <span class="math">1,\\ldots,m</span>, and where <span class="math">q&lt;d^{\\prime}/2</span> is very low. Indeed, we conjecture that the probability this is true, call it <span class="math">p</span>, satisfies</p>

    <p class="text-gray-300"><span class="math">p\\leq(q+1)\\left(1-\\frac{d}{m}\\right),</span></p>

    <p class="text-gray-300">where <span class="math">d</span> is the distance of the code generated by <span class="math">G\\in\\mathbf{F}^{m\\times n}</span>. We may write this in the notation of §1.4 as</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{n}G_{ri}x_{i}-V\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q\\quad\\implies\\quad X\\text{ is }(d^{\\prime}-q)\\text{-close to }V,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where <span class="math">p\\leq(q+1)(1-d/m)</span>. (Note that this claim is always ‘easier’ than the original claim since <span class="math">d&lt;d^{\\prime}/2</span>.)</p>

    <h4 id="sec-95" class="text-lg font-semibold mt-6">Notes.</h4>

    <p class="text-gray-300">Such a statement is similar in spirit to that of <em>[x1]</em>. In a certain sense, the above statement means that we may replace the uniform randomness of the check presented in <em>[x1]</em> with the much more structured ‘randomness’ coming from picking a uniformly random row of an error correcting code matrix <span class="math">G</span> with reasonable distance. For example, an interesting statement, similar in spirit to those used in the proof of the Hadamard case in <em>[x1]</em>, is the following. Given any nonzero vector <span class="math">y\\in\\mathcal{R}(X)</span>, let <span class="math">V^{\\perp}\\subseteq\\mathcal{R}(X)</span> be the space such that any vector <span class="math">v\\in\\mathcal{R}(X)</span> may be written uniquely as</p>

    <p class="text-gray-300"><span class="math">v=\\alpha y+z,</span></p>

    <p class="text-gray-300">for some <span class="math">z\\in V^{\\perp}</span> and <span class="math">\\alpha\\in\\mathbf{F}</span>. (In other words, <span class="math">V^{\\perp}</span> is the remainder of the basis completion of the matrix containing only the column <span class="math">y</span>; in some cases the subspace <span class="math">V^{\\perp}</span> is called the <em>rejection</em> of the ray given by <span class="math">y</span>.) Then, for a randomly drawn row <span class="math">\\tilde{g}_{r}</span> of <span class="math">G</span>, if</p>

    <p class="text-gray-300"><span class="math">X\\tilde{g}_{r}=\\alpha_{r}y+z_{r},</span></p>

    <p class="text-gray-300">where <span class="math">z_{r}\\in V^{\\perp}</span> and <span class="math">\\alpha_{r}\\in\\mathbf{F}</span>, then the probability that <span class="math">\\alpha_{r}=0</span> is no more than <span class="math">1-d/m</span>. In other words, given any possible ‘direction’ <span class="math">y</span> in the range of <span class="math">X</span>, we know that, with high probability, any structured linear combination of the columns of <span class="math">X</span> always has a component in this direction. Unfortunately, unlike the proof of <em>[x1]</em>, we do not know much about the relationship between <span class="math">z_{r}</span> and <span class="math">\\alpha_{r}</span>, which makes it difficult to conclude something about the probability that a given vector is far from <span class="math">\\mathcal{R}(X)</span>. (In their proof, <span class="math">\\alpha_{r}</span> and <span class="math">z_{r}</span> are known to be independent variables, with respect to the randomness <span class="math">r</span>.) We may view this statement as saying that the structured linear combinations given by a uniformly sampled row, <span class="math">\\tilde{g}_{r}</span>, are, in a sense, ‘good testers’ of the range of <span class="math">X</span>.</p>

    <h2 id="sec-96" class="text-2xl font-bold">Appendix D Basis alignment</h2>

    <p class="text-gray-300">In this appendix we prove that certain matrices <span class="math">T_{i}\\in\\mathbf{F}^{n\\times k}</span> for <span class="math">i=1,\\ldots,\\ell</span>, which share sparsity patterns, satisfy the basis alignment property. That is: if <span class="math">X\\in\\mathbf{F}^{k\\times\\ell}</span> is <span class="math">q</span>-close to <span class="math">V^{\\prime}</span> and <span class="math">x_{i}</span> denotes the <span class="math">i</span>th column of <span class="math">X</span>, then we have that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}x_{1}+\\cdots+T_{\\ell}x_{\\ell}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q^{\\prime},$ (28)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">for some reasonably small <span class="math">q^{\\prime}</span>. The proofs are essentially mechanical, and we encourage readers to work them out before reading this appendix as an exercise in definitions.</p>

    <p class="text-gray-300">Warm up.</p>

    <p class="text-gray-300">The easiest nontrivial case to see is when the <span class="math">T_{i}</span> are diagonal matrices and the vector space <span class="math">V</span> satisfies</p>

    <p class="text-gray-300"><span class="math">V=T_{1}V^{\\prime}\\oplus\\cdots\\oplus T_{\\ell}V^{\\prime}.</span></p>

    <p class="text-gray-300">In this case it is not hard to show that the inequality (28) holds for <span class="math">q^{\\prime}=q</span>. To see this, let <span class="math">X</span> be <span class="math">q</span>-close to <span class="math">V</span>; that is, there exists a matrix <span class="math">Y</span>, with columns in <span class="math">V</span>, such that <span class="math">X-Y</span> has at most <span class="math">q</span> nonzero rows. Let <span class="math">x_{i}</span> denote the <span class="math">i</span>th column of <span class="math">X</span> and <span class="math">\\xi_{i}</span> denote the <span class="math">i</span>th column of <span class="math">X-Y</span>, then</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}x_{1}+\\cdots+T_{\\ell}x_{\\ell}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}\\xi_{1}+\\cdots+T_{\\ell}\\xi_{\\ell}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">This holds since, by definition, the columns of <span class="math">Y</span> are vectors in <span class="math">V</span> and we can write <span class="math">\\xi_{i}=x_{i}-y_{i}</span> where <span class="math">y_{i}</span> is the <span class="math">i</span>th column of <span class="math">Y</span>. Now, since <span class="math">0\\in V</span>, then the right hand side of the previous expression can be bounded from above by</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}\\xi_{1}+\\cdots+T_{\\ell}\\xi_{\\ell}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}\\xi_{1}+\\cdots+T_{\\ell}\\xi_{\\ell}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Finally, since the <span class="math">T_{i}</span> are diagonal, then <span class="math">T_{i}\\xi_{i}</span> only scales the entries of <span class="math">\\xi_{i}</span> (potentially by zeroing them out) so:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}\\xi_{1}+\\cdots+T_{\\ell}\\xi_{\\ell}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\{j\\mid\\text{there exists some <span class="math">i</span> such that <span class="math">(\\xi_{i})_{j}\\neq 0</span>}\\}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">(We recommend parsing the right hand side of this expression carefully.) In other words, the left hand side is bounded above by the number of rows of <span class="math">X-Y</span> which are nonzero. Since we assumed that <span class="math">X</span> was <span class="math">q</span>-close to <span class="math">V</span>, that means that <span class="math">X-Y</span> has at most <span class="math">q</span> nonzero rows, so we have:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}\\xi_{1}+\\cdots+T_{\\ell}\\xi_{\\ell}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">as we wanted to prove.</p>

    <h4 id="sec-97" class="text-lg font-semibold mt-6">Basic example.</h4>

    <p class="text-gray-300">One useful example of this is when <span class="math">\\alpha_{1},\\ldots,\\alpha_{n}\\in\\mathbf{F}</span> denotes some evaluation points, while <span class="math">V^{\\prime}</span> denotes the vector space of evaluations of polynomials (at the <span class="math">\\alpha_{i}</span>) whose terms are all of even degree <span class="math">\\leq 2k</span>, and <span class="math">V</span> is the vector space of evaluations of polynomials of degree <span class="math">\\leq 2k+1</span>. In other words, we set</p>

    <p class="text-gray-300">\\[ V^{\\prime}=\\mathcal{R}\\left(\\begin{bmatrix}1&\\alpha_{1}^{2}&\\alpha_{1}^{4}&\\ldots&\\alpha_{1}^{2k}\\\\ \\vdots&\\vdots&\\vdots&\\ddots&\\vdots\\\\ 1&\\alpha_{n}^{2}&\\alpha_{n}^{4}&\\ldots&\\alpha_{n}^{2k}\\end{bmatrix}\\right), \\]</p>

    <p class="text-gray-300">while</p>

    <p class="text-gray-300">\\[ V=\\mathcal{R}\\left(\\begin{bmatrix}1&\\alpha_{1}&\\alpha_{1}^{2}&\\ldots&\\alpha_{1}^{2k}\\\\ \\vdots&\\vdots&\\vdots&\\ddots&\\vdots\\\\ 1&\\alpha_{n}&\\alpha_{n}^{2}&\\ldots&\\alpha_{n}^{2k}\\end{bmatrix}\\right). \\]</p>

    <p class="text-gray-300">(Note that the matrix whose range is <span class="math">V^{\\prime}</span> only has the even powers, while <span class="math">V</span> has all powers.) We can then write</p>

    <p class="text-gray-300"><span class="math">V=V^{\\prime}\\oplus DV^{\\prime},</span></p>

    <p class="text-gray-300">where</p>

    <p class="text-gray-300">\\[ D=\\begin{bmatrix}\\alpha_{1}&0&\\ldots&0\\\\ 0&\\alpha_{2}&\\ldots&0\\\\ \\vdots&\\vdots&\\ddots&\\vdots\\\\ 0&0&\\ldots&\\alpha_{n}\\end{bmatrix}. \\]</p>

    <p class="text-gray-300">It is not hard to see since, first <span class="math">DV^{\\prime}</span> corresponds to the set of evaluations of polynomials whose terms are of odd degree <span class="math">\\leq 2k+1</span>. Since we may write</p>

    <p class="text-gray-300"><span class="math">V=IV^{\\prime}\\oplus DV^{\\prime},</span></p>

    <p class="text-gray-300">where <span class="math">I</span> is the identity matrix, then both <span class="math">I</span> and <span class="math">D</span> are diagonal and we have that these matrices are basis aligned such that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x+Dy-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq q,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">if <span class="math">[x\\ y]</span>, the <span class="math">n\\times 2</span> matrix with columns <span class="math">x</span> and <span class="math">y</span>, is <span class="math">q</span>-close to <span class="math">V^{\\prime}</span>.</p>

    <h4 id="sec-98" class="text-lg font-semibold mt-6">General case.</h4>

    <p class="text-gray-300">The general case is written as follows. Let <span class="math">T_{i}\\in\\mathbf{F}^{n\\times k}</span> be matrices such that each column has at most <span class="math">c</span> nonzero entries and all of the <span class="math">T_{i}</span> share the same sparsity pattern. Then, if <span class="math">X\\in\\mathbf{F}^{k\\times\\ell}</span> is <span class="math">q</span>-close to <span class="math">V^{\\prime}</span>, we have that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}x_{1}+\\cdots+T_{\\ell}x_{\\ell}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq cq.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The proof of this statement is very similar to the previous. Since <span class="math">X</span> is <span class="math">q</span>-close to <span class="math">V^{\\prime}</span>, then there exists some <span class="math">Y\\in\\mathbf{F}^{k\\times\\ell}</span>, whose columns lie in <span class="math">V^{\\prime}</span>, such that <span class="math">X-Y</span> has at most <span class="math">q</span> nonzero rows. Let <span class="math">\\xi_{i}</span> denote the <span class="math">i</span>th column of <span class="math">X-Y</span>, then, by the same reasoning as the previous,</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}x_{1}+\\cdots+T_{\\ell}x_{\\ell}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}\\xi_{1}+\\cdots+T_{\\ell}\\xi_{\\ell}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Again, we note that since <span class="math">0\\in V</span>, we have that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}\\xi_{1}+\\cdots+T_{\\ell}\\xi_{\\ell}-V\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}\\xi_{1}+\\cdots+T_{\\ell}\\xi_{\\ell}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">which means we only have to bound the latter quantity. We can bound this quantity since, letting <span class="math">\\tau_{ij}</span> be the <span class="math">j</span>th column of <span class="math">T_{i}</span>,</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">T_{1}\\xi_{1}+\\cdots+T_{\\ell}\\xi_{\\ell}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}=\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{\\ell}\\sum_{j=1}^{k}\\tau_{ij}(\\xi_{i})_{j}\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq\\sum_{j=1}^{k}\\left\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\sum_{i=1}^{\\ell}\\tau_{ij}(\\xi_{i})_{j}\\right\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">_{0}\\leq cq.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The equality follows by definitions of the <span class="math">\\tau_{ij}</span> and <span class="math">\\xi_{i}</span>. The first inequality follows from the triangle inequality. Finally, the last inequality follows since, by assumption, for fixed <span class="math">j</span>, the vectors <span class="math">\\tau_{ij}</span> share the same sparsity pattern for each <span class="math">i</span>. Since this is true and each column of <span class="math">T_{i}</span> (and therefore each vector <span class="math">\\tau_{ij}</span>) has at most <span class="math">c</span> nonzero entries, then the result follows from the fact that there are at most <span class="math">q</span> indices <span class="math">j</span> such that at least one index <span class="math">i</span> has <span class="math">(\\xi_{i})_{j}\\neq 0</span>, by definition of the <span class="math">\\xi_{i}</span>.</p>

    <p class="text-gray-300">##</p>`;
---

<BaseLayout title="Succinct Proofs and Linear Algebra (2023/1478)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2023 &middot; eprint 2023/1478
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
