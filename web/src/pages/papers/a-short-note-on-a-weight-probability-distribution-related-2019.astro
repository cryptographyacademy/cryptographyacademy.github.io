---
import BaseLayout from '../../layouts/BaseLayout.astro';
import PaperDisclaimer from '../../components/PaperDisclaimer.astro';
import PaperHistory from '../../components/PaperHistory.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2019/750';
const CRAWLER = 'marker';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'A Short Note on a Weight Probability Distribution Related to SPNs';
const AUTHORS_HTML = 'Sondre R&oslash;njom';

const CONTENT = `    <section id="abstract" class="mb-10">
      <h2 class="text-2xl font-bold">Abstract</h2>
      <p class="text-gray-300">We report on a simple technique that supports some recent developments on AES by Grassi and Rechberger and Bao, Guo and List. We construct a weight transition probability matrix related to AES that characterises fixed configurations of active bytes in differences of ciphertexts when plaintext differences are fixed to some (possibly other) configuration of active bytes. The construction is very simple and requires only a little bit of linear algebra. The derived probabilities are essentially identical to recent results on 5- and 6-rounds AES derived through more sophisticated means, indicating that it might be worth a further investigation.</p>
      <p class="text-gray-300"><strong>Keywords:</strong> Block Ciphers &middot; SPNs &middot; AES &middot; Probability</p>
    </section>

    <p class="text-gray-300">We consider transition probability distributions related to active bytes in differences of ciphertexts and plaintexts in AES. The objective is to determine whether the probability distribution for configurations of active bytes in ciphertext di&crarr;erences vary depending on the distribution of configurations of active bytes in the plaintexts. We show how to utilize symmetries in the AES Mix-Column matrix to construct ecient (small) transition matrices for <em>r</em> rounds of AES where <em>r</em> is any number of rounds. The results and techniques are very simple and require only a little bit of linear algebra <sup>1</sup>. We are unable to prove how exact these transition probability matrices emulate the true AES distributions, however, we can confirm that our method obtains results that seem to be identical to recent results reported with more sophisticated analysis, presented in several recent papers on 5- and 6-rounds distinguishers for AES (e.g. [1], [3], [5] and [4]). In particular, probabilities derived from the weight transition probability matrix matches the results recently presented by Bao, Guo and List in [1] on 5- and 6-rounds AES and Grassi and Rechberger in [4] on 5-rounds AES. This may support the view that, as long as the s-box is suciently generic (e.g. not linear), the s-box layer has little e&crarr;ect on this kind of structural analysis. It is thus tempting to conjecture that the presented weight transition probability matrix emulates the true AES-distributions.</p>

    <p class="text-gray-300"><sup>1</sup> Simple C/C++ code for experimenting with and verifying our results can be found at https://github.com/sondrer/SPNTransitionProbability</p>

    <section id="sec-2" class="mb-10">
      <h2 class="text-2xl font-bold">2 Weight Probability Distributions in AES</h2>

    <p class="text-gray-300">One round of AES [2] consists of four steps. First, a non-linear permutation SubBytes is applied to each individual byte of the state. Then each row is shifted cyclically via ShiftRows, followed by applying a fixed linear transformation  <span class="math">M \\in \\mathbb{F}_{28}^{4\\times4}</span>  to each column (MixColumns). In the end a fixed round-key is added to the whole state (AddKey).</p>

    <p class="text-gray-300">We view states in AES in terms of the SuperBox representation, i.e. as a collection of vectors  <span class="math">S=(s_0,s_1,s_2,s_3)\\in (\\mathbb{F}_{2^8}^4)^4</span>  corresponding to the columns of the AES state. To each state we associate a vector  <span class="math">\\nu(S)\\in (\\mathbb{F}_2^4)^4</span>  which indicates the active bytes in each column  <span class="math">s_i</span>  of the state. Let  <span class="math">\\rho(s_i)\\in \\mathbb{F}_2^4</span>  denote this vector which is 1 in position i if the i'th byte of the vector  <span class="math">s_i</span>  is non-zero such that the vector defined as</p>

    <p class="text-gray-300"><span class="math">$\\nu(S) = (\\rho(s_0), \\rho(s_1), \\rho(s_2), \\rho(s_3)) \\tag{1}</span>$</p>

    <p class="text-gray-300">is the configuration of active bytes for a state S. We also use a vector</p>

    <p class="text-gray-300"><span class="math">$\\wp(S) = (\\text{wt}(s_0), \\text{wt}(s_1), \\text{wt}(s_2), \\text{wt}(s_3))</span>$
(2)</p>

    <p class="text-gray-300">to identify the weights of the columns of a state. To simplify the notation we threat vectors also as integers, i.e.  <span class="math">c \\in \\mathbb{F}_2^4</span>  is also treated as an integer  <span class="math">\\sum_{i=0}^3 c_i \\cdot 2^i</span> ,  <span class="math">u \\in (\\mathbb{F}_2^4)^4</span>  as the integer  <span class="math">\\sum_{i=0}^3 (\\sum_{j=0}^3 c_j \\cdot 2^j) 16^j</span> , and  <span class="math">a \\in \\mathbb{Z}_5^4</span>  as an integer  <span class="math">\\sum_{i=0}^3 a_i \\cdot 5^i</span> . The indices of the matrices will then correspond naturally to configurations of active bytes and weights and are then easily derived from each other.</p>

    <p class="text-gray-300">The MixColumns matrix  <span class="math">M \\in \\mathbb{F}_{2^8}^{4 \\times 4}</span>  is applied to each column of the state. We are interested in the transition probabilities for active bytes through M, i.e. for two binary vectors  <span class="math">u, v \\in \\mathbb{F}_2^4</span>  let</p>

    <p class="text-gray-300"><span class="math">$T_{\\mathcal{M}}(u, v) = \\Pr(\\rho(x \\cdot \\mathcal{M}) = v \\mid \\rho(x) = u)</span>$
(3)</p>

    <p class="text-gray-300">denote the probability that a vector  <span class="math">x \\cdot M</span>  is non-zero in byte positions indicated by the 1's in v when x is non-zero in positions indicated by the 1's in u. The matrix M in AES is derived from a linear [8,4,5] MDS code over  <span class="math">\\mathbb{F}_{2^8}</span> . We have computed the transition probabilities exhaustively&sup2;, but there exist explicit formulas for the weight distribution of MDS codes that simplifies this for the general case. There are in total 16 different configurations of active bytes at the input and 16 configurations of active output bytes, so  <span class="math">T_M \\in \\mathbb{R}^{16 \\times 16}</span> . Let  <span class="math">u, v \\in \\mathbb{F}_2^4</span>  and let Z denote the  <span class="math">16 \\times 16</span>  matrix where Z(u, v) counts the number of elements  <span class="math">x \\in \\mathbb{F}_{2^8}^4</span>  with active bytes in positions indicated by u and where  <span class="math">y = x \\cdot M</span>  have active byes indicated by v. The state transition for a column through the MixColumns layer is then as follows.</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;2</sup> Table for Z can be found at https://github.com/sondrer/SPNTransitionProbability</p>

    <p class="text-gray-300"><strong>Definition 1.</strong> Let  <span class="math">T_M \\in \\mathbb{R}^{16 \\times 16}</span>  denote the transition probability matrix for active bytes over the MixColumn M with entries</p>

    <p class="text-gray-300"><span class="math">$T_{M}(u,v) = \\frac{Z(u,v)}{(2^{8}-1)^{wt(u)}}</span>$
(4)</p>

    <p class="text-gray-300">for indicators  <span class="math">u, v \\in \\mathbb{F}_2^4</span>  for configurations of active bytes.</p>

    <p class="text-gray-300">Since the MC-layer applies the matrix M to each column individually, it is now straight-forward to construct a transition probability matrix for the whole MC-layer. The MC-layer maps an input state  <span class="math">x = (x_0, x_1, x_2, x_3) \\in (\\mathbb{F}_{28}^4)^4</span>  to an output state  <span class="math">y = (y_0, y_1, y_2, y_3)</span>  where</p>

    <p class="text-gray-300"><span class="math">$y_i = MC(x)_i \\tag{5}</span>$</p>

    <p class="text-gray-300"><span class="math">$=x_i \\cdot \\mathbf{M}</span>$
(6)</p>

    <p class="text-gray-300">thus we have the following trivial extension.</p>

    <p class="text-gray-300"><strong>Definition 2.</strong> For vectors  <span class="math">u, v \\in (\\mathbb{F}_2^4)^4</span>  indicating the active bytes in each column, let a matrix  <span class="math">T_{\\mathrm{MC}} \\in \\mathbb{R}^{2^{16} \\times 2^{16}}</span>  with entries</p>

    <p class="text-gray-300"><span class="math">$T_{MC}(u,v) = \\Pr(\\nu(MC(x)) = v \\mid \\nu(x) = u)</span>$
(7)</p>

    <p class="text-gray-300"><span class="math">$= \\prod_{i=0}^{3} \\Pr(\\rho(MC(x)_i) = v_i \\mid \\rho(x_i) = u_i)</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\prod_{i=0}^{3} T_M(u_i, v_i)</span>$
(8)</p>

    <p class="text-gray-300"><span class="math">$= \\prod_{i=0}^{3} T_{\\mathcal{M}}(u_i, v_i)</span>$
(9)</p>

    <p class="text-gray-300">denote the transition probability matrix for the full MixColumns layer in AES and where u, v are also treated as indices  <span class="math">0 \\le u, v &lt; 2^{16}</span>  and  <span class="math">u_i, v_i</span>  as indices  <span class="math">0 \\le u_i, v_i &lt; 16.</span></p>

    <p class="text-gray-300">Similarly, let  <span class="math">T_{SR}</span>  denote the  <span class="math">2^{16} \\times 2^{16}</span>  matrix with indices</p>

    <p class="text-gray-300"><span class="math">$T_{SR}(u,v) = \\Pr(\\nu(SR(y)) = v \\mid \\nu(x) = u)</span>$</p>

    <p class="text-gray-300"><span class="math">$\\tag{10}</span>$</p>

    <p class="text-gray-300">where the vectors  <span class="math">u, v \\in (\\mathbb{F}_2^4)^4</span>  are treated as indices in the range  <span class="math">0 \\le u, v, &lt; 2^{16}</span> . The T<sub>SR</sub> matrix is a permutation matrix and has a single 1 in each row and column, hence there is no uncertainty associated with it. Notice also that the SubBytes layer corresponds to the identity map with regards to active bytes transition probabilities, thus this layer is disregarded (determining the real effect, if any, of the s-box layer is the main remaining open problem). We use the SuperBox representation, which means that we remove the first SR-layer in order to work with columns and may or may not remove the final linear layer. Then we define the following r-round transition matrices for active bytes.</p>

    <p class="text-gray-300"><strong>Definition 3.</strong> Let  <span class="math">T_{MC \\circ SR} = T_{SR} \\cdot T_{MC}</span> . Then define the r-round transition probability matrix for active bytes as</p>

    <p class="text-gray-300"><span class="math">$T_{f^r} = T_{MC} \\cdot T_{MC \\circ SR}^{r-1}. \\tag{11}</span>$</p>

    <p class="text-gray-300">If the aim is solely to distinguish AES reduced to r rounds, then since the adversary may remove the first SR layer and last MC  <span class="math">\\circ</span>  SR-layer, the adversary can work with  <span class="math">T_{f^{r-1}}</span> . If the aim is to construct an r-round distinguisher in the hope to extend it to a (r+t)-round key-recovery, the adversary may consider only removing the first SR-layer and thus work with the  <span class="math">T_{f^r}</span> -matrix. The  <span class="math">2^{16} \\times 2^{16}</span>  matrices are quite large, but in the next section we show how to compress them down to  <span class="math">625 \\times 625</span>  weight transition probability matrices.</p>

      <h3 id="sec-2.2" class="text-xl font-semibold mt-8">2.2 The Weight Transition Probability</h3>

    <p class="text-gray-300">In this section we will construct a compressed weight transition probability that only depends on the Hamming weight of columns. The difference will be that we now only consider the number of active bytes in each column and do no longer have control over the exact active bytes. Thus, while the transition probability distributions derived from the previous matrices can be thought of as distributions for the exact configurations of active bytes in the state columns, we now only consider distributions on the number of active bytes (Hamming weight) of the state columns.</p>

    <p class="text-gray-300">The MixColumns matrix M is symmetric with respect to weights in the sense that</p>

    <p class="text-gray-300"><span class="math">$T_{\\mathcal{M}}(u,v) = T_{\\mathcal{M}}(u&#x27;,v&#x27;) \\tag{12}</span>$</p>

    <p class="text-gray-300">for any choice of  <span class="math">u&#x27;, v&#x27; \\in \\mathbb{F}_2^4</span>  with  <span class="math">\\operatorname{wt}(u) = \\operatorname{wt}(u&#x27;)</span>  and  <span class="math">\\operatorname{wt}(v) = \\operatorname{wt}(v&#x27;)</span> . The weight transition probabilities through the M-matrix therefore depend only on the number, and not on the particular configuration, of active bytes. So we can construct a compressed weight transition probability matrix  <span class="math">C_M \\in \\mathbb{R}^{5 \\times 5}</span>  for the matrix M that satisfy</p>

    <p class="text-gray-300"><span class="math">$C_{\\mathcal{M}}(a,b) = \\Pr(\\operatorname{wt}(\\mathcal{M}\\mathcal{C}(x)) = b \\mid \\operatorname{wt}(x) = a)</span>$
(13)</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{\\substack{v \\in \\mathbb{F}_2^4 \\\\ \\text{wt}(v) = b}} T_{\\text{M}}(u, v) \\tag{14}</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\binom{4}{b} \\operatorname{T}_{\\mathcal{M}}(u&#x27;, v&#x27;) \\tag{15}</span>$</p>

    <p class="text-gray-300">for weights a,b and where v,u',v' are any fixed vectors with  <span class="math">\\operatorname{wt}(v)=\\operatorname{wt}(v&#x27;)=b</span>  and  <span class="math">\\operatorname{wt}(u&#x27;)=a</span> . This probability follows since there are  <span class="math">\\binom{4}{\\operatorname{wt}(b)}</span>  possible byte configurations for a vector  <span class="math">b\\in\\mathbb{F}_q^4</span>  of weight  <span class="math">\\operatorname{wt}(b)</span>  at the output and for each of those the probability is  <span class="math">\\operatorname{T}_{\\mathrm{M}}(a,b)</span> . We can now construct a 625 &times; 625 weight transition probability matrix  <span class="math">\\operatorname{C}_{\\mathrm{MC}}</span>  with entries</p>

    <p class="text-gray-300"><span class="math">$C_{MC}(u, v) = \\prod_{k=0}^{3} C_{M}(u_{k}, v_{k})</span>$
(16)</p>

    <p class="text-gray-300">which is the probability for a state S with column weights  <span class="math">\\wp(S) = (u_0, u_1, u_2, u_3)</span>  to map to a state with column weights  <span class="math">\\wp(\\text{MC}(S)) = (v_0, v_1, v_2, v_3)</span>  through the MixColumn layer.</p>

    <p class="text-gray-300">We may construct a weight transition matrix  <span class="math">C_{SR}</span>  for the ShiftRows layer in a similar fashion. For column weight indicators  <span class="math">\\wp(S)=u</span>  and  <span class="math">\\wp(SR(S))=v</span>  the entries of this matrix are given by</p>

    <p class="text-gray-300"><span class="math">$C_{SR}(u,v) = \\frac{1}{\\prod_{j=0}^{3} {4 \\choose u_j}} \\sum_{\\substack{a,b \\in (\\mathbb{F}_2^4)^4 \\\\ \\text{wt}(a_i) = u_i \\\\ \\text{wt}(b_i) = v_i}} T_{SR}(a,b).</span>$
(17)</p>

    <p class="text-gray-300">The probability follows as the sum sums over all possible active byte configurations in the output while the first fraction averages over the number of possible byte configurations in the input. We can now construct weight transition probability matrices for r rounds of AES.</p>

    <p class="text-gray-300"><strong>Definition 4.</strong> Let  <span class="math">C_{MC \\circ SR} = C_{SR} \\cdot C_{MC}</span> . Then let</p>

    <p class="text-gray-300"><span class="math">$C_r = C_{MC} \\cdot C_{MC \\circ SR}^{r-1}</span>$</p>

    <p class="text-gray-300">denote the weight transition probability matrix for r rounds of AES.</p>

    </section>

    <section id="sec-3" class="mb-10">
      <h2 class="text-2xl font-bold">3 Some Results</h2>

    <p class="text-gray-300">If  <span class="math">a \\in \\mathbb{R}^{625}</span>  denotes a weight probability distribution for the plaintext difference, then  <span class="math">b = a \\cdot C_{r-1}</span>  is the weight distribution on the ciphertext differences after r rounds, when the last linear layer is omitted (thus we focus on reduced round distinguishers). The uniform distribution is given by a vector  <span class="math">q \\in \\mathbb{R}^{625}</span>  of values</p>

    <p class="text-gray-300"><span class="math">$q_v = 2^{-128} \\prod_{i=0}^{3} {4 \\choose v_i} (2^8 - 1)^{v_i}</span>$</p>

    <p class="text-gray-300">which is the probability that the output difference has weight pattern  <span class="math">(v_0, v_1, v_2, v_3)</span>  where  <span class="math">v = \\sum_{i=0}^3 v_i \\cdot 5^i</span>  regardless of the input. Now the goal is to determine vectors  <span class="math">a, e \\in \\mathbb{R}^{624}</span>  and investigate the sum</p>

    <p class="text-gray-300"><span class="math">$\\sum_{k=0}^{624} (q_k - b_k)e_k. \\tag{18}</span>$</p>

    <p class="text-gray-300">The scaling vector  <span class="math">e_k</span>  is just an enforced weighting on the ciphertext distribution which the adversary can impose as he would like. If  <span class="math">e_v</span>  is zero, then ciphertext differences with a weight arrangement according to v is ignored completely. For instance, if we only consider events in which the three last columns are zero, then we have to ignore roughly  <span class="math">2^{-96}</span>  ciphertexts until we receive a pair of ciphertexts with our preferred property. Thus, there is a penalty in terms of data-complexity</p>

    <p class="text-gray-300">if we fixate on events that seldom happen, unless the cipher itself has a very unlikely probability distribution.</p>

    <p class="text-gray-300">The matrices  <span class="math">C_{MC}</span> ,  <span class="math">C_{SR}</span>  and  <span class="math">C_{r-1}</span>  are easy to work with and thus we will now use  <span class="math">C_{r-1}</span>  to compute the probabilities corresponding to the same event as recently investigated in [1] and [4].</p>

      <h3 id="sec-3.1" class="text-xl font-semibold mt-8">3.1 Aligning With Recent Results on AES</h3>

    <p class="text-gray-300">To begin we have to define an input distribution  <span class="math">a=(a_0,a_1,\\ldots,a_{624})</span> . For instance, if we assume that the input differences are non-zero and random in only the first column (remember that we are omitting the first SR-layer), we can let the 5 first indices of a correspond to</p>

    <p class="text-gray-300"><span class="math">$a_i = \\binom{4}{i} \\cdot \\frac{(2^8 - 1)^i}{(2^{32} - 1)}</span>$</p>

    <p class="text-gray-300">where  <span class="math">a_i</span>  for  <span class="math">0 \\le i &lt; 5</span>  is the probability that we hit a difference with weight i in the first column given that the plaintext difference is known to be non-zero only in the first column. The corresponding output distribution then becomes  <span class="math">b = a \\cdot C_{r-1}</span> . If we want to compute the probability that the output is non-zero in at least one column, we may sum over the probabilities that contributes to this case in the event of AES</p>

    <p class="text-gray-300"><span class="math">$p_{AES} = \\sum_{\\substack{v = (v_0, v_1, v_2, v_3) \\\\ \\text{at least one } v_i \\text{ zero}}} b_v</span>$</p>

    <p class="text-gray-300">and compare this against the random case given by</p>

    <p class="text-gray-300"><span class="math">$p_{rand} = 2^{-128} \\cdot \\sum_{\\substack{v = (v_0, v_1, v_2, v_3) \\\\ \\text{at least one } v_i \\text{ zero}}} \\prod_{k=0}^{3} {4 \\choose v_k} (2^8 - 1)^{v_k}.</span>$</p>

    <p class="text-gray-300">For instance, if we assume the above input probability distribution a (i.e. input differences are non-zero in the first column only) and the corresponding output distribution  <span class="math">p_{AES}</span>  for r=5 and r=6 rounds, we get the results of Table 1. In particular, [4] arrives at  <span class="math">2^{-30} + 2^{-50.980}</span>  for the event that a ciphertext difference is zero in at least one column when the plaintext difference is active in the first column, which is identical to the result obtained via the weight transition probability matrix.</p>

    <p class="text-gray-300">In the case that the plaintext difference has exactly one active byte in the first column, i.e. the input distribution a has probability 1 in  <span class="math">a_1</span> , the method based on weight transition probabilities returns a probability  <span class="math">2^{-30} + 2^{-51.983}</span>  while [1] arrives at  <span class="math">2^{-30} + 2^{-51.985}</span> .</p>

    <p class="text-gray-300">For 6 rounds the probability in [1] for the same type of event is estimated to be  <span class="math">2^{-30} + 2^{73.995}</span> , which is also identical to the probability derived using the weight transition probability matrix. We have added the probability for 7 rounds into the table for completeness.</p>

    <p class="text-gray-300">Table 1: Comparison between results obtained in literature vs our results obtained using the weight transition probability (WTP) method of AES probabilities, with collision in any ciphertext column as the plaintext event (PE) and with plaintext differences restricted to either one active column or one active byte as the ciphertext event (CE).</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Rounds</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">PE</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">CE</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Probability in literature</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">WTP</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Ref.</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Active Byte</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Zero-column</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">2^{-30} + 2^{-51.985}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">2^{-30} + 2^{-51.983}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">[1]</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Active Column</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Zero-column</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">2^{-30} + 2^{-50.980}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">2^{-30} + 2^{-50.980}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">[4]</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Active Column</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Zero-column</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">2^{-30} + 2^{-73.995}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">2^{-30} + 2^{-73.995}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">[1]</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Active Column</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Zero-column</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">2^{-30} + 2^{-126.891}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">However, there might be better choices of input and output distributions that can be used to optimize this further. For instance, in the same setting as above and for 7 rounds, we get</p>

    <p class="text-gray-300"><span class="math">$p_{AES-7R} = 2^{-30} + 2^{-126.891}.</span>$</p>

    <p class="text-gray-300">If we instead ask what the probability of getting at least one zero-byte, we get</p>

    <p class="text-gray-300"><span class="math">$p_{AES-7R} = 2^{-4} + 2^{-126.036}</span>$
.</p>

    <p class="text-gray-300">Note that the weight transition probability matrix verifies the well-known impossible difference probability too (i.e. you get probability zero for the event of less than 5 active columns in total when evaluated for  <span class="math">C_3</span> ).</p>

    <p class="text-gray-300">These results motivates a conjecture.</p>

    <p class="text-gray-300">Conjecture 1. The weight transition probability matrix defined in Definition 4 emulates the true weight probabilities distributions in AES.</p>

      <h3 id="sec-3.2" class="text-xl font-semibold mt-8">3.2 Weight Distributions Biased in Opposite Directions</h3>

    <p class="text-gray-300">Assume that we fix an output event, e.g. that at least one column in the difference is zero which happens with probability roughly  <span class="math">2^{-30}</span>  at random. The second type of events we could look for is the case when there exist two different input distributions, e.g.  <span class="math">a^1, a^2 \\in R^{625}</span>  with  <span class="math">a^1_i = 1</span>  and  <span class="math">a^2_j = 1</span>  for  <span class="math">i \\neq j</span> , such that the two output probabilities for the same event,</p>

    <p class="text-gray-300"><span class="math">$p_1 = \\sum_{v = (v_0, v_1, v_2, v_3) \\mid \\text{ at least one } v_j \\text{ zero}} b_v^1</span>$</p>

    <p class="text-gray-300">and</p>

    <p class="text-gray-300"><span class="math">$p_2 = \\sum_{v = (v_0, v_1, v_2, v_3) \\mid \\text{ at least one } v_j \\text{ zero}} b_v^2,</span>$</p>

    <p class="text-gray-300">move in opposite direction from random. For instance, assume</p>

    <p class="text-gray-300"><span class="math">$p_1 = p_{rand} - \\epsilon_1 \\tag{19}</span>$</p>

    <p class="text-gray-300">and</p>

    <p class="text-gray-300"><span class="math">$p_2 = p_{rand} + \\epsilon_j \\tag{20}</span>$</p>

    <p class="text-gray-300">thus maximizing the distance between the two same-event probabilities  <span class="math">p_1</span>  and  <span class="math">p_2</span>  instead of comparing single AES-probabilities with random. For instance, for 5-rounds we can pick two different input conditions for the weight in the first column,  <span class="math">u_1 = (3, 0, 0, 0)</span>  and  <span class="math">u_2 = (2, 0, 0, 0)</span>  such that</p>

    <p class="text-gray-300"><span class="math">$p_1 = 2^{-30} - 2^{-50.358}</span>$</p>

    <p class="text-gray-300">becomes the probability for collision in any column after 5 rounds when there are exactly 3 active bytes in the input difference and</p>

    <p class="text-gray-300"><span class="math">$p_2 = 2^{-30} + 2^{-50.390}</span>$</p>

    <p class="text-gray-300">for a collision when there are exactly 2 active bytes, such that the difference</p>

    <p class="text-gray-300"><span class="math">$p_2 - p_1 = 2^{-49.373}</span>$</p>

    <p class="text-gray-300">is larger than if we compared a single event against random.</p>

    </section>

    <section id="sec-4" class="mb-10">
      <h2 class="text-2xl font-bold">4 Possible Further Research</h2>

    <p class="text-gray-300">There might be several interesting directions for further research, but we mention just a few.</p>

      <h3 id="sec-4.1" class="text-xl font-semibold mt-8">4.1 Linear optimization</h3>

    <p class="text-gray-300">To formally find the optimal distribution (choice of input and output events) that minimizes distinguishing complexity, one can employ a data- and computational complexity weighted linear optimization (linear programming).</p>

      <h3 id="sec-4.2" class="text-xl font-semibold mt-8">4.2 Markov chains and stochastic matrices</h3>

    <p class="text-gray-300">Markov chains, stochastic matrices etc. is a very well-studied area. What can be said about these state transition matrices by employing known theory to them?</p>

      <h3 id="sec-4.3" class="text-xl font-semibold mt-8">4.3 Rate of convergence</h3>

    <p class="text-gray-300">For  <span class="math">I,J\\subset\\{0,1,2,3\\}</span> , let  <span class="math">p_{I,J}^r</span>  denote the probability that the ciphertext difference is zero in columns indicated by J given that the plaintext difference is active in exactly the columns indicated by I after r rounds. The motivation in this paper has been to study how probabilities  <span class="math">p_{I,J}^r</span>  for ciphertext events J vary depending on the choice of input events I. Let  <span class="math">s_{I,J}=s_J</span>  denote the uniform probability that ciphertext differences are zero in the columns indicated by J. Then if we look at the rounded values of  <span class="math">\\log_2(\\frac{\\max(p_{I,J}^r,s_J)}{(p_{I,J}^r-s_J)^2})</span>  for increasing r, we observe that the values become independent of the choice of input distributions (determined by I) not until r=10 rounds of AES.</p>

      <h3 id="sec-4.4" class="text-xl font-semibold mt-8">4.4 The e&crarr;ect of the s-box</h3>

    <p class="text-gray-300">The s-box layer acts as a probability 1 identity map in the transition probability matrix. However, the s-box maps di&crarr;erences in certain ways that might at least in theory have some e&crarr;ect on the probability distribution. It is not clear how large, if any, this e&crarr;ect is for a generic s-box.</p>

      <h3 id="sec-4.5" class="text-xl font-semibold mt-8">4.5 Testing ciphers</h3>

    <p class="text-gray-300">This tool can be employed on a range of other similar ciphers which, may be an interesting study in itself, and as a simple and ecient tool to search for optimal new designs.</p>

    <p class="text-gray-300">We have presented a weight transition probability related to SPNs that can be used to derive probabilities for collision events in AES that matches new results recently published in [1] and [4].</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Bao, Z., Guo, J., List, E.: Extended expectation cryptanalysis on round-reduced aes. Cryptology ePrint Archive, Report 2019/622 (2019), https://eprint.iacr.org/2019/622</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Daemen, J., Rijmen, V.: The design of rijndael: Aes the advanced encryption standard. In: Springer (2002)</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Grassi, L.: Mixture di&crarr;erential cryptanalysis: a new approach to distinguishers and attacks on round-reduced aes. IACR Transactions on Symmetric Cryptology 2018(2), 133&ndash;160 (Jun 2018)</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Grassi, L., Rechberger, C.: Rigorous analysis of truncated di&crarr;erentials for 5-round aes. Cryptology ePrint Archive, Report 2018/182 (2018), https://eprint.iacr.org/2018/182</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Grassi, L., Rechberger, C., R&oslash;njom, S.: A new structural-di&crarr;erential property of 5-round AES. In: Advances in Cryptology - EUROCRYPT 2017 - 36th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Paris, France, April 30 - May 4, 2017, Proceedings, Part II. pp. 289&ndash;317 (2017)</li>
    </ol></li>
    </ul>

    </section>
`;
---

<BaseLayout title="A Short Note on a Weight Probability Distribution Related to... (2019/750)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2019 &middot; eprint 2019/750
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <PaperDisclaimer eprintUrl={EPRINT_URL} />
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <nav id="toc" class="mb-10 p-6 rounded-lg" style="background: rgba(255,255,255,0.03); border: 1px solid rgba(255,255,255,0.06);">
      <h2 class="text-lg font-bold mb-4">Table of Contents</h2>
      <ol class="space-y-1 text-sm text-gray-300
        list-decimal list-inside">
        <li><a href="#sec-1" class="hover:text-white">Introduction</a></li>
        <li>
          <a href="#sec-2" class="hover:text-white">Weight Probability Distributions in AES</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-2.1" class="hover:text-white">A 2^&#123;16&#125; \times 2^&#123;16&#125; Transition Probability Matrix for Active Bytes</a></li>
            <li><a href="#sec-2.2" class="hover:text-white">The Weight Transition Probability</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-3" class="hover:text-white">Some Results</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-3.1" class="hover:text-white">Aligning With Recent Results on AES</a></li>
            <li><a href="#sec-3.2" class="hover:text-white">Weight Distributions Biased in Opposite Directions</a></li>
          </ol>
        </li>
        <li>
          <a href="#sec-4" class="hover:text-white">Possible Further Research</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li><a href="#sec-4.1" class="hover:text-white">Linear optimization</a></li>
            <li><a href="#sec-4.2" class="hover:text-white">Markov chains and stochastic matrices</a></li>
            <li><a href="#sec-4.3" class="hover:text-white">Rate of convergence</a></li>
            <li><a href="#sec-4.4" class="hover:text-white">The e&crarr;ect of the s-box</a></li>
            <li><a href="#sec-4.5" class="hover:text-white">Testing ciphers</a></li>
          </ol>
        </li>
        <li><a href="#sec-5" class="hover:text-white">Conclusion</a></li>
      </ol>
      <p class="text-xs text-gray-500 mt-4 mb-1 font-semibold">
        Additional
      </p>
      <ul class="space-y-1 text-sm text-gray-400
        list-disc list-inside">
        <li><a href="#references" class="hover:text-white">References</a></li>
      </ul>
    </nav>


    <Fragment set:html={CONTENT} />

    <PaperHistory slug="a-short-note-on-a-weight-probability-distribution-related-2019" />
  </article>
</BaseLayout>
