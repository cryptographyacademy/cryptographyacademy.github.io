---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2025/620';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs';
const AUTHORS_HTML = 'Alhad Daftardar, Jianqiao Mo, Joey Ah-kiow, Benedikt Bünz, Ramesh Karri, Siddharth Garg, Brandon Reagen';

const CONTENT = `    <p class="text-gray-300">Alhad Daftardar</p>

    <p class="text-gray-300">New York University</p>

    <p class="text-gray-300">Tandon School of Engineering</p>

    <p class="text-gray-300">Brooklyn, NY, USA</p>

    <p class="text-gray-300">ajd9396@nyu.edu</p>

    <p class="text-gray-300">Benedikt Bünz</p>

    <p class="text-gray-300">New York University</p>

    <p class="text-gray-300">Courant Institute</p>

    <p class="text-gray-300">New York, NY, USA</p>

    <p class="text-gray-300">bb@nyu.edu</p>

    <p class="text-gray-300">Jianqiao Mo</p>

    <p class="text-gray-300">New York University</p>

    <p class="text-gray-300">Tandon School of Engineering</p>

    <p class="text-gray-300">Brooklyn, NY, USA</p>

    <p class="text-gray-300">jm8782@nyu.edu</p>

    <p class="text-gray-300">Ramesh Karri</p>

    <p class="text-gray-300">New York University</p>

    <p class="text-gray-300">Tandon School of Engineering</p>

    <p class="text-gray-300">Brooklyn, NY, USA</p>

    <p class="text-gray-300">rkarri@nyu.edu</p>

    <p class="text-gray-300">Joey Ah-kiow</p>

    <p class="text-gray-300">New York University</p>

    <p class="text-gray-300">Tandon School of Engineering</p>

    <p class="text-gray-300">Brooklyn, NY, USA</p>

    <p class="text-gray-300">ja4844@nyu.edu</p>

    <p class="text-gray-300">Siddharth Garg</p>

    <p class="text-gray-300">New York University</p>

    <p class="text-gray-300">Tandon School of Engineering</p>

    <p class="text-gray-300">Brooklyn, NY, USA</p>

    <p class="text-gray-300">sg175@nyu.edu</p>

    <p class="text-gray-300">Brandon Reagen</p>

    <p class="text-gray-300">New York University</p>

    <p class="text-gray-300">Tandon School of Engineering</p>

    <p class="text-gray-300">Brooklyn, NY, USA</p>

    <p class="text-gray-300">bjr5@nyu.edu</p>

    <p class="text-gray-300">Zero-Knowledge Proofs (ZKPs) are a rapidly growing technique for privacy-preserving and verifiable computation. ZKPs enable one party (a prover:  <span class="math">\\mathcal{P}</span> ) to prove to another (a verifier:  <span class="math">\\mathcal{V}</span> ) that a statement is true or correct without revealing any additional information. This powerful capability has led to ZKPs being applied and proposed for application in blockchain technologies, verifiable machine learning, and electronic voting. However, ZKPs have yet to see widespread, ubiquitous adoption due to the exceptionally high computational complexity of the proving process. Naturally, there has been recent work to accelerate ZKP primitives and protocols using GPUs and ASICs. However, the protocols considered so far face one of two challenges: they require a trusted setup for each new application or generate large proofs with high verification costs, limiting their applicability in scenarios with numerous verifiers or strict verification time constraints. HyperPlonk is a state-of-the-art ZKP protocol that supports both one-time, universal setup and small proof sizes/verification costs expected by publicly verifiable, consensus-based systems (e.g., blockchain). While HyperPlonk's setup and verifier properties are highly desirable, the proving phase is costly. A HyperPlonk prover must compute on large bitwidths (e.g., 255-381b) and polynomials (e.g., of degree  <span class="math">2^{24}</span> ), employs computationally (e.g., MSM) and bandwidth (e.g., SumCheck) intensive kernels, and the complete protocol comprises many steps, each</p>

    <p class="text-gray-300">Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.</p>

    <p class="text-gray-300">ISCA '25, June 21-25, 2025, Tokyo, Japan</p>

    <p class="text-gray-300">© 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.</p>

    <p class="text-gray-300">ACM ISBN 979-8-4007-1261-6/2025/06</p>

    <p class="text-gray-300">https://doi.org/10.1145/3695053.3731021</p>

    <p class="text-gray-300">constituting distinct kernels. We present an accelerator, zkSpeed, to address these challenges and effectively accelerate HyperPlonk. zkSpeed provides hardware support for all major primitives (e.g., SumCheck and Multi-Scalar Multiplications (MSMs)) and judiciously schedules each protocol phase onto the allocated hardware. We leverage high-level synthesis to thoroughly explore and optimize the hardware design tradeoffs of each unit. These are then input into a full-chip simulator for large-scale design space exploration to optimize all aspects of the architecture in unison. Our Pareto analysis demonstrates that with a  <span class="math">366\\mathrm{mm}^2</span>  chip and 2 TB/s of off-chip bandwidth, zkSpeed is able to accelerate the entire proof generation by  <span class="math">801\\times</span>  (geomean) over a CPU baseline.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Computer systems organization  <span class="math">\\rightarrow</span>  Special purpose systems;</li>

      <li>Security and privacy  <span class="math">\\rightarrow</span>  Cryptography.</li>

    </ul>

    <p class="text-gray-300">Zero-Knowledge Proofs, Cryptography, Hardware Acceleration</p>

    <p class="text-gray-300">Alhad Daftardar, Jianqiao Mo, Joey Ah-kiow, Benedikt Bunz, Ramesh Karri, Siddharth Garg, and Brandon Reagen. 2025. Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs. In Proceedings of the 52nd Annual International Symposium on Computer Architecture (ISCA '25), June 21-25, 2025, Tokyo, Japan. ACM, New York, NY, USA, 16 pages. https://doi.org/10.1145/3695053.3731021</p>

    <p class="text-gray-300">Zero-Knowledge Proofs (ZKPs) are a privacy-preserving computation technique that enable one party (a prover  <span class="math">\\mathcal{P}</span> ) to prove to another (a verifier  <span class="math">\\mathcal{V}</span> ) that a computation (possibly with secret inputs) was performed correctly. The proof itself reveals no information about the (secret) inputs nor the function, and it can be</p>

    <p class="text-gray-300">verified much faster than the compute time of the original computation. Proof systems can be characterized by several important criteria, including: prover time, verifier time, proof size, protocol setup, and cryptographic assumptions required for the proof to be secure. Each deployment of ZKPs can result in a different set of criteria requirements. For example, private transactions <em>(7)</em> require one proof per transaction be posted on a blockchain and distributed to all blockchain nodes, thus prioritizing small proof size.</p>

    <p class="text-gray-300">Recent years have seen significant advances and heterogeneity in proof systems <em>(4; 11; 22; 25; 59; 69)</em>. Each optimizes for a distinct set of criteria constraints, and we note that in all systems, prover time is vital to optimize for, as faster provers enable new applications and proving is much slower than verification <em>(1; 11)</em>. To understand the ZKP space, consider Groth16 <em>(25)</em> and Orion <em>(69)</em>, two ZKPs with distinct characteristics that have also recently been accelerated <em>(14; 57; 73)</em>. Groth16 produces very short proofs (192 bytes) and enables millisecond verification latency, independent of proved computation size. However, it relies on a strong cryptographic assumption: a circuit-specific trusted setup where a trusted party generates keys using secret randomness. If this randomness is not properly discarded or the party is malicious, the system’s security is compromised, allowing false statements to be proven. Hence, ZCash <em>(7)</em> and other applications have moved away from circuit-specific trusted-setup protocols <em>(50)</em>. On the other hand, Orion does not require a trusted setup or rely on computationally expensive elliptic curve cryptography, enabling a faster prover—but at the cost of large (8 MB) proofs. To put this in perspective, Orion’s proofs are roughly <span class="math">4\\times</span> larger than the maximum block size observed in Ethereum cryptocurrency <em>(45)</em>. Thus, a private transaction with an Orion proof would not fit into a single Ethereum block.</p>

    <p class="text-gray-300">HyperPlonk <em>(11)</em> is a recent system gaining attention for the ZKP criteria it optimizes for, which are desirable in many applications. It has small proofs (typically 5 KB), low verification complexity, and supports universal trusted setup <em>(26)</em>, which runs once for all time and then can be reused by new applications. A major contribution of HyperPlonk is its elimination of the Number Theoretic Transform (NTT), which is used by Groth16 and others, and instead its usage of SumCheck, which lowers the asymptotic runtime from <span class="math">O(n\\log(n))</span> (NTT) to <span class="math">O(n)</span> (SumCheck). Here, <span class="math">n</span> represents the size of the underlying computation, and thus a lower runtime implies larger problems may be applied to ZKPs; something we cannot do today due to long runtime. Despite the improved runtime, the proving phase of HyperPlonk is still slow, running on the order of minutes to hours for some applications.</p>

    <p class="text-gray-300">Accelerating HyperPlonk presents many challenges. First, the prover works over large, computationally demanding data structures, with polynomials on the order of <span class="math">2^{17}</span>-<span class="math">2^{24}</span> and bitwidths ranging from 255-381. Second, the protocol constitutes four major phases of computation, each comprising a different set of kernel functions. Kernels range from small and large compute-bound problems (e.g., SHA3 and MSM, respectively) to memory-bound (e.g., SumCheck). Compared to more traditionally accelerated kernels (e.g., NTT, matrix multiply, and convolution), HyperPlonk’s kernels are also less well understood. Finally, there is heterogeneity in data access patterns across kernels and phases. Some data structures are reused, either between or within kernels, and some are not. This raises questions on how to connect and schedule kernels as well as how to stage data to overlap communication with computation. The complexity of HyperPlonk requires careful design, new hardware optimizations, and thorough design space exploration to identify architectures with area-performance tradeoffs that both meet the computational needs of applications and justify the costs of hardware acceleration.</p>

    <p class="text-gray-300">In this paper we present zkSpeed, a modular HyperPlonk accelerator that overcomes the challenges outlined above. zkSpeed comprises eight unique kernel accelerators, called units. Each unit supports required operators (e.g., large-word modular arithmetic) natively in hardware over a programmable problem size. The units collectively implement the complete zkSpeed chip architecture, which includes shared and unit-local scratchpads to capture reuse, capable of processing entire HyperPlonk proofs. Units and scratchpads communicate via a multi-channel shared bus, and we propose a schedule of each (sequential) HyperPlonk protocol phase onto zkSpeed accordingly. The schedule balances off-chip bandwidth constraints with on-chip reuse from scratchpads, unit computational throughput, and bus resource contention with a goal of overlapping off-chip communication with computation whenever possible. All unit designs and bandwidth constraints are configurable and can be tailored to use the least amount of area needed to achieve this goal. To optimize all units under a given off-chip bandwidth, we developed a zkSpeed simulator capable of sweeping over a wide range of design parameter settings. We consider thousands of unique zkSpeed designs. Analyzing the resulting Pareto frontier, we conclude that a 366mm^{2} chip with 2 TB/s of off-chip bandwidth can speedup proof generation by 801<span class="math">\\times</span> (geomean) over a CPU baseline.</p>

    <p class="text-gray-300">This paper makes the following contributions:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>A high-throughput, fully-pipelined accelerator to handle three flavors of SumCheck for HyperPlonk-based proofs.</li>

      <li>A novel implementation for modular inversion to compute fraction polynomials not seen in other ZKP protocols.</li>

      <li>Additional optimizations–including resource sharing of modular multipliers across units and on-chip memory compression schemes–that save upwards of 50% area per unit and up to 85% in bandwidth utilization.</li>

      <li>A comprehensive design space exploration of all hardware units to investigate design tradeoffs as we scale to high-performance designs and advanced memory technologies.</li>

      <li>A full-chip design that achieves 801<span class="math">\\times</span> gmean speedup over CPU at iso-compute area.</li>

    </ul>

    <h2 id="sec-7" class="text-2xl font-bold">2. Background</h2>

    <p class="text-gray-300">In this section, we describe state-of-the-art ZKPs and introduce the mathematical principles underlying the key kernels of HyperPlonk.</p>

    <h3 id="sec-8" class="text-xl font-semibold mt-8">2.1. zkSNARKs</h3>

    <p class="text-gray-300">Today, the state-of-the-art ZKP protocols are zero-knowledge Succinct Non-interactive Arguments of Knowledge (zkSNARKs). zkSNARKs have three properties: (i) zero-knowledge, i.e., the proof does not reveal any information about the secret witness <span class="math">w</span>; (ii) succinct, i.e., the proof has a few hundreds of bytes; and (iii) non-interactive, i.e., <span class="math">\\mathcal{P}</span> sends the proof to <span class="math">\\mathcal{V}</span> in one exchange.</p>

    <p class="text-gray-300">Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs</p>

    <p class="text-gray-300">ISCA '25, June 21-25, 2025, Tokyo, Japan</p>

    <p class="text-gray-300">zkSNARKs like HyperPlonk use polynomials to encode the correct execution of the target program. Polynomials can encode complex computations and constraints in a compact form, reducing the computational burden on <span class="math">\\mathcal{V}</span> to a few checks, instead of requiring inspection of individual operations in the program. In HyperPlonk, the two most time-consuming kernels are SumCheck and Multi-Scalar Multiplication (MSM). The SumCheck kernel lets <span class="math">\\mathcal{P}</span> demonstrate knowledge of a polynomial by verifying that its properties hold over a large set of inputs without revealing, e.g., the polynomial’s coefficients. MSMs ensure that <span class="math">\\mathcal{P}</span> is bound to that polynomial, preventing manipulation of the polynomial in the proof.</p>

    <h3 id="sec-9" class="text-xl font-semibold mt-8">2.2. The SumCheck Kernel</h3>

    <p class="text-gray-300">SumCheck <em>(65)</em> is an interactive protocol between a prover <span class="math">\\mathcal{P}</span> and a verifier <span class="math">\\mathcal{V}</span>. <span class="math">\\mathcal{P}</span> demonstrates to <span class="math">\\mathcal{V}</span> that it has correctly computed the sum of a polynomial over the <em>boolean hypercube</em>, i.e., over all Boolean <span class="math">(0/1)</span> assignments of its variables.</p>

    <p class="text-gray-300">Given a multivariate polynomial <span class="math">P(x_{1},x_{2},\\ldots,x_{\\mu})</span>, where <span class="math">x_{i}\\in\\mathbb{F}_{q}^{1}</span>, <span class="math">\\mathcal{P}</span> wants to prove to <span class="math">\\mathcal{V}</span> that it correctly computed the sum</p>

    <p class="text-gray-300"><span class="math">H=\\sum_{x_{1}\\in\\{0,1\\}}\\sum_{x_{2}\\in\\{0,1\\}}\\cdots\\sum_{x_{\\mu}\\in\\{0,1\\}}P(x_{1},x_{2},\\ldots,x_{\\mu}).</span></p>

    <p class="text-gray-300"><span class="math">\\mathcal{P}</span> and <span class="math">\\mathcal{V}</span> engage in a multi-round protocol. In Round 1, <span class="math">\\mathcal{P}</span> computes <span class="math">g_{1}(x_{1})</span>, a <em>univariate</em> polynomial of <span class="math">x_{1}</span> by summing over all binary values of the remaining variables:</p>

    <p class="text-gray-300"><span class="math">g_{1}(x_{1})=\\sum_{x_{2}\\in\\{0,1\\}}\\sum_{x_{3}\\in\\{0,1\\}}\\cdots\\sum_{x_{\\mu}\\in\\{0,1\\}}P(x_{1},x_{2},\\ldots,x_{\\mu})</span></p>

    <p class="text-gray-300"><span class="math">\\mathcal{P}</span> then sends coefficients or evaluations of <span class="math">g_{1}(x_{1})</span> to <span class="math">\\mathcal{V}</span>. <span class="math">\\mathcal{V}</span> checks that <span class="math">g_{1}(0)+g_{1}(1)=H</span>, and if so, generates a random challenge <span class="math">r_{1}\\in\\mathbb{F}_{q}</span> and sends it to <span class="math">\\mathcal{P}</span>.</p>

    <p class="text-gray-300">In Round 2, <span class="math">\\mathcal{V}</span> asks <span class="math">\\mathcal{P}</span> to prove that</p>

    <p class="text-gray-300"><span class="math">g_{1}(r_{1})=\\sum_{x_{2}\\in\\{0,1\\}}\\sum_{x_{3}\\in\\{0,1\\}}\\cdots\\sum_{x_{\\mu}\\in\\{0,1\\}}P(r_{1},x_{2},\\ldots,x_{\\mu}),</span></p>

    <p class="text-gray-300">which is simply an instance of SumCheck, except over a <span class="math">(\\mu-1)</span>-variate polynomial. Thus, in Round 2, <span class="math">\\mathcal{P}</span> computes and returns</p>

    <p class="text-gray-300"><span class="math">g_{2}(x_{2})=\\sum_{x_{3}\\in\\{0,1\\}}\\sum_{x_{4}\\in\\{0,1\\}}\\cdots\\sum_{x_{\\mu}\\in\\{0,1\\}}P(r_{1},x_{2},\\ldots,x_{\\mu})</span></p>

    <p class="text-gray-300">to <span class="math">\\mathcal{V}</span> and the protocol repeats recursively for a total of <span class="math">\\mu</span> rounds. If all checks pass, <span class="math">\\mathcal{V}</span> accepts <span class="math">\\mathcal{P}</span>’s claim about <span class="math">H</span>.</p>

    <h3 id="sec-10" class="text-xl font-semibold mt-8">2.3. Multilinear Polynomials</h3>

    <p class="text-gray-300">ZKPs like HyperPlonk use <em>multilinear polynomials</em>, that are <em>linear</em> in each of their variables. For example,</p>

    <p class="text-gray-300"><span class="math">f(x_{1},x_{2},x_{3})=x_{1}x_{2}+2x_{1}x_{3}+3x_{1}x_{2}x_{3}</span></p>

    <p class="text-gray-300">is multilinear because the maximum degree of individual variables is one. ZKP protocols use a general representation of multilinear polynomials, shown below for a 2-variable multilinear polynomial:</p>

    <p class="text-gray-300"><span class="math">f(x_{1},x_{2})=(1-x_{2})(1-x_{1})a_{0}+x_{2}(1-x_{1})a_{1}+(1-x_{2})x_{1}a_{2}+x_{2}x_{1}a_{3}.</span></p>

    <p class="text-gray-300">This representation defines polynomials using evaluations at specific input points (e.g., <span class="math">f(1,0)=a_{2}</span>) rather than using coefficients of symbolic terms (e.g., <span class="math">x_{1}x_{2}</span>). Just as a degree-<span class="math">d</span> polynomial is uniquely determined by <span class="math">d+1</span> coefficients, it can also be uniquely defined by its values at <span class="math">d+1</span> distinct points. This representation then maps cleanly to hardware in the form of lookup tables. For example, for a 2-variable multilinear polynomial, the binary values of <span class="math">(x_{1},x_{2})</span> index into the table to get the corresponding evaluation. In general, a multilinear polynomial with <span class="math">\\mu</span> variables <span class="math">x_{1}\\ldots x_{\\mu}</span> can be stored in a lookup table of <span class="math">2^{\\mu}</span> entries. As we will discuss in Section 3, HyperPlonk uses multilinear polynomials as building blocks for higher-degree polynomials on which we then perform SumCheck and other computations. In the rest of the paper, we will use the term <em>MLE table</em> to refer to these lookup data structures (MLE stands for “multilinear extensions” <em>(65)</em>; the word “extension” indicates that these polynomials can be evaluated at non-boolean, or extended, values).</p>

    <h3 id="sec-11" class="text-xl font-semibold mt-8">2.4. The MSM Kernel</h3>

    <p class="text-gray-300">MSMs are dot products between a vector of scalars <span class="math">\\vec{s}</span> and a vector of 2D or 3D points <span class="math">\\vec{P}</span> on an elliptical curve, e.g., <span class="math">\\sum_{i=0}^{n-1}s_{i}P_{i}</span>. MSMs are used in ZKPs to perform <em>commitments</em>. A commitment is a cryptographic primitive that binds a prover to a value without revealing it. In zkSNARK protocols like HyperPlonk <em>(11)</em>, scalars are the polynomial evaluations stored in MLE tables. Computing a dot-product reduces polynomials to a single value, i.e., the commitment.</p>

    <p class="text-gray-300">MSMs are a bottleneck in ZKP provers and recent work has focused on accelerating them on ASIC and GPU <em>(14; 27; 30; 36; 37; 38; 40; 41; 73; 75)</em>. The bottleneck is due to the extremely expensive elliptic curve point multiplications that they use. To reduce this cost, MSMs use Pippenger’s algorithm <em>(52)</em>, which performs point multiplications via several point additions (PADDs). PADDs are still expensive, typically tens of regular modular multiplications. In the context of ASIC accelerators, the state-of-the-art (SZKP <em>(14)</em>) presents a framework for building scalable MSM architectures.</p>

    <h2 id="sec-12" class="text-2xl font-bold">3. The HyperPlonk Protocol</h2>

    <p class="text-gray-300">In this section, we describe how HyperPlonk encodes the computation being proven, how this encoding shapes the structure of the underlying polynomials, and the key steps in proof generation.</p>

    <h3 id="sec-13" class="text-xl font-semibold mt-8">3.1. Plonk-based encodings</h3>

    <p class="text-gray-300">In ZKPs, the program being proven must be converted into a specific form before generating the proof. While most prior works use <em>Rank-1 Constraint System (R1CS)</em> <em>(1; 25)</em>—a series of sparse matrix-vector encodings—HyperPlonk adopts a Plonk-based polynomial structure <em>(22)</em>. R1CS and Plonk encodings map all program computations into addition, multiplication, and boolean operations, with nonlinear functions (e.g., branches) resolved via bit-wise decompositions.</p>

    <p class="text-gray-300">Plonk-based encodings map each operation in a program’s execution to a <em>gate</em> – similar in principle to gates seen in other privacy-preserving protocols <em>(13; 21; 43; 44)</em> – that supports addition, multiplication, conditionality, and equality checks, as shown in Equation 1:</p>

    <p class="text-gray-300"><span class="math">f=q_{L}w_{1}+q_{R}w_{2}+q_{M}w_{1}w_{2}-q_{O}w_{3}+q_{c}</span> (1)</p>

    <p class="text-gray-300">This can be viewed as a ZKP-specific instruction set where each gate acts as an instruction performing basic arithmetic or logical operations. In Equation 1, terms <span class="math">q_{L},q_{R},q_{M},q_{O}</span> are binary *control</p>

    <p class="text-gray-300">1 each variable can be an integer modulo a prime number q</p>

    <p class="text-gray-300">ISCA '25, June 21-25, 2025, Tokyo, Japan</p>

    <p class="text-gray-300">Alhad Daftardar, Jianqiao Mo, Joey Ah-kiow, Benedikt Bunz, Ramesh Karri, Siddharth Garg, and Brandon Reagen</p>

    <p class="text-gray-300">signals for left, right, multiply, and output ports. The term  <span class="math">q_{c}</span>  represents a constant input. Terms  <span class="math">w_{1}, w_{2}</span>  represent the gate's inputs, and  <span class="math">w_{3}</span>  is its output. These last three terms are collectively called witnesses. An addition operation, for instance, is implemented by setting  <span class="math">q_{L} = 1</span> ,  <span class="math">q_{R} = 1</span> ,  <span class="math">q_{\\mathrm{O}} = 1</span>  and other control and constant inputs to 0. This yields:  <span class="math">f = w_{1} + w_{2} - w_{3}</span> . That is,  <span class="math">f = 0</span>  if and only if the addition is correctly performed.</p>

    <p class="text-gray-300">Each operation in a program is mapped to a Plonk gate. A program with  <span class="math">2^{\\mu}</span>  operations has  <span class="math">2^{\\mu}</span>  Plonk gates connected to form a circuit. A  <span class="math">\\mu</span> -variate polynomial  <span class="math">f(X_{1},X_{2}\\ldots ,X_{\\mu})</span>  represents the entire circuit, with binary assignments to variables  <span class="math">\\{X_1,X_2\\ldots ,X_\\mu \\}</span>  representing individual gates. For example, if  <span class="math">\\mu = 4</span> , the circuit has 16 gates;  <span class="math">f(X_{1} = 0,X_{2} = 0,X_{3} = 0,X_{4} = 0)</span>  represents the first gate.</p>

    <p class="text-gray-300"><span class="math">f(X)</span>  is constructed using multilinear polynomials representing every term from Eq. 1. For example,  <span class="math">q_{L}(X)</span>  is the left control input polynomial,  <span class="math">w_{1}(X)</span>  is the first data input polynomial, and so on. Each of these polynomials also takes  <span class="math">X = [X_{1}, X_{2}, \\ldots, X_{4}]</span>  as an index. For example, in a program that maps to 16 gates,  <span class="math">q_{M}([0,1,0,0])</span>  will tell us whether or not the multiplication control signal is enabled in gate 2.  <span class="math">w_{3}([1,1,1,1])</span>  tells us what the output data signal is at gate 15. All individual polynomials are encoded in this fashion, and can be stored as MLE tables. These MLE tables are populated from the program trace in software before running the HyperPlonk prover. The MLEs are then used by the steps of the HyperPlonk protocol, which we discuss in the following sections.</p>

    <p class="text-gray-300">The key difference between the SumCheck used in HyperPlonk and the example in Section 2.2 lies in the structure of the underlying polynomials. While the earlier example operates on a single polynomial of arbitrary degree, HyperPlonk applies SumCheck to a version of the Plonk polynomial in Equation 1, as well as other polynomials discussed in Section 4.1. These polynomials consist of the products of multilinear polynomials, with terms of varying degrees. Figure 1 shows an example of how a SumCheck of the product of three multilinear polynomials is computed.</p>

    <p class="text-gray-300">In the example from Section 2.2, if  <span class="math">g(X)</span>  was multilinear, we would only need the evaluations at  <span class="math">X_{1} = 0</span>  and 1 because the result of summing over all variables yielded a univariate degree-1 polynomial. In this example, however, after summing over all variables, we are left with a univariate degree-3 polynomial. As mentioned in Section 2.3 (and from basic polynomial principles), a degree-3 polynomial must be evaluated at 4 unique points to fully characterize the polynomial. In the figure example, in the blue region, we are iterating over  <span class="math">[X_{2}, X_{3}] = [0, 0]</span> ,  <span class="math">[0, 1]</span> ,  <span class="math">[1, 0]</span> ,  <span class="math">[1, 1]</span>  to compute the evaluations. For each iteration (red region), we must therefore evaluate each polynomial at  <span class="math">X_{1} = 0</span> , 1, 2, 3. (Here,  <span class="math">X_{1} = 2</span> , 3 are the extensions that we compute from the existing evaluations at 0, 1.) Then, in the green region, we compute the product for  <span class="math">X_{1} = 0</span>  across all polynomials, and then sum across iterations. This is repeated for  <span class="math">X_{1} = 1</span> , 2, 3. After the summations, each polynomial's MLE table is updated with a random challenge  <span class="math">r</span>  from the verifier. We refer to this step as MLE Update. For every boolean hypercube instance (e.g.,  <span class="math">(X_{2}, X_{3})</span>  in Figure 1), we extrapolate the linear polynomial in  <span class="math">X_{1}</span>  to the value of  <span class="math">r</span> . For example, a table  <span class="math">t&#x27;</span>  (for round 2) can be</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Figure 1: SumCheck Example. The subscripts  <span class="math">(0,0)</span> ,  <span class="math">(0,1)</span> , etc. refer to the specific boolean instances of  <span class="math">X_{2}, X_{3}</span> .</p>

    <p class="text-gray-300">constructed from a table  <span class="math">t</span>  (from round 1) using the formula</p>

    <div class="my-4 text-center"><span class="math-block">t ^ {\\prime} [ i ] \\leftarrow (t [ 2 i + 1 ] - t [ 2 i ]) r + t [ 2 i ] \\tag {2}</span></div>

    <p class="text-gray-300">The sum of all of these core computational steps is more expensive than baseline SumCheck. An additional layer of complexity is that HyperPlonk's SumCheck polynomials exhibit degree variation across terms. This leads to imbalance in how many total evaluations are needed per term (i.e.,  <span class="math">q_{L}w_{1}</span>  needs 3 evaluations, while  <span class="math">q_{M}w_{1}w_{2}</span>  needs 4). This is handled by the HyperPlonk SumCheck protocol with a fixed interpolation step before the MLE tables are updated. While these computations are expensive, many of these operations can be performed in parallel. All polynomials can compute their extensions independently, and within a polynomial, extensions at different values can be parallelized. Thus, HyperPlonk's SumChecks have high compute and degrees of parallelism.</p>

    <p class="text-gray-300">In this section, we outline the steps of the HyperPlonk protocol, as seen in Figure 2, what each step achieves, and what hardware units are needed to perform each step.</p>

    <p class="text-gray-300">3.3.1 Witness Commits. The first step in HyperPlonk's prover involves witness commitments. In this step, we compute MSMs between elliptic curve points and the witness polynomials  <span class="math">w_{1}, w_{2}, w_{3}</span>  to reduce each polynomial to individual commitments. The witness polynomials in HyperPlonk are typically "Sparse", meaning that  <span class="math">90\\%</span>  of the values are either 0 or 1, and  <span class="math">10\\%</span>  are up to the full scalar bitwidth. SZKP [14] handles this by using Sparse MSMs. We implement Sparse MSMs using the MSM unit for this step.</p>

    <p class="text-gray-300">3.3.2 Gate Identity. The Gate Identity step confirms that each gate in the circuit performs its computation correctly. The intuition is that if so, then  <span class="math">f(X)</span>  in Equation 1 should evaluate to 0 for each gate, or equivalently, for each binary assignment of  <span class="math">X</span> . Further, the sum of  <span class="math">f(X)</span>  over all  <span class="math">X</span> 's should also equal 0, which can be confirmed by running SumCheck on  <span class="math">f(X)</span> . However, since the prior statement is only a necessary but not sufficient condition for correct computation, HyperPlonk performs SumCheck over a polynomial  <span class="math">f(X)r(X)</span> , where  <span class="math">r(X)</span>  is a multilinear polynomial with evaluations</p>

    <p class="text-gray-300">Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs</p>

    <p class="text-gray-300">ISCA '25, June 21-25, 2025, Tokyo, Japan</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Figure 2: A) HyperPlonk Protocol Steps, B) zkSpeed Architecture, and C) Step Dataflow. Each step is executed in the numerical order listed. Colors of each module in the zkSpeed architecture directly correspond with the operations in the dataflow. In Wire Identity, PermCheck refers to the creation of MLEs and then the ZeroCheck that takes them as input. ProdMLE refers to the construction of Product MLE. Batch Evals only use the Multifunction Tree unit, they are omitted for space.</p>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a> Figure 3: Different computation patterns that fit in the Multifunction Tree unit. Computation outputs are marked in red.</p>

    <p class="text-gray-300">computed from  <span class="math">\\mu</span>  random challenges (the eq polynomial of Lemma 2.1 in [11]). We will henceforth refer to the construction of such a polynomial as Build MLE. Then, the sum over the boolean hypercube of  <span class="math">f(X)r(X)</span>  should also be 0; this is known as a ZeroCheck. The Gate Identity step relies on three units: the Multifunction Tree unit (Section 4.3) to build  <span class="math">r(X)</span> , the SumCheck unit, and the MLE Update unit to update MLE tables between SumCheck rounds.</p>

    <p class="text-gray-300">3.3.3 Wiring Identity. This step verifies that the outputs of each gate are routed correctly to inputs of downstream gates. This is achieved via a PermutationCheck (PermCheck), which is performed by constructing a numerator polynomial  <span class="math">N</span>  that encodes the natural ordering of the outputs and a denominator polynomial  <span class="math">D</span>  that encodes the permuted ordering (derived from permutation polynomials  <span class="math">\\sigma_{1\\dots 3}</span> ), and then checking that  <span class="math">\\phi = N / D</span> , which we refer to as Fraction MLE, equals 1. As we will discuss, computing  <span class="math">D^{-1}</span>  is time consuming, since inverting (or, in effect, performing divisions on) elements of a finite field is difficult. The Product MLE,  <span class="math">\\pi</span> , is generated by computing a cumulative product over  <span class="math">\\phi</span>  to form the first half, then recursively applying cumulative products on  <span class="math">\\pi</span>  itself to complete the second half. Then, the  <span class="math">\\phi</span>  and  <span class="math">\\pi</span>  polynomials are both committed to via MSM computations. A final ZeroCheck is</p>

    <p class="text-gray-300">also performed to ensure that the structure imposed upon  <span class="math">\\phi</span>  and  <span class="math">\\pi</span>  was not violated during their creation, i.e., the sum over the boolean hypercube of the resulting constraint polynomial should be zero everywhere. All polynomials are stored in the form of MLE tables. The Wiring Identity step uses the Construct N&amp;D unit, the FracMLE unit, the Multifunction Tree unit (to construct the Product MLE  <span class="math">\\pi</span>  and later for the Build MLE step within ZeroCheck), the MSM unit, the SumCheck unit, and the MLE Update unit.</p>

    <p class="text-gray-300">3.3.4 Batch Evaluations. The SumCheck protocols require evaluating several MLEs at specific points. This is achieved with batch evaluations, where the input MLEs, as well as  <span class="math">\\phi</span>  and  <span class="math">\\pi</span> , are queried at 6 points, some of which are derived from round challenges in the SumCheck portion of the Gate and Wiring Identity steps, and some of which are fixed at compile time. In total, 22 total evaluations are performed among 13 polynomials using 6 distinct points. This step is almost the exact reverse of the step in 3.3.2 used to construct  <span class="math">r(X)</span> , since we are compressing an entire MLE into 1 value, while  <span class="math">r(X)</span>  is an entire MLE built from  <span class="math">\\mu</span>  values. We will henceforth refer to the operation of evaluating an MLE at a point (consisting of  <span class="math">\\mu</span>  field elements) as MLE Evaluate. These polynomial queries are then</p>

    <p class="text-gray-300">ISCA '25, June 21-25, 2025, Tokyo, Japan</p>

    <p class="text-gray-300">Alhad Daftardar, Jianqiao Mo, Joey Ah-kiow, Benedikt Bunz, Ramesh Karri, Siddharth Garg, and Brandon Reagen</p>

    <p class="text-gray-300">Table 1: Modular multiplications, memory requirements, and arithmetic intensity of select functions for  <span class="math">2^{20}</span>  gates. Links to the source code are provided <span class="math">^2</span> .</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Kernel</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Source Code</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Modmuls (millions)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Input Size (MB)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Output Size (MB)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Arithmetic Intensity (modmul/byte)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Poly Open MSMs</td>

            <td class="px-3 py-2 border-b border-gray-700">M</td>

            <td class="px-3 py-2 border-b border-gray-700">1160</td>

            <td class="px-3 py-2 border-b border-gray-700">127</td>

            <td class="px-3 py-2 border-b border-gray-700">0.00</td>

            <td class="px-3 py-2 border-b border-gray-700">8.70</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Wire Identity MSMs</td>

            <td class="px-3 py-2 border-b border-gray-700">M</td>

            <td class="px-3 py-2 border-b border-gray-700">2290</td>

            <td class="px-3 py-2 border-b border-gray-700">254</td>

            <td class="px-3 py-2 border-b border-gray-700">0.00</td>

            <td class="px-3 py-2 border-b border-gray-700">8.59</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Witness MSMs</td>

            <td class="px-3 py-2 border-b border-gray-700">M</td>

            <td class="px-3 py-2 border-b border-gray-700">1370</td>

            <td class="px-3 py-2 border-b border-gray-700">167</td>

            <td class="px-3 py-2 border-b border-gray-700">0.00</td>

            <td class="px-3 py-2 border-b border-gray-700">7.83</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Batch Evaluations</td>

            <td class="px-3 py-2 border-b border-gray-700">M</td>

            <td class="px-3 py-2 border-b border-gray-700">23.1</td>

            <td class="px-3 py-2 border-b border-gray-700">77.5</td>

            <td class="px-3 py-2 border-b border-gray-700">0.00</td>

            <td class="px-3 py-2 border-b border-gray-700">0.28</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">ZeroCheck Rounds</td>

            <td class="px-3 py-2 border-b border-gray-700">M</td>

            <td class="px-3 py-2 border-b border-gray-700">77.6</td>

            <td class="px-3 py-2 border-b border-gray-700">332</td>

            <td class="px-3 py-2 border-b border-gray-700">0.00</td>

            <td class="px-3 py-2 border-b border-gray-700">0.22</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Fraction MLE</td>

            <td class="px-3 py-2 border-b border-gray-700">M</td>

            <td class="px-3 py-2 border-b border-gray-700">5.19</td>

            <td class="px-3 py-2 border-b border-gray-700">0.00</td>

            <td class="px-3 py-2 border-b border-gray-700">31.9</td>

            <td class="px-3 py-2 border-b border-gray-700">0.16</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">PermCheck Rounds</td>

            <td class="px-3 py-2 border-b border-gray-700">M</td>

            <td class="px-3 py-2 border-b border-gray-700">94.4</td>

            <td class="px-3 py-2 border-b border-gray-700">701</td>

            <td class="px-3 py-2 border-b border-gray-700">0.00</td>

            <td class="px-3 py-2 border-b border-gray-700">0.13</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Linear Combine</td>

            <td class="px-3 py-2 border-b border-gray-700">M</td>

            <td class="px-3 py-2 border-b border-gray-700">18.9</td>

            <td class="px-3 py-2 border-b border-gray-700">77.5</td>

            <td class="px-3 py-2 border-b border-gray-700">191</td>

            <td class="px-3 py-2 border-b border-gray-700">0.07</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">OpenCheck Rounds</td>

            <td class="px-3 py-2 border-b border-gray-700">M</td>

            <td class="px-3 py-2 border-b border-gray-700">31.5</td>

            <td class="px-3 py-2 border-b border-gray-700">765</td>

            <td class="px-3 py-2 border-b border-gray-700">0.00</td>

            <td class="px-3 py-2 border-b border-gray-700">0.04</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Construct N & D</td>

            <td class="px-3 py-2 border-b border-gray-700">M</td>

            <td class="px-3 py-2 border-b border-gray-700">10.5</td>

            <td class="px-3 py-2 border-b border-gray-700">18.2</td>

            <td class="px-3 py-2 border-b border-gray-700">255</td>

            <td class="px-3 py-2 border-b border-gray-700">0.04</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Product MLE</td>

            <td class="px-3 py-2 border-b border-gray-700">M</td>

            <td class="px-3 py-2 border-b border-gray-700">1.05</td>

            <td class="px-3 py-2 border-b border-gray-700">0.00</td>

            <td class="px-3 py-2 border-b border-gray-700">31.9</td>

            <td class="px-3 py-2 border-b border-gray-700">0.03</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">All MLE Updates</td>

            <td class="px-3 py-2 border-b border-gray-700">M</td>

            <td class="px-3 py-2 border-b border-gray-700">33.6</td>

            <td class="px-3 py-2 border-b border-gray-700">1800</td>

            <td class="px-3 py-2 border-b border-gray-700">900</td>

            <td class="px-3 py-2 border-b border-gray-700">0.01</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">used by the verifier to check that the prover obeyed the protocol. The Batch Evaluation step uses the Multifunction Tree unit.</p>

    <p class="text-gray-300">3.3.5 Polynomial Opening. This step succinctly verifies the correctness of the prover's batch evaluations. For brevity, we will omit details of the polynomial opening step. To summarize, it involves first computing 6 MLEs as a linear combination of the MLEs from Eq. 1 and  <span class="math">\\phi</span>  and  <span class="math">\\pi</span> . Then, 6 more MLEs are constructed from the query points in Section 3.3.4. These 12 MLEs are linearly combined into a single MLE, upon which a final SumCheck is computed. To avoid confusion, we will refer to this final SumCheck as OpenCheck and use SumCheck to refer to the underlying computation.</p>

    <p class="text-gray-300">After OpenCheck, the first 6 MLEs used as OpenCheck's inputs are linearly combined with the OpenCheck's round challenges to construct a final MLE, which is denoted as  <span class="math">g&#x27;</span> . This MLE is first reduced to half its size, and it is used as the scalar set for a  <span class="math">2^{\\mu - 1}</span> -point MSM. We then halve the scalar set and perform MSMs. For example, if  <span class="math">\\mu = 10</span> , we compute a  <span class="math">2^9</span> -point MSM, then a  <span class="math">2^8</span> -point MSM, all the way to a  <span class="math">2^0</span> -point MSM. The Polynomial Opening step uses the MLE Combine unit to compute the linear MLE combinations, the Multifunction Tree unit to build the 6 MLEs, the SumCheck unit to perform OpenCheck, and the MSM Unit to compute MSMs.</p>

    <p class="text-gray-300">3.3.6 SHA3. zkSNARKs are non-interactive and use SHA3 to generate challenges as well as maintain transcripts. Transcripts are logs of proof-related computations checked by the verifier. In HyperPlonk, SHA3 is invoked between steps to "log" computed values, which is achieved by updating the SHA3 state. Intuitively, this ensures that all future challenges are bound to the existing history of computations logged in the transcript. As a result, SHA3 effectively acts as an order-enforcing mechanism. This means the protocol steps must be executed in series, as shown in Figure 2.</p>

    <p class="text-gray-300">3.3.7 Compute Demands of HyperPlonk. Table 1 summarizes profiling results to characterize key functions and understand the sources of performance overhead and hardware needs when accelerating HyperPlonk. There are too many functions to list, so we present the twelve with the highest arithmetic intensity, which is defined as modular multiplications (modmuls) per byte, as done in prior</p>

    <p class="text-gray-300">!<a href="img-3.jpeg">img-3.jpeg</a> Figure 4: SumCheck Round unit example. Subscripts of  <span class="math">f</span>  indicate which  <span class="math">X_{2}, X_{3}</span>  instance is being handled by the PE. For simplicity, each MLE is renamed from  <span class="math">a - i</span> . Their subscripts indicate the evaluation, e.g.,  <span class="math">X_{1} = 0 \\ldots 4</span> . The products  <span class="math">p_{j,k}</span>  are labeled to indicate the  <span class="math">j^{tk}</span>  term evaluated at  <span class="math">X_{1} = k</span> .</p>

    <p class="text-gray-300">work [15, 32] (note SHA3 has no modmuls). Additionally, the reference CPU implementation is provided as a link. First, we observe that all functions require an immense amount of computation: ranging from millions to billions of 255/381-bit modmuls (comprising three integer multiplications) over all invocations of each function. For example, the data for Wire Identity MSMs modmuls reflects two function calls; for ZeroCheck Rounds there is one function call (see links in table). This motivates the need for both specialized modmul units and a high degree of parallelism to mitigate overhead. Second, compute intensity drops off sharply after the third function (since data reuse is limited), and the data input/output sizes for all functions are large, typically hundreds of megabytes up to terabytes as problem sizes scale to more gates. This motivates the need for large on-chip scratchpads to mitigate off-chip data movement when possible and high off-chip (i.e., HBM) bandwidth.</p>

    <p class="text-gray-300">HyperPlonk's protocol is based on the BLS12-381 elliptical curve. Here, all MLE datatypes are 255 bits wide and all elliptical curve points in the MSMs are 381 bits wide. All MLE and MSM operations involve modular arithmetic primitives. These are built into each accelerator unit that requires them. zkSpeed comprises eight accelerator units and we describe each below.</p>

    <h3 id="sec-17" class="text-xl font-semibold mt-8">4.1. SumCheck and MLE Update</h3>

    <p class="text-gray-300">Three HyperPlonk steps use SumCheck: ZeroCheck (Section 3.3.2), PermCheck (Section 3.3.3), and OpenCheck (Section 3.3.5). Each step has a unique polynomial shown, respectively, below:</p>

    <p class="text-gray-300">(4) <span class="math">f_{zero}=q_{L}w_{1}f_{z_{1}}+q_{R}w_{2}f_{z_{1}}+q_{M}w_{1}w_{2}f_{z_{1}}-q_{O}w_{3}f_{z_{1}}+q_{c}f_{z_{1}}</span> (5) <span class="math">f_{perm}=\\pi f_{z_{2}}-p_{1}p_{2}f_{z_{2}}+\\alpha(\\phi D_{1}D_{2}D_{3})f_{z_{2}}-\\alpha(N_{1}N_{2}N_{3})f_{z_{2}}</span> (6) <span class="math">f_{open}=y_{1}k_{1}+y_{2}k_{2}+y_{3}k_{3}+y_{4}k_{4}+y_{5}k_{5}+y_{6}k_{6}</span></p>

    <p class="text-gray-300">In these equations, <span class="math">\\alpha</span> is a challenge from the SHA3 unit, and all other symbols represent multilinear polynomials. <span class="math">f_{z_{1}},f_{z_{2}}</span> and <span class="math">k_{i}</span> are all Built MLEs constructed from SHA3 challenges (see the discussion of <span class="math">r(X)</span> in Section 3.3.2). These SumCheck polynomials share a common sum-of-products representation, but are each unique and require slightly different datapaths. We develop a unified SumCheck unit that can handle each of these polynomials and highlight the key contributions of our architecture next.</p>

    <h4 id="sec-18" class="text-lg font-semibold mt-6">4.1.1. SumCheck Round PE Microarchitecture</h4>

    <p class="text-gray-300">In ZeroCheck and PermCheck, there are polynomials that appear multiple times across terms. In HyperPlonk’s CPU baseline, the boolean hypercube summations are performed iteratively term-by-term, incurring redundant computation for these repeating polynomials. We address this by computing all evaluations for each polynomial in parallel. For example, in Equation 3, the polynomial <span class="math">f_{z_{1}}</span> has to be evaluated at <span class="math">X_{i}=0,1,2,3</span> and <span class="math">4</span> because the largest-degree term it appears in has a degree of four. This computation only needs to be performed once before being used to compute the product in each term of <span class="math">f_{zero}</span>. Figure 4 shows an example of how our SumCheck PEs handle ZeroCheck computation for <span class="math">f_{zero}</span>. Each unique polynomial takes its respective <span class="math">X_{i}=0</span> and <span class="math">1</span> values (e.g., <span class="math">c_{0}=q_{R}(X_{i}=0)</span> in Figure 4), and uses these values to extend to the needed <span class="math">X_{i}</span> evaluations. Then, each product in Equation 3 must be computed for each <span class="math">X_{i}</span> evaluation. The products at the evaluation points are then accumulated into registers. Due to the inherent degree imbalance, some terms have fewer evaluations; the additional evaluations are computed via Barycentric Interpolation <em>(Barycentric, 2017)</em>. This is omitted in the figure since it only adds a fixed cost at the end of each round (23 modmuls for ZeroCheck and 46 modmuls for PermCheck). Each polynomial observes a different datapath, so we use a specialized design to exploit high reuse, full-pipelining, and high levels of parallelism.</p>

    <h4 id="sec-19" class="text-lg font-semibold mt-6">4.1.2. Streaming approach</h4>

    <p class="text-gray-300">At the start of the protocol, the MLE tables corresponding to polynomials in Equation 1 are all provided to the prover and can be stored on-chip. However, as these MLEs undergo rounds of SumCheck, the process of incorporating challenges into the MLE tables expands binary values to full 255-bit values. Though the number of MLE table entries reduces by half each round, the data itself grows by over 100<span class="math">\\times</span> between rounds 1 and 2, so the total storage cost for storing all MLEs is intractable. However, each round, the intermediate values of MLE tables are only used by the main SumCheck computation and then by the MLE Update unit to be halved in size. Since there is no data reuse in-between rounds, we adopt a streaming-based solution to alleviate the pressure on on-chip SRAM storage. The key tradeoff here is that our SumCheck and MLE Update units become memory-bound, since each MLE in Equations 3-5 must be updated and written back to off-chip memory after SumCheck rounds, necessitating off-chip traffic. Fortunately, recent advances in high-bandwidth memory (HBM) can supply very high bandwidths to offset this. This is inline with many other cryptographic computing accelerators, which also rely on HBM <em>(Bartlett et al., 2018; HBM, 2018; HBM, 2019; HBM, 2020; HBM, 2020; HBM, 2020a; HBM, 2020b; HBM, 2020c; HBM, 2020b; HBM, 2020c; HBM, 2020d; HBM, 2020e; HBM, 2020f)</em>. We analyze the bandwidth sensitivity of the SumCheck computations in our evaluation section.</p>

    <h4 id="sec-20" class="text-lg font-semibold mt-6">4.1.3. Scaling to Multiple PEs</h4>

    <p class="text-gray-300">Each SumCheck PE handles the product and sum for one iteration over the boolean hypercube. For example, in Figure 1, this corresponds to one red region per polynomial (MLE table) and the first product in the green region for each <span class="math">X_{1}=0,1,2,3</span>. These iterations run in parallel with multiple PEs storing their own accumulation registers. The bottom of Figure 4 shows the accumulation of each evaluation across boolean hypercube values (equivalently, across indices of the MLE tables). After all evaluations are done, an MLE Update PE handles the updates for one MLE table and can provision multiple modmuls. Multiple PEs can run in parallel, handling MLE tables independently.</p>

    <h4 id="sec-21" class="text-lg font-semibold mt-6">4.1.4. Unified SumCheck PE</h4>

    <p class="text-gray-300">The three polynomials <span class="math">f_{zero}</span>, <span class="math">f_{perm}</span>, <span class="math">f_{open}</span> have different datapaths. We use HLS tools to generate a unified PE that handles each SumCheck variation used in HyperPlonk. Each PE requires 94 modular multipliers, compared to 184 modular multipliers without resource sharing, saving 48.9% on area.</p>

    <h4 id="sec-22" class="text-lg font-semibold mt-6">4.1.5. Comparison to Prior SumCheck Implementations</h4>

    <p class="text-gray-300">HyperPlonk’s CPU library is designed to support <em>any</em> composition of multilinear polynomials for different protocols, not just the three we have shown. Consequently, repeating polynomial computations as observed in the CPU implementation greatly improves programmability, as opposed to having specialized functions to handle the specific computation patterns we optimize for.</p>

    <p class="text-gray-300">NoCap <em>(Nolte and Sivakumar, 2019)</em> is a recent accelerator that also accelerates SumCheck, but there are critical differences at the protocol-level that motivate our architecture. NoCap implements Spartan <em>(Sivakumar, 2019)</em>, which uses R1CS encodings resulting in two SumCheck instances that look as follows: <span class="math">f_{1}=g_{1}g_{2}g_{4}-g_{3}g_{4}</span> and <span class="math">f_{2}=g_{5}g_{6}</span>. NoCap uses a vector architecture with 2048 PEs to process boolean hypercube instances with a Beneš network to sum across PEs. This makes sense for NoCap because Spartan’s polynomials are degree 2 and 3 with up to two terms. In contrast, HyperPlonk’s polynomials have a more heterogeneous structure; there are more terms of varying degree. This complexity arises from the usage of the control and constant polynomials (<span class="math">q_{L},q_{R},q_{M},q_{O},q_{C}</span>) to represent gates. These are required to keep HyperPlonk verifier costs low (in Section 7, we see NoCap’s verifier is slower). Consequently, mapping HyperPlonk’s polynomials to a vector architecture would put more pressure on vector register files because of the high amount of intermediate values needed to be read. As seen in Figure 4, our SumChecks also require very complex communication, which can increase bandwidth pressure and may not be efficient to implement with a Beneš network. Further, our specialized PEs immediately reuse values without relying on register files to store the numerous amount of intermediates. We have fewer, heftier PEs, so data movement costs are less relative to those incurred by a vector processor.</p>

    <h3 id="sec-23" class="text-xl font-semibold mt-8">4.2. MSMs</h3>

    <p class="text-gray-300">MSMs are used in three HyperPlonk steps: Witness Commits, Wiring Identity, and Polynomial Opening. Several prior works accelerated</p>

    <p class="text-gray-300">ISCA '25, June 21-25, 2025, Tokyo, Japan</p>

    <p class="text-gray-300">Alhad Daftardar, Jianqiao Mo, Joey Ah-kiow, Benedikt Bunz, Ramesh Karri, Siddharth Garg, and Brandon Reagen</p>

    <p class="text-gray-300">!<a href="img-4.jpeg">img-4.jpeg</a> Figure 5: MSM bucket aggregation comparison.</p>

    <p class="text-gray-300">MSMs; we begin with the base MSM design from SZKP [14], the state-of-the-art for accelerating Groth16, and propose two optimizations for better performance and area efficiency.</p>

    <p class="text-gray-300">In HyperPlonk, the Sparse MSMs run in series and are on the critical path. This is unlike prior protocols like Groth16 where their execution could be masked via parallel processing with the Dense MSMs. Consequently, we opt to use the same MSM hardware unit for both Sparse and Dense MSMs in zkSpeed (as opposed to separate units in SZKP). zkSpeed uses a similar scheme as SZKP for handling sparse computations. First, we compute the sum of all points corresponding to 1-valued scalars. This is done by fetching the points corresponding to 1-valued scalars into the MSM unit's SRAM banks. Then, using a tree-based approach, we feed two points at a time to the pipelined Point Adder (PADD) unit, with the result written back to the SRAM banks. This process repeats until we have reduced all points to the final sum for points corresponding to 1-valued scalars. Note that in this step, we need not fetch scalars into the MSM's SRAM banks since they are all 1. Then, we use Pippenger's algorithm [52] on the remaining  <span class="math">\\approx 10\\%</span>  of (dense) scalars. For the Dense MSMs in the Wiring Identity and Polynomial Opening steps, we use Pippenger's algorithm for the full MSM computation. We now discuss the two improvements to SZKP's MSM architecture.</p>

    <p class="text-gray-300">4.2.1 Reduced Memory Footprint. First, we note that elliptical curve points, while being three-dimensional, are initialized as  <span class="math">(X,Y,1)</span>  coordinates in HyperPlonk. Thus, we only fetch two coordinates per point, saving off-chip bandwidth. We further save on-chip SRAM area. SZKP provisions one scalar memory bank and three point memory banks, to hold  <span class="math">X,Y,Z</span>  coordinates. While Sparse MSMs need not store the 1-valued scalars, the tree-based addition partials still need buffering (their  <span class="math">Z</span>  coordinates are no longer 1-valued) necessitating the  <span class="math">Z</span>  coordinate memory bank. Therefore, zkSpeed allocates three SRAM memory banks. In Dense MSM operation, the  <span class="math">Z</span>  memory bank is reused to store the scalars, and since partial sums are only stored in bucket registers, we do not need to provision another dedicated memory bank, as in SZKP. This represents a savings of  <span class="math">18\\%</span>  in on-chip SRAM area compared to having a dedicated scalar memory bank.</p>

    <p class="text-gray-300">4.2.2 Faster Bucket Aggregation. The second optimization addresses a runtime bottleneck in SZKP's bucket aggregation step. After sorting points into buckets and computing each bucket's sum, SZKP employs a naive aggregation algorithm to calculate the sum  <span class="math">\\sum_{i=1}^{3^W-1} iB_i</span> , where  <span class="math">W</span>  is the window size [14, 52], and  <span class="math">B_i</span>  represents the accumulated sum of the  <span class="math">i</span> -th bucket. This is inefficient when processing</p>

    <p class="text-gray-300">smaller MSMs, e.g., 32-point MSMs, which are prominent in Polynomial Opening. The fixed bucket aggregation latency becomes a performance bottleneck because the point additions are serially performed and do not leverage the pipelining available in the PADD unit. Consequently, the PADD is underutilized in this step. To address this, zkSpeed adapts bucket aggregation introduced in [36]. This scheme divides aggregation into smaller groups, computes the partial sums within each group in parallel, and finally combines the results. As shown in Figure 5, it reduces the bucket aggregation latency by an average of  <span class="math">92\\%</span>  across all window sizes compared to SZKP. We select a group size of 16, which provides the best overall performance and ensures the aggregation step no longer dominates runtime for small MSMs.</p>

    <p class="text-gray-300">4.3.1 Tree-like Computation in HyperPlonk. Many HyperPlonk functions exhibit binary-tree compute patterns, including Build MLE, MLE Evaluate, and constructing Product MLE  <span class="math">(\\pi)</span> . zkSpeed supports these in hardware with our Multifunction Tree Unit (MTU), specially designed to handle these compute patterns effectively. Build MLE is a function used in ZeroCheck and OpenCheck steps. It constructs a table with  <span class="math">2^{\\mu}</span>  entries from random values  <span class="math">r_1</span>  to  <span class="math">r_{\\mu}</span>  where  <span class="math">2^{\\mu}</span>  represents problem size. The computation is divided into  <span class="math">\\mu - 1</span>  layers (as a binary tree) to reduce the number of modular multiplications from  <span class="math">(\\mu - 1)2^{\\mu}</span>  to  <span class="math">2^{\\mu + 1} - 4</span> . The multiplier tree is used for batch inversion during Fraction MLE generation (see Section 4.4), where it efficiently calculates the product  <span class="math">D[0]D[1] \\cdots D[b - 1]</span>  for an inversion batch size,  <span class="math">b</span> . Similarly, the MLE Evaluate in the Batch Evaluation step operates like a multiplier tree but includes additional modular additions in each operation. The Product MLE generation in the Wiring Identity outputs all layer results. The functions' dataflows are presented in Figure 3.</p>

    <p class="text-gray-300">4.3.2 zkSpeed's Tree Approach. The original (CPU) HyperPlonk implementation uses breadth-first (level-order) traversal (BFS). This is inappropriate for hardware acceleration as it puts increased pressure on SRAM capacity and off-chip bandwidth. For example, a problem size of  <span class="math">2^{23}</span>  requires up to  <span class="math">2^{22}</span>  intermediate elements in a level, each 255 bits wide, which would require 128MB for the intermediates alone. We propose a hybrid strategy that applies depth-first traversal (DFS) to the upper levels of the binary tree and switches to BFS at lower levels. This approach leverages efficient memory reuse in the upper levels through DFS, while enabling parallelism in the lower levels via BFS. It reuses and consumes intermediate results as they are produced, reducing the amount of data that must be stored on-chip or spilled to DRAM.</p>

    <p class="text-gray-300">4.3.3 Multifunction Tree Architecture. We further analyze this tree architecture in [42]. Figure 6 shows an example of how the MTU works. Each PE includes a modular multiplier and modular adder <span class="math">^{3}</span> . The hardware supports three processing modes of Figure 3. For the Inverse Tree (e.g., MLE Evaluate), the unit accepts  <span class="math">p</span>  inputs in parallel and reduces tree-level partials via a matching hardware dataflow; in Figure 6,  <span class="math">p = 8</span> , and the data flows from left to right. If the tree has more levels than hardware supports (three levels in the</p>

    <p class="text-gray-300">Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs</p>

    <p class="text-gray-300">ISCA '25, June 21-25, 2025, Tokyo, Japan</p>

    <p class="text-gray-300">!<a href="img-5.jpeg">img-5.jpeg</a> Figure 6: Hardware structure of the Multifunction Tree unit and accumulator schedule (blue: forward, black: inverted, red: outputs to HBM/other modules. Level for binary tree). Accumulator schedule shows the level and node index.</p>

    <p class="text-gray-300">example; a problem size  <span class="math">2^{20}</span>  workload has 20 levels), the remaining levels are scheduled and processed in DFS via the accumulator. Outputs from the hardware tree (Level 3 in Figure 6) are pushed in an accumulator-local register file and once operands are ready, popped to the accumulator PE. The bottom of Figure 6 shows its schedule. Initially, there are gaps as the accumulator must wait two cycles for each input pair. However, once multiple levels are processed, the gaps are filled; this can be seen in cycle 44, where levels 4 and 5 are processed by the PE at the same time (i.e., both in the pipeline). Thus the PEs in the tree have high utilization: for a  <span class="math">2^{20}</span>  workload, they are over  <span class="math">99\\%</span>  utilized during the whole computation. The red arrows coming out of each PE show how computations are sampled and output to create the Product MLE. The Forward Tree (Build MLE) support is shown in blue, and data flows from right to left. Each PE takes the previous level and a challenge  <span class="math">r_i</span>  as inputs and generates two outputs that are fed to the next level. Similarly, if the tree has more levels, the accumulator PE is scheduled to generate (roughly) one output per cycle to feed the rest of the PEs, corresponding to the last 3 levels, outputting 8 results in the end. Switching is supported by muxes at PE inputs.</p>

    <p class="text-gray-300">The advantages of this hybrid traversal [42] are noticeable: it eliminates the need to store entire intermediate levels, making it practical for large problem sizes, and provides the ability to rate-match with upstream or downstream units and maintain throughput. By adjusting the number of PEs, the unit can handle varying input and output rates, forming a full pipeline with other units. The ability to reuse across multi-functions eliminates the need to allocate multiple dedicated units, saving  <span class="math">41.6\\%</span>  area across global Pareto design points in Section 7. As HyperPlonk's code uses BFS, it experiences greater dependence distances. Our traversal mitigates this by scheduling work to avoid dependence stalls. Executing nodes already stresses CPU's limited compute resources, so we expect hybrid traversal to have little performance impact in software.</p>

    <p class="text-gray-300">4.4.1 Creating  <span class="math">\\phi</span>  with Constant-Time Inversion. The Construct N&amp;D stage generates the  <span class="math">N</span>  and  <span class="math">D</span>  MLEs discussed in Section 3.3.3. Elements of six intermediate MLEs,  <span class="math">D_{1\\dots 3}</span> , and  <span class="math">N_{1\\dots 3}</span> , are computed</p>

    <p class="text-gray-300">!<a href="img-6.jpeg">img-6.jpeg</a> Figure 7: Modular inverse unit using multiple batched inverse units and a shared multiplier tree.</p>

    <p class="text-gray-300">in parallel from modular additions and multiplications of the witness  <span class="math">(w_{1\\dots 3})</span>  and wiring permutation  <span class="math">(o_{1\\dots 3})</span>  MLEs stored in on-chip SRAM, and two challenges from SHA3. These intermediate MLEs are written off-chip for the subsequent PermCheck and multiplied to obtain the  <span class="math">D</span>  and  <span class="math">N</span>  (e.g.,  <span class="math">D[i] = D_1[i]D_2[i]D_3[i])</span>  elements, and fed to the FracMLE unit.</p>

    <p class="text-gray-300">The Fraction MLE,  <span class="math">\\phi</span> , requires computing the modular inverse of every element of the Denominator MLE  <span class="math">(D^{-1})</span> , and multiplying each inverted element with the corresponding element of the Numerator MLE  <span class="math">(N)</span> . Given  <span class="math">x</span> , modular inversion outputs a  <span class="math">y</span> , such that  <span class="math">x \\cdot y \\bmod p = 1</span> . We use the constant time Binary Extended Euclidean Algorithm (BEEA) [53] for this operation to make it data-oblivious and ensure constant scheduling. The algorithm requires  <span class="math">2W - 1</span>  iterations of a loop consisting of shifts and subtractions, where  <span class="math">W</span>  is the number of input bits ( <span class="math">W = 255</span> ), resulting in a 509-cycle latency. A data-dependent implementation is faster for smaller input values, but since we are computing on random inputs (derived from SHA3 hashes), the average latency of such an implementation  <span class="math">(2(\\sum_{i=1}^{255} \\frac{255 - i}{2^i}) - 1 \\approx 505</span>  cycles) is only  <span class="math">1\\%</span>  better. In exchange for this negligible latency overhead, our constant-time implementation reduces design complexity as this ensures elements of  <span class="math">D^{-1}</span>  (and thus  <span class="math">\\phi</span> ) are generated in-order if we execute multiple inverses in parallel (as we will discuss shortly). Parallel execution of the data-dependent algorithm may output elements out-of-order and would require buffering or stalling to resolve.</p>

    <p class="text-gray-300">4.4.2 Batching for Modular Inversion. Computing modular inverses for each 255-bit MLE element is expensive, so we heavily optimize it. We leverage Montgomery batching [46] to amortize the cost of one inversion across multiple elements and improve per-inversion throughput. In the standard approach (also implemented in [11]), to compute the inverses of a batch of elements (e.g.,  <span class="math">A, B, C, D</span> ), partial products are computed sequentially (e.g.,  <span class="math">A, AB, ABC, ABCD</span> ) and the final product is inverted. This single inverse is then propagated backward to recover the individual inverses ( <span class="math">D^{-1}, C^{-1}</span> , etc.) through additional sequential multiplications. While this reduces the number of inversions, the sequential multiplications and high modular multiplication latency can limit hardware performance.</p>

    <p class="text-gray-300">We address these limitations with two modifications. First, we use a multiplier tree, detailed in Section 4.3; this significantly reduces latency and improves scaling for large values of the batch size, which we denote  <span class="math">b</span> , from  <span class="math">O(b)</span>  to  <span class="math">O(\\log_2b)</span>  multiplications. Second, we overlap the sequential multiplications for partial products with modular inversion to mask long multiplication latencies.</p>

    <p class="text-gray-300">ISCA '25, June 21-25, 2025, Tokyo, Japan</p>

    <p class="text-gray-300">Alhad Daftardar, Jianqiao Mo, Joey Ah-kiow, Benedikt Bunz, Ramesh Karri, Siddharth Garg, and Brandon Reagen</p>

    <p class="text-gray-300">!<a href="img-7.jpeg">img-7.jpeg</a> Figure 8: Latency imbalance of batched inverse unit on the left (blue) and area cost of the FracMLE unit on the right (red). Both are optimal at 64. The area includes all hardware resources needed and does not account for area savings from reuse in the overall architecture.</p>

    <p class="text-gray-300">4.4.3 Batch Inversion Architecture. Figure 7 illustrates the architecture of our modular inverse unit using batching. We use multiple batched inversion units in round-robin fashion to completely mask long inversion latencies and enable the FracMLE unit to accept one input and generate one output per cycle, behaving as a pipeline with depth  <span class="math">b \\times k</span>  where  <span class="math">k</span>  is the number of FracMLE units. We achieve this by using enough batched inverse units to mask the latency of one batch inversion. The multiplier tree and one multiplier are reused across all units to compute their inputs and produce the individual elements of  <span class="math">D^{-1}</span> , respectively. One batch inversion latency is the maximum of the parallel partial product latency and the combined multiplier tree and modular inverse latencies. The former scales  <span class="math">O(b)</span>  while the latter scales  <span class="math">O(\\log_2 b)</span> .</p>

    <p class="text-gray-300">4.4.4 Optimizing for Batch Size. We frame the choice of batch size  <span class="math">b</span>  as an optimization problem to minimize latency imbalance (between partial products and the multiplier tree and inversion) and area. As shown in Figure 8, the left y-axis plots latency imbalance, which is initially high due to the fixed cost of modular inversion. It decreases as partial product latency rises, reaching a minimum at  <span class="math">b = 64</span> , then increases again as partial-product latency begins to dominate. The right y-axis shows total area (including multiplier trees and partial products SRAM), which also reaches a minimum at  <span class="math">b = 64</span>  due to fewer required inverse units (e.g., 256 units for  <span class="math">b = 2</span>  vs. only 12 for  <span class="math">b = 64</span> ). Additionally, starting at  <span class="math">b = 64</span> , we can reuse the multiplier tree across all units since its  <span class="math">O(\\log_2 b)</span>  latency allows it to complete one batch before the next arrives. Beyond  <span class="math">b = 64</span> , partial-product latency surpasses modular inversion, and SRAM overheads continue to grow without reducing the number of inverse units—diminishing returns in both performance and area. Based on these tradeoffs, we select  <span class="math">b = 64</span>  as the optimal batch size.</p>

    <p class="text-gray-300">The MLE Combine Unit is used in the Polynomial Opening step. As mentioned in Section 3.3.5, there are several linear combinations of MLEs that are performed before OpenCheck and before the MSMs. These operations are straightforward, and use a combination of MLEs stored in on-chip SRAM and off-chip memory to construct the MLEs used in subsequent steps. Because OpenCheck happens</p>

    <p class="text-gray-300">in series with the MSMs, the respective MLE Combine operations also happen in sequence. Consequently, we can share resources between these two operations. For the design point we highlight in Table 5, without sharing, we would require 122 modular multipliers. With sharing, we require only 72, representing  <span class="math">41\\%</span>  area savings.</p>

    <p class="text-gray-300">The MLE table size scales with the number of gates, i.e., for a problem size of  <span class="math">2^{\\mu}</span>  gates, each MLE table has  <span class="math">2^{\\mu}</span>  entries. In practice, input MLEs are sparse. Control MLEs  <span class="math">q_{L}, q_{R}, q_{M}, q_{O}</span>  are all binary, and  <span class="math">q_{C}, w_{1}, w_{2}, w_{3}</span>  are roughly  <span class="math">90\\%</span>  1s and 0s and  <span class="math">10\\%</span>  full bit-width. These MLEs get reused throughout the protocol, so we store them on-chip in global SRAM. We compress the tables, packing together control MLEs and using address translation units to perform lookups to either binary or 255-bit data. These compression strategies save 10 to  <span class="math">11\\times</span>  on MLE storage across problem sizes. This also significantly reduces off-chip accesses; for example, in the Polynomial Opening step, only 2 of 13 MLE tables  <span class="math">(\\phi</span>  and  <span class="math">\\pi)</span>  are stored off-chip, cutting bandwidth usage by  <span class="math">84\\%</span> .</p>

    <p class="text-gray-300">Figure 2 provides an overview of the HyperPlonk protocol and zkSpeed architecture. Colors indicate the mapping of protocol steps (Section 3.3) to the accelerator units (Section 4) they run on. The zkSpeed architecture is streaming in nature and captures on-chip data reuse when feasible via explicitly managed scratchpad memories. The architecture has four major components: accelerator units, local and global SRAM, a multi-channel shared bus, and HBM interface. HBM is needed to feed the chip with high bandwidths needed by HyperPlonk, and we conduct bandwidth sensitivity studies in Section 7.</p>

    <p class="text-gray-300">Dataflow. HyperPlonk is data oblivious at the stage granularity. This allows zkSpeed to statically schedule computations and manage units, SRAM, and the buses via a simple controller. Further, zkSpeed uses a shared bus rather than a crossbar or NoC. This design choice was made after rigorously analyzing the HyperPlonk dataflow (see Figure 2C). We observed that at any given time, only 1-2 zkSpeed units typically communicate, and at most 4 independent bus channels are needed to avoid stalling - this is during Wire Identity where Construct N&amp;D sends results to FracMLE, FracMLE simultaneously feeds ProdMLE and MSM units, and ProdMLE streams to MSM. Units overlap computation with each other, e.g., enabling MSM to start processing partial outputs from FracMLE, effectively masking latency. Without bus stalls, we are able to rate match each accelerator unit to pipeline across modules when possible, further improving performance.</p>

    <p class="text-gray-300">zkSpeed deploys a highly banked global SRAM and two local SRAMs for FracMLE and MSM units that store data unused by other units (the FracMLE SRAM captures MLE table reuse, the MSM's SRAM reuses elliptical curve points). All other units share the global SRAM, which stores input MLEs. At the start of execution, these MLEs are prefetched from HBM and remain unchanged on-chip throughout execution. They are read at the beginning of multiple protocol steps, thereby reducing HBM pressure. zkSpeed allocates a single-channel shared bus for units to read the global SRAM since only one unit requires access at any given time. HBM access is</p>

    <p class="text-gray-300">managed by a memory controller that has dedicated point-to-point connections to each module and the global SRAM, with enough wires to a given component to accommodate the widest access needed. The controller interfaces with the HBM PHYs and arbitrates access to the HBM channels to ensure that no channel is being used more than once simultaneously (i.e., no channel conflict).</p>

    <p class="text-gray-300">zkSpeed Programmability. zkSpeed modules are programmed by instructions specifying problem sizes and configuring local controllers and address data from the buses, SRAM, and HBM. Due to the ASIC nature, much of the fine-grained control is handled by FSMs within each unit. For each HyperPlonk protocol step, each unit (e.g., bus, modules, global SRAM, and HBM controller) are configured with complex instructions and run to completion. Then next set of instructions are loaded to execute the next protocol step.</p>

    <p class="text-gray-300">HyperPlonk Trends and Outlook. Zero-Knowledge protocols are still continuously evolving and improving in several aspects. However, zkSpeed, with its focus on HyperPlonk, still has significant stability. Firstly, HyperPlonk has seen adoption both in industry implementations <em>(17; 74)</em> and academic research <em>(17; 18; 34)</em>. In addition, our design is modular, and the key components of HyperPlonk SumChecks, MSMs, and MLEs, are present in essentially any modern SNARK protocol <em>(9; 25; 35; 59; 60; 64)</em>. Therefore, zkSpeed can also be targeted to new protocols so long as they comprise the fabricated modules, including proof composition methods <em>(66)</em> that seek to compose protocols like Orion and HyperPlonk.</p>

    <h2 id="sec-29" class="text-2xl font-bold">6. Methodology</h2>

    <h3 id="sec-30" class="text-xl font-semibold mt-8">6.1. Performance Modeling</h3>

    <p class="text-gray-300">SumCheck has a fixed, data-oblivious dataflow, which allows us to model its performance analytically. Modules that feed into the SumCheck units are also data-oblivious and are modeled similarly, accounting for rate-matching assumptions. For the MSM, we use a cycle-accurate simulator to model performance. Each unit within zkSpeed is modularized. To understand full-chip performance, we conduct a design space exploration of all combinations of design parameters detailed in Table 2 and then analyze the pareto-optimal space to pick a suitable configuration for profiling runtimes. We also construct power traces to estimate average power for the full-chip architecture. We use Catapult HLS 2023 to generate the RTL for Montgomery multipliers (as done in prior work <em>(14)</em>), the fully-pipelined, unified SumCheck unit (to handle ZeroCheck, PermCheck, and OpenCheck), and the fully-pipelined PADD unit. Consistent with HyperPlonk, we use the BLS12-381 elliptical curve, where all MLE datatypes (e.g., in the SumCheck unit) are 255-bit, and all elliptic curve points (e.g., in the PADD) are 381-bit. Using Design Compiler with TSMC 22nm, we find the critical path in our design is the 381-bit PADD unit at 1.05ns. We use Synopsys 22nm Memory Compiler to generate SRAM estimates. For SHA3, we use the IP block from OpenCores <em>(51)</em>. We scale down to 7nm using scale factors of 3.6<span class="math">\\times</span> for area, 3.3<span class="math">\\times</span> for power, and 1.7<span class="math">\\times</span> for delay (as in prior work <em>(14)</em>), and clock all zkSpeed accelerators at 1 GHz.</p>

    <h3 id="sec-31" class="text-xl font-semibold mt-8">6.2. Benchmarks</h3>

    <p class="text-gray-300">HyperPlonk was evaluated using mock circuit workloads <em>(11)</em>, as there is no publicly available compiler to generate real workloads. We similarly use synthetically generated workloads to model the performance of our architecture, which is standard for ZKP benchmarks, as performance primarily depends on the size of the workload. Similarly, GZKP <em>(41)</em> uses synthetic workloads to benchmark their implementation for workload sizes of <span class="math">2^{22}</span> and higher. NoCap <em>(57)</em> uses workloads from libsnark <em>(1)</em> that prove relatively small circuits and scales them up to larger problem sizes because their proving times are dominated by fixed overheads on smaller ZKP circuits. In the context of HyperPlonk, workload statistics primarily affect the witness commit (Sparse MSM) step. The scalar distributions of the MSMs in the Wiring Identity and Polynomial Opening are random because they are constructed in part from SHA3 challenges. Therefore, while all MSMs are data-dependent, the overall runtimes are effectively workload-agnostic and roughly the same at iso-problem size. All other steps in HyperPlonk are data-oblivious. From prior work <em>(1; 14; 41; 73)</em>, we know that in Sparse MSMs, the scalars are typically 5-10% dense (i.e., full bit-width), and 95-99% sparse. Since the dense components of Sparse MSMs are still runtime dominant, we assume a pessimistic upper bound of 10% dense scalars and 90% sparse scalars, of which 45% are 1s and 45% are 0s. The rest of the protocol steps operate on 100% dense scalars/MLE values. In our evaluation, we use five workloads from prior work <em>(1; 11)</em>, and show our results in Table 3.</p>

    <h2 id="sec-32" class="text-2xl font-bold">7. Evaluation</h2>

    <h3 id="sec-33" class="text-xl font-semibold mt-8">7.1. Pareto Space Analysis</h3>

    <p class="text-gray-300">Figure 9 shows the design space for a problem size of <span class="math">2^{20}</span> gates under seven bandwidth scenarios. We sweep all the parameters in Table 2 and obtain Pareto curves for each bandwidth individually, and then construct the global Pareto curve from these seven local Pareto curves. The key highlight from this plot is that HBM3-scale bandwidths (e.g., 1-4 TB/s <em>(2)</em>) do yield significant performance gains over, e.g., an HBM2-scale bandwidth (0.5 TB/s <em>(28)</em>). Beyond 300 mm^{2}, the globally Pareto-optimal design configurations yield over 2<span class="math">\\times</span> speedups compared to 512 GB/s designs and over 700<span class="math">\\times</span> speedups over the CPU baseline. This is because high-performance SumCheck designs quickly saturate 512 GB/s of bandwidth. In this analysis, we also include the cost of HBM PHYs <em>(20; 28; 31; 32; 33; 43; 55; 56; 57)</em> where the PHY cost is 14.9 mm^{2} for a single HBM2 PHY and 29.6 mm^{2} for a single HBM3 PHY. For low-performance designs (below 100mm^{2}), high-bandwidth memory becomes less effective, as these designs tend to underutilize the available bandwidth while still incurring the high PHY area overhead associated with HBM-scale memory. Figure 9 shows that zkSpeed remains viable even at bandwidths typical of DDR5 <em>(58)</em> (256 GB/s and below). While HBM allows exploring scalability benefits, less expensive memory technologies can be used to achieve Pareto-optimality within a target performance range (e.g., within 50 ms).</p>

    <p class="text-gray-300">We analyze the area and runtime of selected points on the Pareto curve in Figure 10 to further understand bandwidth sensitivity. We pick Pareto points representing the highest-performing design point for each bandwidth level. In the area breakdown, moving from low to high-performance design points (A to D), the proportion of the SumCheck area increases significantly, because SumCheck is bandwidth-intensive, and higher bandwidth allows more parallel SumCheck PEs, boosting throughput. The MSM unit accounts for</p>

    <p class="text-gray-300">ISCA '25, June 21-25, 2025, Tokyo, Japan</p>

    <p class="text-gray-300">Alhad Daftardar, Jianqiao Mo, Joey Ah-kiow, Benedikt Bunz, Ramesh Karri, Siddharth Garg, and Brandon Reagen</p>

    <p class="text-gray-300">!<a href="img-8.jpeg">img-8.jpeg</a> Figure 9: Pareto Frontiers for  <span class="math">2^{20}</span>  Gates. We plot the individual Pareto curves for each bandwidth model and the globally optimal Pareto curve (for designs under 50ms) in the inset.</p>

    <p class="text-gray-300">!<a href="img-9.jpeg">img-9.jpeg</a> Figure 10: Area (left, top legend) and runtime (right, bottom legend) breakdown for the chosen Pareto points in Figure 9.</p>

    <p class="text-gray-300">Table 2: Design Space of zkSpeed Architecture.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Module</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Design Knob</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Values</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">MSM</td>

            <td class="px-3 py-2 border-b border-gray-700">Cores</td>

            <td class="px-3 py-2 border-b border-gray-700">1, 2</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">MSM</td>

            <td class="px-3 py-2 border-b border-gray-700">PEs per Core</td>

            <td class="px-3 py-2 border-b border-gray-700">1, 2, 4, 8, 16</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">MSM</td>

            <td class="px-3 py-2 border-b border-gray-700">Window Size</td>

            <td class="px-3 py-2 border-b border-gray-700">7, 8, 9, 10</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">MSM</td>

            <td class="px-3 py-2 border-b border-gray-700">Points/PE</td>

            <td class="px-3 py-2 border-b border-gray-700">1K, 2K, 4K, 8K, 16K</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">FracMLE</td>

            <td class="px-3 py-2 border-b border-gray-700">PEs</td>

            <td class="px-3 py-2 border-b border-gray-700">1, 2, 4</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">SumCheck</td>

            <td class="px-3 py-2 border-b border-gray-700">PEs</td>

            <td class="px-3 py-2 border-b border-gray-700">1, 2, 4, 8, 16</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">MLE Update</td>

            <td class="px-3 py-2 border-b border-gray-700">PEs</td>

            <td class="px-3 py-2 border-b border-gray-700">1, 2, ..., 11</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">MLE Update</td>

            <td class="px-3 py-2 border-b border-gray-700">Modmuls/PE</td>

            <td class="px-3 py-2 border-b border-gray-700">1, 2, 4, 8, 16</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Memory</td>

            <td class="px-3 py-2 border-b border-gray-700">Bandwidth (GB/s)</td>

            <td class="px-3 py-2 border-b border-gray-700">64, 128, 256, 512, 1T, 2T, 4T</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">a large portion of the total area, but its absolute area remains unchanged when switching to high performance. This trend is also evident in the runtime breakdown: total runtime decreases as bandwidth increases, and the runtime contributions of the SumCheck-related processes (ZeroCheck, PermCheck, and OpenCheck) become smaller. Our analysis of the Pareto design points shows that high performance significantly depends on sufficient bandwidth, particularly improving the SumCheck computation. Conversely, for low-performance designs, the system utilizes less bandwidth and allocates more resources to MSM computation.</p>

    <p class="text-gray-300">!<a href="img-10.jpeg">img-10.jpeg</a> Figure 11: Performance scaling with different memory technologies and PEs for MSM and SumCheck. Speedup normalized to 1 PE at 512 GB/s.</p>

    <p class="text-gray-300">Figure 11 shows how the speedups for MSM-related computation and SumCheck-related computation scale with increased PE count and bandwidth. These are two runtime-dominant components in our design points shown in Figure 10. We take the runtime of all MSM and SumCheck operations for 1 PE under 512 GB/s, and compute respective speedups to these numbers. Because MSMs are compute-bound, adding compute resources improves the speedups significantly, while adding bandwidth does not. We do not see perfectly linear speedup because of the serialization incurred in Polynomial Opening MSMs. SumChecks, which rely on a streaming-based approach, are memory-bound. As we add compute, we see linear speedups initially and then diminishing returns after saturating bandwidth. Consequently, in our Pareto-optimal design space, we see most points along the curve outside high-performance regimes use at most 2 SumCheck PEs compared to 8 or 16 MSM PEs.</p>

    <p class="text-gray-300">Our CPU is an AMD EPYC 7502 32-core processor [6, 14, 47, 63]. The total die size is  <span class="math">296\\mathrm{mm}^2</span> . We sweep the problem sizes, and for each problem size, pick a Pareto-optimal design point that is close to  <span class="math">296\\mathrm{mm}^2</span> . In these comparisons, we exclude the PHY cost, since the AMD EPYC processor has its own separate die for I/O [48]. Therefore, we compare our total compute and on-chip memory area with the CPU's total core area, including on-chip caches. We assume 2 TB/s HBM to achieve Pareto-optimality in Figure 9.</p>

    <p class="text-gray-300">7.3.1 Runtime Breakdown and Utilization. Figure 12 shows the latency breakdown of HyperPlonk proving on a CPU and a pareto-optimal zkSpeed design for a problem size of  <span class="math">2^{20}</span>  gates. The CPU executes kernels sequentially, enabling detailed profiling; we report step latency for zkSpeed due to its parallel scheduling of kernels. As expected, the majority of time goes to processing MSMs, while a handful of other kernels account for single percentage points of runtime. Figure 13 presents the utilization of each unit and relative (datapath) area allocation (design in Table 5). The utilizations vary from over  <span class="math">70\\%</span>  to  <span class="math">5\\%</span>  for some modules. zkSpeed was intentionally designed (via the design space search in Figure 9) to allocate resources to cores to optimize high performance per area, i.e. the Pareto front. This can be seen in our analysis in two ways. First, the cores taking up most area, notably MSM at  <span class="math">64.6\\%</span> , are the most used, and following the profiling data (Figure 12) require the most speedup. Second, though some units are used infrequently, they</p>

    <p class="text-gray-300">Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs</p>

    <p class="text-gray-300">ISCA '25, June 21-25, 2025, Tokyo, Japan</p>

    <p class="text-gray-300">!<a href="img-11.jpeg">img-11.jpeg</a> Figure 12: Runtime breakdown for CPU and zkSpeed at  <span class="math">2^{20}</span>  gates. CPU's sequential kernel execution enables finer breakdowns; aggregate step times are presented for zkSpeed.</p>

    <p class="text-gray-300">!<a href="img-12.jpeg">img-12.jpeg</a></p>

    <p class="text-gray-300">!<a href="img-13.jpeg">img-13.jpeg</a> Figure 13: Utilization of zkSpeed modules, with compute area utilization (AU) listed on top of each bar. Stacked bar colors reflect the protocol steps in which each module is active.</p>

    <p class="text-gray-300">(i) take up little area and (ii) are essential to accelerate to achieve the speedups desired (i.e., 2-3 orders of magnitude). For example, the SHA-3 unit is rarely used, but provides a speedup of over  <span class="math">300 \\times</span>  over the CPU and takes only  <span class="math">5888\\mu m^2</span>  area. Additionally, consider that MLE Combine makes up  <span class="math">3.3\\%</span>  of the CPU runtime, but without acceleration caps speedup to a mere  <span class="math">30.3 \\times</span> , thus justifying its  <span class="math">5.85\\%</span>  area allocation and relatively low utilization.</p>

    <p class="text-gray-300">7.3.2 Iso-CPU Area Comparisons. After picking each Pareto-optimal design, we run synthetic benchmarks over problem sizes  <span class="math">2^{17} - 2^{23}</span> . Figure 14 shows the speedup of each design over CPU baseline, and the breakdown across different steps of the protocol to understand where our speedups come from. In general, we get more speedup from our MSM units than the SumCheck units. This intuitively follows, given our observations that MSMs are compute-bound and more robust to bandwidth constraints. Additionally, the CPU poorly handles sparse computations because it serially computes the point addition for 1-valued scalars. Polynomial Opening MSMs also incur serialization costs that we reduce by overlapping MSM executions where possible. The variations in speedups over different problem sizes are an artifact of our choice to highlight different Pareto points per problem size; for example, at  <span class="math">2^{20}</span>  size problems, a dual-core MSM is used, while at  <span class="math">2^{22}</span>  size a single-core MSM is chosen. This is because on-chip MLE SRAM area begins to dominate, limiting MSM compute area and therefore achievable speedup. Storing MLE tables entirely off-chip may improve MSM speedups at higher SumCheck bandwidth costs. These tradeoffs can be explored in future work.</p>

    <p class="text-gray-300">!<a href="img-14.jpeg">img-14.jpeg</a> Figure 14: Speedup over CPU at Iso-CPU Area Designs. Each problem size has a different Pareto-optimal point. Each bar reflects absolute speedup, while the annotated speedup is the gmean computed across gate counts for each kernel.</p>

    <p class="text-gray-300">Table 3: zkSpeed evaluation on real-world workloads.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Workload</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Problem Size</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Runtime (ms)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">CPU</td>

            <td class="px-3 py-2 border-b border-gray-700">zkSpeed</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Zcash</td>

            <td class="px-3 py-2 border-b border-gray-700">217</td>

            <td class="px-3 py-2 border-b border-gray-700">1429</td>

            <td class="px-3 py-2 border-b border-gray-700">1.984 (720×)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Auction</td>

            <td class="px-3 py-2 border-b border-gray-700">220</td>

            <td class="px-3 py-2 border-b border-gray-700">8619</td>

            <td class="px-3 py-2 border-b border-gray-700">11.405 (755×)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">212 Rescue-Hash Invocations</td>

            <td class="px-3 py-2 border-b border-gray-700">221</td>

            <td class="px-3 py-2 border-b border-gray-700">18637</td>

            <td class="px-3 py-2 border-b border-gray-700">22.082 (844×)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Zexe's Recursive Circuit</td>

            <td class="px-3 py-2 border-b border-gray-700">222</td>

            <td class="px-3 py-2 border-b border-gray-700">37469</td>

            <td class="px-3 py-2 border-b border-gray-700">43.451 (862×)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Rollup of 10 Pvt Tx</td>

            <td class="px-3 py-2 border-b border-gray-700">223</td>

            <td class="px-3 py-2 border-b border-gray-700">74052</td>

            <td class="px-3 py-2 border-b border-gray-700">86.181 (859×)</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Table 4: Comparison of zkSpeed with Prior ZKP Accelerators on  <span class="math">2^{24}</span>  Constraints/Gates. N = NTT, S = SumCheck, M = MSM</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Accelerator</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">NoCap</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">SZKP+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">zkSpeed</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Protocol</td>

            <td class="px-3 py-2 border-b border-gray-700">Spartan+Orion</td>

            <td class="px-3 py-2 border-b border-gray-700">Groth16</td>

            <td class="px-3 py-2 border-b border-gray-700">HyperPlonk</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Main Kernels</td>

            <td class="px-3 py-2 border-b border-gray-700">N & S</td>

            <td class="px-3 py-2 border-b border-gray-700">N & M</td>

            <td class="px-3 py-2 border-b border-gray-700">S & M</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Encoding</td>

            <td class="px-3 py-2 border-b border-gray-700">R1CS</td>

            <td class="px-3 py-2 border-b border-gray-700">R1CS</td>

            <td class="px-3 py-2 border-b border-gray-700">Plonk</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Proof Size</td>

            <td class="px-3 py-2 border-b border-gray-700">8.1 MB</td>

            <td class="px-3 py-2 border-b border-gray-700">0.18 KB</td>

            <td class="px-3 py-2 border-b border-gray-700">5.09 KB</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Setup</td>

            <td class="px-3 py-2 border-b border-gray-700">none</td>

            <td class="px-3 py-2 border-b border-gray-700">circuit-specific</td>

            <td class="px-3 py-2 border-b border-gray-700">universal</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Prime</td>

            <td class="px-3 py-2 border-b border-gray-700">fixed</td>

            <td class="px-3 py-2 border-b border-gray-700">arbitrary</td>

            <td class="px-3 py-2 border-b border-gray-700">arbitrary</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Bit-width</td>

            <td class="px-3 py-2 border-b border-gray-700">64</td>

            <td class="px-3 py-2 border-b border-gray-700">255b/381b</td>

            <td class="px-3 py-2 border-b border-gray-700">255b/381b</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">CPU Prover (s)</td>

            <td class="px-3 py-2 border-b border-gray-700">94.2</td>

            <td class="px-3 py-2 border-b border-gray-700">51.18</td>

            <td class="px-3 py-2 border-b border-gray-700">145.5</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">HW Prover (ms)</td>

            <td class="px-3 py-2 border-b border-gray-700">151.3</td>

            <td class="px-3 py-2 border-b border-gray-700">28.43</td>

            <td class="px-3 py-2 border-b border-gray-700">171.61</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Verifier (ms)</td>

            <td class="px-3 py-2 border-b border-gray-700">134</td>

            <td class="px-3 py-2 border-b border-gray-700">4.2</td>

            <td class="px-3 py-2 border-b border-gray-700">26</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Chip Area (mm2)</td>

            <td class="px-3 py-2 border-b border-gray-700">38.73</td>

            <td class="px-3 py-2 border-b border-gray-700">353.2</td>

            <td class="px-3 py-2 border-b border-gray-700">366.46</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"># Modmuls</td>

            <td class="px-3 py-2 border-b border-gray-700">2432</td>

            <td class="px-3 py-2 border-b border-gray-700">1720</td>

            <td class="px-3 py-2 border-b border-gray-700">1206</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Modmul (mm2)</td>

            <td class="px-3 py-2 border-b border-gray-700">0.002</td>

            <td class="px-3 py-2 border-b border-gray-700">0.133 / 0.314</td>

            <td class="px-3 py-2 border-b border-gray-700">0.133 / 0.314</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Power (W)</td>

            <td class="px-3 py-2 border-b border-gray-700">62</td>

            <td class="px-3 py-2 border-b border-gray-700">>220 W</td>

            <td class="px-3 py-2 border-b border-gray-700">170.88</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We pick a fixed design and show the end-to-end speedups in Table 3. As mentioned in Section 6.2, we assume pessimistic  <span class="math">10\\%</span>  sparse scalar statistics for each workload. Our design has one MSM unit with 9-bit windows, 16 PEs, and 2048 points per PE, with 1 FracMLE PE, 2 SumCheck PEs, 11 MLE Update PEs, and 4 modular multipliers per MLE Update PE. The area breakdown is provided in Table 5. At roughly iso-CPU-core compute cost, zkSpeed achieves a geometric mean speedup of  <span class="math">801\\times</span>  over the CPU, with total area of  <span class="math">366.46~\\mathrm{mm}^2</span> , total average power of  <span class="math">170.88\\mathrm{W}</span> , and total power density of 0.46  <span class="math">\\mathrm{W / mm}^2</span> , which is within that of our CPU [14].</p>

    <p class="text-gray-300">ISCA '25, June 21-25, 2025, Tokyo, Japan</p>

    <p class="text-gray-300">Alhad Daftardar, Jianqiao Mo, Joey Ah-kiow, Benedikt Bunz, Ramesh Karri, Siddharth Garg, and Brandon Reagen</p>

    <p class="text-gray-300">Table 5: Area and power of zkSpeed. Other includes the SHA3 unit and interconnect.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Module</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Area (mm2)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Average Power (W)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">MSM (16 PEs)</td>

            <td class="px-3 py-2 border-b border-gray-700">105.64</td>

            <td class="px-3 py-2 border-b border-gray-700">76.19</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">SumCheck (2 PEs)</td>

            <td class="px-3 py-2 border-b border-gray-700">24.96</td>

            <td class="px-3 py-2 border-b border-gray-700">5.38</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Construct N&D</td>

            <td class="px-3 py-2 border-b border-gray-700">1.35</td>

            <td class="px-3 py-2 border-b border-gray-700">0.19</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">FracMLE</td>

            <td class="px-3 py-2 border-b border-gray-700">1.92</td>

            <td class="px-3 py-2 border-b border-gray-700">0.25</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">MLE Combine</td>

            <td class="px-3 py-2 border-b border-gray-700">9.56</td>

            <td class="px-3 py-2 border-b border-gray-700">0.34</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">MLE Update</td>

            <td class="px-3 py-2 border-b border-gray-700">5.84</td>

            <td class="px-3 py-2 border-b border-gray-700">1.13</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Multifunction Tree</td>

            <td class="px-3 py-2 border-b border-gray-700">12.28</td>

            <td class="px-3 py-2 border-b border-gray-700">4.16</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Other</td>

            <td class="px-3 py-2 border-b border-gray-700">1.98</td>

            <td class="px-3 py-2 border-b border-gray-700">0.04</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Total Compute</td>

            <td class="px-3 py-2 border-b border-gray-700">163.53</td>

            <td class="px-3 py-2 border-b border-gray-700">87.68</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">SRAM</td>

            <td class="px-3 py-2 border-b border-gray-700">143.73</td>

            <td class="px-3 py-2 border-b border-gray-700">19.60</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">HBM3 (2 PHYs)</td>

            <td class="px-3 py-2 border-b border-gray-700">59.20</td>

            <td class="px-3 py-2 border-b border-gray-700">63.60</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Total Memory</td>

            <td class="px-3 py-2 border-b border-gray-700">202.93</td>

            <td class="px-3 py-2 border-b border-gray-700">83.20</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Total</td>

            <td class="px-3 py-2 border-b border-gray-700">366.46</td>

            <td class="px-3 py-2 border-b border-gray-700">170.88</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Much of the prior body of cryptographic hardware and systems research has focused on Fully Homomorphic Encryption and MultiParty Computation [19, 23, 29, 31-33, 43, 49, 55, 56, 62]. ZKP hardware research is relatively newer, and has focused primarily on accelerating NTTs and MSMs [10, 12, 27, 30, 36-38, 40, 54, 67, 68, 71, 72, 75, 76]. A few works have accelerated SumChecks on GPU [39] and ASIC [57] as well as hashing alternatives to SHA-based hash functions [5, 61, 68]. Some systems accelerate end-to-end Groth16 proofs (using NTTs and MSMs) on GPU [41] and ASICs [14, 73], while others accelerate Spartan proofs with Orion commitments (using NTTs and SumChecks) [57]. We compare zkSpeed with two ASICs, SZKP and NoCap, that accelerate full proofs end-to-end.</p>

    <p class="text-gray-300">SZKP is the state-of-the-art for accelerating Groth16 proofs, focusing on scalable MSM designs and (quasi)-deterministic scheduling for Pippenger's algorithm. It accelerates all MSMs, including Sparse G2 MSMs (not present in HyperPlonk), achieving geomean speedups of  <span class="math">493 \\times</span>  over a CPU. SZKP improves on PipeZK [73], the first hardware accelerator for Groth16 proofs. While Groth16 and HyperPlonk have similar application spaces, as mentioned in Section 1, the key advantage of using HyperPlonk is the universal setup, which means that the protocol parameters are application-agnostic. For Groth16, every new application that wants to use a ZKP needs its own trusted setup ceremony [3], which is impractical as the application space grows. Given this context and the recent shift away from Groth16 [50], the slightly larger proof sizes are considered a reasonable tradeoff.</p>

    <p class="text-gray-300">NoCap is a vector-based processor for accelerating Spartan+Orion proofs, but its application space differs from zkSpeed's. NoCap thrives in applications where proof size is not critical, or there are few verifiers. It achieves  <span class="math">41 \\times</span>  geomean speedups over PipeZK. In contrast, zkSpeed is ideal for many verifiers and in consensus-based systems; this is where ZKPs are experiencing growing interest.</p>

    <p class="text-gray-300">Comparison: Table 4 compares zkSpeed, NoCap, and SZKP's protocols, software, and hardware costs. zkSpeed's parent HyperPlonk has the slowest software prover, reflecting the complexity of the protocol. Of note, Spartan's prover is slow; NoCap's authors explain this is due to inefficient implementation.</p>

    <p class="text-gray-300">We compare NoCap's hardware implementation using the design point and numbers from their paper scaled to  <span class="math">7\\mathrm{nm}</span>  using scale factors from prior work [14, 43]. We then select a zkSpeed configuration with roughly similar prover time to NoCap. At iso-prover time, zkSpeed incurs a nearly  <span class="math">10\\times</span>  area cost in return for a three orders-of-magnitude reduction in proof size. NoCap's lower costs come from not having MSMs, having simpler SumChecks, and using a 64-bit Goldilocks-64 prime field that yields smaller modmuls. Consequently, NoCap runs all operations several times, including SumChecks 3 times, to obtain 128 bits of security. In contrast, zkSpeed supports arbitrary 255-bit and 381-bit primes for MLEs and elliptic curves points, respectively. We further compare zkSpeed with an iso-area SZKP (Groth16) implementation, giving them the benefit of zkSpeed's improved MSMs, and optimistically scale up their design to use the BLS12-381 curve. This design, SZKP+, enjoys a  <span class="math">6\\times</span>  reduction in proving time compared to zkSpeed, largely because it has fewer MSMs on its critical path. These speedups come at the cost of circuit-specific setup, incurring large costs any time the application is updated. In sum, NoCap, SZKP, and zkSpeed address different application domains, representing a range of tradeoffs ranging from security properties to software/hardware costs.</p>

    <p class="text-gray-300">Jellyfish: Jellyfish is a HyperPlonk variant supporting gates of arity (fan-in) higher than 2. Unlike R1CS, it supports higher degree constraints, e.g.  <span class="math">x^{7} = y^{5} + y^{2} + 7</span> . The additional expressiveness means, iso-application, the total size of all MLE tables decreases (the number of tables increases with arity, but table size decreases superproportionally). High-degree gates have utility in many applications [16]; this is especially pronounced when proving the correctness of cryptographic operations like encryption [70] or hash-functions [24]. zkSpeed could be extended to support Jellyfish, in which case the ratio of table count to table size may improve the runtime (with sufficient bandwidth). We leave this for future work.</p>

    <p class="text-gray-300">This paper presents zkSpeed, the first work to accelerate HyperPlonk proofs in hardware, which offers  <span class="math">O(n)</span>  time complexity compared to prominent zkSNARKs that rely on computational primitives that have  <span class="math">O(n\\log n)</span>  complexity (e.g. Groth16). zkSpeed constitutes accelerator units for all core HyperPlonk functions, with special attention paid to prominent kernels: SumCheck and MSM. zkSpeed is a modular architecture, and we leverage a performance model to conduct design space optimization, and analyze the pareto frontier to identify well performing designs. A zkSpeed accelerator with  <span class="math">366\\mathrm{mm}^2</span>  and 2 TB/s of bandwidth achieves geomean speedup of  <span class="math">801\\times</span>  over CPU baselines, demonstrating the promise zkSpeed offers to accelerate HyperPlonk.</p>

    <p class="text-gray-300">This research was developed with funding in part from the NSF CAREER award #2340137, an NSF RINGS Award, from DARPA under the Data Protection in Virtual Environments (DPRIVE) program, grant number HR0011-21-9-0003, and the Hybrid Electromagnetic side-channel and Interactive-proof Methods to Detect and Amend Logical. Rifts (HEIMDALLR) programs, grant number HR0011-25-C-0300, and from a gift award from Google.</p>

    <p class="text-gray-300">Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs</p>

    <p class="text-gray-300">ISCA '25, June 21-25, 2025, Tokyo, Japan</p>

    <p class="text-gray-300">[1] 2018. libsnark: a C++ library for zkSNARK proofs. https://github.com/scipr-lab/libsnark [2] 2023. High Bandwidth Memory DRAM (HBM3). Technical Report JESD238A. JEDEC. https://www.jedec.org/standards-documents/docs/jesd238a. [3] 2023. What is the ZCash Ceremony? The Complete Beginners Guide. https://coinbureau.com/education/zcash-ceremony/. [4] Kasra Abbaszadeh, Christodoulos Pappas, Jonathan Katz, and Dimitrios Papadopoulos. 2024. Zero-Knowledge Proofs of Training for Deep Neural Networks. In Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security (Salt Lake City, UT, USA) (CCS '24). Association for Computing Machinery, New York, NY, USA, 4316-4330. https://doi.org/10.1145/3658644.3670316 [5] Anees Ahmed, Nojan Sheybani, Davi Moreno, Nges Brian Njungle, Tengkai Gong, Michel Kinsy, and Farinaz Koushanfar. 2024. AMAZE: Accelerated MiMC Hardware Architecture for Zero-Knowledge Applications on the Edge. arXiv:2411.06350 [cs.CR] https://arxiv.org/abs/2411.06350 Accepted to ICCAD 2024. [6] Product AMD. 2024. Server Processor Specifications. https://www.amd.com/en/products/specifications/server-processor. [7] Eli Ben-Sasson, Alessandro Chiesa, Christina Garman, Matthew Green, Ian Miers, Eran Tromer, and Madars Virza. 2014. Zerocash: Decentralized Anonymous Payments from Bitcoin. In 2014 IEEE Symposium on Security and Privacy, SP 2014, Berkeley, CA, USA, May 18-21, 2014. IEEE Computer Society, 459-474. https://doi.org/10.1109/SP.2014.36 [8] Jean-Paul Berrut and Lloyd N Trefethen. 2004. Barycentric lagrange interpolation. SIAM review 46, 3 (2004), 501-517. [9] Benedikt Bunz and Binyi Chen. 2023. Protostar: Generic Efficient Accumulation/Folding for Special-Sound Protocols. In Advances in Cryptology - ASIACRPT 2023 - 29th International Conference on the Theory and Application of Cryptology and Information Security, Guangzhou, China, December 4-8, 2023, Proceedings, Part II (Lecture Notes in Computer Science, Vol. 14439), Jian Guo and Ron Steinfeld (Eds.). Springer, 77-110. https://doi.org/10.1007/978-981-99-8724-5_3 [10] Shahzad Ahmad Butt, Benjamin Reynolds, Veeraraghavan Ramamurthy, Xiao Xiao, Pohrong Chu, Setareh Sharifian, Sergey Gribok, and Bogdan Pasca. 2024. if-ZKP: Intel FPGA-Based Acceleration of Zero Knowledge Proofs. arXiv:2412.12481 [cs.AR] https://arxiv.org/abs/2412.12481 [11] Binyi Chen, Benedikt Bunz, Dan Boneh, and Zhenfei Zhang. 2022. HyperPlonk: Plonk with Linear-Time Prover and High-Degree Custom Gates. Cryptology ePrint Archive, Paper 2022/1355. https://eprint.iacr.org/2022/1355 [12] Xiangren Chen, Bohan Yang, Wenping Zhu, Hanning Wang, Qichao Tao, Shuying Yin, Min Zhu, Shaojun Wei, and Leibo Liu. 2024. A High-performance NTT/MSM Accelerator for Zero-knowledge Proof Using Load-Subjacent Fully-pipelined Montgomery Multiplier. IACR Transactions on Cryptographic Hardware and Embedded Systems 2025, 1 (Dec. 2024), 275-313. https://doi.org/10.46586/tches.v2025.i1.275-313 [13] Ilaria Chillotti, Nicolas Gama, Mariya Georgieva, and Malika Izabachene. 2020. TFHE: fast fully homomorphic encryption over the torus. Journal of Cryptology 33, 1 (2020), 34-91. [14] Alhad Daftardar, Brandon Reagen, and Siddharth Garg. 2024. SZKP: A Scalable Accelerator Architecture for Zero-Knowledge Proofs. In Proceedings of the 2024 International Conference on Parallel Architectures and Compilation Techniques. 271-283. [15] Leo de Castro, Rashmi Agrawal, Rabia Yazicigil, Anantha Chandrakasan, Vinod Vaikuntanathan, Chiraag Juvekar, and Ajay Joshi. 2021. Does Fully Homomorphic Encryption Need Compute Acceleration? Cryptology ePrint Archive, Paper 2021/1636. https://eprint.iacr.org/2021/1636 [16] Michel Dellepere, Pratyush Mishra, and Alireza Shirzad. 2024. Garuda and Pari: Faster and Smaller SNARKs via Equefficient Polynomial Commitments. Cryptology ePrint Archive, Paper 2024/1245. https://eprint.iacr.org/2024/1245 [17] Benjamin E. Diamond and Jim Posen. 2023. Succinct Arguments over Towers of Binary Fields. Cryptology ePrint Archive, Paper 2023/1784. https://eprint.iacr.org/2023/1784 [18] Benjamin E. Diamond and Jim Posen. 2024. Polylogarithmic Proofs for Multilinears over Binary Towers. IACR Cryptol. ePrint Arch. (2024), 504. https://eprint.iacr.org/2024/504 [19] Austin Ebel, Karthik Garimella, and Brandon Reagen. 2025. Orion: A Fully Homomorphic Encryption Framework for Deep Learning. In Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (Rotterdam, Netherlands) (ASPLOS '25). Association for Computing Machinery, New York, NY, USA, 734-749. https://doi.org/10.1145/3676641.3716008 [20] Austin Ebel and Brandon Reagen. 2024. Osiris: A Systolic Approach to Accelerating Fully Homomorphic Encryption. arXiv:2408.09593 [cs.CR] https://arxiv.org/abs/2408.09593 [21] Boysan Feng, Zheng Wang, Yuke Wang, Shu Yang, and Yufei Ding. 2024. ZENO: A Type-based Optimization Framework for Zero Knowledge Neural Network</p>

    <p class="text-gray-300">Inference. In Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1 (La Jolla, CA, USA) (ASPLOS '24). Association for Computing Machinery, New York, NY, USA, 450-464. https://doi.org/10.1145/3617232.3624852 [22] Ariel Gabizon, Zachary J. Williamson, and Oana Ciobotaru. 2019. PLONK: Permutations over Lagrange-bases for Oecumenical Noninteractive arguments of Knowledge. Cryptology ePrint Archive, Paper 2019/953. https://eprint.iacr.org/2019/953 [23] Karthik Garimella, Zahra Ghodsi, Nandan Kumar Jha, Siddharth Garg, and Brandon Reagen. 2023. Characterizing and Optimizing End-to-End Systems for Private Inference. In Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3 (Vancouver, BC, Canada) (ASPLOS 2023). Association for Computing Machinery, New York, NY, USA, 89–104. https://doi.org/10.1145/3582016.3582065 [24] Lorenzo Grassi, Dmitry Khovratovich, Christian Rechberger, Arnab Roy, and Markus Schoenegger. 2019. Poseidon: A New Hash Function for Zero-Knowledge Proof Systems. Cryptology ePrint Archive, Paper 2019/458. https://eprint.iacr.org/2019/458 [25] Jens Groth. 2016. On the Size of Pairing-based Non-interactive Arguments. Cryptology ePrint Archive, Paper 2016/260. https://eprint.iacr.org/2016/260 https://eprint.iacr.org/2016/260. [26] Jens Groth, Markulf Kohlweiss, Mary Maller, Sarah Meiklejohn, and Ian Miers. 2018. Updatable and Universal Common Reference Strings with Applications to zk-SNARKs. In Advances in Cryptology - CRYPTO 2018 - 38th Annual International Cryptology Conference, Santa Barbara, CA, USA, August 19-23, 2018, Proceedings, Part III (Lecture Notes in Computer Science, Vol. 10993), Hovav Shacham and Alexandra Boldyreva (Eds.). Springer, 698-728. https://doi.org/10.1007/978-3-319-96878-0_24 [27] Florian Hirner, Florian Krieger, and Sujoy Sinha Roy. 2025. Chiplet-Based Techniques for Scalable and Memory-Aware Multi-Scalar Multiplication. Cryptology ePrint Archive, Paper 2025/252. https://eprint.iacr.org/2025/252 [28] Rambus Inc. 2020. White Paper: HBM2E and GDDR6: Memory Solutions for AI. White Paper. [29] Nandan Kumar Jha and Brandon Reagen. 2024. DeepReShape: Redesigning Neural Networks for Efficient Private Inference. Transactions on Machine Learning Research (TMLR) (2024). [30] Zhuoran Ji, Zhiyuan Zhang, Jiming Xu, and Lei Ju. 2024. Accelerating Multi-Scalar Multiplication for Efficient Zero Knowledge Proofs with Multi-GPU Systems. In Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3 (La Jolla, CA, USA) (ASPLOS '24). Association for Computing Machinery, New York, NY, USA, 57-70. https://doi.org/10.1145/3620666.3651364 [31] Jongmin Kim, Sangpyo Kim, Jaewan Choi, Jaiyoung Park, Donghwan Kim, and Jung Ho Ahn. 2023. SHARP: A Short-Word Hierarchical Accelerator for Robust and Practical Fully Homomorphic Encryption. In Proceedings of the 50th Annual International Symposium on Computer Architecture (Orlando, FL, USA) (ISCA '23). Association for Computing Machinery, New York, NY, USA, Article 18, 15 pages. https://doi.org/10.1145/3579371.3589053 [32] Jongmin Kim, Gwangho Lee, Sangpyo Kim, Gina Sohn, Minsoo Rhu, John Kim, and Jung Ho Ahn. 2022. ARK: Fully Homomorphic Encryption Accelerator with Runtime Data Generation and Inter-Operation Key Reuse. In 2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO). 1237–1254. https://doi.org/10.1109/MICRO56248.2022.00086 [33] Sangpyo Kim, Jongmin Kim, Michael Jaemin Kim, Wonkyung Jung, John Kim, Minsoo Rhu, and Jung Ho Ahn. 2022. BTS: An Accelerator for Bootstrappable Fully Homomorphic Encryption. In Proceedings of the 49th Annual International Symposium on Computer Architecture (New York, New York) (ISCA '22). Association for Computing Machinery, New York, NY, USA, 711-725. https://doi.org/10.1145/3470496.3527415 [34] Tohru Kohrita and Patrick Towa. 2024. Zeromorph: Zero-Knowledge Multilinear-Evaluation Proofs from Homomorphic Univariate Commitments. J. Cryptol. 37, 4 (2024), 38. https://doi.org/10.1007/S00145-024-09519-0 [35] Abhiram Kothapalli, Srinath T. V. Setty, and Ioanna Tzialla. 2022. Nova: Recursive Zero-Knowledge Arguments from Folding Schemes. In Advances in Cryptology - CRYPTO 2022 - 42nd Annual International Cryptology Conference, CRYPTO 2022, Santa Barbara, CA, USA, August 15-18, 2022, Proceedings, Part IV (Lecture Notes in Computer Science, Vol. 13510), Yevgeniy Dodis and Thomas Shrimpton (Eds.). Springer, 359-388. https://doi.org/10.1007/978-3-031-15985-5_13 [36] Changxu Liu, Hao Zhou, Patrick Dai, Li Shang, and Fan Yang. 2024. PriorMSM: An Efficient Acceleration Architecture for Multi-Scalar Multiplication. ACM Transactions on Design Automation of Electronic Systems 29, 5 (2024), 1-26. [37] Changxu Liu, Hao Zhou, Lan Yang, Zheng Wu, Patrick Dai, Yinlong Li, Shiyong Wu, and Fan Yang. 2024. Myosotis: An Efficiently Pipelined and Parameterized Multi-Scalar Multiplication Architecture via Data Sharing. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (2024), 1-1. https://doi.org/10.1109/TCAD.2024.3524364 [38] Changxu Liu, Hao Zhou, Lan Yang, Jiamin Xu, Patrick Dai, and Fan Yang. 2024. Gypsophila: A Scalable and Bandwidth-Optimized Multi-Scalar Multiplication Architecture. In Proceedings of the 61st ACM/IEEE Design Automation Conference</p>

    <p class="text-gray-300">ISCA '25, June 21-25, 2025, Tokyo, Japan</p>

    <p class="text-gray-300">Alhad Daftardar, Jianqiao Mo, Joey Ah-kiow, Benedikt Bunz, Ramesh Karri, Siddharth Garg, and Brandon Reagen</p>

    <p class="text-gray-300">(San Francisco, CA, USA) (DAC '24). Association for Computing Machinery, New York, NY, USA, Article 94, 6 pages. https://doi.org/10.1145/3649329.3658259 [39] Tao Lu, Yuxun Chen, Zonghui Wang, Xiaohang Wang, Wenzhi Chen, and Jiaheng Zhang. 2024. BatchZK: A Fully Pipelined GPU-Accelerated System for Batch Generation of Zero-Knowledge Proofs. Cryptology ePrint Archive, Paper 2024/1862. https://eprint.iacr.org/2024/1862 [40] Tao Lu, Chengkun Wei, Ruijing Yu, Chaochao Chen, Wenjing Fang, Lei Wang, Zeke Wang, and Wenzhi Chen. 2022. csiZK: Accelerating Zero-Knowledge Proof with A Faster Parallel Multi-Scalar Multiplication Algorithm on GPUs. Cryptology ePrint Archive, Paper 2022/1321. https://eprint.iacr.org/2022/1321 https://eprint.iacr.org/2022/1321. [41] Weiliang Ma, Qian Xiong, Xuanhua Shi, Xiaosong Ma, Hai Jin, Haozhao Kuang, Mingyu Gao, Ye Zhang, Haichen Shen, and Weifang Hu. 2023. GZKP: A GPU Accelerated Zero-Knowledge Proof System. In Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (Vancouver, BC, Canada) (ASPLOS 2023). Association for Computing Machinery, New York, NY, USA, 340-353. https://doi.org/10.1145/3575693.3575711 [42] Jianqiao Mo, Alhad Daftardar, Joey Ah-kiow, Kaiyue Guo, Benedikt Bunz, Siddharth Garg, and Brandon Reagen. 2025. MTU: The Multifunction Tree Unit in zkSpeed for Accelerating HyperPlonk. arXiv:2507.16793 [cs.AR] https://arxiv.org/abs/2507.16793 [43] Jianqiao Mo, Jayanth Gopinath, and Brandon Reagen. 2025. HAAC: A Hardware-Software Co-Design to Accelerate Garbled Circuits. In Proceedings of the 50th Annual International Symposium on Computer Architecture (Orlando, FL, USA) (ISCA '23). Association for Computing Machinery, New York, NY, USA, Article 10, 13 pages. https://doi.org/10.1145/3579371.3589045 [44] Jianqiao Lambridge Mo, Karthik Garimella, Austin Ebel, and Brandon Reagen. 2025. ABLE: Optimizing Mixed Arithmetic and Boolean Garbled Circuit. Cryptology ePrint Archive, Paper 2025/048. https://eprint.iacr.org/2025/048 [45] Barnabé Monnot. 2024. On Block Sizes, Gas Limits, and Scalability. https://ethresear.ch/t/on-block-sizes-gas-limits-and-scalability/18444. Accessed: 2025-05-06. [46] Peter L. Montgomery. 1987. Speeding the Pollard and elliptic curve methods of factorization. Math. Comp. 48, 177 (1987), 243-264. https://doi.org/10.1090/S0025-5718-1987-0866113-7 [47] Timothy Prickett Morgan. 2019. AMD Doubles Down - And Up - With Rome Epyc Server Chips. https://www.nextplatform.com/2019/08/07/amd-doubles-down-and-up-with-rome-epyc-server-chips/ [48] Timothy Prickett Morgan. 2019. A Deep Dive Into AMD's Rome EPYC Architecture. https://www.nextplatform.com/2019/08/15/a-deep-dive-into-amds-romeepyc-architecture/ [49] Negar Neda, Austin Ebel, Benedict Reynwar, and Brandon Reagen. 2024. CiFlow: Dataflow Analysis and Optimization of Key Switching for Homomorphic Encryption. In 2024 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS). 61-72. https://doi.org/10.1109/ISPASS61541.2024.00016 [50] Jason Nelson. 2022. Zcash Nixes Trusted Setup, Enters New Era With Major Network Update. https://decrypt.co/101762/zcash-nixes-trusted-setup-enters-new-era-with-major-network-update [51] OpenCores. 2015. SHA-3 IP Core. https://opencores.org/projects/sha3. Accessed: November 16, 2024. [52] Nicholas Pippenger. 1976. On the evaluation of powers and related problems. In 17th Annual Symposium on Foundations of Computer Science (sfcs 1976). 258-263. https://doi.org/10.1109/SFCS.1976.21 [53] Thomas Pornin. 2020. Optimized Binary GCD for Modular Inversion. 2020/972 (2020). https://eprint.iacr.org/2020/972 [54] Pengcheng Qiu, Guiming Wu, Tingqiang Chu, Changzheng Wei, Runzhou Luo, Ying Yan, Wei Wang, and Hui Zhang. 2024. MSMAC: Accelerating Multi-Scalar Multiplication for Zero-Knowledge Proof. In Proceedings of the 61st ACM/IEEE Design Automation Conference (San Francisco, CA, USA) (DAC '24). Association for Computing Machinery, New York, NY, USA, Article 66, 6 pages. https://doi.org/10.1145/3649329.3655672 [55] Nikola Samardzic, Axel Feldmann, Aleksandar Krastev, Srinivas Devadas, Ronald Dreslinski, Christopher Peikert, and Daniel Sanchez. 2021. F1: A Fast and Programmable Accelerator for Fully Homomorphic Encryption. In MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture (Virtual Event, Greece) (MICRO '21). Association for Computing Machinery, New York, NY, USA, 238-252. https://doi.org/10.1145/3466752.3480070 [56] Nikola Samardzic, Axel Feldmann, Aleksandar Krastev, Nathan Manohar, Nicholas Genise, Srinivas Devadas, Karim Eldefrawy, Chris Peikert, and Daniel Sanchez. 2022. CraterLake: A Hardware Accelerator for Efficient Unbounded Computation on Encrypted Data. In Proceedings of the 49th Annual International Symposium on Computer Architecture (New York, New York) (ISCA '22). Association for Computing Machinery, New York, NY, USA, 173-187. https://doi.org/10.1145/3470496.3527393 [57] Nikola Samardzic, Simon Langowski, Srinivas Devadas, and Daniel Sanchez. 2024. Accelerating Zero-Knowledge Proofs Through Hardware-Algorithm Co-Design. Preprint. https://people.csail.mit.edu/devadas/pubs/micro24_nocap.pdf.</p>

    <p class="text-gray-300">[58] Scott Schlachter and Brian Drake. 2019. Introducing Micron® DDR5 SDRAM: More than a generational update. XP055844818 31 (2019), 6. [59] Srinath Setty. 2020. Spartan: Efficient and General-Purpose zkSNARKs Without Trusted Setup. In Advances in Cryptology - CRYPTO 2020, Daniele Micciancio and Thomas Ristenpart (Eds.). Springer International Publishing, Cham, 704-737. [60] Srinath T. V. Setty, Justin Thaler, and Riad S. Wabby. 2024. Unlocking the Lookup Singularity with Lasso. In Advances in Cryptology - EUROCRYPT 2024 - 43rd Annual International Conference on the Theory and Applications of Cryptographic Techniques, Zurich, Switzerland, May 26-30, 2024, Proceedings, Part VI (Lecture Notes in Computer Science, Vol. 14656), Marc Joye and Gregor Leander (Eds.). Springer, 180-209. https://doi.org/10.1007/978-3-031-58751-1_7 [61] Nojan Sheybani, Tengkai Gong, Anees Ahmed, Nges Brian Njungle, Michel Kiney, and Farinaz Koushanfar. 2025. Gotta Hash 'Em All! Speeding Up Hash Functions for Zero-Knowledge Proof Applications. arXiv:2501.18780 [cs.CR] https://arxiv.org/abs/2501.18780 [62] Deepraj Soni, Negar Neda, Naifeng Zhang, Benedict Reynwar, Homer Gamil, Benjamin Heyman, Mohammed Nabeel, Ahmad Al Badawi, Yuriy Polyakov, Kellie Canida, Massoud Pedram, Michail Maniatakos, David Bruce Cousins, Franz Franchetti, Matthew French, Andrew Schmidt, and Brandon Reagen. 2023. RPU: The Ring Processing Unit. In 2023 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS). 272-282. https://doi.org/10.1109/ISPASS57527.2023.00034 [63] powerup tech. 2024. AMD EPYC 7502 Specs. https://www.techpowerup.com/cpuspecs/epyc-7502.c2250 [64] Justin Thaler. 2013. Time-Optimal Interactive Proofs for Circuit Evaluation. Cryptology ePrint Archive, Paper 2013/351. https://eprint.iacr.org/2013/351 [65] Justin Thaler. 2022. Proofs, Arguments, and Zero-Knowledge. https://people.cs.georgetown.edu/jthaler/ProofsArgsAndZK.pdf [66] Paul Valiant. 2008. Incrementally Verifiable Computation or Proofs of Knowledge Imply Time/Space Efficiency. In Theory of Cryptography, Fifth Theory of Cryptography Conference, TCC 2008, New York, USA, March 19-21, 2008 (Lecture Notes in Computer Science, Vol. 4948), Ran Canetti (Ed.). Springer, 1-18. https://doi.org/10.1007/978-3-540-78524-8_1 [67] Cheng Wang and Mingyu Gao. 2023. SAM: A Scalable Accelerator for Number Theoretic Transform Using Multi-Dimensional Decomposition. In 2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD). 1-9. https://doi.org/10.1109/ICCAD57390.2023.10323744 [68] Cheng Wang and Mingyu Gao. 2025. UniZK: Accelerating Zero-Knowledge Proof with Unified Hardware and Flexible Kernel Mapping. In Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1 (Rotterdam, Netherlands) (ASPLOS '25). Association for Computing Machinery, New York, NY, USA, 1101-1117. https://doi.org/10.1145/3669940.3707228 [69] Tiancheng Xie, Yupeng Zhang, and Dawn Song. 2022. Orion: Zero Knowledge Proof with Linear Prover Time. In Advances in Cryptology - CRYPTO 2022 - 42nd Annual International Cryptology Conference, CRYPTO 2022, Santa Barbara, CA, USA, August 15-18, 2022, Proceedings, Part IV (Lecture Notes in Computer Science, Vol. 13510), Yevgeniy Dodis and Thomas Shrimpton (Eds.). Springer, 299-328. https://doi.org/10.1007/978-3-031-15985-5_11 [70] Alex Luoyuan Xiong, Binyi Chen, Zhenfei Zhang, Benedikt Bunz, Ben Fisch, Fernando Krell, and Philippe Camacho. 2023. VeriZex: Decentralized Private Computation with Universal Setup. In 32nd USENIX Security Symposium, USENIX Security 2023, Anaheim, CA, USA, August 9-11, 2023, Joseph A. Calandrino and Carmela Troncoso (Eds.). USENIX Association, 4445-4462. https://www.usenix.org/conference/usenixsecurity23/presentation/xiong [71] Zhengbang Yang, Lutan Zhao, Peinan Li, Han Liu, Kai Li, Boyan Zhao, Dan Meng, and Rui Hou. 2025. LegoZK: A Dynamically Reconfigurable Accelerator for Zero-Knowledge Proof. In 2025 IEEE International Symposium on High Performance Computer Architecture (HPCA). 113-126. https://doi.org/10.1109/HPCA61900.2025.00020 [72] Naifeng Zhang and Franz Franchetti. 2025. Code Generation for Cryptographic Kernels using Multi-word Modular Arithmetic on GPU. In Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization (Las Vegas, NV, USA) (CGO '25). Association for Computing Machinery, New York, NY, USA, 476-492. https://doi.org/10.1145/3696443.3708948 [73] Ye Zhang, Shuo Wang, Xian Zhang, Jiangbin Dong, Xingzhong Mao, Fan Long, Cong Wang, Dong Zhou, Mingyu Gao, and Guangyu Sun. 2021. PipeZK: Accelerating Zero-Knowledge Proof with a Pipelined Architecture. In 2021 ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA). [74] Zhenfei Zhang, Binyi Chen, Benedikt Bunz, and Alex Xiong. 2022. Hyperplonk Implementation. https://github.com/EspressoSystems/hyperplonk [75] Hao Zhou, Changxu Liu, Lan Yang, Li Shang, and Fan Yang. 2024. ReZK: A Highly Reconfigurable Accelerator for Zero-Knowledge Proof. IEEE Transactions on Circuits and Systems I: Regular Papers (2024). [76] Xudong Zhu, Haoqi He, Zhengbang Yang, Yi Deng, Lutan Zhao, and Rui Hou. 2024. Elastic MSM: A Fast, Elastic and Modular Preprocessing Technique for Multi-Scalar Multiplication Algorithm on GPUs. Cryptology ePrint Archive, Paper 2024/057. https://eprint.iacr.org/2024/057</p>`;
---

<BaseLayout title="Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge... (2025/620)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2025 &middot; eprint 2025/620
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
