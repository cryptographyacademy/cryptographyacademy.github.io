---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2024/474';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Accumulation without Homomorphism';
const AUTHORS_HTML = 'Benedikt Bünz, Pratyush Mishra, Wilson Nguyen, William Wang';

const CONTENT = `    <p class="text-gray-300">Benedikt Bünz bb@nyu.edu New York University Pratyush Mishra prat@upenn.edu University of Pennsylvania Wilson Nguyen wdnguyen@stanford.edu Stanford University William Wang ww@priv.pub New York University</p>

    <h6 id="sec-2" class="text-base font-medium mt-4">Abstract</h6>

    <p class="text-gray-300">Accumulation schemes are a simple yet powerful primitive that enable highly efficient constructions of incrementally verifiable computation (IVC). Unfortunately, all prior accumulation schemes rely on homomorphic vector commitments whose security is based on public-key assumptions. It is an interesting open question to construct efficient accumulation schemes that avoid the need for such assumptions.</p>

    <p class="text-gray-300">In this paper, we answer this question affirmatively by constructing an accumulation scheme from <em>non-homomorphic</em> vector commitments which can be realized from solely symmetric-key assumptions (e.g. Merkle trees). We overcome the need for homomorphisms by instead performing spot-checks over error-correcting encodings of the committed vectors.</p>

    <p class="text-gray-300">Unlike prior accumulation schemes, our scheme only supports a bounded number of accumulation steps. We show that such <em>bounded-depth</em> accumulation still suffices to construct proof-carrying data (a generalization of IVC). We also demonstrate several optimizations to our PCD construction which greatly improve concrete efficiency.</p>

    <p class="text-gray-300">2</p>

    <p class="text-gray-300">1  Introduction  3 1.1 Our contributions  3 1.2 Related work  5</p>

    <p class="text-gray-300">2  Techniques  7 2.1 Checking linearity  8 2.2 Defining bounded-depth accumulation  10 2.3 Bounded-depth PCD from bounded-depth accumulation  10 2.4 Constructing bounded-depth accumulation  11 2.5 Optimization: batch commitments  13 2.6 Optimization: low-overhead IVC from accumulation  13 2.7 Optimization: PCD composition  14</p>

    <p class="text-gray-300">3  Preliminaries  16 3.1 Non-interactive arguments of knowledge  16 3.2 Proof-carrying data  17 3.3 Instantiating the random oracle  18 3.4 Reed–Solomon codes  18 3.5 Vector commitments  20</p>

    <p class="text-gray-300">4  Bounded-depth accumulation  21</p>

    <p class="text-gray-300">5  PCD from bounded-depth accumulation  23 5.1 Construction  23 5.2 Knowledge soundness  23</p>

    <p class="text-gray-300">6  Constructing bounded-depth accumulation  28 6.1 Non-interactive argument  28 6.2 Accumulation scheme  30 6.3 Soundness analysis  32 6.4 Using arbitrary linear codes  37 6.5 Soundness analysis  39</p>

    <p class="text-gray-300">7  Optimizations  42 7.1 Batch commitments  42 7.2 Low-overhead IVC from accumulation  42 7.3 PCD composition  45</p>

    <p class="text-gray-300">Acknowledgments  47</p>

    <p class="text-gray-300">References  48</p>

    <p class="text-gray-300">1 Introduction</p>

    <p class="text-gray-300"><em>Proof-carrying data</em> (PCD) <em>[x10]</em> is a powerful cryptographic primitive that enables mutually distrustful parties to perform distributed computations that run indefinitely, while ensuring that the correctness of every intermediate step can be verified efficiently. PCD is a generalization of the prior notion of <em>incrementally-verifiable computation</em> (IVC) <em>[x24]</em>.</p>

    <p class="text-gray-300">PCD has found numerous applications in both theory and practice, including enforcing language semantics <em>[x11]</em>, complexity-preserving succinct arguments <em>[x3, x2]</em>, verifiable MapReduce computations <em>[x12]</em>, image provenance <em>[x20]</em>, and consensus protocols and blockchains <em>[x18, x11, x1, x4]</em>. It is thus a key question to understand security assumptions that PCD constructions require, as well as the efficiency that they can attain under these assumptions.</p>

    <p class="text-gray-300">Let us review how existing PCD constructions fare along both dimensions. For simplicity, we focus on the special case of IVC in the following discussion.</p>

    <p class="text-gray-300">PCD from succinctly verifiable arguments. The standard construction of PCD is via recursive composition of succinct non-interactive arguments of knowledge (SNARKs) <em>[x3, x2, x4, x13]</em>. Informally, to prove a <span class="math">t</span>-step computation, the PCD prover proves that the <span class="math">t</span>-th step is correct, and there exists a valid proof for the first <span class="math">t-1</span> steps. The state-of-the-art works in this line follow the template of Fractal <em>[x10]</em> by relying on SNARKs in the random oracle model. This means that we can achieve PCD (heuristically) from only symmetric-key cryptography, but at the cost of relying on the existence of SNARKs, which are complex to construct and incur (asymptotically and concretely) high costs for the PCD prover.</p>

    <p class="text-gray-300">PCD from accumulation. A recent popular approach to avoid this reliance on SNARKs is to construct PCD via <em>accumulation schemes</em> <em>[x4, x2, x14]</em>. Roughly speaking, instead of recursively checking proofs as above, the PCD prover “accumulates” the proof for each step into a running accumulator, and then the PCD verifier performs a single expensive check on the final accumulator. This line of work has led to simple and efficient PCD schemes that incur low costs for the PCD prover, and so has seen much interest in new constructions and deployments <em>[x2, x15, x16, x17, x18]</em>. Unfortunately, all known accumulation schemes rely on homomorphic vector commitments that are only known to exist under public-key assumptions. Additionally, because most existing homomorphic vector commitments are not known to achieve post-quantum security, the resulting accumulation schemes are also quantum-insecure.</p>

    <p class="text-gray-300">Our question. We are thus left in an unsatisfactory state of affairs: on the one hand we have PCD from ROM-based SNARKs that (heuristically) relies on the minimal symmetric-key assumptions, but incurs high PCD prover costs due to this reliance on SNARKs, while on the other hand we have PCD from accumulation that relies on public-key assumptions, but achieves comparatively lower PCD prover costs by avoiding SNARKs. This motivates the questions we tackle in this paper: can we design PCD that achieves low prover costs by avoiding SNARKs, while simultaneously minimizing assumptions?</p>

    <h3 id="sec-4" class="text-xl font-semibold mt-8">1.1 Our contributions</h3>

    <p class="text-gray-300">We answer this question positively by constructing accumulation schemes <em>solely</em> in the random-oracle model. Our constructions satisfy a weaker notion of accumulation than that considered in prior work, but we show that this weaker notion still suffices to construct PCD (again, heuristically after instantiating the random oracle). We provide details below.</p>

    <p class="text-gray-300">(1) Bounded-depth accumulation. We introduce a new notion of bounded-depth accumulation schemes that can only provide (knowledge) soundness guarantees for a limited number of consecutive accumulation steps. In contrast, prior accumulation schemes support an unbounded number of accumulation steps.</p>

    <p class="text-gray-300">(2) PCD from bounded-depth accumulation. We show that this weaker notion of accumulation still suffices to construct (a variant of) proof-carrying data. In particular, we show that bounded-depth accumulation suffices to construct PCD for computation graphs of a-priori bounded depth <span class="math">O(1)</span>, which is already sufficient for many applications, including the primary application of constructing polynomial-length IVC <em>[x1]</em>.</p>

    <p class="text-gray-300">We note that, like our construction, all prior PCD constructions only provably support computation graphs of bounded depth <em>[x1]</em>. However, unlike these prior works, our construction is vulnerable to attacks when the depth of the computation graph exceeds an a priori fixed constant. See Remarks 2.1 and 2.2 for details.</p>

    <p class="text-gray-300">(3) Efficient constructions of bounded-depth accumulation. We construct efficient bounded-depth accumulation schemes from any (non-homomorphic) vector commitment scheme (e.g. random-oracle based Merkle trees) and any linear code.</p>

    <p class="text-gray-300">Compared to the prior state-of-the-art accumulation schemes, our construction has several advantages beyond just avoiding public-key assumptions, such as true linear time for the accumulation prover, and plausible post-quantum security. (We note that both our construction and prior accumulation schemes rely on the random oracle model; it is an open question to construct an accumulation scheme in the standard model.)</p>

    <p class="text-gray-300">(4) Efficiency of and optimizations for instantiated PCD. Instantiating our generic PCD construction with our accumulation scheme leads to PCD schemes with numerous prover efficiency benefits compared to prior work. We also provide several optimizations for this scheme, including support for ‘batch’ accumulation, a new low-overhead compiler from low-depth PCD to IVC, and a new hybrid PCD scheme that combines our low-depth PCD with any SNARK-based PCD scheme to achieve the best of both worlds. We detail the impact of these optimizations in Table 1.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Our scheme also has prover efficiency benefits beyond those captured by Table 1. To elaborate on these, we briefly detail the key factors that contribute to PCD prover cost. In all practical PCD constructions, to produce a proof for the next step of the distributed computation, the PCD prover invokes an underlying cryptographic proof system to prove satisfaction of a circuit <span class="math">C_{\\mathsf{PCD}}</span> that contains a circuit representation <span class="math">C_{\\Phi}</span> of the computation step (or PCD predicate <span class="math">\\Phi</span>), and also performs other checks required by the PCD construction. Thus, PCD prover efficiency is determined by the prover efficiency of this proof system, and by the cost $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C_{\\mathsf{PCD}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C_{\\Phi}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ of the additional checks. We call the former the proof-system overhead, and the latter the PCD circuit overhead.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">PCD constructions based on ROM-based SNARKs have been able to achieve best-in-class proof-system overhead via extensive asymptotic and concrete optimizations (e.g., by achieving truly linear-time provers <em>[x2, x3, x4, x5]</em>, or relying on small fields <em>[x6]</em>), but suffer from high PCD circuit overhead as the SNARK verifier subcircuit must perform numerous expensive random oracle calls.</p>

    <p class="text-gray-300">Accumulation-based PCD constructions, on the other hand, have the smallest recursion overhead (e.g., just <span class="math">10,000</span> gates for Nova <em>[x12]</em> vs. over <span class="math">1</span> million gates for Fractal <em>[x9]</em>). They also try to lower</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">scheme</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">circuit overhead per step</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">IVC verifier</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">max. IVC length</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Fractal [COS20]</td>

            <td class="px-3 py-2 border-b border-gray-700">λ log n ·</td>

            <td class="px-3 py-2 border-b border-gray-700">CMT</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">λ log n TMT</td>

            <td class="px-3 py-2 border-b border-gray-700">poly(λ)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">+ STIR [ACFY24] (concurrent)</td>

            <td class="px-3 py-2 border-b border-gray-700">(log n + λ log log n) ·</td>

            <td class="px-3 py-2 border-b border-gray-700">CMT</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">(log n + λ log log n) TMT</td>

            <td class="px-3 py-2 border-b border-gray-700">poly(λ)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">this paper</td>

            <td class="px-3 py-2 border-b border-gray-700">d · λ ·</td>

            <td class="px-3 py-2 border-b border-gray-700">CMT</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">d · n</td>

            <td class="px-3 py-2 border-b border-gray-700">md</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">+ batch comm. (Sec 2.5)</td>

            <td class="px-3 py-2 border-b border-gray-700">d·λ/m ·</td>

            <td class="px-3 py-2 border-b border-gray-700">CMT</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">d · m · n</td>

            <td class="px-3 py-2 border-b border-gray-700">md</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">+ low-overhead IVC (Sec 2.6)</td>

            <td class="px-3 py-2 border-b border-gray-700">d·λ/m2 ·</td>

            <td class="px-3 py-2 border-b border-gray-700">CMT</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">d · m · n</td>

            <td class="px-3 py-2 border-b border-gray-700">md</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">+ hybrid (Sec 2.7)</td>

            <td class="px-3 py-2 border-b border-gray-700">(d<em>·λ/m2 + λ log n</em> / m2) ·</td>

            <td class="px-3 py-2 border-b border-gray-700">CMT</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">λ log n* TMT</td>

            <td class="px-3 py-2 border-b border-gray-700">poly(λ)</td>

          </tr>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Table 1: Comparison of IVC schemes constructed from PCD over a tree of depth  <span class="math">d</span>  and arity  <span class="math">m</span> . All costs omit constant factors. The circuit overhead measures  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C_{\\mathrm{PCD}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C_{\\Phi}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> . The table displays the cost per invocation of  </span>\\Phi<span class="math"> . Above  </span>n<span class="math">  is the size of the recursive circuit,  </span>n^{\\star} = O(d^{\\star}mn)<span class="math">  is the circuit size of the accumulation decider for the recursive circuit,  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C_{\\mathrm{MT}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  is the circuit size of checking a membership proof in a Merkle Tree with  </span>n<span class="math">  leaves.  </span>T_{\\mathrm{MT}}$  is the time it takes to verify a Merkle Tree opening.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">proof-system overhead by avoiding some cryptographic work (e.g., by requiring commitments only to the witness [BC23]), and via efficient arithmetizations of predicates (e.g., via cheap custom gates). However, the remaining cryptographic work is quite expensive as it requires public-key operations, and hence the proof-system overhead of these constructions is relatively high.</p>

    <p class="text-gray-300">Our construction of bounded-depth accumulation achieves the best of both worlds: it enjoys the low PCD circuit overhead of accumulation-based PCD constructions while taking advantage of the proof-system optimizations enjoyed by both approaches. In fact, the combination opens up new efficiency improvements that are not possible in either of the two paradigms alone. For example, all known ROM-SNARK-based PCD constructions thus far have relied on Reed-Solomon codes, and incur quasilinear prover costs from the quasilinear encoding time of these codes. Our construction, on the other hand, allows the use of any linear code, including linear-time-encodable codes [Spi96; DI14; GLSTW23], thus reducing prover costs.</p>

    <p class="text-gray-300">PCD from symmetric-key assumptions. As noted in Section 1, the only end-to-end construction of PCD from symmetric-key assumptions is that of Chiesa, Ojha, and Spooner [COS20]. We provide a quantitative comparison in Table 1, and focus here on a qualitative comparison. Their construction is based on the Fractal SNARK, which they prove secure in the random oracle model. <span class="math">^6</span></p>

    <p class="text-gray-300">Boneh, Drake, Fisch, and Gabizon [BDFG21] propose an optimization of the foregoing approach that batches the most expensive component, the low-degree test, across multiple proofs. While this concretely reduces prover cost, it does not lead to an asymptotic improvement in the prover overhead.</p>

    <p class="text-gray-300">Like Fractal and similar SNARKs, our construction is able to take advantage of recent advances in the design of efficient code-based Interactive Oracle Proofs (IOPs) [BCS16; RRR21]. For example, like recent work [Sta21; Pol; DP23], we can greatly improve efficiency by relying on extension fields of small characteristic. Furthermore, unlike existing works, our fields do not need to have any special algebraic structure (e.g. large multiplicative subgroups).</p>

    <h4 id="sec-6" class="text-lg font-semibold mt-6">PCD from public-key assumptions.</h4>

    <p class="text-gray-300">Except the foregoing, all existing concretely-efficient IVC/PCD constructions <em>[x1, x2, x3, x4, x5, x6, x7, x8]</em> rely on public-key assumptions, and in particular rely on the hardness of computing discrete logarithms over elliptic curve groups, which forces the usage of cryptographically large fields. Furthermore, efficient implementations require <em>cycles of elliptic curves</em>, which have proved unwieldy to implement correctly in practice <em>[x10]</em>. In comparison, our construction avoids the need for public-key assumptions and this additional algebraic structure, and is able to use non-cryptographic field sizes.</p>

    <h4 id="sec-7" class="text-lg font-semibold mt-6">Concurrent work.</h4>

    <p class="text-gray-300">The concurrent work LatticeFold <em>[x1]</em> takes a complementary approach to constructing plausibly post-quantum accumulation-based PCD: it constructs an accumulation/folding scheme from lattice-based assumptions. Unlike our construction, their accumulation scheme directly supports unbounded depth, allowing it to serve as a drop-in replacement in many existing constructions of accumulation-based PCD. However, this comes at a cost: at each accumulation step, the prover must demonstrate that the accumulation result has a small norm, which incurs a non-trivial computational cost. Furthermore, the dependence on lattice-based assumptions means that their scheme still relies on public-key assumptions.</p>

    <p class="text-gray-300">An interesting direction for future work would be to combine the two approaches to reduce the need for small-norm checks. For example, one could construct a more efficient PCD scheme by first designing a bounded-depth accumulation scheme that relies on the bounded homomorphism supported by lattice commitments. One could then use the transformation of Section 2.7 to combine the resulting (bounded-depth) PCD scheme with the (unbounded-depth) LatticeFold PCD scheme to achieve a more efficient construction than either scheme alone.</p>

    <p class="text-gray-300">Another concurrent work, STIR <em>[x1]</em>, provides a new proximity test that can be used as a drop-in replacement for the proximity test <em>[x3]</em> used in Fractal <em>[x4]</em>. As noted in Table 1, our schemes still have lower recursion overhead than this optimized baseline. Furthermore, this new STIR + Fractal-based PCD should also be compatible with our hybrid construction from Section 2.7.</p>

    <h6 id="sec-8" class="text-base font-medium mt-4">Remark 1.1 (security of bounded-depth PCD).</h6>

    <p class="text-gray-300">All PCD schemes (including ours) only provably support computation graphs of depth <span class="math">O(1)</span>. However, while there are no known attacks that break the security of prior schemes when the depth is <span class="math">\\omega(1)</span>, the same is not true for our scheme. As we explain in Section 2.1, our scheme is vulnerable to a relatively straightforward attack that obviates any security guarantees when the depth of the computation graph exceeds an <em>a priori</em> fixed constant. We emphasize that even such bounded-depth PCD is already powerful enough to support many interesting applications, including the primary application of constructing polynomial-length IVC <em>[x1]</em>. See Remarks 2.1 and 2.2 for a more detailed discussion.</p>

    <p class="text-gray-300">2 Techniques</p>

    <p class="text-gray-300">We begin by reviewing the definition of an accumulation scheme <em>[x1, x2]</em>. At a high level, it is used to perform <em>batch verification</em> of a predicate which, for us, will be a non-interactive argument’s verifier <span class="math">\\mathcal{V}</span>. In other words, an accumulation scheme is used to check that <span class="math">\\mathcal{V}(\\mathbbm{x}_{1},\\pi_{1}),\\dots,\\mathcal{V}(\\mathbbm{x}_{n},\\pi_{n})</span> all accept, more efficiently than the naive approach of individually verifying each instance <span class="math">\\mathbbm{x}_{i}</span> and proof <span class="math">\\pi_{i}</span>.</p>

    <p class="text-gray-300">The workflow of an accumulation scheme is as follows. There are three main algorithms: a prover <span class="math">\\mathrm{P}</span>, verifier <span class="math">\\mathrm{V}</span>, and decider <span class="math">\\mathrm{D}</span>. The prover is initialized with an empty accumulator <span class="math">\\mathsf{acc}_{0}</span>, which is used to accumulate an input <span class="math">(\\mathbbm{x}_{1},\\pi_{1})</span> into a new accumulator <span class="math">\\mathsf{acc}_{1}</span>. The prover additionally outputs a proof; we write this as <span class="math">(\\mathsf{acc}_{1},\\mathsf{pf}_{1})\\leftarrow\\mathrm{P}(\\mathbbm{x}_{1},\\pi_{1},\\mathsf{acc}_{0})</span>. Later, <span class="math">\\mathsf{acc}_{1}</span> can be used to accumulate a second input, i.e. <span class="math">(\\mathsf{acc}_{2},\\mathsf{pf}_{2})\\leftarrow\\mathrm{P}(\\mathbbm{x}_{2},\\pi_{2},\\mathsf{acc}_{1})</span>, and so on. The correctness of a sequence of accumulations can then be established by checking that: (a) each accumulation step is valid, i.e. <span class="math">\\mathrm{V}(\\mathbbm{x}_{i},\\pi_{i},\\mathsf{acc}_{i-1},\\mathsf{acc}_{i},\\mathsf{pf}_{i})=1</span>; and (b) the final accumulator is valid, i.e. <span class="math">\\mathrm{D}(\\mathsf{acc}_{n})=1</span>.</p>

    <p class="text-gray-300">Notice that the decider only acts on the final accumulator, whereas the verifier acts on each accumulation step. Therefore, the crux of an accumulation scheme is making verification as cheap as possible. Towards this, we require that an accumulator <span class="math">\\mathsf{acc}</span> can be split into a short instance part <span class="math">\\mathsf{acc}.\\mathbbm{x}</span> and a (possibly) long witness part <span class="math">\\mathsf{acc}.\\mathbbm{w}</span>; we use <span class="math">\\mathsf{acc}=(\\mathsf{acc}.\\mathbbm{x},\\mathsf{acc}.\\mathbbm{w})</span> as shorthand. Similarly, we require that an argument proof can be split into instance and witness parts <span class="math">\\pi=(\\pi.\\mathbbm{x},\\pi.\\mathbbm{w})</span>. The point is that the verifier can only look at the instance parts; we write this as <span class="math">\\mathrm{V}(\\mathbbm{x}_{i},\\pi_{i}.\\mathbbm{x},\\mathsf{acc}_{i-1}.\\mathbbm{x},\\mathsf{acc}_{i}.\\mathbbm{x},\\mathsf{pf}_{i})</span>.</p>

    <p class="text-gray-300">Definition. An accumulation scheme must satisfy the following properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><em>Completeness:</em> The honest accumulation <span class="math">(\\mathsf{acc}^{\\prime},\\mathsf{pf})\\leftarrow\\mathrm{P}(\\mathbbm{x},\\pi,\\mathsf{acc})</span> of <em>any</em> valid input and accumulator should pass both the verifier’s and decider’s checks. That is, if <span class="math">\\mathcal{V}(\\mathbbm{x},\\pi)=1</span> and <span class="math">\\mathrm{D}(\\mathsf{acc})=1</span>, then <span class="math">\\mathrm{V}(\\mathbbm{x},\\pi.\\mathbbm{x},\\mathsf{acc}.\\mathbbm{x},\\mathsf{acc}^{\\prime}.\\mathbbm{x},\\mathsf{pf})=1</span> and <span class="math">\\mathrm{D}(\\mathsf{acc}^{\\prime})=1</span>.</li>

      <li><em>Knowledge soundness:</em> If a new accumulator <span class="math">\\mathsf{acc}^{\\prime}</span> passes the verifier’s and decider’s checks, then an efficient extractor can find a valid input and old accumulator that explains <span class="math">\\mathsf{acc}^{\\prime}</span>. That is, if <span class="math">\\mathrm{D}(\\mathsf{acc}^{\\prime})=1</span> and <span class="math">\\mathrm{V}(\\mathbbm{x},\\pi.\\mathbbm{x},\\mathsf{acc}.\\mathbbm{x},\\mathsf{acc}^{\\prime}.\\mathbbm{x},\\mathsf{pf})=1</span>, then an efficient extractor can find the witness part of the proof, <span class="math">\\pi.\\mathbbm{w}</span>, and the witness part of the old accumulator, <span class="math">\\mathsf{acc}.\\mathbbm{w}</span>, such that <span class="math">\\mathcal{V}(\\mathbbm{x},\\pi)=1</span> and <span class="math">\\mathrm{D}(\\mathsf{acc})=1</span>.</li>

      <li><em>Efficiency:</em> The cost of running the accumulation verifier <span class="math">n</span> times plus the cost of running the accumulation decider once should be lower than the cost of running the argument verifier <span class="math">n</span> times.</li>

    </ul>

    <p class="text-gray-300">Accumulation schemes can be generalized to handle multiple inputs and accumulators in each step. For example, the prover’s syntax would be <span class="math">\\mathrm{P}([\\mathbbm{x}_{i},\\pi_{i}]_{i=1}^{m_{1}},[\\mathsf{acc}_{i}]_{i=1}^{m_{2}})</span>, where <span class="math">m_{1}</span> and <span class="math">m_{2}</span> are the arities; see Section 4 for a comprehensive definition.</p>

    <p class="text-gray-300">Prior constructions. All prior accumulation schemes <em>[x1, x2, x3, x4, x5, x6]</em> crucially use <em>additively homomorphic vector commitment schemes</em>. Informally, a vector commitment scheme allows one to construct a succinct commitment <span class="math">\\mathsf{cm}</span> to a vector <span class="math">\\mathbf{v}\\in\\mathbb{F}^{n}</span>. The scheme is additively homomorphic if, given <span class="math">\\mathsf{cm}_{1}=\\mathsf{Commit}(\\mathbf{v}_{1})</span> and <span class="math">\\mathsf{cm}_{2}=\\mathsf{Commit}(\\mathbf{v}_{2})</span>, <span class="math">\\mathsf{cm}_{3}=\\alpha\\cdot\\mathsf{cm}_{1}+\\beta\\cdot\\mathsf{cm}_{2}</span> is a commitment to <span class="math">\\alpha\\mathbf{v}_{1}+\\beta\\mathbf{v}_{2}</span>. We remark that all known additively homomorphic vector commitment schemes, e.g. Pedersen commitments <em>[x10]</em>, rely on public-key assumptions.</p>

    <p class="text-gray-300">The general blueprint for an accumulation scheme is as follows. An accumulator witness <span class="math">\\mathsf{acc}.\\mathbbm{w}\\in\\mathbb{F}^{n}</span> is a vector, and the corresponding instance <span class="math">\\mathsf{acc}.\\mathbbm{x}</span> is a commitment to <span class="math">\\mathsf{acc}.\\mathbbm{w}</span>. For simplicity, suppose the prover claims that <span class="math">\\mathsf{acc}_{1}</span> and <span class="math">\\mathsf{acc}_{2}</span> accumulate into <span class="math">\\mathsf{acc}_{3}</span>. Roughly speaking, we want to guarantee that the output</p>

    <p class="text-gray-300">accumulator is a random linear combination of the input accumulators. The verifier checks this by computing the linear combination of the input commitments <span class="math">\\mathsf{acc}_{1}.\\mathtt{x}</span> and <span class="math">\\mathsf{acc}_{2}.\\mathtt{x}</span>, and checking that the result equals the output commitment <span class="math">\\mathsf{acc}_{3}.\\mathtt{x}</span> <em>[x13, x2]</em>. Later, the decider will check that <span class="math">\\mathsf{acc}_{3}.\\mathtt{w}</span> is a “good” vector, and that <span class="math">\\mathsf{acc}_{3}.\\mathtt{x}</span> commits to <span class="math">\\mathsf{acc}_{3}.\\mathtt{w}</span>. Since commitments are binding, <span class="math">\\mathsf{acc}_{3}</span> must be the correct linear combination of <span class="math">\\mathsf{acc}_{1}</span> and <span class="math">\\mathsf{acc}_{2}</span>.</p>

    <p class="text-gray-300">We have omitted many details, most notably how to accumulate argument proofs. However, from this description alone we can observe two key properties of the vector commitment scheme. First, it has succinct commitments; this allows the verifier to be efficient. Second, it is additively homomorphic; this allows the verifier to perform meaningful checks. As noted earlier, this combination of properties unfortunately seems to require public-key assumptions.</p>

    <h3 id="sec-9" class="text-xl font-semibold mt-8">2.1 Checking linearity</h3>

    <p class="text-gray-300">To overcome the foregoing limitation, we make a key observation: to verify that the output accumulator is a linear combination of the input accumulators, it is not necessary to directly compute a linear combination of the input commitments. Instead, it suffices to <em>check</em> that the output accumulator commits to a vector that is a linear combination of the vectors committed by the input accumulators. This idea is a natural one, and has appeared before under the name of “linear combination schemes” <em>[x1]</em>.</p>

    <p class="text-gray-300">Recall that we want to check that <span class="math">\\mathsf{acc}_{3}.\\mathtt{w}=\\alpha\\cdot\\mathsf{acc}_{1}.\\mathtt{w}+\\beta\\cdot\\mathsf{acc}_{2}.\\mathtt{w}</span>, where <span class="math">\\alpha,\\beta\\in\\mathbb{F}</span> are previously chosen scalars. More precisely, we want to check that <span class="math">\\mathbf{v}_{3}=\\alpha\\mathbf{v}_{1}+\\beta\\mathbf{v}_{2}</span>, where <span class="math">\\mathbf{v}_{1}</span>, <span class="math">\\mathbf{v}_{2}</span>, and <span class="math">\\mathbf{v}_{3}</span> are the underlying committed vectors of <span class="math">\\mathsf{acc}_{1}.\\mathtt{x}</span>, <span class="math">\\mathsf{acc}_{2}.\\mathtt{x}</span>, and <span class="math">\\mathsf{acc}_{3}.\\mathtt{x}</span> (and since commitments are binding, these vectors correspond with the accumulator witnesses). A <em>linearity check</em> is a protocol between the prover and the verifier that convinces the verifier of this claim. Assuming the verifier is public-coin, this can be made non-interactive using random oracles.</p>

    <p class="text-gray-300">Our goal is to construct a linearity check which does not require homomorphic vector commitments. Instead, we require vector commitments with <em>local openings</em>. Informally, these allow the prover to generate a succinct proof that the underlying committed vector’s <span class="math">i</span>-th element is some claimed value. For example, Merkle tree commitments support local openings with proof size <span class="math">O(\\lambda\\log n)</span>.</p>

    <h5 id="sec-10" class="text-base font-semibold mt-4">Distance spot checks.</h5>

    <p class="text-gray-300">The key tool that we will be relying on is a protocol for convincing the verifier that two committed vectors are at most a constant distance apart. Concretely, let <span class="math">\\mathsf{cm}_{1}</span> and <span class="math">\\mathsf{cm}_{2}</span> be commitments to vectors <span class="math">\\mathbf{v}_{1}</span> and <span class="math">\\mathbf{v}_{2}</span> respectively. We say that <span class="math">\\mathbf{v}_{1}</span> and <span class="math">\\mathbf{v}_{2}</span> are <span class="math">\\delta</span>-far apart if they differ in at most <span class="math">\\delta n</span> locations. To show that <span class="math">\\mathbf{v}_{1}</span> and <span class="math">\\mathbf{v}_{2}</span> are at most <span class="math">\\delta</span>-far apart, the prover and verifier engage in the following protocol:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The verifier uniformly samples an index <span class="math">i\\in[n]</span> and sends it to the prover.</li>

      <li>The prover responds with the purported <span class="math">i</span>-th elements of <span class="math">\\mathbf{v}_{1}</span> and <span class="math">\\mathbf{v}_{2}</span>, along with opening proofs.</li>

      <li>The verifier accepts if these opening proofs are valid and the claimed elements are equal.</li>

    </ol>

    <p class="text-gray-300">Clearly, if <span class="math">\\mathbf{v}_{1}</span> and <span class="math">\\mathbf{v}_{2}</span> are <span class="math">\\delta</span>-far apart, then the verifier will reject with probability <span class="math">\\delta</span>. For any constant <span class="math">\\delta&gt;0</span>, this soundness error can be made negligible with <span class="math">\\Theta(\\lambda)</span> parallel repetitions.</p>

    <h5 id="sec-11" class="text-base font-semibold mt-4">Linearity spot checks.</h5>

    <p class="text-gray-300">This protocol easily generalizes to testing any kind of element-wise property, and in particular we can use it to check that <span class="math">\\mathbf{v}_{3}</span> is <span class="math">\\delta</span>-close to the “virtual vector” <span class="math">\\alpha\\mathbf{v}_{1}+\\beta\\mathbf{v}_{2}</span>. Unfortunately, we need to ensure that the two vectors are equal at all locations. Suppose a cheating prover commits to a vector that only differs from <span class="math">\\alpha\\mathbf{v}_{1}+\\beta\\mathbf{v}_{2}</span> at a <em>single</em> location <span class="math">j</span>. Detecting this would require <span class="math">\\Theta(\\lambda n)</span> repetitions (essentially opening the entire commitment), which violates the accumulation verifier’s efficiency requirement.</p>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">2.1.1 Error-resilient linearity checks from codes</p>

    <p class="text-gray-300">It seems that we are at an impasse: our spot check can only guarantee that two vectors are <span class="math">\\delta</span>-close, but the accumulation scheme requires exact agreement. To overcome this issue, we need to make our accumulation scheme resilient to a constant <span class="math">\\delta</span>-fraction of corruptions. We do so by relying on linear codes, and in particular those which enjoy good distance properties, such as the Reed–Solomon code <em>[x20]</em>.</p>

    <p class="text-gray-300">At a high level, we make the following changes to the accumulation scheme blueprint. Let <span class="math">C</span> be a linear code, and let <span class="math">\\delta</span> be a constant which is smaller than the unique decoding radius of <span class="math">C</span>. The accumulator witness is a codeword <span class="math">C(\\mathbf{w})</span>, and the corresponding instance <span class="math">\\mathsf{acc.}\\mathbf{x}</span> is a commitment to <span class="math">\\mathsf{acc.w}</span>. The accumulation verifier checks that the output accumulator is <span class="math">\\delta</span>-close to a random linear combination of the input accumulators by running the linearity spot check. Later, the decider will check that <span class="math">\\mathsf{acc}_{3}.\\mathbf{w}</span> is the encoding of a good vector, and that <span class="math">\\mathsf{acc}_{3}.\\mathbf{x}</span> commits to <span class="math">\\mathsf{acc}_{3}.\\mathbf{w}</span>.</p>

    <h5 id="sec-12" class="text-base font-semibold mt-4">Knowledge soundness.</h5>

    <p class="text-gray-300">We would like our linearity spot check to satisfy the following knowledge soundness property. Suppose a (possibly malicious) prover outputs commitments <span class="math">\\mathsf{cm}_{1}</span>, <span class="math">\\mathsf{cm}_{2}</span>, and <span class="math">\\mathsf{cm}_{3}</span> which pass the check. Furthermore, suppose that <span class="math">\\mathsf{cm}_{3}</span> commits to a vector <span class="math">\\mathbf{v}_{3}</span>. Then an efficient extractor can find vectors <span class="math">\\mathbf{v}_{1}</span> and <span class="math">\\mathbf{v}_{2}</span> such that (a) <span class="math">\\alpha\\mathbf{v}_{1}+\\beta\\mathbf{v}_{2}</span> is <span class="math">\\delta</span>-close to <span class="math">\\mathbf{v}_{3}</span>; and (b) <span class="math">\\mathsf{cm}_{1}</span> and <span class="math">\\mathsf{cm}_{2}</span> commit to <span class="math">\\mathbf{v}_{1}</span> and <span class="math">\\mathbf{v}_{2}</span>. Notice that if we can extract vectors that satisfy (b), then our previous analysis of the spot check implies (a). Extraction turns out to be fairly straightforward: if we use Merkle commitments with a random oracle as the hash function, then we can find <span class="math">\\mathbf{v}_{1}</span> and <span class="math">\\mathbf{v}_{2}</span> by observing the prover’s random oracle queries <em>[x24]</em>.</p>

    <p class="text-gray-300">Returning to accumulation, suppose that a (possibly malicious) prover outputs <span class="math">\\mathsf{acc}_{1}.\\mathbf{x},\\mathsf{acc}_{2}.\\mathbf{x},\\mathsf{acc}_{3}</span> which pass the verifier’s and decider’s checks. Since the verifier runs the spot check, we can extract accumulator witnesses <span class="math">\\mathsf{acc}_{1}.\\mathbf{w}</span> and <span class="math">\\mathsf{acc}_{2}.\\mathbf{w}</span> such that <span class="math">\\alpha\\cdot\\mathsf{acc}_{1}.\\mathbf{w}+\\beta\\cdot\\mathsf{acc}_{2}.\\mathbf{w}</span> is <span class="math">\\delta</span>-close to <span class="math">\\mathsf{acc}_{3}.\\mathbf{w}</span>. Since the decider accepts <span class="math">\\mathsf{acc}_{3}.\\mathbf{w}</span>, we know that <span class="math">\\mathsf{acc}_{3}.\\mathbf{w}</span> is a codeword <span class="math">C(\\mathbf{w}_{3})</span>. Similarly, we need <span class="math">\\mathsf{acc}_{1}.\\mathbf{w}</span> and <span class="math">\\mathsf{acc}_{2}.\\mathbf{w}</span> to be codewords in order for the decider to accept <span class="math">\\mathsf{acc}_{1}.\\mathbf{w}</span> and <span class="math">\\mathsf{acc}_{2}.\\mathbf{w}</span>. Unfortunately, this is simply not the case. For example, a cheating prover can always choose <span class="math">\\mathsf{acc}_{1}.\\mathbf{w}</span> which agrees with a codeword at all but one location, and this will almost certainly go undetected.</p>

    <p class="text-gray-300">Can we still say something meaningful about the extracted witnesses? We argue that intuitively, since <span class="math">\\alpha</span> and <span class="math">\\beta</span> are (possibly correlated) random scalars, with high probability <span class="math">\\mathsf{acc}_{1}.\\mathbf{w}</span> and <span class="math">\\mathsf{acc}_{2}.\\mathbf{w}</span> are themselves <span class="math">\\delta</span>-close to codewords. Moreover, <span class="math">\\mathsf{acc}_{1}.\\mathbf{w}</span> and <span class="math">\\mathsf{acc}_{2}.\\mathbf{w}</span> decode to <span class="math">\\mathbf{w}_{1}</span> and <span class="math">\\mathbf{w}_{2}</span> such that <span class="math">\\alpha\\cdot\\mathbf{w}_{1}+\\beta\\cdot\\mathbf{w}_{2}=\\mathbf{w}_{3}</span>. This intuition can be formally proven using a suitable “proximity gap” result <em>[x1]</em>, which exists for a variety of parameter regimes.</p>

    <p class="text-gray-300">The upshot is that we extract accumulators <span class="math">\\mathsf{acc}_{1}</span> and <span class="math">\\mathsf{acc}_{2}</span> which are only accepted by a <em>relaxed</em> decider. Namely, given an accumulator <span class="math">\\mathsf{acc}</span>, this decider checks that <span class="math">\\mathsf{acc.}\\mathbf{x}</span> commits to <span class="math">\\mathsf{acc.w}</span>, and moreover that <span class="math">\\mathsf{acc.w}</span> is <span class="math">\\delta</span>-close to the code.</p>

    <h5 id="sec-13" class="text-base font-semibold mt-4">Recursive extraction.</h5>

    <p class="text-gray-300">The foregoing analysis suffices for a single step of accumulation. However, in order to construct PCD, we will have to recursively extract from old accumulators. It is straightforward to see that a recursively extracted accumulator is only guaranteed to be <span class="math">2\\delta</span>-close to the code, since we are extracting from an accumulator that may already be <span class="math">\\delta</span>-far from the code. More generally, <span class="math">k</span> steps of recursion will only guarantee accumulators that are <span class="math">k\\delta</span>-close to the code. We will see that once <span class="math">k\\delta</span> is larger than the unique decoding radius, extraction is no longer meaningful. In particular, this leads to the following concrete attack: a cheating prover can start with a bad codeword (rejected by the decider) and, over the <span class="math">k</span> accumulation steps, incrementally move it to a good codeword (accepted by the decider). This motivates our notion of “bounded-depth” accumulation, which is not captured by existing definitions <em>[x1]</em>.</p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">To describe our construction which only supports accumulation up to a certain (constant) depth, we introduce a new, relaxed knowledge soundness property; the key differences are highlighted in blue. We say that an accumulation scheme has bounded-depth knowledge soundness (with maximum depth  <span class="math">d</span> ) if there exists a family of deciders  <span class="math">\\{\\mathrm{D}_s\\}_{s=0}^d</span> , where  <span class="math">\\mathrm{D}</span>  is equivalent to  <span class="math">\\mathrm{D}_0</span> , such that the following holds. If  <span class="math">\\mathrm{D}_{s-1}(\\mathsf{acc}&#x27;) = 1</span>  and  <span class="math">\\mathrm{V}(\\mathbf{x}, \\pi.\\mathbf{x}, \\mathsf{acc}.\\mathbf{x}, \\mathsf{acc}&#x27;.\\mathbf{x}) = 1</span> , then an efficient extractor can find  <span class="math">\\pi.\\mathbf{w}</span>  and  <span class="math">\\mathsf{acc}.\\mathbf{w}</span>  such that  <span class="math">\\mathcal{V}(\\mathbf{x}, \\pi) = 1</span>  and  <span class="math">\\mathrm{D}_s(\\mathsf{acc}) = 1</span> .</p>

    <p class="text-gray-300">This is a meaningful definition. In addition to generalizing standard knowledge soundness, which can be recovered by setting  <span class="math">d = \\infty</span>  and using a single decider D, it captures our construction based on error-resilient linearity checks:  <span class="math">\\mathrm{D}_s</span>  is the decider that only accepts if the accumulator is at most  <span class="math">s\\delta</span> -far from the code, and in particular  <span class="math">\\mathrm{D}_0</span>  only accepts codewords. The depth bound  <span class="math">d</span>  is the maximum number of recursive extractions that we can perform before  <span class="math">d\\delta</span>  exceeds the unique decoding radius of the code.</p>

    <p class="text-gray-300">Existing theorems that build PCD from accumulation [BCLMS21; BDFG21; KST22] do not immediately translate to the bounded-depth setting. To see why, let us recall a simplified version of the construction from [BCLMS21]. Suppose we have an accumulation scheme for a non-interactive argument of knowledge (NARK). Informally, a PCD proof for  <span class="math">z_{i}</span> , which consists of a NARK proof  <span class="math">\\pi_{i}</span>  and accumulator  <span class="math">\\mathsf{acc}_i</span> , certifies that  <span class="math">z_{i} = F^{i}(z_{0})</span> , where  <span class="math">z_{0}</span>  is some initial value. We maintain the invariant that if  <span class="math">\\pi_{i}</span>  and  <span class="math">\\mathsf{acc}_i</span>  are valid, then the computation is correct up to the  <span class="math">i</span> -th step.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The PCD prover receives a proof  <span class="math">(\\pi_i, \\mathsf{acc}_i)</span>  for  <span class="math">z_i</span> , and wants to output a proof for  <span class="math">z_{i+1}</span> . First, it accumulates  <span class="math">\\pi_i</span>  and  <span class="math">\\mathsf{acc}_i</span>  into a new accumulator  <span class="math">\\mathsf{acc}_{i+1}</span> , generating an accumulation proof  <span class="math">\\mathsf{pf}_{i+1}</span> . Next, it generates a NARK proof  <span class="math">\\pi_{i+1}</span>  for the following claim, expressed as a circuit  <span class="math">R</span>  (see Figure 1): “ <span class="math">z_{i+1} = F(z_i)</span> , and there exists a NARK proof  <span class="math">\\pi_i</span> , old accumulator  <span class="math">\\mathsf{acc}_i</span> , and accumulation proof  <span class="math">\\mathsf{pf}_{i+1}</span>  which correctly accumulate into  <span class="math">\\mathsf{acc}_{i+1}</span> .” The proof for  <span class="math">z_{i+1}</span>  is  <span class="math">(\\pi_{i+1}, \\mathsf{acc}_{i+1})</span> .</li>

      <li>The PCD verifier checks a proof  <span class="math">(\\pi_i, \\mathsf{acc}_i)</span>  for  <span class="math">z_i</span>  by running the NARK verifier on  <span class="math">\\pi_i</span>  and the decider on  <span class="math">\\mathsf{acc}_i</span> .</li>

    </ul>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Figure 1: Recursion circuit for PCD.</p>

    <p class="text-gray-300">Now suppose we replace the accumulation scheme with one that only has bounded-depth knowledge soundness. The construction remains the same, but we must provide a new soundness analysis.</p>

    <p class="text-gray-300">PCD knowledge soundness. We need to construct an extractor which, given an accepting proof  <span class="math">(\\pi_T,\\mathsf{acc}_T)</span>  for  <span class="math">z_{T}</span> , extracts a sequence of values  <span class="math">z_0,\\ldots ,z_T</span>  such that  <span class="math">z_{i + 1} = F(z_i)</span>  for all  <span class="math">i</span> . [BCLMS21] gives the following strategy, which interleaves the NARK extractor and accumulation extractor. Suppose we have  <span class="math">z_{i + 1}</span> ,  <span class="math">\\pi_{i + 1}</span> , and  <span class="math">\\mathsf{acc}_{i + 1}</span> . First, we invoke the NARK extractor to obtain  <span class="math">(z_{i},\\pi_{i}.\\mathbf{x},\\mathsf{acc}_{i}.\\mathbf{x},\\mathsf{pf}_{i + 1})</span> . Second, we invoke</p>

    <p class="text-gray-300">the accumulation extractor to obtain  <span class="math">(\\pi_i.\\mathbf{w},\\mathbf{acc}_i.\\mathbf{w})</span> . This gives us  <span class="math">\\pi_{i}</span>  and  <span class="math">\\mathbf{acc}_i</span> , and the process continues. We maintain the invariant that in the  <span class="math">i</span> -th step,  <span class="math">\\pi_{i}</span>  and  <span class="math">\\mathbf{acc}_i</span>  are valid.</p>

    <p class="text-gray-300">With bounded-depth accumulation, we need to maintain a slightly weaker invariant: in the  <span class="math">i</span> -th step, instead of requiring that  <span class="math">\\mathsf{acc}_i</span>  is accepted by the strict decider D, we only require that it is accepted by the  <span class="math">i</span> -th relaxed decider  <span class="math">\\mathrm{D}_i</span> . This discussion only provides a high-level overview of the proof strategy, and only describes an IVC construction; we describe the full PCD construction that supports arbitrary (bounded-depth) computation graphs, along with a full soundness analysis, in Section 5.</p>

    <p class="text-gray-300">Remark 2.1 (bounded-depth PCD suffices). As presented, our PCD scheme supports up to  <span class="math">d</span>  steps of computation, where  <span class="math">d</span>  is the maximum depth of the accumulation scheme. We call this bounded-depth PCD. Since  <span class="math">d</span>  will realistically be a small constant, this seems to be of limited use: most computations require more than a constant number of steps! Fortunately, even such a limited PCD scheme can be used to construct IVC for any polynomial-length computation [BCCT13]. The idea is for the PCD prover to receive multiple proofs in each step, yielding a computation tree. In particular, if we can accumulate  <span class="math">m</span>  inputs and  <span class="math">m</span>  accumulators in a single step, then our PCD scheme can support computation trees of size  <span class="math">m^d</span> . Setting  <span class="math">m = \\lambda</span>  and  <span class="math">d = O(1)</span>  allows us to support polynomial-size computations.</p>

    <p class="text-gray-300">Remark 2.2 (bounded-depth vs. constant-depth PCD). Perhaps surprisingly, even with standard (unbounded) accumulation, [BCLMS21] is only able to construct constant-depth  <span class="math">PCD</span> . This is because the size of the PCD extractor grows exponentially in the computation's depth, regardless of the accumulation scheme's knowledge soundness property. We remark that this limitation is largely theoretical: there is no known attack which exploits unbounded recursive proof composition. In contrast, the depth bound in bounded-depth PCD is not merely an artifact of the analysis: there exists a concrete attack that can be mounted against our construction when the depth exceeds  <span class="math">d</span> . This means that the tree-based strategy described in Remark 2.1 is necessary for real-world implementations, unlike in prior work.</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Figure 2: Construction of PCD from bounded-depth accumulation.</p>

    <p class="text-gray-300">Our starting point is the ProtoStar and ProtoGalaxy accumulation schemes [BC23; EG23]. They support a general class of non-interactive arguments where consists of the NP witness along with a short vector</p>

    <p class="text-gray-300">commitment to the witness, and whose verifier performs three steps: (a) computing Fiat–Shamir challenges; (b) checking vector commitment openings; and (c) evaluating a polynomial over the instance, challenges, and openings. The key insight of ProtoStar and ProtoGalaxy is that the accumulation verifier can cheaply perform the first step, while batching the remaining steps and deferring it to the decider.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let us recall ProtoGalaxy’s strategy <em>[x10]</em>, focusing on the case where we are trying to accumulate claims about satisfaction of R1CS, a popular NP language in the succinct argument literature. Recall that an R1CS instance consists of constraint matrices <span class="math">A,B,C\\in\\mathbb{F}^{N\\times(\\ell+n)}</span>, and is said to be satisfied by a public input <span class="math">x\\in\\mathbb{F}^{\\ell}</span> and witness <span class="math">w\\in\\mathbb{F}^{n}</span> if $A\\cdot(x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w)\\circ B\\cdot(x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w)-C\\cdot(x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w)=0^{N}<span class="math">. In ProtoGalaxy, a NARK proof for an R1CS instance with public input </span>x<span class="math"> would consist of the proof witness, which is just the R1CS witness </span>w<span class="math">, and the proof instance, which is just a vector commitment to </span>w<span class="math">. The polynomial </span>p<span class="math"> evaluated by the verifier is of the form </span>p(x,w)=A\\cdot(x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w)\\circ B\\cdot(x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w)-C\\cdot(x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w)<span class="math">. Then, to accumulate R1CS claims, ProtoGalaxy’s accumulator witness acc.w is also a vector </span>w\\in\\mathbb{F}^{n}<span class="math">, and its accumulator instance acc.x consists of a vector </span>\\vec{x}\\in\\mathbb{F}^{\\ell}<span class="math">, a (homomorphic) vector commitment to </span>w<span class="math">, and an error term </span>e\\in\\mathbb{F}$. Thus, a NARK proof verification claim can be seen as a special case of the accumulator verification case where the error term is zero.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">To accumulate <span class="math">m</span> such (accumulation or NARK) verification claims for accumulators <span class="math">\\mathsf{acc}_{1},\\ldots,\\mathsf{acc}_{m}</span>, ProtoGalaxy relies on the following univariate polynomial identity:</p>

    <p class="text-gray-300"><span class="math">p\\left(\\sum_{i=1}^{m}L_{i}(X)\\cdot x_{i},\\sum_{i=1}^{m}L_{i}(X)\\cdot w_{i}\\right)=\\sum_{i=1}^{m}L_{i}(X)\\cdot e_{i}\\mod v_{H}(X)\\quad,</span></p>

    <p class="text-gray-300">where <span class="math">L_{i}</span> is the <span class="math">i</span>-th Lagrange polynomial of some <span class="math">m</span>-sized set <span class="math">H\\subset\\mathbb{F}</span>, and <span class="math">v_{H}(X)</span> is the vanishing polynomial on <span class="math">H</span>. For some quotient polynomial <span class="math">q</span>, this claim can be rewritten as</p>

    <p class="text-gray-300"><span class="math">p\\left(\\sum_{i=1}^{m}L_{i}(X)\\cdot x_{i},\\sum_{i=1}^{m}L_{i}(X)\\cdot w_{i}\\right)=\\sum_{i=1}^{m}L_{i}(X)\\cdot e_{i}+q(X)\\cdot v_{H}(X)\\quad,</span></p>

    <p class="text-gray-300">and this formulation allows the verifier to check the identity at a random point <span class="math">\\alpha\\in\\mathbb{F}</span> if the prover sends <span class="math">q</span>.</p>

    <p class="text-gray-300">This allows us to accumulate the <span class="math">m</span> input claims as follows. The prover constructs a new accumulator acc whose new instance is <span class="math">x:=\\sum_{i}L_{i}(\\alpha)\\cdot x_{i}</span>, new witness vector is <span class="math">w:=\\sum_{i}L_{i}(\\alpha)\\cdot w_{i}</span>, and the new error is <span class="math">e:=v(\\alpha)\\cdot q(\\alpha)+\\sum_{i}L_{i}(\\alpha)\\cdot e_{i}</span>. The verifier checks that acc was computed correctly by homomorphically computing the new vector commitment, and directly computing the new instance and new error term. Finally, the accumulation decider completes the checks by asserting that that <span class="math">p(x,w)=e</span>.</p>

    <h4 id="sec-17" class="text-lg font-semibold mt-6">Our construction.</h4>

    <p class="text-gray-300">We follow the same strategy, except we replace homomorphic computations with error-resilient linearity checks. Concretely, we make the following changes. An accumulator witness is a codeword <span class="math">f\\in C</span>, and an accumulator instance consists of a vector commitment to <span class="math">f</span> and an error term <span class="math">e\\in\\mathbb{F}</span>. The decider accepts an accumulator if <span class="math">f</span> is the encoding of a vector <span class="math">w\\in\\mathbb{F}^{n}</span> such that <span class="math">p(x,w)=e</span>. Finally, as discussed in Section 2.1, the verifier uses a linearity check to ensure that the new accumulator acc is sufficiently consistent with the old accumulators <span class="math">\\mathsf{acc}_{1},\\ldots,\\mathsf{acc}_{m}</span>.</p>

    <p class="text-gray-300">Overall, our construction inherits many desirable properties from ProtoStar <em>[x5]</em> and ProtoGalaxy <em>[x10]</em>, including support for arbitrary arity <span class="math">m=\\mathrm{poly}(\\lambda)</span>, which is crucial for constructing PCD (see Remark 2.1), and efficient support for custom gates.</p>

    <h4 id="sec-18" class="text-lg font-semibold mt-6">Security.</h4>

    <p class="text-gray-300">Our construction naturally corresponds with an interactive oracle proof (IOP) <em>[x6]</em>, where the codewords are now given as oracles instead of vector commitments. Indeed, we prove knowledge soundness of the accumulation scheme by proving soundness of the underlying IOP, and then applying the BCS transformation <em>[x6]</em> (with some technical subtleties).</p>

    <h4 id="sec-19" class="text-lg font-semibold mt-6">Extension to arbitrary linear codes.</h4>

    <p class="text-gray-300">A key parameter in our construction is the linear code. We use Reed–Solomon codes because they display a proximity gap when the coefficients are Lagrange evaluations <span class="math">L_{1}(\\alpha),\\ldots,L_{m}(\\alpha)</span>. However, a modified version of our construction extends to arbitrary linear codes. This is advantageous as these codes can have faster asymptotically faster encoding time compared to Reed–Solomon codes <em>[x10]</em>. The construction can work with any proximity gap (e.g., uniformly random coefficients). The key idea is to commit to two codes within the accumulator, one for proximity checking and the other for the algebraic check using <span class="math">p(X)</span>. See Section 6.4 for details.</p>

    <h4 id="sec-20" class="text-lg font-semibold mt-6">Efficiency.</h4>

    <p class="text-gray-300">The cost of the accumulation verifier is dominated by that of the linearity checker. Recall that to achieve negligible knowledge soundness error at depth <span class="math">d</span>, the latter checks that two code words are <span class="math">d\\cdot\\delta</span> close via <span class="math">k=O(d\\cdot\\lambda)</span> spot checks, where <span class="math">\\delta</span> is such that <span class="math">d\\cdot\\delta</span> is less than the unique decoding radius of the code. Overall, when instantiated with the Merkle tree-based vector commitment, the accumulation verifier checks <span class="math">O(d\\cdot\\lambda)</span> Merkle tree paths. When applying this construction to the PCD scheme in Section 2.3, the latter cost becomes the <em>recursive overhead</em> of the PCD prover. As noted in Table 1, this cost is asymptotically better than the <span class="math">O(\\log n\\cdot\\lambda)</span> cost of prior SNARK-based PCD schemes <em>[x4]</em>.</p>

    <p class="text-gray-300">A keen reader may notice that a disadvantage of our construction is that recursive overhead scales with the depth of the PCD computation graph. We now present several optimizations that reduce the depth of the PCD tree and significantly improve the efficiency of the resulting PCD scheme in practice.</p>

    <h3 id="sec-21" class="text-xl font-semibold mt-8">2.5 Optimization: batch commitments</h3>

    <p class="text-gray-300">Recall from Remarks 2.1 and 2.2 that for our PCD construction, reducing the depth of the computation graph is essential for achieving provable security guarantees, and the standard depth-reduction technique for the case of IVC <em>[x1]</em> works by constructing a <em>PCD tree</em> whose leaves comprise the actual computation being performed. To achieve constant computation depth, Bitansky et al. <em>[x1]</em> set the arity <span class="math">m</span> of this tree to be super-constant (i.e., <span class="math">m=\\lambda</span>). The per-node recursive overhead of our PCD construction in this setting is the cost of performing linearity checks on <span class="math">m</span> codewords of size <span class="math">n</span>, which costs <span class="math">O(m\\cdot\\lambda\\cdot\\log n)</span> hashes when using Merkle trees. We now describe how to reduce this to just <span class="math">O(\\lambda(\\log n+m))</span> hashes.</p>

    <p class="text-gray-300">Recall that the linearity checker opens all <span class="math">m</span> codewords at the same locations. This means that for each spot-check, each of the <span class="math">m</span> Merkle trees is opened at the same leaf. We take advantage of this repetitive structure by committing to all <span class="math">m</span> codewords using a <em>single</em> Merkle tree whose <span class="math">i</span>-th leaf is the concatenation of the <span class="math">i</span>-th symbols of the codewords. Each spot-check now requires opening only a single Merkle tree path (and checking the leaf hash), leading to a cost of <span class="math">O(\\lambda(\\log n+m))</span> hashes for <span class="math">O(\\lambda)</span> spot checks, as required.</p>

    <p class="text-gray-300">However, this modification comes at a cost: it requires us to commit to all codewords together at the same time. While this is straightforward at the leaf layer, it gets more complex at higher layers. For example, even committing to a new accumulator now requires waiting for the batch of “sibling” new accumulators, which in turn means that we must wait for <span class="math">m</span> accumulations (each of size <span class="math">m</span>) to complete before we can compute the commitments to the <span class="math">m</span> new accumulators. Overall, across the entire tree, this requires the PCD prover to maintain a state of <span class="math">O(m^{2})</span> “pending” accumulators. The resulting PCD scheme is illustrated in Figure 3, and we provide more details in Section 7.1.</p>

    <h3 id="sec-22" class="text-xl font-semibold mt-8">2.6 Optimization: low-overhead IVC from accumulation</h3>

    <p class="text-gray-300">We give a generic optimization which improves on the PCD-to-IVC compiler of Bitansky et al. <em>[x23, x1]</em>. They construct a (polynomial-length) IVC scheme for a function <span class="math">F</span> by using a (constant-depth) PCD scheme for a related function <span class="math">F^{\\prime}</span>. In particular, <span class="math">F^{\\prime}</span> computes <span class="math">F</span> (at leaf nodes) and performs consistency</p>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a> Figure 3: PCD with batch commitments.</p>

    <p class="text-gray-300">checks (at internal nodes). This is wasteful: even though we do not need to prove anything about  <span class="math">F</span>  at internal nodes, the PCD prover still generates a proof for  <span class="math">F&#x27;</span>  (which is dominated by  <span class="math">F</span> ).</p>

    <p class="text-gray-300">We improve this compiler by constructing an IVC scheme with minimal overhead. The core idea is that we first construct a tree of accumulators for  <span class="math">F</span> , i.e., a tree the leaf nodes are proofs for  <span class="math">F</span> , and each parent accumulates its children. Then, we construct a PCD tree which proves that the accumulation tree was constructed correctly. When the PCD scheme is instantiated with our accumulation-based construction, the PCD circuit now checks two accumulation verifiers: one that checks the correctness of the accumulation tree, and one that helps check the correctness of the PCD tree.</p>

    <p class="text-gray-300">Accumulating separately means that we no longer have to generate NARK proofs for  <span class="math">F</span>  at internal nodes. Additionally, because we only need to show that internal nodes of the accumulation tree were constructed correctly, our PCD tree has one fewer layer than before. This further reduces cost, in particular for higher arities (as  <span class="math">m</span>  grows, the leaf layer of a tree contains a higher fraction of nodes). The resulting IVC scheme is illustrated in Figure 4, and we provide more details in Section 7.2.</p>

    <p class="text-gray-300">The recursive overhead of our PCD scheme grows linearly with the maximum supported depth. This is contrast with SNARK-based PCD schemes like Fractal [COS20], which do not suffer from such an efficiency loss. However, these schemes pay a higher per-step cost anyway, and are thus asymptotically less efficient than our PCD scheme for low recursion depths.</p>

    <p class="text-gray-300">We provide a generic optimization to combine SNARK-based PCD schemes with our PCD scheme to achieve a scheme that is achieves better efficiency than either scheme alone. The core idea is to first use our accumulation-based PCD up to some depth  <span class="math">d_{1}</span> , and then prove the PCD verifier for the latter with a SNARK-based PCD scheme on top. When invoked with tree PCD, this means that the SNARK-based PCD scheme is invoked only every  <span class="math">m^{d_1}</span>  steps. By choosing  <span class="math">d_{1}</span>  appropriately, the resulting scheme achieves better efficiency than either scheme alone. Furthermore, the resulting scheme supports arbitrary constant depth, as opposed to our accumulation-based scheme, which only supports an a priori fixed depth. We illustrate this idea in Figure 5, and provide details in Section 7.3.</p>

    <p class="text-gray-300">!<a href="img-3.jpeg">img-3.jpeg</a> Figure 4: PCD-to-IVC compiler that checks the correctness of an accumulation tree.</p>

    <p class="text-gray-300">!<a href="img-4.jpeg">img-4.jpeg</a> Figure 5: PCD composition.</p>

    <p class="text-gray-300">Indexed relations. An indexed relation  <span class="math">\\mathcal{R}</span>  is a set of triples  <span class="math">(\\dot{\\mathfrak{i}},\\mathfrak{z},\\mathfrak{w})</span>  where  <span class="math">\\dot{\\mathfrak{i}}</span>  is the index,  <span class="math">\\mathfrak{z}</span>  is the instance, and  <span class="math">\\mathfrak{w}</span>  is the witness; the corresponding indexed language  <span class="math">\\mathcal{L}(\\mathcal{R})</span>  is the set of pairs  <span class="math">(\\dot{\\mathfrak{i}},\\mathfrak{z})</span>  for which there exists a witness  <span class="math">\\mathfrak{w}</span>  such that  <span class="math">(\\dot{\\mathfrak{i}},\\mathfrak{z},\\mathfrak{w})\\in \\mathcal{R}</span> . For example, the indexed relation of satisfiable boolean circuits consists of triples where  <span class="math">\\dot{\\mathfrak{i}}</span>  is the description of a boolean circuit,  <span class="math">\\mathfrak{z}</span>  is a partial assignment to its input wires, and  <span class="math">\\mathfrak{w}</span>  is an assignment to the remaining wires that makes the boolean circuit output 0.</p>

    <p class="text-gray-300">Security parameters. For simplicity of notation, we assume that all public parameters have length at least  <span class="math">\\lambda</span> , so that algorithms which receive such parameters can run in time  <span class="math">\\mathrm{poly}(\\lambda)</span> .</p>

    <p class="text-gray-300">Random oracles. We denote by  <span class="math">\\mathcal{U}(\\lambda)</span>  the set of all functions that map  <span class="math">\\{0,1\\}^<em></span>  to  <span class="math">\\{0,1\\}^\\lambda</span> . A random oracle with security parameter  <span class="math">\\lambda</span>  is a function  <span class="math">\\rho \\colon \\{0,1\\}^</em> \\to \\{0,1\\}^\\lambda</span>  sampled uniformly at random from  <span class="math">\\mathcal{U}(\\lambda)</span> . In our random oracle definitions, we assume that all algorithms (except generators and setup algorithms), adversaries, and extractors have access to the random oracle.</p>

    <p class="text-gray-300">Adversaries. All of the definitions in this paper should be taken to refer to non-uniform adversaries. An adversary (or extractor) running in expected polynomial time is then a Turing machine provided with a polynomial-size non-uniform advice string and access to an infinite random tape, whose expected running time for all choices of advice is polynomial. We sometimes write  <span class="math">(\\mathsf{o};r)\\gets A(x)</span>  when  <span class="math">A</span>  is an expected polynomial-time algorithm, where  <span class="math">\\mathsf{o}</span>  is the output of  <span class="math">A</span>  and  <span class="math">r</span>  is the randomness used by  <span class="math">A</span>  (i.e. up to the rightmost position of the head on the randomness tape).</p>

    <p class="text-gray-300">Hamming distance. Let  <span class="math">\\Sigma</span>  be an alphabet, typically  <span class="math">\\mathbb{F} \\cup \\{\\bot\\}</span> . The relative Hamming distance between two vectors  <span class="math">f, g \\in \\Sigma^n</span> , denoted  <span class="math">\\Delta(f, g)</span> , is the number of locations where  <span class="math">f</span>  and  <span class="math">g</span>  disagree, divided by  <span class="math">n</span> . The distance between a vector  <span class="math">f \\in \\Sigma^n</span>  and a subset  <span class="math">S \\subset \\Sigma^n</span> , denoted  <span class="math">\\Delta(f, S)</span> , is equal to  <span class="math">\\min_{g \\in S} \\Delta(f, g)</span> .</p>

    <p class="text-gray-300">Polynomials. For any field  <span class="math">\\mathbb{F}</span>  and subset  <span class="math">H = \\{a_{1},\\ldots ,a_{k}\\} \\subset \\mathbb{F}</span> , let  <span class="math">L_{i,H}</span>  denote the  <span class="math">i</span> -th Lagrange polynomial, i.e. the unique polynomial of degree less than  <span class="math">k</span>  such that  <span class="math">L_{i,H}(a_i) = 1</span>  and  <span class="math">L_{i,H}(a_j) = 0</span>  for all  <span class="math">j\\neq i</span> . Let  <span class="math">v_{H}</span>  denote the vanishing polynomial on  <span class="math">H</span> , i.e.  <span class="math">v_{H}(X) = \\prod_{i = 1}^{m}(X - a_{i})</span> . When clear from context, we omit the set  <span class="math">H</span> .</p>

    <p class="text-gray-300">In the standard definition of a non-interactive argument of knowledge (NARK), completeness and knowledge soundness hold for the same verifier. We introduce a "relaxed" verifier, for which only knowledge soundness must hold. In other words, an extractor must be able to extract a witness for any proof accepted by the relaxed verifier, but completeness only needs to hold for the original verifier. Concretely, a tuple of algorithms  <span class="math">\\mathsf{ARG} = (\\mathcal{G},\\mathcal{P},\\mathcal{V})</span>  is a non-interactive argument of knowledge in the random oracle model for an indexed relation family  <span class="math">\\{\\mathcal{R}_{\\mathsf{pp}}\\}_{\\mathsf{pp}}</span>  if the following properties hold.</p>

    <p class="text-gray-300">Completeness. For every (unbounded) adversary  <span class="math">\\mathcal{A}</span> ,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} (\\dot {\\mathfrak {i}}, \\mathfrak {z}, \\mathfrak {w}) \\in \\mathcal {R} _ {\\mathsf {p p}} &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\Downarrow &amp;amp; \\mathsf {p p} \\leftarrow \\mathcal {G} (1 ^ {\\lambda}) \\\\ \\mathcal {V} (\\mathsf {p p}, \\dot {\\mathfrak {i}}, \\mathfrak {z}, \\pi) = 1 &amp;amp; (\\dot {\\mathfrak {i}}, \\mathfrak {z}, \\mathfrak {w}) \\leftarrow \\mathcal {A} (\\mathsf {p p}) \\\\ &amp;amp; \\pi \\leftarrow \\mathcal {P} (\\mathsf {p p}, \\dot {\\mathfrak {i}}, \\mathfrak {z}, \\mathfrak {w}) \\end{array} \\right] = 1.</span></div>

    <p class="text-gray-300">Knowledge soundness. We say that ARG has knowledge soundness for a relaxed verifier  <span class="math">\\hat{\\mathcal{V}}</span> , i.e.  <span class="math">\\mathcal{V}</span>  accepting implies  <span class="math">\\hat{\\mathcal{V}}</span>  accepting, if there exists an expected polynomial time extractor  <span class="math">\\mathcal{E}</span>  such that for every expected</p>

    <p class="text-gray-300">polynomial time adversary  <span class="math">\\tilde{\\mathcal{P}}</span> , and auxiliary input distribution  <span class="math">\\mathcal{D}</span> , the following probability is negligibly close to 1:</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} \\hat {\\mathcal {V}} (\\mathsf {p p}, \\mathfrak {i}, \\mathbf {x}, \\pi) = 1 &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\Downarrow &amp;amp; \\mathsf {p p} \\leftarrow \\mathcal {G} (1 ^ {\\lambda}) \\\\ (\\mathfrak {i}, \\mathbf {x}, \\mathsf {w}) \\in \\mathcal {R} _ {\\mathsf {p p}} &amp;amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (1 ^ {\\lambda}) \\\\ &amp;amp; (\\mathfrak {i}, \\mathbf {x}, \\pi ; r) \\leftarrow \\tilde {\\mathcal {P}} (\\mathsf {p p}, \\mathsf {a i}) \\\\ &amp;amp; \\mathsf {w} \\leftarrow \\mathcal {E} ^ {\\tilde {\\mathcal {P}}} (\\mathsf {p p}, \\mathsf {a i}, r) \\end{array} \\right]</span></div>

    <p class="text-gray-300">Remark 3.1. Clearly, any standard NARK satisfies our definition by setting the relaxed verifier to be the original verifier. However, our accumulation construction will require a non-trivial relaxation.</p>

    <p class="text-gray-300">Multi-instance extraction. As in [BCLMS21], we also define a weaker notion of knowledge soundness which is implied by the earlier definition. For every expected polynomial time adversary  <span class="math">\\tilde{\\mathcal{P}}</span>  and auxiliary input distribution  <span class="math">\\mathcal{D}</span> , there exists an expected polynomial time extractor  <span class="math">\\mathcal{E}_{\\tilde{\\mathcal{P}}}</span>  such that for every set  <span class="math">Z</span> ,</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\Pr \\left[ \\begin{array}{c c} (\\mathsf {p p}, \\mathsf {a i}, \\vec {\\mathbb {i}}, \\vec {\\mathbb {x}}, \\mathsf {a o}) \\in Z &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\forall j \\in [ \\ell ], (\\mathfrak {i} _ {j}, \\mathbb {x} _ {j}, \\mathbb {w} _ {j}) \\in \\mathcal {R} _ {\\mathsf {p p}} &amp;amp; \\mathsf {p p} \\leftarrow \\mathcal {G} (1 ^ {\\lambda}) \\\\ &amp;amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (1 ^ {\\lambda}) \\\\ &amp;amp; (\\vec {\\mathbb {i}}, \\vec {\\mathbb {x}}, \\vec {\\mathbb {w}}, \\mathsf {a o}) \\leftarrow \\mathcal {E} _ {\\tilde {\\mathcal {P}}} (\\mathsf {p p}, \\mathsf {a i}) \\end{array} \\right] \\\\ \\geq \\Pr \\left[ \\begin{array}{c c} (\\mathsf {p p}, \\mathsf {a i}, \\vec {\\mathbb {i}}, \\vec {\\mathbb {x}}, \\mathsf {a o}) \\in Z &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\forall j \\in [ \\ell ], \\mathcal {V} (\\mathfrak {i} _ {j}, \\mathbb {x} _ {j}, \\pi_ {j}) = 1 &amp;amp; \\mathsf {p p} \\leftarrow \\mathcal {G} (1 ^ {\\lambda}) \\\\ &amp;amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (1 ^ {\\lambda}) \\\\ &amp;amp; (\\vec {\\mathbb {i}}, \\vec {\\mathbb {x}}, \\vec {\\pi}, \\mathsf {a o}) \\leftarrow \\tilde {\\mathcal {P}} (\\mathsf {p p}, \\mathsf {a i}) \\end{array} \\right] - \\operatorname {n e g l} (\\lambda). \\\\ \\end{array}</span></div>

    <p class="text-gray-300">Before we define proof-carrying data (PCD), we recall some terminology. A transcript  <span class="math">\\mathsf{T}</span>  is a directed acyclic graph where each vertex  <span class="math">u\\in V(\\mathsf{T})</span>  is labeled by local data  <span class="math">z_{\\mathrm{loc}}^{(u)}</span>  and each edge  <span class="math">e\\in E(\\mathsf{T})</span>  is labeled by a message  <span class="math">z^{(e)}\\neq \\bot</span> . The output of a transcript  <span class="math">\\mathsf{T}</span> , denoted  <span class="math">\\mathsf{o}(\\mathsf{T})</span> , is  <span class="math">z^{(e)}</span>  where  <span class="math">e = (u,v)</span>  is the lexicographically-first edge such that  <span class="math">v</span>  is a sink.</p>

    <p class="text-gray-300">Compliance. A vertex  <span class="math">u \\in V(\\mathsf{T})</span>  is  <span class="math">\\varphi</span> -compliant for some compliance predicate  <span class="math">\\varphi : \\{0,1\\}^* \\to \\{0,1\\}</span>  if for all outgoing edges  <span class="math">e = (u,v) \\in E(\\mathsf{T}) \\in E(\\mathsf{T})</span> , one of the following holds. If  <span class="math">u</span>  has no incoming edges,  <span class="math">\\varphi(z^{(e)}, z_{\\mathrm{loc}}^{(u)}, \\bot, \\ldots, \\bot)</span>  accepts. If  <span class="math">u</span>  has incoming edges  <span class="math">e_1, \\ldots, e_m</span> ,  <span class="math">\\varphi(z^{(e)}, z_{\\mathrm{loc}}^{(u)}, z^{(e_1)}, \\ldots, z^{(e_m)})</span>  accepts. We say that a transcript is  <span class="math">\\varphi</span> -compliant if all of its vertices are  <span class="math">\\varphi</span> -compliant.</p>

    <p class="text-gray-300">Depth. The depth of a transcript  <span class="math">\\mathsf{T}</span>  is the largest number of nodes on a source-to-sink path in  <span class="math">\\mathsf{T}</span> , minus two (to ignore the source and sink). The depth of a compliance predicate  <span class="math">\\varphi</span> , denoted  <span class="math">\\mathsf{d}(\\varphi)</span> , is defined to be the maximum depth over all  <span class="math">\\varphi</span> -compliant transcripts.</p>

    <p class="text-gray-300">A tuple of algorithms  <span class="math">\\mathsf{PCD} = (\\mathbb{G},\\mathbb{I},\\mathbb{P},\\mathbb{V})</span>  is a proof-carrying data scheme for a class of compliance predicates  <span class="math">\\mathsf{F}</span>  if the following properties hold.</p>

    <p class="text-gray-300">Completeness. For every (unbounded) adversary  <span class="math">\\mathcal{A}</span> ,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} \\varphi \\in \\mathsf {F} &amp;amp; \\mathfrak {p p} \\leftarrow \\mathbb {G} (1 ^ {\\lambda}) \\\\ \\varphi (z, z _ {\\mathrm {l o c}}, z _ {1}, \\ldots , z _ {m}) = 1 &amp;amp; (\\varphi , z, z _ {\\mathrm {l o c}}, [ z _ {i}, \\pi_ {i} ] _ {i = 1} ^ {m}) \\leftarrow \\mathcal {A} (\\mathfrak {p p}) \\\\ \\forall i, z _ {i} = \\bot \\lor \\forall i, \\mathbb {V} (\\mathsf {i v k}, z _ {i}, \\pi_ {i}) = 1 &amp;amp; (\\mathsf {i p k}, \\mathsf {i v k}) \\leftarrow \\mathbb {I} (\\mathfrak {p p}, \\varphi) \\\\ \\Downarrow &amp;amp; \\pi \\leftarrow \\mathbb {P} (\\mathsf {i p k}, z, z _ {\\mathrm {l o c}}, [ z _ {i}, \\pi_ {i} ] _ {i = 1} ^ {m}) \\end{array} \\right] = 1.</span></div>

    <p class="text-gray-300">Knowledge soundness. For every expected polynomial time adversary  <span class="math">\\tilde{\\mathbb{P}}</span>  there exists an expected polynomial-time extractor  <span class="math">\\mathbb{E}_{\\tilde{\\mathbb{P}}}</span>  such that for every auxiliary input distribution  <span class="math">\\mathcal{D}</span>  and set  <span class="math">Z</span> ,</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\Pr \\left[ \\begin{array}{c c} \\varphi \\in \\mathsf {F} &amp;amp; \\mathfrak {p p} \\leftarrow \\mathbb {G} (1 ^ {\\lambda}) \\\\ (\\mathfrak {p p}, \\mathsf {a i}, \\varphi , \\mathsf {o} (\\mathsf {T}), \\mathsf {a o}) \\in Z &amp;amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (1 ^ {\\lambda}) \\\\ \\mathsf {T} \\text {i s} \\varphi \\text {- c o m p l i a n t} &amp;amp; (\\varphi , \\mathsf {T}, \\mathsf {a o}) \\leftarrow \\mathbb {E} _ {\\tilde {\\mathbb {P}}} (\\mathfrak {p p}, \\mathsf {a i}) \\end{array} \\right] \\\\ \\geq \\Pr \\left[ \\begin{array}{c c} \\varphi \\in \\mathsf {F} &amp;amp; \\begin{array}{c} \\mathfrak {p p} \\leftarrow \\mathbb {G} (1 ^ {\\lambda}) \\\\ (\\mathfrak {p p}, \\mathsf {a i}, \\varphi , \\mathsf {o}, \\mathsf {a o}) \\in Z \\\\ \\mathbb {V} (\\mathsf {i v k}, \\mathsf {o}, \\pi) = 1 \\end{array} \\right] \\\\ (\\varphi , \\mathsf {o}, \\pi , \\mathsf {a o}) \\leftarrow \\tilde {\\mathbb {P}} (\\mathfrak {p p}, \\mathsf {a i}) \\\\ (\\mathsf {i p k}, \\mathsf {i v k}) \\leftarrow \\mathbb {I} (\\mathfrak {p p}, \\varphi) \\end{array} \\right] - \\operatorname {n e g l} (\\lambda) . \\\\ \\end{array}</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Efficiency. The generator  <span class="math">\\mathbb{G}</span> , prover  <span class="math">\\mathbb{P}</span> , indexer  <span class="math">\\mathbb{I}</span> , and verifier  <span class="math">\\mathbb{V}</span>  run in polynomial time. A proof  <span class="math">\\pi</span>  has size  $\\mathrm{poly}(\\lambda,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\varphi</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> ; in particular, it is not permitted to grow with each application of  </span>\\mathbb{P}$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Remark 3.2. In this paper, we are interested in PCD for bounded-depth compliance predicates. Concretely, pick an arbitrary constant  <span class="math">d \\in \\mathbb{N}</span> . We construct PCD for a class  <span class="math">\\{\\varphi : \\mathsf{d}(\\varphi) &amp;lt; d\\}</span> . In contrast, prior work construct PCD for the class of constant-depth compliance predicates  <span class="math">\\{\\varphi : \\mathsf{d}(\\varphi) = O(1)\\}</span> . Intuitively, this is a change in the order of quantifiers; instead of saying "there exists a PCD scheme for predicates of arbitrary (constant) depth," we say "for any  <span class="math">c</span> , there exists a PCD scheme for predicates of depth at most  <span class="math">c</span> ." In general, compliance predicates can be engineered to have bounded depth, e.g. by incrementing a counter in the transcript.</p>

    <p class="text-gray-300">As in prior work [BCMS20; BCLMS21], almost all definitions and constructions in this paper are in the random oracle model. The sole exception is our PCD definition, as we do not know how to build secure PCD schemes in the random oracle model. Instead, we show how to construct PCD in the standard (CRS) model, assuming we have a accumulation-compatible NARK (for circuit satisfiability) in the standard (CRS) model. This can be heuristically realized from our constructions by instantiating the random oracle as a hash function.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A linear code of blocklength  <span class="math">n</span>  over a field  <span class="math">\\mathbb{F}</span>  is a linear subspace  <span class="math">C \\subset \\mathbb{F}^n</span> . The dimension of the code is the dimension of the subspace. The rate of the code is  <span class="math">R = \\dim(C)/n</span> . Given an evaluation domain  <span class="math">L \\subset \\mathbb{F}</span>  and degree bound  $k &lt;</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> , the Reed-Solomon code  </span>\\mathsf{RS}[\\mathbb{F}, L, k]<span class="math">  is defined to be the set of all evaluations over  </span>L<span class="math">  of polynomials of degree at most  </span>k$ :</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\mathsf {R S} [ \\mathbb {F}, L, k ] := \\left\\{\\hat {f} (L): \\hat {f} \\in \\mathbb {F} [ X ], \\deg (\\hat {f}) \\leq k \\right\\}</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">This is a linear code with blocklength  $n =</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  and dimension  </span>k + 1<span class="math"> . Given a codeword  </span>f<span class="math"> , we let  </span>\\hat{f}<span class="math">  denote the corresponding polynomial. We will often interpret  </span>\\hat{f}<span class="math">  as a coefficient vector in  </span>\\mathbb{F}^{k + 1}$ , and vice versa.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Decoding. Let  <span class="math">C = \\mathsf{RS}[\\mathbb{F}, L, k]</span>  be a Reed-Solomon code with rate  <span class="math">R = (k + 1)/n</span> . There exists a polynomial-time decoding algorithm which, given a vector  <span class="math">f \\in (\\mathbb{F} \\cup \\{\\bot\\})^n</span> ,  <span class="math">\\Delta(f, C) \\leq (1 - R)/2</span> , finds the unique codeword  <span class="math">g \\in C</span>  such that  <span class="math">\\Delta(f, g) \\leq (1 - R)/2</span> . If  <span class="math">f</span>  does not satisfy the closeness condition, the algorithm rejects. We refer to  <span class="math">(1 - R)/2</span>  as the unique decoding radius of the code.</p>

    <p class="text-gray-300">Proximity gaps.</p>

    <p class="text-gray-300">Reed-Solomon codes enjoy a number of so-called proximity gap results. Informally, these say the following. Suppose you have vectors <span class="math">f_{1},\\ldots,f_{m}\\in\\mathbb{F}^{n}</span>, of which at least one is <span class="math">\\delta</span>-far from the code, i.e. <span class="math">\\Delta(f_{i},C)\\geq\\delta</span>. Then with high probability, a random linear combination of these vectors will also be <span class="math">\\delta</span>-far from the code. The exact kind of random linear combination is somewhat flexible. Besides uniformly random coefficients, <em>[x1]</em> show that one can sample a single field element <span class="math">\\alpha\\leftarrow\\mathbb{F}</span> and set the coefficients to be the monomial evaluations <span class="math">1,\\alpha,\\alpha^{2},\\ldots,\\alpha^{m-1}</span>. In our accumulation scheme, we set the coefficients to be the evaluations <span class="math">L_{1}(\\alpha),\\ldots,L_{m}(\\alpha)</span> of the Lagrange polynomials of some set of size <span class="math">m</span>. Although the corresponding proximity gap result is not proven in <em>[x1]</em>, it is a straightforward generalization as illustrated in Theorem 3.3.</p>

    <h6 id="sec-29" class="text-base font-medium mt-4">Theorem 3.3.</h6>

    <p class="text-gray-300">Let <span class="math">C=\\mathsf{RS}[\\mathbb{F},L,k]</span> be a Reed–Solomon code with rate <span class="math">R</span> and blocklength <span class="math">n</span>, and suppose <span class="math">\\delta\\leq(1-R)/2</span>. Let <span class="math">L_{0},\\ldots,L_{\\ell}</span> be the Lagrange polynomials for an arbitrary set of <span class="math">\\ell+1</span> points in <span class="math">\\mathbb{F}</span>. Let <span class="math">u_{0},\\ldots,u_{\\ell}:L\\to\\mathbb{F}</span> be functions. Define the set</p>

    <p class="text-gray-300"><span class="math">S=\\left\\{z\\in\\mathbb{F}:\\Delta\\left(\\sum_{i=0}^{\\ell}L_{i}(z)\\cdot u_{i},C\\right)\\leq\\delta\\right\\}</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">and suppose $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">>\\ell\\cdot n<span class="math">. Then for all </span>z\\in\\mathbb{F}$ we have</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\Delta\\left(\\sum_{i=0}^{\\ell}L_{i}(z)\\cdot u_{i},C\\right)\\leq\\delta,</span></p>

    <p class="text-gray-300">and furthermore there exist <span class="math">v_{0},\\ldots,v_{\\ell}\\in C</span> such that for all <span class="math">z\\in\\mathbb{F}</span>,</p>

    <p class="text-gray-300"><span class="math">\\Delta\\left(\\sum_{i=0}^{\\ell}L_{i}(z)\\cdot u_{i},\\sum_{i=0}^{\\ell}L_{i}(z)\\cdot v_{i}\\right)\\leq\\delta,</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">and in fact $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\{x\\in L:(u_{0}(x),\\ldots,u_{\\ell}(x))\\neq(v_{0}(x),\\ldots,v_{\\ell}(x))\\}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\delta</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-30" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">This is a direct adaption of Theorem 6.1 from <em>[x1]</em>. The only difference between the statement of Theorem 3.3 and theirs is the choice of parameterized curve. In particular, their theorem statement is for the curve <span class="math">u_{0}+zu_{1}+\\cdots+z^{\\ell}u_{\\ell}</span>, whereas ours is for the curve <span class="math">L_{0}(z)\\cdot u_{0}+L_{1}(z)\\cdot u_{1}+\\cdots+L_{\\ell}(z)\\cdot u_{\\ell}</span>. Their proof essentially goes through, since it only depends on the degree of <span class="math">x</span> and <span class="math">z</span>; these are identical in both curves. The only change is how we interpret the final polynomial <span class="math">P(X,Z)</span>, which recovers the candidate codewords <span class="math">v_{0},\\ldots,v_{\\ell}</span>. In particular, instead of writing <span class="math">P(X,Z)</span> as <span class="math">v_{0}(X)+Zv_{1}(X)+\\cdots+Z^{\\ell}v_{\\ell}(X)</span>, we use a change of basis: <span class="math">P(X,Z)=L_{0}(Z)\\cdot v_{0}(X)+L_{1}(Z)\\cdot v_{1}(X)+\\cdots+L_{\\ell}(Z)\\cdot v_{\\ell}(X)</span>. ∎</p>

    <p class="text-gray-300">The following lemma is immediately implied by Theorem 3.3.</p>

    <h6 id="sec-31" class="text-base font-medium mt-4">Lemma 3.4.</h6>

    <p class="text-gray-300">Let <span class="math">C=\\mathsf{RS}[\\mathbb{F},L,k]</span> be a Reed-Solomon code with rate <span class="math">R</span> and blocklength <span class="math">n</span>, and suppose <span class="math">\\delta\\leq(1-R)/2</span>. Let <span class="math">L_{1},\\ldots,L_{m}</span> be the Lagrange polynomials for an arbitrary set of <span class="math">m</span> points in <span class="math">\\mathbb{F}</span>. Consider arbitrary vectors <span class="math">f_{1},\\ldots,f_{m}\\in\\mathbb{F}^{n}</span>. If</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\Pr_{\\alpha\\leftarrow\\mathbb{F}}\\left[\\Delta\\left(\\sum_{i=1}^{m}L_{i}(\\alpha)\\cdot f_{i},C\\right)\\leq\\delta\\right]>\\frac{n(m-1)}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">},$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">then there exists a subdomain <span class="math">L^{\\prime}\\subseteq L</span> and codewords <span class="math">g_{1},\\ldots,g_{m}\\in C</span> such that the following holds. First, $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq 1-\\delta<span class="math">. Second, for all </span>i<span class="math">, </span>f_{i}<span class="math"> and </span>g_{i}<span class="math"> agree on </span>L^{\\prime}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">######</p>

    <p class="text-gray-300">An extractable vector commitment scheme in the random oracle model is a tuple of algorithms  <span class="math">\\mathsf{VC} = (\\mathsf{VC}. \\mathsf{Setup}, \\mathsf{VC}. \\mathsf{Commit}, \\mathsf{VC}. \\mathsf{Open}, \\mathsf{VC}. \\mathsf{Answer})</span>  with the following syntax and properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>VC.Setup  <span class="math">(1^{\\lambda},\\Sigma)\\to \\mathsf{vp}</span> : On input a security parameter  <span class="math">\\lambda</span>  and alphabet  <span class="math">\\Sigma</span> , outputs public parameters  <span class="math">\\mathsf{vp}</span>  which allow for committing to arbitrarily-length vectors over  <span class="math">\\Sigma</span> .</li>

      <li>VC.Commit(vp,  <span class="math">m</span> )  <span class="math">\\rightarrow</span>  (cm, aux): On input public parameters vp, message  <span class="math">m \\in \\Sigma^{\\ell}</span> , outputs a commitment cm and auxiliary data aux.</li>

      <li>VC.Open(vp, aux,  <span class="math">\\mathcal{Q}</span> )  <span class="math">\\rightarrow</span>  op: On input public parameters vp, auxiliary data aux, and a query set  <span class="math">\\mathcal{Q} \\subseteq [\\ell]</span> , outputs a partial opening op for the commitment.</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- VC.Answer(vp, cm, op,  <span class="math">\\mathcal{Q}</span> )  <span class="math">\\rightarrow</span>  ans: On input public parameters vp, commitment cm, partial opening op, and query set  <span class="math">\\mathcal{Q} \\subset [\\ell]</span> , outputs an answer ans:  <span class="math">\\mathcal{Q} \\rightarrow \\Sigma \\cup \\{\\bot\\}</span> , which can also be interpreted as a vector of length  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{Q}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> . If ans[i] =  </span>\\bot<span class="math">  for some  </span>i \\in \\mathcal{Q}$ , this implies that op does not contain an opening for that location.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Completeness. For every alphabet  <span class="math">\\Sigma</span> , message length  <span class="math">\\ell</span> , message  <span class="math">m \\in \\Sigma^{\\ell}</span> , and query set  <span class="math">\\mathcal{Q} \\subset [\\ell]</span></p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname * {P r} \\left[ \\begin{array}{c c} &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\mathrm {V C . A n s w e r} (\\mathrm {v p}, \\mathrm {c m}, \\mathrm {o p}, \\mathcal {Q}) = m [ \\mathcal {Q} ] &amp;amp; \\mathrm {v p} \\leftarrow \\mathrm {V C . S e t u p} (1 ^ {\\lambda}) \\\\ &amp;amp; (\\mathrm {c m}, \\mathrm {a u x}) \\leftarrow \\mathrm {V C . C o m m i t} (\\mathrm {v p}, m) \\\\ &amp;amp; \\mathrm {o p} \\leftarrow \\mathrm {V C . O p e n} (\\mathrm {v p}, \\mathrm {a u x}, \\mathcal {Q}) \\end{array} \\right] = 1.</span></div>

    <p class="text-gray-300">Extractability. There exists a polynomial time extractor  <span class="math">\\mathbf{E}</span>  such that for every alphabet  <span class="math">\\Sigma</span> , message length  <span class="math">\\ell</span> , polynomial time adversaries  <span class="math">\\mathcal{A}, \\mathcal{B}</span> , and auxiliary input distribution  <span class="math">\\mathcal{D}</span> , the following is negligibly close to 1:</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname * {P r} \\left[ \\begin{array}{c c} &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\mathcal {Q} \\subset [ \\ell ] &amp;amp; \\mathrm {v p} \\leftarrow \\mathrm {V C . S e t u p} (1 ^ {\\lambda}, \\Sigma) \\\\ \\Downarrow &amp;amp; \\mathrm {a i} \\leftarrow \\mathcal {D} (1 ^ {\\lambda}) \\\\ \\forall i \\in \\mathcal {Q}, \\mathsf {a n s} ^ {\\prime} [ i ] \\in \\{\\mathsf {a n s} [ i ], \\bot \\} &amp;amp; (\\mathsf {c m}; r) \\leftarrow \\mathcal {A} (\\mathsf {v p}, \\mathsf {a i}) \\\\ &amp;amp; \\mathrm {o p} \\leftarrow \\mathrm {E} ^ {\\mathcal {A}} (\\mathsf {v p}, \\mathsf {a i}, r) \\\\ &amp;amp; (\\mathsf {o p} ^ {\\prime}, \\mathcal {Q}) \\leftarrow \\mathcal {B} (\\mathsf {v p}, \\mathsf {a i}) \\\\ &amp;amp; \\mathsf {a n s} \\leftarrow \\mathrm {V C . A n s w e r} (\\mathsf {v p}, \\mathsf {c m}, \\mathsf {o p}, \\mathcal {Q}) \\\\ &amp;amp; \\mathsf {a n s} ^ {\\prime} \\leftarrow \\mathrm {V C . A n s w e r} (\\mathsf {v p}, \\mathsf {c m}, \\mathsf {o p} ^ {\\prime}, \\mathcal {Q}) \\end{array} \\right]</span></div>

    <p class="text-gray-300">The extractor implicitly receives  <span class="math">\\Sigma</span>  and  <span class="math">\\ell</span>  as input.</p>

    <p class="text-gray-300">Remark 3.5. Informally, extractability says that the extractor outputs a "maximal" opening, in the sense that no adversary can open to a value outside or inconsistent with the extractor's opening. This subsumes the standard position binding property of vector commitments.</p>

    <p class="text-gray-300">Remark 3.6. We assume that the expected vector length  <span class="math">\\ell</span>  is implicitly provided to VC.Answer. In our constructions, we assume that VC.Answer accepts auxiliary data aux and interprets it as a full opening to the vector; this can always be done by first calling VC.Open(vp, aux,  <span class="math">[\\ell])</span> . In this case, we omit the query set  <span class="math">\\mathcal{Q}</span> .</p>

    <p class="text-gray-300">Extractable vector commitments can be realized with Merkle trees which use the random oracle as a hash function. Valiant's extractor [Val08] satisfies the extractability property.</p>

    <p class="text-gray-300">Let  <span class="math">\\mathsf{ARG} = (\\mathcal{G},\\mathcal{P},\\mathcal{V})</span>  be a non-interactive argument with knowledge soundness for a relaxed verifier  <span class="math">\\hat{\\mathcal{V}}</span> . Suppose proofs can be split into two parts, i.e.  <span class="math">\\pi = (\\pi .\\mathbb{x},\\pi .\\mathbb{w})</span> . Let  <span class="math">\\mathfrak{q}\\times</span>  denote  <span class="math">(\\mathbb{x},\\pi .\\mathbb{x})</span> , where  <span class="math">\\mathbb{x}</span>  is an instance of the relation; call this the verifier input instance. Let  <span class="math">\\mathfrak{q}\\mathbb{w}</span>  denote  <span class="math">\\pi .\\mathbb{w}</span> ; call this the verifier input witness. We write  <span class="math">\\mathcal{V}(\\mathsf{pp},\\dot{\\mathfrak{i}},\\mathsf{q}\\mathsf{x}_i,\\mathsf{q}\\mathsf{w}_i)</span>  as shorthand for the verifier running on  <span class="math">\\mathbb{x}</span>  and  <span class="math">\\pi</span> . We write acc as shorthand for the tuple (acc.x, acc.w). An accumulation scheme in the random oracle model for ARG is a tuple of algorithms  <span class="math">\\mathsf{AS} = (\\mathrm{G},\\mathrm{I},\\mathrm{P},\\mathrm{V},\\mathrm{D})</span>  with the following syntax and properties.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathrm{G}(1^{\\lambda}) \\to \\mathsf{pp}_{\\mathrm{AS}}</span> : On input a security parameter  <span class="math">\\lambda</span> , the generator  <span class="math">\\mathrm{G}</span>  samples and outputs accumulation parameters  <span class="math">\\mathsf{pp}_{\\mathrm{AS}}</span> .</li>

      <li><span class="math">\\mathrm{I}(\\mathsf{pp}_{\\mathrm{AS}},\\mathsf{pp},\\dot{\\mathfrak{i}})\\to \\mathsf{pp}_{\\mathrm{AS}}</span>  : On input accumulation parameters  <span class="math">\\mathsf{pp}_{\\mathrm{AS}}</span>  and argument parameters  <span class="math">\\mathsf{pp}</span> , the indexer I deterministically computes and outputs a proving key  <span class="math">\\mathsf{apk}</span> , verification key  <span class="math">\\mathsf{avk}</span> , and decision key  <span class="math">\\mathsf{dk}</span> .</li>

      <li><span class="math">\\mathrm{P}(\\mathsf{apk},[\\mathsf{q}\\mathsf{x}_i,\\mathsf{q}\\mathsf{w}_i]_{i = 1}^{m_1},[\\mathsf{acc}_i]_{i = 1}^{m_2})\\to (\\mathsf{acc},\\mathsf{pf})</span>  : On input the proving key  <span class="math">\\mathsf{apk}</span> , verifier inputs  <span class="math">[\\mathsf{q}\\mathsf{x}_i,\\mathsf{q}\\mathsf{w}_i]_{i = 1}^{m_1}</span>  and accumulators  <span class="math">[\\mathsf{acc}_i]_{i = 1}^{m_2}</span> , the accumulation prover  <span class="math">\\mathrm{P}</span>  outputs a new accumulator acc and proof pf. Here,  <span class="math">m_{1}</span>  and  <span class="math">m_{2}</span>  are fixed arities which may be functions of  <span class="math">\\lambda</span> .</li>

      <li><span class="math">\\mathrm{V}(\\mathsf{avk},[\\mathsf{q}\\mathsf{x}_i]_{i = 1}^{m_1},[\\mathsf{acc}.\\mathbb{x}_i]_{i = 1}^{m_2},\\mathsf{acc}.\\mathbb{x},\\mathsf{pf})\\to \\{0,1\\}</span> : On input the verifying key  <span class="math">\\mathsf{avk}</span> , verifier input instances  <span class="math">[\\mathsf{q}\\mathsf{x}_i]_{i = 1}^{m_1}</span> , accumulator instances  <span class="math">[\\mathsf{acc}.\\mathbb{x}_i]_{i = 1}^{m_2}</span> , new accumulator instance  <span class="math">\\mathsf{acc}.\\mathbb{x}</span> , and proof  <span class="math">\\mathsf{pf}</span> , the accumulation verifier  <span class="math">\\mathrm{V}</span>  outputs a bit indicating whether  <span class="math">\\mathsf{acc}.\\mathbb{x}</span>  correctly accumulates the other instances.</li>

      <li><span class="math">\\mathrm{D}(\\mathrm{dk},\\mathrm{acc})\\to \\{0,1\\}</span> : On input the decision key  <span class="math">\\mathrm{dk}</span>  and accumulator acc, the decider outputs a bit indicating whether acc is a valid accumulator.</li>

    </ul>

    <p class="text-gray-300">Completeness. For every (unbounded) adversary  <span class="math">\\mathcal{A}</span> ,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} \\forall i \\in [ m _ {1} ], \\mathcal {V} (\\mathsf {p p}, \\dot {\\mathfrak {i}}, \\mathsf {q x} _ {i}, \\mathsf {q w} _ {i}) = 1 &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\forall i \\in [ m _ {2} ], \\mathrm {D} (\\mathsf {d k}, \\mathsf {a c c} _ {i}) = 1 &amp;amp; \\mathsf {p p} _ {\\mathrm {A S}} \\leftarrow \\mathrm {G} (1 ^ {\\lambda}) \\\\ \\Downarrow &amp;amp; \\mathsf {p p} _ {\\mathrm {A S}} \\leftarrow \\mathrm {G} (1 ^ {\\lambda}) \\\\ \\mathrm {V} (\\mathsf {a v k}, [ \\mathsf {q x} _ {i} ] _ {i = 1} ^ {m _ {1}}, [ \\mathsf {a c c} _ {i}. \\mathsf {x} ] _ {i = 1} ^ {m _ {2}}, \\mathsf {a c c}. \\mathsf {x}, \\mathsf {p f}) = 1 &amp;amp; \\mathsf {a c c} _ {i} ] _ {i = 1} ^ {m _ {2}} \\leftarrow \\mathcal {A} (\\mathsf {p p} _ {\\mathrm {A S}}, \\mathsf {p p}) \\\\ \\mathrm {D} (\\mathsf {d k}, \\mathsf {a c c}) = 1 &amp;amp; (\\mathsf {a c c}, \\mathsf {p f}) \\leftarrow \\mathrm {P} (\\mathsf {a p k}, [ \\mathsf {q x} _ {i}, \\mathsf {q w} _ {i} ] _ {i = 1} ^ {m _ {1}}, [ \\mathsf {a c c} _ {i} ] _ {i = 1} ^ {m _ {2}}) \\end{array} \\right] = 1.</span></div>

    <p class="text-gray-300">To bootstrap accumulation, we also assume the prover can efficiently construct a dummy accumulator and proof, denoted  <span class="math">\\mathsf{acc} = \\mathrm{P}(\\mathsf{apk},\\bot)</span> , which the decider accepts.</p>

    <p class="text-gray-300">Knowledge soundness. We say that AS has bounded-depth knowledge soundness (with maximum depth  <span class="math">d_{s}</span> ) if there exists a family of deciders  <span class="math">\\{\\mathrm{D}_s\\}_{s=0}^{d_s}</span> , where  <span class="math">\\mathrm{D}</span>  is equivalent to  <span class="math">\\mathrm{D}_0</span> , such that the following holds. There exists an expected polynomial time extractor  <span class="math">\\mathrm{E}</span>  such that for every depth parameter  <span class="math">s \\in [d_s]</span> , expected polynomial time adversary  <span class="math">\\tilde{\\mathrm{P}}</span> , and auxiliary input distribution  <span class="math">\\mathcal{D}</span> , the following probability is negligibly close to 1:</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} \\mathrm {V} ^ {\\rho} (\\mathsf {a v k}, [ \\mathsf {q x} _ {i} ] _ {i = 1} ^ {m _ {1}}, [ \\mathsf {a c c} _ {i}. \\mathsf {x} ] _ {i = 1} ^ {m _ {2}}, \\mathsf {a c c}. \\mathsf {x}, \\mathsf {p f}) = 1 &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\mathrm {D} _ {s - 1} (\\mathsf {d k}, \\mathsf {a c c}) = 1 &amp;amp; \\mathsf {p p} _ {\\mathrm {A S}} \\leftarrow \\mathrm {G} (1 ^ {\\lambda}) \\\\ \\Downarrow &amp;amp; \\mathsf {p p} _ {\\mathrm {A S}} \\leftarrow \\mathrm {G} (1 ^ {\\lambda}) \\\\ \\forall i \\in [ m _ {1} ], \\hat {\\mathcal {V}} (\\mathsf {p p}, \\dot {\\mathfrak {i}}, \\mathsf {q x} _ {i}, \\mathsf {q w} _ {i}) = 1 &amp;amp; (\\dot {\\mathfrak {i}}, [ \\mathsf {q x} _ {i} ] _ {i = 1} ^ {m _ {1}}, [ \\mathsf {a c c} _ {i}. \\mathsf {x} ] _ {i = 1} ^ {m _ {2}}, \\mathsf {a c c}, \\mathsf {p f}; r) \\leftarrow \\tilde {\\mathrm {P}} (\\mathsf {p p} _ {\\mathrm {A S}}, \\mathsf {p p}, \\mathsf {a i}) \\\\ \\forall i \\in [ m _ {2} ], \\mathrm {D} _ {s} (\\mathsf {d k}, \\mathsf {a c c} _ {i}) = 1 &amp;amp; ([ \\mathsf {q w} _ {i} ] _ {i = 1} ^ {m _ {1}}, [ \\mathsf {a c c} _ {i}. \\mathsf {w} ] _ {i = 1} ^ {m _ {2}}) \\leftarrow \\mathrm {E} ^ {\\tilde {\\mathrm {P}}} (\\mathsf {p p} _ {\\mathrm {A S}}, \\mathsf {p p}, \\mathsf {a i}, r) \\\\ &amp;amp; (\\mathsf {a p k}, \\mathsf {a v k}, \\mathsf {d k}) \\leftarrow \\mathrm {I} (\\mathsf {p p} _ {\\mathrm {A S}}, \\mathsf {p p}, \\dot {\\mathfrak {i}}) \\end{array} \\right]</span></div>

    <p class="text-gray-300">The extractor implicitly receives  <span class="math">s</span>  as input.</p>

    <p class="text-gray-300">Remark 4.1. We can also define a bounded-depth version of completeness with a separate family of deciders. In the completeness definition, valid accumulators for the  <span class="math">i</span> -th decider accumulate to a valid accumulator for the  <span class="math">(i + 1)</span> -th decider. This is important in settings where even an honest prover can only perform a bounded number of accumulations.</p>

    <p class="text-gray-300">Multi-instance extraction. As in [BCLMS21], we also define a weaker notion of knowledge soundness which is implied by the earlier definition. For every expected polynomial time adversary  <span class="math">\\tilde{\\mathrm{P}}</span>  and auxiliary input distribution  <span class="math">\\mathcal{D}</span> , there exists an expected polynomial time extractor  <span class="math">\\mathrm{E}_{\\tilde{\\mathrm{P}}}</span>  such that for every set  <span class="math">Z</span> ,</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\Pr \\left[ \\begin{array}{c c} &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ (\\mathsf {p p} _ {\\mathrm {A S}}, \\mathsf {p p}, \\mathsf {a i}, \\vec {\\mathrm {i}}, \\vec {\\mathrm {q x}}, \\vec {\\mathrm {a x}}, \\mathsf {a c c}, \\mathsf {a o}) \\in Z \\\\ \\forall j \\in [ \\ell ], \\mathrm {V} ^ {\\rho} (\\mathsf {a v k}, \\mathsf {q x} _ {j}, \\mathsf {a x} _ {j}, \\mathsf {a c c} _ {j}, \\mathbb {x}, \\mathsf {p f} _ {j}) = 1 \\\\ \\forall j \\in [ \\ell ], \\mathrm {D} _ {s - 1} (\\mathsf {d k} _ {j}, \\mathsf {a c c} _ {j}) = 1 \\end{array} \\right] \\\\ \\geq \\Pr \\left[ \\begin{array}{c c} &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ (\\mathsf {p p} _ {\\mathrm {A S}}, \\mathsf {p p}, \\mathsf {a i}, \\vec {\\mathrm {i}}, \\vec {\\mathrm {q x}}, \\vec {\\mathrm {a x}}, \\mathsf {a c c}, \\mathsf {a o}) \\in Z \\\\ \\forall j \\in [ \\ell ], \\forall i \\in [ m _ {1} ], \\hat {\\mathcal {V}} (\\mathsf {p p}, \\mathrm {i} _ {j}, \\mathsf {q x} _ {i} ^ {(j)}, \\mathsf {q w} _ {i} ^ {(j)}) = 1 \\\\ \\forall j \\in [ \\ell ], \\forall i \\in [ m _ {2} ], \\mathrm {D} _ {s} (\\mathsf {d k} _ {j}, \\mathsf {a c c} _ {i} ^ {(j)}) = 1 \\end{array} \\right] \\\\ \\end{array}</span></div>

    <p class="text-gray-300">Here, we write  <span class="math">\\mathbf{q}\\mathbf{x}_j</span>  as shorthand for  <span class="math">[\\mathbf{q}\\mathbf{x}_i^{(j)}]_{i = 1}^{m_1}</span> , and similarly for  <span class="math">\\mathbf{q}\\mathbf{w}_j = [\\mathbf{q}\\mathbf{w}_i^{(j)}]_{i = 1}^{m_1}</span> ,  <span class="math">\\mathbf{a}\\mathbf{x}_j = [\\mathbf{a}\\mathbf{c}\\mathbf{c}_i^{(j)}.\\mathbf{x}]_{i = 1}^{m_2}</span> , and  <span class="math">\\mathbf{a}\\mathbf{w}_j = [\\mathbf{a}\\mathbf{c}\\mathbf{c}_i^{(j)}.\\mathbf{w}]_{i = 1}^{m_2}</span> .</p>

    <p class="text-gray-300">We construct PCD from bounded-depth accumulation (Section 5.1), and analyze its knowledge soundness (Section 5.2). To simplify our analysis, we only consider compliance predicates which correspond with regular  <span class="math">m</span> -ary trees, i.e.  <span class="math">\\varphi(z, z_{\\mathrm{loc}}, z_1, \\ldots, z_m)</span>  only accepts if either  <span class="math">\\forall i \\in [m], z_i = \\bot</span>  or  <span class="math">\\forall i \\in [m], z_i \\neq \\bot</span> . We omit an analysis of completeness and efficiency, as these follow with minimal or no change from the analyses in prior work [BCLMS21].</p>

    <p class="text-gray-300">Let  <span class="math">\\mathcal{H}(\\lambda)</span>  be a family of collision-resistant hash functions which map to  <span class="math">\\lambda</span>  bits. Let  <span class="math">\\{\\mathcal{R}_{\\mathrm{pp}}\\}_{\\mathrm{pp}}</span>  be an indexed relation family which encodes circuit satisfiability, e.g. R1CS over a field specified by the public parameters. Let  <span class="math">\\mathsf{ARG} = (\\mathcal{G},\\mathcal{P},\\mathcal{V})</span>  be a NARK for  <span class="math">\\{\\mathcal{R}_{\\mathrm{pp}}\\}_{\\mathrm{pp}}</span> . Let  <span class="math">\\mathsf{AS} = (\\mathrm{G},\\mathrm{I},\\mathrm{P},\\mathrm{V},\\mathrm{D})</span>  be an accumulation scheme for ARG, with bounded-depth knowledge soundness for maximum depth  <span class="math">d</span> . We construct a PCD scheme  <span class="math">\\mathsf{PCD} = (\\mathbb{G},\\mathbb{I},\\mathbb{P},\\mathbb{V})</span> , shown in Figure 7, for the class of bounded-depth compliance predicates  <span class="math">\\mathsf{F} = \\{\\varphi :\\mathsf{d}(\\varphi) &amp;lt; d\\}</span> .</p>

    <p class="text-gray-300">!<a href="img-5.jpeg">img-5.jpeg</a> Figure 6: Recursion circuit for PCD.</p>

    <p class="text-gray-300">Remark 5.1 (accumulator instance size). As noted in [BCLMS21, Remark 5.4], the size of an accumulator instance must be independent of the size of an argument instance. This is not the true for the construction presented in Section 6; to avoid this issue, they suggest converting it into a new scheme, where the accumulator instance is hashed and appended to the accumulator witness/proof. We take an alternative approach (also in [KST22]) where the circuit's instance is hashed and appended to the witness. This means that the argument instance is always  <span class="math">\\lambda</span>  bits, irrespective of the accumulation scheme.</p>

    <p class="text-gray-300">The extracted transcript  <span class="math">\\mathsf{T}</span>  will be a tree, so each vertex  <span class="math">u</span>  has a unique outgoing edge  <span class="math">e</span> . For convenience, we associate the label  <span class="math">z^{(e)}</span>  with the vertex  <span class="math">u</span>  itself by writing  <span class="math">z^{(u)} = z^{(e)}</span> . In our extractors, we will also label a vertex  <span class="math">u</span>  with a NARK proof  <span class="math">\\pi^{(u)}</span>  and accumulator  <span class="math">\\mathsf{acc}^{(u)}</span> . We recursively construct a sequence of extractors  <span class="math">\\mathbb{E}_0,\\ldots ,\\mathbb{E}_d</span> , where  <span class="math">\\mathbb{E}_j</span>  outputs a tree of depth  <span class="math">j</span> . The overall PCD extractor  <span class="math">\\mathbb{E}_{\\updownarrow}</span>  is (essentially)  <span class="math">\\mathbb{E}_d</span> .</p>

    <p class="text-gray-300">!<a href="img-6.jpeg">img-6.jpeg</a> Figure 7: PCD algorithms.</p>

    <p class="text-gray-300">We first construct  <span class="math">\\mathbb{E}_0</span>  using the PCD adversary  <span class="math">\\tilde{\\mathbb{P}}</span> :</p>

    <p class="text-gray-300"><span class="math">\\mathbb{E}_0(\\mathbb{P}\\mathbb{P},\\mathsf{a}\\mathsf{i}_{\\mathsf{PCD}} = \\mathsf{a}\\mathsf{i})</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Get the prover's output  <span class="math">(\\varphi, \\mathsf{o}, (\\pi, \\mathsf{acc}), \\mathsf{ao}) \\gets \\tilde{\\mathbb{P}}(\\mathbb{P}\\mathbb{P}, \\mathsf{a}\\mathsf{i})</span> .</li>

      <li>Initialize a transcript  <span class="math">\\mathsf{T}</span>  with two nodes  <span class="math">u, v</span>  and an edge  <span class="math">(u, v)</span> , labeled with  <span class="math">z^{(u)} \\coloneqq \\mathsf{o}</span> .</li>

      <li>Label  <span class="math">u</span>  with  <span class="math">\\pi^{(u)}</span>  and  <span class="math">\\mathsf{acc}^{(u)}</span> .</li>

      <li>Output  <span class="math">(\\varphi, \\mathsf{T}, \\mathsf{a}\\mathsf{o}_{\\mathsf{PCD}} = \\mathsf{a}\\mathsf{o})</span></li>

    </ol>

    <p class="text-gray-300">Suppose we have the extractor  <span class="math">\\mathbb{E}_{j-1}</span> . We show how to construct  <span class="math">\\mathbb{E}_j</span>  in several steps. First, we construct an adversary for ARG:</p>

    <p class="text-gray-300"><span class="math">\\tilde{\\mathcal{P}}_j(\\mathsf{pp},\\mathsf{ai}_{\\mathsf{ARG}} = (\\mathsf{pp}_{\\mathsf{AS}},\\mathsf{H},\\mathsf{ai}))</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run the extractor  <span class="math">(\\varphi, \\mathsf{T}, \\mathsf{a}\\mathsf{o}_{\\mathsf{PCD}} = \\mathsf{a}\\mathsf{o}) \\gets \\mathbb{E}_{j-1}(\\mathbb{P}\\mathbb{P} = (\\mathsf{pp}, \\mathsf{pp}_{\\mathsf{AS}}, \\mathsf{H}), \\mathsf{a}\\mathsf{i}_{\\mathsf{PCD}} = \\mathsf{a}\\mathsf{i})</span> .</li>

      <li>Construct the circuit  <span class="math">R \\coloneqq R_{\\mathrm{V},\\varphi,\\mathrm{H}}^{(\\lambda,N)}</span> .</li>

      <li>Run the accumulator indexer  <span class="math">(\\mathsf{apk},\\mathsf{dk},\\mathsf{avk})\\coloneqq \\mathrm{I}(\\mathsf{pp}_{\\mathsf{AS}},\\mathsf{pp},R)</span></li>

      <li>Initialize an empty set  <span class="math">S_{\\mathsf{ARG}}</span></li>

      <li>For each vertex  <span class="math">v</span>  in the  <span class="math">(j + 1)</span> -th layer of  <span class="math">\\mathsf{T}</span> :</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Compute the hash  <span class="math">h \\coloneqq \\mathsf{H}(\\mathsf{avk}, z^{(v)}, \\mathsf{acc}^{(v)}.\\mathbb{x})</span> .</li>

      <li>Set  <span class="math">\\mathfrak{i}_v\\coloneqq R,\\mathbb{x}_v\\coloneqq h,\\pi_v\\coloneqq \\pi^{(v)}</span></li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Output  <span class="math">(\\vec{\\mathfrak{s}},\\vec{\\mathfrak{x}},\\vec{\\pi},\\mathsf{a}\\mathsf{o}_{\\mathsf{ARG}} = (\\varphi ,\\mathsf{T},\\mathsf{a}\\mathsf{o},S_{\\mathsf{ARG}}))</span></li>

    </ol>

    <p class="text-gray-300">Next, letting <span class="math">\\mathcal{E}_{\\tilde{\\mathcal{P}}_j}</span> be the extractor for <span class="math">\\tilde{\\mathcal{P}}_j</span> according to the multi-instance knowledge soundness property of ARG, we construct an adversary for AS:</p>

    <p class="text-gray-300"><span class="math">\\tilde{\\mathrm{P}}_j(\\mathsf{pp}_{\\mathsf{AS}},\\mathsf{pp},\\mathsf{ai}_{\\mathsf{AS}} = (\\mathsf{H},\\mathsf{ai}))</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run the extractor <span class="math">(\\vec{\\mathbf{i}},\\vec{\\mathbf{x}},\\vec{\\mathbf{w}},\\mathsf{ao}_{\\mathsf{ARG}} = (\\varphi ,\\mathsf{T},\\mathsf{ao},S_{\\mathsf{ARG}}))\\gets \\mathcal{E}_{\\tilde{\\mathcal{P}}_j}(\\mathsf{pp},\\mathsf{ai}_{\\mathsf{ARG}} = (\\mathsf{pp}_{\\mathsf{AS}},\\mathsf{H},\\mathsf{ai}))</span></li>

      <li>Construct the circuit <span class="math">R\\coloneqq R_{\\mathrm{V},\\varphi ,\\mathrm{H}}^{(\\lambda ,N)}</span></li>

      <li>Run the accumulator indexer (apk, dk, avk) := I(ppAS, pp, R).</li>

      <li>For each vertex <span class="math">v</span> in the <span class="math">(j + 1)</span>-th layer of <span class="math">\\mathsf{T}</span>:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse <span class="math">\\mathsf{avk}&#x27;</span>, <span class="math">z&#x27;</span>, <span class="math">\\mathsf{acc}&#x27;\\cdot \\mathbf{x}</span>, local data <span class="math">z_{\\mathrm{loc}}</span>, incoming data <span class="math">[z_i, \\pi_i \\cdot \\mathbf{x}, \\mathsf{acc}_i \\cdot \\mathbf{x}]_{i \\in [m]}</span>, and accumulation proof <span class="math">\\mathsf{pf}</span> from the witness <span class="math">\\mathbf{w}^{(v)}</span>.</li>

      <li>If <span class="math">(\\mathsf{avk}&#x27;, z&#x27;, \\mathsf{acc}&#x27;\\cdot \\mathbf{x}) \\neq (\\mathsf{avk}, z^{(v)}, \\mathsf{acc}^{(v)}\\cdot \\mathbf{x})</span>, this constitutes a hash collision; abort.</li>

      <li>Label <span class="math">v</span> with <span class="math">z_{\\mathrm{loc}}^{(v)} \\coloneqq z_{\\mathrm{loc}}</span> in <span class="math">\\mathsf{T}</span>.</li>

      <li>If there exists <span class="math">i \\in [m], z_i \\neq \\bot</span>:</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Add vertices <span class="math">u_{1}, \\ldots, u_{m}</span> to <span class="math">\\mathsf{T}</span>.</li>

      <li>For each <span class="math">i \\in [m]</span>, add an edge <span class="math">(u_i, v)</span>, labeled with <span class="math">z^{(u_i)} \\coloneqq z_i</span>, to <span class="math">\\mathsf{T}</span>; this is the <span class="math">i</span>-th incoming edge to <span class="math">v</span>.</li>

      <li>For each <span class="math">i \\in [m]</span>, compute the hash <span class="math">h_i := \\mathsf{H}(\\mathsf{avk}, z^{(u_i)}, \\mathsf{acc}_i \\cdot \\mathbf{x})</span> and set <span class="math">\\mathbf{qx}_i := (h_i, \\pi_i \\cdot \\mathbf{x})</span>.</li>

      <li>Set <span class="math">\\mathbf{qx}_v = [\\mathbf{qx}_i]_{i=1}^m</span>, <span class="math">\\mathbf{ax}_v := [\\mathbf{acc}_i \\cdot \\mathbf{x}]_{i=1}^m</span>, <span class="math">\\mathbf{acc}_v := \\mathbf{acc}^{(v)}</span>, <span class="math">\\mathbf{pf}_v := \\mathbf{pf}</span>.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Output <span class="math">(\\vec{\\mathbf{i}},\\vec{\\mathbf{q}}\\vec{\\mathbf{x}},\\vec{\\mathbf{ax}},\\vec{\\mathbf{acc}},\\vec{\\mathbf{pf}},\\vec{\\mathbf{ao}}_{\\mathrm{AS}} = (\\varphi ,\\mathsf{T},\\mathsf{ao}))</span></li>

    </ol>

    <p class="text-gray-300">Let <span class="math">\\mathrm{E}_{\\tilde{\\mathrm{P}}_j}</span> be the extractor for <span class="math">\\tilde{\\mathrm{P}}_j</span> according to the multi-instance knowledge soundness property of AS. We use the latter to construct the PCD extractor <span class="math">\\mathbb{E}_j</span>:</p>

    <p class="text-gray-300"><span class="math">\\mathbb{E}_j(\\mathbb{P}\\mathbb{P} = (\\mathsf{pp},\\mathsf{pp}_{\\mathsf{AS}},\\mathsf{H}),\\mathsf{ai}_{\\mathsf{PCD}} = \\mathsf{ai})</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run the extractor <span class="math">(\\vec{\\mathbf{i}},\\vec{\\mathbf{q}}\\vec{\\mathbf{x}},\\vec{\\mathbf{q}}\\vec{\\mathbf{w}},\\vec{\\mathbf{ax}},\\vec{\\mathbf{aw}},\\vec{\\mathbf{acc}},\\vec{\\mathbf{ao}}_{\\mathrm{AS}} = (\\varphi ,\\mathsf{T},\\mathsf{ao}))\\gets \\mathrm{E}_j(\\mathsf{pp}_{\\mathsf{AS}},\\mathsf{pp},\\mathsf{ai}_{\\mathsf{AS}} = (\\mathsf{H},\\mathsf{ai}))</span></li>

      <li>For each vertex <span class="math">v</span> in the <span class="math">(j + 1)</span>-th layer of <span class="math">\\mathsf{T}</span>:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse <span class="math">[\\mathbf{qx}_i = (h_i,\\pi_i.\\mathbf{x})]_{i = 1}^m</span> from <span class="math">\\mathbf{qx}^{(v)}</span>.</li>

      <li>Parse <span class="math">[\\mathbf{qw}_i = \\pi_i.\\mathbf{w}]_{i = 1}^m</span> from <span class="math">\\mathbf{qw}^{(v)}</span>.</li>

      <li>Parse <span class="math">[\\mathrm{acc}_i.\\mathbf{x}]_{i = 1}^m</span> from <span class="math">\\mathbf{ax}^{(v)}</span>.</li>

      <li>Parse <span class="math">[\\mathrm{acc}_i.\\mathbf{w}]_{i = 1}^m</span> from <span class="math">\\mathbf{aw}^{(v)}</span>.</li>

      <li>Let <span class="math">u_{1}, \\ldots, u_{m}</span> be the children of <span class="math">v</span>.</li>

      <li>For each <span class="math">i \\in [m]</span>:</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Combine <span class="math">\\pi_i.\\mathbf{x}</span> and <span class="math">\\pi_i.\\mathbf{w}</span> into a NARK proof <span class="math">\\pi</span>.</li>

      <li>Combine <span class="math">\\mathrm{acc}_i.\\mathbf{x}</span> and <span class="math">\\mathrm{acc}_i.\\mathbf{w}</span> into an accumulator <span class="math">\\mathrm{acc}</span>.</li>

      <li>Label <span class="math">u_{i}</span> with <span class="math">\\pi^{(u_i)}\\coloneqq \\pi</span> and <span class="math">\\mathrm{acc}^{(u_i)}\\coloneqq \\mathrm{acc}</span>.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Output <span class="math">(\\varphi ,\\mathsf{T},\\mathsf{ao}_{\\mathsf{PCD}} = \\mathsf{ao})</span></li>

    </ol>

    <p class="text-gray-300">Finally, we construct the overall PCD extractor:</p>

    <p class="text-gray-300"><span class="math">\\mathbb{E}_{\\tilde{\\mathbb{P}}}(\\mathbb{P}\\mathbb{P},\\mathsf{ai})</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run the extractor <span class="math">(\\varphi ,\\mathsf{T},\\mathsf{ao}_{\\mathsf{PCD}} = \\mathsf{ao})\\gets \\mathbb{E}_{d + 1}(\\mathbb{P}\\mathbb{P},\\mathsf{ai}_{\\mathsf{PCD}} = \\mathsf{ai})</span></li>

      <li>Remove any unnecessary labeling, such as <span class="math">\\pi^{(v)}</span> and <span class="math">\\mathrm{acc}^{(v)}</span>, from each vertex <span class="math">v</span> in <span class="math">\\mathsf{T}</span>.</li>

      <li>Output <span class="math">(\\varphi ,\\mathsf{T},\\mathsf{ao})</span></li>

    </ol>

    <p class="text-gray-300">25</p>

    <p class="text-gray-300">Running time of the extractor. It follows from the extraction guarantees of ARG and AS that  <span class="math">\\mathbb{E}_j</span>  runs in expected time polynomial in the expected running time of  <span class="math">\\mathbb{E}_{j - 1}</span> . Since  <span class="math">d</span>  is constant, the overall extractor runs in expected polynomial time.</p>

    <p class="text-gray-300">Correctness of the extractor. Fix a set  <span class="math">Z</span> , and suppose</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} \\varphi \\in \\mathsf {F} &amp;amp; \\mathbb {p} \\mathbb {p} \\leftarrow \\mathbb {G} \\left(1 ^ {\\lambda}\\right) \\\\ (\\mathbb {p} \\mathbb {p}, \\mathrm {a i}, \\varphi , \\mathrm {o}, \\mathrm {a o}) \\in Z &amp;amp; \\mathrm {a i} \\leftarrow \\mathcal {D} \\left(1 ^ {\\lambda}\\right) \\\\ \\mathbb {V} (\\mathrm {i v k}, \\mathrm {o}, (\\pi , \\mathrm {a c c})) = 1 &amp;amp; (\\varphi , \\mathrm {o}, (\\pi , \\mathrm {a c c}), \\mathrm {a o}) \\leftarrow \\hat {\\mathbb {P}} (\\mathbb {p} \\mathbb {p}, \\mathrm {a i}) \\\\ &amp;amp; (\\mathrm {i p k}, \\mathrm {i v k}) \\leftarrow \\mathbb {I} (\\mathbb {p} \\mathbb {p}, \\varphi) \\end{array} \\right] = \\mu . \\tag {1}</span></div>

    <p class="text-gray-300">Throughout our proof, we will reference the index  <span class="math">R</span> , verification key  <span class="math">\\mathsf{avk}</span> , and decision key  <span class="math">\\mathsf{dk}</span>  with the understanding that these can be deterministically derived from  <span class="math">\\mathbb{p}\\mathbb{p}</span>  and  <span class="math">\\varphi</span>  via the PCD indexer. We show by induction that, for all  <span class="math">j \\in \\{0, \\dots, d\\}</span> , the extractor  <span class="math">\\mathbb{E}_j(\\mathbb{p}\\mathbb{p}, \\mathsf{ai})</span>  outputs  <span class="math">(\\varphi, \\mathsf{T}, \\mathsf{a}\\mathsf{o}_{\\mathsf{PCD}} = \\mathsf{a}\\mathsf{o})</span>  such that the following holds with probability  <span class="math">\\mu - \\mathrm{negl}(\\lambda)</span>  (over the public parameters, auxiliary input, and the extractor's randomness):</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\varphi \\in \\mathsf{F}</span>  and  <span class="math">(\\mathbb{P}\\mathbb{P},\\mathsf{a}\\mathsf{i},\\varphi ,\\mathsf{o}(\\mathsf{T}),\\mathsf{a}\\mathsf{o})\\in Z.</span></li>

      <li><span class="math">\\mathsf{T}</span>  is a transcript tree of depth at most  <span class="math">j</span>  (and hence there are at most  <span class="math">j + 2</span>  layers). Moreover, the vertices in the first  <span class="math">j + 1</span>  layers of  <span class="math">\\mathsf{T}</span>  are  <span class="math">\\varphi</span> -compliant.</li>

      <li>For all  <span class="math">u</span>  in the  <span class="math">(j + 2)</span> -th layer of  <span class="math">\\mathsf{T}</span> , both  <span class="math">\\hat{\\mathcal{V}}(R, h, \\pi^{(u)})</span>  and  <span class="math">\\mathrm{D}_j(\\mathrm{dk}, \\mathrm{acc}^{(u)})</span>  accept, where  <span class="math">h := \\mathsf{H}(\\mathsf{avk}, z^{(u)}, \\mathsf{acc}^{(u)}.\\mathbf{x})</span> .</li>

    </ul>

    <p class="text-gray-300">For the base case  <span class="math">\\mathbb{E}_0</span> , this is implied by Equation (1). In particular, the sink  <span class="math">v</span>  is trivially  <span class="math">\\varphi</span> -compliant, since it has no outgoing edges. Since the PCD verifier accepts, the strict decider  <span class="math">\\mathrm{D}</span>  and verifier  <span class="math">\\mathcal{V}</span>  accept. Hence,  <span class="math">\\mathrm{D}_0</span>  and  <span class="math">\\hat{\\mathcal{V}}</span>  accept. For the inductive step, suppose that  <span class="math">\\mathbb{E}_{j-1}</span>  satisfies the inductive hypothesis.</p>

    <p class="text-gray-300">Correctness of  <span class="math">\\mathcal{E}_j</span> . The set  <span class="math">Z_{\\mathrm{ARG}}</span>  is defined as follows:  <span class="math">(\\mathsf{pp}, \\mathsf{ai}_{\\mathrm{ARG}} = (\\mathsf{pp}_{\\mathrm{AS}}, \\mathsf{H}, \\mathsf{ai}), \\vec{\\mathbb{i}}, \\vec{\\mathbf{x}}, \\mathsf{ao}_{\\mathrm{ARG}} = (\\varphi, \\mathsf{T}, \\mathsf{ao}))</span>  is an element of  <span class="math">Z_{\\mathrm{ARG}}</span>  if and only if the following holds:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\varphi \\in \\mathsf{F}</span>  and  <span class="math">(\\mathbb{P}\\mathbb{P} = (\\mathsf{pp},\\mathsf{pp}_{\\mathsf{AS}},\\mathsf{H}),\\mathsf{ai},\\varphi ,\\mathsf{o}(\\mathsf{T}),\\mathsf{ao})\\in Z.</span></li>

      <li><span class="math">\\mathsf{T}</span>  is a transcript tree of depth at most  <span class="math">j - 1</span>  (and hence there are  <span class="math">j + 1</span>  layers). Moreover, the vertices in the first  <span class="math">j</span>  layers of  <span class="math">\\mathsf{T}</span>  are  <span class="math">\\varphi</span> -compliant.</li>

      <li>For all  <span class="math">v</span>  in the  <span class="math">(j + 1)</span> -th layer of  <span class="math">\\mathsf{T}</span> ,  <span class="math">\\mathrm{D}_{j - 1}(\\mathrm{dk},\\mathrm{acc}^{(v)})</span>  accepts. Moreover,  <span class="math">\\mathbb{1}^{(v)} = R</span>  and  <span class="math">\\mathbf{x}_v = \\mathsf{H}(\\mathsf{avk},z^{(v)},\\mathsf{acc}^{(v)}.\\mathbf{x})</span> .</li>

    </ul>

    <p class="text-gray-300">By construction, with probability  <span class="math">\\mu -\\mathrm{negl}(\\lambda)</span> , the adversary  <span class="math">\\hat{\\mathcal{P}}_j(\\mathsf{pp},\\mathsf{ai}_{\\mathsf{ARG}})</span>  outputs  <span class="math">(\\vec{\\mathbb{i}},\\vec{\\mathbf{x}},\\vec{\\pi},\\mathsf{ao}_{\\mathsf{ARG}})</span>  such that  <span class="math">(\\mathsf{pp},\\mathsf{ai}_{\\mathsf{ARG}},\\vec{\\mathbb{i}},\\vec{\\mathbf{x}},\\mathsf{ao}_{\\mathsf{ARG}})\\in Z_{\\mathsf{ARG}}</span>  and for all  <span class="math">v</span> ,  <span class="math">\\hat{\\mathcal{V}} (\\mathbb{i}_v,\\mathbb{x}_v,\\pi_v)</span>  accepts. By (multi-instance) knowledge soundness of ARG, with probability  <span class="math">\\mu -\\mathrm{negl}(\\lambda)</span> , the extractor  <span class="math">\\mathcal{E}_{\\hat{\\mathcal{P}}_j}(\\mathsf{pp},\\mathsf{ai}_{\\mathsf{ARG}})</span>  outputs  <span class="math">(\\vec{\\mathbb{i}},\\vec{\\mathbf{x}},\\vec{\\mathbf{w}},\\mathsf{ao}_{\\mathsf{ARG}})</span>  and we have that  <span class="math">(\\mathsf{pp},\\mathsf{ai}_{\\mathsf{ARG}},\\vec{\\mathbb{i}},\\vec{\\mathbf{x}},\\mathsf{ao}_{\\mathsf{ARG}})\\in Z_{\\mathsf{ARG}}</span>  and for all  <span class="math">v</span> ,  <span class="math">(\\mathbb{i}_v,\\mathbb{x}_v,\\mathbb{w}_v)\\in \\mathcal{R}_{\\mathsf{pp}}</span> .</p>

    <p class="text-gray-300">Correctness of  <span class="math">\\mathrm{E}_j</span> . Define the set  <span class="math">Z_{\\mathrm{AS}}</span>  as follows:</p>

    <div class="my-4 text-center"><span class="math-block">\\left(\\mathsf {p p} _ {\\mathsf {A S}}, \\mathsf {p p}, \\mathsf {a i} _ {\\mathsf {A S}} = (\\mathsf {H}, \\mathsf {a i}), \\vec {\\mathbb {i}}, \\vec {\\mathbf {q x}}, \\vec {\\mathbf {a x}}, \\vec {\\mathbf {a c c}}, \\vec {\\mathsf {p f}}, \\mathsf {a o} _ {\\mathsf {A S}} = (\\varphi , \\mathsf {T}, \\mathsf {a o})\\right) \\in Z _ {\\mathsf {A S}}</span></div>

    <p class="text-gray-300">if and only if the following holds:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\varphi \\in \\mathsf{F}</span>  and  <span class="math">(\\mathbb{P}\\mathbb{P} = (\\mathsf{pp},\\mathsf{pp}_{\\mathsf{AS}},\\mathsf{H}),\\mathsf{ai},\\varphi ,\\mathsf{o}(\\mathsf{T}),\\mathsf{ao})\\in Z.</span></li>

      <li><span class="math">\\mathsf{T}</span>  is a transcript tree of depth at most  <span class="math">j</span>  (and hence there are  <span class="math">j + 2</span>  layers). Moreover, the vertices in the first  <span class="math">j + 1</span>  layers of  <span class="math">\\mathsf{T}</span>  are  <span class="math">\\varphi</span> -compliant.</li>

      <li>For each non-source vertex  <span class="math">v</span>  in the  <span class="math">(j + 1)</span> -th layer of  <span class="math">\\mathsf{T}</span> ,  <span class="math">v</span>  has children  <span class="math">u_1, \\ldots, u_m</span>  such that  <span class="math">\\mathbb{1}_v = R</span>  and  <span class="math">\\mathbf{ax}_v = [\\mathsf{acc}^{u_i}.\\mathbf{x}]_{i=1}^m</span>  such that  <span class="math">\\mathbf{qx}_v = [h_i, \\pi_i.\\mathbf{x}]_{i=1}^m</span>  for  <span class="math">h_i = \\mathsf{H}(\\mathsf{avk}, z^{(u_i)}, \\mathsf{acc}_i.\\mathbf{x})</span> .</li>

    </ul>

    <p class="text-gray-300">Suppose  <span class="math">\\mathrm{E}_j</span>  obtains  <span class="math">(\\vec{\\mathbb{1}},\\vec{\\mathbf{x}},\\vec{\\mathbf{w}},\\mathsf{ao}_{\\mathsf{ARG}})</span>  such that  <span class="math">(\\mathsf{pp},\\mathsf{ai}_{\\mathsf{ARG}},\\vec{\\mathbb{1}},\\vec{\\mathbf{x}},\\mathsf{ao}_{\\mathsf{ARG}})\\in Z_{\\mathsf{ARG}}</span>  and for each  <span class="math">v</span> ,  <span class="math">(\\mathbb{1}_v,\\mathbb{x}_v,\\mathbb{w}_v)\\in \\mathcal{R}_{\\mathsf{pp}}</span> . By membership in  <span class="math">Z_{\\mathsf{ARG}}</span> , for each  <span class="math">v</span>  in the  <span class="math">(j + 1)</span> -th layer of the tree, we have the following:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{H}(\\mathsf{avk}&#x27;, z&#x27;, \\mathsf{acc}&#x27;, \\mathfrak{x}) = \\mathfrak{x}_v</span>.</li>

      <li>If <span class="math">v</span> has no children <span class="math">\\varphi(z&#x27;, z_{\\mathrm{loc}}^{(v)}, \\bot, \\dots, \\bot)</span> accepts.</li>

      <li>If <span class="math">v</span> has children <span class="math">u_1, \\ldots, u_m</span>, <span class="math">\\varphi(z&#x27;, z_{\\mathrm{loc}}^{(v)}, z^{(u_1)}, \\ldots, z^{(u_m)})</span> accepts and <span class="math">\\mathrm{V}(\\mathsf{avk}&#x27;, \\mathbf{qx}_v, \\mathsf{ax}_v, \\mathsf{acc}_v, \\mathsf{pf}_v)</span> accepts.</li>

    </ul>

    <p class="text-gray-300">By membership in <span class="math">Z_{\\mathsf{ARG}}</span>, we also have <span class="math">\\mathsf{H}(\\mathsf{avk}, z^{(v)}, \\mathsf{acc}^{(v)}.\\mathfrak{x}) = \\mathfrak{x}_v</span>. Since <span class="math">\\mathcal{H}</span> is collision-resistant, we conclude that <span class="math">\\mathsf{avk} = \\mathsf{avk}&#x27;</span>, <span class="math">z^{(v)} = z&#x27;</span>, and <span class="math">\\mathsf{acc}^{(v)}.\\mathfrak{x} = \\mathsf{acc}&#x27;.\\mathfrak{x}</span>. The rest of the argument follows from construction: with probability <span class="math">\\mu - \\mathrm{negl}(\\lambda)</span>, the adversary <span class="math">\\tilde{\\mathrm{P}}_j(\\mathsf{pp}_{\\mathsf{AS}}, \\mathsf{pp}, \\mathsf{ai}_{\\mathsf{AS}})</span> outputs <span class="math">(\\vec{\\mathbf{i}}, \\vec{\\mathbf{q}}\\vec{\\mathbf{x}}, \\vec{\\mathbf{a}}\\vec{\\mathbf{x}}, \\vec{\\mathbf{a}}\\vec{\\mathbf{c}}\\mathbf{c}, \\vec{\\mathbf{p}}\\vec{\\mathbf{f}}, \\mathsf{ao}_{\\mathsf{AS}})</span> such that <span class="math">(\\mathsf{pp}_{\\mathsf{AS}}, \\mathsf{pp}, \\mathsf{ai}_{\\mathsf{AS}}, \\vec{\\mathbf{i}}, \\vec{\\mathbf{q}}\\vec{\\mathbf{x}}, \\vec{\\mathbf{a}}\\vec{\\mathbf{x}}, \\vec{\\mathbf{a}}\\vec{\\mathbf{c}}\\mathbf{c}, \\vec{\\mathbf{p}}\\vec{\\mathbf{f}}, \\mathsf{ao}_{\\mathsf{AS}}) \\in Z_{\\mathsf{AS}}</span>, and for all <span class="math">v</span>, both <span class="math">\\mathrm{V}(\\mathsf{avk}_v, \\mathbf{qx}_v, \\mathbf{ax}_v, \\mathsf{acc}_v, \\mathsf{pf}_v)</span> and <span class="math">\\mathrm{D}_{j-1}(\\mathsf{dk}_v, \\mathsf{acc}_v)</span> accept. Here, <span class="math">\\mathsf{avk}_v</span> and <span class="math">\\mathsf{dk}_v</span> are derived from <span class="math">\\dot{\\mathbf{i}}_v</span>. By (multi-instance) knowledge soundness of AS, with probability <span class="math">\\mu - \\mathrm{negl}(\\lambda)</span>, the extractor <span class="math">\\mathrm{E}_j(\\mathsf{pp}_{\\mathsf{AS}}, \\mathsf{pp}, \\mathsf{ai}_{\\mathsf{AS}})</span> outputs <span class="math">(\\vec{\\mathbf{i}}, \\vec{\\mathbf{q}}\\vec{\\mathbf{x}}, \\vec{\\mathbf{q}}\\vec{\\mathbf{w}}, \\vec{\\mathbf{a}}\\vec{\\mathbf{x}}, \\vec{\\mathbf{a}}\\vec{\\mathbf{w}}, \\vec{\\mathbf{a}}\\vec{\\mathbf{c}}\\mathbf{c}, \\mathsf{ao}_{\\mathsf{AS}})</span> such that <span class="math">(\\mathsf{pp}_{\\mathsf{AS}}, \\mathsf{pp}, \\mathsf{ai}_{\\mathsf{AS}}, \\vec{\\mathbf{i}}, \\vec{\\mathbf{q}}\\vec{\\mathbf{x}}, \\vec{\\mathbf{a}}\\vec{\\mathbf{x}}, \\vec{\\mathbf{a}}\\vec{\\mathbf{c}}\\mathbf{c}, \\vec{\\mathbf{p}}\\vec{\\mathbf{f}}, \\mathsf{ao}_{\\mathsf{AS}}) \\in Z_{\\mathsf{AS}}</span> and for all <span class="math">v</span> and <span class="math">i \\in [m]</span>, both <span class="math">\\hat{\\mathcal{V}}(\\dot{\\mathbf{i}}_v, \\mathbf{qx}_i^{(v)}, \\mathbf{qw}_i^{(v)})</span> and <span class="math">\\mathrm{D}_j(\\mathsf{dk}_v, \\mathsf{acc}_i^{(v)})</span> accept. Here, <span class="math">\\mathsf{dk}_v</span> is derived from <span class="math">\\dot{\\mathbf{i}}</span>.</p>

    <p class="text-gray-300"><strong>Correctness of <span class="math">\\mathbb{E}_j</span></strong>. By construction, with probability <span class="math">\\mu - \\mathrm{negl}(\\lambda)</span>, the extractor <span class="math">\\mathbb{E}_j</span> satisfies the inductive hypothesis. The key requirement is that the NARK proof <span class="math">\\pi^{(u)}</span> and accumulator <span class="math">\\mathsf{acc}^{(u)}</span> are related by the hash, which is guaranteed by membership in <span class="math">Z_{\\mathsf{AS}}</span>. This concludes our proof by induction.</p>

    <p class="text-gray-300"><strong>Correctness of <span class="math">\\mathbb{E}_{\\tilde{\\varphi}}</span></strong>. With probability <span class="math">\\mu - \\mathrm{negl}(\\lambda)</span>, <span class="math">\\mathbb{E}_{\\tilde{\\varphi}}</span> outputs <span class="math">(\\phi, \\mathsf{T}, \\mathsf{ao})</span> such that <span class="math">\\varphi \\in \\mathsf{F}</span>, <span class="math">(\\mathfrak{pp}, \\mathsf{ai}, \\mathsf{o}(\\mathsf{T}), \\mathsf{ao}) \\in Z</span>, and the first <span class="math">d + 2</span> layers of <span class="math">\\mathsf{T}</span> are <span class="math">\\varphi</span>-compliant. Since the depth of <span class="math">\\varphi</span> is at most <span class="math">d</span>, we conclude that all of the vertices in the <span class="math">(d + 2)</span>-th layer are trivially accepted by the compliance predicate, and their incoming edges must all be labeled with <span class="math">\\bot</span>. Hence, <span class="math">\\mathsf{T}</span> is <span class="math">\\varphi</span>-compliant.</p>

    <p class="text-gray-300">27</p>

    <p class="text-gray-300">6 Constructing bounded-depth accumulation</p>

    <p class="text-gray-300">We construct a bounded-depth accumulation scheme, which supports (possibly distinct) arities <span class="math">m_{1}=\\operatorname{poly}(\\lambda)</span> and <span class="math">m_{2}=\\operatorname{poly}(\\lambda)</span>, for a general class of non-interactive arguments. Across all of our constructions, we fix the following global constants: depth bound <span class="math">d_{s}</span>, code rate <span class="math">R\\in(0,1)</span>, and distance <span class="math">\\delta\\leq(1-R)/(2d_{s})</span>; this guarantees that <span class="math">d_{s}\\delta</span> is smaller than the unique decoding radius of a Reed–Solomon code with rate <span class="math">R</span>. Additionally, we use domain separation on the random oracle <span class="math">\\rho</span> to model three disjoint oracles: <span class="math">\\rho_{H}</span> for Merkle trees and hashing, <span class="math">\\rho_{\\mathsf{ARG}}</span> for the argument verifier’s randomness, and <span class="math">\\rho_{\\mathsf{AS}}</span> for the accumulation verifier’s randomness. When querying <span class="math">\\rho_{\\mathsf{ARG}}</span> and <span class="math">\\rho_{\\mathsf{AS}}</span>, we assume the random oracle’s output is used to sample from the verifier’s challenge set.</p>

    <p class="text-gray-300">Notation. If <span class="math">x,y,z</span> are vectors, we will often interpret tuples like <span class="math">(x,(y,z))</span> as a vector consisting of <span class="math">x,y,z</span> concatenated together. Given a codeword <span class="math">f\\in C</span>, let <span class="math">\\hat{f}</span> denote the corresponding message which encodes to <span class="math">f</span>. We write <span class="math">\\mathbf{f}</span> as shorthand for the tuple <span class="math">(f^{(1)},\\ldots,f^{(\\mu)})</span> and <span class="math">\\mathbf{C}</span> as shorthand for the Cartesian product <span class="math">C^{(1)}\\times\\cdots\\times C^{(\\mu)}</span>. Similarly, let <span class="math">\\hat{\\mathbf{f}}=(\\hat{f}^{(1)},\\ldots,\\hat{f}^{(\\mu)})</span> and <span class="math">\\Delta(\\mathbf{f},\\mathbf{g})=\\max_{j\\in[\\mu]}\\Delta(f^{(j)},g^{(j)})</span>. When querying locations in a codeword, let <span class="math">\\mathbf{Q}=(\\mathcal{Q}^{(1)},\\ldots,\\mathcal{Q}^{(\\mu)})</span> and <span class="math">\\mathbf{f}[\\mathbf{Q}]=(f^{(1)}[\\mathcal{Q}^{(1)}],\\ldots,f^{(\\mu)}[\\mathcal{Q}^{(\\mu)}])</span>. We use arrow notation as shorthand for tuples of commitment data, e.g. <span class="math">\\mathsf{cm}=\\left(\\mathsf{cm}^{(1)},\\ldots,\\mathsf{cm}^{(\\mu)}\\right)</span>. Vector commitment functions map over tuples, e.g. <span class="math">(\\mathsf{cm},\\mathsf{aux})\\leftarrow\\mathsf{VC.Commit}(\\mathsf{vp},\\mathbf{f})</span> should be interpreted as saying “for each <span class="math">j\\in[\\mu]</span>, let <span class="math">(\\mathsf{cm}^{(j)},\\mathsf{aux}^{(j)})\\leftarrow\\mathsf{VC.Commit}(\\mathsf{vp},f^{(j)})</span>.”</p>

    <h3 id="sec-37" class="text-xl font-semibold mt-8">6.1 Non-interactive argument</h3>

    <p class="text-gray-300">Our starting point is any special-sound interactive proof with an algebraic verifier. By this, we mean that the verifier’s check can be expressed as a sequence of degree <span class="math">d</span> polynomials (derived from the index) which take the transcript as input. The verifier accepts if all of the polynomials evaluate to zero.</p>

    <p class="text-gray-300">In more detail, we require an interactive proof for some indexed relation <span class="math">\\mathscr{R}(\\mathbb{F})</span>. Let <span class="math">\\mu</span> be the number of rounds in the protocol; this may be a function of the index. For simplicity, we assume that the instance <span class="math">\\mathbf{x}</span>, the prover’s messages <span class="math">m^{(1)},\\ldots,m^{(\\mu)}</span>, and the verifier’s challenges <span class="math">r^{(1)},\\ldots,r^{(\\mu)}</span> are all vectors over <span class="math">\\mathbb{F}</span>; their lengths may be a function of the index. From the index, the verifier derives degree <span class="math">d</span> polynomials <span class="math">p_{1},\\ldots,p_{\\ell}</span> over <span class="math">\\mathbb{F}</span>. It accepts if, for all <span class="math">i</span>, <span class="math">p_{i}(\\mathbf{x},\\mathbf{r},\\mathbf{m})=0</span>.</p>

    <p class="text-gray-300">Compressing the verifier. Without loss of generality, we can assume that the algebraic verifier consists of a single polynomial. This is because multiple polynomial checks can be compressed into a single check, e.g. by using the following technique due to <em>[EG23, BC23]</em>.</p>

    <p class="text-gray-300">Let <span class="math">\\Pi</span> be an interactive proof where the verifier’s check consists of <span class="math">\\ell</span> polynomials <span class="math">p_{0},\\ldots,p_{\\ell-1}</span>, each of degree <span class="math">d</span>. We transform this into an interactive proof <span class="math">\\mathsf{CV}[\\Pi]</span> for the same relation, where the verifier’s check is a single polynomial</p>

    <p class="text-gray-300"><span class="math">p(\\vec{X},\\vec{Y})=\\sum_{i=0}^{\\ell-1}\\mathsf{pow}_{i}(\\vec{Y})\\cdot p_{i}(\\vec{X}).</span></p>

    <p class="text-gray-300">Here, <span class="math">\\mathsf{pow}_{i}</span> is the unique degree <span class="math">\\log\\ell</span> polynomial satisfying <span class="math">\\mathsf{pow}_{i}(1,\\beta,\\beta^{2},\\beta^{4},\\ldots,\\beta^{\\ell/2})=\\beta^{i}</span> for all <span class="math">\\beta\\in\\mathbb{F}</span>. It follows that <span class="math">p</span> is of degree <span class="math">d+\\log\\ell</span>. The interactive protocol is the same as before, except that the verifier additionally samples a challenge <span class="math">y=(1,\\beta,\\beta^{2},\\beta^{4},\\ldots,\\beta^{\\ell/2})</span> where <span class="math">\\beta\\leftarrow\\mathbb{F}</span>. The verifier accepts if <span class="math">p(x,y)=0</span>, where <span class="math">x</span> is the transcript from the original proof.</p>

    <p class="text-gray-300">If <span class="math">\\Pi</span> is <span class="math">(k_{1},\\ldots,k_{\\mu})</span>-special-sound, then <span class="math">\\mathsf{CV}[\\Pi]</span> is <span class="math">(k_{1},\\ldots,k_{\\mu},\\ell)</span>-special-sound. To see why, suppose we have a tree <span class="math">T</span> of accepting transcripts for <span class="math">\\mathsf{CV}[\\Pi]</span>. Consider an arbitrary node in the penultimate layer of the tree. Its children correspond with transcripts of the form <span class="math">(x,y_{1}),\\ldots,(x,y_{\\ell})</span>, each <span class="math">y_{i}</span> distinct. Since</p>

    <p class="text-gray-300">the transcripts are accepting, the degree  <span class="math">\\ell - 1</span>  univariate polynomial  <span class="math">\\sum_{i=0}^{\\ell-1} Z^i \\cdot p_i(x)</span>  is zero at  <span class="math">\\ell</span>  points. It follows that  <span class="math">f</span>  is the zero polynomial and, for all  <span class="math">i</span> ,  <span class="math">p_i(x) = 0</span> . Let  <span class="math">T&#x27;</span>  denote  <span class="math">T</span>  with its bottom layer removed. We have shown that  <span class="math">T&#x27;</span>  is a tree of accepting transcripts for  <span class="math">\\Pi</span> . Hence, we construct an extractor for  <span class="math">\\mathbb{C}\\mathbb{V}[\\Pi]</span>  by running the extractor for  <span class="math">\\Pi</span>  on  <span class="math">T&#x27;</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{G}(1^{\\lambda})</span> :</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">1. Choose a suitable field  $\\mathbb{F},\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\Omega (\\lambda)$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let  <span class="math">\\mathsf{vp} \\gets \\mathsf{VC.Setup}(1^{\\lambda},\\mathbb{F})</span></li>

      <li>Output  <span class="math">\\mathsf{pp} = (\\mathbb{F},\\mathsf{vp})</span></li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{I}^{\\rho}(\\mathsf{pp} = (\\mathbb{F},\\mathsf{vp}),\\dot{\\mathfrak{s}})</span></li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Query  <span class="math">\\tau \\gets \\rho_H(\\dot{\\mathfrak{s}})</span></li>

      <li>From  <span class="math">\\mathbb{F}</span>  and  <span class="math">\\dot{\\mathfrak{s}}</span> , derive the following parameters, collected into  <span class="math">\\mathbb{P}</span> :</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The number of rounds, denoted  <span class="math">\\mu</span> .</li>

      <li>The length of the instance.</li>

      <li>For each  <span class="math">j \\in [\\mu]</span> , the length, denoted  <span class="math">\\ell^{(j)}</span> , of the prover's  <span class="math">j</span> -th message.</li>

      <li>For each  <span class="math">j \\in [\\mu]</span> , the format of the verifier's  <span class="math">j</span> -th challenge.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>From  <span class="math">\\mathbb{F}</span>  and  <span class="math">\\dot{\\mathfrak{s}}</span> , derive the verifier's check  <span class="math">p</span> .</li>

      <li>For each  <span class="math">j \\in [\\mu]</span> , let  <span class="math">C^{(j)}</span>  be a Reed-Solomon code over  <span class="math">\\mathbb{F}</span>  with dimension  <span class="math">\\ell^{(j)}</span> , rate  <span class="math">R</span> , and evaluation domain  <span class="math">L^{(j)}</span> .</li>

      <li>Output  <span class="math">\\mathrm{ipk} = (\\mathbb{F},\\mathsf{vp},\\dot{\\mathfrak{s}},\\tau ,\\mathbb{P},\\mathbf{C})</span>  and  <span class="math">\\mathrm{ivk} = (\\mathbb{F},\\mathsf{vp},\\tau ,\\mathbb{P},p,\\mathbf{C})</span></li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{P}^{\\rho}(\\mathsf{pp},\\dot{\\mathfrak{s}},\\mathfrak{x},\\mathfrak{w})</span></li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Compute the proving key  <span class="math">\\mathrm{ipk} = (\\mathbb{F},\\mathsf{vp},\\dot{\\mathfrak{s}},\\tau ,\\mathbb{P},\\mathbf{C})</span>  according to  <span class="math">\\mathcal{I}^{\\rho}(\\mathsf{pp},\\dot{\\mathfrak{s}})</span></li>

      <li>For  <span class="math">j \\in [\\mu]</span> :</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Compute the prover's  <span class="math">j</span> -th message  <span class="math">m^{(j)} \\gets P(\\mathbb{F}, \\dot{\\mathfrak{s}}, \\mathfrak{x}, \\mathfrak{w}, [m^{(i)}, r^{(i)}]_{i=1}^{j-1})</span> .</li>

      <li>Encode  <span class="math">m^{(j)}</span>  to  <span class="math">f^{(j)}\\in C^{(j)}</span></li>

      <li>Let  <span class="math">(\\mathsf{cm}^{(j)},\\mathsf{aux}^{(j)})\\gets \\mathsf{VC. Commit}^{\\rho_H}(\\mathsf{vp},f^{(j)})</span></li>

      <li>Query  <span class="math">r^{(j)} \\gets \\rho_{\\mathsf{ARG}}(\\tau, \\mathfrak{x}, \\mathsf{cm}^{(1)}, \\ldots, \\mathsf{cm}^{(j)})</span> .</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Output  <span class="math">\\pi = (\\mathsf{cm},\\mathsf{aux})</span></li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}^{\\rho}(\\mathsf{pp},\\dot{\\mathfrak{s}},\\mathfrak{x},\\pi = (\\mathsf{cm},\\mathsf{aux}))</span></li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Compute the verification key  <span class="math">\\mathrm{ivk} = (\\mathbb{F},\\mathsf{vp},\\tau ,\\mathbb{P},p,\\mathbf{C})</span>  according to  <span class="math">\\mathcal{I}^{\\rho}(\\mathsf{pp},\\dot{\\mathfrak{s}})</span></li>

      <li>For each  <span class="math">j \\in [\\mu]</span> , query  <span class="math">r^{(j)} \\gets \\rho_{\\mathsf{ARG}}(\\tau, \\mathfrak{x}, \\mathsf{cm}^{(1)}, \\ldots, \\mathsf{cm}^{(j)})</span> .</li>

      <li>Let  <span class="math">\\mathbf{f} \\gets \\mathsf{VC.Answer}^{\\rho_H}(\\mathsf{vp}, \\mathsf{cm}, \\mathsf{aux})</span> .</li>

      <li>Verify that  <span class="math">\\mathbf{f} \\in \\mathbf{C}</span> .</li>

      <li>Accept if  <span class="math">p(\\mathfrak{x},\\mathbf{r},\\tilde{\\mathbf{f}}) = 0</span></li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}^{\\rho}(\\mathsf{pp},\\dot{\\mathfrak{s}},\\mathfrak{x},\\pi = (\\mathsf{cm},\\mathsf{aux}))</span></li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Compute the verification key  <span class="math">\\mathrm{ivk} = (\\mathbb{F},\\mathsf{vp},\\tau ,\\mathbb{P},p,\\mathbf{C})</span>  according to  <span class="math">\\mathcal{I}^{\\rho}(\\mathsf{pp},\\dot{\\mathfrak{s}})</span></li>

      <li>For each  <span class="math">j \\in [\\mu]</span> , query  <span class="math">r^{(j)} \\gets \\rho_{\\mathsf{ARG}}(\\tau, \\mathfrak{x}, \\mathsf{cm}^{(1)}, \\ldots, \\mathsf{cm}^{(j)})</span> .</li>

      <li>Let  <span class="math">\\mathbf{f} \\gets \\mathsf{VC.Answer}^{\\rho_H}(\\mathsf{vp}, \\mathsf{cm}, \\mathsf{aux})</span> .</li>

      <li>Find  <span class="math">\\mathbf{g} \\in \\mathbf{C}</span>  by uniquely decoding  <span class="math">\\mathbf{f}</span> . If no such codeword exists, reject.</li>

      <li>Accept if  <span class="math">p(\\mathfrak{x},\\mathbf{r},\\dot{\\mathbf{g}}) = 0</span></li>

    </ol>

    <p class="text-gray-300">Figure 8: Our NARK construction.</p>

    <p class="text-gray-300">Committing to messages.</p>

    <p class="text-gray-300">In order to achieve efficient accumulation, we will instead have the prover send commitments to messages. Only in the final move of the protocol does the prover send openings to all of the commitments. Strictly speaking, this is only special-sound for an “augmented relation”; namely, there exists an extractor which, given a tree of accepting transcripts, outputs either a witness or a break of the commitment scheme. Nonetheless, assuming the scheme is computationally binding, applying the Fiat-Shamir transformation yields a non-interactive argument of knowledge for the original relation. We refer to <em>[x1]</em> for a more detailed analysis.</p>

    <p class="text-gray-300">Removing interaction. Given a special-sound interactive proof <span class="math">(P,V)</span>, we apply the Fiat–Shamir transformation (with commitments) to get a non-interactive argument of knowledge <em>[x1]</em>. In order to achieve efficient accumulation, we use a standard variant of the transformation where the index is first hashed to a succinct value <span class="math">\\tau</span>. The Fiat–Shamir transform outputs a non-interactive argument <span class="math">\\mathsf{ARG}=(\\mathcal{G},\\mathcal{P},\\mathcal{V})</span>, shown in Figure 8, for the indexed relation family <span class="math">\\{\\mathscr{R}_{\\mathsf{pp}}=\\mathscr{R}(\\mathbb{F})\\}</span>. We also define an indexer <span class="math">\\mathcal{I}</span> as a helper algorithm.</p>

    <p class="text-gray-300">Attema et al. <em>[x1]</em> prove that multi-round public-coin protocols can be compiled into non-interactive arguments. However, their definition of knowledge-soundness is slightly different from ours: they require that the extractor succeeds with non-negligible probability if the adversary succeeds with non-negligible probability. Our definition, on the other hand, requires that the extractor succeeds with all but negligible probability whenever the adversary succeeds. However, these definitions are equivalent as one can boost the extractor’s success probability by running it until it succeeds. This works as the extractor is only required to run in <em>expected</em> polynomial time.</p>

    <p class="text-gray-300">Relaxed verifier. We use a specific commitment scheme to support accumulation: the prover sends a vector commitment to a codeword of the message, along with the full auxiliary data. We relax the verifier in two different ways to get <span class="math">\\tilde{\\mathcal{V}}</span> (also shown in Figure 8). First, we allow it to decode noisy codewords. Second, we allow it to accept partial openings to commitments; the missing positions correspond with erasure errors. These changes do not affect knowledge soundness, since the prover is still bound to (decoded) messages.</p>

    <h3 id="sec-38" class="text-xl font-semibold mt-8">6.2 Accumulation scheme</h3>

    <p class="text-gray-300">Fix a subset <span class="math">H\\subset\\mathbb{F}</span> of size <span class="math">m=m_{1}+m_{2}</span>; this may be a function of <span class="math">\\lambda</span>. We construct an accumulation scheme <span class="math">\\mathsf{AS}=(\\mathrm{G},\\mathrm{I},\\mathrm{P},\\mathrm{V},\\mathrm{D})</span> for <span class="math">\\mathsf{ARG}</span>. The argument verifier inputs are split into <span class="math">\\mathsf{qx}=(\\mathtt{x},\\mathsf{cm})</span> and <span class="math">\\mathsf{qw}=\\mathsf{adx}</span>. Accumulators have a nearly identical structure; in fact, any verifier input <span class="math">(\\mathsf{qx},\\mathsf{qw})</span> can be converted into an accumulator <span class="math">\\mathsf{acc}</span> by setting <span class="math">\\mathsf{acc.w}=\\mathsf{qw}</span> and <span class="math">\\mathsf{acc.x}=\\mathsf{CastInput}^{\\rho}(\\tau,\\mathsf{qx})</span>, which is defined below.</p>

    <p class="text-gray-300"><span class="math">\\mathsf{CastInput}^{\\rho}(\\tau,\\mathsf{qx}=(\\mathtt{x},\\mathsf{cm}))</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For each <span class="math">j\\in[\\mu]</span>, query <span class="math">r^{(j)}\\leftarrow\\rho_{\\mathsf{ARG}}(\\tau,\\mathtt{x},\\mathsf{cm}^{(1)},\\ldots,\\mathsf{cm}^{(j)})</span>.</li>

      <li>Collect <span class="math">\\mathtt{x}</span> and <span class="math">\\mathbf{r}</span> into a vector <span class="math">x</span>.</li>

      <li>Output <span class="math">\\mathsf{acc.x}=(\\mathrm{0},\\mathrm{x},\\mathrm{cm})</span>.</li>

    </ol>

    <p class="text-gray-300">We also define a helper function which casts <span class="math">[\\mathsf{qx}_{i}]_{i=1}^{m_{1}}</span> and <span class="math">[\\mathsf{acc}_{i}.\\mathtt{x}]_{i=1}^{m_{2}}</span> into a single list of <span class="math">m=m_{1}+m_{2}</span> accumulator instances.</p>

    <p class="text-gray-300"><span class="math">\\mathsf{Cast}^{\\rho}(\\tau,[\\mathsf{qx}_{i}]_{i=1}^{m_{1}},[\\mathsf{acc}_{i}.\\mathtt{x}]_{i=1}^{m_{2}})</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Output <span class="math">[\\mathsf{CastInput}(\\tau,\\mathsf{qx}_{1}),\\ldots,\\mathsf{CastInput}(\\tau,\\mathsf{qx}_{m_{1}}),\\mathsf{acc}_{1}.\\mathtt{x},\\ldots,\\mathsf{acc}_{m_{2}}.\\mathtt{x}]</span>.</li>

    </ol>

    <p class="text-gray-300">Finally, we define helper functions which perform the bulk of proving and verification.</p>

    <p class="text-gray-300">PROVE <span class="math">^{\\rho}</span>  (apk,  <span class="math">[e_i, x_i, \\mathsf{cm}_i, \\mathsf{aux}_i]_{i=1}^m</span> ):</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For each  <span class="math">i\\in [m]</span>  , let  <span class="math">\\mathbf{f}_i\\gets \\mathsf{VC.Answer}^{\\rho_H}(\\mathsf{vp},\\mathsf{cm}_i,\\mathsf{aux}_i)</span></li>

      <li>Compute the univariate polynomial  <span class="math">q \\in \\mathbb{F}[X]</span>  of degree at most  <span class="math">d(m - 1) - m</span>  such that</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">p \\left(\\sum_ {i = 1} ^ {m} L _ {i, H} (X) \\cdot \\left(x _ {i}, \\hat {\\mathbf {f}} _ {i}\\right)\\right) = v _ {H} (X) \\cdot q (X) + \\sum_ {i = 1} ^ {m} L _ {i, H} (X) \\cdot e _ {i}.</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Query  <span class="math">\\alpha \\gets \\rho_{\\mathrm{AS}}(\\tau, [\\mathrm{acc}_i.\\mathbf{x}]_{i=1}^m, q)</span> , where  <span class="math">\\alpha \\in \\mathbb{F}</span>  is a uniformly sampled field element.</li>

      <li>Compute  <span class="math">e = v(\\alpha)\\cdot q(\\alpha) + \\sum_{i}L_{i}(\\alpha)\\cdot e_{i}</span></li>

      <li>Compute  <span class="math">(x,\\hat{\\mathbf{f}}) = \\sum_{i}L_{i}(\\alpha)\\cdot (x_{i},\\hat{\\mathbf{f}}_{i})</span></li>

      <li>Let  <span class="math">(\\mathsf{cm},\\mathsf{aux})\\gets \\mathsf{VC.}\\mathsf{Commit}^{\\rho_H}(\\mathsf{vp},\\mathbf{f})</span></li>

      <li>Set  <span class="math">\\mathsf{acc}.\\mathbf{x} = (e,x,\\mathsf{cm})</span>  and  <span class="math">\\mathsf{acc}.\\mathbf{w} = \\mathsf{aux}</span></li>

      <li>Query  <span class="math">\\mathbf{Q} \\gets \\rho_{\\mathrm{AS}}(\\tau, [\\mathrm{acc}_i.\\mathbf{x}]_{i=1}^m, q, \\mathrm{acc}.\\mathbf{x})</span> , where  <span class="math">\\mathcal{Q}^{(j)}</span>  is a uniformly sampled  <span class="math">t</span> -sized subset of  <span class="math">L^{(j)}</span> .</li>

      <li>For each  <span class="math">i\\in [m]</span>  , let  <span class="math">\\mathsf{op}_i\\gets \\mathsf{VC.}\\mathsf{Open}^{\\rho_H}(\\mathsf{vp},\\mathsf{aux}_i,\\mathbf{Q})</span></li>

      <li>Let  <span class="math">\\mathsf{op} \\gets \\mathsf{VC. Open}^{\\rho_H}(\\mathsf{vp}, \\mathsf{aux}, \\mathbf{Q})</span> .</li>

      <li>Output acc and pf = (q, [op]i=1, op).</li>

    </ol>

    <p class="text-gray-300">VERIFY <span class="math">\\rho</span>  (avk,  <span class="math">[e_i, x_i, \\mathsf{cm}_i]_{i=1}^m</span> ,  <span class="math">(e, x, \\mathsf{cm})</span> ,  <span class="math">(q, [\\mathsf{op}_i]_{i=1}^m, \\mathsf{op})</span> ):</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Query  <span class="math">\\alpha \\gets \\rho_{\\mathrm{AS}}(\\tau, [\\mathrm{acc}_i.\\mathbf{x}]_{i=1}^m, q)</span> .</li>

      <li>Query  <span class="math">\\mathbf{Q} \\gets \\rho_{\\mathrm{AS}}(\\tau, [\\mathrm{acc}_i.\\mathbf{x}]_{i=1}^m, q, \\mathrm{acc}.\\mathbf{x})</span> .</li>

      <li>For each  <span class="math">i\\in [m]</span>  , let  <span class="math">\\mathbf{v}_i = \\mathsf{VC.Answer}^{\\rho_H}(\\mathsf{vp},\\mathsf{cm}_i,\\mathsf{op}_i)</span>  . If  <span class="math">\\mathbf{v}_i[\\mathbf{Q}]</span>  contains  <span class="math">\\perp</span>  , reject.</li>

      <li>Let  <span class="math">\\mathbf{v} = \\mathsf{VC.Answer}^{\\rho_H}(\\mathsf{vp},\\mathsf{cm},\\mathsf{op},\\mathbf{Q})</span>  . If  <span class="math">\\mathbf{v}[\\mathbf{Q}]</span>  contains  <span class="math">\\perp</span>  , reject.</li>

      <li>Verify that  <span class="math">e = v_{H}(\\alpha) \\cdot q(\\alpha) + \\sum_{i=1}^{m} L_{i,H}(\\alpha) \\cdot e^{(i)}</span> .</li>

      <li>Verify that  <span class="math">(x,\\mathbf{v}) = \\sum_{i = 1}^{m}L_{i,H}(\\alpha)\\cdot (x_{i},\\mathbf{v}_{i})</span></li>

    </ol>

    <p class="text-gray-300">See Figure 9 for a full description of AS, along with the family of deciders.</p>

    <p class="text-gray-300">G(1):</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Choose a suitable spot check parameter  <span class="math">t = \\Omega(\\lambda)</span> .</li>

      <li>Output  <span class="math">\\mathsf{pp}_{\\mathsf{AS}} = t</span></li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathrm{I}^{\\rho}(\\mathsf{pp}_{\\mathsf{AS}} = t, \\mathsf{pp} = (\\mathbb{F}, \\mathsf{vp}), \\dot{\\mathfrak{s}})</span> :</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Obtain  <span class="math">\\tau, \\mathbb{P}, p, \\mathbf{C}</span>  from  <span class="math">\\mathcal{I}^{\\rho}(\\mathsf{pp}, \\dot{\\mathfrak{s}})</span> .</li>

      <li>Output  <span class="math">\\mathsf{apk} = (\\mathbb{F},\\mathsf{vp},t,\\tau ,\\mathbb{P},p,\\mathbf{C})</span>  ,  <span class="math">\\mathsf{avk} = (\\mathbb{F},\\mathsf{vp},t,\\tau ,\\mathbb{P},\\mathbf{C})</span>  , and  <span class="math">\\mathsf{dk} = (\\mathbb{F},\\mathsf{vp},\\mathbb{P},p,\\mathbf{C})</span></li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathrm{P}^{\\rho}(\\mathsf{apk},[\\mathsf{qx}_i,\\mathsf{qw}_i]_{i = 1}^{m_1},[\\mathsf{acc}]_{i = 1}^{m_2})</span></li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let  <span class="math">[e_i, x_i, \\mathsf{cm}_i]_{i=1}^m \\gets \\mathsf{CAST}(\\tau, [\\mathsf{qx}_i]_{i=1}^{m_1}, [\\mathsf{acc}_i.\\mathbf{x}]_{i=1}^{m_2})</span> .</li>

      <li>Parse  <span class="math">[\\mathsf{aux}_i]_{i = 1}^m = [\\mathsf{qw}_1,\\dots ,\\mathsf{qw}_{m_1},\\mathsf{acc}_1.\\mathsf{w},\\dots ,\\mathsf{acc}_{m_2}.\\mathsf{w}]</span></li>

      <li>Output PROVE <span class="math">^{\\rho}</span>  (apk,  <span class="math">[e_i, x_i, \\mathsf{cm}_i, \\mathsf{aux}_i]_{i=1}^m</span> ).</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathrm{V}^{\\rho}(\\mathsf{avk},[\\mathsf{qx}_i]_{i = 1}^{m_1},[\\mathsf{acc}_i.\\mathbf{x}]_{i = 1}^{m_2},\\mathsf{acc}.\\mathbf{x},\\mathsf{pf})</span></li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let  <span class="math">[e_i, x_i, \\mathsf{cm}_i]_{i=1}^m \\gets \\mathsf{CAST}(\\tau, [\\mathsf{qx}_i]_{i=1}^{m_1}, [\\mathsf{acc}_i.\\mathbf{x}]_{i=1}^{m_2})</span> .</li>

      <li>Accept if VERIFY(avk,  <span class="math">[e_i, x_i, \\mathsf{cm}_i]_{i=1}^m</span> , acc.  <span class="math">\\mathbf{x}</span> , pf) accepts.</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathrm{D}_{\\mathrm{v}}^{\\rho}(\\mathrm{dk},\\mathrm{acc}.\\mathbf{x} = (e,x,\\mathrm{cm}),\\mathrm{acc}.\\mathbf{w} = \\mathrm{aux})</span></li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let  <span class="math">\\mathbf{f} \\gets \\mathsf{VC.Answer}^{\\rho_H}(\\mathsf{vp}, \\mathsf{cm}, \\mathsf{aux})</span> .</li>

      <li>Find  <span class="math">\\mathbf{g} \\in \\mathbf{C}, \\Delta(\\mathbf{f}, \\mathbf{g}) \\leq s\\delta</span>  by decoding  <span class="math">\\mathbf{f}</span> . If no such codeword exists, reject.</li>

      <li>Accept if  <span class="math">p(x, \\dot{\\mathbf{g}}) = e</span> .</li>

    </ol>

    <p class="text-gray-300">Figure 9: Accumulation scheme algorithms.</p>

    <p class="text-gray-300">.</p>

    <h4 id="sec-39" class="text-lg font-semibold mt-6">Completeness.</h4>

    <p class="text-gray-300">Suppose <span class="math">\\mathcal{A}</span> outputs <span class="math">\\mathbb{i}</span>, <span class="math">[\\mathsf{qx}_{i},\\mathsf{qw}_{i}]_{i=1}^{m_{1}}</span>, and <span class="math">[\\mathsf{acc}_{i}]_{i=1}^{m_{2}}</span>, where the inputs are accepted by <span class="math">\\mathcal{V}</span> and the accumulators are accepted by <span class="math">\\mathrm{D}</span>. After casting, the prover holds <span class="math">[e_{i},x_{i},\\mathsf{cm}_{i},\\mathsf{adx}_{i}]_{i=1}^{m}</span> such that, for all <span class="math">i</span>, the auxiliary data <span class="math">\\mathsf{adx}_{i}</span> opens to codewords <span class="math">\\mathbf{f}_{i}\\in\\mathbf{C},p(x_{i},\\hat{\\mathbf{f}}_{i})=e_{i}</span>. Consider the degree <span class="math">d(m-1)</span> polynomial</p>

    <p class="text-gray-300"><span class="math">p\\left(\\sum_{i=1}^{m}L_{i,H}(X)\\cdot(x_{i},\\hat{\\mathbf{f}}_{i})\\right)-\\sum_{i=1}^{n}L_{i,H}(X)\\cdot e_{i}.</span></p>

    <p class="text-gray-300">At each evaluation point <span class="math">a_{j}\\in H</span>, <span class="math">\\sum_{i}L_{i}(a_{j})\\cdot(x_{i},\\hat{\\mathbf{f}}_{i})=(x_{j},\\hat{\\mathbf{f}}_{j})</span>, since <span class="math">L_{j}(a_{j})=1</span> and <span class="math">L_{i}(a_{j})=0</span> for <span class="math">i\\neq j</span>. Similarly, <span class="math">\\sum_{i}L_{i}(a_{j})\\cdot e_{i}=e_{j}</span>. It follows that the polynomial is zero at all points in <span class="math">H</span>, and thus factors into <span class="math">v_{H}(X)\\cdot q(X)</span>. Since <span class="math">v_{H}</span> has degree <span class="math">m</span>, <span class="math">q</span> has degree <span class="math">d(m-1)-m</span>. It remains to be shown that the spot check succeeds. Since the accumulators are valid, the prover can open the codewords at any location. Next, recall that the prover computes <span class="math">\\hat{\\mathbf{f}}=\\sum_{i}L_{i}(\\alpha)\\cdot\\hat{\\mathbf{f}}_{i}</span>. By linearity of the code, this relationship holds over the entire codeword.</p>

    <h3 id="sec-40" class="text-xl font-semibold mt-8">6.3 Soundness analysis</h3>

    <p class="text-gray-300">Our accumulation scheme can be viewed as a compiled interactive oracle proof, where the prover corresponds with Prove and the verifier corresponds with Verify plus <span class="math">\\mathrm{D}_{s-1}</span>. The relation corresponds with <span class="math">\\mathrm{D}_{s}</span>; in particular, for field <span class="math">\\mathbb{F}</span> and depth parameter <span class="math">s\\in[d_{s}]</span>, define the indexed language</p>

    <p class="text-gray-300"><span class="math">\\mathscr{L}(\\mathbb{F},s)=\\{(\\mathbb{i},(e,x,\\mathbf{f})):\\exists\\mathbf{g}\\in\\mathbf{C},\\Delta(\\mathbf{f},\\mathbf{g})\\leq s\\delta,p(x,\\hat{\\mathbf{g}})=e\\}.</span></p>

    <p class="text-gray-300">Here, <span class="math">\\mathbb{i}</span> is an index of <span class="math">\\mathscr{R}(\\mathbb{F})</span> from which <span class="math">p</span> and <span class="math">\\mathbf{C}</span> are implicitly derived. We construct a public-coin interactive oracle proof <span class="math">\\mathsf{IOP}</span> for the multi-instance language</p>

    <p class="text-gray-300"><span class="math">\\mathscr{L}(\\mathbb{F},s,m)=\\{(\\mathbb{i},[e_{i},x_{i},\\mathbf{f}_{i}]_{i=1}^{m}):\\forall i\\in[m],(\\mathbb{i},(e_{i},x_{i},\\mathbf{f}_{i}))\\in\\mathscr{L}(\\mathbb{F},s)\\}.</span></p>

    <p class="text-gray-300">Note that all algorithms in <span class="math">\\mathsf{IOP}</span> implicitly take as input the following protocol parameters: field <span class="math">\\mathbb{F}</span>, depth parameter <span class="math">s</span>, arity <span class="math">m</span>, and spot check parameter <span class="math">t</span>. Since we are only interested in proving soundness, we omit the prover’s description (it essentially matches the accumulation prover). The protocol is as follows.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The prover sends <span class="math">q\\in\\mathbb{F}[X]</span>, a polynomial of degree at most <span class="math">d(m-1)-m</span>.</li>

      <li>The verifier uniformly samples and sends a field element <span class="math">\\alpha\\in\\mathbb{F}</span>.</li>

      <li>The prover sends <span class="math">(e,x,\\mathbf{f})</span>.</li>

      <li>For each <span class="math">j\\in[\\mu]</span>, the verifier uniformly samples and sends a query set <span class="math">\\mathcal{Q}^{(j)}\\subset L^{(j)}</span> of size <span class="math">t</span>.</li>

    </ol>

    <p class="text-gray-300">The verifier then performs two sets of checks. The first set corresponds with the accumulation verifier:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Verify that <span class="math">e=v(\\alpha)\\cdot q(\\alpha)+\\sum_{i}L_{i}(\\alpha)\\cdot e_{i}</span>.</li>

      <li>Verify that <span class="math">x=\\sum_{i}L_{i}(\\alpha)\\cdot x_{i}</span>.</li>

      <li>Verify that <span class="math">\\mathbf{f}[\\mathbf{Q}]=\\sum_{i}L_{i}(\\alpha)\\cdot\\mathbf{f}_{i}[\\mathbf{Q}]</span>.</li>

    </ul>

    <p class="text-gray-300">The second set corresponds with the decider:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Find <span class="math">\\mathbf{g}\\in\\mathbf{C}</span> by decoding <span class="math">\\mathbf{f}</span>. If no such codewords exist, reject.</li>

      <li>Verify that <span class="math">\\Delta(\\mathbf{f},\\mathbf{g})\\leq(s-1)\\delta</span>.</li>

      <li>Verify that <span class="math">p(x,\\hat{\\mathbf{g}})=e</span>.</li>

    </ul>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">Theorem 6.1. IOP has round-by-round soundness error</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\epsilon_{\\mathrm{rbr}}(\\mathbb{F}, m, t, n) = \\max \\left(\\frac{n(m - 1)}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}, \\frac{d(m - 1)}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}, (1 - \\delta)^t\\right),</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">where <span class="math">n = \\max_j \\ell^{(j)} / R</span> is the maximum blocklength.</p>

    <p class="text-gray-300">Proof. We define a doomed set <span class="math">\\mathcal{D}</span> as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">([e_i, x_i, \\mathbf{f}_i]_{i=1}^m, \\varnothing) \\in \\mathcal{D}</span> if the instance is not in the language, i.e. there exists <span class="math">i \\in [m]</span> such that for all <span class="math">\\mathbf{g} \\in \\mathbf{C}</span>, <span class="math">\\Delta(\\mathbf{f}_i, \\mathbf{g}) &amp;gt; s\\delta</span> or <span class="math">p(x_i, \\hat{\\mathbf{g}}) \\neq e_i</span>. Here, <span class="math">\\varnothing</span> denotes the empty transcript.</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- $([e_i, x_i, \\mathbf{f}_i]_{i=1}^m, q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\alpha) \\in \\mathcal{D}<span class="math"> if for all </span>\\mathbf{g} \\in \\mathbf{C}$,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\Delta \\left(\\sum_{i=1}^m L_{i,H}(\\alpha) \\cdot \\mathbf{f}_i, \\mathbf{g}\\right) &amp;gt; s\\delta \\quad \\text{or} \\quad p(x, \\hat{\\mathbf{g}}) \\neq v_H(\\alpha) \\cdot q(\\alpha) + \\sum_{i=1}^m L_{i,H}(\\alpha) \\cdot e_i.</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- $([e_i, x_i, \\mathbf{f}_i]_{i=1}^m, q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(e, x, \\mathbf{f})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{Q}) \\in \\mathcal{D}$ if the verifier rejects the transcript.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The statement follows from Claims 6.2 and 6.3.</p>

    <p class="text-gray-300">Claim 6.2. Suppose <span class="math">([e_i, x_i, \\mathbf{f}_i]_{i=1}^m, \\varnothing)</span> is in the doomed set. Then</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Pr_{\\alpha} \\left[ (e_i, x_i, \\mathbf{f}_i)_{i=1}^m, q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\alpha) \\notin \\mathcal{D} \\right] \\leq \\max \\left(\\frac{n(m - 1)}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}, \\frac{d(m - 1)}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\right).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Proof. Suppose not. Let $\\epsilon_1 = n(m - 1) /</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, \\epsilon_2 = d(m - 1) /</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$, and define the events</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">E_1(\\mathbf{g}, \\alpha): \\Delta \\left(\\sum_{i=1}^m L_{i,H}(\\alpha) \\cdot \\mathbf{f}_i, \\mathbf{g}\\right) \\leq s\\delta,</span></div>

    <div class="my-4 text-center"><span class="math-block">E_2(\\mathbf{g}, \\alpha): p(x, \\hat{\\mathbf{g}}) = v_H(\\alpha) \\cdot q(\\alpha) + \\sum_{i=1}^m L_{i,H}(\\alpha) \\cdot e_i.</span></div>

    <p class="text-gray-300">Our supposition is that <span class="math">\\operatorname{Pr}_{\\alpha}[\\exists \\mathbf{g} \\in \\mathbf{C}, E_1(\\mathbf{g}, \\alpha) \\wedge E_2(\\mathbf{g}, \\alpha)] &amp;gt; \\max(\\epsilon_1, \\epsilon_2)</span>. It follows that</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr_{\\alpha} \\left[ \\exists \\mathbf{g} \\in \\mathbf{C}, E_1(\\mathbf{g}, \\alpha) \\right] = \\Pr_{\\alpha} \\left[ \\forall j \\in [\\mu], \\Delta \\left(\\sum_{i=1}^m L_{i,H}(\\alpha) \\cdot \\mathbf{f}_i^{(j)}, C^{(j)}\\right) \\leq s\\delta \\right] &amp;gt; \\epsilon_1.</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">For each <span class="math">j</span>, by Lemma 3.4, there exist codewords <span class="math">g_1^{(j)}, \\ldots, g_m^{(j)} \\in C^{(j)}</span> and subdomain $L' \\subseteq L^{(j)},</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L^{(j)}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq 1 - s\\delta<span class="math">, such that, for all </span>i<span class="math">, </span>f_i^{(j)}<span class="math"> and </span>g_i^{(j)}<span class="math"> agree on </span>L'$. This implies the following.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\Delta(\\mathbf{f}_i, \\mathbf{g}_i) \\leq s\\delta</span>. Since we start in the doomed set, this implies that, for some <span class="math">i</span>, <span class="math">p(x_i, \\hat{\\mathbf{g}}_i) \\neq e_i</span>. Hence, the degree <span class="math">d(m - 1)</span> polynomial</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">z(X) = p \\left(\\sum_{i=1}^m L_{i,H}(X) \\cdot (x_i, \\hat{\\mathbf{g}}_i)\\right) - v_H(X) \\cdot q(X) - \\sum_{i=1}^m L_{i,H} \\cdot e_i</span></div>

    <p class="text-gray-300">is non-zero. By the Schwartz-Zippel lemma, <span class="math">\\operatorname{Pr}_{\\alpha}[z(\\alpha) = 0] \\leq \\epsilon_2</span>.</p>

    <p class="text-gray-300">33</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For all <span class="math">\\alpha\\in\\mathbb{F}</span>, <span class="math">\\Delta(\\sum_{i}L_{i}(\\alpha)\\cdot\\mathbf{f}_{i},\\sum_{i}L_{i}(\\alpha)\\cdot\\mathbf{g}_{i})\\leq s\\delta</span>. In other words, <span class="math">E_{1}(\\mathbf{g},\\alpha)</span> holds for <span class="math">\\mathbf{g}=\\mathbf{g}(\\alpha)=\\sum_{i}L_{i}(\\alpha)\\cdot\\mathbf{g}_{i}</span>; moreover, since <span class="math">s\\delta</span> is smaller than the unique decoding radius, this is the only satisfying assignment. It follows that <span class="math">\\Pr_{\\alpha}[E_{2}(\\mathbf{g}(\\alpha),\\alpha)]&gt;\\epsilon_{2}</span>.</li>

    </ul>

    <p class="text-gray-300">Notice that the events <span class="math">z(\\alpha)=0</span> and <span class="math">E_{2}(\\mathbf{g}(\\alpha),\\alpha)</span> are equivalent. Thus, we have shown a contradiction. ∎</p>

    <h6 id="sec-41" class="text-base font-medium mt-4">Claim 6.3.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Suppose $([e_{i},x_{i},\\mathbf{f}_{i}]_{i=1}^{m},q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\alpha)$ is in the doomed set. Then</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\Pr_{\\alpha}[((e_{i},x_{i},\\mathbf{f}_{i})_{i=1}^{m},q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\alpha</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(e,x,\\mathbf{f})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{Q})\\not\\in\\mathcal{D}]\\leq(1-\\delta)^{t}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-42" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">In order for the verifier to accept, <span class="math">\\mathbf{f}</span> must decode to codewords <span class="math">\\mathbf{g}\\in\\mathbf{C},\\Delta(\\mathbf{f},\\mathbf{g})\\leq(s-1)\\delta</span> such that <span class="math">p(x,\\hat{\\mathbf{g}})=e=v(\\alpha)\\cdot q(\\alpha)+\\sum_{i}L_{i}(\\alpha)\\cdot e_{i}</span>. Since we start in the doomed set, this implies that, for some <span class="math">j</span>, <span class="math">\\Delta(\\sum_{i}L_{i}(\\alpha)\\cdot f_{i}^{(j)},g^{(j)})&gt;s\\delta</span>. Hence, <span class="math">\\Delta(\\sum_{i}L_{i}(\\alpha)\\cdot f_{i}^{(j)},f^{(j)})&gt;\\delta</span>. The probability that the vectors are consistent at a random index is <span class="math">1-\\delta</span>, and the claim follows. ∎</p>

    <h4 id="sec-43" class="text-lg font-semibold mt-6">From IOP to Accumulation.</h4>

    <p class="text-gray-300">We apply the BCS transformation <em>[x1]</em> to get a non-interactive argument <span class="math">(\\mathbf{P},\\mathbf{V})</span> which matches our accumulation scheme. At a high level, the transformation replaces each IOP message with a vector commitment, and each challenge with a query to the random oracle. The prover then includes partial openings to all of the verifier’s oracle accesses in the proof.</p>

    <p class="text-gray-300">However, this does not immediately work. The most glaring issue is that the accumulation verifier does not have full access to the IOP instance <span class="math">[e_{i},x_{i},\\mathbf{f}_{i}]_{i=1}^{m}</span>. We will instead treat the IOP instance as an oracle, in the sense that <span class="math">\\mathbf{P}</span> outputs a vector commitment to some instance and provides partial openings in the proof. Recall that the BCS transformation uses Valiant’s extractor <em>[x23]</em> to extract IOP messages from each vector commitment in the proof. Similarly, we should be able to extract an instance from the proof, which is valid if <span class="math">\\mathbf{V}</span> accepts. Listed below are some additional modifications to the BCS transformation that we require. These are relatively minor, and follow from a close reading of <em>[x1]</em>.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Our IOP prover sends certain values which will always be read by the verifier, namely <span class="math">q</span>, <span class="math">e</span>, and <span class="math">x</span>. Therefore, <span class="math">\\mathbf{P}</span> should include these values directly in the proof. Similarly, <span class="math">\\mathbf{P}</span> should output parts of the instance without committing, namely <span class="math">[e_{i},x_{i}]_{i=1}^{m}</span>.</li>

      <li>Our IOP prover sends many codewords <span class="math">f^{(1)},\\ldots,f^{(\\mu)}</span> in the same round. Therefore, <span class="math">\\mathbf{P}</span> should output separate commitments for each codeword. Similarly, <span class="math">\\mathbf{P}</span> should output separate commitments for each codeword <span class="math">f_{i}^{(j)}</span> in the instance.</li>

      <li>Our IOP verifier accesses the codewords <span class="math">\\mathbf{f}</span> twice: first for the spot check, and second for decoding to <span class="math">\\mathbf{g}</span>. Since these checks will be separated across the accumulation verifier and decider, <span class="math">\\mathbf{P}</span> should send separate openings for each access.</li>

      <li>Suppose (a potentially malicious) <span class="math">\\mathbf{P}</span> provides a partial opening which does not contain one of the locations in the query set. Instead of rejecting, <span class="math">\\mathbf{V}</span> should fill any missing locations with a default symbol <span class="math">\\bot</span> using VC.Answer. This affords more flexibility to the IOP verifier, in particular when it attempts to decode <span class="math">\\mathbf{f}</span>.</li>

    </ol>

    <p class="text-gray-300">Items 1 and 2 guarantees that the committed IOP instance can be parsed as <span class="math">m</span> accumulator instances <span class="math">[\\mathsf{acc}_{i}.\\mathbf{x}]_{i=1}^{m}</span>. Items 1 to 3 guarantee that a proof output by <span class="math">\\mathbf{P}</span> can be parsed as an accumulator <span class="math">\\mathsf{acc}</span> and accumulation proof <span class="math">\\mathsf{pf}</span>. Items 3 and 4 guarantees that <span class="math">\\mathbf{V}</span> can be decomposed into <span class="math">\\mathsf{Verify}</span> and <span class="math">\\mathsf{D}_{s-1}</span>. Our requirements are formally summarized in Claim 6.4.</p>

    <p class="text-gray-300">Claim 6.4. There exists a transformation BCS such that BCS[IOP, VC] = (P, V) satisfies the following soundness property. There exists a polynomial time extractor  <span class="math">\\mathbf{E}</span>  such that for every choice of protocol parameters  <span class="math">(\\mathbb{F}, s, m, t)</span> , polynomial time adversary  <span class="math">\\tilde{\\mathbf{P}}</span> , and auxiliary input distribution  <span class="math">\\mathcal{D}</span> ,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\mathbf {V} ^ {\\rho} (\\mathsf {v p}, \\mathbb {i}, \\bar {\\mathbf {x}}, \\pi) = 1 &amp;amp; \\mathsf {v p} \\leftarrow \\mathsf {V C . S e t u p} ^ {\\rho_ {H}} (1 ^ {\\lambda}) \\\\ \\Downarrow &amp;amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (1 ^ {\\lambda}) \\\\ (\\mathbb {i}, [ e _ {i}, x _ {i}, \\mathbf {f} _ {i} ] _ {i = 1} ^ {m}) \\in \\mathcal {L} (\\mathbb {F}, s, m) &amp;amp; (\\mathbb {i}, \\bar {\\mathbf {x}} = [ e _ {i}, x _ {i}, \\mathsf {c m} _ {i} ] _ {i = 1} ^ {m}, \\pi ; r) \\leftarrow \\tilde {\\mathbf {P}} ^ {\\rho} (\\mathsf {v p}, \\mathsf {a i}) \\\\ &amp;amp; [ \\mathsf {o p} _ {i} ] _ {i = 1} ^ {m} \\leftarrow \\mathbf {E} ^ {\\tilde {\\mathbf {P}}, \\rho} (\\mathsf {v p}, \\mathsf {a i}, r) \\\\ &amp;amp; \\forall i \\in [ m ], \\mathbf {f} _ {i} \\leftarrow \\mathsf {V C . A n s w e r} ^ {\\rho_ {H}} (\\mathsf {v p}, \\mathsf {c m} _ {i}, \\mathsf {o p} _ {i}) \\end{array} \\right]</span></div>

    <p class="text-gray-300">is negligibly close to  <span class="math">1 - \\epsilon_{\\mathrm{rbr}}(\\mathbb{F},m,t,n)\\cdot Q</span> . Here,  <span class="math">n</span>  is an upper bound on the blocklengths derived from any index output by  <span class="math">\\tilde{\\mathbf{P}}</span> , and  <span class="math">Q</span>  is an upper bound on the number of random oracle queries made by  <span class="math">\\tilde{\\mathbf{P}}</span> . The extractor implicitly receives the protocol parameters as input. Additionally,  <span class="math">\\mathbf{V}</span>  can be implemented as follows.</p>

    <p class="text-gray-300"><span class="math">\\mathbf{V}^{\\rho}(\\mathsf{vp},\\mathbb{i},\\bar{\\mathbf{x}} = [e_i,x_i,\\mathsf{cm}_i]_{i = 1}^m,\\pi = (q,(e,x,\\mathsf{cm}),(\\mathsf{op}_1,\\ldots ,\\mathsf{op}_m,\\mathsf{op},\\mathsf{op}&#x27;))):</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let  <span class="math">(\\mathsf{apk},\\mathsf{avk},\\mathsf{dk})\\gets \\mathrm{I}^{\\rho}(\\mathsf{pp}_{\\mathsf{AS}} = t,\\mathsf{pp} = (\\mathbb{F},\\mathsf{vp}),\\mathsf{i}_{\\Phi} = \\mathbb{i})</span></li>

      <li>Verify that  <span class="math">\\mathrm{VERIFY}^{\\rho}(\\mathsf{avk},[e_i,x_i,\\mathsf{cm}_i]_{i = 1}^m,(e,x,\\mathsf{cm}),(q,[\\mathsf{op}_i]_{i = 1}^m,\\mathsf{op}))</span>  accepts.</li>

      <li>Verify that  <span class="math">\\mathrm{D}_{s - 1}^{\\rho}(\\mathrm{dk},(e,x,\\mathrm{cm}),\\mathrm{op}^{\\prime})</span>  accepts.</li>

    </ol>

    <p class="text-gray-300">Theorem 6.5. AS has bounded-depth knowledge soundness for depth  <span class="math">d_{s}</span> .</p>

    <p class="text-gray-300">Proof. Let  <span class="math">\\tilde{\\mathbf{P}}</span>  be an adversary and  <span class="math">\\mathcal{D}</span>  be an auxiliary input distribution for the accumulation scheme. Let  <span class="math">\\mathbf{E}</span>  be the BCS extractor. We first construct an auxiliary input distribution  <span class="math">\\mathcal{D}&#x27;</span>  and adversary  <span class="math">\\tilde{\\mathbf{P}}</span>  for BCS[IOP, VC].</p>

    <p class="text-gray-300"><span class="math">\\mathcal{D}&#x27;(1^{\\lambda})</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Sample  <span class="math">\\mathsf{ai}\\gets \\mathcal{D}(1^{\\lambda})</span></li>

      <li>Sample  <span class="math">t</span>  according to  <span class="math">\\mathrm{G}(1^{\\lambda})</span></li>

      <li>Sample  <span class="math">\\mathbb{F}</span>  according to  <span class="math">\\mathcal{G}(1^{\\lambda})</span></li>

      <li>Output  <span class="math">\\mathsf{ai}&#x27; = (\\mathsf{ai},\\mathbb{F},t)</span></li>

    </ol>

    <p class="text-gray-300"><span class="math">\\tilde{\\mathbf{P}}^{\\rho}(\\mathsf{vp},\\mathsf{ai}^{\\prime} = (\\mathsf{ai},\\mathbb{F},t))</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let  <span class="math">(\\mathbb{i},[qx_i]_{i = 1}^{m_1},[acc_i.x]_{i = 1}^{m_2},acc,pf = (q,[\\tilde{o}\\tilde{p}_i]_{i = 1}^m,\\tilde{o}\\tilde{p}))\\gets \\tilde{\\mathrm{P}}^\\rho (\\mathsf{pp}_{\\mathsf{AS}} = t,\\mathsf{pp} = (\\mathbb{F},\\mathsf{vp}),\\mathsf{ai}).</span></li>

      <li>Query  <span class="math">\\tau \\gets \\rho_{H}(\\mathbb{1})</span></li>

      <li>Let  <span class="math">\\bar{\\mathbf{x}}\\gets \\mathrm{CAST}^{\\rho}(\\tau ,[qx_i]_{i = 1}^{m_1},[acc_i.x]_{i = 1}^{m_2})</span></li>

      <li>Output  <span class="math">\\mathbb{i}</span> ,  <span class="math">\\bar{\\mathbf{x}}</span> , and  <span class="math">\\pi = (q, \\mathrm{acc}.\\mathbf{x}, (\\mathrm{op}_1, \\dots, \\mathrm{op}_m, \\mathrm{op}, \\mathrm{acc}.\\mathbf{w}))</span> .</li>

    </ol>

    <p class="text-gray-300">By Claim 6.4, the following is negligibly close to  <span class="math">1 - \\epsilon_{\\mathrm{rbr}}(\\mathbb{F},m,t,n)\\cdot Q</span></p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\mathbf {V} ^ {\\rho} (\\mathsf {v p}, \\mathbb {i}, \\bar {\\mathbf {x}}, \\pi) = 1 &amp;amp; \\mathsf {v p} \\leftarrow \\mathsf {V C . S e t u p} ^ {\\rho_ {H}} (1 ^ {\\lambda}) \\\\ \\Downarrow &amp;amp; \\mathsf {a i} ^ {\\prime} \\leftarrow \\mathcal {D} ^ {\\prime} (1 ^ {\\lambda}) \\\\ (\\mathbb {i}, [ e _ {i}, x _ {i}, \\mathbf {f} _ {i} ] _ {i = 1} ^ {m}) \\in \\mathcal {L} (\\mathbb {F}, s, m) &amp;amp; (\\mathbb {i}, \\bar {\\mathbf {x}} = [ e _ {i}, x _ {i}, \\mathsf {c m} _ {i} ] _ {i = 1} ^ {m}, \\pi ; r) \\leftarrow \\tilde {\\mathbf {P}} ^ {\\rho} (\\mathsf {v p}, \\mathsf {a i} ^ {\\prime}) \\\\ &amp;amp; [ \\mathsf {o p} _ {i} ] _ {i = 1} ^ {m} \\leftarrow \\mathbf {E} ^ {\\tilde {\\mathbf {P}}, \\rho} (\\mathsf {v p}, \\mathsf {a i} ^ {\\prime}, r) \\\\ &amp;amp; \\forall i \\in [ m ], \\mathbf {f} _ {i} \\leftarrow \\mathsf {V C . A n s w e r} ^ {\\rho_ {H}} (\\mathsf {v p}, \\mathsf {c m} _ {i}, \\mathsf {o p} _ {i}) \\end{array} \\right]</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Since the adversary is polynomial-size, we have  <span class="math">n = \\mathrm{poly}(\\lambda)</span>  and  <span class="math">Q = \\mathrm{poly}(\\lambda)</span> . Setting  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= \\Omega(\\lambda)<span class="math"> ,  </span>m = \\mathrm{poly}(\\lambda)<span class="math"> , and  </span>t = \\Omega(\\lambda)$ , we find that the probability is negligibly close to 1. Finally, we show that this</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">probabilistic experiment is essentially equivalent to that of the accumulation scheme's knowledge soundness guarantee. Notice that calling VC.Answer and testing language membership corresponds with running the relaxed decider; rewriting, we get</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} \\mathbf {V} ^ {\\rho} (\\mathsf {v p}, \\mathbb {i}, [ e _ {i}, x _ {i}, \\mathsf {c m} _ {i} ] _ {i = 1} ^ {m}, \\pi) = 1 &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\Downarrow &amp;amp; \\mathsf {v p} \\leftarrow \\mathsf {V C . S e t u p} ^ {\\rho_ {H}} (1 ^ {\\lambda}) \\\\ \\forall i \\in [ m ], \\mathsf {D} _ {s} ^ {\\rho} (\\mathsf {d k}, (e _ {i}, x _ {i}, \\mathsf {c m} _ {i}), \\mathsf {o p} _ {i}) = 1 &amp;amp; \\mathsf {a i} ^ {\\prime} \\leftarrow \\mathsf {D} ^ {\\prime} (1 ^ {\\lambda}) \\\\ &amp;amp; (\\mathbb {i}, [ e _ {i}, x _ {i}, \\mathsf {c m} _ {i} ] _ {i = 1} ^ {m}, \\pi ; r) \\leftarrow \\tilde {\\mathbf {P}} ^ {\\rho} (\\mathsf {v p}, \\mathsf {a i} ^ {\\prime}) \\\\ &amp;amp; [ \\mathsf {o p} _ {i} ] _ {i = 1} ^ {m} \\leftarrow \\mathbf {E} ^ {\\tilde {\\mathbf {P}}, \\rho} (\\mathsf {v p}, \\mathsf {a i} ^ {\\prime}, r) \\end{array} \\right]</span></div>

    <p class="text-gray-300">Since  <span class="math">\\tilde{\\mathbf{P}}</span>  does not use any additional randomness, the randomness output by  <span class="math">\\tilde{\\mathbf{P}}</span>  is the same as the randomness output by  <span class="math">\\tilde{\\mathbf{P}}</span> . Unwrapping the implementations of  <span class="math">\\tilde{\\mathbf{P}}</span> ,  <span class="math">\\mathcal{D}&#x27;</span> , and  <span class="math">\\mathbf{V}</span> , we get</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\text {V E R I F Y} ^ {\\rho} (\\mathsf {a v k}, [ (e _ {i}, x _ {i}, \\mathsf {c m} _ {i}) ] _ {i = 1} ^ {m}, \\mathsf {a c c . x}, \\mathsf {p f}) = 1 &amp;amp; \\mathsf {p p} _ {\\mathsf {A S}} \\leftarrow \\mathsf {G} (1 ^ {\\lambda}) \\\\ \\mathsf {D} _ {s - 1} ^ {\\rho} (\\mathsf {d k}, \\mathsf {a c c}) &amp;amp; \\mathsf {p p} \\leftarrow \\mathcal {G} (1 ^ {\\lambda}) \\\\ \\Downarrow &amp;amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (1 ^ {\\lambda}) \\\\ \\forall i \\in [ m ], \\mathsf {D} _ {s} ^ {\\rho} (\\mathsf {d k}, (e _ {i}, x _ {i}, \\mathsf {c m} _ {i}), \\mathsf {o p} _ {i}) = 1 &amp;amp; (\\mathbb {i}, [ \\mathsf {q x} _ {i} ] _ {i = 1} ^ {m _ {1}}, [ \\mathsf {a c c} _ {i}. \\mathsf {x} ] _ {i = 1} ^ {m _ {2}}, \\mathsf {a c c}, \\mathsf {p f}; r) \\leftarrow \\tilde {\\mathsf {P}} ^ {\\rho} (\\mathsf {p p} _ {\\mathsf {A S}}, \\mathsf {p p}, \\mathsf {a i}) \\\\ &amp;amp; \\tau \\leftarrow \\rho_ {H} (\\mathbb {i}) \\\\ &amp;amp; [ (e _ {i}, x _ {i}, \\mathsf {c m} _ {i}) ] _ {i = 1} ^ {m} \\leftarrow \\mathsf {C A S T} ^ {\\rho} (\\tau , [ \\mathsf {q x} _ {i} ] _ {i = 1} ^ {m _ {1}}, [ \\mathsf {a c c} _ {i}. \\mathsf {x} ] _ {i = 1} ^ {m _ {2}}) \\\\ &amp;amp; [ \\mathsf {o p} _ {i} ] _ {i = 1} ^ {m} \\leftarrow \\mathbf {E} ^ {\\tilde {\\mathbf {P}}, \\rho} (\\mathsf {v p}, (\\mathsf {a i}, \\mathbb {F}, t), r) \\\\ &amp;amp; (\\mathsf {a p k}, \\mathsf {a v k}, \\mathsf {d k}) \\leftarrow \\mathsf {I} ^ {\\rho} (\\mathsf {p p} _ {\\mathsf {A S}}, \\mathsf {p p}, \\mathbb {i}) \\end{array} \\right]</span></div>

    <p class="text-gray-300">Notice that if the verification helper accepts the cast inputs, then the accumulation verifier accepts the original inputs. Rewriting, we get</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\mathrm {V} ^ {\\rho} (\\mathsf {a v k}, [ \\mathsf {q x} ] _ {i = 1} ^ {m _ {1}}, [ \\mathsf {a c c} _ {i}. \\mathsf {x} ] _ {i = 1} ^ {m _ {2}}, \\mathsf {a c c}. \\mathsf {x}, \\mathsf {p f}) = 1 &amp;amp; \\mathrm {p p} _ {\\mathsf {A S}} \\leftarrow \\mathrm {G} (1 ^ {\\lambda}) \\\\ \\mathrm {D} _ {s - 1} ^ {\\rho} (\\mathsf {d k}, \\mathsf {a c c}) &amp;amp; \\mathsf {p p} \\leftarrow \\mathcal {G} (1 ^ {\\lambda}) \\\\ \\Downarrow &amp;amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (1 ^ {\\lambda}) \\\\ \\forall i \\in [ m ], \\mathrm {D} _ {s} ^ {\\rho} (\\mathsf {d k}, (e _ {i}, x _ {i}, \\mathsf {c m} _ {i}), \\mathsf {o p} _ {i}) = 1 &amp;amp; (\\mathbb {i}, [ \\mathsf {q x} _ {i} ] _ {i = 1} ^ {m _ {1}}, [ \\mathsf {a c c} _ {i}. \\mathsf {x} ] _ {i = 1} ^ {m _ {2}}, \\mathsf {a c c}, \\mathsf {p f}; r) \\leftarrow \\tilde {\\mathrm {P}} ^ {\\rho} (\\mathsf {p p} _ {\\mathsf {A S}}, \\mathsf {p p}, \\mathsf {a i}) \\\\ &amp;amp; \\tau \\leftarrow \\rho_ {H} (\\mathbb {i}) \\\\ &amp;amp; [ (e _ {i}, x _ {i}, \\mathsf {c m} _ {i}) ] _ {i = 1} ^ {m} \\leftarrow \\mathsf {C A S T} ^ {\\rho} (\\tau , [ \\mathsf {q x} _ {i}) ] _ {i = 1} ^ {m _ {1}}, [ \\mathsf {a c c} _ {i}. \\mathsf {x} ] _ {i = 1} ^ {m _ {2}}) \\\\ &amp;amp; [ \\mathsf {o p} _ {i} ] _ {i = 1} ^ {m} \\leftarrow \\mathbf {E} ^ {\\tilde {\\mathbf {P}}, \\rho} (\\mathsf {v p}, (\\mathsf {a i}, \\mathbb {F}, t), r) \\\\ &amp;amp; (\\mathsf {a p k}, \\mathsf {a v k}, \\mathsf {d k}) \\leftarrow \\mathrm {I} ^ {\\rho} (\\mathsf {p p} _ {\\mathsf {A S}}, \\mathsf {p p} _ {\\Phi}, \\mathbb {i}) \\end{array} \\right]</span></div>

    <p class="text-gray-300">Similarly, if the relaxed decider accepts the cast inputs, then the relaxed verifier accepts the original inputs. Hence, the following probability is negligibly close to 1:</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} &amp;amp; \\rho \\leftarrow \\mathcal {U} (\\lambda) \\\\ \\mathrm {V} ^ {\\rho} (\\mathsf {a v k}, [ \\mathsf {q x} ] _ {i = 1} ^ {m _ {1}}, [ \\mathsf {a c c} _ {i}. \\mathsf {x} ] _ {i = 1} ^ {m _ {2}}, \\mathsf {a c c}. \\mathsf {x}, \\mathsf {p f}) = 1 &amp;amp; \\mathsf {p p} _ {\\mathsf {A S}} \\leftarrow \\mathrm {G} (1 ^ {\\lambda}) \\\\ \\mathrm {D} _ {s - 1} ^ {\\rho} (\\mathsf {d k}, \\mathsf {a c c}) &amp;amp; \\mathsf {p p} \\leftarrow \\mathcal {G} (1 ^ {\\lambda}) \\\\ \\Downarrow &amp;amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (1 ^ {\\lambda}) \\\\ \\forall i \\in [ m _ {1} ], \\hat {\\mathrm {V}} ^ {\\rho} (\\mathsf {p p}, \\mathbb {i}, \\mathsf {q x} _ {i}, \\mathsf {q w} _ {i}) = 1 &amp;amp; (\\mathbb {i}, [ \\mathsf {q x} _ {i} ] _ {i = 1} ^ {m _ {1}}, [ \\mathsf {a c c} _ {i}. \\mathsf {x} ] _ {i = 1} ^ {m _ {2}}, \\mathsf {a c c}, \\mathsf {p f}; r) \\leftarrow \\tilde {\\mathrm {P}} ^ {\\rho} (\\mathsf {p p} _ {\\mathsf {A S}}, \\mathsf {p p}, \\mathsf {a i}) \\\\ &amp;amp; [ \\mathsf {o p} _ {i} ] _ {i = 1} ^ {m} \\leftarrow \\mathbf {E} ^ {\\tilde {\\mathbf {P}}, \\rho} (\\mathsf {v p}, (\\mathsf {a i}, \\mathbb {F}, t), r) \\\\ &amp;amp; [ \\mathsf {q w} _ {1}, \\ldots , \\mathsf {q w} _ {m _ {1}}, \\mathsf {a c c} _ {1}. \\mathbb {w}, \\ldots , \\mathsf {a c c} _ {m _ {2}}. \\mathbb {w} ] = [ \\mathsf {o p} _ {i} ] _ {i = 1} ^ {m} \\\\ &amp;amp; (\\mathsf {a p k}, \\mathsf {a v k}, \\mathsf {d k}) \\leftarrow \\mathrm {I} ^ {\\rho} (\\mathsf {p p} _ {\\mathsf {A S}}, \\mathsf {p p}, \\mathbb {i}) \\end{array} \\right]</span></div>

    <p class="text-gray-300">We conclude that the following accumulation extractor satisfies knowledge soundness.</p>

    <p class="text-gray-300"><span class="math">\\mathrm{E}^{\\tilde{\\mathrm{P}},\\rho}(\\mathsf{pp} = t,\\mathsf{pp}_{\\Phi} = (\\mathbb{F},\\mathsf{vp}),\\mathsf{ai},r)</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let  <span class="math">[\\tilde{\\mathsf{op}}_i]_{i=1}^m \\gets \\mathbf{E}^{\\tilde{\\mathbf{P}},\\rho}(\\mathsf{vp}, (\\mathsf{ai}, \\mathbb{F}, t), r)</span> , where  <span class="math">\\mathbf{E}</span>  implicitly receives  <span class="math">(\\mathbb{F}, s, m, t)</span>  as input.</li>

      <li>Parse  <span class="math">[\\mathsf{qw}_1,\\dots ,\\mathsf{qw}_{m_1},\\mathsf{acc}_1.\\mathbb{w},\\dots ,\\mathsf{acc}_{m_2}.\\mathbb{w}] = [\\tilde{\\mathsf{op}}_i]_i^m</span></li>

      <li>Output  <span class="math">[\\mathsf{qw}_i]_{i=1}^{m_1}</span>  and  <span class="math">[\\mathsf{acc}_i.\\mathsf{w}]_{i=1}^{m_2}</span> .</li>

    </ol>

    <p class="text-gray-300">6.4 Using arbitrary linear codes</p>

    <p class="text-gray-300">At first glance, our accumulation scheme does not use any special properties of the Reed–Solomon code. Because other codes might have desirable properties, e.g. linear-time encoding, this motivates the following question: can we instantiate it with an arbitrary linear code, so long as it has good distance? Recall that the accumulator’s vectors are a random linear combination of the input vectors. In particular, the coefficients are Lagrange evaluations of a random field element; this is necessary for compressing the polynomial evaluation claims. Unfortunately, existing proximity gaps for arbitrary linear codes <em>[x21, x1, x10]</em> do not support this specific distribution of coefficients.</p>

    <h4 id="sec-44" class="text-lg font-semibold mt-6">Separating the proximity claim.</h4>

    <p class="text-gray-300">In some sense, our construction accumulates two distinct claims for the same vector: a polynomial evaluation claim, and a proximity claim. To overcome the foregoing issue, we modify our accumulation scheme to separate these claims. Specifically, each accumulator now holds <em>two</em> codewords: the first is a linear combination using Lagrange coefficients, and the second is a linear combination using proximity gap coefficients. Accordingly, the accumulation verifier uses the first codeword to compress evaluation claims, and the second codeword to maintain proximity. This will be roughly twice as expensive as before.</p>

    <h6 id="sec-45" class="text-base font-medium mt-4">Definition 6.6 (Proximity Gaps for Linear Codes).</h6>

    <p class="text-gray-300">Let <span class="math">C</span> be a linear code with relative distance <span class="math">d</span> and blocklength <span class="math">n</span>. We will treat elements of <span class="math">C</span> as functions <span class="math">v:[n]\\to\\mathbb{F}</span>. Let <span class="math">(r_{1},\\ldots,r_{\\ell})\\leftarrow\\mathsf{Coeffs}(\\mathbf{\\Gamma})</span> be a function that takes in randomness <span class="math">\\mathbf{\\Gamma}</span>. We say that <span class="math">C</span> has a proximity gap with respect to distribution <span class="math">\\mathsf{Coeffs}</span>, error <span class="math">0\\leq\\mathsf{err}(\\ell)\\leq 1</span>, slack <span class="math">\\gamma</span>, relative error bound <span class="math">\\mathsf{e_{bnd}}&lt;d/2</span>, if the following holds:</p>

    <p class="text-gray-300">For any <span class="math">\\delta\\leq\\mathsf{e_{bnd}}</span> and arbitrary functions <span class="math">u_{1},\\ldots,u_{\\ell}\\in\\mathbb{F}^{n}:[n]\\to\\mathbb{F}</span>, if</p>

    <p class="text-gray-300"><span class="math">\\Pr_{\\mathbf{\\Gamma}}\\Big{[}\\Delta\\left(\\sum_{i=1}^{\\ell}r_{i}\\cdot u_{i},C\\right)\\leq\\delta\\,:\\,(r_{1},\\ldots,r_{\\ell})\\leftarrow\\mathsf{Coeffs}(\\mathbf{\\Gamma})\\Big{]}&gt;\\mathsf{err}(\\ell)</span></p>

    <p class="text-gray-300">Then, for all <span class="math">(r_{1},\\ldots,r_{\\ell})</span> in the support of the distribution <span class="math">\\mathsf{Coeffs}(\\mathbf{\\Gamma})</span>, we must have</p>

    <p class="text-gray-300"><span class="math">\\Delta\\left(\\sum_{i=1}^{\\ell}r_{i}\\cdot u_{i},C\\right)\\leq\\delta.</span></p>

    <p class="text-gray-300">and furthermore there exists <span class="math">v_{1},\\ldots,v_{\\ell}\\in C</span> such that for all <span class="math">(r_{1},\\ldots,r_{\\ell})</span> in the support,</p>

    <p class="text-gray-300"><span class="math">\\Delta\\left(\\sum_{i=1}^{\\ell}r_{i}\\cdot u_{i},\\sum_{i=1}^{\\ell}r_{i}\\cdot v_{i}\\right)\\leq\\gamma\\delta,</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">and in fact $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\{x\\in[n]:(u_{1}(x),\\ldots,u_{\\ell}(x))\\neq(v_{1}(x),\\ldots,v_{\\ell}(x))\\}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq\\gamma\\delta n.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The following lemma is immediately implied by Definition 6.6.</p>

    <h6 id="sec-46" class="text-base font-medium mt-4">Lemma 6.7.</h6>

    <p class="text-gray-300">Let <span class="math">C</span> be a linear code with relative distance <span class="math">d</span> and blocklength <span class="math">n</span> with a corresponding proximity gap (Definition 6.6) with respect to distribution <span class="math">\\mathsf{Coeffs}</span>, error <span class="math">0\\leq\\mathsf{err}(\\ell)\\leq 1</span>, slack <span class="math">\\gamma</span>, relative error bound <span class="math">\\mathsf{e_{bnd}}&lt;d/2</span>, and suppose <span class="math">\\delta\\leq\\mathsf{e_{bnd}}</span>. Consider arbitrary vectors <span class="math">f_{1},\\ldots,f_{\\ell}\\in\\mathbb{F}^{n}</span>. If</p>

    <p class="text-gray-300"><span class="math">\\Pr_{\\mathbf{\\Gamma}}\\Big{[}\\Delta\\left(\\sum_{i=1}^{\\ell}r_{i}\\cdot f_{i},C\\right)\\leq\\delta\\,:\\,(r_{1},\\ldots,r_{\\ell})\\leftarrow\\mathsf{Coeffs}(\\mathbf{\\Gamma})\\Big{]}&gt;\\mathsf{err}(\\ell)</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">then there exists a subdomain <span class="math">L^{\\prime}\\subseteq[n]</span> and codewords <span class="math">g_{1},\\ldots,g_{\\ell}\\in C</span> such that the following holds. First, $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">/[n]\\geq 1-\\gamma\\delta<span class="math">. Second, for all </span>i<span class="math">, </span>f_{i}<span class="math"> and </span>g_{i}<span class="math"> agree on </span>L^{\\prime}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">######</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Arbitrary Slack. For clarity, the following construction considers only slack factor  <span class="math">\\gamma = 1</span> , which applies to the proximity gaps in [AHIV17; BCIKS23]. With minor modifications, the construction can support arbitrary slack factors, which extends support to works such as [RVW13; DP24]. In particular, instead of setting  <span class="math">\\delta \\leq \\mathsf{e}_{\\mathsf{bnd}} / d_s</span> , we would instead choose  <span class="math">\\delta \\leq \\mathsf{e}_{\\mathsf{bnd}} / (\\sum_{i=0}^{d_s-1} \\gamma^i)</span> . In the construction and soundness analysis, replace every instance of  <span class="math">s\\delta</span>  and  <span class="math">(s-1)\\delta</span>  with  <span class="math">\\sum_{i=0}^{s-1} \\gamma^i</span>  and  <span class="math">\\sum_{i=0}^{s-2} \\gamma^i</span> , respectively. The round-by-round soundness will become  $\\epsilon_{\\mathsf{rbr}}(\\mathbb{F}, m, t) = \\max(\\mathsf{err}(2m), d(m-1)/</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, (1 - \\gamma^{s-1}\\delta)^t)$  instead.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Construction. We use linear codes with efficient decoding up to  <span class="math">\\mathsf{e}_{\\mathsf{bnd}} = O(1)</span> , the error bound of the proximity gap. Fix  <span class="math">\\delta \\leq \\mathsf{e}_{\\mathsf{bnd}} / d_s</span> ; this guarantees that  <span class="math">d_s\\delta \\leq \\mathsf{e}_{\\mathsf{bnd}}</span>  which is smaller than the unique decoding radius. The modified construction is shown below; all changes are highlighted in blue. We omit the description of unchanged algorithms from Figure 9.</p>

    <p class="text-gray-300">CASTINPUT <span class="math">^{\\rho}</span> <span class="math">(\\tau, qx = (\\Xi, \\bar{c}\\bar{m}))</span> :</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For each  <span class="math">j \\in [\\mu]</span> , query  <span class="math">r^{(j)} \\gets \\rho_{\\mathsf{ARG}}(\\tau, \\Xi, \\mathsf{cm}^{(1)}, \\ldots, \\mathsf{cm}^{(j)})</span> .</li>

      <li>Collect  <span class="math">\\Xi</span>  and  <span class="math">\\mathbf{r}</span>  into a vector  <span class="math">x</span> .</li>

      <li>Output  <span class="math">\\mathsf{acc}.\\Xi = (0,x,\\bar{\\mathsf{cm}},\\bar{\\mathsf{cm}}^{\\prime})</span>  , where  <span class="math">\\bar{\\mathsf{cm}}^{\\prime}</span>  are commitments to zero vectors.</li>

    </ol>

    <p class="text-gray-300">PROVE <span class="math">^{\\rho}</span>  (apk,  <span class="math">[e_i, x_i, \\bar{\\mathsf{cm}}_i, \\mathsf{a}\\bar{\\mathsf{ux}}_i, \\bar{\\mathsf{cm}}_i&#x27;, \\mathsf{a}\\bar{\\mathsf{ux}}_i&#x27;]_{i=1}^m</span> ):</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For each  <span class="math">i\\in [m]</span>  , let  <span class="math">\\mathbf{f}_i\\gets \\mathsf{VC.Answer}^{\\rho_H}(\\mathsf{vp},\\mathsf{cm}_i,\\mathsf{a}\\bar{\\mathsf{ux}}_i)</span>  , and  <span class="math">\\mathbf{f}_i^\\prime \\gets \\mathsf{VC.Answer}^{\\rho_H}(\\mathsf{vp},\\mathsf{cm}_i^\\prime ,\\mathsf{a}\\bar{\\mathsf{ux}}_i^\\prime)</span></li>

      <li>Compute the univariate polynomial  <span class="math">q \\in \\mathbb{F}[X]</span>  of degree at most  <span class="math">d(m - 1) - m</span>  such that</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">p \\left(\\sum_ {i = 1} ^ {m} L _ {i, H} (X) \\cdot \\left(x _ {i}, \\hat {\\mathbf {f}} _ {i}\\right)\\right) = v _ {H} (X) \\cdot q (X) + \\sum_ {i = 1} ^ {n} L _ {i, H} (X) \\cdot e _ {i}.</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Query  <span class="math">\\alpha, \\Gamma \\gets \\rho_{\\mathsf{AS}}(\\tau, [\\mathsf{acc}_i.\\Xi]_{i=1}^m, q)</span> , where  <span class="math">\\alpha \\in \\mathbb{F}</span>  and  <span class="math">\\Gamma</span>  are sampled uniformly.</li>

      <li>Compute  <span class="math">e = v(\\alpha) \\cdot q(\\alpha) + \\sum_{i} L_{i}(\\alpha) \\cdot e_{i}</span> .</li>

      <li>Compute  <span class="math">(x,\\hat{\\mathbf{f}}) = \\sum_{i}L_{i}(\\alpha)\\cdot (x_{i},\\hat{\\mathbf{f}}_{i})</span></li>

      <li>Let  <span class="math">(r_1, \\ldots, r_m, r_1&#x27;, \\ldots, r_m&#x27;) \\gets \\mathsf{Coeffs}(\\Gamma)</span> . Compute  <span class="math">\\mathbf{f}&#x27; = \\sum_{i=1}^{m} r_i \\cdot \\mathbf{f}_i + r_i&#x27; \\cdot \\mathbf{f}_i&#x27;</span> .</li>

      <li>Let  <span class="math">(\\bar{\\mathsf{cm}},\\mathsf{a}\\bar{\\mathsf{ux}})\\gets \\mathsf{VC.}\\mathsf{Commit}^{\\rho_H}(\\mathsf{vp},\\mathbf{f})</span>  , and  <span class="math">(\\bar{\\mathsf{cm}}^{\\prime},\\mathsf{a}\\bar{\\mathsf{ux}}^{\\prime})\\gets \\mathsf{VC.}\\mathsf{Commit}^{\\rho_H}(\\mathsf{vp},\\mathbf{f}^{\\prime})</span></li>

      <li>Set  <span class="math">\\mathsf{acc}.\\Xi = (e,x,\\bar{\\mathsf{cm}},\\bar{\\mathsf{cm}}^{\\prime})</span>  and  <span class="math">\\mathsf{acc.w} = (\\mathsf{a}\\bar{\\mathsf{ux}},\\mathsf{a}\\bar{\\mathsf{ux}}^{\\prime})</span></li>

      <li>Query  <span class="math">\\mathbf{Q} \\gets \\rho_{\\mathsf{AS}}(\\tau, [\\mathsf{acc}_i.\\Xi]_{i=1}^m, q, \\mathsf{acc}.\\Xi)</span> , where  <span class="math">\\mathcal{Q}^{(j)}</span>  is a uniformly sampled  <span class="math">t</span> -sized subset of  <span class="math">[n]</span> .</li>

      <li>For each  <span class="math">i\\in [m]</span>  , let  <span class="math">\\bar{\\mathsf{op}}_i\\gets \\mathsf{VC.}\\mathsf{Open}^{\\rho_H}(\\mathsf{vp},\\mathsf{a}\\bar{\\mathsf{ux}}_i,\\mathbf{Q})</span>  , and  <span class="math">\\bar{\\mathsf{op}}_i^\\prime \\gets \\mathsf{VC.}\\mathsf{Open}^{\\rho_H}(\\mathsf{vp},\\mathsf{a}\\bar{\\mathsf{ux}}_i^\\prime ,\\mathbf{Q})</span></li>

      <li>Let  <span class="math">\\bar{\\mathsf{op}}\\gets \\mathsf{VC.}\\mathsf{Open}^{\\rho_H}(\\mathsf{vp},\\mathsf{a}\\bar{\\mathsf{ux}},\\mathbf{Q})</span>  , and  <span class="math">\\bar{\\mathsf{op}}^{\\prime}\\gets \\mathsf{VC.}\\mathsf{Open}^{\\rho_H}(\\mathsf{vp},\\mathsf{a}\\bar{\\mathsf{ux}}^{\\prime},\\mathbf{Q})</span></li>

      <li>Output acc and  <span class="math">\\mathsf{pf} = (q, [\\bar{\\mathsf{op}}_i, \\bar{\\mathsf{op}}_i&#x27;]_{i=1}^m, \\bar{\\mathsf{op}}, \\bar{\\mathsf{op}}&#x27;)</span> .</li>

    </ol>

    <p class="text-gray-300">VERIFY <span class="math">^{\\rho}</span>  (avk,  <span class="math">[e_i, x_i, \\bar{\\mathsf{cm}}_i, \\bar{\\mathsf{cm}}_i&#x27;]_{i=1}^m</span> ,  <span class="math">(e, x, \\bar{\\mathsf{cm}}, \\bar{\\mathsf{cm}}&#x27;)</span> ,  <span class="math">(q, [\\bar{\\mathsf{op}}_i, \\bar{\\mathsf{op}}_i&#x27;]_{i=1}^m, \\bar{\\mathsf{op}}, \\bar{\\mathsf{op}}&#x27;))</span> :</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Query  <span class="math">\\alpha, \\Gamma \\gets \\rho_{\\mathsf{AS}}(\\tau, [\\mathsf{acc}_i.\\Xi]_{i=1}^m, q)</span> .</li>

      <li>Query  <span class="math">\\mathbf{Q} \\gets \\rho_{\\mathsf{AS}}(\\tau, [\\mathsf{acc}_i.\\Xi]_{i=1}^m, q, \\mathsf{acc}.\\Xi)</span> .</li>

      <li>For each  <span class="math">i\\in [m]</span>  , let  <span class="math">\\mathbf{v}_i = \\mathsf{VC.Answer}^{\\rho_H}(\\mathsf{vp},\\bar{\\mathsf{cm}}_i,\\bar{\\mathsf{op}}_i)</span>  . If  <span class="math">\\mathbf{v}_i[\\mathbf{Q}]</span>  contains  <span class="math">\\perp</span>  , reject.</li>

      <li>Let  <span class="math">\\mathbf{v} = \\mathsf{VC.Answer}^{\\rho_H}(\\mathsf{vp},\\bar{\\mathsf{cm}},\\bar{\\mathsf{op}},\\mathbf{Q})</span>  . If  <span class="math">\\mathbf{v}[\\mathbf{Q}]</span>  contains  <span class="math">\\perp</span>  , reject.</li>

      <li>For each  <span class="math">i\\in [m]</span>  , let  <span class="math">\\mathbf{v}_i^{\\prime} = \\mathsf{VC.Answer}^{\\rho_H}(\\mathsf{vp},\\bar{\\mathsf{cm}}_i^{\\prime},\\bar{\\mathsf{op}}_i^{\\prime})</span>  . If  <span class="math">\\mathbf{v}_i^\\prime [\\mathbf{Q}]</span>  contains  <span class="math">\\perp</span>  , reject.</li>

      <li>Let  <span class="math">\\mathbf{v}&#x27; = \\mathsf{VC.Answer}^{\\rho_H}(\\mathsf{vp},\\bar{\\mathsf{cm}}&#x27;,\\bar{\\mathsf{op}}&#x27;,\\mathbf{Q})</span>  . If  <span class="math">\\mathbf{v}&#x27;[\\mathbf{Q}]</span>  contains  <span class="math">\\perp</span>  , reject.</li>

      <li>Verify that  <span class="math">e = v_{H}(\\alpha) \\cdot q(\\alpha) + \\sum_{i=1}^{n} L_{i,H}(\\alpha) \\cdot e^{(i)}</span> .</li>

      <li>Verify that  <span class="math">(x,\\mathbf{v}) = \\sum_{i = 1}^{m}L_{i,H}(\\alpha)\\cdot (x_{i},\\mathbf{v}_{i})</span></li>

      <li>Let  <span class="math">(r_1, \\ldots, r_m, r_1&#x27;, \\ldots, r_m&#x27;) \\gets \\mathsf{Coeffs}(\\Gamma)</span> . Verify that  <span class="math">\\mathbf{v}&#x27; = \\sum_{i=1}^{m} r_i \\cdot v_i + r_i&#x27; \\cdot v_i&#x27;</span> .</li>

    </ol>

    <p class="text-gray-300"><span class="math">\\mathrm{D}_{s}^{\\rho}(\\mathrm{d}k,\\mathrm{acc}.\\mathtt{x}=(e,x,\\mathrm{c}\\overline{\\mathsf{m}},\\mathrm{c}\\overline{\\mathsf{m}}^{\\prime}),\\mathrm{acc}.\\mathtt{w}=(\\mathrm{a}\\overline{\\mathsf{u}}\\mathsf{x},\\mathrm{a}\\overline{\\mathsf{u}}\\mathsf{x}^{\\prime}))</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let <span class="math">\\mathbf{f}\\leftarrow\\mathsf{VC.Answer}^{\\rho_{H}}(\\mathsf{vp},\\mathsf{c}\\overline{\\mathsf{m}},\\mathsf{a}\\overline{\\mathsf{u}}\\mathsf{x})</span>.</li>

      <li>Let <span class="math">\\mathbf{f}^{\\prime}\\leftarrow\\mathsf{VC.Answer}^{\\rho_{H}}(\\mathsf{vp},\\mathsf{c}\\overline{\\mathsf{m}}^{\\prime},\\mathsf{a}\\overline{\\mathsf{u}}\\mathsf{x}^{\\prime})</span>.</li>

      <li>Find <span class="math">\\mathbf{g},\\mathbf{g}^{\\prime}\\in\\mathbf{C}</span> such that <span class="math">\\Delta(\\mathbf{f},\\mathbf{g}),\\Delta(\\mathbf{f}^{\\prime},\\mathbf{g}^{\\prime})\\leq(s-1)\\delta</span> by decoding <span class="math">\\mathbf{f}</span> and <span class="math">\\mathbf{f}^{\\prime}</span>. If no such codewords exists, reject.</li>

      <li>Accept if <span class="math">p(x,\\hat{\\mathbf{g}})=e</span>.</li>

    </ol>

    <h4 id="sec-47" class="text-lg font-semibold mt-6">Completeness.</h4>

    <p class="text-gray-300">Follows almost immediately from the completeness of the prior construction in Section 6.2.</p>

    <h3 id="sec-48" class="text-xl font-semibold mt-8">6.5 Soundness analysis</h3>

    <p class="text-gray-300">Similarly to Section 6.3, this accumulation scheme can be viewed as a compiled interactive oracle proof, where the prover corresponds with Prove and the verifier corresponds with Verify plus <span class="math">\\mathrm{D}_{s-1}</span>. The relation corresponds with <span class="math">\\mathrm{D}_{s}</span>; in particular, for field <span class="math">\\mathbb{F}</span> and depth parameter <span class="math">s\\in[d_{s}]</span>, define the indexed language</p>

    <p class="text-gray-300"><span class="math">\\mathscr{L}(\\mathbb{F},s)=\\{(\\dot{\\mathtt{i}},(e,x,\\mathbf{f},\\mathbf{f}^{\\prime})):\\exists\\mathbf{g},\\mathbf{g}^{\\prime}\\in\\mathbf{C},\\ \\Delta(\\mathbf{f},\\mathbf{g}),\\Delta(\\mathbf{f}^{\\prime},\\mathbf{g}^{\\prime})\\leq s\\delta,\\ p(x,\\hat{\\mathbf{g}})=e\\}.</span></p>

    <p class="text-gray-300">Here, <span class="math">\\dot{\\mathtt{i}}</span> is an index of <span class="math">\\mathscr{R}(\\mathbb{F})</span> from which <span class="math">p</span> and <span class="math">\\mathbf{C}</span> are implicitly derived. We construct a public-coin interactive oracle proof <span class="math">\\mathsf{IOP}</span> for the multi-instance language</p>

    <p class="text-gray-300"><span class="math">\\mathscr{L}(\\mathbb{F},s,m)=\\{(\\dot{\\mathtt{i}},[e_{i},x_{i},\\mathbf{f}_{i},\\mathbf{f}^{\\prime}_{i}]_{i=1}^{m}):\\forall i\\in[m],(\\dot{\\mathtt{i}},(e_{i},x_{i},\\mathbf{f}_{i},\\mathbf{f}^{\\prime}_{i}))\\in\\mathscr{L}(\\mathbb{F},s)\\}.</span></p>

    <p class="text-gray-300">Note that all algorithms in <span class="math">\\mathsf{IOP}</span> implicitly take as input the following protocol parameters: field <span class="math">\\mathbb{F}</span>, depth parameter <span class="math">s</span>, arity <span class="math">m</span>, and spot check parameter <span class="math">t</span>. Since we are only interested in proving soundness, we omit the prover’s description (it essentially matches the accumulation prover). The protocol is as follows.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The prover sends <span class="math">q\\in\\mathbb{F}[X]</span>, a polynomial of degree at most <span class="math">d(m-1)-m</span>.</li>

      <li>The verifier uniformly samples and sends a field element <span class="math">\\alpha\\in\\mathbb{F}</span> and <span class="math">\\mathbf{\\Gamma}</span>.</li>

      <li>The prover sends <span class="math">(e,x,\\mathbf{f},\\mathbf{f}^{\\prime})</span>.</li>

      <li>For each <span class="math">j\\in[\\mu]</span>, the verifier uniformly samples and sends a query set <span class="math">\\mathcal{Q}^{(j)}\\subset L^{(j)}</span> of size <span class="math">t</span>.</li>

    </ol>

    <p class="text-gray-300">The verifier then performs two sets of checks. The first set corresponds with the accumulation verifier:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Verify that <span class="math">e=v(\\alpha)\\cdot q(\\alpha)+\\sum_{i}L_{i}(\\alpha)\\cdot e_{i}</span>.</li>

      <li>Verify that <span class="math">x=\\sum_{i}L_{i}(\\alpha)\\cdot x_{i}</span>.</li>

      <li>Verify that <span class="math">\\mathbf{f}[\\mathbf{Q}]=\\sum_{i}L_{i}(\\alpha)\\cdot\\mathbf{f}_{i}[\\mathbf{Q}]</span>.</li>

      <li>Let <span class="math">(r_{1},\\ldots,r_{m},r^{\\prime}_{1},\\ldots,r^{\\prime}_{m})\\leftarrow\\mathsf{Coeffs}(\\mathbf{\\Gamma})</span>. Verify that <span class="math">\\mathbf{f}^{\\prime}=\\sum_{i=1}^{m}r_{i}\\cdot\\mathbf{f}_{i}+r^{\\prime}_{i}\\cdot\\mathbf{f}^{\\prime}_{i}</span>.</li>

    </ul>

    <p class="text-gray-300">The second set corresponds with the decider:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Find <span class="math">\\mathbf{g},\\mathbf{g}^{\\prime}\\in\\mathbf{C}</span> by decoding <span class="math">(\\mathbf{f},\\mathbf{f}^{\\prime})</span>. If no such codewords exist, reject.</li>

      <li>Verify that <span class="math">\\Delta(\\mathbf{f},\\mathbf{g}),\\Delta(\\mathbf{f}^{\\prime},\\mathbf{g}^{\\prime})\\leq(s-1)\\delta</span>.</li>

      <li>Verify that <span class="math">p(x,\\hat{\\mathbf{g}})=e</span>.</li>

    </ul>

    <h6 id="sec-49" class="text-base font-medium mt-4">Theorem 6.8.</h6>

    <p class="text-gray-300"><span class="math">\\mathsf{IOP}</span> has round-by-round soundness error</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\epsilon_{\\mathsf{rbr}}(\\mathbb{F},m,t)=\\max\\left(\\mathsf{err}(2m),\\ \\frac{d(m-1)}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">},\\ (1-\\delta)^{t}\\right)$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-50" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">We define a doomed set <span class="math">\\mathcal{D}</span> as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">([e_i, x_i, \\mathbf{f}_i, \\mathbf{f}_i&#x27;]_{i=1}^m, \\emptyset) \\in \\mathcal{D}</span>  if the instance is not in the language, i.e. there exists  <span class="math">i \\in [m]</span>  such that for all  <span class="math">\\mathbf{g}, \\mathbf{g}&#x27; \\in \\mathbf{C}</span> ,  <span class="math">\\Delta(\\mathbf{f}_i, \\mathbf{g}) &amp;gt; s\\delta</span>  or  <span class="math">\\Delta(\\mathbf{f}_i&#x27;, \\mathbf{g}&#x27;) &amp;gt; s\\delta</span>  or  <span class="math">p(x_i, \\hat{\\mathbf{g}}) \\neq e_i</span> . Here,  <span class="math">\\emptyset</span>  denotes the empty transcript.</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-  $([e_i, x_i, \\mathbf{f}_i, \\mathbf{f}_i']_{i=1}^m, q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\alpha, \\Gamma) \\in \\mathcal{D}<span class="math">  if for all  </span>\\mathbf{g}, \\mathbf{g}' \\in \\mathbf{C}<span class="math"> , for  </span>(r_1, \\ldots, r_m, r_1', \\ldots, r_m') \\gets \\text{Coeffs}(\\Gamma)$ ,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\Delta \\left(\\sum_ {i = 1} ^ {m} L _ {i, H} (\\alpha) \\cdot \\mathbf {f} _ {i}, \\mathbf {g}\\right) &amp;gt; s \\delta \\quad \\text {o r} \\quad \\Delta \\left(\\sum_ {i = 1} ^ {m} r _ {i} \\cdot \\mathbf {f} _ {i} + r _ {i} ^ {\\prime} \\cdot \\mathbf {f} _ {i} ^ {\\prime}, \\mathbf {g} ^ {\\prime}\\right) &amp;gt; s \\delta \\\\ \\text {o r} \\quad p (x, \\hat {\\mathbf {g}}) \\neq v _ {H} (\\alpha) \\cdot q (\\alpha) + \\sum_ {i = 1} ^ {m} L _ {i, H} (\\alpha) \\cdot e _ {i}. \\\\ \\end{array}</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-  $([e_i, x_i, \\mathbf{f}_i, \\mathbf{f}_i']_{i=1}^m, q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\alpha, \\Gamma</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(e, x, \\mathbf{f}, \\mathbf{f}')</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf{Q}) \\in \\mathcal{D}$  if the verifier rejects the transcript.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The statement follows from Claims 6.9 and 6.10.</p>

    <p class="text-gray-300">Claim 6.9. Suppose  <span class="math">([e_i, x_i, \\mathbf{f}_i, \\mathbf{f}_i]_{i=1}^m, \\emptyset)</span>  is in the doomed set. Then</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Pr_ {\\alpha , \\mathbf {f}} [ ([ e _ {i}, x _ {i}, \\mathbf {f} _ {i}, \\mathbf {f} _ {i} ] _ {i = 1} ^ {m}, q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\alpha , \\Gamma) \\notin \\mathcal {D} ] \\leq \\max  \\left(\\operatorname {e r r} (2 m), \\frac {d (m - 1)}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\right).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Proof. Suppose not. Let  $\\epsilon_{1} = \\mathrm{err}(2m),\\epsilon_{2} = d(m - 1) /</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ , and define the events</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block">E _ {1} (\\mathbf {g}, \\alpha): \\Delta \\left(\\sum_ {i = 1} ^ {m} L _ {i, H} (\\alpha) \\cdot \\mathbf {f} _ {i}, \\mathbf {g}\\right) \\leq s \\delta ,</span></div>

    <div class="my-4 text-center"><span class="math-block">E _ {1} ^ {\\prime} (\\mathbf {g} ^ {\\prime}, \\boldsymbol {\\Gamma}): \\Delta \\left(\\sum_ {i = 1} ^ {m} r _ {i} \\cdot \\mathbf {f} _ {i} + r _ {i} ^ {\\prime} \\cdot \\mathbf {f} _ {i} ^ {\\prime}, \\mathbf {g} ^ {\\prime}\\right) \\leq s \\delta ,</span></div>

    <div class="my-4 text-center"><span class="math-block">E _ {2} (\\mathbf {g}, \\alpha): p (x, \\hat {\\mathbf {g}}) = v _ {H} (\\alpha) \\cdot q (\\alpha) + \\sum_ {i = 1} ^ {m} L _ {i, H} (\\alpha) \\cdot e _ {i}.</span></div>

    <p class="text-gray-300">Our supposition is that  <span class="math">\\operatorname{Pr}_{\\alpha, \\Gamma}[\\exists \\mathbf{g}, \\mathbf{g}&#x27; \\in \\mathbf{C}, E_1(\\mathbf{g}, \\alpha) \\wedge E_1&#x27;(\\mathbf{g}&#x27;, \\Gamma) \\wedge E_2(\\mathbf{g}, \\alpha)] &amp;gt; \\max(\\epsilon_1, \\epsilon_2)</span> . It follows that</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr_ {\\Gamma} \\left[ \\begin{array}{c} \\exists \\mathbf {g} ^ {\\prime} \\in \\mathbf {C}, \\\\ E _ {1} ^ {\\prime} (\\mathbf {g} ^ {\\prime}, \\boldsymbol {\\Gamma}) \\end{array} \\right] = \\Pr_ {\\Gamma} \\left[ \\forall j \\in [ \\mu ], \\Delta \\left(\\sum_ {i = 1} ^ {m} r _ {i} \\mathbf {f} _ {i} ^ {(j)} + r _ {i} ^ {\\prime} \\mathbf {f} _ {i} ^ {\\prime (j)}, C ^ {(j)}\\right) \\leq s \\delta \\right] &amp;gt; \\epsilon_ {1}.</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">For each  <span class="math">j</span> , by Lemma 6.7, there exist codewords  <span class="math">g_1^{(j)}, \\ldots, g_m^{(j)}, g&#x27;_1^{(j)}, \\ldots, g&#x27;_m^{(j)} \\in C^{(j)}</span>  and subdomain  <span class="math">L&#x27; \\subseteq [n^{(j)}]</span> ,  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">L'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">/ n^{(j)} \\geq 1 - s\\delta<span class="math"> , such that, for all  </span>i<span class="math"> ,  </span>f_i^{(j)}<span class="math">  and  </span>g_i^{(j)}<span class="math"> ,  </span>f'_i^{(j)}<span class="math">  and  </span>g'_i^{(j)}<span class="math">  agree on  </span>L'$ . This implies the following.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\Delta (\\mathbf{f}_i,\\mathbf{g}_i),\\Delta (\\mathbf{f}_i&#x27;,\\mathbf{g}_i&#x27;)\\leq s\\delta</span>  . Since we start in the doomed set, this implies that, for some  <span class="math">i,p(x_{i},\\hat{\\mathbf{g}}_{i})\\neq e_{i}</span>  Hence, the degree  <span class="math">d(m - 1)</span>  polynomial</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">z (X) = p \\left(\\sum_ {i = 1} ^ {m} L _ {i, H} (X) \\cdot \\left(x _ {i}, \\hat {\\mathbf {g}} _ {i}\\right)\\right) - v _ {H} (X) \\cdot q (X) - \\sum_ {i = 1} ^ {m} L _ {i, H} (X) \\cdot e _ {i}</span></div>

    <p class="text-gray-300">is non-zero. By the Schwartz-Zippel lemma,  <span class="math">\\operatorname{Pr}_{\\alpha}[z(\\alpha) = 0] \\leq \\epsilon_2</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For all  <span class="math">\\alpha \\in \\mathbb{F}</span>  and  <span class="math">\\Gamma</span> , for  <span class="math">(r_1, \\ldots, r_m, r_1&#x27;, \\ldots, r_m&#x27;) \\gets \\text{Coeffs}(\\Gamma)</span> , we have  <span class="math">\\Delta\\left(\\sum_{i=1}^{m} L_{i,H}(\\alpha) \\cdot \\mathbf{f}_i, \\sum_{i=1}^{m} L_{i,H}(\\alpha) \\cdot \\mathbf{g}_i\\right)</span> ,  <span class="math">\\Delta\\left(\\sum_{i=1}^{m} r_i \\cdot \\mathbf{f}_i + r_i&#x27; \\cdot \\mathbf{f}_i&#x27;, \\sum_{i=1}^{m} r_i \\cdot \\mathbf{g}_i + r_i&#x27; \\cdot \\mathbf{g}_i&#x27;\\right) \\leq s\\delta</span> . In other words,  <span class="math">E_1(\\mathbf{g}, \\alpha)</span>  and  <span class="math">E_1&#x27;(\\mathbf{g}&#x27;, \\Gamma)</span>  hold for  <span class="math">\\mathbf{g} = \\mathbf{g}(\\alpha) = \\sum_{i} L_i(\\alpha) \\cdot \\mathbf{g}_i</span>  and  <span class="math">\\mathbf{g}&#x27; = \\sum_{i=1}^{m} r_i \\cdot \\mathbf{g}_i + r_i&#x27; \\cdot \\mathbf{g}_i&#x27;</span> ; moreover, since  <span class="math">s\\delta</span>  is smaller than the unique decoding radius, these are the only satisfying assignments. It follows that  <span class="math">\\operatorname{Pr}_{\\alpha}[E_2(\\mathbf{g}(\\alpha), \\alpha)] &amp;gt; \\epsilon_2</span> .</li>

    </ul>

    <p class="text-gray-300">Notice that the events  <span class="math">z(\\alpha) = 0</span>  and  <span class="math">E_2(\\mathbf{g}(\\alpha),\\alpha)</span>  are equivalent. Thus, we have shown a contradiction.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Claim 6.10. Suppose  $([e_i, x_i, \\mathbf{f}_i, \\mathbf{f}_i']_{i=1}^m, q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\alpha, \\Gamma)$  is in the doomed set. Then</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Pr_ {\\alpha} \\left[ \\left([ e _ {i}, x _ {i}, \\mathbf {f} _ {i}, \\mathbf {f} _ {i} ^ {\\prime} ] _ {i = 1} ^ {m}, q</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\alpha , \\Gamma</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(e, x, \\mathbf {f}, \\bar {\\mathbf {f}} ^ {\\prime})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbf {Q}\\right) \\notin \\mathcal {D} \\right] \\leq (1 - \\delta) ^ {t}.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">Proof. In order for the verifier to accept,  <span class="math">\\mathbf{f},\\mathbf{f}^{\\prime}</span>  must decode to codewords  <span class="math">\\mathbf{g},\\mathbf{g}^{\\prime}\\in \\mathbf{C}</span>  with  <span class="math">\\Delta (\\mathbf{f},\\mathbf{g})</span> <span class="math">\\Delta (\\mathbf{f}^{\\prime},\\mathbf{g}^{\\prime})</span> <span class="math">\\leq (s - 1)\\delta</span>  such that  <span class="math">p(x,\\hat{\\mathbf{g}}) = e = v(\\alpha)\\cdot q(\\alpha) + \\sum_{i}L_{i}(\\alpha)\\cdot e_{i}</span> . Since we start in the doomed set, this implies that, for some  <span class="math">j</span> , either  <span class="math">\\Delta \\left(\\sum_{i = 1}^{m}L_{i,H}(\\alpha)\\cdot f_{i}^{(j)},g^{(j)}\\right) &amp;gt; s\\delta</span>  or  <span class="math">\\Delta \\left(\\sum_{i = 1}^{m}r_{i}f_{i}^{(j)} + r_{i}^{\\prime}f_{i}^{\\prime (j)},g^{\\prime (j)}\\right) &amp;gt; s\\delta</span> . Hence, for some  <span class="math">j</span> , either  <span class="math">\\Delta (\\sum_{i = 1}^{m}L_{i,H}(\\alpha)\\cdot f_{i}^{(j)},f^{(j)}) &amp;gt; \\delta</span>  or  <span class="math">\\Delta (\\sum_{i = 1}^{m}r_{i}f_{i}^{(j)} + r_{i}^{\\prime}f_{i}^{\\prime (j)},f^{\\prime (j)}) &amp;gt; \\delta</span> . Thus, for at least one of the pairs, the probability that the vectors are consistent at a random index is  <span class="math">1 - \\delta</span> , and the claim follows.</p>

    <p class="text-gray-300">7 Optimizations</p>

    <h3 id="sec-51" class="text-xl font-semibold mt-8">7.1 Batch commitments</h3>

    <p class="text-gray-300">The accumulation scheme in Section 6 enables accumulating <span class="math">m</span> accumulators (or proofs) into one. Each accumulator consists of a short commitment, e.g. a Merkle tree, and a long witness, the vector inside the commitment. The most expensive step of the accumulation verifier requires opening a vector commitment, at <span class="math">k</span> locations of the accumulator’s codewords. Naively, this requires opening <span class="math">m\\cdot k</span> Merkle proofs, which have total size <span class="math">k\\cdot m\\cdot\\log n</span>, where <span class="math">n</span> is the size of one accumulator witness. We can optimize the construction by committing to <em>all</em> <span class="math">m</span> codewords inside a <em>single</em> vector commitment. To do this we commit to a tuple of <span class="math">m</span> entries, one per codeword, at each position of the vector commitment. This enables opening all <span class="math">m</span> vectors at the same position using only a single Merkle proof. When performing the linearity check, we open the same position for all codewords. This batch accumulator construction, now only requires a single Merkle proof per opening. The total opening proof size is, thus, reduced from <span class="math">k\\cdot m\\cdot\\log n</span> to just <span class="math">k\\cdot(m+\\log n)</span>. This is a very significant saving, especially for larger values of <span class="math">m</span>, which we use to build PCD trees with higher arity <span class="math">m</span> and lower depth.</p>

    <h5 id="sec-52" class="text-base font-semibold mt-4">Batch commitments and PCD.</h5>

    <p class="text-gray-300">Using batch commitments naively is incompatible with our PCD construction from Section 5.1. The reason is that each node containing an accumulator or proof is constructed independently, thus committing to <span class="math">m</span> accumulator witnesses or proof witnesses in one commitment isn’t possible. Fortunately, there are many instances of PCD where it is possible to still take advantage of batch commitments and batch accumulation. For example, consider the IVC construction from Section 7.2 with uniform <span class="math">m</span>-ary PCD and accumulation trees. Instead of constructing the PCD tree node by node, we can construct <span class="math">m</span> new PCD nodes and accumulators at the same time and use a batch commitment to commit to the accumulator and proof witnesses. More formally, this is a PCD tree where the predicate <span class="math">\\varphi_{\\textsf{big}}</span> is <span class="math">m</span> concatenations of the original PCD predicate <span class="math">\\varphi_{\\textsf{small}}</span>. Each accumulator now is a single batch commitment with <span class="math">m</span> witnesses and similarly, each proof consists of a batch proof with <span class="math">m</span> witnesses. Each batch proof proves <span class="math">\\varphi_{\\textsf{big}}</span> and the accumulation of <span class="math">m</span> batch accumulators (<span class="math">m^{2}</span> witnesses) into a single output batch accumulator (<span class="math">m</span> witnesses). More specifically, the <span class="math">m</span> proof witnesses each prove one <span class="math">\\varphi_{\\textsf{small}}</span> and the accumulation of a batch accumulator (<span class="math">m</span> witnesses) into the same output batch accumulator (localized to one index). The construction is displayed in Figure 3. The big advantage is that the number of Merkle tree openings in the recursive circuit is reduced by a factor of <span class="math">m</span>. The downside is that the PCD prover’s memory (and the amount of data needed to construct a new PCD node), now consists of at least <span class="math">m^{2}</span> accumulator witness, a factor <span class="math">m</span> more than in the construction without batch commitments.</p>

    <h3 id="sec-53" class="text-xl font-semibold mt-8">7.2 Low-overhead IVC from accumulation</h3>

    <p class="text-gray-300">As mentioned in Remark 2.2, constructing polynomial-length IVC from bounded-depth PCD requires a tree-based strategy. Let us recall a simplified version of the construction from <em>[x18, x1]</em>. The idea is to use a PCD scheme for the following compliance predicate.</p>

    <p class="text-gray-300"><span class="math">\\varphi_{F}(z,z_{\\textsf{loc}},[z_{i}]_{i=1}^{m})</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><em>Leaf node.</em> If <span class="math">z=(0,\\textsf{in},\\textsf{out})</span> and each <span class="math">z_{i}=\\bot</span>:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse <span class="math">z_{\\textsf{loc}}=w</span>.</li>

      <li>Check that <span class="math">\\textsf{out}=F(\\textsf{in},w)</span>.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><em>Internal node.</em> If <span class="math">z=(k,\\textsf{in},\\textsf{out})</span> for some <span class="math">k\\in[d]</span> and each <span class="math">z_{i}=(k-1,\\textsf{in}_{i},\\textsf{out}_{i})</span>:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Check that <span class="math">\\textsf{in}=\\textsf{in}_{1}</span> and <span class="math">\\textsf{out}=\\textsf{out}_{m}</span>.</li>

      <li>Check that <span class="math">\\textsf{out}_{1}=\\textsf{in}_{2},\\textsf{out}_{2}=\\textsf{in}_{3},\\ldots,\\textsf{out}_{m-1}=\\textsf{in}_{m}</span>.</li>

    </ul>

    <p class="text-gray-300">Suppose a transcript with output <span class="math">(k,\\mathsf{in},\\mathsf{out})</span> is <span class="math">\\varphi_{F}</span>-compliant. Then <span class="math">\\mathsf{out}</span> must be the result of <span class="math">m^{k}</span> applications of <span class="math">F</span> to <span class="math">\\mathsf{in}</span>. Moreover, the leaf nodes of the transcript are labeled with the witness values. Using a PCD scheme for <span class="math">\\varphi_{F}</span>, we construct IVC for computations of length at most <span class="math">m^{d}</span> as follows. The IVC prover begins with an empty <span class="math">m</span>-ary tree of depth <span class="math">d</span>. In each step, it adds a leaf node, which consists of the message <span class="math">(0,\\mathsf{in},\\mathsf{out})</span> and a PCD proof <span class="math">\\sigma</span>. Whenever there exists a full set of <span class="math">m</span> nodes in a layer, the IVC prover creates a parent node by running the PCD prover. This means that it only needs to keep track of the tree’s “frontier,” denoted <span class="math">\\tau</span>, which consists of at most <span class="math">md</span> nodes. At any step, the IVC verifier can check the computation by running the PCD verifier on each node in the frontier.</p>

    <p class="text-gray-300">In more detail, let <span class="math">\\mathsf{PCD}=(\\mathbb{G},\\mathbb{I},\\mathbb{P},\\mathbb{V})</span> be a PCD scheme for the class of compliance predicates <span class="math">\\{\\varphi_{F}\\}</span>. A full description of the IVC scheme is given below.</p>

    <p class="text-gray-300">IVC.Generate(<span class="math">1^{\\lambda}</span>):</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Sample <span class="math">\\mathbb{pp}\\leftarrow\\mathbb{G}(1^{\\lambda})</span>.</li>

      <li>Output <span class="math">\\mathbb{pp}</span>.</li>

    </ol>

    <p class="text-gray-300">IVC.Index(<span class="math">\\mathbb{pp},F</span>):</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Compute <span class="math">(\\mathsf{ipk},\\mathsf{ivk}):=\\mathbb{I}(\\mathbb{pp},\\varphi_{F})</span>.</li>

      <li>Output <span class="math">\\mathsf{ipk}</span> and <span class="math">\\mathsf{ivk}</span>.</li>

    </ol>

    <p class="text-gray-300">IVC.Prove(<span class="math">\\mathsf{ipk},\\tau,\\mathsf{in},w,\\mathsf{out}</span>):</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Generate a PCD proof <span class="math">\\sigma\\leftarrow\\mathbb{P}(\\mathsf{ipk},(0,\\mathsf{in},\\mathsf{out}),w,[\\bot]_{i=1}^{m})</span>.</li>

      <li>Append <span class="math">(0,\\mathsf{in},\\mathsf{out},\\sigma)</span> to <span class="math">\\tau</span>.</li>

      <li>For each <span class="math">k\\in[d]</span>: if there are <span class="math">m</span> nodes in the <span class="math">(k-1)</span>-th layer of the frontier, i.e. <span class="math">\\tau</span> contains <span class="math">[k-1,\\mathsf{in}_{i},\\mathsf{out}_{i},\\sigma_{i}]_{i=1}^{m}</span>:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Remove the nodes from <span class="math">\\tau</span>.</li>

      <li>Generate a PCD proof <span class="math">\\sigma\\leftarrow\\mathbb{P}(\\mathsf{ipk},(k,\\mathsf{in}_{1},\\mathsf{out}_{m}),\\bot,[(k-1,\\mathsf{in}_{i},\\mathsf{out}_{i}),\\sigma_{i}]_{i=1}^{m})</span>.</li>

      <li>Append <span class="math">(k,\\mathsf{in}_{1},\\mathsf{out}_{m},\\sigma)</span> to <span class="math">\\tau</span>.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Output <span class="math">\\tau</span>.</li>

    </ol>

    <p class="text-gray-300">IVC.Verify(<span class="math">\\mathsf{ivk},\\tau,x,T</span>):</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>If <span class="math">\\tau</span> is empty, <span class="math">x</span> is the initial value, and <span class="math">T=0</span>, accept.</li>

      <li>Parse <span class="math">\\tau</span> as a list of nodes <span class="math">[k_{j},\\mathsf{in}_{j},\\mathsf{out}_{j},\\sigma_{j}]_{j=1}^{\\ell}</span>.</li>

      <li>For each <span class="math">j\\in[\\ell]</span>, check that <span class="math">\\mathbb{V}(\\mathsf{ivk},(k_{j},\\mathsf{in}_{j},\\mathsf{out}_{j}),\\sigma_{j})</span> accepts.</li>

      <li>Check that <span class="math">\\mathsf{in}_{1}</span> is the initial value and <span class="math">\\mathsf{out}_{\\ell}=x</span>.</li>

      <li>Check that <span class="math">\\mathsf{out}_{1}=\\mathsf{in}_{2},\\mathsf{out}_{2}=\\mathsf{in}_{3},\\ldots,\\mathsf{out}_{\\ell-1}=\\mathsf{in}_{\\ell}</span>.</li>

      <li>Check that <span class="math">T=\\sum_{j=1}^{\\ell}m^{k_{j}}</span>.</li>

    </ol>

    <p class="text-gray-300">This IVC scheme is somewhat wasteful, in the sense that the internal nodes of the tree do not use <span class="math">F</span>. If we were to instantiate PCD with the construction from Section 5, then the internal NARK proofs would be proving <span class="math">F</span> for nothing.</p>

    <p class="text-gray-300">Accumulating separately. Our idea is to accumulate computations of <span class="math">F</span> separately, and use PCD to verify the accumulations. In particular, let <span class="math">\\mathsf{ARG}=(\\mathcal{G},\\mathcal{P},\\mathcal{V})</span> be a NARK for the indexed relation <span class="math">\\mathscr{R}=\\{(F,(x,x^{\\prime}),w):x^{\\prime}=F(x,w)\\}</span>. Let <span class="math">\\mathsf{AS}=(\\mathrm{G},\\mathrm{I},\\mathrm{P},\\mathrm{V},\\mathrm{D})</span> be an accumulation scheme for <span class="math">\\mathsf{ARG}</span>. For simplicity, we will assume that NARK proofs can be “cast” into accumulators (this is true for the construction in Section 6). Finally, let <span class="math">\\mathsf{PCD}^{\\prime}=(\\mathbb{G}^{\\prime},\\mathbb{I}^{\\prime},\\mathbb{P}^{\\prime},\\mathbb{V}^{\\prime})</span> be a (not necessarily accumulation-based) PCD scheme for the class of compliance predicates <span class="math">\\{\\varphi^{\\prime}_{\\mathsf{avk}}\\}</span>, which is defined below.</p>

    <p class="text-gray-300"><span class="math">\\varphi_{\\mathsf{avk}}^{\\prime}(z,z_{\\mathsf{loc}},[z_{i}]_{i = 1}^{m})</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Leaf node. If <span class="math">z = (0, \\mathrm{in}, \\mathrm{out}, \\pi . \\mathbb{x})</span> and each <span class="math">z_{i} = \\bot</span>, accept.</li>

      <li>Internal node. If <span class="math">z = (k, \\mathrm{in}, \\mathrm{out}, \\mathrm{acc}. \\mathbb{x})</span> and each <span class="math">z_{i} = (k - 1, \\mathrm{in}_{i}, \\mathrm{out}_{i}, \\mathrm{acc}_{i}. \\mathbb{x})</span> for some <span class="math">k \\in [d]</span>:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>If <span class="math">k = 1</span>, check that each <span class="math">\\mathrm{acc}_i.\\mathbf{x}</span> is cast from some <span class="math">\\pi .\\mathbf{x}</span> with instance <span class="math">(\\mathrm{in}_i,\\mathrm{out}_i)</span>.</li>

      <li>Check that <span class="math">\\mathrm{in} = \\mathrm{in}_1</span> and <span class="math">\\mathrm{out} = \\mathrm{out}_m</span>.</li>

      <li>Check that <span class="math">\\mathrm{out}_1 = \\mathrm{in}_2, \\mathrm{out}_2 = \\mathrm{in}_3, \\ldots, \\mathrm{out}_{m-1} = \\mathrm{in}_m</span>.</li>

      <li>Pare <span class="math">z_{\\mathrm{loc}} = \\mathrm{pf}</span>.</li>

      <li>Check that <span class="math">\\mathrm{V}(\\mathrm{avk},[\\mathrm{acc}_i.\\mathbf{x}]_{i = 1}^m,\\mathrm{acc}.\\mathbf{x},\\mathrm{pf})</span> accepts.</li>

    </ul>

    <p class="text-gray-300">Similar to before, the IVC prover begins with an empty <span class="math">m</span>-ary tree of depth <span class="math">d</span>. In the <span class="math">T</span>-th step, it adds a leaf node, which consists of the message <span class="math">(0,\\mathrm{in},\\mathrm{out})</span>, a NARK proof certifying the computation <span class="math">\\mathrm{out} = F(\\mathrm{in},w)</span> for some <span class="math">w</span>, and a PCD proof <span class="math">\\sigma</span>. Whenever there exists a full set of <span class="math">m</span> nodes in a layer, the IVC prover creates a parent node by running the accumulation and PCD provers. A full description of the IVC scheme is given below.</p>

    <p class="text-gray-300">IVC. Generate <span class="math">(1^{\\lambda})</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Sample <span class="math">\\mathsf{pp} \\gets \\mathcal{G}(1^{\\lambda})</span>.</li>

      <li>Sample <span class="math">\\mathsf{pp}_{\\mathsf{AS}} \\gets \\mathrm{G}(1^{\\lambda})</span>.</li>

      <li>Sample <span class="math">\\mathbb{pp} \\gets \\mathbb{G}&#x27;(1^{\\lambda})</span>.</li>

      <li>Output <span class="math">(\\mathsf{pp},\\mathsf{pp}_{\\mathsf{AS}},\\mathbb{pp})</span>.</li>

    </ol>

    <p class="text-gray-300">IVC. Index <span class="math">((\\mathsf{pp},\\mathsf{pp}_{\\mathsf{AS}},\\mathbb{pp}),F)</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Compute <span class="math">(\\mathsf{apk},\\mathsf{avk},\\mathsf{dk}):= \\mathrm{I}(\\mathsf{pp}_{\\mathsf{AS}},F)</span></li>

      <li>Compute <span class="math">(\\mathrm{ipk},\\mathrm{ivk}):= \\mathbb{I}&#x27;(\\mathbb{pp},\\varphi_{\\mathrm{avk}})</span></li>

      <li>Output <span class="math">(\\mathsf{pp},F,\\mathsf{apk},\\mathsf{ipk})</span> and <span class="math">(\\mathsf{pp},F,\\mathsf{dk},\\mathsf{ivk})</span></li>

    </ol>

    <p class="text-gray-300">IVC. Prove <span class="math">((\\mathsf{pp},F,\\mathsf{apk},\\mathsf{ipk}),\\tau ,\\mathsf{in},w,\\mathsf{out})</span>  :</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Generate a NARK proof <span class="math">\\pi \\gets \\mathcal{P}(\\mathsf{pp},F,(\\mathsf{in},\\mathsf{out}),w)</span> and cast it into an accumulator acc.</li>

      <li>Generate a dummy PCD proof <span class="math">\\sigma := \\bot</span>.</li>

      <li>Append <span class="math">(0, \\mathrm{in}, \\mathrm{out}, \\mathrm{acc}, \\sigma)</span> to <span class="math">\\tau</span>.</li>

      <li>For each <span class="math">k = 1, \\ldots, d</span>: if there are <span class="math">m</span> nodes in the <span class="math">(k - 1)</span>-th layer of the frontier, i.e. <span class="math">\\tau</span> contains <span class="math">[k - 1, \\mathrm{in}_i, \\mathrm{out}_i, \\mathrm{acc}_i, \\sigma_i]_{i=1}^m</span>:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Remove the nodes from <span class="math">\\tau</span>.</li>

      <li>Accumulate <span class="math">(\\mathrm{acc},\\mathrm{pf}) \\gets \\mathrm{P}(\\mathrm{apk},[\\mathrm{acc}_i]_{i=1}^m)</span>.</li>

      <li>Generate a PCD proof <span class="math">\\sigma \\gets \\mathbb{P}&#x27;(\\mathrm{ipk},(k,\\mathrm{in}_1,\\mathrm{out}_m,\\mathrm{acc}.\\mathbf{x}),\\mathrm{pf},[(k - 1,\\mathrm{in}_i,\\mathrm{out}_i,\\mathrm{acc}_i.\\mathbf{x}),\\sigma_i]_{i = 1}^m)</span>.</li>

      <li>Append <span class="math">(k,\\mathrm{in}_1,\\mathrm{out}_m,\\mathrm{acc},\\sigma)</span> to <span class="math">\\tau</span>.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Output <span class="math">\\tau</span>.</li>

    </ol>

    <p class="text-gray-300">IVC. Verify <span class="math">((\\mathsf{pp},F,\\mathsf{dk},\\mathsf{ivk}),\\tau ,x,T)</span>  :</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>If <span class="math">\\tau</span> is empty, <span class="math">x</span> is the initial value, and <span class="math">T = 0</span>, accept.</li>

      <li>Parse <span class="math">\\tau</span> as a list of nodes <span class="math">[k_j,\\mathrm{in}_j,\\mathrm{out}_j,\\mathrm{acc}_j,\\sigma_j]_{j = 1}^{\\ell}</span>.</li>

      <li>For each <span class="math">j \\in [\\ell]</span>, check that <span class="math">\\mathbb{V}&#x27;(\\mathrm{ivk}, (k_j, \\mathrm{in}_j, \\mathrm{out}_j, \\mathrm{acc}_j, \\mathbf{x}), \\sigma_j)</span> accepts. If <span class="math">k_j = 0</span>, recover <span class="math">\\pi_j</span> from <span class="math">\\mathrm{acc}_j</span> and check that <span class="math">\\mathcal{V}(\\mathrm{pp}, F, (\\mathrm{in}_j, \\mathrm{out}_j), \\pi_j)</span> accepts. Otherwise, check that <span class="math">\\mathrm{D}(\\mathrm{dk}, \\mathrm{acc}_j)</span> accepts.</li>

      <li>Check that <span class="math">\\mathrm{in}_1</span> is the initial value and <span class="math">\\mathrm{out}_{\\ell} = x</span>.</li>

      <li>Check that <span class="math">\\mathrm{out}_1 = \\mathrm{in}_2, \\mathrm{out}_2 = \\mathrm{in}_3, \\ldots, \\mathrm{out}_{\\ell - 1} = \\mathrm{in}_{\\ell}</span>.</li>

      <li>Accept if <span class="math">T = \\sum_{j=1}^{\\ell} m^{k_j}</span>.</li>

    </ol>

    <p class="text-gray-300">44</p>

    <p class="text-gray-300">We sketch the knowledge soundness extraction strategy for the IVC scheme. First, run the PCD extractor on each node in the frontier to obtain all of the accumulator instances and proofs. Then, run the accumulation extractor at each layer of the tree to obtain accumulator witnesses. The PCD compliance predicate guarantees that the accumulators in the leaf layer are cast from NARK proofs. Run the NARK extractor on these proofs to obtain each step of the computation.</p>

    <p class="text-gray-300">Efficiency. We say that an IVC scheme’s proving cost is the amount of extra work the prover does, outside of the original computation. Let <span class="math">S_{d}:=\\sum_{i=0}^{d}m^{i}</span> be the number of nodes in a tree with height <span class="math">d</span> and arity <span class="math">m</span>. In the old construction, the overhead is generating a tree of <span class="math">S_{d}</span> PCD proofs. In the new construction, the overhead is generating a tree of <span class="math">S_{d}</span> accumulators and a tree of <span class="math">S_{d-1}</span> PCD proofs.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Recall that in accumulation-based PCD, a PCD proof consists of a NARK proof and accumulator. The cost of generating a tree of <span class="math">S_{d}</span> PCD proofs is roughly the cost of generating <span class="math">S_{d}</span> NARK proofs, plus the cost of generating <span class="math">S_{d-1}</span> accumulators (since the PCD prover outputs a dummy accumulator when there are no incoming edges). Let <span class="math">R</span> be the PCD circuit which consists of the compliance predicate and accumulation verifier. We assume that the cost of generating a NARK proof or accumulator is roughly $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. Hence, the cost of generating a tree of </span>m^{d}<span class="math"> PCD proofs is roughly </span>(S_{d}+S_{d-1})\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">R</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In the old construction, the compliance predicate <span class="math">\\varphi</span> is dominated by the function <span class="math">F</span>. The size of the circuit <span class="math">R</span> is roughly $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">F</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathrm{V}_{R}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, where </span>\\mathrm{V}_{R}<span class="math"> denotes the accumulation verifier for </span>R<span class="math">. Hence, the IVC scheme’s total cost is </span>(S_{d}+S_{d-1})\\cdot(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">F</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathrm{V}_{R}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In the new construction, the compliance predicate <span class="math">\\varphi^{\\prime}</span> is dominated by <span class="math">\\mathrm{V}_{F}</span>, where <span class="math">\\mathrm{V}_{F}</span> denotes the accumulation verifier for <span class="math">F</span>. The size of the corresponding circuit <span class="math">R^{\\prime}</span> is roughly $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathrm{V}_{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathrm{V}_{R^{\\prime}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, where </span>\\mathrm{V}_{R^{\\prime}}<span class="math"> denotes the accumulation verifier for </span>R^{\\prime}<span class="math">. Hence, the IVC scheme’s total cost is </span>S_{d}\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">F</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+(S_{d-1}+S_{d-2})\\cdot(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathrm{V}_{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathrm{V}_{R^{\\prime}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">To compare these costs, notice that <span class="math">\\mathrm{V}_{F}</span> is cheaper than <span class="math">\\mathrm{V}_{R}</span>, since the circuit <span class="math">R</span> contains <span class="math">F</span>. Assuming <span class="math">F</span> is sufficiently large, we can also reasonably expect that <span class="math">\\mathrm{V}_{R^{\\prime}}</span> is cheaper than <span class="math">\\mathrm{V}_{R}</span>. This means that the new construction’s overhead is bounded by $S_{d}\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">F</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+(S_{d-1}+S_{d-2})\\cdot 2</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathrm{V}_{R}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. Hence, the new construction reduces cost by at least </span>S_{d-1}\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">F</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+(m-2)(S_{d-1}+S_{d-2})\\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathrm{V}_{R}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-54" class="text-xl font-semibold mt-8">7.3 PCD composition</h3>

    <p class="text-gray-300">We show that combining our accumulation-based PCD scheme with a SNARK-based PCD scheme can yield a new PCD scheme that is more performant than either scheme on their own.</p>

    <p class="text-gray-300">Recursion overhead is linear in tree depth. In Section 5 we show that for every constant depth <span class="math">d</span> predicate there exists a PCD scheme. Note that this is a different order of quantifiers than prior unbounded accumulation or SNARK-based schemes which showed that there exists a PCD scheme for any constant depth <span class="math">d</span> predicate. This change of quantifiers is not only interesting from a security point of view but also from an efficiency perspective. The reason is that in our scheme the PCDs recursive overhead is linearly dependent on <span class="math">d</span>. The reason is that within each accumulation step, we prove that the output accumulator code is <span class="math">\\delta</span> close to the input accumulator code. After <span class="math">d</span> steps the distance is <span class="math">d\\cdot\\delta</span>. Even if the final accumulator is a codeword we need to ensure that the accumulators at the leaves of the PCD tree are still within the unique decoding radius of the code. If <span class="math">d</span> increases, we, therefore, decrease <span class="math">\\delta</span> by increasing the spot-checking parameter in our accumulation scheme. The relationship is roughly linear, as we need to do the linearity check at <span class="math">O(\\lambda d)</span> positions.</p>

    <p class="text-gray-300">Reducing PCD depth. This relationship motivates the need for lower-depth PCD trees. One avenue is using higher arity accumulation/PCD trees. Another optimization combines two PCD schemes. Let <span class="math">\\mathsf{PCD}^{\\mathsf{acc}}</span> be a depth-bounded accumulation-based PCD scheme. Let <span class="math">\\mathsf{PCD}^{\\mathsf{ARG}}</span> be a SNARK-based PCD scheme (that</p>

    <p class="text-gray-300">is not depth bounded). This second PCD scheme checks the original predicate <span class="math">\\varphi</span> as well as checking the PCD proof output by <span class="math">\\mathsf{PCD^{acc}}</span>.</p>

    <p class="text-gray-300">Let <span class="math">d^{<em>}</span> be the maximum depth supported by <span class="math">\\mathsf{PCD^{acc}}</span> and <span class="math">m</span> it’s arity. We combine the schemes by first building PCD trees up to depth <span class="math">d^{</em>}</span>. Then we use <span class="math">\\mathsf{PCD^{ARG}}</span> to combine the roots of these PCD schemes. Note that we only need to use <span class="math">\\mathsf{PCD^{ARG}}</span> every <span class="math">m^{d^{<em>}}</span> PCD step. Even for relatively small values of <span class="math">d^{</em>}</span> this is likely a marginal cost compared to the cost of running <span class="math">\\mathsf{PCD^{acc}}</span>. In fact, we can even pick our parameters optimally. Assume that <span class="math">\\mathsf{PCD^{ARG}}</span> is <span class="math">c</span> times as expensive as running <span class="math">\\mathsf{PCD^{acc}}</span> for a depth <span class="math">1</span> predicate. Let <span class="math">n</span> be the cost of running <span class="math">\\mathsf{PCD^{acc}}</span> for a depth <span class="math">1</span> predicate. Since <span class="math">\\mathsf{PCD^{acc}}</span> is linear in the maximum supported depth, we have that the total PCD cost is proportional to <span class="math">d^{<em>}\\cdot n+\\frac{c\\cdot n}{2^{d^{</em>}}}</span>. Setting <span class="math">d^{*}=\\log c</span>, we get a cost of <span class="math">\\log c\\cdot n</span>, significantly lower than either scheme on its own.</p>

    <p class="text-gray-300">This optimization can be further used for code switching techniques, as the first PCD scheme could be used using a linear-time code and the SNARK-based PCD scheme could be using Fractal <em>[x10]</em> and FRI <em>[x5]</em> which are based on Reed–Solomon codes.</p>

    <h4 id="sec-55" class="text-lg font-semibold mt-6">Compatibility.</h4>

    <p class="text-gray-300">The optimization works for any depth-bounded PCD scheme with an arbitrary other PCD scheme. It is even possible to stack two accumulation-based schemes. For instance, one could use a fast linear-time encodable code for the first PCD and then use a Reed-Solomon code (which has longer encoding time but shorter codes) for the second PCD. The optimization is also fully compatible with both batch accumulators and the low-overhead IVC.</p>

    <p class="text-gray-300">Acknowledgments</p>

    <p class="text-gray-300">The third author was supported by NSF, DARPA, the Simons Foundation, UBRI, NTT Research, and the Stanford Future of Digital Currency Initiative (FDCI). Opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA.</p>

    <p class="text-gray-300">##</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[ACFY24] G. Arnon, A. Chiesa, G. Fenzi, and E. Yogev. “STIR: Reed-Solomon Proximity Testing with Fewer Queries”. In: Proceedings of the 44th Annual International Cryptology Conference. CRYPTO ’24. 2024, pp. 380–413.</li>

      <li>[AFK23] T. Attema, S. Fehr, and M. Klooß. “Fiat-Shamir Transformation of Multi-Round Interactive Proofs (Extended Version)”. In: Journal of Cryptology 36.4 (2023), p. 36.</li>

      <li>[AHIV17] S. Ames, C. Hazay, Y. Ishai, and M. Venkitasubramaniam. “Ligero: Lightweight Sublinear Arguments Without a Trusted Setup”. In: Proceedings of the 24th ACM Conference on Computer and Communications Security. CCS ’17. 2017, pp. 2087–2104.</li>

      <li>[AST24] A. Arun, S. T. V. Setty, and J. Thaler. “Jolt: SNARKs for Virtual Machines via Lookups”. In: Proceedings of the 43rd Annual International Conference on the Theory and Applications of Cryptographic Techniques. EUROCRYPT ’24. 2024, pp. 3–33.</li>

      <li>[BBHR18a] E. Ben-Sasson, I. Bentov, Y. Horesh, and M. Riabzev. “Fast Reed-Solomon Interactive Oracle Proofs of Proximity”. In: Proceedings of the 45th International Colloquium on Automata, Languages, and Programming. Vol. 107. ICALP ’18. 2018, 14:1–14:17.</li>

      <li>[BBHR18b] E. Ben-Sasson, I. Bentov, Y. Horesh, and M. Riabzev. “Fast Reed–Solomon Interactive Oracle Proofs of Proximity”. In: Proceedings of the 45th International Colloquium on Automata, Languages and Programming. ICALP ’18. 2018, 14:1–14:17.</li>

      <li>[BC23] B. Bünz and B. Chen. “Protostar: Generic Efficient Accumulation/Folding for Special-Sound Protocols”. In: Proceedings of the 29th International Conference on the Theory and Application of Cryptology and Information Security. ASIACRYPT ’23. 2023, pp. 77–110.</li>

      <li>[BC24] D. Boneh and B. Chen. “LatticeFold: A Lattice-based Folding Scheme and its Applications to Succinct Proof Systems”. Cryptology ePrint Archive, Report 2024/257. 2024.</li>

      <li>[BCCT13] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer. “Recursive Composition and Bootstrapping for SNARKs and Proof-Carrying Data”. In: Proceedings of the 45th ACM Symposium on the Theory of Computing. STOC ’13. 2013, pp. 111–120.</li>

      <li>[BCG20] J. Bootle, A. Chiesa, and J. Groth. “Linear-Time Arguments with Sublinear Verification from Tensor Codes”. In: Proceedings of the 18th International Conference on the Theory of Cryptography. TCC ’20. 2020, pp. 19–46.</li>

      <li>[BCG24] E. Boyle, R. Cohen, and A. Goel. “Breaking the <span class="math">O(\\sqrt{n})</span>-Bit Barrier: Byzantine Agreement with Polylog Bits Per Party”. In: Journal of Cryptology 37.1 (2024), p. 2.</li>

      <li>[BCGJM18] J. Bootle, A. Cerulli, J. Groth, S. K. Jakobsen, and M. Maller. “Arya: Nearly Linear-Time Zero-Knowledge Proofs for Correct Program Execution”. In: Proceedings of the 24th International Conference on the Theory and Application of Cryptology and Information Security. ASIACRYPT ’18. 2018, pp. 595–626.</li>

      <li>[BCIKS23] E. Ben-Sasson, D. Carmon, Y. Ishai, S. Kopparty, and S. Saraf. “Proximity Gaps for Reed-Solomon Codes”. In: Journal of the ACM 70.5 (2023), 31:1–31:57.</li>

      <li>[BCL22] J. Bootle, A. Chiesa, and S. Liu. “Zero-Knowledge IOPs with Linear-Time Prover and Polylogarithmic-Time Verifier”. In: Proceedings of the 41st Annual International Conference on the Theory and Applications of Cryptographic Techniques. EUROCRYPT ’22. 2022, pp. 275–304.</li>

      <li>[BCLMS21] B. Bünz, A. Chiesa, W. Lin, P. Mishra, and N. Spooner. “Proof-Carrying Data Without Succinct Arguments”. In: Proceedings of the 41st Annual International Cryptology Conference. CRYPTO ’21. 2021, pp. 681–710.</li>

      <li>[BCMS20] B. Bünz, A. Chiesa, P. Mishra, and N. Spooner. “Proof-Carrying Data from Accumulation Schemes”. In: Proceedings of the 18th Theory of Cryptography Conference. TCC ’20. 2020.</li>

    </ul>

    <p class="text-gray-300">[BCS16] E. Ben-Sasson, A. Chiesa, and N. Spooner. “Interactive Oracle Proofs”. In: Proceedings of the 14th Theory of Cryptography Conference. TCC ’16-B. 2016, pp. 31–60.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[BCTV14] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza. “Scalable Zero Knowledge via Cycles of Elliptic Curves”. In: Proceedings of the 34th Annual International Cryptology Conference. CRYPTO ’14. 2014, pp. 276–294.</li>

      <li>[BCTV17] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza. “Scalable Zero Knowledge Via Cycles of Elliptic Curves”. In: Algorithmica 79.4 (2017), pp. 1102–1160.</li>

      <li>[BDFG21] D. Boneh, J. Drake, B. Fisch, and A. Gabizon. “Halo Infinite: Proof-Carrying Data from Additive Polynomial Commitments”. In: Proceedings of the 41st Annual International Cryptology Conference. CRYPTO ’21. 2021.</li>

      <li>[BDFLSZ11] D. Boneh, Ö. Dagdelen, M. Fischlin, A. Lehmann, C. Schaffner, and M. Zhandry. “Random Oracles in a Quantum World”. In: Proceedings of the 17th International Conference on the Theory and Application of Cryptology and Information Security. ASIACRYPT ’11. 2011, pp. 41–69.</li>

      <li>[BGH19] S. Bowe, J. Grigg, and D. Hopwood. “Halo: Recursive Proof Composition without a Trusted Setup”. Cryptology ePrint Archive, Report 2019/1021. 2019.</li>

      <li>[BMRS20] J. Bonneau, I. Meckler, V. Rao, and E. Shapiro. “Coda: Decentralized Cryptocurrency at Scale”. Cryptology ePrint Archive, Report 2020/352. 2020.</li>

      <li>[Can+19] R. Canetti, Y. Chen, J. Holmgren, A. Lombardi, G. N. Rothblum, R. D. Rothblum, and D. Wichs. “Fiat–Shamir: from practice to theory”. In: Proceedings of the 51st Annual ACM Symposium on Theory of Computing. STOC ’19. 2019, pp. 1082–1090.</li>

      <li>[CBBZ23] B. Chen, B. Bünz, D. Boneh, and Z. Zhang. “HyperPlonk: Plonk with Linear-Time Prover and High-Degree Custom Gates”. In: Proceedings of the 42nd Annual International Conference on the Theory and Applications of Cryptographic Techniques. EUROCRYPT ’23. 2023, pp. 499–530.</li>

      <li>[CCDW20] W. Chen, A. Chiesa, E. Dauterman, and N. P. Ward. “Reducing Participation Costs via Incremental Verification for Ledger Systems”. Cryptology ePrint Archive, Report 2020/1522. 2020.</li>

      <li>[CMS19] A. Chiesa, P. Manohar, and N. Spooner. “Succinct Arguments in the Quantum Random Oracle Model”. In: Proceedings of the 17th International Conference on the Theory of Cryptography. TCC ’19. 2019, pp. 1–29.</li>

      <li>[COS20] A. Chiesa, D. Ojha, and N. Spooner. “Fractal: Post-Quantum and Transparent Recursive Proofs from Holography”. In: Proceedings of the 39th Annual International Conference on the Theory and Applications of Cryptographic Techniques. EUROCRYPT ’20. 2020.</li>

      <li>[CT10] A. Chiesa and E. Tromer. “Proof-Carrying Data and Hearsay Arguments from Signature Cards”. In: Proceedings of the 1st Symposium on Innovations in Computer Science. ICS ’10. 2010, pp. 310–331.</li>

      <li>[CTV13] S. Chong, E. Tromer, and J. A. Vaughan. “Enforcing Language Semantics Using Proof-Carrying Data”. Cryptology ePrint Archive, Report 2013/513. 2013.</li>

      <li>[CTV15] A. Chiesa, E. Tromer, and M. Virza. “Cluster Computing in Zero Knowledge”. In: Proceedings of the 34th Annual International Conference on Theory and Application of Cryptographic Techniques. EUROCRYPT ’15. 2015, pp. 371–403.</li>

      <li>[DI14] E. Druk and Y. Ishai. “Linear-Time Encodable Codes Meeting the Gilbert-Varshamov Bound and Their Cryptographic Applications”. In: Proceedings of the 5th Innovations in Theoretical Computer Science Conference. ITCS ’14. 2014, pp. 169–182.</li>

      <li>[DMS24] M. Dellepere, P. Mishra, and A. Shirzad. “Garuda and Pari: Faster and Smaller SNARKs via Equifficient Polynomial Commitments”. Cryptology ePrint Archive, Report 2024/1245. 2024.</li>

      <li>[DP23] B. E. Diamond and J. Posen. “Succinct Arguments over Towers of Binary Fields”. Cryptology ePrint Archive, Report 2023/1784. 2023.</li>

    </ul>

    <p class="text-gray-300">[DP24] B. E. Diamond and J. Posen. “Proximity Testing with Logarithmic Randomness”. In: IACR Commun. Cryptol. 1.1 (2024), p. 2.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[EG23] L. Eagen and A. Gabizon. “ProtoGalaxy: Efficient ProtoStar-style folding of multiple instances”. Cryptology ePrint Archive, Report 2023/1106. 2023.</li>

      <li>[GLSTW23] A. Golovnev, J. Lee, S. T. V. Setty, J. Thaler, and R. S. Wahby. “Brakedown: Linear-Time and Field-Agnostic SNARKs for R1CS”. In: Proceedings of the 43rd Annual International Cryptology Conference. CRYPTO ’23. 2023, pp. 193–226.</li>

      <li>[GW19] A. Gabizon and Z. J. Williamson. “The Turbo-Plonk Program Syntax for Specifying Snark Programs”. In: ZKProof Workshop 3. 2019.</li>

      <li>[GW20] A. Gabizon and Z. J. Williamson. “plookup: A simplified polynomial protocol for lookup tables”. Cryptology ePrint Archive, Report 2020/315. 2020.</li>

      <li>[Hol19] J. Holmgren. “On Round-By-Round Soundness and State Restoration Attacks”. Cryptology ePrint Archive, Report 2019/1261. 2019.</li>

      <li>[KB20] A. Kattis and J. Bonneau. “Proof of Necessary Work: Succinct State Verification with Fairness Guarantees”. Cryptology ePrint Archive, Report 2020/190. 2020.</li>

      <li>[KS23] A. Kothapalli and S. Setty. “CycleFold: Folding-scheme-based recursive arguments over a cycle of elliptic curves”. Cryptology ePrint Archive, Report 2023/1192. Aug. 2023.</li>

      <li>[KS24] A. Kothapalli and S. T. V. Setty. “HyperNova: Recursive Arguments for Customizable Constraint Systems”. In: Proceedings of the 44th Annual International Cryptology Conference. CRYPTO ’24. 2024, pp. 345–379.</li>

      <li>[KST22] A. Kothapalli, S. T. V. Setty, and I. Tzialla. “Nova: Recursive Zero-Knowledge Arguments from Folding Schemes”. In: Proceedings of the 42nd Annual International Cryptology Conference. CRYPTO ’22. 2022, pp. 359–388.</li>

      <li>[Mina] O(1) Labs. “Mina Cryptocurrency”. minaprotocol.org. 2020.</li>

      <li>[NBS23] W. D. Nguyen, D. Boneh, and S. T. V. Setty. “Revisiting the Nova Proof System on a Cycle of Curves”. In: Proceedings of the 5th Conference on Advances in Financial Technologies. AFT ’23. 2023, 18:1–18:22.</li>

      <li>[NT16] A. Naveh and E. Tromer. “PhotoProof: Cryptographic Image Authentication for Any Set of Permissible Transformations”. In: Proceedings of the 37th IEEE Symposium on Security and Privacy. S&P ’16. 2016, pp. 255–271.</li>

      <li>[Ped92] T. P. Pedersen. “Non-Interactive and Information-Theoretic Secure Verifiable Secret Sharing”. In: Proceedings of the 11th Annual International Cryptology Conference. CRYPTO ’91. 1992, pp. 129–140.</li>

      <li>[Pol] Polygon Zero Team. “Plonky2: Fast Recursive Arguments with PLONK and FRI”.</li>

      <li>[RRR21] O. Reingold, G. N. Rothblum, and R. D. Rothblum. “Constant-Round Interactive Proofs for Delegating Computation”. In: SIAM Journal on Computing 50.3 (2021).</li>

      <li>[RSM60] I. S. Reed, G. Solomon, and K. H. March. “Polynomial Codes Over Certain Finite Fields”. In: Journal of The Society for Industrial and Applied Mathematics 8 (1960), pp. 300–304.</li>

      <li>[RVW13] G. N. Rothblum, S. P. Vadhan, and A. Wigderson. “Interactive proofs of proximity: delegating computation in sublinear time”. In: Proceedings of the 45th ACM Symposium on the Theory of Computing. STOC ’13. 2013, pp. 793–802.</li>

      <li>[Spi96] D. A. Spielman. “Linear-time encodable and decodable error-correcting codes”. In: IEEE Transactions on Information Theory 42.6 (1996), pp. 1723–1731.</li>

      <li>[Sta21] StarkWare. “ethSTARK Documentation”. Cryptology ePrint Archive, Report 2021/582. 2021.</li>

    </ul>

    <p class="text-gray-300">[Val08] P. Valiant. “Incrementally Verifiable Computation or Proofs of Knowledge Imply Time/Space Efficiency”. In: <em>Proceedings of the 5th Theory of Cryptography Conference</em>. TCC ’08. 2008, pp. 1–18.</p>`;
---

<BaseLayout title="Accumulation without Homomorphism (2024/474)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2024 &middot; eprint 2024/474
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
