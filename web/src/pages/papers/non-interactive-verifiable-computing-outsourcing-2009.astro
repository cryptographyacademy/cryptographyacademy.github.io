---
import BaseLayout from '../../layouts/BaseLayout.astro';
import PaperDisclaimer from '../../components/PaperDisclaimer.astro';
import PaperHistory from '../../components/PaperHistory.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2009/547';
const CRAWLER = 'marker';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Non-Interactive Verifiable Computing: Outsourcing Computation to Untrusted Workers';
const AUTHORS_HTML = 'Rosario Gennaro, Craig Gentry, Bryan Parno';

const CONTENT = `    <p class="text-gray-300">Rosario Gennaro† Craig Gentry‡ Bryan Parno§ February 1, 2010</p>

    <h4 id="sec-2" class="text-lg font-semibold mt-6"><strong>Abstract</strong></h4>

    <p class="text-gray-300"><em>Verifiable Computation</em> enables a computationally weak client to "outsource" the computation of a function <em>F</em> on various inputs <em>x</em>1,...,<em>x<sup>k</sup></em> to one or more workers. The workers return the result of the function evaluation, e.g., <em>y<sup>i</sup></em> = <em>F</em>(<em>xi</em>), as well as a proof that the computation of <em>F</em> was carried out correctly on the given value <em>x<sup>i</sup></em> . The verification of the proof should require substantially less computational effort than computing <em>F</em>(<em>xi</em>) from scratch.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We present a protocol that allows the worker to return a computationally-sound, non-interactive proof that can be verified in <em>O</em>(<em>m</em>) time, where <em>m</em> is the bit-length of the output of <em>F</em>. The protocol requires a one-time pre-processing stage by the client which takes <em>O</em>(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><em>C</em></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">) time, where <em>C</em> is the smallest Boolean circuit computing <em>F</em>. Our scheme also provides input and output privacy for the client, meaning that the workers do not learn any information about the <em>x<sup>i</sup></em> or <em>y<sup>i</sup></em> values.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Several trends are contributing to a growing desire to "outsource" computing from a (relatively) weak computational device to a more powerful computation service. For years, a variety of projects, including SETI@Home [5], Folding@Home [2], and the Mersenne prime search [4], have distributed computations to millions of clients around the Internet to take advantage of their idle cycles. A perennial problem is dishonest clients: end users who modify their client software to return plausible results without performing any actual work [22]. Users commit such fraud, even when the only incentive is to increase their relative ranking on a website listing. Many projects cope with such fraud via redundancy; the same work unit is sent to several clients and the results are compared for consistency. Apart from wasting resources, this provides little defense against colluding users.</p>

    <p class="text-gray-300">A related fear plagues cloud computing, where businesses buy computing time from a service, rather than purchase, provision, and maintain their own computing resources [1, 3]. Sometimes the applications outsourced to the cloud are so critical that it is imperative to rule out accidental errors during the computation. Moreover, in such arrangements, the business providing the computing services may have a strong financial incentive to return incorrect answers, if such answers require less work and are unlikely to be detected by the client.</p>

    <p class="text-gray-300"><sup>∗</sup>This research was supported in part by the US Army Research laboratory and the UK Ministry of Defence under Agreement Number W911NF-06-3-0001, as well as by the National Science Foundation (NSF), under award number CCF-0424422. Bryan Parno was supported in part by an NSF Graduate Research Fellowship. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the US Army Research Laboratory, U.S. Government, UK Ministry of Defense, UK Government, or NSF. The US and UK Governments are authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation hereon.</p>

    <p class="text-gray-300"><sup>†</sup> IBM T.J.Watson Research Center. rosario@us.ibm.com</p>

    <p class="text-gray-300"><sup>‡</sup> IBM T.J.Watson Research Center. cbgentry@us.ibm.com</p>

    <p class="text-gray-300"><sup>§</sup>CyLab, Carnegie Mellon University. parno@cmu.edu</p>

    <p class="text-gray-300">The proliferation of mobile devices, such as smart phones and netbooks, provides yet another venue in which a computationally weak device would like to be able to outsource a computation, e.g., a cryptographic operation or a photo manipulation, to a third-party and yet obtain a strong assurance that the result returned is correct.</p>

    <p class="text-gray-300">In all of these scenarios, a key requirement is that the amount of work performed by the client to generate and verify work instances must be substantially cheaper than performing the computation on its own. It is also desirable to keep the work performed by the workers as close as possible to the amount of work needed to compute the original function. Otherwise, the worker may be unable to complete the task in a reasonable amount of time, or the cost to the client may become prohibitive.</p>

    <p class="text-gray-300">PRIOR WORK: In the security community, research has focused on solutions based on audits and various forms of secure co-processors. Audit-based solutions [9, 23] typically require the client (or randomly selected workers) to recalculate some portion of the work done by untrusted workers. This may be infeasible for resource-constrained clients and often relies on some fraction of the workers to be honest, or at least non-colluding. Audits based on the time taken to compute the result [25] require detailed knowledge of the hardware employed by the worker.</p>

    <p class="text-gray-300">Secure co-processors [26, 30] provide isolated execution environments, but their tamper-resistance typically makes them quite expensive (thousands of dollars each) and sparsely deployed. The requirements of tamper-resistance also lead to the use of weak CPUs to limit the amount of heat dissipation needed. The growing ubiquity of Trusted Platform Modules (TPMs) [27] in commodity machines promises to improve platform security, but TPMs have achieved widespread deployment in part due to reduced costs (one to five dollars each) that result in little to no physical tamper resistance.</p>

    <p class="text-gray-300">In the cryptographic community, the idea to outsource expensive cryptographic operations to a semitrusted device has a long history. Chaum and Pedersen define the notion of <em>wallets with observers</em> [10], a piece of secure hardware installed by a third party, e.g. a bank, on the client's computer to "help" with expensive computations. The hardware is not trusted by the client who retains assurance that it is performing correctly by analyzing its communication with the bank. Hohenberger and Lysyanskaya formalize this model [16], and present protocols for the computation of modular exponentiations (arguably the most expensive step in public-key cryptography operations). Their protocol requires the client to interact with <em>two</em> non-colluding servers. Other work targets specific function classes, such as one-way function inversion [15].</p>

    <p class="text-gray-300">Recent advances in fully-homomorphic encryption [12] allow a worker to compute arbitrary functions over encrypted data, but they do not suffice to provide outsourceable computing. Indeed, fully-homomorphic encryption provides <em>no guarantee</em> that the worker performed the correct computation. While our solution does employ fully-homomorphic encryption, we combine it with other techniques to provide verifiability.</p>

    <p class="text-gray-300">The theoretical community has devoted considerable attention to the verifiable computation of arbitrary functions. <em>Interactive proofs</em> [6, 14] are a way for a powerful (e.g. super-polynomial) prover to (probabilistically) convince a weak (e.g. polynomial) verifier of the truth of statements that the verifier could not compute on its own. As it is well known, the work on interactive proofs lead to the concept of <em>probabilistically checkable proofs</em> (PCPs), where a prover can prepare a proof that the verifier can check in only very few places (in particular only a constant number of bits of the proofs needed for NP languages). Notice, however, that the PCP proof might be very long, potentially too long for the verifier to process. To avoid this complication, Kilian proposed the use of efficient arguments<sup>1</sup> [18,19] in which the prover sends the verifier a short commitment to the entire proof using a Merkle tree. The prover can then interactively open the bits requested by the verifier (this requires the use of a collision-resistant hash function). A non-interactive solution can be obtained using Micali's CS Proofs [21], which remove interaction from the above argument</p>

    <p class="text-gray-300"><sup>1</sup>We follow the standard terminology: an <em>argument</em> is a computationally sound proof, i.e. a protocol in which the prover is assumed to be computationally bounded. In an argument, an infinitely powerful prover can convince the verifier of a false statement, as opposed to a proof where this is information-theoretically impossible or extremely unlikely.</p>

    <p class="text-gray-300">by choosing the bits to open based on the application of a random oracle to the commitment string. In more recent work, which still uses some of the standard PCP machinery, Goldwasser et al. [13] show how to build an interactive proof to verify arbitrary polynomial time computations in almost linear time. They also extend the result to a non-interactive argument for a restricted class of functions.</p>

    <p class="text-gray-300">Therefore, if we restrict our attention to non-interactive protocols, the state of the art offers either Micali's CS Proofs [21] which are arguments that can only be proven in the random oracle model, or the arguments from [13] that can only be used for a restricted class of functions.</p>

    <p class="text-gray-300">OUR CONTRIBUTION. We slightly move away from the notions of proofs and arguments, to define the notion of a <em>Verifiable Computation Scheme</em>: this is a protocol between two polynomial time parties, a <em>client</em> and a <em>worker</em>, to collaborate on the computation of a function <em>F</em> : {0,1} <em><sup>n</sup></em> → {0,1} <em><sup>m</sup></em>. Our definition uses an amortized notion of complexity for the client: he can perform some expensive pre-processing, but after this stage, he is required to run very efficiently. More specifically, a verifiable computation scheme consists of three phases:</p>

    <p class="text-gray-300"><strong>Preprocessing</strong> A one-time stage in which the client computes some auxiliary (public and private) information associated with <em>F</em>. This phase can take time comparable to computing the function from scratch, but it is performed only once, and its cost is amortized over all the future executions.</p>

    <p class="text-gray-300"><strong>Input Preparation</strong> When the client wants the worker to compute <em>F</em>(<em>x</em>), it prepares some auxiliary (public and private) information about <em>x</em>. The public information is sent to the worker.</p>

    <p class="text-gray-300"><strong>Output Computation and Verification</strong> Once the worker has the public information associated with <em>F</em> and <em>x</em>, it computes a string π<em><sup>x</sup></em> which encodes the value <em>F</em>(<em>x</em>) and returns it to the client. From the value π<em>x</em>, the client can compute the value <em>F</em>(<em>x</em>) and verify its correctness.</p>

    <p class="text-gray-300">Notice that this is inherently a non-interactive protocol: the client sends a single message to the worker and vice versa. The crucial efficiency requirement is that Input Preparation and Output Verification must take less time than computing <em>F</em> from scratch (ideally linear time, <em>O</em>(<em>n</em> + <em>m</em>)). Also, the Output Computation stage should take roughly the same amount of computation as <em>F</em>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">After formally defining the notion of verifiable computation, we present a verifiable computation scheme for <em>any</em> function. Assume that the function <em>F</em> is described by a Boolean circuit <em>C</em>. Then the Preprocessing stage of our protocol takes time <em>O</em>(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><em>C</em></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">), i.e., time comparable to computing the function from scratch. Apart from that, the client runs in linear time, as Input Preparation takes <em>O</em>(<em>n</em>) time and Output Verification takes <em>O</em>(<em>m</em>) time. Finally the worker takes time <em>O</em>(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><em>C</em></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">) to compute the function for the client.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The computational assumptions underlying the security of our scheme are the security of block ciphers (i.e., the existence of one-way functions) and the existence of a secure fully homomorphic encryption scheme [11,12] (more details below). We stress that our non-interactive protocol works for <em>any</em> function (as opposed to Goldwasser et al.'s protocol [13] which works only for a restricted class of functions) and can be proven in the standard model (as opposed to Micali's proofs [21] which require the random oracle model).</p>

    <p class="text-gray-300"><em>Motivation:</em> In our setting, the client must still perform an expensive one-time preprocessing phase. After that, in our scheme, the client runs in linear time. Since the preprocessing stage happens only once, it is important to stress that it can be performed in a trusted environment where the weak client, who does not have the computational power to perform it, outsources it to a trusted party (think of a military application in which the client loads the result of the preprocessing stage performed inside the military base by a trusted server, and then goes off into the field where outsourcing servers may not be trusted anymore – or think of the preprocessing phase executed on the client's home machine and then used by his portable device in the field).</p>

    <p class="text-gray-300"><em>Dynamic and Adaptive Input Choice.</em> We note that in this amortized model of computation, Goldwasser et al.'s protocol [13] can be modified using Kalai and Raz's transformation [17] to achieve a non-interactive scheme (see [24]). However an important feature of our scheme, that is not enjoyed by Goldwasser et al.'s protocol [13], is that the inputs to the computation of <em>F</em> can be chosen in a dynamic and adaptive fashion throughout the execution of the protocol (as opposed to [13] where they must be fixed and known in advance).</p>

    <p class="text-gray-300"><em>Privacy.</em> We also note that our construction has the added benefit of providing input and output privacy for the client, meaning that the worker does not learn any information about <em>x</em> or <em>F</em>(<em>x</em>) (details below). This privacy feature is bundled into the protocol and comes at no additional cost. This is a very important aspect, which should be considered a requirement in real-life applications. After all, if you don't trust the worker to compute the function correctly, why would you trust him with the knowledge of your input data? Homomorphic encryption already solves the problem of computing over private data, but it does not address the problem of efficiently verifying the result. Our work therefore is the first to provide a weak client with the ability to efficiently and verifiably offload computation to an untrusted server in such a way that the input remains secret.</p>

    <p class="text-gray-300">OUR SOLUTION IN A NUTSHELL. Our work is based on the crucial (and somewhat surprising) observation that Yao's Garbled Circuit Construction [28,29], in addition to providing secure two-party computation, also provides a "one-time" verifiable computation. In other words, we can adapt Yao's construction to allow a client to outsource the computation of a function on a single input. More specifically, in the preprocessing stage the client garbles the circuit <em>C</em> according to Yao's construction. Then in the "input preparation" stage, the client reveals the random labels associated with the input bits of <em>x</em> in the garbling. This allows the worker to compute the random labels associated with the output bits, and from them the client will reconstruct <em>F</em>(<em>x</em>). If the output bit labels are sufficiently long and random, the worker will not be able to guess the labels for an incorrect output, and therefore the client is assured that <em>F</em>(<em>x</em>) is the correct output.</p>

    <p class="text-gray-300">Unfortunately, reusing the circuit for a second input <em>x</em> ′ is insecure, since once the output labels of <em>F</em>(<em>x</em>) are revealed, nothing can stop the worker from presenting those labels as correct for <em>F</em>(<em>x</em> ′ ). Creating a new garbled circuit requires as much work as if the client computed the function itself, so on its own, Yao's Circuits do not provide an efficient method for outsourcing computation.</p>

    <p class="text-gray-300">The second crucial idea of the paper is to combine Yao's Garbled Circuit with a fully homomorphic encryption system (e.g., Gentry's recent proposal [12]) to be able to safely reuse the garbled circuit for multiple inputs. More specifically, instead of revealing the labels associated with the bits of input <em>x</em>, the client will encrypt those labels under the public key of a fully homomorphic scheme. A new public key is generated for every input in order to prevent information from one execution from being useful for later executions. The worker can then use the homomorphic property to compute an encryption of the output labels and provide them to the client, who decrypts them and reconstructs <em>F</em>(<em>x</em>).</p>

    <p class="text-gray-300">Since we use the fully-homomorphic encryption scheme in a black-box fashion, we anticipate that any performance improvements in future schemes will directly result in similar performance gains for our protocol as well.</p>

    <p class="text-gray-300"><em>One pre-processing step for many workers:</em> Note that the pre-processing stage is independent of the worker, since it simply produces a Yao-garbled version of the circuit <em>C</em>. Therefore, in addition to being reused many times, this garbled circuit can also be sent to many different workers, which is the usage scenario for applications like Folding@Home [2], which employ a multitude of workers across the Internet.</p>

    <p class="text-gray-300"><em>How to handle malicious workers.</em> In our scheme, if we assume that the worker learns whether or not the client accepts the proof π<em>x</em>, then for every execution, a malicious worker potentially learns a bit of information about the labels of the Yao-garbled circuit. For example, the worker could try to guess one of the labels, encrypt it with the homomorphic encryption and see if the client accepts. In a sense, the output of the client at the end of the execution can be seen as a very restricted "decryption oracle" for the homomorphic encryption scheme (which is, by definition, not CCA secure). Because of this one-bit leakage, we are unable to prove security in this case.</p>

    <p class="text-gray-300">There are two ways to deal with this. One is to assume that the verification output bit by the client remains private. The other is to repeat the pre-processing stage, i.e. the Yao garbling of the circuit, every</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">wa</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">wb</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">wz</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">wa</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">wb</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">wz</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">wa</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">wb</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">wz</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">wa<br>wb<br>g<br>wz</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">g(0,0)</td>

            <td class="px-3 py-2 border-b border-gray-700">0<br>k<br>a</td>

            <td class="px-3 py-2 border-b border-gray-700">0<br>k<br>b</td>

            <td class="px-3 py-2 border-b border-gray-700">g(0,0)<br>k<br>z</td>

            <td class="px-3 py-2 border-b border-gray-700">0<br>k<br>a</td>

            <td class="px-3 py-2 border-b border-gray-700">0<br>k<br>b</td>

            <td class="px-3 py-2 border-b border-gray-700">g(0,0)<br>Ek<br>(Ek<br>(k<br>))<br>z<br>0<br>0<br>a<br>b</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">g(0,1)</td>

            <td class="px-3 py-2 border-b border-gray-700">0<br>k<br>a</td>

            <td class="px-3 py-2 border-b border-gray-700">1<br>k<br>b</td>

            <td class="px-3 py-2 border-b border-gray-700">g(0,1)<br>k<br>z</td>

            <td class="px-3 py-2 border-b border-gray-700">0<br>k<br>a</td>

            <td class="px-3 py-2 border-b border-gray-700">1<br>k<br>b</td>

            <td class="px-3 py-2 border-b border-gray-700">g(0,1)<br>Ek<br>(Ek<br>(k<br>))<br>z<br>0<br>1<br>a<br>b</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">0</td>

            <td class="px-3 py-2 border-b border-gray-700">g(1,0)</td>

            <td class="px-3 py-2 border-b border-gray-700">1<br>k<br>a</td>

            <td class="px-3 py-2 border-b border-gray-700">0<br>k<br>b</td>

            <td class="px-3 py-2 border-b border-gray-700">g(1,0)<br>k<br>z</td>

            <td class="px-3 py-2 border-b border-gray-700">1<br>k<br>a</td>

            <td class="px-3 py-2 border-b border-gray-700">0<br>k<br>b</td>

            <td class="px-3 py-2 border-b border-gray-700">g(1,0)<br>Ek<br>(Ek<br>(k<br>))<br>z<br>1<br>0<br>a<br>b</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">g(1,1)</td>

            <td class="px-3 py-2 border-b border-gray-700">1<br>k<br>a</td>

            <td class="px-3 py-2 border-b border-gray-700">1<br>k<br>b</td>

            <td class="px-3 py-2 border-b border-gray-700">g(1,1)<br>k<br>z</td>

            <td class="px-3 py-2 border-b border-gray-700">1<br>k<br>a</td>

            <td class="px-3 py-2 border-b border-gray-700">1<br>k<br>b</td>

            <td class="px-3 py-2 border-b border-gray-700">g(1,1)<br>Ek<br>(Ek<br>(k<br>))<br>z<br>1<br>1<br>a<br>b</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">(a)</td>

            <td class="px-3 py-2 border-b border-gray-700">(b)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">(c)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">(d)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Figure 1: <strong>Yao's Garbled Circuits.</strong> <em>The original binary gate</em> <strong>(a)</strong> <em>can be represented by a standard truth table</em> <strong>(b)</strong><em>. We then replace the 0 and 1 values with the corresponding randomly chosen</em> λ<em>-bit values</em> <strong>(c)</strong><em>. Finally, we use the values for w<sup>a</sup> and w<sup>b</sup> to encrypt the values for the output wire w<sup>z</sup></em> <strong>(d)</strong><em>. The random permutation of these ciphertexts is the garbled representation of gate g.</em></p>

    <p class="text-gray-300">time a verification fails. In this case, in order to preserve a good amortized complexity, we must assume that failures do not happen very often. This is indeed the case in the previous scenario, where the same garbled circuit is used with several workers, under the assumption that only a small fraction of workers will be malicious. Details appear in Section 5.</p>

    <h2 id="sec-4" class="text-2xl font-bold"><strong>2 Background</strong></h2>

    <h4 id="sec-5" class="text-lg font-semibold mt-6"><strong>2.1 Yao's Garbled Circuit Construction</strong></h4>

    <p class="text-gray-300">We summarize Yao's protocol for two-party private computation [28, 29]. For more details, we refer the interested reader to Lindell and Pinkas' excellent description [20].</p>

    <p class="text-gray-300">We assume two parties, Alice and Bob, wish to compute a function <em>F</em> over their private inputs <em>a</em> and <em>b</em>. For simplicity, we focus on polynomial-time deterministic functions, but the generalization to stochastic functions is straightforward.</p>

    <p class="text-gray-300">At a high-level, Alice converts <em>F</em> into a boolean circuit <em>C</em>. She prepares a garbled version of the circuit, <em>G</em>(<em>C</em>), and sends it to Bob, along with a garbled version, <em>G</em>(<em>a</em>), of her input. Alice and Bob then engage in a series of oblivious transfers so that Bob obtains <em>G</em>(<em>b</em>) without Alice learning anything about <em>b</em>. Bob then applies the garbled circuit to the two garbled outputs to derive a garbled version of the output: <em>G</em>(<em>F</em>(<em>a</em>,<em>b</em>)). Alice can then translate this into the actual output and share the result with Bob. Note that this protocol assumes an honest-but-curious adversary model.</p>

    <p class="text-gray-300">In more detail, Alice constructs the garbled version of the circuit as follows. For each wire <em>w</em> in the circuit, Alice chooses two random values <em>k</em> 0 <em>w</em> , <em>k</em> 1 <em>w <sup>R</sup></em>← {0,1} λ to represent the bit values of 0 or 1 on that wire. Once she has chosen wire values for every wire in the circuit, Alice constructs a garbled version of each gate <em>g</em> (see Figure 1). Let <em>g</em> be a gate with input wires <em>w<sup>a</sup></em> and <em>wb</em>, and output wire <em>w<sup>z</sup></em> . Then the garbled version <em>G</em>(<em>g</em>) of <em>g</em> is simply four ciphertexts:</p>

    <div class="my-4 text-center"><span class="math-block">\\gamma_{00} = E_{k_a^0}(E_{k_b^0}(k_z^{g(0,0)})), \\ \\gamma_{01} = E_{k_a^0}(E_{k_b^1}(k_z^{g(0,1)})), \\ \\gamma_{10} = E_{k_a^1}(E_{k_b^0}(k_z^{g(1,0)})), \\ \\gamma_{11} = E_{k_a^1}(E_{k_b^1}(k_z^{g(1,1)})), \\ (1)</span></div>

    <p class="text-gray-300">where <em>E</em> is an secure symmetric encryption scheme with an "elusive range" (more details below). The order of the ciphertexts is randomly permuted to hide the structure of the circuit (i.e., we shuffle the ciphertexts, so that the first ciphertext does not necessarily encode the output for (0,0)).</p>

    <p class="text-gray-300">We refer to <em>w</em> 0 <em>z</em> and <em>w</em> 1 <em>z</em> as the "acceptable" outputs for gate <em>g</em>, since they are the only two values that represent valid bit-values for the output wire. Given input keys <em>k x a</em> , <em>k y b</em> , we will refer to <em>w g</em>(<em>x</em>,<em>y</em>) <em><sup>z</sup></em> as the "legitimate" output, and <em>w</em> 1−<em>g</em>(<em>x</em>,<em>y</em>) <em><sup>z</sup></em> as the "illegitimate" output.</p>

    <p class="text-gray-300">In Yao's protocol, Alice transfers all of the ciphertexts to Bob, along with the wire values corresponding to the bit-level representation of her input. In other words, she transfers either <em>k</em> 0 <em>a</em> if her input bit is 0 or <em>k</em> 1 <em>a</em> if</p>

    <p class="text-gray-300">her input bit is 1. Since these are randomly chosen values, Bob learns nothing about Alice's input. Alice and Bob then engage in an oblivious transfer so that Bob can obtain the wire values corresponding to his inputs (e.g.,  <span class="math">k_b^0</span>  or  <span class="math">k_b^1</span> ). Bob learns exactly one value for each wire, and Alice learns nothing about his input. Bob can then use the wire values to recursively decrypt the gate ciphertexts, until he arrives at the final output wire values. When he transmits these to Alice, she can map them back to 0 or 1 values and hence obtain the result of the function computation.</p>

    <h3 id="sec-6" class="text-xl font-semibold mt-8">2.2 The Security of Yao's Protocol</h3>

    <p class="text-gray-300">Lindell and Pinkas prove [20] that Yao is a secure two-party computation protocol under some specific assumptions on the encryption scheme E used to garble the circuit. More specifically the encryption function E needs:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Indistinguishable ciphertexts for multiple messages: For every two vectors of messages  <span class="math">\\overline{x}</span>  and  <span class="math">\\overline{y}</span> , no polynomial time adversary can distinguish between an encryption of  <span class="math">\\overline{x}</span>  and an encryption of  <span class="math">\\overline{y}</span> . Notice that because we require security for multiple messages, we cannot use a one-time pad.</li>

      <li>An elusive range: Encryptions under different keys fall into different ranges of the ciphertext space (at least with high probability).</li>

      <li>An efficiently verifiable range: Given the key k, it is possible to decide efficiently if a given ciphertext falls into the range of encryptions under k.</li>

    </ul>

    <p class="text-gray-300">We give a formal definition of these properties. Recall that a private encryption scheme is a pair of algorithms (E,D), the encryption and decryption algorithms respectively, that run on input the security parameter  <span class="math">\\lambda</span> , a random  <span class="math">\\lambda</span> -bit key k, and  <span class="math">\\lambda</span> -bit strings (the plaintext and ciphertext, respectively). In the following negli() denotes a negligible function of its input.</p>

    <p class="text-gray-300"><strong>Definition 1</strong> We say that a private encryption scheme (E,D) is Yao-secure if the following properties are satisfied. Assume  <span class="math">k \\leftarrow \\{0,1\\}^{\\lambda}</span> :</p>

    <p class="text-gray-300">• Indistinguishability of ciphertexts for multiple messages: For every efficient adversary A, and every two vectors of ciphertexts  <span class="math">[x_1,...,x_\\ell]</span>  and  <span class="math">[y_1,...,y_\\ell]</span>  (with  <span class="math">\\ell = poly(\\lambda)</span> ), and  <span class="math">u_i = E_k(x_i)</span> ,  <span class="math">z_i = E_k(y_i)</span> , we have that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathit{Prob}[\\mathit{A}[\\mathit{u}_1,\\ldots,\\mathit{u}_\\ell]=1] - \\mathit{Prob}[\\mathit{A}[\\mathit{z}_1,\\ldots,\\mathit{z}_\\ell]=1]</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">< \\mathit{negli}(\\lambda)$$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">• Elusive Range: Let  <span class="math">\\mathsf{Range}_{\\lambda}(k) = \\{E_k(x)\\}_{x \\in \\{0,1\\}^{\\lambda}}</span> . For every efficient adversary A we require:</p>

    <div class="my-4 text-center"><span class="math-block">Prob[A(1^{\\lambda}) \\in \\mathsf{Range}_{\\lambda}(k)] &lt; \\mathit{negli}(\\lambda)</span></div>

    <p class="text-gray-300">• Efficiently Verifiable Range: There exists an efficient machine M such that M(k,c) = 1 if and only if  <span class="math">c \\in \\mathsf{Range}_{\\lambda}(k)</span> .</p>

    <p class="text-gray-300">Lindell and Pinkas show [20] that Yao's garbled circuit technique, combined with a secure oblivious transfer protocol, is a secure two-party computation protocol (for semi-honest parties) if E is Yao-secure. They also show how to build Yao-secure encryption schemes based on one-way functions.</p>

    <h4 id="sec-7" class="text-lg font-semibold mt-6">2.3 Fully-Homomorphic Encryption</h4>

    <p class="text-gray-300">A fully-homomorphic encryption scheme  <span class="math">\\mathcal{E}</span>  is defined by four algorithms: the standard encryption functions  <span class="math">\\mathbf{KeyGen}_{\\mathcal{E}}</span> ,  <span class="math">\\mathbf{Encrypt}_{\\mathcal{E}}</span> , and  <span class="math">\\mathbf{Decrypt}_{\\mathcal{E}}</span> , as well as a fourth function  <span class="math">\\mathbf{Evaluate}_{\\mathcal{E}}</span> .  <span class="math">\\mathbf{Evaluate}_{\\mathcal{E}}</span>  takes in a circuit C and a tuple of ciphertexts and outputs a ciphertext that decrypts to the result of applying C to the plaintexts. A nontrivial scheme requires that  <span class="math">\\mathbf{Encrypt}_{\\mathcal{E}}</span>  and  <span class="math">\\mathbf{Decrypt}_{\\mathcal{E}}</span>  operate in time independent of C [11, 12]. More precisely, the time needed to generate a ciphertext for an input wire of C, or decrypt a ciphertext for an output wire, is polynomial in the security parameter of the scheme (independent of C). Note that this implies that</p>

    <p class="text-gray-300">the length of the ciphertexts for the output wires is bounded by some polynomial in the security parameter (independent of <em>C</em>).</p>

    <p class="text-gray-300">Gentry recently proposed a scheme, based on ideal lattices, that satisfies these requirements for arbitrary circuits [11, 12]. The complexity of <strong>KeyGen</strong><em>E</em> in his initial <em>leveled</em> fully homomorphic encryption scheme grows linearly with the depth of <em>C</em>. However, under the assumption that his encryption scheme is <em>circular secure</em> – i.e., roughly, that it is "safe" to reveal an encryption of a secret key under its associated public key – the complexity of <strong>KeyGen</strong><em>E</em> is independent of <em>C</em>. See [8, 11, 12] for more discussion on circular-security (and, more generally, key-dependent-message security) as it relates to fully homomorphic encryption.</p>

    <p class="text-gray-300">In this paper, we use fully homomorphic encryption as a black box, and therefore do not discuss the details of any specific scheme.</p>

    <p class="text-gray-300">At a high-level, a verifiable computation scheme is a two-party protocol in which a <em>client</em> chooses a function and then provides an encoding of the function and inputs to the function to a <em>worker</em>. The worker is expected to evaluate the function on the input and respond with the output. The client then verifies that the output provided by the worker is indeed the output of the function computed on the input provided.</p>

    <h3 id="sec-9" class="text-xl font-semibold mt-8"><strong>3.1 Basic Requirements</strong></h3>

    <p class="text-gray-300">A <em>verifiable computation scheme V C</em> = (<strong>KeyGen</strong>,<strong>ProbGen</strong>,<strong>Compute</strong>,<strong>Verify</strong>) consists of the four algorithms defined below.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>1. <strong>KeyGen</strong>(<em>F</em>,λ) → (<em>PK</em>,<em>SK</em>): Based on the security parameter λ, the randomized <em>key generation</em> algorithm generates a public key that encodes the target function <em>F</em>, which is used by the worker to compute <em>F</em>. It also computes a matching secret key, which is kept private by the client.</li>

      <li>2. <strong>ProbGen</strong><em>SK</em>(<em>x</em>) → (σ<em>x</em>, τ<em>x</em>): The <em>problem generation</em> algorithm uses the secret key <em>SK</em> to encode the function input <em>x</em> as a public value σ<em><sup>x</sup></em> which is given to the worker to compute with, and a secret value τ<em><sup>x</sup></em> which is kept private by the client.</li>

      <li>3. <strong>Compute</strong><em>PK</em>(σ<em>x</em>) → σ<em>y</em>: Using the client's public key and the encoded input, the worker <em>computes</em> an encoded version of the function's output <em>y</em> = <em>F</em>(<em>x</em>).</li>

      <li>4. <strong>Verify</strong><em>SK</em>(τ<em>x</em>,σ<em>y</em>) → <em>y</em> ∪ ⊥: Using the secret key <em>SK</em> and the secret "decoding" τ<em>x</em>, the <em>verification</em> algorithm converts the worker's encoded output into the output of the function, e.g., <em>y</em> = <em>F</em>(<em>x</em>) or outputs ⊥ indicating that σ<em><sup>y</sup></em> does not represent the valid output of <em>F</em> on <em>x</em>.</li>

    </ul>

    <p class="text-gray-300">A verifiable computation scheme should be both correct and secure. A scheme is correct if the problem generation algorithm produces values that allows an honest worker to compute values that will verify successfully and correspond to the evaluation of <em>F</em> on those inputs. More formally:</p>

    <p class="text-gray-300"><strong>Definition 2 (Correctness)</strong> <em>A verifiable computation scheme V C is</em> correct <em>if for any choice of function F, the key generation algorithm produces keys</em> (<em>PK</em>,<em>SK</em>) ← <strong>KeyGen</strong>(<em>F</em>,λ) <em>such that,</em> ∀<em>x</em> ∈ Domain(<em>F</em>)<em>, if</em> (σ<em>x</em>, τ<em>x</em>) ← <strong>ProbGen</strong><em>SK</em>(<em>x</em>) <em>and</em> σ<em><sup>y</sup></em> ← <strong>Compute</strong><em>PK</em>(σ<em>x</em>) <em>then y</em> = <em>F</em>(<em>x</em>) ← <strong>Verify</strong><em>SK</em>(τ<em>x</em>,σ<em>y</em>)<em>.</em></p>

    <p class="text-gray-300">Intuitively, a verifiable computation scheme is secure if a malicious worker cannot persuade the verification algorithm to accept an incorrect output. In other words, for a given function <em>F</em> and input <em>x</em>, a malicious worker should not be able to convince the verification algorithm to output ˆ<em>y</em> such that <em>F</em>(<em>x</em>) 6= <em>y</em>ˆ. Below, we formalize this intuition with an experiment, where <em>poly</em>(·) is a polynomial.</p>

    <pre><code class="language-text">Experiment \\mathbf{Exp}_{A}^{Verif}[\\mathcal{VC},F,\\lambda]

(PK,SK) \\stackrel{R}{\\leftarrow} \\mathbf{KeyGen}(F,\\lambda);

For i=1,\\ldots,\\ell=poly(\\lambda);

x_i \\leftarrow A(PK,x_1,\\sigma_1,\\ldots,x_i,\\sigma_i);

(\\sigma_i,\\tau_i) \\leftarrow \\mathbf{ProbGen}_{SK}(x_i);

(i,\\hat{\\sigma}_y) \\leftarrow A(PK,x_1,\\sigma_1,\\ldots,x_\\ell,\\sigma_\\ell);

\\hat{y} \\leftarrow \\mathbf{Verify}_{SK}(\\tau_i,\\hat{\\sigma}_y)

If \\hat{y} \\neq \\bot and \\hat{y} \\neq F(x_i), output &#x27;1&#x27;, else &#x27;0&#x27;;</code></pre>

    <p class="text-gray-300">Essentially, the adversary is given oracle access to generate the encoding of multiple problem instances. The adversary succeeds if it produces an output that convinces the verification algorithm to accept on the wrong output value for a given input value. We can now define the security of the system based on the adversary's success in the above experiment.</p>

    <p class="text-gray-300"><strong>Definition 3 (Security)</strong> For a verifiable computation scheme VC, we define the advantage of an adversary A in the experiment above as:</p>

    <p class="text-gray-300"><span class="math-block">Adv_A^{Verif}(\\mathcal{VC}, F, \\lambda) = Prob[\\mathbf{Exp}_A^{Verif}[\\mathcal{VC}, F, \\lambda] = 1]</span> (2)</p>

    <p class="text-gray-300">A verifiable computation scheme VC is secure for a function F, if for any adversary A running in probabilistic polynomial time,</p>

    <div class="my-4 text-center"><span class="math-block">Adv_A^{Verif}(\\mathcal{VC}, F, \\lambda) \\le \\text{negli}(\\lambda) \\tag{3}</span></div>

    <p class="text-gray-300">where negli() is a negligible function of its input.</p>

    <p class="text-gray-300">In the above definition, we could have also allowed the adversary to select the function F. However, our protocol is a verifiable computation scheme that is secure for <em>all</em> F, so the above definition suffices.</p>

    <h4 id="sec-10" class="text-lg font-semibold mt-6">3.2 Input and Output Privacy</h4>

    <p class="text-gray-300">While the basic definition of a verifiable computation protects the integrity of the computation, it is also desirable that the scheme protect the secrecy of the input given to the worker(s). We define input privacy based on a typical indistinguishability argument that guarantees that <em>no</em> information about the inputs is leaked. Input privacy, of course, immediately yields output privacy.</p>

    <p class="text-gray-300">Intuitively, a verifiable computation scheme is <em>private</em> when the public outputs of the problem generation algorithm <strong>ProbGen</strong> over two different inputs are indistinguishable; i.e., nobody can decide which encoding is the correct one for a given input. More formally consider the following experiment: the adversary is given the public key for the scheme and selects two inputs  <span class="math">x_0, x_1</span> . He is then given the encoding of a randomly selected one of the two inputs and must guess which one was encoded. During this process the adversary is allowed to request the encoding of any input he desires. The experiment is described below. The oracle <strong>PubProbGen</strong><sub>SK</sub>(x) calls <strong>ProbGen</strong><sub>SK</sub>(x) to obtain ( <span class="math">x_1, x_2</span> ) and returns only the public part  <span class="math">x_2</span> .</p>

    <pre><code class="language-text">Experiment \\operatorname{Exp}_{A}^{Priv}[\\mathcal{VC},F,\\lambda]

(PK,SK) \\stackrel{R}{\\leftarrow} \\operatorname{KeyGen}(F,\\lambda);

(x_0,x_1) \\leftarrow A^{\\operatorname{PubProbGen}_{SK}(\\cdot)}(PK)

(\\sigma_0,\\tau_0) \\leftarrow \\operatorname{ProbGen}_{SK}(x_0);

(\\sigma_1,\\tau_1) \\leftarrow \\operatorname{ProbGen}_{SK}(x_1);

b \\stackrel{R}{\\leftarrow} \\{0,1\\};

\\hat{b} \\leftarrow A^{\\operatorname{PubProbGen}_{SK}(\\cdot)}(PK,x_0,x_1,\\sigma_b)

If \\hat{b} = b, output &#x27;1&#x27;, else &#x27;0&#x27;;</code></pre>

    <p class="text-gray-300"><strong>Definition 4 (Privacy)</strong> <em>For a verifiable computation scheme V C, we define the advantage of an adversary A in the experiment above as:</em></p>

    <p class="text-gray-300"><span class="math-block">Adv_A^{Priv}(\\mathcal{VC}, F, \\lambda) = Prob[\\mathbf{Exp}_A^{Priv}[\\mathcal{VC}, F, \\lambda] = 1]</span> (4)</p>

    <p class="text-gray-300"><em>A verifiable computation scheme V C is</em> private <em>for a function F, if for any adversary A running in probabilistic polynomial time,</em></p>

    <p class="text-gray-300"><span class="math-block">Adv_A^{Priv}(\\mathcal{VC}, F, \\lambda) \\le negli(\\lambda)</span>  (5)</p>

    <p class="text-gray-300"><em>where</em> negli() <em>is a negligible function of its input.</em></p>

    <p class="text-gray-300">An immediate consequence of the above definition is that in a private scheme, the encoding of the input must be probabilistic (since the adversary can always query <em>x</em>0, <em>x</em><sup>1</sup> to the <strong>PubProbGen</strong> oracle, and if the answer were deterministic, he could decide which input is encoded in σ<em>b</em>).</p>

    <p class="text-gray-300">A similar definition can be made for output privacy.</p>

    <h3 id="sec-11" class="text-xl font-semibold mt-8"><strong>3.3 Efficiency</strong></h3>

    <p class="text-gray-300">The final condition we require from a verifiable computation scheme is that the time to encode the input and verify the output must be smaller than the time to compute the function from scratch.</p>

    <p class="text-gray-300"><strong>Definition 5 (Outsourceable)</strong> <em>A V C can be outsourced if it permits efficient generation and efficient verification. This implies that for any x and any</em> σ<em>y, the time required for</em> <strong>ProbGen</strong><em>SK</em>(<em>x</em>) <em>plus the time required for</em> <strong>Verify</strong>(σ<em>y</em>) <em>is o</em>(<em>T</em>)<em>, where T is the time required to compute F</em>(<em>x</em>)<em>.</em></p>

    <p class="text-gray-300">Some functions are naturally outsourceable (i.e., they can be outsourced with no additional mechanisms), but many are not.</p>

    <p class="text-gray-300">Notice that we are not including the time to compute the key generation algorithm (i.e., the encoding of the function itself). Therefore, the above definition captures the idea of an outsourceable verifiable computation scheme which is more efficient than computing the function in an <em>amortized</em> sense, since the cost of encoding the function can be amortized over many input computations.</p>

    <h4 id="sec-13" class="text-lg font-semibold mt-6"><strong>4.1 Protocol Definition</strong></h4>

    <p class="text-gray-300">We are now ready to describe our scheme. Informally, our protocol works as follows. The key generation algorithm consists of running Yao's garbling procedure over a Boolean circuit computing the function <em>F</em>: the public key is the collection of ciphertexts representing the garbled circuit, and the secret key consists of all the random wire labels. The input is encoded in two steps: first a fresh public/secret key pair for a homomorphic encryption scheme is generated, and then the labels of the correct input wires are encrypted with it. These ciphertexts constitute the public encoding of the input, while the secret key is kept private by the client. Using the homomorphic properties of the encryption scheme, the worker performs the computation steps of Yao's protocol, but working over ciphertexts (i.e., for every gate, given the encrypted labels for the correct input wires, obtain an encryption of the correct output wire, by applying the homomorphic encryption over the circuit that computes the "double decryption" in Yao's protocol). At the end, the worker will hold the encryption of the labels of the correct output wires. He returns these ciphertexts to the client who decrypts them and then computes the output from them. We give a detailed description below.</p>

    <h3 id="sec-14" class="text-xl font-semibold mt-8"><strong>Protocol</strong> <em>V C<strong></em>.</strong></h3>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>1. <strong>KeyGen</strong> <span class="math">(F,\\lambda) \\to (PK,SK)</span> : Represent F as a circuit C. Following Yao's Circuit Construction (see Section 2.1), choose two values,  <span class="math">w_i^0, w_i^1 \\stackrel{R}{\\leftarrow} \\{0,1\\}^{\\lambda}</span>  for each wire  <span class="math">w_i</span> . For each gate g, compute the four ciphertexts  <span class="math">(\\gamma_{00}^g, \\gamma_{01}^g, \\gamma_{10}^g, \\gamma_{11}^g)</span>  described in Equation 1. The public key PK will be the full set of ciphertexts, i.e.,  <span class="math">PK \\leftarrow \\bigcup_g (\\gamma_{00}^g, \\gamma_{01}^g, \\gamma_{10}^g, \\gamma_{11}^g)</span> , while the secret key will be the wire values chosen:  <span class="math">SK \\leftarrow \\bigcup_i (w_i^0, w_i^1)</span> .</li>

      <li>2. <strong>ProbGen</strong><sub>SK</sub> <span class="math">(x) \\rightarrow \\sigma_x</span> : Run the doubly-homomorphic encryption scheme's key generation algorithm to create a new key pair:  <span class="math">(PK_{\\mathcal{E}}, SK_{\\mathcal{E}}) \\leftarrow \\mathbf{KeyGen}_{\\mathcal{E}}(\\lambda)</span> . Let  <span class="math">w_i \\subset SK</span>  be the wire values representing the binary expression of x. Set  <span class="math">\\sigma_x \\leftarrow (PK_{\\mathcal{E}}, \\mathbf{Encrypt}_{\\mathcal{E}}(PK_{\\mathcal{E}}, w_i))</span>  and  <span class="math">\\tau_x \\leftarrow SK_{\\mathcal{E}}</span> .</li>

      <li>3. Compute<sub>PK</sub>( <span class="math">\\sigma_x</span> )  <span class="math">\\to \\sigma_y</span> : Calculate Encrypt<sub>E</sub>( <span class="math">PK_E, \\gamma_i</span> ). Construct a circuit  <span class="math">\\Delta</span>  that on input  <span class="math">w, w&#x27;, \\gamma</span>  outputs  <span class="math">D_w(D_{w&#x27;}(\\gamma))</span> , where D is the decryption algorithm corresponding to the encryption E used in Yao's garbling (therefore  <span class="math">\\Delta</span>  computes the appropriate decryption in Yao's construction). Calculate Evaluate<sub>E</sub>( <span class="math">\\Delta</span> , Encrypt<sub>E</sub>( <span class="math">PK_E, w_i</span> ), Encrypt<sub>E</sub>( <span class="math">PK_E, \\gamma_i</span> )) repeatedly, to decrypt your way through the ciphertexts, just as in the evaluation of Yao's garbled circuit. The result is  <span class="math">\\sigma_y \\leftarrow</span>  Encrypt<sub>E</sub>( <span class="math">PK_E, \\overline{w_i}</span> ), where  <span class="math">\\overline{w_i}</span>  are the wire values representing y = F(x) in binary.</li>

      <li>4. <strong>Verify</strong><sub>SK</sub> <span class="math">(\\sigma_y) \\rightarrow y \\cup \\bot</span> : Use  <span class="math">SK_{\\mathcal{E}}</span>  to decrypt <strong>Encrypt</strong><sub> <span class="math">\\mathcal{E}</span> </sub> <span class="math">(PK_{\\varepsilon}, \\overline{w_i})</span> , obtaining  <span class="math">\\overline{w_i}</span> . Use SK to map the wire values to an output y. If the decryption or mapping fails, output  <span class="math">\\bot</span> .</li>

    </ul>

    <p class="text-gray-300"><strong>Remark:</strong> On verifying ciphertext ranges in an encrypted form. Recall that Yao's scheme requires the encryption scheme E to have an efficiently verifiable range: Given the key k, it is possible to decide efficiently if a given ciphertext falls into the range of encryptions under k. In other words, there exists an efficient machine M such that  <span class="math">M(k,\\gamma)=1</span>  if and only if  <span class="math">\\gamma\\in\\mathsf{Range}_{\\lambda}(k)</span> . This is necessary to "recognize" which ciphertext to pick among the four ciphertexts associated with each gate.</p>

    <p class="text-gray-300">In our verifiable computation scheme  <span class="math">\\mathcal{VC}</span> , we need to perform this check using an encrypted form of the key  <span class="math">c = \\mathbf{Encrypt}_{\\mathcal{E}}(PK_{\\mathcal{E}}, k)</span> . When applying the homomorphic properties of  <span class="math">\\mathcal{E}</span>  to the range testing machine M, the worker obtains an encryption of 1 for the correct ciphertext, and an encryption of 0 for the others. Of course he is not able to distinguish which one is the correct one.</p>

    <p class="text-gray-300">The worker then proceeds as follows: for the four ciphertexts  <span class="math">\\gamma_1, \\gamma_2, \\gamma_3, \\gamma_4</span>  associated with a gate g, he first computes  <span class="math">c_i = \\mathbf{Encrypt}_{\\mathcal{E}}(PK_{\\mathcal{E}}, M(k, \\gamma_i))</span>  using the homomorphic properties of  <span class="math">\\mathcal{E}</span>  over the circuit describing M. Note that only one of these ciphertexts encrypts a 1, exactly the one corresponding to the correct  <span class="math">\\gamma_i</span> . Then the worker computes  <span class="math">d_i = \\mathbf{Encrypt}_{\\mathcal{E}}(PK_{\\mathcal{E}}, D_k(\\gamma_i))</span>  using the homomorphic properties of  <span class="math">\\mathcal{E}</span>  over the decryption circuit  <span class="math">\\Delta</span> . Note that  <span class="math">k&#x27; = \\Sigma_i M(k, \\gamma_i) D_k(\\gamma_i)</span>  is the correct label for the output wire. Therefore, the worker can use the homomorphic properties of  <span class="math">\\mathcal{E}</span>  to compute  <span class="math">c = \\mathbf{Encrypt}_{\\mathcal{E}}(PK_{\\mathcal{E}}, k&#x27;) = \\mathbf{Encrypt}_{\\mathcal{E}}(PK_{\\mathcal{E}}, \\Sigma_i M(k, \\gamma_i) D_k(\\gamma_i))</span>  from  <span class="math">c_i, d_i</span> , as desired.</p>

    <h4 id="sec-15" class="text-lg font-semibold mt-6">4.2 Proof of Security</h4>

    <p class="text-gray-300">The main result of our paper is the following.</p>

    <p class="text-gray-300"><strong>Theorem 1</strong> Let E be a Yao-secure symmetric encryption scheme and E be a semantically secure homomorphic encryption scheme. Then protocol VC is a secure, outsourceable and private verifiable computation scheme.</p>

    <p class="text-gray-300">The proof of Theorem 1 requires two high-level steps. First, we show that Yao's garbled circuit scheme is a one-time secure verifiable computation scheme, i.e. a scheme that can be used to compute F securely on one input. Then, by using the semantic security of the homomorphic encryption scheme, we reduce the security of our scheme (with multiple executions) to the security of a single execution where we expect the adversary to cheat.</p>

    <h4 id="sec-16" class="text-lg font-semibold mt-6">4.3 Proof Sketch of Yao's Security for One Execution</h4>

    <p class="text-gray-300">Consider the verifiable computation scheme  <span class="math">VC_{Yao}</span>  defined as follows:</p>

    <h4 id="sec-17" class="text-lg font-semibold mt-6">Protocol <span class="math">VC_{Yao}</span> .</h4>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>1. <strong>KeyGen</strong> <span class="math">(F,\\lambda) \\to (PK,SK)</span> : Represent F as a circuit C. Following Yao's Circuit Construction (see Section 2.1), choose two values,  <span class="math">w_i^0, w_i^1 \\overset{R}{\\leftarrow} \\{0,1\\}^{\\lambda}</span>  for each wire  <span class="math">w_i</span> . For each gate g, compute the four ciphertexts  <span class="math">(\\gamma_{00}^g, \\gamma_{01}^g, \\gamma_{10}^g, \\gamma_{11}^g)</span>  described in Equation 1. The public key PK will be the full set of ciphertexts, i.e,  <span class="math">PK \\leftarrow \\bigcup_g (\\gamma_{00}^g, \\gamma_{01}^g, \\gamma_{10}^g, \\gamma_{11}^g)</span> , while the secret key will be the wire values chosen:  <span class="math">SK \\leftarrow \\bigcup_i (w_i^0, w_i^1)</span> .</li>

      <li>2. <strong>ProbGen</strong><sub>SK</sub> <span class="math">(x) \\rightarrow \\sigma_x</span> : Reveal the labels of the input wires associated with x. In other words, let  <span class="math">w_i \\subset SK</span>  be the wire values representing the binary expression of x, and set  <span class="math">\\sigma_x \\leftarrow (PK_{\\varepsilon}, w_i)</span> .  <span class="math">\\tau_x</span>  is the empty string.</li>

      <li>3. <strong>Compute</strong><sub>PK</sub>( <span class="math">\\sigma_x</span> )  <span class="math">\\rightarrow \\sigma_y</span> : Compute the decryptions in Yao's protocol to obtain the labels of the correct output wires. Set  <span class="math">\\sigma_y</span>  to be these labels.</li>

      <li>4. <strong>Verify</strong><sub>SK</sub> <span class="math">(\\sigma_y) \\rightarrow y \\cup \\bot</span> : Use <em>SK</em> to map the wire values in  <span class="math">\\sigma_y</span>  to the binary representation of the output y. If the mapping fails, output  <span class="math">\\bot</span> .</li>

    </ul>

    <p class="text-gray-300"><strong>Theorem 2</strong>  <span class="math">VC_{Yao}</span>  is a correct verifiable computation scheme.</p>

    <p class="text-gray-300"><strong>Proof of Theorem 2:</strong> The proof of correctness follows directly from the proof of correctness for Yao's garbled circuit construction [20]. Using C and  <span class="math">\\tilde{x}</span>  will produce a  <span class="math">\\tilde{y}</span>  that represents the correct evaluation of F(x).</p>

    <p class="text-gray-300">We prove that  <span class="math">\\mathcal{V}C_{Yao}</span>  is a <em>one-time</em> secure verifiable computation scheme. The definition of <em>one-time</em> secure is the same as Definition 3 except that in experiment  <span class="math">\\mathbf{Exp}_A^{Verif}</span> , the adversary is allowed to query the oracle  <span class="math">\\mathbf{ProbGen}_{SK}(\\cdot)</span>  only once (i.e.,  <span class="math">\\ell=1</span> ) and must cheat on that input.</p>

    <p class="text-gray-300">Intuitively, an adversary who violates the security of this scheme must either guess the "incorrect" random value  <span class="math">k_w^{1-y_i}</span>  for one of the output bit values representing y, or he must break the encryption scheme used to encode the "incorrect" wire values in the circuit. The former happens with probability  <span class="math">\\leq \\frac{1}{2\\lambda}</span> , i.e., negligible in  <span class="math">\\lambda</span> . The latter violates our security assumptions about the encryption scheme. We formalize this intuition below using an hybrid argument similar to the one used in [20].</p>

    <p class="text-gray-300"><strong>Theorem 3</strong> Let E be a Yao-secure symmetric encryption scheme. Then  <span class="math">VC_{Yao}</span>  is a one-time secure verifiable computation scheme.</p>

    <p class="text-gray-300"><strong>Proof of Theorem 3:</strong> Assume w.l.o.g. that the function F outputs a single bit (at the end of the proof we show how to deal with the case of multiple-bit outputs). Assume a canonical order on the gates in the circuit computing F, and let m be the number of such gates. Let PK be the garbled circuit obtained by running  <span class="math">\\mathbf{KeyGen}(F,\\lambda)</span> .</p>

    <p class="text-gray-300">Fix any adversary A; we show that for A, the probability of successfully cheating is negligible in  <span class="math">\\lambda</span> , if the encryption scheme E is Yao-secure. We do this by defining a series of <em>hybrid</em> experiments where we change the setting in which A is run, but in a controlled way: each experiment in the series will be <em>computationally indistinguishable</em> from the previous one, if the security of the encryption scheme holds. The first experiment in the series is  <span class="math">\\mathbf{Exp}_A^{Verif}</span> . In the last experiment, we will show that information-theoretically A can cheat only with negligible probability, therefore proving that in order to cheat in the original experiment, A must distinguish between two experiments in the series, and thus break the encryption scheme.</p>

    <p class="text-gray-300">We denote with  <span class="math">H_A^i[\\mathcal{VC}, F, \\lambda]</span> , the  <span class="math">i^{th}</span>  hybrid experiment, run with an adversary A, verifiable computation scheme  <span class="math">\\mathcal{VC}</span> , function F and security parameter  <span class="math">\\lambda</span> . All experiments output a Boolean value, and therefore we can define  <span class="math">Adv_A^i(\\mathcal{VC}, F, \\lambda) = Prob[H_A^i[\\mathcal{VC}, F, \\lambda] = 1]</span> .</p>

    <p class="text-gray-300">Define</p>

    <div class="my-4 text-center"><span class="math-block">p_b = Prob[A \\text{ in } \\mathbf{Exp}_A^{Verif}[\\mathcal{V}C_{Yao}, F, \\lambda] \\text{ outputs } x \\text{ s.t. } F(x) = b]</span></div>

    <p class="text-gray-300">Note that we can estimate these probabilities by running the experiment many times. Set  <span class="math">\\beta</span>  to be the bit such that  <span class="math">p_{\\beta} \\ge p_{\\overline{\\beta}}</span> . Notice that  <span class="math">p_{\\beta} \\ge 1/2</span> .</p>

    <p class="text-gray-300"><strong>Experiment</strong>  <span class="math">H_A^0[\\mathcal{V}C_{Yao}, F, \\lambda]</span> : This experiment is exactly like  <span class="math">\\mathbf{Exp}_A^{Verif}[\\mathcal{V}C_{Yao}, F, \\lambda]</span>  except that when A queries <strong>ProbGen</strong> on the input x (recall that we are considering the case where the adversary only submits a single input value and must cheat on that input), the oracle selects a random<sup>2</sup> x' such that  <span class="math">F(x&#x27;) = \\beta</span>  and returns  <span class="math">\\sigma_{x&#x27;}</span> , where  <span class="math">(\\sigma_{x&#x27;}, \\tau_{x&#x27;}) \\leftarrow \\mathbf{ProbGen}_{SK}(x&#x27;)</span> . The experiment's output bit is set to 1 if A manages to cheat over input x', i.e. produces a valid proof for  <span class="math">\\beta</span>  (and to 0 otherwise).</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><strong>Lemma 1</strong> If E is a Yao-secure encryption scheme, then for all efficient adversaries A we have  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Adv_A^0(\\mathcal{VC}_{Yao}, F, \\lambda) - Adv_A^{Verif}(\\mathcal{VC}_{Yao}, F, \\lambda)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq \\text{negli}(\\lambda)$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><strong>Proof of Lemma 1:</strong> The Lemma follows from the security of Yao's two-party computation protocol [20]. Recall that in Yao's protocol, two parties  <span class="math">P_1</span>  and  <span class="math">P_2</span>  want to compute a function F over inputs x and y privately held respectively by  <span class="math">P_1</span>  and  <span class="math">P_2</span> , without revealing any information about their inputs except the value F(x,y). The protocol goes as follows:  <span class="math">P_1</span>  garbles a circuit computing the function F, and gives to  <span class="math">P_2</span>  the labels of his input x. Moreover,  <span class="math">P_1</span>  and  <span class="math">P_2</span>  engage in OT protocols to give  <span class="math">P_2</span>  the labels of her input y, without revealing this input to  <span class="math">P_1</span> . Then  <span class="math">P_2</span>  executes the circuit on his own and sends the output label to  <span class="math">P_1</span> , who reveals the output of the function F(x,y). Note that  <span class="math">P_1</span>  sends his input labels in the clear to  <span class="math">P_2</span> . The intuition is that  <span class="math">P_1</span> 's input remains private since  <span class="math">P_2</span>  can't associate the labels with the bit values they represent. This intuition is formalized in the proof in [20].</p>

    <p class="text-gray-300">Therefore we reduce the indistinguishability of  <span class="math">H_A^0[\\mathcal{V}C_{Yao}, F, \\lambda]</span>  and  <span class="math">\\mathbf{Exp}_{A^*}^{Verif}[\\mathcal{V}C_{Yao}, F, \\lambda]</span>  to the security of Yao's protocol. We show that if there exists A such that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Adv_A^0(\\mathcal{V}\\mathcal{C}_{Yao},F,\\lambda)-Adv_A^{Verif}(\\mathcal{V}\\mathcal{C}_{Yao},F,\\lambda)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">>\\epsilon$$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">with non-negligible  <span class="math">\\varepsilon</span> , then we can learn some information about  <span class="math">P_1</span> 's input with roughly the same advantage.</p>

    <p class="text-gray-300">Suppose we run Yao's two-party protocol between  <span class="math">P_1</span>  and  <span class="math">P_2</span>  with the function F computed over just  <span class="math">P_1</span> 's input x'. We assume that  <span class="math">P_1</span> 's input is chosen with the right distribution<sup>3</sup> (i.e.  <span class="math">F(x&#x27;) = \\beta</span> ). For any two values x, x', with F(x) = F(x'), the security of Yao's protocol implies that no efficient player  <span class="math">P_2</span>  can distinguish if x or x' was used.</p>

    <p class="text-gray-300">We build a simulator S that plays the role of  <span class="math">P_2</span>  and distinguishes between the two input cases, with probability  <span class="math">p_{\\beta}\\varepsilon</span> , thus creating a contradiction.</p>

    <p class="text-gray-300">The protocol starts with  <span class="math">P_1</span>  sending the garbled circuit PK and the encoding of his input  <span class="math">\\sigma_{x&#x27;}</span> . The simulator computes the label  <span class="math">\\ell</span>  associated with the output F(x'). At this point the simulator engages A over the input PK, and A requests the encoding of an input x. If  <span class="math">F(x) \\neq \\beta</span>  the simulator tosses a random coin, and outputs the resulting bit. Notice however that with probability  <span class="math">p_{\\beta}</span> ,  <span class="math">F(x) = \\beta = F(x&#x27;)</span> . In this case, the simulator provides A with the encoding  <span class="math">\\sigma_{x&#x27;}</span> , and returns as its output the experiment bit.</p>

    <p class="text-gray-300">simulator provides A with the encoding  <span class="math">\\sigma_{x&#x27;}</span> , and returns as its output the experiment bit. Notice that if x = x' we are running  <span class="math">\\mathbf{Exp}_A^{Verif}[\\mathcal{V}\\mathcal{C}_{Yao}, F, \\lambda]</span> , while if  <span class="math">x \\neq x&#x27;</span>  we are running  <span class="math">H_{A^*}^0[\\mathcal{V}\\mathcal{C}_{Yao}, F, \\lambda]</span> . Therefore the simulator distinguishes between the two input values exactly with probability  <span class="math">p_{\\beta}\\varepsilon</span> , therefore creating a contradiction.</p>

    <p class="text-gray-300">Experiment  <span class="math">H_A^i[\\mathcal{V}C_{Yao},F,\\lambda]</span>  for  <span class="math">i=1,\\ldots,m</span> : During the  <span class="math">i^{th}</span>  experiment the <strong>ProbGen</strong> oracle still chooses a random value x' to answer A's query as in  <span class="math">H_A^0[\\mathcal{V}C_{Yao},F,\\lambda]</span> . This value x' defines 0/1 values for all the wires in the circuit. We say that a label  <span class="math">w^b</span>  for wire w is <em>active</em> if the value of wire w when the circuit is computed over x' is b. We now define a family of fake garbled circuits  <span class="math">PK_{fake}^i</span>  for  <span class="math">i=0,\\ldots,m</span> , as follows. For gate  <span class="math">g_j</span>  with  <span class="math">j \\leq i</span> , if  <span class="math">w^b</span>  is the active label associated with its output wire w, then <em>all</em> four ciphertexts associated with  <span class="math">g_j</span>  encrypt  <span class="math">w^b</span> . For gate  <span class="math">g_j</span> , with j > i, the four ciphertexts are computed correctly as in Yao's garbling technique, where the value encrypted depends on the keys used to encrypt it. Notice that  <span class="math">PK_{fake}^0 = PK</span>  since for all of the gates, the ciphertexts are computed correctly. The experiment's output bit is still set to 1 if A manages to cheat over input x', i.e. produces a valid proof for  <span class="math">\\beta</span>  (and to 0 otherwise).</p>

    <p class="text-gray-300"><sup>&</sup>lt;sup>2</sup>Since F is a Boolean function, w.l.o.g. we can assume that we can efficiently sample x' such that F(x') = b.</p>

    <p class="text-gray-300"><sup>&</sup>lt;sup>3</sup>We can assume this since the security of Yao's protocol is for all inputs, so in particular for this distribution.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><strong>Lemma 2</strong> If E is a Yao-secure encryption scheme, then for all efficient adversaries A we have  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Adv_A^i(\\mathcal{VC}_{Yao}, F, \\lambda) - Adv_A^{i-1}(\\mathcal{VC}_{Yao}, F, \\lambda)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq \\text{negli}(\\lambda)$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">This lemma is actually proven in [20], and we refer the reader to it for a full proof. Intuitively, the lemma follows from the ciphertext indistinguishability of the encryption scheme E.</p>

    <p class="text-gray-300"><strong>Lemma 3</strong> <span class="math-block">Adv_A^m(\\mathcal{V}C_{Yao}, F, \\lambda) = 2^{-\\lambda}</span></p>

    <p class="text-gray-300"><strong>Proof of Lemma 3:</strong> Recall that  <span class="math">Adv_A^m(\\mathcal{V}C_{Yao}, F, \\lambda)</span>  is the probability that A manages to cheat over input x', i.e., to provide the incorrect output label. However, the view of A is information-theoretically independent of that label, since the incorrect output label is inactive and has not been encrypted in the garbled circuit  <span class="math">PK_{fake}^m</span> . Since labels are chosen as random  <span class="math">\\lambda</span> -bit strings, the probability of guessing the incorrect output label is exactly  <span class="math">2^{-\\lambda}</span> .</p>

    <p class="text-gray-300">This completes the proof of Theorem 3.</p>

    <p class="text-gray-300"><strong>Remark:</strong> This proof does not readily extend to the case of a function F with multiple output bits, because in that case it might not be possible to sample an x which produces a specific output (think of a one-way function F for example). However, notice that if the output is n bits, then the value y computed by a successful cheating adversary must be different from F(x) in at least one bit. Thus, at the beginning of the simulation, we can try to guess the bit on which the adversary will cheat and then run the proof for the 1-bit case. Our guess will be right with probability 1/n.</p>

    <h4 id="sec-18" class="text-lg font-semibold mt-6">4.4 Proof of Theorem 1</h4>

    <p class="text-gray-300">The proof of Theorem 1 follows from Theorem 2 and the semantic security of the homomorphic encryption scheme. More precisely, we show that if the homomorphic encryption scheme is semantically secure, then we can transform (via a simulation) a successful adversary against the full verifiable computation scheme VC into an attacker for the one-time secure protocol  <span class="math">VC_{Yao}</span> . The intuition is that for each query, the labels in the circuit are encrypted with a semantically-secure encryption scheme (the homomorphic scheme), so multiple queries do not help the adversary to learn about the labels, and hence if he cheats, he must be able to cheat in the one-time case as well.</p>

    <p class="text-gray-300"><strong>Proof of Theorem 1:</strong> Let us assume for the sake of contradiction that there is an adversary A such that  <span class="math">Adv_A^{Verif}(\\mathcal{VC},F,\\lambda) \\geq \\varepsilon</span> , where  <span class="math">\\varepsilon</span>  is non-negligible in  <span class="math">\\lambda</span> . We use A to build another adversary A' which queries the <strong>ProbGen</strong> oracle only once, and for which  <span class="math">Adv_{A&#x27;}^{Verif}(\\mathcal{VC}_{Yao},F,\\lambda) \\geq \\varepsilon&#x27;</span> , where  <span class="math">\\varepsilon&#x27;</span>  is close to  <span class="math">\\varepsilon</span> . The details of A' follow.</p>

    <p class="text-gray-300">A' receives as input the garbled circuit PK. It activates A with the same input. Let  <span class="math">\\ell</span>  be an upper bound on the number of queries that A makes to its <strong>ProbGen</strong> oracle. The adversary A' chooses an index i at random between 1 and  <span class="math">\\ell</span>  and continues as follows. For the  <span class="math">j^{th}</span>  query by A, with  <span class="math">j \\neq i</span> , A' will respond by (i) choosing a random private/public key pair for the homomorphic encryption scheme  <span class="math">(PK_{\\mathcal{E}}^j, SK_{\\mathcal{E}}^j)</span>  and (ii) encrypting random  <span class="math">\\lambda</span> -bit strings under  <span class="math">PK_{\\mathcal{E}}^j</span> . For the  <span class="math">i^{th}</span>  query, x, the adversary A' gives x to its own <strong>ProbGen</strong> oracle and receives  <span class="math">\\sigma_x</span> , the collection of active input labels corresponding to x. It then generates a random private/public key pair for the homomorphic encryption scheme  <span class="math">(PK_{\\mathcal{E}}^i, SK_{\\mathcal{E}}^i)</span> , and it encrypts  <span class="math">\\sigma_x</span>  (label by label) under  <span class="math">PK_{\\mathcal{E}}^i</span> .</p>

    <p class="text-gray-300">Once we prove the Lemma 4 below, we have our contradiction and the proof of Theorem 1 is complete</p>

    <p class="text-gray-300"><strong>Lemma 4</strong>  <span class="math">Adv_{A&#x27;}^{Verif}(\\mathcal{V}\\mathcal{C}_{Yao},F,\\lambda) \\geq \\varepsilon&#x27;</span>  where  <span class="math">\\varepsilon&#x27;</span>  is non-negligible in  <span class="math">\\lambda</span> .</p>

    <p class="text-gray-300"><strong>Proof of Lemma 4:</strong> This proof also proceeds by defining, for any adversary A, a set of hybrid experiments  <span class="math">\\mathcal{H}_A^k(\\mathcal{VC},F,\\lambda)</span>  for  <span class="math">k=0,\\ldots,\\ell-1</span> . We define the experiments below. Let i be an index randomly selected between 1 and  <span class="math">\\ell</span>  as in the proof above.</p>

    <p class="text-gray-300"><strong>Experiment</strong>  <span class="math">\\mathcal{H}_{A}^{k}(\\mathcal{VC},F,\\lambda)=1</span> : In this experiment, we change the way the oracle <strong>ProbGen</strong> computes its answers. For the  <span class="math">j^{th}</span>  query:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">j \\le k</span>  and  <span class="math">j \\ne i</span> : The oracle will respond by (i) choosing a random private/public key pair for the homomorphic encryption scheme  <span class="math">(PK_{\\mathcal{F}}^j, SK_{\\mathcal{F}}^j)</span>  and (ii) encrypting random  <span class="math">\\lambda</span> -bit strings under  <span class="math">PK_{\\mathcal{F}}^j</span> .</li>

      <li>j > k or j = i: The oracle will respond exactly as in  <span class="math">\\mathcal{VC}</span> , i.e. by (i) choosing a random private/public key pair for the homomorphic encryption scheme  <span class="math">(PK_{\\mathcal{E}}^j, SK_{\\mathcal{E}}^j)</span>  and (ii) encrypting the correct input labels in Yao's garbled circuit under  <span class="math">PK_{\\mathcal{E}}^j</span> .</li>

    </ul>

    <p class="text-gray-300">In the end, the bit output by the experiment  <span class="math">\\mathcal{H}_{A}^{k}</span>  is 1 if A successfully cheats on the  <span class="math">i^{th}</span>  input and otherwise is 0. We denote with  <span class="math">Adv_{A}^{k}(\\mathcal{VC},F,\\lambda)=Prob[\\mathcal{H}_{A}^{k}(\\mathcal{VC},F,\\lambda)=1]</span> . Note that</p>

    <p class="text-gray-300">•  <span class="math">\\mathcal{H}_{A}^{0}(\\mathcal{VC},F,\\lambda)</span>  is identical to the experiment  <span class="math">\\mathbf{Exp}_{A}^{Verif}[\\mathcal{VC},F,\\lambda]</span> , except for the way the bit is computed at the end. Since the index i is selected at random between 1 and  <span class="math">\\ell</span> , we have that</p>

    <div class="my-4 text-center"><span class="math-block">Adv_A^0(\\mathcal{VC},F,\\lambda) = \\frac{Adv_A^{Verif}(\\mathcal{VC},F,\\lambda)}{\\ell} \\geq \\frac{\\epsilon}{\\ell}</span></div>

    <p class="text-gray-300">•  <span class="math">\\mathcal{H}_{A}^{\\ell-1}(\\mathcal{VC},F,\\lambda)</span>  is equal to the simulation conducted by A' above, so</p>

    <div class="my-4 text-center"><span class="math-block">Adv_A^{\\ell-1}(\\mathcal{VC},F,\\lambda) = Adv_{A&#x27;}^{Verif}(\\mathcal{VC}_{Yao},F,\\lambda)</span></div>

    <p class="text-gray-300">If we prove for  <span class="math">k = 0, ..., \\ell - 1</span>  that experiments  <span class="math">\\mathcal{H}_A^k(\\mathcal{VC}, F, \\lambda)</span>  and  <span class="math">\\mathcal{H}_A^{k-1}(\\mathcal{VC}, F, \\lambda)</span>  are computationally indistinguishable, that is for every A</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Adv_A^k(\\mathcal{VC}, F, \\lambda) - Adv_A^{k-1}(\\mathcal{VC}, F, \\lambda)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\le \\text{negli}(\\lambda)$$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"> (6)</p>

    <p class="text-gray-300">we are done, since that implies that</p>

    <div class="my-4 text-center"><span class="math-block">Adv_{A&#x27;}^{Verif}(\\mathcal{VC}_{Yao},F,\\lambda) \\geq \\frac{\\epsilon}{\\ell} - \\ell \\cdot \\text{negli}(\\lambda)</span></div>

    <p class="text-gray-300">which is the desired non-negligible  <span class="math">\\varepsilon&#x27;</span> .</p>

    <p class="text-gray-300">But Eq. 6 easily follows from the semantic security of the homomorphic encryption scheme. Indeed assume that we could distinguish between  <span class="math">\\mathcal{H}_{A}^{k}</span>  and  <span class="math">\\mathcal{H}_{A}^{k-1}</span> , then we can decide the following problem, which is easily reducible to the semantic security of  <span class="math">\\mathcal{E}</span> :</p>

    <p class="text-gray-300"><strong>Security of</strong>  <span class="math">\\mathcal{E}</span>  with respect to Yao Garbled Circuits: Given a Yao-garbled circuit  <span class="math">PK_{Yao}</span> , an input x for it, a random public key  <span class="math">PK_{\\mathcal{E}}</span>  for the homomorphic encryption scheme, a set of ciphertexts  <span class="math">c_1, \\ldots, c_n</span>  where n is the size of x, decide if for all i,  <span class="math">c_i = \\mathbf{Encrypt}_{\\mathcal{E}}(PK_{\\mathcal{E}}, w_i^{x_i})</span> , where  <span class="math">w_i</span>  is the  <span class="math">i^{th}</span>  input wire and  <span class="math">x_i</span>  is the  <span class="math">i^{th}</span>  input bit of x, or  <span class="math">c_i</span>  is the encryption of a random value.</p>

    <p class="text-gray-300">Now run experiment  <span class="math">\\mathcal{H}_A^{k-1}</span>  with the following modification: at the  <span class="math">k^{th}</span>  query, instead of choosing a fresh random key for  <span class="math">\\mathcal{E}</span>  and encrypting random labels, answer with  <span class="math">PK_{\\mathcal{E}}</span>  and the ciphertexts  <span class="math">c_1, \\ldots, c_n</span>  defined by the problem above. If  <span class="math">c_i</span>  is the encryption of a random value, then we are still running experiment  <span class="math">\\mathcal{H}_A^{k-1}</span> , but if  <span class="math">c_i = \\mathbf{Encrypt}_{\\mathcal{E}}(PK_{\\mathcal{E}}, w_i^{x_i})</span> , then we are actually running experiment  <span class="math">\\mathcal{H}_A^k</span> . Therefore we can decide the Security of  <span class="math">\\mathcal{E}</span>  with respect to Yao Garbled Circuits with the same advantage with which we can distinguish between  <span class="math">\\mathcal{H}_A^k</span>  and  <span class="math">\\mathcal{H}_A^{k-1}</span> .</p>

    <p class="text-gray-300">The reduction of the Security of  <span class="math">\\mathcal{E}</span>  with respect to Yao Garbled Circuits to the basic semantic security of  <span class="math">\\mathcal{E}</span>  is an easy exercise, and details will appear in the final version.</p>

    <h4 id="sec-19" class="text-lg font-semibold mt-6">4.5 Proof of Input and Output Privacy</h4>

    <p class="text-gray-300">Note that for each oracle query the input and the output are encrypted under the homomorphic encryption scheme  <span class="math">\\mathcal{E}</span> . It is not hard to see that the proof of correctness above, easily implies the proof of input and output privacy. For the one-time case, it obviously follows from the security of Yao's two-party protocol. For the general case, it follows from the semantic security of  <span class="math">\\mathcal{E}</span> , and the proof relies on the same hybrid arguments described above.</p>

    <h3 id="sec-20" class="text-xl font-semibold mt-8">4.6 Efficiency</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The protocol we have described meets the efficiency goals outlined in Section 3.3. During the preprocessing stage, the client performs O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">) work to prepare the Garbled Yao circuit. For each invocation of <strong>ProbGen</strong>, the client generates a new keypair and encrypts one Yao label for each bit of the input, which requires O(n) effort. The worker computes its way through the circuit by performing a constant amount of work per gate, so the worker takes time linear in the time to evaluate the original circuit, namely O(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">). Finally, to verify the worker's response, the client performs a single decryption and comparison operation for each bit of the output, for a total effort of O(m). Thus, amortized over many inputs, the client performs O(n+m) work to prepare and verify each input and result.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Our definition of security (Definition 3) assumes that the adversary does not see the output of the <strong>Verify</strong> procedure run by the client on the value  <span class="math">\\sigma</span>  returned by the adversary. Theorem 1 is proven under the same assumption. In practice this means that our protocol  <span class="math">\\mathcal{VC}</span>  is secure if the client keeps the result of the computation private.</p>

    <p class="text-gray-300">In practice, there might be circumstances where this is not feasible, as the behavior of the client will change depending on the result of the evaluation (e.g., the client might refuse to pay the worker). Intuitively, and we prove this formally below, seeing the result of <strong>Verify</strong> on proofs the adversary correctly <strong>Computes</strong> using the output of <strong>PubProbGen</strong> does not help the adversary (since it already knows the result based on the inputs it supplied to <strong>PubProbGen</strong>). But what if the worker returns a malformed response – i.e., something for which <strong>Verify</strong> outputs  <span class="math">\\bot</span> . How does the client respond, if at all? One option is for the client to ask the worker to perform the computation again. But this repeated request informs the worker that its response was malformed, which is an additional bit of information that a cheating worker might exploit in its effort to generate forgeries. Is our scheme secure in this setting? In this section, we prove that our scheme remains secure as long as the client terminates after detecting a malformed response. We also consider the interesting question of whether our scheme is secure if the client terminates only after detecting k > 1 malformed responses, but we are unable to provide a proof of security in this setting.</p>

    <p class="text-gray-300">Note that there is a real attack on the scheme in this setting if the client does not terminate. Specifically, for concreteness, suppose that each ciphertext output by  <span class="math">\\mathbf{Encrypt}_{\\mathcal{E}}</span>  encrypts a single bit of a label for an input wire of the garbled circuit, and that the adversary wants to determine the first bit  <span class="math">w_{11}^{b_1}</span>  of the first label (where that label stands in for unknown input  <span class="math">b_1 \\in \\{0,1\\}</span> ). To do this, the adversary runs  <span class="math">\\mathbf{Compute}</span>  as before, obtaining ciphertexts that encrypt the bits  <span class="math">\\overline{w_i}</span>  of a label for the output wire. Using the homomorphism of the encryption scheme  <span class="math">\\mathcal{E}</span> , it XORs  <span class="math">w_{11}^{b_1}</span>  with the first bit of  <span class="math">\\overline{w_i}</span>  to obtain  <span class="math">\\overline{w_i}</span> , and it sends (the encryption of)  <span class="math">\\overline{w_i}</span>  as its response. If  <span class="math">\\mathbf{Verify}</span>  outputs  <span class="math">\\bot</span> , then  <span class="math">w_{11}^{b_1}</span>  must have been a 1; otherwise, it is a 0 with overwhelming probability. The adversary can thereby learn the labels of the garbled circuit one bit at a time – in particular, it can similarly learn the labels of the output wire, and thereafter generate a verifiable response without actually performing the computation.</p>

    <p class="text-gray-300">Intuitively, one might think that if the client terminates after detecting k malformed responses, then the adversary should only be able to obtain about k bits of information about the garbled circuit before the client terminates (using standard entropy arguments), and therefore it should still be hard for the adversary to output the entire "wrong" label for the output wire as long as  <span class="math">\\lambda</span>  is sufficiently larger than k. However, we are unable to make this argument go through. In particular, the difficulty is with the hybrid argument in the proof of Theorem 1, where we gradually transition to an experiment in which the simulator is encrypting the same Yao input labels in every round. This experiment must be indistinguishable from the real world experiment, which permits different inputs in different rounds. When we don't give the adversary information about whether or not its response was well-formed or not, the hybrid argument is straightforward – it simply depends on the semantic security of the FHE scheme.</p>

    <p class="text-gray-300">However, if we do give the adversary that information, then the adversary can easily distinguish rounds with the same input from rounds with random inputs. To do so, it chooses some "random" predicate P over the input labels, such that  <span class="math">P(w_{b_1}^1, w_{b_2}^2, \\ldots) = P(w_{b_1&#x27;}^1, w_{b_2&#x27;}^2, \\ldots)</span>  with probability 1/2 if  <span class="math">(b_1, b_2, \\ldots) \\neq (b_1&#x27;, b_2&#x27;, \\ldots)</span> . Given the encryptions of  <span class="math">w_{b_1}^1, w_{b_2}^2, \\ldots</span> , the adversary runs <strong>Compute</strong> as in the scheme, obtaining ciphertexts that encrypt the bits  <span class="math">\\overline{w_i}</span>  of a label for the output wire, XORs (using the homomorphism)  <span class="math">P(w_{b_1}^1, w_{b_2}^2, \\ldots)</span>  with the first bit of  <span class="math">\\overline{w_i}</span> , and sends (an encryption of) the result  <span class="math">\\overline{w_i&#x27;}</span>  as its response. If the client is making the same query in every round – i.e., the Yao input labels are the same every time – then, the predicate always outputs the same bit, and thus the adversary gets the same response (well-formed or malformed) in every round. Otherwise, the responses will tend to vary.</p>

    <p class="text-gray-300">One could try to make the adversary's distinguishing attack more difficult by (for example) trying to hide which ciphertexts encrypt the bits of which labels – i.e., via some form of obfuscation. However, the adversary may define its predicate in such a way that it "analyzes" this obfuscated circuit, determines whether two ostensibly different inputs in fact represent the same set of Yao input labels, and outputs the same bit if they do. (It performs this analysis on the encrypted inputs, using the homomorphism.) We do not know of any way to prevent this distinguishing attack, and suspect that preventing it may be rather difficult in light of Barak et al.'s result that there is no general obfuscator [7].</p>

    <p class="text-gray-300">Security with Verification Access. We say that a verifiable computation scheme is secure with verification access if the adversary is allowed to see the result of <strong>Verify</strong> over the queries  <span class="math">x_i</span>  he has made to the <strong>ProbGen</strong> oracle in  <span class="math">\\mathbf{Exp}_{i}^{Verif}</span>  (see Definition 3).</p>

    <p class="text-gray-300">Let  <span class="math">\\mathcal{VC}^{\\dagger}</span>  be like  <span class="math">\\mathcal{VC}</span> , except that the client terminates if it receives a malformed response from the worker. Below, we show that  <span class="math">\\mathcal{VC}^{\\dagger}</span>  is secure with verification access. In other words, it is secure to provide the worker with verification access (indicating whether a response was well-formed or not), until the worker gives a malformed response. Let  <span class="math">\\mathbf{Exp}_A^{Verif^{\\dagger}} \\left[ \\mathcal{VC}^{\\dagger}, F, \\lambda \\right]</span>  denote the experiment described in Section 3.1, with the obvious modifications.</p>

    <p class="text-gray-300"><strong>Theorem 4</strong> If VC is a secure outsourceable verifiable computation scheme, then  <span class="math">VC^{\\dagger}</span>  is a secure outsourceable verifiable computation scheme with verification access. If VC is private, then so is  <span class="math">VC^{\\dagger}</span> .</p>

    <p class="text-gray-300"><strong>Proof of Theorem 4:</strong> Consider two games between a challenger and an adversary A. In the real world game for  <span class="math">\\mathcal{VC}^{\\dagger}</span> , Game 0, the interactions between the challenger and A are exactly like those between the client and a worker in the real world – in particular, if A's response was well-formed, the challenger tells A so, but the challenger immediately aborts if A's response is malformed. Game 1 is identical to Game 0, except that when A queries <strong>Verify</strong>, the challenger always answers with the correct y, whether A's response was well-formed or not, and the challenger never aborts. Let  <span class="math">\\varepsilon_i</span>  be A's success probability in Game i.</p>

    <p class="text-gray-300">First, we show that if VC is secure, then  <span class="math">\\varepsilon_1</span>  must be negligible. The intuition is simple: since the challenger always responds with the correct y, there is actually no information in these responses, since A could have computed y on its own. More formally, there is an algorithm B that breaks VC with probability  <span class="math">\\varepsilon_1</span>  by using A as a sub-routine. B simply forwards communications between the challenger (now a challenger</p>

    <p class="text-gray-300">for the VC game) and A, except that B tells A the correct y w.r.t. all of A's responses. B forwards A's forgery along to the challenger.</p>

    <p class="text-gray-300">Now, we show that  <span class="math">\\varepsilon_0 \\leq \\varepsilon_1</span> , from which the result follows. Let  <span class="math">E_{mal}</span>  be the event that A makes a malformed response, and let  <span class="math">E_f</span>  be the event that A successfully outputs a forgery – i.e., where  <span class="math">\\mathbf{Exp}_A^{Verif^{\\dagger}}[\\mathcal{VC}^{\\dagger}, F, \\lambda]</span>  outputs '1'. A's success probability, in either Game 0 or Game 1, is:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$$Prob[E_f] = Prob[E_f</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E_{mal}] \\cdot Prob[E_{mal}] + Prob[E_f</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\neg E_{mal}] \\cdot Prob[\\neg E_{mal}]$$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"> (7)</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">If A does not make a malformed response, then Games 0 and 1 are indistinguishable to A; therefore, the second term above has the same value in Games 0 and 1. In Game 0,  $Prob[E_f</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">E_{mal}] = 0<span class="math"> , since the challenger aborts. Therefore,  </span>\\varepsilon_0 \\leq \\varepsilon_1$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In practice Theorem 4 implies that every time a malformed response is received, the client must regarble the circuit (or, as we said above, make sure that the results of the verification procedure remain secret). Therefore the amortized efficiency of the client holds only if we assume that malformed responses do not happen very frequently.</p>

    <p class="text-gray-300">In some settings, it is not necessary to inform the worker that its response is malformed, at least not immediately. For example, in the Folding@Home application [2], suppose the client generates a new garbled circuit each morning for its many workers. At the end of the day, the client stops accepting computations using this garbled circuit, and it (optionally) gives the workers information about the well-formedness of their responses. (Indeed, the client may reveal all of its secrets for that day.) In this setting, our previous security proof clearly holds even if there are arbitrarily many malformed responses.</p>

    <h3 id="sec-22" class="text-xl font-semibold mt-8"><strong>6</strong> Conclusions and Future Directions</h3>

    <p class="text-gray-300">In this work, we introduced the notion of Verifiable Computation as a natural formulation for the increasingly common phenomenon of outsourcing computational tasks to untrusted workers. We describe a scheme that combines Yao's Garbled Circuits with a fully-homomorphic encryption scheme to provide extremely efficient outsourcing, even in the presence of an adaptive adversary. As an additional benefit, our scheme maintains the privacy of the client's inputs and outputs.</p>

    <p class="text-gray-300">Our work leaves open several interesting problems. It would be desirable to devise a verifiable computation scheme that used a more efficient primitive than fully-homomorphic encryption. Similarly, it seems plausible that a verifiable scheme might sacrifice input privacy to increase its efficiency. While our scheme is resilient against a single malformed response from the worker, ideally we would like a scheme that tolerates k > 1 malformed responses. Finally, it would be interesting to enhance a verifiable computation scheme to include a non-repudiation property, so that a client who receives a malformed response from a worker can demonstrate the worker's misbehavior to a third party.</p>

    <h4 id="sec-23" class="text-lg font-semibold mt-6">References</h4>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[1] Amazon Elastic Compute Cloud. Online at http://aws.amazon.com/ec2.</li>

      <li>[2] The Folding@home project. Stanford University, http://www.stanford.edu/group/pandegroup/cosm/.</li>

      <li>[3] Sun Utility Computing. Online at http://www.sun.com/service/sungrid/index.jsp.</li>

      <li>[4] The Great Internet Mersenne Prime Search. http://www.mersenne.org/prime.htm.</li>

      <li>[5] D. P. Anderson, J. Cobb, E. Korpela, M. Lebofsky, and D. Werthimer. SETI@Home: An experiment in public-resource computing. <em>Communications of the ACM</em>, 45(11):56–61, 2002.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[6] L. Babai. Trading group theory for randomness. In <em>Proceedings of the ACM Symposium on Theory of Computing (STOC)</em>, pages 421–429, New York, NY, USA, 1985. ACM.</li>

      <li>[7] B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich, A. Sahay, S. Vadhan, and K. Yang. On the (im)possibility of obfuscating programs. In <em>Proceedings of CRYPTO</em>, pages 1–18, 2001.</li>

      <li>[8] B. Barak, I. Haitner, D. Hofheinz, and Y. Ishai. Bounded key-dependent message security. 2009.</li>

      <li>[9] M. Belenkiy, M. Chase, C. C. Erway, J. Jannotti, A. Kupc¸ ¨ u, and A. Lysyanskaya. Incentivizing out- ¨ sourced computation. In <em>Proceedings of the Workshop on Economics of Networked Systems (NetEcon)</em>, pages 85–90, New York, NY, USA, 2008. ACM.</li>

      <li>[10] D. Chaum and T. Pedersen. Wallet databases with observers. In <em>Proceedings of CRYPTO</em>, 1992.</li>

      <li>[11] C. Gentry. <em>A fully homomorphic encryption scheme</em>. PhD thesis, Stanford University, 2009.</li>

      <li>[12] C. Gentry. Fully homomorphic encryption using ideal lattices. In <em>Proceedings of the ACM Symposium on the Theory of Computing (STOC)</em>, 2009.</li>

      <li>[13] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum. Delegating computation: interactive proofs for muggles. In <em>Proceedings of the ACM Symposium on the Theory of Computing (STOC)</em>, 2008.</li>

      <li>[14] S. Goldwasser, S. Micali, and C. Rackoff. The knowledge complexity of interactive proof-systems. <em>SIAM Journal on Computing</em>, 18(1):186–208, 1989.</li>

      <li>[15] P. Golle and I. Mironov. Uncheatable distributed computations. In <em>Proceedings of the RSA Conference</em>, 2001.</li>

      <li>[16] S. Hohenberger and A. Lysyanskaya. How to securely outsource cryptographic computations. In <em>Proceedings of TCC</em>, 2005.</li>

      <li>[17] Y. T. Kalai and R. Raz. Probabilistically checkable arguments. In <em>Proceedings of CRYPTO</em>, 2009.</li>

      <li>[18] J. Kilian. A note on efficient zero-knowledge proofs and arguments (extended abstract). In <em>Proceedings of the ACM Symposium on Theory of computing (STOC)</em>, pages 723–732, New York, NY, USA, 1992. ACM.</li>

      <li>[19] J. Kilian. Improved efficient arguments (preliminary version). In <em>Proceedings of the International Cryptology Conference on Advances in Cryptology</em>, pages 311–324, London, UK, 1995. Springer-Verlag.</li>

      <li>[20] Y. Lindell and B. Pinkas. A proof of Yao's protocol for secure two-party computation. <em>Journal of Cryptology</em>, 22(2):161–188, 2009.</li>

      <li>[21] S. Micali. CS proofs (extended abstract). In <em>Proceedings of the IEEE Symposium on Foundations of Computer Science</em>, 1994.</li>

      <li>[22] D. Molnar. The SETI@Home problem. <em>ACM Crossroads</em>, 7.1, 2000.</li>

      <li>[23] F. Monrose, P. Wyckoff, and A. Rubin. Distributed execution with remote audit. In <em>Proceedings of ISOC Network and Distributed System Security Symposium (NDSS)</em>, Feb. 1999.</li>

      <li>[24] G. Rothblum. <em>Delegating Computation Reliably: Paradigms and Constructions</em>. PhD thesis, Massachusetts Institute of Technology, 2009.</li>

      <li>[25] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. VanDoorn, and P. Khosla. Pioneer: Verifying integrity and guaranteeing execution of code on legacy platforms. In <em>Proceedings of the Symposium on Operating Systems Principals</em>, 2005.</li>

      <li>[26] S. Smith and S. Weingart. Building a high-performance, programmable secure coprocessor. <em>Computer Networks (Special Issue on Computer Network Security)</em>, 31:831–960, 1999.</li>

      <li>[27] Trusted Computing Group. Trusted platform module main specification. Version 1.2, Revision 103, July 2007.</li>

      <li>[28] A. Yao. Protocols for secure computations. In <em>Proceedings of the IEEE Symposium on Foundations of Computer Science</em>, 1982.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[29] A. Yao. How to generate and exchange secrets. In <em>Proceedings of the IEEE Symposium on Foundations of Computer Science</em>, 1986.</li>

      <li>[30] B. S. Yee. <em>Using Secure Coprocessors</em>. PhD thesis, Carnegie Mellon University, 1994.</li>

    </ul>`;
---

<BaseLayout title="Non-Interactive Verifiable Computing: Outsourcing Computatio... (2009/547)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2009 &middot; eprint 2009/547
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <PaperDisclaimer eprintUrl={EPRINT_URL} />
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

    <PaperHistory slug="non-interactive-verifiable-computing-outsourcing-2009" />
  </article>
</BaseLayout>
