---
import BaseLayout from '../../layouts/BaseLayout.astro';
import PaperDisclaimer from '../../components/PaperDisclaimer.astro';
import PaperHistory from '../../components/PaperHistory.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2013/356';
const CRAWLER = 'modal-marker';
const CONVERTED_DATE = '2026-02-18';
const TITLE_HTML = 'Verifying computations with state (extended version)\\*';
const AUTHORS_HTML = 'Benjamin Braun, Ariel J. Feldman? , Zuocheng Ren, Srinath Setty, Andrew J. Blumberg, and Michael Walfish The University of Texas at Austin ?University of Pennsylvania';

const CONTENT = `    <p class="text-gray-300">Benjamin Braun, Ariel J. Feldman? , Zuocheng Ren, Srinath Setty, Andrew J. Blumberg, and Michael Walfish The University of Texas at Austin ?University of Pennsylvania</p>

    <h4 id="sec-1" class="text-lg font-semibold mt-6">Abstract</h4>

    <p class="text-gray-300">When a client outsources a job to a third party (e.g., the cloud), how can the client check the result, without reexecuting the computation? Recent work in <em>proof-based verifiable computation</em> has made significant progress on this problem by incorporating deep results from complexity theory and cryptography into built systems. However, these systems work within a stateless model: they exclude computations that interact with RAM or a disk, or for which the client does not have the full input.</p>

    <p class="text-gray-300">This paper describes Pantry, a built system that overcomes these limitations. Pantry composes proofbased verifiable computation with untrusted storage: the client expresses its computation in terms of digests that attest to state, and verifiably outsources <em>that</em> computation. Using Pantry, we extend verifiability to MapReduce jobs, simple database queries, and interactions with private state. Thus, Pantry takes another step toward practical proof-based verifiable computation for realistic applications.</p>

    <h3 id="sec-2" class="text-xl font-semibold mt-8">&lt;span id=&quot;page-0-0&quot;&gt;&lt;/span&gt;1 Introduction</h3>

    <p class="text-gray-300">This paper addresses a fundamental problem in systems security: how can a local computer verify the correctness of a remote execution? (Checking that the given program was expressed correctly is a complementary concern, studied by the field of program verification.) Our focus on execution verification is motivated by large MapReduce jobs, remote database queries, and cloud computing more generally. In these scenarios, the causes of incorrect execution include corruption of input data in storage or transit, hardware faults, platform bugs, and misconfiguration. Unfortunately, the faults, and their effects, may not be visible as such. Indeed, when a job completes, after having processed petabytes of data, how can the client be sure that the output is correct <a href="#page-41-0">[83]</a>?</p>

    <p class="text-gray-300">The client could audit the output <a href="#page-40-0">[60]</a>, but this technique fails if a problem happens outside the selected sample. The client could replicate the computation (using state machine replication <a href="#page-39-0">[27]</a>, quorums <a href="#page-40-1">[56]</a>, or outsourcing to two clouds <a href="#page-38-0">[5,</a> <a href="#page-39-1">26]</a>), but this technique works only if replica faults are uncorrelated. The client could trust the remote hardware and use attestation <a href="#page-40-2">[66,</a> <a href="#page-40-3">69]</a>, but what if the hardware is faulty? The client could use a tailored solution <a href="#page-38-1">[8,</a> <a href="#page-38-2">16,</a> <a href="#page-39-2">22,</a> <a href="#page-39-3">32,</a> <a href="#page-39-4">43,</a> <a href="#page-40-4">64,</a> <a href="#page-41-1">76,</a> <a href="#page-41-2">79,</a> <a href="#page-41-3">81]</a>, but such solutions are not available for all applications.</p>

    <p class="text-gray-300">Perhaps surprisingly, the client can receive a guarantee that covers the entire execution of the computation, that makes no assumptions about the performing platform (other than cryptographic hardness assumptions), and that applies generally. In <em>proof-based verifiable computation</em>, the performing computer (or <em>prover</em>) returns the results along with a <em>proof</em> that the client (or <em>verifier</em>) can efficiently and probabilistically check. If the entire computation was executed correctly, the client accepts, and if there is any error, the client rejects with high probability.</p>

    <p class="text-gray-300">These protocols are based on deep theoretical tools: probabilistically checkable proofs (PCPs) <a href="#page-38-3">[6,</a> <a href="#page-38-4">7]</a>, interactive proofs <a href="#page-38-5">[9,</a> <a href="#page-39-5">41,</a> <a href="#page-39-6">42,</a> <a href="#page-40-5">53,</a> <a href="#page-41-4">75]</a>, and cryptography <a href="#page-38-6">[18,</a> <a href="#page-39-7">23,</a> <a href="#page-39-8">35,</a> <a href="#page-39-9">36,</a> <a href="#page-40-6">47,</a> <a href="#page-40-7">50]</a>. This theory provides very</p>

    <p class="text-gray-300">*This is the full version of <a href="#page-39-10">[25]</a>. This version includes proofs (Appendices <a href="#page-21-0">A</a><a href="#page-33-0">–C)</a>, further experimental details (Appendices <a href="#page-35-0">D–</a> <a href="#page-37-0">E)</a>, and minor improvements to the text.</p>

    <p class="text-gray-300">strong guarantees and is usually phrased as defending against an arbitrarily malicious prover. Note that maliciousness is not an accusation but rather a comprehensive <em>model</em> that includes benign malfunctions with unpredictable effects.</p>

    <p class="text-gray-300">Recent works have aimed to realize proof-based verifiable computation in built systems <a href="#page-38-7">[15,</a> <a href="#page-39-11">28,</a> <a href="#page-40-8">65,</a> <a href="#page-40-9">70–</a> <a href="#page-40-10">73,</a> <a href="#page-41-5">77,</a> <a href="#page-41-6">78,</a> <a href="#page-41-7">80]</a>. On the one hand, these systems appear to approach practicality. Some of them come with compilers that allow programmers to express computations in a high-level language <a href="#page-38-7">[15,</a> <a href="#page-40-8">65,</a> <a href="#page-40-11">71,</a> <a href="#page-40-10">73,</a> <a href="#page-41-7">80]</a>. And the best of them achieve reasonable client performance, provided that there are many identical computations (with potentially different inputs) over which to amortize overhead—a requirement met by typical data-parallel cloud computing applications.</p>

    <p class="text-gray-300">On the other hand, almost none of these systems admit a notion of state or storage:&lt;sup&gt;1&lt;/sup&gt; their compilation target is <em>constraints</em>, a generalization of circuits (<a href="#page-2-0">§2)</a>. Given this &quot;assembly language&quot;, the computation cannot feasibly use memory, and the client must handle all of the input and output. Besides hindering programmability, these limitations are inconsistent with remotely stored inputs (as in MapReduce jobs, queries on remote databases, etc.); for example, verifying a large MapReduce job would require the client to materialize the entire dataset.</p>

    <p class="text-gray-300">This paper introduces Pantry, the first system to provide verifiable computation with state. To do so, Pantry marries machinery for verifying pure computations with techniques from untrusted storage <a href="#page-39-12">[21,</a> <a href="#page-39-13">33,</a> <a href="#page-40-12">52,</a> <a href="#page-40-13">58]</a>. While this picture is folklore among theorists <a href="#page-38-8">[14,</a> <a href="#page-38-6">18,</a> <a href="#page-39-9">36,</a> <a href="#page-40-14">46]</a>, the contributions of Pantry are to work out the details and build a system, specifically:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>(1) Pantry enhances state of the art systems (<a href="#page-2-0">§2)</a> for verifiable computation (Ginger <a href="#page-40-10">[73]</a>, Zaatar <a href="#page-40-11">[71]</a>, Pinocchio <a href="#page-40-8">[65]</a>) with a storage abstraction (<a href="#page-6-0">§3)</a>. The programmer expresses a computation using a subset of C plus two new primitives—PutBlock and GetBlock—and the Pantry compiler produces appropriate constraints. These primitives name data blocks by a cryptographic digest, or hash, of their contents. Such blocks are used extensively in systems for untrusted storage <a href="#page-39-13">[33,</a> <a href="#page-40-12">52]</a>; however, in Pantry, the verifier will not be fetching the blocks to check them. The key insight here is that there exist hash functions that are amenable to the constraint formalism.</li>
      <li>(2) Using PutBlock and GetBlock, we build a verifiable MapReduce framework (<a href="#page-8-0">§4)</a>. The programmer writes Map and Reduce functions, much as in standard MapReduce frameworks. Here, however, input and output files are named by the digests of their contents.</li>
      <li>(3) We also use PutBlock and GetBlock (together with well-known techniques <a href="#page-39-12">[21,</a> <a href="#page-40-13">58]</a>) to build higher-level storage abstractions: a RAM and a searchable tree (<a href="#page-11-0">§5)</a>. We use the tree to build a database application that supports verifiable queries in a (small) subset of SQL. The notable aspects here are the placement of functionality and the result: the abstractions are exposed to the C programmer, they need not be built into the compiler, and operations on these abstractions happen verifiably even though the client does not have the state.</li>
      <li>(4) We compose PutBlock and GetBlock with a zero-knowledge variant of Pinocchio <a href="#page-39-9">[36,</a> <a href="#page-40-8">65]</a>, to build applications in which the prover's state is private: face matching, toll collection, etc. (<a href="#page-14-0">§6)</a>.</li>
    </ul>

    <p class="text-gray-300">The components just described have awkward usage restrictions (the database is single-writer, iteration constructs need static upper bounds, etc.), due in part to the clumsiness of the constraint formalism. Worse, the measured cost (<a href="#page-15-0">§8)</a> of the implementation (<a href="#page-15-1">§7)</a> is very high: the prover's overhead is tremendous, and the verifier incurs a similarly high per-computation setup cost, requiring many invocations to justify this expense.</p>

    <p class="text-gray-300">However, compared to prior systems for verifiable computation (<a href="#page-19-0">§9)</a>, Pantry improves performance: by not handling inputs, the verifier saves CPU and network costs. This effect, together with Pantry's enhanced expressiveness, expands the universe of applications for which verification makes sense (<a href="#page-20-0">§10)</a>. MapReduce, for example, works over remote state, and is well-suited to amortizing the setup costs, since it</p>

    <p class="text-gray-300">&lt;sup&gt;1&lt;/sup&gt;The exception is concurrent work by Ben-Sasson et al. <a href="#page-38-7">[15]</a>; see <a href="#page-19-0">§9.</a></p>

    <p class="text-gray-300">    <img src="_page_2_Picture_0.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300"><strong>Figure 1</strong>—Verifiable outsourcing in Zaatar and Pinocchio, assuming a single instance of a computation  <span class="math">\\Psi</span>  on input x (amortization is depicted in Figure 2). Step ①:  <span class="math">\\mathcal{V}</span>  and  <span class="math">\\mathcal{P}</span>  compile  <span class="math">\\Psi</span>  from a high-level language to constraints  <span class="math">\\mathcal{C}</span> . Step ②:  <span class="math">\\mathcal{P}</span>  produces a satisfying assignment, z, to  <span class="math">\\mathcal{C}(X=x,Y=y)</span> . Step ③:  <span class="math">\\mathcal{P}</span>  uses complexity-theoretic and cryptographic machinery to convince  <span class="math">\\mathcal{V}</span>  that  <span class="math">\\mathcal{P}</span>  holds a satisfying assignment.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-2-1&quot;&gt;&lt;/span&gt;entails many identical computations. And the private state applications provide functionality that does not exist otherwise or previously required intricate custom protocols. In summary, Pantry extends proof-based verifiable computation to real applications of cloud computing (albeit at much smaller scales for now).</p>

    <h4 id="sec-3" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-2-0&quot;&gt;&lt;/span&gt;2 Pantry's base: Zaatar and Pinocchio</h4>

    <p class="text-gray-300">We present Zaatar [71] and Pinocchio [65], and the underlying theory, in a unified framework. Similar frameworks appear in prior work [65, 71–73, 80], and aspects of our presentation are borrowed [71, §2][80, §2].</p>

    <h4 id="sec-4" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-2-2&quot;&gt;&lt;/span&gt;2.1 Overview of Zaatar and Pinocchio</h4>

    <p class="text-gray-300">A client, or <em>verifier</em>  <span class="math">\\mathcal{V}</span> , sends a program  <span class="math">\\Psi</span> , expressed in a high-level language, to a server, or <em>prover</em>  <span class="math">\\mathcal{P}</span> .  <span class="math">\\mathcal{V}</span>  sends input x and receives output y, which is supposed to be  <span class="math">\\Psi(x)</span> .  <span class="math">\\mathcal{V}</span>  then engages  <span class="math">\\mathcal{P}</span>  in a protocol that allows  <span class="math">\\mathcal{V}</span>  to check whether  <span class="math">\\mathcal{P}</span>  executed correctly. This protocol assumes a computational bound on  <span class="math">\\mathcal{P}</span>  (e.g., that  <span class="math">\\mathcal{P}</span>  cannot break a cryptographic primitive). However, the protocol makes no other assumptions about  <span class="math">\\mathcal{P}</span> : its guarantees hold regardless of how or why  <span class="math">\\mathcal{P}</span>  malfunctions. These guarantees are probabilistic (over  <span class="math">\\mathcal{V}</span> 's random choices):</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Completeness. If  <span class="math">y = \\Psi(x)</span> , then if  <span class="math">\\mathcal{P}</span>  follows the protocol,  <span class="math">\\Pr{\\mathcal{V} \\text{ accepts}} = 1</span> .</li>
      <li>Soundness. If  <span class="math">y \\neq \\Psi(x)</span> , then  <span class="math">\\Pr\\{V \\text{ rejects}\\} &gt; 1 \\epsilon</span> , where  <span class="math">\\epsilon</span>  can be made small.</li>
    </ul>

    <p class="text-gray-300">Given a specific computation  <span class="math">\\Psi</span> , we call each invocation of it an <em>instance</em>. The per-instance costs for  <span class="math">\\mathcal{V}</span>  are very low. However, in order to participate in the protocol,  <span class="math">\\mathcal{V}</span>  incurs a setup cost for each  <span class="math">\\Psi</span> , which amortizes over multiple instances, either over a batch [71] or indefinitely [65] (see Section 2.3).</p>

    <h4 id="sec-5" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-2-3&quot;&gt;&lt;/span&gt;2.2 Zaatar and Pinocchio in more detail</h4>

    <p class="text-gray-300">Verifiably outsourcing a computation happens in three steps, depicted in Figure 1. First, a compiler transforms the computation  <span class="math">\\Psi</span>  to an algebraic system of <em>constraints</em>. Next,  <span class="math">\\mathcal{P}</span>  produces a solution to these constraints that implies  <span class="math">y = \\Psi(x)</span> . Finally,  <span class="math">\\mathcal{P}</span>  convinces  <span class="math">\\mathcal{V}</span>  that it has produced such a solution, thereby establishing that  <span class="math">y = \\Psi(x)</span> . We now describe each step in detail; for the time being, we assume only one instance (§2.3 revisits).</p>

    <p class="text-gray-300">(1)  <span class="math">\\Psi</span>  is represented as constraints. The programmer begins by expressing a computation,  <span class="math">\\Psi</span> , in a subset of C or an equivalent high-level language (described in §2.4) and invoking a compiler [55, 65, 71, 73]. Here, we focus on the compilation target: <em>a set of constraints</em> [24, 73].</p>

    <p class="text-gray-300">In our context, a set of constraints C is a system of equations in variables (X, Y, Z), over a large finite field,  <span class="math">\\mathbb{F}</span> ; we choose  <span class="math">\\mathbb{F} = \\mathbb{F}_p</span>  (the integers mod a prime p), where p is large (e.g., 128 bits). Each constraint</p>

    <p class="text-gray-300">has total degree 2, so each summand in a constraint is either a variable or a product of two variables. Variables <em>X</em> and <em>Y</em> represent the input and output variables, respectively; for now, we assume one of each. Upper-case letters (<em>X</em>, <em>Y</em>, <em>Z</em>, . . .) represent constraint variables; their lower-case counterparts (<em>x</em>, <em>y</em>,<em>z</em>, . . .) represent concrete values taken by (or assigned to, or bound to) those variables.</p>

    <p class="text-gray-300">Also, let C(<em>X</em>=<em>x</em>) mean C with <em>X</em> bound to <em>x</em> (V's requested input); C(<em>X</em>=<em>x</em>, <em>Y</em>=<em>y</em>) indicates that in addition <em>Y</em> is bound to <em>y</em> (the purported output). Notice that C(<em>X</em>=<em>x</em>, <em>Y</em>=<em>y</em>) is a set of constraints over the variables <em>Z</em>. If for some <em>z</em>, setting <em>Z</em>=<em>z</em> makes all constraints in C(<em>X</em>=<em>x</em>, <em>Y</em>=<em>y</em>) hold simultaneously, then C(<em>X</em>=<em>x</em>, <em>Y</em>=<em>y</em>) is said to be <em>satisfiable</em>, and <em>z</em> is a <em>satisfying assignment</em>.</p>

    <p class="text-gray-300">For a given computation Ψ, a set of constraints C is said to be <em>equivalent</em> to Ψ if: for all <em>x</em>, <em>y</em>, we have <em>y</em> = Ψ(<em>x</em>) if and only if C(<em>X</em>=<em>x</em>, <em>Y</em>=<em>y</em>) is satisfiable. As a simple example, the constraints C={<em>Z</em> − <em>X</em> = 0, <em>Z</em> + 1 − <em>Y</em> = 0} are equivalent to add-1 <a href="#page-39-14">[24]</a>. Indeed, consider a pair (<em>x</em>, <em>y</em>). If <em>y</em> = <em>x</em> + 1, then there is a satisfying assignment to C(<em>X</em>=<em>x</em>, <em>Y</em>=<em>y</em>), namely <em>Z</em>=<em>x</em>. However, if <em>y</em> 6= <em>x</em> + 1, then C(<em>X</em>=<em>x</em>, <em>Y</em>=<em>y</em>) is not satisfiable.</p>

    <p class="text-gray-300">(2) P computes and identifies a satisfying assignment. P &quot;executes&quot; Ψ(<em>x</em>) by identifying a satisfying assignment to the equivalent constraints C(<em>X</em>=<em>x</em>), and obtaining the output <em>y</em> in the process. To do so, P runs a constraint-solving routine that takes as input a compiler-produced list of annotated constraints. This routine goes constraint-by-constraint. A common case is that a constraint introduces a variable and can be written as an assignment to that new variable (e.g., {. . . , <em>Z</em>&lt;sup&gt;4&lt;/sup&gt; = <em>Z</em>&lt;sup&gt;3&lt;/sup&gt; · (<em>Z</em>&lt;sup&gt;2&lt;/sup&gt; + <em>Z</em>1), <em>Z</em>&lt;sup&gt;5&lt;/sup&gt; = <em>Z</em>&lt;sup&gt;4&lt;/sup&gt; · <em>Z</em>2, . . .}); the routine &quot;solves&quot; such constraints by evaluating their right-hand sides.</p>

    <p class="text-gray-300">Some constraints require additional work of P. An example is the != test (this will give some intuition for the techniques in Section <a href="#page-6-0">3)</a>. Consider the following snippet:</p>

    <pre><code class="language-text">if (Z1 != Z2)
    Z3 = 1;
else
    Z3 = 0;
</code></pre>

    <p class="text-gray-300">This compiles to the following constraints <a href="#page-39-14">[24]</a>:</p>

    <p class="text-gray-300"><span class="math">$C_{!=} = \\left\\{ \\begin{array}{rcl} M \\cdot (Z_1 - Z_2) - Z_3 &amp; = &amp; 0 \\\\ (1 - Z_3) \\cdot (Z_1 - Z_2) &amp; = &amp; 0 \\end{array} \\right\\}.</span>$</p>

    <p class="text-gray-300">Notice that the first constraint introduces <em>two</em> new variables (<em>M</em>, <em>Z</em>3), and thus there are multiple ways to satisfy this constraint. To choose values for these variables that also satisfy the second constraint, P's constraint-solving routine consults the constraints' annotations. The relevant annotation tells P that if <em>Z</em>&lt;sup&gt;1&lt;/sup&gt; 6= <em>Z</em>2, then P should set <em>M</em> equal to the multiplicative inverse of <em>Z</em>&lt;sup&gt;1&lt;/sup&gt; − <em>Z</em>2, which P computes outside of the constraint formalism. We call this &quot;computing exogenously&quot; (in theoretical terms, <em>M</em> and <em>Z</em>&lt;sup&gt;3&lt;/sup&gt; are &quot;non-deterministic input&quot;), and there is an analogy between the exogenous computation of <em>M</em> and supplying values from storage in Section <a href="#page-6-0">3.</a></p>

    <p class="text-gray-300">(3) P argues that it has a satisfying assignment. P wants to prove to V that it knows a satisfying assignment to C(<em>X</em>=<em>x</em>, <em>Y</em>=<em>y</em>); this would convince V that the output <em>y</em> is correct (and moreover that the computation, expressed in constraints, was executed correctly). Of course, there is a simple proof that a satisfying assignment exists: the satisfying assignment itself. However, V could check this proof only by examining all of it, which would be as much work as executing the computation.</p>

    <p class="text-gray-300">Instead, Zaatar and Pinocchio apply the theory of PCPs <a href="#page-38-3">[6,</a> <a href="#page-38-4">7]</a>,&lt;sup&gt;2&lt;/sup&gt; which implies that a classical proof—a satisfying assignment <em>z</em>, in this case—can be <em>encoded</em> into a long string π in a way that allows V to detect</p>

    <p class="text-gray-300">&lt;sup&gt;2&lt;/sup&gt;Our description takes some expositional license: Pinocchio's explicit base is GGPR <a href="#page-39-9">[36]</a>, which does not invoke PCPs. However, one can regard the <em>key</em> in their work as PCP queries, in encrypted form <a href="#page-39-15">[20]</a>.</p>

    <p class="text-gray-300">    <img src="_page_4_Figure_0.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">&lt;span id=&quot;page-4-0&quot;&gt;&lt;/span&gt;<strong>Figure 2</strong>—Amortization in Zaatar [71] and Pinocchio [65]. Superscripts denote different instances. In Zaatar,  <span class="math">\\mathcal{V}</span> 's work to formulate queries amortizes over a batch of  <span class="math">\\beta</span>  instances; in Pinocchio, analogous work amortizes over all future instances of the same computation (this is better). In both protocols, the  <span class="math">\\Psi \\to \\mathcal{C}</span>  step happens only once for each  <span class="math">\\Psi</span>  (not depicted).</p>

    <p class="text-gray-300">the proof's validity by (a) inspecting a small number of randomly-chosen locations in  <span class="math">\\pi</span> , and (b) applying efficient tests to the contents found at those locations. The details—what is in the encoding  <span class="math">\\pi</span> , how  <span class="math">\\mathcal V</span>  selects locations to inspect, what tests  <span class="math">\\mathcal V</span>  applies, and why all of this works—are beyond the scope of this paper.</p>

    <p class="text-gray-300">The protocols do not use PCPs alone: the encoded proof  <span class="math">\\pi</span>  is far larger than the number of steps in  <span class="math">\\Psi</span> , so making  <span class="math">\\mathcal V</span>  receive  <span class="math">\\pi</span>  would again defeat our purpose. To get around this issue, Zaatar and Pinocchio—and their theoretical progenitors—compose PCPs with cryptography, based on assumptions that  <span class="math">\\mathcal P</span>  cannot break certain primitives. There are two types of protocols; our compiler produces  <span class="math">\\mathcal V</span>  and  <span class="math">\\mathcal P</span>  binaries for both.</p>

    <p class="text-gray-300">First, Zaatar [71] instantiates an <em>efficient argument</em> [23, 47, 50, 72, 73]:  <span class="math">\\mathcal{V}</span>  extracts from  <span class="math">\\mathcal{P}</span>  a cryptographic <em>commitment</em> to  <span class="math">\\pi</span> , and then  <span class="math">\\mathcal{V}</span>  queries  <span class="math">\\mathcal{P}</span> , meaning that  <span class="math">\\mathcal{V}</span>  asks  <span class="math">\\mathcal{P}</span>  what values  <span class="math">\\pi</span>  contains at particular locations.  <span class="math">\\mathcal{V}</span>  uses PCPs to choose the locations and test the replies, and cryptography to ensure that  <span class="math">\\mathcal{P}</span> 's replies pass  <span class="math">\\mathcal{V}</span> 's tests only if  <span class="math">\\mathcal{P}</span> 's replies are consistent with a proof  <span class="math">\\pi</span>  that a satisfying assignment exists. The protocol details are given in prior works [71, §2][73, §2][72].</p>

    <p class="text-gray-300">The second variant is instantiated by Pinocchio [65] and known as a <em>non-interactive argument</em> [36, 37]: V preencrypts queries and sends them to P. As in the first variant, the queries are chosen by PCP machinery and describe locations where V wants to inspect an eventual  <span class="math">\\pi</span> . Here, however, P replies to the queries without knowing which locations V is querying. This process (hiding the queries, replying to them, testing the answers) relies on sophisticated cryptography layered atop the PCP machinery. The details are described elsewhere [20, 36, 65].</p>

    <h4 id="sec-6" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-4-1&quot;&gt;&lt;/span&gt;2.3 Amortization, guarantees, and costs</h4>

    <p class="text-gray-300"><span class="math">\\mathcal{V}</span>  incurs a setup cost (to express which locations in  <span class="math">\\pi</span>  to query) for each computation  <span class="math">\\Psi</span>  and each input size. This cost amortizes differently in Zaatar and Pinocchio.</p>

    <p class="text-gray-300">In Zaatar, amortization happens over a <em>batch</em>: a set of  <span class="math">\\beta</span>  instances of the identical computation  <span class="math">\\Psi</span> , on different inputs (Figure 2(a)). Thus, Zaatar presumes parallelism: for  <span class="math">j \\in \\{1, ..., \\beta\\}</span> ,  <span class="math">\\mathcal{V}</span>  sends parallel inputs  <span class="math">x^{(j)}</span> ,  <span class="math">\\mathcal{P}</span>  returns parallel outputs  <span class="math">y^{(j)}</span> , and  <span class="math">\\mathcal{P}</span>  formulates parallel proofs  <span class="math">\\pi^{(j)}</span>  establishing that  <span class="math">y^{(j)} = \\Psi(x^{(j)})</span> . The synchronization requirement is that V extract commitments to all  <span class="math">\\pi^{(j)}</span>  before issuing the queries (because queries are reused across the batch). Note that  <span class="math">\\mathcal{P}</span>  is an abstraction and could represent multiple machines (as in our MapReduce application in Section 4). Zaatar meets the completeness and</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">naive</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Zaatar [71], Pinocchio [65]</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">V, setup</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">c2&lt;br&gt;· ( Z  +  C )</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">V, runtime</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">β · (T( x ) + c1 y )</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">β · (c3&lt;br&gt;· ( x  +  y ))&lt;br&gt;+ c4</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">P, runtime</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">β · (c5&lt;br&gt;· ( Z  +  C ) + c6&lt;br&gt;·  C  · log  C )</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300"><em>T</em>: running time of computation as a function of input length.</p>

    <p class="text-gray-300">Figure 3—CPU costs of step (3) under Zaatar and Pinocchio, and under the naive approach: reexecute and compare. The amortization behavior is different for Zaatar and Pinocchio (see text). Also, the constants (<em>c</em>2, <em>c</em>3, . . .) differ: Pinocchio's <em>c</em>&lt;sup&gt;4&lt;/sup&gt; is lower while for the other constants, Zaatar's values are lower. Section <a href="#page-15-2">8.1</a> discusses these constants, the magnitudes of |<em>Z</em>| and |C|, and the costs of step (2).</p>

    <p class="text-gray-300">soundness properties given earlier (<a href="#page-2-2">§2.1)</a>, with &lt; 1/10&lt;sup&gt;6&lt;/sup&gt; (see <a href="#page-40-11">[71,</a> Apdx. A.2]), and in addition provides soundness for the batch: if for any <em>j</em> ∈ {1, . . . , β}, <em>y</em> (<em>j</em>) 6= Ψ(<em>x</em> (<em>j</em>) ), then Pr{<em>V</em> rejects the batch} &gt; 1 − .</p>

    <p class="text-gray-300">In Pinocchio, query formulation by V and installation on P happen once per Ψ, thereby amortizing over all future instances of the identical computation (Figure <a href="#page-4-0">2(</a>b)). Pinocchio meets the completeness and soundness properties, with &lt; 1/2 &lt;sup&gt;128&lt;/sup&gt;. Pinocchio also has versions that provide zero-knowledge (the prover can keep private the contents of the satisfying assignment <em>z</em>) and public verifiability <a href="#page-40-8">[65]</a>; the former provides a crucial foundation for Pantry's privacy-preserving applications (<a href="#page-14-0">§6)</a>.</p>

    <p class="text-gray-300">Figure <a href="#page-5-1">3</a> depicts the protocols' CPU costs for step (3). A key performance goal is that V <em>should incur lower (amortized) CPU costs than the naive alternative: reexecuting the computation <a href="#page-39-8">[35]</a></em>. &lt;sup&gt;3&lt;/sup&gt; Performance is thus evaluated as follows <a href="#page-40-8">[65,</a> <a href="#page-40-11">71</a><a href="#page-40-10">–73,</a> <a href="#page-41-7">80]</a>. (1) Are the per-instance costs for V less than the running time of Ψ, when Ψ is expressed in C and compiled to machine code? (Otherwise, the performance goal cannot be met.) (2) What is the <em>cross-over</em> point, meaning the number of instances past which V expends less total CPU than the naive verifier? (3) What are the overheads of P, relative to normal execution?</p>

    <p class="text-gray-300">Rough answers are as follows (see also Section <a href="#page-15-0">8)</a>. For question (1), the answer is &quot;sometimes; it depends on the computation&quot;. For (2), the cross-over points are tens of thousands or millions <a href="#page-40-11">[71,</a> §5.2], depending on the computation. For (3), the overheads are very high: factors of 10&lt;sup&gt;4&lt;/sup&gt; or 10&lt;sup&gt;5&lt;/sup&gt; are not uncommon.</p>

    <p class="text-gray-300">To briefly compare the performance of Zaatar and Pinocchio, Pinocchio has superior amortization behavior (see above) but higher proving and setup costs (and hence higher cross-over points), by constant factors.</p>

    <h4 id="sec-7" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-5-0&quot;&gt;&lt;/span&gt;2.4 Expressiveness</h4>

    <p class="text-gray-300">As context for Pantry, we now describe the language features and limitations of prior work <a href="#page-39-14">[24,</a> <a href="#page-40-8">65,</a> <a href="#page-40-11">71,</a> <a href="#page-40-10">73]</a>. Pre-Pantry, compilers accepted a C subset <a href="#page-40-8">[65]</a> (or the equivalent <a href="#page-40-15">[55,</a> <a href="#page-40-11">71,</a> <a href="#page-40-10">73]</a>) that includes functions, structs, typedefs, preprocessor definitions, if-else statements, explicit type conversion, and standard integer and bitwise operations. These compilers partially support pointers and loops: pointers and array indexes must be compile-time constants (ruling out a RAM abstraction), and likewise with the maximum number of loop iterations.</p>

    <p class="text-gray-300">When compiled, most operations introduce only a few new variables or constraints <a href="#page-40-11">[71,</a> §4]. There are four exceptions. The first two are inequalities and bitwise operations; these constructs separate numbers into their bits and glue them back together <a href="#page-39-14">[24,</a> <a href="#page-40-8">65,</a> <a href="#page-40-10">73]</a>, requiring ≈ log&lt;sup&gt;2&lt;/sup&gt; |F| constraints and variables per operation. The other two are looping and if-else statements: loops are unrolled at compile time, and the costs of an if-else statement combine the costs of the then-block and the else-block <a href="#page-39-14">[24]</a>.</p>

    <p class="text-gray-300"><em>x</em>, <em>y</em>: input and output of computation.</p>

    <p class="text-gray-300">β: number of instances over which V's setup cost amortizes</p>

    <p class="text-gray-300">&lt;span id=&quot;page-5-1&quot;&gt;&lt;/span&gt;<em>c</em>1, <em>c</em>2, . . .: model costs of processing input/output, cryptographic primitives, PCP queries, etc.</p>

    <p class="text-gray-300">&lt;sup&gt;3&lt;/sup&gt;One might think to compare to replicated execution (<a href="#page-0-0">§1)</a>, but a goal of verifiable computation is to provide very strong guarantees (<a href="#page-2-2">§2.1)</a>; replication stops working when faults are correlated.</p>

    <p class="text-gray-300">Apart from the specifics of language constructs and costs, the pre-Pantry model of computation is severely limited, even hermetic: computations can interact with state neither as auxiliary input, nor during execution, nor as auxiliary output. Therefore, using Zaatar or Pinocchio requires V to supply all inputs, receive all outputs, and eschew any notion of RAM, disk, or storage. These are the limitations addressed by Pantry.</p>

    <p class="text-gray-300">The core of Pantry is two primitives, verifiable PutBlock and GetBlock, that extend the model above. This section describes the primitives; Sections <a href="#page-8-0">4</a><a href="#page-14-0">–6</a> describe their use.</p>

    <p class="text-gray-300">To explain Pantry's approach, we note that the interface to step (3) in Section <a href="#page-2-3">2.2</a> is a set of constraints and a purported satisfying assignment. Thus, a first cut attempt at incorporating state into verifiable computation would be to represent load and store operations with constraints explicitly. However, doing so naively would incur horrific expense: if memory is an array of variables, then load(addr) would require a separate constraint for each possible value of addr (assuming addr is not resolvable at compile-time). This approach would also require the input state to be available to the verifier V.</p>

    <p class="text-gray-300">To overcome these problems, we want a model in which computations do not execute storage but can efficiently verify it. Given such a model, we could use constraints to represent computation (as we do now) as well as efficient <em>checks</em> of storage. But such a model is actually well-studied, in the context of untrusted storage: the state is represented by hash trees <a href="#page-39-12">[21,</a> <a href="#page-40-13">58]</a>, often accompanied by a naming scheme in which data blocks are referenced by hashes of their contents <a href="#page-39-13">[33,</a> <a href="#page-40-12">52]</a>.</p>

    <p class="text-gray-300">If we could efficiently represent the computation of the hash function as constraints, then we could extend the computational model in Section <a href="#page-2-0">2</a> with the semantics of untrusted storage. At that point, a satisfying assignment to the constraints would imply correct computation <em>and</em> correct interaction with state—and we could use step (3) from Section <a href="#page-2-3">2.2</a> to prove to V that P holds such an assignment. We now describe this approach.</p>

    <h3 id="sec-8" class="text-xl font-semibold mt-8">&lt;span id=&quot;page-6-1&quot;&gt;&lt;/span&gt;3.1 Verifiable blocks: overview</h3>

    <p class="text-gray-300">The lowest level of storage is a block store; it consists of variable-length blocks of data, in which the blocks are named by collision-resistant hash functions (CRHFs) of those blocks. Letting <em>H</em> denote a CRHF, a correct block store is a map</p>

    <p class="text-gray-300"><span class="math">$S: name \\rightarrow block \\cup \\bot</span>$
,</p>

    <p class="text-gray-300">where if <em>block</em> = <em>S</em>(<em>name</em>), then <em>H</em>(<em>block</em>) = <em>name</em>. In other words, <em>S</em> implements the relation <em>H</em> −1 . This naming scheme allows clients to use untrusted storage servers <a href="#page-39-13">[33,</a> <a href="#page-40-12">52]</a>. The technique's power is that given a name for data, the client can check that the returned block is correct, in the sense of being consistent with its name. Likewise, a client that creates new blocks can compute their names and use those names as references later in the computation.</p>

    <p class="text-gray-300">But unlike the scenario in prior work, our V cannot actually check the contents of the blocks that it &quot;retrieves&quot; or impose the correct names of the blocks that it &quot;stores&quot;, as the entire computation is remote. Instead, V represents its computations with constraints that P can satisfy only if P uses the right blocks. Another way to understand this approach is that V uses the verification machinery to outsource the storage checks to P; in fact, P itself could be using an untrusted block store!</p>

    <p class="text-gray-300">We will show in later sections how to write general-purpose computations; for now, we illustrate the model with a simple example. Imagine that the computation takes as input the name of a block and returns the associated contents as output. The constraints are set up to be satisfiable if and only if the return value hashes to the requested name. In effect, P is being asked to identify a preimage of <em>H</em>, which</p>

    <pre><code class="language-text">GetBlock(name n):
   block ← read block with name n in block store S
   assert n == H(block)
   return block
                                                           PutBlock(block):
                                                               n ← H(block)
                                                               store (n, block) in block store S
                                                               return n
</code></pre>

    <p class="text-gray-300">&lt;span id=&quot;page-7-0&quot;&gt;&lt;/span&gt;Figure 4—Pseudocode for verifiable storage primitives. These primitives compile to constraints that enforce the required relation between <em>n</em> and <em>block</em>; the constraints do not represent interactions with <em>S</em> explicitly.</p>

    <p class="text-gray-300">(by the collision-resistance of <em>H</em>) P can do only if it returns the actual block previously stored under the requested name.</p>

    <h3 id="sec-9" class="text-xl font-semibold mt-8">&lt;span id=&quot;page-7-1&quot;&gt;&lt;/span&gt;3.2 Verifiable blocks: details and costs</h3>

    <p class="text-gray-300">Pantry provides two primitives to the programmer:</p>

    <pre><code class="language-text">block = GetBlock(name);
name = PutBlock(block);
</code></pre>

    <p class="text-gray-300">These primitives are detailed in Figure <a href="#page-7-0">4.</a> Notice that in a correct execution, <em>H</em>(block)=name. Given this relation, and given the collision-resistance of <em>H</em>, the programmer receives from GetBlock and PutBlock a particular storage model: <em>S</em> functions as write-once memory, where the addresses are in practice unique, and where an address certifies the data that it holds.</p>

    <p class="text-gray-300">Of course, how <em>S</em> is implemented is unspecified here; the choice can be different for different kinds of storage (MapReduce, RAM, etc.). And, per the definition of <em>S</em>, block length can vary; for example, in the MapReduce application (<a href="#page-8-0">§4)</a>, an entire file will be one block.</p>

    <p class="text-gray-300">To bootstrap, the client supplies one or more names as input, and it may receive one or more names as output, for use in further computations. These names are related to capabilities <a href="#page-39-17">[44,</a> <a href="#page-40-17">51]</a>: with capabilities, a reference certifies to the system, by its existence, that the programmer is entitled to refer to a particular object; here, the reference itself certifies to the programmer that the system is providing the programmer with the correct object.</p>

    <p class="text-gray-300">We now describe the constraints that enforce the model. The code b = GetBlock(n) compiles to constraints C<em>H</em>−&lt;sup&gt;1&lt;/sup&gt; , where: the input variable, <em>X</em>, represents the name; the output variable, <em>Y</em>, represents the block contents; and C<em>H</em>−&lt;sup&gt;1&lt;/sup&gt; (<em>X</em>=<em>n</em>, <em>Y</em>=<em>b</em>) is satisfiable if and only if <em>b</em> ∈ <em>H</em> −1 (<em>n</em>) (i.e., <em>H</em>(<em>b</em>) = <em>n</em>). The code n = PutBlock(b) compiles to the same constraints, except that the inputs and outputs are switched. Specifically, this line compiles to constraints C<em>H</em>, where: <em>X</em> represents the block contents, <em>Y</em> represents the name, and C<em>H</em>(<em>X</em>=<em>b</em>, <em>Y</em>=<em>n</em>) is satisfiable if and only if <em>n</em> = <em>H</em>(<em>b</em>).</p>

    <p class="text-gray-300">Of course, C<em>&lt;sup&gt;H&lt;/sup&gt;</em> and C<em>H</em>−&lt;sup&gt;1&lt;/sup&gt; will usually appear inside a larger set of constraints, in which case the compiler relabels the inputs and outputs of C<em>&lt;sup&gt;H&lt;/sup&gt;</em> and C<em>H</em>−&lt;sup&gt;1&lt;/sup&gt; to correspond to intermediate program variables. As an example, consider the following computation:</p>

    <pre><code class="language-text">add(int x1, name x2) {
    block b = GetBlock(x2);
    /* assume that b is a field element */
    return b + x1;
}
</code></pre>

    <p class="text-gray-300">The corresponding constraints are:</p>

    <p class="text-gray-300"><span class="math">$C = \\{Y - B - X_1 = 0\\} \\cup C_{H^{-1}}(X = X_2, Y = B),</span>$</p>

    <p class="text-gray-300">where the notation <em>X</em>=<em>X</em>&lt;sup&gt;2&lt;/sup&gt; and <em>Y</em>=<em>B</em> means that, in C<em>H</em>−&lt;sup&gt;1&lt;/sup&gt; above, the appearances of <em>X</em> are relabeled <em>X</em>&lt;sup&gt;2&lt;/sup&gt; and the appearances of <em>Y</em> are relabeled <em>B</em>. Notice that variable <em>B</em> is unbound in C(<em>X</em>1=<em>x</em>1, <em>X</em>2=<em>x</em>2, <em>Y</em>=<em>y</em>). To assign <em>B</em>=<em>b</em> in a way that satisfies the constraints, P must identify a concrete <em>b</em>, presumably from storage, such that <em>H</em>(<em>b</em>)=<em>x</em>2.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-8-1&quot;&gt;&lt;/span&gt;<strong>Costs.</strong> The main cost of GetBlock and PutBlock is the set of constraints required to represent the hash function H in  <span class="math">C_H</span>  and  <span class="math">C_{H^{-1}}</span> . Unfortunately, widely-used functions (e.g., SHA-1) make heavy use of bitwise operations, which do not have compact representations as constraints (§2.4). Instead, we use an <em>algebraic</em> hash function, due to Ajtai [4, 40] and based on the hardness of approximation problems in lattices. The Ajtai function multiplies its input, represented as a bit vector, by a large matrix modulo an integer. This matrix-vector multiplication can be expressed concisely in constraints because constraints naturally encode sums of products (§2.2). Indeed, Ajtai requires approximately ten times fewer constraints than SHA-1 would. Nevertheless, Ajtai uses some bitwise operations (for modular arithmetic) and hence requires a substantial number of constraints (§8.1).</p>

    <h4 id="sec-10" class="text-lg font-semibold mt-6">3.3 Guarantees and non-guarantees</h4>

    <p class="text-gray-300">Appendices A and B describe the formal guarantees of Pantry; here we give an informal and heuristic explanation.</p>

    <p class="text-gray-300">Notice that the constraints do not capture the actual interaction with the block store S; the prover P is separately responsible for maintaining the map S. What ensures that P does so honestly? The high-level answer is the checks in the constraints plus the collision-resistance of H.</p>

    <p class="text-gray-300">As an illustration, consider this code snippet:</p>

    <pre><code class="language-text">n = PutBlock(b);
b&#x27; = GetBlock(n);
</code></pre>

    <p class="text-gray-300">In a reasonable (sequential) computational model, a read of a memory location should return the value written at that location; since our names act as &quot;locations&quot;, a correct execution of the code above should have variables b and b' equal. But the program is compiled to constraints that include  <span class="math">C_H</span>  (for PutBlock) and  <span class="math">C_{H^{-1}}</span>  (for GetBlock), and these constraints could in principle be satisfied with  <span class="math">b&#x27; \\neq b</span> , if H(b') = H(b). However,  <span class="math">\\mathcal{P}</span>  is prevented from supplying a spurious satisfying assignment because collision-resistance implies that identifying such a b and b' is computationally infeasible. That is, practically speaking,  <span class="math">\\mathcal{P}</span>  can satisfy the constraints only if it stores the actual block and then returns it.</p>

    <p class="text-gray-300">However, Pantry does not formally enforce <em>durability</em>: a malicious  <span class="math">\\mathcal{P}</span>  could discard blocks inside PutBlock yet still exhibit a satisfying assignment. Such a  <span class="math">\\mathcal{P}</span>  might be caught only when executing a subsequent computation (when  <span class="math">\\mathcal{V}</span>  issues a corresponding GetBlock,  <span class="math">\\mathcal{P}</span>  would be unable to satisfy the constraints), and at that point, it might be too late to get the data back. For a formal guarantee of durability, one can in principle use other machinery [74]. Also, Pantry (like its predecessors) does not enforce <em>availability</em>:  <span class="math">\\mathcal{P}</span>  could refuse to engage, or fail to supply a satisfying assignment, even if it knows one.</p>

    <p class="text-gray-300">What Pantry enforces is <em>integrity</em>, meaning that purported memory values (the blocks that are used in the computation) are consistent with their names, or else the computation does not verify.</p>

    <p class="text-gray-300">For this reason, if  <span class="math">\\mathcal{V}</span> 's computation executes GetBlock(foo), and foo is an erroneous name in the sense that it does not represent the hash of any block previously stored, then  <span class="math">\\mathcal{P}</span>  has no way of providing a satisfying assignment. This is as it should be: the computation itself is erroneous (in this model, correct programs pass the assert in GetBlock; see Figure 4).</p>

    <p class="text-gray-300">A limitation of this model is that  <span class="math">\\mathcal{P}</span>  cannot prove to  <span class="math">\\mathcal{V}</span>  that  <span class="math">\\mathcal{V}</span>  made such an error; to the argument step (step (3) in §2.2), this case looks like the one in which  <span class="math">\\mathcal{P}</span>  refuses to provide a satisfying assignment. While that might be disconcerting, Pantry's goal is to establish that a remote execution is consistent with an expressed computation; program verification is a complementary concern (§1).</p>

    <h4 id="sec-11" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-8-0&quot;&gt;&lt;/span&gt;4 Verifiable MapReduce</h4>

    <p class="text-gray-300">This section describes how Pantry provides verifiability for MapReduce jobs. We begin with a brief review of the standard MapReduce model [30].</p>

    <pre><code class="language-text">DigestArray Mapper(Digest X) {
    Block list_in = GetBlock(X);
    Block list_out[NUM_REDUCERS];
    Digest Y[NUM_REDUCERS];
    // invoke programmer-supplied Map
    Map(list_in, &amp;list_out);
    for (i = 0; i &lt; NUM_REDUCERS; i++)
        Y[i] = PutBlock(list_out[i]);
    return Y;
}
                                                        Digest Reducer(DigestArray X) {
                                                            Block list_in[NUM_MAPPERS];
                                                            Block list_out;
                                                            for (i = 0; i &lt; NUM_MAPPERS; i++)
                                                                list_in[i] = GetBlock(X[i]);
                                                            // invoke programmer-supplied Reduce
                                                            Reduce(list_in, &amp;list_out);
                                                            Y = PutBlock(list_out);
                                                            return Y;
                                                        }
</code></pre>

    <p class="text-gray-300">&lt;span id=&quot;page-9-0&quot;&gt;&lt;/span&gt;Figure 5—For verifiable MapReduce, Pantry regards the depicted functions, Mapper and Reducer, as separate computations. The two functions compile to separate constraints, and V verifies in two batches: one for the mappers and one for the reducers.</p>

    <p class="text-gray-300">A MapReduce <em>job</em> consists of Map and Reduce functions, and input data structured as a list of key-value pairs; the output is a transformed list of key-value pairs. The programmer supplies the implementations of Map and Reduce; Map takes as input a list of key-value pairs and outputs another list of key-value pairs, and Reduce takes as input a list of values associated with a single key and outputs another list of values. The <em>framework</em> runs multiple instances of Map and Reduce as stand-alone processes, called <em>mappers</em> and <em>reducers</em>. The framework gives each mapper a chunk of the input data, <em>shuffles</em> the mappers' output, and supplies it to the reducers; each reducer's output contributes a chunk to the overall output of the job. A centralized module, which is part of the framework, drives the job (by assigning processes to machines, etc.).</p>

    <p class="text-gray-300">Overview of MapReduce in Pantry. The verifier V is a machine that invokes a MapReduce job (for instance, the desktop machine of a cloud customer). The goal of Pantry's MapReduce is to assure V that its job starts from the correct input data and executes correctly from there.</p>

    <p class="text-gray-300">The model here will be similar to the standard one outlined above, except that the input and output files will be verifiable blocks (<a href="#page-6-0">§3)</a>: a file will be referenced by a collision-resistant hash, or <em>digest</em>, of its contents (from now on, we use &quot;digest&quot; and &quot;name&quot; interchangeably). In this model, invoking a MapReduce job requires V to supply a list of digests, one for each input file; call this list <em>x</em>. Likewise, V receives as output a list of digests, <em>y</em>. V learns of the digests in <em>x</em> either from a bootstrapping step (creating the data and keeping track of its digest, say) or as the output of a job; likewise, V can use the digests in <em>y</em> either to download (and verify the integrity of) the actual data or to feed another job. That is, these digests are self-certifying references to the data <a href="#page-39-13">[33,</a> <a href="#page-40-12">52]</a>.</p>

    <p class="text-gray-300">Given this model, V will be guaranteed that the output digests <em>y</em> are correct, meaning that the actual input data (the key-value pairs whose digests are <em>x</em>), when transformed by V's desired Map and Reduce functions, results in output data with digests <em>y</em>. But providing this guarantee requires an application of the verification machinery (<a href="#page-2-0">§2–</a><a href="#page-6-0">§3)</a>, which raises a design question: what exactly is the computation to be verified, and which machine(s) implement P?</p>

    <p class="text-gray-300">Pantry's approach is as follows (we discuss the rationale later). The verifier regards the MapReduce job as two separate batch computations (<a href="#page-4-1">§2.3)</a>, one for the map phase and one for the reduce phase. In these computations, each mapper and reducer is an instance, with a prover. In our design, V handles an intermediate digest for every (mapper, reducer) pair.</p>

    <p class="text-gray-300">Mechanics. Pantry's MapReduce framework wraps Map and Reduce into functions Mapper and Reducer, which are depicted in Figure <a href="#page-9-0">5;</a> the job is executed by multiple instances of each. For verification, Pantry's C-to-constraint compiler transforms these functions into constraints, and then each instance—</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">naive (local)</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Pantry</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">CPU costs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">V, setup</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">c2&lt;br&gt;· ( Zmapper  +  CMapper )</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">V, runtime</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">M · Tmapper( ch )</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">M · (c3&lt;br&gt;·  d  · (R + 1))&lt;br&gt;+ c4</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">network costs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">setup</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">c7&lt;br&gt;· ( Zmapper  +  CMapper )</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">runtime</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">M ·  ch</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">M · (c8&lt;br&gt;+  d  · (R + 1))</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Tmapper: running time of a map instance&lt;br&gt;M: # of mappers</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">ch : length of a mapper's input</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">d : length of a digest</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">&lt;span id=&quot;page-10-0&quot;&gt;&lt;/span&gt;Figure 6—Verification costs in Pantry's MapReduce and naive (local) verification, for the map phase; the reduce phase is similar. The CPU costs largely follow Figure <a href="#page-5-1">3;</a> the main difference is that V now handles only a <em>digest</em> of the inputs. P's costs are omitted, but the substitutions are similar.</p>

    <p class="text-gray-300">playing the role of the prover—convinces V that it knows a satisfying assignment to the corresponding constraints (<a href="#page-2-3">§2.2,</a> step (3)). Execution and verification can be decoupled, but under Zaatar, the complete execution of a phase (map or reduce) must happen before verification of that phase.</p>

    <p class="text-gray-300">We now give more detail, beginning with some notation. Let <em>M</em> and <em>R</em> be the number of mappers and reducers, and CMapper and CReducer the constraint representations of Mapper and Reducer. Also, recall that superscripts denote instances in a batch (<a href="#page-4-1">§2.3)</a>.</p>

    <p class="text-gray-300">When the mappers execute, each instance <em>j</em> ∈ {1, . . . , <em>M</em>} gets as its input, <em>x</em> (<em>j</em>) , the digest of some data. The output of an instance, <em>map out</em>(<em>j</em>) , is a vector of <em>R</em> digests, one for each reducer that this mapper is &quot;feeding&quot;; the framework receives this output and forwards it to V. Verification convinces V that each mapper <em>j</em> knows a satisfying assignment to CMapper(<em>X</em>=<em>x</em> (<em>j</em>) , <em>Y</em>=<em>map out</em>(<em>j</em>) ), which establishes for V that the mapper worked over the correct data, applied Map correctly, partitioned the transformed data over the reducers correctly, and—in outputting <em>map out</em>(<em>j</em>)—named the transformed data correctly. Note that {<em>map out</em>(<em>j</em>)}<em>j</em>={1,...,<em>M</em>} are the <em>M</em> · <em>R</em> intermediate digests mentioned above.</p>

    <p class="text-gray-300">The framework then supplies the inputs to the second phase, by shuffling the digests {<em>map out</em>(<em>j</em>)}<em>j</em>={1,...,<em>M</em>} and regrouping them as {<em>reduce in</em>(<em>j</em>) }<em>j</em>={1,...,<em>R</em>} , where each <em>reduce in</em>(<em>j</em>) is a vector of <em>M</em> digests, one for each mapper. (V does this regrouping too, in order to know the reducers' inputs.)</p>

    <p class="text-gray-300">The framework then invokes the reducers, and the output of each reducer <em>j</em> ∈ {1, . . . , <em>R</em>} is a single digest <em>y</em> (<em>j</em>) . Verification convinces V that each reducer <em>j</em> knows a satisfying assignment to CReducer(<em>X</em>=<em>reduce in</em>(<em>j</em>) , <em>Y</em>=<em>y</em> (<em>j</em>) ). This establishes for V that each reducer worked over the correct <em>M</em> blocks, applied Reduce to them correctly, and produced the correct output digests.</p>

    <p class="text-gray-300">Analysis. Figure <a href="#page-10-0">6</a> compares the costs of the map phase under Pantry's MapReduce and the naive approach of verifying a job by downloading the inputs (perhaps checking them against digests) and locally executing the computation. A similar analysis applies to the reduce phase.</p>

    <p class="text-gray-300">Both pre-Pantry and under Pantry, the verifier can save CPU cycles compared to the naive verifier provided that the per-instance verification cost is less than the cost to execute the instance. Pre-Pantry, this condition holds only if <em>c</em>&lt;sup&gt;3&lt;/sup&gt; + <em>c</em>&lt;sup&gt;4&lt;/sup&gt; ·(|<em>x</em>| + |<em>y</em>|) &lt; <em>T</em>(|<em>x</em>|) + <em>c</em>1|<em>y</em>|, implying that using the verification machinery makes sense only if the computation is superlinear in its input size (see Figure <a href="#page-5-1">3)</a>. Under Pantry, however, the analogous condition holds when <em>c</em>&lt;sup&gt;3&lt;/sup&gt; + <em>c</em>&lt;sup&gt;4&lt;/sup&gt; · |<em>d</em>| · (<em>R</em> + 1) &lt; <em>T</em>mapper(|<em>ch</em>|), which can hold even when the computation is <em>linear</em> in its input. If this condition holds, then the CPU cross-over point (<a href="#page-4-1">§2.3)</a> occurs when <em>M</em> ≥ <em>c</em>2·(|<em>Z</em>mapper|+|CMapper|) <em>T</em>mapper(|<em>ch</em>|)−<em>c</em>3−<em>c</em>4·|<em>d</em>|·(<em>R</em>+1) , per Figure <a href="#page-10-0">6.</a></p>

    <p class="text-gray-300">Pantry also saves the verifier network costs. This happens when <em>M</em> ≥ <em>c</em>7·(|<em>Z</em>mapper|+|CMapper|) |<em>ch</em>|−<em>c</em>8−<em>R</em>·|<em>d</em>| . Notice that the floor on <em>M</em> is proportional to the setup costs: the higher the setup costs, the more instances are needed to beat naive verification. Also, the floor moves inversely with |<em>ch</em>|: the larger the chunk size, the greater the expense incurred by the naive verifier in downloading the inputs.</p>

    <p class="text-gray-300">We emphasize that this analysis is predicated on a baseline that is favorable to Pantry. If the baseline were instead local execution and local storage (no remote party at all), then Pantry would never save network costs. However, the analyzed baseline corresponds to common uses of the cloud today: MapReduce jobs execute remotely because their inputs <em>are</em> remote, so downloading and uploading ought to be recognized as a cost. Another basis for comparison is Zaatar and Pinocchio: their verifiers handle all inputs and outputs, and thus cannot ever save network costs.</p>

    <p class="text-gray-300">Summarizing the analysis, a MapReduce application calls for Pantry if (a) verifiability is needed and (b) the computational cost of the job is high (so there is a CPU cross-over point), there is a lot of data (so there is a network cross-over point), or both.</p>

    <p class="text-gray-300">Rationale and limitations. Our design reflects awkward aspects of the framework. For example, because of the existence of setup costs (<a href="#page-4-1">§2.3)</a>, we chose to have V handle intermediate digests. In more detail, V could avoid handling intermediate digests—it could verify the job's output digests {<em>y</em> (<em>j</em>)} directly from the input digests {<em>x</em> (<em>j</em>)}—by verifying a single batch. But each instance would have to encompass constraints for one reducer and <em>M</em> mappers, causing setup costs to be, undesirably, proportional to the <em>aggregate</em> mappers' (instead of a single mapper's) work. To further explain our choice, we note that quadratic intermediate state is not inherently disastrous: in standard MapReduce, the framework keeps <em>O</em>(<em>M</em> · <em>R</em>) state <a href="#page-39-19">[30]</a>.</p>

    <p class="text-gray-300">Other limitations stem from the constraint model. For example, we eschew a general-purpose partitioning module in the mapper, as it would compile to a large number of constraints, increasing costs. Instead, the programmer must partition the output of Map into <em>R</em> chunks, and must similarly read from <em>M</em> inputs in Reduce—tasks that are hidden in standard MapReduce. Moreover, Map and Reduce face the expressiveness restrictions described earlier (<a href="#page-5-0">§2.4)</a>; one consequence is that each mapper's chunk size must be identical and fixed at compile time, and likewise with the reducers.</p>

    <p class="text-gray-300">This section describes Pantry's higher-level storage abstractions: RAM, a searchable tree, and a simple database. As with MapReduce, we want to implement the abstractions as data structures in a subset of C, augmented with PutBlock and GetBlock (<a href="#page-6-0">§3)</a>. To do so, we apply the technique of embedding in data blocks the names (or references or hashes—these concepts are equivalent here) of other blocks <a href="#page-39-12">[21,</a> <a href="#page-39-13">33,</a> <a href="#page-40-12">52,</a> <a href="#page-40-18">54,</a> <a href="#page-40-13">58]</a> (see also <a href="#page-19-0">§9)</a>. In the resulting structure, the hashes are links—or pointers that authenticate what they point to. The starting hash (for instance, of the root of a tree) can authenticate any value in the structure; we review how this is done below. We can then incorporate the resulting abstractions into some larger C program, compile that program to constraints, and apply the argument step (<a href="#page-2-3">§2.2)</a> to those constraints.</p>

    <p class="text-gray-300">Pantry's verifiable RAM abstraction enables random access to contiguously-addressable, fixed-size memory cells. It exposes the following interface:</p>

    <pre><code class="language-text">value = Load(address, digest);
new digest = Store(address, value, digest);
</code></pre>

    <p class="text-gray-300">Pseudocode for the implementation is in Figure <a href="#page-12-0">7.</a></p>

    <p class="text-gray-300">The high-level idea behind this pseudocode is that the digest commits to the full state of memory <a href="#page-39-12">[21,</a> <a href="#page-40-13">58]</a>, in a way that we explain shortly. Then, a Load guarantees that the claim &quot;<em>address</em> contains <em>value</em>&quot; is consistent with <em>digest</em>. For Store, the guarantee is that <em>new digest</em> captures the same memory state that <em>digest</em> does with the exception that <em>address</em> now holds <em>value</em>.</p>

    <pre><code class="language-text">Load(address a, digest d):
  \` ← dlogNe
  h ← d
  for i = 1 to \`:
     node ← GetBlock(h)
     x ← ith bit of a
     if x = 0:
        h ← node.left
     else:
        h ← node.right
  node ← GetBlock(h)
  return node.value
                                                       Store(address a, value v, digest d):
                                                          path ← LoadPath(a, d)
                                                          \` ← dlogNe
                                                          node ← path[\`]
                                                          node.value ← v
                                                          d
                                                           0 ← PutBlock(node)
                                                          for i = \` to 1:
                                                             node ← path[i − 1]
                                                             x ← ith bit of a
                                                             if x = 0:
                                                               node.left ← d
                                                                              0
                                                             else:
                                                               node.right ← d
                                                                               0
                                                             d
                                                              0 ← PutBlock(node)
                                                          return d
                                                                  0
</code></pre>

    <p class="text-gray-300">&lt;span id=&quot;page-12-0&quot;&gt;&lt;/span&gt;Figure 7—RAM operations use verifiable blocks in a Merkle tree <a href="#page-39-12">[21,</a> <a href="#page-40-13">58]</a>. <em>N</em> is the number of addresses in the memory.</p>

    <p class="text-gray-300">To explain how a digest <em>d</em> can commit to memory, we briefly review Merkle trees <a href="#page-39-12">[21,</a> <a href="#page-40-13">58]</a>. Every node is named by a collision-resistant hash (denoted <em>H</em>) of its contents. An interior node's contents are the names (or hashes) of the node's left and right children. Each leaf node corresponds to a memory address, and contains the value currently held at the memory address. Then, the digest <em>d</em> is the hash of the root node's contents. Indeed, if entity <em>A</em> holds a digest <em>d</em>, and entity <em>B</em> claims &quot;the value at address <em>a</em> is <em>v</em>&quot;, then <em>B</em> could argue that claim to <em>A</em> by exhibiting a <em>witness-path</em>: the purported name of <em>a</em>'s sibling, the purported name of their parent, and so on, to the root. <em>A</em> could then check that the hash relationships hold and match <em>d</em>. For <em>B</em> to succeed in a spurious claim, it would have to identify a collision in <em>H</em>.</p>

    <p class="text-gray-300">The pseudocode in Figure <a href="#page-12-0">7</a> is simply applying this idea: the verifiable blocks in Section <a href="#page-6-0">3</a> provide the required names-are-hashes referencing scheme, and the GetBlock invocations compile to constraints that force P to exhibit a witness-path. Thus, using CLoad to denote the constraints to which Load compiles, CLoad(<em>X</em>=(<em>a</em>, <em>d</em>), <em>Y</em>=<em>v</em>) can be satisfied only if the digest <em>d</em> is consistent with address <em>a</em> holding value <em>v</em>, which is the guarantee that Load is supposed to be providing.</p>

    <p class="text-gray-300">How does P identify a path through the tree? In principle, it could recompute the internal nodes on demand from the leaves. But for efficiency, our implementation caches the internal nodes to avoid recomputation.</p>

    <p class="text-gray-300">To invoke Load or Store, the program must begin with a digest; in Pantry, V supplies this digest as part of the input to the computation. One way to bootstrap this is for V to first create a small amount of state locally, then compute the digest directly, then send the data to P, and then use the verification machinery to track the changes in the digest. Of course, this requires that a computation's output include the new digest.</p>

    <p class="text-gray-300">This brings us to the implementation of Store, which takes as input one digest and returns a digest of the new state. Store begins by placing in local variables the contents of the nodes along the required path (LoadPath in Figure <a href="#page-12-0">7</a> is similar to Load and involves calls to GetBlock); this ensures continuity between the old state and the new digest. Store then updates this path by creating new verifiable blocks, starting with the block for address <em>a</em> (which is a new verifiable block that contains a new value), to that block's parent, and so on, up to the root. Let CStore denote the constraints that Store compiles to. To satisfy CStore(<em>X</em>=(<em>a</em>, <em>v</em>, <em>d</em>), <em>Y</em>=<em>d</em> 0 ), P must (1) exhibit a path through the tree, to <em>a</em>, that is consistent with <em>d</em>, and (2) compute a new digest that is consistent with the old path and with the memory update. Thus, the constraints enforce the guarantee that Store promises.</p>

    <p class="text-gray-300">Costs. We briefly describe the blowup from the constraint representation; Sections <a href="#page-2-3">2.2</a> and <a href="#page-8-0">4</a> show how this blowup feeds into the costs of V and P. Letting <em>N</em> denote the number of memory addresses, a Load or Store compiles to <em>O</em>(log<em>N</em>) constraints and variables, with the constant mostly determined by the constraint representation of <em>H</em> inside GetBlock and PutBlock (<a href="#page-8-1">§3.2)</a>.</p>

    <h3 id="sec-12" class="text-xl font-semibold mt-8">&lt;span id=&quot;page-13-0&quot;&gt;&lt;/span&gt;5.2 Search tree</h3>

    <p class="text-gray-300">We now consider a searchable tree; we wish to support efficient range searches over any keys for which the less-than comparison is defined. Specifically, we wish to support the following API:</p>

    <pre><code class="language-text">values = FindEquals(key, digest)
values = FindRange(key start, key end, digest)
new digest = Insert(key, value, digest)
new digest = Remove(key, digest)
</code></pre>

    <p class="text-gray-300">To implement this interface, a first cut approach would be to use the general-purpose RAM abstraction (<a href="#page-11-1">§5.1)</a> to build a binary tree or B-tree out of pointers (memory addresses). Unfortunately, this approach is more expensive than we would like: since every pointer access in RAM costs <em>O</em>(log<em>N</em>), a search in a balanced tree of <em>m</em> elements would cost <em>O</em>((log <em>N</em>) · (log <em>m</em>)). Instead, we use an alternative construction, which illustrates a strategy applicable to a wide class of data structures.</p>

    <p class="text-gray-300">To get the per-operation cost down to <em>O</em>(log <em>m</em>), we build a <em>searchable</em> Merkle tree (this is different from the tree in <a href="#page-11-1">§5.1)</a>. Each node in the tree contains a key, one or more values corresponding to that key, and pointers to (that is, hashes of) its children. The nodes are in sorted order, and the tree is a balanced (AVL) tree, so operations take time that is logarithmic in the number of keys stored.</p>

    <p class="text-gray-300">A search operation (FindEquals, FindRange) descends the tree, via a series of GetBlock calls. An update operation (Insert, Remove) first descends the tree to identify the node where the operation will be performed; then modifies that node (via PutBlock, thereby giving it a new name); and then updates the nodes along the path to the root (again via PutBlock), resulting in a new digest. As with RAM, these operations are expressed in C and compile to constraints; if P satisfies the resulting constraints then, unless it has identified a collision in <em>H</em>, it is returning the correct state (in the case of searches) and the correct digests (in the case of updates).</p>

    <h4 id="sec-13" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-13-1&quot;&gt;&lt;/span&gt;5.3 Verifiable database queries</h4>

    <p class="text-gray-300">The data structures described above enable us to implement a simple database that supports verifiable queries.</p>

    <p class="text-gray-300">V specifies queries in a primitive SQL-like language, which supports the following non-transactional queries on single tables: SELECT (the WHERE predicates must refer to a single column), INSERT, UPDATE, DELETE, CREATE, and DROP. V and P convert each query into C code that invokes the APIs from Sections <a href="#page-7-1">3.2</a> and <a href="#page-13-0">5.2,</a> and is then compiled into constraints.</p>

    <p class="text-gray-300">The database itself has a simple design. Each row of every table is stored as a verifiable block, accessed through GetBlock/PutBlock (<a href="#page-6-0">§3)</a>. These blocks are pointed to by one or more indexes, and there is a separate index for each column that the author of the computation wants to be searchable. Indexes are implemented as verifiable search trees (<a href="#page-13-0">§5.2)</a>, and database queries are converted into a series of calls to the trees' FindEquals, FindRange, Insert, and Remove operations.</p>

    <p class="text-gray-300">Because this database uses verifiable data structures and the code is compiled into constraints, we get strong integrity guarantees—with little programmer effort beyond implementing the data structures and queries.</p>

    <h4 id="sec-14" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-13-2&quot;&gt;&lt;/span&gt;5.4 Compromises and limitations</h4>

    <p class="text-gray-300">A key compromise is that efficiency sometimes requires not using RAM and instead constructing data structures directly from verifiable pointers (<a href="#page-13-0">§5.2,</a> <a href="#page-13-1">§5.3)</a>. One consequence is that the implementer of these data structures is directly exposed to the clumsiness of the constraint model (<a href="#page-5-0">§2.4)</a>; for example, if the data structure implementation indexes into a small array at a variable offset, the code must loop through the set of possible indexes.</p>

    <p class="text-gray-300">The constraint model imposes several other limitations. First, because traversal loops have fixed bounds, data structures have a static size (a fixed depth for trees, etc.), regardless of the number of elements that they logically contain. (However, empty cells and nodes need not consume memory or disk.) For similar reasons, the number of results returned by the search API must be fixed at compile time. Third, as every operation on a data structure is compiled into a fixed number of constraints, P's running time to perform the operation is largely determined by the data structure's static size.</p>

    <h3 id="sec-15" class="text-xl font-semibold mt-8">&lt;span id=&quot;page-14-0&quot;&gt;&lt;/span&gt;6 Private prover state</h3>

    <p class="text-gray-300">Pantry enables applications where the prover's state is private. For example, the prover holds photographs (e.g., of suspects), the verifier (e.g., a surveillance camera) submits a photograph, and the prover indicates if there is a match. Using Pantry, the client is assured that the response is correct, but no information about the prover's database leaks (beyond what the output implies).</p>

    <p class="text-gray-300">Pinocchio's zero-knowledge (ZK) variant <a href="#page-39-9">[36,</a> <a href="#page-40-8">65]</a> provides most of the solution. Here, step (3) of Section <a href="#page-2-3">2.2</a> persuades V that P has a satisfying assignment to a set of constraints (as usual), but P cryptographically hides the actual satisfying assignment. Since the contents of P's state appear in the satisfying assignment (<a href="#page-6-0">§3)</a>, the ZK variant effectively hides P's state—almost. The wrinkle is that, under Pantry as so far described, V would begin with a cryptographic digest of P's state (<a href="#page-11-0">§5)</a>, and this digest itself leaks information (V could conceivably guess P's state and use a digest to check the guess).</p>

    <p class="text-gray-300">Thus, we assume that V begins with a cryptographic <em>commitment</em> <a href="#page-39-20">[39,</a> §4.4.1] to the prover's state. A commitment binds the prover to its state in a way that permits verifiable queries against that state (as with the previously described digests) but also hides the state. Then, the computation to be verified takes as input a commitment (not a digest), begins by querying for values and checking that they are consistent with the commitment (as with digests), and then uses those values in the rest of the computation. To summarize, the commitment hides the prover's beginning state from V, and the ZK machinery hides the prover's execution.</p>

    <p class="text-gray-300">To realize this approach, we want a commitment primitive that has a reasonably efficient representation in constraints. As a compromise, we instantiate a simple scheme using HMAC-SHA256 <a href="#page-38-10">[13]</a> (see Appendix C for details). Relative to the protocol of Pedersen <a href="#page-40-19">[67]</a>, our scheme makes a stronger cryptographic assumption but saves an order of magnitude in constraint size. Of course, this scheme uses SHA-256,&lt;sup&gt;4&lt;/sup&gt; so it is more expensive for us than Ajtai's function (<a href="#page-8-1">§3.2)</a>, but the expense is incurred only once per execution (<a href="#page-15-2">§8.1)</a>.</p>

    <p class="text-gray-300">Applications. We build (<a href="#page-15-1">§7)</a> and evaluate (<a href="#page-15-0">§8)</a> several applications of the machinery described above. The first is <em>face matching</em>, which implements the example at the start of this section. This example is inspired by previous work <a href="#page-40-20">[63]</a>, but that work provides privacy to both parties and verifiability to neither. The second is <em>tolling</em>; the prover is a car, the verifier is a toll collector, and the verifier checks the prover's claim about what it owes for the billing period. This example is inspired by <a href="#page-40-21">[68]</a>, which requires a custom protocol, while we require only a simple C program (<a href="#page-15-1">§7)</a>. The third application is <em>regression analysis</em> (again inspired by prior work that requires a custom protocol <a href="#page-40-22">[62]</a>); the prover holds a set of patient files, the verifier is an analyst seeking to fit a model to this data, and the computation returns the best-fit parameters. The details of our applications are in Appendix D.</p>

    <p class="text-gray-300">&lt;sup&gt;4&lt;/sup&gt;Ajtai is unsuitable because it is not a pseudorandom function (PRF) and therefore would not hide the prover's beginning state.</p>

    <p class="text-gray-300">The Pantry implementation modifies the Ginger-Zaatar compiler <a href="#page-39-14">[24,</a> <a href="#page-40-11">71,</a> <a href="#page-40-10">73]</a>. The base compiler first transforms programs written in a high-level language (<a href="#page-5-0">§2.4)</a> into a list of assignment statements, producing a constraint or <em>pseudoconstraint</em> for each statement. The pseudoconstraints abstract operations that require multiple constraints (inequality comparisons, bitwise operations, etc.). Next, the compiler expands the pseudoconstraints and annotates the results (<a href="#page-2-3">§2.2)</a>. The verifier and prover each consist of computationindependent routines that take a list of annotated constraints as input. P's routines solve the constraints and use the resulting satisfying assignment to respond to queries; V's routine selects queries according to the argument protocol and tests the replies (<a href="#page-2-3">§2.2)</a>.</p>

    <p class="text-gray-300">Pantry adds several conveniences to the base compiler. Following Pinocchio <a href="#page-40-8">[65]</a>, the Pantry compiler accepts a subset of C (<a href="#page-5-0">§2.4)</a>. More significantly, the compiler targets the Pinocchio and the Zaatar encodings, with a unified code base. The main work here was implementing Pinocchio's pairing-based cryptography, for which we use a public library <a href="#page-38-11">[2,</a> <a href="#page-38-12">17]</a>.</p>

    <p class="text-gray-300">To implement GetBlock and PutBlock (<a href="#page-6-0">§3)</a>, Pantry includes new pseudoconstraints, which expand to C<em>H</em>−&lt;sup&gt;1&lt;/sup&gt; and C<em>H</em>, respectively. The associated annotations tell P how to interact with storage <em>S</em> (see Figure <a href="#page-7-0">4)</a>; we implement <em>S</em> using the LevelDB key-value store <a href="#page-38-13">[3]</a>.</p>

    <p class="text-gray-300">The C<em>H</em>−&lt;sup&gt;1&lt;/sup&gt; and C<em>&lt;sup&gt;H&lt;/sup&gt;</em> constraints implement <em>H</em> as (a variable-length version of) the Ajtai <a href="#page-38-9">[4,</a> <a href="#page-39-18">40]</a> hash function. Using the notation in <a href="#page-39-18">[40]</a>, this function hashes <em>m</em> bits into <em>n</em> · log <em>q</em> bits. Based on the analysis in <a href="#page-40-23">[59]</a>, we set these parameters as <em>m</em>=7296, <em>n</em>=64, and <em>q</em>=2 &lt;sup&gt;19&lt;/sup&gt;—resulting in a digest of 1216 bits—to achieve at least 180 bits of security. To support variable-length input, we use a prefix-free variant of the Merkle-Damgard transform <a href="#page-40-24">[49,</a> Ch. 4.6.4] that prepends the input with its length <a href="#page-39-21">[29]</a>. ˚</p>

    <p class="text-gray-300">To implement GetBlock and PutBlock, we added to the compiler pipeline 2200 lines of Java (for parsing Pantry's subset-of-C), 2100 lines of Go and 360 lines of Python (for expanding pseudoconstraints into constraints), and 300 lines of C++ (in the prover's constraint solving module). The MapReduce framework (<a href="#page-8-0">§4)</a> requires 1500 lines of C++. The verifiable data structures (<a href="#page-11-1">§5.1–</a><a href="#page-13-0">§5.2)</a> require 400 lines in Pantry's subset-of-C. The main component in the database application (<a href="#page-13-1">§5.3)</a> is a query-to-C translator, which we implement with 2000 lines of Java, on top of Cassandra's CQL parser <a href="#page-38-14">[1]</a>. Our private state applications (<a href="#page-14-0">§6)</a> are 60 lines for face matching, 80 lines for tolling, and 143 lines for regression analysis.</p>

    <p class="text-gray-300">Our evaluation answers two questions: (1) What are the overheads for the prover and verifier? and (2) What does the verifier gain from Pantry, versus alternatives? Given Pantry's goals (<a href="#page-0-0">§1–</a><a href="#page-2-0">§2)</a>, these alternatives must be general-purpose and not make restrictive hypotheses about failure classes. This often means comparing to naive verifiers (<a href="#page-4-1">§2.3)</a>. However, we would be the first to admit that tailored protocols (of the kind cited in the introduction; an example is <a href="#page-41-1">[76]</a>) or replication are likely to far outperform Pantry.</p>

    <p class="text-gray-300">Applications and setup. We experiment with a set of sample applications, listed in Figure <a href="#page-16-0">8.</a> Additional parameters (for the cryptographic primitives in Zaatar and Pinocchio, etc.) are described in Appendix D.</p>

    <p class="text-gray-300">Our experiments use a local cluster of machines, each running Linux on an Intel Xeon processor E5 2680 2.7 GHz with 32GB of RAM and a 250GB 7.5K RPM SATA disk; they are connected by a 56 Gb/s InfiniBand network. Additionally, each machine has an access to a 14PB Lustre 2.1.3 parallel file system.</p>

    <h3 id="sec-16" class="text-xl font-semibold mt-8">&lt;span id=&quot;page-15-2&quot;&gt;&lt;/span&gt;8.1 Overhead and its sources</h3>

    <p class="text-gray-300">Pantry's costs boil down to three sources of overhead:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>T1 The techniques of untrusted storage;</li>
      <li>T2 The constraint representation of computations; and</li>
      <li>T3 The argument step.</li>
    </ul>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">computation (Ψ)</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">type</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">O(·)</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">dot product of two length-m vectors&lt;br&gt;search m nucleotides for length-d substring&lt;br&gt;nearest neigh. search of m length-d vectors&lt;br&gt;covariance matrix for m samples of dim. d</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">MapReduce (Z)&lt;br&gt;MapReduce (Z)&lt;br&gt;MapReduce (Z)&lt;br&gt;MapReduce (Z)</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m&lt;br&gt;m · d&lt;br&gt;m · d&lt;br&gt;2&lt;br&gt;m · d</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">SELECT rows from a table with m rows&lt;br&gt;INSERT a row into a table with m rows&lt;br&gt;UPDATE a row in a table with m rows</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Database (P)&lt;br&gt;Database (P)&lt;br&gt;Database (P)</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">log m&lt;br&gt;log m&lt;br&gt;log m</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">match against m 900-bit face fingerprints&lt;br&gt;compute toll bill for a maximum of m tolls&lt;br&gt;fit a linear model to m-many d-dim. records</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Private state (P)&lt;br&gt;Private state (P)&lt;br&gt;Private state (P)</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m&lt;br&gt;m&lt;br&gt;2 + d&lt;br&gt;3&lt;br&gt;m · d</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">&lt;span id=&quot;page-16-0&quot;&gt;&lt;/span&gt;Figure 8—Sample applications in our experiments. The MapReduce applications uses Zaatar (Z); the other two categories use Pinocchio (P). In the MapReduce applications (<a href="#page-8-0">§4)</a>, Map and Reduce are roughly 60 lines, combined. The DB queries are expressed in Pantry's query framework (<a href="#page-13-1">§5.3,</a> <a href="#page-15-1">§7)</a>. The private state applications (details and code size) are described in <a href="#page-14-0">§6</a> and <a href="#page-15-1">§7.</a></p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">operation</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">number of constraints ( C )</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">GetBlock or PutBlock; 1KB blocks</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">13,000</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">GetBlock or PutBlock; 4KB blocks</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">47,000</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">GetBlock or PutBlock; 16KB blocks</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">180,000</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Load (Store); 220 memory cells</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">93,000 (190,000)</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">Load (Store); 230 memory cells</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">140,000 (280,000)</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">&lt;span id=&quot;page-16-1&quot;&gt;&lt;/span&gt;Figure 9—Cost of Pantry's storage primitives, in constraints (to the nearest 1000), for varying block size or memory size; the number of variables (|<em>Z</em>|) is similar (not shown). PutBlock is the same as GetBlock (<a href="#page-7-1">§3.2)</a>. Store is shown in the same row as Load, and is twice as expensive (<a href="#page-11-1">§5.1)</a>; the memory cell size here is 64 bits, and the intermediate Merkle nodes are 2432 bits. The costs scale linearly (in the block size) for GetBlock and logarithmically (in the memory size) for Load and Store.</p>

    <p class="text-gray-300">Below, we investigate each of these overheads.</p>

    <p class="text-gray-300">We assess the cost of T1 in terms of the <em>number of constraints and variables</em> to which Pantry's primitives compile. (We will focus on the number of constraints, |C|, as the number of variables, |<em>Z</em>|, scales linearly in |C|.) We use this metric because constraints are the computational model (and later, we will express actual running times in terms of constraint set size). Each constraint corresponds to a &quot;register operation&quot; (arithmetic, assignment, etc.), which provides an interpretation of our metric.</p>

    <p class="text-gray-300">Figure <a href="#page-16-1">9</a> shows the number of constraints to which GetBlock and PutBlock (<a href="#page-6-0">§3)</a> compile, varying the size of the block. The cost is ≈12 constraints per byte, or 50 constraints per 32-bit word; thus, in this model, reading a number is 50 times more expensive than adding—a ratio superior to the analogous comparison between hard disks and a CPU's register operations.&lt;sup&gt;5&lt;/sup&gt; On the other hand, disks benefit from sequential access whereas the costs of GetBlock and PutBlock scale linearly. Moreover, constraints will translate into active CPU costs (as we will cover below), whereas real disks leverage DMA.</p>

    <p class="text-gray-300">The preceding discussion presumes that each data item has its own name, or hash. If instead we want to give the programmer contiguously addressable random access memory (e.g., for a program's heap), we must use the RAM abstraction (<a href="#page-11-1">§5.1)</a>. Unfortunately, as shown in Figure <a href="#page-16-1">9,</a> a verifiable Load costs 93,000 constraints to read 64 bits of memory; the ratio here is <em>not</em> close to the analogous memory-vs-register comparison. Thus, GetBlock and PutBlock are best used to implement data structures built directly from verifiable blocks (<a href="#page-13-0">§5.2–</a><a href="#page-13-1">§5.3)</a>; as indicated above, the costs are manageable if the programmer interacts with them as if they lived on disk.</p>

    <p class="text-gray-300">&lt;sup&gt;5&lt;/sup&gt;Of course, P (not V) also has to pay for actual execution (in step (2)).</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">input size</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">baseline</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">$ \\mathcal{C} $ (millions)</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"><span class="math">\\mathbf{prover}\\ (\\mathcal{P})</span></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"><span class="math">3</span> verifier <span class="math">(\\mathcal{V})</span></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">\\textbf{computation} \\ (\\Psi)</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">storage</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">total</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">② solve</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">③ argue</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">total</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">setup</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">per-instance</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">dot product</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m=20k</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">10 ms</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.7</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.8</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4.5 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">8.2 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">13 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5.4 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">380 μs</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">nucleotide substr. search</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m = 600 k, d = 4</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">13 ms</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.6</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4.0</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4.4 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">18 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">23 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">9.9 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">390 \\mu s</span></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">nearest neigh, search</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m = 20k, d = 10</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5.6 ms</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.9</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.1</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2.5 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">9.5 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">380 \\mu s</span></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">covariance matrix</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m = 2.5 k, d = 10</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">3.8 ms</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.6</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.8</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.4 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5.4 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2.3 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">380 \\mu s</span></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">SELECT query</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">m=2^{27}</span> rows</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">90 μs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.0</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2.5 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">17 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">20 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">18 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6.9 ms</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">INSERT query</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">m = 2^{20}</span> rows</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">89 \\mu s</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2.0</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2.4</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6.3 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">31 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">37 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">34 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">13 ms</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">UPDATE query</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">m=2^{20}</span> rows</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">64 \\mu s</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2.0</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">2.4</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6.4 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">31 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">37 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">34 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">14 ms</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">face matching</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m=128</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">100 μs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.7*</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">27 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7.8 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">8.2 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6.5 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7.2 ms</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">tolling</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m = 512</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">6.7~\\mu s</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.1</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.5*</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">9.8 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7.1 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7.3 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">5.2 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6.2 ms</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">regression analysis</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">m=1024, d=8</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"><span class="math">30 \\mu \\mathrm{s}</span></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.4</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.7*</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">50 s</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">8.2 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">9.1 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">7.7 min</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6.2 ms</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">*Includes 250k constraints for commitment (§6)</p>

    <p class="text-gray-300">&lt;span id=&quot;page-17-0&quot;&gt;&lt;/span&gt;Figure 10—Overheads in our sample applications at sample input sizes; for the four MapReduce applications, only the map phase is included. The input size represents a single instance. The baseline column represents the execution of a normally compiled C program. For MapReduce, the baseline is the naive verifier (§4), including a SHA-256 digest check for data integrity (§4); for the database queries, the baseline is a MySQL query; and for the private state apps, the baseline is normal execution (no verifiability). The quantity |Z| is not depicted but is roughly the same as |C| for each sample application. The remaining columns depict the running times (for a single instance; no amortization) of steps (2) and (3), as defined in §2.2; circled numbers refer to these steps.</p>

    <p class="text-gray-300">Even so, storage constraints contribute heavily to the total constraint set size in our applications; the weight is clear from the two columns labeled  <span class="math">|\\mathcal{C}|</span>  in Figure 10, which displays many of Pantry's costs for our sample experiments.</p>

    <p class="text-gray-300">This brings us to the next source of overhead: the fact that there <em>are</em> constraints (T2). Indeed, the costs of step (2) are due to the constraint representation. The final source of overhead is the argument step (T3), which—together with T2—determines the cost of step (3). We consider steps (2) and (3) in turn.</p>

    <p class="text-gray-300">Constraint solving (step (2), §2.2) is a cost for  <span class="math">\\mathcal{P}</span> . We compute the ratio of solving time (Figure 10, the &quot;solve&quot; column) to  <span class="math">|\\mathcal{C}|</span>  for each of our sample applications. This ratio ranges from 20 to 160  <span class="math">\\mu</span> s per constraint, where tolling has the smallest ratio and UPDATE query has the largest. The computations with the largest ratios are those with the highest proportion of GetBlock and PutBlock calls: &quot;solving&quot; these requires computing the Ajtai function (§3.2), which invokes many large integer arithmetic operations. (Another source of overhead here is that GetBlock / PutBlock operations incur I/O costs associated with accessing the block store.)</p>

    <p class="text-gray-300">Arguing (step (3), §2.2) induces costs for  <span class="math">\\mathcal{P}</span>  and  <span class="math">\\mathcal{V}</span> , which are depicted for our measured applications in Figure 10 (the columns labeled ③). These costs are largely determined by  <span class="math">|\\mathcal{C}|</span>  and |Z|, as indicated by the models given earlier (Figures 3 and 6). In these models, the largest constants are  <span class="math">c_2</span> ,  <span class="math">c_3</span> ,  <span class="math">c_5</span>  (representing cryptographic operations), and are on the order of  <span class="math">100\\mu s</span> . Note that these models are chosen for simplicity; their predictions are within a factor of two of empirical results. The primary sources of variation are the structure of the constraints (treated in prior work [71, §4]) and the relative number of bitwise constraints (small values reduce the costs of some of the cryptographic steps). A model that is more faithful (but more involved) is in Appendix E, which also quantifies the constants  <span class="math">\\{c_i\\}</span> .</p>

    <p class="text-gray-300">The aforementioned costs can be understood by comparing to the cost of simply executing the computation (Figure 10, the &quot;baseline&quot; column). Both  <span class="math">\\mathcal{V}</span> 's setup work and  <span class="math">\\mathcal{P}</span> 's runtime work are orders of magnitude more than this baseline, in our sample applications. On top of these costs, the largest experiments (e.g., nucleotide substring search with m=600k, d=4) use roughly 75% of the available RAM in our machines (in the setup phase for  <span class="math">\\mathcal{V}</span>  and per-instance for  <span class="math">\\mathcal{P}</span> ).</p>

    <p class="text-gray-300"><span class="math">&lt;sup&gt;^6&lt;/sup&gt;</span> These costs are higher than necessary. Our implementation of  <span class="math">\\mathcal{P}</span> 's constraint-solving routine is decidedly unoptimized.</p>

    <p class="text-gray-300">    <img src="_page_18_Figure_0.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">    <img src="_page_18_Figure_1.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">&lt;span id=&quot;page-18-0&quot;&gt;&lt;/span&gt;Figure 11—The verifier's CPU and network costs (extrapolated) as a function of job size for the nucleotide substring application in Figures <a href="#page-16-0">8</a> and <a href="#page-17-0">10</a> (each mapper gets a chunk of 600k nucleotides; one reducer is allocated per ten mappers). All y-intercepts (fixed costs) and slopes (per-instance costs) are empirically determined, based on experiments that exhibit the depicted scaling with hundreds of machines. In the CPU (resp., network) graph, Pantry's y-intercept is roughly ten minutes (resp., 2.3 GB); meanwhile, the baseline's slope is tens of milliseconds per chunk (resp., 146.5 KB per chunk). Thus, 40,000–50,000 chunks are required for V to break even, corresponding to 24–30 billion nucleotides.</p>

    <p class="text-gray-300">Amidst the many appalling overheads in Figure <a href="#page-17-0">10,</a> there is actually some encouraging news: the <em>perinstance</em> CPU costs for V are sometimes less than local execution (compare the &quot;per-instance&quot; and &quot;baseline&quot; columns). And though it is not depicted, an analogous thing happens for network costs. Given enough instances, then, the Pantry verifier could save resources relative to the naive verifier (<a href="#page-4-1">§2.3)</a>. We investigate these and other benefits by taking a closer look at some of our sample applications.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-18-2&quot;&gt;&lt;/span&gt;MapReduce. For the MapReduce examples, we want to determine the cross-over points (<a href="#page-4-1">§2.3,</a> <a href="#page-8-0">§4)</a> for CPU and network. We will focus on the nucleotide substring search example; results for the other applications are similar.</p>

    <p class="text-gray-300">We experiment within the limits of our testbed, and use the resulting data to extrapolate. A <em>work unit</em> will be 10 mappers (each with a chunk size of 600k nucleotides, per Figure <a href="#page-17-0">10)</a> and one reducer; let <em>N</em> denote the total job size, in number of input nucleotides. We experiment with <em>N</em>=6 million (one work unit, 10 machines), <em>N</em>=60 million (ten work units, 100 machines), and <em>N</em>=1.2 billion (200 work units, 250 machines, each machine executing multiple workers sequentially). Across these (and smaller-scale) experiments, we observe little variation (std. deviations are within 10% of means, scaling is linear, etc.).</p>

    <p class="text-gray-300">Figure <a href="#page-18-0">11</a> reports the extrapolated resource costs for V; the CPU (resp., network) cross-over point is 29 billion nucleotides, or 48,340 mappers (resp., 24 billion nucleotides, or 40,000 mappers). While the chunk size is tiny—reflecting overheads (<a href="#page-15-2">§8.1)</a>—the results are nevertheless encouraging. First, the baseline is stiff competition: it is linear-time, it runs as optimized machine code, and it uses SHA-256 (not Ajtai) for data integrity. Second, Pantry's V beats this baseline at a job size that is plausible: the human genome is roughly 3 billion nucleotides, so the cross-over point is ≈10 such genomes.</p>

    <p class="text-gray-300">DB queries. This class of applications has an additional overhead: storage at the prover, for the hash trees (<a href="#page-13-0">§5.2)</a>. Below, we assess that cost, and ask about Pantry's ability to save resources for V. What should the baseline be? In Figure <a href="#page-17-0">10,</a> we present the running time of MySQL, which helps us gauge the prover's overhead. However, for a naive verifier to benefit from MySQL's optimized query execution <em>while achieving verifiability</em>, it would have to download the entire database and execute the query itself.</p>

    <p class="text-gray-300">Instead, our baseline will be reasonably network-efficient and avoid two sources of overhead in Pantry: constraints and the argument step. We assume a server that implements a hash-based block store <a href="#page-39-13">[33,</a> <a href="#page-40-12">52]</a> (akin to the map <em>S</em> in <a href="#page-6-1">§3.1)</a> and a verifier that runs the computation <em>natively</em>; where the program calls GetBlock and PutBlock, the verifier issues an RPC to the server. Since the computation is run natively rather than in constraints, <em>H</em> is SHA-256 (<a href="#page-8-1">§3.2)</a>. We have not yet built this alternative, so we estimate its network costs; we can do this since queries are highly constrained (<a href="#page-5-0">§2.4,</a> <a href="#page-13-2">§5.4)</a>.</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Pantry</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">block store (est.)</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">network costs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">setup, kept as storage (argue step)</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">430 MB</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0 MB</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">per-instance (argue step)</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">288 bytes</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">8.3 KB</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">per-instance (input, output)</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">624 bytes</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">620 bytes</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">storage costs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
            <td class="px-3 py-2 border-b border-gray-700 text-left"></td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">data</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">11.5 GB</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">11.5 GB</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">metadata (for hash tree)</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">262 GB</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">≥53.5 GB</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">&lt;span id=&quot;page-19-1&quot;&gt;&lt;/span&gt;Figure 12—Resource costs of a SELECT query, under Pantry and estimates for an alternative based on an untrusted block store. The table has 2&lt;sup&gt;27&lt;/sup&gt; rows, each holding 92 bytes in 12 columns; the query allows 5 matching rows (<a href="#page-13-1">§5.3,</a> <a href="#page-13-2">§5.4)</a>.</p>

    <p class="text-gray-300">Figure <a href="#page-19-1">12</a> depicts the comparison, for a SELECT query. This table indicates, first, that our implementation needs some work: the metadata is far larger than the data (for both Pantry and the alternative) due in part to unoptimized parameter choices (number of indexes, branching factor, etc.). Second, the effect of the size of Ajtai digests (versus SHA-256) is apparent in the metadata row. Nevertheless, despite these limitations, the Pantry verifier can amortize its network costs in the setup phase (because it does not incur the network cost of handling the verifiable blocks themselves); for this computation, the network cross-over point is 55,000 instances.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-19-2&quot;&gt;&lt;/span&gt;Private state. For these applications, we do not ask about cross-over points because V cannot naively re-execute the computation. Instead, we just report the costs, for our sample application of tolling; costs for the others are similar. The CPU costs are in Figure <a href="#page-17-0">10;</a> the storage and network resources are given below:</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">private state</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">5 KB</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">network (setup) and storage (ongoing)</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">170 MB</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">network (per-instance), for inputs/outputs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1 KB</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">network (per-instance), for argument step</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">288 bytes</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">The storage overhead here is proportional to the size of the private state; the reason is as follows. The storage overhead reflects setup costs (see above), setup costs are proportional to |C| and |<em>Z</em>| (see Figures <a href="#page-5-1">3</a> and <a href="#page-10-0">6)</a>, |C| and |<em>Z</em>| include terms for GetBlock's input (<a href="#page-7-1">§3.2)</a>, and GetBlock's input is all of the state because there is no hash tree structure (<a href="#page-11-0">§5)</a>. Although the constant of proportionality is high (due to the argument step), the absolute quantities are not necessarily alarming: the tolling application does not involve much state, and an overhead of several hundred megabytes could fit comfortably on a mobile phone. Moreover, the per-instance network costs are very low, owing to Pinocchio's machinery (<a href="#page-2-3">§2.2–</a><a href="#page-4-1">§2.3)</a>.</p>

    <h3 id="sec-17" class="text-xl font-semibold mt-8">&lt;span id=&quot;page-19-0&quot;&gt;&lt;/span&gt;9 Related work</h3>

    <p class="text-gray-300">Although verifiable computation has a decades-long history (see <a href="#page-40-8">[65,</a> <a href="#page-40-16">72,</a> <a href="#page-41-7">80]</a> for surveys), only recently have systems emerged that are both (a) general-purpose (i.e., not targeted to a class of functionality) and (b) rooted in powerful complexity theory and cryptography.</p>

    <p class="text-gray-300">One line of work <a href="#page-39-11">[28,</a> <a href="#page-41-5">77,</a> <a href="#page-41-6">78]</a> refines the Muggles interactive proof protocol <a href="#page-39-5">[41]</a>, which is purely complexity-theoretic (no cryptography). As a consequence, the resulting systems are very efficient for the verifier and prover. However, they are restricted to straight-line computations (though this limitation has been partially relaxed <a href="#page-41-7">[80]</a>).</p>

    <p class="text-gray-300">Another line of work <a href="#page-40-9">[70</a><a href="#page-40-10">–73,</a> <a href="#page-41-7">80]</a> refines an efficient argument protocol (<a href="#page-2-0">§2)</a> due to Ishai et al. <a href="#page-40-6">[47]</a>. Zaatar <a href="#page-40-11">[71]</a> is the best-performing entry in this line; it leverages the remarkable encoding of GGPR <a href="#page-39-9">[36]</a> and handles general side-effect free computations <a href="#page-40-10">[73]</a>.</p>

    <p class="text-gray-300">Pinocchio <a href="#page-40-8">[65]</a> applies both GGPR's encoding and its cryptographic constructions <a href="#page-39-9">[36]</a>, and is the first implementation of a general-purpose non-interactive argument (it is a SNARG <a href="#page-39-16">[37]</a> and a SNARK <a href="#page-38-6">[18]</a>). It uses essentially the same computational model as Zaatar <a href="#page-40-11">[71,</a> <a href="#page-40-10">73]</a>, and for systems working within this model, Pinocchio and Zaatar have the best performance in the literature (on different axes). The two are compared in <a href="#page-2-3">§2.2</a> and <a href="#page-4-1">§2.3.</a></p>

    <p class="text-gray-300">None of these three efforts handles computations over state. Pantry's principal contribution is to extend the computational model of Pinocchio and Zaatar to do so, using ideas from untrusted storage. First, Pantry relies on Merkle trees <a href="#page-40-13">[58]</a> to authenticate a large untrusted memory, an idea used in theory <a href="#page-39-12">[21]</a> and in practice (for smartcards <a href="#page-39-22">[34]</a>, databases <a href="#page-39-23">[31,</a> <a href="#page-40-18">54,</a> <a href="#page-40-25">57]</a>, file systems <a href="#page-39-24">[38,</a> <a href="#page-40-26">48]</a>, etc.). Second, Pantry names data blocks by their digests, and treats the digests as references for the purposes of building data structures (including Merkle trees); this idiom is due to the SFSRO <a href="#page-39-13">[33]</a> file system and used elsewhere (e.g., SUNDR <a href="#page-40-12">[52]</a>). One (rough) way to understand Pantry is that it verifiably outsources an SFSRO or SUNDR <em>client</em>. Of course, Pantry's general approach is known <a href="#page-38-8">[14,</a> <a href="#page-38-6">18,</a> <a href="#page-39-9">36,</a> <a href="#page-40-14">46]</a>. However, Pantry is the first realization of this strategy.</p>

    <p class="text-gray-300">A fourth project, appearing in parallel with Pantry, offers a different approach to state. BCGTV <a href="#page-38-7">[15]</a> use a promising circuit representation from <a href="#page-38-8">[14]</a> (a different instantiation of steps (1) and (2) in <a href="#page-2-3">§2.2)</a>.&lt;sup&gt;7&lt;/sup&gt; Using insights from <a href="#page-39-15">[20,</a> <a href="#page-39-9">36,</a> <a href="#page-40-11">71]</a>, BCGTV combine their representation with a step (3) that is much like Pinocchio's (like Pinocchio, BCGTV is a &quot;SNARK with pre-preprocessing&quot;). On the one hand, BCGTV achieve expressivity relative to Pantry, specifically data-dependent loops. On the other hand, they do not (at present) work with remote state (<a href="#page-8-0">§4–</a><a href="#page-14-0">§6)</a>. Furthermore, although a complete evaluation has not been done, their preliminary reported results indicate that performance is often orders of magnitude worse than Pantry. A detailed comparison is future work.</p>

    <p class="text-gray-300">Pantry has many limitations. A number of these stem from the clumsiness of the constraint model (<a href="#page-5-0">§2.4)</a>, which led to various compromises described earlier (<a href="#page-8-0">§4,</a> <a href="#page-13-2">§5.4,</a> <a href="#page-14-0">§6)</a>. A further compromise is the assumption throughout that the verifier knows the digest of the remote state; this holds when the state is read-only or when there is one client. Future work is to handle multiple writers, perhaps by outsourcing <em>signature</em> (not just hash) checks.</p>

    <p class="text-gray-300">But the biggest limitation by far is costs—which are currently so high for the prover and the verifier's setup phase (<a href="#page-15-2">§8.1)</a> that they limit our experiments (<a href="#page-18-1">§8.2)</a> to scales smaller than those of real applications (to put it mildly). This issue afflicts the entire research area (<a href="#page-19-0">§9)</a>. Indeed, key challenges are to reduce the overhead of the argument protocol (which seems possible, as the costs stem from high constants, not unfavorable asymptotics); reduce the overhead of memory operations within the constraint model (evidence exists that this can be done <a href="#page-38-8">[14]</a>); and go beyond, or around, the constraint model.</p>

    <p class="text-gray-300">Nevertheless, Pantry dramatically expands the set of scenarios where verifiable computation makes sense. First, Pantry extends verifiability to computations that make indirect memory accesses (to RAM, disk, etc.). Second, because the verifier can supply digests of inputs, the per-instance CPU cost of verification can drop below the time cost to handle the actual inputs, thereby allowing the verifier to beat naive verification even when outsourcing <em>linear</em>-time computations (<a href="#page-8-0">§4,</a> <a href="#page-18-2">§8.2)</a>. Third, Pantry can save network costs for the verifier versus the naive alternative (<a href="#page-8-0">§4,</a> <a href="#page-18-2">§8.2)</a>. Thus, Pantry may be beneficial even if verification costs more CPU cycles than local execution—a case that defeats the goals (<a href="#page-4-1">§2.3)</a> of prior work <a href="#page-40-8">[65,</a> <a href="#page-40-11">71–</a><a href="#page-40-10">73,</a> <a href="#page-41-7">80]</a>. Fourth, Pantry (with a major assist from Pinocchio) extends verifiability to a class of computations involving <em>private</em> remote state (<a href="#page-14-0">§6)</a>.</p>

    <p class="text-gray-300">&lt;sup&gt;7&lt;/sup&gt;Recent work takes a different approach to efficient circuit representations of various standard data structures <a href="#page-41-9">[82]</a>. Incorporating into our system and comparing to Pantry and BCGTV is work in progress.</p>

    <p class="text-gray-300">The preceding paragraph describes when Pantry <em>could</em> be applicable, but we must also consider when it actually <em>is</em>. The answer depends on computation-specific factors: the cross-over points, one's tolerance for prover overhead, and the details of the scenario. But data-parallel cloud computing (e.g., MapReduce) seems to fit the requirements: many instances of the same computation and an abundance of server CPU cycles. Moreover, a high price for the private state applications might be acceptable, since there is no naive alternative (<a href="#page-19-2">§8.2)</a>.</p>

    <p class="text-gray-300">In conclusion, there is a great deal of work remaining to bring verifiable computation to practice, but Pantry is a significant step toward that goal.</p>

    <h3 id="sec-18" class="text-xl font-semibold mt-8">&lt;span id=&quot;page-21-0&quot;&gt;&lt;/span&gt;A Pantry's correctness</h3>

    <p class="text-gray-300">This appendix and the next will establish Pantry's correctness. These arguments mainly draw on existing techniques and folklore; we write them down here for completeness.</p>

    <p class="text-gray-300">We wish to establish that Pantry's verifier V accepts correct outputs <em>y</em> and rejects incorrect ones with probability similar to that of Zaatar's soundness (<a href="#page-2-2">§2.1,</a> <a href="#page-4-1">§2.3)</a>. By the Completeness property of Zaatar <a href="#page-40-11">[71,</a> Apdx. A] and an equivalent property in Pinocchio <a href="#page-39-9">[36,</a> <a href="#page-40-8">65]</a>, and the implementation of the prover P (specifically, the use of the map <em>S</em>), V can be made to accept correct outputs with certainty. The more involved step is showing that V rejects incorrect answers. One might think to apply the soundness property (<a href="#page-2-3">§2.2)</a>, but this property is not enough: its technical guarantee is that <em>if no satisfying assignment exists</em>, then V is likely to reject <a href="#page-39-9">[36,</a> <a href="#page-40-8">65,</a> <a href="#page-40-11">71]</a>. Meanwhile, C(<em>X</em>=<em>x</em>, <em>Y</em>=<em>y</em>) could be satisfiable, even if <em>y</em> is incorrect in the context of steps 1 and 2 (<a href="#page-2-3">§2.2)</a>. As a simple example, imagine that the computation Ψ is:</p>

    <pre><code class="language-text">name = PutBlock(x);
B = GetBlock(name);
if (B == x)
    y = 1;
else
    y = 0;
return y;
</code></pre>

    <p class="text-gray-300">The correct answer here is <em>y</em>=1. But <em>y</em>=0 also results in many satisfying assignments to CΨ(<em>X</em>=<em>x</em>, <em>Y</em>=0); in particular, any setting of the <em>B</em> variables for which <em>H</em>(<em>B</em>)=<em>H</em>(<em>x</em>)=<em>name</em>, where <em>B</em>6=<em>x</em>, will satisfy CΨ(<em>X</em>=<em>x</em>, <em>Y</em>=0). Since soundness says nothing about what V does when there <em>are</em> satisfying assignments, soundness cannot be used to argue that V will reject <em>y</em> = 0.</p>

    <p class="text-gray-300">We need another property, called <em>proof of knowledge</em> (PoK). A formal definition is below; less formally, this property states that if P can make V accept a claimed output <em>y</em> with non-negligible probability, then there is an efficient algorithm that can run P to produce a satisfying assignment to C(<em>X</em>=<em>x</em>, <em>Y</em>=<em>y</em>). Even more informally, one can think of this property as stating that if V accepts the interaction, then P must have &quot;known&quot; an assignment.</p>

    <p class="text-gray-300">The power of the PoK property in our context is the following. If <em>y</em> is an incorrect output and C(<em>X</em>=<em>x</em>, <em>Y</em>=<em>y</em>) is satisfiable, <em>the only satisfying assignments contain memory consistency violations</em>; meanwhile, memory consistency violations imply hash collisions, and manufacturing such collisions is presumed to be hard. Therefore, no efficient algorithm can produce satisfying assignments of this adverse form, and hence (by the italicized assertion) no efficient algorithm can produce any satisfying assignments, and hence—here is where we use the PoK property—the prover cannot systematically make the verifier accept the corresponding output. Very informally, the prover must not &quot;know&quot; any adverse satisfying assignments, which, by the PoK property, implies that it cannot make the verifier accept them.</p>

    <p class="text-gray-300">In the rest of this appendix, we formally define a PoK property and use it to establish Pantry's correctness; Appendix <a href="#page-25-0">B</a> proves that Pantry meets this property. We will restrict attention to the case that Pantry uses Zaatar; a similar analysis applies when Pantry uses Pinocchio.&lt;sup&gt;8&lt;/sup&gt;</p>

    <h4 id="sec-19" class="text-lg font-semibold mt-6">A.1 Setup and definition of proof-of-knowledge</h4>

    <p class="text-gray-300">Recall the Zaatar setup. V and P are given a set of constraints C (over variables <em>X</em>, <em>Y</em>, <em>Z</em>), input <em>x</em>, and output <em>y</em>. C(<em>X</em>=<em>x</em>, <em>Y</em>=<em>y</em>) is a set of constraints over variables <em>Z</em> = (<em>Z</em>1, . . . , <em>Z&lt;sup&gt;n&lt;/sup&gt;</em> &lt;sup&gt;0&lt;/sup&gt;); each <em>Z&lt;sup&gt;i&lt;/sup&gt;</em> ∈ F. V and (a possibly incorrect P) interact. If, after getting the purported output <em>y</em>, V accepts, we notate that as (V,P)(C, <em>x</em>, <em>y</em>) = 1.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-22-0&quot;&gt;&lt;/span&gt;Definition A.1 (Proof of knowledge (PoK).). There exists a PPT <em>extractor algorithm E</em> (which is presumed to have oracle access to the prover: it can run the prover by supplying arbitrary patterns) for which the following holds. For all P and all polynomially-bounded (C, <em>x</em>, <em>y</em>), if</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\{(\\mathcal{V}, \\mathcal{P})(\\mathcal{C}, x, y) = 1\\} &gt; \\epsilon_K</span>$</p>

    <p class="text-gray-300">then</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{s}\\{E_{s}^{\\mathcal{P}}(\\mathcal{C}, x, y) \\to z = z_{1}, \\dots, z_{n&#x27;}, \\text{ such that } z \\text{ satisfies } \\mathcal{C}(X = x, Y = y)\\} &gt; \\epsilon&#x27;_{K},</span>$</p>

    <p class="text-gray-300">where 0 <em>K</em> is non-negligible. The first probability is taken over the random choices of the Zaatar protocol (specifically, the coin flips of the commit phase, the decommit phase, and the choice of PCP queries). The second probability is taken over <em>s</em>, the random choices of the extractor algorithm <em>E</em>.</p>

    <p class="text-gray-300">The next appendix proves that Zaatar has this property; for now, we take it as a given. As we will see below, the quantity <em>&lt;sup&gt;K&lt;/sup&gt;</em> will wind up being Pantry's actual error: it will upper-bound the probability that V accepts an incorrect output. Sometimes this parameter is referred to as &quot;knowledge error&quot;, and we will be motivated to ensure that it is not much larger than the soundness error. Notice that we cannot make this parameter lower than the soundness error, since a protocol that has knowledge error of at most <em>&lt;sup&gt;K&lt;/sup&gt;</em> has soundness error of at most <em>&lt;sup&gt;K&lt;/sup&gt;</em> (that is, PoK implies soundness). This is because if no satisfying assignment exists at all, then of course the probability of producing one is zero (for all algorithms), which implies (by PoK) that V rejects with probability at least 1 − <em>K</em>, which yields the soundness property.</p>

    <p class="text-gray-300">This section considers only single executions; the next section generalizes to the case of state carried across program executions.</p>

    <p class="text-gray-300">We will use the PoK property (Defn. <a href="#page-22-0">A.1)</a> to establish that V rejects semantically incorrect outputs <em>y</em> 0 with high probability. In the context of a computation Ψ, the (unique) semantically correct output <em>y</em> on input <em>x</em> is the value or vector that results from following the logic of Ψ on input <em>x</em>. This logic includes <em>program logic</em> and <em>storage consistency</em>. Program logic means, for example, that the result of an &quot;add&quot; operation should actually be the sum of the two numbers.</p>

    <p class="text-gray-300">Storage consistency is a typical definition: &quot;reads should see writes&quot;. In our context, this means that if the program &quot;reads address <em>n</em>&quot; (that is, executes GetBlock with input <em>n</em>), then the return value <em>b</em> should be the &quot;most recently written value to address <em>n</em>&quot; (that is, the program should have executed <em>n</em> = PutBlock(<em>b</em>), and between that call and the GetBlock, there should be no intervening invocations <em>n</em> = PutBlock(<em>b</em> 0 ), where <em>b</em> &lt;sup&gt;0&lt;/sup&gt; 6= <em>b</em>). If an input <em>x</em> would cause Ψ to issue a call GetBlock(<em>n</em>) for which there was no preceding call <em>n</em> = PutBlock(<em>b</em>), then there is no semantically correct output; in this situation, we sometimes say that the correct output is ⊥ and that <em>x</em> itself as a semantically incorrect input.</p>

    <p class="text-gray-300">&lt;sup&gt;8&lt;/sup&gt; Pinocchio has been shown to have a PoK property <a href="#page-39-9">[36,</a> §8]. This PoK property is stronger than the one that we prove for Zaatar (though Pinocchio's relies on non-falsifiable &quot;knowledge assumptions&quot; whereas Zaatar's relies on standard assumptions). As a consequence, the analysis in this appendix also applies to Pantry's use of Pinocchio.</p>

    <p class="text-gray-300">Of course, the preceding notions require an ordering on operations; this order follows from program order, and induces an ordering on the constraints that the Pantry compiler produces. In more detail, recall that for a high-level program  <span class="math">\\Psi</span> , the Pantry compiler produces constraints  <span class="math">\\mathcal{C}</span>  that correspond to  <span class="math">\\Psi</span> 's program logic: the program variables in  <span class="math">\\Psi</span>  appear in  <span class="math">\\mathcal{C}</span> , and the equations in  <span class="math">\\mathcal{C}</span>  enforce program logic through the relations among the program variables. (The constraints  <span class="math">\\mathcal{C}</span>  are said to be <em>equivalent</em> to the computation  <span class="math">\\Psi</span> .) An assignment w = (x, y, z) to  <span class="math">\\mathcal{C}</span>  thus corresponds to a <em>transcript</em> for  <span class="math">\\Psi</span> : a string consisting of the program  <span class="math">\\Psi</span>  with loops unrolled and with all variables  <span class="math">(X, Y, Z_1, Z_2, \\ldots)</span>  replaced with values  <span class="math">(x, y, z_1, z_2, \\ldots)</span> . In what follows, we will move back and forth between the notion of transcript  <span class="math">\\tau</span>  and its corresponding assignment  <span class="math">w_{\\tau} = (x, y, z)</span> .</p>

    <p class="text-gray-300">A valid transcript is one that obeys program semantics. Specifically, in a valid transcript  <span class="math">\\tau</span> :</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>P1 All operations respect program logic. By the transcript-assignment equivalence, this property is equivalent to saying that the assignment  <span class="math">w_{\\tau} = (x, y, z)</span>  satisfies the constraints C.</li>
      <li>P2 Storage operations respect consistency. Specifically, if b = GetBlock(n) appears in  <span class="math">\\tau</span> , then an operation n = PutBlock(b) appears earlier in  <span class="math">\\tau</span>  (with no intervening n = PutBlock(b'), where  <span class="math">b&#x27; \\neq b</span> ).</li>
    </ul>

    <p class="text-gray-300">&lt;span id=&quot;page-23-0&quot;&gt;&lt;/span&gt;Claim A.1. For a computation  <span class="math">\\Psi</span> , if  <span class="math">y \\neq \\bot</span>  is semantically correct on input x, then there exists a valid transcript in which the input variables are set to x and the output variables are set to y. (Also, this transcript is unique in our present context.)</p>

    <p class="text-gray-300"><em>Proof.</em> The transcript is an unrolled program execution. So if the program  <span class="math">\\Psi</span>  would correctly produce y from x, then we can write down all of the operations that lead from x to y. This list will respect validity (properties P1 and P2), since validity admits those transcripts (and only those transcripts) that obey the semantics.</p>

    <p class="text-gray-300">The transcript is unique since each operation, when executed correctly, is deterministic. Note in particular that storage operations are deterministic: PutBlock operations are deterministic by construction (given an input block, PutBlock returns a digest of it), and the semantics given above specify the unique return value of a GetBlock invocation.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-23-1&quot;&gt;&lt;/span&gt;<strong>Claim A.2.</strong> Let  <span class="math">\\mathcal{V}</span>  be Pantry's verifier, operating on constraints  <span class="math">\\mathcal{C}</span>  and input x. If  <span class="math">y \\neq \\bot</span>  is the semantically correct output, then for all provers  <span class="math">\\mathcal{P}</span>  and all  <span class="math">y&#x27; \\neq y</span> ,  <span class="math">\\Pr\\{(\\mathcal{V}, \\mathcal{P})(\\mathcal{C}, x, y&#x27;) = 1\\} \\leq \\epsilon_K</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> Assume otherwise. Then there exists a prover  <span class="math">\\mathcal{P}&#x27;</span>  and an incorrect answer y' for which  <span class="math">\\Pr\\{(\\mathcal{V}, \\mathcal{P}&#x27;)(\\mathcal{C}, x, y&#x27;) = 1\\} &gt; \\epsilon_K</span> . By the PoK property (Defn A.1, Lemma B.1), there exists an extractor algorithm  <span class="math">E^{\\mathcal{P}&#x27;}</span>  that, with probability greater than  <span class="math">\\epsilon_K&#x27;</span> , produces some assignment z' such that (x, y', z') satisfies  <span class="math">\\mathcal{C}</span> ; let  <span class="math">\\tau&#x27;</span>  be the transcript corresponding to the assignment  <span class="math">w_{\\tau&#x27;}&#x27; = (x, y&#x27;, z&#x27;)</span> . Also, since  <span class="math">y \\neq \\bot</span>  is semantically correct, Claim A.1 implies that there exists a valid transcript  <span class="math">\\tau</span>  (while  <span class="math">\\tau</span>  is unique, we will not explicitly rely on that uniqueness below). By the validity of  <span class="math">\\tau</span> , there is an assignment  <span class="math">w_{\\tau} = (x, y, z)</span>  that satisfies  <span class="math">\\mathcal{C}</span> .</p>

    <p class="text-gray-300">Compare  <span class="math">\\tau</span>  and  <span class="math">\\tau&#x27;</span> . Consider the first position in these strings where they disagree (they must disagree somewhere, for their outputs are different). We now make two claims about this point of divergence: (1) it must be a GetBlock(n) operation, and (2) the input to this operation must be the same in both  <span class="math">\\tau</span>  and  <span class="math">\\tau&#x27;</span> .</p>

    <p class="text-gray-300">The reason for (1) is that if  <span class="math">\\tau</span>  and  <span class="math">\\tau&#x27;</span>  first disagreed on a different operation (either its inputs or outputs), they would agree up until that operation, and then disagree on a deterministic operation (all operations besides GetBlock are deterministic); hence, at least one of the two transcripts would be in violation of program logic, which would mean that at least one of  <span class="math">w_{\\tau}</span>  and  <span class="math">w&#x27;_{\\tau&#x27;}</span>  would not satisfy  <span class="math">\\mathcal{C}</span> , which would contradict statements above. Similarly, to establish (2), observe that the constraints are constructed so that the input to GetBlock is deterministically produced from the computation's input (x) and the computation up to that point (and  <span class="math">\\tau</span>  and  <span class="math">\\tau&#x27;</span>  agree up to that point).</p>

    <p class="text-gray-300">From claims (1) and (2), the output of the GetBlock in  <span class="math">\\tau</span>  (call it b) and in  <span class="math">\\tau&#x27;</span>  (call it b') are different; that is,  <span class="math">b \\neq b&#x27;</span> . However, w and w' are both satisfying, so  <span class="math">\\tau</span>  and  <span class="math">\\tau&#x27;</span>  obey property P1. From the compilation of GetBlock into  <span class="math">\\mathcal{C}_{H^{-1}}</span> , and the construction of  <span class="math">\\mathcal{C}_{H^{-1}}</span> , per Section 3, we have n = H(b) and n = H(b'), where H is a collision-resistant hash function (CRHF). Also, because  <span class="math">\\tau</span>  is valid, it obeys P2, which means that  <span class="math">\\tau</span>  contains an earlier instance of  <span class="math">n = \\operatorname{PutBlock}(b)</span> , where (by P1) H(b) = n. But  <span class="math">\\tau</span>  and  <span class="math">\\tau&#x27;</span>  match through that earlier point in the transcript, which means that  <span class="math">\\tau&#x27;</span>  also contains  <span class="math">n = \\operatorname{PutBlock}(b)</span> . Thus,  <span class="math">\\tau&#x27;</span>  contains  <span class="math">n = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock}(b) = \\operatorname{PutBlock</span></p>

    <p class="text-gray-300">Therefore, an adversarial algorithm  <span class="math">\\mathcal{A}</span>  can produce a collision in H as follows.  <span class="math">\\mathcal{A}</span>  runs  <span class="math">E^{\\mathcal{P}&#x27;}</span>  to get z' (which succeeds with  <span class="math">&gt; \\epsilon&#x27;_K</span>  probability), forms w = (x, y', z'), sorts w by output digests, scans to find b and b', and outputs them. This succeeds in producing a collision with probability  <span class="math">&gt; \\epsilon&#x27;_K</span> , which contradicts the assumed collision-resistance of H.</p>

    <h4 id="sec-20" class="text-lg font-semibold mt-6">A.3 Remote state</h4>

    <p class="text-gray-300">Arguing the correctness of Pantry's MapReduce (§4), among other applications, requires allowing state to be carried across executions. To this end, we generalize the definitions above.</p>

    <p class="text-gray-300">We consider a model in which  <span class="math">\\mathcal{V}</span>  and  <span class="math">\\mathcal{P}</span>  interact sequentially:  <span class="math">\\mathcal{V}</span>  supplies input  <span class="math">x_0</span>  and specifies  <span class="math">\\Psi_0</span>  to  <span class="math">\\mathcal{P}</span> , receiving output  <span class="math">y_0</span> ; next,  <span class="math">\\mathcal{V}</span>  supplies input  <span class="math">x_1</span>  and specifies  <span class="math">\\Psi_1</span>  to  <span class="math">\\mathcal{P}</span> , receiving output  <span class="math">y_1</span> , etc. Suppose that there are t+1 pairs in all:  <span class="math">(x_0, y_0), \\ldots, (x_t, y_t)</span> .</p>

    <p class="text-gray-300">We define the semantic correctness of  <span class="math">y_i</span>  inductively. Specifically, we say that  <span class="math">y_0</span>  is semantically correct if it meets the earlier description (i.e., if the correct operation of  <span class="math">\\Psi_0</span>  on input  <span class="math">x_0</span>  produces  <span class="math">y_0</span> ). For  <span class="math">y_i</span> , where i&gt;0, we say that  <span class="math">y_i</span>  is semantically correct if (a) all previous  <span class="math">\\{(x_j,y_j)\\}_{j=0}^{i-1}</span>  are semantically correct; (b)  <span class="math">y_i</span>  respects program logic on  <span class="math">x_i</span> ; and (c) if  <span class="math">\\Psi_i</span>  issues  <span class="math">\\mathtt{GetBlock}(n)</span> , then the return value should be the b in the most recent  <span class="math">n=\\mathtt{PutBlock}(b)</span>  call, as above; here, however, we are looking not only at the current execution but at the concatenated (valid) transcripts  <span class="math">\\tau_0,\\ldots,\\tau_{i-1}</span>  together (these transcripts exist by the correctness of  <span class="math">y_0,\\ldots,y_{i-1}</span> ).</p>

    <p class="text-gray-300">Label with  <span class="math">C_i</span>  the constraints that correspond to computation  <span class="math">\\Psi_i</span> . We now make a claim that is analogous to Claim A.2:</p>

    <p class="text-gray-300"><strong>Claim A.3.</strong> Consider a sequence of interactions between  <span class="math">\\mathcal{V}</span>  and  <span class="math">\\mathcal{P}</span>  that produces pairs  <span class="math">(x_0, \\hat{y}_0), \\ldots, (x_t, \\hat{y}_t)</span> , where for  <span class="math">i \\in \\{0, \\ldots, t\\}</span> , the semantically correct output  <span class="math">y_i</span>  is not  <span class="math">\\bot</span> . For all provers  <span class="math">\\mathcal{P}</span> , and all i, if  <span class="math">\\hat{y}_i \\neq y_i</span> , then for some  <span class="math">j \\leq i</span> , we have  <span class="math">\\Pr\\{(\\mathcal{V}, \\mathcal{P})(\\mathcal{C}_i, x_j, \\hat{y}_i) = 1\\} \\leq \\epsilon_K</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> (Sketch.) The proof is similar to that of Claim A.2. Let  <span class="math">\\hat{y}_i</span>  be the first semantically incorrect output in the sequence. Assume to the contrary that  <span class="math">\\Pr\\{(\\mathcal{V}, \\mathcal{P})(\\mathcal{C}_j, x_j, \\hat{y}_j) = 1\\} &gt; \\epsilon_K</span> , for all  <span class="math">j \\in \\{0, \\dots, i\\}</span> ; by the PoK property, E can produce, with probability greater than  <span class="math">(\\epsilon&#x27;_K)^{i+1}</span> , a list of assignments  <span class="math">\\hat{z}_0, \\dots, \\hat{z}_i</span>  (which satisfy the respective constraint sets, given the respective inputs and outputs). Let  <span class="math">\\hat{\\tau}_0, \\dots, \\hat{\\tau}_i</span>  be the corresponding transcripts, and concatenate these together to form one large aggregate transcript,  <span class="math">\\hat{\\tau}_*</span> . There is a valid aggregate transcript  <span class="math">\\tau_*</span>  that differs from  <span class="math">\\hat{\\tau}_*</span>  in at least one location (because  <span class="math">y_i \\neq \\hat{y}_i</span> ).</p>

    <p class="text-gray-300">As in Claim A.2, the two transcripts must again diverge in a GetBlock operation (all other operations are deterministic; furthermore, the inputs  <span class="math">\\{x_0,\\ldots,x_i\\}</span>  match in the two transcripts, and so do the outputs  <span class="math">\\{\\hat{y}_0,\\ldots,\\hat{y}_{i-1}\\}</span> , since  <span class="math">\\hat{y}_i</span>  is the first semantically incorrect output in the sequence). This implies that  <span class="math">\\hat{\\tau}_*</span>  contains a collision. An adversarial PPT algorithm can thus produce a collision with probability at least  <span class="math">(\\epsilon&#x27;_K)^{i+1}/t</span>  (by guessing i, running i instances of the extractor E, and sorting the resulting witnesses), in contradiction to the presumed collision-resistance of H.</p>

    <p class="text-gray-300">The preceding analysis can be extended to cover the data structures that we build using the GetBlock and PutBlock abstractions (§5). In the case of the verifiable RAM, this analysis is a mild variant of the arguments for online memory-checking given by Blum et al. [21]. That paper specifies a simple memory semantics (roughly, reads and writes are totally ordered and each read is matched by a preceding write),</p>

    <p class="text-gray-300">describes a Merkle tree-based on-line checking algorithm, and argues that in order to violate the memory semantics an adversary must fake some of the hash checks that validate a path through the Merkle tree. Inspection of our verifiable RAM design (Section 5.1, Figure 7) indicates that violation of the memory semantics would result in a violation of Claim A.2.</p>

    <p class="text-gray-300"><strong>Discussion.</strong> Notice that the preceding claims are conditional on  <span class="math">\\mathcal{V}</span>  supplying correct inputs (i.e., a condition for the claims is that there <em>are</em> correct outputs). In particular, if the verifier supplies a made-up digest as a reference to storage, the protocol provides no guarantees. In practice, this means that the onus is on the verifier to supply correct digests as input.</p>

    <p class="text-gray-300">Of course, if the verifier makes up a digest, then heuristically speaking, the prover will not be able to manufacture a satisfying assignment, since that would require inverting H. In fact, if the verifier chooses a digest d by random selection of b and then setting  <span class="math">d \\leftarrow H(b)</span> , then we can show that the prover cannot convince the verifier to accept with greater than the knowledge error  <span class="math">\\epsilon_K</span>  (this relies on the preimage-resistance, or one-wayness, of H, which is Ajtai's function [4]). By contrast, if the verifier chooses an input digest arbitrarily (perhaps in collusion with the prover!), then we cannot apply the preceding guarantees; however, cases where the verifier chooses a &quot;wrong&quot; digest for which it knows that the prover knows a preimage are elaborate exercises in shooting oneself in the foot.</p>

    <p class="text-gray-300">Finally, note that the security proof for remote state presumes that either the same verifier is participating across the sequence, or that there is a chain of trust linking them. This issue is handled somewhat better in the non-interactive &quot;proof-carrying data&quot; (PCD) framework [19], where an extractor can produce a complete transcript, given a certificate. On the other hand, existing PCD protocols rely on non-falsifiable hypotheses.</p>

    <p class="text-gray-300">This appendix will establish that Zaatar meets a proof-of-knowledge (PoK) property. Recall from the prior appendix that we are motivated to ensure that the knowledge error,  <span class="math">\\epsilon_K</span> , is not much larger than Zaatar's soundness error,  <span class="math">\\epsilon_{\\text{zaat}}</span> ; as established elsewhere [71, Apdx. A],  <span class="math">\\epsilon_{\\text{zaat}} = \\epsilon_{\\text{pcp}} + \\epsilon_c</span> , where  <span class="math">\\epsilon_{\\text{pcp}}</span>  is the soundness error of the Zaatar PCP (approximately  <span class="math">5 \\cdot 10^{-7}</span> ), and  <span class="math">\\epsilon_c</span>  is the error from the commitment protocol (for Zaatar,  <span class="math">\\epsilon_c \\approx 6000 \\cdot \\sqrt[3]{1/|\\mathbb{F}|}</span> ).</p>

    <p class="text-gray-300">&lt;span id=&quot;page-25-1&quot;&gt;&lt;/span&gt;<strong>Lemma B.1.</strong> The Zaatar argument protocol has the PoK property with  <span class="math">\\epsilon_K = 2 \\cdot \\epsilon_{\\text{pcp}} + \\epsilon_c</span> , and  <span class="math">\\epsilon_K&#x27; = (\\epsilon_{\\text{pcp}}/2) \\cdot (1 - n&#x27; \\cdot e^{-100})</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> The proof combines techniques from Barak and Goldreich (BG02) [10] and from the soundness proof of Pepper [72, Apdx. B] and IKO [47] (which is Pepper's and Zaatar's base). We will assume familiarity with the technical details of Zaatar, Pepper, and IKO, but not of BG02. At a very high level, all of these protocols consist of a commit phase (in which the verifier makes the prover commit to an oracle, which is supposed to be the PCP) and a decommit phase; in the latter phase, the verifier submits the PCP queries.</p>

    <p class="text-gray-300">The above works prove, loosely speaking, that at the end of the commit phase of the protocol, the prover is effectively bound to a particular (possibly inefficient) function f, from queries to responses. We face several technical difficulties in the present context. One of them is that just because f exists does not mean that it is easy to make the prover <em>respond</em> to queries. We will get around this issue by first showing that if there is  <span class="math">a &gt; \\epsilon_K</span>  probability of  <span class="math">\\mathcal V</span>  accepting, then it must be true that for almost all of the possible queries, the prover responds with non-negligible probability. Then, loosely speaking, the extraction procedure will amplify the non-negligible probability to be near-certain. This is done by pumping the prover: feeding it many different interactions. Another difficulty is that when the extractor performs this pumping, we have to be sure that values <em>other</em> than the correct one will be sufficiently</p>

    <p class="text-gray-300">infrequent that the pumping process won't get confused; we get around this by reformulating the claims that the prover is bound to a function <em>f</em> .</p>

    <p class="text-gray-300">The proof proceeds according to the following outline:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>We will describe an extraction procedure, leaving a number of parameters unspecified.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>We will analyze the extraction procedure and in so doing fill in the parameters. The analysis is in several parts:</li>
    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>We will reformulate some of the analysis of the binding properties of Pepper <a href="#page-40-16">[72,</a> Apdx. B].</li>
      <li>We will define notions <a href="#page-38-16">[10]</a> of queries being &quot;strong&quot; (or weak) and &quot;clear&quot; (or confounding); these notions are relative to a given commit phase. We hope that in a <em>useful</em> commit phase, the vast majority of queries are both strong and clear; furthermore, we hope that a non-negligible fraction of commit phases are useful.</li>
      <li>We will show that in useful commit phases, the function that the prover is bound to is a valid PCP oracle that encodes a satisfying assignment and has a soundness error identical to our usual.</li>
      <li>We will show that in useful commit phases, the overwhelming majority of queries are strong.</li>
      <li>We will show that in useful commit phases, the overwhelming majority of queries are clear.</li>
      <li>The above results will be used to upper-bound <em>&lt;sup&gt;K&lt;/sup&gt;</em> and lower-bound 0 <em>K</em> .</li>
    </ul></li>
    </ul>

    <h4 id="sec-21" class="text-lg font-semibold mt-6">B.1 Preliminaries</h4>

    <p class="text-gray-300">There are three sets of random coin flips in the Zaatar protocol: <em>c</em> represents the random coin flips that determine the commit phase, <em>d</em> represents the random coin flips that determine the decommit phase, and <em>r</em> represents the random coin flips that determine the PCP queries. Often, we will assume that the coins for the commit phase have been flipped, and we will be working within a commit phase <em>c</em>.</p>

    <p class="text-gray-300">Let <em>A&lt;sup&gt;i&lt;/sup&gt;</em> be the prover's response to the <em>i</em>th query, independent of whether the decommitment succeeds; when <em>A&lt;sup&gt;i&lt;/sup&gt;</em> depends on all three sources of randomness, we write <em>Ai</em>(<em>c</em>, <em>d</em>,<em>r</em>). A common case is that we will be interested in <em>A&lt;sup&gt;i&lt;/sup&gt;</em> , within some commit phase (i.e., the commit coin flips will have already been determined); in that case, <em>A&lt;sup&gt;i&lt;/sup&gt;</em> is a function of (<em>d</em>,<em>r</em>) and can be written <em>Ai</em>(<em>d</em>,<em>r</em>).</p>

    <p class="text-gray-300"><em>Whether</em> V <em>accepts</em> is a random variable that is a function of (<em>c</em>, <em>d</em>,<em>r</em>). Likewise, <em>whether</em> V <em>decommits</em> (that is, whether the decommitment succeeds) is a random variable.</p>

    <p class="text-gray-300">Let <em>Q</em>1(<em>r</em>), . . . , <em>Q</em>µ(<em>r</em>) represent the µ PCP queries generated by a particular choice of the PCP verifier's coin flips, <em>r</em>. The <em>Q&lt;sup&gt;i&lt;/sup&gt;</em> are random variables, but of course they do not depend on <em>c</em> or <em>d</em>.</p>

    <p class="text-gray-300">Let Vpcp denote Zaatar's PCP verifier. We will refer to Vpcp as generating queries and <em>accepting</em> their replies. (This can be formalized/notated with a query generation procedure Q((C, <em>x</em>, <em>y</em>),<em>r</em>, <em>i</em>), which, given the PCP coin flips, returns the <em>i</em>th query. Similarly, we can write down a decision procedure D((C, <em>x</em>, <em>y</em>),<em>r</em>, <em>a</em>1, . . . , <em>a</em>µ) that returns 1 or 0. While the notation is borrowed from BG02 <a href="#page-38-16">[10]</a>, the formalization itself is standard in the PCP literature.)</p>

    <p class="text-gray-300">A PCP admits <em>reverse sampling</em> (as defined in BG02 <a href="#page-38-16">[10]</a>) if, given a PCP query <em>q</em> and a position <em>i</em>, it is possible to choose the other PCP queries according to the random coins <em>r</em>, but holding <em>q</em> in the <em>i</em>th position. BG02 formalize this by saying that, given <em>q</em>, <em>i</em>, there is an efficient algorithm that can randomly and uniformly sample from all <em>r</em> such that Q((C, <em>x</em>, <em>y</em>),<em>r</em>, <em>i</em>) = <em>q</em>. In our context, it will be more helpful to think of the reverse sampling property as saying that for all <em>q</em>, <em>i</em>, it is possible to efficiently sample according to the conditional distribution {<em>Q</em>1(<em>r</em>), . . . , <em>Q</em>µ(<em>r</em>)}|<em>Qi</em>(<em>r</em>)=<em>&lt;sup&gt;q&lt;/sup&gt;</em> . Zaatar's PCP has the reverse sampling property.</p>

    <h4 id="sec-22" class="text-lg font-semibold mt-6">B.2 The extraction procedure</h4>

    <p class="text-gray-300">See Figure <a href="#page-27-0">13</a> for the extractor, <em>E</em>.</p>

    <pre><code class="language-text">// Goal is to produce a witness z that satisfies C(X=x,Y=y)
extract(P, C, x, y):
    flip the &quot;commit coins&quot;, and run the commit phase.
    // for the remainder of the procedure, we will be in this commit phase.
    for t = 1, ..., n&#x27;: // extract the tth witness element
        for k = 1, ..., T_1:
            choose q_r \\in_R \\mathbb{F}^{n&#x27;}
            q_s \\leftarrow q_r + e_t
            \\sigma_1 \\leftarrow \\text{extract\\_response}(q_r, C, x, y)
            \\sigma_2 \\leftarrow \\text{extract\\_response}(q_s, \\mathcal{C}, x, y)
           z_t^{(k)} \\leftarrow \\sigma_2 - \\sigma_1
        if a majority of \\{z_t^{(1)}, \\dots, z_t^{(T_1)}\\} equal the same value v:
        else:
            abort()
    output z_1, \\ldots, z_n
extract_response(q, C, x, y):
    for i = 1, \\ldots, \\mu:
        for i = 1, ..., T_2:
            • place q in position i, and reverse sample to get full set of queries: q_1, \\ldots, q_\\mu. Here, q_i = q.
            \\bullet run \\mathcal{P} in the decommit phase, flipping decommit coins randomly.
            • if decommit succeeds, save the ith response, labeling it \\sigma^{(i,j)}
        if more than (\\delta/3) \\cdot T_2 of the saved \\sigma^{(i,\\cdot)} are equal, store the value, calling it a candidate.
    if there is exactly one candidate value, \\sigma:
        return \\sigma
    else:
        abort()
</code></pre>

    <p class="text-gray-300">&lt;span id=&quot;page-27-0&quot;&gt;&lt;/span&gt;<strong>Figure 13</strong>—Definition of knowledge extractor, E. It borrows techniques from the oracle recovery procedure of Barak and Goldreich [10]. For now,  <span class="math">\\delta</span> ,  <span class="math">T_1</span> ,  <span class="math">T_2</span>  are parameters.  <span class="math">e_t</span>  is the vector with a 1 in component t and 0s elsewhere.</p>

    <h4 id="sec-23" class="text-lg font-semibold mt-6"><strong>B.3</strong> Analysis of the extractor</h4>

    <h4 id="sec-24" class="text-lg font-semibold mt-6">The binding of Pepper and Zaatar, revisited</h4>

    <p class="text-gray-300">Following IKO [47], Pepper's soundness analysis contains a binding game (Defn. B1 [72]); a commitment protocol is <em>admissible</em> if for all <em>environments</em> (loosely speaking, an environment encapsulates the process of producing PCP queries), the probability of the prover winning the binding game is negligible. The definition in IKO and Pepper is quantified over all deterministic environments.</p>

    <p class="text-gray-300">In the present work, the binding game is now played inside an environment  <span class="math">\\mathcal{E}</span>  that (a) chooses a distinguished query q and the positions i and i' deterministically (as previously), and (b) chooses the other queries  <span class="math">\\vec{q}</span>  and  <span class="math">\\vec{q&#x27;}</span>  randomly, according to a distribution of  <span class="math">\\mathcal{E}</span> 's choosing. The definition of &quot; <span class="math">S^*</span>  wins&quot; is the same (outputting conflicting field values and successfully decommitting), and a protocol is now admissible if for all environments  <span class="math">\\mathcal{E}</span> , the probability of  <span class="math">S^*</span>  winning is less than  <span class="math">\\epsilon_B = 1/|\\mathbb{F}|</span> , where the probability now is taken over the coins r, r' that generate the two choices of queries as well as the three</p>

    <p class="text-gray-300">phases of the binding game (commit phase, and two runs of the decommit phase).</p>

    <p class="text-gray-300">The new definition of admissible protocol (which quantifies over probabilistic environments) is, by averaging, equivalent to the old one (which quantifies over deterministic environments); IKO also observe this equivalence [47]. To see that meeting the old definition implies meeting the new one, observe that if the protocol doesn't meet the new property in some environment  <span class="math">\\mathcal{E}</span> , then there must (in  <span class="math">\\mathcal{E}</span> ) be an adverse  <span class="math">\\vec{q}</span>  and  <span class="math">\\vec{q&#x27;}</span>  for which  <span class="math">S^*</span> 's probability of winning the old binding game is larger than  <span class="math">\\epsilon_B</span> , contradicting the old definition.</p>

    <p class="text-gray-300">Next, we rerun some of the analysis in Pepper, under probabilistic environments. Define  <span class="math">A_c(q, i, a) = \\Pr_{d,r}\\{A_i(d,r) = a \\mid Q_i(r) = q\\}</span> ; this quantity is with respect to a particular commit phase c, and answers the question, &quot;given that q is in the ith position, if we reverse sample to get the other queries and flip the decommit coins, what is the probability that the ith output is a?&quot;. Define  <span class="math">\\operatorname{Ext}(c,q,i) = \\operatorname{argmax}_{a \\in \\mathbb{F}} A_c(q,i,a)</span> . Also, define  <span class="math">f_c(q)</span>  to be  <span class="math">\\operatorname{Ext}(c,q,i^*)</span> , for some distinguished  <span class="math">i^*</span>  (for example,  <span class="math">i^* = 1</span> ).</p>

    <p class="text-gray-300">&lt;span id=&quot;page-28-0&quot;&gt;&lt;/span&gt;<strong>Claim B.2.</strong> For all  <span class="math">q \\in \\mathbb{F}^{n&#x27;}</span> ,  <span class="math">i \\in [\\mu]</span> , we have:</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{c}\\left\\{\\Pr_{d,r}\\left\\{\\left\\{A_{i}(c,d,r)\\neq f_{c}(q)\\right\\} \\text{ and decommit happens } \\mid Q_{i}(r)=q\\right\\}&lt;\\epsilon_{3}\\right\\}&gt;1-\\epsilon_{3},</span>$</p>

    <p class="text-gray-300">where  <span class="math">\\epsilon_3 &lt; 6 \\cdot \\sqrt[3]{1/|\\mathbb{F}|}</span> .</p>

    <p class="text-gray-300"><em>Proof.</em> (Sketch.) This claim is similar to Claim B.4 in Pepper [72]. Essentially, wherever Pepper's proofs for Claims B.3 and B.4 talk about &quot;the probability over the decommit phase&quot;, one should write &quot;... over the decommit phase and choice of Q(r)&quot;. Also, the binding game that enforces the probabilities is of course over five (not three) sets of random coin flips.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-28-1&quot;&gt;&lt;/span&gt;Claim B.3 (Existence of  <span class="math">f_c(\\cdot)</span>  and commit error). Define  <span class="math">\\epsilon_c = 2 \\cdot \\mu \\cdot \\epsilon_3</span> .</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{c,d,r}\\left\\{\\text{decommit happens and } \\cup_{i=1}^{\\mu}\\left\\{A_i(c,d,r)\\neq f_c(Q_i(r))\\right\\}\\right\\}&lt;\\epsilon_c,</span>$</p>

    <p class="text-gray-300"><em>Proof.</em> Fix  <span class="math">i \\in [\\mu]</span> . Claim B.2 implies that</p>

    <p class="text-gray-300"><span class="math">$\\forall q\\colon \\Pr_{c,d,r}\\left\\{\\{A_i(c,d,r)\\neq f_c(q)\\}\\right. \\text{ and decommit happens }\\mid Q_i(r)=q\\}&lt;2\\epsilon_3.</span>$</p>

    <p class="text-gray-300">By an averaging argument, we get:</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{c,d,r} \\{ \\{ A_i(c,d,r) \\neq f_c(Q_i(r)) \\} \\text{ and decommit happens} \\} &lt; 2\\epsilon_3.</span>$</p>

    <p class="text-gray-300">A union bound over the  <span class="math">\\mu</span>  query positions implies the result.</p>

    <h4 id="sec-25" class="text-lg font-semibold mt-6">Notions of strong and clear</h4>

    <p class="text-gray-300"><strong>Definition B.1</strong> (strong and weak queries). Consider the event  <span class="math">\\{A_j(d,r) = f_c(Q_j(r))\\}</span> ; notice that whether this event holds is a function of the random coin flips (c,d,r). In commit view c, a query  <span class="math">q \\in \\mathbb{F}^{n&#x27;}</span>  is:</p>

    <p class="text-gray-300">•  <span class="math">\\delta</span> -strong if</p>

    <p class="text-gray-300"><span class="math">$\\exists i \\colon \\Pr_{d,r} \\left\\{ \\mathcal{V} \\text{ accepts and } \\cap_{j=1}^{\\mu} \\left\\{ A_j(d,r) = f_c(Q_j(r)) \\right\\} \\mid Q_i(r) = q \\right\\} \\geq \\delta.</span>$</p>

    <p class="text-gray-300">•  <span class="math">\\delta</span> -weak if</p>

    <p class="text-gray-300"><span class="math">$\\forall i \\colon \\Pr_{d,r} \\left\\{ \\mathcal{V} \\text{ accepts and } \\cap_{j=1}^{\\mu} \\left\\{ A_j(d,r) = f_c(Q_j(r)) \\right\\} \\mid Q_i(r) = q \\right\\} &lt; \\delta.</span>$</p>

    <p class="text-gray-300">This differs slightly from the Barak-Goldreich definition, which refers to strong and weak <em>answers</em>. The motivation for this definition is that if we can show most queries are strong (which we will be able to), then extract_response (in Figure <a href="#page-27-0">13)</a> will produce <em>fc</em>(<em>q</em>) with non-negligible probability.</p>

    <p class="text-gray-300">Definition B.2 (clear and confounding queries). In commit view <em>c</em>, a query <em>q</em> ∈ F <em>n</em> 0 is:</p>

    <p class="text-gray-300">• δ/10<em>-clear</em> if</p>

    <p class="text-gray-300"><span class="math">$\\forall i</span>$
:  <span class="math">\\Pr_{d,r} \\{ \\mathcal{V} \\text{ decommits and } \\{ A_i(d,r) \\neq f_c(q) \\} \\mid Q_i(r) = q \\} \\leq \\delta/10.</span></p>

    <p class="text-gray-300">• δ/10<em>-confounding</em> if</p>

    <p class="text-gray-300"><span class="math">$\\exists i \\colon \\Pr_{d,r} \\{ \\mathcal{V} \\text{ decommits and } \\{ A_i(d,r) \\neq f_c(q) \\} \\mid Q_i(r) = q \\} &gt; \\delta/10.</span>$</p>

    <p class="text-gray-300">This, too, is different from the analogous Barak-Goldreich definition, since they do not talk about a specific function <em>fc</em>(·). The motivation for this definition is that if we can show most queries are clear (which we will be able to), then extract_response (Figure <a href="#page-27-0">13)</a> does not have to worry that a field element other than <em>fc</em>(<em>q</em>) shows up often enough to be confounding.</p>

    <p class="text-gray-300">When a query is both strong and clear, observe that the extract_response subroutine is likely to deliver a clear &quot;signal.&quot;</p>

    <h3 id="sec-26" class="text-xl font-semibold mt-8"><em>Auspicious commit phases happen often enough</em></h3>

    <p class="text-gray-300">Define a commit phase as <em>auspicious</em> if, in that phase, Pr<em>d</em>,<em>r</em>{V accepts and∩ µ <em>j</em>=1 {<em>Aj</em>(<em>d</em>,<em>r</em>) = <em>fc</em>(<em>Qj</em>(<em>r</em>))}} &gt; (1/2) · ; an <em>auspicious</em> commit phase will not necessarily be <em>useful</em>, but auspiciousness is a precondition to usefulness (see Claim <a href="#page-31-0">B.9</a> and the analysis that follows it).</p>

    <p class="text-gray-300">Recall the premise of the PoK property: Pr<em>c</em>,<em>d</em>,<em>r</em>{V accepts} &gt; <em>K</em>. The next claim guarantees that, when this premise holds, auspicious commit phases happen with non-negligible probability.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-29-0&quot;&gt;&lt;/span&gt;Claim B.4 (Auspicious commit phases). If Pr<em>c</em>,<em>d</em>,<em>r</em>{V accepts} &gt; <em>K</em>, then</p>

    <p class="text-gray-300"><span class="math">$\\Pr_c\\left\\{\\Pr_{d,r}\\{\\mathcal{V} \\text{ accepts and } \\cap_{j=1}^{\\mu}\\left\\{A_j(d,r)=f_c(Q_j(r))\\right\\}\\right\\} &gt; (1/2)\\cdot\\epsilon\\right\\} &gt; (1/2)\\cdot\\epsilon,</span>$</p>

    <p class="text-gray-300">where def &lt;sup&gt;=&lt;/sup&gt; <em>&lt;sup&gt;K&lt;/sup&gt;</em> &lt;sup&gt;−&lt;/sup&gt; <em>c</em>, and <em>&lt;sup&gt;c&lt;/sup&gt;</em> was defined in Claim <a href="#page-28-1">B.3.</a></p>

    <p class="text-gray-300"><em>Proof.</em> From Claim <a href="#page-28-1">B.3,</a></p>

    <p class="text-gray-300"><span class="math">$\\Pr_{c,d,r}\\{\\mathcal{V} \\text{ decommits and } \\cup_{j=1}^{\\mu} \\{A_j(c,d,r) \\neq f_c(Q_j(r))\\}\\} &lt; \\epsilon_c.</span>$</p>

    <p class="text-gray-300">But accepting implies decommitting and not the other way around, so</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{c,d,r}\\{\\mathcal{V} \\text{ accepts and } \\cup_{j=1}^{\\mu} \\{A_j(c,d,r) \\neq f_c(Q_j(r))\\}\\} &lt; \\epsilon_c.</span>$</p>

    <p class="text-gray-300">Combining the given with the inequality immediately above, we get:</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{c,d,r}\\{\\mathcal{V} \\text{ accepts and } \\cap_{j=1}^{\\mu} \\{A_j(c,d,r) = f_c(Q_j(r))\\}\\} &gt; \\epsilon_K - \\epsilon_c = \\epsilon.</span>$</p>

    <p class="text-gray-300">Standard counting or averaging implies the result.</p>

    <p class="text-gray-300">Recall that Vpcp denotes the Zaatar PCP verifier. The next two claims state that with probability that cannot be neglected (a) Vpcp accepts (which implies that <em>fc</em>(·) is of the right form), and (b) all queries issued by Vpcp are, in the context of the argument protocol, δ-strong.</p>

    <p class="text-gray-300"><em>After auspicious commit phases, fc</em>(·) <em>is a valid PCP oracle</em></p>

    <p class="text-gray-300">&lt;span id=&quot;page-30-1&quot;&gt;&lt;/span&gt;Claim B.5 (Vpcp accepts often). Assuming we are in an auspicious commit phase,</p>

    <p class="text-gray-300"><span class="math">$\\Pr_r \\left\\{ \\mathcal{V}_{\\text{pcp}} \\text{ accepts } \\left( f_c(Q_1(r)), \\dots, f_c(Q_\\mu(r)) \\right) \\right\\} &gt; (1/2) \\cdot \\epsilon.</span>$</p>

    <p class="text-gray-300"><em>Proof.</em> In an auspicious commit phase</p>

    <p class="text-gray-300"><span class="math">$(1/2) \\cdot \\epsilon &lt; \\Pr_{d,r} \\left\\{ \\mathcal{V} \\text{ accepts and } \\cap_{i=1}^{\\mu} \\left\\{ A_i(d,r) = f_c(Q_i(r)) \\right\\} \\right\\}.</span>$</p>

    <p class="text-gray-300">But if V accepts on a particular set of coin flips, then Vpcp must accept the same answers, since the latter is a precondition for the former. So we can bound the expression above:</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} &amp;\\leq \\Pr_{d,r} \\left\\{ \\mathcal{V}_{\\text{pcp}} \\text{ accepts } \\left( A_1(d,r), \\ldots, A_{\\mu}(d,r) \\right) \\text{ and } \\cap_{i=1}^{\\mu} \\left\\{ A_i(d,r) = f_c(Q_i(r)) \\right\\} \\right\\} \\\\ &amp;\\leq \\Pr_{d,r} \\left\\{ \\mathcal{V}_{\\text{pcp}} \\text{ accepts } \\left( f_c(Q_1(r)), \\ldots, f_c(Q_{\\mu}(r)) \\right) \\right\\} \\\\ &amp;= \\Pr_{r} \\left\\{ \\mathcal{V}_{\\text{pcp}} \\text{ accepts } \\left( f_c(Q_1(r)), \\ldots, f_c(Q_{\\mu}(r)) \\right) \\right\\}. \\end{split}</span>$</p>

    <p class="text-gray-300">The second inequality holds because the event in its LHS is a restricted case of the event in its RHS. The equality holds because its LHS is independent of the <em>d</em> coins.</p>

    <p class="text-gray-300">Take /2 = pcp, where pcp is Zaatar's PCP soundness error. The claim above, together with the properties of Zaatar (soundness <a href="#page-40-11">[71,</a> Lemma A.3] and one other: see below), implies the following:</p>

    <p class="text-gray-300">&lt;span id=&quot;page-30-0&quot;&gt;&lt;/span&gt;Corollary B.6 (<em>fc</em>(·) is often a valid PCP oracle). In auspicious commit phases, <em>fc</em>(·) is a well-formed Zaatar PCP oracle: it is 0.0294-close to a linear function that encodes a witness <em>z</em> that satisfies C(<em>X</em>=<em>x</em>, <em>Y</em>=<em>y</em>).</p>

    <p class="text-gray-300">This corollary relies on a property of Zaatar's PCP that is stronger than soundness: &quot;well-formedness&quot;. As stated, this property is (a shade) stronger than <em>PCP proof-of-knowledge (PCP PoK)</em>. PCP PoK <a href="#page-38-16">[10]</a> says that if Vpcp accepts with greater than the soundness error, then not only is C satisfiable (which is what the soundness property gives) but also there is an efficient algorithm that can extract a satisfying witness, given access to the PCP oracle. As Barak and Goldreich <a href="#page-38-16">[10]</a> observe, many PCPs have the PCP PoK property (Zaatar does too), but there are few (if any) proofs in the literature. The reason that our well-formedness property is slightly stronger than a PCP PoK property is that it actually specifies the form of the PCP (and any PCP meeting this form can, through self-correction, yield a witness).</p>

    <h4 id="sec-27" class="text-lg font-semibold mt-6"><em>After auspicious commit phases, most queries are strong</em></h4>

    <p class="text-gray-300">Claim B.7. Assuming we are in an auspicious commit phase,</p>

    <p class="text-gray-300"><span class="math">$\\Pr_r\\{\\mathcal{V}_{\\text{pcp}} \\text{ makes only } \\delta\\text{-strong queries}\\} &gt; \\epsilon/4,</span>$</p>

    <p class="text-gray-300">for
<span class="math">$\\delta = (1/4)\\epsilon/\\mu</span>$
.</p>

    <p class="text-gray-300"><em>Proof.</em> Fix a query position <em>i</em> ∈ [µ]:</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{d,r} \\left\\{ \\mathcal{V} \\text{ accepts and } \\bigcap_{j=1}^{\\mu} \\left\\{ A_j(d,r) = f_c(Q_j(r)) \\right\\} \\text{ and } Q_i(r) \\text{ is } \\delta\\text{-weak} \\right\\}</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{q: \\ q \\text{ is } \\delta\\text{-weak}} \\Pr_{d,r} \\left\\{ \\mathcal{V} \\text{ accepts and } \\bigcap_{j=1}^{\\mu} \\left\\{ A_j(d,r) = f_c(Q_j(r)) \\right\\} \\mid Q_i(r) = q \\right\\} \\cdot \\Pr_r \\left\\{ Q_i(r) = q \\right\\}</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\sum_{q: \\ q \\text{ is } \\delta\\text{-weak}} \\delta \\cdot \\Pr_r \\left\\{ Q_i(r) = q \\right\\} &lt; \\delta</span>$</p>

    <p class="text-gray-300">By the union bound over positions 1, . . . , µ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{d,r} \\Big\\{ \\mathcal{V} \\text{ accepts and } \\cap_{j=1}^{\\mu} \\big\\{ A_j(d,r) = f_c(Q_j(r)) \\big\\} \\text{ and } \\mathit{any } Q_j(r) \\text{ is } \\delta\\text{-weak} \\Big\\} &lt; \\mu \\cdot \\delta.</span>$</p>

    <p class="text-gray-300">Combining this with the definition of auspicious, we get</p>

    <p class="text-gray-300"><span class="math">$(1/2)\\epsilon - \\mu \\cdot \\delta &lt; \\Pr_{d,r} \\left\\{ \\mathcal{V} \\text{ accepts and } \\cap_{j=1}^{\\mu} \\left\\{ A_{j}(d,r) = f_{c}(Q_{j}(r)) \\right\\} \\text{ and all of } Q_{1}(r), \\dots, Q_{\\mu}(r) \\text{ are } \\delta\\text{-strong} \\right\\}</span>$</p>

    <p class="text-gray-300"><span class="math">$\\leq \\Pr_{d,r} \\left\\{ \\text{all of } Q_{1}(r), \\dots, Q_{\\mu}(r) \\text{ are } \\delta\\text{-strong} \\right\\}</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\Pr_{r} \\left\\{ \\text{all of } Q_{1}(r), \\dots, Q_{\\mu}(r) \\text{ are } \\delta\\text{-strong} \\right\\}</span>$</p>

    <p class="text-gray-300">Substituting δ = (1/4)/µ in the lower bound gives the result.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-31-1&quot;&gt;&lt;/span&gt;Corollary B.8 (Most queries are strong). Recalling that Vpcp makes µ PCP queries, if ρ &lt;sup&gt;0&lt;/sup&gt; of these queries are <em>independently and uniformly random</em>, then (in auspicious commit phases) the fraction of total queries that is δ-strong is greater than (/4) 1/ρ&lt;sup&gt;0&lt;/sup&gt; .</p>

    <p class="text-gray-300">At this point, we are ready to argue that the overwhelming majority of queries are δ-strong. Looking at Zaatar's PCP, it has ρ &lt;sup&gt;0&lt;/sup&gt; = 320 queries that hit π<em>&lt;sup&gt;z&lt;/sup&gt;</em> randomly. Furthermore, we took = 2pcp ≈ 10−&lt;sup&gt;6&lt;/sup&gt; (since pcp, the soundness error of Zaatar's PCP, is ≈ 5 · 10−&lt;sup&gt;7&lt;/sup&gt; <a href="#page-40-11">[71,</a> Apdx. A]). Thus, by Corollary <a href="#page-31-1">B.8,</a> after auspicious commit phases, the fraction of total queries that is δ-strong is greater than (/4) &lt;sup&gt;1&lt;/sup&gt;/&lt;sup&gt;320&lt;/sup&gt; &gt; 0.95.</p>

    <h4 id="sec-28" class="text-lg font-semibold mt-6"><em>In most commit phases, most queries are not confounding</em></h4>

    <p class="text-gray-300">Recall that the notion of being δ-confounding is a function of the commit phase. We will now show that in the vast majority of commit phases, the vast majority of <em>q</em> are not 3-confounding (&lt;sup&gt;3&lt;/sup&gt; is from Claim <a href="#page-28-0">B.2)</a>.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-31-0&quot;&gt;&lt;/span&gt;Claim B.9 (Most queries are clear). Letting Pr<em>&lt;sup&gt;q&lt;/sup&gt;</em> denote a uniformly random choice of <em>q</em>,</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{c} \\left\\{ \\Pr_{q} \\left\\{ q \\text{ is } \\epsilon_{3}\\text{-confounding} \\right\\} &lt; 1/20 \\right\\} &gt; 1 - 20\\mu\\epsilon_{3}</span>$</p>

    <p class="text-gray-300"><em>Proof.</em> Let <em>Gq</em>,<em>i</em>(<em>c</em>) denote the event in commit phase <em>c</em> that</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{d,r}\\left\\{\\left\\{A_i(d,r)\\neq f_c(q)\\right\\} \\text{ and decommit happens } \\mid Q_i(r)=q\\right\\} &gt; \\epsilon_3.</span>$</p>

    <p class="text-gray-300">Once <em>q</em> and <em>i</em> have been fixed, this expression is either true or not in commit phase <em>c</em>, and that is what the events <em>G</em> will capture. Claim <a href="#page-28-0">B.2</a> implies:</p>

    <p class="text-gray-300"><span class="math">$\\forall q, i: \\Pr_{c} \\left\\{ G_{q,i}(c) \\right\\} &lt; \\epsilon_3.</span>$</p>

    <p class="text-gray-300">Applying a union bound over query positions, we get</p>

    <p class="text-gray-300"><span class="math">$\\forall q \\colon \\Pr_{c} \\left\\{ \\cup_{i=1}^{\\mu} G_{q,i}(c) \\right\\} &lt; \\mu \\epsilon_3.</span>$</p>

    <p class="text-gray-300">By definition of 3-confounding</p>

    <p class="text-gray-300"><span class="math">$\\forall q \\colon \\Pr_{c} \\{q \\text{ is } \\epsilon_3\\text{-confounding}\\} &lt; \\mu \\epsilon_3.</span>$</p>

    <p class="text-gray-300">Applying a standard averaging argument followed by a Markov bound</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{c} \\left\\{ \\Pr_{q} \\left\\{ q \\text{ is } \\epsilon_{3}\\text{-confounding} \\right\\} &gt; 1/20 \\right\\} &lt; 20\\mu\\epsilon_{3}</span>$</p>

    <p class="text-gray-300">The complementary probabilities and events to the ones immediately above imply the claim.</p>

    <h4 id="sec-29" class="text-lg font-semibold mt-6">Completing the analysis</h4>

    <p class="text-gray-300">We require</p>

    <p class="text-gray-300"><span class="math">$\\epsilon_3 &lt; \\min\\left\\{\\frac{\\epsilon}{40\\mu}, \\, \\frac{\\epsilon}{80\\mu}\\right\\}</span>$</p>

    <p class="text-gray-300">because:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The first component in the min ensures that  <span class="math">\\epsilon_3 &lt; \\delta/10</span>  (recall that  <span class="math">\\delta = \\epsilon/(4\\mu)</span> ). This bound gives us a gap (between  <span class="math">\\delta</span>  and  <span class="math">\\delta/10</span> ) that helps us pump the prover in the &quot;inner extraction loop&quot;.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The second component will ensure that the fraction of useful commit phases is  <span class="math">&gt; \\epsilon/2 20\\mu\\epsilon_3 &gt; \\epsilon/4</span> , which we want, to ensure that  <span class="math">\\epsilon&#x27;_K</span>  (in the definition of PoK) is non-negligible.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">We must verify that the upper bound on  <span class="math">\\epsilon_3</span>  holds. Recall that  <span class="math">\\epsilon_3 &lt; 6 \\cdot \\sqrt[3]{1/|\\mathbb{F}|}</span>  (from Claim B.2) and  <span class="math">\\epsilon = 2\\epsilon_{\\rm pcp} \\approx 10^{-6}</span>  (see Corollaries B.6 and B.8); also,  <span class="math">\\mu</span>  is almost exactly 1000. Fortunately, at the field size that Pantry works with (128 bits),  <span class="math">6 \\cdot \\sqrt[3]{1/|\\mathbb{F}|} &lt; \\epsilon/(80\\mu)</span> , so the bound holds.</p>

    <p class="text-gray-300">Analyzing the steps of the extractor. By Claim B.4, if the PoK premise  <span class="math">(\\Pr{\\mathcal{V} \\text{ accepts}}) &gt; \\epsilon_K)</span>  holds, the choice of commit phase in the extractor is <em>useful</em> with probability  <span class="math">&gt; \\epsilon/2 - (20\\mu\\epsilon_3) &gt; \\epsilon/4</span> ; this is a commit phase that is both auspicious <em>and</em> bounds the fraction of  <span class="math">\\epsilon_3</span> -confounding queries, in the sense of Claim B.9. From now on, we assume such a useful commit phase. By Corollary B.6,  <span class="math">f_c(\\cdot)</span>  is  <span class="math">\\delta&#x27;</span> -close to a linear function that encodes a satisfying witness  <span class="math">\\vec{z}</span> , for some  <span class="math">\\delta&#x27;</span>  that is &lt; .03. Note that this  <span class="math">\\delta&#x27;</span>  is different from the  <span class="math">\\delta</span>  in some of the claims stated earlier.</p>

    <p class="text-gray-300">Now fix t; consider iteration k. Look at query  <span class="math">q_r</span>  in this iteration. By definition of  <span class="math">\\delta&#x27;</span> -close, we have  <span class="math">\\Pr_{q_r}\\{q_r \\text{ hits } f_c(\\cdot) \\text{ where it is not linear}\\} &lt; .03</span> , where the probability is taken over the coins that generate  <span class="math">q_r</span> . Also, by Corollary B.8,  <span class="math">\\Pr_{q_r}\\{q_r \\text{ is } \\delta\\text{-weak}\\} &lt; 1 - (\\epsilon/4)^{1/\\rho&#x27;} &lt; .05</span> . And we have  <span class="math">1/20 &gt; \\Pr_{q_r}\\{q_r \\text{ is } \\epsilon_3\\text{-confounding}\\} \\ge \\Pr_{q_r}\\{q_r \\text{ is } \\delta/10\\text{-confounding}\\}</span> . The first inequality comes from Claim B.9; the second, from the bound on  <span class="math">\\epsilon_3</span>  and the definition of confounding. Therefore, the probability (over the random choice of  <span class="math">q_r</span>  and  <span class="math">q_s</span> ) that  <span class="math">q_r</span>  and  <span class="math">q_s</span>  both have the desirable properties (namely:  <span class="math">\\Pr_{q_r}\\{e_r\\}</span> ) where linear; strong; clear) is at least 1 - 2(.03 + .05 + .05) = 0.74. Call an iteration k in which this event occurs &quot;good&quot;.</p>

    <p class="text-gray-300">Next, consider the &quot;inner loop&quot; (the function extract_response), assuming the iteration is good. We'll speak of  <span class="math">q_r</span> , but the same analysis applies to  <span class="math">q_s</span> :</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Because  <span class="math">q_r</span>  is  <span class="math">\\delta</span> -strong, there is a query position  <span class="math">i^*</span>  for which the  <span class="math">i^*</span>  response is  <span class="math">f_c(q_r)</span> , with probability at least  <span class="math">\\delta</span>  over the reverse sampling coins. Thus, the expected number of times decommit succeeds when  <span class="math">i=i^*</span>  is  <span class="math">\\geq \\delta \\cdot T_2</span> . Now we apply a Chernoff bound, using this form [61, Thm. 4.2]:  <span class="math">\\Pr\\{X \\leq (1-a)E[X]\\} &lt; e^{-a^2 \\cdot E[X]/2}</span> . We take  <span class="math">E[X] \\geq \\delta \\cdot T_2</span>  and  <span class="math">a \\geq 2/3</span> . This implies that for  <span class="math">T_2 &gt; 21/\\delta</span> , the probability in iteration k that position  <span class="math">i^*</span>  will <em>not</em> label  <span class="math">f_c(q_r)</span>  a candidate is &lt; (1/100). The probability is over the coins used for reverse sampling in the j loop of iteration  <span class="math">i^*</span> .</li>
      <li>Now fix any position  <span class="math">i \\in [\\mu]</span> . Call all field elements besides  <span class="math">f_c(q_r)</span>  scrap. We wish to upper bound the probability of the event (over the reverse sampling coins used in the j loop) that all scrap, together, is decommitted more than  <span class="math">(\\delta/3) \\cdot T_2</span>  times: this probability is an upper bound on the probability that any field value is actually labeled a candidate (since if the scrap together does not clear the threshold, then no element by itself does).  <span class="math">q_r</span>  is  <span class="math">(\\delta/10)</span> -clear, so the expected number of times that all scrap, together, is decommitted is  <span class="math">&lt;(\\delta/10) \\cdot T_2</span> . We use this form of the Chernoff bound [61, Thm 4.3]:  <span class="math">\\Pr\\{X \\geq (1+a)E[X]\\} &lt; e^{-a^2E[X]/4}</span> . For  <span class="math">T_2 \\geq 4.7/\\delta &gt; (\\ln(100\\mu))/(2.5 \\cdot \\delta)</span> , an upper bound on the event in question is  <span class="math">10^{-5}</span> .</li>
      <li>Now we can union bound over all  <span class="math">\\mu</span>  query positions: the probability (over the reverse sampling coins in extract_response) that <em>any</em> position has a scrap candidate is  <span class="math">&lt; \\mu \\cdot 10^{-5}</span> . Combining this with the event that  <span class="math">f_c(q_r)</span>  is not labeled a candidate, we get that  <span class="math">f_c(q_r)</span>  is not returned from extract_response</li>
    </ul>

    <p class="text-gray-300">with probability upper-bounded by 2/100. The same goes for  <span class="math">f_c(q_s)</span> .</p>

    <p class="text-gray-300">Now, if iteration k is good, and furthermore produces  <span class="math">f_c(q_r)</span>  and  <span class="math">f_c(q_s)</span> , then  <span class="math">\\sigma_2 - \\sigma_1 = f_c(q_r + e_t) - f_c(q_r) = \\vec{z} \\cdot (q_r + e_t) - \\vec{z} \\cdot (q_r) = \\vec{z} \\cdot e_t = z_t</span> . Thus, in iteration k, the probability (over all of the randomness that the algorithm used in the iteration: choice of  <span class="math">q_r, q_s</span>  and reverse sampling in extract_response) of outputting  <span class="math">z_t</span>  is greater than &gt; 1 - 2(.03 + .05 + .05 + .02) = 7/10. Now we apply another Chernoff bound, this time over the iterations k. For  <span class="math">T_1 &gt; 3500</span> , the probability that there are fewer than  <span class="math">T_1/2</span>  instances of  <span class="math">z_t</span>  is  <span class="math">&lt; e^{-100}</span> .</p>

    <p class="text-gray-300">Applying a union bound to all positions in the witness, the probability of not extracting the witness (if we're in a useful commit phase) is  <span class="math">&lt; n&#x27; \\cdot e^{-100}</span> . Also, the probability of a useful commit phase is, as stated above, greater than  <span class="math">\\epsilon/4</span> ; furthermore,  <span class="math">\\epsilon = 2 \\cdot \\epsilon_{\\rm pcp}</span>  (see page 31). Therefore, the probability (over all of the extractor's many coin flips) of producing a witness is at least  <span class="math">(\\epsilon_{\\rm pcp}/2) \\cdot (1 - n&#x27; \\cdot e^{-100})</span> , which was what the lemma claimed.</p>

    <p class="text-gray-300">Our analysis produced lower bounds for  <span class="math">T_1</span>  and  <span class="math">T_2</span> :  <span class="math">T_1 &gt; 3500</span>  and  <span class="math">T_2 &gt; 80</span>  billion. The extractor thus has an appalling concrete cost: producing <em>one</em> component of a witness requires running the verifier-prover decommit phase (including generating queries)  <span class="math">5 \\cdot 10^{17}</span>  times, and that's only if the event of a useful commit phase happened, which has probability  <span class="math">\\geq \\epsilon/4 \\approx 2.5 \\cdot 10^{-7}</span> ! Thus, the expected time to generate a witness is  <span class="math">10^{24}</span>  times the effort required to run the decommit phase. Nevertheless, the extractor runs in &quot;polynomial time&quot;, as required. (The quotation marks are because our analysis is not asymptotic; in an asymptotic analysis, n' would grow, the error terms would depend on n', etc.)</p>

    <p class="text-gray-300">Furthermore, the expected time to obtain a witness, though massive, is still far less than the expected time to generate a hash collision, as Pantry uses a hash function with at least 180 bits of security (§7). This gap is sufficient to generate the required contradictions in the proofs in Appendix A.</p>

    <h4 id="sec-30" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-33-0&quot;&gt;&lt;/span&gt;C An HMAC-based commitment</h4>

    <p class="text-gray-300">In Section 6, we explain that in order to enable applications where the prover's state is private, we need a commitment to bind the prover to the state while hiding it from the verifier. Ordinarily, we would use a standard commitment scheme, such as Pedersen's [67], which would guarantee binding with respect to a computationally-bound prover along with information-theoretic hiding with respect to the verifier. Because Pedersen's protocol cannot be represented efficiently as constraints, we instead use a simple scheme based on HMAC-SHA256, which also provides computational binding, but hiding that is only computational. We present our scheme and prove its security here.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Setup(1&lt;sup&gt;n&lt;/sup&gt;) → CK
Setup takes a unary string of length n, a security parameter, and returns CK, a public commitment key that is used to distinguish commitments based on this construction from other MACs generated using HMAC-SHA256.</li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>Commit <span class="math">(m,r) \\to c</span> , where  <span class="math">c = \\text{HMAC-SHA256}_r(CK \\mid\\mid m)</span>  and  <span class="math">r \\leftarrow_R \\{0,1\\}^{512}</span>  Commit takes the message m and a randomly-chosen value r as input and returns a commitment c. r can later be revealed to decommit.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathsf{Decommit}(m&#x27;,r&#x27;,c) \\to \\left\\{ \\begin{array}{ll} \\mathsf{true} &amp; \\mathsf{if}\\ c = \\mathsf{HMAC}\\text{-}\\mathsf{SHA256}_{r&#x27;}(CK\\,||\\,m&#x27;) \\\\ \\mathsf{false} &amp; \\mathsf{otherwise} \\end{array} \\right.</span>   <span class="math">\\mathsf{Decommit}\\ \\mathsf{takes}\\ \\mathsf{the}\\ \\mathsf{purported}\\ \\mathsf{message}\\ m&#x27;\\ \\mathsf{and}\\ \\mathsf{decommitment}\\ \\mathsf{key}\\ r&#x27;\\ \\mathsf{as}\\ \\mathsf{input}\\ \\mathsf{and}\\ \\mathsf{recomputes}\\ \\mathsf{the}\\ \\mathsf{HMAC}\\text{-}\\mathsf{SHA256}\\ \\mathsf{to}\\ \\mathsf{check}\\ \\mathsf{whether}\\ \\mathsf{it}\\ \\mathsf{equals}\\ \\mathsf{the}\\ \\mathsf{received}\\ \\mathsf{commitment}\\ c.\\ \\mathsf{If}\\ \\mathsf{so},\\ \\mathsf{the}\\ \\mathsf{commitment}\\ \\mathsf{is}\\ \\mathsf{considered}\\ \\mathsf{validly}\\ \\mathsf{decommitted},\\ \\mathsf{and}\\ \\mathsf{it}\\ \\mathsf{is}\\ \\mathsf{considered}\\ \\mathsf{invalidly}\\ \\mathsf{decommitted}\\ \\mathsf{otherwise}.</span></li>
    </ol></li>
    </ul>

    <p class="text-gray-300"><strong>Lemma C.1.</strong> The construction above, which we denote  <span class="math">\\Pi = (\\text{Setup}, \\text{Commit}, \\text{Decommit})</span> , is a correct, computationally hiding, computationally binding commitment if (1) HMAC-SHA256 is a PRF and (2) SHA-256 is a CRHF.</p>

    <p class="text-gray-300"><em>Proof.</em> A commitment scheme is correct if  <span class="math">\\mathsf{Decommit}(m, r, \\mathsf{Commit}(m, r)) = \\mathsf{true}</span>  for all m and r. One can see that  <span class="math">\\Pi</span>  is correct because  <span class="math">\\mathsf{Decommit}(m, r, c) = \\mathsf{true}</span>  when  <span class="math">c = \\mathsf{HMAC}\\text{-SHA256}_r(CK \\mid\\mid m)</span> , which is exactly what  <span class="math">\\mathsf{Commit}(m, r)</span>  computes. The proofs of hiding and binding follow from Claims C.2 and C.3 respectively.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-34-0&quot;&gt;&lt;/span&gt;Claim C.2. If HMAC-SHA256 is a PRF,  <span class="math">^9</span>  then  <span class="math">\\Pi</span>  is a computationally hiding commitment.</p>

    <p class="text-gray-300"><em>Proof.</em> Computational hiding is defined with respect to the following game played by a probabilistic polynomial time (PPT) adversary A:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The committer runs  <span class="math">\\mathsf{Setup}(1^n) \\to \\mathsf{CK}</span></li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{A}</span>  picks two messages  <span class="math">m_0</span>  and  <span class="math">m_1</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>The committer chooses  <span class="math">b \\leftarrow_R \\{0,1\\}</span>  and  <span class="math">r \\leftarrow_R \\{0,1\\}^k</span> , computes  <span class="math">c = \\mathsf{Commit}(m_b,r)</span> , and sends c to  <span class="math">\\mathcal{A}^{10}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{A}</span>  outputs b' and wins if b' = b.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Denote the probability (over the random choices of  <span class="math">\\mathcal{A}</span>  and the committer) that  <span class="math">\\mathcal{A}</span>  wins this game against commitment scheme  <span class="math">\\Pi</span>  by  <span class="math">\\Pr\\left\\{\\mathsf{BreakHiding}_{\\mathcal{A},\\Pi}(n)=1\\right\\}</span> . We say that  <span class="math">\\Pi</span>  is computationally hiding if  <span class="math">\\epsilon(n)\\stackrel{\\mathrm{def}}{=}\\Pr\\left\\{\\mathsf{BreakHiding}_{\\mathcal{A},\\Pi}(n)=1\\right\\}-\\frac{1}{2}</span>  is negligible.</p>

    <p class="text-gray-300">To see why  <span class="math">\\epsilon(n)</span>  must be negligible, we consider a variant of our scheme  <span class="math">\\widetilde{\\Pi}=(\\widetilde{\\operatorname{Setup}},\\widetilde{\\operatorname{Commit}},\\operatorname{Decommit})</span>  where  <span class="math">\\operatorname{HMAC-SHA256}_r(\\operatorname{CK}||m)</span>  is replaced by  <span class="math">f(\\operatorname{CK}||m)</span>  and f is a truly random function. In that case,  <span class="math">\\operatorname{Pr}\\left\\{\\operatorname{BreakHiding}_{\\mathcal{A},\\widetilde{\\Pi}}(n)=1\\right\\}=\\frac{1}{2}</span>  and therefore,</p>

    <p class="text-gray-300"><span class="math">$\\epsilon(n) = \\Pr\\left\\{\\mathsf{BreakHiding}_{\\mathcal{A},\\Pi}(n) = 1\\right\\} - \\Pr\\left\\{\\mathsf{BreakHiding}_{\\mathcal{A},\\widetilde{\\Pi}}(n) = 1\\right\\}.</span>$</p>

    <p class="text-gray-300">Now, suppose that we construct a PPT algorithm  <span class="math">\\mathcal{D}</span>  that attempts to distinguish between HMAC-SHA256 and f defined as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{D}</span>  is given  <span class="math">1^n</span>  along with an oracle  <span class="math">\\mathcal{O}</span>  that is either HMAC-SHA256, where  <span class="math">r \\leftarrow_R \\{0, 1\\}^{512}</span> , or f.</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{D}</span>  runs  <span class="math">\\mathsf{Setup}(1^n) \\to \\mathsf{CK}</span>  and  <span class="math">\\mathcal{A}(1^n)</span> . When  <span class="math">\\mathcal{A}</span>  provides two messages  <span class="math">m_0</span>  and  <span class="math">m_1</span> ,  <span class="math">\\mathcal{D}</span>  picks  <span class="math">b \\leftarrow_R \\{0, 1\\}</span> , and returns  <span class="math">c = \\mathcal{O}(CK || m_b)</span>  to  <span class="math">\\mathcal{A}</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>When  <span class="math">\\mathcal{A}</span>  outputs b',  <span class="math">\\mathcal{D}</span>  returns 1 if b' = b and 0 otherwise.</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">If  <span class="math">\\mathcal{O}</span>  is HMAC-SHA256&lt;sub&gt;r&lt;/sub&gt;, then  <span class="math">\\mathcal{A}</span> 's view when run as a subroutine of  <span class="math">\\mathcal{D}</span>  is identical to  <span class="math">\\mathcal{A}</span> 's view when playing the computational hiding game. Thus,</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left\\{\\mathcal{D}^{\\text{HMAC-SHA256}_r}(1^n) = 1\\right\\} = \\Pr\\left\\{\\text{BreakHiding}_{\\mathcal{A},\\Pi}(n) = 1\\right\\}</span>$</p>

    <p class="text-gray-300">where  <span class="math">\\Pr \\{ \\mathcal{D}^{\\text{HMAC-SHA256}_r}(1^n) = 1 \\}</span>  is taken over r and  <span class="math">\\mathcal{D}</span> 's and  <span class="math">\\mathcal{A}</span> 's random choices, and similarly,</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left\\{\\mathcal{D}^f(1^n)=1\\right\\}=\\Pr\\left\\{\\mathsf{BreakHiding}_{\\mathcal{A},\\widetilde{\\Pi}}(n)=1\\right\\}</span>$</p>

    <p class="text-gray-300">and so</p>

    <p class="text-gray-300"><span class="math">$\\epsilon(n) = \\Pr\\left\\{\\mathcal{D}^{\\text{HMAC-SHA256}_r}(1^n) = 1\\right\\} - \\Pr\\left\\{\\mathcal{D}^f(1^n) = 1\\right\\}.</span>$</p>

    <p class="text-gray-300">If  <span class="math">\\epsilon(n)</span>  were not negligible, then  <span class="math">\\mathcal{D}</span>  would be able to distinguish between HMAC-SHA256 and f, violating our assumption that HMAC-SHA256 is a PRF.</p>

    <p class="text-gray-300">&lt;sup&gt;&amp;&lt;/sup&gt;lt;sup&gt;9&lt;/sup&gt;Bellare shows that HMAC is a PRF if the underlying compression function is a PRF [12]. We assume that SHA-256 is a PRF when its initialization vector is chosen randomly and kept secret.</p>

    <p class="text-gray-300"><span class="math">&lt;sup&gt;^{10}&lt;/sup&gt;</span> The value of k depends on the commitment scheme.</p>

    <p class="text-gray-300">&lt;span id=&quot;page-35-1&quot;&gt;&lt;/span&gt;<strong>Claim C.3.</strong> If SHA-256 is a CRHF, then  <span class="math">\\Pi</span>  is a computationally binding commitment.</p>

    <p class="text-gray-300"><em>Proof.</em> Computational binding is defined with respect to the following game played by a PPT adversary A.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{A}</span>  runs  <span class="math">\\mathsf{Setup}(1^n) \\to \\mathsf{CK}</span></li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{A}</span>  picks two messages  <span class="math">m_0</span>  and  <span class="math">m_1</span>  such that  <span class="math">m_0 \\neq m_1</span>  and two decommitment keys  <span class="math">r_0</span>  and  <span class="math">r_1</span> .  <span class="math">\\mathcal{A}</span>  then computes  <span class="math">\\mathsf{Commit}(m_0, r_0) \\to c_0</span>  and  <span class="math">\\mathsf{Commit}(m_1, r_1) \\to c_1</span></li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{A}</span>  outputs CK,  <span class="math">m_0</span> ,  <span class="math">m_1</span> ,  <span class="math">r_0</span> ,  <span class="math">r_1</span> ,  <span class="math">r_0</span> , and  <span class="math">r_1</span>  and wins if  <span class="math">r_0 = r_1</span> .</li>
    </ol></li>
    </ul>

    <p class="text-gray-300">Let the probability (over  <span class="math">\\mathcal{A}</span> 's random choices) that  <span class="math">\\mathcal{A}</span>  wins this game against our scheme  <span class="math">\\Pi</span>  be  <span class="math">\\Pr\\left\\{\\mathsf{BreakBinding}_{\\mathcal{A},\\Pi}(n)=1\\right\\}</span> . If this probability is negligible, then we can say that  <span class="math">\\Pi</span>  is computationally binding.</p>

    <p class="text-gray-300">To see why it must be negligible, we construct a PPT algorithm  <span class="math">\\mathcal{B}</span>  that uses  <span class="math">\\mathcal{A}</span>  in an attempt to find a collision in SHA-256.  <span class="math">\\mathcal{B}</span>  is defined as follows.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><span class="math">\\mathcal{B}</span>  is given  <span class="math">1^n</span>  and runs  <span class="math">\\mathcal{A}(1^n)</span> .</li>
    </ol></li>
      <li><ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>When  <span class="math">\\mathcal{A}</span>  outputs CK,  <span class="math">m_0</span> ,  <span class="math">m_1</span> ,  <span class="math">r_0</span> ,  <span class="math">r_1</span> ,  <span class="math">c_0</span> , and  <span class="math">c_1</span> ,  <span class="math">\\mathcal{B}</span>  constructs four messages:</li>
    </ol></li>
    </ul>

    <p class="text-gray-300"><span class="math">$a_0 = (r_0 \\oplus \\text{ipad}) || CK || m_0</span>$</p>

    <p class="text-gray-300"><span class="math">b_0 = (r_0 \\oplus \\text{opad}) || SHA-256(a_0)</span>
<span class="math">a_1 = (r_1 \\oplus \\text{ipad}) || CK || m_1</span>
<span class="math">b_1 = (r_1 \\oplus \\text{opad}) || SHA-256(a_1),</span></p>

    <p class="text-gray-300">where opad is a string of 64 0x5c bytes and ipad is a string of 64 0x36 bytes. If  <span class="math">b_0 \\neq b_1</span> ,  <span class="math">\\mathcal{B}</span>  outputs  <span class="math">m = b_0</span>  and  <span class="math">m&#x27; = b_1</span> . Otherwise,  <span class="math">\\mathcal{B}</span>  outputs  <span class="math">m = a_0</span>  and  <span class="math">m&#x27; = a_1</span> .  <span class="math">\\mathcal{B}</span>  wins if SHA-256(m') = SHA-256(m') and  <span class="math">m \\neq m&#x27;</span> .</p>

    <p class="text-gray-300"><span class="math">\\mathcal{A}</span> 's view when run as a subroutine of  <span class="math">\\mathcal{B}</span>  is identical to  <span class="math">\\mathcal{A}</span> 's view when playing the computational binding game. Moreover, because HMAC-SHA256 <span class="math">_r(x) = \\text{SHA-256}((r \\oplus \\text{opad}) || \\text{SHA-256}((r \\oplus \\text{ipad}) || x))</span> ,  <span class="math">\\mathcal{B}</span>  wins exactly when  <span class="math">\\mathcal{A}</span>  would have won the computational binding game (i.e., when  <span class="math">\\text{Commit}(m_0, r_0) = \\text{Commit}(m_1, r_1)</span>  where  <span class="math">m_0 \\neq m_1</span> ). Thus,</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left\\{\\mathsf{Collision}_{\\mathcal{B}}^{\\mathsf{SHA-256}}(1^n) = 1\\right\\} = \\Pr\\left\\{\\mathsf{BreakBinding}_{\\mathcal{A},\\Pi}(n) = 1\\right\\}</span>$</p>

    <p class="text-gray-300">where  <span class="math">\\Pr\\left\\{ \\text{Collision}_{\\mathcal{B}}^{\\text{SHA-256}}(1^n) = 1 \\right\\}</span>  is taken over  <span class="math">\\mathcal{B}</span> 's (really  <span class="math">\\mathcal{A}</span> 's) random choices. As a result, if the probability that  <span class="math">\\mathcal{A}</span>  wins the computational binding game were non-negligible, then the probability that  <span class="math">\\mathcal{B}</span>  finds a collision in SHA-256 would be as well, violating the assumption that SHA-256 is a CRHF.</p>

    <h4 id="sec-31" class="text-lg font-semibold mt-6">&lt;span id=&quot;page-35-0&quot;&gt;&lt;/span&gt;D Applications and parameters</h4>

    <p class="text-gray-300">This appendix describes the configuration of our experimental evaluation (§8) in more detail.</p>

    <h4 id="sec-32" class="text-lg font-semibold mt-6"><strong>D.1</strong> Details of sample applications</h4>

    <p class="text-gray-300"><em>Dot product.</em> Computes the dot product between two integer arrays, each of length <em>m</em>. Each mapper gets a chunk of the input vectors and computes a partial dot product, outputting an integer. Each reducer gets as input a list of numbers, and sums it. Another reducer phase sums the sums.</p>

    <p class="text-gray-300"><em>Nucleotide substring search.</em> Searches <em>m</em> nucleotides for length-<em>d</em> substring. Each mapper gets as input a chunk of DNA and the same length-<em>d</em> substring; if a mapper finds a match, it outputs the position of the match. Each reducer takes as input a list of locations and concatenates them.</p>

    <p class="text-gray-300"><em>Nearest neighbor search.</em> The search takes as input a length-<em>d</em> target vector and a list of <em>m</em> vectors, each of length <em>d</em>. Each mapper gets as input a subset of the search list of <em>m</em> vectors and the target vector. A mapper computes the Euclidean distance between the target vector and each vector in the subset, outputting a list of distances. Each reducer takes as input a list of Euclidean distances and computes the minimum. Another reducer phases computes the minimum among these minimums.&lt;sup&gt;11&lt;/sup&gt;</p>

    <p class="text-gray-300"><em>Covariance matrix.</em> Computes the covariance matrix for <em>m</em> samples, each of dimension <em>d</em>. Each mapper gets as input a subset of the samples and computes a <em>d</em> ×<em>d</em> covariance matrix, for its samples. Each reducer aggregates a set of these matrices, producing another <em>d</em> × <em>d</em> matrix. Then, a final reduce phase produces the final covariance matrix.</p>

    <p class="text-gray-300">SELECT<em>,</em> INSERT<em>, and</em> UPDATE<em>.</em> These queries do as their names imply. Our database has three indices, and parameters are given in Figures <a href="#page-17-0">10</a> and <a href="#page-19-1">12.</a></p>

    <p class="text-gray-300"><em>Face matching.</em> The prover stores a list of 928-bit fingerprints of faces and a threshold for each fingerprint. The verifier supplies a fingerprint of 928 bits, and the prover indicates that there is a match if and only if the Hamming distance between the input fingerprint and one of the faces in the list is below the threshold for that fingerprint. This algorithm is based on the approach of Osadchy et al. <a href="#page-40-20">[63]</a>.</p>

    <p class="text-gray-300"><em>Tolling.</em> The verifier is a toll collector, and the prover is a driver. The prover uses toll roads during a month and maintains a private database of its own toll road usage. Whenever the prover passes a tolling location, it adds a tuple to its database of the form (time, tolling location id, toll amount). The verifier can randomly and unpredictably &quot;spot check&quot; the prover whenever it uses a tolling location by storing a tuple of the same form in a separate database; the prover cannot tell whether it has been spot checked. At the end of the month, the prover sends a commitment to its database to the verifier. The computation to be verified takes as input the prover's commitment to its database and the spot checks that the verifier collected. The computation outputs REJECT if one of the spot checks does not have a &quot;close matching tuple&quot; in the database (two tuples are a close match when the tolling location id and toll amount match and when the difference in the times is less than a system parameter). Otherwise, the computation returns the total cost of tolls incurred by the prover in that month.</p>

    <p class="text-gray-300"><em>Regression analysis.</em> The verifier is a data analyst who, for example, would like to learn a model for the effectiveness of a drug, based on a patient's background and symptoms; the prover is a clinic. The prover holds a list of patient records and sends a commitment to this data to the verifier. The computation takes as input the prover's commitment, a set of patient features to model, and a parameter <em>k</em> &gt; 0. The computation returns a linear function obtained by applying ridge regression <a href="#page-39-25">[45]</a> with regularization parameter <em>k</em> to all patient records in the prover's database; in the regression, the independent variables are the features, and the dependent variable is patient recovery time. That is, the linear function produced by the computation predicts a patient's recovery time, as a function of the patient's features, but does not reveal the details of any particular patient record.</p>

    <h4 id="sec-33" class="text-lg font-semibold mt-6">D.2 Parameters</h4>

    <p class="text-gray-300">For the experiments that use Zaatar, we configure the field F (recall that F = F<em>p</em>) to have a prime modulus of 128 bits. Zaatar uses ElGamal encryption (as part of step (3) in Section <a href="#page-2-3">2.2)</a>, and our experiments presume 1024-bit keys <a href="#page-40-11">[71]</a>. For the experiments that use Pinocchio, we configure the field to have a prime modulus of 254 bits. For Pinocchio's pairing-based cryptography, we use a BN curve that provides 128 bits of security <a href="#page-38-18">[11]</a>.</p>

    <p class="text-gray-300">&lt;sup&gt;11&lt;/sup&gt;This computation would be better named &quot;nearest neighbor distance search&quot;, as it returns the distance rather than the closest vector; with minor changes (and few performance effects), the computation could return the distance and the nearest vector.</p>

    <p class="text-gray-300">Below, we quantify the constants in the cost model in Figure <a href="#page-5-1">3.</a> We run a set of microbenchmarks to measure the costs of the basic operations (e.g., encryption, decryption, multiplication, etc.) on our hardware platform (<a href="#page-15-0">§8)</a>, and we use a detailed cost model from prior work <a href="#page-40-11">[71]</a> to estimate the constants. The values are as follows:</p>

    <div class="overflow-x-auto my-4">
      <table class="min-w-full text-sm text-gray-300">
        <thead>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left"></th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Zaatar</th>
            <th class="px-3 py-2 border-b border-gray-600 font-semibold text-left">Pinocchio</th>
        </thead>
        <tbody>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">c1</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">9 ns</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">9 ns</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">c2</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">77 µs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">230 µs</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">c3</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">205 µs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">6 ms</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">c4</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">4.8 µs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">0.35 µs</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">c5</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">170 µs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">243 µs</td>
          </tr>
          <tr>
            <td class="px-3 py-2 border-b border-gray-700 text-left">c6</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">1.5 µs</td>
            <td class="px-3 py-2 border-b border-gray-700 text-left">9.5 µs</td>
          </tr>
        </tbody>
      </table>
    </div>

    <p class="text-gray-300">Accuracy and assumptions. For applications that we use in Pantry, our end-to-end empirical results are generally within 20% of their predictions, but for the prover, the empirics are smaller than predictions of the cost model by up to a factor of 2. The primary reason for this deviation, as mentioned earlier, is that Pantry's applications include a large number of storage constraints (<a href="#page-15-0">§8)</a>, and the values taken by the variables in those constraints are much smaller than the prime modulus, <em>p</em>, which reduces the value of <em>c</em>&lt;sup&gt;5&lt;/sup&gt; for such applications.</p>

    <p class="text-gray-300">Extensions for a more faithful model. One way to improve the accuracy of our simple cost model is to make <em>c</em>&lt;sup&gt;5&lt;/sup&gt; depend on the relative number of bitwise operations and on the average number of bits in the values taken by variables in the constraints of a computation.</p>

    <h4 id="sec-34" class="text-lg font-semibold mt-6">Acknowledgments</h4>

    <p class="text-gray-300">We first learned of the folklore approach to verifying computations with state from motivating comments by Yuval Ishai and an anonymous NDSS 2012 reviewer. Suggestions by Dan Boneh, Bryan Parno, Chris Peikert, and Shabsi Walfish substantially strengthened this work. We thank Chris and Shabsi for patient explanations. Feedback and comments from Sebastian Angel, Allen Clement, Josh Leners, David Mazieres, Bryan Parno, Riad Wahby, Brent \` Waters, Edmond L. Wong, George Candea (our shepherd), and the anonymous reviewers improved this draft. The Texas Advanced Computing Center (TACC) at UT supplied computing resources. This work was supported by AFOSR grant FA9550-10-1-0073; NSF grants 1040672, 1055057, and 1040083; a Sloan Fellowship; and an Intel Early Career Faculty Award.</p>

    <p class="text-gray-300">For Pantry's source code: <a href="http://cs.utexas.edu/pepper">http://cs.utexas.edu/pepper</a></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-14&quot;&gt;&lt;/span&gt;[1] Cassandra CQL. <a href="http://cassandra.apache.org/doc/cql/CQL.html">http://cassandra.apache.org/doc/cql/CQL.html</a>.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-11&quot;&gt;&lt;/span&gt;[2] High-speed software implementation of the optimal Ate pairing over Barreto-Naehrig curves. <a href="https://github.com/herumi/ate-pairing">https://github.com/herumi/ate-pairing</a>.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-13&quot;&gt;&lt;/span&gt;[3] leveldb – a fast and lightweight key/value database library by Google. <a href="https://code.google.com/p/leveldb/">https://code.google.com/p/leveldb/</a>.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-9&quot;&gt;&lt;/span&gt;[4] M. Ajtai. Generating hard instances of lattice problems. In <em>ACM Symposium on the Theory of Computing (STOC)</em>, pages 99–108, May 1996.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-0&quot;&gt;&lt;/span&gt;[5] D. P. Anderson, J. Cobb, E. Korpela, M. Lebofsky, and D. Werthimer. SETI@home: An experiment in public-resource computing. <em>Communications of the ACM (CACM)</em>, 45(11):56–61, Nov. 2002.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-3&quot;&gt;&lt;/span&gt;[6] S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. Proof verification and the hardness of approximation problems. <em>Journal of the ACM</em>, 45(3):501–555, May 1998.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-4&quot;&gt;&lt;/span&gt;[7] S. Arora and S. Safra. Probabilistic checking of proofs: a new characterization of NP. <em>Journal of the ACM</em>, 45(1):70–122, Jan. 1998.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-1&quot;&gt;&lt;/span&gt;[8] M. J. Atallah and K. B. Frikken. Securely outsourcing linear algebra computations. In <em>ACM Symposium on Information, Computer and Communications Security (ASIACCS)</em>, pages 48–59, Apr. 2010.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-5&quot;&gt;&lt;/span&gt;[9] L. Babai. Trading group theory for randomness. In <em>ACM Symposium on the Theory of Computing (STOC)</em>, pages 421–429, May 1985.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-16&quot;&gt;&lt;/span&gt;[10] B. Barak and O. Goldreich. Universal arguments and their applications. <em>SIAM Journal on Computing</em>, 38(5):1661–1694, 2008.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-18&quot;&gt;&lt;/span&gt;[11] P. S. L. M. Barreto and M. Naehrig. Pairing-friendly elliptic curves of prime order. In <em>Selected Areas in Cryptography (SAC)</em>, 2006.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-17&quot;&gt;&lt;/span&gt;[12] M. Bellare. New proofs for NMAC and HMAC: Security without collision-resistance. In <em>CRYPTO</em>, 2006.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-10&quot;&gt;&lt;/span&gt;[13] M. Bellare, R. Canetti, and H. Krawczyk. Keying hash functions for message authentication. In <em>IACR International Cryptology Conference (CRYPTO)</em>, pages 1–15, 1996.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-8&quot;&gt;&lt;/span&gt;[14] E. Ben-Sasson, A. Chiesa, D. Genkin, and E. Tromer. Fast reductions from RAMs to delegatable succinct constraint satisfaction problems. In <em>Innovations in Theoretical Computer Science (ITCS)</em>, pages 401–414, Jan. 2013.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-7&quot;&gt;&lt;/span&gt;[15] E. Ben-Sasson, A. Chiesa, D. Genkin, E. Tromer, and M. Virza. SNARKs for C: Verifying program executions succinctly and in zero knowledge. In <em>IACR International Cryptology Conference (CRYPTO)</em>, pages 90–108, Aug. 2013.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-2&quot;&gt;&lt;/span&gt;[16] S. Benabbas, R. Gennaro, and Y. Vahlis. Verifiable delegation of computation over large datasets. In <em>IACR International Cryptology Conference (CRYPTO)</em>, pages 111–131, Aug. 2011.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-12&quot;&gt;&lt;/span&gt;[17] J.-L. Beuchat, J. E. G. Diaz, S. Mitsunari, E. Okamoto, F. Rodriguez-Henriquez, and T. Teruya. High-speed software implementation of the optimal Ate pairing over Barreto-Naehrig curves. Cryptology ePrint Archive, Report 2010/354, June 2010. <a href="http://eprint.iacr.org/">http://eprint.iacr.org/</a>.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-6&quot;&gt;&lt;/span&gt;[18] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer. From extractable collision resistance to succinct non-interactive arguments of knowledge, and back again. In <em>Innovations in Theoretical Computer Science (ITCS)</em>, pages 326–349, Jan. 2012.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-38-15&quot;&gt;&lt;/span&gt;[19] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer. Recursive composition and bootstrapping for SNARKs and proof-carrying data. In <em>ACM Symposium on the Theory of Computing (STOC)</em>, pages 111–120, June 2013.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-15&quot;&gt;&lt;/span&gt;[20] N. Bitansky, A. Chiesa, Y. Ishai, R. Ostrovsky, and O. Paneth. Succinct non-interactive arguments via linear interactive proofs. In <em>IACR Theory of Cryptography Conference (TCC)</em>, pages 315–333, Mar. 2013.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-12&quot;&gt;&lt;/span&gt;[21] M. Blum, W. Evans, P. Gemmell, S. Kannan, and M. Naor. Checking the correctness of memories. In <em>Symposium on Foundations of Computer Science (FOCS)</em>, pages 90–99, Oct. 1991.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-2&quot;&gt;&lt;/span&gt;[22] D. Boneh and D. M. Freeman. Homomorphic signatures for polynomial functions. In <em>Annual International Conference on the Theory and Applications of Cryptographic Techniques (EUROCRYPT)</em>, pages 149–168, May 2011.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-7&quot;&gt;&lt;/span&gt;[23] G. Brassard, D. Chaum, and C. Crepeau. Minimum disclosure proofs of knowledge. ´ <em>Journal of Computer and System Sciences</em>, 37(2):156–189, Oct. 1988.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-14&quot;&gt;&lt;/span&gt;[24] B. Braun. Compiling computations to constraints for verified computation. UT Austin Honors thesis HR-12-10, Dec. 2012.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-10&quot;&gt;&lt;/span&gt;[25] B. Braun, A. J. Feldman, Z. Ren, S. Setty, A. J. Blumberg, and M. Walfish. Verifying computations with state. In <em>ACM Symposium on Operating Systems Principles (SOSP)</em>, pages 341–357, Nov. 2013.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-1&quot;&gt;&lt;/span&gt;[26] R. Canetti, B. Riva, and G. Rothblum. Practical delegation of computation using multiple servers. In <em>ACM Conference on Computer and Communications Security (CCS)</em>, pages 445–454, Oct. 2011.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-0&quot;&gt;&lt;/span&gt;[27] M. Castro and B. Liskov. Practical Byzantine fault tolerance and proactive recovery. <em>ACM Transactions on Computer Systems (TOCS)</em>, 20(4):398–461, Nov. 2002.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-11&quot;&gt;&lt;/span&gt;[28] G. Cormode, M. Mitzenmacher, and J. Thaler. Practical verified computation with streaming interactive proofs. In <em>Innovations in Theoretical Computer Science (ITCS)</em>, pages 90–112, Jan. 2012.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-21&quot;&gt;&lt;/span&gt;[29] J.-S. Coron, Y. Dodis, C. Malinaud, and P. Puniya. Merkle-damgard revisited: how to construct a hash ˚ function. In <em>IACR International Cryptology Conference (CRYPTO)</em>, pages 430–448, Aug. 2005.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-19&quot;&gt;&lt;/span&gt;[30] J. Dean and S. Ghemawat. MapReduce: simplified data processing on large clusters. In <em>Symposium on Operating Systems Design and Implementation (OSDI)</em>, pages 107–113, Dec. 2004.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-23&quot;&gt;&lt;/span&gt;[31] P. Devanbu, M. Gertz, C. Martel, and S. G. Stubblebine. Authentic third-party data publication. In <em>Data and Application Security: Development and Directions</em>, pages 101–112. Springer, 2002.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-3&quot;&gt;&lt;/span&gt;[32] D. Fiore and R. Gennaro. Publicly verifiable delegation of large polynomials and matrix computations, with applications. In <em>ACM Conference on Computer and Communications Security (CCS)</em>, pages 501–512, May 2012.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-13&quot;&gt;&lt;/span&gt;[33] K. Fu, M. F. Kaashoek, and D. Mazieres. Fast and secure distributed read-only file system. In \` <em>Symposium on Operating Systems Design and Implementation (OSDI)</em>, pages 1–24, Oct. 2000.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-22&quot;&gt;&lt;/span&gt;[34] B. Gassend, G. E. Suh, D. Clarke, M. van Dijk, and S. Devadas. Caches and hash trees for efficient memory integrity verification. In <em>IEEE International Symposium on High Performance Computer Architecture (HPCA)</em>, pages 295–306, Feb. 2003.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-8&quot;&gt;&lt;/span&gt;[35] R. Gennaro, C. Gentry, and B. Parno. Non-interactive verifiable computing: Outsourcing computation to untrusted workers. In <em>IACR International Cryptology Conference (CRYPTO)</em>, pages 465–482, Aug. 2010.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-9&quot;&gt;&lt;/span&gt;[36] R. Gennaro, C. Gentry, B. Parno, and M. Raykova. Quadratic span programs and succinct NIZKs without PCPs. In <em>Annual International Conference on the Theory and Applications of Cryptographic Techniques (EUROCRYPT)</em>, pages 626–645, May 2013.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-16&quot;&gt;&lt;/span&gt;[37] C. Gentry and D. Wichs. Separating succinct non-interactive arguments from all falsifiable assumptions. In <em>ACM Symposium on the Theory of Computing (STOC)</em>, pages 99–108, June 2011.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-24&quot;&gt;&lt;/span&gt;[38] E.-J. Goh, H. Shacham, N. Modadugu, and D. Boneh. SiRiUS: securing remote untrusted storage. In <em>Network and Distributed System Security Symposium (NDSS)</em>, pages 131–145, Feb. 2003.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-20&quot;&gt;&lt;/span&gt;[39] O. Goldreich. <em>Foundations of Cryptography: II Basic Applications</em>. Cambridge University Press, 2004.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-18&quot;&gt;&lt;/span&gt;[40] O. Goldreich, S. Goldwasser, and S. Halevi. Collision-free hashing from lattice problems. <em>Electronic Colloquium on Computational Complexity (ECCC)</em>, TR96-042:236–241, 1996.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-5&quot;&gt;&lt;/span&gt;[41] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum. Delegating computation: Interactive proofs for muggles. In <em>ACM Symposium on the Theory of Computing (STOC)</em>, pages 113–122, May 2008.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-6&quot;&gt;&lt;/span&gt;[42] S. Goldwasser, S. Micali, and C. Rackoff. The knowledge complexity of interactive proof systems. <em>SIAM Journal on Computing</em>, 18(1):186–208, 1989.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-4&quot;&gt;&lt;/span&gt;[43] P. Golle and I. Mironov. Uncheatable distributed computations. In <em>RSA Conference</em>, pages 425–440, Apr. 2001.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-17&quot;&gt;&lt;/span&gt;[44] N. Hardy. The Confused Deputy: (or why capabilities might have been invented). <em>ACM SIGOPS Operating Systems Review</em>, 22(4):36–38, Oct. 1988.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-39-25&quot;&gt;&lt;/span&gt;[45] A. E. Hoerl and R. W. Kennard. Ridge regression: Biased estimation for nonorthogonal problems.</p></li>
      <li><p class="text-gray-300"><em>Technometrics</em>, 12(1):55–67, 1970.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-14&quot;&gt;&lt;/span&gt;[46] Y. Ishai. Personal communication, June 2012.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-6&quot;&gt;&lt;/span&gt;[47] Y. Ishai, E. Kushilevitz, and R. Ostrovsky. Efficient arguments without short PCPs. In <em>IEEE Conference on Computational Complexity (CCC)</em>, pages 278–291, June 2007.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-26&quot;&gt;&lt;/span&gt;[48] M. Kallahalla, E. Riedel, R. Swaminathan, Q. Wang, and K. Fu. Plutus: scalable secure file sharing on untrusted storage. In <em>Conference on File and Storage Technologies (FAST)</em>, pages 29–42, Mar. 2003.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-24&quot;&gt;&lt;/span&gt;[49] J. Katz and Y. Lindell. <em>Introduction to Modern Cryptography</em>. Chapman &amp; Hall / CRC Press, 2007.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-7&quot;&gt;&lt;/span&gt;[50] J. Kilian. A note on efficient zero-knowledge proofs and arguments (extended abstract). In <em>ACM Symposium on the Theory of Computing (STOC)</em>, pages 723–732, May 1992.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-17&quot;&gt;&lt;/span&gt;[51] H. M. Levy. <em>Capability-Based Computer Systems</em>. Digital Press, 1984.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-12&quot;&gt;&lt;/span&gt;[52] J. Li, M. N. Krohn, D. Mazieres, and D. Shasha. Secure untrusted data repository (SUNDR). In \` <em>Symposium on Operating Systems Design and Implementation (OSDI)</em>, pages 121–136, Dec. 2004.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-5&quot;&gt;&lt;/span&gt;[53] C. Lund, L. Fortnow, H. J. Karloff, and N. Nisan. Algebraic methods for interactive proof systems. <em>Journal of the ACM</em>, 39(4):859–868, 1992.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-18&quot;&gt;&lt;/span&gt;[54] U. Maheshwari, R. Vingralek, and W. Shapiro. How to build a trusted database system on untrusted storage. In <em>Symposium on Operating Systems Design and Implementation (OSDI)</em>, pages 135–150, Oct. 2000.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-15&quot;&gt;&lt;/span&gt;[55] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella. Fairplay—a secure two-party computation system. In <em>USENIX Security</em>, pages 287–302, Aug. 2004.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-1&quot;&gt;&lt;/span&gt;[56] D. Malkhi and M. Reiter. Byzantine quorum systems. <em>Distributed Computing</em>, 11(4):203–213, Oct. 1998.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-25&quot;&gt;&lt;/span&gt;[57] C. Martel, G. Nuckolls, P. Devanbu, M. Gertz, A. Kwong, and S. G. Stubblebine. A general model for authenticated data structures. <em>Algorithmica</em>, 39(1):21–41, Jan. 2004.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-13&quot;&gt;&lt;/span&gt;[58] R. C. Merkle. A digital signature based on a conventional encryption function. In <em>IACR International Cryptology Conference (CRYPTO)</em>, pages 369–378, Aug. 1987.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-23&quot;&gt;&lt;/span&gt;[59] D. Micciancio and O. Regev. Lattice-based cryptography. In D. J. Bernstein and J. Buchmann, editors, <em>Post-quantum Cryptography</em>, pages 147–191. Springer, 2008.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-0&quot;&gt;&lt;/span&gt;[60] F. Monrose, P. Wycko, and A. D. Rubin. Distributed execution with remote audit. In <em>Network and Distributed System Security Symposium (NDSS)</em>, pages 103–113, Feb. 1999.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-27&quot;&gt;&lt;/span&gt;[61] R. Motwani and P. Raghavan. <em>Randomized Algorithms</em>. Cambridge University Press, 1995.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-22&quot;&gt;&lt;/span&gt;[62] V. Nikolaenko, U. Weinsberg, S. Ioannidis, M. Joye, D. Boneh, and N. Taft. Privacy-preserving ridge regression on hundreds of millions of records. In <em>IEEE Symposium on Security and Privacy</em>, pages 334–348, May 2013.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-20&quot;&gt;&lt;/span&gt;[63] M. Osadchy, B. Pinkas, A. Jarrous, and B. Moskovich. SCiFI – a system for secure face identification. In <em>IEEE Symposium on Security and Privacy</em>, pages 239–254, May 2010.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-4&quot;&gt;&lt;/span&gt;[64] C. Papamanthou, E. Shi, and R. Tamassia. Signatures of correct computation. In <em>IACR Theory of Cryptography Conference (TCC)</em>, pages 222–242, Mar. 2013.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-8&quot;&gt;&lt;/span&gt;[65] B. Parno, C. Gentry, J. Howell, and M. Raykova. Pinocchio: Nearly practical verifiable computation. In <em>IEEE Symposium on Security and Privacy</em>, pages 238–252, May 2013.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-2&quot;&gt;&lt;/span&gt;[66] B. Parno, J. M. McCune, and A. Perrig. <em>Bootstrapping Trust in Modern Computers</em>. Springer, 2011.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-19&quot;&gt;&lt;/span&gt;[67] T. P. Pedersen. Non-interactive and information-theoretic secure verifiable secret sharing. In <em>IACR International Cryptology Conference (CRYPTO)</em>, pages 129–140, Aug. 1991.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-21&quot;&gt;&lt;/span&gt;[68] R. A. Popa, H. Balakrishnan, and A. Blumberg. VPriv: Protecting privacy in location-based vehicular services. In <em>USENIX Security</em>, pages 335–350, Aug. 2009.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-3&quot;&gt;&lt;/span&gt;[69] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and P. Khosla. Pioneer: Verifying integrity and guaranteeing execution of code on legacy platforms. In <em>ACM Symposium on Operating Systems Principles (SOSP)</em>, pages 1–16, Oct. 2005.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-9&quot;&gt;&lt;/span&gt;[70] S. Setty, A. J. Blumberg, and M. Walfish. Toward practical and unconditional verification of remote computations. In <em>Workshop on Hot Topics in Operating Systems (HotOS)</em>, May 2011.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-11&quot;&gt;&lt;/span&gt;[71] S. Setty, B. Braun, V. Vu, A. J. Blumberg, B. Parno, and M. Walfish. Resolving the conflict between generality and plausibility in verified computation. In <em>European Conference on Computer Systems (EuroSys)</em>, pages 71–84, Apr. 2013.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-16&quot;&gt;&lt;/span&gt;[72] S. Setty, R. McPherson, A. J. Blumberg, and M. Walfish. Making argument systems for outsourced computation practical (sometimes). In <em>Network and Distributed System Security Symposium (NDSS)</em>, Feb. 2012.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-40-10&quot;&gt;&lt;/span&gt;[73] S. Setty, V. Vu, N. Panpalia, B. Braun, A. J. Blumberg, and M. Walfish. Taking proof-based verified</p></li>
      <li><p class="text-gray-300">computation a few steps closer to practicality. In <em>USENIX Security</em>, pages 253–268, Aug. 2012.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-41-8&quot;&gt;&lt;/span&gt;[74] H. Shacham and B. Waters. Compact proofs of retrievability. In <em>ASIACRYPT</em>, pages 90–107, Dec. 2008.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-41-4&quot;&gt;&lt;/span&gt;[75] A. Shamir. IP = PSPACE. <em>Journal of the ACM</em>, 39(4):869–877, Oct. 1992.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-41-1&quot;&gt;&lt;/span&gt;[76] R. Sion. Query execution assurance for outsourced databases. In <em>International Conference on Very Large Databases (VLDB)</em>, pages 601–612, Aug. 2005.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-41-5&quot;&gt;&lt;/span&gt;[77] J. Thaler. Time-optimal interactive proofs for circuit evaluation. In <em>IACR International Cryptology Conference (CRYPTO)</em>, pages 71–89, Aug. 2013.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-41-6&quot;&gt;&lt;/span&gt;[78] J. Thaler, M. Roberts, M. Mitzenmacher, and H. Pfister. Verifiable computation with massively parallel interactive proofs. In <em>USENIX HotCloud Workshop</em>, June 2012.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-41-2&quot;&gt;&lt;/span&gt;[79] B. Thompson, S. Haber, W. G. Horne, T. Sander, and D. Yao. Privacy-preserving computation and verification of aggregate queries on outsourced databases. In <em>Privacy Enhancing Technologies Symposium</em>, pages 185–201, Aug. 2009.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-41-7&quot;&gt;&lt;/span&gt;[80] V. Vu, S. Setty, A. J. Blumberg, and M. Walfish. A hybrid architecture for interactive verifiable computation. In <em>IEEE Symposium on Security and Privacy</em>, pages 223–237, May 2013.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-41-3&quot;&gt;&lt;/span&gt;[81] C. Wang, K. Ren, and J. Wang. Secure and practical outsourcing of linear programming in cloud computing. In <em>IEEE International Conference on Computer Communications (INFOCOM)</em>, pages 820–828, Apr. 2011.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-41-9&quot;&gt;&lt;/span&gt;[82] S. Zahur and D. Evans. Circuit structures for improved efficiency of security and privacy tools. In <em>IEEE Symposium on Security and Privacy</em>, pages 493–507, May 2013.</p></li>
      <li><p class="text-gray-300">&lt;span id=&quot;page-41-0&quot;&gt;&lt;/span&gt;[83] L. Zhou. Personal communication, Oct. 2012.</p></li>
    </ul>

`;
---

<BaseLayout title="Verifying computations with state (extended version)\* (2013/356)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2013 &middot; eprint 2013/356
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <PaperDisclaimer eprintUrl={EPRINT_URL} />
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

    <PaperHistory slug="verifying-computations-with-state-extended-version-2013" />
  </article>
</BaseLayout>
