---
import BaseLayout from '../../layouts/BaseLayout.astro';
import PaperDisclaimer from '../../components/PaperDisclaimer.astro';
import PaperHistory from '../../components/PaperHistory.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2013/222';
const CRAWLER = 'modal-marker';
const CONVERTED_DATE = '2026-02-18';
const TITLE_HTML = 'Tight security bounds for key-alternating ciphers';
const AUTHORS_HTML = 'Shan Chen, John Steinberger';

const CONTENT = `    <section id="abstract" class="mb-10">
      <h2 class="text-2xl font-bold">Abstract</h2>
      <p class="text-gray-300">A $t$-round \\emph{key-alternating cipher} (also called \\emph{iterated
Even-Mansour cipher}) can be viewed as an abstraction of AES.  It
defines a cipher $E$ from $t$ fixed public permutations $P_1, \\ldots,
P_t : \\bits^n \\ra \\bits^n$ and a key $k = k_0\\Vert \\cdots \\Vert k_t
\\in \\bits^{n(t+1)}$ by setting $E_{k}(x) = k_t \\oplus P_t(k_{t-1}
\\oplus P_{t-1}(\\cdots k_1 \\oplus P_1(k_0 \\oplus x) \\cdots))$.  The
indistinguishability of $E_k$ from a truly random permutation by an
adversary who also has oracle access to the (public) random
permutations $P_1, \\ldots, P_t$ was investigated in 1997 by Even and
Mansour for $t = 1$ and for higher values of $t$ in a series of recent
papers.  For $t = 1$, Even and Mansour proved indistinguishability
security up to $2^{n/2}$ queries, which is tight.  Much later Bogdanov
et al$.$ (2011) conjectured that security should be $2^{\\frac{t}{t+1}n}$
queries for general $t$, which matches an easy distinguishing attack
(so security cannot be more) .  A number of partial results have been
obtained supporting this conjecture, besides Even and Mansour&#x27;s
original result for $t = 1$: Bogdanov et al$.$ proved security of
$2^{\\frac{2}{3}n}$ for $t \\geq 2$, Steinberger (2012) proved security
of $2^{\\frac{3}{4}n}$ for $t \\geq 3$, and Lampe, Patarin and Seurin
(2012) proved security of $2^{\\frac{t}{t+2}n}$ for all even values of
$t$, thus &quot;barely&quot; falling short of the desired
$2^{\\frac{t}{t+1}n}$.

Our contribution in this work is to prove the long-sought-for security
bound of $2^{\\frac{t}{t+1}n}$, up to a constant multiplicative factor
depending on $t$. Our method is essentially an application of
Patarin&#x27;s H-coefficient technique.
The proof contains some coupling-like and inclusion-exclusion ideas,
but the main trick that pushes the computations through is
to stick with the combinatorics and to
refrain from rounding any quantities too early.
For the reader&#x27;s interest, we include a self-contained
tutorial on the H-coefficient technique.</p>
    </section>

    <section id="sec-1" class="mb-10">
      <h2 class="text-2xl font-bold">1 Introduction</h2>

    <p class="text-gray-300">Given t permutations  <span class="math">P_1, \\ldots, P_t : \\{0,1\\}^n \\to \\{0,1\\}^n</span>  the t-round key-alternating cipher based on  <span class="math">P_1, \\ldots, P_t</span>  is a blockcipher  <span class="math">E : \\{0,1\\}^{(t+1)n} \\times \\{0,1\\}^n \\to \\{0,1\\}^n</span>  of keyspace  <span class="math">\\{0,1\\}^{(t+1)n}</span>  and message space  <span class="math">\\{0,1\\}^n</span> , where for a key  <span class="math">k = k_0 ||k_1|| \\cdots ||k_t \\in \\{0,1\\}^{(t+1)n}</span>  and a message  <span class="math">x \\in \\{0,1\\}^n</span>  we set</p>

    <p class="text-gray-300"><span class="math">$E(k,x) = k_t \\oplus P_t(k_{t-1} \\oplus P_{t-1}(\\cdots P_1(k_0 \\oplus x)\\cdots)). \\tag{1}</span>$</p>

    <p class="text-gray-300">(See Figure 1.) Plainly,  <span class="math">E(k,\\cdot)</span>  is a permutation of  <span class="math">\\{0,1\\}^n</span>  for each fixed  <span class="math">k \\in \\{0,1\\}^{(t+1)n}</span> ; we let  <span class="math">E^{-1}(k,\\cdot)</span>  denote the inverse permutation. The  <span class="math">P_i</span> 's are called the <em>round permutations</em> of E and t is the <em>number of rounds</em> of E. Thus t and the permutations  <span class="math">P_1, \\ldots, P_t</span>  are parameters determining E.</p>

    <p class="text-gray-300">    <img src="_page_0_Picture_9.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Fig. 1. A t-round key alternating cipher.</p>

    <p class="text-gray-300">Key-alternating ciphers were first proposed (for values of t greater than 1) by the designers of AES [5,6], the Advanced Encryption Standard. Indeed, AES-128 itself can be viewed as a particular</p>

    <p class="text-gray-300"><sup>*</sup> Supported by National Basic Research Program of China Grant 2011CBA00300, 2011CBA00301, the National Natural Science Foundation of China Grant 61033001, 61361136003, and by the China Ministry of Education grant number 20121088050.</p>

    <p class="text-gray-300"><sup>** &copy;</sup>IACR 2014. This article is the full version of [3].</p>

    <p class="text-gray-300">instantiation of the key-alternating cipher paradigm in which the round permutations  <span class="math">P_1, \\ldots, P_t</span>  equal a single permutation P (the Rijndael round function, in this case), in which t = 10, and in which only a subset of the  <span class="math">\\{0,1\\}^{(t+1)n} = \\{0,1\\}^{11n}</span>  possible keys are used (more precisely, the 11n bits of key are derived pseudorandomly from a seed of n bits, making the key space  <span class="math">\\{0,1\\}^n = \\{0,1\\}^{128}</span> ). However, for t = 1 the design was proposed much earlier by Even and Mansour as a means of constructing a blockcipher from a fixed permutation [7]. Indeed, key-alternating ciphers also go by the name of iterated Even-Mansour ciphers.</p>

    <p class="text-gray-300">Even and Mansour accompanied their proposal with &quot;provable security&quot; guarantees by showing that, for t = 1, an adversary needs roughly  <span class="math">2^{n/2}</span>  queries to distinguish  <span class="math">E(k,\\cdot)</span>  for a random key k (k being hidden from the adversary) from a true random permutation, in a model where the adversary is given oracle access to  <span class="math">E(k,\\cdot)</span> ,  <span class="math">E^{-1}(k,\\cdot)</span>  as well as to  <span class="math">P_1</span> ,  <span class="math">P_1^{-1}</span> , where  <span class="math">P_1</span>  is modeled as a random permutation (in the dummy world, the adversary is given oracle access to two independent random permutations and their inverses). Their bound was matched by Daemen [4], who showed a  <span class="math">2^{n/2}</span> -query distinguishing attack for t = 1.</p>

    <p class="text-gray-300">For t &gt; 1, we can generalize the Even-Mansour indistinguishability experiment by giving the adversary oracle access to  <span class="math">P_1, \\ldots, P_t</span>  and their inverses and to  <span class="math">E(k, \\cdot)</span> ,  <span class="math">E^{-1}(k, \\cdot)</span>  in the real world (for a randomly chosen, hidden  <span class="math">k \\in \\{0,1\\}^{(t+1)n}</span> ), and to a tuple of t+1 independent random permutations and their inverses in the &quot;ideal&quot; or &quot;dummy&quot; world (see Figure 2). In this case, Daemen's attack can be easily generalized to an attack of query complexity  <span class="math">2^{\\frac{t}{t+1}n}</span> , as pointed out by Bogdanov et al. [2], but the security analysis of Even and Mansour could not be easily generalized to match this bound (though security of  <span class="math">2^{n/2}</span>  queries still holds, and is easy to prove in a black-box fashion from the Even-Mansour result).</p>

    <p class="text-gray-300">Bogdanov et al. did show, though, security of  <span class="math">2^{\\frac{2}{3}n}</span>  for  <span class="math">t \\geq 2</span>  (modulo lower-order terms), which is tight for t=2 as it matches the  <span class="math">2^{\\frac{t}{t+1}n}</span> -query attack. Later Steinberger [19] improved this bound to  <span class="math">2^{\\frac{3}{4}n}</span>  queries for  <span class="math">t \\geq 3</span>  by modifying technical aspects of Bogdanov et al.'s analysis. Orthogonally and simultaneously, Lampe, Patarin and Seurin [13] used coupling-based techniques to show security of  <span class="math">2^{\\frac{t}{t+1}n}</span>  queries for nonadaptive adversaries and security  <span class="math">2^{\\frac{t}{t+2}n}</span>  for adaptive adversaries (and even values of t). While the bound  <span class="math">2^{\\frac{t}{t+2}n}</span>  might seem &quot;almost&quot; sharp, we note that</p>

    <p class="text-gray-300"><span class="math">$2^{\\frac{t}{t+2}n} = 2^{\\frac{(t/2)}{(t/2)+1}n}</span>$</p>

    <p class="text-gray-300">is actually the conjectured adaptive security for t/2 rounds. Indeed, Lampe et al. basically show that an adaptive adversary attacking the t-round construction has no more advantage than a nonadapative adversary attacking t/2 rounds (this reduction follows upon work of Maurer et al. [16, 17]). Seen this way, Lampe et al.'s result appears less sharp. The issue is not only qualitative since their bound only improves on Steinberger's for  <span class="math">t \\ge 8</span> .</p>

    <p class="text-gray-300">Our Results. In this paper we finally prove security of  <span class="math">2^{\\frac{t}{t+1}n}</span>  queries for key-alternating ciphers, which has been the conjectured security since the paper of Bogdanov et al., and which is provably tight by the attack in the same paper. More precisely, we show that an adaptive adversary making at most q queries to each of its oracles has distinguishing advantage bounded by  <span class="math">O(1)q^{t+1}/N^t + O(1)</span> , where  <span class="math">N = 2^n</span>  and the two O(1) terms depend on t. (See Section 2 for a formal statement.)</p>

    <p class="text-gray-300">Our techniques are (maybe disappointingly) not as conceptually novel as those of [19] or [13], as we simply apply Patarin's H-coefficient technique. The crucial step is lower bounding the probability of a certain event, namely of the event that q input-output values become linked when t partially defined composed permutations (whose composition so far poses no contradiction to the linking of said q input-output pairs) are randomly extended. The surprising aspect of these computations is that various &quot;second-order&quot; factors (that one might otherwise expect to not matter) actually need to be taken into account. Informally, this can be ascribed to the fact that the values of q under consideration are far beyond birthday.</p>

    <p class="text-gray-300">Besides shedding some light on the structural and probabilistic aspects of key-alternating ciphers in the ideal permutation model, we also hope this paper will serve as a useful additional tutorial on (or introduction to) Patarin's H-coefficient technique, which still seems to suffer from a lack of exposure.</p>

    <p class="text-gray-300">We note that [13] also uses H-coefficient-based techniques and, indeed, our approach is much more closely inspired by that of [13] than by [2,19].</p>

    <p class="text-gray-300">PAPER ORGANIZATION. Definitions relating to key-alternating ciphers as well as a formal statement of our main result are given in Section 2. An overview of the H-coefficient technique is given in Section 3. The proof of the main theorem is given in Section 4.</p>

    <p class="text-gray-300">EXTENSIONS. As we note in the proof, our main result holds even if the subkeys  <span class="math">k_0, \\ldots, k_t</span>  are only t-wise independent instead of (t+1)-wise independent. This is particularly interesting for t=1. Along different lines, and as pointed out to us by Jooyoung Lee, our result also implies tight security bounds for the &quot;XOR-cascade&quot; cipher introduced by Ga&#382;i and Tessaro [9,10] via a reduction by Peter Ga&#382;i [10,11].</p>

    <p class="text-gray-300">ACKNOWLEDGMENTS. The authors would like to thank Jooyoung Lee, Rodolphe Lampe and Yannick Seurin for helpful conversations.</p>

    </section>

    <section id="sec-2" class="mb-10">
      <h2 class="text-2xl font-bold">2 Definitions and Main Result</h2>

    <p class="text-gray-300">    <img src="_page_2_Picture_6.jpeg" alt="" class="my-4 max-w-full" />
</p>

    <p class="text-gray-300">Fig. 2. The two worlds for the Even-Mansour security experiment. In World 1 the distinguisher D has oracle access to random permutations  <span class="math">P_1, \\ldots, P_t</span>  and the key-alternating cipher  <span class="math">E_k</span>  (cf. Eq. (1)) for a random key k. In World 2, D has oracle access to t+1 independent random permutations. In either world D also has oracle access to the inverse of each permutation.</p>

    <p class="text-gray-300">A t-round key-alternating cipher E has keyspace  <span class="math">\\{0,1\\}^{(t+1)n}</span>  and message space  <span class="math">\\{0,1\\}^n</span> . We refer back to equation (1) for the definition of E(k,x) (which implicitly depends on the choice of round permutations  <span class="math">P_1, \\ldots, P_t</span> ). We note that  <span class="math">E^{-1}(k,y)</span>  has an analoguous formula in which  <span class="math">P_t^{-1}, \\ldots, P_1^{-1}</span>  are called. We write  <span class="math">E_k</span>  for the permutation  <span class="math">E(k,\\cdot)</span> .</p>

    <p class="text-gray-300">We work in the ideal permutation model. For our purposes, the PRP security of a t-round keyalternating cipher E against a distinguisher (or &quot;adversary&quot;) D is defined as</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}_{E,t}^{\\text{PRP}}(D) = \\Pr[k = k_0 \\cdots k_t \\longleftarrow \\{0,1\\}^{(t+1)n}; D^{E_k, P_1, \\dots, P_t} = 1] - \\Pr[D^{Q, P_1, \\dots, P_t} = 1]</span>$
(2)</p>

    <p class="text-gray-300">where in each experiment  <span class="math">Q, P_1, \\ldots, P_t</span>  are independent uniform random permutations, where  <span class="math">D^A</span>  denotes that D has oracle access to A and  <span class="math">A^{-1}</span>  (since all oracles are permutations), and where  <span class="math">k = k_0 \\cdots k_t</span>  is selected uniformly at random (and hidden from D). See Figure 2. We further define</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}_{E,t}^{\\mathrm{PRP}}(q_e, q) = \\max_{D} \\mathbf{Adv}_{E,t}^{\\mathrm{PRP}}(D)</span>$</p>

    <p class="text-gray-300">where the maximum is taken over all distinguishers D that make at most  <span class="math">q_e</span>  queries to their first oracle and at most q queries to each of their other oracles. (The notation  <span class="math">\\mathbf{Adv}_{E,t}^{\\mathrm{PRP}}(\\cdot)</span>  is thus overloaded.)</p>

    <p class="text-gray-300">Accounting for cipher queries and permutation queries separately has the main advantage of clarifying &quot;which q is which&quot; in the security bound. Lampe et al. [13] do an even more fine-grained query accounting, with a separate variable for each permutation; this can be done here, too, but in our case the conceptual gain doesn't seem worth the notational complication. We also note that, besides t, n is a parameter on which E (and hence AdvPRP E,t (q)) depends.</p>

    <p class="text-gray-300">(As an aside, we note the above indistinguishability experiment differs from the recently popular framework of indifferentiability by, among others, the presence of a secret key and the absence of a simulator; the similarity, on the other hand, is that the adversary can query the internal components of the structure. The end goal of the security proof is also different, since we simply prove PRP-security (with tight bounds) whereas indifferentiability aims to prove something much stronger, but, typically, with much inferior bounds. See [1, 14] for indifferentiability results on key-alternating ciphers.)</p>

    <p class="text-gray-300">Our main result is the following:</p>

    <p class="text-gray-300">Theorem 1. Let N = 2<sup>n</sup> and let q &le; N/3, t &ge; 1. Then for any constant C &gt; 0,</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}_{E,t}^{\\mathrm{PRP}}(q_e, q) \\leq \\frac{q_e q^t}{N^t} \\cdot Ct^2 (6C)^t + (t+1)^2 \\frac{1}{C}.</span>$</p>

    <p class="text-gray-300">The presence of the adjustable constant C in Theorem 1 is typical of security proofs that involve a threshold-based &quot;bad event&quot;. The constant corresponds to the bad event's (adjustable) threshold. Some terms in the security bound grow with C, others decrease with C, and for every qe, q, t and N there is an optimal C. Choosing</p>

    <p class="text-gray-300"><span class="math">$C = \\left(\\frac{(t+1)N^t}{6^tt^2q_eq^t}\\right)^{1/(t+2)}</span>$</p>

    <p class="text-gray-300">(which happens to be the analytical optimum) and using a little algebra yields the following, more readable corollary for the case q = qe:</p>

    <p class="text-gray-300">Corollary 1. Let N = 2<sup>n</sup> , q &le; N/3, t &ge; 1. Then</p>

    <p class="text-gray-300"><span class="math">$\\mathbf{Adv}_{E,t}^{PRP}(q,q) \\le (t+1)^2 (t+2) \\left(\\frac{6tq}{N^{t/(t+1)}}\\right)^{(t+1)/(t+2)}.</span>$
(3)</p>

    <p class="text-gray-300">Security therefore holds up to about q &asymp; N <sup>t</sup>+1 /6t 4 , with &quot;security exponent&quot; (t + 1)/(t + 2). Since t is typically viewed as a constant the polynomial factor 6t 4 is not bothersome from the asymptotic point of view even though, obviously, such a factor considerably waters down the security bound for concrete parameters like t = 10, n = 128. We also note that if we fix q and N and let t &rarr; &infin; then (3) becomes worse and worse (i.e., closer to 1 and eventually greater than 1) for sufficiently large t. This apparent security degradation is obviously an artefact of our bound, since a straightforward reduction shows that security can only increase with t.</p>

    <p class="text-gray-300">Generalization. In the case when D's queries are accounted for by t + 1 separate variables qe, q1, . . . , q<sup>t</sup> , the product qeq t in Theorem 1 should simply be replaced by qeq<sup>1</sup> &middot; &middot; &middot; q<sup>t</sup> . The proof of this more general fact is easy to reconstruct from the proof of Theorem 1 given here.</p>

    <p class="text-gray-300">In this section we give a quick high-level outline of Patarin's H-coefficient technique. Indeed, we imagine that many readers might feel more curiosity about the high-level approach than about the technical details of our proof. This tutorial takes a broader view than Patarin's own [18], but [18] mentions refinements for nonadaptive adversaries and &quot;plaintext only&quot; attacks that we don't touch upon here. We emphasize that the material in this section is &quot;informal by design&quot;.</p>

    <p class="text-gray-300">The general setting is that of a q-query information-theoretic distinguisher D interacting with one of two oracles, the &quot;real world&quot; oracle or the &quot;ideal world&quot; oracle. (Each oracle might consist of several interfaces for D to query.) By such interaction, D creates a transcript, which is a list of queries made and answers returned. We can assume without loss of generality that D is deterministic, and makes its final decision as a (deterministic) function of the transcript obtained.</p>

    <p class="text-gray-300">We note the probability of obtaining a certain transcript might be different in either world (even if nonzero in both worlds). Denoting X the probability distribution on transcripts induced by the real world and denoting Y the probability distribution on transcripts induced by the ideal world (for some fixed deterministic distinguisher D) then D's distinguishing advantage (cf. (2)) is easily seen to be upper bounded by</p>

    <p class="text-gray-300"><span class="math">$\\Delta(X,Y) := \\frac{1}{2} \\sum_{\\tau \\in \\mathcal{T}} |\\Pr[X = \\tau] - \\Pr[Y = \\tau]|</span>$</p>

    <p class="text-gray-300">(the so-called statistical distance or total variation distance between X and Y ) where T denotes the set of possible transcripts.</p>

    <p class="text-gray-300">The technique's central idea is to use the fact that</p>

    <p class="text-gray-300"><span class="math">$\\Delta(X,Y) = 1 - E_{\\tau \\sim Y} \\left[ \\min(1, \\Pr[X=\\tau]/\\Pr[Y=\\tau]) \\right]</span>$
(4)</p>

    <p class="text-gray-300">in order to upper bound &#8710;(X, Y ). Here E&tau;&sim;<sup>Y</sup> [Z(&tau; )] is the expectation of the random variable Z(&tau; ) when &tau; is sampled according to Y , and one assumes min(1,Pr[X = &tau; ]/Pr[Y = &tau; ]) = 1 if Pr[Y = &tau; ] = 0. For completeness we record the easy proof of (4):</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\Delta(X,Y) &amp;= \\sum_{\\tau \\in \\mathcal{T}: \\Pr[Y=\\tau] &gt; \\Pr[X=\\tau]} (\\Pr[Y=\\tau] - \\Pr[X=\\tau]) \\\\ &amp;= \\sum_{\\tau \\in \\mathcal{T}: \\Pr[Y=\\tau] &gt; \\Pr[X=\\tau]} \\Pr[Y=\\tau] (1 - \\Pr[X=\\tau] / \\Pr[Y=\\tau]) \\\\ &amp;= \\sum_{\\tau \\in \\mathcal{T}} \\Pr[Y=\\tau] (1 - \\min(1, \\Pr[X=\\tau] / \\Pr[Y=\\tau])) \\\\ &amp;= 1 - E_{\\tau \\sim Y} \\big[ \\min(1, \\Pr[X=\\tau] / \\Pr[Y=\\tau]) \\big]. \\end{split}</span>$</p>

    <p class="text-gray-300">Thus, by (4), upper bounding the distinguisher's advantage reduces to lower bounding the expectation</p>

    <p class="text-gray-300"><span class="math">$E_{\\tau \\sim Y} \\left[ \\min(1, \\Pr[X = \\tau] / \\Pr[Y = \\tau]) \\right]. \\tag{5}</span>$</p>

    <p class="text-gray-300">Typically, some transcripts are better than others, in the sense that for some transcripts &tau; the ratio</p>

    <p class="text-gray-300"><span class="math">$\\Pr[X = \\tau] / \\Pr[Y = \\tau]</span>$</p>

    <p class="text-gray-300">might be quite small (when we would rather the ratio be near 1), but these &quot;bad&quot; transcripts occur with small probability. A typical proof classifies the set T of possible transcripts into a finite number of combinatorially distinct classes T1, . . . , T<sup>k</sup> and exhibits values &epsilon;1, . . . , &epsilon;<sup>k</sup> &ge; 0 such that</p>

    <p class="text-gray-300"><span class="math">$\\tau \\in \\mathcal{T}_i \\implies \\Pr[X = \\tau] / \\Pr[Y = \\tau] \\ge 1 - \\varepsilon_i.</span>$
(6)</p>

    <p class="text-gray-300">Then</p>

    <p class="text-gray-300"><span class="math">$E_{\\tau \\sim Y} \\left[ \\min(1, \\Pr[X = \\tau] / \\Pr[Y = \\tau]) \\right] \\ge \\sum_{i=1}^{k} \\Pr[Y \\in \\mathcal{T}_i] (1 - \\varepsilon_i)</span>$</p>

    <p class="text-gray-300">and, by (4),</p>

    <p class="text-gray-300"><span class="math">$\\Delta(X,Y) \\le \\sum_{i=1}^k \\Pr[Y \\in \\mathcal{T}_i] \\varepsilon_i.</span>$</p>

    <p class="text-gray-300">The &quot;ideal world&quot; random variable Y often has a very simple distribution, making the probabilities  <span class="math">\\Pr[Y \\in \\mathcal{T}_i]</span>  easy to compute. On the other hand, proving the lower bounds (6) for  <span class="math">i = 1 \\dots k</span>  can be difficult, and we rediscuss this issue below.</p>

    <p class="text-gray-300">Many proofs (including ours) have k=2, with  <span class="math">\\mathcal{T}_1</span>  consisting of the set of &quot;good&quot; transcripts and  <span class="math">\\mathcal{T}_2</span>  consisting of the set of &quot;bad&quot; transcripts (i.e., those with small value of  <span class="math">\\Pr[X=\\tau]/\\Pr[Y=\\tau]</span> ); then  <span class="math">\\varepsilon_1</span>  is small and  <span class="math">\\varepsilon_2</span>  is large, while (hopefully)  <span class="math">\\Pr[Y\\in\\mathcal{T}_1]</span>  is large and  <span class="math">\\Pr[Y\\in\\mathcal{T}_2]</span>  is small, and</p>

    <p class="text-gray-300"><span class="math">$\\Delta(X,Y) \\le \\Pr[Y \\in \\mathcal{T}_1]\\varepsilon_1 + \\Pr[Y \\in \\mathcal{T}_2]\\varepsilon_2 \\le \\varepsilon_1 + \\Pr[Y \\in \\mathcal{T}_2].</span>$</p>

    <p class="text-gray-300">The final upper bound on  <span class="math">\\Delta(X,Y)</span> , in this case, can thus be verbalized as &quot;one minus the probability ratio of good transcripts [i.e.,  <span class="math">\\varepsilon_1</span> ], plus the probability of a transcript being bad&quot; (the latter probability being computed with respect to the distribution Y). This is the form taken by our own bound.</p>

    <p class="text-gray-300">Theoretically, by using a sufficiently large (and possibly non-constant) value of k, the H-coefficient technique can be used to give sharp indistinguishability bounds in any (information-theoretic) setting. However, lower bounding the probability ratio  <span class="math">\\Pr[X = \\tau]/\\Pr[Y = \\tau]</span> , even when some structure is understood on  <span class="math">\\tau</span> , can sometimes reveal itself to be an intractable problem (but see below for some general techniques). Moreover, other indistinguishability proof methods, such as game-playing or couplings, may be more appropriate or easier to apply than the H-coefficient technique depending on the situation.</p>

    <p class="text-gray-300">Lower bounding the ratio  <span class="math">\\Pr[X=\\tau]/\\Pr[Y=\\tau]</span> . The random variables X and Y are, formally, defined on underlying probability spaces that contain respectively all the coins needed for the real and ideal world experiments. To be more illustrative, in the case of the key-alternating cipher distinguishability experiment X's underlying probability space consists of all possible (t+1)-tuples of the form  <span class="math">(k, P_1, \\ldots, P_t)</span>  where  <span class="math">k \\in \\{0, 1\\}^{(t+1)n}</span>  and where each  <span class="math">P_i</span>  is a permutation of  <span class="math">\\{0, 1\\}^n</span> , while Y's underlying probability space is all (t+1)-tuples of the form  <span class="math">(Q, P_1, \\ldots, P_t)</span>  where Q as well as each  <span class="math">P_i</span>  is a permutation of  <span class="math">\\{0, 1\\}^n</span> . (In either case the measure is uniform, and for simplicity we also assume uniform&mdash;and hence finite&mdash;probability spaces in our discussion here.) For the following, we write  <span class="math">\\Omega_X</span> ,  <span class="math">\\Omega_Y</span>  for the probability spaces on which respectively X and Y are defined. We note that each  <span class="math">\\omega</span>  in  <span class="math">\\Omega_X</span>  or  <span class="math">\\Omega_Y</span>  can be viewed as an oracle for D to interact with, thus we may use phrases such as &quot;D runs with oracle  <span class="math">\\omega</span> &quot;, etc. To summarize, X and Y are, formally, functions  <span class="math">X: \\Omega_X \\to \\mathcal{T}</span> ,  <span class="math">Y: \\Omega_Y \\to \\mathcal{T}</span> , where  <span class="math">X(\\omega)</span>  is the transcript obtained by running D with oracle  <span class="math">\\omega \\in \\Omega_X</span> , and where  <span class="math">Y(\\omega)</span>  is the transcript obtained by running D oracle  <span class="math">\\omega \\in \\Omega_Y</span> .</p>

    <p class="text-gray-300">There is usually an obvious notion of &quot;compatibility&quot; between a transcript  <span class="math">\\tau</span>  and an element  <span class="math">\\omega \\in \\Omega_X</span>  or  <span class="math">\\omega \\in \\Omega_Y</span> . For example, in the case of key-alternating ciphers, if  <span class="math">\\tau</span>  contains a query to  <span class="math">P_1</span>  and nothing else, the  <span class="math">\\omega</span> 's in  <span class="math">\\Omega_X</span>  that are compatible with  <span class="math">\\tau</span>  will be exactly those where the  <span class="math">P_1</span> -coordinate of  <span class="math">\\omega</span>  agrees with the query in  <span class="math">\\tau</span> ; there are  <span class="math">2^{(t+1)n} \\cdot (2^n - 1)! \\cdot (2^n !)^{t-1}</span>  such &quot;compatible&quot;  <span class="math">\\omega</span> 's in  <span class="math">\\Omega_X</span> . For the same transcript, there would be  <span class="math">(2^n - 1)! \\cdot (2^n !)^t</span>  compatible  <span class="math">\\omega</span> 's in  <span class="math">\\Omega_Y</span> . We write  <span class="math">\\mathsf{comp}_X(\\tau)</span>  for the set of  <span class="math">\\omega</span> 's in  <span class="math">\\Omega_X</span>  compatible with a transcript  <span class="math">\\tau</span> , and we define  <span class="math">\\mathsf{comp}_Y(\\tau)</span>  likewise with respect to  <span class="math">\\Omega_Y</span> .</p>

    <p class="text-gray-300">We note that the statement &quot; <span class="math">\\omega</span>  is compatible with  <span class="math">\\tau</span> &quot; is actually not equivalent to the statement &quot;running D with oracle  <span class="math">\\omega</span>  produces  <span class="math">\\tau</span> &quot;. Indeed, some  <span class="math">\\tau</span> 's may never be produced by D at all; e.g., if a transcript  <span class="math">\\tau</span>  contains more than q queries, or if it contains queries to  <span class="math">P_1</span>  when D is a distinguisher that never queries  <span class="math">P_1</span> , etc, then  <span class="math">\\tau</span>  is never produced by D (i.e.,  <span class="math">\\Pr[X = \\tau] = \\Pr[Y = \\tau] = 0</span> ), but this does not prevent  <span class="math">\\mathsf{comp}_X(\\tau)</span> ,  <span class="math">\\mathsf{comp}_Y(\\tau)</span>  from being well-defined.</p>

    <p class="text-gray-300">A central insight of the H-coefficient technique (but which is usually taken for granted and used without mention) is that when  <span class="math">\\tau</span>  is a possible transcript of D at all (i.e., if either  <span class="math">\\Pr[X=\\tau]&gt;0</span>  or  <span class="math">\\Pr[Y=\\tau]&gt;0</span> ) then</p>

    <p class="text-gray-300"><span class="math">$\\Pr[X = \\tau] = \\frac{|\\mathsf{comp}_X(\\tau)|}{|\\Omega_X|}</span>$
and  <span class="math">\\Pr[Y = \\tau] = \\frac{|\\mathsf{comp}_Y(\\tau)|}{|\\Omega_Y|}</span> . (7)</p>

    <p class="text-gray-300">These equalities, argued below, might seem obvious (or not) but one should note they carry some counterintuitive consequences. Firstly:</p>

    <p class="text-gray-300">(c1) The order in which queries appear in a transcript  <span class="math">\\tau</span>  does not affect the probability of  <span class="math">\\tau</span>  occurring; only the set of queries appearing in  <span class="math">\\tau</span>  matters.</p>

    <p class="text-gray-300">(This because the sets  <span class="math">\\mathsf{comp}_X(\\tau)</span> ,  <span class="math">\\mathsf{comp}_Y(\\tau)</span>  are unaffected by the order with which queries appear in  <span class="math">\\tau</span> .) Along the same lines, one has:</p>

    <p class="text-gray-300">(c2) If two different (deterministic) distinguishers can obtain a transcript  <span class="math">\\tau</span>  each with nonzero probability, these distinguishers will obtain  <span class="math">\\tau</span>  with equal probability. Moreover, by (c1), this holds even if the transcript carries no information about the order in which queries are made.</p>

    <p class="text-gray-300">(This because the right-hand sides in (7) are distinguisher-independent.) Thus, if  <span class="math">D_1</span>  and  <span class="math">D_2</span>  are two adaptive, deterministic distinguishers that can arrive (by a potentially completely different query order) at transcripts  <span class="math">\\tau_1</span>  and  <span class="math">\\tau_2</span>  that contain the same set of queries, then  <span class="math">D_1</span>  has the same probability of obtaining  <span class="math">\\tau_1</span>  as  <span class="math">D_2</span>  has of obtaining  <span class="math">\\tau_2</span> , with this equality holding separately both in the real and ideal worlds. While very basic, the order-independence property (c1) and distinguisher-independence property (c2) of deterministic distinguishers seem not to have been highlighted anywhere before. (A bit of thought reveals that (c1), (c2) will hold for any experiment (real, ideal, or whatever) involving a stateless<sup>1</sup> set of oracles, in the sense that asking the same question twice to an oracle results twice the same answer. Then  <span class="math">comp_{...}(\\tau)</span>  has an obvious definition which is independent of the order with which the queries appear in  <span class="math">\\tau</span> , and for which the proof sketch in the next paragraph goes through.)</p>

    <p class="text-gray-300">We now informally argue (7), focusing on the first equality (the X-world) for concreteness. Firstly, executing D with an  <span class="math">\\omega \\in \\Omega_X</span> ,  <span class="math">\\omega \\notin \\mathsf{comp}_X(\\tau)</span>  can obviously not produce  <span class="math">\\tau</span>  as a transcript, since  <span class="math">\\omega</span>  is not compatible with  <span class="math">\\tau</span> . It therefore suffices to show that running D on an oracle  <span class="math">\\omega \\in \\mathsf{comp}_X(\\tau)</span>  produces the transcript  <span class="math">\\tau</span> . For this, we know by assumption that there exists<sup>2</sup> an  <span class="math">\\omega&#x27; \\in \\Omega_X \\cup \\Omega_Y</span>  such that running D on oracle  <span class="math">\\omega&#x27;</span>  produces  <span class="math">\\tau</span> . However, one can show by induction on the number of queries made by D that the computations  <span class="math">D^{\\omega}</span>  and  <span class="math">D^{\\omega&#x27;}</span>  will not &quot;diverge&quot;, since every time D makes a query to  <span class="math">\\omega&#x27;</span>  this query appears in  <span class="math">\\tau</span>  and, hence, because  <span class="math">\\omega \\in \\mathsf{comp}_X(\\tau)</span> , will be answered the same by  <span class="math">\\omega</span>  (also recall that D is deterministic). Hence  <span class="math">D^{\\omega}</span>  will produce the same transcript as  <span class="math">D^{\\omega&#x27;}</span> , i.e.,  <span class="math">\\tau</span> .</p>

    <p class="text-gray-300">By (7), since<sup>3</sup></p>

    <p class="text-gray-300"><span class="math">$\\frac{|\\mathsf{comp}_X(\\tau)|}{|\\varOmega_X|} = \\Pr_{\\varOmega_X}[\\omega \\in \\mathsf{comp}_X(\\tau)] \\quad \\text{and} \\quad \\frac{|\\mathsf{comp}_Y(\\tau)|}{|\\varOmega_Y|} = \\Pr_{\\varOmega_Y}[\\omega \\in \\mathsf{comp}_Y(\\tau)] \\tag{8}</span>$</p>

    <p class="text-gray-300">the ratio  <span class="math">\\Pr[X = \\tau] / \\Pr[Y = \\tau]</span>  is equal to</p>

    <p class="text-gray-300"><span class="math">$\\frac{\\Pr_{\\Omega_X}[\\omega \\in \\mathsf{comp}_X(\\tau)]}{\\Pr_{\\Omega_Y}[\\omega \\in \\mathsf{comp}_Y(\\tau)]} \\tag{9}</span>$</p>

    <p class="text-gray-300">and it therefore suffices to lower bound the latter ratio of probabilities. (One could also try directly counting the size of the sets  <span class="math">\\mathsf{comp}_X(\\tau)</span> ,  <span class="math">\\mathsf{comp}_Y(\\tau)</span> , however, this is often intractable for  <span class="math">\\mathsf{comp}_X(\\tau)</span> , making a probabilistic approach preferable.) We note the ideal world probability  <span class="math">\\mathsf{Pr}_{\\varOmega_Y}[\\omega \\in \\mathsf{comp}_Y(\\tau)]</span>  is often quite trivial to compute, due to the ideal world's nice structure.</p>

    <p class="text-gray-300">Looking at (9) it is possible to wonder whether anything substantial has been gained so far, or whether notations are simply being shuffled around; after all,  <span class="math">\\Pr[X = \\tau]</span>  and  <span class="math">\\Pr_{\\Omega_X}[\\omega \\in \\mathsf{comp}_X(\\tau)]</span>  are &quot;obviously the same thing&quot; (and the same for Y). However the probability  <span class="math">\\Pr_{\\Omega_X}[\\omega \\in \\mathsf{comp}_X(\\tau)]</span>  offers</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;1</sup> More formally, the oracle is a deterministic function taking as input a query and a (large) random tape, where the random tape is sampled and fixed at the start of the experiment.</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;2</sup> Here  <span class="math">\\omega&#x27;</span>  could also lie outside  <span class="math">\\Omega_X \\cup \\Omega_Y</span> ; the argument goes through as long as there exists <em>some</em> oracle leading to the transcript  <span class="math">\\tau</span> .</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;3</sup> In fact, replacing  <span class="math">|\\mathsf{comp}_X(\\tau)|/|\\Omega_X|</span>  and  <span class="math">|\\mathsf{comp}_X(\\tau)|/|\\Omega_X|</span>  by respectively  <span class="math">\\Pr_{\\Omega_X}[\\omega \\in \\mathsf{comp}_X(\\tau)]</span>  and  <span class="math">\\Pr_{\\Omega_Y}[\\omega \\in \\mathsf{comp}_Y(\\tau)]</span>  in (7) gives a more general formulation of these identities, for cases where the probability distributions on  <span class="math">\\Omega_X</span> ,  <span class="math">\\Omega_Y</span>  are not uniform. W prefer the fractions  <span class="math">|\\mathsf{comp}_X(\\tau)|/|\\Omega_X|</span> ,  <span class="math">|\\mathsf{comp}_X(\\tau)|/|\\Omega_X|</span>  because these expressions seem more concrete.</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;4</sup> In fact, as already pointed out,  <span class="math">\\Pr[X = \\tau]</span>  and  <span class="math">\\Pr_{\\Omega_X}[\\omega \\in \\mathsf{comp}_X(\\tau)]</span>  are <em>not</em> the same thing for  <span class="math">\\tau</span> 's outside the range of D.</p>

    <p class="text-gray-300">a considerable conceptual advantage over the probability  <span class="math">\\Pr[X = \\tau]</span> , as  <span class="math">\\Pr_{\\Omega_X}[\\omega \\in \\mathsf{comp}_X(\\tau)]</span>  refers to an experiment with a non-adaptive flavor (a transcript  <span class="math">\\tau</span>  is fixed, and a uniform random element of  <span class="math">\\Omega_X</span>  is drawn&mdash;what is the probability of compatibility?) while the probability  <span class="math">\\Pr[X = \\tau]</span>  refers, by definition, to the adaptive interaction of D with its oracle, which is much messier to think about. Indeed, (c1) and (c2) already show that adaptivity is in a sense &quot;thrown out&quot; when (7) is applied.</p>

    <p class="text-gray-300">We finally note that a common way of computing</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{\\varOmega_X}[\\omega\\in\\mathsf{comp}_X(\\tau)]</span>$</p>

    <p class="text-gray-300">is to write</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} \\Pr_{\\Omega_X}[\\omega \\in \\mathsf{comp}_X(\\tau)] &amp;= \\Pr_{\\Omega_X}[\\omega \\in \\mathsf{comp}_X&#x27;(\\tau)] \\cdot \\Pr_{\\Omega_X}[\\omega \\in \\mathsf{comp}_X(\\tau) \\, | \\, \\omega \\in \\mathsf{comp}_X&#x27;(\\tau)] \\\\ &amp;= (|\\mathsf{comp}_X&#x27;(\\tau)| / |\\Omega_X|) \\cdot \\Pr_{\\mathsf{comp}_X&#x27;(\\tau)}[\\omega \\in \\mathsf{comp}_X(\\tau)] \\end{split}</span>$</p>

    <p class="text-gray-300">for some set  <span class="math">\\mathsf{comp}_X&#x27;(\\tau) \\subseteq \\Omega_X</span>  such that  <span class="math">\\mathsf{comp}_X(\\tau) \\subseteq \\mathsf{comp}_X&#x27;(\\tau)</span> . E.g., in the case of key-alternating ciphers,  <span class="math">\\mathsf{comp}_X&#x27;(\\tau)</span>  might be defined as all points of  <span class="math">\\Omega_X</span>  that at least agree with  <span class="math">\\tau</span>  on the queries to  <span class="math">P_1, \\ldots, P_t</span> , if not on the queries to  <span class="math">P_0</span> . The question then becomes, when a uniform random element  <span class="math">\\omega \\in \\mathsf{comp}_X&#x27;(\\tau)</span>  is picked, what is the probability this  <span class="math">\\omega</span>  also agrees with the queries to  <span class="math">P_0</span> ?</p>

    </section>

    <section id="sec-4" class="mb-10">
      <h2 class="text-2xl font-bold">4 Proof of Theorem 1</h2>

    <p class="text-gray-300">We make the standard simplifying assumption that the distinguisher D is deterministic. This assumption is without loss of generality since if D is randomized it is easy to see that D's coins can be fixed to value such that the resulting &quot;induced&quot; distinguisher D (running on the fixed random tape) has advantage at least that of the original randomized D.</p>

    <p class="text-gray-300">For simplicity, we also assume the distinguisher never makes redundant queries; e.g., queries  <span class="math">P_i</span>  twice on the same point, or queries  <span class="math">P_i(x)</span>  obtaining answer y and then later queries  <span class="math">P_i^{-1}(y)</span> . Moreover, we will assume that D makes exactly  <span class="math">q_e</span>  queries to its first oracle and exactly q queries to each of its other oracles. This assumption is obviously without loss of generality.</p>

    <p class="text-gray-300">We refer to the case where D has an oracle tuple of the type  <span class="math">(E_k, P_1, \\ldots, P_t)</span>  as the &quot;real world&quot; and to the case when D has an oracle tuple of the type  <span class="math">(Q, P_1, \\ldots, P_t)</span>  as the &quot;ideal world&quot;. For convenience, we will be generous with the distinguisher in the following way: at the end of the experiment (when the distinguisher has made its (t+1)q queries, but before the distinguisher outputs its decision) we reveal the key  <span class="math">k = k_0 k_1 \\cdots k_t</span>  to the distinguisher in the real world, while in the ideal world we sample a dummy key  <span class="math">k&#x27; = k&#x27;_0 k&#x27;_1 \\cdots k&#x27;_t</span>  and reveal this dummy key to the distinguisher. A distinguisher playing this &quot;enhanced&quot; game is obviously at no disadvantage, since it can disregard the key if it wants.</p>

    <p class="text-gray-300">For the remainder of the proof we consider a fixed distinguisher D conforming to the conventions above. We can summarize D's interaction with its oracles by a transcript consisting of a sequence of tuples of the form  <span class="math">(i, \\sigma, x, y)</span>  where  <span class="math">i \\in \\{0, \\ldots, t\\}</span> ,  <span class="math">\\sigma \\in \\{+, -\\}</span>  and  <span class="math">x, y \\in \\{0, 1\\}^n</span> , plus the key value k at the end of the transcript. If  <span class="math">\\sigma = +</span>  such a tuple denotes that D made the query  <span class="math">P_i(x)</span>  obtaining answer y, or if  <span class="math">\\sigma = -</span>  that D made the query  <span class="math">P_i^{-1}(y)</span>  obtaining answer x, and D's interaction with its oracles (as well as D's final output bit) can be uniquely reconstructed from such a sequence of tuples. In fact, we can (and shall) encode the transcript as an unordered set of directionless tuples of the form (i, x, y) (plus the key value k). Indeed, given that D is deterministic, D's interaction can still be reconstructed from such a transcript. (Consider that D always makes the same first query, since it is deterministic; we can look up the answer to this query in the transcript, deduce the second query made by D again since D is deterministic, and so on.) All in all, therefore, the transcript can be encoded as a tuple  <span class="math">(k, p_0, p_1, \\ldots, p_t)</span>  where  <span class="math">k \\in \\{0, 1\\}^{(t+1)n}</span>  is the key (real or dummy) and where  <span class="math">p_i</span> ,  <span class="math">i \\geq 1</span> , is a table containing q pairs (x, y), where each such pair either indicates a query  <span class="math">P_i(x) = y</span>  or a query  <span class="math">P_i^{-1}(y) = x</span>  (which it is can</p>

    <p class="text-gray-300">be deduced from the transcript), and where  <span class="math">p_0</span>  similarly contains the  <span class="math">q_e</span>  input-output pairs queried to the cipher. One can also view  <span class="math">p_i</span>  as a bipartite graph with shores  <span class="math">\\{0,1\\}^n</span>  and containing q (resp.  <span class="math">q_e</span> , in the case of  <span class="math">p_0</span> ) disjoint edges.</p>

    <p class="text-gray-300">We let  <span class="math">\\mathcal{T}</span>  denote the set of all possible transcripts, i.e., the set of all tuples of the form  <span class="math">(k, p_0, \\dots, p_t)</span>  as described above. Thus  <span class="math">|\\mathcal{T}| = 2^{(t+1)n} \\left( \\binom{2^n}{q_e} \\frac{2^{n!}}{(2^n - q_e)!} \\right) \\left( \\binom{2^n}{q} \\frac{2^{n!}}{(2^n - q)!} \\right)^t</span> . We note that some elements of  <span class="math">\\mathcal{T}</span> &mdash;in fact, most elements&mdash;may never be obtained by D. For example, if D's first query is  <span class="math">P_1(0^n)</span>  then (this first query never varies and) any transcript obtained by D contains a pair of the form  <span class="math">(0^n, y)</span>  in the table  <span class="math">p_1</span> , for some  <span class="math">y \\in \\{0, 1\\}^n</span> .</p>

    <p class="text-gray-300">Let  <span class="math">\\mathcal{P}</span>  be the set of all permutations of  <span class="math">\\{0,1\\}^n</span> ; thus  <span class="math">|\\mathcal{P}| = (2^n)!</span> . Let  <span class="math">\\mathcal{P}^t = \\mathcal{P} \\times \\cdots \\times \\mathcal{P}</span>  be the t-fold direct product of  <span class="math">\\mathcal{P}</span> . Let  <span class="math">\\Omega_X = \\{0,1\\}^{(t+1)n} \\times \\mathcal{P}^t</span>  and let  <span class="math">\\Omega_Y = \\{0,1\\}^{(t+1)n} \\times \\mathcal{P}^{t+1}</span> . In the obvious way, elements of  <span class="math">\\Omega_X</span>  can be viewed as real world oracles for D while elements of  <span class="math">\\Omega_Y</span>  can be viewed as &quot;ideal world&quot; oracles for D. (We note that  <span class="math">\\Omega_Y</span>  is slightly different from the  <span class="math">\\Omega_Y</span>  appearing in the discussion of Section 3, due to our convention of giving away the key as part of the transcript.) We write  <span class="math">X(\\omega)</span>  for the transcript obtained by running D with oracle  <span class="math">\\omega \\in \\Omega_X</span> , and  <span class="math">Y(\\omega)</span>  for the transcript obtained by running D with oracle  <span class="math">\\omega \\in \\Omega_Y</span> . Thus  <span class="math">X: \\Omega_X \\to \\mathcal{T}</span> ,  <span class="math">Y: \\Omega_Y \\to \\mathcal{T}</span>  and by endowing  <span class="math">\\Omega_X</span> ,  <span class="math">\\Omega_Y</span>  with the uniform probability distribution, X and Y become random variables of range  <span class="math">\\mathcal{T}</span> , whose distributions are exactly those obtained by running D in the real and ideal worlds respectively. Since D's output is a deterministic function of the transcript, D's distinguishing advantage can be written</p>

    <p class="text-gray-300"><span class="math">$\\Pr[D(X) = 1] - \\Pr[D(Y) = 1]</span>$</p>

    <p class="text-gray-300">(here identifying D with a function outputting a final decision from the transcript); thus D's advantage is upper bounded by</p>

    <p class="text-gray-300"><span class="math">$\\Delta(X,Y) = \\frac{1}{2} \\sum_{\\tau \\in \\mathcal{T}} |\\Pr[X = \\tau] - \\Pr[Y = \\tau]|</span>$</p>

    <p class="text-gray-300">by standard considerations.</p>

    <p class="text-gray-300">In order to upper bound  <span class="math">\\Delta(X,Y)</span>  we make use of the equality</p>

    <p class="text-gray-300"><span class="math">$\\Delta(X,Y) = 1 - E_{\\tau \\sim Y} \\left[ \\min(1, \\Pr[X = \\tau] / \\Pr[Y = \\tau]) \\right]</span>$</p>

    <p class="text-gray-300">mentioned in Section 3. More precisely, we will identify a set  <span class="math">\\mathcal{T}_1 \\subseteq \\mathcal{T}</span>  of &quot;good&quot; query transcripts, and a set  <span class="math">\\mathcal{T}_2 \\subseteq \\mathcal{T}</span>  of &quot;bad&quot; transcripts, such that  <span class="math">\\mathcal{T}</span>  is the disjoint union of  <span class="math">\\mathcal{T}_1</span>  and  <span class="math">\\mathcal{T}_2</span> . Then, as shown in Section 3,</p>

    <p class="text-gray-300"><span class="math">$\\Delta(X,Y) \\le \\varepsilon_1 + \\Pr[Y \\in \\mathcal{T}_2] \\tag{10}</span>$</p>

    <p class="text-gray-300">where  <span class="math">\\varepsilon_1</span>  is a number such that</p>

    <p class="text-gray-300"><span class="math">$\\frac{\\Pr[X = \\tau]}{\\Pr[Y = \\tau]} \\ge 1 - \\varepsilon_1</span>$</p>

    <p class="text-gray-300">for all  <span class="math">\\tau \\in \\mathcal{T}_1</span>  such that  <span class="math">\\Pr[Y = \\tau] &gt; 0</span> .</p>

    <p class="text-gray-300">We next discuss the definitions of  <span class="math">\\mathcal{T}_1</span>  and  <span class="math">\\mathcal{T}_2</span> ; next we show  <span class="math">\\Pr[Y \\in \\mathcal{T}_2] \\leq (t+1)^2 \\frac{1}{C}</span> ; and finally we will show  <span class="math">\\Pr[X = \\tau] / \\Pr[Y = \\tau] \\geq 1 - \\varepsilon_1</span>  for  <span class="math">\\tau \\in \\mathcal{T}_1</span>  and  <span class="math">\\varepsilon_1 = q_e(\\frac{q}{N})^t Ct^2(6C)^t</span> . We will assume for these computations that  <span class="math">Cq_eq^t &lt; N^t</span> . This assumption is without loss of generality since Theorem 1 is vacuously true otherwise.</p>

    <p class="text-gray-300">BAD TRANSCRIPTS. Let  <span class="math">\\tau = (k, p_0, p_1, \\dots, p_t) \\in \\mathcal{T}</span>  be a transcript. We associate to  <span class="math">\\tau</span>  a graph  <span class="math">G(\\tau)</span> , dubbed the round graph, that encodes the information contained in k as well as in  <span class="math">p_1, \\dots, p_t</span>  (but that ignores  <span class="math">p_0</span> ).  <span class="math">G(\\tau)</span>  has  <span class="math">2(t+1) \\cdot 2^n</span>  vertices, grouped into &quot;shores&quot; of size  <span class="math">2^n</span>  each, with each shore being identified with a copy  <span class="math">\\{0,1\\}^n</span> . We index the 2(t+1) shores as  <span class="math">0^-</span> ,  <span class="math">0^+</span> ,  <span class="math">1^-</span> ,  <span class="math">1^+</span> , ...,  <span class="math">t^-</span> ,  <span class="math">t^+</span> . Vertex y in shore  <span class="math">i^-</span>  is connected to vertex  <span class="math">y \\oplus k_i</span>  in shore  <span class="math">i^+</span>  by an edge, and these are the only edges between</p>

    <p class="text-gray-300">shores  <span class="math">i^-</span>  and  <span class="math">i^+</span> . Moreover, for each  <span class="math">(x,y) \\in p_i</span> ,  <span class="math">1 \\le i \\le t</span> , we connect vertex x in shore  <span class="math">(i-1)^+</span>  to vertex y in shore  <span class="math">i^-</span> . Thus  <span class="math">G(\\tau)</span>  consists of (t+1) full bipartite matchings (one per subkey) alternately glued with q-edge partial matchings (one for each  <span class="math">p_i</span> ,  <span class="math">1 \\le i \\le t</span> ). Since  <span class="math">G(\\tau)</span>  encodes all the information in  <span class="math">k, p_1, \\ldots, p_t</span> , we can also write a transcript  <span class="math">\\tau</span>  in the form  <span class="math">\\tau = (p_0, G)</span>  where  <span class="math">G = G(\\tau)</span> .</p>

    <p class="text-gray-300">Obviously, the presence of the full bipartite graphs corresponding to the subkeys  <span class="math">k_0, \\ldots, k_t</span>  within  <span class="math">G(\\tau)</span>  is not topologically interesting. Call an edge of  <span class="math">G(\\tau)</span>  a &quot;key edge&quot; if the edge joins the shores  <span class="math">i^-, i^+</span>  for some  <span class="math">i \\in \\{0, \\ldots, t\\}</span> . We then define the contracted round graph  <span class="math">\\tilde{G}(\\tau)</span>  obtained from  <span class="math">G(\\tau)</span>  by contracting all key edges; thus  <span class="math">\\tilde{G}(\\tau)</span>  has only t+1 shores; moreover, when an edge  <span class="math">(y, y \\oplus k_i)</span>  between shores  <span class="math">i^-</span> ,  <span class="math">i^+</span>  of  <span class="math">G(\\tau)</span>  is contracted, the resulting vertex of  <span class="math">\\tilde{G}(\\tau)</span>  is given label y if  <span class="math">0 \\le i \\le t-1</span> , and is given label  <span class="math">y \\oplus k_i</span>  if i = t. (The labeling of vertices of  <span class="math">\\tilde{G}(\\tau)</span>  is somewhat unimportant and arbitrary, but we adopt the above convention so that vertices in shores  <span class="math">0^-</span>  and  <span class="math">t^+</span>  of  <span class="math">G(\\tau)</span>  keep their original labels in  <span class="math">\\tilde{G}(\\tau)</span> . The latter ensures compatibility between these vertex labels and triples in  <span class="math">p_0</span> .) We note that a transcript  <span class="math">\\tau</span>  is not determined by the pair  <span class="math">(p_0, \\tilde{G}(\\tau))</span>  (the key material being unrecoverable from the latter pair) but, as we will see,  <span class="math">\\Pr[X = \\tau]</span>  is determined by  <span class="math">(p_0, \\tilde{G}(\\tau))</span> .</p>

    <p class="text-gray-300">An edge between shores (i-1) and i of  <span class="math">\\tilde{G}(\\tau)</span>  is called an i-edge. (Each i-edge arises from an entry in  <span class="math">p_i</span> .) We write  <span class="math">Z_{ij}(\\tilde{G}(\\tau))</span>  for the set of (necessarily edge-disjoint) paths that exists between shores i and j of  <span class="math">\\tilde{G}(\\tau)</span> . We write  <span class="math">Z_{ij}^-(\\tilde{G}(\\tau))</span> ,  <span class="math">Z_{ij}^+(\\tilde{G}(\\tau))</span>  for vertices of paths in  <span class="math">Z_{ij}(\\tilde{G}(\\tau))</span>  that are respectively in shores i and j of  <span class="math">\\tilde{G}(\\tau)</span> . We write  <span class="math">p_0^- = \\{x : (x,y) \\in p_0\\}</span>  and  <span class="math">p_0^+ = \\{y : (x,y) \\in p_0\\}</span>  be the projection of  <span class="math">p_0</span>  to its first and second coordinates respectively.</p>

    <p class="text-gray-300">We say a transcript  <span class="math">\\tau</span>  is bad if there exist  <span class="math">0 \\le i &lt; j \\le t</span>  such that</p>

    <p class="text-gray-300"><span class="math">$|Z_{ij}(\\tilde{G}(\\tau))| &gt; \\frac{Cq^{j-i}}{N^{j-i-1}} \\tag{11}</span>$</p>

    <p class="text-gray-300">or if there exists  <span class="math">0 \\le i \\le j \\le t</span>  such that</p>

    <p class="text-gray-300"><span class="math">$|\\{(x,y) \\in p_0 : x \\in Z_{0,i}^-(\\tilde{G}(\\tau)) \\land y \\in Z_{j,t}^+(\\tilde{G}(\\tau))\\}| &gt; \\frac{Cq_eq^{i+t-j}}{N^{i+t-j}}.</span>$
(12)</p>

    <p class="text-gray-300">To motivate this definition we note that  <span class="math">q^{j-i}/N^{j-i-1}</span>  is exactly the expected number of paths from shore i to shore j in the ideal world, whereas, likewise,  <span class="math">q_eq^{i+t-j}/N^{i+t-j}</span>  is the expected number of paths from shore j to shore i that &quot;wrap around&quot; through an edge in  <span class="math">p_0</span>  (though such edges are not encoded in  <span class="math">\\tilde{G}(\\tau)</span>  and, hence, such &quot;wrap around&quot; paths don't physically exist in  <span class="math">\\tilde{G}(\\tau)</span> ). The set of bad transcripts is denoted  <span class="math">\\mathcal{T}_2</span>  and we let  <span class="math">T_1 = \\mathcal{T} \\setminus \\mathcal{T}_2</span> . Transcripts in  <span class="math">\\mathcal{T}_1</span>  are called good.</p>

    <p class="text-gray-300">PROBABILITY OF BADNESS. We next upper bound  <span class="math">\\Pr_{\\tau \\sim Y}[\\tau \\in \\mathcal{T}_2]</span> . We view  <span class="math">|Z_{ij}| = |Z_{ij}(\\tilde{G}(\\tau))|</span>  as a random variable defined on  <span class="math">\\Omega_Y</span> . Since k is independent of  <span class="math">p_0, p_1, \\ldots, p_t</span> , any sequence</p>

    <p class="text-gray-300"><span class="math">$(x_{i+1}, y_{i+1}) \\in p_{i+1}, (x_{i+2}, y_{i+2}) \\in p_{i+2}, \\dots, (x_j, y_j) \\in p_j</span>$</p>

    <p class="text-gray-300">of j-i edges have probability  <span class="math">(1/N)^{j-i-1}</span>  of becoming connected by  <span class="math">k_{i+1}, \\ldots, k_{j-1}</span> . (I.e., there is chance  <span class="math">(1/N)^{j-i+1}</span>  that  <span class="math">k_h = y_h \\oplus x_{h+1}</span>  for  <span class="math">h = i+1, \\ldots, j-1</span> .) By linearity of expectation, thus,</p>

    <p class="text-gray-300"><span class="math">$E_{\\tau \\sim Y}[|Z_{ij}|] = \\frac{q^{j-i}}{N^{j-i-1}}</span>$</p>

    <p class="text-gray-300">since there are  <span class="math">q^{j-i}</span>  such sequences of edges in  <span class="math">p_{i+1}, \\ldots, p_j</span> . By Markov's inequality, thus,</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{\\tau \\sim Y} \\left[ |Z_{ij}| &gt; \\frac{Cq^{j-i}}{N^{j-i-1}} \\right] \\le \\frac{1}{C}</span>$
(13)</p>

    <p class="text-gray-300">for every  <span class="math">0 \\le i &lt; j \\le t</span> .</p>

    <p class="text-gray-300">Because  <span class="math">|p_0| = q_e</span> , it is similarly easy to see that</p>

    <p class="text-gray-300"><span class="math">$E_{\\tau \\sim Y} [|\\{(x,y) \\in p_0 : x \\in Z_{0,i}^- \\land y \\in Z_{j,t}^+\\}|] = \\frac{q_e q^{i+(t-j)}}{N^{i+t-j}}</span>$</p>

    <p class="text-gray-300">for every  <span class="math">0 \\le i \\le j \\le t</span> , by which Markov again implies that</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{\\tau \\sim Y} \\left[ |\\{(x,y) \\in p_0 : x \\in Z_{0,i}^- \\land y \\in Z_{j,t}^+\\}| &gt; C \\frac{q_e q^{i+(t-j)}}{N^{i+t-j}} \\right] \\le \\frac{1}{C}</span>$
(14)</p>

    <p class="text-gray-300">for every  <span class="math">0 \\le i \\le j \\le t</span> .</p>

    <p class="text-gray-300">Collecting the probabilities (13) for  <span class="math">0 \\le i &lt; j \\le t</span>  and (14) for  <span class="math">0 \\le i \\le j \\le t</span>  we obtain</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{\\tau \\sim Y} [\\tau \\in \\mathcal{T}_2] \\le {t+1 \\choose 2} \\frac{1}{C} + {t+2 \\choose 2} \\frac{1}{C} = (t+1)^2 \\frac{1}{C}.</span>$
(15)</p>

    <p class="text-gray-300">LOWER BOUNDING  <span class="math">\\Pr[X = \\tau]/\\Pr[Y = \\tau]</span>  for  <span class="math">\\tau \\in \\mathcal{T}_1</span> . An element  <span class="math">\\omega = (k, P_1, \\dots, P_t) \\in \\Omega_x</span>  is compatible with a transcript  <span class="math">\\tau = (k^*, p_0, \\dots, p_t)</span>  if  <span class="math">k = k^*</span> , if  <span class="math">P_i(x) = y</span>  for every  <span class="math">(x, y) \\in p_i</span> ,  <span class="math">1 \\le i \\le t</span> , and if  <span class="math">E_k(x) = y</span>  for every  <span class="math">(x, y) \\in p_0</span> , where  <span class="math">E_k</span>  stands for the Even-Mansour cipher instantiated with permutations  <span class="math">P_1, \\dots, P_t</span>  (and key k). We write  <span class="math">\\mathsf{comp}_X(\\tau)</span>  for the set of w's in  <span class="math">\\Omega_X</span>  that are compatible with  <span class="math">\\tau</span> .</p>

    <p class="text-gray-300">Analogously, an  <span class="math">w=(k,P_0,P_1,\\ldots,P_t)\\in\\Omega_Y</span>  is compatible with  <span class="math">\\tau</span>  if the same conditions as above are respected, but replacing the constraint  <span class="math">E_k(x)=y</span>  with  <span class="math">P_0(x)=y</span>  for  <span class="math">(x,y)\\in p_0</span> . We write  <span class="math">\\mathsf{comp}_Y(\\tau)</span>  for the set of  <span class="math">\\omega</span> 's in  <span class="math">\\Omega_Y</span>  that are compatible with  <span class="math">\\tau</span> .</p>

    <p class="text-gray-300">We also say  <span class="math">\\omega = (k, P_1, \\dots, P_t)</span>  is partially compatible with  <span class="math">\\tau = (k^*, p_0, p_1, \\dots, p_t)</span>  if  <span class="math">k = k^*</span>  and if  <span class="math">P_i(x) = y</span>  for all  <span class="math">(x, y) \\in p_i</span> ,  <span class="math">1 \\le i \\le t</span> . (Thus, the requirement that  <span class="math">p_0</span>  agrees with  <span class="math">E_k</span>  is dropped for partial compatibility.) Likewise  <span class="math">\\omega \\in \\Omega_Y</span>  is partially compatible with  <span class="math">\\tau</span>  if (exactly as above)  <span class="math">k = k^*</span>  and  <span class="math">P_i(x) = y</span>  for all  <span class="math">(x, y) \\in p_i</span> ,  <span class="math">1 \\le i \\le t</span> . (Thus, the requirement that  <span class="math">p_0</span>  agrees with  <span class="math">P_0</span>  is dropped.) We write  <span class="math">\\mathsf{comp}&#x27;_X(\\tau)</span> ,  <span class="math">\\mathsf{comp}&#x27;_Y(\\tau)</span>  for the set of  <span class="math">\\omega</span> 's in, respectively,  <span class="math">\\Omega_X</span>  or  <span class="math">\\Omega_Y</span>  that are partially compatible with  <span class="math">\\tau</span> . Note that</p>

    <p class="text-gray-300"><span class="math">$\\frac{|\\mathsf{comp}_X&#x27;(\\tau)|}{|\\Omega_X|} = \\frac{|\\mathsf{comp}_Y&#x27;(\\tau)|}{|\\Omega_Y|} = \\frac{1}{N^{t+1}} \\cdot \\prod_{i=1}^t \\frac{(N - |p_i|)!}{N!}</span>$
(16)</p>

    <p class="text-gray-300">for any transcript  <span class="math">\\tau = (k, p_0, p_1, \\dots, p_t)</span> , where  <span class="math">|p_i|</span>  denotes the number of pairs in  <span class="math">p_i</span> .</p>

    <p class="text-gray-300">We say that a transcript  <span class="math">\\tau \\in \\mathcal{T}</span>  is attainable if  <span class="math">\\Pr[Y = \\tau] &gt; 0</span> . (Note that  <span class="math">\\Pr[X = \\tau] &gt; 0 \\implies \\Pr[Y = \\tau] &gt; 0</span> .) In other words, a transcript is attainable if there exists an  <span class="math">\\omega \\in \\Omega_Y</span>  such that  <span class="math">D^{\\omega}</span>  produces the transcript  <span class="math">\\tau</span> .</p>

    <p class="text-gray-300">It is necessary and sufficient to lower bound  <span class="math">\\Pr[X = \\tau]/\\Pr[Y = \\tau]</span>  for attainable transcripts  <span class="math">\\tau \\in \\mathcal{T}_1</span> . It is easy to check that for an attainable transcript  <span class="math">\\tau</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr[Y = \\tau] = \\frac{|\\mathsf{comp}_Y(\\tau)|}{|\\Omega_Y|},\\tag{17}</span>$</p>

    <p class="text-gray-300"><span class="math">$\\Pr[X = \\tau] = \\frac{|\\mathsf{comp}_X(\\tau)|}{|\\Omega_X|}.</span>$
(18)</p>

    <p class="text-gray-300">The elementary argument required to prove these identities is sketched in Section 3, and we omit it here. Thus, by (16),</p>

    <p class="text-gray-300"><span class="math">$\\frac{\\Pr[X=\\tau]}{\\Pr[Y=\\tau]} = \\frac{|\\mathsf{comp}_X(\\tau)|}{|\\mathsf{comp}_X&#x27;(\\tau)|} / \\frac{|\\mathsf{comp}_Y(\\tau)|}{|\\mathsf{comp}_Y&#x27;(\\tau)|}</span>$
(19)</p>

    <p class="text-gray-300">for  <span class="math">\\tau</span>  such that  <span class="math">\\Pr[Y = \\tau] &gt; 0</span> .</p>

    <p class="text-gray-300">For the remainder of the argument we fix an arbitrary transcript  <span class="math">\\tau = (k, p_0, p_1, \\dots, p_t) \\in \\mathcal{T}_1</span> . We aim to lower bound the right-hand side fraction in (19).</p>

    <p class="text-gray-300">For random permutations  <span class="math">P_1, \\ldots, P_t</span>  and partial permutations  <span class="math">p_1, \\ldots, p_t</span> , let  <span class="math">P_i \\downarrow p_i</span>  denote the event that  <span class="math">P_i</span>  extends  <span class="math">p_i</span> , i.e., that  <span class="math">P_i(x) = y</span>  for all  <span class="math">(x, y) \\in p_i</span> ; then it is easy to see that</p>

    <p class="text-gray-300"><span class="math">$\\frac{|\\mathsf{comp}_X(\\tau)|}{|\\mathsf{comp}&#x27;_X(\\tau)|} = \\Pr\\left[E_k \\downarrow p_0 \\mid k, P_1 \\downarrow p_1, \\dots, P_t \\downarrow p_k\\right]</span>$
(20)</p>

    <p class="text-gray-300">where the underlying probability space is the choice of the uniform random permutations  <span class="math">P_1, \\ldots, P_t</span>  (the notation conditions on  <span class="math">\\tau</span> 's key k only to emphasize that k is not randomly chosen) and where  <span class="math">E_k \\downarrow p_0</span>  is the event that  <span class="math">E_k(x) = y</span>  for all  <span class="math">(x, y) \\in p_0</span> , where  <span class="math">E_k</span>  is the Even-Mansour cipher with key k and permutations  <span class="math">P_1, \\ldots, P_t</span> . Similarly,</p>

    <p class="text-gray-300"><span class="math">$\\frac{|\\mathsf{comp}_{Y}(\\tau)|}{|\\mathsf{comp}&#x27;_{Y}(\\tau)|} = \\Pr\\left[P_0 \\downarrow p_0 \\mid k, P_1 \\downarrow p_1, \\dots, P_t \\downarrow p_k\\right]</span>$</p>

    <p class="text-gray-300">where the underlying probability space is the uniform random choice of  <span class="math">P_0, P_1, \\ldots, P_t</span> . In the latter conditional probability, however, the event  <span class="math">P_0 \\downarrow p_0</span>  is independent of the conditioned premise, so</p>

    <p class="text-gray-300"><span class="math">$\\frac{|\\mathsf{comp}_{Y}(\\tau)|}{|\\mathsf{comp}_{Y}&#x27;(\\tau)|} = \\Pr\\left[P_0 \\downarrow p_0\\right] = \\prod_{\\ell=0}^{q_e-1} \\frac{1}{N-\\ell}.</span>$
(21)</p>

    <p class="text-gray-300">To facilitate the computation of the conditional probability that appears in (20), let (in accordance with the definition of the graph  <span class="math">\\tilde{G}(\\tau)</span>  above)  <span class="math">\\tilde{p}_i</span>  be defined by</p>

    <p class="text-gray-300"><span class="math">$(x,y) \\in \\tilde{p}_i \\iff (x \\oplus k_{i-1},y) \\in p_i</span>$</p>

    <p class="text-gray-300">for  <span class="math">1 \\le i \\le t - 1</span> , and by</p>

    <p class="text-gray-300"><span class="math">$(x,y) \\in \\tilde{p}_i \\iff (x \\oplus k_{i-1}, y \\oplus k_i) \\in p_i</span>$</p>

    <p class="text-gray-300">for i = t. Thus  <span class="math">\\tilde{p}_1, \\ldots, \\tilde{p}_t</span>  are the t edge sets of the graph  <span class="math">\\tilde{G}(\\tau)</span> , i.e.,  <span class="math">\\tilde{p}_i</span>  is the set of edges between shores i - 1 and i of  <span class="math">\\tilde{G}(\\tau)</span> . By elementary considerations, one has</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[E_k \\downarrow p_0 \\mid k, P_1 \\downarrow p_1, \\dots, P_t \\downarrow p_k\\right] = \\Pr\\left[E_0 \\downarrow p_0 \\mid P_1 \\downarrow \\tilde{p}_1, \\dots, P_t \\downarrow \\tilde{p}_k\\right]</span>$
(22)</p>

    <p class="text-gray-300">where  <span class="math">E_0</span>  denotes the Even-Mansour cipher instantiated with key  <span class="math">0^{(t+1)n}</span> , and where the probability is taken (on either side) over the choice of the uniform random permutations  <span class="math">P_1, \\ldots, P_t</span> . We will therefore focus on the right-hand side probability in (22).</p>

    <p class="text-gray-300">We say shore i of  <span class="math">\\tilde{G}(\\tau)</span>  is &quot;to the left&quot; of shore j if i &lt; j. We also view paths in  <span class="math">\\tilde{G}(\\tau)</span>  as oriented from left to right: the path &quot;starts&quot; at the leftmost vertex and &quot;ends&quot; at the rightmost vertex.</p>

    <p class="text-gray-300">Let  <span class="math">(x_1, y_1), \\ldots, (x_{q_e}, y_{q_e})</span>  be the  <span class="math">q_e</span>  edges in  <span class="math">p_0</span> . We write  <span class="math">\\mathsf{R}(x_\\ell)</span>  for the rightmost vertex in the path of  <span class="math">\\tilde{G}(\\tau)</span>  starting at  <span class="math">x_\\ell</span> , and  <span class="math">\\mathsf{L}(y_\\ell)</span>  for the leftmost vertex in the path of  <span class="math">\\tilde{G}(\\tau)</span>  ending at  <span class="math">y_\\ell</span> . (More often than not,  <span class="math">x_\\ell</span>  and  <span class="math">y_\\ell</span>  are not adjacent to any edges of  <span class="math">\\tilde{G}(\\tau)</span> , in which case  <span class="math">\\mathsf{R}(x_\\ell) = x_\\ell</span> ,  <span class="math">\\mathsf{L}(y_\\ell) = y_\\ell</span> .) We write the index of the shore containing vertex v as  <span class="math">\\mathsf{Sh}(v)</span> . (Thus  <span class="math">\\mathsf{Sh}(v) \\in \\{0, 1, \\ldots, t\\}</span> .) Because  <span class="math">\\tau</span>  is good, and because we are assuming  <span class="math">Cq_e(q/N)^t &lt; 1</span> ,  <span class="math">\\mathsf{Sh}(\\mathsf{R}(x_\\ell)) &lt; \\mathsf{Sh}(\\mathsf{L}(y_\\ell))</span>  for  <span class="math">1 \\le \\ell \\le q_e</span> .</p>

    <p class="text-gray-300">A vertex in shore  <span class="math">i \\ge 1</span>  is <em>left-free</em> if it is not adjacent to a vertex in shore i - 1. A vertex in shore  <span class="math">i \\le t - 1</span>  is <em>right-free</em> if it is not adjacent to a vertex in shore i + 1.</p>

    <p class="text-gray-300">To compute the conditional probability</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[E_0 \\downarrow p_0 \\mid P_1 \\downarrow \\tilde{p}_1, \\dots, P_t \\downarrow \\tilde{p}_t\\right]</span>$</p>

    <p class="text-gray-300">we imagine the following experiment in  <span class="math">q_e</span>  stages. Let  <span class="math">G_0 = \\tilde{G}(\\tau)</span> . At the  <span class="math">\\ell</span> -th stage,  <span class="math">G_\\ell</span>  is inductively defined from  <span class="math">G_{\\ell-1}</span> . Let  <span class="math">\\tilde{p}_i^\\ell</span>  be the edges between shore i-1 and i of  <span class="math">G_\\ell</span> . Initially,  <span class="math">G_\\ell = G_{\\ell-1}</span> . Then, as long as  <span class="math">\\mathsf{R}(x_\\ell)</span>  is not in shore t, a value y is chosen uniformly at random from the set of left-free vertices in shore  <span class="math">\\mathsf{Sh}(\\mathsf{R}(x_\\ell)) + 1</span> , and the edge  <span class="math">(\\mathsf{R}(x_\\ell), y)</span>  is added to  <span class="math">\\tilde{p}_{\\mathsf{Sh}(\\mathsf{R}(x_\\ell))+1}^\\ell</span> .  <span class="math">G_\\ell</span>  is the result obtained when  <span class="math">\\mathsf{R}(x_\\ell)</span>  reaches shore t. Thus,  <span class="math">G_\\ell</span>  has at most t more edges than  <span class="math">G_{\\ell-1}</span> .</p>

    <p class="text-gray-300">Since the permutations  <span class="math">P_1, \\ldots, P_t</span>  are uniformly random and independently chosen, it is easy to see that</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[E_0 \\downarrow p_0 \\mid P_1 \\downarrow \\tilde{p}_1, \\dots, P_t \\downarrow \\tilde{p}_t\\right] = \\Pr\\left[G_{q_e} \\downarrow p_0\\right]</span>$</p>

    <p class="text-gray-300">for the random graph  <span class="math">G_{q_e}</span>  defined in the process above, where the notation  <span class="math">G_{q_e} \\downarrow p_0</span>  is a shorthand to indicate that vertices  <span class="math">x_\\ell</span>  and  <span class="math">y_\\ell</span>  are connected by a path in  <span class="math">G_{q_e}</span>  for  <span class="math">1 \\le \\ell \\le q_e</span> . Moreover, writing  <span class="math">x_\\ell \\to y_\\ell</span>  for the event that  <span class="math">x_\\ell</span>  and  <span class="math">y_\\ell</span>  are connected by a path in  <span class="math">G_\\ell</span>  (and thus in  <span class="math">G_{q_e}</span> ), and writing  <span class="math">G_\\ell \\downarrow p_0</span>  for the event  <span class="math">x_j \\to y_j</span>  for  <span class="math">1 \\le j \\le \\ell</span> , we finally find</p>

    <p class="text-gray-300"><span class="math">$\\frac{|\\mathsf{comp}_X(\\tau)|}{|\\mathsf{comp}_X&#x27;(\\tau)|} = \\prod_{\\ell=0}^{q_e-1} \\Pr[x_{\\ell+1} \\to y_{\\ell+1} \\,|\\, G_\\ell \\downarrow p_0]. \\tag{23}</span>$</p>

    <p class="text-gray-300">This formula should be compared with (21). Indeed, (21) and (23) imply that</p>

    <p class="text-gray-300"><span class="math">$\\frac{|\\mathsf{comp}_X(\\tau)|}{|\\mathsf{comp}_X&#x27;(\\tau)|} / \\frac{|\\mathsf{comp}_Y(\\tau)|}{|\\mathsf{comp}_Y&#x27;(\\tau)|} = \\prod_{\\ell=0}^{q_e-1} \\frac{\\Pr[x_{\\ell+1} \\to y_{\\ell+1} \\mid G_\\ell \\downarrow p_0]}{1/(N-\\ell)}</span>$</p>

    <p class="text-gray-300"><span class="math">$(24)</span>$</p>

    <p class="text-gray-300">which suggests that to lower bound  <span class="math">\\Pr[X = \\tau]/\\Pr[Y = \\tau]</span>  one should compare  <span class="math">\\Pr[x_{\\ell+1} \\to y_{\\ell+1} \\mid G_{\\ell} \\downarrow p_0]</span>  and  <span class="math">1/(N-\\ell)</span> . (More specifically, give a lower bound for the former that is not much less than the latter.)</p>

    <p class="text-gray-300">Some preliminary quantitative intuition for (24). Up to now, the proof has mostly been notational setup. (The possible exception is the upper bounding of  <span class="math">\\Pr[\\tau \\in \\mathcal{T}_2]</span> , but this is just an application of Markov's inequality, and the definition of  <span class="math">\\mathcal{T}_2</span>  is also the obvious one.) The heart of the proof, indeed, is lower bounding the product that appears in (24). At this stage we &quot;pause&quot; the proof to give some quantitative intuition about this product. This intuition shows, in particular, the need for a conservative computation. We will make the simplifying assumption that  <span class="math">\\operatorname{Sh}(R(x_\\ell)) = 0</span> ,  <span class="math">\\operatorname{Sh}(L(y_\\ell)) = t</span>  for all  <span class="math">1 \\le \\ell \\le q_e</span> . (Which, as it turns out, still captures the most interesting features of the problem.)</p>

    <p class="text-gray-300">As a warm-up we can consider the case t=1. In this case, firstly, the &quot;simplifying assumption&quot;  <span class="math">Sh(R(x_{\\ell})) = 0</span> ,  <span class="math">Sh(L(y_{\\ell})) = 1</span>  actually holds with probability 1 for all  <span class="math">\\tau \\in \\mathcal{T}_1</span> , by the second bad event in the definition of a bad transcript (i.e., (12)), and by our wlog assumption that</p>

    <p class="text-gray-300"><span class="math">$1 &gt; Cq_e(q/N)^t = Cq_eq/N. (25)</span>$</p>

    <p class="text-gray-300">(In more detail, the right-hand side of (12) is  <span class="math">Cq_eq/N</span>  for i=j=0 or i=j=1. Thus, if there exists an  <span class="math">(x_\\ell,y_\\ell)\\in p_0</span>  such that either  <span class="math">\\mathsf{R}(x_\\ell)=1</span>  or  <span class="math">\\mathsf{L}(y_\\ell)=0</span> , then  <span class="math">\\tau\\in\\mathcal{T}_2</span> .) Next (still for t=1) it can be directly observed that</p>

    <p class="text-gray-300"><span class="math">$\\Pr\\left[x_{\\ell+1} \\to y_{\\ell+1} | G_{\\ell} \\downarrow p_0\\right] = \\frac{1}{N - q - \\ell}</span>$</p>

    <p class="text-gray-300">since  <span class="math">\\tilde{p}_1 = \\tilde{p}_1^0</span>  contains q edges and since  <span class="math">\\ell</span>  additional edges have been drawn by the time  <span class="math">G_{\\ell+1}</span>  is constructed. In fact, the ratio  <span class="math">1/(N-q-\\ell)</span>  is greater than  <span class="math">1/(N-\\ell)</span> , which means that in this case the product (24) is also greater than 1, and one can therefore use  <span class="math">\\varepsilon_1 = 0</span> . I.e., for t = 1 the distinguisher's advantage is upper bounded by</p>

    <p class="text-gray-300"><span class="math">$\\varepsilon_1 + \\Pr[Y \\in \\mathcal{T}_2] \\le 0 + \\Pr[Y \\in \\mathcal{T}_2] \\le \\frac{2q_eq}{N}</span>$</p>

    <p class="text-gray-300">where the last inequality is obtained by direct inspection of the event  <span class="math">\\tau \\in \\mathcal{T}_2</span>  for t = 1. (For t = 1, the only thing that can cause a transcript to be bad is if  <span class="math">p_0^- \\oplus k_0 \\cap p_1^- \\neq \\emptyset</span>  or if  <span class="math">p_0^+ \\oplus k_1 \\cap p_1^+ \\neq \\emptyset</span> .) Note that even while  <span class="math">\\Pr[X = \\tau]/\\Pr[Y = \\tau] \\geq 1</span>  for all  <span class="math">\\tau \\in \\mathcal{T}_1</span>  such that  <span class="math">\\Pr[Y = \\tau] &gt; 0</span> , one has  <span class="math">\\Pr[X = \\tau]/\\Pr[Y \\in \\tau] = 0</span>  for most  <span class="math">\\tau \\in \\mathcal{T}_2</span>  such that  <span class="math">\\Pr[Y = \\tau] &gt; 0</span> . This is why  <span class="math">\\varepsilon_1</span>  can attain zero.</p>

    <p class="text-gray-300">In passing, note we have proved the  <span class="math">(2q_eq/N)</span> -security of the key-alternating cipher for t=1, which exactly recovers Even and Mansour's original result for t=1. The difference is that the H-coefficient technique &quot;mechanizes&quot; the bound-proving, to a certain extent. (Even and Mansour's proof [7] is more complicated, though it pursues the same basic idea. See also Kilian and Rogaway's paper on DESX [12] for a nice game-based take on this argument.)</p>

    <p class="text-gray-300">Given these auspicious beginnings for t=1 one might feel inclined to optimism and to conjecture, say, that the product (24) is always greater than 1 for good transcripts. However, let us start by dashing these hopes with an example for t=2. For the example, assume that  <span class="math">\\tilde{p}_1</span>  and  <span class="math">\\tilde{p}_2</span>  are disjoint, i.e., no edge in  <span class="math">\\tilde{p}_1</span>  touches an edge in  <span class="math">\\tilde{p}_2</span> . (Thus  <span class="math">G_0 = \\tilde{G}(\\tau)</span>  contains no paths of length 2.) The example will be clearer if we start by examining the case  <span class="math">\\tilde{p}_1 = \\emptyset</span>  (i.e., when there are no edges between shore 0 and shore 1). Then one can compute that<sup>5</sup></p>

    <p class="text-gray-300"><span class="math">$\\Pr[x_1 \\to y_1] = \\left(1 - \\frac{|\\tilde{p}_2|}{N}\\right) \\frac{1}{N - |\\tilde{p}_2|} = \\left(\\frac{N - |\\tilde{p}_2|}{N}\\right) \\frac{1}{N - |\\tilde{p}_2|} = \\frac{1}{N}.</span>$</p>

    <p class="text-gray-300">Similarly,</p>

    <p class="text-gray-300"><span class="math">$\\Pr[x_2 \\to y_2 | G_1 \\downarrow p_0] = \\left(1 - \\frac{|\\tilde{p}_2|}{N-1}\\right) \\frac{1}{N-1 - |\\tilde{p}_2|} = \\frac{1}{N-1}</span>$</p>

    <p class="text-gray-300">since the vertex in shore 1 to which  <span class="math">x_2</span>  is connected is sampled uniformly from a set of size N-1, and similarly the new vertex sampled in shore 2 (if such vertex is sampled) comes uniformly from a set of size  <span class="math">N-1-|\\tilde{p}_2|</span> . More generally, thus,</p>

    <p class="text-gray-300"><span class="math">$\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_{\\ell} \\downarrow p_0] = \\left(1 - \\frac{|\\tilde{p}_2|}{N - \\ell}\\right) \\frac{1}{N - \\ell - |\\tilde{p}_2|} = \\frac{1}{N - \\ell}.</span>$</p>

    <p class="text-gray-300">So far so good, but these computations are under the false assumption that  <span class="math">\\tilde{p}_1 = \\emptyset</span> !</p>

    <p class="text-gray-300">Now we remove the assumption  <span class="math">\\tilde{p}_1 = \\emptyset</span> , but keep the assumption that  <span class="math">\\tilde{p}_1</span>  and  <span class="math">\\tilde{p}_2</span>  are disjoint. In this case, one has</p>

    <p class="text-gray-300"><span class="math">$\\Pr[x_1 \\to y_1] = \\left(1 - \\frac{|\\tilde{p}_2|}{N - |\\tilde{p}_1|}\\right) \\frac{1}{N - |\\tilde{p}_2|} = \\left(\\frac{N - 2q}{N - q}\\right) \\frac{1}{N - q} = \\frac{N - 2q}{(N - q)^2}.</span>$</p>

    <p class="text-gray-300">As our interest is to compare this quantity to 1/N, we further massage this expression by writing</p>

    <p class="text-gray-300"><span class="math">$\\frac{N-2q}{(N-q)^2} = \\frac{1}{N} - \\frac{1}{N} + \\frac{N-2q}{(N-q)^2} = \\frac{1}{N} - \\frac{(N-q)^2}{N(N-q)^2} + \\frac{N(N-2q)}{N(N-q)^2} = \\frac{1}{N} - \\frac{q^2}{N(N-q)^2}.</span>$</p>

    <p class="text-gray-300">More generally, one finds that</p>

    <p class="text-gray-300"><span class="math">$\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_{\\ell} \\downarrow p_0] = \\left(1 - \\frac{|\\tilde{p}_2|}{N - \\ell - |\\tilde{p}_1|}\\right) \\frac{1}{N - \\ell - |\\tilde{p}_2|} = \\frac{1}{N - \\ell} - \\frac{q^2}{(N - \\ell)(N - \\ell - q)^2}</span>$
(26)</p>

    <p class="text-gray-300">as can be seen by substituting N by  <span class="math">N-\\ell</span>  everywhere in the first computation. Thus the probability  <span class="math">\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_\\ell \\downarrow p_0]</span>  is now slightly lower than  <span class="math">1/(N-\\ell)</span> , which rules out the optimistic conjecture</p>

    <p class="text-gray-300">In more detail: when we travel from  <span class="math">x_1</span>  to  <span class="math">y_1</span> , the sampling process first chooses a random endpoint in shore 1 to attach  <span class="math">x_1</span>  to, and this endpoint has probability  <span class="math">|\\tilde{p}_2|/N</span>  of &quot;hitting&quot; an edge in  <span class="math">\\tilde{p}_2</span>  (in which case we have no hope of reaching  <span class="math">y_1</span> ). If we don't hit an edge in  <span class="math">\\tilde{p}_2</span> , there is further chance  <span class="math">1/(N-|\\tilde{p}_2|)</span>  that we reach  <span class="math">y_1</span> , since the vertex in shore 2 is sampled uniformly at random from a set of size  <span class="math">N-|\\tilde{p}_2|</span> .</p>

    <p class="text-gray-300">above. As for the value of the product (24) one finds, by (26),</p>

    <p class="text-gray-300"><span class="math">$\\prod_{\\ell=0}^{q_e-1} \\left( 1 - \\frac{q^2}{(N-\\ell-q)^2} \\right) \\ge \\left( 1 - \\frac{q^2}{(N-2q)^2} \\right)^{q_e} \\ge 1 - \\frac{q_e q^2}{(N-2q)^2}.</span>$</p>

    <p class="text-gray-300">This is acceptably close to 1 (i.e., taking  <span class="math">\\varepsilon_1 = q_e q^2/(N-2q)^2</span>  is acceptably close to zero) as long as  <span class="math">q_e q^2 \\ll N^2</span> . We are (coincidentally or not, since the assumption  <span class="math">q_e q^2 \\ll N^2</span>  has already been used to upper bound  <span class="math">\\Pr[\\tau \\in \\mathcal{T}_2]</span> ) &quot;bumping into&quot; the security bound for t=2. Thus, the approach still works for t=2, but this time the approach &quot;barely&quot; works!</p>

    <p class="text-gray-300">In fact, the simplifying assumption that  <span class="math">\\tilde{p}_1</span>  and  <span class="math">\\tilde{p}_2</span>  are disjoint can easily be removed since, as is not hard to see, having  <span class="math">\\tilde{p}_1</span>  and  <span class="math">\\tilde{p}_2</span>  disjoint is actually the worst case possible<sup>6</sup> for t=2.</p>

    <p class="text-gray-300">Moreover, the initial simplifying assumption that  <span class="math">R(x_\\ell) = 0</span> ,  <span class="math">L(y_\\ell) = 2</span>  for all  <span class="math">\\ell</span>  is also easy to remove for t = 2, because  <span class="math">\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_\\ell \\downarrow p_0]</span>  actually increases to  <span class="math">1/(N-q-\\ell)</span>  (cf. the case t=1) when either  <span class="math">R(x_\\ell) = 1</span>  or  <span class="math">L(y_\\ell) = 1</span> . Thus, the above computations essentially prove security of  <span class="math">q_e q^2/N^2</span>  for  <span class="math">t \\geq 2</span>  (indeed, security is easily seen to &quot;transfer upwards&quot; from smaller to larger values of t), which is the main result of Bogdanov et al. [2]. The proof sketched above is arguably simpler than Bogdanov et al.'s, though. (Also, Bogdanov et al. seem to forget that if the only goal is to prove security of  <span class="math">q_e q^2/N^2</span>  for  <span class="math">t \\geq 2</span>  it suffices to restrict oneself to the case t=2. Their general approach, however, can be pushed slightly further to cover the case t=3, as shown by Steinberger [19].)</p>

    <p class="text-gray-300">We now consider the case t=3. Already, doing an exact probability computation for the conditional probability  <span class="math">\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_{\\ell} \\downarrow p_0]</span>  (as done in (26) for t=2) promises to be quite tedious for t=3, so we can look at doing back-of-the-envelope estimates instead. The simplest estimate is to lower bound the probability of  <span class="math">x_{\\ell+1}</span>  reaching  <span class="math">y_{\\ell+1}</span>  by upper bounding the probability that the path being constructed meets a pre-existing edge in either shore 1 or shore 2, viz.,</p>

    <p class="text-gray-300"><span class="math">$\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_{\\ell} \\downarrow p_0] \\ge \\left(1 - \\frac{2q}{N - \\ell - q}\\right) \\frac{1}{N - \\ell - q}</span>$
(27)</p>

    <p class="text-gray-300">where  <span class="math">2q/(N-\\ell-q)</span>  is a (crude) upper bound on the probability that the path touches a pre-existing edge in either shore 1 or shore 2, and where  <span class="math">1/(N-\\ell-q)</span>  is the probability of reaching  <span class="math">y_{\\ell+1}</span>  if the path reaches a right-free vertex in shore 2. However, (27) is worse than (26), so we are heading at best for security of  <span class="math">\\varepsilon_1 \\approx q_e q^2/N^2</span>  if we use this estimate. One can argue that  <span class="math">2q/(N-\\ell-q)</span>  can be replaced by  <span class="math">q/(N-\\ell-q)</span>  in (27) (because: if we hit an edge in  <span class="math">\\tilde{p}_2</span>  that is not adjacent to an edge in  <span class="math">\\tilde{p}_3</span>  this only helps us, and if we hit an edge in  <span class="math">\\tilde{p}_2</span>  that is adjacent to an edge in  <span class="math">\\tilde{p}_3</span>  this can be &quot;billed&quot; to the corresponding edge in  <span class="math">\\tilde{p}_3</span> ) but even so we are headed towards a security of  <span class="math">q_e q^2/N^2</span> , by comparison with (26). In fact, we can reflect that any approach that doesn't somehow seriously take into account the presence of three rounds is doomed to fail, because the computation for t=2 is actually tight (cf. footnote 6), and thus cannot be tweaked to give security better than  <span class="math">q_e q^2/N^2</span> .</p>

    <p class="text-gray-300">As it turns out, the &quot;exact but tedious&quot; probability computation that we shied from above does deliver a bound that implies the desired security of  <span class="math">q_eq^3/N^3</span> , even while back-of-the-envelope estimates indicate a security bound of  <span class="math">q_eq^2/N^2</span> . Intuitively, the gain that occurs is due to the fact that when the path hits an edge of  <span class="math">\\tilde{p}_2</span>  not connected to an edge of  <span class="math">\\tilde{p}_3</span> &mdash;and at most  <span class="math">Cq^2/N \\ll q</span>  edges in  <span class="math">\\tilde{p}_2</span>  are adjacent to edges in  <span class="math">\\tilde{p}_3</span> , by definition of  <span class="math">\\mathcal{T}_2</span> &mdash;this is actually better than not hitting any edge at all in shore 1, because it guarantees we won't hit an edge in  <span class="math">\\tilde{p}_3</span> . While this intuition is easy to see, it is somewhat</p>

    <p class="text-gray-300">On the other hand, we cannot count on  <span class="math">\\tilde{p}_1</span>  and  <span class="math">\\tilde{p}_2</span>  having some small intersection in order to possibly repair our optimistic conjecture. Indeed, the distinguisher could make sure that  <span class="math">\\tilde{p}_1</span>  and  <span class="math">\\tilde{p}_2</span>  are almost certainly disjoint. For example, the distinguisher could make q  <span class="math">P_2</span> -queries with values that start with n/3 0's, and also make q  <span class="math">P_1^{-1}</span> -queries with values that start with n/3 0's. Then  <span class="math">\\tilde{p}_1</span>  and  <span class="math">\\tilde{p}_2</span>  are disjoint unless the first n/3 bits of the key are 0, which occurs with negligible probability.</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;7</sup> Note that one always has  <span class="math">R(x_{\\ell}) &lt; L(y_{\\ell})</span>  by the definition of  <span class="math">\\mathcal{T}_2</span>  and by the wlog assumption  <span class="math">Cq_{\\ell}q^t &lt; N^t</span> .</p>

    <p class="text-gray-300">harder to believe such a small &quot;second-order&quot; effect would make a crucial difference in the final security bound. Yet, this is exactly so. In fact, given the &quot;completeness&quot; of the H-coefficient method it makes sense to have faith that the exact probability computation (if doable) will deliver security  <span class="math">q_e q^3/N^3</span> . (Though in reality even this is not a given: by giving away the key at the end of each transcript we have been more generous to the adversary than those who devised the security conjecture of  <span class="math">q_e q^t/N^t</span> , so it's possible to conceive that it's the &quot;key's fault&quot; if the security is (apparently) topping off at  <span class="math">q_e q^2/N^2</span>  (as opposed to the fault of our lossy estimates). Note that even if we have the correct intuition, and we believe it isn't the &quot;key's fault&quot; and that the approach is theoretically sound, we are still up against the problem of actually doing the computations in a such way that the desired security gain becomes apparent, and isn't lost in a sea of fractions.)</p>

    <p class="text-gray-300">We will show the &quot;exact&quot; probability computation for t = 3 in the next subsection, where we will see it is neither more nor less terrible than might be expected. The t = 3 computation also serves as a useful reference point for the general case.</p>

    <p class="text-gray-300">Before that, we will estimate what kind of lower bound is actually needed for  <span class="math">\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_{\\ell} \\downarrow p_0]</span>  in order to reach overall security  <span class="math">\\approx q_e q^t / N^t</span> . Writing</p>

    <p class="text-gray-300"><span class="math">$\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_{\\ell} \\downarrow p_0] = \\frac{1}{N - \\ell} + z_t</span>$</p>

    <p class="text-gray-300">where  <span class="math">z_t</span>  is an &quot;error term&quot; whose magnitude will determine  <span class="math">\\varepsilon_1</span> , we find that</p>

    <p class="text-gray-300"><span class="math">$\\prod_{\\ell=0}^{q_e-1} \\frac{\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_\\ell \\downarrow p_0]}{1/(N-\\ell)} = \\prod_{\\ell=0}^{q_e-1} (1 - (N-\\ell)z_t) \\ge (1 - N|z_t|)^{q_e} \\ge 1 - Nq_e|z_t|.</span>$</p>

    <p class="text-gray-300">Thus we will have  <span class="math">\\varepsilon_1 \\approx Nq_e|z_t|</span>  and so we need need  <span class="math">Nq_e|z_t| \\ll 1</span>  in order for  <span class="math">\\varepsilon_1</span>  to be small. Having</p>

    <p class="text-gray-300"><span class="math">$|z_t| = q^t / N^{t+1} \\tag{28}</span>$</p>

    <p class="text-gray-300">gives us precisely this under the assumption  <span class="math">q_e q^t/N^t \\ll 1</span> .</p>

    <p class="text-gray-300">The quantity  <span class="math">q^t/N^t</span>  affords a natural interpretation that resurfaces in the proof, so we will preemptively point out this interpretation here. Let  <span class="math">0 \\le i_0 &lt; \\ldots &lt; i_s = t</span>  be some strictly increasing sequence of shore indices,  <span class="math">s \\le t</span> . If we select a vertex uniformly at random from shore  <span class="math">i_j</span>  of (say, for simplicity)  <span class="math">G_0 = \\tilde{G}(\\tau)</span>  for  <span class="math">1 \\le j \\le s</span>  then the probability that the selected vertex in shore  <span class="math">i_j</span>  is a vertex in  <span class="math">Z_{i_j-1i_j}</span>  for  <span class="math">1 \\le j \\le s</span>  is upper bounded by</p>

    <p class="text-gray-300"><span class="math">$\\prod_{j=1}^{s} \\frac{|Z_{i_{j-1}i_{j}}|}{N} \\le \\prod_{j=1}^{s} \\left( \\frac{Cq^{i_{j}-i_{j-1}}}{N^{i_{j}-i_{j-1}-1}} / N \\right) = C^{s} \\left( \\frac{q}{N} \\right)^{t-i_{0}}</span>$</p>

    <p class="text-gray-300">given the definition of  <span class="math">\\mathcal{T}_2</span> . Discarding the constant factor of  <span class="math">C^s</span> , we see this probability is as small as  <span class="math">q^t/N^t</span>  as long as  <span class="math">i_0 = 0</span> . As we will see in the general proof, the error term  <span class="math">z_t</span>  can be written as a linear combination of probabilities that are (close to) the form above, but involving nonzero values of  <span class="math">i_0</span> . We will break up these probabilities into smaller (similar) probabilities such that all terms cancel except those with  <span class="math">i_0 = 0</span> . The latter terms are small enough so that the sum of their absolute values is an &quot;acceptable&quot; upper bound on  <span class="math">|z_t|</span> . (The number of such small terms will be exponentially many in t, as reflected in the bound of Theorem 1.) These hand-wavy ideas will make more sense after we see the case t = 3.</p>

    <p class="text-gray-300">DETAILS ON THE CASE t=3. Let  <span class="math">U_{ij}</span>  be the set of paths from shore i to shore j in  <span class="math">G(\\tau)</span> ,  <span class="math">0 \\le i &lt; j \\le 3</span> , such that the vertex of the path in shore i is left-free (i.e., is the head of the path), but where the vertex in shore j may or may not be right-free. The  <span class="math">U_{ij}</span> 's are therefore &quot;half-open&quot; paths. Note  <span class="math">|U_{ij}| \\le |Z_{ij}| \\le Cq^{j-1}/N^{j-i-1}</span>  by definition of  <span class="math">\\mathcal{T}_2</span> . For notational consistency with Lemma 1 below we rename  <span class="math">\\tilde{p}_i</span>  as  <span class="math">E_i</span></p>

    <p class="text-gray-300">for i = 1, 2, 3. Thus  <span class="math">|E_i| = q</span>  and  <span class="math">E_i</span>  is the set of edges between shores (i - 1) and i of  <span class="math">\\tilde{G}(\\tau)</span> . Moreover, one can note that  <span class="math">E_i = \\bigcup_{0 \\le i \\le i} U_{ji}</span>  for all i, with the latter being a disjoint union.</p>

    <p class="text-gray-300">We start by computing  <span class="math">\\Pr[x_1 \\to y_1]</span> , from which the general case  <span class="math">\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_{\\ell} \\downarrow p_0]</span>  will be easy to deduce. We view the underlying probability space as the selection of three vertices  <span class="math">u_1</span> ,  <span class="math">u_2</span>  and  <span class="math">u_3</span>  from shores 1, 2 and 3 of  <span class="math">\\tilde{G}(\\tau)</span>  respectively, such that  <span class="math">u_i</span>  is selected independently and uniformly at random from the set of left-free vertices in shore i. This defines a path  <span class="math">w_0 := x_1</span> ,  <span class="math">w_1 := u_1</span> ,  <span class="math">w_2</span> ,  <span class="math">w_3</span>  where  <span class="math">w_2</span>  equals  <span class="math">u_2</span>  if  <span class="math">u_1</span>  is right-free and equals the other endpoint of the edge adjacent to  <span class="math">u_1</span>  otherwise, and where  <span class="math">w_3</span>  equals  <span class="math">u_3</span>  if  <span class="math">w_2</span>  is right-free, otherwise equals the vertex in shore 3 adjacent to  <span class="math">w_2</span> . Then  <span class="math">\\Pr[x_1 \\to y_1]</span>  is equal to the probability that  <span class="math">w_3 = y_1</span> .</p>

    <p class="text-gray-300">Since  <span class="math">y_1</span>  is left-free we have</p>

    <p class="text-gray-300"><span class="math">$w_3 = y_1 \\iff (u_3 = y_1) \\land \\neg (w_1 \\in U_{13} \\lor w_2 \\in U_{23}).</span>$</p>

    <p class="text-gray-300">(The event  <span class="math">\\neg(w_1 \\in U_{13} \\lor w_2 \\in U_{23})</span>  coincides with the event that  <span class="math">w_2</span>  is right-free.) Note the event  <span class="math">u_3 = y_1</span>  is independent from the event  <span class="math">\\neg(w_1 \\in U_{13} \\lor w_2 \\in U_{23})</span> , and also that the events  <span class="math">w_1 \\in U_{13}</span>  and  <span class="math">w_2 \\in U_{23}</span>  are disjoint. Moreover,</p>

    <p class="text-gray-300"><span class="math">$w_2 \\in U_{23} \\iff (u_2 \\in U_{23}) \\land \\neg (w_1 \\in U_{12})</span>$</p>

    <p class="text-gray-300">since the vertices in shore 2 of  <span class="math">U_{23}</span>  are left-free. By independence of  <span class="math">u_1</span>  and  <span class="math">u_2</span> , thus,</p>

    <p class="text-gray-300"><span class="math">$\\Pr[w_2 \\in U_{23}] = \\Pr[u_2 \\in U_{23}] \\cdot (1 - \\Pr[w_1 \\in U_{12}])</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\frac{|U_{23}|}{N - |E_2|} \\left(1 - \\frac{|U_{12}|}{N - |E_1|}\\right)</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\frac{|U_{23}|}{N - |E_2|} - \\frac{|U_{12}||U_{23}|}{(N - |E_1|)(N - |E_2|)}.</span>$</p>

    <p class="text-gray-300">Thus</p>

    <p class="text-gray-300">$$\\Pr[w_3 = y_1] = \\Pr[u_3 = y_1] (1 - \\Pr[w_1 \\in U_{13}] - \\Pr[w_2 \\in U_{23}])
= \\frac{1}{N - |E_3|} \\left( 1 - \\frac{|U_{13}|}{N - |E_1|} - \\frac{|U_{23}|}{N - |E_2|} + \\frac{|U_{12}||U_{23}|}{(N - |E_1|)(N - |E_2|)} \\right)
= \\frac{1}{N - |E_3|} - \\frac{|U_{13}|}{(N - |E_1|)(N - |E_3|)} - \\frac{|U_{23}|}{(N - |E_2|)(N - |E_3|)}</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">
      <li>\\frac{|U_{12}||U_{23}|}{(N - |E_1|)(N - |E_2|)(N - |E_3|)}.$$</li>
    </ul>

    <p class="text-gray-300">(Note that none of the terms above are as small as  <span class="math">\\approx q^3/N^4</span>  (cf. (28)), even with the approximation  <span class="math">\\frac{1}{N-|E_i|} \\approx \\frac{1}{N}</span> , so none of the terms above can (yet) be folded into the error term.) Adding and subtracting the &quot;ideal&quot; probability  <span class="math">\\frac{1}{N}</span>  to  <span class="math">\\frac{1}{N-|E_3|}</span>  gives</p>

    <p class="text-gray-300"><span class="math">$\\frac{1}{N} - \\frac{1}{N} + \\frac{1}{N - |E_3|} = \\frac{1}{N} + \\frac{|E_3|}{N(N - |E_3|)} = \\frac{1}{N} + \\frac{|U_{03}| + |U_{13}| + |U_{23}|}{N(N - |E_3|)}</span>$</p>

    <p class="text-gray-300">(Here  <span class="math">\\frac{|U_{03}|}{N(N-|E_3|)}</span>  is basically the same order of magnitude as  <span class="math">q^3/N^4</span> , given that  <span class="math">|U_{03}| \\leq |Z_{03}| \\leq Cq^3/N^2</span> . So we can leave this term alone.) Next,</p>

    <p class="text-gray-300"><span class="math">$\\frac{|U_{13}|}{N(N-|E_3|)} - \\frac{|U_{13}|}{(N-|E_1|)(N-|E_3|)} = -\\frac{|E_1||U_{13}|}{N(N-|E_1|)(N-|E_3|)} = -\\frac{|U_{01}||U_{13}|}{N(N-|E_1|)(N-|E_3|)}</span>$</p>

    <p class="text-gray-300">(same order of magnitude as  <span class="math">q^3/N^4</span> , given that  <span class="math">|U_{13}| \\leq Cq^2/N</span> ), and</p>

    <p class="text-gray-300"><span class="math">$\\frac{|U_{23}|}{N(N-|E_3|)} - \\frac{|U_{23}|}{(N-|E_2|)(N-|E_3|)} = -\\frac{|E_2||U_{13}|}{N(N-|E_2|)(N-|E_3|)}</span>$</p>

    <p class="text-gray-300"><span class="math">$= -\\frac{|U_{02}||U_{13}|}{N(N-|E_2|)(N-|E_3|)} - \\frac{|U_{12}||U_{23}|}{N(N-|E_2|)(N-|E_3|)}</span>$</p>

    <p class="text-gray-300">where only  <span class="math">\\frac{|U_{02}||U_{13}|}{N(N-|E_2|)(N-|E_3|)}</span>  is small enough to fit inside the error term. But then, of course, we lastly compute that</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} &amp;-\\frac{|U_{12}||U_{23}|}{N(N-|E_2|)(N-|E_3|)} + \\frac{|U_{12}||U_{23}|}{(N-|E_1|)(N-|E_2|)(N-|E_3|)} \\\\ &amp;= \\frac{|E_1||U_{12}||U_{23}|}{N(N-|E_1|)(N-|E_2|)(N-|E_3|)} \\\\ &amp;= \\frac{|U_{01}||U_{12}||U_{23}|}{N(N-|E_1|)(N-|E_2|)(N-|E_3|)} \\end{split}</span>$</p>

    <p class="text-gray-300">which is small enough to fit inside the error term. Collecting the leftovers after the various cancellations above, thus, we find</p>

    <p class="text-gray-300"><span class="math">$\\Pr[w_{3} = y_{1}] = \\frac{1}{N} + \\frac{|U_{03}|}{N(N - |E_{3}|)} - \\frac{|U_{01}||U_{13}|}{N(N - |E_{1}|)(N - |E_{3}|)} - \\frac{|U_{02}||U_{13}|}{N(N - |E_{1}|)(N - |E_{3}|)} + \\frac{|U_{01}||U_{12}||U_{23}|}{N(N - |E_{1}|)(N - |E_{2}|)(N - |E_{3}|)}</span>$
(29)</p>

    <p class="text-gray-300">where all the terms except  <span class="math">\\frac{1}{N}</span>  are &quot;error-term small&quot;. Moreover, when we compute  <span class="math">\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_{\\ell} \\downarrow p_0]</span>  for  <span class="math">\\ell \\geq 1</span>  we can discard the  <span class="math">\\ell</span>  completed paths from shore 0 to shore 3 linking the vertex pairs  <span class="math">(x_1, y_1), \\ldots, (x_{\\ell}, y_{\\ell})</span> , and thus reduce to the case  <span class="math">\\ell + 1 = 1</span>  with N replaced by  <span class="math">N - \\ell</span> . I.e., the expression for  <span class="math">\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_{\\ell} \\downarrow p_0]</span>  will be identical to (29) except with N replaced by  <span class="math">N - \\ell</span>  throughout.</p>

    <p class="text-gray-300">From here the proof for t=3 can be finished without many suprises. (For more details, see how the general case is treated after Lemma 1.) The crux of the proof is indeed the very simple idea of adding and subtracting  <span class="math">\\frac{1}{N}</span>  from the probability, and of letting cancellations occur. This approach is purely algebraic. In Lemma 1 below, when we carry out the same process for an arbitrary value of t, we will adopt a combinatorial approach that recasts the algebraic manipulations as manipulations of events. (This seems more satisfying because it gives the algebraic cancellations a combinatorial interpretation.) Doing so requires enlarging the probability space beyond its original confines. Indeed, for example, the original probability space has no event that occurs with probability  <span class="math">\\frac{1}{N}</span>  even while factors of  <span class="math">\\frac{1}{N}</span>  are ubiquitous in the final expression. Details follow below.</p>

    <p class="text-gray-300">MAIN LEMMA. To accurately lower bound the probability  <span class="math">\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_{\\ell} \\downarrow p_0]</span>  we will abstract the setup within which that probability computation takes place. Let G be a graph with r+1 shores equal to  <span class="math">\\{0,1\\}^n</span>  indexed  <span class="math">0,1,\\ldots,r</span> . (Eventually, r will correspond to  <span class="math">\\mathsf{L}(y_{\\ell+1}) - \\mathsf{R}(x_{\\ell+1})</span> , and G will be the graph  <span class="math">G_{\\ell}</span>  with shores  <span class="math">0,\\ldots,\\mathsf{R}(x_{\\ell+1})-1</span>  and  <span class="math">\\mathsf{L}(y_{\\ell+1})+1,\\ldots,t</span>  deleted.) The edges of G are divided into r sets  <span class="math">E_1,\\ldots,E_r</span>  where  <span class="math">E_i</span>  is a (partial) matching between shores i-1 and i. Moreover, G has two distinguished vertices u,v in shores 0,r, respectively, such that u is right-free and that v is left-free. These will eventually correspond to  <span class="math">x_{\\ell+1}</span>  and  <span class="math">y_{\\ell+1}</span> .</p>

    <p class="text-gray-300">As above we define  <span class="math">U_{ij}</span> ,  <span class="math">0 \\le i &lt; j \\le r</span> , to be the set of paths from shore i to shore j of G such that the vertex in shore i is left-free, but where the vertex in shore j may or may not be right-free.</p>

    <p class="text-gray-300">For  <span class="math">1 \\le i \\le r</span>  we let  <span class="math">u_i</span>  be a vertex chosen uniformly at random from the set of left-free vertices in shore i. The choice of  <span class="math">u_1, \\ldots, u_r</span>  defines a path  <span class="math">w_0, w_1, \\ldots, w_r</span>  in the following way: we put  <span class="math">w_0 = u</span>  and</p>

    <p class="text-gray-300"><span class="math">$w_i = \\begin{cases} y &amp; \\text{if there exists an edge } (w_{i-1}, y) \\in E_i, \\\\ u_i &amp; \\text{otherwise} \\end{cases}</span>$</p>

    <p class="text-gray-300">for  <span class="math">1 \\le i \\le r</span> . We write  <span class="math">\\Pr_G[u \\to v] = \\Pr_G[w_r = v]</span>  for the probability that we arrive at vertex v in shore r by following this path. (In order not to confuse matters we do <em>not</em> view the above experiment as defining new edges that are added to G. Thus G is a static graph.)</p>

    <p class="text-gray-300">The next lemma constitutes the technical heart of our proof.</p>

    <p class="text-gray-300"><strong>Lemma 1.</strong> Let G be as described above, with  <span class="math">U_{ij}</span>  as described above. Then</p>

    <p class="text-gray-300"><span class="math">$\\Pr_{G}[u \\to v] = \\frac{1}{N} - \\frac{1}{N} \\sum_{\\sigma} (-1)^{|\\sigma|} \\prod_{j=1}^{|\\sigma|} \\frac{|U_{i_{j}i_{j-1}}|}{N - |E_{i_{j}}|}</span>$</p>

    <p class="text-gray-300">where the sum is taken over all sequences  <span class="math">\\sigma = (i_0, \\dots, i_s)</span>  with  <span class="math">0 = i_0 &lt; \\dots &lt; i_s = r</span> , and where  <span class="math">|\\sigma| = s</span> .</p>

    <p class="text-gray-300">Proof. A sequence  <span class="math">\\sigma = (i_0, \\ldots, i_s)</span>  such that  <span class="math">0 \\le i_0 &lt; \\ldots &lt; i_s \\le r</span>  is called an  <span class="math">i_0i_s</span> -partition of size s. We write  <span class="math">|\\sigma| = s</span> , as in the lemma statement. We write  <span class="math">\\mathfrak{S}_{ij}</span>  for the set of all ij-partitions. For example, the sum in the lemma statement is taken over  <span class="math">\\mathfrak{S}_{0r}</span> . We allow s = 0 and note that  <span class="math">\\mathfrak{S}_{ii}</span>  contains the partition  <span class="math">\\sigma = (i)</span>  of size zero.</p>

    <p class="text-gray-300">It will be notationally convenient if we add an (r+1)-th shore to G, with a single edge between shores r and r+1 having endpoint at v in shore r. We extend the definitions of the set of paths  <span class="math">U_{ij}</span>  to allow j = r+1. Note that  <span class="math">U_{i(r+1)} = \\emptyset</span>  for all i &lt; r because v is left-free and that  <span class="math">U_{r(r+1)}</span>  consists of the single edge adjacent to v.</p>

    <p class="text-gray-300">For  <span class="math">1 \\leq i &lt; j \\leq r+1</span>  (thus, in particular,  <span class="math">1 \\leq i \\leq r</span> ) let  <span class="math">\\odot_{ij}</span>  denote the event that  <span class="math">u_i \\in U_{ij}</span>  and let  <span class="math">\\otimes_{ij}</span>  denote the event that  <span class="math">w_i \\in U_{ij}</span> . Then  <span class="math">\\odot_{r(r+1)}</span>  is the event that  <span class="math">u_r = v</span>  and  <span class="math">\\otimes_{r(r+1)}</span>  is the event that  <span class="math">w_r = v</span> . In particular  <span class="math">\\Pr[u \\to v] = \\Pr[\\otimes_{r(r+1)}]</span> . (For the proof, we write simply  <span class="math">\\Pr[u \\to v]</span>  instead of  <span class="math">\\Pr_G[u \\to v]</span> .)</p>

    <p class="text-gray-300">We will use &quot;arithmetical&quot; notation for boolean operations on events: AB means the conjunction of events A and B, 1-A means the complement of A, etc. When using such notation, one should identify an event A with characteristic function  <span class="math">1_A</span> ; thus  <span class="math">A+A\\neq A</span>  (even though  <span class="math">A\\cup A=A</span> ) because  <span class="math">1_A+1_A=2\\cdot 1_A\\neq 1_A</span> . While intermediate expressions may evaluate to functions that are not 0,1-valued, the final value of most expressions we give are 0,1-functions on the probability space (occasionally, the final value is a 0,-1-function). Moreover, if  <span class="math">A_1+\\ldots+A_g-B_1\\ldots-B_h</span>  is a linear combination of events that sums to a 0,1-function, then  <span class="math">\\Pr[A_1+\\ldots-B_h]</span>  makes sense and  <span class="math">\\Pr[A_1+\\ldots-B_h]=\\Pr[A_1]+\\ldots-\\Pr[B_h]</span> . (On the other hand  <span class="math">\\Pr[AB]=\\Pr[A]\\Pr[B]</span>  if and only A and B are independent.) Finally, in this arithmetic an empty product corresponds to the certain event.</p>

    <p class="text-gray-300">We note that</p>

    <p class="text-gray-300"><span class="math">$\\otimes_{ij} = \\odot_{ij} (1 - \\otimes_{1i} - \\otimes_{2i} - \\dots - \\otimes_{(i-1)i})</span>$</p>

    <p class="text-gray-300"><span class="math">$\\tag{30}</span>$</p>

    <p class="text-gray-300">for all  <span class="math">1 \\leq i &lt; j \\leq r+1</span> . Indeed, for the path  <span class="math">w_1, \\ldots, w_r</span>  to &quot;hit&quot; the head of a path in  <span class="math">U_{ij}</span> , we need  <span class="math">u_i</span>  to be the head of a path in  <span class="math">U_{ij}</span>  (this is the event  <span class="math">\\odot_{ij}</span> ) and we also need the path not to have been &quot;hijacked&quot; by a pre-existing path in G that goes at least up to shore i; this &quot;hijack&quot; occurs if and only if the event</p>

    <p class="text-gray-300"><span class="math">$\\otimes_{1i} + \\otimes_{2i} + \\ldots + \\otimes_{(i-1)i} \\tag{31}</span>$</p>

    <p class="text-gray-300">occurs. (Note the events in (31) are disjoint.) Whence (30). We note that only  <span class="math">\\odot_{ij}</span>  depends on j in the right-hand side of (30).</p>

    <p class="text-gray-300">In particular, for j in the relevant ranges,</p>

    <p class="text-gray-300">$$\\begin{aligned}
\\otimes_{1j} &amp;= \\odot_{1j} \\
\\otimes_{2j} &amp;= \\odot_{2j} (1 - \\otimes_{12}) = \\odot_{2j} (1 - \\odot_{12}) = \\odot_{2j} - \\odot_{12} \\odot_{2j} \\
\\otimes_{3j} &amp;= \\odot_{3j} (1 - \\otimes_{13} - \\otimes_{23}) = \\odot_{3j} (1 - \\odot_{13} - \\odot_{23} + \\odot_{12} \\odot_{23}) \\
&amp;= \\odot_{3j} - \\odot_{13} \\odot_{3j} - \\odot_{23} \\odot_{3j} + \\odot_{12} \\odot_{23} \\odot_{3j}
\\end{aligned}$$</p>

    <p class="text-gray-300">By repeatedly &quot;unfolding&quot; in this fashion the definition of the  <span class="math">\\otimes_{ij}</span> 's in terms of the  <span class="math">\\odot_{ij}</span> 's we arrive at the inclusion-exclusion formula</p>

    <p class="text-gray-300"><span class="math">$\\otimes_{ij} = \\odot_{ij} \\sum_{y=1}^{i} \\sum_{\\sigma \\in \\mathfrak{S}_{yi}} (-1)^{|\\sigma|} \\prod_{h=1}^{|\\sigma|} \\odot_{i_{h-1}i_h}</span>$</p>

    <p class="text-gray-300"><span class="math">$(32)</span>$</p>

    <p class="text-gray-300">where the partition  <span class="math">\\sigma</span>  that appears in the sum is notated  <span class="math">(i_0, \\ldots, i_{|\\sigma|})</span> . (We keep this convention, which already appeared in the lemma statement, for all sums with an index  <span class="math">\\sigma</span> .)</p>

    <p class="text-gray-300">We note, for completeness, the very standard proof of (32) by induction on i. The expression clearly holds for i = 1 since then the sum over  <span class="math">\\sigma</span>  contains a single element consisting of  <span class="math">(-1)^0</span>  times an empty product. Now assume i &gt; 1 and that (32) holds for smaller values of i. By (30) and the induction hypothesis,</p>

    <p class="text-gray-300">$$\\bigotimes_{ij} = \\bigotimes_{ij} \\left( 1 - \\sum_{x=1}^{i-1} \\bigotimes_{xi} \\right) \\
= \\bigotimes_{ij} \\left( 1 - \\sum_{x=1}^{i-1} \\bigotimes_{xi} \\sum_{y=1}^{x} \\sum_{\\sigma \\in \\mathfrak{S}<em>{yx}} (-1)^{|\\sigma|} \\prod</em>{h=1}^{|\\sigma|} \\bigotimes_{i_{h-1}i_{h}} \\right) \\
= \\bigotimes_{ij} \\left( 1 - \\sum_{y=1}^{i-1} \\sum_{x=y}^{i-1} \\sum_{\\sigma \\in \\mathfrak{S}<em>{yx}} (-1)^{|\\sigma|} \\left( \\prod</em>{h=1}^{|\\sigma|} \\bigotimes_{i_{h-1}i_{h}} \\right) \\bigotimes_{xi} \\right) \\
= \\bigotimes_{ij} \\left( 1 - \\sum_{y=1}^{i-1} \\sum_{\\sigma \\in \\mathfrak{S}<em>{yi}} (-1)^{|\\sigma|-1} \\prod</em>{h=1}^{|\\sigma|} \\bigotimes_{i_{h-1}i_{h}} \\right) \\
= \\bigotimes_{ij} \\left( 1 + \\sum_{y=1}^{i-1} \\sum_{\\sigma \\in \\mathfrak{S}<em>{yi}} (-1)^{|\\sigma|} \\prod</em>{h=1}^{|\\sigma|} \\bigotimes_{i_{h-1}i_{h}} \\right) \\
= \\bigotimes_{ij} \\left( \\sum_{y=1}^{i} \\sum_{\\sigma \\in \\mathfrak{S}<em>{yi}} (-1)^{|\\sigma|} \\prod</em>{h=1}^{|\\sigma|} \\bigotimes_{i_{h-1}i_{h}} \\right) \\tag{33}$$</p>

    <p class="text-gray-300">which proves (32). In particular, (32) gives us the formulas</p>

    <p class="text-gray-300"><span class="math">$\\otimes_{r(r+1)} = \\odot_{r(r+1)} \\left( \\sum_{y=1}^{r} \\sum_{\\sigma \\in \\mathfrak{S}_{yr}} (-1)^{|\\sigma|} \\prod_{h=1}^{|\\sigma|} \\odot_{i_{h-1}i_h} \\right)</span>$</p>

    <p class="text-gray-300"><span class="math">$(34)</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\odot_{r(r+1)} + \\odot_{r(r+1)} \\sum_{y=1}^{r-1} \\sum_{\\sigma \\in \\mathfrak{S}_{yr}} (-1)^{|\\sigma|} \\prod_{h=1}^{|\\sigma|} \\odot_{i_{h-1}i_h}</span>$
(35)</p>

    <p class="text-gray-300">for the event  <span class="math">\\otimes_{r(r+1)}</span> .</p>

    <p class="text-gray-300">We next introduce a brand new probability space. For  <span class="math">1 \\le i \\le r</span>  let  <span class="math">u_i&#x27;</span>  be a vertex uniformly chosen in shore i, and let  <span class="math">u_i&#x27;&#x27;</span>  be a vertex uniformly and independently chosen among all left-free vertices in shore i. (So  <span class="math">u_i&#x27;&#x27;</span>  has the same distribution as  <span class="math">u_i</span> .) The vertices  <span class="math">u_1&#x27;&#x27;, \\ldots, u_r&#x27;&#x27;</span>  are independently distributed and also independent from the  <span class="math">u_i&#x27;</span> 's. However, we will introduce some correlations among  <span class="math">u_1&#x27;, \\ldots, u_r&#x27;</span> . Specifically, if  <span class="math">u_i&#x27;</span>  is not right-free,  <span class="math">i \\le r - 1</span> , then  <span class="math">u_{i+1}&#x27;</span>  must be (with probability 1) the other endpoint of the edge in  <span class="math">E_{i+1}</span>  adjacent to  <span class="math">u_i&#x27;</span> ; otherwise, if  <span class="math">u_i&#x27;</span>  is right-free,  <span class="math">u_{i+1}&#x27;</span>  should be left-free. To see that random variables  <span class="math">u_1&#x27;, \\ldots, u_r&#x27;</span>  really can be defined with this property (including the fact that  <span class="math">u_i&#x27;</span>  is, individually, uniform in shore i) we imagine the following experiment: first  <span class="math">u_1&#x27;</span>  is chosen uniformly at random from shore 1; if</p>

    <p class="text-gray-300"><span class="math">u&#x27;_1</span>  is adjacent to an edge in  <span class="math">E_2</span> ,  <span class="math">u&#x27;_2</span>  is defined as the other endpoint of that edge; otherwise  <span class="math">u&#x27;_2</span>  is chosen uniformly at random from the set of left-free vertices in shore 2, and so on (with the sampling of  <span class="math">u&#x27;_3</span>  depending on whether  <span class="math">u&#x27;_2</span>  is right-free or not). It is easy to see by induction on the shore index that each  <span class="math">u&#x27;_i</span>  is uniformly distributed in its shore. (One can reflect that  <span class="math">u&#x27;_1, \\ldots, u&#x27;_r</span>  have a very similar distribution to the &quot;real path&quot; vertices  <span class="math">w_1, \\ldots, w_r</span>  defined above, except for the fact that  <span class="math">u&#x27;_1</span>  might not be left-free in G, while  <span class="math">w_1</span>  is always left-free in G.)</p>

    <p class="text-gray-300">We next define a vertex  <span class="math">u_i&#x27;&#x27;&#x27;</span>  which is a deterministic function of  <span class="math">u_i&#x27;</span>  and  <span class="math">u_i&#x27;&#x27;</span> . Specifically,  <span class="math">u_i&#x27;&#x27;&#x27;</span>  is defined as being  <span class="math">u_i&#x27;</span>  if  <span class="math">u_i&#x27;</span>  is left-free, and is defined as being  <span class="math">u_i&#x27;&#x27;</span>  otherwise. Thus  <span class="math">u_i&#x27;&#x27;&#x27;</span>  is always left-free, like  <span class="math">u_i</span> .</p>

    <p class="text-gray-300">We next argue that  <span class="math">u_1&#x27;&#x27;&#x27;, \\ldots, u_r&#x27;&#x27;&#x27;</span>  are independent, despite the dependencies among  <span class="math">u_1&#x27;, \\ldots, u_r&#x27;</span> . To see this it's sufficient to argue that  <span class="math">u_i&#x27;&#x27;&#x27;</span>  is independent from  <span class="math">u_1&#x27;&#x27;&#x27;, \\ldots, u_{i-1}&#x27;&#x27;&#x27;</span> . If  <span class="math">u_{i-1}&#x27;</span>  is right-free then  <span class="math">u_i&#x27;&#x27;&#x27; = u_i&#x27;&#x27;</span>  and this is again obvious. Hence  <span class="math">u_1&#x27;&#x27;&#x27;, \\ldots, u_r&#x27;&#x27;&#x27;</span>  are independent.</p>

    <p class="text-gray-300">Since  <span class="math">u_1&#x27;&#x27;&#x27;, \\ldots, u_r&#x27;&#x27;&#x27;</span>  are independent they are equidistributed with  <span class="math">u_1, \\ldots, u_r</span> . In fact, we will identify  <span class="math">u_i</span>  with  <span class="math">u_i&#x27;&#x27;&#x27;</span> . That is, we will choose to think of the actual process whereby  <span class="math">u_1, \\ldots, u_r</span>  are sampled as being the following:  <span class="math">u_1&#x27;, \\ldots, u_r&#x27;</span>  and  <span class="math">u_1&#x27;&#x27;, \\ldots, u_r&#x27;&#x27;</span>  are sampled as described aboved; then we set  <span class="math">u_i := u_i&#x27;&#x27;&#x27;</span>  for  <span class="math">u_i&#x27;&#x27;&#x27;</span>  as defined above from  <span class="math">u_i&#x27;</span>  and  <span class="math">u_i&#x27;&#x27;</span> . Since  <span class="math">u_1&#x27;&#x27;&#x27;, \\ldots, u_r&#x27;&#x27;&#x27;</span>  are (totally) independent and since each  <span class="math">u_i&#x27;&#x27;&#x27;</span>  is uniformly distributed among all left-free vertices in shore i, this definition of  <span class="math">u_1, \\ldots, u_r</span>  produces an identical random experiment. Having identified  <span class="math">u_i&#x27;&#x27;&#x27;</span>  with  <span class="math">u_i</span> , we will make no further mention of  <span class="math">u_1&#x27;&#x27;&#x27;, \\ldots, u_r&#x27;&#x27;&#x27;</span> , these being replaced by  <span class="math">u_1, \\ldots, u_r</span> . To summarize,  <span class="math">u_i&#x27;</span>  is the &quot;primary choice&quot; for  <span class="math">u_i</span> , and if this primary choice fails (because it is not left-free),  <span class="math">u_i</span>  falls back onto the &quot;secondary choice&quot;  <span class="math">u_i&#x27;&#x27;</span> , which is left-free by design.</p>

    <p class="text-gray-300">We define events  <span class="math">\\triangle_{ij}</span>  and  <span class="math">\\square_{ij}</span>  with respect to  <span class="math">u&#x27;_i</span>  and  <span class="math">u&#x27;&#x27;_i</span>  the same way  <span class="math">\\odot_{ij}</span>  is defined with respect to  <span class="math">u_i</span> . More precisely, for  <span class="math">0 \\le i &lt; j \\le r+1</span> , the event  <span class="math">\\triangle_{ij}</span>  occurs if  <span class="math">u&#x27;_h \\in U_{ij}</span>  for any  <span class="math">i \\le h \\le j</span> . Note that if  <span class="math">u&#x27;_h \\in U_{ij}</span>  for some h in the range  <span class="math">i \\le h \\le j</span> , then  <span class="math">u&#x27;_z \\in U_{ij}</span>  for all h in the range  <span class="math">\\max(1,i) \\le h \\le \\min(r,j)</span> , by the way the  <span class="math">u&#x27;_i</span> 's are defined. (We need  <span class="math">\\max(1,i)</span>  and  <span class="math">\\min(r,j)</span>  because  <span class="math">u&#x27;_0</span>  and  <span class="math">u&#x27;_{r+1}</span>  are not defined.) We note that it would make little sense to define an event such as  <span class="math">\\odot_{01}</span> , since  <span class="math">u_0</span>  is not defined, but it does make sense to define  <span class="math">\\triangle_{01}</span> , since  <span class="math">u&#x27;_1</span>  may or may not be in  <span class="math">U_{01}</span> . The definition of the  <span class="math">\\square_{ij}</span> 's is exactly analogous to the  <span class="math">\\odot_{ij}</span> 's: for  <span class="math">1 \\le i &lt; j \\le r+1</span> ,  <span class="math">\\square_{ij}</span>  occurs if  <span class="math">u&#x27;&#x27;_i</span>  is in  <span class="math">U_{ij}</span> .</p>

    <p class="text-gray-300">We note that (i)  <span class="math">\\triangle_{ij}</span>  is independent from  <span class="math">\\square_{i&#x27;j&#x27;}</span>  if  <span class="math">i \\neq i&#x27;</span> ; (ii)  <span class="math">\\triangle_{ij}</span>  is independent from  <span class="math">\\odot_{i&#x27;j&#x27;}</span>  if  <span class="math">i&#x27; \\neq i</span> ; (iii)  <span class="math">\\square_{ij}</span>  is independent from  <span class="math">\\odot_{i&#x27;j&#x27;}</span>  if  <span class="math">i&#x27; \\neq i</span> . We leave it to the reader to check these three facts, which can be argued using a similar case analysis as when we checked the independence of the  <span class="math">u&#x27;&#x27;&#x27;_{i&#x27;}</span> 's above.</p>

    <p class="text-gray-300">Note that for any  <span class="math">1 \\le i &lt; j \\le r+1</span>  one has</p>

    <p class="text-gray-300"><span class="math">$\\odot_{ij} = \\triangle_{ij} + \\sum_{x=0}^{i-1} \\triangle_{xi} \\square_{ij}</span>$</p>

    <p class="text-gray-300">because for the event  <span class="math">u_i \\in U_{ij}</span>  to occur we either need  <span class="math">u_i&#x27; \\in U_{ij}</span>  or else we need that  <span class="math">u_i&#x27;&#x27; \\in U_{ij}</span>  and that  <span class="math">u_i&#x27;</span>  is not left-free, which means that  <span class="math">u_i&#x27; \\in E_i = \\bigcup_{x=0}^{i-1} U_{xi}</span> , where the latter is a disjoint union. In fact, we even have the equality of events</p>

    <p class="text-gray-300"><span class="math">$\\odot_{ij} = \\triangle_{ij} + \\sum_{x=0}^{i-1} \\triangle_{xi} \\odot_{ij}. \\tag{36}</span>$</p>

    <p class="text-gray-300">because  <span class="math">\\triangle_{xi}\\square_{ij}</span>  if and only if  <span class="math">\\triangle_{xi}\\odot_{ij}</span>  for x &lt; i, as is easy to verify.</p>

    <p class="text-gray-300">Applying (36) to the first term  <span class="math">\\odot_{i_0i_1}</span>  in each product of (35) as well as to standalone term  <span class="math">\\odot_{r(r+)}</span>  on the left of (35) yields</p>

    <p class="text-gray-300"><span class="math">$\\otimes_{r(r+1)} = \\left( \\triangle_{r(r+1)} + \\sum_{x=0}^{r-1} \\triangle_{xr} \\odot_{r(r+1)} \\right)</span>$</p>

    <p class="text-gray-300"><span class="math">$\\begin{split} &amp;+ \\odot_{r(r+1)} \\sum_{y=1}^{r-1} \\sum_{\\sigma \\in \\mathfrak{S}_{yr}} (-1)^{|\\sigma|} \\left( \\triangle_{i_0 i_1} + \\sum_{x=0}^{i_0 - 1} \\triangle_{x i_0} \\odot_{i_0 i_1} \\right) \\prod_{h=2}^{|\\sigma|} \\odot_{i_{h-1} i_h} \\\\ &amp;= \\left( \\triangle_{r(r+1)} + \\sum_{x=0}^{r-1} \\sum_{\\sigma \\in \\mathfrak{S}_{yr}} (-1)^{|\\sigma|} \\triangle_{i_0 i_1} \\circ_{r(r+1)} \\right) \\\\ &amp;+ \\odot_{r(r+1)} \\sum_{y=1}^{r-1} \\sum_{\\sigma \\in \\mathfrak{S}_{yr}} (-1)^{|\\sigma|} \\triangle_{i_0 i_1} \\prod_{h=2}^{|\\sigma|} \\odot_{i_{h-1} i_h} \\\\ &amp;+ \\odot_{r(r+1)} \\sum_{y=1}^{r-1} \\sum_{\\sigma \\in \\mathfrak{S}_{yr}} (-1)^{|\\sigma|} \\left( \\sum_{x=0}^{i_0 - 1} \\triangle_{x i_0} \\odot_{i_0 i_1} \\right) \\prod_{h=2}^{|\\sigma|} \\odot_{i_{h-1} i_h} \\\\ &amp;= \\triangle_{r(r+1)} + \\odot_{r(r+1)} \\sum_{y=1}^{r-1} \\sum_{\\sigma \\in \\mathfrak{S}_{yr}} (-1)^{|\\sigma|} \\triangle_{i_0 i_1} \\prod_{h=2}^{|\\sigma|} \\odot_{i_{h-1} i_h} \\\\ &amp;+ \\odot_{r(r+1)} \\sum_{y=1}^{r-2} \\sum_{\\sigma \\in \\mathfrak{S}_{yr}} (-1)^{|\\sigma|} \\triangle_{i_0 i_1} \\prod_{h=2}^{|\\sigma|} \\odot_{i_{h-1} i_h} \\\\ &amp;+ \\odot_{r(r+1)} \\sum_{x=0}^{r-2} \\sum_{y=x+1} \\sum_{\\sigma \\in \\mathfrak{S}_{yr}} (-1)^{|\\sigma|} \\triangle_{x i_0} \\odot_{i_0 i_1} \\prod_{h=2}^{|\\sigma|} \\odot_{i_{h-1} i_h} \\\\ &amp;= \\triangle_{r(r+1)} - \\odot_{r(r+1)} \\sum_{y=1}^{r-1} \\sum_{\\sigma \\in \\mathfrak{S}_{yr}} (-1)^{|\\sigma|} \\triangle_{i_0 i_1} \\prod_{h=2}^{|\\sigma|} \\odot_{i_{h-1} i_h} \\\\ &amp;- \\odot_{r(r+1)} \\sum_{x=0}^{r-2} \\sum_{\\sigma \\in \\mathfrak{S}_{xr}, |\\sigma| \\geq 2} (-1)^{|\\sigma|} \\triangle_{i_0 i_1} \\prod_{h=2}^{|\\sigma|} \\odot_{i_{h-1} i_h} \\\\ &amp;= \\triangle_{r(r+1)} - \\odot_{r(r+1)} \\sum_{\\sigma \\in \\mathfrak{S}_{0r}} (-1)^{|\\sigma|} \\triangle_{i_0 i_1} \\prod_{h=2}^{|\\sigma|} \\odot_{i_{h-1} i_h} \\end{split}</span>$</p>

    <p class="text-gray-300">Taking probabilities, we finally obtain,  <span class="math">\\Pr[\\triangle_{ij}] = \\frac{|U_{ij}|}{N}</span>  and  <span class="math">\\Pr[\\odot_{ij}] = \\frac{|U_{ij}|}{N - |E_i|}</span> , and since  <span class="math">|U_{r(r+1)}| = 1</span> ,</p>

    <p class="text-gray-300"><span class="math">$\\Pr[\\bigotimes_{r(r+1)}] = \\frac{1}{N} - \\frac{1}{N - |E_r|} \\sum_{\\sigma \\in \\mathfrak{S}_{0r}} (-1)^{|\\sigma|} \\frac{|U_{i_0 i_1}|}{N} \\prod_{h=2}^{|\\sigma|} \\frac{|U_{i_{h-1} i_h}|}{N - |E_{i_{h-1}}|}</span>$
<span class="math">$= \\frac{1}{N} - \\frac{1}{N} \\sum_{\\sigma \\in \\mathfrak{S}_{0r}} (-1)^{|\\sigma|} \\prod_{h=1}^{|\\sigma|} \\frac{|U_{i_{h-1} i_h}|}{N - |E_{i_h}|}</span>$</p>

    <p class="text-gray-300">as claimed.</p>

    <p class="text-gray-300">Reflections on the proof of Lemma 1. As noted in the proof the vertices  <span class="math">u&#x27;_1, \\ldots, u&#x27;_r</span>  are always &quot;path-compatible&quot; with G, in the sense that if  <span class="math">u&#x27;_i</span>  is not right-free then  <span class="math">u&#x27;_{i+1}</span>  is the other endpoint of the edge to the right of  <span class="math">u&#x27;_i</span> . Moreover, it's not hard to see that if  <span class="math">w_i = u&#x27;_i</span>  for some i, then  <span class="math">w_j = u&#x27;_j</span>  for all  <span class="math">j \\geq i</span> , and in particular  <span class="math">w_r = u&#x27;_r</span> . For example, if  <span class="math">u&#x27;_1</span>  is left-free then  <span class="math">w_1 = u&#x27;_1 = u_1</span>  and  <span class="math">w_r = u&#x27;_r</span> . More</p>

    <p class="text-gray-300">generally, if there exists an  <span class="math">i \\leq r</span>  such that  <span class="math">w_i</span>  and  <span class="math">u&#x27;_i</span>  are both left-free in G, then  <span class="math">w_i = u&#x27;_i</span>  and  <span class="math">w_r = u&#x27;_r</span> . Conceptually, thus, the introduction of the &quot;primary choices&quot;  <span class="math">u&#x27;_1, \\ldots, u&#x27;_r</span>  can be seen as establishing a coupling<sup>8</sup> between the endpoint  <span class="math">u&#x27;_r</span>  of an &quot;ideal path&quot; in G (&quot;ideal&quot; because vertices are uniform in each shore, and in particular  <span class="math">u&#x27;_r</span>  is uniform in shore r) and the endpoint  <span class="math">w_r</span>  of the &quot;real path&quot;.</p>

    <p class="text-gray-300">While the proof of Lemma 1 can indeed be recast, with appropriate changes, as a coupling argument, the current proof isn't a coupling, technically speaking. More exactly, a coupling argument consists (philosophically at least) in &quot;deforming&quot; the probability space underlying a &quot;real&quot; random variable to better compare the behavior of the &quot;real&quot; random variable with that of an &quot;ideal&quot; random variable (whereby the two probability spaces become &quot;aligned&quot; or &quot;almost aligned&quot;). In the proof of Lemma 1 we carry through the deformation (or alignment) but eschew the comparison with the &quot;ideal&quot; random variable. Indeed, we don't need to compare against the &quot;ideal&quot; random variable when we can exactly compute the &quot;real&quot; random variable probability of interest to us!</p>

    <p class="text-gray-300">FINISHING THE PROOF OF THEOREM 1. We now apply Lemma 1 to lower bounding the product (24). For  <span class="math">1 \\le r \\le t</span> , let</p>

    <p class="text-gray-300"><span class="math">$\\mathcal{L}_r = \\{\\ell : \\mathsf{L}(y_\\ell) - \\mathsf{R}(x_\\ell) = r\\} \\subseteq \\{1, \\dots, q_e\\}</span>$</p>

    <p class="text-gray-300">where (we recall) the elements of  <span class="math">p_0</span>  are  <span class="math">(x_1, y_1), \\ldots, (x_{q_e}, y_{q_e})</span> . By the definition of  <span class="math">\\mathcal{T}_2, \\mathcal{L}_1, \\ldots, \\mathcal{L}_t</span>  cover  <span class="math">\\{1, \\ldots, q_e\\}</span>  (i.e., there is no  <span class="math">\\ell</span>  with  <span class="math">\\mathsf{R}(x_\\ell) \\geq \\mathsf{L}(y_\\ell)</span> ). Assuming the event  <span class="math">G_\\ell \\downarrow p_0</span> , we apply Lemma 1 with the graph G obtained by removing shores  <span class="math">1, \\ldots, \\mathsf{R}(x_{\\ell+1}) - 1, \\mathsf{L}(y_{\\ell+1}) + 1, \\ldots, t</span>  from  <span class="math">G_\\ell</span> , and also (mainly for convenience) removing completed paths between  <span class="math">x_h</span>  and  <span class="math">y_h</span>  for  <span class="math">1 \\leq h \\leq \\ell</span> . (Thus the shores of G will have size  <span class="math">N - \\ell</span> , not N. Indeed, we committed a white lie when we stated in Lemma 1 that the shores of G would be copies of  <span class="math">\\{0,1\\}^n</span> . Of course, all that mattered was the size of those shores, and we can apply Lemma 1 by replacing N with  <span class="math">N - \\ell</span>  throughout in the main bound.) Also,  <span class="math">u = \\mathsf{R}(x_{\\ell+1})</span> ,  <span class="math">v = \\mathsf{L}(y_{\\ell+1})</span> . We note that with this definition of G,  <span class="math">|U_{ij}| \\leq |Z_{(i+\\mathsf{R}(x_{\\ell+1}))(j+\\mathsf{R}(x_{\\ell+1}))}| \\leq Cq^{j-i}/N^{j-i-1}</span>  (by the definition of  <span class="math">\\mathcal{T}_2</span> ) for  <span class="math">0 \\leq i &lt; j \\leq t</span> , and  <span class="math">|E_i| \\leq q</span>  for  <span class="math">1 \\leq i \\leq r</span> . Thus for  <span class="math">\\ell + 1 \\in \\mathcal{L}_r</span>  we obtain, by Lemma 1,</p>

    <p class="text-gray-300"><span class="math">$\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_{\\ell} \\downarrow p_{0}] = \\frac{1}{N - \\ell} - \\frac{1}{N - \\ell} \\sum_{\\sigma \\in \\mathfrak{S}_{0r}} (-1)^{|\\sigma|} \\prod_{h=1}^{|\\sigma|} \\frac{|U_{i_{h-1}i_{h}}|}{N - \\ell - |E_{i_{h}}|}</span>$</p>

    <p class="text-gray-300"><span class="math">$\\geq \\frac{1}{N - \\ell} - \\frac{1}{N - \\ell} \\sum_{\\sigma \\in \\mathfrak{S}_{0r}} \\prod_{h=1}^{|\\sigma|} \\frac{Cq^{i_{h} - i_{h-1}}/N^{i_{h} - i_{h-1} - 1}}{N - \\ell - q}</span>$</p>

    <p class="text-gray-300"><span class="math">$= \\frac{1}{N - \\ell} - \\frac{1}{N - \\ell} 2^{r-1} \\left(\\frac{q}{N}\\right)^{r} \\left(\\frac{CN}{N - \\ell - q}\\right)^{|\\sigma|}</span>$</p>

    <p class="text-gray-300"><span class="math">$\\geq \\frac{1}{N - \\ell} - \\frac{1}{N - \\ell} \\left(\\frac{2q}{N}\\right)^{r} \\left(\\frac{CN}{N - 2q}\\right)^{r}</span>$</p>

    <p class="text-gray-300"><span class="math">$\\geq \\frac{1}{N - \\ell} - \\frac{1}{N - \\ell} \\left(\\frac{6Cq}{N}\\right)^{r}.</span>$</p>

    <p class="text-gray-300"><sup>&amp;</sup>lt;sup&gt;8</sup> This remark is made for the benefit of readers who know what couplings are. Basically, random variables X and Y defined on a common probability space and having a common range are &quot;coupled&quot; if some special effort has been made to define X and Y in such way that  <span class="math">\\Pr[X \\neq Y]</span>  is small, while preserving predefined distributions of X and Y over their ranges. Doing a coupling is useful because one has, among others, that  <span class="math">\\Delta(X,Y) \\leq \\Pr[X \\neq Y]</span>  for any X, Y defined over the same probability space (without the latter condition, the expression  <span class="math">\\Pr[X \\neq Y]</span>  doesn't makes sense).</p>

    <p class="text-gray-300">Moreover  <span class="math">|\\mathcal{L}_r| \\leq t \\cdot \\frac{Cq_e q^{t-r}}{N^{t-r}}</span>  by the definition of  <span class="math">\\mathcal{T}_2</span> , so</p>

    <p class="text-gray-300"><span class="math">$\\prod_{\\ell+1\\in\\mathcal{L}_r} \\frac{\\Pr[x_{\\ell+1} \\to y_{\\ell+1}|G_{\\ell} \\downarrow p_0]}{1/(N-\\ell)} \\ge \\prod_{\\ell+1\\in\\mathcal{L}_r} \\left(1 - \\left(\\frac{6Cq}{N}\\right)^r\\right)</span>$</p>

    <p class="text-gray-300"><span class="math">$\\ge 1 - \\frac{Ctq_eq^{t-r}}{N^{t-r}} \\left(\\frac{6Cq}{N}\\right)^r</span>$</p>

    <p class="text-gray-300"><span class="math">$= 1 - \\frac{Ctq_eq^t}{N^t} (6C)^r</span>$</p>

    <p class="text-gray-300">Thus</p>

    <p class="text-gray-300"><span class="math">$\\prod_{\\ell=0}^{q_e-1} \\frac{\\Pr[x_{\\ell+1} \\to y_{\\ell+1} | G_{\\ell} \\downarrow p_0]}{1/(N-\\ell)} \\ge 1 - \\sum_{r=1}^t \\frac{Ctq_eq^t}{N^t} (6C)^r</span>$
<span class="math">$\\ge 1 - \\frac{q_eq^t}{N^t} Ct^2 (6C)^t.</span>$</p>

    <p class="text-gray-300">This means</p>

    <p class="text-gray-300"><span class="math">$\\frac{\\Pr[X = \\tau]}{\\Pr[Y = \\tau]} \\ge 1 - \\varepsilon_1</span>$</p>

    <p class="text-gray-300">for  <span class="math">\\varepsilon_1 = \\frac{q_e q^t}{N^t} C t^2 (6C)^t</span> , for all  <span class="math">\\tau \\in \\mathcal{T}_1</span>  such that  <span class="math">\\Pr[Y = \\tau] &gt; 0</span> . Having already established that  <span class="math">\\Pr[Y \\in \\mathcal{T}_2] \\leq (t+1)^2 \\frac{1}{C}</span> , this concludes the proof of Theorem 1 by (10).</p>

    </section>

    <section id="references" class="mb-10">
      <h2 class="text-2xl font-bold">References</h2>

    <ul class="space-y-2 text-gray-400 text-sm list-none">
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>Elena Andreeva, Andrey Bogdanov, Yevgeniy Dodis, Bart Mennink, John Steinberger, Indifferentiability of Key-Alternating Ciphers.</li>
    </ul></li>
      <li><p class="text-gray-300">Andrey Bogdanov, Lars R. Knudsen, Gregor Leander, Francois-Xavier Standaert, John Steinberger and Elmar Tischhauser, Key-Alternating Ciphers in a Provable Setting: Encryption Using a Small Number of Public Permutations. EUROCRYPT 2012, LNCS 7237, pp., Springer-Verlag, 2012.</p></li>
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>Shan Chen and John Steinberger, Tight Security Bounds for Key-Alternating Ciphers. Eurocrypt 2014 (proceedings version of this paper).</li>
    </ul></li>
      <li><p class="text-gray-300">Joan Daemen, Limitations of the Even-Mansour Construction. ASIACRYPT 1991, LNCS 739, pp. 495-498, Springer-Verlag, 1991.</p></li>
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>Joan Daemen and Vincent Rijmen, The Design of Rijndael. Springer-Verlag, 2002.</li>
    </ul></li>
      <li><p class="text-gray-300">Joan Daemen and Vincent Rijmen, The Wide Trail Design Strategy. IMA Int. Conf., LNCS 2260, pp. 222-238, Springer-Verlag, 2001.</p></li>
      <li><p class="text-gray-300">Shimon Even and Yishay Mansour, A Construction of a Cipher From a Single Pseudorandom Permutation. ASI-ACRYPT 1991, LNCS 739, pp. 210&ndash;224, Springer-Verlag, 1993.</p></li>
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>Shimon Even and Yishay Mansour, A Construction of a Cipher from a Single Pseudorandom Permutation. J. Cryptology, vol. 10, num. 3, pp. 151-162, 1997.</li>
    </ul></li>
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>Peter Ga&#382;i and Stefano Tessaro, Efficient and optimally secure key-length extension for block ciphers via randomized cascading. EUROCRYPT 2012, Lecture Notes in Computer Science volume 7237, pp 63-80, 2012.</li>
    </ul></li>
      <li><p class="text-gray-300">Peter Ga&#382;i, Plain versus Randomized Cascading-Based Key-Length Extension for Block Ciphers, CRYPTO 2013, Lecture Notes in Computer Science Volume 8042, pp 551&ndash;570, 2013.</p></li>
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>Peter Ga&#382;i, Plain versus Randomized Cascading-Based Key-Length Extension for Block Ciphers http://eprint.iacr.org/2013/019.pdf. Full version of [10].</li>
    </ul></li>
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>Joe Kilian and Phillip Rogaway, How to protect DES against exhaustive key search (an analysis of DESX). Journal of Cryptology 14 (1), 17-35 (2001).</li>
    </ul></li>
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>Rudolphe Lampe, Jacques Patarin and Yannick Seurin, An Asymptotically Tight Security Analysis of the Iterated Even-Mansour Cipher, Asiacrypt 2012, Lecture Notes in Computer Science Volume 7658, pp 278-295, 2012.</li>
    </ul></li>
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>Rudolphe Lampe and Yannick Seurin. How to Construct an Ideal Cipher from a Small Set of Public Permutations, Asiacrypt 2013.</li>
    </ul></li>
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>Michael Luby and Charles Rackoff, How to Construct Pseudorandom Permutations from Pseudorandom Functions. SIAM J. Comput., vol. 17, num. 2, pp. 373-386, 1988.</li>
    </ul></li>
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>Ueli Maurer and Krzysztof Pietrzak, Composition of Random Systems: When Two Weak Make One Strong. TCC 2004, LNCS 2951, pp. 410427, Feb 2004.</li>
    </ul></li>
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>Ueli Maurer, Krzysztof Pietrzak and Renato Renner: Indistinguishability Amplification. CRYPTO 2007, LNCS 4622, pp. 130149, 2007.</li>
    </ul></li>
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>Jacques Patarin, The &quot;Coefficients H&quot; Technique, Selected Areas in Cryptography, LNCS 5381, 2009, pp. 328-345.</li>
    </ul></li>
      <li><ul class="space-y-2 text-gray-400 text-sm list-none">
      <li>John Steinberger, Improved Security Bounds for Key-Alternating Ciphers via Hellinger Distance, http://eprint.iacr.org/2012/481.pdf.</li>
    </ul></li>
    </ul>

    </section>
`;
---

<BaseLayout title="Tight security bounds for key-alternating ciphers (2013/222)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2013 &middot; eprint 2013/222
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <PaperDisclaimer eprintUrl={EPRINT_URL} />
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

    <PaperHistory slug="tight-security-bounds-for-key-alternating-ciphers-2013" />
  </article>
</BaseLayout>
