---
import BaseLayout from '../../layouts/BaseLayout.astro';
import PaperDisclaimer from '../../components/PaperDisclaimer.astro';
import PaperHistory from '../../components/PaperHistory.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2019/750';
const CRAWLER = 'marker';
const CONVERTED_DATE = '2026-02-14';
---

<BaseLayout title="Weight Probability Distribution for SPNs (2019/750)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <!-- ============================================================ -->
    <!-- HEADER                                                       -->
    <!-- ============================================================ -->

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4">
        A Short Note on a Weight Probability Distribution
        Related to SPNs
      </h1>
      <p class="text-gray-400 mb-2">
        Sondre R&oslash;njom
      </p>
      <p class="text-gray-500 text-sm mb-4">
        2019 &middot; Full Version &middot; eprint 2019/750
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <PaperDisclaimer eprintUrl={EPRINT_URL} />
      <p class="mt-1 text-xs text-gray-600">Converted with: {CRAWLER} &middot; {CONVERTED_DATE}</p>
    </header>

    <!-- ============================================================ -->
    <!-- TABLE OF CONTENTS                                            -->
    <!-- ============================================================ -->

    <nav id="toc" class="mb-10 p-6 rounded-lg"
      style="background: rgba(255,255,255,0.03);
             border: 1px solid rgba(255,255,255,0.06);">
      <h2 class="text-lg font-bold mb-4">Table of Contents</h2>
      <ol class="space-y-1 text-sm text-gray-300
        list-decimal list-inside">
        <li>
          <a href="#abstract"
            class="hover:text-white">Abstract</a>
        </li>
        <li>
          <a href="#sec-1"
            class="hover:text-white">Introduction</a>
        </li>
        <li>
          <a href="#sec-2"
            class="hover:text-white">
            Weight Probability Distributions in AES</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li>
              <a href="#sec-2.1"
                class="hover:text-white">
                A <span class="math">2^&#123;16&#125; \times
                2^&#123;16&#125;</span> Transition Probability
                Matrix for Active Bytes</a>
            </li>
            <li>
              <a href="#sec-2.2"
                class="hover:text-white">
                The Weight Transition Probability</a>
            </li>
          </ol>
        </li>
        <li>
          <a href="#sec-3"
            class="hover:text-white">Some Results</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li>
              <a href="#sec-3.1"
                class="hover:text-white">
                Aligning With Recent Results on AES</a>
            </li>
            <li>
              <a href="#sec-3.2"
                class="hover:text-white">
                Weight Distributions Biased in Opposite
                Directions</a>
            </li>
          </ol>
        </li>
        <li>
          <a href="#sec-4"
            class="hover:text-white">
            Possible Further Research</a>
          <ol class="ml-6 mt-1 space-y-1 list-decimal
            list-inside text-gray-400">
            <li>
              <a href="#sec-4.1"
                class="hover:text-white">
                Linear Optimization</a>
            </li>
            <li>
              <a href="#sec-4.2"
                class="hover:text-white">
                Markov Chains and Stochastic Matrices</a>
            </li>
            <li>
              <a href="#sec-4.3"
                class="hover:text-white">
                Rate of Convergence</a>
            </li>
            <li>
              <a href="#sec-4.4"
                class="hover:text-white">
                The Effect of the S-box</a>
            </li>
            <li>
              <a href="#sec-4.5"
                class="hover:text-white">
                Testing Ciphers</a>
            </li>
          </ol>
        </li>
        <li>
          <a href="#sec-5"
            class="hover:text-white">Conclusion</a>
        </li>
      </ol>
      <p class="text-xs text-gray-500 mt-4 mb-1 font-semibold">
        Additional
      </p>
      <ul class="space-y-1 text-sm text-gray-400 list-disc
        list-inside">
        <li>
          <a href="#references"
            class="hover:text-white">References</a>
        </li>
      </ul>
    </nav>

    <!-- ============================================================ -->
    <!-- ABSTRACT                                                     -->
    <!-- ============================================================ -->

    <section id="abstract" class="mb-10">
      <h2 class="text-2xl font-bold">Abstract</h2>
      <p class="text-gray-300">
        We report on a simple technique that supports some recent
        developments on AES by Grassi and Rechberger and Bao, Guo and
        List. We construct a weight transition probability matrix
        related to AES that characterises fixed configurations of
        active bytes in differences of ciphertexts when plaintext
        differences are fixed to some (possibly other) configuration
        of active bytes. The construction is very simple and requires
        only a little bit of linear algebra. The derived probabilities
        are essentially identical to recent results on 5- and 6-round
        AES derived through more sophisticated means, indicating that
        it might be worth a further investigation.
      </p>
    </section>

    <!-- ============================================================ -->
    <!-- 1 INTRODUCTION                                               -->
    <!-- ============================================================ -->

    <section id="sec-1" class="mb-10">
      <h2 class="text-2xl font-bold">1 Introduction</h2>
      <p class="text-gray-300">
        We consider transition probability distributions related to
        active bytes in differences of ciphertexts and plaintexts in
        AES. The objective is to determine whether the probability
        distribution for configurations of active bytes in ciphertext
        differences vary depending on the distribution of
        configurations of active bytes in the plaintexts. We show how
        to utilize symmetries in the AES Mix-Column matrix to
        construct efficient (small) transition matrices for
        <span class="math">r</span> rounds of AES where
        <span class="math">r</span> is any number of rounds. The
        results and techniques are very simple and require only a
        little bit of linear algebra. We are unable to prove how exact
        these transition probability matrices emulate the true AES
        distributions, however, we can confirm that our method obtains
        results that seem to be identical to recent results reported
        with more sophisticated analysis, presented in several recent
        papers on 5- and 6-round distinguishers for AES (e.g. [BGL19],
        [Gra18], [GRR17] and [GR18]). In particular, probabilities derived from
        the weight transition probability matrix matches the results
        recently presented by Bao, Guo and List in [BGL19] on 5- and
        6-round AES and Grassi and Rechberger in [GR18] on 5-round AES.
        This may support the view that, as long as the s-box is
        sufficiently generic (e.g. not linear), the s-box layer has
        little effect on this kind of structural analysis. It is thus
        tempting to conjecture that the presented weight transition
        probability matrix emulates the true AES-distributions.
      </p>
      <p class="text-gray-300 text-sm mt-2">
        Simple C/C++ code for experimenting with and verifying our
        results can be found at
        <a href="https://github.com/sondrer/SPNTransitionProbability"
          target="_blank" rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300">
          github.com/sondrer/SPNTransitionProbability</a>.
      </p>
    </section>

    <!-- ============================================================ -->
    <!-- 2 WEIGHT PROBABILITY DISTRIBUTIONS IN AES                    -->
    <!-- ============================================================ -->

    <section id="sec-2" class="mb-10">
      <h2 class="text-2xl font-bold">
        2 Weight Probability Distributions in AES
      </h2>
      <p class="text-gray-300">
        One round of AES [DR02] consists of four steps. First, a
        non-linear permutation SubBytes is applied to each individual
        byte of the state. Then each row is shifted cyclically via
        ShiftRows, followed by applying a fixed linear transformation
        <span class="math">M \in \mathbb&#123;F&#125;_&#123;2^8&#125;^&#123;4 \times 4&#125;</span>
        to each column (MixColumns). In the end a fixed round-key is
        added to the whole state (AddKey).
      </p>
      <p class="text-gray-300">
        We view states in AES in terms of the SuperBox representation,
        i.e. as a collection of vectors
        <span class="math">S = (s_0, s_1, s_2, s_3) \in (\mathbb&#123;F&#125;_&#123;2^8&#125;^4)^4</span>
        corresponding to the columns of the AES state. To each state
        we associate a vector
        <span class="math">\nu(S) \in (\mathbb&#123;F&#125;_2^4)^4</span>
        which indicates the active bytes in each column
        <span class="math">s_i</span> of the state. Let
        <span class="math">\rho(s_i) \in \mathbb&#123;F&#125;_2^4</span>
        denote this vector which is 1 in position
        <span class="math">i</span> if the
        <span class="math">i</span>'th byte of the vector
        <span class="math">s_i</span> is non-zero such that the
        vector defined as
      </p>
      <div class="math-block">
        \nu(S) = (\rho(s_0), \rho(s_1), \rho(s_2), \rho(s_3))
        \tag&#123;1&#125;
      </div>
      <p class="text-gray-300">
        is the configuration of active bytes for a state
        <span class="math">S</span>. We also use a vector
      </p>
      <div class="math-block">
        \wp(S) = (\text&#123;wt&#125;(s_0), \text&#123;wt&#125;(s_1),
        \text&#123;wt&#125;(s_2), \text&#123;wt&#125;(s_3))
        \tag&#123;2&#125;
      </div>
      <p class="text-gray-300">
        to identify the weights of the columns of a state. To simplify
        the notation we treat vectors also as integers, i.e.
        <span class="math">c \in \mathbb&#123;F&#125;_2^4</span> is
        also treated as an integer
        <span class="math">\sum_&#123;i=0&#125;^3 c_i \cdot 2^i</span>,
        <span class="math">u \in (\mathbb&#123;F&#125;_2^4)^4</span>
        as the integer
        <span class="math">\sum_&#123;i=0&#125;^3 \left(\sum_&#123;j=0&#125;^3 c_j \cdot 2^j\right) 16^j</span>,
        and
        <span class="math">a \in \mathbb&#123;Z&#125;_5^4</span> as
        an integer
        <span class="math">\sum_&#123;i=0&#125;^3 a_i \cdot 5^i</span>.
        The indices of the matrices will then correspond naturally to
        configurations of active bytes and weights and are then easily
        derived from each other.
      </p>

      <!-- ========================================================== -->
      <!-- 2.1 A 2^16 x 2^16 TRANSITION PROBABILITY MATRIX            -->
      <!-- ========================================================== -->

      <h3 id="sec-2.1" class="text-xl font-semibold mt-8">
        2.1 A <span class="math">2^&#123;16&#125; \times
        2^&#123;16&#125;</span> Transition Probability Matrix for
        Active Bytes
      </h3>
      <p class="text-gray-300">
        The MixColumns matrix
        <span class="math">M \in \mathbb&#123;F&#125;_&#123;2^8&#125;^&#123;4 \times 4&#125;</span>
        is applied to each column of the state. We are interested in
        the transition probabilities for active bytes through
        <span class="math">M</span>, i.e. for two binary vectors
        <span class="math">u, v \in \mathbb&#123;F&#125;_2^4</span>
        let
      </p>
      <div class="math-block">
        T_&#123;\mathcal&#123;M&#125;&#125;(u, v) =
        \Pr(\rho(x \cdot \mathcal&#123;M&#125;) = v \mid
        \rho(x) = u)
        \tag&#123;3&#125;
      </div>
      <p class="text-gray-300">
        denote the probability that a vector
        <span class="math">x \cdot M</span> is non-zero in byte
        positions indicated by the 1's in
        <span class="math">v</span> when
        <span class="math">x</span> is non-zero in positions
        indicated by the 1's in <span class="math">u</span>. The
        matrix <span class="math">M</span> in AES is derived from a
        linear
        <span class="math">[8,4,5]</span> MDS code over
        <span class="math">\mathbb&#123;F&#125;_&#123;2^8&#125;</span>.
        We have computed the transition probabilities exhaustively, but
        there exist explicit formulas for the weight distribution of
        MDS codes that simplifies this for the general case. There are
        in total 16 different configurations of active bytes at the
        input and 16 configurations of active output bytes, so
        <span class="math">T_M \in \mathbb&#123;R&#125;^&#123;16 \times 16&#125;</span>.
        Let
        <span class="math">u, v \in \mathbb&#123;F&#125;_2^4</span>
        and let <span class="math">Z</span> denote the
        <span class="math">16 \times 16</span> matrix where
        <span class="math">Z(u, v)</span> counts the number of
        elements
        <span class="math">x \in \mathbb&#123;F&#125;_&#123;2^8&#125;^4</span>
        with active bytes in positions indicated by
        <span class="math">u</span> and where
        <span class="math">y = x \cdot M</span> have active bytes
        indicated by <span class="math">v</span>. The state
        transition for a column through the MixColumns layer is then
        as follows.
      </p>
      <p class="text-gray-300 text-sm mt-2">
        Table for <span class="math">Z</span> can be found at
        <a href="https://github.com/sondrer/SPNTransitionProbability"
          target="_blank" rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300">
          github.com/sondrer/SPNTransitionProbability</a>.
      </p>

      <div class="formal-block formal-block-definition">
        <div class="formal-block-title text-blue-400">
          Definition 1
        </div>
        <div class="formal-block-content">
          <p class="text-gray-300">
            Let
            <span class="math">T_M \in \mathbb&#123;R&#125;^&#123;16 \times 16&#125;</span>
            denote the transition probability matrix for active bytes
            over the MixColumn
            <span class="math">M</span> with entries
          </p>
          <div class="math-block">
            T_&#123;M&#125;(u, v) =
            \frac&#123;Z(u, v)&#125;&#123;(2^&#123;8&#125; - 1)^&#123;\text&#123;wt&#125;(u)&#125;&#125;
            \tag&#123;4&#125;
          </div>
          <p class="text-gray-300">
            for indicators
            <span class="math">u, v \in \mathbb&#123;F&#125;_2^4</span>
            for configurations of active bytes.
          </p>
        </div>
      </div>

      <p class="text-gray-300">
        Since the MC-layer applies the matrix
        <span class="math">M</span> to each column individually, it
        is now straight-forward to construct a transition probability
        matrix for the whole MC-layer. The MC-layer maps an input
        state
        <span class="math">x = (x_0, x_1, x_2, x_3) \in (\mathbb&#123;F&#125;_&#123;2^8&#125;^4)^4</span>
        to an output state
        <span class="math">y = (y_0, y_1, y_2, y_3)</span> where
      </p>
      <div class="math-block">
        y_i = \text&#123;MC&#125;(x)_i
        \tag&#123;5&#125;
      </div>
      <div class="math-block">
        = x_i \cdot \mathbf&#123;M&#125;
        \tag&#123;6&#125;
      </div>
      <p class="text-gray-300">
        thus we have the following trivial extension.
      </p>

      <div class="formal-block formal-block-definition">
        <div class="formal-block-title text-blue-400">
          Definition 2
        </div>
        <div class="formal-block-content">
          <p class="text-gray-300">
            For vectors
            <span class="math">u, v \in (\mathbb&#123;F&#125;_2^4)^4</span>
            indicating the active bytes in each column, let a matrix
            <span class="math">T_&#123;\mathrm&#123;MC&#125;&#125; \in \mathbb&#123;R&#125;^&#123;2^&#123;16&#125; \times 2^&#123;16&#125;&#125;</span>
            with entries
          </p>
          <div class="math-block">
            T_&#123;\text&#123;MC&#125;&#125;(u, v) =
            \Pr(\nu(\text&#123;MC&#125;(x)) = v \mid \nu(x) = u)
            \tag&#123;7&#125;
          </div>
          <div class="math-block">
            = \prod_&#123;i=0&#125;^&#123;3&#125;
            \Pr(\rho(\text&#123;MC&#125;(x)_i) = v_i
            \mid \rho(x_i) = u_i)
          </div>
          <div class="math-block">
            = \prod_&#123;i=0&#125;^&#123;3&#125;
            T_M(u_i, v_i)
            \tag&#123;8&#125;
          </div>
          <div class="math-block">
            = \prod_&#123;i=0&#125;^&#123;3&#125;
            T_&#123;\mathcal&#123;M&#125;&#125;(u_i, v_i)
            \tag&#123;9&#125;
          </div>
          <p class="text-gray-300">
            denote the transition probability matrix for the full
            MixColumns layer in AES and where
            <span class="math">u, v</span> are also treated as
            indices
            <span class="math">0 \le u, v &lt; 2^&#123;16&#125;</span>
            and
            <span class="math">u_i, v_i</span> as indices
            <span class="math">0 \le u_i, v_i &lt; 16</span>.
          </p>
        </div>
      </div>

      <p class="text-gray-300">
        Similarly, let <span class="math">T_&#123;\text&#123;SR&#125;&#125;</span>
        denote the
        <span class="math">2^&#123;16&#125; \times 2^&#123;16&#125;</span>
        matrix with indices
      </p>
      <div class="math-block">
        T_&#123;\text&#123;SR&#125;&#125;(u, v) =
        \Pr(\nu(\text&#123;SR&#125;(y)) = v \mid \nu(x) = u)
        \tag&#123;10&#125;
      </div>
      <p class="text-gray-300">
        where the vectors
        <span class="math">u, v \in (\mathbb&#123;F&#125;_2^4)^4</span>
        are treated as indices in the range
        <span class="math">0 \le u, v &lt; 2^&#123;16&#125;</span>.
        The <span class="math">T_&#123;\text&#123;SR&#125;&#125;</span>
        matrix is a permutation matrix and has a single 1 in each row
        and column, hence there is no uncertainty associated with it.
        Notice also that the SubBytes layer corresponds to the
        identity map with regards to active bytes transition
        probabilities, thus this layer is disregarded (determining the
        real effect, if any, of the s-box layer is the main remaining
        open problem). We use the SuperBox representation, which means
        that we remove the first SR-layer in order to work with
        columns and may or may not remove the final linear layer. Then
        we define the following
        <span class="math">r</span>-round transition matrices for
        active bytes.
      </p>

      <div class="formal-block formal-block-definition">
        <div class="formal-block-title text-blue-400">
          Definition 3
        </div>
        <div class="formal-block-content">
          <p class="text-gray-300">
            Let
            <span class="math">T_&#123;\text&#123;MC&#125; \circ \text&#123;SR&#125;&#125; = T_&#123;\text&#123;SR&#125;&#125; \cdot T_&#123;\text&#123;MC&#125;&#125;</span>.
            Then define the <span class="math">r</span>-round
            transition probability matrix for active bytes as
          </p>
          <div class="math-block">
            T_&#123;f^r&#125; = T_&#123;\text&#123;MC&#125;&#125;
            \cdot T_&#123;\text&#123;MC&#125; \circ
            \text&#123;SR&#125;&#125;^&#123;r-1&#125;
            \tag&#123;11&#125;
          </div>
        </div>
      </div>

      <p class="text-gray-300">
        If the aim is solely to distinguish AES reduced to
        <span class="math">r</span> rounds, then since the adversary
        may remove the first SR layer and last
        <span class="math">\text&#123;MC&#125; \circ \text&#123;SR&#125;</span>-layer,
        the adversary can work with
        <span class="math">T_&#123;f^&#123;r-1&#125;&#125;</span>.
        If the aim is to construct an
        <span class="math">r</span>-round distinguisher in the hope
        to extend it to a
        <span class="math">(r+t)</span>-round key-recovery, the
        adversary may consider only removing the first SR-layer and
        thus work with the
        <span class="math">T_&#123;f^r&#125;</span>-matrix. The
        <span class="math">2^&#123;16&#125; \times 2^&#123;16&#125;</span>
        matrices are quite large, but in the next section we show how
        to compress them down to
        <span class="math">625 \times 625</span> weight transition
        probability matrices.
      </p>

      <!-- ========================================================== -->
      <!-- 2.2 THE WEIGHT TRANSITION PROBABILITY                       -->
      <!-- ========================================================== -->

      <h3 id="sec-2.2" class="text-xl font-semibold mt-8">
        2.2 The Weight Transition Probability
      </h3>
      <p class="text-gray-300">
        In this section we will construct a compressed weight
        transition probability that only depends on the Hamming weight
        of columns. The difference will be that we now only consider
        the number of active bytes in each column and do no longer
        have control over the exact active bytes. Thus, while the
        transition probability distributions derived from the previous
        matrices can be thought of as distributions for the exact
        configurations of active bytes in the state columns, we now
        only consider distributions on the number of active bytes
        (Hamming weight) of the state columns.
      </p>
      <p class="text-gray-300">
        The MixColumns matrix <span class="math">M</span> is
        symmetric with respect to weights in the sense that
      </p>
      <div class="math-block">
        T_&#123;\mathcal&#123;M&#125;&#125;(u, v) =
        T_&#123;\mathcal&#123;M&#125;&#125;(u', v')
        \tag&#123;12&#125;
      </div>
      <p class="text-gray-300">
        for any choice of
        <span class="math">u', v' \in \mathbb&#123;F&#125;_2^4</span>
        with
        <span class="math">\text&#123;wt&#125;(u) = \text&#123;wt&#125;(u')</span>
        and
        <span class="math">\text&#123;wt&#125;(v) = \text&#123;wt&#125;(v')</span>.
        The weight transition probabilities through the
        <span class="math">M</span>-matrix therefore depend only on
        the number, and not on the particular configuration, of active
        bytes. So we can construct a compressed weight transition
        probability matrix
        <span class="math">C_M \in \mathbb&#123;R&#125;^&#123;5 \times 5&#125;</span>
        for the matrix <span class="math">M</span> that satisfies
      </p>
      <div class="math-block">
        C_&#123;\mathcal&#123;M&#125;&#125;(a, b) =
        \Pr(\text&#123;wt&#125;(\mathcal&#123;MC&#125;(x)) = b
        \mid \text&#123;wt&#125;(x) = a)
        \tag&#123;13&#125;
      </div>
      <div class="math-block">
        = \sum_&#123;\substack&#123;v \in \mathbb&#123;F&#125;_2^4 \\
        \text&#123;wt&#125;(v) = b&#125;&#125;
        T_&#123;\text&#123;M&#125;&#125;(u, v)
        \tag&#123;14&#125;
      </div>
      <div class="math-block">
        = \binom&#123;4&#125;&#123;b&#125;
        T_&#123;\mathcal&#123;M&#125;&#125;(u', v')
        \tag&#123;15&#125;
      </div>
      <p class="text-gray-300">
        for weights <span class="math">a, b</span> and where
        <span class="math">v, u', v'</span> are any fixed vectors
        with
        <span class="math">\text&#123;wt&#125;(v) = \text&#123;wt&#125;(v') = b</span>
        and
        <span class="math">\text&#123;wt&#125;(u') = a</span>. This
        probability follows since there are
        <span class="math">\binom&#123;4&#125;&#123;\text&#123;wt&#125;(b)&#125;</span>
        possible byte configurations for a vector
        <span class="math">b \in \mathbb&#123;F&#125;_q^4</span> of
        weight <span class="math">\text&#123;wt&#125;(b)</span> at
        the output and for each of those the probability is
        <span class="math">T_&#123;\text&#123;M&#125;&#125;(a, b)</span>.
        We can now construct a
        <span class="math">625 \times 625</span> weight transition
        probability matrix
        <span class="math">C_&#123;\text&#123;MC&#125;&#125;</span>
        with entries
      </p>
      <div class="math-block">
        C_&#123;\text&#123;MC&#125;&#125;(u, v) =
        \prod_&#123;k=0&#125;^&#123;3&#125;
        C_&#123;M&#125;(u_k, v_k)
        \tag&#123;16&#125;
      </div>
      <p class="text-gray-300">
        which is the probability for a state
        <span class="math">S</span> with column weights
        <span class="math">\wp(S) = (u_0, u_1, u_2, u_3)</span> to
        map to a state with column weights
        <span class="math">\wp(\text&#123;MC&#125;(S)) = (v_0, v_1, v_2, v_3)</span>
        through the MixColumn layer.
      </p>
      <p class="text-gray-300">
        We may construct a weight transition matrix
        <span class="math">C_&#123;\text&#123;SR&#125;&#125;</span>
        for the ShiftRows layer in a similar fashion. For column
        weight indicators
        <span class="math">\wp(S) = u</span> and
        <span class="math">\wp(\text&#123;SR&#125;(S)) = v</span> the
        entries of this matrix are given by
      </p>
      <div class="math-block">
        C_&#123;\text&#123;SR&#125;&#125;(u, v) =
        \frac&#123;1&#125;&#123;\prod_&#123;j=0&#125;^&#123;3&#125;
        \binom&#123;4&#125;&#123;u_j&#125;&#125;
        \sum_&#123;\substack&#123;a, b \in
        (\mathbb&#123;F&#125;_2^4)^4 \\
        \text&#123;wt&#125;(a_i) = u_i \\
        \text&#123;wt&#125;(b_i) = v_i&#125;&#125;
        T_&#123;\text&#123;SR&#125;&#125;(a, b)
        \tag&#123;17&#125;
      </div>
      <p class="text-gray-300">
        The probability follows as the sum sums over all possible
        active byte configurations in the output while the first
        fraction averages over the number of possible byte
        configurations in the input. We can now construct weight
        transition probability matrices for
        <span class="math">r</span> rounds of AES.
      </p>

      <div class="formal-block formal-block-definition">
        <div class="formal-block-title text-blue-400">
          Definition 4
        </div>
        <div class="formal-block-content">
          <p class="text-gray-300">
            Let
            <span class="math">C_&#123;\text&#123;MC&#125; \circ \text&#123;SR&#125;&#125; = C_&#123;\text&#123;SR&#125;&#125; \cdot C_&#123;\text&#123;MC&#125;&#125;</span>.
            Then let
          </p>
          <div class="math-block">
            C_r = C_&#123;\text&#123;MC&#125;&#125; \cdot
            C_&#123;\text&#123;MC&#125; \circ
            \text&#123;SR&#125;&#125;^&#123;r-1&#125;
          </div>
          <p class="text-gray-300">
            denote the weight transition probability matrix for
            <span class="math">r</span> rounds of AES.
          </p>
        </div>
      </div>
    </section>

    <!-- ============================================================ -->
    <!-- 3 SOME RESULTS                                               -->
    <!-- ============================================================ -->

    <section id="sec-3" class="mb-10">
      <h2 class="text-2xl font-bold">3 Some Results</h2>
      <p class="text-gray-300">
        If
        <span class="math">a \in \mathbb&#123;R&#125;^&#123;625&#125;</span>
        denotes a weight probability distribution for the plaintext
        difference, then
        <span class="math">b = a \cdot C_&#123;r-1&#125;</span> is
        the weight distribution on the ciphertext differences after
        <span class="math">r</span> rounds, when the last linear
        layer is omitted (thus we focus on reduced round
        distinguishers). The uniform distribution is given by a vector
        <span class="math">q \in \mathbb&#123;R&#125;^&#123;625&#125;</span>
        of values
      </p>
      <div class="math-block">
        q_v = 2^&#123;-128&#125;
        \prod_&#123;i=0&#125;^&#123;3&#125;
        \binom&#123;4&#125;&#123;v_i&#125;
        (2^8 - 1)^&#123;v_i&#125;
      </div>
      <p class="text-gray-300">
        which is the probability that the output difference has weight
        pattern
        <span class="math">(v_0, v_1, v_2, v_3)</span> where
        <span class="math">v = \sum_&#123;i=0&#125;^3 v_i \cdot 5^i</span>
        regardless of the input. Now the goal is to determine vectors
        <span class="math">a, e \in \mathbb&#123;R&#125;^&#123;624&#125;</span>
        and investigate the sum
      </p>
      <div class="math-block">
        \sum_&#123;k=0&#125;^&#123;624&#125;
        (q_k - b_k) e_k
        \tag&#123;18&#125;
      </div>
      <p class="text-gray-300">
        The scaling vector <span class="math">e_k</span> is just an
        enforced weighting on the ciphertext distribution which the
        adversary can impose as he would like. If
        <span class="math">e_v</span> is zero, then ciphertext
        differences with a weight arrangement according to
        <span class="math">v</span> is ignored completely. For
        instance, if we only consider events in which the three last
        columns are zero, then we have to ignore roughly
        <span class="math">2^&#123;-96&#125;</span> ciphertexts
        until we receive a pair of ciphertexts with our preferred
        property. Thus, there is a penalty in terms of
        data-complexity if we fixate on events that seldom happen,
        unless the cipher itself has a very unlikely probability
        distribution.
      </p>
      <p class="text-gray-300">
        The matrices
        <span class="math">C_&#123;\text&#123;MC&#125;&#125;</span>,
        <span class="math">C_&#123;\text&#123;SR&#125;&#125;</span>
        and
        <span class="math">C_&#123;r-1&#125;</span> are easy to work
        with and thus we will now use
        <span class="math">C_&#123;r-1&#125;</span> to compute the
        probabilities corresponding to the same event as recently
        investigated in [BGL19] and [GR18].
      </p>

      <!-- ========================================================== -->
      <!-- 3.1 ALIGNING WITH RECENT RESULTS ON AES                     -->
      <!-- ========================================================== -->

      <h3 id="sec-3.1" class="text-xl font-semibold mt-8">
        3.1 Aligning With Recent Results on AES
      </h3>
      <p class="text-gray-300">
        To begin we have to define an input distribution
        <span class="math">a = (a_0, a_1, \ldots, a_&#123;624&#125;)</span>.
        For instance, if we assume that the input differences are
        non-zero and random in only the first column (remember that we
        are omitting the first SR-layer), we can let the 5 first
        indices of <span class="math">a</span> correspond to
      </p>
      <div class="math-block">
        a_i = \binom&#123;4&#125;&#123;i&#125; \cdot
        \frac&#123;(2^8 - 1)^i&#125;&#123;(2^&#123;32&#125; - 1)&#125;
      </div>
      <p class="text-gray-300">
        where <span class="math">a_i</span> for
        <span class="math">0 \le i &lt; 5</span> is the probability
        that we hit a difference with weight
        <span class="math">i</span> in the first column given that
        the plaintext difference is known to be non-zero only in the
        first column. The corresponding output distribution then
        becomes
        <span class="math">b = a \cdot C_&#123;r-1&#125;</span>. If
        we want to compute the probability that the output is
        non-zero in at least one column, we may sum over the
        probabilities that contribute to this case in the event of AES
      </p>
      <div class="math-block">
        p_&#123;\text&#123;AES&#125;&#125; =
        \sum_&#123;\substack&#123;v = (v_0, v_1, v_2, v_3) \\
        \text&#123;at least one &#125; v_i
        \text&#123; zero&#125;&#125;&#125; b_v
      </div>
      <p class="text-gray-300">
        and compare this against the random case given by
      </p>
      <div class="math-block">
        p_&#123;\text&#123;rand&#125;&#125; = 2^&#123;-128&#125;
        \cdot \sum_&#123;\substack&#123;v = (v_0, v_1, v_2, v_3) \\
        \text&#123;at least one &#125; v_i
        \text&#123; zero&#125;&#125;&#125;
        \prod_&#123;k=0&#125;^&#123;3&#125;
        \binom&#123;4&#125;&#123;v_k&#125;
        (2^8 - 1)^&#123;v_k&#125;
      </div>
      <p class="text-gray-300">
        For instance, if we assume the above input probability
        distribution <span class="math">a</span> (i.e. input
        differences are non-zero in the first column only) and the
        corresponding output distribution
        <span class="math">p_&#123;\text&#123;AES&#125;&#125;</span>
        for <span class="math">r = 5</span> and
        <span class="math">r = 6</span> rounds, we get the results
        of Table 1. In particular, [GR18] arrives at
        <span class="math">2^&#123;-30&#125; + 2^&#123;-50.980&#125;</span>
        for the event that a ciphertext difference is zero in at least
        one column when the plaintext difference is active in the
        first column, which is identical to the result obtained via
        the weight transition probability matrix.
      </p>
      <p class="text-gray-300">
        In the case that the plaintext difference has exactly one
        active byte in the first column, i.e. the input distribution
        <span class="math">a</span> has probability 1 in
        <span class="math">a_1</span>, the method based on weight
        transition probabilities returns a probability
        <span class="math">2^&#123;-30&#125; + 2^&#123;-51.983&#125;</span>
        while [BGL19] arrives at
        <span class="math">2^&#123;-30&#125; + 2^&#123;-51.985&#125;</span>.
      </p>
      <p class="text-gray-300">
        For 6 rounds the probability in [BGL19] for the same type of
        event is estimated to be
        <span class="math">2^&#123;-30&#125; + 2^&#123;-73.995&#125;</span>,
        which is also identical to the probability derived using the
        weight transition probability matrix. We have added the
        probability for 7 rounds into the table for completeness.
      </p>

      <!-- Table 1 -->
      <p class="text-gray-400 text-sm mt-6 mb-2">
        <strong>Table 1:</strong> Comparison between results obtained
        in literature vs our results obtained using the weight
        transition probability (WTP) method of AES probabilities, with
        collision in any ciphertext column as the plaintext event (PE)
        and with plaintext differences restricted to either one active
        column or one active byte as the ciphertext event (CE).
      </p>
      <div class="overflow-x-auto">
        <table class="w-full text-sm">
          <thead>
            <tr class="border-b border-gray-700">
              <th class="text-left py-2 px-3">Rounds</th>
              <th class="text-left py-2 px-3">PE</th>
              <th class="text-left py-2 px-3">CE</th>
              <th class="text-left py-2 px-3">
                Probability in literature
              </th>
              <th class="text-left py-2 px-3">WTP</th>
              <th class="text-left py-2 px-3">Ref.</th>
            </tr>
          </thead>
          <tbody class="text-gray-300">
            <tr class="border-b border-gray-800">
              <td class="py-2 px-3">5</td>
              <td class="py-2 px-3">Active Byte</td>
              <td class="py-2 px-3">Zero-column</td>
              <td class="py-2 px-3">
                <span class="math">2^&#123;-30&#125; + 2^&#123;-51.985&#125;</span>
              </td>
              <td class="py-2 px-3">
                <span class="math">2^&#123;-30&#125; + 2^&#123;-51.983&#125;</span>
              </td>
              <td class="py-2 px-3">[BGL19]</td>
            </tr>
            <tr class="border-b border-gray-800">
              <td class="py-2 px-3">5</td>
              <td class="py-2 px-3">Active Column</td>
              <td class="py-2 px-3">Zero-column</td>
              <td class="py-2 px-3">
                <span class="math">2^&#123;-30&#125; + 2^&#123;-50.980&#125;</span>
              </td>
              <td class="py-2 px-3">
                <span class="math">2^&#123;-30&#125; + 2^&#123;-50.980&#125;</span>
              </td>
              <td class="py-2 px-3">[GR18]</td>
            </tr>
            <tr class="border-b border-gray-800">
              <td class="py-2 px-3">6</td>
              <td class="py-2 px-3">Active Column</td>
              <td class="py-2 px-3">Zero-column</td>
              <td class="py-2 px-3">
                <span class="math">2^&#123;-30&#125; + 2^&#123;-73.995&#125;</span>
              </td>
              <td class="py-2 px-3">
                <span class="math">2^&#123;-30&#125; + 2^&#123;-73.995&#125;</span>
              </td>
              <td class="py-2 px-3">[BGL19]</td>
            </tr>
            <tr class="border-b border-gray-800">
              <td class="py-2 px-3">7</td>
              <td class="py-2 px-3">Active Column</td>
              <td class="py-2 px-3">Zero-column</td>
              <td class="py-2 px-3">&mdash;</td>
              <td class="py-2 px-3">
                <span class="math">2^&#123;-30&#125; + 2^&#123;-126.891&#125;</span>
              </td>
              <td class="py-2 px-3"></td>
            </tr>
          </tbody>
        </table>
      </div>

      <p class="text-gray-300">
        However, there might be better choices of input and output
        distributions that can be used to optimize this further. For
        instance, in the same setting as above and for 7 rounds, we
        get
      </p>
      <div class="math-block">
        p_&#123;\text&#123;AES-7R&#125;&#125; = 2^&#123;-30&#125;
        + 2^&#123;-126.891&#125;
      </div>
      <p class="text-gray-300">
        If we instead ask what the probability of getting at least one
        zero-byte, we get
      </p>
      <div class="math-block">
        p_&#123;\text&#123;AES-7R&#125;&#125; = 2^&#123;-4&#125;
        + 2^&#123;-126.036&#125;
      </div>
      <p class="text-gray-300">
        Note that the weight transition probability matrix verifies
        the well-known impossible difference probability too (i.e. you
        get probability zero for the event of less than 5 active
        columns in total when evaluated for
        <span class="math">C_3</span>).
      </p>
      <p class="text-gray-300">
        These results motivate a conjecture.
      </p>

      <div class="formal-block formal-block-conjecture">
        <div class="formal-block-title text-cyan-400">
          Conjecture 1
        </div>
        <div class="formal-block-content">
          <p class="text-gray-300">
            The weight transition probability matrix defined in
            Definition 4 emulates the true weight probabilities
            distributions in AES.
          </p>
        </div>
      </div>

      <!-- ========================================================== -->
      <!-- 3.2 WEIGHT DISTRIBUTIONS BIASED IN OPPOSITE DIRECTIONS      -->
      <!-- ========================================================== -->

      <h3 id="sec-3.2" class="text-xl font-semibold mt-8">
        3.2 Weight Distributions Biased in Opposite Directions
      </h3>
      <p class="text-gray-300">
        Assume that we fix an output event, e.g. that at least one
        column in the difference is zero which happens with
        probability roughly
        <span class="math">2^&#123;-30&#125;</span> at random. The
        second type of events we could look for is the case when there
        exist two different input distributions, e.g.
        <span class="math">a^1, a^2 \in \mathbb&#123;R&#125;^&#123;625&#125;</span>
        with <span class="math">a^1_i = 1</span> and
        <span class="math">a^2_j = 1</span> for
        <span class="math">i \neq j</span>, such that the two output
        probabilities for the same event,
      </p>
      <div class="math-block">
        p_1 = \sum_&#123;\substack&#123;v = (v_0, v_1, v_2, v_3) \\
        \text&#123;at least one &#125; v_j
        \text&#123; zero&#125;&#125;&#125; b_v^1
      </div>
      <p class="text-gray-300">and</p>
      <div class="math-block">
        p_2 = \sum_&#123;\substack&#123;v = (v_0, v_1, v_2, v_3) \\
        \text&#123;at least one &#125; v_j
        \text&#123; zero&#125;&#125;&#125; b_v^2
      </div>
      <p class="text-gray-300">
        move in opposite direction from random. For instance, assume
      </p>
      <div class="math-block">
        p_1 = p_&#123;\text&#123;rand&#125;&#125; - \epsilon_1
        \tag&#123;19&#125;
      </div>
      <p class="text-gray-300">and</p>
      <div class="math-block">
        p_2 = p_&#123;\text&#123;rand&#125;&#125; + \epsilon_j
        \tag&#123;20&#125;
      </div>
      <p class="text-gray-300">
        thus maximizing the distance between the two same-event
        probabilities <span class="math">p_1</span> and
        <span class="math">p_2</span> instead of comparing single
        AES-probabilities with random. For instance, for 5-rounds we
        can pick two different input conditions for the weight in the
        first column,
        <span class="math">u_1 = (3, 0, 0, 0)</span> and
        <span class="math">u_2 = (2, 0, 0, 0)</span> such that
      </p>
      <div class="math-block">
        p_1 = 2^&#123;-30&#125; - 2^&#123;-50.358&#125;
      </div>
      <p class="text-gray-300">
        becomes the probability for collision in any column after 5
        rounds when there are exactly 3 active bytes in the input
        difference and
      </p>
      <div class="math-block">
        p_2 = 2^&#123;-30&#125; + 2^&#123;-50.390&#125;
      </div>
      <p class="text-gray-300">
        for a collision when there are exactly 2 active bytes, such
        that the difference
      </p>
      <div class="math-block">
        p_2 - p_1 = 2^&#123;-49.373&#125;
      </div>
      <p class="text-gray-300">
        is larger than if we compared a single event against random.
      </p>
    </section>

    <!-- ============================================================ -->
    <!-- 4 POSSIBLE FURTHER RESEARCH                                  -->
    <!-- ============================================================ -->

    <section id="sec-4" class="mb-10">
      <h2 class="text-2xl font-bold">4 Possible Further Research</h2>
      <p class="text-gray-300">
        There might be several interesting directions for further
        research, but we mention just a few.
      </p>

      <!-- ========================================================== -->
      <!-- 4.1 LINEAR OPTIMIZATION                                     -->
      <!-- ========================================================== -->

      <h3 id="sec-4.1" class="text-xl font-semibold mt-8">
        4.1 Linear Optimization
      </h3>
      <p class="text-gray-300">
        To formally find the optimal distribution (choice of input and
        output events) that minimizes distinguishing complexity, one
        can employ a data- and computational complexity weighted
        linear optimization (linear programming).
      </p>

      <!-- ========================================================== -->
      <!-- 4.2 MARKOV CHAINS AND STOCHASTIC MATRICES                   -->
      <!-- ========================================================== -->

      <h3 id="sec-4.2" class="text-xl font-semibold mt-8">
        4.2 Markov Chains and Stochastic Matrices
      </h3>
      <p class="text-gray-300">
        Markov chains, stochastic matrices etc. is a very well-studied
        area. What can be said about these state transition matrices
        by employing known theory to them?
      </p>

      <!-- ========================================================== -->
      <!-- 4.3 RATE OF CONVERGENCE                                     -->
      <!-- ========================================================== -->

      <h3 id="sec-4.3" class="text-xl font-semibold mt-8">
        4.3 Rate of Convergence
      </h3>
      <p class="text-gray-300">
        For
        <span class="math">I, J \subset \&#123;0, 1, 2, 3\&#125;</span>,
        let <span class="math">p_&#123;I,J&#125;^r</span> denote the
        probability that the ciphertext difference is zero in columns
        indicated by <span class="math">J</span> given that the
        plaintext difference is active in exactly the columns
        indicated by <span class="math">I</span> after
        <span class="math">r</span> rounds. The motivation in this
        paper has been to study how probabilities
        <span class="math">p_&#123;I,J&#125;^r</span> for ciphertext
        events <span class="math">J</span> vary depending on the
        choice of input events <span class="math">I</span>. Let
        <span class="math">s_&#123;I,J&#125; = s_J</span> denote the
        uniform probability that ciphertext differences are zero in
        the columns indicated by <span class="math">J</span>. Then
        if we look at the rounded values of
        <span class="math">\log_2\!\left(\frac&#123;\max(p_&#123;I,J&#125;^r, s_J)&#125;&#123;(p_&#123;I,J&#125;^r - s_J)^2&#125;\right)</span>
        for increasing <span class="math">r</span>, we observe that
        the values become independent of the choice of input
        distributions (determined by <span class="math">I</span>) not
        until <span class="math">r = 10</span> rounds of AES.
      </p>

      <!-- ========================================================== -->
      <!-- 4.4 THE EFFECT OF THE S-BOX                                 -->
      <!-- ========================================================== -->

      <h3 id="sec-4.4" class="text-xl font-semibold mt-8">
        4.4 The Effect of the S-box
      </h3>
      <p class="text-gray-300">
        The s-box layer acts as a probability 1 identity map in the
        transition probability matrix. However, the s-box maps
        differences in certain ways that might at least in theory have
        some effect on the probability distribution. It is not clear
        how large, if any, this effect is for a generic s-box.
      </p>

      <!-- ========================================================== -->
      <!-- 4.5 TESTING CIPHERS                                         -->
      <!-- ========================================================== -->

      <h3 id="sec-4.5" class="text-xl font-semibold mt-8">
        4.5 Testing Ciphers
      </h3>
      <p class="text-gray-300">
        This tool can be employed on a range of other similar ciphers
        which may be an interesting study in itself, and as a simple
        and efficient tool to search for optimal new designs.
      </p>
    </section>

    <!-- ============================================================ -->
    <!-- 5 CONCLUSION                                                 -->
    <!-- ============================================================ -->

    <section id="sec-5" class="mb-10">
      <h2 class="text-2xl font-bold">5 Conclusion</h2>
      <p class="text-gray-300">
        We have presented a weight transition probability related to
        SPNs that can be used to derive probabilities for collision
        events in AES that matches new results recently published in
        [BGL19] and [GR18].
      </p>
    </section>

    <!-- ============================================================ -->
    <!-- REFERENCES                                                   -->
    <!-- ============================================================ -->

    <section id="references" class="mb-10">
      <h2 class="text-2xl font-bold">References</h2>
      <ul class="space-y-2 text-gray-300 text-sm list-none">
        <li>
          <span class="text-gray-500">[BGL19]</span>
          Bao, Z., Guo, J., List, E.: Extended expectation
          cryptanalysis on round-reduced AES. Cryptology ePrint
          Archive, Report 2019/622 (2019).
          <a href="https://eprint.iacr.org/2019/622"
            target="_blank" rel="noopener noreferrer"
            class="text-blue-400 hover:text-blue-300">
            eprint.iacr.org/2019/622</a>
        </li>
        <li>
          <span class="text-gray-500">[DR02]</span>
          Daemen, J., Rijmen, V.: The design of Rijndael: AES &ndash;
          the Advanced Encryption Standard. Springer (2002)
        </li>
        <li>
          <span class="text-gray-500">[Gra18]</span>
          Grassi, L.: Mixture differential cryptanalysis: a new
          approach to distinguishers and attacks on round-reduced AES.
          IACR Transactions on Symmetric Cryptology 2018(2),
          133&ndash;160 (Jun 2018).
          <a href="/papers/mixture-differential-aes-2017"
            class="text-blue-400 hover:text-blue-300">
            [page on this site]</a>
        </li>
        <li>
          <span class="text-gray-500">[GR18]</span>
          Grassi, L., Rechberger, C.: Rigorous analysis of truncated
          differentials for 5-round AES. Cryptology ePrint Archive,
          Report 2018/182 (2018).
          <a href="https://eprint.iacr.org/2018/182"
            target="_blank" rel="noopener noreferrer"
            class="text-blue-400 hover:text-blue-300">
            eprint.iacr.org/2018/182</a>
          <a href="/papers/truncated-diff-diagonal-aes-2018"
            class="text-blue-400 hover:text-blue-300">
            [page on this site]</a>
        </li>
        <li>
          <span class="text-gray-500">[GRR17]</span>
          Grassi, L., Rechberger, C., R&oslash;njom, S.: A new
          structural-differential property of 5-round AES. In:
          Advances in Cryptology &ndash; EUROCRYPT 2017 &ndash; 36th
          Annual International Conference on the Theory and
          Applications of Cryptographic Techniques, Paris, France,
          April 30 &ndash; May 4, 2017, Proceedings, Part II.
          pp. 289&ndash;317 (2017)
        </li>
      </ul>
    </section>

    <PaperHistory slug="weight-probability-spn-2019" />
  </article>
</BaseLayout>
