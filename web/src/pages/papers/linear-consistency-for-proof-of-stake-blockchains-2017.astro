---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2017/241';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Linear Consistency for Proof-of-Stake Blockchains';
const AUTHORS_HTML = 'Erica Blum, Aggelos Kiayias, Cristopher Moore, Saad Quader, Alexander Russell';

const CONTENT = `    <p class="text-gray-300">The combinatorics of the longest-chain rule: Linear consistency for proof-of-stake blockchains</p>

    <p class="text-gray-300">Erica Blum¹, Aggelos Kiayias²,⁵, Cristopher Moore³, Saad Quader⁴, and Alexander Russell⁴,⁵</p>

    <p class="text-gray-300">¹University of Maryland, College Park ²University of Edinburgh ³Santa Fe Institute ⁴University of Connecticut ⁵IOHK</p>

    <p class="text-gray-300">November 22, 2019</p>

    <h2 id="sec-1" class="text-2xl font-bold">Abstract</h2>

    <p class="text-gray-300">Blockchain data structures maintained via the longest-chain rule have emerged as a powerful algorithmic tool for consensus algorithms. The technique—popularized by the Bitcoin protocol—has proven to be remarkably flexible and now supports consensus algorithms in a wide variety of settings. Despite such broad applicability and adoption, current analytic understanding of the technique is highly dependent on details of the protocol's leader election scheme. A particular challenge appears in the proof-of-stake setting, where existing analyses suffer from quadratic dependence on suffix length.</p>

    <p class="text-gray-300">We describe an axiomatic theory of blockchain dynamics that permits rigorous reasoning about the longest-chain rule in quite general circumstances and establish bounds—optimal to within a constant—on the probability of a consistency violation. This settles a critical open question in the proof-of-stake setting where we achieve linear consistency for the first time.</p>

    <p class="text-gray-300">Operationally, blockchain consensus protocols achieve consistency by instructing parties to remove a suffix of a certain length from their local blockchain. While the analysis of Bitcoin guarantees consistency with error <span class="math">2^{-k}</span> by removing <span class="math">O(k)</span> blocks, recent work on proof-of-stake (PoS) blockchains has suffered from quadratic dependence: (PoS) blockchain protocols, exemplified by Ouroboros (Crypto 2017), Ouroboros Praos (Eurocrypt 2018) and Sleepy Consensus (Asiacrypt 2017), can only establish that the length of this suffix should be <span class="math">\\Theta(k^2)</span>. This consistency guarantee is a fundamental design parameter for these systems, as the length of the suffix is a lower bound for the time required to wait for transactions to settle. Whether this gap is an intrinsic limitation of PoS—due to issues such as the "nothing-at-stake" problem—has been an urgent open question, as deployed PoS blockchains further rely on consistency for protocol correctness: in particular, security of the protocol itself relies on this parameter. Our general theory directly improves the required suffix length from <span class="math">\\Theta(k^2)</span> to <span class="math">\\Theta(k)</span>. Thus we show, for the first time, how PoS protocols can match proof-of-work blockchain protocols for exponentially decreasing consistency error.</p>

    <p class="text-gray-300">Our analysis focuses on the articulation of a two-dimensional stochastic process that captures the features of interest, an exact recursive closed form for the critical functional of the process, and tail bounds established for associated generating functions that dominate the failure events. Finally, the analysis provides an explicit polynomial-time algorithm for exactly computing the exponentially-decaying error function which can directly inform practice.</p>

    <p class="text-gray-300">Erica Blum's work was partly supported by financial assistance award 70NANB19H126 from U.S. Department of Commerce, National Institute of Standards and Technology. Aggelos Kiayias' research was partly supported by H2020 Grant #780477, PRIVILEGE. Cristopher Moore's research was partly supported by NSF grant BIGDATA-1838251. Alexander Russell's work was partly supported by NSF Grant #1717432.</p>

    <p class="text-gray-300">1 Introduction</p>

    <p class="text-gray-300">A blockchain is a data structure consisting of a collection of data blocks placed in linear order. It further requires that each block contains a collision-free hash of the previous block: thus blocks implicitly commit to the entire prefix of the blockchain preceding them. This elementary data structure has remarkable applications in distributed computing, and now appears as an essential component of consensus protocols in a wide variety of models and settings; this notably includes both the “permissionless” setting popularized by Bitcoin and the classic “permissioned” model.</p>

    <p class="text-gray-300">Such consensus protocols call for players to collaboratively assemble a blockchain by repeatedly selecting players to add blocks. Specifically, the protocol determines a stochastic process resembling a lottery: each “leader” selected by the lottery is then responsible for broadcasting a new block. While the algorithmic details of this lottery depend heavily on the protocol, the outcome can be privately determined and provides the winning player a proof of leadership that can be publicly demonstrated. Assuming that the expected wait time for some player to win the lottery is constant, the blockchain experiences steady growth when players follow the protocol.</p>

    <p class="text-gray-300">Network infelicities, adversarial behavior, or the possibility that two players simultaneously win the lottery can lead to disagreements among the players about the current blockchain. Thus protocols adopt a “chain selection rule” that determines how players should break ties among the various chains they observe on the network; ideally, the combination of the chain selection rule and the lottery should guarantee that the players’ blockchains agree, perhaps with the exception of a short suffix. The emblematic chain selection strategy among such systems is the longest-chain rule, which calls for players to adopt the longest chain among various contenders.</p>

    <p class="text-gray-300">The first blockchain protocol was the core of the sensational Bitcoin system <em>[18]</em>; it adopted a lottery mechanism based on a cryptographic puzzle <em>[7, 1]</em>—also known as proof-of-work or PoW, for short—and a chain selection rule favoring chains that represent more work. The system is particularly notable for its ability to survive in a permissionless setting—where players may freely join and depart—even when a portion of the players are actively attacking the protocol. Unfortunately, the proof-of-work mechanism makes quite striking energy demands: the system currently consumes as much electricity as a small country. This motivated the blockchain community to exploring alternative lottery mechanisms, e.g., proof-of-stake (PoS) <em>[3, 21, 13]</em>, proof of space <em>[8, 20]</em> and others <em>[16]</em>. The proof-of-stake mechanism is particularly attractive from the perspective of efficiency, as it makes no assumption of external computational resources.</p>

    <p class="text-gray-300">The fundamental consistency property—critical in all these blockchain systems—is common-prefix (cf. <em>[9]</em>). It precisely captures the intuition described above: by trimming a <span class="math">k</span>-block suffix from the chain held by any honest player the resulting blockchain is a prefix of the blockchain possessed by any honest party at any future point of the execution. A principal goal in the analysis of these systems is a to guarantee common prefix, for an appropriate value of <span class="math">k</span>, even if some of the players collude to disrupt the protocol. Common prefix is typically only shown to hold with high probability <span class="math">1-\\varepsilon</span>, where <span class="math">\\varepsilon</span> is an error term that is a function of <span class="math">k</span>. The exact dependency of <span class="math">\\varepsilon</span> on <span class="math">k</span> is critically important: it determines the length of the suffix that is to be removed from a blockchain in order to ensure that the remaining prefix will be retained at any future point of the execution. This directly imposes a lower bound on how long one has to wait for information in the blockchain (such as a payment transaction) to “settle.” Additionally, many blockchain protocols internally rely on common prefix for correctness; thus the relationship between <span class="math">\\varepsilon</span> and <span class="math">k</span> is critical to establishing the regime of correctness of the entire protocol.</p>

    <p class="text-gray-300">A relatively straightforward lower bound for <span class="math">\\varepsilon</span> is <span class="math">\\varepsilon\\geq\\exp(-\\alpha k)</span> for some <span class="math">\\alpha&gt;0</span>. This lower bound applies when there is a coalition of adversarial players of constant fraction, the case of primary interest in practice. The result is easy to infer from the analysis of <em>[18]</em>, where a strategy is demonstrated that violates common prefix with such probability (this is referred to as a “double-spending” attack in that paper). The tightness of this bound is an important open problem. For the special case of proof-of-work an upper bound of <span class="math">\\exp(-\\Omega(k))</span> was shown first in <em>[9]</em> and further verified in extended security models by <em>[11, 24]</em>. In the proof-of-stake setting, on the other hand, the tightness of the bound remains open. While recent proof-of-stake algorithms have been presented with rigorous analyses that rival proof-of-work in many regards, they suffer from a quadratic relationship between <span class="math">k</span> and <span class="math">\\log(\\varepsilon)</span>. For example, the Ouroboros protocols <em>[13, 6, 2]</em>, as well as Snow White <em>[4]</em>, provide an upper bound</p>

    <p class="text-gray-300">on <span class="math">\\varepsilon</span> of <span class="math">\\exp(-\\Omega(\\sqrt{k}))</span>; this should be compared with <span class="math">\\varepsilon=\\exp(-\\Theta(k))</span> for proof-of-work. The significant gap from the known lower bound was attributed to a notable, general attack that distinguished PoS from PoW: Known as the <em>nothing-at-stake</em> problem, this refers to the ability of an adversarial coalition of players to strategically reuse a winning PoS lottery to extend multiple blockchains.</p>

    <h4 id="sec-2" class="text-lg font-semibold mt-6">Our results.</h4>

    <p class="text-gray-300">Our objective is to control the common-prefix error <span class="math">\\varepsilon</span> as tightly as possible while making minimal assumptions on the underlying blockchain protocol. We work in a general model formulated by a simple family of <em>blockchain axioms</em>. The axioms themselves are easy to interpret and few in number. This permits us to abstract many features of the underlying blockchain protocol (e.g., the details of the leader-election process, the cryptographic security of the relevant signature schemes and hash functions, and randomness generation), while still establishing results that are strong enough to directly incorporate into existing specific analyses.</p>

    <p class="text-gray-300">Our most interesting finding is a quite tight theory of common prefix that depends <em>only on the schedule of participants certified to add a block</em>. Under common assumptions about this schedule, we achieve the optimal relationship <span class="math">\\varepsilon=\\exp(-\\Theta(k))</span>. This directly improves the common prefix guarantees (and settlement times) of existing proof-of-stake blockchains such as Snow White <em>[4]</em>, Ouroboros <em>[13]</em>, Ouroboros Praos <em>[6]</em>, and Ouroboros Genesis <em>[2]</em>. Specifically, this improves the scaling in the exponent from <span class="math">\\sqrt{k}</span> to <span class="math">k</span> and establishes a tight characterization for <span class="math">\\varepsilon=\\exp(-\\Theta(k))</span>. (In fact, we even obtain reasonable control of the constants.) We remark that our assumptions about the schedule distribution can be weakened—without any effect on the final bounds—to apply to martingale-style distributions such as those that arise in the analysis of adaptive adversaries <em>[6, 2]</em>.</p>

    <p class="text-gray-300">Our new analysis offers an additional, but lower order, improvement for several of these blockchains. The existing analysis of, e.g., Ouroboros Praos <em>[6]</em>, required a union bound to be taken over the entire lifetime of the protocol in order to rule out a common prefix violation at a particular point of time; thus such events were actually bounded above by a function of the form <span class="math">T\\exp(-\\Omega(\\sqrt{k}))</span>, where <span class="math">T</span> is the lifetime of the protocol. While this event <em>does</em> depend on the entire dynamics of the protocol, we show how to avoid this pessimistic tail bound to achieve a “single shot” common prefix violation—at a particular time of interest—of form <span class="math">\\exp(-\\Theta(k))</span>; this removes the dependence on <span class="math">T</span>.</p>

    <p class="text-gray-300">From a technical perspective, we contrast the structure of our proofs with existing techniques for the PoW case. The PoW results find a direct connection between common-prefix and the behavior of a biased, one-dimensional random walk. Interestingly, our results give a tight relationship between the general (e.g., PoS) case and a pair of <em>coupled</em> biased random walks. A major challenge in the analysis is to bound the behavior of this richer stochastic process. Our tools yield precise, explicit upper bounds on the probability of persistence violations that can be directly applied to tune the parameters of deployed PoS systems. See Appendix A where we record some concrete results of the general theory. The importance of these results in the practice of PoS blockchain systems cannot be overstated: they provide, for the first time, concrete error bounds for settlement times for PoS blockchains that follow the longest chain rule.</p>

    <h4 id="sec-3" class="text-lg font-semibold mt-6">Further analytic details.</h4>

    <p class="text-gray-300">Our approach begins with the graph-theoretic framework of <em>forks</em> and <em>margin</em> developed for the analysis of the Ouroboros <em>[13]</em> protocol. (A fork is an abstraction of the protocol execution given the outcomes of the leader-election process.) We begin by generalizing the notion of margin to account for local, rather than global, features of a leader schedule, and provide an exact, recursive closed form for this new quantity (see Section 5). This proof identifies an optimal online adversary (i.e., a fork-building strategy whose current decisions do not depend on the future) for PoS blockchain algorithms with the remarkable property that the sequence of forks produced by this adversary <em>simultaneously</em> achieve the worst-case (slot) common-prefix violations associated with all slots (see Section 8). We then study the stochastic process generated when the <em>characteristic string</em>—a Boolean string representing the outcome of the leader election scheme—is given by a family of i.i.d. Bernoulli random variables. In this case, we identify a generating function that bounds the tail events off interest, and analytically upper bound the growth of the function. We then show how to extend the analysis to the setting where the characteristic string is drawn from a martingale sequence. As it happens, this more general distribution arises naturally in the analyses of PoS protocols that survive adaptive adversaries; e.g., Ouroboros Genesis <em>[2]</em>. We obtain the pleasing result that the common prefix error probability in the martingale case is no more than that in the i.i.d. Bernoulli case.</p>

    <p class="text-gray-300">Direct consequences. Our results establish consistency bounds in a quite general setting—see below: In particular, they directly imply <span class="math">\\exp(-\\Theta(k))</span> consistency for the Sleepy consensus (Snow White) <em>[21]</em>, Ouroboros <em>[13]</em>, Ouroboros Praos <em>[6]</em>, and Ouroboros Genesis <em>[2]</em> blockchain protocols. (The Ouroboros Praos and Ouroboros Genesis analyses in fact directly relied on an earlier e-print version of the present article for their settlement estimates.)</p>

    <h4 id="sec-4" class="text-lg font-semibold mt-6">Related work.</h4>

    <p class="text-gray-300">Blockchain protocol analysis in the PoW-setting was initiated in <em>[9]</em> and further improved in <em>[24, 11]</em>. The established security bounds for consistency are linear in the security parameter. Sleepy consensus <em>[21, Theorem 13]</em> provides a consistency bound of the form <span class="math">\\exp(-\\Omega(\\sqrt{k}))</span>. Note that <em>[21]</em> is not a PoS protocol per se, but it is possible to turn it into one (as was demonstrated in <em>[4]</em>). The analysis of the Ouroboros blockchain <em>[13]</em> achieves <span class="math">\\exp(-\\Omega(\\sqrt{k}))</span>. We remark that the analyses of Ouroboros Praos <em>[6]</em> and Ouroboros Genesis <em>[2]</em> developed significant new machinery for handling other challenges (e.g., adaptive adversaries, partial synchrony), but directly referred to a preliminary version of this article to conclude their guarantees of <span class="math">\\exp(-\\Omega(k))</span>.</p>

    <p class="text-gray-300">Our results complement the recent results of <em>[5]</em>, which also considers longest-chain PoS protocols. <em>[5]</em> focuses on identifying dynamics unique to longest-chain PoS protocols. In particular, they show that longest-chain PoS protocols that are <em>predictable</em> (i.e., for which some portion of the schedule of slot leaders is known ahead of time) are necessarily vulnerable to “predictable double-spends.” The conventional defense against such attacks is to wait for the specified settlement time to elapse before accepting a transaction, which (until now) has resulted in slow confirmation times. As such, <em>[5]</em> raised the question of whether long confirmation times are a necessary evil in longest-chain PoS blockchains. As double-spending attacks imply a consistency violation, our results show that PoS protocols can safely decrease settlement times to asymptotically match PoW protocols without sacrificing security against double-spends.</p>

    <p class="text-gray-300">Because we focus on the longest-chain rule, our analysis is not applicable to protocols like Algorand <em>[15]</em> which, in fact, offer settlement in expected constant time without invoking blockchain reorganisation or forks; however, Algorand lacks the ability to operate in the “sleepy” <em>[21]</em> or “dynamic availability” <em>[2]</em> setting. In our combinatorial analysis, synchronous operation is assumed against a rushing adversary; this is without loss of generality vis-a-vis the result of <em>[6]</em> where it was shown how to reduce the combinatorial analysis in the partially synchronous setting to the synchronous one. We note that a number of works have shown how to use a blockchain protocol to bootstrap a cryptographic protocol that can offer faster settlement time under stronger assumptions than honest majority, e.g., Hybrid Consensus <em>[22]</em> or Thunderella <em>[23]</em>; our results are orthogonal and synergistic to those since they can be used to improve the settlement time bounds of the blockchain protocol that operates as a fallback mechanism.</p>

    <h4 id="sec-5" class="text-lg font-semibold mt-6">Outline.</h4>

    <p class="text-gray-300">We begin in Section 2 by describing a simple general model for blockchain dynamics. Section 3 builds on this model to set down a number of basic definitions required for the proofs. The first part of the main proof is described in Section 5, which develops a “relative” version of the theory of margin from <em>[13]</em>; most details are then relegated to Section 7 in order to move quickly to the consistency estimates in Section 6. In Section 8, we present an optimal online adversary who can simultaneously maximize the relative margins for all prefixes of the characteristic string. Finally, in Appendix A, we compute exact upper bounds on <span class="math">k</span>-settlement error probabilities for various values of <span class="math">k</span> and describe a simple <span class="math">O(k^{3})</span>-time algorithm to compute these probabilities in general.</p>

    <h2 id="sec-6" class="text-2xl font-bold">2 The blockchain axioms and the settlement security model</h2>

    <p class="text-gray-300">Typical blockchain consensus protocols call for each participant to maintain a <em>blockchain</em>; this is a data structure that organizes transactions and other protocol metadata into an ordered historical record of “blocks.” A basic design goal of these systems is to guarantee that participants’ blockchains always agree on a common prefix; the differing suffixes of the chains held by various participants roughly correspond to the possible future states of the system. Thus the major analytic challenge is to ensure that—despite evolving adversarial control of some of the participants—the portion of honest participants’ blockchains that might pairwise disagree is confined to a short</p>

    <p class="text-gray-300">suffix. This analysis in turn supports the fundamental guarantee of <em>consistency</em> for these algorithms, which asserts that data appearing deep enough in the chain can be considered to be stable, or “settled.”</p>

    <p class="text-gray-300">We adopt a discrete notion of time organized into a sequence of <em>slots</em> <span class="math">\\{sl_{0},sl_{1},...\\}</span> and assume all protocol participants have the luxury of synchronized clocks that report the current slot number. As discussed above, the protocols we consider rely on two algorithmic devices:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>A <em>leader election mechanism</em>, which randomly assigns to each time slot a set of “leaders” permitted to post a new block in that slot.</li>

      <li>The <em>longest-chain rule</em>, which calls for the leader(s) of each slot to add a block to the end of the longest blockchain she has yet observed, and broadcast this new chain to other participants.</li>

    </ul>

    <p class="text-gray-300">The Bitcoin protocol uses a proof-of-work mechanism to carry out leader election, which can be modeled using a random oracle <em>[9, 24, 11]</em>. Proof-of-stake systems typically require more intricate leader election mechanisms; for example, the Ouroboros protocol <em>[13]</em> uses a full multi-party private computation to distribute clean randomness, while Snow White <em>[4]</em>, Algorand <em>[15]</em>, and Ouroboros Praos <em>[6]</em> use hashing and a family of values determined on-the-fly. Despite these differences, all existing analyses show that the leader election mechanism suitably approximates an ideal distribution, which is also the approach we will adopt for our analysis.</p>

    <h3 id="sec-7" class="text-xl font-semibold mt-8">2.1 The blockchain axioms and forks</h3>

    <p class="text-gray-300">To simplify our analysis, we assume a synchronous communication network in the presence of a <em>rushing</em> adversary: in particular, any message broadcast by an honest participant at the beginning of a particular slot is received by the adversary first, who may decide strategically and individually for each recipient in the network whether to inject additional messages and in what order all messages are to be delivered prior to the conclusion of the slot. (See §2.5 below for comments on this network assumption.)</p>

    <p class="text-gray-300">Given this, the behavior of the protocol when carried out by a group of honest participants (who follow the protocol in the presence of an adversary who may only reorganize messages) is clear. Assuming that the system is initialized with a common “genesis block” corresponding to <span class="math">sl_{0}</span> and the leader election process in fact elects a single leader per slot, the players observe a common, linearly growing blockchain:</p>

    <p class="text-gray-300">Here node <span class="math">i</span> represents the block broadcast by the leader of slot <span class="math">i</span> and the arrows represent the direction of increasing time. (Note that the requirement of a single leader per slot is important in this simple picture; it is possible for a network adversary to induce divergent views between the players by taking advantage of slots where more than a single honest participant is elected a leader.)</p>

    <h5 id="sec-8" class="text-base font-semibold mt-4">The blockchain axioms: Informal discussion.</h5>

    <p class="text-gray-300">The introduction of adversarial participants or multiple slot leaders complicates the family of possible blockchains that could emerge from this process. To explore this in the context of our protocols, we work with an abstract notion of a blockchain which ignores all internal structure. We consider a fixed assignment of leaders to time slots, and assume that the blockchain uses a proof mechanism to ensure that any block labeled with slot <span class="math">sl_{t}</span> was indeed produced by a leader of slot <span class="math">sl_{t}</span>; this is guaranteed in practice by appropriate use of a secure digital signature scheme.</p>

    <p class="text-gray-300">Specifically, we treat a <em>blockchain</em> as a sequence of abstract blocks, each labeled with a slot number, so that:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The blockchain begins with a fixed “genesis” block, assigned to slot <span class="math">sl_{0}</span>.</li>

      <li>The (slot) labels of the blocks are in strictly increasing order.</li>

    </ul>

    <p class="text-gray-300">It is further convenient to introduce the structure of a directed graph on our presentation, where each block is treated as a vertex; in light of the first two axioms above, a blockchain is a path beginning with a special “genesis” vertex, labeled <span class="math">0</span>, followed by vertices with strictly increasing labels that indicate which slot is associated with the block.</p>

    <p class="text-gray-300">The protocols of interest call for honest players to add a <em>single</em> block during any slot. In particular:</p>

    <p class="text-gray-300">If a slot <span class="math">sl_{t}</span> was assigned to a single honest player, then a single block is created—during the entire protocol—with the label <span class="math">sl_{t}</span>.</p>

    <p class="text-gray-300">Recall that blockchains are <em>immutable</em> in the sense that any block in the chain commits to the entire previous history of the chain; this is achieved in practice by including with each block a collision-free hash of the previous block. These properties imply that if a specific slot <span class="math">sl_{t}</span> was assigned to a unique honest player, then any chain that includes the unique block from <span class="math">sl_{t}</span> must also include that block’s associated prefix in its entirety.</p>

    <p class="text-gray-300">As we analyze the dynamics of blockchain algorithms, it is convenient to maintain an entire family of blockchains at once. As a matter of bookkeeping, when two blockchains agree on a common prefix, we can glue together the associated paths to reflect this, as indicated below.</p>

    <p class="text-gray-300">When we glue together many chains to form such a diagram, we call it a “fork”—the precise definition appears below. Observe that while these two blockchains agree through the vertex (block) labeled 5, they contain (distinct) vertices labeled 9; this reflects two distinct blocks associated with slot 9 which, in light of the axiom above, must have been produced by an adversarial participant.</p>

    <p class="text-gray-300">Finally, as we assume that messages from honest players are delivered without delay, we note a direct consequence of the longest chain rule:</p>

    <p class="text-gray-300">If two honestly generated blocks <span class="math">B_{1}</span> and <span class="math">B_{2}</span> are labeled with slots <span class="math">sl_{1}</span> and <span class="math">sl_{2}</span> for which <span class="math">sl_{1}&lt;sl_{2}</span>, then the length of the unique blockchain terminating at <span class="math">B_{1}</span> is strictly less than the length of the unique blockchain terminating at <span class="math">B_{2}</span>.</p>

    <p class="text-gray-300">Recall that the honest participant assigned to slot <span class="math">sl_{2}</span> will be aware of the blockchain terminating at <span class="math">B_{1}</span> that was broadcast by the honest player in slot <span class="math">sl_{1}</span> as a result of synchronicity; according to the longest-chain rule, it must have placed <span class="math">B_{2}</span> on a chain that was at least this long. In contrast, not all participants are necessarily aware of all blocks generated by dishonest players, and indeed dishonest players may often want to delay the delivery of an adversarial block to a participant or show one block to some participants and show a completely different block to others.</p>

    <h4 id="sec-9" class="text-lg font-semibold mt-6">Characteristic strings, forks, and the formal axioms.</h4>

    <p class="text-gray-300">Note that with the axioms we have discussed above, whether or not a particular fork diagram (such as the one just above) corresponds to a valid execution of the protocol depends on how the slots have been awarded to the parties by the leader election mechanism. We introduce the notion of a “characteristic” string as a convenient means of representing information about slot leaders in a given execution.</p>

    <h6 id="sec-10" class="text-base font-medium mt-4">Definition 1 (Characteristic string).</h6>

    <p class="text-gray-300">Let <span class="math">sl_{1},...\\,,sl_{n}</span> be a sequence of slots. A <em>characteristic string</em> <span class="math">w</span> is an element of <span class="math">\\{0,1\\}^{n}</span> defined for a particular execution of a blockchain protocol so that</p>

    <p class="text-gray-300">\\[ w_{t}=\\begin{cases}0&\\text{if }sl_{t}\\text{ was assigned to a single honest participant,}\\\\ 1&\\text{otherwise.}\\end{cases} \\]</p>

    <p class="text-gray-300">For two Boolean strings <span class="math">x</span> and <span class="math">w</span>, we write <span class="math">x\\prec w</span> iff <span class="math">x</span> is a strict prefix of <span class="math">w</span>. Similarly, we write <span class="math">x\\preceq w</span> iff either <span class="math">x=w</span> or <span class="math">x\\prec w</span>. The empty string <span class="math">\\varepsilon</span> is a prefix to any string. With this discussion behind us, we set down the formal object we use to reflect the various blockchains adopted by honest players during the execution of a blockchain protocol. This definition formalizes the blockchains axioms discussed above.</p>

    <p class="text-gray-300">Definition 2 (Fork; [13]). Let  <span class="math">w \\in \\{0,1\\}^n</span>  and let  <span class="math">H = \\{i \\mid w_i = 0\\}</span> . A fork for the string  <span class="math">w</span>  consists of a directed and rooted tree  <span class="math">F = (V,E)</span>  with a labeling  <span class="math">\\ell : V \\to \\{0,1,\\dots,n\\}</span> . We insist that each edge of  <span class="math">F</span>  is directed away from the root vertex and further require that</p>

    <p class="text-gray-300">(F1.) the root vertex  <span class="math">r</span>  has label  <span class="math">\\ell(r) = 0</span> ; (F2.) the labels of vertices along any directed path are strictly increasing; (F3.) each index  <span class="math">i \\in H</span>  is the label for exactly one vertex of  <span class="math">F</span> ; (F4.) for any vertices  <span class="math">i, j \\in H</span> , if  <span class="math">i &amp;lt; j</span> , then the depth of vertex  <span class="math">i</span>  in  <span class="math">F</span>  is strictly less than the depth of vertex  <span class="math">j</span>  in  <span class="math">F</span> .</p>

    <p class="text-gray-300">If  <span class="math">F</span>  is a fork for the characteristic string  <span class="math">w</span> , we write  <span class="math">F \\vdash w</span> . Note that the conditions (F1.)-(F4.) are direct analogues of the axioms A1-A4 above. See Fig. 1 for an example fork. A final notational convention: If  <span class="math">F \\vdash x</span>  and  <span class="math">\\hat{F} \\vdash w</span> , we say that  <span class="math">F</span>  is a prefix of  <span class="math">\\hat{F}</span> , written  <span class="math">F \\sqsubseteq \\hat{F}</span> , if  <span class="math">x \\preceq w</span>  and  <span class="math">F</span>  appears as a consistently-labeled subgraph of  <span class="math">\\hat{F}</span> . (Specifically, each path of  <span class="math">F</span>  appears, with identical labels, in  <span class="math">\\hat{F}</span> .)</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Figure 1: A fork  <span class="math">F</span>  for the characteristic string  <span class="math">w = 010100110</span> ; vertices appear with their labels and honest vertices are highlighted with double borders. Note that the depths of the (honest) vertices associated with the honest indices of  <span class="math">w</span>  are strictly increasing. Note, also, that this fork has two disjoint paths of maximum depth.</p>

    <p class="text-gray-300">Let  <span class="math">w</span>  be a characteristic string. The directed paths in the fork  <span class="math">F \\vdash w</span>  originating from the root are called tines; these are abstract representations of blockchains. (Note that a tine might not terminate at a leaf of the fork.) We naturally extend the label function  <span class="math">\\ell</span>  for tines: i.e.,  <span class="math">\\ell(t) \\triangleq \\ell(v)</span>  where the tine  <span class="math">t</span>  terminates at vertex  <span class="math">v</span> . The length of a tine  <span class="math">t</span>  is denoted by  <span class="math">\\text{length}(t)</span> .</p>

    <p class="text-gray-300">Viable tines. The longest-chain rule dictates that honest players build on chains that are at least as long as all previously broadcast honest chains. It is convenient to distinguish such tines in the analysis: specifically, a tine  <span class="math">t</span>  of  <span class="math">F</span>  is called viable if its length is at least the depth of any honest vertex  <span class="math">v</span>  for which  <span class="math">\\ell(v) \\leq \\ell(t)</span> . A tine  <span class="math">t</span>  is viable at slot  <span class="math">s</span>  if the portion of  <span class="math">t</span>  appearing over slots  <span class="math">0, \\ldots, s</span>  has length at least that of any honest vertices labeled from this set. (As noted, the properties (F3.) and (F4.) together imply that an honest observer at slot  <span class="math">s</span>  will only adopt a viable tine.) The honest depth function  <span class="math">\\mathbf{d}: H \\to [n]</span>  gives the depth of the (unique) vertex associated with an honest slot; by (F4.),  <span class="math">\\mathbf{d}(\\cdot)</span>  is strictly increasing.</p>

    <p class="text-gray-300">We are now ready to explore the power of an adversary in this setting who has corrupted a (perhaps evolving) coalition of the players. We focus on the possibility that such an adversary can blatantly confound consistency of the honest player's blockchains. In particular, we consider the possibility that, at some time  <span class="math">t</span> , the adversary conspires to produce two blockchains of maximum length that diverge prior to a previous slot  <span class="math">s \\leq t</span> ; in this case honest players adopting the longest-chain rule may clearly disagree about the history of the blockchain after slot  <span class="math">s</span> . We call such a circumstance a settlement violation.</p>

    <p class="text-gray-300">To reflect this in our abstract language, let  <span class="math">F \\vdash w</span>  be a fork corresponding to an execution with characteristic string  <span class="math">w</span> . Such a settlement violation induces two viable tines  <span class="math">t_1, t_2</span>  with the same length that diverge prior to a particular slot of interest. We record this below.</p>

    <h6 id="sec-12" class="text-base font-medium mt-4">Definition 3 (Settlement with parameters <span class="math">s,k\\in\\mathbb{N}</span>).</h6>

    <p class="text-gray-300">Let <span class="math">w\\in\\{0,1\\}^{n}</span> be a characteristic string. Let <span class="math">F\\vdash w_{1}\\ldots w_{t}</span> be a fork for a prefix of <span class="math">w</span> with <span class="math">s+k\\leq t\\leq n</span>. We say that a slot <span class="math">s</span> is not <span class="math">k</span>-settled in <span class="math">F</span> if the fork contains two tines <span class="math">t_{1},t_{2}</span> of maximum length that “diverge prior to <span class="math">s</span>,” i.e., they either contain different vertices labeled with <span class="math">s</span>, or one contains a vertex labeled with <span class="math">s</span> while the other does not. Note that such tines are viable by definition. Otherwise, slot <span class="math">s</span> is <span class="math">k</span>-settled in <span class="math">F</span>. We say that a slot <span class="math">s</span> is <span class="math">k</span>-settled (for the characteristic string <span class="math">w</span>) if it is <span class="math">k</span>-settled in every fork <span class="math">F\\vdash w_{1},\\ldots w_{t}</span>, for each <span class="math">t\\geq s+k</span>.</p>

    <h4 id="sec-13" class="text-lg font-semibold mt-6">Common prefix.</h4>

    <p class="text-gray-300">Settlement violations are a convenient and intuitive proxy for the notion of common prefix discussed in the introduction. Indeed, as we show in Section 4, the two notions are equivalent, so we have the luxury of discussing settlement violations which have the advantage of a more ready interpretation. Concretely, we will simultaneously upper bound—using the same analytic techniques—the probability of settlement violations and common prefix violations.</p>

    <p class="text-gray-300">Recall that the common prefix property with parameter <span class="math">k</span> asserts that, for any slot index <span class="math">s</span>, if an honest observer at slot <span class="math">s+k</span> adopts a blockchain <span class="math">\\mathcal{C}</span>, the prefix <span class="math">\\mathcal{C}[0:s]</span> will be present in every honestly-held blockchain at or after slot <span class="math">s+k</span>. (Here, <span class="math">\\mathcal{C}[0:s]</span> denotes the prefix of the blockchain <span class="math">\\mathcal{C}</span> containing only the blocks issued from slots <span class="math">0,1,\\ldots,s</span>.)</p>

    <p class="text-gray-300">We translate this property into the framework of forks. Consider a tine <span class="math">t</span> of a fork <span class="math">F\\vdash w</span>. The trimmed tine <span class="math">t^{\\lceil k}</span> is defined as the portion of <span class="math">t</span> labeled with slots <span class="math">\\{0,...\\,,\\ell(t)-k\\}</span>. For two tines, we use the notation <span class="math">t_{1}\\preceq t_{2}</span> to indicate that the tine <span class="math">t_{1}</span> is a prefix of tine <span class="math">t_{2}</span>.</p>

    <h6 id="sec-14" class="text-base font-medium mt-4">Definition 4 (Common Prefix Property with parameter <span class="math">k\\in\\mathbb{N}</span>).</h6>

    <p class="text-gray-300">Let <span class="math">w</span> be a characteristic string. A fork <span class="math">F\\vdash w</span> satisfies <span class="math">k</span>-<span class="math">\\mathrm{CP}^{\\mathrm{slot}}</span> if, for all pairs <span class="math">(t_{1},t_{2})</span> of viable tines <span class="math">F</span> for which <span class="math">\\ell(t_{1})\\leq\\ell(t_{2})</span>, we have <span class="math">t_{1}^{\\lceil k}\\preceq t_{2}</span>. Otherwise, we say that the tine-pair <span class="math">(t_{1},t_{2})</span> is a witness to a <span class="math">k</span>-<span class="math">\\mathrm{CP}^{\\mathrm{slot}}</span> violation. Finally, <span class="math">w</span> satisfies <span class="math">k</span>-<span class="math">\\mathrm{CP}^{\\mathrm{slot}}</span> if every fork <span class="math">F\\vdash w</span> satisfies <span class="math">k</span>-<span class="math">\\mathrm{CP}^{\\mathrm{slot}}</span>.</p>

    <p class="text-gray-300">If a string <span class="math">w</span> does not possess the <span class="math">k</span>-<span class="math">\\mathrm{CP}^{\\mathrm{slot}}</span> property, we say that <span class="math">w</span> violates <span class="math">k</span>-<span class="math">\\mathrm{CP}^{\\mathrm{slot}}</span>. Observe that we defined the common prefix property in terms of deleting any blocks associated with the last <span class="math">k</span> trailing slots from a local blockchain <span class="math">\\mathcal{C}</span>. Traditionally (cf. <em>[10]</em>), this property has been defined in terms of deleting a suffix of (block-)length <span class="math">k</span> from <span class="math">\\mathcal{C}</span>. We denote the block-deletion-based version of the common prefix property as the <span class="math">k</span>-CP property. Note, however, that a <span class="math">k</span>-CP violation immediately implies a <span class="math">k</span>-<span class="math">\\mathrm{CP}^{\\mathrm{slot}}</span> violation, so bounding the probability of a <span class="math">k</span>-<span class="math">\\mathrm{CP}^{\\mathrm{slot}}</span> violation is sufficient to rule out both events.</p>

    <h3 id="sec-15" class="text-xl font-semibold mt-8">2.3 Adversarial attacks on settlement time; the settlement game</h3>

    <p class="text-gray-300">To clarify the relationship between forks and the chains at play in a canonical blockchain protocol, we define a game-based model below that explicitly describes the relationship between forks and executions. By design, the probability that the adversary wins this game is at most the probability that a slot <span class="math">s</span> is not <span class="math">k</span>-settled. We remark that while we focus on settlement violations for clarity, one could equally well have designed the game around common prefix violations.</p>

    <p class="text-gray-300">Consider the <span class="math">(\\mathcal{D},T;s,k)</span>-settlement game, played between an adversary <span class="math">\\mathcal{A}</span> and a challenger <span class="math">\\mathcal{C}</span> with a leader election mechanism modeled by an ideal distribution <span class="math">\\mathcal{D}</span>. Intuitively, the game should reflect the ability of the adversary to achieve a settlement violation; that is, to present two maximally-long viable blockchains to a future honest observer, thus forcing them to choose between two alternate histories which disagree on slot <span class="math">s</span>. The challenger plays the role(s) of the honest players during the protocol.</p>

    <p class="text-gray-300">Note that in typical PoS settings the distribution <span class="math">\\mathcal{D}</span> is determined by the combined stake held by the adversarial players, the leader election mechanism, and the dynamics of the protocol. The most common case (as seen in Snow White <em>[21]</em> and Ouroboros <em>[13]</em>) guarantees that the characteristic string <span class="math">w=w_{1}\\ldots w_{T}</span> is drawn from an i.i.d. distribution for which <span class="math">\\Pr[w_{i}=1]\\leq(1-\\varepsilon)/2</span>; here the constant <span class="math">(1-\\varepsilon)/2</span> is directly related to the stake held by the adversary. Settings involving adaptive adversaries (e.g., Ouroboros Praos <em>[6]</em> and Ouroboros Genesis <em>[2]</em>) yield the weaker martingale-type guarantee that <span class="math">\\Pr[w_{i}=1\\mid w_{1},...\\,,w_{i-1}]\\leq(1-\\varepsilon)/2</span>.</p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">The <span class="math">(\\mathcal{D},T;s,k)</span>-settlement game</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>A characteristic string <span class="math">w\\in\\{0,1\\}^{T}</span> is drawn from <span class="math">\\mathcal{D}</span> and provided to <span class="math">\\mathcal{A}</span>. (This reflects the results of the leader election mechanism.)</li>

      <li>Let <span class="math">A_{0}\\vdash\\varepsilon</span> denote the initial fork for the empty string <span class="math">\\varepsilon</span> consisting of a single node corresponding to the genesis block.</li>

      <li>For each slot <span class="math">t=1,...\\,,T</span> in increasing order:</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>If <span class="math">w_{t}=0</span>, this is an honest slot. In this case, the challenger is given the fork <span class="math">A_{t-1}\\vdash w_{1}\\ldots w_{t-1}</span> and must determine a new fork <span class="math">F_{t}\\vdash w_{1}\\ldots w_{t}</span> by adding a single vertex (labeled with <span class="math">t</span>) to the end of a longest path in <span class="math">A_{t-1}</span>. (If there are ties, <span class="math">\\mathcal{A}</span> may choose which path the challenger adopts.)</li>

      <li>If <span class="math">w_{t}=1</span>, this is an adversarial slot. <span class="math">\\mathcal{A}</span> may set <span class="math">F_{t}\\vdash w_{1}\\ldots w_{t}</span> to be an arbitrary fork for which <span class="math">A_{t-1}\\sqsubseteq F_{t}</span>.</li>

      <li>(Adversarial augmentation.) <span class="math">\\mathcal{A}</span> determines an arbitrary fork <span class="math">A_{t}\\vdash w_{1}\\ldots,w_{t}</span> for which <span class="math">F_{t}\\sqsubseteq A_{t}</span>.</li>

    </ol>

    <p class="text-gray-300">Recall that <span class="math">F\\sqsubseteq F^{\\prime}</span> indicates that <span class="math">F^{\\prime}</span> contains, as a consistently-labeled subgraph, the fork <span class="math">F</span>.</p>

    <p class="text-gray-300"><span class="math">\\mathcal{A}</span> wins the settlement game if slot <span class="math">s</span> is not <span class="math">k</span>-settled in some fork <span class="math">A_{t}</span> (with <span class="math">t\\geq s+k</span>).</p>

    <h6 id="sec-16" class="text-base font-medium mt-4">Definition 5.</h6>

    <p class="text-gray-300">Let <span class="math">\\mathcal{D}</span> be a distribution on <span class="math">\\{0,1\\}^{T}</span>. Then define the <span class="math">(s,k)</span>-settlement insecurity of <span class="math">\\mathcal{D}</span> to be</p>

    <p class="text-gray-300"><span class="math">\\mathbf{S}^{s,k}[\\mathcal{D}]\\triangleq\\max_{\\mathcal{A}}\\,\\Pr[\\mathcal{A}\\text{ wins the }(\\mathcal{D},T;s,k)\\text{-settlement game}]\\,,</span></p>

    <p class="text-gray-300">this maximum taken over all adversaries <span class="math">\\mathcal{A}</span>.</p>

    <h5 id="sec-17" class="text-base font-semibold mt-4">Remarks.</h5>

    <p class="text-gray-300">Observe that the adversarial augmentation step permits the adversary to “suddenly” inject new paths in the fork between two honest players at adjacent slots; this corresponds to circumstances when the adversary chooses to deliver a new blockchain to an honest participant which may consist of an earlier honest chain with some adversarial blocks appended to the end. Observe, additionally, that the behavior of the challenger in the game is entirely deterministic, as it simply plays according to the longest-chain rule (even permitting the adversary to break ties). Thus the result of the game is entirely determined by the characteristic string <span class="math">w</span> drawn from <span class="math">\\mathcal{D}</span> and the choices of the adversary <span class="math">\\mathcal{A}</span>. We record the following immediate conclusion:</p>

    <h6 id="sec-18" class="text-base font-medium mt-4">Lemma 1.</h6>

    <p class="text-gray-300">Let <span class="math">s,k,T\\in\\mathbb{N}</span>. Let <span class="math">\\mathcal{D}</span> be a distribution on <span class="math">\\{0,1\\}^{T}</span>. Then</p>

    <p class="text-gray-300"><span class="math">\\mathbf{S}^{s,k}[\\mathcal{D}]\\leq\\Pr_{w\\sim\\mathcal{D}}[\\text{slot </span>s<span class="math"> is not </span>k<span class="math">-settled for </span>w<span class="math">}]\\,.</span></p>

    <p class="text-gray-300">In the subsequent sections, we will develop some further notation and tools to analyze this event. We will investigate two different families of distributions, those with i.i.d. coordinates and those with martingale-type conditioning guarantees. For <span class="math">T\\in\\mathbb{N}</span> and <span class="math">\\varepsilon\\in(0,1)</span>, let <span class="math">B_{\\varepsilon}=(B_{1},...,B_{n})</span> denote the random variable taking values in <span class="math">\\{0,1\\}^{n}</span> so that the <span class="math">B_{i}</span> are independent and <span class="math">\\Pr[B_{i}=1]=(1-\\varepsilon)/2</span>; we let <span class="math">\\mathcal{B}_{\\varepsilon}</span> denote the distribution on <span class="math">\\{0,1\\}^{n}</span> associated with <span class="math">B_{\\varepsilon}</span>. When <span class="math">\\varepsilon</span> can be inferred from context, we simply write <span class="math">B</span> and <span class="math">\\mathcal{B}</span>.</p>

    <p class="text-gray-300">We also study a more general family of distributions, defined next.</p>

    <h6 id="sec-19" class="text-base font-medium mt-4">Definition 6 (<span class="math">\\varepsilon</span>-martingale condition).</h6>

    <p class="text-gray-300">Let <span class="math">W=(W_{1},...,W_{n})</span> be a random variable taking values in <span class="math">\\{0,1\\}^{n}</span>. We say that <span class="math">W</span> satisfies the <span class="math">\\varepsilon</span>-martingale condition if for each <span class="math">t\\in\\{1,...\\,,n\\}</span>,</p>

    <p class="text-gray-300"><span class="math">\\mathbb{E}[W_{t}\\mid W_{1},\\cdots,W_{t-1}]\\leq(1-\\varepsilon)/2\\,.</span></p>

    <p class="text-gray-300">Equivalently, <span class="math">\\Pr[W_{t}=1\\mid W_{1},...,W_{t-1}]\\leq(1-\\varepsilon)/2</span>. The conditioning on the variables <span class="math">W_{1},\\cdots,W_{t-1}</span> is arbitrary in both cases; as a consequence, <span class="math">\\Pr[W_{t}=1]\\leq(1-\\varepsilon)/2</span>. As a matter of notation, we let <span class="math">\\mathcal{W}</span> denote the distribution</p>

    <p class="text-gray-300">associated with the random variable <span class="math">W</span>. We use the term “<span class="math">\\epsilon</span>-martingale condition” to qualify both a random variable and its distribution.</p>

    <p class="text-gray-300">There are settings, such as Genesis <em>[2]</em>, where this martingale-type conditioning is important. Note that <span class="math">\\mathcal{B}_{\\epsilon}</span> satisfies the <span class="math">\\epsilon</span>-martingale condition. Now we are ready to state our main theorem.</p>

    <h6 id="sec-20" class="text-base font-medium mt-4">Theorem 1 (Main theorem).</h6>

    <p class="text-gray-300">Let <span class="math">\\epsilon\\in(0,1),s,k,T\\in\\mathbb{N}</span>. Let <span class="math">\\mathcal{W}</span> and <span class="math">\\mathcal{B}_{\\epsilon}</span> be two distributions on <span class="math">\\{0,1\\}^{T}</span> where <span class="math">\\mathcal{B}_{\\epsilon}</span> is defined above and <span class="math">\\mathcal{W}</span> satisfies the <span class="math">\\epsilon</span>-martingale condition. Then</p>

    <p class="text-gray-300"><span class="math">\\mathbf{S}^{s,k}[\\mathcal{W}]\\leq\\mathbf{S}^{s,k}[\\mathcal{B}_{\\epsilon}]\\leq\\exp\\bigl{(}-\\Omega(\\epsilon^{3}(1-O(\\epsilon))k)\\bigr{)}\\,.</span></p>

    <p class="text-gray-300">(Here, the asymptotic notation hides constants that do not depend on <span class="math">\\epsilon</span> or <span class="math">k</span>.)</p>

    <p class="text-gray-300">By techniques similar to the ones used to prove this result, we obtain the following theorem pertaining directly to <span class="math">k</span>-CP^{slot} (and <span class="math">k</span>-CP).</p>

    <h6 id="sec-21" class="text-base font-medium mt-4">Theorem 2 (Main theorem; <span class="math">k</span>-CP version).</h6>

    <p class="text-gray-300">Let <span class="math">\\epsilon\\in(0,1)</span> and <span class="math">T\\in\\mathbb{N}</span>. Let <span class="math">w\\in\\{0,1\\}^{T}</span> be a random variable satisfying the <span class="math">\\epsilon</span>-martingale condition. Then</p>

    <p class="text-gray-300"><span class="math">\\Pr[w\\text{ violates }k\\text{-CP}]\\leq\\Pr[w\\text{ violates }k\\text{-CP}^{\\text{slot}}]\\leq T\\cdot\\exp\\bigl{(}-\\Omega(\\epsilon^{3}(1-O(\\epsilon))k)\\bigr{)}\\,.</span></p>

    <p class="text-gray-300">The proofs of these theorems are presented in Section 6.5. Additionally, we provide a <span class="math">O(k^{3})</span>-time algorithm for computing an explicit upper bound on these probabilities; cf. Appendix A.</p>

    <h3 id="sec-22" class="text-xl font-semibold mt-8">2.4 Survey of the proofs of the main theorems</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A central object in our combinatorial analysis is an “<span class="math">x</span>-balanced fork” for a characteristic string <span class="math">w=xy</span>. Such a fork contains two distinct, maximum-length tines that are disjoint over <span class="math">y</span>; see Definition 9 for details. A settlement violation for the slot $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+1<span class="math"> implies an </span>x<span class="math">-balanced fork for the string </span>xy<span class="math">; see Observation 1. In particular, for any distribution on characteristic strings in </span>\\{0,1\\}^{n}<span class="math"> and </span>s+k\\leq n$,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">$\\Pr[\\text{slot }s\\text{ is not }k\\text{-settled}]\\leq\\Pr_{w}\\left[\\begin{array}[]{l}\\text{there is a decomposition }w=xyz\\text{ and }\\\\</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\text{a fork }F\\vdash xy\\text{, where }</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=s-1\\text{ and }\\\\</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">(This is a variant of Lemma 5 from Section 6.5.)</p>

    <p class="text-gray-300">As promised above, common prefix violations can be handled the same way: we likewise establish (see Section 4; Theorem 3) that a common prefix violation implies that there exists a balanced fork for some prefix of <span class="math">w</span>. Specifically, for any distribution of characteristic strings,</p>

    <p class="text-gray-300"><span class="math">\\Pr_{w}[\\text{</span>w$ violates }k\\text{-CP}^{\\text{slot}}]\\leq\\Pr_{w}\\left[\\begin{array}[]{l}\\text{there is a decomposition }w=xyz\\text{ and }\\\\</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\text{a fork }F\\vdash xy\\text{, where }</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k+1\\text{, so }\\\\</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">\\text{that }F\\text{ is }x\\text{-balanced}\\end{array}\\right]\\,.$ (1)</p>

    <p class="text-gray-300">Next, in Section 5, we give a recursive expression for the combinatorial quantity “relative margin,” written <span class="math">\\mu_{x}(y)</span> (see Definition 13 in Section 3). We establish that, for an arbitrary decomposition of the characteristic string <span class="math">w=xy</span>, the event “there is an <span class="math">x</span>-balanced fork for <span class="math">xy</span>” is equivalent to the event “the relative margin <span class="math">\\mu_{x}(y)</span> is non-negative;” this is Fact 1. In Lemma 3, we develop an exact recursive presentation for <span class="math">\\mu_{x}(y)</span>; hence we can bound the probability of a common prefix violation (or a settlement violation) by reasoning about the non-negativity of the relative margin and, in particular, without reasoning directly about forks.</p>

    <p class="text-gray-300">In Section 6, we prove two bounds for the probability</p>

    <p class="text-gray-300">$\\Pr_{\\begin{subarray}{c}w=xy\\\\</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=s\\end{subarray}}[\\mu_{x}(y)\\geq 0]\\,,$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">for a fixed length <span class="math">s</span>. The first bound pertains to the setting where <span class="math">w=xy</span> is drawn from <span class="math">\\mathcal{B}_{\\epsilon}</span>. The second pertains to any distribution <span class="math">\\mathcal{W}</span> satisfying the <span class="math">\\epsilon</span>-martingale condition. For characteristic strings with distribution <span class="math">\\mathcal{B}_{\\epsilon}</span>, we</p>

    <p class="text-gray-300">identify a random variable which stochastically dominates <span class="math">\\mu_{x}(y)</span> and is amenable to exact analysis via generating functions; this yields the bound</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\Pr_{w=xy}\\left[\\mu_{x}(y)\\geq 0\\right]\\leq\\exp(-\\Omega(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">))\\,.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Notice that this bound does not depend on <span class="math">s</span>, the length of <span class="math">x</span>. The result for distributions satisfying the <span class="math">\\epsilon</span>-martingale condition then follows from stochastic dominance (Lemma 4). See Section 6 for details.</p>

    <p class="text-gray-300">It immediately follows that an <span class="math">(s,k)</span>-settlement violation (or a <span class="math">k</span>-CP^{shet} violation) is a rare event for distributions of interest. The multiplicative factor <span class="math">T</span> in Theorem 2 comes from a union bound taken over all prefixes of <span class="math">w</span>.</p>

    <h3 id="sec-23" class="text-xl font-semibold mt-8">2.5 Comments on the model</h3>

    <h4 id="sec-24" class="text-lg font-semibold mt-6">Analysis in the <span class="math">\\Delta</span>-synchronous setting.</h4>

    <p class="text-gray-300">The security game above most naturally models a blockchain protocol over a synchronous network with immediate delivery (because each “honest” play of the challenger always builds on a fork that contains the fork generated by previous honest plays). However, the model can be easily adapted to protocols in the <span class="math">\\Delta</span>-synchronous model adopted by the Snow White and Ouroboros Praos protocols and analyses. In particular, David et al. <em>[6]</em> developed a “<span class="math">\\Delta</span>-reduction” mapping on the space of characteristic strings that permits analyses of forks (and the related statistics of interest, cf. §3) in the <span class="math">\\Delta</span>-synchronous setting by a direct appeal to the synchronous setting.</p>

    <h4 id="sec-25" class="text-lg font-semibold mt-6">Public leader schedules.</h4>

    <p class="text-gray-300">One attractive feature of this model is that it gives the adversary full information about the future schedule of leaders. The analysis of some protocols indeed demand this (e.g., Ouroboros, Snow White). Other protocols—especially those designed to offer security against adaptive adversaries (Praos, Genesis)—in fact contrive to keep the leader schedule private. Of course, as our analysis is in the more difficult “full information” model, it applies to all of these systems.</p>

    <h4 id="sec-26" class="text-lg font-semibold mt-6">Bootstrapping multi-phase algorithms; stake shift.</h4>

    <p class="text-gray-300">We remark that several existing proof-of-stake blockchain protocols proceed in phases, each of which is obligated to generate the randomness (for leader election, say) for the next phase based on the current stake distribution. The blockchain security properties of each phase are then individually analyzed—assuming clean randomness—which yields a recursive security argument; in this context the game outlined above precisely reflects the single phase analysis.</p>

    <h2 id="sec-27" class="text-2xl font-bold">3 Definitions</h2>

    <p class="text-gray-300">We rely on the elementary framework of forks and margin from Kiayias et al. <em>[13]</em>. We restate and briefly discuss the pertinent definitions below. With these basic notions behind us, we then define a new “relative” notion of margin, which will allow us to significantly improve the efficacy of these tools for reasoning about settlement times.</p>

    <p class="text-gray-300">Recall that for a given execution of the protocol, we record the result of the leader election process via a <em>characteristic string</em> <span class="math">w\\in\\{0,1\\}^{T}</span>, defined such that <span class="math">w_{i}=0</span> when a unique and honest party is assigned to slot <span class="math">i</span> and <span class="math">w_{i}=1</span> otherwise. A vertex of a fork is said to be <em>honest</em> if it is labeled with an index <span class="math">i</span> such that <span class="math">w_{i}=0</span>.</p>

    <h6 id="sec-28" class="text-base font-medium mt-4">Definition 7 (Tines, length, and height).</h6>

    <p class="text-gray-300">Let <span class="math">F\\vdash w</span> be a fork for a characteristic string. A <em>tine</em> of <span class="math">F</span> is a directed path starting from the root. For any tine <span class="math">t</span> we define its <em>length</em> to be the number of edges in the path, and for any vertex <span class="math">v</span> we define its <em>depth</em> to be the length of the unique tine that ends at <span class="math">v</span>. If a tine <span class="math">t_{1}</span> is a strict prefix of another tine <span class="math">t_{2}</span>, we write <span class="math">t_{1}\\prec t_{2}</span>. Similarly, if <span class="math">t_{1}</span> is a non-strict prefix of <span class="math">t_{2}</span>, we write <span class="math">t_{1}\\preceq t_{2}</span>. The longest common prefix of two tines <span class="math">t_{1},t_{2}</span> is denoted by <span class="math">t_{1}\\cap t_{2}</span>. That is, <span class="math">\\ell(t_{1}\\cap t_{2})=\\max\\{\\ell(u)\\ :\\ u\\preceq t_{1}\\ \\text{and}\\ u\\preceq t_{2}\\}</span>. The height of a fork (as usual for a tree) is the length of the longest tine, denoted <span class="math">\\operatorname{height}(F)</span>.</p>

    <h6 id="sec-29" class="text-base font-medium mt-4">Definition 8 (The <span class="math">\\sim_{x}</span> relations).</h6>

    <p class="text-gray-300">For two tines <span class="math">t_{1}</span> and <span class="math">t_{2}</span> of a fork <span class="math">F</span>, we write <span class="math">t_{1}\\sim t_{2}</span> when <span class="math">t_{1}</span> and <span class="math">t_{2}</span> share an edge; otherwise we write <span class="math">t_{1}\\nsim t_{2}</span>. We generalize this equivalence relation to reflect whether tines share an edge over a particular suffix of <span class="math">w</span>: for <span class="math">w=xy</span> we define <span class="math">t_{1}\\sim_{x}t_{2}</span> if <span class="math">t_{1}</span> and <span class="math">t_{2}</span> share an edge that terminates at some node labeled</p>

    <p class="text-gray-300">with an index in  <span class="math">y</span> ; otherwise, we write  <span class="math">t_1 \\nrightarrow_x t_2</span>  (observe that in this case the paths share no vertex labeled by a slot associated with  <span class="math">y</span> ). We sometimes call such pairs of tines disjoint (or, if  <span class="math">t_1 \\nrightarrow_x t_2</span>  for a string  <span class="math">w = xy</span> , disjoint over  <span class="math">y</span> ). Note that  <span class="math">\\sim</span>  and  <span class="math">\\sim_{\\varepsilon}</span>  are the same relation.</p>

    <p class="text-gray-300">The basic structure we use to use to reason about settlement times is that of a "balanced fork."</p>

    <p class="text-gray-300">Definition 9 (Balanced fork; cf. "flat" in [13]). A fork  <span class="math">F</span>  is balanced if it contains a pair of tines  <span class="math">t_1</span>  and  <span class="math">t_2</span>  for which  <span class="math">t_1 \\nrightarrow t_2</span>  and  <span class="math">\\mathrm{length}(t_1) = \\mathrm{length}(t_2) = \\mathrm{height}(F)</span> . We define a relative notion of balance as follows: a fork  <span class="math">F \\vdash xy</span>  is  <span class="math">x</span> -balanced if it contains a pair of tines  <span class="math">t_1</span>  and  <span class="math">t_2</span>  for which  <span class="math">t_1 \\nrightarrow_x t_2</span>  and  <span class="math">\\mathrm{length}(t_1) = \\mathrm{length}(t_2) = \\mathrm{height}(F)</span> .</p>

    <p class="text-gray-300">Thus, balanced forks contain two completely disjoint, maximum-length tines, while  <span class="math">x</span> -balanced forks contain two maximum-length tines that may share edges in  <span class="math">x</span>  but must be disjoint over the rest of the string. See Figures 2 and 3 for examples of balanced forks.</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Figure 2: A balanced fork</p>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a> Figure 3: An  <span class="math">x</span> -balanced fork, where  <span class="math">x = 00</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Balanced forks and settlement time. A fundamental question arising in typical blockchain settings is how to determine settlement time, the delay after which the contents of a particular block of a blockchain can be considered stable. The existence of a balanced fork is a precise indicator for "settlement violations" in this sense. Specifically, consider a characteristic string  <span class="math">xy</span>  and a transaction appearing in a block associated with the first slot of  <span class="math">y</span>  (that is, slot  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+ 1<span class="math"> ). One clear violation of settlement at this point of the execution is the existence of two chains—each of maximum length—which diverge prior to  </span>y<span class="math"> ; in particular, this indicates that there is an  </span>x<span class="math"> -balanced fork  </span>F<span class="math">  for  </span>xy$ . Let us record this observation below.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Observation 1. Let  <span class="math">s, k \\in \\mathbb{N}</span>  be given and let  <span class="math">w</span>  be a characteristic string. Slot  <span class="math">s</span>  is not  <span class="math">k</span> -settled for the characteristic string  <span class="math">w</span>  if there exist a decomposition  <span class="math">w = xyz</span> , where  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= s - 1<span class="math">  and  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k + 1<span class="math"> , and an  </span>x<span class="math"> -balanced fork for  </span>xy$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In fact, every  <span class="math">k</span> -CP <span class="math">^{\\text{slot}}</span>  violation produces a balanced fork as well; see Theorem 3 in Section 4. In particular, to provide a rigorous  <span class="math">k</span> -slot settlement guarantee—which is to say that the transaction can be considered settled once  <span class="math">k</span>  slots have gone by—it suffices to show that with overwhelming probability in choice of the characteristic string determined by the leader election process (of a full execution of the protocol), no such forks are possible. Specifically, if the protocol runs for a total of  <span class="math">T</span>  time steps yielding the characteristics string  <span class="math">w = xy</span>  (where</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">w\\in\\{0,1\\}^{T}</span> and the transaction of interest appears in slot $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+1<span class="math"> as above) then it suffices to ensure that there is no </span>x<span class="math">-balanced fork for </span>x\\hat{y}<span class="math">, where </span>\\hat{y}<span class="math"> is an arbitrary prefix of </span>y<span class="math"> of length at least </span>k+1<span class="math">; see Corollary 1 in Section 6. Note that for systems adopting the longest chain rule, this condition must necessarily involve the <em>entire future dynamics</em> of the blockchain. We remark that our analysis below will in fact let us take </span>T=\\infty$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-30" class="text-base font-medium mt-4">Definition 10 (Closed fork).</h6>

    <p class="text-gray-300">A fork <span class="math">F</span> is <em>closed</em> if every leaf is honest. For convenience, we say the trivial fork is closed.</p>

    <p class="text-gray-300">Closed forks have two nice properties that make them especially useful in reasoning about the view of honest parties. First, a closed fork must have a unique longest tine (since honest parties are aware of all previous honest blocks, and honest parties observe the longest chain rule). Second, recalling our description of the settlement game, closed forks intuitively capture decision points for the adversary. The adversary can potentially show many tines to many honest parties, but once an honest node has been placed on top of a tine, any adversarial blocks beneath it are part of the public record and are visible to all honest parties. For these reasons, we will often find it easier to reason about closed forks than arbitrary forks.</p>

    <p class="text-gray-300">The next few definitions are the start of a general toolkit for reasoning about an adversary’s capacity to build highly diverging paths in forks, based on the underlying characteristic string.</p>

    <h6 id="sec-31" class="text-base font-medium mt-4">Definition 11 (Gap, reserve, and reach).</h6>

    <p class="text-gray-300">For a closed fork <span class="math">F\\vdash w</span> and its unique longest tine <span class="math">\\hat{t}</span>, we define the <em>gap</em> of a tine <span class="math">t</span> to be <span class="math">\\mathrm{gap}(t)=\\mathrm{length}(\\hat{t})-\\mathrm{length}(t)</span>. Furthermore, we define the <em>reserve</em> of <span class="math">t</span>, denoted <span class="math">\\mathrm{reserve}(t)</span>, to be the number of adversarial indices in <span class="math">w</span> that appear after the terminating vertex of <span class="math">t</span>. More precisely, if <span class="math">v</span> is the last vertex of <span class="math">t</span>, then</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\mathrm{reserve}(t)=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\{\\,i\\mid w_{i}=1\\text{ and }i>\\ell(v)\\}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">These quantities together define the <em>reach</em> of a tine: <span class="math">\\mathrm{reach}(t)=\\mathrm{reserve}(t)-\\mathrm{gap}(t)</span>.</p>

    <p class="text-gray-300">The notion of reach can be intuitively understood as a measurement of the resources available to our adversary in the settlement game. Reserve tracks the number of slots in which the adversary has the right to issue new blocks. When reserve exceeds gap (or equivalently, when reach is nonnegative), such a tine could be extended—using a sequence of dishonest blocks—until it is as long as the longest tine. Such a tine could be offered to an honest player who would prefer it over, e.g., the current longest tine in the fork. In contrast, a tine with negative reach is too far behind to be directly useful to the adversary at that time.</p>

    <h6 id="sec-32" class="text-base font-medium mt-4">Definition 12 (Maximum reach).</h6>

    <p class="text-gray-300">For a closed fork <span class="math">F\\vdash w</span>, we define <span class="math">\\rho(F)</span> to be the largest reach attained by any tine of <span class="math">F</span>, i.e.,</p>

    <p class="text-gray-300"><span class="math">\\rho(F)=\\max_{t}\\,\\mathrm{reach}(t)\\,.</span></p>

    <p class="text-gray-300">Note that <span class="math">\\rho(F)</span> is never negative (as the longest tine of any fork always has reach at least 0). We overload this notation to denote the maximum reach over all forks for a given characteristic string:</p>

    <p class="text-gray-300">\\[ \\rho(w)=\\max_{\\begin{subarray}{c}F\\vdash w\\\\ F\\text{ closed}\\end{subarray}}\\left[\\max_{t}\\,\\mathrm{reach}(t)\\right]. \\]</p>

    <h6 id="sec-33" class="text-base font-medium mt-4">Definition 13 (Margin).</h6>

    <p class="text-gray-300">The <em>margin</em> of a fork <span class="math">F\\vdash w</span>, denoted <span class="math">\\mu(F)</span>, is defined as</p>

    <p class="text-gray-300"><span class="math">\\mu(F)=\\max_{t_{1}=t_{2}}\\bigl{(}\\min\\{\\mathrm{reach}(t_{1}),\\mathrm{reach}(t_{2})\\}\\bigr{)}\\,,</span> (2)</p>

    <p class="text-gray-300">where this maximum is extended over all pairs of disjoint tines of <span class="math">F</span>; thus margin reflects the “second best” reach obtained over all disjoint tines. In order to study splits in the chain over particular portions of a string, we generalize this to define a “relative” notion of margin: If <span class="math">w=xy</span> for two strings <span class="math">x</span> and <span class="math">y</span> and, as above, <span class="math">F\\vdash w</span>, we define</p>

    <p class="text-gray-300"><span class="math">\\mu_{x}(F)=\\max_{t_{1}=_{x}t_{2}}\\bigl{(}\\min\\{\\mathrm{reach}(t_{1}),\\mathrm{reach}(t_{2})\\}\\bigr{)}\\,.</span></p>

    <p class="text-gray-300">Note that <span class="math">\\mu_{\\varepsilon}(F)=\\mu(F)</span>.</p>

    <p class="text-gray-300">######</p>

    <p class="text-gray-300">For convenience, we once again overload this notation to denote the margin of a string. <span class="math">\\mu(w)</span> refers to the maximum value of <span class="math">\\mu(F)</span> over all possible closed forks <span class="math">F</span> for a characteristic string <span class="math">w</span>:</p>

    <p class="text-gray-300"><span class="math">\\mu(w)=\\max_{\\begin{subarray}{c}F\\vdash w,\\\\F\\hbox{ closed}\\end{subarray}}\\mu(F)\\,.</span></p>

    <p class="text-gray-300">Likewise, if <span class="math">w=xy</span> for two strings <span class="math">x</span> and <span class="math">y</span> we define</p>

    <p class="text-gray-300"><span class="math">\\mu_{x}(y)=\\max_{\\begin{subarray}{c}F\\vdash w,\\\\F\\hbox{ closed}\\end{subarray}}\\mu_{x}(F)\\,.</span></p>

    <p class="text-gray-300">Note that, at least informally, “second-best” tines are of natural interest to an adversary intent on the construction of an <span class="math">x</span>-balanced fork, which involves two (partially disjoint) long tines.</p>

    <h4 id="sec-34" class="text-lg font-semibold mt-6">Balanced forks and relative margin.</h4>

    <p class="text-gray-300"><em>Kiayias et al. [13]</em> showed that a balanced fork can be constructed for a given characteristic string <span class="math">w</span> if and only if there exists some closed <span class="math">F\\vdash w</span> such that <span class="math">\\mu(F)\\geq 0</span>. We record a relative version of this theorem below, which will ultimately allow us to extend the analysis of <em>[13]</em> to more general class of disagreement and settlement failures.</p>

    <h6 id="sec-35" class="text-base font-medium mt-4">Fact 1.</h6>

    <p class="text-gray-300">Let <span class="math">xy\\in\\{0,1\\}^{n}</span> be a characteristic string. Then there is an <span class="math">x</span>-balanced fork <span class="math">F\\vdash xy</span> if and only if <span class="math">\\mu_{x}(y)\\geq 0</span>.</p>

    <h6 id="sec-36" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">The proof is immediate from the definitions. We sketch the details for completeness.</p>

    <p class="text-gray-300">Suppose <span class="math">F</span> is an <span class="math">x</span>-balanced fork for <span class="math">xy</span>. Then <span class="math">F</span> must contain a pair of tines <span class="math">t_{1}</span> and <span class="math">t_{2}</span> for which <span class="math">t_{1}\\nsim_{x}t_{2}</span> and <span class="math">\\mathrm{length}(t_{1})=\\mathrm{length}(t_{2})=\\mathrm{height}(F)</span>. We observe that (1) <span class="math">\\mathrm{gap}(t_{i})=0</span> for both <span class="math">t_{1}</span> and <span class="math">t_{2}</span>, and (2) reserve is always a nonnegative quantity. Together with the definition of reach, these two facts immediately imply <span class="math">\\mathrm{reach}(t_{i})\\geq 0</span>. Because <span class="math">t_{1}</span> and <span class="math">t_{2}</span> are edge-disjoint over <span class="math">y</span> and <span class="math">\\min\\{\\mathrm{reach}(t_{1}),\\mathrm{reach}(t_{2})\\}\\geq 0</span>, we conclude that <span class="math">\\mu_{x}(y)\\geq 0</span>, as desired.</p>

    <p class="text-gray-300">Suppose <span class="math">\\mu_{x}(y)\\geq 0</span>. Then there is some closed fork <span class="math">F</span> for <span class="math">xy</span> such that <span class="math">\\mu_{x}(F)\\geq 0</span>. By the definition of relative margin, we know that <span class="math">F</span> has two tines <span class="math">t_{1}</span>, <span class="math">t_{2}</span> such that <span class="math">t_{1}\\nsim_{x}t_{2}</span> and <span class="math">\\mathrm{reach}(t_{i})\\geq 0</span>. Recall that we define reach by <span class="math">\\mathrm{reach}(t)=\\mathrm{reserve}(t)-\\mathrm{gap}(t)</span>, and so in this case it follows that <span class="math">\\mathrm{reserve}(t_{i})-\\mathrm{gap}(t_{i})\\geq 0</span>. Thus, an <span class="math">x</span>-balanced fork <span class="math">F^{\\prime}\\vdash xy</span> can be constructed from <span class="math">F</span> by appending a path of <span class="math">\\mathrm{gap}(t_{i})</span> adversarial vertices to each <span class="math">t_{i}</span>. ∎</p>

    <p class="text-gray-300">As indicated above, we can define the “forkability” of a characteristic string in terms of its margin.</p>

    <h6 id="sec-37" class="text-base font-medium mt-4">Definition 14 (Forkable strings).</h6>

    <p class="text-gray-300">A charactersitic string <span class="math">w</span> is <em>forkable</em> if its margin is non-negative, i.e., <span class="math">\\mu(w)\\geq 0</span>. Equivalently, <span class="math">w</span> is forkable if there is a balanced fork for <span class="math">w</span>.</p>

    <p class="text-gray-300">Although this definition is not necessary for our presentation, it reflects the terminology of existing literature.</p>

    <h2 id="sec-38" class="text-2xl font-bold">4 Common prefix violation and balanced forks</h2>

    <p class="text-gray-300">In this section, we show that a common prefix violation implies the existence of a balanced fork. This allows us to bound consistency errors by reasoning about balanced forks. In particular, inequality (1) is a direct consequence of the theorem below.</p>

    <h6 id="sec-39" class="text-base font-medium mt-4">Theorem 3.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">k,T\\in\\mathbb{N}</span>. Let <span class="math">w\\in\\{0,1\\}^{T}</span> be a characteristic string which violates <span class="math">k</span>-<span class="math">\\mathrm{CP}^{\\mathrm{slot}}</span>. Then there exist a decomposition <span class="math">w=xyz</span> and a fork <span class="math">\\hat{F}\\vdash xy</span>, where $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k+1<span class="math">, so that </span>\\hat{F}<span class="math"> is </span>x$-balanced.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-40" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Recall that <span class="math">\\ell(t)</span> is the slot index of the last vertex of tine <span class="math">t</span>. Define <span class="math">A\\triangleq\\bigcup_{F\\vdash w}A_{F}</span> where, for a given fork <span class="math">F\\vdash w</span>, define</p>

    <p class="text-gray-300">\\[ A_{F}\\triangleq\\begin{cases}\\quad&\\tau_{1},\\tau_{2}\\text{ are two viable tines in the fork }F,\\\\ (\\tau_{1},\\tau_{2})\\;:\\;\\ell(\\tau_{1})\\leq\\ell(\\tau_{2}),\\text{ and the pair }(\\tau_{1},\\tau_{2})\\text{ is a}\\\\ &\\text{ witness to a }k\\text{-}\\mathrm{CP}^{\\mathrm{slot}}\\text{ violation}\\end{cases}\\,. \\]</p>

    <p class="text-gray-300">Define the <em>slot divergence</em> of two tines as <span class="math">\\operatorname{div}_{\\mathrm{slot}}(\\tau_{1},\\tau_{2})\\triangleq\\ell(\\tau_{1})-\\ell(\\tau_{1}\\cap\\tau_{2})</span> where <span class="math">\\tau_{1}\\cap\\tau_{2}</span> denotes the common prefix of the tines <span class="math">\\tau_{1}</span> and <span class="math">\\tau_{2}</span>. Recalling the definition of a <span class="math">k</span>-<span class="math">\\mathrm{CP}^{\\mathrm{slot}}</span> violation, it is clear that</p>

    <p class="text-gray-300"><span class="math">\\operatorname{div}_{\\mathrm{slot}}(\\tau_{1},\\tau_{2})\\geq k+1\\quad\\text{for all }(\\tau_{1},\\tau_{2})\\in A\\,.</span> (3)</p>

    <p class="text-gray-300">Notice that there must be a tine-pair <span class="math">(t_{1},t_{2})\\in A</span> which satisfies the following two conditions:</p>

    <p class="text-gray-300"><span class="math">\\operatorname{div}_{\\mathrm{slot}}(t_{1},t_{2})\\text{ is maximal over }A\\,,\\text{and}</span> (4)</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\ell(t_{2})-\\ell(t_{1})</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\text{ is minimal among all tine-pairs in }A\\text{ for which \\eqref{eq:tine_pairs} holds.}$ (5)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The tines <span class="math">t_{1},t_{2}</span> will play a special role in our proof; let <span class="math">F</span> be a fork containing these tines.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The prefix <span class="math">x</span>, fork <span class="math">F_{x}</span>, and vertex <span class="math">u</span>. Let <span class="math">u</span> denote the last vertex on the tine <span class="math">t_{1}\\cap t_{2}</span>, as shown in the diagram below, and let <span class="math">\\alpha\\triangleq\\ell(u)=\\ell(t_{1}\\cap t_{2})</span>. Let <span class="math">x\\triangleq w_{1},\\ldots,w_{\\alpha}</span> and let <span class="math">F_{x}</span> be the fork-prefix of <span class="math">F</span> supported on <span class="math">x</span>. We will argue that <span class="math">u</span> must be honest and, in addition, that <span class="math">F_{x}</span> must contain a unique longest tine <span class="math">t_{u}</span> terminating at the vertex <span class="math">u</span>. We will also identify a substring <span class="math">y</span>, $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k+1<span class="math"> such that </span>w<span class="math"> can be written as </span>w=xyz<span class="math">. Then we will construct a balanced fork </span>\\bar{F}_{y}\\vdash y<span class="math"> by modifying the subgraph of </span>F<span class="math"> supported on </span>y<span class="math">. We will finish the proof by constructing an </span>x<span class="math">-balanced fork by suitably appending </span>\\bar{F}_{y}<span class="math"> to </span>F_{x}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">u</span> must be an honest vertex. We observe, first of all, that the vertex <span class="math">u</span> cannot be adversarial: otherwise it is easy to construct an alternative fork <span class="math">F^{\\prime}\\vdash w</span> and a pair of tines in <span class="math">F^{\\prime}</span> that violate (4). Specifically, construct <span class="math">F^{\\prime}</span> from <span class="math">F</span> by adding a new (adversarial) vertex <span class="math">u^{\\prime}</span> to <span class="math">F</span> for which <span class="math">\\ell(u^{\\prime})=\\ell(u)</span>, adding an edge to <span class="math">u^{\\prime}</span> from the vertex preceding <span class="math">u</span>, and replacing the edge of <span class="math">t_{1}</span> following <span class="math">u</span> with one from <span class="math">u^{\\prime}</span>; then the other relevant properties of the fork are maintained, but the slot divergence of the resulting tines has increased by at least one. (See the diagram below.)</p>

    <p class="text-gray-300"><span class="math">F_{x}</span> has a unique, longest (and honest) tine <span class="math">t_{u}</span>. A similar argument implies that the fork <span class="math">F_{x}</span> has a unique vertex of depth <span class="math">\\mathrm{depth}(u)</span>: namely, <span class="math">u</span> itself. In the presence of another vertex <span class="math">u^{\\prime}</span> (of <span class="math">F_{x}</span>) with depth <span class="math">\\mathrm{depth}(u)</span>, “redirecting” <span class="math">t_{1}</span> through <span class="math">u^{\\prime}</span> (as in the argument above) would likewise result in a fork with a larger slot divergence. To see this, notice that <span class="math">\\ell(u^{\\prime})</span> must be strictly less than <span class="math">\\ell(u)</span> since <span class="math">\\ell(u)</span> is an honest slot (which means <span class="math">u</span> is the only vertex at that slot). Thus <span class="math">\\ell(\\cdot)</span> would indeed be increasing along this new tine (resulting from redirecting <span class="math">t_{1}</span>). As <span class="math">\\alpha</span> is the last index of the string <span class="math">x</span>, this additionally implies that <span class="math">F_{x}</span> has no vertices of depth exceeding <span class="math">\\mathrm{depth}(u)</span>. Let <span class="math">t_{u}\\in F_{x}</span> be the tine with <span class="math">\\ell(t_{u})=\\alpha</span>.</p>

    <p class="text-gray-300">The honest tine <span class="math">t_{u}</span> is the unique longest tine in <span class="math">F_{x}</span> . (6)</p>

    <p class="text-gray-300">.</p>

    <h4 id="sec-41" class="text-lg font-semibold mt-6">Identifying <span class="math">y</span>.</h4>

    <p class="text-gray-300">Let <span class="math">\\beta</span> denote the smallest honest index of <span class="math">w</span> for which <span class="math">\\beta\\geq\\ell(t_{2})</span>, with the convention that if there is no such index we define <span class="math">\\beta=T+1</span>. Observe that <span class="math">\\beta-1\\geq\\ell(t_{1})</span>. (If <span class="math">\\ell(t_{2})</span> is an honest slot then <span class="math">\\beta=\\ell(t_{2})</span> but <span class="math">\\ell(t_{1})&lt;\\ell(t_{2})</span>. The case <span class="math">\\ell(t_{1})=\\ell(t_{2})</span> is possible if <span class="math">\\ell(t_{2})</span> is an adversarial slot; but then <span class="math">\\beta&gt;\\ell(t_{2})</span>.) These indices, <span class="math">\\alpha</span> and <span class="math">\\beta</span>, distinguish the substrings <span class="math">y=w_{\\alpha+1}\\ldots w_{\\beta-1}</span> and <span class="math">z=w_{\\beta}\\ldots w_{T}</span>; we will focus on <span class="math">y</span> in the remainder of the proof. Since the function <span class="math">\\ell(\\cdot)</span> is strictly increasing along any tine, observe that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\beta-\\alpha-1\\geq\\ell(t_{1})-\\ell(u)\\geq k+1\\,.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Hence <span class="math">y</span> has the desired length and it suffices to establish that it is forkable. We can extract from <span class="math">F</span> a balanced fork (for <span class="math">y</span>) in two steps: (i.) we subject the fork <span class="math">F</span> to some minor restructuring to ensure that all “long” tines pass through <span class="math">u</span>; (ii.) we construct a flat fork by treating the vertex <span class="math">u</span> as the root of a portion of the subtree of <span class="math">F</span> labeled with the indices of <span class="math">y</span>. At the conclusion of the construction, the segments of the two tines <span class="math">t_{1}</span> and <span class="math">t_{2}</span> will yield the required “long, disjoint, equal-length” tines satisfying the definition of a balanced fork.</p>

    <h4 id="sec-42" class="text-lg font-semibold mt-6">Honest indices in <span class="math">xy</span> have low depths.</h4>

    <p class="text-gray-300">The minimality assumption (5) implies that any honest index <span class="math">h</span> for which <span class="math">h&lt;\\beta</span> has depth no more than <span class="math">\\min(\\text{length}(t_{1}),\\text{length}(t_{2}))</span>: specifically,</p>

    <p class="text-gray-300"><span class="math">h&lt;\\beta\\quad\\Longrightarrow\\quad\\mathbf{d}(h)\\leq\\min(\\text{length}(t_{1}),\\text{length}(t_{2}))\\,.</span> (7)</p>

    <p class="text-gray-300">To see this, consider an honest index <span class="math">h,h&lt;\\beta</span> and a tine <span class="math">t_{h}</span> for which <span class="math">\\ell(t_{h})=h</span>. Recall that <span class="math">t_{1}</span> and <span class="math">t_{2}</span> are viable and that <span class="math">h&lt;\\ell(t_{2})</span>. (If <span class="math">\\ell(t_{2})</span> is honest, it is obvious. Otherwise, <span class="math">h&lt;\\ell(t_{2})&lt;\\beta</span> since <span class="math">\\ell(t_{2})</span> is adversarial.) As <span class="math">t_{2}</span> is viable, it follows immediately that <span class="math">\\mathbf{d}(h)=\\text{length}(t_{h})\\leq\\text{length}(t_{2})</span>. Similarly, if <span class="math">h\\leq\\ell(t_{1})</span> then <span class="math">\\mathbf{d}(h)\\leq\\text{length}(t_{1})</span> since <span class="math">t_{1}</span> is viable as well. The remaining case, i.e., when <span class="math">\\ell(t_{1})&lt;h&lt;\\ell(t_{2})</span>, can be ruled out by the argument below.</p>

    <h4 id="sec-43" class="text-lg font-semibold mt-6">There is no honest index between <span class="math">\\ell(t_{1})</span> and <span class="math">\\ell(t_{2})</span>.</h4>

    <p class="text-gray-300">We claim that</p>

    <p class="text-gray-300"><span class="math">\\text{There is no honest index }h\\text{ satisfying }\\ell(t_{1})&lt;h&lt;\\ell(t_{2})\\,.</span> (8)</p>

    <p class="text-gray-300">The claim above is trivially true if <span class="math">\\ell(t_{1})=\\ell(t_{2})</span>. Otherwise, suppose (toward a contradiction) that <span class="math">h</span> is an honest index satisfying <span class="math">\\ell(t_{1})&lt;h&lt;\\ell(t_{2})</span>. Let <span class="math">t_{h}</span> be the (honest) tine at slot <span class="math">h</span>. The tine-pair <span class="math">(t_{1},t_{h})</span> may or may not be in <span class="math">A</span>. We will show that both cases lead to contradictions.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>If <span class="math">(t_{1},t_{h})</span> is in <span class="math">A</span> and <span class="math">\\ell(t_{1}\\cap t_{h})\\leq\\ell(u)</span>, <span class="math">\\text{div}_{\\text{slot}}(t_{1},t_{h})</span> is at least <span class="math">\\text{div}_{\\text{slot}}(t_{1},t_{2})</span>. In fact, due to (4), this inequality must be an equality. However, the assumption <span class="math">\\ell(t_{1})&lt;h&lt;\\ell(t_{2})</span> contradicts (5).</li>

      <li>If <span class="math">(t_{1},t_{h})</span> is in <span class="math">A</span> and <span class="math">\\ell(t_{1}\\cap t_{h})&gt;\\ell(u)</span>, it follows that <span class="math">\\text{div}_{\\text{slot}}(t_{h},t_{2})&gt;\\text{div}_{\\text{slot}}(t_{1},t_{2})</span>. As the latter quantity is at least <span class="math">k+1</span>, <span class="math">(t_{h},t_{2})</span> must be in <span class="math">A</span>. The preceding inequality, however, contradicts (4).</li>

      <li>If <span class="math">(t_{1},t_{h})\\notin A</span>, <span class="math">\\text{div}_{\\text{slot}}(t_{1},t_{h})</span> is at most <span class="math">k</span>. As <span class="math">\\text{div}_{\\text{slot}}(t_{1},t_{2})</span> is at least <span class="math">k+1</span>, <span class="math">t_{h}</span> and <span class="math">t_{1}</span> must share a vertex after slot <span class="math">\\ell(u)</span>. Since <span class="math">\\ell(t_{1})&lt;h&lt;\\ell(t_{2})</span> by assumption, <span class="math">\\text{div}_{\\text{slot}}(t_{h},t_{2})&gt;\\text{div}_{\\text{slot}}(t_{1},t_{2})\\geq k+1</span> and, as a result, <span class="math">(t_{h},t_{2})\\in A</span>. However, the preceding strict inequality violates condition (4).</li>

    </ul>

    <h4 id="sec-44" class="text-lg font-semibold mt-6">A fork <span class="math">F^{\\triangleright u\\lhd 1}</span> where all long tines go through <span class="math">u</span>.</h4>

    <p class="text-gray-300">In light of the remarks above, we observe that the fork <span class="math">F</span> may be “pinched” at <span class="math">u</span> to yield an essentially identical fork <span class="math">F^{\\triangleright u\\lhd 1}\\vdash w</span> with the exception that all tines of length exceeding <span class="math">\\text{depth}(u)</span> pass through the vertex <span class="math">u</span>. Specifically, the fork <span class="math">F^{\\triangleright u\\lhd 1}\\vdash w</span> is defined to be the graph obtained from <span class="math">F</span> by changing every edge of <span class="math">F</span> directed towards a vertex of <span class="math">\\text{depth}\\ \\text{depth}(u)+1</span> so that it originates from <span class="math">u</span>. To see that the resulting tree is a well-defined fork, it suffices to check that <span class="math">\\ell(\\cdot)</span> is still increasing along all tines of <span class="math">F^{\\triangleright u\\lhd 1}</span>. For this purpose, consider the effect of this pinching on an individual tine <span class="math">t</span> terminating at a particular vertex <span class="math">v</span>—it is replaced with a tine <span class="math">t^{\\triangleright u\\lhd 1}</span> defined so that:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>If <span class="math">\\text{length}(t)\\leq\\text{depth}(u)</span>, the tine <span class="math">t</span> is unchanged: <span class="math">t^{\\triangleright u\\lhd 1}=t</span>.</li>

      <li>Otherwise, <span class="math">\\text{length}(t)&gt;\\text{depth}(u)</span> and <span class="math">t</span> has a vertex <span class="math">v</span> of <span class="math">\\text{depth}\\ \\text{depth}(u)+1</span>; note that <span class="math">\\ell(v)&gt;\\ell(u)</span> because <span class="math">F_{x}</span> contains no vertices of depth exceeding <span class="math">\\text{depth}(u)</span>. Then <span class="math">t^{\\triangleright u\\lhd 1}</span> is defined to be the path given by the tine terminating at <span class="math">u</span>, a (new) edge from <span class="math">u</span> to <span class="math">v</span>, and the suffix of <span class="math">t</span> beginning at <span class="math">z</span>. (As <span class="math">\\ell(v)&gt;\\ell(u)</span> this has the increasing label property.)</li>

    </ul>

    <p class="text-gray-300">Thus the tree <span class="math">F^{\\triangleright u\\lhd 1}</span> is a legal fork on the same vertex set; note that the depths of vertices in <span class="math">F</span> and <span class="math">F^{\\triangleright u\\lhd 1}</span> are identical.</p>

    <p class="text-gray-300">.</p>

    <h5 id="sec-45" class="text-base font-semibold mt-4">Constructing a shallow fork <span class="math">F_{y}\\vdash y</span>.</h5>

    <p class="text-gray-300">By excising the tree rooted at <span class="math">u</span> from this pinched fork <span class="math">F^{\\triangleright u\\lhd}</span>, we may extract a fork for the string <span class="math">w_{\\alpha+1}...w_{T}</span>. Specifically, consider the induced subgraph <span class="math">F^{u\\lhd}</span> of <span class="math">F^{\\triangleright u\\lhd}</span> given by the vertices <span class="math">\\{u\\}\\cup\\{v\\mid\\text{depth}(v)&gt;\\text{depth}(u)\\}</span>. By treating <span class="math">u</span> as a root vertex and suitably defining the labels <span class="math">\\ell^{u\\lhd}</span> of <span class="math">F^{u\\lhd}</span> so that <span class="math">\\ell^{u\\lhd}(v)=\\ell(v)-\\ell(u)</span>, this subgraph has the defining properties of a fork for <span class="math">w_{\\alpha+1}...w_{T}</span>. In particular, considering that <span class="math">\\alpha</span> is honest it follows that each honest index <span class="math">h&gt;\\alpha</span> has depth <span class="math">\\mathbf{d}(h)&gt;\\text{length}(u)</span> and hence <span class="math">h</span> labels a vertex in <span class="math">F^{u\\lhd}</span>. For a tine <span class="math">t</span> of <span class="math">F^{\\triangleright u\\lhd}</span>, we let <span class="math">t^{u\\lhd}</span> denote the suffix of this tine beginning at <span class="math">u</span>, which forms a tine in <span class="math">F^{u\\lhd}</span>. (If <span class="math">\\text{length}(t)\\leq\\text{depth}(u)</span>, we define <span class="math">t^{u\\lhd}</span> to consist solely of the vertex <span class="math">u</span>.) Note that <span class="math">t_{1}^{u\\lhd}</span> and <span class="math">t_{2}^{u\\lhd}</span> share no edges in the fork <span class="math">F^{u\\lhd}</span>.</p>

    <p class="text-gray-300">Finally, let <span class="math">F_{y}</span> denote the subtree obtained from <span class="math">F^{u\\lhd}</span> as the union of all tines <span class="math">t^{u\\lhd}</span> of <span class="math">F^{u\\lhd}</span> so that all labels of <span class="math">t^{u\\lhd}</span> are drawn from <span class="math">y</span> (as it appears as a prefix of <span class="math">w_{\\alpha+1}...w_{T}</span>), and</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\text{length}(t^{u\\lhd})\\leq\\max_{\\begin{subarray}{c}h\\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\\\</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">h\\text{ honest}\\end{subarray}}\\mathbf{d}(h)\\,.$ (9)</p>

    <p class="text-gray-300">It is immediate that <span class="math">F_{y}\\vdash y</span>.</p>

    <h5 id="sec-46" class="text-base font-semibold mt-4">Two longest viable tines in <span class="math">F_{y}</span>.</h5>

    <p class="text-gray-300">Consider the tines <span class="math">t_{1}^{u\\lhd}</span> and <span class="math">t_{2}^{u\\lhd}</span>. As mentioned above, they share no edges in <span class="math">F^{u\\lhd}</span> and hence the prefixes <span class="math">\\hat{t_{1}}</span> and <span class="math">\\hat{t_{2}}</span> (of <span class="math">t_{1}^{u\\lhd}</span> and <span class="math">t_{2}^{u\\lhd}</span>) appearing in <span class="math">F_{y}</span> share no edges. We wish to show that these prefixes have the maximal length in <span class="math">F_{y}</span>, making <span class="math">F_{y}</span> balanced, as desired. Let <span class="math">h</span> be the largest honest index in <span class="math">y</span>. Since the lengths of the tines in <span class="math">F_{y}</span> are at most <span class="math">\\mathbf{d}(h)</span>, it suffices to show that the lengths of <span class="math">\\hat{t}_{i},i\\in\\{1,2\\}</span> is at least <span class="math">\\mathbf{d}(h)</span>.</p>

    <p class="text-gray-300">This is immediate for the tine <span class="math">\\hat{t}_{1}</span> since all labels of <span class="math">t_{1}^{u\\lhd}</span> are drawn from <span class="math">y</span> and, considering (7), its depth is at least that of all relevant honest vertices. As for <span class="math">\\hat{t_{2}}</span>, observe that if <span class="math">\\ell(t_{2})</span> is not honest then <span class="math">\\beta&gt;\\ell(t_{2})</span> so that, as with <span class="math">\\hat{t}_{1}</span>, the tine <span class="math">\\hat{t}_{2}</span> is labeled by <span class="math">y</span> so that the same argument, relying on (7), ensures that the <span class="math">\\text{length}(\\hat{t}_{2})</span> is at least the depth of all relevant honest vertices. If <span class="math">\\ell(t_{2})</span> is honest, <span class="math">\\beta=\\ell(t_{2})</span>, and the terminal vertex of <span class="math">t_{2}^{u\\lhd}</span> does not appear in <span class="math">F_{y}</span> (as <span class="math">\\ell(t_{2}^{u\\lhd})</span> falls outside <span class="math">y</span>). In this case, however, <span class="math">\\text{length}(t_{2}^{u\\lhd})&gt;\\mathbf{d}(h)</span> for any honest index <span class="math">h</span> of <span class="math">y</span>. It follows that <span class="math">\\text{length}(\\hat{t_{2}})</span>, which equals <span class="math">\\text{length}(t_{2}^{u\\lhd})-1</span>, is at least the depth of any honest index of <span class="math">y</span>, as desired. Thus we have proved</p>

    <p class="text-gray-300"><span class="math">\\hat{t}_{1}\\text{ and }\\hat{t}_{2}\\text{ are two maximally long viable tines in }F_{y}\\vdash y\\,.</span> (10)</p>

    <h5 id="sec-47" class="text-base font-semibold mt-4">Constructing a flat fork <span class="math">\\hat{F}_{y}\\vdash y</span>.</h5>

    <p class="text-gray-300">Let us identify the fork prefix <span class="math">\\hat{F}_{y}\\sqsubseteq F_{y}</span> which is either identical to <span class="math">F_{y}</span> or differs from <span class="math">F_{y}</span> in only one of the tines <span class="math">\\hat{t}_{1},\\hat{t}_{2}</span>. In particular, if <span class="math">\\text{length}(\\hat{t}_{1})=\\text{length}(\\hat{t}_{2})</span>, we set <span class="math">\\hat{F}_{y}=F_{y}</span>. Otherwise, let <span class="math">\\hat{t}_{a}</span> be the longer of the two tines <span class="math">\\hat{t}_{1},\\hat{t}_{2}</span>; let <span class="math">\\hat{t}_{b}</span> be the shorter one. We modify <span class="math">F_{y}</span> by deleting some trailing adversarial nodes from <span class="math">\\hat{t}_{a}</span> until it has the same length as <span class="math">\\hat{t}_{b}</span>; we set <span class="math">\\hat{F}_{y}</span> as the resulting fork and, in addition, set <span class="math">\\hat{t}_{b}=\\hat{t}_{b}</span> and <span class="math">\\hat{t}_{a}</span> as the tine after trimming <span class="math">\\hat{t}_{a}</span>.</p>

    <p class="text-gray-300">We claim that <span class="math">\\hat{F}_{y}</span> is balanced. The claim is obvious if <span class="math">\\text{length}(\\hat{t}_{1})=\\text{length}(\\hat{t}_{2})</span>. Otherwise, thanks to (10), it remains to show that the longer tine, <span class="math">\\hat{t}_{a}</span>, has sufficiently many trailing adversarial nodes which, if deleted, yields <span class="math">\\text{length}(\\hat{t}_{1})=\\text{length}(\\hat{t}_{2})</span>. To that end, let <span class="math">h_{i}</span> be the index of the last honest vertex on <span class="math">\\hat{t}_{i}\\in F_{y},i\\in\\{1,2\\}</span>.</p>

    <p class="text-gray-300">Suppose <span class="math">\\text{length}(\\hat{t}_{2})&gt;\\text{length}(\\hat{t}_{1})</span>. By (8), we also have <span class="math">\\text{length}(\\hat{t}_{1})\\geq\\mathbf{d}(h_{2})</span> and hence we can trim some of the trailing adversarial nodes from <span class="math">\\hat{t}_{2}</span> to get the tine <span class="math">\\hat{t}_{2}</span> whose length is the same as that of <span class="math">\\hat{t}_{1}</span>. Otherwise, suppose <span class="math">\\text{length}(\\hat{t}_{1})&gt;\\text{length}(\\hat{t}_{2})</span>. Since <span class="math">t_{2}</span> is a viable tine in <span class="math">F</span>, we also have <span class="math">\\text{length}(\\hat{t}_{2})\\geq\\mathbf{d}(h_{1})</span>. Thus we can trim some of the trailing adversarial nodes from <span class="math">\\hat{t}_{1}</span> to have a tine <span class="math">\\hat{t}_{1}</span> whose length is the same as that of <span class="math">\\hat{t}_{2}</span>. In any case, the quantity <span class="math">\\text{min}(\\text{length}(\\hat{t}_{1}),\\text{length}(\\hat{t}_{2}))</span> remains the same as <span class="math">\\text{min}(\\text{length}(\\hat{t}_{1}),\\text{length}(\\hat{t}_{2}))</span>. Thus the fork <span class="math">\\hat{F}_{y}</span> has at least two tines, <span class="math">\\hat{t}_{1}</span> and <span class="math">\\hat{t}_{2}</span>, that achieve the maximum length of all tines in <span class="math">\\hat{F}_{y}</span>; hence <span class="math">\\hat{F}_{y}</span> is balanced.</p>

    <h5 id="sec-48" class="text-base font-semibold mt-4">An <span class="math">x</span>-balanced fork <span class="math">\\hat{F}\\sqsubseteq F</span>.</h5>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let us identify the root of the fork <span class="math">\\hat{F}_{y}</span> with the vertex <span class="math">u</span> of <span class="math">F_{x}</span> and let <span class="math">\\hat{F}</span> be the resulting graph (after “gluing” the root of <span class="math">\\hat{F}_{y}</span> to <span class="math">u</span>). By (6), it is easy to see that the fork <span class="math">\\hat{F}\\sqsubseteq F</span> is indeed a valid fork on the string <span class="math">xy</span>. Moreover, <span class="math">\\hat{F}</span> is <span class="math">x</span>-balanced since <span class="math">\\hat{F}_{y}</span> is balanced. The claim in Theorem 3 follows immediately since $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k+1$. ∎</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">##</p>

    <p class="text-gray-300">5 A simple recursive formulation of relative margin</p>

    <p class="text-gray-300">A significant finding of <em>Kiayias et al. [13]</em> is that the margin of a characteristic string <span class="math">\\mu(w)</span>—the maximum value of a quantity taken over a (typically) exponentially-large family of forks—can be given a simple, mutually recursive formulation with the associated quantity of reach <span class="math">\\rho(w)</span>. Specifically, they prove the following lemma.</p>

    <h6 id="sec-49" class="text-base font-medium mt-4">Lemma 2 (<em>[13, Lemma 4.19]</em>).</h6>

    <p class="text-gray-300"><span class="math">\\rho(\\varepsilon)=0</span> where <span class="math">\\varepsilon</span> is the empty string, and, for all nonempty strings <span class="math">w\\in\\{0,1\\}^{*}</span>,</p>

    <p class="text-gray-300">\\[ \\rho(w1)=\\rho(w)+1\\,,\\qquad\\text{and}\\qquad\\rho(w0)=\\begin{cases}0&\\text{if }\\rho(w)=0,\\\\ \\rho(w)-1&\\text{otherwise}.\\end{cases} \\] (11)</p>

    <p class="text-gray-300">Furthermore, margin satisfies the mutually recursive relationship <span class="math">\\mu(\\varepsilon)=0</span> and for all <span class="math">w\\in\\{0,1\\}^{*}</span>,</p>

    <p class="text-gray-300">\\[ \\mu(w1)=\\mu(w)+1\\,,\\qquad\\text{and}\\qquad\\mu(w0)=\\begin{cases}0&\\text{if }\\rho(w)>\\mu(w)=0,\\\\ \\mu(w)-1&\\text{otherwise}.\\end{cases} \\] (12)</p>

    <p class="text-gray-300">Additionally, there exists a closed fork <span class="math">F\\vdash w</span> such that <span class="math">\\rho(F)=\\rho(w)</span> and <span class="math">\\mu(F)=\\mu(w)</span>.</p>

    <p class="text-gray-300">We prove an analogous recursive statement for relative margin, recorded below.</p>

    <h6 id="sec-50" class="text-base font-medium mt-4">Lemma 3 (Relative margin).</h6>

    <p class="text-gray-300">Given a fixed string <span class="math">x\\in\\{0,1\\}^{<em>}</span>, <span class="math">\\mu_{x}(\\varepsilon)=\\rho(x)</span> where <span class="math">\\varepsilon</span> is the empty string, and, for all nonempty strings <span class="math">w=xy\\in\\{0,1\\}^{</em>}</span>,</p>

    <p class="text-gray-300">\\[ \\mu_{x}(y1)=\\mu_{x}(y)+1\\,,\\qquad\\text{and}\\qquad\\mu_{x}(y0)=\\begin{cases}0&\\text{if }\\rho(xy)>\\mu_{x}(y)=0\\,,\\\\ \\mu_{x}(y)-1&\\text{otherwise}.\\end{cases} \\] (13)</p>

    <p class="text-gray-300">Additionally, there exists a closed fork <span class="math">F\\vdash xy</span> such that <span class="math">\\rho(F)=\\rho(xy)</span> and <span class="math">\\mu_{x}(F)=\\mu_{x}(y)</span>.</p>

    <p class="text-gray-300">We delay the proof of Lemma 3 to Section 7, preferring to immediately focus on the application to settlement times in Section 6.</p>

    <h4 id="sec-51" class="text-lg font-semibold mt-6">Discussion.</h4>

    <p class="text-gray-300">The proof of Lemma 3 shares many technical similarities with the proof of Lemma 2 given by <em>Kiayias et al. [13]</em>. However, there is an important respect in which the proofs differ. Each of the proofs requires the definition of a particular adversary (which, in effect, constructs a fork achieving the worst case reach and margin guaranteed by the lemma). The adversary constructed by <em>[13]</em> can create a balanced fork for <span class="math">w</span> whenever <span class="math">\\mu(w)\\geq 0</span> (i.e., <span class="math">w</span> is “forkable”). However, the adversary only focuses on the problem of producing disjoint tines over the entire string <span class="math">w</span> (consistent with the definition of <span class="math">\\mu(\\cdot)</span>). The “optimal online adversary,” developed in Section 8, uses a more sophisticated rule for extending chains (tines) of the fork. Notably, this adversary can simultaneously maximize relative margin over all prefixes of the string.</p>

    <h2 id="sec-52" class="text-2xl font-bold">6 General settlement guarantees and proof of main theorems</h2>

    <p class="text-gray-300">With the recursive formulation for relative margin in hand, we study the stochastic process that arises when the characteristic string <span class="math">w</span> is chosen from a distribution satisfying the <span class="math">\\varepsilon</span>-martingale condition. Let us write <span class="math">w=xy</span> (where the decomposition is arbitrary) and let <span class="math">E</span> be the event that the relative margin <span class="math">\\mu_{x}(y)</span> is non-negative. As Fact 1 and Observation 1 point out, this event has a direct bearing on the settlement violation on <span class="math">w</span>.</p>

    <p class="text-gray-300">In this section, we prove two bounds on the probability of the event <span class="math">E</span>. The first bound corresponds to the distribution <span class="math">\\mathcal{B}_{\\varepsilon}</span> whereas the second bound applies to any distribution that satisfies the <span class="math">\\varepsilon</span>-martingale condition. (Recall that the distribution <span class="math">\\mathcal{B}_{\\varepsilon}</span>, mentioned in Theorem 1, satisfies the <span class="math">\\varepsilon</span>-martingale condition with equality.) Our exposition in this section culminates in the proofs of our main theorems.</p>

    <p class="text-gray-300">We start with the following theorem which is a direct consequences of these bounds; see Section 6.1 for a proof.</p>

    <h6 id="sec-53" class="text-base font-medium mt-4">Theorem 4.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">T,k\\in\\mathbb{N}</span>. Let <span class="math">w\\in\\{0,1\\}^{T}</span> be a random variable satisfying the <span class="math">\\varepsilon</span>-martingale condition. Consider the decomposition $w=xy,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=k$. Then</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\Pr_{w=xy}\\left[\\text{there is an </span>x<span class="math">-balanced fork for </span>xy<span class="math">}\\right]=\\Pr_{w=xy}\\left[\\mu_{x}(y)\\geq 0\\right]\\leq\\exp(-\\Omega(k))\\,.</span></p>

    <p class="text-gray-300">(The asymptotic notation hides constants that depend only on <span class="math">\\varepsilon</span>.)</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Notice how the final bound does not depend on $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. Indeed, as we show in Lemma 4, the reach of a Boolean string </span>x<span class="math"> drawn from the distribution </span>\\mathcal{B}_{\\varepsilon}<span class="math"> converges to a fixed exponential distribution as </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\to\\infty<span class="math">. This limiting distribution “stochastically dominates” any distribution that satisfies the </span>\\varepsilon$-martingale condition; see Section 6.2. The following corollary is immediate.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-54" class="text-base font-medium mt-4">Corollary 1.</h6>

    <p class="text-gray-300">Let <span class="math">T,s,k\\in\\mathbb{N}</span>. Let <span class="math">w\\in\\{0,1\\}^{T}</span> be a random variable satisfying the <span class="math">\\varepsilon</span>-martingale condition. Then</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">\\Pr_{w}\\left[\\begin{matrix}\\text{there is a decomposition </span>w=xyz$, where}\\cr</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=s-1\\text{ and }</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k\\text{, so that }\\mu_{x}(y)\\geq 0\\end{matrix}\\right]\\leq O(1)\\cdot\\exp(-\\Omega(k))\\,.$ (14)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-55" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Notice that Theorem 4 works for <em>any</em> prefix <span class="math">x</span> of the characteristic string <span class="math">w=xy</span>. Thus we can fix the prefix <span class="math">x</span> with length <span class="math">s-1</span> and sum the bound in Theorem 4 over all suffixes <span class="math">y</span> with length at least <span class="math">k</span>. This would give an upper bound to the left-hand side of our claim, the bound being <span class="math">\\sum_{i\\geq k}\\exp(-\\Omega(t))=O(1)\\cdot\\exp(-\\Omega(k))</span>. ∎</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We obtain another imporant corollary by setting $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=0<span class="math"> and </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=n$ in Theorem 4.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-56" class="text-base font-medium mt-4">Corollary 2.</h6>

    <p class="text-gray-300">Let <span class="math">w\\in\\{0,1\\}^{n}</span> be a random variable satisfying the <span class="math">\\varepsilon</span>-martingale condition. Then</p>

    <p class="text-gray-300"><span class="math">\\Pr[w\\text{ is for kable}]=\\Pr[\\mu(w)\\geq 0]\\leq\\exp(-\\Omega(n))\\,.</span></p>

    <p class="text-gray-300">Thus <em>forkable strings are rare</em> where “forkable” is defined in Definition 14. This result significantly strengthens the <span class="math">\\exp(-\\Omega(\\sqrt{n}))</span> bound obtained in Theorem 4.13 of <em>[13]</em>. The improvement comes in two respects: first, Corollary 1 improves the exponent from <span class="math">\\sqrt{n}</span> to <span class="math">n</span>, and second, the characteristic string is allowed to be drawn from any distribution satisfying the <span class="math">\\varepsilon</span>-martingale condition. For comparison, the characteristic string in Theorem 4.13 of <em>[13]</em> has the distribution <span class="math">\\mathcal{B}_{\\varepsilon}</span>, i.e., the bits were i.i.d. Bernoulli random variables with expectation <span class="math">(1-\\varepsilon)/2</span>.</p>

    <h3 id="sec-57" class="text-xl font-semibold mt-8">6.1 Two bounds for non-negative relative margin</h3>

    <p class="text-gray-300">The main ingredients to proving Theorem 4 are two bounds on the event that for a characteristic string <span class="math">xy</span>, the relative margin <span class="math">\\mu_{x}(y)</span> is non-negative.</p>

    <h6 id="sec-58" class="text-base font-medium mt-4">Bound 1.</h6>

    <p class="text-gray-300">Let <span class="math">x\\in\\{0,1\\}^{m}</span> and <span class="math">y\\in\\{0,1\\}^{k}</span> be independent random variables, each chosen according to <span class="math">\\mathcal{B}_{\\varepsilon}</span>. Then</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mu_{x}(y)\\geq 0]\\leq\\exp(-\\varepsilon^{3}(1-O(\\varepsilon))k/2)\\,.</span></p>

    <h6 id="sec-59" class="text-base font-medium mt-4">Bound 2.</h6>

    <p class="text-gray-300">Let <span class="math">x\\in\\{0,1\\}^{m}</span> and <span class="math">y\\in\\{0,1\\}^{k}</span> be random variables (jointly) satisfying the <span class="math">\\varepsilon</span>-martingale condition with respect to the ordering <span class="math">x_{1},...\\,,x_{m},y_{1},...\\,,y_{k}</span>. Let <span class="math">x^{\\prime}\\in\\{0,1\\}^{m}</span> and <span class="math">y^{\\prime}\\in\\{0,1\\}^{k}</span> be independent random variables, each chosen independently according to <span class="math">\\mathcal{B}_{\\varepsilon}</span>. Then</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mu_{x}(y)\\geq 0]\\leq\\Pr[\\mu_{x^{\\prime}}(y^{\\prime})\\geq 0]\\leq\\exp(-\\varepsilon^{3}(1-O(\\varepsilon))k/2)\\,.</span></p>

    <h6 id="sec-60" class="text-base font-medium mt-4">Proof of Theorem 4.</h6>

    <p class="text-gray-300">The equality is Fact 1 and the inequality is Bound 2.</p>

    <p class="text-gray-300">6.2 A stochastically dominant prefix distribution</p>

    <p class="text-gray-300">Stochastic dominance plays an important role in the arguments below. First of all, we observe that the distribution <span class="math">\\mathcal{B}_{\\varepsilon}</span> stochastically dominates any distribution satisfying the <span class="math">\\varepsilon</span>-martingale condition; this yields the first inequality in Theorem 1. A more delicate application of stochastic dominance is used in order to achieving bounds, such as those of Section 6.1, that are independent of the length of <span class="math">x</span>. This follows from the fact that <span class="math">\\operatorname{reach}(B_{\\varepsilon})</span> converges to a particular, dominant distribution as its argument increases in length.</p>

    <p class="text-gray-300">For notational convenience, we denote the probability distribution associated with a random variable using uppercase script letters; for example, the distribution of a random variable <span class="math">R</span> is denoted by <span class="math">\\mathcal{R}</span>. This usage should be clear from the context.</p>

    <h6 id="sec-61" class="text-base font-medium mt-4">Definition 15 (Monotonicity and stochastic dominance).</h6>

    <p class="text-gray-300">Let <span class="math">\\Omega</span> be a set endowed with a partial order <span class="math">\\leq</span>. A subset <span class="math">A\\subset\\Omega</span> is monotone if for all <span class="math">x\\leq y</span>, <span class="math">x\\in A</span> implies <span class="math">y\\in A</span>. Let <span class="math">X</span> and <span class="math">Y</span> be random variables taking values in <span class="math">\\Omega</span>. We say that <span class="math">X</span> <em>stochastically dominates</em> <span class="math">Y</span>, written <span class="math">Y\\preceq X</span>, if <span class="math">\\mathcal{X}(A)\\geq\\mathcal{Y}(A)</span> for all monotone <span class="math">A\\subseteq\\Omega</span>. As a special case, when <span class="math">\\Omega=\\mathbb{R}</span>, <span class="math">Y\\preceq X</span> if <span class="math">\\Pr[X\\geq\\Lambda]\\geq\\Pr[Y\\geq\\Lambda]</span> for every <span class="math">\\Lambda\\in\\mathbb{R}</span>. We extend this notion to probability distributions in the natural way.</p>

    <p class="text-gray-300">Observe that for any non-decreasing function <span class="math">u</span> defined on <span class="math">\\Omega</span>, <span class="math">Y\\preceq X</span> implies <span class="math">u(Y)\\leq u(X)</span>. Finally, we note that for real-valued random variables <span class="math">X</span>, <span class="math">Y</span>, and <span class="math">Z</span>, if <span class="math">Y\\preceq X</span> and <span class="math">Z</span> is independent of both <span class="math">X</span> and <span class="math">Y</span>, then <span class="math">Z+Y\\preceq Z+X</span>.</p>

    <h6 id="sec-62" class="text-base font-medium mt-4">Lemma 4.</h6>

    <p class="text-gray-300">Suppose <span class="math">W=(W_{1},...,W_{n})\\in\\{0,1\\}^{n}</span> satisfies the <span class="math">\\varepsilon</span>-martingale condition. Let <span class="math">\\varepsilon\\in(0,1)</span> and <span class="math">B=(B_{1},...,B_{n})\\in\\{0,1\\}^{n}</span> where each <span class="math">B_{i}</span> is independent with expectation <span class="math">(1-\\varepsilon)/2</span>. Let <span class="math">R_{\\infty}\\in\\{0,1,...\\}</span> be a random variable whose distribution <span class="math">\\mathcal{R}_{\\infty}</span> is defined as</p>

    <p class="text-gray-300"><span class="math">\\mathcal{R}_{\\infty}(k)=\\Pr[R_{\\infty}=k]\\triangleq\\left(\\frac{2\\varepsilon}{1+\\varepsilon}\\right)\\cdot\\left(\\frac{1-\\varepsilon}{1+\\varepsilon}\\right)^{k}\\qquad\\text{for }k=0,1,2,...\\ .</span> (15)</p>

    <p class="text-gray-300">Then <span class="math">\\rho(W)\\preceq\\rho(B)\\preceq R_{\\infty}</span>.</p>

    <h6 id="sec-63" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">We begin by observing that <span class="math">B</span> stochastically dominates <span class="math">W</span>. As a matter of notation, for any fixed values <span class="math">w_{1},...,w_{k}\\in\\{0,1\\}^{k}</span>, let</p>

    <p class="text-gray-300"><span class="math">\\vartheta[w_{1},...,w_{k}]=\\Pr[W_{k+1}=1\\mid W_{i}=w_{i},\\text{for }i\\leq k]\\leq(1-\\varepsilon)/2</span></p>

    <p class="text-gray-300">and <span class="math">\\vartheta[\\varepsilon]=\\Pr[W_{1}=1]</span> where <span class="math">\\varepsilon</span> is the empty string. Then consider <span class="math">n</span> uniform and independent real numbers <span class="math">(A_{1},...,A_{n})</span>, each taking a value in the unit interval <span class="math">[0,1]</span>; we use these random variables to construct a monotone coupling between <span class="math">W</span> and <span class="math">B</span>. Specifically, define <span class="math">\\beta:[0,1]^{n}\\to\\{0,1\\}^{n}</span> by the rule <span class="math">\\beta(\\alpha_{1},...,\\alpha_{n})=(b_{1},...,b_{n})</span> where</p>

    <p class="text-gray-300">\\[ b_{t}=\\begin{cases}1&\\text{if }\\alpha_{t}\\leq(1-\\varepsilon)/2,\\\\ 0&\\text{if }\\alpha_{t}>(1-\\varepsilon)/2,\\end{cases} \\]</p>

    <p class="text-gray-300">and define <span class="math">B=(B_{1},...,B_{n})=\\beta(A_{1},...,A_{n})</span>; these <span class="math">B_{i}</span>s are independent zero-one Bernoulli random variables with expectation <span class="math">(1-\\varepsilon)/2</span>. Likewise define the function <span class="math">\\omega:[0,1]^{n}\\to\\{0,1\\}^{n}</span> so that <span class="math">\\omega(\\alpha_{1},...,\\alpha_{n})=(w_{1},...,w_{n})</span> where each <span class="math">w_{t}</span> is assigned by the iterative rule</p>

    <p class="text-gray-300">\\[ w_{t+1}=\\begin{cases}1&\\text{if }\\alpha\\leq\\vartheta[w_{1},...,w_{t}],\\\\ 0&\\text{if }\\alpha>\\vartheta[w_{1},...,w_{t}],\\end{cases} \\]</p>

    <p class="text-gray-300">and observe that the probability law of <span class="math">\\omega(A_{1},...,A_{n})</span> is precisely that of <span class="math">W=(W_{1},...,W_{n})</span>. For convenience, we simply identify the random variable <span class="math">W</span> with <span class="math">\\omega(A_{1},...,A_{n})</span>. Note that for any <span class="math">\\alpha=(\\alpha_{1},...,\\alpha_{n})</span> and for each <span class="math">i</span>, the <span class="math">i</span>th coordinates of <span class="math">\\beta(\\alpha)</span> and <span class="math">\\omega(\\alpha)</span> satisfy <span class="math">\\omega(\\alpha)_{i}\\leq\\beta(\\alpha)_{i}</span> (which is to say that <span class="math">W_{i}\\leq B_{i}</span> with probability <span class="math">1</span>). But this is equivalent to saying <span class="math">W\\preceq B</span>. (See <em>[14, Lemma 22.5]</em>.) Now consider the following partial order <span class="math">\\leq</span> on the <span class="math">n</span>-bit Boolean strings: for <span class="math">x,y\\in\\{0,1\\}^{n}</span>, we write <span class="math">x\\leq y</span> if and only if <span class="math">x_{i}=1</span> implies <span class="math">y_{i}=1,i\\in[n]</span>. Since</p>

    <p class="text-gray-300"><span class="math">\\rho</span> is non-decreasing with respect to this partial order, we have <span class="math">\\rho(\\omega(\\alpha))\\leq\\rho(\\beta(\\alpha))</span> with probability <span class="math">1</span> and hence <span class="math">\\rho(W)\\preceq\\rho(B)</span> as well.</p>

    <p class="text-gray-300">To complete the proof, we now establish that <span class="math">\\rho(B)\\preceq R_{\\infty}</span>. We remark that the random variables <span class="math">\\rho(B)</span> (and <span class="math">R_{\\infty}</span>) have an immediate interpretation in terms of the Markov chain corresponding to a biased random walk on <span class="math">\\mathbb{Z}</span> with a “reflecting boundary” at -1. Specifically, consider the Markov chain on <span class="math">\\{0,1,...\\}</span> given by the transition diagram</p>

    <p class="text-gray-300">where edges pointing right have probability <span class="math">(1-\\epsilon)/2</span> and edges pointing left—including the loop at <span class="math">0</span>—have probability <span class="math">(1+\\epsilon)/2</span>. Examining the recursive description of <span class="math">\\rho(w)</span>, it is easy to confirm that the random variable <span class="math">\\rho(B_{1},...\\,,B_{n})</span> is precisely given by the result of evolving the Markov chain above for <span class="math">n</span> steps with all probability initially placed at <span class="math">0</span>. It is further easy to confirm that the distribution given by (15) above is stationary for this chain.</p>

    <p class="text-gray-300">To establish stochastic dominance, it is convenient to work with the underlying distributions and consider walks of varying lengths: let <span class="math">\\mathcal{R}_{n}:\\mathbb{Z}\\to\\mathbb{R}</span> denote the probability distribution given by <span class="math">\\rho(B_{1},...\\,,B_{n})</span>; likewise define <span class="math">\\mathcal{R}_{\\infty}</span>. For a distribution <span class="math">\\mathcal{R}</span> on <span class="math">\\mathbb{Z}</span>, we define <span class="math">[\\mathcal{R}]_{0}</span> to denote the probability distribution obtained by shifting all probability mass on negative numbers to zero; that is, for <span class="math">x\\in\\mathbb{Z}</span>,</p>

    <p class="text-gray-300">\\[ [\\mathcal{R}]_{0}(x)=\\begin{cases}\\mathcal{R}(x)&\\text{if }x>0,\\\\ \\sum_{t\\leq 0}\\mathcal{R}(t)&\\text{if }x=0,\\\\ 0&\\text{if }x<0.\\end{cases} \\]</p>

    <p class="text-gray-300">We observe that if <span class="math">A\\preceq C</span> then <span class="math">[A]_{0}\\preceq[C]_{0}</span> for any distributions <span class="math">A</span> and <span class="math">C</span> on <span class="math">\\mathbb{Z}</span>. It will also be convenient to introduce the shift operators: for a distribution <span class="math">\\mathcal{R}:\\mathbb{Z}\\to\\mathbb{R}</span> and an integer <span class="math">k</span>, we define <span class="math">S^{k}\\mathcal{R}</span> to be the distribution given by the rule <span class="math">S^{k}\\mathcal{R}(x)=\\mathcal{R}(x-k)</span>. With these operators in place, we may write</p>

    <p class="text-gray-300"><span class="math">\\mathcal{R}_{t}=\\left(\\frac{1-\\epsilon}{2}\\right)S^{1}\\mathcal{R}_{t-1}+\\left(\\frac{1+\\epsilon}{2}\\right)\\left[S^{-1}\\mathcal{R}_{t-1}\\right]_{0}\\,,</span></p>

    <p class="text-gray-300">with the understanding that <span class="math">\\mathcal{R}_{0}</span> is the distribution placing unit probability at <span class="math">0</span>. The proof now proceeds by induction. It is clear that <span class="math">\\mathcal{R}_{0}\\preceq\\mathcal{R}_{\\infty}</span>. Assuming that <span class="math">\\mathcal{R}_{n}\\preceq\\mathcal{R}_{\\infty}</span>, we note that for any <span class="math">k</span></p>

    <p class="text-gray-300"><span class="math">S^{k}\\mathcal{R}_{n}\\preceq S^{k}\\mathcal{R}_{\\infty}\\qquad\\text{and, additionally, that}\\qquad[S^{-1}\\mathcal{R}_{n}]_{0}\\preceq[S^{-1}\\mathcal{R}_{\\infty}]_{0}\\,.</span></p>

    <p class="text-gray-300">Finally, it is clear that stochastic dominance respects convex combinations, in the sense that if <span class="math">A_{1}\\preceq C_{1}</span> and <span class="math">A_{2}\\preceq C_{2}</span> then <span class="math">\\lambda A_{1}+(1-\\lambda)A_{2}\\preceq\\lambda C_{1}+(1-\\lambda)C_{2}</span> (for <span class="math">0\\leq\\lambda\\leq 1</span>). We conclude that</p>

    <p class="text-gray-300"><span class="math">\\mathcal{R}_{t+1}=\\left(\\frac{1-\\epsilon}{2}\\right)S^{1}\\mathcal{R}_{t}+\\left(\\frac{1+\\epsilon}{2}\\right)\\left[S^{-1}\\mathcal{R}_{t}\\right]_{0}\\preceq\\left(\\frac{1-\\epsilon}{2}\\right)S^{1}\\mathcal{R}_{\\infty}+\\left(\\frac{1+\\epsilon}{2}\\right)\\left[S^{-1}\\mathcal{R}_{\\infty}\\right]_{0}\\,.</span></p>

    <p class="text-gray-300">By inspection, the right-hand side equals <span class="math">\\mathcal{R}_{\\infty}</span>, as desired. Hence <span class="math">\\rho(B)\\preceq R_{\\infty}</span>. ∎</p>

    <h5 id="sec-64" class="text-base font-semibold mt-4">Remark.</h5>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In fact, the random variable <span class="math">\\rho(B)</span> actually converges to <span class="math">R_{\\infty}</span> as <span class="math">n\\to\\infty</span>. This can be seen, for example, by solving for the stationary distribution of the Markov chain in the proof above. However, we will only require the dominance for our exposition. Importantly, since <span class="math">\\mu_{x}(\\epsilon)=\\rho(x)</span>, and <span class="math">\\Pr[\\mu_{x}(y)\\geq 0]</span> increases monotonically with an increase in <span class="math">\\Pr[\\mu_{x}(\\epsilon)\\geq r]</span> for any <span class="math">r\\geq 0</span>, it suffices to take $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\to\\infty<span class="math"> when reasoning about an upper bound on </span>\\Pr[\\mu_{x}(y)\\geq 0]$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-65" class="text-xl font-semibold mt-8">6.3 Proof of Bound 1</h3>

    <p class="text-gray-300">Anticipating the proof, we make a few remarks about generating functions and stochastic dominance. We reserve the term <em>generating function</em> to refer to an “ordinary” generating function which represents a sequence <span class="math">a_{0},a_{1},...</span> of non-negative real numbers by the formal power series <span class="math">\\mathsf{A}(Z)=\\sum_{t=0}^{\\infty}a_{t}Z^{t}</span>. When <span class="math">\\mathsf{A}(1)=\\sum_{t}a_{t}=1</span> we say that</p>

    <p class="text-gray-300">the generating function is a <em>probability generating function</em>; in this case, the generating function <span class="math">\\mathsf{A}</span> can naturally be associated with the integer-valued random variable <span class="math">A</span> for which <span class="math">\\Pr[A=k]=a_{k}</span>. If the probability generating functions <span class="math">\\mathsf{A}</span> and <span class="math">\\mathsf{B}</span> are associated with the random variables <span class="math">A</span> and <span class="math">B</span>, it is easy to check that <span class="math">\\mathsf{A}\\cdot\\mathsf{B}</span> is the generating function associated with the convolution <span class="math">A+B</span> (where <span class="math">A</span> and <span class="math">B</span> are assumed to be independent). Translating the notion of stochastic dominance to the setting with generating functions, we say that the generating function <span class="math">\\mathsf{A}</span> <em>stochastically dominates</em> <span class="math">\\mathsf{B}</span> if <span class="math">\\sum_{t\\leq T}a_{t}\\leq\\sum_{t\\leq T}b_{t}</span> for all <span class="math">T\\geq 0</span>; we write <span class="math">\\mathsf{B}\\preceq\\mathsf{A}</span> to denote this state of affairs. If <span class="math">\\mathsf{B}_{1}\\preceq\\mathsf{A}_{1}</span> and <span class="math">\\mathsf{B}_{2}\\preceq\\mathsf{A}_{2}</span> then <span class="math">\\mathsf{B}_{1}\\cdot\\mathsf{B}_{2}\\preceq\\mathsf{A}_{1}\\cdot\\mathsf{A}_{2}</span> and <span class="math">\\alpha\\mathsf{B}_{1}+\\beta\\mathsf{B}_{2}\\preceq\\alpha\\mathsf{A}_{1}+\\beta\\mathsf{A}_{2}</span> (for any <span class="math">\\alpha,\\beta\\geq 0</span>). Moreover, if <span class="math">\\mathsf{B}\\preceq\\mathsf{A}</span> then it can be checked that <span class="math">\\mathsf{B}(\\mathsf{C})\\preceq\\mathsf{A}(\\mathsf{C})</span> for any probability generating function <span class="math">\\mathsf{C}(Z)</span>, where we write <span class="math">\\mathsf{A}(\\mathsf{C})</span> to denote the composition <span class="math">\\mathsf{A}(\\mathsf{C}(Z))</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Finally, we remark that if <span class="math">\\mathsf{A}(Z)</span> is a generating function which converges as a function of a complex <span class="math">Z</span> for $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><R<span class="math"> for some non-negative </span>R<span class="math">, </span>R<span class="math"> is called the <em>radius of convergence</em> of </span>\\mathsf{A}<span class="math">. It follows from <em>[26, Theorem 2.19]</em> that </span>\\lim_{k\\to\\infty}a_{k}R^{k}=0<span class="math"> and </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a_{k}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=O(R^{-k})<span class="math">. In addition, if </span>\\mathsf{A}<span class="math"> is a probability generating function associated with the random variable </span>A<span class="math"> then it follows that </span>\\Pr[A\\geq T]=O(R^{-T})$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We define <span class="math">p=(1-\\varepsilon)/2</span> and <span class="math">q=1-p</span> and as in the proof of Bound 2, consider the independent <span class="math">\\{0,1\\}</span>-valued random variables <span class="math">w_{1},w_{2},...</span> where <span class="math">\\Pr[w_{t}=1]=p</span>. We also define the associated <span class="math">[\\pm 1]</span>-valued random variables <span class="math">W_{t}=(-1)^{1+w_{t}}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Although our actual interest is in the random variable <span class="math">\\mu_{x}(y)</span> from (13) on a characteristic string <span class="math">w=xy</span>, we begin by analyzing the case when $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=0$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-66" class="text-lg font-semibold mt-6">Case 1: <span class="math">x</span> is the empty string.</h4>

    <p class="text-gray-300">In this case, the random variable <span class="math">\\mu_{x}(y)</span> is identical to <span class="math">\\mu(w)</span> from (12) with <span class="math">w=y</span>. Our strategy is to study the probability generating function</p>

    <p class="text-gray-300"><span class="math">\\mathsf{L}(Z)=\\sum_{t=0}^{\\infty}\\ell_{t}Z^{t}</span></p>

    <p class="text-gray-300">where <span class="math">\\ell_{t}=\\Pr[t</span> is the last time <span class="math">\\mu_{t}=0]</span>. Controlling the decay of the coefficients <span class="math">\\ell_{t}</span> suffices to give a bound on the probability that <span class="math">w_{1}...w_{k}</span> is forkable because</p>

    <p class="text-gray-300"><span class="math">\\Pr[w_{1}...w_{k}\\text{ is forkable}]\\leq 1-\\sum_{t=0}^{k-1}\\ell_{t}=\\sum_{t=k}^{\\infty}\\ell_{t}\\,.</span></p>

    <p class="text-gray-300">It seems challenging to give a closed-form algebraic expression for the generating function <span class="math">\\mathsf{L}</span>; our approach is to develop a closed-form expression for a probability generating function <span class="math">\\hat{\\mathsf{L}}=\\sum_{t}\\hat{\\ell}_{t}Z^{t}</span> which stochastically dominates <span class="math">\\mathsf{L}</span> and apply the analytic properties of this closed form to bound the partial sums <span class="math">\\sum_{t\\geq k}\\hat{\\ell}_{k}</span>. Observe that if <span class="math">\\mathsf{L}\\preceq\\hat{\\mathsf{L}}</span> then the series <span class="math">\\hat{\\mathsf{L}}</span> gives rise to an upper bound on the probability that <span class="math">w_{1}...w_{k}</span> is forkable as <span class="math">\\sum_{t=k}^{\\infty}\\ell_{t}\\leq\\sum_{t=k}^{\\infty}\\hat{\\ell}_{t}</span>.</p>

    <p class="text-gray-300">The coupled random variables <span class="math">\\rho_{t}</span> and <span class="math">\\mu_{t}</span> are Markovian in the sense that values <span class="math">(\\rho_{s},\\mu_{s})</span> for <span class="math">s\\geq t</span> are entirely determined by <span class="math">(\\rho_{t},\\mu_{t})</span> and the subsequent values <span class="math">W_{t+1}</span>, … of the underlying variables <span class="math">W_{t}</span>. We organize the sequence <span class="math">(\\rho_{0},\\mu_{0}),(\\rho_{1},\\mu_{1}),...</span> into “epochs” punctuated by those times <span class="math">t</span> for which <span class="math">\\rho_{t}=\\mu_{t}=0</span>. With this in mind, we define <span class="math">\\mathsf{M}(Z)=\\sum m_{t}Z^{t}</span> to be the generating function for the first completion of such an epoch, corresponding to the least <span class="math">t&gt;0</span> for which <span class="math">\\rho_{t}=\\mu_{t}=0</span>. As we discuss below, <span class="math">\\mathsf{M}(Z)</span> is not a probability generating function, but rather <span class="math">\\mathsf{M}(1)=1-\\varepsilon</span>. It follows that</p>

    <p class="text-gray-300"><span class="math">\\mathsf{L}(Z)</span> <span class="math">=\\left(1+(1-\\varepsilon)\\cdot\\frac{\\mathsf{M}(Z)}{\\mathsf{M}(1)}+\\left((1-\\varepsilon)\\cdot\\frac{\\mathsf{M}(Z)}{\\mathsf{M}(1)}\\right)^{2}+\\cdots\\right)\\cdot\\varepsilon</span> <span class="math">=(1+\\mathsf{M}(Z)+\\mathsf{M}(Z)^{2}+\\cdots)\\cdot\\varepsilon</span> <span class="math">=\\frac{\\varepsilon}{1-\\mathsf{M}(Z)}\\,.</span> (16)</p>

    <p class="text-gray-300">The expression above represents the following geometric process: before the beginning of an epoch, we “ask” whether the walk is ever going to come back to zero. With probability <span class="math">\\varepsilon</span>, the answer is “no” and we stop the process. Otherwise, i.e., with probability <span class="math">1-\\varepsilon</span>, we commence an epoch which is guaranteed to finish; then we ask again.</p>

    <p class="text-gray-300">Below we develop an analytic expression for a generating function <span class="math">\\hat{\\mathsf{M}}</span> for which <span class="math">\\mathsf{M}\\preceq\\hat{\\mathsf{M}}</span> and define <span class="math">\\hat{\\mathsf{L}}=\\varepsilon/(1-\\hat{\\mathsf{M}}(Z))</span>. We then proceed as outlined above, noting that <span class="math">\\mathsf{L}\\preceq\\hat{\\mathsf{L}}</span> and using the asymptotics of <span class="math">\\hat{\\mathsf{L}}</span> to upper bound the probability that a string is forkable.</p>

    <p class="text-gray-300">In preparation for defining <span class="math">\\hat{\\mathsf{M}}</span>, we set down two elementary generating functions for the “descent” and “ascent” stopping times. Treating the random variables <span class="math">W_{1},...</span> as defining a (negatively) biased random walk, define <span class="math">\\mathsf{D}</span> to be the generating function for the <em>descent stopping time</em> of the walk; this is the first time the random walk, starting at <span class="math">0</span>, visits <span class="math">-1</span>. The natural recursive formulation of the descent time yields a simple algebraic equation for the descent generating function, <span class="math">\\mathsf{D}(Z)=qZ+pZ\\mathsf{D}(Z)^{2}</span>, and from this we may conclude</p>

    <p class="text-gray-300"><span class="math">\\mathsf{D}(Z)=\\frac{1-\\sqrt{1-4pqZ^{2}}}{2pZ}\\,.</span></p>

    <p class="text-gray-300">We likewise consider the generating function <span class="math">\\mathsf{A}(Z)</span> for the <em>ascent stopping time</em>, associated with the first time the walk, starting at <span class="math">0</span>, visits <span class="math">1</span>: we have <span class="math">\\mathsf{A}(Z)=pZ+qZ\\mathsf{A}(Z)^{2}</span> and</p>

    <p class="text-gray-300"><span class="math">\\mathsf{A}(Z)=\\frac{1-\\sqrt{1-4pqZ^{2}}}{2qZ}\\,.</span></p>

    <p class="text-gray-300">Note that while <span class="math">\\mathsf{D}</span> is a probability generating function, the generating function <span class="math">\\mathsf{A}</span> is not: according to the classical “gambler’s ruin” analysis <em>[12]</em>, the probability that a negatively-biased random walk starting at <span class="math">0</span> ever rises to <span class="math">1</span> is exactly <span class="math">p/q</span>; thus <span class="math">\\mathsf{A}(1)=p/q</span>.</p>

    <p class="text-gray-300">Returning to the generating function <span class="math">\\mathsf{M}</span> above, we note that an epoch can have one of two “shapes”: in the first case, the epoch is given by a walk for which <span class="math">W_{1}=1</span> followed by a descent (so that <span class="math">\\rho</span> returns to zero); in the second case, the epoch is given by a walk for which <span class="math">W_{1}=-1</span>, followed by an ascent (so that <span class="math">\\mu</span> returns to zero), followed by the eventual return of <span class="math">\\rho</span> to <span class="math">0</span>. Considering that when <span class="math">\\rho_{t}&gt;0</span> it will return to zero in the future almost surely, it follows that the probability that such a biased random walk will complete an epoch is <span class="math">p+q(p/q)=2p=1-\\varepsilon</span>, as mentioned in the discussion of (16) above. One technical difficulty arising in a complete analysis of <span class="math">\\mathsf{M}</span> concerns the second case discussed above: while the distribution of the smallest <span class="math">t&gt;0</span> for which <span class="math">\\mu_{t}=0</span> is proportional to <span class="math">\\mathsf{A}</span> above, the distribution of the smallest subsequent time <span class="math">t^{\\prime}</span> for which <span class="math">\\rho_{t^{\\prime}}=0</span> depends on the value <span class="math">t</span>. More specifically, the distribution of the return time depends on the value of <span class="math">\\rho_{t}</span>. Considering that <span class="math">\\rho_{t}\\leq t</span>, however, this conditional distribution (of the return time of <span class="math">\\rho</span> to zero conditioned on <span class="math">t</span>) is stochastically dominated by <span class="math">\\mathsf{D}^{t}</span>, the time to descend <span class="math">t</span> steps. This yields the following generating function <span class="math">\\hat{\\mathsf{M}}</span> which, as described, stochastically dominates <span class="math">\\mathsf{M}</span>:</p>

    <p class="text-gray-300"><span class="math">\\hat{\\mathsf{M}}(Z)=pZ\\cdot\\mathsf{D}(Z)+qZ\\cdot\\mathsf{D}(Z)\\cdot\\mathsf{A}(Z\\cdot\\mathsf{D}(Z))\\,.</span></p>

    <p class="text-gray-300">It remains to establish a bound on the radius of convergence of <span class="math">\\hat{\\mathsf{L}}</span>. Recall that if the radius of convergence of <span class="math">\\hat{\\mathsf{L}}</span> is <span class="math">\\exp(\\delta)</span> it follows that <span class="math">\\Pr[w_{1}...w_{k}\\text{ is forkable}]=O(\\exp(-\\delta k))</span>. A sufficient condition for convergence of <span class="math">\\hat{\\mathsf{L}}(z)=\\varepsilon/(1-\\hat{\\mathsf{M}}(z))</span> at <span class="math">z</span> is that that all generating functions appearing in the definition of <span class="math">\\hat{\\mathsf{M}}</span> converge at <span class="math">z</span> and that the resulting value <span class="math">\\hat{\\mathsf{M}}(z)&lt;1</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The generating function <span class="math">\\mathsf{D}(z)</span> (and <span class="math">\\mathsf{A}(z)</span>) converges when the discriminant <span class="math">1-4pqz^{2}</span> is positive; equivalently $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><1/\\sqrt{1-\\varepsilon^{2}}<span class="math"> or </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><1+\\varepsilon^{2}/2+O(\\varepsilon^{4})<span class="math">. Considering </span>\\hat{\\mathsf{M}}<span class="math">, it remains to determine when the second term, </span>qzD(z)\\mathsf{A}(z\\mathsf{D}(z))$, converges; this is likewise determined by positivity of the discriminant, which is to say that</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">1-(1-\\varepsilon^{2})\\left(\\frac{1-\\sqrt{1-(1-\\varepsilon^{2})z^{2}}}{1-\\varepsilon}\\right)^{2}&gt;0\\,.</span></p>

    <p class="text-gray-300">Equivalently,</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><\\sqrt{\\frac{1}{1+\\varepsilon}\\left(\\frac{2}{\\sqrt{1-\\varepsilon^{2}}}-\\frac{1}{1+\\varepsilon}\\right)}=1+\\varepsilon^{3}/2+O(\\varepsilon^{4})\\,.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Note that when the series <span class="math">pz\\cdot\\mathsf{D}(z)</span> converges, it converges to a value less than <span class="math">1/2</span>; the same is true of <span class="math">qz\\cdot\\mathsf{A}(z)</span>. It follows that for $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=1+\\varepsilon^{3}/2+O(\\varepsilon^{4})<span class="math">, </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\hat{\\mathsf{M}}(z)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><1<span class="math"> and </span>\\hat{\\mathsf{L}}(z)$ converges, as desired. We conclude that</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\Pr[w_{1}...w_{k}\\text{ is forkable}]=\\exp(-\\varepsilon^{3}(1+O(\\varepsilon))k/2)\\,.</span> (17)</p>

    <p class="text-gray-300">.</p>

    <h4 id="sec-67" class="text-lg font-semibold mt-6">Case 2: <span class="math">x</span> is non-empty.</h4>

    <p class="text-gray-300">The relative margin before <span class="math">y</span> begins is <span class="math">\\mu_{x}(\\varepsilon)</span>. Recalling that <span class="math">\\mu_{x}(\\varepsilon)=\\rho(x)</span> and conditioning on the event that <span class="math">\\rho(x)=r</span>, let us define the random variables <span class="math">\\{\\tilde{\\mu}_{t}\\}</span> for <span class="math">t=0,1,2,\\cdots</span> as follows: <span class="math">\\tilde{\\mu}_{0}=\\rho(x)</span> and</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\Pr[\\tilde{\\mu}_{t}=s]\\,=\\,\\Pr[\\mu_{x}(y)=s\\mid\\rho(x)=r\\text{ and }</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=t]\\,.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">If the <span class="math">\\tilde{\\mu}</span> random walk makes the <span class="math">r</span>th descent at some time <span class="math">t&lt;n</span>, then <span class="math">\\tilde{\\mu}_{t}=0</span> and the remainder of the walk is identical to an <span class="math">(k-t)</span>-step <span class="math">\\mu</span> random walk which we have already analyzed. Hence we investigate the probability generating function</p>

    <p class="text-gray-300"><span class="math">\\mathsf{B}_{r}(Z)=\\mathsf{D}(Z)^{r}\\mathsf{L}(Z)\\quad\\text{with coefficients}\\quad b_{t}^{(r)}:=\\Pr[t\\text{ is the last time }\\tilde{\\mu}_{t}=0\\mid\\tilde{\\mu}_{0}=r]</span></p>

    <p class="text-gray-300">where <span class="math">t=0,1,2,\\cdots</span>. Our interest lies in the quantity</p>

    <p class="text-gray-300"><span class="math">b_{t}:=\\Pr[t\\text{ is the last time }\\tilde{\\mu}_{t}=0]=\\sum_{r\\geq 0}b_{t}^{(r)}\\mathcal{R}_{m}(r)\\,,</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">where the <em>reach distribution</em> <span class="math">\\mathcal{R}_{m}:\\mathbb{Z}\\to[0,1]</span> associated with the random variable $\\rho(x),</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=m$ is defined as</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\mathcal{R}_{m}(r)=\\Pr_{x:</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=m}[\\rho(x)=r]\\,.$ (18)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Let <span class="math">\\mathsf{R}_{m}(Z)</span> be the probability generating function for the distribution <span class="math">\\mathcal{R}_{m}</span>. Using Lemma 4 and Definition 15, we deduce that <span class="math">\\mathsf{R}_{m}\\preceq\\mathsf{R}_{\\infty}</span> for every <span class="math">m\\geq 0</span> since <span class="math">\\mathcal{R}_{m}\\preceq\\mathcal{R}_{\\infty}</span>. In addition, it is easy to check from (15) that the probability generating function for <span class="math">\\mathcal{R}_{\\infty}</span> is in fact <span class="math">\\mathsf{R}_{\\infty}(Z)=(1-\\beta)/(1-\\beta Z)</span> where <span class="math">\\beta:=(1-\\varepsilon)/(1+\\varepsilon)</span>. Thus the generating function corresponding to the probabilities <span class="math">\\{b_{t}\\}_{t=0}^{\\infty}</span> is</p>

    <p class="text-gray-300"><span class="math">\\mathsf{B}(Z)</span> <span class="math">=\\sum_{t=0}^{\\infty}b_{t}Z^{t}=\\sum_{r=0}^{\\infty}\\mathcal{R}_{m}(r)\\sum_{t=0}^{\\infty}b_{t}^{(r)}Z^{t}=\\sum_{r=0}^{\\infty}\\mathcal{R}_{m}(r)\\mathsf{B}_{r}(Z)</span> <span class="math">=\\mathsf{L}(Z)\\sum_{r=0}^{\\infty}\\mathcal{R}_{m}(r)\\mathsf{D}(Z)^{r}=\\mathsf{L}(Z)\\,\\mathsf{R}_{m}(\\mathsf{D}(Z))\\preceq\\hat{\\mathsf{L}}(Z)\\,\\mathsf{R}_{\\infty}(\\mathsf{D}(Z))</span> <span class="math">=\\frac{(1-\\beta)\\,\\hat{\\mathsf{L}}(Z)}{1-\\beta\\mathsf{D}(Z)}\\,.</span> (19)</p>

    <p class="text-gray-300">The dominance notation above follows because <span class="math">\\mathsf{L}\\preceq\\hat{\\mathsf{L}}</span> and <span class="math">\\mathsf{R}_{m}\\preceq\\mathsf{R}_{\\infty}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">For <span class="math">\\mathsf{B}(Z)</span> to converge, we need to check that <span class="math">\\mathsf{D}(Z)</span> should never converge to <span class="math">1/\\beta</span>. One can easily check that the radius of convergence of <span class="math">\\mathsf{D}(Z)</span>—which is <span class="math">1/\\sqrt{1-\\varepsilon^{2}}</span>—is strictly less than <span class="math">1/\\beta</span> when <span class="math">\\varepsilon&gt;0</span>. We conclude that <span class="math">\\mathsf{B}(Z)</span> converges if both <span class="math">\\mathsf{D}(Z)</span> and <span class="math">\\mathsf{L}(Z)</span> converge. The radius of convergence of <span class="math">\\mathsf{B}(Z)</span> would be the smaller of the radii of convergence of <span class="math">\\mathsf{D}(Z)</span> and <span class="math">\\mathsf{L}(Z)</span>. We already know from the previous analysis that <span class="math">\\hat{\\mathsf{L}}(Z)</span> has the smaller radius of the two; therefore, the bound in (17) applies to the relative margin <span class="math">\\mu_{x}(y)</span> for $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq 0$. ∎</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-68" class="text-xl font-semibold mt-8">6.4 Proof of Bound 2</h3>

    <p class="text-gray-300">Let <span class="math">\\varepsilon\\in(0,1)</span>, <span class="math">W\\in\\{0,1\\}^{m},W^{\\prime}\\in\\{0,1\\}^{k}</span> where both <span class="math">(W_{1},...,W_{n})</span> and <span class="math">(W^{\\prime}_{1},...,W^{\\prime}_{n})</span> satisfy the <span class="math">\\varepsilon</span>-martingale condition. Let <span class="math">B\\in\\{0,1\\}^{m},B^{\\prime}\\in\\{0,1\\}^{k}</span> where the components of <span class="math">B,B^{\\prime}</span> are independent with expectation <span class="math">(1-\\varepsilon)/2</span>. By Lemma 4,</p>

    <p class="text-gray-300"><span class="math">W\\preceq B\\quad\\text{and}\\quad W^{\\prime}\\preceq B^{\\prime}\\,.</span> (<span class="math">\\ast</span>)</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let us define the partial order <span class="math">\\leq</span> on Boolean strings <span class="math">\\{0,1\\}^{k},k\\in\\mathbb{N}</span> as follows: <span class="math">a\\leq b</span> if and only if for all <span class="math">i\\in[k]</span>, <span class="math">a_{i}=1</span> implies <span class="math">b_{i}=1</span>. Let <span class="math">\\mu:\\{0,1\\}^{k}\\to\\mathbb{Z}</span> be the margin function from Lemma 3. Observe that for Boolean strings <span class="math">a,a^{\\prime},b,b^{\\prime}</span> with $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">a^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> and </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">b^{\\prime}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, (i.) </span>b\\leq b^{\\prime}<span class="math"> implies </span>\\mu_{a}(b)\\leq\\mu_{a}(b^{\\prime})<span class="math"> and (ii.) </span>a\\leq a^{\\prime}<span class="math"> implies </span>\\mu_{a}(b)\\leq\\mu_{a^{\\prime}}(b)$. That is,</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\mu_{a}(b)\\text{ is non-decreasing in both }a\\text{ and }b\\,.</span> (<span class="math">\\dagger</span>)</p>

    <p class="text-gray-300">######</p>

    <p class="text-gray-300">Using <span class="math">(\\ast)</span> and <span class="math">(\\dagger)</span>, it follows that <span class="math">\\mu_{W}(W^{\\prime})\\preceq\\mu_{B}(B^{\\prime})</span>. Writing <span class="math">x=W</span> and <span class="math">y=W^{\\prime}</span>, we have</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mu_{x}(y)\\geq 0]\\,=\\Pr[\\mu_{W}(W^{\\prime})\\geq 0]\\,\\leq\\Pr[\\mu_{B}(B^{\\prime})\\geq 0]</span></p>

    <p class="text-gray-300">where the inequality comes from the definition of stochastic dominance. A bound on the right-hand side is obtained in Bound 1. ∎</p>

    <p class="text-gray-300">In Appendix B, we present a weaker bound on <span class="math">\\Pr[\\mu_{x}(y)\\geq 0]</span> where the sequence <span class="math">x_{1},...,x_{m},y_{1},...,y_{k}</span> satisfies <span class="math">\\varepsilon</span>-martingale conditions. The proof directly uses the properties of the martingale and Azuma’s inequality but it does not use a stochastic dominance argument. Although it gives a bound of <span class="math">3\\exp\\left(-\\varepsilon^{4}(1-O(\\varepsilon))k/64\\right)</span>, the reader might find the proof of independent interest.</p>

    <h3 id="sec-69" class="text-xl font-semibold mt-8">6.5 Proof of main theorems</h3>

    <h6 id="sec-70" class="text-base font-medium mt-4">Proof of Theorem 1.</h6>

    <p class="text-gray-300">Let us start with the following observation. It allows us to formulate the <span class="math">(s,k)</span>-settlement insecurity of a distribution <span class="math">\\mathcal{D}</span> directly in terms of the relative margin.</p>

    <h6 id="sec-71" class="text-base font-medium mt-4">Lemma 5.</h6>

    <p class="text-gray-300">Let <span class="math">s,k,T\\in\\mathbb{N}</span>. Let <span class="math">\\mathcal{D}</span> be any distribution on <span class="math">\\{0,1\\}^{T}</span>. Then</p>

    <p class="text-gray-300">\\[ \\mathbf{S}^{s,k}[\\mathcal{D}]\\leq\\Pr_{w\\sim\\mathcal{D}}\\begin{bmatrix}\\text{there is a decomposition }w=xyz\\text{, where}\\\\</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=s-1\\text{ and }</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k+1\\text{, so that }\\mu_{x}(y)\\geq\\end{bmatrix}. \\]</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-72" class="text-base font-medium mt-4">Proof.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Lemma 1 implies that <span class="math">\\mathbf{S}^{s,k}[\\mathcal{D}]</span> is no more than the probability that slot <span class="math">s</span> is not <span class="math">k</span>-settled for the characteristic string <span class="math">w</span>. By Observation 1, this probability, in turn, is no more than the probability that there exists an <span class="math">x</span>-balanced fork <span class="math">F\\vdash xy</span> where we write $w=xyz,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=s-1,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k+1,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq 0<span class="math">. Finally, Fact 1 states that for any characteristic string </span>xy<span class="math">, the two events “exists an </span>x<span class="math">-balanced fork </span>F\\vdash xy<span class="math">” and “</span>\\mu_{x}(y)$ is non-negative” have the same measure. Hence the claim follows. ∎</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">If the distribution <span class="math">\\mathcal{D}</span> in the lemma above satisfies the <span class="math">\\varepsilon</span>-martingale condition, the probability in this lemma is no more than the probability in the left-hand side of Corollary 1. Finally, by retracing the proof of Corollary 1 using the explicit probability from Bound 2, we see that the bound in Corollary 1 is <span class="math">O(1)\\cdot\\exp\\bigl{(}-\\Omega(\\varepsilon^{3}(1-O(\\varepsilon))k)\\bigr{)}</span>. Since <span class="math">\\mathcal{B}_{\\varepsilon}</span> satisfies the <span class="math">\\varepsilon</span>-martingale condition, we conclude that <span class="math">\\mathbf{S}^{s,k}[\\mathcal{B}_{\\varepsilon}]</span> is no more than this quantity as well.</p>

    <p class="text-gray-300">For any player playing the settlement game, the set of strings on which the player wins is monotone with respect to the partial order <span class="math">\\leq</span> defined in Section 6.4. To see why, note that if the adversary wins with a specific string <span class="math">w</span>, he can certainly win with any string <span class="math">w^{\\prime}</span> where <span class="math">w\\leq w^{\\prime}</span>. As <span class="math">\\mathcal{B}_{\\varepsilon}</span> stochastically dominates <span class="math">\\mathcal{W}</span>, it follows that <span class="math">\\mathbf{S}^{s,k}[\\mathcal{W}]\\leq\\mathbf{S}^{s,k}[\\mathcal{B}_{\\varepsilon}]</span>.</p>

    <p class="text-gray-300">∎</p>

    <h6 id="sec-73" class="text-base font-medium mt-4">Proof of Theorem 2.</h6>

    <p class="text-gray-300">For the first inequality, observe that if <span class="math">w</span> violates <span class="math">k</span>-CP, it must violate <span class="math">k</span>-CP^{slot} as well. It remains to prove the second inequality. Let <span class="math">\\mathcal{D}</span> be any distribution on <span class="math">\\{0,1\\}^{T}</span>. We can apply Fact 1 on the statement of Theorem 3 to deduce that</p>

    <p class="text-gray-300">$\\Pr_{w\\sim\\mathcal{D}}\\bigl{[}w\\text{ violates }k\\text{-CP^{slot}}\\bigr{]}\\leq\\Pr_{w\\sim\\mathcal{D}}\\begin{bmatrix}\\text{there is a decomposition }w=xyz,\\\\</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\text{where }</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k\\text{, so that }\\mu_{x}(y)\\geq 0\\end{bmatrix}.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">By using a union bound over $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$, the above probability is at most</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">\\[ \\sum_{s=1}^{T-k+1}\\quad\\Pr_{w}\\begin{bmatrix}\\text{there is a decomposition }w=xyz\\text{, where}\\\\</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=s-1\\text{ and }</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k\\text{, so that }\\mu_{x}(y)\\geq 0\\end{bmatrix}. \\]</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Since <span class="math">w</span> satisfies the <span class="math">\\varepsilon</span>-martingale condition, we can upper bound the probability inside the sum using Corollary 1. As we have seen in the proof of Theorem 1, the bound in Corollary 1 is <span class="math">O(1)\\cdot\\exp\\bigl{(}-\\Omega(\\varepsilon^{3}(1-O(\\varepsilon))k)\\bigr{)}</span>. It follows that the sum above is at most <span class="math">T\\exp\\bigl{(}-\\Omega(\\varepsilon^{3}(1-O(\\varepsilon))k)\\bigr{)}</span>. ∎</p>

    <p class="text-gray-300">It remains to prove the recursive formulation of the relative margin from Section 5; we tackle it in the next section.</p>

    <p class="text-gray-300">7 Proof of the relative margin recurrence</p>

    <p class="text-gray-300">We set the stage by formally defining <em>fork prefixes</em>.</p>

    <h6 id="sec-74" class="text-base font-medium mt-4">Definition 16 (Fork prefixes).</h6>

    <p class="text-gray-300">Let <span class="math">w,x\\in\\{0,1\\}^{<em>}</span> so that <span class="math">x\\preceq w</span>. Let <span class="math">F,F^{\\prime}</span> be two forks for <span class="math">x</span> and <span class="math">w</span>, respectively. We say that <span class="math">F</span> is a </em>prefix* of <span class="math">F^{\\prime}</span> if <span class="math">F</span> is a consistently labeled subgraph of <span class="math">F^{\\prime}</span>. That is, all vertices and edges of <span class="math">F</span> also appear in <span class="math">F^{\\prime}</span> and the label of any vertex appearing in both <span class="math">F</span> and <span class="math">F^{\\prime}</span> is identical. We denote this relationship by <span class="math">F\\sqsubseteq F^{\\prime}</span>.</p>

    <p class="text-gray-300">When speaking about a tine that appears in both <span class="math">F</span> and <span class="math">F^{\\prime}</span>, we place the fork in the subscript of relevant properties, e.g., writing <span class="math">\\operatorname{reach}_{F}</span>, etc.</p>

    <p class="text-gray-300">Observe that for any Boolean strings <span class="math">x</span> and <span class="math">w,x\\preceq w</span>, one can <em>extend</em> (i.e., augment) a fork prefix <span class="math">F\\vdash x</span> into a larger fork <span class="math">F^{\\prime}\\vdash w</span> so that <span class="math">F\\sqsubseteq F^{\\prime}</span>. A <em>conservative extension</em> is a minimal extension in that it consumes the least amount of reserve (cf. Definition 11), leaving the remaining reserve to be used in future. Extensions and, in particular, conservative extensions play a critical role in the exposition that follows.</p>

    <h6 id="sec-75" class="text-base font-medium mt-4">Definition 17 (Conservative extension of closed forks).</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">w</span> be a Boolean string, <span class="math">F</span> a closed fork for <span class="math">w</span>, and let <span class="math">s</span> be an honest tine in <span class="math">F</span>. Let <span class="math">F^{\\prime}</span> be a closed fork for <span class="math">w0</span> so that <span class="math">F\\sqsubseteq F^{\\prime}</span> and <span class="math">F^{\\prime}</span> contains an honest tine <span class="math">\\sigma</span>, $\\ell(\\sigma)=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+1<span class="math">. We say that </span>F^{\\prime}<span class="math"> <em>is an extension of</em> </span>F<span class="math"> or, equivalently, that </span>\\sigma<span class="math"> <em>is an extension of</em> </span>s<span class="math">, if </span>s\\prec\\sigma<span class="math">. If, in addition, </span>\\operatorname{length}(\\sigma)=\\operatorname{height}(F)+1$, we call this extension a <em>conservative extension</em>.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Clearly, <span class="math">\\sigma</span> is the longest tine in <span class="math">F^{\\prime}</span>. Since <span class="math">\\sigma</span> is honest, it follows that <span class="math">\\operatorname{length}(\\sigma)\\geq 1+\\operatorname{height}(F)=1+\\operatorname{length}(s)+\\operatorname{gap}(s)</span>. The root-to-leaf path in <span class="math">F^{\\prime}</span> that ends at <span class="math">\\sigma</span> contains at least <span class="math">\\operatorname{gap}(s)</span> adversarial vertices <span class="math">u\\in F^{\\prime}</span> so that $\\ell(u)\\in[\\ell(s)+1,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">]<span class="math"> and </span>u\\notin F<span class="math">. If </span>\\sigma<span class="math"> is a conservative extension, the number of such vertices is exactly </span>\\operatorname{gap}(s)<span class="math"> and, in particular, the height of </span>F^{\\prime}<span class="math"> is exactly one more than the height of </span>F$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The main ingredients to proving Lemma 3 are a fork-building strategy for the string <span class="math">xy</span> and Propositions 1 and 2. Specifically, recall equation (13). The first proposition shows that the fork <span class="math">F\\vdash xy0</span> built by the said strategy achieves <span class="math">\\mu_{x}(F)\\geq\\mu_{x}(y0)</span> while the second proposition shows that this value, in fact, is the largest possible, i.e., <span class="math">\\mu_{x}(y0)\\leq\\mu_{x}(y0)</span>. In addition, any fork-building strategy whose forks satisfy the premise of Proposition 1 can be used to prove Lemma 3.</p>

    <h3 id="sec-76" class="text-xl font-semibold mt-8">7.1 A fork-building strategy to maximize <span class="math">x</span>-relative margin</h3>

    <p class="text-gray-300">Any fork <span class="math">F\\vdash xy</span> contains two tines <span class="math">t_{x},t_{\\rho}</span> so that <span class="math">\\operatorname{reach}(t_{\\rho})=\\rho(F)</span>, <span class="math">\\operatorname{reach}_{F}(t_{x})=\\mu_{x}(F)</span>, and the tines <span class="math">t_{x},t_{\\rho}</span> are disjoint over the suffix <span class="math">y</span>. We say that the tine-pair <span class="math">(t_{\\rho},t_{x})</span> is a <em>witness</em> to <span class="math">\\mu_{x}(F)</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">x,y\\in\\{0,1\\}^{*}</span> and write <span class="math">w=xy</span>. Recursively build closed forks $F_{0},F_{1},...,F_{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}<span class="math"> where </span>F_{i}\\vdash w_{1}...w_{i},i\\geq 1<span class="math"> and </span>F_{0}\\vdash\\varepsilon<span class="math"> is the trivial fork consisting of a single vertex corresponding to the genesis block. For </span>i=0,1,...,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-1<span class="math"> in increasing order, do as follows. If </span>w_{i+1}=1<span class="math">, set </span>F_{i+1}\\leftarrow F_{i}<span class="math">. If </span>w_{i+1}=0<span class="math">, set </span>F_{i+1}\\vdash w0<span class="math"> as a conservative extension of </span>F_{i}\\vdash w<span class="math"> so that </span>\\sigma\\in F_{i+1},\\ell(\\sigma)=i+1<span class="math"> is a conservative extension of a tine </span>s\\in F_{i}<span class="math"> identified as follows. If </span>F_{i}<span class="math"> contains no zero-reach tine, </span>s<span class="math"> is the unique longest tine in </span>F_{i}<span class="math">. Otherwise, first identify a maximal-reach tine </span>t_{\\rho}\\in F_{i}<span class="math"> as follows: if </span>i\\geq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+1<span class="math">, </span>t_{\\rho}<span class="math"> is a maximal-reach tine in </span>F_{i}<span class="math"> which belongs to a tine-pair witnessing </span>\\mu_{x}(F_{i})<span class="math">; otherwise, </span>t_{\\rho}<span class="math"> can be an arbitrary maximal-reach tine in </span>F_{i}<span class="math">. Finally, </span>s<span class="math"> is the zero-reach tine in </span>F_{i}<span class="math"> that diverges earliest from </span>t_{\\rho}<span class="math">. If there are multiple candidates for </span>s<span class="math"> or </span>t_{\\rho}$, break tie arbitrarily.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-77" class="text-base font-medium mt-4">Proposition 1.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">x,y</span> be arbitrary Boolean strings, $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq 1<span class="math"> and </span>w=xy<span class="math">. Let </span>F\\vdash w<span class="math"> and </span>F^{\\prime}\\vdash w0<span class="math"> be two closed forks built by the strategy above so that </span>F\\sqsubseteq F^{\\prime}<span class="math"> and suppose, in addition, that </span>\\rho(F)=\\rho(xy)<span class="math"> and </span>\\mu_{x}(F)=\\mu_{x}(y)<span class="math">. Then </span>\\rho(F^{\\prime})=\\rho(xy0)<span class="math"> and </span>\\mu_{x}(F^{\\prime})\\geq\\mu_{x}(y0)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-78" class="text-xl font-semibold mt-8">7.2 Proof of Proposition 1</h3>

    <p class="text-gray-300">Before we proceed further, let us record two useful results related to conservative extensions and closed fork prefixes.</p>

    <h6 id="sec-79" class="text-base font-medium mt-4">Claim 1 (A conservative extension has reach zero).</h6>

    <p class="text-gray-300">Consider closed forks <span class="math">F\\vdash w,F^{\\prime}\\vdash w0</span> such that <span class="math">F\\sqsubseteq F^{\\prime}</span>. If a tine <span class="math">t</span> of <span class="math">F^{\\prime}</span> is a conservative extension then <span class="math">\\operatorname{reach}_{F^{\\prime}}(t)=0</span>.</p>

    <p class="text-gray-300">Proof.</p>

    <p class="text-gray-300">We have assumed that <span class="math">t</span> is a conservative extension, so its terminal vertex must be the new honest node. By definition, <span class="math">\\operatorname{reach}_{F^{\\prime}}(t)=\\operatorname{reserve}_{F^{\\prime}}(t)-\\operatorname{gap}_{F^{\\prime}}(t)</span>. Honest players will only place nodes at a depth strictly greater than all other honest nodes, so we infer that <span class="math">t</span> is the longest tine of <span class="math">F^{\\prime}</span>, and so <span class="math">\\operatorname{gap}_{F^{\\prime}}(t)=0</span>. Moreover, we observe that there are no 1s occurring after this point in the characteristic string, and so <span class="math">\\operatorname{reserve}_{F^{\\prime}}(t)=0</span>. Plugging these values into our definition of reach we see that <span class="math">\\operatorname{reach}_{F^{\\prime}}(t)=0-0=0</span>. ∎</p>

    <h6 id="sec-80" class="text-base font-medium mt-4">Claim 2 (Reach of non-extended tines).</h6>

    <p class="text-gray-300">Consider a closed fork <span class="math">F\\vdash w</span> and some closed fork <span class="math">F^{\\prime}\\vdash w0</span> such that <span class="math">F\\sqsubseteq F^{\\prime}</span>. If <span class="math">t\\in F</span> then <span class="math">\\operatorname{reach}_{F^{\\prime}}(t)\\leq\\operatorname{reach}_{F}(t)-1</span>. The inequality becomes and equality if <span class="math">F^{\\prime}</span> is obtained via a conservative extension from <span class="math">F</span>.</p>

    <h6 id="sec-81" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Definitionally, we know that <span class="math">\\operatorname{reach}_{F^{\\prime}}(t)=\\operatorname{reserve}_{F^{\\prime}}(t)-\\operatorname{gap}_{F^{\\prime}}(t)</span>. From <span class="math">F</span> to <span class="math">F^{\\prime}</span>, the length of the longest tine increases by at least one, and the length of <span class="math">t</span> does not change, so we observe that <span class="math">\\operatorname{gap}_{F^{\\prime}}(t)\\geq\\operatorname{gap}_{F}(t)+1</span> with equality only for conservative extensions. The reserve of <span class="math">t</span> does not change, because there are no new 1s in the characteristic string. Therefore, <span class="math">\\operatorname{reach}_{F^{\\prime}}(t)=\\operatorname{reserve}_{F^{\\prime}}(t)-\\operatorname{gap}_{F^{\\prime}}(t)\\leq\\operatorname{reserve}_{F}(t)-\\operatorname{gap}_{F}(t)-1=\\operatorname{reach}_{F}(t)-1</span>. ∎</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Assume the premise of Proposition 1. That is, <span class="math">F</span> is a fork for <span class="math">xy</span> so that <span class="math">\\rho(F)=\\rho(xy)</span>, <span class="math">\\mu_{x}(F)=\\mu_{x}(y)</span>, and the tine <span class="math">t_{\\rho}</span> identified by the fork-building strategy in Section 7.1 belongs to an <span class="math">F</span>-tine-pair <span class="math">(t_{\\rho},t_{x})</span> that witnesses <span class="math">\\mu_{x}(F)</span>. To recap, this means <span class="math">\\operatorname{reach}_{F}(t_{\\rho})=\\rho(F)=\\rho(x)</span>, <span class="math">\\operatorname{reach}_{F}(t_{x})=\\mu_{x}(F)=\\mu_{x}(y)</span>, and the tines <span class="math">t_{\\rho},t_{x}</span> are disjoint over <span class="math">y</span> (i.e., $\\ell(t_{\\rho}\\cap t_{x})\\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">). In addition, since </span>\\sigma\\in F^{\\prime}<span class="math"> is a conservative extension of </span>s<span class="math">, we have </span>\\operatorname{reach}_{F^{\\prime}}(\\sigma)=0<span class="math">. Finally, let </span>S<span class="math"> be the set of all zero-reach tines in </span>F$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We will break this part of the proof into several cases based on the relative reach and margin of the fork.</p>

    <h4 id="sec-82" class="text-lg font-semibold mt-6">Case 1: <span class="math">\\rho(xy)&gt;0</span> and <span class="math">\\mu_{x}(y)=0</span>.</h4>

    <p class="text-gray-300">We wish to show that <span class="math">\\rho(F^{\\prime})=\\rho(xy0)</span> and <span class="math">\\mu_{x}(F^{\\prime})\\geq 0</span>. Since <span class="math">\\rho(F)&gt;0</span>, <span class="math">s\\neq t_{\\rho}</span> and therefore, By (11) and Claim 2, Thus <span class="math">\\rho(F^{\\prime})\\geq\\operatorname{reach}_{F^{\\prime}}(t_{\\rho})=\\operatorname{reach}_{F}(t_{\\rho})-1=\\rho(xy)-1=\\rho(xy0)</span>. Therefore, <span class="math">\\rho(F^{\\prime})=\\rho(xy0)</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Since <span class="math">\\mu_{x}(y)=0</span>, <span class="math">t_{x}</span> is a candidate for being selected as <span class="math">s</span> and hence $\\ell(s\\cap t_{\\rho})\\leq\\ell(t_{x}\\cap t_{\\rho})\\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. Thus </span>\\sigma,t_{\\rho}\\in F^{\\prime}<span class="math"> are disjoint over </span>y0<span class="math"> and, therefore, </span>\\mu_{x}(F^{\\prime})\\geq\\operatorname{reach}_{F^{\\prime}}(\\sigma)=0$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-83" class="text-lg font-semibold mt-6">Case 2: <span class="math">\\rho(xy)=0</span>.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We wish to show that <span class="math">\\rho(F^{\\prime})=\\rho(xy0)</span> and <span class="math">\\mu_{x}(F^{\\prime})\\geq\\mu_{x}(y)-1</span>. Since there is at least one zero-reach tine, <span class="math">\\operatorname{reach}_{F}(s)=0</span> and, in addition, $t_{\\rho}\\in S,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">S</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq 1<span class="math">. Since </span>\\operatorname{reach}_{F^{\\prime}}(\\sigma)=0=\\rho(xy0)<span class="math"> by (11), </span>\\sigma<span class="math"> has the maximal reach in </span>F^{\\prime}<span class="math"> and, in particular, </span>\\rho(F^{\\prime})=\\rho(xy0)<span class="math">. Depending on </span>S<span class="math"> and </span>s<span class="math">, there are three possibilities. If </span>s=t_{\\rho}<span class="math">, this means </span>S=\\{t_{\\rho}\\}<span class="math">, </span>t_{x}<span class="math">’s </span>F^{\\prime}<span class="math">-reach is one less than its </span>F<span class="math">-reach, and </span>\\sigma,t_{x}<span class="math"> are still disjoint over </span>y0<span class="math">. Hence </span>\\mu_{x}(F^{\\prime})\\geq\\operatorname{reach}_{F}(t_{x})-1=\\mu_{x}(y)-1<span class="math">. If </span>s=t_{x}<span class="math">, then </span>t_{\\rho}<span class="math">’s </span>F^{\\prime}<span class="math">-reach is one less than its </span>F<span class="math">-reach and </span>\\sigma,t_{\\rho}<span class="math"> are disjoint over </span>y0<span class="math">. Hence </span>\\mu_{x}(F^{\\prime})\\geq\\operatorname{reach}_{F}(t_{\\rho})-1=\\rho(xy)-1\\geq\\mu_{x}(y)-1<span class="math">. Finally, suppose </span>s\\neq t_{\\rho}<span class="math"> and </span>s\\neq t_{x}<span class="math">. Then </span>\\mu_{x}(y)=\\operatorname{reach}_{F}(t_{x})<0<span class="math"> and, in addition, </span>s<span class="math"> (and </span>\\sigma<span class="math">) must share an edge with </span>t_{\\rho}<span class="math"> somewhere over </span>y<span class="math"> since otherwise, we would have achieved </span>\\mu_{x}(y)=0<span class="math">. As a result, </span>t_{x}<span class="math"> and </span>\\sigma<span class="math"> must be disjoint over </span>y0<span class="math">. Hence </span>\\mu_{x}(F^{\\prime})\\geq\\operatorname{reach}_{F^{\\prime}}(t_{x})=\\operatorname{reach}_{F}(t_{x})-1=\\mu_{x}(y)-1$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h4 id="sec-84" class="text-lg font-semibold mt-6">Case 3: <span class="math">\\rho(xy)&gt;0</span>, <span class="math">\\mu_{x}(y)\\neq 0</span>.</h4>

    <p class="text-gray-300">We wish to show that <span class="math">\\rho(F^{\\prime})=\\rho(xy0)</span> and <span class="math">\\mu_{x}(F^{\\prime})\\geq\\mu_{x}(y)-1</span>. In this case, <span class="math">s\\neq t_{\\rho}</span> and <span class="math">s\\neq t_{x}</span> and therefore, <span class="math">\\operatorname{reach}_{F^{\\prime}}(t_{i})=\\operatorname{reach}_{F}(t_{i})-1</span> for <span class="math">i=1,2</span>. The tines <span class="math">t_{\\rho},t_{x}</span> are still disjoint over <span class="math">y0</span>. In addition, <span class="math">t_{\\rho}</span> will still have the maximal reach in <span class="math">F^{\\prime}</span> since <span class="math">\\operatorname{reach}_{F^{\\prime}}(t_{\\rho})=\\rho(xy)-1=\\rho(xy0)</span> by 11. Therefore, <span class="math">\\rho(F^{\\prime})=\\rho(xy0)</span> and, in addition, <span class="math">\\mu_{x}(F^{\\prime})\\geq\\operatorname{reach}_{F^{\\prime}}(t_{x})=\\operatorname{reach}_{F}(t_{x})-1=\\mu_{x}(y)-1</span>.</p>

    <p class="text-gray-300">This complete the proof of Proposition 1. ∎</p>

    <h3 id="sec-85" class="text-xl font-semibold mt-8">7.3 Proof of Lemma 3</h3>

    <p class="text-gray-300">Let <span class="math">F</span> be a closed fork for the characteristic string <span class="math">xy</span>. Let <span class="math">t_{\\rho},t_{x}\\in F</span> be the two tines that witness <span class="math">\\mu_{x}(F)</span>, i.e., <span class="math">\\operatorname{reach}(t_{\\rho})=\\rho(F)</span>, <span class="math">\\operatorname{reach}_{F}(t_{x})=\\mu_{x}(F)</span>, and <span class="math">t_{\\rho},t_{x}</span> are disjoint over <span class="math">y</span>. Let <span class="math">\\hat{t}</span> be the longest tine in <span class="math">F</span>.</p>

    <p class="text-gray-300">In the base case, where <span class="math">y=\\varepsilon</span>, we observe that any two tines of <span class="math">F</span> are disjoint over <span class="math">y</span>. Moreover, even a single tine <span class="math">t_{\\rho}</span> is disjoint with itself over <span class="math">\\varepsilon</span>. Therefore, the relative margin <span class="math">\\mu_{x}(\\varepsilon)</span> must be greater than or equal to the reach of the tine <span class="math">t</span> that achieves <span class="math">\\operatorname{reach}(t)=\\rho(x)</span>. The relative margin must also be less than or equal to <span class="math">\\rho(x)</span>, because</p>

    <p class="text-gray-300">that is, by definition, the maximum reach over all tines in all forks <span class="math">F\\vdash w</span>. Putting these facts together, we have <span class="math">\\mu_{x}(\\varepsilon)=\\rho(x)</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Moving beyond the base case, we will consider a pair of closed forks <span class="math">F\\vdash xy</span> and <span class="math">F^{\\prime}\\vdash xyb</span> such that <span class="math">F\\sqsubseteq F^{\\prime}</span>, <span class="math">x,y\\in\\{0,1\\}^{*}</span>, $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq 1<span class="math">, and </span>b\\in\\{0,1\\}<span class="math">. If </span>b=1<span class="math">, we have set </span>F^{\\prime}=F<span class="math">. The reach of each tine increases by </span>1<span class="math"> from </span>F<span class="math"> to </span>F^{\\prime}<span class="math"> since the gap has not changed but the reserve has increased by one. Therefore, </span>\\mu_{x}(y1)=\\mu_{x}(y)+1$, as desired.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">If <span class="math">b=0</span>, however, things are more nuanced. Consider the following proposition:</p>

    <h6 id="sec-86" class="text-base font-medium mt-4">Proposition 2.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">x,y</span> be arbitrary Boolean strings, $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq 1<span class="math">, and </span>w=xy0<span class="math">. Then </span>\\mu_{x}(y0)\\leq 0<span class="math"> if </span>\\rho(xy)>\\mu_{x}(y)=0<span class="math">, and </span>\\mu_{x}(y0)\\leq\\mu_{x}(y)-1$ otherwise.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Recall that <span class="math">\\mu_{x}(F^{\\prime})\\geq\\mu_{x}(y0)</span> by Proposition 1. Combining this with Proposition 2 above, we conclude that <span class="math">\\mu_{x}(F^{\\prime})=\\mu_{x}(y0)</span> and, in addition, that the fork <span class="math">F^{\\prime}</span> actually achieves the maximum reach and the maximum relative margin for the characteristic string <span class="math">xy0</span>. It remains to prove Proposition 2.</p>

    <h6 id="sec-87" class="text-base font-medium mt-4">Proof of Proposition 2.</h6>

    <p class="text-gray-300">Suppose <span class="math">F^{\\prime}\\vdash xy0</span> is a closed fork such that <span class="math">\\rho(xy0)=\\rho(F^{\\prime})</span> and <span class="math">\\mu_{x}(y0)=\\mu_{x}(F^{\\prime})</span>. Let <span class="math">t_{\\rho},t_{x}\\in F^{\\prime}</span> to be a pair of tines disjoint over <span class="math">y</span> in <span class="math">F^{\\prime}</span> such that <span class="math">\\text{reach}_{F^{\\prime}}(t_{\\rho})=\\rho(F^{\\prime})</span> and <span class="math">\\text{reach}_{F^{\\prime}}(t_{x})=\\mu_{x}(F^{\\prime})=\\mu_{x}(y0)</span>. Let <span class="math">F\\vdash xy</span> be the unique closed fork such that <span class="math">F\\sqsubseteq F^{\\prime}</span>. Note that while <span class="math">F^{\\prime}</span> is an extension of <span class="math">F</span>, it is not necessarily a conservative extension.</p>

    <h4 id="sec-88" class="text-lg font-semibold mt-6">Case 1: <span class="math">\\rho(xy)&gt;0</span> and <span class="math">\\mu_{x}(y)=0</span>.</h4>

    <p class="text-gray-300">We wish to show that <span class="math">\\mu_{x}(y0)\\leq 0</span>. Suppose (toward a contradiction) that <span class="math">\\mu_{x}(y0)&gt;0</span>. Then neither <span class="math">t_{\\rho}</span> or <span class="math">t_{x}</span> is a conservative extension because, as we proved in Claim 1, conservative extensions have reach exactly <span class="math">0</span>. This means that <span class="math">t_{\\rho}</span> and <span class="math">t_{x}</span> existed in <span class="math">F</span>, and had strictly greater reach in <span class="math">F</span> than they do presently in <span class="math">F^{\\prime}</span> (by Claim 2). Because <span class="math">t_{\\rho}</span> and <span class="math">t_{x}</span> are disjoint over <span class="math">y0</span>, they must also be disjoint over <span class="math">y</span>; therefore the <span class="math">\\mu_{x}(F)</span> must be at least <span class="math">\\min\\{\\text{reach}_{F}(t_{\\rho}),\\text{reach}_{F}(t_{x})\\}</span>. Following this line of reasoning, we have <span class="math">0=\\mu_{x}(y)\\geq\\min_{i\\in\\{1,2\\}}\\{\\text{reach}_{F}(t_{i})\\}&gt;\\min_{i\\in\\{1,2\\}}\\{\\text{reach}_{F^{\\prime}}(t_{i})\\}=\\mu_{x}(F^{\\prime})=\\mu_{x}(y0)&gt;0</span>, a contradiction, as desired.</p>

    <h4 id="sec-89" class="text-lg font-semibold mt-6">Case 2: <span class="math">\\rho(xy)=0</span>.</h4>

    <p class="text-gray-300">We wish to show that <span class="math">\\mu_{x}(y0)\\leq\\mu_{x}(y)-1</span> or, equivalently, that <span class="math">\\mu_{x}(y0)&lt;\\mu_{x}(y)</span>. First, we claim that <span class="math">t_{\\rho}</span> must arise from an extension. Suppose, toward a contradiction, that <span class="math">t_{\\rho}</span> is not an extension, i.e., <span class="math">t_{\\rho}\\in F</span>. The fact that <span class="math">t_{\\rho}</span> achieves the maximum reach in <span class="math">F^{\\prime}</span> implies that <span class="math">t_{\\rho}</span> has non-negative reach since the longest honest tine always achieves reach <span class="math">0</span>. Furthermore, Claim 2 states that all tines other than the extended tine see their reach decrease. Therefore, <span class="math">t_{\\rho}\\in F</span> must have had a strictly positive reach. But this contradicts the central assumption of the case, i.e., that <span class="math">\\rho(xy)=0</span>. Therefore, we conclude that <span class="math">t_{\\rho}\\in F^{\\prime},t_{\\rho}\\notin F</span>, and, since <span class="math">F^{\\prime}</span> differs from <span class="math">F</span> by a single extension, <span class="math">t_{x}\\in F</span>.</p>

    <p class="text-gray-300">Let <span class="math">s\\in F</span> be the tine-prefix of <span class="math">t_{\\rho}\\in F^{\\prime}</span> so that <span class="math">t_{\\rho}</span> is an extension of <span class="math">s</span>. Since <span class="math">\\text{reach}_{F^{\\prime}}(t_{\\rho})=\\rho(xy0)=0</span> by (11), <span class="math">\\text{reach}_{F}(s)</span> must be at least <span class="math">0</span>. Additionally, since <span class="math">\\rho(xy)=0</span>, <span class="math">\\text{reach}_{F}(s)\\leq 0</span>. Together, these statements tell us that <span class="math">\\text{reach}_{F}(s)=0</span>. Restricting our view to <span class="math">F</span>, we see that <span class="math">s</span> and <span class="math">t_{x}</span> are disjoint over <span class="math">y</span> and so it must be true that <span class="math">\\min\\{\\text{reach}_{F}(s),\\text{reach}_{F}(t_{x})\\}\\leq\\mu_{x}(y)</span>. Because <span class="math">\\text{reach}_{F}(s)=0</span> and <span class="math">\\text{reach}_{F}(t_{x})\\leq\\rho(xy)=0</span>, we can simplify that statement to <span class="math">\\text{reach}_{F}(t_{x})\\leq\\mu_{x}(y)</span>. Finally, since <span class="math">t_{x}\\in F</span>, Claim 2 tells us that <span class="math">\\text{reach}_{F^{\\prime}}(t_{x})&lt;\\text{reach}_{F}(t_{x})</span>. Taken together, these two inequalities show that <span class="math">\\mu_{x}(y0)=\\text{reach}_{F^{\\prime}}(t_{x})&lt;\\text{reach}_{F}(t_{x})\\leq\\mu_{x}(y)</span>.</p>

    <h4 id="sec-90" class="text-lg font-semibold mt-6">Case 3: <span class="math">\\rho(xy)&gt;0,\\mu_{x}(y)\\neq 0</span>.</h4>

    <p class="text-gray-300">We wish to show that <span class="math">\\mu_{x}(y0)\\leq\\mu_{x}(y)-1</span> or, equivalently, that <span class="math">\\mu_{x}(y0)&lt;\\mu_{x}(y)</span>. Note that by 11, <span class="math">\\rho(xy0)=\\rho(xy)-1\\geq 0</span>. We will break this case into two sub-cases.</p>

    <p class="text-gray-300">If both <span class="math">t_{\\rho},t_{x}\\in F</span>. Then <span class="math">t_{\\rho},t_{x}\\in F</span> and, consequently, <span class="math">\\min\\{\\text{reach}_{F}(t_{\\rho}),\\text{reach}_{F}(t_{x})\\}\\leq\\mu_{x}(y)</span> since <span class="math">t_{\\rho}</span> and <span class="math">t_{x}</span> must be disjoint over <span class="math">y</span>. Furthermore, by Claim 2, <span class="math">\\text{reach}_{F^{\\prime}}(t_{i})&lt;\\text{reach}_{F}(t_{i})</span> for <span class="math">i\\in\\{1,2\\}</span>. Therefore, <span class="math">\\mu_{x}(y0)=\\text{reach}_{F^{\\prime}}(t_{x})=\\min\\{\\text{reach}_{F^{\\prime}}(t_{\\rho}),\\text{reach}_{F^{\\prime}}(t_{x})\\}&lt;\\min\\{\\text{reach}_{F}(t_{\\rho}),\\text{reach}_{F}(t_{x})\\}\\leq\\mu_{x}(y)</span>, as desired. If either <span class="math">t_{\\rho}\\notin F</span> or <span class="math">t_{x}\\notin F</span>. It must be true that <span class="math">\\text{reach}_{F^{\\prime}}(t_{x})\\leq 0</span>, because either <span class="math">t_{x}</span> is the extension (and therefore has reach exactly <span class="math">0</span>) or <span class="math">t_{\\rho}</span> is the extension and we have <span class="math">\\text{reach}_{F^{\\prime}}(t_{x})=\\mu_{x}(y0)\\leq\\rho(xy0)=\\text{reach}_{F^{\\prime}}(t_{\\rho})=0</span>. Recall that we have assumed <span class="math">\\mu_{x}(y)\\neq 0</span>. If <span class="math">\\mu_{x}(y)&gt;0</span>, we are done: certainly <span class="math">\\mu_{x}(y0)\\leq 0&lt;\\mu_{x}(y)</span>. If, however, <span class="math">\\mu_{x}(y)&lt;0</span>, there is more work to do. In this case, we claim that <span class="math">t_{x}\\in F</span>, i.e., <span class="math">t_{x}</span> did not arise from an extension. To see why, consider the following: if <span class="math">t_{x}</span> arose from extension, then there must be some <span class="math">s\\in F</span> so that <span class="math">s\\prec t_{x}</span> and <span class="math">\\text{reach}_{F}(s)\\geq 0</span>. Additionally, by our claim about non-extended tines, we see that</p>

    <p class="text-gray-300"><span class="math">\\operatorname{reach}_{F}(t_{\\rho})&gt;\\operatorname{reach}_{F^{\\prime}}(t_{\\rho})=\\rho(xy0)\\geq 0</span>. Therefore, <span class="math">\\mu_{x}(y)\\geq\\min\\{\\operatorname{reach}_{F}(t_{\\rho}),\\operatorname{reach}_{F}(s)\\}\\geq 0</span>, contradicting our assumption that <span class="math">\\mu_{x}(y)&lt;0</span>. Thus <span class="math">t_{x}\\in F</span>.</p>

    <p class="text-gray-300">The only remaining scenario is the one in which <span class="math">\\mu_{x}(y)&lt;0</span> and <span class="math">t_{\\rho}</span> arises from an extension of some tine <span class="math">s\\in F,\\operatorname{reach}_{F}(s)\\geq 0</span>. In this scenario, <span class="math">t_{x}</span> cannot have been the extension (since there is only one). By Claim 2, <span class="math">\\operatorname{reach}_{F}(t_{x})&gt;\\operatorname{reach}_{F^{\\prime}}(t_{x})</span>. Using a now-familiar line of reasoning, note that the two tines <span class="math">t_{x}</span> and <span class="math">s</span> are disjoint over <span class="math">y</span> and, therefore, <span class="math">\\mu_{x}(y)\\geq\\min\\{\\operatorname{reach}_{F}(s),\\operatorname{reach}_{F}(t_{x})\\}</span>. Since, <span class="math">\\mu_{x}(y)&lt;0</span> by assumption and <span class="math">\\operatorname{reach}_{F}(s)\\geq 0</span>, it follows that <span class="math">\\mu_{x}(y)\\geq\\operatorname{reach}_{F}(t_{x})&gt;\\operatorname{reach}_{F^{\\prime}}(t_{x})=\\mu_{x}(y0)</span>, as desired. ∎</p>

    <p class="text-gray-300">This completes the proof of Lemma 3. ∎</p>

    <h2 id="sec-91" class="text-2xl font-bold">8 Canonical forks and an optimal online adversary</h2>

    <p class="text-gray-300">Let <span class="math">w</span> be a characteristic string, written <span class="math">w=xy</span>, and recall the online fork-building strategy from Section 7.1. In Proposition 1, we showed that the fork produced by this strategy (for the string <span class="math">w</span>) always contains a tine-pair <span class="math">(t_{\\rho},t_{x})</span> that witnesses <span class="math">\\mu_{x}(y)</span>. In this section, we present an online fork-building strategy which produces a fork that <em>simultaneously</em> contains, for every prefix <span class="math">x\\preceq w</span>, a tine-pair that witnesses <span class="math">\\mu_{x}(y)</span>. These forks are called <em>canonical forks</em>, defined below.</p>

    <h6 id="sec-92" class="text-base font-medium mt-4">Definition 18 (Canonical forks).</h6>

    <p class="text-gray-300">Let <span class="math">w_{1}\\&gt;...\\&gt;w_{T}\\in\\{0,1\\}^{T}</span>. For <span class="math">n=0,1,...\\,,T</span>, a <em>canonical fork</em> <span class="math">F_{n}</span> for <span class="math">w=w_{1}\\&gt;...\\&gt;w_{n}</span> is inductively defined as follows. If <span class="math">n=0</span> then <span class="math">F_{0}</span> is the trivial fork for the empty string; it consists of a single (honest) vertex and no edge. If <span class="math">n\\geq 1</span>, the following holds: <span class="math">F_{n}</span> is a closed fork so that <span class="math">F_{n-1}\\subseteq F_{n}</span>. <span class="math">F_{n}</span> contains an honest tine <span class="math">\\tau_{\\rho}</span> so that <span class="math">\\operatorname{reach}(\\tau_{\\rho})=\\rho(F_{n})=\\rho(w)</span>. For every decomposition <span class="math">w=xy,x\\prec w</span>, <span class="math">F_{n}</span> contains two honest tines <span class="math">\\tau_{x},\\tau_{\\rho x}</span> so that the tine-pair <span class="math">(\\tau_{\\rho x},\\tau_{x})</span> witnesses <span class="math">\\mu_{x}(F_{n})=\\mu_{x}(y)</span>. The (possibly non-distinct) designated tines <span class="math">\\tau_{\\rho},\\tau_{\\rho x},\\tau_{x},x\\prec w</span> are called the <em>witness tines</em>.</p>

    <p class="text-gray-300">Note that if one’s objective is to create a fork which contains many early-diverging tine-pairs witnessing large relative margins, a canonical fork is the best one can hope for.</p>

    <h3 id="sec-93" class="text-xl font-semibold mt-8">8.1 An online strategy for building canonical forks</h3>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">w</span> be a characteristic string, written as <span class="math">w=xy</span>, and let <span class="math">F</span> be a fork for <span class="math">w</span>. If the tines <span class="math">t_{1},t_{2}\\in F</span> are disjoint over <span class="math">y</span>, we say <span class="math">t_{1}</span> and <span class="math">t_{2}</span> are <span class="math">y</span>-disjoint, or equivalently, <span class="math">t_{1}</span> is <span class="math">y</span>-disjoint with <span class="math">t_{2}</span>. Note that this means $\\ell(t_{1}\\cap t_{2})\\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. Let </span>\\leq_{\\pi}<span class="math"> be the lexicographical ordering of the tines where each tine is represented as the list of vertex labels appearing in the tine’s root-to-leaf path. If two tines have the same vertex labels, </span>\\leq_{\\pi}$ must break tie in an arbitrary but consistent way.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">For a fixed fork, let <span class="math">A,B</span> be two sets of tines. We define the <em>early-divergence witness for <span class="math">(A,B)</span></em> as follows. Let <span class="math">C_{AB}</span> be an ordered set of tine-pairs <span class="math">(t^{\\prime}_{a},t^{\\prime}_{b}),a^{\\prime}\\in A,b^{\\prime}\\in B</span> that minimize <span class="math">\\ell(t_{a}\\cap t_{b}),t_{a}\\in A,t_{b}\\in B</span>. The order of the elements in <span class="math">C_{AB}</span> is the following: <span class="math">(t_{1},t_{2})\\leq(t^{\\prime}_{1},t^{\\prime}_{2})</span> if and only if <span class="math">t_{1}\\leq_{\\pi}t^{\\prime}_{1}</span> and <span class="math">t_{2}\\leq_{\\pi}t^{\\prime}_{2}</span>. The first element of <span class="math">C_{AB}</span> is called the early-divergence witness for <span class="math">(A,B)</span>.</p>

    <p class="text-gray-300">The fork-building strategy <span class="math">\\mathcal{A}^{<em>}</span> presented in Figure 4 builds canonical forks in an online fashion, i.e., it scans the characteristic string <span class="math">w</span> once, from left to right, maintains a “current fork,” and updates it after seeing each new symbol by only adding new vertices. Since the final fork <span class="math">F\\vdash w</span> is canonical, it satisfies <span class="math">\\mu_{x}(F)=\\mu_{x}(y)</span> simultaeneously for all decompositions <span class="math">w=xy</span>; hence we call <span class="math">\\mathcal{A}^{</em>}</span> the <em>optimal online adversary</em>.</p>

    <h6 id="sec-94" class="text-base font-medium mt-4">Theorem 5 (<span class="math">\\mathcal{A}^{*}</span> builds canonical forks).</h6>

    <p class="text-gray-300">Let <span class="math">w\\in\\{0,1\\}^{n}</span> and <span class="math">b\\in\\{0,1\\}</span>. Let <span class="math">F\\vdash w</span> and <span class="math">F^{\\prime}\\vdash wb</span> be two closed forks built by the strategy <span class="math">\\mathcal{A}^{*}</span> so that <span class="math">F\\sqsubseteq F^{\\prime}</span> and suppose, in addition, that <span class="math">F</span> is canonical. Then <span class="math">F^{\\prime}</span> is canonical as well.</p>

    <p class="text-gray-300">We remark that the fork-building strategy <span class="math">\\mathcal{A}^{*}</span> would certainly satisfy Proposition 1 and, therefore, satisfy the recurrence relation (13) as well.</p>

    <p class="text-gray-300">Let  <span class="math">w = w_{1} \\ldots w_{n} \\in \\{0, 1\\}^{n}</span>  and  <span class="math">w_{n+1} \\in \\{0, 1\\}</span> . If  <span class="math">n = 0</span> , set  <span class="math">F_{0} \\vdash \\varepsilon</span>  as the trivial fork comprising a single vertex. Otherwise, for  <span class="math">n \\geq 0</span> , let  <span class="math">F_{n}</span>  be the closed fork built recursively by  <span class="math">\\mathcal{A}^{*}</span>  for the string  <span class="math">w</span> . If  <span class="math">w_{n+1} = 1</span> , set  <span class="math">F_{n+1} = F_{n}</span> . Otherwise, the closed fork  <span class="math">F_{n+1} \\vdash w0</span>  is the result of a single conservative extension of a tine  <span class="math">s \\in F_{n}</span>  into a new honest tine  <span class="math">\\sigma \\in F_{n+1}</span> ,  <span class="math">\\ell(\\sigma) = n + 1</span> ; The tine  <span class="math">s</span>  can be identified as follows. If  <span class="math">F_{n}</span>  contains no tine with reach zero,  <span class="math">s</span>  is the unique longest tine in  <span class="math">F_{n}</span> . Otherwise,  <span class="math">s</span>  is the reach-zero tine that diverges earliest with respect to the set of maximal-reach tines in  <span class="math">F_{n}</span> . If there are multiple candidates for  <span class="math">s</span> , select the one with the smallest  <span class="math">\\leq_{\\pi}</span> -rank.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Writing  <span class="math">w&#x27; = ww_{n+1}, F = F_n</span> , and  <span class="math">F&#x27; = F_{n+1}</span> , identify the tines  <span class="math">\\tau_{\\rho}, \\tau_w, \\tau_x, \\tau_{\\rho x} \\in F&#x27;, x \\prec w</span>  as follows. Let  <span class="math">R</span>  (resp.  <span class="math">R&#x27;</span> ) be the set of  <span class="math">F</span> -tines (resp.  <span class="math">F&#x27;</span> -tines) with the maximal  <span class="math">F</span> -reach (resp.  <span class="math">F&#x27;</span> -reach). Set  <span class="math">\\tau_{\\rho}</span>  as the element of  <span class="math">R&#x27;</span>  with smallest  <span class="math">\\leq_{\\pi}</span> -rank. Set  <span class="math">(\\tau_w, \\tau_{\\rho w})</span>  as the early-divergence witness for  <span class="math">(R, R&#x27;)</span> . For every decomposition  <span class="math">w = xy</span> ,  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq 1<span class="math"> ,  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq 0<span class="math"> , do as follows. Let  </span>B_x<span class="math">  be the set of  </span>F'<span class="math"> -tines that are  </span>yw_{n+1}<span class="math"> -disjoint with some maximal-reach tine in  </span>R'<span class="math"> . Let  </span>C_x \\subseteq B_x<span class="math">  contain the tines with the maximal  </span>F'<span class="math"> -reach, the maximum taken over  </span>B_x<span class="math"> . Set  </span>(\\tau_x, \\tau_{\\rho x})<span class="math">  as the early-divergence witness for  </span>(C_x, R')$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Figure 4: Optimal online adversary  <span class="math">\\mathcal{A}^*</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Consider the player in the  <span class="math">(\\mathcal{D}, T; s, k)</span> -settlement game who, at the first step, samples a characteristic string  <span class="math">w \\sim \\mathcal{D}, w = w_1w_2\\ldots w_T</span> . Since the challenger is deterministic, the game is completely determined by the characteristic string and the choices of the player. In particular, for a given prefix  <span class="math">x \\prec w</span> ,  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">= s - 1<span class="math"> , consider the decompositions  </span>w = xyz<span class="math"> . The player&#x27;s chance of winning the game will be maximized if, for every  </span>y<span class="math"> ,  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq k + 1<span class="math">  (so that  </span>n =</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">xy</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\geq s + k<span class="math"> ), the fork  </span>F_n \\vdash xy<span class="math">  contains a tine-pair  </span>(\\tau_{\\rho x}, \\tau_x)<span class="math">  that witnesses  </span>\\mu_x(y)<span class="math"> . In fact, if  </span>\\mu_x(y) \\geq 0<span class="math">  for some  </span>y<span class="math">  then, as shown in Fact 1, the player wins the game by augmenting  </span>F_n<span class="math">  to an  </span>x<span class="math"> -balanced fork  </span>A_n \\vdash xy$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Note, in addition, that if  <span class="math">F_{n}</span>  is canonical, the player can optimally play  <span class="math">(\\mathcal{D}, T; s, k)</span> -settlement games simultaneously for every  <span class="math">s \\in [n - k]</span> . That is, given a distribution  <span class="math">\\mathcal{D}</span> , a canonical fork  <span class="math">F_{n}</span>  gives the player the largest probability of causing a settlement violation at as many slots  <span class="math">s \\in [n - k]</span>  as possible, at once.</p>

    <p class="text-gray-300">For convenience, let us record the following fact which compacts Claims 1 and 2.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Fact 2. Let  <span class="math">F \\vdash w</span>  and  <span class="math">F&#x27; \\vdash w0</span>  be closed forks so that  <span class="math">F \\subseteq F&#x27;</span>  and  <span class="math">F&#x27;</span>  differs from  <span class="math">F</span>  by a single conservative extension  <span class="math">\\sigma \\in F&#x27;</span> ,  $\\ell(\\sigma) =</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+ 1<span class="math"> . Then  </span>\\operatorname{reach}_{F'}(t) = \\operatorname{reach}_F(t) - 1<span class="math">  for every  </span>t \\in F<span class="math">  and, in addition,  </span>\\operatorname{reach}_{F'}(\\sigma) = 0$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In the rest of the proof, we will frequently use the above fact along with Lemma 2 and Lemma 3, often without an explicit reference.</p>

    <p class="text-gray-300">By assumption,  <span class="math">F</span>  is a canonical fork. Thus  <span class="math">\\mathrm{reach}_F(t_\\rho) = \\rho(w)</span>  and for every prefix  <span class="math">x \\prec w</span> ,  <span class="math">\\mathrm{reach}_F(t_x) = \\mu_x(y)</span> . Let  <span class="math">w&#x27; = wb</span>  and let  <span class="math">\\tau_\\rho, \\tau_w, \\tau_{\\rho w}, \\tau_x, \\tau_{\\rho x} \\in F&#x27;</span> ,  <span class="math">x \\prec w</span>  be the purported witness tines in  <span class="math">F&#x27;</span> . Note that  <span class="math">\\tau_x</span>  must be  <span class="math">yb</span> -disjoint with  <span class="math">\\tau_{\\rho x}</span>  by construction. Similarly,  <span class="math">\\tau_w</span>  must be  <span class="math">w_{n+1}</span> -disjoint with  <span class="math">\\tau_{\\rho w}</span>  since both cannot contain the unique vertex from slot  <span class="math">n+1</span> . It is evident from the construction that  <span class="math">\\rho(F&#x27;) = \\mathrm{reach}_{F&#x27;}(\\tau_\\rho) = \\mathrm{reach}_{F&#x27;}(\\tau_{\\rho w}) = \\mathrm{reach}_{F&#x27;}(\\tau_{\\rho x})</span>  for  <span class="math">x \\prec w</span> . Therefore, we wish to show that  <span class="math">\\mathrm{reach}_{F&#x27;}(\\tau_\\rho) = \\rho(wb)</span> ,  <span class="math">\\mathrm{reach}_{F&#x27;}(\\tau_w) = \\mu_w(b)</span>  and  <span class="math">\\mathrm{reach}_{F&#x27;}(\\tau_x) = \\mu_x(yb)</span>  for  <span class="math">x \\prec w</span> .</p>

    <p class="text-gray-300">If  <span class="math">b = 1</span> . In this case,  <span class="math">F&#x27; = F</span>  and  <span class="math">w&#x27; = w1</span> . Examining the rule for assigning  <span class="math">\\tau_{\\rho}, \\tau_{x}, \\tau_{\\rho x}</span> , and  <span class="math">\\tau_{w}</span> , we see that  <span class="math">\\tau_{\\rho} = t_{\\rho}</span> ,  <span class="math">\\tau_{w} = t_{\\rho}</span> ,  <span class="math">\\tau_{x} = t_{x}</span> , and  <span class="math">\\tau_{\\rho x} = t_{\\rho x}</span>  for all  <span class="math">x \\prec w</span> . Since  <span class="math">F&#x27; = F</span>  and  <span class="math">b = 1</span> , the  <span class="math">F&#x27;</span> -reach of every  <span class="math">F</span> -tine is one plus its  <span class="math">F</span> -reach. Thus for any  <span class="math">x, x \\prec w</span> , writing  <span class="math">w&#x27; = xy1</span> , we have  <span class="math">\\mu_x(y1) = 1 + \\mu_x(y) =</span></p>

    <p class="text-gray-300"><span class="math">1+\\operatorname{reach}_{F}(t_{x})=\\operatorname{reach}_{F^{\\prime}}(t_{x})=\\operatorname{reach}_{F^{\\prime}}(\\tau_{x})</span>. Similarly, <span class="math">\\rho(w1)=1+\\rho(w)=\\operatorname{reach}_{F^{\\prime}}(t_{\\rho})=\\operatorname{reach}_{F^{\\prime}}(\\tau_{\\rho})</span>. By construction, <span class="math">\\tau_{w}</span> has the largest reach in <span class="math">F</span>; but this means <span class="math">\\operatorname{reach}_{F^{\\prime}}(\\tau_{w})=\\operatorname{reach}_{F^{\\prime}}(t_{\\rho})=\\rho(F^{\\prime})=\\rho(w1)</span> but, on the other hand, <span class="math">\\mu_{w}(1)=1+\\mu_{w}(\\varepsilon)=1+\\rho(w)=\\rho(w1)</span>; hence <span class="math">\\operatorname{reach}_{F^{\\prime}}(\\tau_{w})=\\mu_{w}(1)</span>. If <span class="math">b=0</span>. The contingencies of this case are covered by Propositions 3, 4, and 5 below.</p>

    <h6 id="sec-99" class="text-base font-medium mt-4">Proposition 3.</h6>

    <p class="text-gray-300">Assume the premise of Theorem 5 with <span class="math">b=0</span>. Then <span class="math">F^{\\prime}</span> contains a witness tine <span class="math">\\tau_{\\rho}</span> so that <span class="math">\\operatorname{reach}_{F^{\\prime}}(\\tau_{\\rho})=\\rho(w0)</span>.</p>

    <h6 id="sec-100" class="text-base font-medium mt-4">Proof.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Recall that the tine <span class="math">\\sigma\\in F^{\\prime}</span>, $\\ell(\\sigma)=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+1<span class="math"> is a conservative extension to a tine </span>s\\in F<span class="math">, </span>\\operatorname{reach}_{F}(s)=0<span class="math"> so that </span>\\operatorname{reach}_{F^{\\prime}}(\\sigma)=0<span class="math">. Also recall that </span>\\mu_{z}(\\varepsilon)=\\rho(z)<span class="math"> for any characteristic string </span>z<span class="math">. Finally, note that it suffices to show that </span>\\operatorname{reach}_{F^{\\prime}}(\\tau_{\\rho})\\geq\\rho(w0)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Suppose <span class="math">\\rho(w)&gt;0</span>. Using Fact 2, Lemma 3, and examining the rule for assigning <span class="math">\\tau_{\\rho}</span>, we see that <span class="math">\\operatorname{reach}_{F^{\\prime}}(\\tau_{\\rho})\\geq\\operatorname{reach}_{F^{\\prime}}(t_{\\rho})=\\operatorname{reach}_{F}(t_{\\rho})-1=\\rho(w)-1=\\rho(w0)</span>. On the other hand, if <span class="math">\\rho(w)=0</span> then <span class="math">\\rho(w0)</span> is zero as well. It follows that <span class="math">\\operatorname{reach}_{F^{\\prime}}(\\tau_{\\rho})\\geq\\operatorname{reach}_{F^{\\prime}}(\\sigma)=0=\\rho(w0)</span>.</p>

    <p class="text-gray-300">∎</p>

    <h6 id="sec-101" class="text-base font-medium mt-4">Proposition 4.</h6>

    <p class="text-gray-300">Assume the premise of Theorem 5 with <span class="math">b=0</span>. Then <span class="math">F^{\\prime}</span> contains a tine-pair <span class="math">(\\tau_{\\rho w},\\tau_{w})</span> that witnesses <span class="math">\\mu_{w}(0)</span>.</p>

    <h6 id="sec-102" class="text-base font-medium mt-4">Proof.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Recall that the tine <span class="math">\\sigma\\in F^{\\prime}</span>, $\\ell(\\sigma)=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+1<span class="math"> is a conservative extension to a tine </span>s\\in F<span class="math">, </span>\\operatorname{reach}_{F}(s)=0<span class="math"> so that </span>\\operatorname{reach}_{F^{\\prime}}(\\sigma)=0<span class="math">. In addition, since </span>F^{\\prime}<span class="math"> contains a single vertex at slot </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+1<span class="math">, </span>\\tau_{w}<span class="math"> and </span>\\tau_{\\rho w}<span class="math"> are disjoint over the suffix </span>w_{n+1}<span class="math"> and, moreover, </span>\\operatorname{reach}_{F^{\\prime}}(\\tau_{\\rho w})=\\rho(F^{\\prime})=\\rho(w0)<span class="math"> by Proposition 3. Now consider the following contingencies based on </span>\\rho(w)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">If <span class="math">\\rho(w)&gt;0</span>. Thus <span class="math">\\mu_{w}(0)=\\mu_{w}(\\varepsilon)-1=\\rho(w)-1=\\rho(w0)</span>. There are two mutually exclusive scenarios based on <span class="math">\\tau_{\\rho w}</span> and <span class="math">\\sigma</span>. If <span class="math">\\tau_{\\rho w}=\\sigma</span> then, by construction, <span class="math">\\tau_{w}\\neq\\sigma</span> (since $\\ell(\\tau_{\\rho w},\\tau_{w})\\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">) and, in addition, </span>\\operatorname{reach}_{F}(\\tau_{w})=\\rho(w)<span class="math">. This implies </span>\\operatorname{reach}_{F^{\\prime}}(\\tau_{w})=\\operatorname{reach}_{F}(\\tau_{w})-1=\\rho(w)-1=\\mu_{w}(0)<span class="math">. On the other hand, if </span>\\tau_{\\rho w}\\neq\\sigma<span class="math"> then </span>\\tau_{\\rho w}\\in F<span class="math">. Since </span>\\tau_{w}<span class="math"> is the </span>F<span class="math">-tine with the largest </span>F^{\\prime}<span class="math">-reach, it follows that </span>\\operatorname{reach}_{F^{\\prime}}(\\tau_{w})=\\operatorname{reach}_{F^{\\prime}}(\\tau_{\\rho w})=\\rho(w0)=\\mu_{w}(0)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">If <span class="math">\\rho(w)=0</span>. Since <span class="math">\\rho(F)=\\rho(w)=0</span>, Fact 2 tells us that every <span class="math">F</span>-tine must have a negative reach in <span class="math">F^{\\prime}</span>. Since <span class="math">\\rho(F^{\\prime})</span> is non-negative, it must be the case that <span class="math">\\tau_{\\rho w}=\\sigma</span>. We can reuse the argument from the subcase “<span class="math">\\tau_{\\rho w}=\\sigma</span>” of the preceding case and conclude that <span class="math">\\operatorname{reach}_{F^{\\prime}}(\\tau_{w})=\\mu_{w}(0)</span>.</p>

    <p class="text-gray-300">∎</p>

    <h6 id="sec-103" class="text-base font-medium mt-4">Proposition 5.</h6>

    <p class="text-gray-300">Assume the premise of Theorem 5 with <span class="math">b=0</span>. Let <span class="math">x\\prec w</span> and write <span class="math">w=xy</span>. Then <span class="math">F^{\\prime}</span> contains a tine-pair <span class="math">(\\tau_{\\rho x},\\tau_{x})</span> that witnesses <span class="math">\\mu_{x}(y0)</span>.</p>

    <h6 id="sec-104" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">By construction, <span class="math">\\operatorname{reach}_{F^{\\prime}}(\\tau_{x})=\\mu_{x}(F^{\\prime})</span> and, by the definition of relative margin, <span class="math">\\mu_{x}(F^{\\prime})\\leq\\mu_{x}(y0)</span>. In light of (13), it suffices to show that <span class="math">\\operatorname{reach}_{F^{\\prime}}(\\tau_{x})\\geq 0</span> if <span class="math">\\rho(xy)&gt;\\mu_{x}(y)=0</span>, and <span class="math">\\operatorname{reach}_{F^{\\prime}}(\\tau_{x})\\geq\\mu_{x}(y)-1</span> otherwise.</p>

    <p class="text-gray-300">Let <span class="math">R</span> be the set of <span class="math">F</span>-tines with the maximal <span class="math">F</span>-reach and let <span class="math">R^{\\prime}</span> be the set of <span class="math">F^{\\prime}</span>-tines with the maximal <span class="math">F^{\\prime}</span>-reach; thus <span class="math">\\tau_{\\rho x}\\in R^{\\prime}</span>. We know that <span class="math">t_{x}</span> is <span class="math">y</span>-disjoint with <span class="math">t_{\\rho}</span> in <span class="math">F</span>. Consider the following mutually exclusive cases.</p>

    <p class="text-gray-300">If <span class="math">\\rho(w)&gt;0</span> and <span class="math">\\mu_{x}(y)=0</span>. In this case, <span class="math">\\mu_{x}(y0)=0</span> using Lemma 3. Since <span class="math">\\operatorname{reach}_{F}(s)=0&lt;\\operatorname{reach}_{F}(t_{\\rho x})=\\rho(w)</span>, it follows that <span class="math">s\\neq t_{\\rho x}</span>. In addition, observe that <span class="math">t_{\\rho x}</span> must be in <span class="math">R^{\\prime}</span>. By our choice of <span class="math">s</span>, <span class="math">\\ell(s\\cap t_{\\rho x})\\leq\\ell(t_{x}\\cap t_{\\rho x})</span> since <span class="math">\\operatorname{reach}_{F}(t_{x})=\\mu_{x}(y)=0=\\operatorname{reach}_{F}(s)</span>. Since <span class="math">t_{x}</span> is <span class="math">y</span>-disjoint with <span class="math">t_{\\rho x}</span>, so is <span class="math">s</span>. Recall that <span class="math">\\operatorname{reach}_{F^{\\prime}}(\\tau_{x})</span> is the largest among all tines that are <span class="math">y0</span>-disjoint with <span class="math">\\tau_{\\rho x}</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">If <span class="math">\\tau_{\\rho x}=t_{\\rho x}</span>. Thus <span class="math">t_{x}</span> is <span class="math">y0</span>-disjoint with <span class="math">\\tau_{\\rho x}</span>. Since $\\ell(\\sigma)=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+1<span class="math">, </span>\\sigma<span class="math"> must be </span>y0<span class="math">-disjoint with </span>t_{\\rho x}=\\tau_{\\rho x}<span class="math">, it follows that </span>\\operatorname{reach}_{F^{\\prime}}(\\tau_{x})\\geq\\operatorname{reach}_{F^{\\prime}}(\\sigma)=0=\\mu_{x}(y0)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">\\rho(w)=0</span>. Let <span class="math">x\\prec w</span> and note that <span class="math">\\mu_{x}(y0)=\\mu_{x}(y)-1</span>. Since <span class="math">\\rho(w)=0</span>, <span class="math">\\operatorname{reach}_{F}(s)=0</span> all <span class="math">F</span>-tines will have a negative reach in <span class="math">F^{\\prime}</span>; by Fact 2, <span class="math">\\sigma</span> is the only tine in <span class="math">F^{\\prime}</span> with the maximal reach <span class="math">\\rho(F^{\\prime})=\\rho(w0)=0</span>, i.e., <span class="math">\\tau_{\\rho x}=\\tau_{\\rho}=\\sigma</span>. In addition, we must also have <span class="math">\\operatorname{reach}_{F}(s)=0</span>, i.e., <span class="math">s\\in R</span>; we conclude that <span class="math">s</span> has the smallest <span class="math">\\leq_{\\pi}</span> rank among all members of <span class="math">R</span> and, therefore, <span class="math">s=t_{\\rho}</span>. It follows that <span class="math">\\tau_{x}</span> is <span class="math">y0</span>-disjoint with <span class="math">s=t_{\\rho}</span> and, in particular, <span class="math">\\tau_{x}\\in F</span>. Considering <span class="math">t_{x}</span>, if it is <span class="math">y</span>-disjoint with <span class="math">t_{\\rho}</span> then we must have <span class="math">\\tau_{x}=t_{x}</span>; in this case, <span class="math">\\operatorname{reach}_{F^{\\prime}}(\\tau_{x})=\\operatorname{reach}_{F^{\\prime}}(t_{x})=\\operatorname{reach}_{F}(t_{x})-1=\\mu_{x}(y)-1=\\mu_{x}(y0)</span>. Otherwise, $\\ell(t_{x}\\cap t_{\\rho})\\geq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+1<span class="math"> and there must be a tine </span>t_{\\rho x}\\in F<span class="math"> that is </span>y<span class="math">-disjoint with </span>t_{x}<span class="math"> (and hence, with </span>\\tau_{\\rho x}<span class="math">). Therefore, </span>\\operatorname{reach}_{F^{\\prime}}(\\tau_{x})\\geq\\operatorname{reach}_{F^{\\prime}}(t_{\\rho x})\\geq\\operatorname{reach}_{F^{\\prime}}(t_{x})=\\operatorname{reach}_{F}(t_{x})-1=\\mu_{x}(y)-1<span class="math">. Here, the first inequality follows from the construction of </span>\\tau_{x}<span class="math"> and the second one follows since </span>t_{\\rho x}<span class="math">) has the maximal reach in </span>F$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">If <span class="math">\\rho(w)&gt;0</span> and <span class="math">\\mu_{x}(y)\\neq 0</span>. There can be two cases depending on whether <span class="math">s</span> has zero reach in <span class="math">F</span>.</p>

    <p class="text-gray-300">If <span class="math">\\operatorname{reach}_{F}(s)=0</span>. Then <span class="math">s\\notin\\{t_{\\rho x},t_{x}\\}</span>. Observe that <span class="math">\\operatorname{reach}_{F^{\\prime}}(t_{\\rho x})=\\operatorname{reach}_{F}(t_{\\rho x})-1=\\rho(w)-1=\\rho(w0)</span>. It follwos that <span class="math">t_{\\rho x}\\in R^{\\prime}</span>. Since <span class="math">t_{x}</span> is <span class="math">y0</span>-disjoint with <span class="math">t_{\\rho x}\\in R^{\\prime}</span> and, in addition, that <span class="math">\\tau_{x}</span> has the largest reach among all tines that are <span class="math">y0</span>-disjoint with some member of <span class="math">R^{\\prime}</span>, we conclude that <span class="math">\\operatorname{reach}_{F^{\\prime}}(\\tau_{x})\\geq\\operatorname{reach}_{F^{\\prime}}(t_{x})=\\operatorname{reach}_{F}(t_{x})-1=\\mu_{x}(y)-1=\\mu_{x}(y0)</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">If <span class="math">\\operatorname{reach}_{F}(s)\\geq 1</span>. In this case, <span class="math">s</span> is the longest tine in <span class="math">F</span>. Considering fork <span class="math">F^{\\prime}</span>, if some tine <span class="math">r^{\\prime}\\in R^{\\prime}</span> is <span class="math">y0</span>-disjoint with <span class="math">t_{x}</span> then <span class="math">\\operatorname{reach}_{F^{\\prime}}(\\tau_{x})\\geq\\operatorname{reach}_{F^{\\prime}}(t_{x})=\\operatorname{reach}_{F}(t_{x})-1=\\mu_{x}(y)-1=\\mu_{x}(y0)</span>. Otherwise, $\\ell(r^{\\prime}\\cap t_{x})></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> for every tine </span>r^{\\prime}\\in R^{\\prime}<span class="math">, i.e., no maximal-reach </span>F^{\\prime}<span class="math">-tine is </span>y0<span class="math">-disjoint with </span>t_{x}<span class="math">. Since </span>\\ell(t_{x},t_{\\rho x})\\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> by assumption and </span>\\tau_{\\rho x}\\in R^{\\prime}<span class="math">, it follows that </span>\\ell(\\tau_{\\rho x}\\cap t_{\\rho x})\\leq</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, i.e., </span>t_{\\rho x}<span class="math"> is </span>y0<span class="math">-disjoint with </span>\\tau_{\\rho x}<span class="math">. Therefore, </span>\\operatorname{reach}_{F^{\\prime}}(\\tau_{x})\\geq\\operatorname{reach}_{F^{\\prime}}(t_{\\rho x})=\\operatorname{reach}_{F}(t_{\\rho x})-1=\\rho(w)-1\\geq\\mu_{x}(y)-1=\\mu_{x}(y0)<span class="math">. Here, the second inequality is true since </span>\\mu_{x}(y)\\leq\\rho(xy)=\\rho(w)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">∎</p>

    <p class="text-gray-300">This completes the proof of Theorem 5. ∎</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In regards to the canonical fork <span class="math">F\\vdash w</span> produced by the strategy <span class="math">\\mathcal{A}^{*}</span> (see Figure 4), it is possible to maintain witness tines <span class="math">\\tau_{\\rho},\\tau_{m}^{\\prime}\\in F</span>, for integers $m=-</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,...\\,,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">w</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, so that for every prefix </span>x\\prec w<span class="math">, the tine-pair </span>(\\tau_{\\rho},\\tau_{\\mu_{x}(y)}^{\\prime})<span class="math"> witnesses </span>\\mu_{x}(y)<span class="math">. In particular, a single maxmimal-reach tine </span>\\tau_{\\rho}$ appears in every witness tine-pair. We omit futher details.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h2 id="sec-105" class="text-2xl font-bold">Acknowledgments</h2>

    <p class="text-gray-300">We are grateful to Shreyas Gandlur and Bruce Hajek (UIUC) for their suggestion about using the dominance argument in the proof of Bound 2.</p>

    <h2 id="sec-106" class="text-2xl font-bold">References</h2>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[1] Adam Back. Hashcash. http://www.cypherspace.org/hashcash, 1997.</li>

      <li>[2] Christian Badertscher, Peter Gazi, Aggelos Kiayias, Alexander Russell, and Vassilis Zikas. Ouroboros genesis: Composable proof-of-stake blockchains with dynamic availability. IACR Cryptology ePrint Archive, 2018:378, 2018.</li>

      <li>[3] Iddo Bentov, Ariel Gabizon, and Alex Mizrahi. Cryptocurrencies without proof of work. CoRR, abs/1406.5694, 2014.</li>

      <li>[4] Iddo Bentov, Rafael Pass, and Elaine Shi. Snow white: Provably secure proofs of stake. IACR Cryptology ePrint Archive, 2016:919, 2016.</li>

      <li>[5] Jonah Brown-Cohen, Arvind Narayanan, Christos-Alexandros Psomas, and S. Matthew Weinberg. Formal barriers to longest-chain proof-of-stake protocols. CoRR, abs/1809.06528, 2018.</li>

    </ul>

    <p class="text-gray-300">-</p>

    <p class="text-gray-300">[6] Bernardo David, Peter Gazi, Aggelos Kiayias, and Alexander Russell. Ouroboros praos: An adaptively-secure, semi-synchronous proof-of-stake blockchain. In Nielsen and Rijmen [19], pages 66–98.</p>

    <p class="text-gray-300">[7] Cynthia Dwork and Moni Naor. Pricing via processing or combatting junk mail. In Ernest F. Brickell, editor, Advances in Cryptology – CRYPTO’92, volume 740 of Lecture Notes in Computer Science, pages 139–147, Santa Barbara, CA, USA, August 16–20, 1993. Springer, Heidelberg, Germany.</p>

    <p class="text-gray-300">[8] Stefan Dziembowski, Sebastian Faust, Vladimir Kolmogorov, and Krzysztof Pietrzak. Proofs of space. In Rosario Gennaro and Matthew J. B. Robshaw, editors, Advances in Cryptology – CRYPTO 2015, Part II, volume 9216 of Lecture Notes in Computer Science, pages 585–605, Santa Barbara, CA, USA, August 16–20, 2015. Springer, Heidelberg, Germany.</p>

    <p class="text-gray-300">[9] Juan A. Garay, Aggelos Kiayias, and Nikos Leonardos. The bitcoin backbone protocol: Analysis and applications. In Elisabeth Oswald and Marc Fischlin, editors, Advances in Cryptology - EUROCRYPT 2015 - 34th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Sofia, Bulgaria, April 26-30, 2015, Proceedings, Part II, volume 9057 of Lecture Notes in Computer Science, pages 281–310. Springer, 2015.</p>

    <p class="text-gray-300">[10] Juan A. Garay, Aggelos Kiayias, and Nikos Leonardos. The bitcoin backbone protocol with chains of variable difficulty. In Jonathan Katz and Hovav Shacham, editors, Advances in Cryptology – CRYPTO 2017, Part I, volume 10401 of Lecture Notes in Computer Science, pages 291–323, Santa Barbara, CA, USA, August 20–24, 2017. Springer, Heidelberg, Germany.</p>

    <p class="text-gray-300">[11] Juan A. Garay, Aggelos Kiayias, and Nikos Leonardos. The bitcoin backbone protocol with chains of variable difficulty. In Jonathan Katz and Hovav Shacham, editors, Advances in Cryptology - CRYPTO 2017 - 37th Annual International Cryptology Conference, Santa Barbara, CA, USA, August 20-24, 2017, Proceedings, Part I, volume 10401 of Lecture Notes in Computer Science, pages 291–323. Springer, 2017.</p>

    <p class="text-gray-300">[12] Charles M. Grinstead and J. Laurie Snell. Introduction to Probability. American Mathematical Association, 1997.</p>

    <p class="text-gray-300">[13] Aggelos Kiayias, Alexander Russell, Bernardo David, and Roman Oliynykov. Ouroboros: A provably secure proof-of-stake blockchain protocol. In Jonathan Katz and Hovav Shacham, editors, Advances in Cryptology - CRYPTO 2017 - 37th Annual International Cryptology Conference, volume 10401 of Lecture Notes in Computer Science, pages 357–388. Springer, 2017.</p>

    <p class="text-gray-300">[14] David A Levin, Yuval Peres, and Elizabeth L Wilmer. Markov chains and mixing times, volume 58. American Mathematical Society, 2009.</p>

    <p class="text-gray-300">[15] Silvio Micali. ALGORAND: the efficient and democratic ledger. CoRR, abs/1607.01341, 2016.</p>

    <p class="text-gray-300">[16] Tal Moran and Ilan Orlov. Proofs of space-time and rational proofs of storage. Cryptology ePrint Archive, Report 2016/035, 2016. http://eprint.iacr.org/2016/035.</p>

    <p class="text-gray-300">[17] Rajeev Motwani and Prabhakar Raghavan. Randomized Algorithms. Cambridge University Press, New York, NY, USA, 1995.</p>

    <p class="text-gray-300">[18] Satoshi Nakamoto. Bitcoin: A peer-to-peer electronic cash system. http://bitcoin.org/bitcoin.pdf, 2008.</p>

    <p class="text-gray-300">[19] Jesper Buus Nielsen and Vincent Rijmen, editors. Advances in Cryptology - EUROCRYPT 2018 - 37th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Tel Aviv, Israel, April 29 - May 3, 2018 Proceedings, Part II, volume 10821 of Lecture Notes in Computer Science, 2018. Springer.</p>

    <p class="text-gray-300">[20] Sunoo Park, Krzysztof Pietrzak, Albert Kwon, Joël Alwen, Georg Fuchsbauer, and Peter Gazi. Spacemint: A cryptocurrency based on proofs of space. IACR Cryptology ePrint Archive, 2015:528, 2015.</p>

    <p class="text-gray-300">33</p>

    <p class="text-gray-300">[21] Rafael Pass and Elaine Shi. The sleepy model of consensus. In Tsuyoshi Takagi and Thomas Peyrin, editors, Advances in Cryptology - ASIACRYPT 2017 - 23rd International Conference on the Theory and Applications of Cryptology and Information Security, Hong Kong, China, December 3-7, 2017, Proceedings, Part II, volume 10625 of Lecture Notes in Computer Science, pages 380–409. Springer, 2017.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[22] Rafael Pass and Elaine Shi. Hybrid consensus: Efficient consensus in the permissionless model. In Andréa W. Richa, editor, 31st International Symposium on Distributed Computing, DISC 2017, October 16-20, 2017, Vienna, Austria, volume 91 of LIPIcs, pages 39:1–39:16. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2017.</li>

      <li>[23] Rafael Pass and Elaine Shi. Thunderella: Blockchains with optimistic instant confirmation. In Nielsen and Rijmen <em>[19]</em>, pages 3–33.</li>

      <li>[24] Rafael Pass, Lior Seeman, and Abhi Shelat. Analysis of the blockchain protocol in asynchronous networks. In Jean-Sébastien Coron and Jesper Buus Nielsen, editors, Advances in Cryptology - EUROCRYPT 2017 - 36th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Paris, France, April 30 - May 4, 2017, Proceedings, Part II, volume 10211 of Lecture Notes in Computer Science, pages 643–673, 2017.</li>

      <li>[25] Saad Quader and Alexander Russell. C++ source code to compute settlement error estimates. https://github.com/saad0105050/forkable-strings-code, 2018. Accessed: 2019-10-14.</li>

      <li>[26] Herbert S Wilf. generatingfunctionology. AK Peters/CRC Press, 3 edition, 2005.</li>

    </ul>

    <h2 id="sec-107" class="text-2xl font-bold">Appendix A Exact settlement probabilities</h2>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let <span class="math">m,k\\in\\mathbb{N}</span> and <span class="math">\\varepsilon\\in(0,1]</span>. Let <span class="math">w</span> be a characteristic string of length <span class="math">T=m+k</span> such that the bits of <span class="math">w</span> are i.i.d. Bernoulli with expectation <span class="math">\\alpha=(1-\\varepsilon)/2</span>. Write <span class="math">w</span> as <span class="math">w=xy</span> where $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=m,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=k<span class="math">. The recursive definition of relative margin (cf. Lemma 3) implies an algorithm for computing the probability </span>\\Pr[\\mu_{x}(y)\\geq 0]<span class="math"> in time </span>\\mathrm{poly}(m,k)<span class="math">. In typical circumstances, however, it is more interesting to establish an explicit upper bound on </span>\\Pr[\\mu_{x}(y)\\geq 0]<span class="math"> where </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\to\\infty<span class="math">; this corresponds to the case where the distribution of the initial reach </span>\\rho(x)<span class="math"> is the dominant distribution </span>\\mathcal{R}_{\\infty}<span class="math"> in Lemma 4. Due to dominance, </span>\\mathcal{R}_{\\infty}(m)<span class="math"> serves as an upper bound on </span>\\rho(x)<span class="math"> for any finite </span>m=</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">. For this purpose, one can implicitly maintain a sequence of matrices </span>(M_{t})<span class="math"> for </span>t=0,1,2,\\cdots,k<span class="math"> such that </span>M_{0}(r,r)=\\mathcal{R}_{\\infty}(r)<span class="math"> for all </span>0\\leq r\\leq 2k$ and the invariant</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">M_{t}(r,s)=\\Pr_{y\\sim\\mathcal{B}(t,\\alpha)}[\\rho(xy)=r\\text{ and }\\mu_{x}(y)=s]</span></p>

    <p class="text-gray-300">is satisfied for every integer <span class="math">t\\in[1,k],r\\in[0,2k]</span>, and <span class="math">s\\in[-2k,2k]</span>. Here, <span class="math">M(i,j)</span> denotes the entry at the <span class="math">i</span>th row and <span class="math">j</span>th column of the matrix <span class="math">M</span>. Observe that <span class="math">M_{t}(r,s)</span> can be computed solely from the neighboring cells of <span class="math">M_{t-1}</span>, that is, from the values <span class="math">M_{t-1}(r\\pm 1,s\\pm 1)</span>. Of course, only the transitions approved by the recursions in Lemma 2 and Lemma 3 should be considered.</p>

    <p class="text-gray-300">Finally, one can compute <span class="math">\\Pr[\\mu_{x}(y)\\geq 0]</span> by summing <span class="math">M_{k}(r,s)</span> for <span class="math">r,s\\geq 0</span>. Table 1 contains these probabilities where <span class="math">\\alpha</span> ranges from 0.05 to 0.40 and <span class="math">k</span> ranges from 50 to 1000. In addition, Figure 5 shows the base-10 logarithm of these probabilities. The points corresponding to a fixed <span class="math">\\alpha</span> appear to form a straight line. This means the probability decays exponentially in <span class="math">k</span>, or equivalently, that the exponent depends linearly on <span class="math">k</span>, as stipulated by Bound 1.</p>

    <p class="text-gray-300">A C++ implementation of the above algorithm is publicly available at https://github.com/saad0105050/forkable-strings-code <em>[25]</em>.</p>

    <h2 id="sec-108" class="text-2xl font-bold">Appendix</h2>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Table 1: Exact probabilities  <span class="math">\\operatorname{Pr}[\\mu_x(y) \\geq 0]</span>  where the bits of the characteristic string  <span class="math">xy</span>  are i.i.d. Bernoulli with expectation  <span class="math">\\alpha</span> . Each row of the table corresponds to a different  $k =</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">k</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">α</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">0.05</td>

            <td class="px-3 py-2 border-b border-gray-700">0.10</td>

            <td class="px-3 py-2 border-b border-gray-700">0.15</td>

            <td class="px-3 py-2 border-b border-gray-700">0.20</td>

            <td class="px-3 py-2 border-b border-gray-700">0.25</td>

            <td class="px-3 py-2 border-b border-gray-700">0.30</td>

            <td class="px-3 py-2 border-b border-gray-700">0.35</td>

            <td class="px-3 py-2 border-b border-gray-700">0.40</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">50</td>

            <td class="px-3 py-2 border-b border-gray-700">5.37E-15</td>

            <td class="px-3 py-2 border-b border-gray-700">1.16E-09</td>

            <td class="px-3 py-2 border-b border-gray-700">1.02E-06</td>

            <td class="px-3 py-2 border-b border-gray-700">8.68E-05</td>

            <td class="px-3 py-2 border-b border-gray-700">1.96E-03</td>

            <td class="px-3 py-2 border-b border-gray-700">1.86E-02</td>

            <td class="px-3 py-2 border-b border-gray-700">9.36E-02</td>

            <td class="px-3 py-2 border-b border-gray-700">2.92E-01</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">100</td>

            <td class="px-3 py-2 border-b border-gray-700">1.23E-28</td>

            <td class="px-3 py-2 border-b border-gray-700">5.10E-18</td>

            <td class="px-3 py-2 border-b border-gray-700">3.52E-12</td>

            <td class="px-3 py-2 border-b border-gray-700">2.28E-08</td>

            <td class="px-3 py-2 border-b border-gray-700">1.03E-05</td>

            <td class="px-3 py-2 border-b border-gray-700">8.00E-04</td>

            <td class="px-3 py-2 border-b border-gray-700">1.72E-02</td>

            <td class="px-3 py-2 border-b border-gray-700">1.37E-01</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">150</td>

            <td class="px-3 py-2 border-b border-gray-700">2.83E-42</td>

            <td class="px-3 py-2 border-b border-gray-700">2.24E-26</td>

            <td class="px-3 py-2 border-b border-gray-700">1.22E-17</td>

            <td class="px-3 py-2 border-b border-gray-700">6.05E-12</td>

            <td class="px-3 py-2 border-b border-gray-700">5.54E-08</td>

            <td class="px-3 py-2 border-b border-gray-700">3.57E-05</td>

            <td class="px-3 py-2 border-b border-gray-700">3.30E-03</td>

            <td class="px-3 py-2 border-b border-gray-700">6.74E-02</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">200</td>

            <td class="px-3 py-2 border-b border-gray-700">6.49E-56</td>

            <td class="px-3 py-2 border-b border-gray-700">9.82E-35</td>

            <td class="px-3 py-2 border-b border-gray-700">4.21E-23</td>

            <td class="px-3 py-2 border-b border-gray-700">1.61E-15</td>

            <td class="px-3 py-2 border-b border-gray-700">2.98E-10</td>

            <td class="px-3 py-2 border-b border-gray-700">1.60E-06</td>

            <td class="px-3 py-2 border-b border-gray-700">6.40E-04</td>

            <td class="px-3 py-2 border-b border-gray-700">3.36E-02</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">250</td>

            <td class="px-3 py-2 border-b border-gray-700">1.49E-69</td>

            <td class="px-3 py-2 border-b border-gray-700">4.31E-43</td>

            <td class="px-3 py-2 border-b border-gray-700">1.46E-28</td>

            <td class="px-3 py-2 border-b border-gray-700">4.27E-19</td>

            <td class="px-3 py-2 border-b border-gray-700">1.61E-12</td>

            <td class="px-3 py-2 border-b border-gray-700">7.21E-08</td>

            <td class="px-3 py-2 border-b border-gray-700">1.25E-04</td>

            <td class="px-3 py-2 border-b border-gray-700">1.69E-02</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">300</td>

            <td class="px-3 py-2 border-b border-gray-700">3.42E-83</td>

            <td class="px-3 py-2 border-b border-gray-700">1.89E-51</td>

            <td class="px-3 py-2 border-b border-gray-700">5.05E-34</td>

            <td class="px-3 py-2 border-b border-gray-700">1.14E-22</td>

            <td class="px-3 py-2 border-b border-gray-700">8.67E-15</td>

            <td class="px-3 py-2 border-b border-gray-700">3.25E-09</td>

            <td class="px-3 py-2 border-b border-gray-700">2.44E-05</td>

            <td class="px-3 py-2 border-b border-gray-700">8.52E-03</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">350</td>

            <td class="px-3 py-2 border-b border-gray-700">7.84E-97</td>

            <td class="px-3 py-2 border-b border-gray-700">8.29E-60</td>

            <td class="px-3 py-2 border-b border-gray-700">1.75E-39</td>

            <td class="px-3 py-2 border-b border-gray-700">3.02E-26</td>

            <td class="px-3 py-2 border-b border-gray-700">4.67E-17</td>

            <td class="px-3 py-2 border-b border-gray-700">1.46E-10</td>

            <td class="px-3 py-2 border-b border-gray-700">4.78E-06</td>

            <td class="px-3 py-2 border-b border-gray-700">4.31E-03</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">400</td>

            <td class="px-3 py-2 border-b border-gray-700">1.80E-110</td>

            <td class="px-3 py-2 border-b border-gray-700">3.64E-68</td>

            <td class="px-3 py-2 border-b border-gray-700">6.06E-45</td>

            <td class="px-3 py-2 border-b border-gray-700">8.02E-30</td>

            <td class="px-3 py-2 border-b border-gray-700">2.52E-19</td>

            <td class="px-3 py-2 border-b border-gray-700">6.59E-12</td>

            <td class="px-3 py-2 border-b border-gray-700">9.37E-07</td>

            <td class="px-3 py-2 border-b border-gray-700">2.18E-03</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">450</td>

            <td class="px-3 py-2 border-b border-gray-700">4.13E-124</td>

            <td class="px-3 py-2 border-b border-gray-700">1.60E-76</td>

            <td class="px-3 py-2 border-b border-gray-700">2.10E-50</td>

            <td class="px-3 py-2 border-b border-gray-700">2.13E-33</td>

            <td class="px-3 py-2 border-b border-gray-700">1.36E-21</td>

            <td class="px-3 py-2 border-b border-gray-700">2.97E-13</td>

            <td class="px-3 py-2 border-b border-gray-700">1.84E-07</td>

            <td class="px-3 py-2 border-b border-gray-700">1.11E-03</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">500</td>

            <td class="px-3 py-2 border-b border-gray-700">9.47E-138</td>

            <td class="px-3 py-2 border-b border-gray-700">7.00E-85</td>

            <td class="px-3 py-2 border-b border-gray-700">7.26E-56</td>

            <td class="px-3 py-2 border-b border-gray-700">5.67E-37</td>

            <td class="px-3 py-2 border-b border-gray-700">7.32E-24</td>

            <td class="px-3 py-2 border-b border-gray-700">1.34E-14</td>

            <td class="px-3 py-2 border-b border-gray-700">3.60E-08</td>

            <td class="px-3 py-2 border-b border-gray-700">5.62E-04</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">550</td>

            <td class="px-3 py-2 border-b border-gray-700">2.17E-151</td>

            <td class="px-3 py-2 border-b border-gray-700">3.07E-93</td>

            <td class="px-3 py-2 border-b border-gray-700">2.51E-61</td>

            <td class="px-3 py-2 border-b border-gray-700">1.51E-40</td>

            <td class="px-3 py-2 border-b border-gray-700">3.95E-26</td>

            <td class="px-3 py-2 border-b border-gray-700">6.02E-16</td>

            <td class="px-3 py-2 border-b border-gray-700">7.05E-09</td>

            <td class="px-3 py-2 border-b border-gray-700">2.86E-04</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">600</td>

            <td class="px-3 py-2 border-b border-gray-700">4.98E-165</td>

            <td class="px-3 py-2 border-b border-gray-700">1.35E-101</td>

            <td class="px-3 py-2 border-b border-gray-700">8.70E-67</td>

            <td class="px-3 py-2 border-b border-gray-700">4.00E-44</td>

            <td class="px-3 py-2 border-b border-gray-700">2.13E-28</td>

            <td class="px-3 py-2 border-b border-gray-700">2.71E-17</td>

            <td class="px-3 py-2 border-b border-gray-700">1.38E-09</td>

            <td class="px-3 py-2 border-b border-gray-700">1.45E-04</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">650</td>

            <td class="px-3 py-2 border-b border-gray-700">1.14E-178</td>

            <td class="px-3 py-2 border-b border-gray-700">5.91E-110</td>

            <td class="px-3 py-2 border-b border-gray-700">3.01E-72</td>

            <td class="px-3 py-2 border-b border-gray-700">1.06E-47</td>

            <td class="px-3 py-2 border-b border-gray-700">1.15E-30</td>

            <td class="px-3 py-2 border-b border-gray-700">1.22E-18</td>

            <td class="px-3 py-2 border-b border-gray-700">2.71E-10</td>

            <td class="px-3 py-2 border-b border-gray-700">7.37E-05</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">700</td>

            <td class="px-3 py-2 border-b border-gray-700">2.62E-192</td>

            <td class="px-3 py-2 border-b border-gray-700">2.59E-118</td>

            <td class="px-3 py-2 border-b border-gray-700">1.04E-77</td>

            <td class="px-3 py-2 border-b border-gray-700">2.83E-51</td>

            <td class="px-3 py-2 border-b border-gray-700">6.19E-33</td>

            <td class="px-3 py-2 border-b border-gray-700">5.51E-20</td>

            <td class="px-3 py-2 border-b border-gray-700">5.31E-11</td>

            <td class="px-3 py-2 border-b border-gray-700">3.75E-05</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">750</td>

            <td class="px-3 py-2 border-b border-gray-700">6.02E-206</td>

            <td class="px-3 py-2 border-b border-gray-700">1.14E-126</td>

            <td class="px-3 py-2 border-b border-gray-700">3.61E-83</td>

            <td class="px-3 py-2 border-b border-gray-700">7.52E-55</td>

            <td class="px-3 py-2 border-b border-gray-700">3.33E-35</td>

            <td class="px-3 py-2 border-b border-gray-700">2.48E-21</td>

            <td class="px-3 py-2 border-b border-gray-700">1.04E-11</td>

            <td class="px-3 py-2 border-b border-gray-700">1.91E-05</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">800</td>

            <td class="px-3 py-2 border-b border-gray-700">1.38E-219</td>

            <td class="px-3 py-2 border-b border-gray-700">4.99E-135</td>

            <td class="px-3 py-2 border-b border-gray-700">1.25E-88</td>

            <td class="px-3 py-2 border-b border-gray-700">2.00E-58</td>

            <td class="px-3 py-2 border-b border-gray-700">1.80E-37</td>

            <td class="px-3 py-2 border-b border-gray-700">1.12E-22</td>

            <td class="px-3 py-2 border-b border-gray-700">2.04E-12</td>

            <td class="px-3 py-2 border-b border-gray-700">9.69E-06</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">850</td>

            <td class="px-3 py-2 border-b border-gray-700">3.17E-233</td>

            <td class="px-3 py-2 border-b border-gray-700">2.19E-143</td>

            <td class="px-3 py-2 border-b border-gray-700">4.33E-94</td>

            <td class="px-3 py-2 border-b border-gray-700">5.31E-62</td>

            <td class="px-3 py-2 border-b border-gray-700">9.69E-40</td>

            <td class="px-3 py-2 border-b border-gray-700">5.04E-24</td>

            <td class="px-3 py-2 border-b border-gray-700">4.00E-13</td>

            <td class="px-3 py-2 border-b border-gray-700">4.93E-06</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">900</td>

            <td class="px-3 py-2 border-b border-gray-700">7.27E-247</td>

            <td class="px-3 py-2 border-b border-gray-700">9.61E-152</td>

            <td class="px-3 py-2 border-b border-gray-700">1.50E-99</td>

            <td class="px-3 py-2 border-b border-gray-700">1.41E-65</td>

            <td class="px-3 py-2 border-b border-gray-700">5.23E-42</td>

            <td class="px-3 py-2 border-b border-gray-700">2.27E-25</td>

            <td class="px-3 py-2 border-b border-gray-700">7.84E-14</td>

            <td class="px-3 py-2 border-b border-gray-700">2.50E-06</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">950</td>

            <td class="px-3 py-2 border-b border-gray-700">1.67E-260</td>

            <td class="px-3 py-2 border-b border-gray-700">4.22E-160</td>

            <td class="px-3 py-2 border-b border-gray-700">5.19E-105</td>

            <td class="px-3 py-2 border-b border-gray-700">3.75E-69</td>

            <td class="px-3 py-2 border-b border-gray-700">2.82E-44</td>

            <td class="px-3 py-2 border-b border-gray-700">1.02E-26</td>

            <td class="px-3 py-2 border-b border-gray-700">1.54E-14</td>

            <td class="px-3 py-2 border-b border-gray-700">1.27E-06</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">1000</td>

            <td class="px-3 py-2 border-b border-gray-700">3.83E-274</td>

            <td class="px-3 py-2 border-b border-gray-700">1.85E-168</td>

            <td class="px-3 py-2 border-b border-gray-700">1.80E-110</td>

            <td class="px-3 py-2 border-b border-gray-700">9.98E-73</td>

            <td class="px-3 py-2 border-b border-gray-700">1.52E-46</td>

            <td class="px-3 py-2 border-b border-gray-700">4.61E-28</td>

            <td class="px-3 py-2 border-b border-gray-700">3.01E-15</td>

            <td class="px-3 py-2 border-b border-gray-700">6.48E-07</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">!<a href="img-3.jpeg">img-3.jpeg</a> Figure 5: The probabilities from Table 1 drawn in the base-10 logarithmic scale.</p>

    <p class="text-gray-300">Below we present a bound (Bound 3) on the probability that a characteristic string satisfying the  <span class="math">\\epsilon</span> -martingale condition has a non-negative relative margin. We remark that the bound below is weaker than Bound 2. Before</p>

    <p class="text-gray-300">we proceed, recall the following standard large deviation bound for supermartingales.</p>

    <h6 id="sec-110" class="text-base font-medium mt-4">Theorem 6 (Azuma’s inequality (Azuma; Hoeffding).</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">See <em>[17, 4.16]</em> for a discussion). Let <span class="math">X_{0},...\\,,X_{n}</span> be a sequence of real-valued random variables so that, for all <span class="math">t</span>, <span class="math">\\mathbb{E}[X_{t+1}\\mid X_{0},...\\,,X_{t}]\\leq X_{t}</span> and $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">X_{t+1}-X_{t}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq c<span class="math"> for some constant </span>c<span class="math">. Then </span>\\Pr[X_{n}-X_{0}\\geq\\Lambda]\\leq\\exp\\left(-\\Lambda^{2}/2nc^{2}\\right)<span class="math"> for every </span>\\Lambda\\geq 0$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-111" class="text-base font-medium mt-4">Bound 3.</h6>

    <p class="text-gray-300">Let <span class="math">x\\in\\{0,1\\}^{m}</span> and <span class="math">y\\in\\{0,1\\}^{k}</span> be random variables, satisfying the <span class="math">\\varepsilon</span>-martingale condition (with respect to the ordering <span class="math">x_{1},...\\,,x_{m},y_{1},...\\,,y_{k}</span>). Then</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mu_{x}(y)\\geq 0]\\leq 3\\exp\\left(-\\varepsilon^{4}(1-O(\\varepsilon))k/64\\right)\\,.</span></p>

    <h6 id="sec-112" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Let <span class="math">w_{1},w_{2},...</span> be random variables obeying the <span class="math">\\varepsilon</span>-martingale condition. Specifically, <span class="math">\\Pr[w_{t}=1\\mid E]\\leq(1-\\varepsilon)/2</span> conditioned on any event <span class="math">E</span> expressed in the variables <span class="math">w_{1},...\\,,w_{t-1}</span>. For convenience, define the associated <span class="math">\\{\\pm 1\\}</span>-valued random variables <span class="math">W_{t}=(-1)^{1+w_{t}}</span> and observe that <span class="math">\\mathbb{E}[W_{t}]\\leq-\\varepsilon</span>.</p>

    <h4 id="sec-113" class="text-lg font-semibold mt-6">If <span class="math">x</span> is empty.</h4>

    <p class="text-gray-300">Observe that in this case, the relative margin <span class="math">\\mu_{x}(y)</span> reduces to the non-relative margin <span class="math">\\mu(y)</span> from Lemma 2. Since the sequence <span class="math">y_{1},y_{2},...</span> in the statement of the claim is identical to the sequence <span class="math">w_{1},w_{2},...</span> defined above, we focus on the reach and margin of the latter sequence. Specifically, define <span class="math">\\rho_{t}=\\rho(w_{1}\\&gt;...\\&gt;w_{t})</span> and <span class="math">\\mu_{t}=\\mu(w_{1}\\&gt;...\\&gt;w_{t})</span> to be the two random variables from Lemma 2 acting on the string <span class="math">w=w_{1}\\&gt;...\\&gt;w_{t}</span>. The analysis will rely on the ancillary random variables <span class="math">\\overline{\\mu}_{t}=\\min(0,\\mu_{t})</span>. Observe that <span class="math">\\Pr[w\\text{ forkable}]=\\Pr[\\mu(w)\\geq 0]=\\Pr[\\overline{\\mu}_{k}=0]</span>, so we may focus on the event that <span class="math">\\overline{\\mu}_{k}=0</span>. As an additional preparatory step, define the constant <span class="math">\\alpha=(1+\\varepsilon)/(2\\varepsilon)\\geq 1</span> and define the random variables <span class="math">\\Phi_{t}\\in\\mathbb{R}</span> by the inner product</p>

    <p class="text-gray-300">\\[ \\Phi_{t}=(\\rho_{t},\\overline{\\mu}_{t})\\cdot\\left(\\begin{array}[]{c}1\\\\ \\alpha\\end{array}\\right)=\\rho_{t}+\\alpha\\overline{\\mu}_{t}\\,. \\]</p>

    <p class="text-gray-300">The <span class="math">\\Phi_{t}</span> will act as a “potential function” in the analysis: we will establish that <span class="math">\\Phi_{k}&lt;0</span> with high probability and, considering that <span class="math">\\alpha\\overline{\\mu}_{k}\\leq\\rho_{k}+\\alpha\\overline{\\mu}_{k}=\\Phi_{k}</span>, this implies <span class="math">\\overline{\\mu}_{k}&lt;0</span>, as desired.</p>

    <p class="text-gray-300">Let <span class="math">\\Delta_{t}=\\Phi_{t}-\\Phi_{t-1}</span>; we claim that—conditioned on any fixed value <span class="math">(\\rho,\\mu)</span> for <span class="math">(\\rho_{t},\\mu_{t})</span>—the random variable <span class="math">\\Delta_{t+1}\\in[-(1+\\alpha),1+\\alpha]</span> has expectation no more than <span class="math">-\\varepsilon</span>. The analysis has four cases, depending on the various regimes of <span class="math">\\rho</span> and <span class="math">\\mu</span> from Lemma 2. When <span class="math">\\rho&gt;0</span> and <span class="math">\\mu&lt;0</span>, <span class="math">\\rho_{t+1}=\\rho+W_{t+1}</span> and <span class="math">\\overline{\\mu}_{t+1}=\\overline{\\mu}+W_{t+1}</span>, where <span class="math">\\overline{\\mu}=\\max(0,\\mu)</span>; then <span class="math">\\Delta_{t+1}=(1+\\alpha)W_{t+1}</span> and <span class="math">\\mathbb{E}[\\Delta_{t+1}]\\leq-(1+\\alpha)\\varepsilon\\leq-\\varepsilon</span>. When <span class="math">\\rho&gt;0</span> and <span class="math">\\mu\\geq 0</span>, <span class="math">\\rho_{t+1}=\\rho+W_{t+1}</span> but <span class="math">\\overline{\\mu}_{t+1}=\\overline{\\mu}</span> so that <span class="math">\\Delta_{t+1}=W_{t+1}</span> and <span class="math">\\mathbb{E}[\\Delta_{t+1}]\\leq-\\varepsilon</span>. Similarly, when <span class="math">\\rho=0</span> and <span class="math">\\mu&lt;0</span>, <span class="math">\\overline{\\mu}_{t+1}=\\overline{\\mu}+W_{t+1}</span> while <span class="math">\\rho_{t+1}=\\rho+\\max(0,W_{t+1})</span>; we may compute</p>

    <p class="text-gray-300"><span class="math">\\mathbb{E}[\\Delta_{t+1}]\\leq\\frac{1-\\varepsilon}{2}(1+\\alpha)-\\frac{1+\\varepsilon}{2}\\alpha=\\frac{1-\\varepsilon}{2}-\\varepsilon\\alpha=\\frac{1-\\varepsilon}{2}-\\varepsilon\\left(\\frac{1}{\\varepsilon}\\cdot\\frac{1+\\varepsilon}{2}\\right)=-\\varepsilon\\,.</span></p>

    <p class="text-gray-300">Finally, when <span class="math">\\rho=\\mu=0</span> exactly one of the two random variables <span class="math">\\rho_{t+1}</span> and <span class="math">\\overline{\\mu}_{t+1}</span> differs from zero: if <span class="math">W_{t+1}=1</span> then <span class="math">(\\rho_{t+1},\\overline{\\mu}_{t+1})=(1,0)</span>; likewise, if <span class="math">W_{t+1}=-1</span> then <span class="math">(\\rho_{t+1},\\overline{\\mu}_{t+1})=(0,-1)</span>. It follows that</p>

    <p class="text-gray-300"><span class="math">\\mathbb{E}[\\Delta_{t+1}]\\leq\\frac{1-\\varepsilon}{2}-\\frac{1+\\varepsilon}{2}\\alpha\\leq-\\varepsilon\\,.</span></p>

    <p class="text-gray-300">Thus <span class="math">\\mathbb{E}[\\Phi_{k}]=\\mathbb{E}\\sum_{t=1}^{k}\\Delta_{t}\\leq-\\varepsilon k</span>. We wish to apply Azuma’s inequality to conclude that <span class="math">\\Pr[\\Phi_{k}\\geq 0]</span> is exponentially small. For this purpose, we transform the random variables <span class="math">\\Phi_{t}</span> to a related supermartingale by shifting them: specifically, define <span class="math">\\bar{\\Phi}_{t}=\\Phi_{t}+\\varepsilon t</span> and <span class="math">\\bar{\\Delta}_{t}=\\Delta_{t}+\\varepsilon</span> so that <span class="math">\\bar{\\Phi}_{t}=\\sum_{i}^{t}\\bar{\\Delta}_{t}</span>. Then</p>

    <p class="text-gray-300"><span class="math">\\mathbb{E}[\\bar{\\Phi}_{t+1}\\mid\\bar{\\Phi}_{1},...\\,,\\bar{\\Phi}_{t}]=\\mathbb{E}[\\bar{\\Phi}_{t+1}\\mid W_{1},...\\,,W_{t}]\\leq\\bar{\\Phi}_{t}\\,,\\qquad\\bar{\\Delta}_{t}\\in[-(1+\\alpha)+\\varepsilon,1+\\alpha+\\varepsilon]\\,,</span></p>

    <p class="text-gray-300">where</p>

    <p class="text-gray-300">and <span class="math">\\tilde{\\Phi}_k = \\Phi_k + \\varepsilon k</span>. It follows from Azuma's inequality that</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} \\operatorname{Pr}[w \\text{ for k a b l e}] &amp;amp;= \\operatorname{Pr}[\\widetilde{\\mu}_k = 0] \\leq \\operatorname{Pr}[\\Phi_k \\geq 0] = \\operatorname{Pr}[\\tilde{\\Phi}_k \\geq \\varepsilon k] \\\\ &amp;amp;\\leq \\exp\\left(-\\frac{\\varepsilon^2 k^2}{2k(1 + \\alpha + \\varepsilon)^2}\\right) = \\exp\\left(-\\left(\\frac{2\\varepsilon^2}{1 + 3\\varepsilon + 2\\varepsilon^2}\\right)^2 \\cdot \\frac{k}{2}\\right) \\\\ &amp;amp;\\leq \\exp\\left(-\\frac{2\\varepsilon^4}{1 + 35\\varepsilon} \\cdot k\\right). \\end{aligned} \\tag{20}</span></div>

    <p class="text-gray-300">If <span class="math">x</span> is not empty. In this case, we go back to study the sequences <span class="math">x</span> and <span class="math">y</span> as in the statement of the claim. Recall the reach distribution (i.e., the distribution of the random variable <span class="math">\\rho(x)</span>) <span class="math">\\mathcal{R}_m: \\mathbb{Z} \\to [0,1]</span> from (18). Since <span class="math">x = (x_1, \\ldots, x_m)</span> satisfies the <span class="math">\\varepsilon</span>-martingale condition, Lemma 4 states that <span class="math">\\mathcal{R}_m \\preceq \\mathcal{R}_\\infty</span>. We reserve the symbol <span class="math">\\mu_x^{(r)}</span> for the relative margin random walk <span class="math">\\mu_x</span> which starts at a non-negative initial position <span class="math">r</span>. Thus <span class="math">\\rho(x) = \\mu_x(\\varepsilon) = r</span>, and</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname{Pr}\\left[\\mu_x(y) \\geq 0\\right] = \\sum_{r \\geq 0} \\mathcal{R}_m(r) \\operatorname{Pr}\\left[\\mu_x^{(r)}(y) \\geq 0\\right] \\leq \\sum_{r \\geq 0} \\mathcal{R}_\\infty(r) \\operatorname{Pr}\\left[\\mu_x^{(r)}(y) \\geq 0\\right] \\tag{21}</span></div>

    <p class="text-gray-300">since the sequence <span class="math">(\\operatorname{Pr}[\\mu_x^{(r)}(y) \\geq 0])_{r=0}^{\\infty}</span> is non-decreasing and <span class="math">\\mathcal{R}_m \\preceq \\mathcal{R}_\\infty</span>. Fix a "large enough" positive integer <span class="math">r^*</span> whose value will be assigned later in the analysis. Let us define the following events:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Event <span class="math">\\mathsf{B}_r</span>: it occurs when <span class="math">r \\in [0, r^*]</span> and the <span class="math">\\mu_x^{(r)}</span> walk is strictly positive on every prefix of <span class="math">y</span> with length at most <span class="math">k/2</span>; and</li>

      <li>Event <span class="math">\\mathsf{C}_{r,s}</span>: it occurs when <span class="math">r \\in [0, r^*]</span> and <span class="math">\\hat{y}</span> is the smallest prefix of <span class="math">y</span> of length <span class="math">s \\in [r, k/2]</span> such that <span class="math">\\mu_x^{(r)}(\\hat{y}) = 0</span>. We say that <span class="math">\\hat{y}</span> is a witness to the event <span class="math">\\mathsf{C}_{r,s}</span>.</li>

    </ul>

    <p class="text-gray-300">The right-hand side of (21) can be written as</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} &amp;amp;\\sum_{r &amp;gt; r^*} \\mathcal{R}_\\infty(r) \\operatorname{Pr}\\left[\\mu_x^{(r)}(y) \\geq 0\\right] + \\sum_{r \\leq r^*} \\mathcal{R}_\\infty(r) \\operatorname{Pr}\\left[\\mathrm{B}_r\\right] \\cdot \\operatorname{Pr}\\left[\\mu_x^{(r)}(y) \\geq 0 \\mid \\mathrm{B}_r\\right] \\\\ &amp;amp;+ \\sum_{r \\leq r^*} \\mathcal{R}_\\infty(r) \\sum_{s = r}^{k/2} \\operatorname{Pr}\\left[\\mathrm{C}_{r,s}\\right] \\cdot \\operatorname{Pr}\\left[\\mu_x^{(r)}(y) \\geq 0 \\mid \\mathrm{C}_{r,s}\\right]. \\end{aligned}</span></div>

    <p class="text-gray-300">We observe that the probabilities <span class="math">\\operatorname{Pr}[\\mu_x^{(r)}(y) \\geq 0]</span> and <span class="math">\\operatorname{Pr}[\\mu_x^{(r)}(y) \\geq 0 \\mid \\mathsf{B}_r]</span> are at most one. In addition, recall that for two non-negative sequences <span class="math">(a_i), (b_i)</span> of equal lengths, we have <span class="math">\\sum a_i b_i \\leq \\max b_i</span> if <span class="math">\\sum a_i \\leq 1</span>. Thus (21) can be simplified as</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{aligned} \\operatorname{Pr}\\left[\\mu_x(y) \\geq 0\\right] &amp;amp;\\leq \\sum_{r &amp;gt; r^*} \\mathcal{R}_\\infty(r) + \\sum_{r \\leq r^*} \\mathcal{R}_\\infty(r) \\operatorname{Pr}\\left[\\mathrm{B}_r\\right] \\\\ &amp;amp;\\quad + \\sum_{r \\leq r^*} \\mathcal{R}_\\infty(r) \\max_{r \\leq s \\leq k/2} \\operatorname{Pr}\\left[\\mu_x^{(r)}(y) \\geq 0 \\mid \\mathrm{C}_{r,s}\\right] \\\\ &amp;amp;\\leq \\sum_{r &amp;gt; r^*} \\mathcal{R}_\\infty(r) + \\max_{r \\leq r^*} \\operatorname{Pr}\\left[\\mathrm{B}_r\\right] + \\max_{\\substack{r \\leq r^* \\\\ r \\leq s \\leq k/2}} \\operatorname{Pr}\\left[\\mu_x^{(r)}(y) \\geq 0 \\mid \\mathrm{C}_{r,s}\\right]. \\tag{22} \\end{aligned}</span></div>

    <p class="text-gray-300">The first term in (22) is the right-tail of the distribution <span class="math">\\mathcal{R}_\\infty</span>. Using Lemma 4, this quantity is at most <span class="math">\\beta^{r^*}</span> where <span class="math">\\beta := (1 - \\varepsilon)/(1 + \\varepsilon)</span>. Furthermore, it can be easily checked that the above quantity is at most <span class="math">\\exp(-5\\varepsilon/3)</span>.</p>

    <p class="text-gray-300">The second term in (22) concerns the event <span class="math">\\mathsf{B}_r</span> and calls for more care. Define</p>

    <div class="my-4 text-center"><span class="math-block">S_k^{(r)} := \\sum_{t = 0}^{k} W_t</span></div>

    <p class="text-gray-300">and the random variables <span class="math">W_{t}</span> are defined at the outset of this proof for <span class="math">t\\geq 1</span>. We know that the <span class="math">\\mu_{x}^{(r)}</span> walk starts with <span class="math">\\rho(x)=\\mu(x)=r\\geq 0</span>. Since <span class="math">\\mathsf{B}_{r}</span> holds, both the margin <span class="math">\\mu_{x}(\\hat{y})</span> and the reach <span class="math">\\rho(x\\hat{y})</span> remain non-negative for all prefixes <span class="math">\\hat{y}</span> of length <span class="math">t=1,2,\\cdots,k/2</span>. These two facts imply that the random variable <span class="math">\\mu_{x}^{(r)}(\\hat{y})</span> is identical to the sum <span class="math">S_{t}^{(r)}</span> for all prefixes <span class="math">\\hat{y}</span> of length <span class="math">t=1,2,\\cdots,k/2</span>.</p>

    <p class="text-gray-300">To be precise,</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mathsf{B}_{r}]=\\Pr[S_{t}^{(r)}\\geq 0\\quad\\text{for all }t\\leq k/2]\\,.</span></p>

    <p class="text-gray-300">The latter probability is at most <span class="math">\\Pr[S_{k/2}^{(r)}\\geq 0]</span> because the event <span class="math">S_{k/2}^{(r)}\\geq 0</span> does not constrain the intermediate sums <span class="math">S_{t}^{(r)}</span> for <span class="math">t&lt;k/2</span>. Since <span class="math">\\Pr[S_{k/2}^{(r)}\\geq 0]</span> increases monotonically in <span class="math">r</span>, we conclude that the second term in (22) is at most <span class="math">\\Pr[S_{k/2}^{(r^{*})}\\geq 0]</span>. Now we are free to shift our focus from the relative margin walk to the sum of a martingale sequence.</p>

    <p class="text-gray-300">For notational clarity, let us write <span class="math">S:=S_{k/2}^{(r^{<em>})}</span>. Since the sequence <span class="math">(w_{t})</span> obeys the <span class="math">\\varepsilon</span>-martingale condition, <span class="math">\\mathbb{E}\\,S</span> is at most <span class="math">M:=r^{</em>}-k\\varepsilon/2</span>. Let us set <span class="math">r^{*}=W_{0}=k\\varepsilon/4</span>. Then <span class="math">\\mathbb{E}\\,S</span> is at most <span class="math">-k\\varepsilon/4</span> and Azuma’s inequality gives us</p>

    <p class="text-gray-300"><span class="math">\\Pr[S\\geq 0]=\\Pr[(S-\\mathbb{E}\\,S)\\geq k\\varepsilon/4]\\leq\\exp\\left(-\\frac{(k\\varepsilon/4)^{2}}{2(k/2)\\cdot 2^{2}}\\right)=\\exp\\left(-\\frac{k\\varepsilon^{2}}{64}\\right)\\,.</span></p>

    <p class="text-gray-300">This is an upper bound on the second term in (22).</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><em>The third term in (22)</em> concerns the event <span class="math">\\mathsf{C}_{r,s}</span> and it can be bounded using our existing analysis of the $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=0<span class="math"> case. Specifically, suppose </span>y=\\hat{y}z<span class="math"> where </span>\\hat{y}<span class="math"> is a witness to the event </span>\\mathsf{C}_{r,s}<span class="math">. Since the </span>\\mu_{x}^{(r)}<span class="math"> walk remains non-negative over the entire string </span>\\hat{y}<span class="math">, it follows that </span>\\rho(x\\hat{y})=\\mu(x\\hat{y})=0<span class="math"> and as a consequence, the </span>\\mu_{x\\hat{y}}<span class="math"> walk on </span>z<span class="math"> is identical to the </span>\\mu<span class="math"> walk on </span>z<span class="math">. Our analysis in the </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=0<span class="math"> case suggests that </span>\\Pr[\\mu(z)\\geq 0]<span class="math"> is at most </span>A(k-s,\\varepsilon)<span class="math"> where </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=k-s<span class="math"> and </span>A(k,\\varepsilon)<span class="math"> is the bound in (20). Since </span>A(\\cdot,\\varepsilon)<span class="math"> decreases monotonically in the first argument, </span>A(k-s,\\varepsilon)<span class="math"> is at most </span>A(k/2,\\varepsilon)<span class="math">. However, since the last quantity is independent of </span>r<span class="math">, the third term in (22) is at most </span>A(k/2,\\varepsilon)=\\exp\\left(-k\\varepsilon^{4}/(1+35\\varepsilon)\\right)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Returning to (22) and using <span class="math">r^{*}=k\\varepsilon/4</span>, we get</p>

    <p class="text-gray-300"><span class="math">\\Pr[\\mu_{x}(y)\\geq 0]\\leq\\exp\\left(-\\frac{5\\varepsilon}{3}\\cdot\\frac{k\\varepsilon}{4}\\right)+\\exp\\left(-\\frac{2\\varepsilon^{4}}{1+35\\varepsilon}\\cdot\\frac{n}{2}\\right)+\\exp\\left(-\\frac{k\\varepsilon^{2}}{64}\\right)\\,.</span></p>

    <p class="text-gray-300">It is easy to check that the above quantity is at most <span class="math">3\\exp\\left(-k\\varepsilon^{4}/(64+35\\varepsilon)\\right)=3\\exp\\left(-\\varepsilon^{4}(1-O(\\varepsilon))k/64\\right)</span>.</p>

    <p class="text-gray-300">∎</p>

    <p class="text-gray-300">##</p>`;
---

<BaseLayout title="Linear Consistency for Proof-of-Stake Blockchains (2017/241)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2017 &middot; eprint 2017/241
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
