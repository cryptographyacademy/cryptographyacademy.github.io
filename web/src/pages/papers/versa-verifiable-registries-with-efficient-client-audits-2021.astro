---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2021/627';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'VeRSA: Verifiable Registries with Efficient Client Audits from RSA Authenticated Dictionaries';
const AUTHORS_HTML = 'Nirvan Tyagi, Ben Fisch, Andrew Zitek-Estrada, Joseph Bonneau, Stefano Tessaro';

const CONTENT = `    <p class="text-gray-300">1</p>

    <p class="text-gray-300">Nirvan Tyagi Cornell University</p>

    <p class="text-gray-300">Ben Fisch Yale University</p>

    <p class="text-gray-300">Andrew Zitek-Estrada New York University</p>

    <p class="text-gray-300">Joseph Bonneau New York University</p>

    <p class="text-gray-300">Stefano Tessaro University of Washington</p>

    <p class="text-gray-300">Abstract. Verifiable registries allow clients to securely access a key-value mapping maintained by an untrusted server. Registries must be audited to ensure global invariants are preserved, which, in turn, allows for efficient monitoring of individual registry entries by their owners. To this end, existing proposals either assume trusted third-party auditors or rely on incrementally verifiable computation (IVC) via expensive recursive SNARKs to make registries client-auditable.</p>

    <p class="text-gray-300">In this work, we give new client-auditable verifiable registries that achieve throughputs up to <span class="math">100 \\times</span> greater than baseline IVC solutions. Our approach relies on an authenticated dictionary based on RSA accumulators for which we develop a new constant-size invariant proof. We use this as a replacement for Merkle trees to optimize the baseline IVC approach, but also provide a novel construction which dispenses with SNARKs entirely. This latter solution adopts a new checkpointing method to ensure client view consistency.</p>

    <p class="text-gray-300">1 Introduction 2 2 Setting and Threat Model 3 3 Preliminaries 5 4 Versioned Invariant Proofs for RSA Authenticated Dictionaries 6 5 Authenticated History Dictionaries 7 5.1 Syntax, Semantics, and Security 7 5.2 Towards a Generic Construction 8 5.3 AHDs from SNARK Recursion 9 5.4 AHDs from Amortized Proving 9 5.5 AHDs from Amortized SNARK Aggregation 10 6 Client Checkpoint Auditing 10 7 Implementation 12 8 Evaluation 13 8.1 Client Auditing Costs 14 8.2 Server Epoch Update Costs 14 8.3 Key Lookup Costs 15 9 Related Work 16 A Merkle Tree and Compact Range Preliminaries 20 B Open Addressing Optimization for Merkle Tree Update Circuit Representation 20 C Additional Definition Preliminaries 21 C.1 Additional RSA Preliminaries 21 C.2 Non-interactive Arguments of Knowledge 21 C.3 Authenticated Dictionaries 21 C.4 Append-only Vector Commitments 22 D Versioned Invariant Proofs and Batch Updates for RSA Authenticated Dictionary 22 D.1 RSA Authenticated Dictionary 22 D.2 Versioned Invariant Update Proofs and Strong Key Binding 22 E RSA Lookup Proof Computation 26 E.1 Promises 26 E.2 Batch Computation 26 E.3 Caching 27 E.4 Logarithmic Witness Verification 28 F Security of AHD Constructions 28 G Checkpoint Auditing Security 30 G.1 Security Definition 30 G.2 Proof of Shared Checkpoint Epoch 31 G.3 Proof of Checkpoint Auditing Eventual Detection 32 H An RSA Authenticated Dictionary with Append-Only Invariant Proofs 32 I AHDs from Groth16 SNARK Aggregation 34 I.1 Groth16 SNARK Aggregation 34 I.2 AHDs from Amortized Aggregation 36</p>

    <p class="text-gray-300">1 Introduction</p>

    <p class="text-gray-300">A number of systems have demonstrated the promise of transparency as a means to enhance security, most prominently the Certificate Transparency protocol first launched in 2013 <em>[x13, x10]</em>. The goal of transparency systems is to ensure that an authority’s behavior can be monitored by users. Typically, misbehavior by the authority is not prevented but is detectable. The implicit assumption is that large, public-facing authorities are potentially malicious (or compromised) but are cautious: they are unwilling or at least extremely hesitant to carry out any attack that will leave public evidence.</p>

    <p class="text-gray-300">Transparency has been proposed in a number of other security contexts, including user-public key mappings in encrypted communication systems <em>[x22, MBB^{+}15]</em>, usage of cryptographic keys <em>[x24]</em>, and distribution of software binaries <em>[FDP^{+}14, NKJ^{+}17, x1]</em>. Verifiable registries <em>[x6, MKL^{+}20]</em> are an abstraction capable of providing transparency for the key-value mappings required for all of these applications. Without such a transparency solution, the only defense against malicious behavior by the authority (or provider) is out-of-band cross-checking of the authority’s behavior (e.g. checking the fingerprints of downloaded public keys), an error-prone process which the vast majority of users neither understand nor attempt <em>[DSB^{+}16, TBB^{+}17, VWO^{+}17, ASB^{+}17]</em>.</p>

    <p class="text-gray-300">Client monitoring and auditing. Verifiable registries provide lookup proofs (or binding proofs) that prove the results of a lookup are consistent with the committed state of the registry at a particular epoch. These lookup proofs can be monitored by users to detect any unexpected changes. Typically there is no well-defined notion of correctness for a specific registry mapping as the authority is trusted to update mappings when needed (e.g. account recovery for a user who has lost their private key). Thus, monitoring is inherently a process specific to each mapping and/or user.</p>

    <p class="text-gray-300">By contrast, auditing is the process of ensuring that the entire registry is well-formed and maintains promised invariants across epochs. Unlike monitoring, auditing can be fully automated, with any violation by the provider producing unambiguous cryptographic proof of misbehavior. Early constructions propose clients directly perform audits in every epoch <em>[x13, x22, MBB^{+}15]</em>. As this approach incurs large overhead which is linear in the number of epochs, later proposals instead suggest outsourcing auditing of global registry invariants (such as update counts) to a third party. This enables clients to monitor their own key-value mapping at a lower frequency, with significant cost savings <em>[MBB^{+}15, x6, TBP^{+}19, HHK^{+}21]</em>.</p>

    <p class="text-gray-300">However, this assumes suitable trusted parties exist which can regularly perform expensive global audits. One could rely on the validation process underlying existing blockchain infrastructure (in particular, by implementing auditing in a smart contract <em>[x3]</em>), but this may result in large transaction fees. In this paper, we focus on solutions that rely on general-purpose, application agnostic, trusted infrastructure. In particular, we can instantiate our solutions assuming the existence of a trusted bulletin board, which can be shared with a number of different applications, and which will provide a consistent (or eventually consistent) mapping between an epoch number <span class="math">i</span> and a commitment <span class="math">d_{i}</span> to the state of the registry at epoch <span class="math">i</span>. Apart from this, our solutions will be client auditable, in that the client themselves verify global registry invariant proofs.</p>

    <p class="text-gray-300">The challenges of IVC-based client auditability. A natural starting point to build client-auditable verifiable registries is to use incrementally verifiable computation (IVC) <em>[x27]</em> via recursive proofs <em>[x2, x3]</em>, following e.g. <em>[x4]</em>. IVC enables the server to supply a commitment <span class="math">d_{i}</span> to the state of the registry at epoch <span class="math">i</span>, along with a succinct proof <span class="math">\\pi_{i}</span> that <span class="math">d_{i}</span> represents a state which evolved from a genesis state <span class="math">d_{0}</span> through a sequence of transitions which preserve the registry’s invariants. Clients can efficiently verify these invariant proofs on their own, without relying on dedicated third-party invariant auditors.</p>

    <p class="text-gray-300">However, IVC proofs are, by themselves, not sufficient.Two users may come online at different epochs <span class="math">i</span> and <span class="math">j</span> and receive invariant proofs <span class="math">\\pi_{i}</span> and <span class="math">\\pi_{j}</span>, along with commitments <span class="math">d_{i}</span> and <span class="math">d_{j}</span> to different states of the registry. An IVC proof attests to invariant preservation for updates across some sequence of intermediate states leading to the states represented by <span class="math">d_{i}</span> and <span class="math">d_{j}</span>, respectively, but without additional verification, there is no guarantee that the intermediate states attested to in <span class="math">\\pi_{i}</span> and <span class="math">\\pi_{j}</span> are consistent with each other. To ensure that this is the case, a bulletin board could store the commitments <span class="math">d_{1},d_{2},\\ldots</span>, along with a hash chain <span class="math">h_{0},h_{1},h_{2},\\ldots</span>, where <span class="math">h_{i}=H(h_{i-1},d_{i})</span> for some hash function <span class="math">H</span>. Third-party auditors are responsible for verifying hash chain consistency, and the IVC proof <span class="math">\\pi_{i}</span> would attest that <span class="math">h_{i}</span> commits to the unique hash sequence of valid registry states appearing on the bulletin board.</p>

    <p class="text-gray-300">In practice, hash chain verification is only slightly more expensive than maintaining a bulletin board. A more important obstacle with IVC solutions is that generating invariant proofs is computationally expensive. Merkle trees are the predominant data structure for implementing an authenticated dictionary (AD) in existing verifiable registries <em>[MBB^{+}15, x6, MKL^{+}20]</em>. Proving the invariant for a sequence of updates typically corresponds to verifying consistency of a sequence of Merkle paths. To achieve succinctness through IVC, the verification of Merkle paths is done within a succinct proof (in particular, a SNARK <em>[x11, x12]</em>). However encoding the Merkle path verification into a circuit representation suitable for SNARKs results in a large circuit and concretely expensive proving times, ultimately translating to a verifiable registry with low update throughput (<span class="math">&lt;5</span> key updates/second). In contrast, the Certificate Transparency ecosystem requires throughput of approximately <span class="math">60</span> key up</p>

    <p class="text-gray-300">ates per second <em>[x11]</em>.</p>

    <p class="text-gray-300">Our contributions. We aim to provide new verifiable registries which overcome the update throughput bottlenecks in IVC based solutions. Our new solutions will rely on the use of an RSA-based authenticated dictionary. Our main insight is a new cryptographic approach to produce succinct invariant proofs for large sequences of updates to an authenticated dictionary based on the KVaC key-value commitment construction from <em>[x1]</em>, opening up its use in the verifiable registry setting.</p>

    <p class="text-gray-300">We then use our new insights to provide two systems, which we refer to as VeRSA-IVC and VeRSA-Amtz. In VeRSA-IVC, we show how KVaC and our new succinct proof can be combined with IVC to allow the server to produce succinct invariant proofs for client auditability at much higher throughput (<span class="math">\\sim 10</span>-<span class="math">100\\times</span> greater) than applying IVC to Merkle tree-based registries: the invariant proofs for the RSA dictionary encode as a constant-size circuit regardless of the number of updates, as opposed to a circuit linear in the number of updates for Merkle tree dictionaries (i.e., a Merkle path for each update), resulting in faster SNARK proving times.</p>

    <p class="text-gray-300">Our second system, VeRSA-Amtz, provides instead a new amortized proving approach that dispenses with the need for IVC/SNARKs entirely, resulting in the first construction for efficient client auditability without IVC or generic SNARKs. We discuss in our related work section why prior solutions fall short of achieving this. Succinct invariant proofs for RSA authenticated dictionaries can be precomputed for carefully chosen sequences of updates over the lifetime of the registry in such a way that expensive computations for long sequences do not occur often, and any sequence of updates queried by a client can be served via a small number of precomputed invariant proofs for contiguous sequences. This alternate non-IVC approach enables even higher throughput in some deployment contexts.</p>

    <p class="text-gray-300">A novel challenge with VeRSA-Amtz is ensuring view consistency, as recursive SNARKs inherently gave us an easy solution via the use of hash chains. To this end, we introduce a new model of client-based auditing based on <em>checkpointing</em>. When a client comes online, they select a short (sublinear) sequence of checkpoint states between the current state and the state from when they were last online. The client can obtain a consistent view of the checkpoint digests thanks to the bulletin board, and then requests and verifies succinct proofs that the registry invariant is preserved between this sequence of checkpoints. Any two clients that individually perform these audits (over different checkpoint sequences) are guaranteed to have a consistent view up to their latest shared checkpoint; checkpoints are chosen so that two clients are guaranteed to have a shared checkpoint that is not too far behind their latest time online.</p>

    <p class="text-gray-300">Our new auditing model relaxes consistency guarantees from previous approaches by allowing clients to temporarily accept an inconsistent state: the inconsistency is detected when the shared checkpoint catches up. But on the other hand, it enables clients to maintain eventually consistent views without expensive linear work and without relying on recursive SNARKs.</p>

    <p class="text-gray-300">While our new proof techniques for RSA authenticated dictionaries allow for constructing client-auditable verifiable registries at high update throughput, computing lookup proofs for individual key-value mappings is more costly, naively requiring work linear in the size of the registry. We provide some deployment optimizations that help alleviate these costs with batching and caching, but ultimately this limitation means our RSA-based verifiable registries are better suited to transparency applications that need only maintain mappings on the order of millions, rather than Merkle tree approaches which can easily provide lookup proofs for billions of mappings. Nevertheless, examples of such settings where our constructions are immediately applicable include binary transparency (as of Jan 2022, Google Play Store included 3.3 million apps and Apple App Store included 2.1 million apps <em>[x27]</em> whereas Ubuntu’s main repository included 106 thousand packages) or smaller messaging services such as Signal (40 million users <em>[x28]</em>). We demonstrate how our systems scale with increased resources, but new techniques or improved scaling through specialized hardware <em>[x21, ZWZ+21]</em> will likely be needed to make client-auditable verifiable registries practical for larger applications like Certificate Transparency (340 million domains) or WhatsApp (2 billion users).</p>

    <p class="text-gray-300">We will present our results as modularly as possible, following the roadmap illustrated in Figure 1. In particular, we will start with the abstraction of an <em>authenticated dictionary</em> (AD) with an efficient invariant update proof, for which we provide an RSA instantiation by combining KVaC with our new update proofs. Then, we will show how to <em>generically</em> enhance such an AD into an <em>authenticated history dictionary</em> (AHD) which additionally allows for invariant proofs over the history of the dictionary, either via IVC or via our new amortization technique. Finally, we will combine the resulting AHDs with different trusted auditing mechanism (a plain bulletin board or one additionally verifying hash chains) to obtain our final systems.</p>

    <h2 id="sec-3" class="text-2xl font-bold">2 Setting and Threat Model</h2>

    <p class="text-gray-300">A <em>verifiable registry</em> <em>[x10, MKL+20]</em> maintains a collection <span class="math">D</span> of key-value pairs <span class="math">(k,v)</span> administered by a centralized <em>server</em>. We assume that <span class="math">D</span> contains at most one pair <span class="math">(k,v)</span> for each <span class="math">k</span>. The server periodically signs and publishes, at each <em>epoch</em>, a commitment (or <em>digest</em>) <span class="math">d_{i}</span> to the registry state <span class="math">D_{i}</span> on a public bulletin board (discussed shortly). Moving from epoch <span class="math">i</span> to epoch <span class="math">i+1</span>, means that one or more key-</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Figure 1: Overview of approaches to building verifiable registries efficiently auditable by clients. The highlighted boxes correspond to our new techniques and constructions, resulting in our two proposed verifiable registries, VeRSA-IVC and VeRSA-Amtz. The MT-VR-IVC verifiable registry can be considered as a baseline solution proposed in previous work [CCDW20]. We denote that the IVC-based registries can be instantiated via hashchain verification or via our new client checkpoint auditing mechanism.</p>

    <p class="text-gray-300">value pairs have been updated, i.e.,  <span class="math">(k,\\nu)</span>  has been replaced by  <span class="math">(k,\\nu^{\\prime})</span>  or that an entry for a new  <span class="math">k</span>  is added to  <span class="math">D</span> . There is an implicit notion that the updates and additions of these entries are the outcome of users requests—we do not specify these mechanisms further as they are application-specific. Also, we do not bound the number of updates of  <span class="math">D_{i + 1}\\backslash D_i</span> . Depending on the application context, a server may try to batch many updates into a single epoch, perhaps increasing epoch latency but achieving better throughput. Clients will then able to issue lookup queries to the registry and perform monitoring of entries to detect unexpected changes. We describe these below, after clarifying a few more high-level aspects of the model.</p>

    <p class="text-gray-300">Threat model. Our primary goal is to guarantee a consistent view of the key-value mappings to all clients, and to allow for efficient monitoring of these mappings. The server is not trusted and may arbitrarily deviate from the protocol. Our goal is not to prevent attacks, in principle, but to ensure that they are eventually detected by some client accessing the system. This is particularly suitable for a malicious-but-cautious adversary  <span class="math">\\left[\\mathrm{CDR14}\\right]^2</span> . We do not attempt to guarantee availability, as a malicious server can simply refuse to respond to any queries. We also do not provide any privacy guarantees, though existing techniques for enhancing privacy can be implemented at the application-layer specification of  <span class="math">(k,\\nu)</span> <span class="math">\\left[\\mathrm{MBB}^{+}15,\\mathrm{EMBB17}\\right]</span>  (See Section 9).</p>

    <p class="text-gray-300">Bulletin board. As stated above, our solutions rely on a public bulletin board to prevent split-view attacks, in which a malicious server convinces user Alice to accept digest  <span class="math">d_{i}</span>  and user Bob to accept digest  <span class="math">d_{i}^{\\prime} \\neq d_{i}</span>  for the same epoch  <span class="math">i</span> . Both digests might be valid updates from a common ancestor  <span class="math">d_{j}</span> , but map a key to two distinct values. We assume that all digests  <span class="math">d_{0}, d_{1}, \\ldots</span>  (i.e., one unique digest per epoch) are published by the server on the bulletin board, from which clients will read to maintain a consistent view, and that there exists an efficient mechanism for a client to read  <span class="math">d_{i}</span>  for any  <span class="math">i</span> . Reliance on an out-of-band mechanism is necessary, in line with prior work on transparency systems [LLK13, MBB+15, CDGM19, MKL+20, LKMS04]. Bulletin boards, in particular, are a common assumption in cryptographic protocols [Ben87, CBM15, CGJ+17] which admits several possible implementations — e.g. a public blockchain [TD17] or a gossip protocol [STV+16, MKL+20]. The implementation of the bulletin board will require, either directly or indirectly, some trusted auditors ensuring that every epoch  <span class="math">i</span>  is mapped to a unique  <span class="math">d_{i}</span> . In this work, all other auditing can be performed by clients themselves.</p>

    <p class="text-gray-300">Basic lookups and monitoring. Clients can interact with the server to query a key  <span class="math">k</span>  at epoch  <span class="math">i</span>  and retrieve the associated value  <span class="math">\\nu</span> , along with a proof  <span class="math">\\pi</span>  of validity with respect to  <span class="math">d_{i}</span>  and some additional metadata (such as a version number). Clients perform lookups at the current epoch  <span class="math">i</span>  to learn the authoritative value for a given key. We envision particular applications where key-value entries are owned by some clients, e.g., if the registry implements a public key directory, a client will own the entry mapping their username to public key. We then assume clients continually look up their own keys to ensure that the mapped value is correct, a process called monitoring.</p>

    <p class="text-gray-300">Associating certain invariant metadata (such as a version number) with each mapping enables efficient monitoring across digests even after the client has spent a long period offline, but requires that every digest preserves these invariants with respect to the prior digest. Past work has considered two such invariants. The versioned invariant  <span class="math">\\left[\\mathrm{MBB}^{+}15,\\mathrm{Bon}16\\right]</span>  associates with each key a version number that must be incremented whenever that key's value is updated. The append-only invariant  <span class="math">\\left[\\mathrm{TBP}^{+}19,\\mathrm{MKL}^{+}20\\right]</span>  associates with each key an append-only list of the entire history of values for that key over the lifetime of the dictionary. Either invariant makes it easy to detect if a mapping has been modified; for example, in the versioned setting, if a client queries its own key at digest  <span class="math">d_{i}</span>  and the associated metadata indicates the version number has not changed since the last digest  <span class="math">d_{j}</span>  which the client queried, this guarantees the mapping has not changed during this period. In this work, we primarily focus on the simpler versioned invariant, observing that in most of our applications,</p>

    <p class="text-gray-300">it is sufficient to provide the most up-to-date value mapping.</p>

    <p class="text-gray-300">Where monitoring can go wrong. It is instructive to consider concrete attacks a malicious server can mount to understand where monitoring can fail. The canonical attack we consider is sometimes called a <em>ghost value attack</em> (or ghost key attack) <em>[MBB+15]</em>. Consider a key owner that monitors their key at epochs <span class="math">i</span> and <span class="math">j</span>, and a second client that performs a lookup on the key at epoch <span class="math">\\ell</span> where <span class="math">i&lt;\\ell&lt;j</span>. Suppose the key owner’s expected mapped value for the key across epoch <span class="math">i</span> to <span class="math">j</span> is <span class="math">v</span>. A ghost value attack occurs if the server can get the lookup client to accept a “ghost value” <span class="math">v^{\\prime}\\neq v</span> for the key at epoch <span class="math">\\ell</span> and then switch the value back to <span class="math">v</span> at epoch <span class="math">j</span> so that the owner’s monitoring does not detect misbehavior. This attack is typically addressed, as mentioned above, through the use of invariant proofs that help with monitoring, e.g., detecting a change in version number. As long as (1) the view of epoch to digest mapping is consistent across clients and (2) the invariant is preserved between each digest, ghost value attacks will be detected. Thus, a ghost value attack can succeed if either of these assumptions fail – we next consider two attacks against these assumptions.</p>

    <p class="text-gray-300">In a <em>split-view attack</em> <em>[x10]</em>, a server can publish different digests for an epoch to clients that are partitioned in different “worlds”. In this attack, even if the invariant is preserved across the published digests in the key owner’s world, it says nothing about the published digests in the lookup client’s world, and monitoring will fail. We address the split-view attack by assuming a public bulletin board maintained by trusted auditors (see above) ensuring all clients have an eventually consistent view of the epoch-to-digest mapping — this appears to be a minimal assumption needed for a transparency system.</p>

    <p class="text-gray-300">However, even with a consistent epoch-to-digest mapping, the question remains of who will verify invariant preservation between published digests. The server may mount an <em>oscillation attack</em> <em>[MKL+20]</em>, in which it serves clients interleaving sequences of digests where each sequence preserves the invariant, but the two sequences interleaved do not preserve the invariant. For example, say the key owner is only served digests for even epochs, while the lookup client is served digests for odd epochs, and clients only verify the invariant holds for digests they are served. Monitoring will fail unless at some point an invariant proof is checked between an odd and even epoch digest. (Oscillation is of particular concern with asynchronous clients that come online at different times.) Prior work has addressed this by verifying invariant preservation between <em>every</em> consecutive pair of published digests using one of the following two approaches. The first approach simply assumes a set of trusted auditors that perform this task — we specify the use of outsourced trusted auditors because, typically, the invariant verification work (linear in the number of epochs) is considered too costly for the client to perform. The second approach, proposed in concurrent work <em>[x1, x23]</em>, uses IVC with recursive SNARKs to allow for more efficient client verification. Specifically, registry digests are tied into a hash chain where <span class="math">h_{i}=H(h_{i-1},d_{i-1})</span>, and the pair <span class="math">(h_{i},d_{i})</span> is stored for epoch <span class="math">i</span> on the bulletin board. A succinct proof is created that attests to (1) invariant preservation between <span class="math">d_{i-1}</span> and <span class="math">d_{i}</span>, (2) inclusion in the hash chain <span class="math">h_{i}=H(h_{i-1},d_{i-1})</span>, and (3) recursive verification of the same proof for <span class="math">(h_{i-1},d_{i-1})</span>. By collision-resistance of the hash function, such a proof indirectly attests to the existence of a unique sequence of digests that each consecutively preserve the invariant. Even so, there is no guarantee that the sequence of digests attested to in the proof match the sequence of digests published on the bulletin board. To prevent oscillation attacks, a client must additionally verify the hash chain posted on the bulletin board: if the hash chain is valid, then it must be that the sequence of published digests preserve the invariant. Verification of the hash chain is still linear in the number of epochs, but it is concretely inexpensive, and it is plausible a client may perform this task or that it may be outsourced to the trusted auditors maintaining the public bulletin board (e.g., via a smart contract).</p>

    <p class="text-gray-300">Here, we put forward a novel approach to client-efficient auditing of invariant proofs to prevent oscillation attacks, which we overview next. Our approach assumes only a bulletin board (without relying on a hash chain), and will enable SNARK-free solutions such as VeRSA-Amtz.</p>

    <p class="text-gray-300">Client checkpoint auditing. We introduce a new <em>checkpointing</em> technique, which we describe in detail in Section 6. Consider a client that was last online at epoch <span class="math">i</span> and comes back online at epoch <span class="math">j</span>. Instead of requiring the client to verify the invariant for all consecutive epochs in the range from <span class="math">i</span> to <span class="math">j</span>, the client will audit the invariant for a logarithmic number of <em>checkpoint digests</em> corresponding to certain canonical epochs between <span class="math">i</span> and <span class="math">j</span>. Crucially, these checkpoints are chosen so that any two overlapping ranges will share at least one checkpoint. This implicitly guarantees that, for any two clients, the invariant is preserved through the sequence of digests in their interleaved view up to their latest common checkpoint, and any oscillation that may have occurred since then will eventually be detected on future audits. We note that clients <em>may</em> temporarily accept two digests which do not preserve the invariant with respect to each other. Crucially, however, such an oscillation attack is <em>guaranteed</em> to eventually be detected at the next shared checkpoint.</p>

    <h2 id="sec-4" class="text-2xl font-bold">3 Preliminaries</h2>

    <p class="text-gray-300">Authenticated dictionaries. An <em>authenticated dictionary</em> (AD) maintains and commits to a collection of key/value pairs <span class="math">[(k_{i},v_{i})]_{i}</span>, where every key is unique, with a digest <span class="math">d</span>. An initial digest and state are produced via <span class="math">(d_{0},st)\\leftarrow\\mathsf{Init}^{pp}()</span> following a setup producing public parameters <span class="math">pp\\leftrightarrows\\mathsf{Setup}(\\lambda)</span> where <span class="math">\\lambda</span> is a security parameter. The public parameters are</p>

    <p class="text-gray-300">included implicitly in all algorithms, and we may drop the superscript if the use is clear from context. A set of key-value mappings may be updated to produce a new digest, <span class="math">(d^{\\prime},st)\\leftarrow\\mathsf{Upd}([(k_{j},v_{j})]_{j}:st)</span>. It provides proofs for key lookups, <span class="math">(v,\\pi)\\leftarrow\\mathsf{Lkup}(k:st)</span>, that can be verified given the digest commitment, <span class="math">0/1\\leftarrow\\mathsf{VerLkup}(d,k,v,\\pi)</span>. An authenticated dictionary must satisfy <em>key binding</em>, which means that it is infeasible to produce valid lookup proofs for key <span class="math">k</span> to different values <span class="math">v</span> and <span class="math">v^{\\prime}</span>. ADs can also be augmented with invariant update proofs, proving that a certain invariant <span class="math">\\Phi(k,v,v^{\\prime})</span> is preserved for all keys during an update; we augment the <span class="math">\\mathsf{Upd}</span> algorithm to additionally return a proof and provide an accompanying verification algorithm, <span class="math">0/1\\leftarrow\\mathsf{VerUpd}(d,d^{\\prime},\\pi)</span>. The invariant proof must satisfy soundness, meaning if the verification algorithm succeeds, the invariant is preserved. We will primarily be concerned with the versioned invariant which has been previously used in Merkle trees <em>[MBB^{+}15, x11]</em>.</p>

    <p class="text-gray-300">The most prevalent authenticated dictionary implementations in practice are based on <em>Merkle trees</em> <em>[x23, MBB^{+}15, x25]</em>. Merkle trees admit lookup proofs and update proofs for a single key which are of size and verification time <span class="math">\\mathcal{O}(\\log N)</span> for dictionaries of size <span class="math">N</span>. We review these algorithms in Appendix A and introduce our own optimization using open addressing in Appendix B.</p>

    <p class="text-gray-300">Append-only vector commitments. A <em>vector commitment</em> (VC) commits to an ordered list of elements <span class="math">[v_{i}]_{i}</span>. Setup and initialization syntax follow the same as for ADs. An <em>append-only</em> VC provides an update algorithm to append elements to the end of the list, <span class="math">(d^{\\prime},st)\\leftarrow\\mathsf{Upd}([v^{\\prime}_{i}]_{i}:st)</span>, as well as supports efficient prefix proofs that a commitment commits to a prefix of another: <span class="math">\\pi\\leftarrow\\mathsf{ProveUpd}(j:st)</span> and <span class="math">0/1\\leftarrow\\mathsf{VerUpd}(d^{\\prime},d,j,\\pi)</span> where <span class="math">L[0:j]=L^{\\prime}</span> for list <span class="math">L</span> and <span class="math">L^{\\prime}</span> corresponding to digests <span class="math">d</span> and <span class="math">d^{\\prime}</span>, respectively. A VC supports efficient lookups with proof of elements by index, <span class="math">(v,\\pi)\\leftarrow\\mathsf{Lkup}(i:st)</span> with accompanying verification algorithm <span class="math">0/1\\leftarrow\\mathsf{VerLkup}(d,i,v,\\pi)</span>. A VC must satisfy <em>index binding</em> meaning that it should not be possible to provide valid lookup proofs to different values for the same index. Again, append-only VCs can be derived from Merkle trees <em>[x13, MKL^{+}20, x1]</em>; it supports lookup proofs and arbitrary-length update proofs of size and verification time <span class="math">\\mathcal{O}(\\log N)</span> for vectors of size <span class="math">N</span> (see Appendix A).</p>

    <p class="text-gray-300">Compact ranges. A <em>compact range</em> is a succinct, canonical representation of a range <span class="math">[L,R)</span> where <span class="math">L,R</span> are non-negative integers <em>[MKL^{+}20]</em>. A compact range, <span class="math">[(L_{i},R_{i})]_{i=1}^{m}\\leftarrow\\mathsf{CompactR}((L,R))</span>, is the minimum set of <span class="math">m</span> subranges that "span" <span class="math">[L,R)</span> where <span class="math">L_{1}=L</span>, <span class="math">R_{m}=R</span>, and <span class="math">R_{i}=L_{i+1}</span> for all <span class="math">1\\leq i&lt;m</span>. Each subrange is restricted to be of the form: <span class="math">(L_{i}=a_{i}\\cdot 2^{b_{i}},R_{i}=L_{i}+2^{b_{i}})</span> for non-negative integers <span class="math">(a_{i},b_{i})</span>. It is guaranteed that a unique compact range exists for every range; further, the time to compute the compact range and the number of subranges <span class="math">m</span> is logarithmic in the size of the range, <span class="math">\\mathcal{O}(\\log(R-L))</span> (see <em>[MKL^{+}20]</em> for more details).</p>

    <p class="text-gray-300">RSA groups and key-value dictionaries. An <em>RSA group</em> is the multiplicative group of invertible integers modulo <span class="math">N</span> (denoted <span class="math">\\mathbb{Z}_{N}^{\\times}</span>), where <span class="math">N</span> is the product of two secret primes. We define the <em>RSA quotient group</em> for <span class="math">N</span> as <span class="math">\\mathbb{Z}_{N}^{\\times}\\setminus\\{\\pm 1\\}</span>. The widely believed Strong RSA Assumption (Strong-RSA) asserts that it is computationally difficult to compute <span class="math">e^{\\text{th}}</span> roots of a non-trivial element of <span class="math">\\mathbb{Z}_{N}^{\\times}</span> for <span class="math">e\\geq 3</span>.</p>

    <p class="text-gray-300">Recently, it was shown how to construct efficient authenticated key-value dictionaries based on the Strong-RSA assumption <em>[x1, x2]</em>. Our work builds on the KVaC construction <em>[x1]</em> which we provide in Appendix D.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Lastly, proofs of integer discrete log <em>[x31, x2]</em> have been useful for batching insertions and membership proofs in RSA accumulators <em>[x10]</em>. In such a proof, a prover convinces a verifier that for <span class="math">u,v\\in\\mathbb{G}</span> and <span class="math">\\alpha\\in\\mathbb{Z}</span>, the relation <span class="math">v=u^{\\alpha}</span> holds, where <span class="math">\\mathbb{G}</span> is an RSA quotient group. Importantly, the integer <span class="math">\\alpha</span> can be much larger than $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{G}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">, but the verifier’s running time remains </span>\\tilde{\\mathcal{O}}(\\log</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{G}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)$. Later, we will extend these techniques to apply to the RSA key-value dictionary.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">SNARKs and incrementally-verifiable computation. A <em>non-interactive proof system</em> for a relation <span class="math">\\mathcal{R}</span> over <em>statement-witness</em> pairs <span class="math">(x,w)</span> enables producing a proof, <span class="math">\\pi\\leftarrow\\mathsf{Prove}(pk,x,w)</span>, that convinces a verifier <span class="math">\\exists w:(x;w)\\in\\mathcal{R}</span>, <span class="math">0/1\\leftarrow\\mathsf{Ver}(vk,\\pi,x)</span>; <span class="math">pk</span> and <span class="math">vk</span> are proving and verification keys output by a setup, <span class="math">(pk,vk)\\leftarrow\\mathsf{Setup}(\\lambda)</span>.</p>

    <p class="text-gray-300">A <em>non-interactive argument of knowledge</em> further convinces the verifier not only that the witness <span class="math">w</span> exists but also that the prover <em>knows</em> <span class="math">w</span>. If <span class="math">\\pi</span> is succinct, i.e. of “small” size and verification time, with respect to <span class="math">x</span> and <span class="math">\\mathcal{R}</span>, the protocol is further known as a (preprocessing) <em>SNARK</em> <em>[x16, x12]</em>. We make use of SNARKs for relations of general circuit satisfiability, of which there exist many constructions <em>[x11, x16, x17, CHM^{+}20, x1, x12]</em>.</p>

    <p class="text-gray-300">An <em>incrementally-verifiable computation</em> (IVC) <em>[x34]</em> allows proving correctness of repeated application of a circuit computation. The predominant approach to IVC uses <em>recursive SNARKs</em> <em>[x5, x6, x14, x11]</em>, in which the proof circuit for each intermediate state verifies one step of computation from the previous state <em>and</em> verifies correct computation from the initial state to the previous state by recursively verifying the proof for the previous state; such a proving circuit can be described because the recursive verification can be computed succinctly.</p>

    <h2 id="sec-5" class="text-2xl font-bold">4 Versioned Invariant Proofs for RSA Authenticated Dictionaries</h2>

    <p class="text-gray-300">We begin by constructing the first RSA-based authenticated dictionary that efficiently supports succinct versioned invariant proofs. Our starting point is the KVaC authenticated dictionary construction of Agrawal and Raghuraman <em>[x1]</em>. We extend the original construction in two ways in order to make it suitable for use with verifiable registries. First, we</p>

    <p class="text-gray-300">show how to support efficient updates for a batch of key-value mappings (<span class="math">[k_{j},v_{j}]_{j}</span>), instead of only a sole key-value update. Second, as our most significant contribution, we construct a succinct proof that a batch of updates applied to the dictionary preserve the versioned invariant. Building this proof, enables KVaC to achieve the <em>strong</em> key binding security property needed for verifiable registries, in which key binding holds for adversarially chosen digests. Prior to this work, the construction was only secure with respect to <em>weak</em> key binding, i.e., digests that were produced honestly, limiting its applicability significantly.</p>

    <p class="text-gray-300">In KVaC, key-value pairs are committed to with the following digest, where <span class="math">u</span> represents a version number for the key, <span class="math">\\mathsf{H}</span> is a collision-resistant hash function mapping keys to primes, and <span class="math">g</span> is a member of an RSA quotient group:</p>

    <p class="text-gray-300"><span class="math">d\\leftarrow\\left(g^{\\left(\\prod_{i}\\mathsf{H}(k_{i})^{\\alpha_{i}}\\right)\\cdot\\left(\\sum_{i}v_{i}/\\mathsf{H}(k_{i})\\right)},g\\prod_{i}\\mathsf{H}(k_{i})^{\\alpha_{i}}\\right)</span></p>

    <p class="text-gray-300">To update a key’s value from <span class="math">v</span> to <span class="math">v+\\delta</span>, the new digest <span class="math">d^{\\prime}=(d_{1}^{\\mathsf{H}(k)}d_{2}^{\\delta},d_{2}^{\\mathsf{H}(k)})</span> is computed, where the previous digest <span class="math">d=(d_{1},d_{2})</span>. We defer the full details including lookup proof computation to Appendix D.</p>

    <p class="text-gray-300">Batching updates. When updating the values associated with many keys, we observe that instead of applying each update in sequence, all updates <span class="math">[k,\\delta]_{i}</span> can be applied at once by the following:</p>

    <p class="text-gray-300"><span class="math">Z\\leftarrow\\prod_{i}\\mathsf{H}(k_{i})\\qquad\\Delta\\leftarrow(\\prod_{i}\\mathsf{H}(k_{i}))\\cdot(\\sum_{i}\\delta_{i}/\\mathsf{H}(k_{i})).</span></p>

    <p class="text-gray-300">Then the batched update follows the same form as before, <span class="math">d^{\\prime}=(d_{1}^{Z}d_{2}^{\\Delta},d_{2}^{Z})</span>. We will take advantage of this form to construct succinct proofs for the versioned invariant.</p>

    <p class="text-gray-300">Proving the versioned invariant. Informally, the versioned invariant enforces over an update that the only way to change a key’s value is by increasing its version number. More formally, we define the invariant as follows with two constraints: (1) a key’s version number does not decrease in an updated digest, and (2) two different values for a key cannot be shown for the same version number,</p>

    <p class="text-gray-300"><span class="math">\\Phi_{\\mathsf{vsn}}(k,(v,u),(v^{\\prime},u^{\\prime}))=u&lt;u^{\\prime}\\ \\vee\\ (u=u^{\\prime}\\ \\wedge\\ v=v^{\\prime})\\ .</span> (1)</p>

    <p class="text-gray-300">One approach to prove this invariant (and bootstrap strong key binding from weak key binding) is to prove that <span class="math">d^{\\prime}</span> is the result of correctly applying the batch update procedure to <span class="math">d</span>, i.e., that the update equations above hold, however it turns out that proving a weaker statement suffices. The prover constructs a proof of knowledge for the following relation between <span class="math">d=(X_{1},X_{2})</span> and updated digest <span class="math">d^{\\prime}=(Y_{1},Y_{2})</span>:</p>

    <p class="text-gray-300"><span class="math">\\mathcal{R}_{\\mathsf{KVaC}}=\\left\\{((X_{1},X_{2},Y_{1},Y_{2});(\\alpha,\\beta)):Y_{1}=X_{1}^{\\alpha}X_{2}^{\\beta}\\wedge Y_{2}=X_{2}^{\\alpha}\\right\\}.</span></p>

    <p class="text-gray-300">We show in Appendix D that it is computationally infeasible to produce a valid proof for this relation if the versioned invariant is violated. This is a somewhat surprising result, as we do not enforce any extra structure on <span class="math">\\alpha</span> and <span class="math">\\beta</span>, such as matching the structure of <span class="math">(Z,\\Delta)</span> (which would result in a much more costly proof). Rather, simply proving knowledge of <em>any</em> <span class="math">\\alpha</span> and <span class="math">\\beta</span> ensures that either the underlying pair of dictionary states do not violate the versioned invariant <em>or</em> that the prover has solved a computational problem related to factoring, breaking the Strong-RSA assumption.</p>

    <p class="text-gray-300">We use the generalized knowledge of integer discrete log proof system from <em>[x1]</em> (Figure 13, Appendix D) as the non-interactive proof of knowledge for <span class="math">\\mathcal{R}_{\\mathsf{KVaC}}</span>. Importantly, this proof system, which leverages the algebraic structure of the RSA group, has a constant-time verification algorithm and constant-sized proof. This is a significant improvement over other Merkle-based <em>[MBB^{+}15, MKL^{+}20]</em> and bilinear pairing-based <em>[TBP^{+}19, LGG^{+}20]</em> constructions of authenticated dictionaries with versioned proofs. We defer the full formalism and proofs of security of strong key binding and versioned invariant preservation to Appendix D.</p>

    <p class="text-gray-300">Computing lookup proofs. Unfortunately, computing membership and non-membership proofs for keys from scratch is expensive – on the order of the combined number of keys with non-null values and number of past updates to the dictionary. Given a (non-)membership proof for a previous epoch, the proof can be updated to be valid for the current epoch in time linear in the number of key updates that have since occurred. However, even these updates can be expensive for the provider if many epochs have passed since a key’s last query date. In our evaluation (Section 8), we show that for dictionaries with millions of keys, lookup proof computation costs are manageable; we discuss batch computation techniques that help alleviate these costs in Appendix E.</p>

    <p class="text-gray-300">Extending to the append-only invariant. While in this work, we focus on the versioned invariant, some applications may require the stronger append-only invariant that tracks the entire history of mapped values of a key. In Appendix H, we propose an extension of KVaC for which we construct succinct append-only invariant proofs.</p>

    <h2 id="sec-6" class="text-2xl font-bold">5 Authenticated History Dictionaries</h2>

    <p class="text-gray-300">In this section we will define an <em>authenticated history dictionary</em> (AHD), the novel cryptographic primitive behind our verifiable registry system, and present several constructions of this primitive from authenticated dictionaries.</p>

    <h3 id="sec-7" class="text-xl font-semibold mt-8">5.1 Syntax, Semantics, and Security</h3>

    <p class="text-gray-300">An AHD commits not only to its current state, but also to all previous states in its history. It is also able to efficiently provide update invariant proofs between any sequence of previous states. As for authenticated dictionaries, we define an invariant <span class="math">\\Phi</span> as a boolean function on input <span class="math">k,v_{i},v_{j}</span> that outputs <span class="math">1</span> if the invariant is preserved; we require the invariant to be preserved for all keys. Again, in this work, we will be interested in the versioned invariant <span class="math">\\Phi_{\\mathsf{vsn}}</span> (Equation 1). An AHD is defined by the following set of algorithms:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">pp\\mathop{\\leftarrow}\\mathop{\\ast}\\textsf{Setup}(\\lambda)</span>: The setup algorithm takes a security parameter and returns public parameters.</li>

      <li><span class="math">(d_{0},st_{0})\\mathop{\\leftarrow}\\textsf{Init}()</span>: The initialization algorithm returns an initial digest to the empty dictionary.</li>

      <li><span class="math">(d_{i+1},st_{i+1})\\mathop{\\leftarrow}\\textsf{Upd}([k_{j},v_{j}]_{j}:st_{i})</span>: The update algorithm updates the dictionary values for input keys <span class="math">\\{k_{j}\\}</span> to the values <span class="math">\\{v_{j}\\}</span> and outputs a new digest <span class="math">d_{i+1}</span> representing the new dictionary history for epoch <span class="math">i+1</span>.</li>

      <li><span class="math">(v,\\pi_{\\textsf{lkup}})\\mathop{\\leftarrow}\\textsf{Lkup}(k:st_{i})</span>: The lookup algorithm returns the value <span class="math">v</span> associated with <span class="math">k</span> along with a membership proof <span class="math">\\pi_{\\textsf{lkup}}</span>. If the <span class="math">k</span> is not present in the dictionary, <span class="math">v</span> is set to <span class="math">\\bot</span> and a non-membership proof is provided.</li>

      <li><span class="math">0/1\\mathop{\\leftarrow}\\textsf{VerLkup}(d_{i},k,v,\\pi_{\\textsf{lkup}})</span>: The lookup verification algorithm verifies the key-value mapping in <span class="math">d_{i}</span>.</li>

      <li><span class="math">\\pi_{\\textsf{hist}}\\mathop{\\leftarrow}\\textsf{ProveHist}([c_{j}]_{j}^{m}:st_{i})</span>: The prove history algorithm takes as input an ordered list of checkpoint epochs, <span class="math">c_{1}&lt;\\ldots&lt;c_{m}&lt;i</span>, and provides a proof that the digest at each checkpoint is included in the committed history.</li>

      <li><span class="math">0/1\\mathop{\\leftarrow}\\textsf{VerHist}(d_{i},[(c_{j},d_{c_{j}})]_{j}^{m},\\pi_{\\textsf{hist}})</span>: The history verification algorithm verifies the ordered list of checkpoint digests are included in the history of digest <span class="math">d_{i}</span>.</li>

      <li><span class="math">\\pi_{\\Phi}\\mathop{\\leftarrow}\\textsf{ProveInv}([c_{j}]_{j}^{m}:st_{i})</span>: The prove invariant algorithm takes as input an ordered list of checkpoint epochs, <span class="math">c_{1}&lt;\\ldots&lt;c_{m}\\leq i</span>, and provides a proof that the invariant <span class="math">\\Phi</span> is preserved between the dictionary states of each pair of digests in sequence: <span class="math">(d_{c_{j}},d_{c_{j+1}})</span>.</li>

      <li><span class="math">0/1\\mathop{\\leftarrow}\\textsf{VerInv}(d_{i},[(c_{j},d_{c_{j}})]_{j}^{m},\\pi_{\\Phi})</span>: The invariant verification algorithm verifies the invariant is preserved between the sequence of ordered checkpoint digests.</li>

    </ul>

    <p class="text-gray-300">An important feature of the AHD syntax and semantics is allowing querying of history and invariant properties for previous states. While critical to support client auditing as clients often come online after long periods of disconnection, this functionality is what creates the main challenge in coming up with efficient constructions.</p>

    <p class="text-gray-300">In terms of correctness, informally, the dictionary should correctly update its key-value mappings and lookups should return the latest value added. Previous digests should be correctly committed to in the appropriate epoch position in history. And lastly, the proofs produced by the proving algorithms should pass their accompanying verification algorithms.</p>

    <p class="text-gray-300">In terms of security, we define three properties. The first two properties are analogous to the security properties of ADs. First, an AHD must satisfy <em>key binding</em>, which is defined equivalently to as in ADs: it should not be possible to provide valid lookup proofs to two different values for a key in a digest. Second, <em>invariant soundness</em> requires that it should not be possible to produce a valid invariant proof for a sequence of checkpoints such that the invariant is not preserved between any two checkpoint digests. The last property is <em>history binding</em>, which requires that it should not be possible to provide two valid history proofs for a digest including a different checkpoint digest at the same checkpoint epoch. We formally define these security properties as pseudocode games in Appendix F.</p>

    <h3 id="sec-8" class="text-xl font-semibold mt-8">5.2 Towards a Generic Construction</h3>

    <p class="text-gray-300">We begin by discussing useful building blocks and strawman solutions for constructing an AHD from an underlying AD.</p>

    <p class="text-gray-300">Composing an AD with a history commitment. A core additional functionality AHDs provide over ADs is the ability to track and commit to the history of previous states. As such, a natural starting point to build an AHD is to combine an AD with an append-only vector commitment (VC), committing the digest of the AD at time step <span class="math">i</span> to the <span class="math">i^{th}</span> position of the vector commitment; we will refer to the vector commitment as a <em>history commitment</em>.</p>

    <p class="text-gray-300">More specifically, consider an AHD made of an authenticated dictionary <span class="math">D</span> and a vector commitment <span class="math">L</span>: the digest of the AHD is a pair of digests (or hash of pair), one from an authenticated dictionary and the other of the history commitment: <span class="math">(d_{\\textsf{AD}},d_{\\textsf{VC}})</span>. To perform a set of key-value updates <span class="math">[k_{i},v_{i}]_{i}</span>, first, a new AD digest is computed by updating the AD, <span class="math">(d^{\\prime}_{\\textsf{AD}},D^{\\prime})\\mathop{\\leftarrow}\\textsf{AD.Upd}(D,[k_{i},v_{i}]_{i})</span>. Then, the vector commitment is updated to append the old digest, <span class="math">(d^{\\prime}_{\\textsf{VC}},L^{\\prime})\\mathop{\\leftarrow}\\textsf{VC.Upd}(L,[(d_{\\textsf{AD}},d_{\\textsf{VC}})])</span>. The new AHD digest is set as <span class="math">(d^{\\prime}_{\\textsf{AD}},d^{\\prime}_{VC})</span>.</p>

    <p class="text-gray-300">This construction also supports succinct proofs to AHD.ProveHist queries for arbitrary checkpoints. A prefix proof using VC.ProveUpd is computed for each checkpoint with respect to the current state. For the Merkle tree instantiation of VC (Appendix A), these proofs both can be computed and verified in time and are of size <span class="math">\\mathcal{O}(\\log N)</span> where <span class="math">N</span> is length of the vector. This basic combination of AD and history commitment form the basis of our proposed constructions. The pseudocode details are given in Figure 2; and we provide proof sketches for history binding and key binding in Appendix F.</p>

    <p class="text-gray-300">Challenge of succinct invariant proofs. Unfortunately, it is not straightforward how to provide succinct invariant proofs for arbitrary checkpoints in response to AHD.ProveInv. Recall, an AD can be augmented to provide invariant proofs for updates. An invariant proof <span class="math">\\pi_{i}</span> can be computed during each epoch update for <span class="math">d_{\\textsf{AD},i-1}</span> to <span class="math">d_{\\textsf{AD},i}</span>. For a queried pair of checkpoints <span class="math">(c_{j},c_{j+1})</span>, the sequence of epoch invariant proofs <span class="math">[\\pi_{i}]_{i=c_{j}}^{c_{j+1}}</span> together attest to invariant preservation for <span class="math">d_{\\textsf{AD},c_{j}}</span> to <span class="math">d_{\\textsf{AD},c_{j+1}}</span>. However, this would not be succinct, ultimately leading to a proof of size linear in the range of epochs the checkpoints are over.</p>

    <p class="text-gray-300">Alternatively, it is also not efficient to compute a fresh invariant proof for pairs of checkpoints <span class="math">(c_{j},c_{j+1})</span> on the fly in response to a ProveInv query. Each invariant proof is computed in time linear in the number of key-value updates made to the dictionary.</p>

    <p class="text-gray-300">Protocol: \\mathsf{AHD}_{\\mathsf{IVC}}[\\mathsf{AD},\\mathsf{VC},\\mathsf{SNARK}]</p>

    <p class="text-gray-300">Instead, we will need different approaches. We present two generic constructions for AHDs from ADs. First, we present a construction for succinct invariant proofs based on IVC. It is our most general solution and is compatible with any AD that supports the invariant proof. Second, we present a construction based on amortized proving of invariant preservation over power-of-two ranges of epochs: an invariant proof for any pair of checkpoints can be provided as a  <span class="math">\\log N</span>  sequence of precomputed proofs. This approach dispenses with the heavyweight machinery of IVC, but requires that the underlying AD supports a succinct invariant proof. This is the case for our new RSA construction (Section 4), however does not hold for Merkle tree ADs.</p>

    <p class="text-gray-300">Our first construction is from IVC; for concreteness, we present the construction using recursive proofs [BCCT13, BCTV14], the prevailing approach to IVC. IVC allows constructing a succinct proof of an output (digest) that attests to its correct computation over a series of steps (invariant preserved over epochs). IVC has previously been proposed for producing succinct proofs for verifiers of invariant-based ledger systems [CCDW20], a more general case of verifiable registries.</p>

    <p class="text-gray-300">The starting point of our construction  <span class="math">\\mathrm{AHD}_{\\mathrm{IVC}}</span>  is an AD with history commitment (described in the previous Section 5.2). On each epoch update, in addition to updating the digests as before, a recursive SNARK proof is computed attesting to invariant preservation. Namely, at epoch  <span class="math">i</span> , the proofs  <span class="math">\\pi_{\\Phi}</span>  from AD.Upd showing the updated key-values satisfy the invariant and  <span class="math">\\pi_{\\mathrm{hist}}</span>  from VC.ProveUpd showing the new AD digest was appended to history commitment are computed. Then using a SNARK,  <span class="math">\\pi_{\\mathrm{SNARK},i}</span>  proves that (1)  <span class="math">\\pi_{\\Phi}</span>  verifies with respect to  <span class="math">d_{\\mathrm{AD},i-1}</span>  and  <span class="math">d_{\\mathrm{AD},i}</span> , (2)  <span class="math">\\pi_{\\mathrm{hist}}</span>  verifies with respect to  <span class="math">d_{\\mathrm{VC},i-1}</span>  and  <span class="math">d_{\\mathrm{VC},i}</span> , and (3) that recursively verifies a SNARK  <span class="math">\\pi_{\\mathrm{SNARK},i-1}</span>  for  <span class="math">d_{i-1}</span> . Informally, this SNARK proves "the invariant is preserved across the sequence of digests committed to in the history commitment". The complexity of the recursive relation is proportional to the combined complexity of the SNARK verification algorithm, vector commitment update verification, and importantly, the AD invariant verification algorithm, which differs significantly between a Merkle tree-based AD and our new RSA AD.</p>

    <p class="text-gray-300">Completing the picture, the proof of invariant preservation over a sequence of checkpoints  <span class="math">[c_j]_j</span>  consists of two parts: (1) the most recent SNARK proved for the current epoch  <span class="math">i</span> ,  <span class="math">\\pi_{\\mathrm{SNARK},i}</span> , and (2) a lookup proof in the history commitment for each of the checkpoints, proving the value at index  <span class="math">c_j</span>  is  <span class="math">d_{\\mathrm{AD},c_j}</span> . Intuitively, the SNARK proves that the invariant is preserved across digests in the history commitment, and the lookup proofs reveal the checkpoint digests are indeed included in the history. A protocol description for the  <span class="math">\\mathrm{AHD}_{\\mathrm{IVC}}</span>  construction is given in Figure 2, and a proof sketch for the invariant soundness of  <span class="math">\\mathrm{AHD}_{\\mathrm{IVC}}</span>  is given in Appendix F.</p>

    <p class="text-gray-300">Setup: The public parameters of the scheme consist of the public parameters of its underlying components:  <span class="math">pp \\gets (pp_{\\mathrm{AD}}, pp_{\\mathrm{VC}}, (pk, vk)_{\\mathrm{SNARK}})</span> .</p>

    <p class="text-gray-300">Init: The dictionary is initialized with an empty authenticated dictionary and empty vector commitment, returning an initial digest  <span class="math">d_0 = (d_{\\mathrm{AD},0}, d_{\\mathrm{VC},0})</span> . It stores the following as its current state  <span class="math">st_i</span> :</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">st_{\\mathrm{AD},i}</span> : state of the AD representing current state of key-value mapping.</li>

      <li><span class="math">st_{\\mathrm{VC},i}</span> : state of the VC representing list of previous epoch digests.</li>

      <li><span class="math">\\pi_{\\mathrm{SNARK},i}</span> : SNARK proof attesting to invariant preservation for latest epoch.</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\mathsf{Upd}([k_j,v_j]_j:st_i)</span></p>

    <p class="text-gray-300">(1) The AD is updated with the new key-value mappings:</p>

    <p class="text-gray-300"><span class="math">(d_{\\mathrm{AD},i + 1},\\pi_{\\Phi},st_{\\mathrm{AD},i + 1})\\gets \\mathrm{AD.Upd}([k_j,v_j]_j:st_{\\mathrm{AD},i}).</span></p>

    <p class="text-gray-300">(2) The previous digest is appended to the history commitment:</p>

    <p class="text-gray-300"><span class="math">(d_{\\mathrm{VC},i + 1},st_{\\mathrm{VC},i + 1})\\gets \\mathsf{Upd}([d_i]:st_{\\mathrm{VC},i})</span>  , and  <span class="math">\\pi_{\\mathrm{hist}}\\gets \\mathsf{ProveUpd}(i:</span> <span class="math">st_{\\mathrm{VC},i + 1})</span> <span class="math">\\pi_{\\mathrm{lkup}}\\gets \\mathsf{Lkup}(i:st_{\\mathrm{VC},i + 1})</span></p>

    <p class="text-gray-300">(3) A new SNARK  <span class="math">\\pi_{\\mathrm{SNARK},i + 1}</span>  is computed attesting to invariant preservation for new digest  <span class="math">d_{i + 1} = (d_{\\mathrm{AD},i + 1},d_{VC,i + 1})</span>  , proving the following relation:</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal {R} _ {\\mathrm {S N A R K}} = \\left\\{ \\begin{array}{c} \\left( \\begin{array}{c} (d _ {i + 1}), (d _ {i}, \\pi_ {\\Phi}, \\pi_ {\\mathrm {h i s t}}, \\pi_ {\\mathrm {S N A R K}, i}) \\end{array} \\right): \\\\ \\mathrm {A D . V e r U p d} (d _ {\\mathrm {A D}, i}, d _ {\\mathrm {A D}, i + 1}, \\pi_ {\\Phi}) \\\\ \\mathrm {V C . V e r U p d} (d _ {\\mathrm {V C}, i}, d _ {\\mathrm {V C}, i + 1}, i, \\pi_ {\\mathrm {h i s t}}) \\\\ \\mathrm {V C . V e r L k u p} (d _ {\\mathrm {V C}, i + 1}, i, d _ {i}, \\pi_ {\\mathrm {l k u p}}) \\\\ \\mathrm {S N A R K . V e r} (v k _ {\\mathrm {S N A R K}}, d _ {i}, \\pi_ {\\mathrm {S N A R K}, i}) \\end{array} \\right\\}.</span></div>

    <p class="text-gray-300"><span class="math">\\mathsf{ProveInv}([c_j]_j^m:st_i)</span></p>

    <p class="text-gray-300">(1) For each checkpoint, a lookup proof in the history commitment for the checkpoint index is computed:  <span class="math">\\left[\\pi_{\\mathrm{lkup},j}\\gets \\mathrm{VC.Lkup}(c_j:st_{\\mathrm{VC},i})\\right]_j^m</span> (2) Proof  <span class="math">\\pi_{\\Phi} \\gets (\\pi_{\\mathrm{SNARK},i}, [\\pi_{\\mathrm{lkup},j}]_j^m)</span>  is returned.</p>

    <p class="text-gray-300"><span class="math">\\mathsf{VerInv}(d_i,[(c_j,d_{c_j})]_j^m,\\pi_\\Phi = (\\pi_{\\mathsf{SNARK}},[\\pi_{\\mathsf{lkup},j}]_j^m))</span></p>

    <p class="text-gray-300">(1) The SNARK proof is verified: SNARK.Ver(vkSNARK,  <span class="math">d_{i}</span> ,  <span class="math">\\pi_{\\mathrm{SNARK}}</span> ). (2) The history commitment lookup proof for each checkpoint digest is verified: [VC.VerLkup  <span class="math">(d_{\\mathrm{VC},i},c_j,d_{\\mathrm{AD},c_j},\\pi_{\\mathrm{lkup},j})]_j^m</span></p>

    <p class="text-gray-300"><span class="math">\\mathsf{Lkup}(k:st_i)</span>  and  <span class="math">\\mathsf{VerLkup}(d_i,k,v,\\pi_{\\mathsf{lkup}})</span> : Lookup and lookup verification use the lookup algorithms of the underlying AD over  <span class="math">st_{\\mathrm{AD},i}</span>  and  <span class="math">d_{\\mathrm{AD},i}</span> :</p>

    <p class="text-gray-300"><span class="math">(v,\\pi_{\\mathrm{lkup}})\\gets \\mathrm{AD.Lkup}(k:st_{\\mathrm{AD},i}),\\qquad \\mathrm{AD.VerLkup}(d_{\\mathrm{AD},i},k,v,\\pi_{\\mathrm{lkup}})</span></p>

    <p class="text-gray-300"><span class="math">\\mathsf{ProveHist}([c_j]_j^m:st_i)</span> : For each checkpoint, an lookup proof for the history commitment is provided:  <span class="math">\\pi_{\\mathrm{hist}} = [(\\pi_{\\mathrm{lkup},j},\\pi_{\\mathrm{hist},j})]_j^m</span></p>

    <p class="text-gray-300"><span class="math">\\pi_{\\mathrm{lkup},j}\\gets \\mathrm{VC.Lkup}(c_j:st_{\\mathrm{VC},i}),\\pi_{\\mathrm{hist},j}\\gets \\mathrm{VC.ProveUpd}(c_j:st_{\\mathrm{VC},i}).</span></p>

    <p class="text-gray-300"><span class="math">\\mathsf{VerHist}(d_i,[(c_j,d_{c_j})]_j^m,\\pi_{\\mathrm{hist}} = [(\\pi_{\\mathrm{lkup},j},\\pi_{\\mathrm{hist},j})]_j^m)</span></p>

    <p class="text-gray-300"><span class="math">\\left[\\mathrm{VC.VerLkup}(d_{\\mathrm{VC},i},c_j,d_{c_j},\\pi_{\\mathrm{lkup},j}),\\mathrm{VC.VerUpd}(d_{\\mathrm{VC},i},d_{c_j},c_j,\\pi_{\\mathrm{hist},j})\\right]_j^m</span></p>

    <p class="text-gray-300">Figure 2: Generic construction of an AHD from an AD using incrementally-verifiable computation through recursive SNARKS. The history of the AHD is committed to using an append-only vector commitment referred to as a history commitment.</p>

    <p class="text-gray-300">Recall the two strawman proving approaches for providing an invariant proof for checkpoints  <span class="math">(c_{j}, c_{j+1})</span>  from Section 5.2. The first was to provide a sequence of "epoch invariant proofs", one for each epoch between  <span class="math">c_{j}</span>  and  <span class="math">c_{j+1}</span> : these can</p>

    <p class="text-gray-300">Protocol: \\mathsf{AHD}_{\\mathsf{Amtz}}[\\mathsf{AD},\\mathsf{VC}]</p>

    <p class="text-gray-300">Setup: The public parameters of the scheme consist of the public parameters of its underlying components:  <span class="math">pp \\gets (pp_{\\mathrm{AD}}, pp_{\\mathrm{VC}})</span> .</p>

    <p class="text-gray-300">Init: The dictionary is initialized with an empty authenticated dictionary and empty vector commitment, returning an initial digest  <span class="math">d_0 = (d_{\\mathrm{AD},0}, d_{\\mathrm{VC},0})</span> . It stores the following as its current state  <span class="math">st_i</span> :</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">L_{\\mathrm{AD}} = [\\mathrm{st}_{\\mathrm{AD},\\ell},d_{\\mathrm{AD},\\ell}]_{\\ell}^{i}</span>  : state of the AD at each epoch.</li>

      <li><span class="math">st_{\\mathrm{VC},i}</span> : state of the VC representing list of previous epoch digests.</li>

      <li><span class="math">L_{k} = \\left[[k_{\\ell ,j},v_{\\ell ,j}]_{j}^{m_{\\ell}}\\right]_{\\ell}^{i}</span>  : list of key-value updates applied at each epoch.</li>

      <li><span class="math">T_{\\Phi}</span> : table of precomputed invariant proofs for all compact subranges.</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\mathsf{Upd}([k_j,v_j]_j:st_i)</span></p>

    <p class="text-gray-300">(1) The AD is updated with the new key-value mappings:</p>

    <p class="text-gray-300"><span class="math">(d_{\\mathrm{AD},i + 1},\\pi_{\\Phi},st_{\\mathrm{AD},i + 1})\\gets \\mathsf{AD}.\\mathsf{Upd}([k_j,v_j]_j:st_{\\mathrm{AD},i}).</span></p>

    <p class="text-gray-300">(2) The new AD digest is appended to the history commitment:</p>

    <p class="text-gray-300"><span class="math">(d_{\\mathrm{VC},i + 1},st_{\\mathrm{VC},i + 1})\\gets \\mathsf{Upd}([d_{\\mathrm{AD},i + 1}]:st_{\\mathrm{VC},i}).</span></p>

    <p class="text-gray-300">(3) Compute and store an invariant proof for the key updates applied during every compact subrange of epochs that  <span class="math">i + 1</span>  closes, i.e.,  <span class="math">[L_j]_j^m</span>  such that there exists  <span class="math">(a_j, b_j)</span>  where  <span class="math">L_j = a_j \\cdot 2^{b_j}</span>  and  <span class="math">L_j + 2^{b_j} = i + 1</span> :</p>

    <p class="text-gray-300"><span class="math">T_{\\Phi}[L_j,i + 1]\\gets \\mathsf{AD}.\\mathsf{ProveUpd}([k_{\\ell ,k},v_{\\ell ,k}]_k]_{\\ell = L_j}^{i + 1},st_{\\mathsf{AD},L_j})</span></p>

    <p class="text-gray-300">(4) The new digest  <span class="math">d_{i+1} = (d_{\\mathrm{AD},i+1}, d_{VC,i+1})</span>  is returned.</p>

    <p class="text-gray-300"><span class="math">\\mathsf{ProveInv}([c_j]_j^m :st_i)</span>  : For each checkpoint pair  <span class="math">(c_{j},c_{j + 1})</span>  for  <span class="math">1\\leq j &amp;lt;   m</span>  compute  <span class="math">\\pi_{\\Phi ,j}</span>  then return  <span class="math">\\pi_{\\Phi}\\gets \\left[\\pi_{\\Phi ,j}\\right]_j^m</span></p>

    <p class="text-gray-300">(1) Compute the  <span class="math">n_j</span>  compact subranges that span  <span class="math">(c_{j},c_{j + 1}]</span> :</p>

    <p class="text-gray-300"><span class="math">\\left[(L_{j,\\ell},R_{j,\\ell})\\right]_{\\ell}^{n_j}\\gets \\mathsf{CompactR}((c_j,c_{j + 1}))</span></p>

    <p class="text-gray-300">(2) Construct an invariant proof for  <span class="math">(c_{j}, c_{j+1})</span>  with the precomputed invariant proofs of each compact subrange:  <span class="math">\\pi_{\\Phi, j} = \\left[T_{\\Phi}[L_{j,\\ell}, R_{j,\\ell}], d_{L_{j,\\ell}}\\right]_{\\ell}^{n_j}</span> .</p>

    <p class="text-gray-300"><span class="math">\\mathsf{VerInv}(d_i,[(c_j,d_{c_j})]_j^m,\\pi_\\Phi = \\left[[(\\pi_{\\Phi ,j,\\ell}),d_{\\mathrm{AD},j,\\ell})]_{\\ell}^{n_j}\\right]_j^m)</span>  : For each checkpoint pair  <span class="math">(c_{j},c_{j + 1})</span>  for  <span class="math">1\\leq j &amp;lt;   m</span></p>

    <p class="text-gray-300">(1) Verify compact range endpoints:  <span class="math">d_{c_j} = d_{\\Phi, j, 1}</span>  and  <span class="math">d_{c_{j+1}} = d_{\\Phi, j, n_j}</span> . (2) Verify each compact subrange invariant proof:</p>

    <p class="text-gray-300"><span class="math">\\left[\\mathsf{AD}.\\mathsf{VerUpd}(d_{\\Phi ,j,\\ell},d_{\\Phi ,j,\\ell +1},\\pi_{\\Phi ,j,\\ell})\\right]_{\\ell}^{n_j - 1}.</span></p>

    <p class="text-gray-300">Figure 3: Generic construction of an AHD from an AD using amortized proving of invariant preservation over compact subranges. The underlying AD must support succinct invariant proofs (e.g., as in the new RSA AD construction).</p>

    <p class="text-gray-300">be efficiently precomputed, but do not result in a succinct proof. The second was to directly prove an invariant proof for the key-value updates in the range from  <span class="math">c_{j}</span>  to  <span class="math">c_{j+1}</span> : this cannot be precomputed efficiently as there are quadratically many possible checkpoint ranges that could be queried, however would result in a succinct proof if the invariant proving algorithm of the underlying AD is succinct (as it is for our RSA AD from Section 4).</p>

    <p class="text-gray-300">In this section, we propose a construction  <span class="math">\\mathsf{AHD}_{\\mathsf{Amtz}}</span>  that serves as a middle ground between these two approaches. Instead of attempting to precompute proofs for all possible start and end epoch ranges, only proofs for compact subranges will be precomputed (see preliminaries, Section 3). Recall a</p>

    <p class="text-gray-300">compact range for a range  <span class="math">(c_{j}, c_{j+1})</span>  produces a succinct sequence of subranges  <span class="math">[(L_{\\ell}, R_{\\ell})]_{\\ell}^{m}</span>  that "span"  <span class="math">(c_{j}, c_{j+1})</span> ; that is,  <span class="math">L_{1} = c_{j}</span> ,  <span class="math">R_{m} = c_{j+1}</span> , and  <span class="math">R_{i} = L_{i+1}</span>  for all  <span class="math">1 \\leq i &amp;lt; m &amp;lt; \\log(c_{j+1} - c_{j})</span> . Importantly, each compact subrange is guaranteed to be of the form:  <span class="math">(L_{i} = a_{i} \\cdot 2^{b_{i}}, R_{i} = L_{i} + 2^{b_{i}})</span>  for nonnegative integers  <span class="math">(a_{i}, b_{i})</span> . Figure 4 depicts compact ranges as subtrees of a binary tree.</p>

    <p class="text-gray-300">Precomputing invariant proofs for just these compact subranges is amortized efficient. The structure of compact subranges – that they start on multiples of powers-of-two and are of length power-of-two – mean that there are only linear (in the number of epochs) such subranges. At epoch  <span class="math">N</span> , there are  <span class="math">\\leq N</span>  compact subranges,  <span class="math">\\sum_{i=1}^{\\lg N} N / 2^i</span> , and the sum of their lengths is  <span class="math">\\leq N \\lg N</span> . Invariant proofs for ranges of length  <span class="math">n</span>  are computed in work linear in  <span class="math">n</span> . Thus, by a classic amortization argument, for an AHD at epoch  <span class="math">N</span> , the total work to compute invariant proofs for all  <span class="math">N</span>  compact subranges can be amortized efficiently to a cost of  <span class="math">O(\\lg N)</span>  for each new published epoch [Ove83].</p>

    <p class="text-gray-300">Given precomputed invariant proofs for compact subranges, a succinct invariant proof can be constructed for any pair of checkpoints  <span class="math">(c_{j}, c_{j+1})</span>  simply by providing the precomputed invariant proofs for each compact subrange in compact range of  <span class="math">(c_{j}, c_{j+1}]</span> . If the invariant is preserved between each sub-range, then it is preserved across the queried checkpoint range. If the AD invariant proofs for the compact subranges are succinct, then the resulting checkpoint invariant proof is also succinct. A protocol description for the  <span class="math">\\mathsf{AHD}_{\\mathsf{Amtz}}</span>  construction is given in Figure 3. We provide only the update and invariant proving logic, as the remaining functionality follows from the same history commitment and AD combination as given in Figure 2. A proof sketch for the invariant soundness of  <span class="math">\\mathsf{AHD}_{\\mathsf{Amtz}}</span>  is given in Appendix F.</p>

    <p class="text-gray-300">In a previous version of this paper, we presented another transform to building an AHD based on Groth16 SNARK aggregation  <span class="math">\\left[\\mathrm{BMM}^{+}21\\right]</span> . We now defer the presentation and evaluation of this approach to Appendix I.</p>

    <p class="text-gray-300">We show here how to use an AHD for the versioned invariant as described above along with a public bulletin board to build a verifiable registry. We consider a single server that maintains a dictionary of key-value mappings within an AHD. The server collects client requests for new mappings or updates to mappings, and incorporates the updates on a regular schedule by updating the AHD and publishing, on a public bulletin board, a (signed) digest  <span class="math">d_{i+1}</span> , where  <span class="math">(d_{i+1}, st) \\gets \\mathsf{Upd}([k_j, v_j]_j : st)</span> . As discussed in Section 2, we assume that all clients have a consistent view of this bulletin board and can efficiently lookup digests by epoch.</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a> Figure 4: Checkpoint epochs for two overlapping ranges; checkpoints are chosen by the compact subranges that span the range. We depict the compact subranges as the minimum complete subtrees to span the left-filled binary tree and select checkpoints as the leading node in the subtree. Two overlapping ranges are guaranteed to share a checkpoint, indicated by the dashed lines.</p>

    <p class="text-gray-300">Client lookups, monitoring, and key updates. Clients can monitor values for keys that they own ensuring no unexpected changes have been made, or clients can lookup the value of other keys in the registry. In our construction, both actions consist of the client simply making a lookup request to the server for the desired key  <span class="math">k</span> . The server responds with the value  <span class="math">\\nu</span>  and version number  <span class="math">u</span>  along with a proof  <span class="math">\\pi</span>  of the lookup for the current epoch  <span class="math">i</span> :  <span class="math">(\\nu, u, \\pi) \\gets \\mathsf{Lkup}(k : st)</span> . The client reads the digest  <span class="math">d_i</span>  from the bulletin board and verifies the proof:  <span class="math">\\mathsf{VerLkup}(d_i, k, \\nu, u, \\pi)</span> . If monitoring, the client additionally checks the returned value and version match the client's stored value and version. Updates to keys proceed similarly. When a client requests a key update from  <span class="math">\\nu</span>  to  <span class="math">\\nu&#x27;</span>  at epoch  <span class="math">i</span> , the server provides the client with a lookup proof for  <span class="math">(\\nu, u)</span>  in  <span class="math">d_i</span>  and a lookup proof for the updated  <span class="math">(\\nu&#x27;, u&#x27;)</span>  incorporated in new  <span class="math">d_{i+1}</span> . The client, again, reads the digests from the bulletin board, verifies the proofs, and checks the version  <span class="math">u</span>  against the stored version for the key. Finally, the client checks  <span class="math">u&#x27; = u + 1</span>  storing the new version number and value for future monitoring.</p>

    <p class="text-gray-300">Assuming the versioned invariant is preserved between all epoch digests published to the bulletin board, these checks are sufficient for convincing a client that (1) any lookups to owned keys made by other clients returned correct values, and (2) any lookups made by the client to other keys either returned correct values or that server misbehavior will be detected the next time the key's owner performs monitoring.</p>

    <p class="text-gray-300">Of course, the client cannot efficiently verify the versioned invariant for the full bulletin board. We solve this by requiring the client to perform a process we call checkpoint auditing, in which the client verifies the invariant is preserved across spe</p>

    <p class="text-gray-300">cific canonical checkpoint epochs. On each operation (lookup, monitoring, or update), the client performs checkpoint auditing for the epoch range  <span class="math">(\\ell, i)</span>  where  <span class="math">\\ell</span>  is the epoch of their last operation ( <span class="math">\\ell = 0</span>  for the client's first operation) and  <span class="math">i</span>  is the epoch of their current operation.</p>

    <p class="text-gray-300">Checkpoint auditing. We make use of the notion of compact ranges from amortized proving in a different context. Clients select checkpoints  <span class="math">[c_j]_j^m</span>  for range  <span class="math">(\\ell, i)</span>  as the endpoints in the compact range representation:  <span class="math">[(c_j, R_j)]_j^m \\gets \\text{CompactR}((\\ell, i))</span>  - this results in a number of checkpoints that is logarithmic in the length of the range. The server proves the invariant is preserved between adjacent checkpoints,  <span class="math">\\pi_{\\Phi} \\gets \\text{Provenv}([c_j]_j^m : st)</span> , which the client can verify after reading the checkpoint digests from the bulletin board. This is however not enough to prevent oscillation attacks (see Section 2). Imagine two clients auditing ranges that always result in disjoint sets of checkpoints: there will be no guarantee the invariant is preserved between digests seen by one client to digests seen by the other.</p>

    <p class="text-gray-300">Our insight, inspired by the deterministic skiplist approach of [MB02], is summarized by the following result:</p>

    <p class="text-gray-300">Theorem 9: (Informal) If two ranges  <span class="math">(\\ell_1, r_1)</span>  and  <span class="math">(\\ell_2, r_2)</span>  are overlapping, i.e.,  <span class="math">\\ell_1 \\leq \\ell_2 &amp;lt; r_1 \\leq r_2</span> , then the two ranges will have at least one shared checkpoint.</p>

    <p class="text-gray-300">We formalize this result (illustrated in Figure 4) and provide a proof in Appendix G.2; a detailed pseudocode diagram of the checkpointing auditing protocol is given in Figure 6. The implication of this result is that two clients that individually perform checkpoint auditing will be guaranteed a shared checkpoint, and further, any deviation by the server from the invariant in the client views up until that checkpoint would have been detected.</p>

    <p class="text-gray-300">The shared checkpoint progresses based on how frequently clients perform audits. More precisely, if a client is served a lookup proof that violates the invariant, it is guaranteed that one of the two clients will detect the inconsistency once each client comes online once more in sequence, i.e., if client A is served a bad lookup value, it will be detected after client B audits next and client A audits again after that. We formalize this guarantee in an eventual detection by checkpoint auditing security property which we prove secure for any AHD under the versioned or append-only invariant. We can illustrate the high level argument for eventual detection through a simple example illustrated in Figure 5. The formal definition and security proof are deferred to Appendix G.</p>

    <p class="text-gray-300">Consider two clients, client A and client B, where client A periodically monitors a key that they own and client B performs lookups and periodic audits. Following Figure 5, consider the following sequence of events:</p>

    <p class="text-gray-300">(1) Client A monitors at  <span class="math">A1</span> . (2) Client B looks up A's key at  <span class="math">B2</span> . (3) Client A monitors at  <span class="math">A3</span>  and  <span class="math">A4</span> .</p>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a> Figure 5: Eventual inconsistency detection for Alice's and Bob's view using shared checkpoints. Large ticks with circle labels indicate points in time where Alice or Bob perform auditing. They verify that the invariant is preserved between consecutive checkpoints selected in the range from their last audit; the checkpoints are indicated by small circles. Checkpoints are chosen to guarantee that any two of Alice and Bob's overlapping audit ranges will share at least one checkpoint, highlighted in green. Thus, the interleaved epochs at which Alice and Bob audit are implicitly guaranteed to preserve the invariant, up until their most recent shared checkpoint. The time at which an epoch is committed to their shared view is indicated on the bottom timeline. The shared checkpoint lags behind the most recent lookups made by Alice and Bob, but will eventually catch up on future lookups.</p>

    <p class="text-gray-300">We address detection of a ghost key attack where the server serves client B a different value at  <span class="math">B2</span>  than what client A expects. Checkpoint auditing guarantees that either client A or B will detect an inconsistency by the next time each have audited in sequence, which, in this case, is when client B audits at  <span class="math">B5</span> . We can see this by considering three ranges that were audited: (1) client B audits range  <span class="math">(0, B2)</span>  on lookup, (2) client A audits range  <span class="math">(A1, A3)</span>  on monitoring, and (3) client B audits range  <span class="math">(B2, B5)</span> . Of these three ranges, we have that  <span class="math">(0, B2)</span>  and  <span class="math">(A1, A3)</span>  are overlapping and that  <span class="math">(A1, A3)</span>  and  <span class="math">(B2, B5)</span>  are overlapping. Then by Theorem 9, we have the existence of checkpoints  <span class="math">C1</span>  and  <span class="math">C2</span>  such that invariant proofs for the following paths were checked during each audit respectively: (1)  <span class="math">0 \\rightarrow C1 \\rightarrow B2</span> , (2)  <span class="math">A1 \\rightarrow C1 \\rightarrow C2 \\rightarrow A3</span> , and (3)  <span class="math">B2 \\rightarrow C2 \\rightarrow B5</span> . Put together, we have invariant proofs for the following path, implying that the invariant is preserved from  <span class="math">A1 \\rightarrow B2 \\rightarrow A3</span> :</p>

    <div class="my-4 text-center"><span class="math-block">A 1 \\rightarrow C 1 \\rightarrow B 2 \\rightarrow C 2 \\rightarrow A 3.</span></div>

    <p class="text-gray-300">Now consider for the versioned invariant, client A monitors for expected value and version  <span class="math">(\\nu ,u)</span>  at  <span class="math">A1</span>  and  <span class="math">A3</span> . Since the invariant is preserved from  <span class="math">A1\\rightarrow B2</span> , it must be that the value  <span class="math">(\\nu^{\\prime},u^{\\prime})</span>  served to client B cannot be different  <span class="math">(\\nu^{\\prime}\\neq \\nu)</span>  unless the version number has increased  <span class="math">u^{\\prime} &amp;gt; u</span> . Similarly, from  <span class="math">B2\\to A3</span> , since the invariant is preserved, if  <span class="math">\\nu^{\\prime}\\neq \\nu</span> , it must be that  <span class="math">u &amp;gt; u^{\\prime}</span> . This is a contradiction, so this inconsistency will either be caught by failure to verify client A's lookup of  <span class="math">(\\nu ,u)</span>  during monitoring or by failure to verify an invariant proof for one of the three audits. It is clear that this argument can be extended to any pair of clients.</p>

    <p class="text-gray-300">Lastly, we note the interplay between checkpoint auditing and  <span class="math">\\mathrm{AHD}_{\\mathrm{Amtz}}</span> . Since the format of checkpoints that are passed to Provelnv are already compact subranges, the invariant proof for each pair of checkpoints consists of a single precomputed proof, instead of a logarithmic sequence of proofs. This results in proof sizes for checkpoint auditing to be of size  <span class="math">\\mathcal{O}(\\log N)</span>  as opposed to  <span class="math">\\mathcal{O}(\\log^2 N)</span>  for range length  <span class="math">N</span> .</p>

    <p class="text-gray-300">We implement our proposed constructions in Rust. Our implementation consists of a number of modular parts (following Figure 1). We define a generic authenticated dictionary interface that supports versioned invariant update proofs for consecutive epochs, and an accompanying interface for generating SNARK constraints for verification of the update proof. We then implement our two generic transforms, IVC (Figure 2) and amortized proving (Figure 3), to take an object implementing the authenticated dictionary interface and produce an object implementing a defined authenticated history dictionary interface. Lastly, given an object implementing the AHD interface, we instantiate a verifiable registry service exposing a RESTful API for key lookups, key updates, and client checkpoint auditing (Figure 6). The service is backed by an in-memory Redis datastore. In total, our implementation consists of  <span class="math">\\approx 12000</span>  lines of code and is available open source  <span class="math">^{5}</span> .</p>

    <p class="text-gray-300">The constraints and generic IVC transform are implemented within the arkworks ecosystem for SNARKs [BCG+20] and make use of the SNARK implementations from arkworks. We instantiate and evaluate the recursion constructions on [Gro16] over the MNT4-753 and MNT6-753 pairing-friendly cycle of curves to target 128 bits of security. This choice of SNARK requires a trusted setup and results in a state-of-the-art constant proof size; however, other general-purpose recursive SNARKs [Set20, CHM+20, BCMS20, BDFG21] can be swapped in with different trade-offs in setup assumptions, proving costs, and proof size. Ultimately, looking forward to evaluation, we will be interested in the difference between SNARK proving costs for verifying the Merkle tree AD update proof versus the RSA AD update proof. We expect the proving cost ratio to be comparable across SNARKS as it is dependent on the ratio of circuit constraints.</p>

    <p class="text-gray-300">VeRSA constructions. We build our two VeRSA variants</p>

    <p class="text-gray-300">Protocol: Client Checkpoint Auditing Init: The client pulls the public parameters  <span class="math">pp_{\\mathrm{AHD}}</span>  from the registry server and verifies against the bulletin board. The client initializes its state as follows:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">(\\ell, d_{\\ell})</span> : latest epoch and digest audited with registry.</li>

      <li><span class="math">(\\ell&#x27;, d_{\\ell}&#x27;)</span> : (optional) latest epoch and digest audited with public bulletin board.</li>

      <li><span class="math">T[k] = (v, u)</span> : table of owned keys and expected values to monitor.</li>

    </ul>

    <p class="text-gray-300">Audit: Verify consistent view and invariant preservation (1) Client computes current epoch  <span class="math">i</span>  (deterministically computed from clock). (2) Client computes checkpoint epochs  <span class="math">[c_j]_j^m</span>  for range  <span class="math">(\\ell, i)</span> : <span class="math">[(c_j, R_j)]_j^m \\gets \\text{CompactR}((\\ell, i))</span> . (3) Client reads digests  <span class="math">[d_{c_j}]_j^m</span>  for checkpoint epochs (2 options). (a) Client reads directly from public bulletin board. (b) (Optional) Client reads digests from server, and lazily confirms with public bulletin board.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Server provides checkpoint digests and history proof, which client verifies:  <span class="math">\\pi_{\\mathrm{hist}} \\gets \\mathrm{AHD}.\\mathrm{ProveHist}(([c_j]_j^m : st_i))</span> .</li>

      <li>At some later epoch  <span class="math">t &amp;gt; i</span> , client reads digest  <span class="math">d_t</span>  from the public bulletin board, and requests and verifies a history proof for checkpoints  <span class="math">[\\ell&#x27;, t]</span>  from the server.</li>

      <li>Client updates state  <span class="math">(\\ell&#x27;, d_{\\ell}&#x27;) \\gets (t, d_t)</span> .</li>

    </ul>

    <p class="text-gray-300">(4) Client requests and verifies invariant proof for checkpoints from server: <span class="math">\\pi_{\\Phi} \\gets \\mathrm{AHD}.\\mathrm{ProveInv}([c_j]_j^m : st_i), \\quad \\mathrm{VerInv}(d_i, [(c_j, d_{c_j})]_j^m, \\pi_{\\Phi})</span> . (5) Client updates state  <span class="math">(i, d_i) \\gets (\\ell, d_\\ell)</span> . Lookup: Authenticated lookup of key  <span class="math">k</span> (1) Client performs audit to current epoch  <span class="math">i</span> . (2) Client requests and verifies lookup proof for audited epoch  <span class="math">i</span>  from server: <span class="math">(v, \\pi_{\\mathrm{lkup}}) \\gets \\mathrm{Lkup}(k : st_i), \\quad \\mathrm{VerLkup}(d_i, k, v, \\pi_{\\mathrm{lkup}})</span> . Monitor: Monitor owned keys in  <span class="math">T</span>  for unexpected changes (1) Client performs audit to current epoch  <span class="math">i</span> . (2) For each  <span class="math">[(k_j, v_j, u_j)]_j \\in T</span> : (a) Client performs lookup of  <span class="math">k_j</span>  receiving value  <span class="math">(\\hat{v}, \\hat{u})</span> . (b) Client verifies  <span class="math">(v_j, u_j) = (\\hat{v}, \\hat{u})</span> . Update: Update value for key  <span class="math">k</span>  from  <span class="math">v</span>  to  <span class="math">v&#x27;</span> . (1) Server confirms update was included in epoch  <span class="math">i + 1</span> . (2) Client audits to epoch  <span class="math">i</span>  and again from  <span class="math">i</span>  to  <span class="math">i + 1</span> . (3) Client performs lookup of  <span class="math">k</span>  for epoch  <span class="math">i</span>  receiving  <span class="math">(\\hat{v},\\hat{u})</span>  and verifying  <span class="math">(v,u) = (\\hat{v},\\hat{u})</span> . (4) Client performs lookup of  <span class="math">k</span>  for epoch  <span class="math">i + 1</span>  receiving  <span class="math">(\\hat{v}&#x27;, \\hat{u}&#x27;)</span>  and verifying  <span class="math">(v&#x27;, u + 1) = (\\hat{v}&#x27;, \\hat{u}&#x27;)</span> . (5) Client updates  <span class="math">T[k] = (v&#x27;, u + 1)</span> .</p>

    <p class="text-gray-300">Figure 6: Description of the continuous client auditing protocol that enables eventual inconsistency detection between clients. The registry server maintains an AHD under the versioned invariant.</p>

    <p class="text-gray-300">using the described modular implementation. First we implement the KVaC RSA AD [AR20] along with our proposed update proof (Section 4) following the proof of homomorphism over hidden order groups [BBF19]. We instantiate the construction with an RSA group of 2048 bits. We further imple</p>

    <p class="text-gray-300">ment SNARK constraints for verification of the update proof; the constraints make use of optimizations for multiprecision arithmetic [KPS18] and hashing to primes [OWWB20]. VeRSA-IVC is the registry resulting from the modular IVC transform and VeRSA-Amtz is the registry from the amortized proving transform. Our RSA constructions require a hidden-order RSA group from a trusted setup; while not ideal, academic work  <span class="math">\\mathrm{[CHI^{+}21,BGG18,BGM17]}</span>  has suggested that large-scale multi-party setup ceremonies can be conducted in practice. Class groups [BW88] provide an alternate tack to constructing a hidden-order group without trusted setup, but would significantly hinder performance.</p>

    <p class="text-gray-300">Baselines. To evaluate our VeRSA constructions, we compare to verifiable registries based on Merkle tree ADs. We implement a Merkle tree AD supporting versioned invariant proofs (see Appendix A). The first baseline, which we denote as MT-VR, is the verifiable registry not designed for efficient client auditability in which update proofs for each consecutive epoch must be checked, either by the client or a trusted auditor party. The performance characteristics of MT-VR represent a set of previous work, most closely being CONIKS  <span class="math">\\left[\\mathrm{MBB}^{+}15\\right]</span> , but also sharing structure with SEEMless [CDGM19] and Mog  <span class="math">\\left[\\mathrm{MKL}^{+}20\\right]</span> . The second baseline we consider is the verifiable registry resulting from applying the IVC transform to the Merkle tree AD, which we denote MT-VR-IVC. While we use this construction as a baseline, as it has been proposed abstractly in concurrent work [CCDW20], we note, to the best of our knowledge, ours is the first implementation of this approach. Further, the implementation was non-trivial. Namely, we implement constraints for the Merkle tree AD. We introduce a new "open addressing" approach to the Merkle tree AD construction that optimizes the update proof constraint size by shortening the depth of the tree; see Appendix B. We set the height of the Merkle tree to 32, which with our open addressing optimization can support  <span class="math">2^{30}</span>  keys, and instantiate the hash function with the Poseidon algebraic hash function  <span class="math">\\left[\\mathrm{GKK}^{+}19\\right]</span>  for MT-VR-IVC and with SHA3 for MT-VR.</p>

    <p class="text-gray-300">We wish to answer the following questions about VeRSA-IVC and VeRSA-Amtz in comparison to the Merkle tree baselines:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Client auditing costs: What are the bandwidth and computation costs for a client to audit a range of epochs?</li>

      <li>Server update costs: What are the computation costs for the server to incorporate key updates and publish a new epoch digest? At what latency can new digests be published; supporting what key update throughput?</li>

      <li>Lookup costs: What are the bandwidth and computation costs for key lookups?</li>

    </ul>

    <p class="text-gray-300">Experimental setup. We benchmark our constructions using</p>

    <p class="text-gray-300">!<a href="img-3.jpeg">img-3.jpeg</a> Figure 7: Client auditing costs. The size (left) and verification time (right) of invariant proofs for varying epoch range lengths.</p>

    <p class="text-gray-300">!<a href="img-4.jpeg">img-4.jpeg</a></p>

    <p class="text-gray-300">an Amazon EC2 r5.16xlarge instance with 32 CPU cores and 512 GB memory. Client computation is evaluated single-threaded, and network costs of gathering client input are not evaluated; our experiments simulate client input, generating random requests of the appropriate size.</p>

    <p class="text-gray-300">VeRSA-Amtz grows in update cost over the history of the registry due to increasing amortized costs of proving. We present the amortized costs of proving for epoch  <span class="math">2^{k}</span>  by averaging the proving costs incurred between the  <span class="math">2^{k-1}</span>  updates from epoch  <span class="math">2^{k-1} + 1</span>  to  <span class="math">2^{k}</span> . While these proving costs occur in spikes over the range, VeRSA-Amtz is not delayed by the need to complete an expensive proof for a large range; the invariant proofs can be computed in the background and audits can still be fulfilled (see further discussion on parallelism in Section 8.2). Therefore, we believe reporting the amortized costs in this manner leads to a fair evaluation.</p>

    <p class="text-gray-300">We contrast the auditing costs in terms of proof size and verification time for different lengths of audit ranges; the results are shown in Figure 7. MT-VR-IVC, VeRSA-IVC, and VeRSA-Amtz have client auditing costs that scale logarithmically in the length of the audit range. Note, the IVC constructions' proof size and verification costs would become truly constant were they instantiated in the auditing model where a third-party verifies the hashchain. In any case, the costs among the client-auditable constructions, VeRSA and MT-VR-IVC, are comparable. The proof sizes, even for large epoch ranges, remain under  <span class="math">20\\mathrm{KB}</span> , and proofs are verified in under  <span class="math">100\\mathrm{ms}</span> .</p>

    <p class="text-gray-300">The naive comparison for client auditing costs is the baseline MT-VR in which clients (or trusted auditors) must perform linear work auditing every consecutive epoch. Against MT-VR, for an epoch range of length 32, client bandwidth costs are  <span class="math">10^{3} \\times</span>  lower and verification time is  <span class="math">10 \\times</span>  lower. For epoch ranges of length 1000, the improvement grows to  <span class="math">10^{5} \\times</span>  lower for bandwidth costs and  <span class="math">10^{3} \\times</span>  lower for verification time. In context, with an epoch publishing time of 5 minutes, auditing at epoch ranges of length 32 and 1000 correspond to a client auditing every 3 hours or twice a week, respectively.</p>

    <p class="text-gray-300">Building efficiently auditable proofs for clients adds significant computational costs to the server. We investigate what levels of key update throughput are achievable and at what latency. To anchor our evaluation, we set a target of  <span class="math">\\approx 60</span>  key updates per second based on current statistics from the certificate transparency ecosystem [Clo20].</p>

    <p class="text-gray-300">Figure 8 shows the latency to prove an epoch update depending on how many key updates are made in the epoch. The throughput is computed as the number of key updates divided by latency. At a high level, we find that VeRSA-IVC and VeRSA-Amtz can both achieve throughput levels  <span class="math">&amp;gt;60</span>  key updates per second, while MT-VR-IVC achieves only  <span class="math">\\approx 1</span>  key update per second under the tested computation resources; we discuss how throughput can be increased through increased parallelism later.</p>

    <p class="text-gray-300">However, for VeRSA-IVC to achieve a throughput of 60 key updates per second, epochs are published at a latency of  <span class="math">\\approx 30</span>  minutes. This is because of the large constant cost of verifying the RSA AD update proof within a circuit. This cost is incurred per epoch update no matter how many key updates are included, but the incremental cost of including more key updates is minimal as they do not increase the dominating cost of proving the SNARK. Thus, the throughput of VeRSA-IVC increases when more key updates are batched together. At its limit, we can extrapolate from our experiments that the throughput will cap out at  <span class="math">\\approx 400</span>  key updates per second due to costs of performing RSA exponentiation and computing the algebraic invariant proof (outside of the SNARK).</p>

    <p class="text-gray-300">On the other hand, the throughput of VeRSA-Amtz is not affected by the number of key updates in an epoch; the latency is directly proportional to the number of key updates. VeRSA-Amtz achieves a throughput of  <span class="math">\\approx 90</span>  key updates per second while supporting publishing digests at low latencies. So while VeRSA-IVC can achieve higher throughput than VeRSA-Amtz, it would require a significantly higher latency that may not be suitable for some deployments — extrapolated results indicate VeRSA-IVC to surpass VeRSA-Amtz in throughput at a latency of 50 minutes. In contrast to MT-VR, which achieves a throughput of 40,000 key updates per second but does not produce efficiently auditable proofs, our VeRSA systems incur a  <span class="math">\\approx 480\\times</span>  proving overhead.</p>

    <p class="text-gray-300">Lastly, in terms of persistent storage, VeRSA-Amtz incurs 1123 B per epoch, and VeRSA-IVC and MT-VR-IVC incur (on average) just 64 B per epoch for the history tree vector commitment.</p>

    <p class="text-gray-300">Improving throughput via parallelism. The dominant cost for the IVC constructions (VeRSA-IVC and MT-VR-IVC) is the SNARK proving time, and it has been shown that SNARK proving work is highly parallelizable  <span class="math">\\left[\\mathrm{WZC}^{+}18\\right]</span> . Thus, we would expect the throughput of the IVC constructions to increase more-or-less directly with increased computation resources. Figure 9 (left) shows the number of constraints to be</p>

    <p class="text-gray-300">!<a href="img-5.jpeg">img-5.jpeg</a> Figure 8: Server epoch update costs plotting the epoch update latency varying the number of key updates batched in the epoch. The key update throughput is computed as the number of key updates per epoch divided by the epoch latency. MT-VR-IVC measurements are truncated due to running out-of-memory on the benchmark machine.</p>

    <p class="text-gray-300">!<a href="img-6.jpeg">img-6.jpeg</a> Figure 9: (Left) The number of constraints in the SNARK circuit for varying number of key updates. (Right) The epoch latency (dominated by the SNARK proving time) for different levels of hardware parallelism.</p>

    <p class="text-gray-300">!<a href="img-7.jpeg">img-7.jpeg</a></p>

    <p class="text-gray-300">proved in the SNARK circuit for different numbers of key updates batched per epoch. The RSA circuit is of constant size, just under 20M constraints. The MT circuit grows linearly with the number of key updates,  <span class="math">\\approx 20,000</span>  constraints per key update. We demonstrate the parallelism of the workload by measuring epoch update latency using different numbers of physical cores, shown in Figure 9 (right). For the circuit sizes evaluated, doubling the number of processors halves the epoch latency up until between 16 and 32 processors where the marginal benefits of adding more processors decreases. Larger circuit sizes, e.g. by adding more key updates to the MT constructions, will continue to benefit from increased processors [WZC+18].</p>

    <p class="text-gray-300">In VeRSA-Amtz, the dominant cost consists of proving invariant proofs for large subranges over the registry's life. While proving a single invariant proof (Wesolowski proof of homomorphism [Wes19, BBF19]) is mostly a sequential task, at any one time there will be approximately  <span class="math">\\log N</span>  (for  <span class="math">N</span>  total epochs) such invariant proofs being proved in the background, one for each subrange length. These tasks can be easily parallelized given  <span class="math">\\log N</span>  processors such that the epoch update cost for VeRSA-Amtz is constant instead of logarithmically increasing over time. It is reasonable to assume computational resources supporting  <span class="math">\\log N</span>  parallelism. For example, in our experiments with 32 cores, it would take a registry publishing epochs at 5 minute latency thousands of years to reach  <span class="math">2^{32}</span>  epochs.</p>

    <p class="text-gray-300">Improving throughput via sharding. A second way to increase throughput is by sharding the key space and running</p>

    <p class="text-gray-300">!<a href="img-8.jpeg">img-8.jpeg</a> Figure 10: (Left) Batch computation of RSA membership proofs for varying levels of hardware parallelism. (Middle) Update computation of an individual RSA membership proof over a range of key updates. (Right) Verification costs of RSA membership proofs with respect to version number of entry.</p>

    <p class="text-gray-300">!<a href="img-9.jpeg">img-9.jpeg</a></p>

    <p class="text-gray-300">!<a href="img-10.jpeg">img-10.jpeg</a></p>

    <p class="text-gray-300">separate instances of a verifiable registry. If perfectly sharded, i.e., key updates are evenly distributed across shards, then the throughput of the system is expected to increase proportionally to the number of shards (assuming the total computing resources are also increased proportionally). However, client auditing costs will increase proportionally: clients must audit each shard assuming keys are distributed randomly across shards. If we can guarantee that each client will only be interacting with a small number of shards, then the throughput gains of sharding may come with little increase in client cost.</p>

    <p class="text-gray-300">The VeRSA constructions achieve higher key update throughput than Merkle tree solutions, however they also incur large costs for computing membership proofs for key lookups. In Section 4 and Appendix E, we describe techniques for batch membership proof computation to manage these costs. We evaluate these costs and find that VeRSA can reasonably compute lookup proofs for registries storing on the order of millions of keys, however for hundreds of millions or billions of keys, the costs of producing timely lookup proofs are infeasible. In contrast, producing lookup proofs for Merkle tree registries is extremely low cost (order of milliseconds) even for registries with billions of keys.</p>

    <p class="text-gray-300">Figure 10 (left) shows the time to compute all membership proofs for a batch of keys. As a concrete example, consider a registry with 1 million keys: Figure 10 indicates that membership proofs for all keys can be computed using a single thread every  <span class="math">\\approx 3</span>  hours. In the time between batch computations, membership proofs become outdated as the registry updates, and if queried must be updated individually. Figure 10 (right) shows the cost of updating a single membership proof with respect to the number of key updates made to the registry. With an update throughput of 60 key updates per second, in the 3 hour batch update cycle of our example,  <span class="math">\\approx 2^{13}</span>  key updates are made, which can be individually applied to respond to a lookup proof in  <span class="math">\\approx 10</span>  seconds. This strategy does not incur any storage overhead on top of the storage of the lookup proofs themselves. More advanced caching strategies for batch updating frequently queried keys may be employed to further improve lookup costs (see Appendix E). Nonmembership</p>

    <p class="text-gray-300">proofs for lookups of all possible non-member keys cannot be precomputed efficiently and must be responded to in a delayed fashion by batch computation of a set of non-member lookups together on some schedule.</p>

    <p class="text-gray-300">Lookup proofs are small and of constant size: <span class="math">0.8</span> KB for VeRSA, comparable to the <span class="math">1</span> KB proof sizes of MT-VR. For MT-VR-IVC, the open addressing optimization (Appendix B) increases the size of the lookup proof in the worst case proportionally by the maximum nonce <span class="math">\\omega</span> (<span class="math">16</span> KB for <span class="math">\\omega=16</span>). Figure 10 plots the verification time of a lookup proof with respect to the version number. Verification increases linearly with version number because the verifier must compute an RSA exponentiation to an exponent of the form <span class="math">\\mathsf{H}(k)^{u}</span>. Despite this trend, we find that the cost of verification remains feasible for clients if version numbers do not get too large (<span class="math">&lt;1</span> second for version numbers less than 1000). We believe this range of version numbers is reasonable for our envisioned applications of binary transparency and PKI for E2EE messaging. As an example for a potential application of binary transparency, we crawled version history for a random sample of 1000 software packages available in the Ubuntu 22.04 main repository. These packages had a mean of 3.4 versions (median 3), with a maximum value of 20. We also manually recorded the version history of the ten most popular apps on the iOS App Store finding a median of 52.5 (maximum of 127) versions published in 2021. If a setting must support large version numbers <span class="math">u</span>, we provide details for a dictionary variant that increases lookup proof size by <span class="math">\\log_{t}u</span> for some branching factor <span class="math">t</span> but allows for verification in time <span class="math">\\log_{t}\\times</span> the time to verify a constant-size lookup proof of version <span class="math">t</span> (see Appendix E.4).</p>

    <h2 id="sec-19" class="text-2xl font-bold">9 Related Work</h2>

    <p class="text-gray-300">Registries from Merkle trees. Most previous proposals for verifiable registries (under various names) are constructed via Merkle trees and require auditors to do work linear in the total number of updates to the registry per epoch (at least one Merkle path verification per update) <em>[BCK^{+}14, KHP^{+}13, Lau14, Rya14, CDGM19, MBB^{+}15, MKL^{+}20]</em>. An exception is Merkle^{2} <em>[HHK^{+}21]</em> which reduces the per-epoch work of auditors to be logarithmic in the number of key updates; auditors verify a single Merkle extension proof. Merkle^{2} fundamentally relies on a stronger assumption called signature chains in which key updates must be signed by an authorization key not controlled by the server. This security policy does not allow users to recover if the authorization key is lost or compromised and hence may not be suitable for some deployments. In fact, in typical end-user applications it is a requirement that the server can unilaterally change a user’s public key – a property needed for users to recover access if they lose their current device (and private keys) <em>[MBB^{+}15, BBG^{+}20]</em>. We note that in applications where this restricted key update policy is applicable, Merkle^{2} can be adapted using our amortized proving transform along with checkpoint auditing to construct an extremely efficient registry supporting efficient client audits (given a bulletin board); the Merkle extension proofs provide succinct invariant proofs for AD updates.</p>

    <p class="text-gray-300">Privacy of registry contents has also been considered in prior work. Techniques to keep lookup keys private using verifiable random functions and lookup values private using commitments <em>[MBB^{+}15, EMBB17]</em> can be adapted directly to all of our constructions. While we do not consider other privacy notions such as hiding total directory size and update patterns <em>[CDGM19]</em>, RSA accumulators may be better suited to this task than Merkle trees <em>[BCD^{+}17]</em>; we leave further investigation to future work.</p>

    <p class="text-gray-300">Registries from algebraic accumulators. There are a few proposals using non-Merkle-based ADs. <em>[TBP^{+}19]</em> and Aardvark <em>[LGG^{+}20]</em> use bilinear pairing-based accumulators: <em>[TBP^{+}19]</em> admits succinct invariant proofs (logarithmic in the number of updates) which makes it a candidate for our amortized proving transform, however it is concretely expensive, while Aardvark, like Merkle-based approaches, provides linear invariant proofs (Aardvark improves parallelism of updates). RSA accumulators have also been proposed to construct registries with constant-sized verification work per epoch <em>[BBF19, TXN20]</em>. <em>[BBF19]</em> is not concretely efficient, requiring dictionary values to be committed bit-by-bit. <em>[TXN20]</em> propose a construction similar to <em>[AR20]</em> (both building on the line of work of <em>[CF13, LM19]</em>) but with two downsides: (1) Updating the digest requires computing an update hint which is similar in complexity to lookup proofs, and (2) the proposed invariant proof verifies that a dictionary contains a superset of keys of another dictionary, but does not verify properties about the mapped values of keys over time (a property necessary for our applications). In contrast, we build on the RSA AD of <em>[AR20]</em> which does not require update hints, and we propose invariant proofs for the versioned and append-only invariants allowing verifiable updates of a key’s mapped value.</p>

    <p class="text-gray-300">Regarding proving updates of values, <em>[OWWB20]</em> and <em>[CFH^{+}21]</em> provide techniques for proving batch updates to an RSA accumulator with respect to a committed batch. <em>[CFH^{+}21]</em> improves over <em>[OWWB20]</em> by moving expensive linear-in-batch-size computation “out of” the generic SNARK. In our treatment of the verifiable registry setting, it is not necessary to prove that a specific set of keys were updated at each epoch (with respect to a committed batch of keys), rather only that all keys preserve the update invariant. Were this property desired, it may be possible to adapt these techniques to the authenticated dictionary primitive.</p>

    <p class="text-gray-300">Applying SNARKs to registries. Verifiable computation <em>[BFR^{+}13, LNS20, SAGL18]</em> using SNARKs has also been proposed to lower per-epoch auditing costs by either (1) producing a succinct proof attesting to the updates for each epoch (so-called ZK rollups) <em>[But, WGH^{+}, SSV21]</em> or</p>

    <p class="text-gray-300">(2) producing a recursive proof attesting to updates across all epochs committed in a hash chain <em>[x13, x32]</em>. These approaches require per-epoch auditors to perform only a SNARK verification or a simple hash verification, respectively. (Verdict <em>[x32]</em> requires an inexpensive constraint accumulation check in addition to hash verification.) Swapping in our RSA AD (and invariant proof) over a Merkle-based AD would result in a smaller SNARK circuit encoding and more efficient proving for all of these approaches.</p>

    <p class="text-gray-300">Finally, we note that while our focus has been on client-auditability, the succinct proofs provided by the above SNARK-based approaches or our new RSA AD approach may also be beneficial in making third-party auditing much more efficient. For example, per-epoch auditing may be inexpensive enough to run as a smart contract on a public blockchain. We leave a full evaluation of this setup to future work.</p>

    <h2 id="sec-20" class="text-2xl font-bold">Acknowledgments</h2>

    <p class="text-gray-300">Nirvan Tyagi was supported by a Facebook Graduate Research Fellowship, and part of his work took place while a visiting student at the University of Washington. Ben Fisch was funded by NSF, DARPA, and a grant from ONR. Andrew Zitek was supported by NSF grant CNS-1940713. Joseph Bonneau was supported by DARPA under Agreement HR00112020022 and NSF grant CNS-1940713. Stefano Tessaro was supported by NSF grants CNS-1930117 (CAREER), CNS-2026774, CNS-2154174, a JP Morgan Faculty Award, a CISCO Faculty Award, and a gift from Microsoft. Any opinions, findings and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the United States Government or DARPA.</p>

    <h2 id="sec-21" class="text-2xl font-bold">References</h2>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[AM18] Mustafa Al-Bassam and Sarah Meiklejohn. Contour: A practical system for binary transparency. 11025:94–110, 2018.</li>

      <li>[AR20] Shashank Agrawal and Srinivasan Raghuraman. KVaC: Key-value commitments for blockchains and beyond. In ASIACRYPT (3), volume 12493 of Lecture Notes in Computer Science, pages 839–869. Springer, 2020.</li>

      <li>[ASB^{+}17] Ruba Abu-Salma, M. Angela Sasse, Joseph Bonneau, Anastasia Danilova, Alena Naiakshina, and Matthew Smith. Obstacles to the adoption of secure communication tools. In IEEE Symposium on Security and Privacy, pages 137–153. IEEE Computer Society, 2017.</li>

      <li>[BBF19] Dan Boneh, Benedikt Bünz, and Ben Fisch. Batching techniques for accumulators with applications to iops and stateless blockchains. In CRYPTO (1), volume 11692 of Lecture Notes in Computer Science, pages 561–586. Springer, 2019.</li>

      <li>[BBG^{+}20] Josh Blum, Simon Booth, Oded Gal, Maxwell Krohn, Julia Len, Karan Lyons, Antonio Marcedone, Mike Maxim, Merry Ember Mou, Jack O’Connor, et al. E2e encryption for zoom meetings, 2020.</li>

      <li>[BBHR19] Eli Ben-Sasson, Iddo Bentov, Yinon Horesh, and Michael Riabzev. Scalable zero knowledge with no trusted setup. In CRYPTO (3), volume 11694 of Lecture Notes in Computer Science, pages 701–732. Springer, 2019.</li>

      <li>[BCCT13] Nir Bitansky, Ran Canetti, Alessandro Chiesa, and Eran Tromer. Recursive composition and bootstrapping for SNARKS and proof-carrying data. In STOC, pages 111–120. ACM, 2013.</li>

      <li>[BCD^{+}17] Foteini Baldimtsi, Jan Camenisch, Maria Dubovitskaya, Anna Lysyanskaya, Leonid Reyzin, Kai Samelin, and Sophia Yakoubov. Accumulators with applications to anonymity-preserving revocation. In EuroS&P, pages 301–315. IEEE, 2017.</li>

      <li>[BCG^{+}20] Sean Bowe, Alessandro Chiesa, Matthew Green, Ian Miers, Pratyush Mishra, and Howard Wu. ZEXE: enabling decentralized private computation. In IEEE Symposium on Security and Privacy, pages 947–964. IEEE, 2020.</li>

      <li>[BCK^{+}14] David A. Basin, Cas J. F. Cremers, Tiffany Hyun-Jin Kim, Adrian Perrig, Ralf Sasse, and Pawel Szalachowski. ARPKI: attack resilient public-key infrastructure. In CCS, pages 382–393. ACM, 2014.</li>

      <li>[BCMS20] Benedikt Bünz, Alessandro Chiesa, Pratyush Mishra, and Nicholas Spooner. Recursive proof composition from accumulation schemes. In TCC (2), volume 12551 of Lecture Notes in Computer Science, pages 1–18. Springer, 2020.</li>

      <li>[BCTV14] Eli Ben-Sasson, Alessandro Chiesa, Eran Tromer, and Madars Virza. Scalable zero knowledge via cycles of elliptic curves. In CRYPTO (2), volume 8617 of Lecture Notes in Computer Science, pages 276–294. Springer, 2014.</li>

      <li>[BDFG21] Dan Boneh, Justin Drake, Ben Fisch, and Ariel Gabizon. Halo infinite: Proof-carrying data from additive polynomial commitments. In CRYPTO (1), volume 12825 of Lecture Notes in Computer Science, pages 649–680. Springer, 2021.</li>

      <li>[Ben87] Josh Daniel Cohen Benaloh. Verifiable Secret-Ballot Elections. PhD thesis, Yale University, USA, 1987.</li>

      <li>[BFR^{+}13] Benjamin Braun, Ariel J. Feldman, Zuocheng Ren, Srinath T. V. Setty, Andrew J. Blumberg, and Michael Walfish. Verifying computations with state. In SOSP, pages 341–357. ACM, 2013.</li>

      <li>[BFS20] Benedikt Bünz, Ben Fisch, and Alan Szepieniec. Transparent snarks from DARK compilers. In EUROCRYPT (1), volume 12105 of Lecture Notes in Computer Science, pages 677–706. Springer, 2020.</li>

      <li>[BGG18] Sean Bowe, Ariel Gabizon, and Matthew D. Green. A multi-party protocol for constructing the public parameters of the pinocchio zk-snark. In Financial Cryptography Workshops, volume 10958 of Lecture Notes in Computer Science, pages 64–77. Springer, 2018.</li>

      <li>[BGH19] Sean Bowe, Jack Grigg, and Daira Hopwood. Halo: Recursive proof composition without a trusted setup. IACR Cryptol. ePrint Arch., 2019:1021, 2019.</li>

      <li>[BGM17] Sean Bowe, Ariel Gabizon, and Ian Miers. Scalable multi-party computation for zk-snark parameters in the random beacon model. IACR Cryptol. ePrint Arch., 2017:1050, 2017.</li>

      <li>[BKLZ20] Benedikt Bünz, Lucianna Kiffer, Loi Luu, and Mahdi Zamani. Flyclient: Super-light clients for cryptocurrencies. In IEEE Symposium on Security and Privacy, pages 928–946. IEEE, 2020.</li>

      <li>[BMM^{+}21] Benedikt Bünz, Mary Maller, Pratyush Mishra, Nirvan Tyagi, and Psi Vesely. Proofs for inner pairing products and applications. In ASIACRYPT (3), volume 13092 of Lecture Notes in Computer Science, pages 65–97. Springer, 2021.</li>

      <li>[Bon16] Joseph Bonneau. Ethiks: Using ethereum to audit a CONIKS key transparency log. In Financial Cryptography Workshops, volume 9604 of Lecture Notes in Computer Science, pages 95–105. Springer, 2016.</li>

      <li>[But] Vitalik Buterin. The dawn of hybrid layer 2 protocols. https://vitalik.ca/general/2019/08/28/hybrid_layer_2.html.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[BW88] Johannes Buchmann and Hugh C. Williams. A key-exchange system based on imaginary quadratic fields. J. Cryptol., 1(2):107–118, 1988.</li>

      <li>[CBM15] Henry Corrigan-Gibbs, Dan Boneh, and David Mazières. Riposte: An anonymous messaging system handling millions of users. In IEEE Symposium on Security and Privacy, pages 321–338. IEEE Computer Society, 2015.</li>

      <li>[CCDW20] Weikeng Chen, Alessandro Chiesa, Emma Dauterman, and Nicholas P. Ward. Reducing participation costs via incremental verification for ledger systems. IACR Cryptol. ePrint Arch., 2020:1522, 2020.</li>

      <li>[CDGM19] Melissa Chase, Apoorvaa Deshpande, Esha Ghosh, and Harjasleen Malvai. Seemless: Secure end-to-end encrypted messaging with less trust. In CCS, pages 1639–1656. ACM, 2019.</li>

      <li>[CDR14] Vincent Cheval, Stéphanie Delaune, and Mark Ryan. Tests for establishing security properties. In TGC, volume 8902 of Lecture Notes in Computer Science, pages 82–96. Springer, 2014.</li>

      <li>[CF13] Dario Catalano and Dario Fiore. Vector commitments and their applications. In Public Key Cryptography, volume 7778 of Lecture Notes in Computer Science, pages 55–72. Springer, 2013.</li>

      <li>[CFH^{+}21] Matteo Campanelli, Dario Fiore, Semin Han, Jihye Kim, Dimitris Kolonelos, and Hyunok Oh. Succinct zero-knowledge batch proofs for set accumulators. IACR Cryptol. ePrint Arch., page 1672, 2021.</li>

      <li>[CGJ^{+}17] Arka Rai Choudhuri, Matthew Green, Abhishek Jain, Gabriel Kaptchuk, and Ian Miers. Fairness in an unfair world: Fair multiparty computation from public bulletin boards. In CCS, pages 719–728. ACM, 2017.</li>

      <li>[CHI^{+}21] Megan Chen, Carmit Hazay, Yuval Ishai, Yuriy Kashnikov, Daniele Micciancio, Tarik Riviere, Abhi Shelat, Muthu Venkitasubramaniam, and Ruihan Wang. Diogenes: Lightweight scalable RSA modulus generation with a dishonest majority. In IEEE Symposium on Security and Privacy, pages 590–607. IEEE, 2021.</li>

      <li>[CHM^{+}20] Alessandro Chiesa, Yuncong Hu, Mary Maller, Pratyush Mishra, Noah Vesely, and Nicholas P. Ward. Marlin: Pre-processing zksnarks with universal and updatable SRS. In EUROCRYPT (1), volume 12105 of Lecture Notes in Computer Science, pages 738–768. Springer, 2020.</li>

      <li>[CL02] Jan Camenisch and Anna Lysyanskaya. Dynamic accumulators and application to efficient revocation of anonymous credentials. In CRYPTO, volume 2442 of Lecture Notes in Computer Science, pages 61–76. Springer, 2002.</li>

      <li>[Clo20] Cloudflare. Merkle town, 2020.</li>

      <li>[CW09] Scott A. Crosby and Dan S. Wallach. Efficient data structures for tamper-evident logging. In USENIX Security Symposium, pages 317–334. USENIX Association, 2009.</li>

      <li>[DPP16] Rasmus Dahlberg, Tobias Pulls, and Roel Peeters. Efficient sparse merkle trees - caching strategies and secure (non-)membership proofs. In NordSec, volume 10014 of Lecture Notes in Computer Science, pages 199–215, 2016.</li>

      <li>[DSB^{+}16] Sergej Dechand, Dominik Schürmann, Karoline Busse, Yasemin Acar, Sascha Fahl, and Matthew Smith. An empirical study of textual key-fingerprint representations. In USENIX Security Symposium, pages 193–208. USENIX Association, 2016.</li>

      <li>[EMBB17] Saba Eskandarian, Eran Messeri, Joseph Bonneau, and Dan Boneh. Certificate transparency with privacy. Proc. Priv. Enhancing Technol., 2017(4):329–344, 2017.</li>

      <li>[FDP^{+}14] Sascha Fahl, Sergej Dechand, Henning Perl, Felix Fischer, Jaromir Smrcek, and Matthew Smith. Hey, NSA: stay away from my market! future proofing app markets against powerful attackers. In CCS, pages 1143–1155. ACM, 2014.</li>

      <li>[GGPR13] Rosario Gennaro, Craig Gentry, Bryan Parno, and Mariana Raykova. Quadratic span programs and succinct nizks without pcps. In EUROCRYPT, volume 7881 of Lecture Notes in Computer Science, pages 626–645. Springer, 2013.</li>

      <li>[GKK^{+}19] Lorenzo Grassi, Daniel Kales, Dmitry Khovratovich, Arnab Roy, Christian Rechberger, and Markus Schofnegger. Starkad and poseidon: New hash functions for zero knowledge proof systems. IACR Cryptol. ePrint Arch., 2019:458, 2019.</li>

      <li>[Gro10] Jens Groth. Short pairing-based non-interactive zero-knowledge arguments. In ASIACRYPT, volume 6477 of Lecture Notes in Computer Science, pages 321–340. Springer, 2010.</li>

      <li>[Gro16] Jens Groth. On the size of pairing-based non-interactive arguments. In EUROCRYPT (2), volume 9666 of Lecture Notes in Computer Science, pages 305–326. Springer, 2016.</li>

      <li>[GWC19] Ariel Gabizon, Zachary J. Williamson, and Oana Ciobotaru. PLONK: permutations over lagrange-bases for oecumenical noninteractive arguments of knowledge. IACR Cryptol. ePrint Arch., 2019:953, 2019.</li>

      <li>[HHK^{+}21] Yuncong Hu, Kian Hooshmand, Harika Kalidhindi, Seung Jin Yang, and Raluca Ada Popa. Merkle^2: A low-latency transparency log system. In IEEE Symposium on Security and Privacy. IEEE Computer Society, 2021.</li>

      <li>[KHP^{+}13] Tiffany Hyun-Jin Kim, Lin-Shung Huang, Adrian Perrig, Collin Jackson, and Virgil D. Gligor. Accountable key infrastructure (AKI): a proposal for a public-key validation infrastructure. In WWW, pages 679–690. International World Wide Web Conferences Steering Committee / ACM, 2013.</li>

      <li>[KPS18] Ahmed E. Kosba, Charalampos Papamanthou, and Elaine Shi. xjsnark: A framework for efficient verifiable computation. In IEEE Symposium on Security and Privacy, pages 944–961. IEEE Computer Society, 2018.</li>

      <li>[KZG10] Aniket Kate, Gregory M. Zaverucha, and Ian Goldberg. Constant-size commitments to polynomials and their applications. In ASIACRYPT, volume 6477 of Lecture Notes in Computer Science, pages 177–194. Springer, 2010.</li>

      <li>[Lau14] Ben Laurie. Certificate transparency. Commun. ACM, 57(10):40–46, 2014.</li>

      <li>[LGG^{+}20] Derek Leung, Yossi Gilad, Sergey Gorbunov, Leonid Reyzin, and Nickolai Zeldovich. Aardvark: A concurrent authenticated dictionary with short proofs. IACR Cryptol. ePrint Arch., 2020:975, 2020.</li>

      <li>[LKMS04] Jinyuan Li, Maxwell N. Krohn, David Mazières, and Dennis E. Shasha. Secure untrusted data repository (SUNDR). In OSDI, pages 121–136. USENIX Association, 2004.</li>

      <li>[LLK13] Ben Laurie, Adam Langley, and Emilia Käsper. Certificate transparency. RFC, 6962:1–27, 2013.</li>

      <li>[LM19] Russell W. F. Lai and Giulio Malavolta. Subvector commitments with application to succinct arguments. In CRYPTO (1), volume 11692 of Lecture Notes in Computer Science, pages 530–560. Springer, 2019.</li>

      <li>[LNS20] Jonathan Lee, Kirill Nikitin, and Srinath T. V. Setty. Replicated state machines without replicated execution. In IEEE Symposium on Security and Privacy, pages 119–134. IEEE, 2020.</li>

      <li>[MB02] Petros Maniatis and Mary Baker. Secure history preservation through timeline entanglement. In USENIX Security Symposium, pages 297–312. USENIX, 2002.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[MBB^{+}15] Marcela S. Melara, Aaron Blankstein, Joseph Bonneau, Edward W. Felten, and Michael J. Freedman. CONIKS: bringing key transparency to end users. In USENIX Security Symposium, pages 383–398. USENIX Association, 2015.</li>

      <li>[Mer87] Ralph C. Merkle. A digital signature based on a conventional encryption function. In CRYPTO, volume 293 of Lecture Notes in Computer Science, pages 369–378. Springer, 1987.</li>

      <li>[MHKS14] Andrew Miller, Michael Hicks, Jonathan Katz, and Elaine Shi. Authenticated data structures, generically. pages 411–424, 2014.</li>

      <li>[MKL^{+}20] Sarah Meiklejohn, Pavel Kalinnikov, Cindy S. Lin, Martin Hutchinson, Gary Belvin, Mariana Raykova, and Al Cutter. Think global, act local: Gossip and client audits in verifiable data structures. CoRR, abs/2011.04551, 2020.</li>

      <li>[NKJ^{+}17] Kirill Nikitin, Eleftherios Kokoris-Kogias, Philipp Jovanovic, Nicolas Gailly, Linus Gasser, Ismail Khoffi, Justin Cappos, and Bryan Ford. CHAINIAC: proactive software-update transparency via collectively signed skipchains and verified builds. In USENIX Security Symposium, pages 1271–1287. USENIX Association, 2017.</li>

      <li>[Öst16] Rasmus Östersjö. Sparse merkle trees: Definitions and space-time trade-offs with applications for balloon. Master’s thesis, 2016.</li>

      <li>[Ove83] Mark H. Overmars. The Design of Dynamic Data Structures, volume 156 of Lecture Notes in Computer Science. Springer, 1983.</li>

      <li>[OWWB20] Alex Ozdemir, Riad S. Wahby, Barry Whitehat, and Dan Boneh. Scaling verifiable computation using efficient set accumulators. In USENIX Security Symposium, pages 2075–2092. USENIX Association, 2020.</li>

      <li>[PP15] Tobias Pulls and Roel Peeters. Balloon: A forward-secure append-only persistent authenticated data structure. In ESORICS (2), volume 9327 of Lecture Notes in Computer Science, pages 622–641. Springer, 2015.</li>

      <li>[Rya14] Mark Dermot Ryan. Enhanced certificate transparency and end-to-end encrypted mail. In NDSS. The Internet Society, 2014.</li>

      <li>[SAGL18] Srinath T. V. Setty, Sebastian Angel, Trinabh Gupta, and Jonathan Lee. Proving the correct execution of concurrent services in zero-knowledge. In OSDI, pages 339–356. USENIX Association, 2018.</li>

      <li>[Set20] Srinath Setty. Spartan: Efficient and general-purpose zksnarks without trusted setup. In CRYPTO (3), volume 12172 of Lecture Notes in Computer Science, pages 704–737. Springer, 2020.</li>

      <li>[SHT21] Kavya Sreedhar, Mark Horowitz, and Christopher Torng. A fast large-integer extended gcd algorithm and hardware design for verifiable delay functions and modular inversion. IACR Cryptology ePrint Archive, 2021/1292, 2021.</li>

      <li>[SSV21] Cosimo Sguanci, Roberto Spatafora, and Andrea Mario Vergani. Layer 2 blockchain scaling: a survey. CoRR, abs/2107.10881, 2021.</li>

      <li>[Sta22] Statista. Number of apps available in leading app stores as of 1st quarter 2022, 2022.</li>

      <li>[STV^{+}16] Ewa Syta, Iulia Tamas, Dylan Visher, David Isaac Wolinsky, Philipp Jovanovic, Linus Gasser, Nicolas Gailly, Ismail Khoffi, and Bryan Ford. Keeping authorities "honest or bust" with decentralized witness cosigning. In IEEE Symposium on Security and Privacy, pages 526–545. IEEE Computer Society, 2016.</li>

      <li>[TBB^{+}17] Joshua Tan, Lujo Bauer, Joseph Bonneau, Lorrie Faith Cranor, Jeremy Thomas, and Blase Ur. Can unicorns help users compare crypto key fingerprints? In CHI, pages 3787–3798. ACM, 2017.</li>

      <li>[TBP^{+}19] Alin Tomescu, Vivek Bhupatiraju, Dimitrios Papadopoulos, Charalampos Papamanthou, Nikos Triandopoulos, and Srinivas Devadas. Transparency logs via append-only authenticated dictionaries. In CCS, pages 1299–1316. ACM, 2019.</li>

      <li>[TD17] Alin Tomescu and Srinivas Devadas. Catena: Efficient non-equivocation via bitcoin. In IEEE Symposium on Security and Privacy, pages 393–409. IEEE Computer Society, 2017.</li>

      <li>[Tec21] TechCrunch. Signal’s brian acton talks about exploding growth, monetization and whatsapp data-sharing outrage, 2021.</li>

      <li>[TKPS21] Ioanna Tzialla, Abhiram Kothapalli, Bryan Parno, and Srinath Setty. Transparency dictionaries with succinct proofs of correct operation. IACR Cryptol. ePrint Arch., page 1263, 2021.</li>

      <li>[TXN20] Alin Tomescu, Yu Xia, and Zachary Newman. Authenticated dictionaries with cross-incremental proof (dis)aggregation. IACR Cryptol. ePrint Arch., 2020:1239, 2020.</li>

      <li>[Val08] Paul Valiant. Incrementally verifiable computation or proofs of knowledge imply time/space efficiency. In TCC, volume 4948 of Lecture Notes in Computer Science, pages 1–18. Springer, 2008.</li>

      <li>[VWO^{+}17] Elham Vaziripour, Justin Wu, Mark O’Neill, Jordan Whitehead, Scott Heidbrink, Kent E. Seamons, and Daniel Zappala. Is that you, alice? A usability study of the authentication ceremony of secure messaging applications. In SOUPS, pages 29–47. USENIX Association, 2017.</li>

      <li>[Wes19] Benjamin Wesolowski. Efficient verifiable delay functions. In EUROCRYPT (3), volume 11478 of Lecture Notes in Computer Science, pages 379–407. Springer, 2019.</li>

      <li>[WGH^{+}] Barry Whitehat, Alex Gluchowski, HarryR, Yondon Fu, and Philippe Castonguay. Roll up / roll back snark. https://ethresear.ch/t/roll-up-roll-back-snark-side-chain-17000-tps/.</li>

      <li>[WZC^{+}18] Howard Wu, Wenting Zheng, Alessandro Chiesa, Raluca Ada Popa, and Ion Stoica. DIZK: A distributed zero knowledge proof system. In USENIX Security Symposium, pages 675–692. USENIX Association, 2018.</li>

      <li>[YRC15] Jiangshan Yu, Mark Ryan, and Cas Cremers. How to detect unauthorised usage of a key. IACR Cryptol. ePrint Arch., 2015:486, 2015.</li>

      <li>[ZWZ^{+}21] Ye Zhang, Shuo Wang, Xian Zhang, Jiangbin Dong, Xingzhong Mao, Fan Long, Cong Wang, Dong Zhou, Mingyu Gao, and Guangyu Sun. Pipezk: Accelerating zero-knowledge proof with a pipelined architecture. In ISCA, pages 416–428. IEEE, 2021.</li>

    </ul>

    <p class="text-gray-300">A Merkle Tree and Compact Range Preliminaries</p>

    <p class="text-gray-300">A <em>Merkle tree</em> is an authenticated data structure constructed via a tree in which the internal nodes are given a label equal to the hash of the concatenation of their children’s labels. Data values are typically stored in the leaf nodes of the tree. Given a collision-resistant hash function, each node cryptographically commits to all of its children and hence the hash label of the root commits to the entire structure of the tree and the accumulated data values in all of its leaves. Merkle originally considered only binary trees with data values in the leaves and this remains the best known construction <em>[x18]</em>. This implements a vector commitment (a commitment to an ordered list of values) and not an authenticated dictionary with key-value mappings. However, Merkle’s general approach is applicable to any tree-based data structure <em>[x16]</em> and several constructions are possible for authenticated dictionaries.</p>

    <p class="text-gray-300">Authenticated dictionaries from Merkle trees. When using a Merkle tree as an authenticated key-value dictionary, the key is defined by the path from the root to the leaf: left children encode 0 and right children encode 1. A lookup proof for a value consists of the labels of all the sibling nodes along the path from the leaf to the root. Verification is run by using the claimed value and sibling nodes to compute the labels along the path and comparing the final label to the root digest. Proving an invariant update to a leaf can be done similarly. Given a lookup proof for a leaf’s old value, the claimed updated value is used to compute new labels along the path using the same siblings and comparing the final label with the new root digest; this additionally verifies no other leaves were modified. The invariant can be checked to be preserved between the old value and the new value. For example, for the versioned invariant, the value will include a version counter that can be checked to having been incremented by one. The lookup proofs and update proofs are both of size <span class="math">\\mathcal{O}(\\log N)</span> and incur <span class="math">\\mathcal{O}(\\log N)</span> verification time for a balanced tree of size <span class="math">N</span>.</p>

    <p class="text-gray-300">A <em>sparse Merkle tree</em> <em>[x20, x7, x11]</em> allows for initializing a complete Merkle tree over a large key space of size <span class="math">N=2^{h}</span> efficiently (in <span class="math">\\mathcal{O}(\\log N)</span> time). All leaf labels are implicitly initialized to some canonical null value. A canonical null label for internal nodes at a given height <span class="math">i</span> are also computed as the hash of the concatenation of two null labels of height <span class="math">i-1</span>. As values are added, non-null internal nodes are stored explicitly. This way, storage of a sparse Merkle tree is of <span class="math">\\mathcal{O}(n\\log N)</span> instead of <span class="math">\\mathcal{O}(N)</span> where <span class="math">n</span> is the number of non-null values.</p>

    <p class="text-gray-300">Append-only vector commitments from Merkle trees. Merkle trees can also be used as a vector commitment supporting efficient append-only proofs for any prefix vector. A <em>history Merkle tree</em> <em>[x10, MKL^{+}20, x3]</em> of size <span class="math">N</span> is a Merkle tree in which the left subtree is a complete tree of size <span class="math">2^{\\ell}</span> where <span class="math">\\ell=\\lfloor\\log(N-1)\\rfloor</span> and the right tree a history tree of size <span class="math">N-2^{\\ell}</span>. To append a value to the vector, the value is appended recursively to the right subtree if it is not complete. When it is complete, a new root is created and the new entry is added as the right child, creating a new right subtree of size 1. The time to append a value is <span class="math">\\mathcal{O}(\\log N)</span>. This construction has the property that complete subtree roots are frozen and only ever moved underneath new parent nodes. The digest of the vector commitment is the Merkle root. An append-only proof can be efficiently generated using compact ranges (see Section 3). To show a <span class="math">j^{th}</span> prefix, first note that we can interpret the subranges from <span class="math">\\mathsf{CompactR}</span> as complete subtrees and provide the hashes corresponding to each subtree root (internal node). An append-only proof then consists of the subtree roots of <span class="math">\\mathsf{CompactR}((0,j))</span> and <span class="math">\\mathsf{CompactR}((j,N))</span>. The proof can be verified by using the subtree roots to compute and check <span class="math">d_{j}</span> and <span class="math">d_{N}</span> in <span class="math">\\mathcal{O}(\\log N)</span> time. Full details of the append-only proof and algorithm for computing compact ranges can be found in <em>[MKL^{+}20]</em>.</p>

    <h2 id="sec-22" class="text-2xl font-bold">Appendix B Open Addressing Optimization for Merkle Tree Update Circuit Representation</h2>

    <p class="text-gray-300">We present an optimization to reduce the length of the Merkle paths in the circuit from 256 required for collision-resistance to a height determined by the number of expected keys in the registry. The tree height is reduced to one in which collisions may occur and collisions are handled by remapping the colliding key to a different index using open addressing, a technique used in hash tables. This produces a more efficient circuit representation than other approaches used for path compression, e.g., Merkle Patricia tries <em>[MBB^{+}15, x6]</em>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">More specifically, to find the index for a key, the key is hashed along with a counter nonce <span class="math">\\omega</span> initialized to 0, $\\mathsf{H}(k\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,\\omega)<span class="math">. If the index is already populated, </span>\\omega<span class="math"> is incremented and a new index is computed until the first open index is found (up to some max increment </span>\\omega_{\\mathsf{max}}<span class="math">). Since it is possible to find collisions for an index, each leaf now additionally encodes the key </span>k<span class="math"> when it is initially populated (for version-only, leafs encode </span>k\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,\\textnormal{\\em v}\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,u<span class="math">); constraints are added to ensure future updates to the leaf do not change the encoded key. This approach allows the tree height to be set based on the expected max capacity of the registry. For example, if the registry is not expected to exceed </span>2^{30}<span class="math"> keys, a tree height set to </span>32<span class="math"> with </span>\\omega_{\\mathsf{max}}=16<span class="math"> leads to a failure probability of less than </span>1/2^{64}<span class="math">. Any reduction in Merkle path length is significant as it leads to an equally proportional decrease in proving time (in this example, 4</span>\\times$).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The tradeoff to using open addressing for a faster epoch update proving time is that lookup proofs increase in size and verification time. A lookup proof for a key inserted at nonce  <span class="math">\\omega</span>  includes Merkle paths for all indices derived from nonces 0 to  <span class="math">\\omega</span> , and in the case of a non-membership proof, will include all  <span class="math">\\omega_{\\mathrm{max}}</span>  Merkle paths. Still, these proofs are relatively small and hashes are fast to compute, so this tradeoff is largely beneficial.</p>

    <p class="text-gray-300">Groups of unknown order. We assume the existence of a randomized polynomial time sampling algorithm  <span class="math">\\mathsf{GGen}(\\lambda)</span>  that takes as input the security parameter  <span class="math">\\lambda</span>  and generates a group of unknown order consisting of two integers  <span class="math">a, b</span>  along with a description of the group  <span class="math">\\mathbb{G}</span> . The group  <span class="math">\\mathbb{G}</span>  is of unknown order in the range  <span class="math">[a, b]</span>  where  <span class="math">a, b</span> , and  <span class="math">a - b</span>  are all exponential in  <span class="math">\\lambda</span> .</p>

    <p class="text-gray-300">The RSA quotient group  <span class="math">\\mathbb{Z}_N^\\times \\setminus \\{\\pm 1\\}</span>  where  <span class="math">N</span>  is an RSA modulus is believed to have no element of known order other than the identity. The group generation algorithm here may require trusted setup to generate the group modulus  <span class="math">N</span> .</p>

    <p class="text-gray-300">Strong RSA assumption. The strong RSA assumption tasks an adversary with computing a chosen non-trivial root of a random group element. We define the advantage of an adversary  <span class="math">\\mathcal{A}</span>  against the strong RSA assumption as follows:</p>

    <div class="my-4 text-center"><span class="math-block">\\mathbf {A d v} _ {\\mathsf {G G e n}, \\mathcal {A}} ^ {\\mathsf {s t r o n g - r s a}} (\\lambda) = \\Pr \\left[ \\begin{array}{l l} u ^ {\\ell} = w &amp;amp; (a, b, \\mathbb {G}) \\leftarrow \\# \\mathsf {G G e n} (\\lambda); \\\\ \\ell \\in \\mathsf {P r i m e s} (\\lambda) \\setminus \\{2 \\} &amp;amp; w \\leftarrow \\# \\mathbb {G}; \\\\ &amp;amp; (u, \\ell) \\leftarrow \\# \\mathcal {A} (a, b, \\mathbb {G}, w) \\end{array} \\right].</span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Extended Euclidean algorithm. Given two integers  <span class="math">x, y</span>  such that the  <span class="math">\\operatorname{ged}(x, y) = 1</span> , then  <span class="math">(a, b) \\gets \\mathsf{EEA}(x, y)</span>  returns the Bézout coefficients  <span class="math">(a, b)</span>  where  <span class="math">ax + by = 1</span> . The coefficients are such that  <span class="math">a \\leq y</span>  and  <span class="math">b \\leq x</span> . The algorithm runs in time  $\\mathcal{O}(\\max(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">y</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">))$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">We provide the following two definitions for completeness and knowledge soundness of a non-interactive argument of knowledge  <span class="math">\\Pi</span> .</p>

    <p class="text-gray-300">Completeness. A proof system is complete if given a true statement, a prover with a witness can convince the verifier. Correctness of our protocols will rely on a proof system with perfect completeness. A proof system has perfect completeness if for all  <span class="math">(x,w)\\in \\mathcal{R}</span>  and all  <span class="math">(pk,vk)\\gets \\# \\Pi .\\mathsf{Setup}_{\\mathcal{R}}(\\lambda)</span> ,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\Pi . \\operatorname {V e r} (v k, \\Pi . \\operatorname {P r o v e} (p k, x, w), x) = 1 \\right] = 1.</span></div>

    <p class="text-gray-300">Knowledge soundness. A proof system is computationally knowledge sound if whenever a prover is able to produce a valid proof, it is possible to extract a valid witness. Knowledge soundness is defined by the security game  <span class="math">\\mathrm{SOUND}_{\\Pi, \\mathcal{R}, \\mathsf{X}}^{\\mathcal{A}}(\\lambda)</span>  in which an adversary is tasked with finding a verifying statement and proof for which the extractor does not extract a valid witness. The advantage of an adversary is defined as  <span class="math">\\mathbf{Adv}_{\\Pi, \\mathcal{R}, \\mathcal{A}, \\mathsf{X}}^{\\mathrm{sound}}(\\lambda) = \\Pr[\\mathrm{SOUND}_{\\Pi, \\mathcal{R}, \\mathsf{X}}^{\\mathcal{A}}(\\lambda) = 1]</span> .</p>

    <p class="text-gray-300">|  Game SOUNDα, R, X(λ)  |</p>

    <p class="text-gray-300">| --- |</p>

    <p class="text-gray-300">|  (pk, vk, stX) ← #X.Setup(λ)  |</p>

    <p class="text-gray-300">|  (x, π) ← #A(pk, vk)  |</p>

    <p class="text-gray-300">|  w ← X.Extract(x, π : stX)  |</p>

    <p class="text-gray-300">|  b ← Π.Ver(vk, π, x)  |</p>

    <p class="text-gray-300">|  Return (x, w)∉R ∧ b  |</p>

    <p class="text-gray-300">Figure 11 provides the security games for the strong key binding and invariant update soundness properties of authenticated dictionaries. The binding game requires an adversary to output two lookup proofs for different values that verify under the same key for the same digest. The invariant update soundness game requires an adversary to provide valid lookups for a key that does not satisfy the invariant across two digests, while also providing a sequence of invariant proofs that the invariant is preserved across the two digests. The invariant is defined as a boolean function  <span class="math">\\Phi</span>  that takes as input a key, initial value, and updated value, then outputs 1 if the invariant is satisfied. We define an adversary's advantage against these games, respectively, as:</p>

    <div class="my-4 text-center"><span class="math-block">\\mathbf {A d v} _ {\\mathrm {A D}, \\mathcal {A}} ^ {\\mathrm {b i n d}} (\\lambda) = \\Pr [ \\mathrm {B i n d} _ {\\mathcal {A}} ^ {\\mathrm {A D}} (\\lambda) = 1 ], \\qquad \\mathbf {A d v} _ {\\mathrm {A D}, \\Phi , \\mathcal {A}} ^ {\\mathrm {i n v}} (\\lambda) = \\Pr [ \\mathrm {I N V S O U N D} _ {\\mathcal {A}} ^ {\\mathrm {A D}, \\Phi} (\\lambda) = 1 ].</span></div>

    <p class="text-gray-300">!<a href="img-11.jpeg">img-11.jpeg</a> Figure 11: Security games for strong key binding (left) and invariant preservation of updates (middle) for authenticated dictionaries. Security game for index binding (right) for append-only vector commitments.</p>

    <p class="text-gray-300">!<a href="img-12.jpeg">img-12.jpeg</a></p>

    <p class="text-gray-300">!<a href="img-13.jpeg">img-13.jpeg</a></p>

    <p class="text-gray-300">In this work, we focus on the versioned invariant. The versioned invariant  <span class="math">\\Phi_{\\mathrm{vsn}}</span>  parses values as a value-version tuple  <span class="math">(v,u)</span> . It enforces (1) the key's version number does not decrease, and (2) two different values for a key cannot be shown for the same version number. It is defined as follows:</p>

    <div class="my-4 text-center"><span class="math-block">\\Phi_ {\\mathrm {v s n}} (k, (v _ {A}, u _ {A}), (v _ {B}, u _ {B})) = u _ {A} &amp;lt;   u _ {B} \\vee (u _ {A} = u _ {B} \\wedge v _ {A} = v _ {B}).</span></div>

    <p class="text-gray-300">Some applications require a stronger invariant to be maintained among mapped values in an AD, which we will refer to as the append-only invariant. In the append-only invariant, values of an AD are parsed as lists of values  <span class="math">L = [v_{j}]_{j}^{\\ell}</span> . The invariant enforces that the list can only be appended to, i.e., previous values in the list do not change. More precisely, we define  <span class="math">\\Phi_{\\mathrm{app}}</span>  as follows:</p>

    <div class="my-4 text-center"><span class="math-block">\\Phi_ {\\mathrm {a p p}} (k, L _ {A} = [ v _ {A, j} ] _ {j} ^ {\\ell_ {A}}, L _ {B} = [ v _ {B, j} ] _ {j} ^ {\\ell_ {B}}) = \\ell_ {A} \\leq \\ell_ {B} \\wedge \\bigwedge_ {j} ^ {\\ell_ {A}} v _ {A, j} = v _ {B, j}.</span></div>

    <p class="text-gray-300">Figure 11 (right) provides the pseudocode security game defining index binding for append-only vector commitments. The game requires an adversary to produce two valid lookup proofs to the same index for different values. The adversary is allowed to give lookup proofs for different digests as long as they additionally prove that the two digests share prefixes. We define an adversary's advantage against index binding as:</p>

    <div class="my-4 text-center"><span class="math-block">\\mathbf {A d v} _ {\\mathsf {V C}, \\mathcal {A}} ^ {\\mathsf {b i n d}} (\\lambda) = \\Pr [ \\mathrm {B i n d} _ {\\mathcal {A}} ^ {\\mathsf {V C}} (\\lambda) = 1 ].</span></div>

    <p class="text-gray-300">We make use of the key-value commitment KVaC from [AR20]; the construction pseudocode is given in Figure 12. The hash function  <span class="math">\\mathsf{H}</span>  maps keys to primes of size  <span class="math">2^{\\lambda}</span>  that are larger than the group order upper bound  <span class="math">b</span> . The space of values that can be committed to is the set of positive integers bounded above by  <span class="math">b</span> . [AR20] prove KVaC secure with respect to a weak key binding property in which the commitment must have been produced correctly, rather than adversarially. This is not sufficient for the verifiable registry setting; in the next section we show how to augment KVaC with update proofs to protect against adversarially generated commitments.</p>

    <p class="text-gray-300">Figure 13 shows our protocol for proving updates preserve a versioned invariant. We use the generalized proof of linear homomorphism [BBF19] to prove that the commitment is updated only by a particular homomorphism that we show guarantees a versioned invariant. The proof of knowledge from [BBF19] is sound in the hidden order generic group model. We also show</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">KVaC.Setup(λ) (a,b,G)←GGen(λ) g←G Return (a,b,G,g) KVaC Init() Return (1,g) KVaC.Commit([k,v,u])i [z]i←[H(k)]i C1←gΣj(vjzj-1Πi≠jzni) C2←gΠi zni Return (C1,C2)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">KVaC.ProveMem([k,v,u])i,m) [z]i←[H(k)]i π1←gΣj≠m(vjzj-1Πi≠j,mzni) π2←gΠi≠mzni (a,b)←EEA(Πi≠mzni,zm) π←((π1,π2),(gb,a),um) Return π KVaC.VerifyMem(C,(k,v),π) z←H(k) ((π1,π2),(B,a),u)←π (C1,C2)←C Return Λ(π1)z^u(π2)v·z^u-1=C1 (π2)z^u=C2 (π2)^aB^z=g</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">KVaC.Upd(C,(k,δ)) z←H(k) (C1,C2)←C C'←(C1^aC_2^d,C_2^z) Return C' KVaC.UpdateMemProof((k,π),(kδ,δ)) z←H(k) ((π1,π2),(B,a),u)←π If k=kδ then π'←((π1,π2),(B,a),u+1) Else zδ←H(kδ) (s,t)←EEA(z,zδ) q←[at/z]; r←at mod z a'←r; B'←π2^a+qzδB π'←((π1^zδπ_2^δ,π_2^z), (B',a'),u) Return π'</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">KVaC.ProveNonMem([k,v,u])i,k') [z]i←[H(k)]i; z'←H(k') (a,b)←EEA(Πi zni, z') Return (a,gb) KVaC.VerNonMem(C,k',π) (a,B)←π z'←H(k'); (C1,C2)←C Return C_2^aB^z' = g KVaC.UpdNonMemProof((k',π),(kδ,δ)) (a,B)←π z'←H(k'); zδ←H(kδ) (s,t)←EEA(z',zδ) q←[at/z]; r←at mod z a'←r; B'←π2^a+qzδB Return (a',B')</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Figure 12: KVaC construction from [AR20]. The AD Lkup (resp. VerLkup) algorithm combines the prove (resp. verify) membership and non-membership algorithms.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">KVaC.BatchUpdate(C,[(k,δ)i))</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">KVaC.ProveUpdate(C,C',(Z,Δ))</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">RkVaC = {((X1,X2,Y1,Y2);(α,β)):Y1=X1αX2β∧Y2=X2α}</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">[z]i←[H(k)]i</td>

            <td class="px-3 py-2 border-b border-gray-700">(C1,C2)←C; (C1',C2')←C'</td>

            <td class="px-3 py-2 border-b border-gray-700">BBF.Prove((α,β),(X1,X2,Y1,Y2))</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">(C1,C2)←C</td>

            <td class="px-3 py-2 border-b border-gray-700">π←BBF.Prove((Z,Δ),(C1,C2,C1',C2'))</td>

            <td class="px-3 py-2 border-b border-gray-700">sa←gα; sb←gβ</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Z←Πizi</td>

            <td class="px-3 py-2 border-b border-gray-700">Return π</td>

            <td class="px-3 py-2 border-b border-gray-700">l←HPrimes(X1</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">X2</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">Y1</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">Y2</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">sa</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">sb)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Δ←Σj(δjΠi≠jzi)</td>

            <td class="px-3 py-2 border-b border-gray-700">KVaC.VerUpdate(C,C',π)</td>

            <td class="px-3 py-2 border-b border-gray-700">qa←[α/ℓ]; ra←α mod ℓ</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">C'←(C1^ZC2^Δ,C2^Z)</td>

            <td class="px-3 py-2 border-b border-gray-700">(C1,C2)←C; (C1',C2')←C'</td>

            <td class="px-3 py-2 border-b border-gray-700">qb←[β/ℓ]; rb←β mod ℓ</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Return C'</td>

            <td class="px-3 py-2 border-b border-gray-700">Return BBF.Ver((C1,C2,C1',C2'),π)</td>

            <td class="px-3 py-2 border-b border-gray-700">Wa←gqa; Wb←gqb</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">KVaC.UpdateMemProof((k,π),(Z,Δ))</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">W1←X1^qaX2^qb; W2←X2^qa</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">z←H(k)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">π←(Wa,Wb,W1,W2,ra,rb,ℓ)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">((π1,π2),(B,a),u)←π</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">Return π</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">(s,t)←EEA(z,Z)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">BBF.Ver((X1,X2,Y1,Y2),π)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">q←[at/z]; r←at mod z</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">π←(Wa,Wb,W1,W2,ra,rb,ℓ)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">a'←r; B'←π2^a+qZB</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">sa←Wb^ℓg^ra; sb←Wb^ℓg^rb</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">π'←((π1^Zπ2^Δ,π2^Z),(B',a'),u)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">Return Λ(ℓ=HPrimes(X1</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">X2</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">Y1</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">Y2</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">sa</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">sb)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Return π'</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">Y1=W1^ℓX1^raX2^rb</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|   |  | Y2=W2^ℓX2^ra  |</p>

    <p class="text-gray-300">Figure 13: Extension for KVaC to batch many key updates together (left). Extension to prove that key updates satisfy a versioned invariant (center) using the generalized proof of linear homomorphism from [BBF19], shown for the particular update homomorphism relevant to KVaC (right).</p>

    <p class="text-gray-300">(in Figure 13) how to batch many key-value updates together such that the batched update follows the same homomorphic form as a single update. Individual membership proofs can be updated with respect to batched changes.</p>

    <p class="text-gray-300">Next, we prove when KVaC construction from Figure 12 is combined with the update proofs from Figure 13, the construction achieves strong key binding and the versioned invariant is preserved. More specifically, to achieve strong key binding, we require that a digest from KVaC is accompanied with an update proof proving a valid update from the initial digest output from Init.</p>

    <p class="text-gray-300">First, we will prove some useful lemmas.</p>

    <h6 id="sec-31" class="text-base font-medium mt-4">Lemma 1.</h6>

    <p class="text-gray-300">[Shamir’s trick] For any integer modulo <span class="math">N</span>, given integers <span class="math">u,v\\in\\mathbb{Z}_{N}^{\\times}</span> and <span class="math">x,y\\in\\mathbb{Z}</span>, such that <span class="math">u^{x}=v^{y}\\mod N</span> and <span class="math">\\gcd(x,y)=1</span>, it is efficient to compute <span class="math">w\\in\\mathbb{Z}_{N}^{\\times}</span> where <span class="math">w^{a}=v\\mod N</span>.</p>

    <h6 id="sec-32" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Since <span class="math">\\gcd(x,y)=1</span>, we can compute the Bézout coefficients <span class="math">(a,b)\\leftarrow\\mathsf{EEA}(x,y)</span> where <span class="math">ax+by=1</span>. Let <span class="math">w=u^{b}v^{a}\\mod n</span>, then</p>

    <p class="text-gray-300"><span class="math">w^{x}=u^{bx}v^{ax}=(u^{x})^{b}v^{ax}=(v^{y})^{b}v^{ax}=v\\pmod{N}.</span></p>

    <p class="text-gray-300">∎</p>

    <h6 id="sec-33" class="text-base font-medium mt-4">Lemma 2.</h6>

    <p class="text-gray-300">[Non-trivial root of unity] For RSA quotient group <span class="math">\\mathbb{G}</span> with elements of unknown order bounded above by <span class="math">b</span>, given integers <span class="math">u,v\\in\\mathbb{G}</span> and prime <span class="math">z&gt;b</span>, if <span class="math">u^{z}=v^{z}</span>, then <span class="math">u=v</span>.</p>

    <h6 id="sec-34" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Let <span class="math">\\alpha=u/v\\in\\mathbb{G}</span>. Then <span class="math">\\alpha^{z}=1</span>. Since <span class="math">z</span> is prime, if <span class="math">\\alpha\\neq 1</span>, then <span class="math">z</span> must be the order of <span class="math">\\alpha</span> in <span class="math">\\mathbb{G}</span>. However, <span class="math">z&gt;b</span>, an upper bound on the order of elements in <span class="math">\\mathbb{G}</span>, which is not possible, so <span class="math">\\alpha=1</span> and <span class="math">u=v</span>. ∎</p>

    <h6 id="sec-35" class="text-base font-medium mt-4">Lemma 3.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">[Coprime] For RSA quotient group <span class="math">\\mathbb{G}</span>, given integers <span class="math">u,w\\in\\mathbb{G}</span>, random integer <span class="math">v\\in\\mathbb{G}</span>, integers <span class="math">a,b,c\\in\\mathbb{Z}</span>, and prime <span class="math">z</span>, then if <span class="math">u^{z^{c}}=v^{a}</span> and <span class="math">u^{b}w^{z}=v</span>, then $z^{c}\\,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,a<span class="math"> and if let </span>d=a/z^{c}\\in\\mathbb{Z}<span class="math">, then </span>u=v^{d}<span class="math"> and </span>\\gcd(z,d)=1$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-36" class="text-base font-medium mt-4">Proof.</h6>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">First, we prove that <span class="math">d</span> exists, i.e., that $z^{c}\\,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,a<span class="math">. Consider </span>(u^{z^{c-1}})^{z}=v^{a}<span class="math">. If </span>z\\not</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,a<span class="math">, then </span>\\gcd(z,a)=1<span class="math"> and by Lemma 1, we can compute </span>x^{z}=v<span class="math"> which wins the strong RSA security game. Therefore </span>z\\,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,a<span class="math"> and </span>u^{z^{c-1}}=g^{a/z}<span class="math"> by Lemma 2. We can repeat this argument for </span>(u^{z^{c-i}})^{z}=v^{a/z^{i-1}}<span class="math"> for </span>i\\in[2,c]<span class="math">, ultimately arriving at </span>z^{c}\\,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,a<span class="math"> and </span>u=v^{a/z^{c}}=v^{d}$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Next, we show that $z\\not</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,d<span class="math">. Consider </span>u^{b}w^{z}=v<span class="math"> rewritten as </span>v^{bd-1}=w^{-z}<span class="math">. If </span>z\\,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,d<span class="math">, then </span>\\gcd(bd-1,-z)=1<span class="math">, and by Lemma 1, we can compute </span>x^{z}=v<span class="math"> which again wins the strong RSA security game. Therefore, </span>z\\not</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,d<span class="math"> meaning </span>\\gcd(z,d)=1$. ∎</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h6 id="sec-37" class="text-base font-medium mt-4">Theorem 1.</h6>

    <p class="text-gray-300">For any adversary <span class="math">\\mathcal{A}</span> against the versioned invariant soundness of KVaC augmented with proof of update from initialization, we give adversaries <span class="math">\\mathcal{B}</span> and <span class="math">\\mathcal{C}</span> such that</p>

    <p class="text-gray-300"><span class="math">\\mathbf{Adv}^{\\text{inv}}_{\\text{KVaC},\\Phi_{\\text{vsn}},\\mathcal{A}}(\\lambda)\\leq\\mathbf{Adv}^{\\text{strong}-\\text{rsa}}_{\\text{GGen},\\mathcal{B}}(\\lambda)+\\mathbf{Adv}^{\\text{sound}}_{\\text{BBF},\\mathcal{C},\\mathsf{X}}(\\lambda)\\,,</span></p>

    <p class="text-gray-300">where <span class="math">\\text{GGen}</span> is the group generation algorithm for the RSA quotient group used in KVaC and <span class="math">\\mathsf{X}</span> is the knowledge extractor for BBF <em>[2]</em>.</p>

    <h6 id="sec-38" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">First, we extract the update structure of the digests returned by adversary <span class="math">\\mathcal{A}</span>. Using the extractor <span class="math">\\mathsf{X}</span> for BBF, we extract the values <span class="math">(\\alpha_{A},\\beta_{A})</span> from the update proof of <span class="math">d_{1}=C_{A}</span> from the initial digest <span class="math">(1,g)</span>. This gives us:</p>

    <p class="text-gray-300"><span class="math">C_{A}=\\left(g^{\\beta_{A}},g^{\\alpha_{A}}\\right)\\,.</span></p>

    <p class="text-gray-300">Next, we extract the update structure of each of the updates from <span class="math">d_{1}</span> to <span class="math">d_{m}</span> from the update proofs <span class="math">[\\pi_{\\Phi,j}]_{j}^{m-1}</span>. Denote these extracted values as <span class="math">\\left[(\\alpha_{j},\\beta_{j})\\right]_{j}^{m-1}</span>. We observe that using these values, we can write <span class="math">d_{m}=C_{B}</span> where we can define <span class="math">\\alpha_{B}</span> and <span class="math">\\beta_{B}</span> as follows, as a single update from <span class="math">C_{A}</span>:</p>

    <p class="text-gray-300"><span class="math">C_{B}=\\left(C_{A,1}^{\\alpha_{B}}C_{A,2}^{\\beta_{B}},C_{A,2}^{\\alpha_{B}}\\right),\\qquad\\alpha_{B}=\\prod_{j}^{m-1}\\alpha_{j},\\qquad\\beta_{A}=\\sum_{j}^{m-1}\\left(\\beta_{j}\\prod_{i\\neq j}\\alpha_{i}\\right)</span></p>

    <p class="text-gray-300">If the extractor fails, we build adversary <span class="math">\\mathcal{C}</span> against the soundness of BBF.</p>

    <p class="text-gray-300">The proof proceeds by considering each of the two winning conditions and showing that, in each case, a winning adversary can break strong RSA.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">u_{A}&gt;u_{B}</span></li>

      <li><span class="math">v_{A}\\neq v_{B}\\wedge u_{A}=u_{B}</span></li>

    </ol>

    <p class="text-gray-300">Case 1: <span class="math">u_A &amp;gt; u_B</span></p>

    <p class="text-gray-300">From the verification equations of <span class="math">\\pi_A</span>, we have that:</p>

    <div class="my-4 text-center"><span class="math-block">\\pi_{A,2}^{z^{u_A}} = C_{A,2} = g^{\\alpha_A}, \\quad \\pi_{A,2}^{a_A} B_A^z = g.</span></div>

    <p class="text-gray-300">Thus, by Lemma 3, we know that <span class="math">\\pi_{A,2} = g^{\\alpha_A / z^{u_A}}</span>. Similarly, from the verification equations of <span class="math">\\pi_B</span>, we have that:</p>

    <div class="my-4 text-center"><span class="math-block">\\pi_{B,2}^{z^{u_B}} = C_{B,2} = g^{\\alpha_A \\alpha_B}, \\quad \\pi_{B,2}^{a_B} B_B^z = g.</span></div>

    <p class="text-gray-300">Again, by Lemma 3, we have that <span class="math">\\pi_{B,2} = g^{\\alpha_A \\alpha_B / z^{u_B}}</span> and <span class="math">\\gcd(\\alpha_A \\alpha_B / z^{u_B}, z) = 1</span>. Since <span class="math">u_A &amp;gt; u_B</span>, we can construct group element <span class="math">u</span> as follows:</p>

    <div class="my-4 text-center"><span class="math-block">u = \\pi_{A,2}^{\\alpha_B \\cdot z^{u_A - u_B - 1}} \\quad \\text{and then,} \\quad u^z = (\\pi_{A,2}^{\\alpha_B \\cdot z^{u_A - u_B - 1}})^z = ((g^{\\alpha_A / z^{u_A}})^{\\alpha_B \\cdot z^{u_A - u_B - 1}})^z = g^{\\alpha_A \\alpha_B / z^{u_B}}.</span></div>

    <p class="text-gray-300">Since <span class="math">\\gcd(\\alpha_A \\alpha_B / z^{u_B}, z) = 1</span>, we can compute <span class="math">w</span> from Lemma 1, where <span class="math">w^z = g</span> which wins the strong RSA security game.</p>

    <p class="text-gray-300">Case 2: <span class="math">v_A \\neq v_B \\wedge u_A = u_B</span></p>

    <p class="text-gray-300">Let <span class="math">u = u_A = u_B</span>. By the verification equation of <span class="math">\\pi_B</span>, we have:</p>

    <div class="my-4 text-center"><span class="math-block">C_{B,1} = \\pi_{B,1}^{z^u} \\pi_{B,2}^{v_B z^{u-1}}</span></div>

    <p class="text-gray-300">We also have, from the update proof and verification equations of <span class="math">\\pi_A</span>, that:</p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} C_{B,1} = C_{A,1}^{\\alpha_B} C_{A,2}^{\\beta_B} \\\\ = \\left(\\pi_{A,1}^{\\alpha_B z^u} \\pi_{A,2}^{\\alpha_B v_A z^{u-1}}\\right) \\left(\\pi_{A,2}^{\\beta_B z^u}\\right) \\end{array}</span></div>

    <p class="text-gray-300">We also can derive the following relation:</p>

    <div class="my-4 text-center"><span class="math-block">\\pi_{A,2}^{z^u} = C_{A,2} \\quad \\text{(by verification of } \\pi_A\\text{)}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\pi_{A,2}^{\\alpha_B z^u} = C_{A,2}^{\\alpha_B} = C_{B,2}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\pi_{B,2}^{z^u} = C_{B,2} \\quad \\text{(by verification of } \\pi_B\\text{)}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\pi_{A,2}^{\\alpha_B} = \\pi_{B,2} \\quad \\text{(by repeated application of Lemma 2)}</span></div>

    <p class="text-gray-300">Putting this together we have as follows:</p>

    <div class="my-4 text-center"><span class="math-block">\\pi_{A,1}^{\\alpha_B z^u} \\pi_{A,2}^{\\alpha_B v_A z^{u-1}} \\pi_{A,2}^{\\beta_B z^u} = \\pi_{B,1}^{z^u} \\pi_{B,2}^{v_B z^{u-1}} \\quad \\text{(by equality to } C_{B,1}\\text{)}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\frac{\\pi_{A,1}^{\\alpha_B z^u} \\pi_{A,2}^{\\beta_B z^u}}{\\pi_{B,1}^{z^u}} = \\frac{\\pi_{B,2}^{v_B z^{u-1}}}{\\pi_{A,2}^{\\alpha_B v_A z^{u-1}}}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\frac{\\pi_{A,1}^{\\alpha_B z^u} B_A^{\\beta_B z^u}}{\\pi_{B,1}^{z^u}} = \\pi_{B,2}^{(v_B - v_A) z^{u-1}} \\quad \\text{(by relation between } \\pi_{B,2} \\text{ and } \\pi_{A,2}\\text{)}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\left(\\left(\\frac{\\pi_{A,1}^{\\alpha_B} \\pi_{A,2}^{\\beta_B}}{\\pi_{B,1}}\\right)^z\\right)^{z^{u-1}} = \\left(\\pi_{B,2}^{v_B - v_A}\\right)^{z^{u-1}}</span></div>

    <div class="my-4 text-center"><span class="math-block">\\left(\\frac{\\pi_{A,1}^{\\alpha_B} \\pi_{A,2}^{\\beta_B}}{\\pi_{B,1}}\\right)^z = \\pi_{B,2}^{v_B - v_A} \\quad \\text{(by repeated application of Lemma 2)}</span></div>

    <p class="text-gray-300">Thus, we have found a <span class="math">z^{th}</span> root of a non-trivial element. By Lemma 3, we have that <span class="math">\\pi_{B,2} = g^{\\alpha_A \\alpha_B / z^u}</span> where <span class="math">\\gcd(\\alpha_A \\alpha_B / z^u, z) = 1</span>. This gives us</p>

    <div class="my-4 text-center"><span class="math-block">\\left(\\frac{\\pi_{A,1}^{\\alpha_B} \\pi_{A,2}^{\\beta_B}}{\\pi_{B,1}}\\right)^z = g^{\\frac{(v_B - v_A) \\alpha_A \\alpha_B}{z^u}}.</span></div>

    <p class="text-gray-300"><span class="math">z</span> is prime and the domain of values is chosen to be smaller than all <span class="math">z</span>, we also have that <span class="math">\\gcd(v_{A}-v_{B},z)=1</span>, and therefore by Lemma 1, we can compute <span class="math">w</span> where <span class="math">w^{z}=g</span> winning the strong RSA security game.</p>

    <p class="text-gray-300">∎</p>

    <h6 id="sec-39" class="text-base font-medium mt-4">Theorem 2.</h6>

    <p class="text-gray-300">For any adversary <span class="math">\\mathcal{A}</span> against the strong key binding of <span class="math">\\mathsf{KVaC}</span> augmented with proof of update from initialization, we give adversaries <span class="math">\\mathcal{B}</span> and <span class="math">\\mathcal{C}</span> such that</p>

    <p class="text-gray-300"><span class="math">\\mathbf{Adv}_{\\mathsf{KVaC},\\mathcal{A}}^{\\text{bind}}(\\lambda)\\leq\\mathbf{Adv}_{\\mathsf{GGen},\\mathcal{B}}^{\\text{strong-rsa}}(\\lambda)+\\mathbf{Adv}_{\\mathsf{BBF},\\mathcal{C},\\mathsf{X}}^{\\text{sound}}(\\lambda)\\,,</span></p>

    <p class="text-gray-300">where <span class="math">\\mathsf{GGen}</span> is the group generation algorithm for the RSA quotient group used in <span class="math">\\mathsf{KVaC}</span> and <span class="math">\\mathsf{X}</span> is the knowledge extractor for <span class="math">\\mathsf{BBF}</span> <em>[x1]</em>.</p>

    <h6 id="sec-40" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">The proof follows similarly to that of Theorem 1. Using extractor <span class="math">\\mathsf{X}</span> for <span class="math">\\mathsf{BBF}</span>, we extract values <span class="math">(\\alpha,\\beta)</span> from the update proof of <span class="math">d</span> from the initial digest <span class="math">(1,g)</span>, giving us: <span class="math">d=C=(g^{\\beta},g^{\\alpha})</span>. We then proceed by considering the following two winning conditions; in each case, a winning adversary can break strong RSA.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">u_{A}\\neq u_{B}</span></li>

      <li><span class="math">v_{A}\\neq v_{B}\\,\\wedge\\,u_{A}=u_{B}</span></li>

    </ol>

    <p class="text-gray-300">Case 1: <span class="math">u_{A}\\neq u_{B}</span></p>

    <p class="text-gray-300">The first case follows similarly to (Case 1) of Theorem 1. From the verification equations of <span class="math">\\pi_{A}</span>, we have that:</p>

    <p class="text-gray-300"><span class="math">\\pi_{A,2}^{z^{u_{A}}}=C_{2}=g^{\\alpha},\\qquad\\pi_{A,2}^{u_{A}}B_{A}^{z}=g\\,.</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Thus, by Lemma 3, we know that $z^{u_{A}}\\,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,\\alpha<span class="math">. Similarly, from the verification equations of </span>\\pi_{B}$, we have that:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\pi_{B,2}^{z^{u_{B}}}=C_{2}=g^{\\alpha},\\qquad\\pi_{B,2}^{u_{B}}B_{B}^{z}=g\\,.</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Again, by Lemma 3, we have that <span class="math">\\gcd(\\alpha/z^{u_{B}},z)=1</span>. However, this is a contradiction. Wlog say <span class="math">u_{A}&gt;u_{B}</span>, then since $z^{u_{A}}\\,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,\\alpha<span class="math">, it cannot be that </span>\\gcd(\\alpha/z^{u_{B}},z)=1$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Case 2: <span class="math">v_{A}\\neq v_{B}\\wedge u_{A}=u_{B}</span></p>

    <p class="text-gray-300">The second case follows exactly from (Case 2) of Theorem 1 where <span class="math">\\alpha_{A}=\\alpha</span>, <span class="math">\\beta_{A}=\\beta</span>, <span class="math">\\alpha_{B}=1</span>, and <span class="math">\\beta_{B}=0</span>. ∎</p>

    <h2 id="sec-41" class="text-2xl font-bold">Appendix E RSA Lookup Proof Computation</h2>

    <p class="text-gray-300">This section provides details for batch computation of RSA membership and non-membership proofs.</p>

    <h3 id="sec-42" class="text-xl font-semibold mt-8">E.1 Promises</h3>

    <p class="text-gray-300">One solution to alleviate the server workload and client latency in waiting for these proofs is the use of <em>promises</em>. A <em>promise</em> <em>[MBB^{+}15]</em> is a signed statement by the server of a claimed lookup value and the promise to compute a corresponding (non-)membership proof for a specific epoch (by a certain time). A promise allows a client to act on their query without waiting for the full proof; the client can later query the full proof by the promised time and provide evidence of a broken promise if appropriate.</p>

    <h3 id="sec-43" class="text-xl font-semibold mt-8">E.2 Batch Computation</h3>

    <p class="text-gray-300">Delaying computation of (non-)membership proofs is also of benefit to the server, as it allows use of existing techniques <em>[x1, x28]</em> for computing a batch of <span class="math">m</span> (non-)membership proofs together in time <span class="math">O(N+m\\log m)</span> time, an improvement over computing each proof individually at the time of request (<span class="math">O(N\\cdot m)</span>) where <span class="math">N</span> is the total number of past updates. Naively with batching, there is a dependence on <span class="math">N</span>, the total number of updates (as opposed to simply the total number of keys), however we show that by storing some additional state, batch computation can be achieved in time <span class="math">O(K+m\\log m)</span> where <span class="math">K</span> is the number of keys in the dictionary.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Figure 14 (left) provides pseudocode for the <span class="math">O(K+m\\log m)</span> algorithm to batch compute membership proofs for a subset of <span class="math">m</span> keys over <span class="math">N</span> total updates in the key-value commitment. We consider a set <span class="math">\\mathcal{K}</span> of unique keys in the commitment and a subset <span class="math">\\mathcal{K}^{\\prime}\\subseteq\\mathcal{K}</span> of size <span class="math">m</span> for which to compute membership proofs, where $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathcal{K}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=K<span class="math">. For the case of non-membership, we consider </span>\\mathcal{K}^{\\prime}<span class="math"> a disjoint set from </span>\\mathcal{K}<span class="math">, </span>\\mathcal{K}^{\\prime}\\cap\\mathcal{K}=\\varnothing<span class="math">. If instead of storing only the information </span>[k,v,u]_{i}<span class="math"> for each entry of </span>\\mathcal{K}<span class="math">, and instead precomputing and additionally maintaining </span>\\mathsf{H}(k_{i})^{u-1}<span class="math">, then the batch computation cost will no longer have a dependence on the number of updates to the dictionary, only the number of keys. The </span>O(m\\log m)<span class="math"> work takes place in the </span>\\mathsf{BatchRecurse}$ protocol which adapts existing techniques from <em>[x1, x28]</em> for computing batch membership and non-membership proofs</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">!<a href="img-14.jpeg">img-14.jpeg</a> Figure 14: Algorithms for batch computation of membership proofs (left) and non-membership proofs (right).</p>

    <p class="text-gray-300">for RSA accumulators. The  <span class="math">O(K)</span>  work is in computing the initial values  <span class="math">(h,g,B,a)</span>  passed to BatchRecurse representing the state of all keys in  <span class="math">\\mathcal{K} \\setminus \\mathcal{K}&#x27;</span> ; we will refer to these as helper values for membership proof computation.</p>

    <p class="text-gray-300">An alternative to promises for computing membership proofs is to periodically precompute membership proofs for all keys, and then on a lookup query, perform individual key updates for the key since the last batch precomputation. We provide caching as a more granular precomputation strategy, allowing for the server to maintain different caches of keys that allow for efficient precomputation, and that can be recomputed on different schedules based on, for example, the "hotness" of the cache. Our approach is to maintain the helper values  <span class="math">(h,g,B,a)</span>  for a cache  <span class="math">\\mathcal{K}&#x27;</span>  as a set of  <span class="math">\\ell</span>  updates  <span class="math">\\mathcal{U} = [(k,\\delta)]_i^\\ell</span>  is applied to the commitment. Recall, originally computing these helper values takes time  <span class="math">O(K)</span> . However, once computed, if the helper values are maintained to reflect the updated set  <span class="math">\\mathcal{K}</span>  then membership proofs for the keys in  <span class="math">\\mathcal{K}&#x27;</span>  can be recomputed with only  <span class="math">O(m\\log m)</span>  work.</p>

    <p class="text-gray-300">!<a href="img-15.jpeg">img-15.jpeg</a></p>

    <p class="text-gray-300">The UpdateHelper pseudocode above shows how to maintain the helper values by applying updates from  <span class="math">\\mathcal{U}</span> . The update protocol runs in  <span class="math">O(m + \\ell)</span>  time.</p>

    <p class="text-gray-300">Because maintaining a cache requires persistently updating its corresponding helper value, the system cannot efficiently maintain too many caches. One possible distribution of cache sizes if there are  <span class="math">K</span>  total keys is by sizes of power of 2, leading to  <span class="math">\\log K</span>  caches to maintain.</p>

    <p class="text-gray-300">E.4 Logarithmic Witness Verification</p>

    <p class="text-gray-300">Here we present an alternative dictionary construction that admits membership proof verification time logarithmic in the version number rather than linear. It does so at the expense of increasing from constant to logarithmic size proofs, and by increasing the total number of keys stored in the RSA accumulator structure leading to increases in batch computation time.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Linear strawman. For illustrative purposes, first consider the following strawman. Instead of encoding the value of a key <span class="math">k</span> using <span class="math">z=\\mathsf{H}(k)</span>, we encode the value of the key using two values, <span class="math">z=\\mathsf{H}(k)</span> and $z_{1}=\\mathsf{H}(k\\mathbin{\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}ctr)<span class="math">, where </span>ctr<span class="math"> is initialized to 1. The version number of </span>z<span class="math"> is initialized to </span>ctr=1<span class="math">, and the value of </span>k<span class="math"> is encoded into </span>z_{1}<span class="math"> and updated by incrementing the version number of </span>z_{1}<span class="math"> as before. However, now when the version number of </span>z_{1}<span class="math"> reaches some threshold </span>t<span class="math">, instead of incrementing the version number past </span>t<span class="math">, the counter is incremented and the value is initialized as version 1 of </span>z_{2}=\\mathsf{H}(k\\mathbin{\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}2)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">We can continue this update pattern to ensure that users only need to verify two lookup proofs for monitoring and lookups: <span class="math">z</span> and <span class="math">z_{ctr}</span>. When monitoring, a user verifies the version number of <span class="math">z</span> is what they expect with respect to <span class="math">ctr=\\lceil\\frac{u}{t}\\rceil</span>, <span class="math">u_{z}=ctr</span>, that the version of <span class="math">z_{ctr}</span> is what they expect, <span class="math">u_{z_{ctr}}=u\\mod t</span>, and that the value of <span class="math">z_{ctr}</span> is equal to the current value <span class="math">v</span>. When performing a lookup, a user looks up the version of <span class="math">z</span> to determine the current counter <span class="math">ctr</span> to query for the value, which can be found by querying $z_{ctr}=\\mathsf{H}(k\\mathbin{\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}ctr)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The time complexity of this strawman is as follows: Verification of the value lookup for <span class="math">z_{ctr}</span> is guaranteed to be of time <span class="math">\\mathcal{O}(t)</span> since the version number will always be <span class="math">\\leq t</span>, however the verification of the version of <span class="math">z</span> will continue to grow linearly in <span class="math">u</span>, <span class="math">\\mathcal{O}(u/t)</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Logarithmic solution via tree organization. We can resolve the linear dependence by repeating the process recursively creating a tree. The sentinel <span class="math">z=\\mathsf{H}(k)</span> now encodes a version number representing the current height of the tree <span class="math">u_{z}=\\ell</span>. The current root of the tree is found at $z_{\\ell,0}=\\mathsf{H}(k\\mathbin{\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\ell\\mathbin{\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}0)<span class="math"> and encodes a version number counter representing which of its children is the current active child </span>u_{z_{\\ell,0}}=ctr_{\\ell,0}<span class="math">. The lookup proceeds by checking the indicated child at the next layer of the tree at </span>z_{\\ell-1,0,ctr_{\\ell,0}}=\\mathsf{H}(k\\mathbin{\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\ell-1\\mathbin{\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}0\\mathbin{\\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}ctr_{\\ell,0})<span class="math">, which encodes a version counter for the next child, and so on until the tree height is equal to 0. At layer 0, the indicated </span>z_{0}$ value encodes the value of the key.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">As in the linear strawman, we bound the version number of all non-sentinel <span class="math">z_{\\ell}</span> values to <span class="math">t</span>, where <span class="math">t</span> now represents the branching factor of the tree. If an internal <span class="math">z_{\\ell}</span> value reaches its maximum version number <span class="math">t</span>, the parent <span class="math">z_{\\ell+1}</span> is incremented (or created as a new root and initialized with version 1), and the parent’s next child at layer <span class="math">\\ell</span> is initialized at version 1, and so forth until a new leaf is created where the new value is encoded. If a parent reaches its maximum version number <span class="math">t</span> and a new root is created, the sentinel value <span class="math">z</span> is also incremented.</p>

    <p class="text-gray-300">The verifier time complexity of this solution is in verifying a single sentinel lookup proof with version <span class="math">u_{z}=\\ell=\\lceil\\log_{t}u\\rceil</span> indicating the tree height and then <span class="math">\\ell</span> lookup proofs of maximum version <span class="math">t</span>. In total, this results in a verification time of <span class="math">\\mathcal{O}(t\\log_{t}u)</span>, and a proof size of <span class="math">\\mathcal{O}(\\log_{t}u)</span>.</p>

    <p class="text-gray-300">Unfortunately encoding values in this tree structure means that entries for each internal node are added to the RSA accumulator (<span class="math">\\frac{2u}{t}</span> internal nodes). In total, the RSA accumulator contains entries on the order of linear in the versions of all of its included keys, which can significantly slow down batch computation of all membership proofs. We observe that for each included key, only the logarithmic number of entries representing the current active path are needed to serve lookup proofs for a key. A server may maintain a cache using the techniques of Appendix E.3 of the set of entries logarithmic in the versions of included keys to more efficiently keep membership proofs updated. As keys are updated and the membership paths in the tree are changed, new initialized internal nodes can be easily added to the cache. However, even still, occasionally an expensive linear in the total entries (i.e., in the versions of all keys) batch computation operation will be needed to prune out-dated path entries from the cache.</p>

    <h2 id="sec-45" class="text-2xl font-bold">Appendix F Security of AHD Constructions</h2>

    <p class="text-gray-300">In this section we provide theorem statements and proof sketches for the AHD security of the two generic transforms, <span class="math">\\mathsf{AHD}_{\\mathsf{IVC}}</span> (Figure 2) and <span class="math">\\mathsf{AHD}_{\\mathsf{Amtz}}</span> (Figure 3). The security properties for an AHD scheme are formalized as pseudocode security games and provided in Figure 15. The key binding game is equivalent to that of authenticated dictionaries. The history binding game tasks an adversary with producing two history proofs (or sequences of history proofs) that verify with two different digests for the same epoch. The invariant soundness game tasks an adversary with producing lookup proofs for a key with two values that do not satisfy the invariant, while also proving the invariant holds between the two epochs for which the lookup proofs were provided. We define an adversary’s advantage against these games, respectively, as:</p>

    <p class="text-gray-300"><span class="math">\\mathbf{Adv}^{\\text{bind}}_{\\mathsf{AHD},\\mathcal{A}}(\\lambda)=\\Pr[\\textsc{Bind}^{\\mathsf{AHD}}_{\\mathcal{A}}(\\lambda)=1]\\;,\\qquad\\mathbf{Adv}^{\\text{hbind}}_{\\mathsf{AHD},\\mathcal{A}}(\\lambda)=\\Pr[\\textsc{HistBind}^{\\mathsf{AHD}}_{\\mathcal{A}}(\\lambda)=1]\\;,</span></p>

    <p class="text-gray-300"><span class="math">\\mathbf{Adv}^{\\text{inv}}_{\\mathsf{AHD},\\Phi,\\mathcal{A}}(\\lambda)=\\Pr[\\textsc{InvSound}^{\\mathsf{AHD},\\Phi}_{\\mathcal{A}}(\\lambda)=1]\\;.</span></p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">!<a href="img-16.jpeg">img-16.jpeg</a></p>

    <p class="text-gray-300">!<a href="img-17.jpeg">img-17.jpeg</a> Figure 15: Security games for strong key binding (left), history binding (middle), and invariant preservation (right) for authenticated history dictionaries.</p>

    <p class="text-gray-300">!<a href="img-18.jpeg">img-18.jpeg</a></p>

    <p class="text-gray-300">Our AHD transforms are generic with respect to an AD, a VC, and a succinct non-interactive proof system that supports circuit relations. For the AD, we will require binding and invariant soundness, and for the VC we will require binding; defined in Figure 11. For the non-interactive proof system, we will require soundness.</p>

    <p class="text-gray-300">Key binding and history binding. We first consider key binding and history binding, for which both  <span class="math">\\mathsf{AHD}_{\\mathsf{IVC}}</span>  and  <span class="math">\\mathsf{AHD}_{\\mathsf{Amtz}}</span>  use the same mechanisms. Key binding is achieved by relying directly on an underlying AD and history binding relies on an append-only VC. We provide the following theorems:</p>

    <p class="text-gray-300">Theorem 3. For any adversary  <span class="math">\\mathcal{A}</span>  against the key binding of  <span class="math">\\mathrm{AHD}_{\\mathrm{IVC}}[\\mathrm{AD},\\mathrm{VC},\\mathrm{SNARK}]</span> , we give adversary  <span class="math">\\mathcal{B}</span>  such that</p>

    <div class="my-4 text-center"><span class="math-block">\\mathbf {A d v} _ {\\mathrm {A H D} _ {\\mathrm {I V C}} [ \\mathrm {A D}, \\mathrm {V C}, \\mathrm {S N A R K} ], \\mathcal {A}} ^ {\\text {b i n d}} (\\lambda) \\leq \\mathbf {A d v} _ {\\mathrm {A D}, \\mathcal {B}} ^ {\\text {b i n d}} (\\lambda).</span></div>

    <p class="text-gray-300">Theorem 4. For any adversary  <span class="math">\\mathcal{A}</span>  against the key binding of  <span class="math">\\mathrm{AHD}_{\\mathrm{Amtz}}[\\mathrm{AD},\\mathrm{VC}]</span> , we give adversary  <span class="math">\\mathcal{B}</span>  such that</p>

    <div class="my-4 text-center"><span class="math-block">\\mathbf {A d v} _ {\\mathrm {A H D} _ {\\mathrm {A m t z}} [ \\mathrm {A D}, \\mathrm {V C} ], \\mathcal {A}} ^ {\\text {b i n d}} (\\lambda) \\leq \\mathbf {A d v} _ {\\mathrm {A D}, \\mathcal {B}} ^ {\\text {b i n d}} (\\lambda).</span></div>

    <p class="text-gray-300">Proof sketch: The lookup proofs in  <span class="math">\\mathsf{AHD}_{\\mathsf{IVC}}</span>  and  <span class="math">\\mathsf{AHD}_{\\mathsf{Amtz}}</span>  operate directly over the AD component of the digest,  <span class="math">d_{\\mathsf{AD}}</span> . Thus, a win in the AHD key binding game translates directly to a win in the AD key binding game by constructing a wrapper adversary  <span class="math">\\mathcal{B}</span>  that forwards the same values output from  <span class="math">\\mathcal{A}</span>  replacing  <span class="math">d = (d_{\\mathsf{AD}}, d_{\\mathsf{VC}})</span>  with  <span class="math">d_{\\mathsf{AD}}</span> .</p>

    <p class="text-gray-300">Theorem 5. For any adversary  <span class="math">\\mathcal{A}</span>  against the history binding of  <span class="math">\\mathrm{AHD}_{\\mathrm{IVC}}[\\mathrm{AD},\\mathrm{VC},\\mathrm{SNARK}]</span> , we give adversary  <span class="math">\\mathcal{B}</span>  such that</p>

    <div class="my-4 text-center"><span class="math-block">\\mathbf {A d v} _ {\\mathrm {A H D} _ {\\mathrm {I V C}} [ \\mathrm {A D}, \\mathrm {V C}, \\mathrm {S N A R K} ], \\mathcal {A}} ^ {\\text {b i n d}} (\\lambda) \\leq \\mathbf {A d v} _ {\\mathrm {A D}, \\mathcal {B}} ^ {\\text {b i n d}} (\\lambda).</span></div>

    <p class="text-gray-300">Theorem 6. For any adversary  <span class="math">\\mathcal{A}</span>  against the history binding of  <span class="math">\\mathrm{AHD}_{\\mathrm{Amtz}}[\\mathrm{AD},\\mathrm{VC}]</span> , we give adversary  <span class="math">\\mathcal{B}</span>  such that</p>

    <div class="my-4 text-center"><span class="math-block">\\mathbf {A d v} _ {\\mathrm {A H D} _ {\\mathrm {A m t z}} [ \\mathrm {A D}, \\mathrm {V C} ], \\mathcal {A}} ^ {\\text {b i n d}} (\\lambda) \\leq \\mathbf {A d v} _ {\\mathrm {A D}, \\mathcal {B}} ^ {\\text {b i n d}} (\\lambda).</span></div>

    <p class="text-gray-300">Proof sketch: We construct  <span class="math">\\mathcal{B} = (\\mathcal{B}_1, \\mathcal{B}_2)</span>  against the index binding of VC as a relatively simple wrapper around  <span class="math">\\mathcal{A} = (\\mathcal{A}_1, \\mathcal{A}_2)</span> . First stage adversary  <span class="math">\\mathcal{B}_1</span>  runs AHD setup and replaces the parameters for VC with its own public parameters, then runs  <span class="math">\\mathcal{A}_1</span> .  <span class="math">\\mathcal{B}_1</span>  parses the digest  <span class="math">d = (d_{\\mathrm{AD}}, d_{\\mathrm{VC}})</span>  and outputs  <span class="math">d_{\\mathrm{VC}}</span> .</p>

    <p class="text-gray-300">Second stage adversary  <span class="math">\\mathcal{B}_2</span>  runs  <span class="math">\\mathcal{A}_2</span>  and simulates PROVEHIST. Whenever  <span class="math">\\mathcal{A}_2</span>  queries a valid history proof,  <span class="math">\\mathcal{B}_2</span>  stores the VC lookup proof for each index  <span class="math">c_j</span>  and passes along the VC update proof to its own Prefix oracle. If  <span class="math">\\mathcal{A}_2</span>  makes a query that sets the win flag,  <span class="math">\\mathcal{B}_2</span>  must have two valid lookups for the same  <span class="math">c_j</span>  index for different values, which it will return to win the index binding game. Thus,  <span class="math">\\mathcal{B}</span>  wins whenever  <span class="math">\\mathcal{A}</span>  wins.</p>

    <p class="text-gray-300">Invariant soundness. The mechanisms by which invariant soundness is achieved differ between  <span class="math">\\mathrm{AHD}_{\\mathrm{IVC}}</span>  and  <span class="math">\\mathrm{AHD}_{\\mathrm{Amtz}}</span> . We consider each separately.</p>

    <p class="text-gray-300">Theorem 7. For any adversary  <span class="math">\\mathcal{A}</span>  against the invariant soundness of  <span class="math">\\mathrm{AHD}_{\\mathrm{IVC}}[\\mathrm{AD},\\mathrm{VC},\\mathrm{SNARK}]</span> , we give adversaries  <span class="math">\\mathcal{B},\\mathcal{C}</span> , and  <span class="math">\\mathcal{D}</span>  such that</p>

    <div class="my-4 text-center"><span class="math-block">\\mathbf {A d v} _ {\\mathrm {A H D} _ {\\mathrm {I V C}} [ \\mathrm {A D}, \\mathrm {V C}, \\mathrm {S N A R K} ], \\Phi_ {\\mathrm {v i n}}, \\mathcal {A}} ^ {\\mathrm {i n v}} (\\lambda) \\leq \\mathbf {A d v} _ {\\mathrm {A D}, \\Phi_ {\\mathrm {v i n}}, \\mathcal {B}} ^ {\\mathrm {i n v}} (\\lambda) + \\mathbf {A d v} _ {\\mathrm {V C}, \\mathcal {C}} ^ {\\mathrm {b i n d}} (\\lambda) + \\mathbf {A d v} _ {\\mathrm {S N A R K}, \\mathcal {D}, \\mathrm {X}} ^ {\\mathrm {s o u n d}} (\\lambda),</span></div>

    <p class="text-gray-300">where  <span class="math">X</span>  is the knowledge extractor for SNARK.</p>

    <h6 id="sec-46" class="text-base font-medium mt-4">Proof sketch.</h6>

    <p class="text-gray-300">In building <span class="math">\\mathcal{B}</span> and <span class="math">\\mathcal{C}</span> against the invariant soundness and index binding of <span class="math">\\mathsf{AD}</span> and <span class="math">\\mathsf{VC}</span>, respectively, we will first need to extract the valid lookup and update proofs attested to in the recursive <span class="math">\\mathsf{SNARK}</span> for the checkpoint epochs <span class="math">[c_{j}]_{j}^{m}</span>. To show that valid proofs for <span class="math">\\mathsf{AD}</span> and <span class="math">\\mathsf{VC}</span> can be extracted, we build <span class="math">\\mathcal{D}</span> against the soundness of <span class="math">\\mathsf{SNARK}</span> that wins if this is not the case. When <span class="math">\\mathcal{A}</span> outputs valid <span class="math">\\mathsf{SNARK}</span> <span class="math">\\pi_{\\Phi}</span>, <span class="math">\\mathcal{D}</span> extracts the full history of <span class="math">\\mathsf{AD.VerUpd}</span>, <span class="math">\\mathsf{VC.VerUpd}</span>, and <span class="math">\\mathsf{VC.VerLkup}</span> proofs to the initial digest. It does this recursively by additionally extracting the <span class="math">\\mathsf{SNARK}</span> proof for the prior epoch, and then repeating extraction on the prior epoch <span class="math">\\mathsf{SNARK}</span> proof. If any extraction fails to produce valid proofs, <span class="math">\\mathcal{D}</span> wins the soundness game. Naively, from the way we present <span class="math">\\mathsf{AHD}_{\\mathsf{IVC}}</span>, this extraction will be linear in the number of epochs. We did this for simplicity of presentation, to create a tighter reduction, one would use tree-based techniques to execute recursion with logarithmic depth <em>[x1]</em>. Then <span class="math">\\mathcal{D}</span> would perform logarithmic extraction for each checkpoint given by <span class="math">\\mathcal{A}</span>.</p>

    <p class="text-gray-300">Now given these extracted proofs, we show that a winning adversary <span class="math">\\mathcal{A}</span> corresponds to either a break in invariant soundness of <span class="math">\\mathsf{AD}</span> or a break in index binding of <span class="math">\\mathsf{VC}</span>. First we show that the <span class="math">\\mathcal{A}</span> provided digests <span class="math">[d_{c_{j}}]_{j}^{m}</span> will be equal to the extracted digests (for which we have valid extracted proofs). If <span class="math">\\mathcal{A}</span> wins, the provided digests verify under <span class="math">\\mathsf{VerHist}</span>, meaning that there exists a valid <span class="math">\\mathsf{VC.VerLkup}</span> proof for the digest at index <span class="math">c_{j}</span>. On the other hand, we have a sequence of extracted <span class="math">\\mathsf{VC.VerUpd}</span> proofs with an extracted lookup proof for an extracted digest each index. If the extracted digest for an index does not match that of a provided digest, we construct <span class="math">\\mathcal{C}</span> that wins the index binding game by querying the sequence of update proofs to <span class="math">\\mathsf{Prefix}</span> and then outputting the two lookup proofs for the index <span class="math">c_{j}</span> where the extracted digest differs from the provided digest.</p>

    <p class="text-gray-300">Finally, now given that the provided digests match the extracted digests, we build <span class="math">\\mathcal{B}</span> against invariant soundness. By <span class="math">\\mathcal{A}</span>’s winning condition, we have that the invariant is not preserved for key <span class="math">k</span> between <span class="math">c_{i_{A}}</span> and <span class="math">c_{i_{B}}</span>. However, we have an extracted sequence of valid invariant proofs for <span class="math">\\mathsf{AD}</span> between <span class="math">c_{i_{A}}</span> and <span class="math">c_{i_{B}}</span>. <span class="math">\\mathcal{B}</span> outputs the sequence of extracted invariant proofs along with the lookup proofs provided by <span class="math">\\mathcal{A}</span> to win the invariant soundness game for <span class="math">\\mathsf{AD}</span>.</p>

    <h6 id="sec-47" class="text-base font-medium mt-4">Theorem 8.</h6>

    <p class="text-gray-300">For any adversary <span class="math">\\mathcal{A}</span> against the invariant soundness of <span class="math">\\mathsf{AHD}_{\\mathsf{Amtz}}[\\mathsf{AD},\\mathsf{VC}]</span>, we give adversary <span class="math">\\mathcal{B}</span> such that</p>

    <p class="text-gray-300"><span class="math">\\mathbf{Adv}^{\\text{inv}}_{\\mathsf{AHD}_{\\mathsf{Amtz}}[\\mathsf{AD},\\mathsf{VC}],\\Phi_{\\mathsf{vsn}},\\mathcal{A}}(\\lambda)\\leq\\mathbf{Adv}^{\\text{inv}}_{\\mathsf{AD},\\Phi_{\\mathsf{vsn}},\\mathcal{B}}(\\lambda)\\,.</span></p>

    <h6 id="sec-48" class="text-base font-medium mt-4">Proof sketch.</h6>

    <p class="text-gray-300">In <span class="math">\\mathsf{AHD}_{\\mathsf{Amtz}}</span>, the invariant proof already consists of a sequence of invariant proofs for <span class="math">\\mathsf{AD}</span> between each of the checkpoints. <span class="math">\\mathcal{B}</span> simply returns the sequence of invariant proofs between <span class="math">c_{i_{A}}</span> and <span class="math">c_{i_{B}}</span> along with the lookup proofs to win the invariant soundness game for <span class="math">\\mathsf{AD}</span>.</p>

    <h2 id="sec-49" class="text-2xl font-bold">Appendix G Checkpoint Auditing Security</h2>

    <p class="text-gray-300">In this section, we prove the security of the checkpoint auditing mechanism.</p>

    <h3 id="sec-50" class="text-xl font-semibold mt-8">G.1 Security Definition</h3>

    <p class="text-gray-300">First we provide a formal definition for checkpoint auditing with respect to an authenticated history dictionary and an immediately consistent bulletin board. This definition is inspired by the “oscillation” security definition of <em>[MKL^{+}20]</em> in which an adversary wins if a client does not detect a ghost key attack. Our security game is slightly more complex as client checkpoint auditing requires pairwise clients to perform audits, in contrast to <em>[MKL^{+}20]</em> where a single client may audit and rely on additional assurances from trusted third-party auditors.</p>

    <p class="text-gray-300">The security game for detection of invariant breaks in checkpoint auditing is defined by the pseudocode game <span class="math">\\mathsf{CKPTDetect}</span> given in Figure 16. It models two clients: client 1 monitors an adversary-chosen key over time, and client 0 performs lookups to the key. The goal of the adversary is to serve a lookup value that is accepted by client 0, but is not consistent with the “true” value maintained by client 1. More specifically, the adversary may induce periodic audits by client 0 and periodic monitoring audits or value updates of the key by client 1. The exposed oracles represent the verification procedure that clients would take during auditing and, as such, take as input proofs that would be served by the server (fully controlled by the adversary). As specified in Figure 6, clients audit logarithmic number checkpoints selected by the compact range, and on a value update, a monitoring client audits up to epoch prior to the change in value. The adversary also has full control over the digest, but may only publish a single digest for each epoch, representing an immediately consistent bulletin board. At the end of the game, the adversary outputs a value <span class="math">v^{\\prime}</span> and lookup proof along with three epoch numbers <span class="math">i_{1},i_{2},i_{3}</span>. The adversary wins if the following conditions are satisfied:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">v^{\\prime}</span> verifies under the lookup proof at epoch <span class="math">i_{1}</span> for client 0. Thus, we additionally require that client 0 audited epoch <span class="math">i_{1}</span>.</li>

      <li><span class="math">v^{\\prime}</span> does not match the expected value of the key at digest <span class="math">i_{1}</span> as monitored by client 1 and tracked by the game.</li>

      <li>The appropriate eventual detection auditing conditions have been met. There exists an epoch <span class="math">i_{2}\\geq i_{1}</span> that was monitored by client 1, and there exists an epoch <span class="math">i_{3}\\geq i_{2}</span> that was audited by client 0.</li>

    </ol>

    <p class="text-gray-300">We define an adversary <span class="math">\\mathcal{A}</span>’s advantage against the checkpoint auditing game as:</p>

    <p class="text-gray-300"><span class="math">\\mathbf{Adv}^{\\text{ckpt}}_{\\mathsf{AHD},\\Phi,\\mathcal{A}}(\\lambda)=\\Pr[\\mathsf{CKPTDetect}^{\\mathsf{AHD},\\Phi}_{\\mathcal{A}}(\\lambda)=1]\\,.</span></p>

    <p class="text-gray-300">!<a href="img-19.jpeg">img-19.jpeg</a></p>

    <p class="text-gray-300">!<a href="img-20.jpeg">img-20.jpeg</a> Figure 16: Security game for invariant break detection with checkpoint auditing. Figure 17: Cases for proof of shared checkpoint epoch. Case 1 (left) has  <span class="math">\\ell_2</span>  as leftmost leaf of  <span class="math">x</span> 's subtree. Case 2 (right) does not.</p>

    <p class="text-gray-300">Before proving security of the checkpointing auditing definition, we first prove the core theorem of shared checkpoints for overlapping ranges that the following proof of security will rely on.</p>

    <p class="text-gray-300">Theorem 9. For any two ranges  <span class="math">(\\ell_1, r_1)</span>  and  <span class="math">(\\ell_2, r_2)</span>  that are overlapping, i.e.,  <span class="math">\\ell_1 \\leq \\ell_2 &amp;lt; r_1 \\leq r_2</span> , the compact range of  <span class="math">(\\ell_1, r_1)</span>  shares a subrange boundary with the compact range of  <span class="math">(\\ell_2, r_2)</span> . That is, for  <span class="math">[( \\ell_{1,i}, r_{1,i})]_i^{m} \\gets \\text{CompactR}((\\ell_1, r_1))</span>  and  <span class="math">[( \\ell_{2,i}, r_{2,i})]_i^n \\gets \\text{CompactR}((\\ell_2, r_2))</span> , there exists  <span class="math">i, j</span>  such that  <span class="math">\\ell_{1,i} = \\ell_{2,j}</span> .</p>

    <p class="text-gray-300">Proof. First consider the binary tree imposed over all epochs. In this binary tree, define node  <span class="math">x</span>  as the root of the smallest subtree that contains  <span class="math">\\ell_2</span>  and  <span class="math">r_1</span> . We will show that their exists a shared boundary in the compact range representation induced by  <span class="math">(\\ell_1, r_1)</span>  and  <span class="math">(\\ell_2, r_2)</span>  somewhere within this subtree rooted at  <span class="math">x</span> .</p>

    <p class="text-gray-300">Consider the following two exhaustive cases (depicted in Figure 17):</p>

    <p class="text-gray-300">Case 1:  <span class="math">\\ell_2</span>  is the leftmost leaf of  <span class="math">x</span> 's subtree.</p>

    <p class="text-gray-300">In this case, we will show that  <span class="math">\\ell_2</span>  itself is a shared boundary between the two compact range representations.</p>

    <p class="text-gray-300">If <span class="math">r_{2}</span> is not in <span class="math">x</span>’s subtree, then <span class="math">x</span>’s subtree (or a supertree of <span class="math">x</span>’s subtree if <span class="math">x</span> is a left child) is included in the compact range of <span class="math">(\\ell_{2},r_{2})</span>. Otherwise, if <span class="math">r_{2}</span> is in <span class="math">x</span>’s subtree, <span class="math">r_{2}</span> would necessarily be in <span class="math">x</span>’s right subtree (since <span class="math">r_{2}\\geq r_{1}</span>) and thus <span class="math">x</span>’s left subtree is included in the compact range. For the other range, since <span class="math">r_{1}</span> is included in <span class="math">x</span>’s right subtree and <span class="math">\\ell_{1}&lt;\\ell_{2}</span> is not in <span class="math">x</span>’s left subtree, then <span class="math">x</span>’s left subtree is included in the compact range of <span class="math">(\\ell_{1},r_{1})</span>.</p>

    <p class="text-gray-300">Case 2: <span class="math">\\ell_{2}</span> is not the leftmost leaf of <span class="math">x</span>’s subtree.</p>

    <p class="text-gray-300">Call <span class="math">y</span> the leftmost leaf of <span class="math">x</span>’s right subtree. We argue that <span class="math">y</span> is a shared boundary between the two compact range representations.</p>

    <p class="text-gray-300">First, we argue that if the right endpoint of a range is in a subtree <span class="math">T</span> <em>and</em> the left endpoint is not, then the leftmost leaf of <span class="math">T</span> is a boundary in the range’s compact range representation. Consider two cases. First, if the right endpoint is in <span class="math">T</span>’s right subtree, then <span class="math">T</span>’s left subtree is a compact subrange included in the representation and therefore, the leftmost leaf of <span class="math">T</span> is a boundary. Second, if the right endpoint is in <span class="math">T</span>’s left subtree, then we use a recursive argument to claim that the leftmost leaf of <span class="math">T</span>’s left subtree (i.e., the leftmost leaf of <span class="math">T</span>) is a boundary. The base case of this argument is that the right endpoint is itself the leftmost leaf of <span class="math">T</span>, in which case, it is a boundary.</p>

    <p class="text-gray-300">Now with this argument, first consider <span class="math">r_{1}</span> which is in <span class="math">x</span>’s right subtree (<span class="math">\\ell_{1}</span> is not), then <span class="math">y</span> is a boundary of <span class="math">(\\ell_{1},r_{1})</span>. Next consider, <span class="math">(\\ell_{2},r_{2})</span>. If <span class="math">r_{2}</span> is in <span class="math">x</span>’s right subtree (<span class="math">\\ell_{2}</span> is not), then <span class="math">y</span> is a boundary by the same argument as above. Else, <span class="math">r_{2}</span> is not in <span class="math">x</span>’s subtree, so since <span class="math">\\ell_{2}</span> is not the leftmost leaf of <span class="math">x</span>’s subtree, then <span class="math">x</span>’s right subtree is included as a subrange in the compact range of <span class="math">(\\ell_{2},r_{2})</span> and <span class="math">y</span> is a boundary. ∎</p>

    <h3 id="sec-52" class="text-xl font-semibold mt-8">G.3 Proof of Checkpoint Auditing Eventual Detection</h3>

    <h6 id="sec-53" class="text-base font-medium mt-4">Theorem 10.</h6>

    <p class="text-gray-300">For any adversary <span class="math">\\mathcal{A}</span> against the checkpoint auditing eventual detection of <span class="math">\\mathsf{AHD}</span>, we give adversary <span class="math">\\mathcal{B}</span> such that</p>

    <p class="text-gray-300"><span class="math">\\mathbf{Adv}_{\\mathsf{AHD},\\Phi_{\\mathsf{van}},\\mathcal{A}}^{{\\mathsf{ckpr}}}(\\lambda)\\leq\\mathbf{Adv}_{\\mathsf{AHD},\\Phi_{\\mathsf{van}},\\mathcal{B}}^{{\\mathsf{inv}}}(\\lambda)\\,.</span></p>

    <h6 id="sec-54" class="text-base font-medium mt-4">Proof sketch.</h6>

    <p class="text-gray-300">Say the expected value of <span class="math">k</span> at <span class="math">i_{1}</span> according to client 1 is <span class="math">v</span> (i.e., <span class="math">V[i_{1}]=v</span>), and further say that it was updated to be equal to <span class="math">v^{\\prime}</span> at epoch <span class="math">i_{0}\\leq i_{1}</span>. Redefine <span class="math">i_{2}</span> to be the smallest epoch in <span class="math">aud_{1}</span> such that <span class="math">i_{2}\\geq i_{1}</span>. This ensures that <span class="math">V[i_{2}]=v</span>, and it is guaranteed that such an <span class="math">i_{2}</span> redefinition exists by how <span class="math">V</span> is populated in <span class="math">\\mathsf{CkptDetect}</span>. For a winning adversary, we have that the following sequences of invariant proofs were verified by either client 0 or client 1 because <span class="math">i_{1},i_{2},i_{3}</span> are in the sets of successful audits:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">0\\to c_{1}\\to i_{1}</span>: We know that client 0 verified some path of valid invariant proofs from epoch 0 through a shared checkpoint <span class="math">c_{1}</span> (we will show why such a shared checkpoint exists shortly) through epoch <span class="math">i_{1}</span>.</li>

      <li><span class="math">i_{0}\\to c_{1}\\to c_{2}\\to i_{2}</span>: We know that client 1 verified some path of valid invariant proofs from <span class="math">i_{0}</span> to <span class="math">i_{2}</span>, and since <span class="math">(i_{0},i_{2})</span> is overlapping with <span class="math">(0,i_{1})</span>, by Theorem 9, we have the existence of shared checkpoint <span class="math">c_{1}</span>, where <span class="math">i_{0}\\leq c_{1}\\leq i_{1}</span>. Again, we will show shortly the existence of a second shared checkpoint <span class="math">c_{2}</span>.</li>

      <li><span class="math">i_{1}\\to c_{2}\\to i_{3}</span>: We know that client 0 verified some path of valid invariant proofs from <span class="math">i_{1}</span> to <span class="math">i_{3}</span>, and since <span class="math">(i_{1},i_{3})</span> is overlapping with <span class="math">(i_{0},i_{2})</span>, by Theorem 9, we have the existence of shared checkpoint <span class="math">c_{2}</span>, where <span class="math">i_{1}\\leq c_{2}\\leq i_{2}</span>.</li>

    </ol>

    <p class="text-gray-300">Taking the above, we have that between client 0 and client 1, a path of valid invariant proofs were verified for:</p>

    <p class="text-gray-300"><span class="math">i_{0}\\to c_{1}\\to i_{1}\\to c_{2}\\to i_{2}\\,.</span></p>

    <p class="text-gray-300">By our redefinition of <span class="math">i_{2}</span>, we have that client 1 verified lookup proofs for <span class="math">v</span> at <span class="math">i_{0}</span> and <span class="math">i_{2}</span>. By the adversary’s winning condition, we have that client 0 verified a lookup proof for <span class="math">v^{\\prime}</span> at <span class="math">i_{1}</span>. However, by the versioned invariant, it is not possible for the value to change to <span class="math">v^{\\prime}</span> and then change back to <span class="math">v</span>. Say <span class="math">v=(v,u)</span> where <span class="math">u</span> denotes the version number. By the versioned invariant, <span class="math">v^{\\prime}=(v^{\\prime},u^{\\prime})</span>, where <span class="math">u^{\\prime}&gt;u</span>. Any future value <span class="math">v^{\\prime\\prime}=(v^{\\prime\\prime},u^{\\prime\\prime})</span> that preserves the versioned invariant cannot have <span class="math">u^{\\prime\\prime}&lt;u^{\\prime}</span>, so a valid lookup of <span class="math">v=(v,u)</span> at epoch <span class="math">i_{2}</span> is a break in invariant. We build <span class="math">\\mathcal{B}</span> to output the set of invariant and history proofs from epoch <span class="math">i_{1}</span> to epoch <span class="math">i_{2}</span> and provide the lookup proof at <span class="math">i_{1}</span> for <span class="math">v^{\\prime}</span> output by <span class="math">\\mathcal{A}</span> at game end and the lookup proof at <span class="math">i_{2}</span> provided by <span class="math">\\mathcal{A}</span> to <span class="math">\\mathsf{Monitor}_{1}</span> at <span class="math">i_{2}</span> for <span class="math">v</span>.</p>

    <h6 id="sec-55" class="text-base font-medium mt-4">Lemma 4.</h6>

    <p class="text-gray-300">For any adversary <span class="math">\\mathcal{A}</span> against the checkpoint auditing eventual detection of <span class="math">\\mathsf{AHD}</span>, we give adversary <span class="math">\\mathcal{B}</span> such that</p>

    <p class="text-gray-300"><span class="math">\\mathbf{Adv}_{\\mathsf{AHD},\\Phi_{\\mathsf{app}},\\mathcal{A}}^{{\\mathsf{ckpr}}}(\\lambda)\\leq\\mathbf{Adv}_{\\mathsf{AHD},\\Phi_{\\mathsf{app}},\\mathcal{B}}^{{\\mathsf{inv}}}(\\lambda)\\,.</span></p>

    <p class="text-gray-300">We immediately have the above lemma since the append-only invariant, like the versioned invariant, also ensures that no value can be reproduced once changed.</p>

    <h2 id="sec-56" class="text-2xl font-bold">Appendix H An RSA Authenticated Dictionary with Append-Only Invariant Proofs</h2>

    <p class="text-gray-300">The main body of the paper focuses on the versioned invariant for ADs, and we propose a versioned invariant proof for the <span class="math">\\mathsf{KVaC}</span> RSA AD construction in Appendix D. However, some applications require the stronger append-only invariant to be maintained</p>

    <p class="text-gray-300">for mapped values in an AD. Recall, in the append-only invariant, values of an AD are parsed as lists of values  <span class="math">L = [v_{j}]_{j}^{\\ell}</span> . It is formalized as  <span class="math">\\Phi_{\\mathrm{app}}</span>  in Appendix C.</p>

    <p class="text-gray-300">Here, we propose an extension of KVaC for which we can construct invariant proofs for the append-only invariant; we refer to this construction as AO-KVaC. The commitment structure is shown below:</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C \\leftarrow \\left(g ^ {\\left(\\prod_ {i} ^ {n} \\mathsf {H} \\left(k _ {i}\\right) ^ {\\ell_ {i}}\\right) \\cdot \\left(\\prod_ {i} ^ {n} \\prod_ {j} ^ {\\ell_ {i}} \\mathsf {H} \\left(k _ {i} \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">j\\right)\\right) \\cdot \\left(\\sum_ {i} ^ {n} \\sum_ {j} ^ {\\ell_ {i}} v _ {i, j} / \\mathsf {H} \\left(k _ {i} \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">j\\right)\\right)}, g ^ {\\left(\\prod_ {i} ^ {n} \\mathsf {H} \\left(k _ {i}\\right) ^ {\\ell_ {i}}\\right) \\cdot \\left(\\prod_ {i} ^ {n} \\prod_ {j} ^ {\\ell_ {i}} \\mathsf {H} \\left(k _ {i} \\</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">j\\right)\\right)}\\right).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">Intuitively, the commitment is made up of (1) a counter dictionary to track the length  <span class="math">\\ell</span>  of the append-only list for key  <span class="math">k</span>  and (2) an insert-only key-value dictionary, much like KVaC, to store the current and previous values for each key. The counter dictionary is represented by accumulating  <span class="math">z = \\mathsf{H}(k)</span>  repeatedly as  <span class="math">z^{\\ell}</span> . The insert-only key-value dictionary is represented by a KVaC in which inserted elements are not allowed to be updated, i.e., only elements at version number 1 are valid. The value  <span class="math">v</span>  for key  <span class="math">k</span>  is appended to position  <span class="math">j</span>  of  <span class="math">k</span> 's append-only list by inserting  <span class="math">v</span>  at "key"  <span class="math">k \\parallel j</span>  using  <span class="math">z_{j} = \\mathsf{H}(k \\parallel j)</span> . The counter dictionary is also incremented for key  <span class="math">k</span>  whenever a value is inserted. The full construction is given in Figure 18.</p>

    <p class="text-gray-300">We argue security below, but first provide some comments on the construction and opportunities for future work. First, as presented in Figure 18, the lookup proof for a list consists of the lookup proofs of each index of the list. It may be possible to aggregate these proofs into a single proof of smaller size and verification time using existing aggregation techniques [AR20, TXN20].</p>

    <p class="text-gray-300">Second, in some cases, it may be desirable to open just a single index of the list, e.g., if it is more efficient to do so than opening the entire list. We provide algorithms for doing so, but we do not formalize security for their individual use, and indeed, there exists some subtlety. In AO-KVaC, it is possible for a specific index of a list to be opened validly, but for other indices of the list to be invalid, e.g., if a value has not been set yet (version number is 0) or if a value has been updated past version number 1. When providing an index opening proof, you might want that verification will fail if the full list is not valid. To achieve this property, the index opening proof would need to be augmented with another proof that verifies completeness of the list. We provide such a proof below in which the prover proves that the counter dictionary includes exactly  <span class="math">\\ell z_{i}</span>  values (proving the length of the list) and exactly one  <span class="math">z_{i,j}</span>  value for each  <span class="math">j\\in [1,\\ell ]</span>  (proving version number is 1 for all indices). Unfortunately, such a completeness proof is of verification cost linear in the size of the list  <span class="math">\\ell</span> . We leave to future work the problem of investigating append-only constructions with efficient index opening proofs.</p>

    <p class="text-gray-300">!<a href="img-21.jpeg">img-21.jpeg</a></p>

    <p class="text-gray-300">We provide proof sketches below for the AD security of AO-KVaC, i.e., that it satisfies strong key binding and invariant update soundness with respect to  <span class="math">\\Phi_{\\mathrm{app}}</span> .</p>

    <p class="text-gray-300">Theorem 11. For any adversary  <span class="math">\\mathcal{A}</span>  against the strong key binding of AO-KVaC augmented with proof of update from initialization, we give adversaries  <span class="math">\\mathcal{B}</span>  and  <span class="math">\\mathcal{C}</span>  such that</p>

    <div class="my-4 text-center"><span class="math-block">\\mathbf {A d v} _ {\\mathsf {A O - K V a C}, \\mathcal {A}} ^ {b i n d} (\\lambda) \\leq \\mathbf {A d v} _ {\\mathsf {G G e n}, \\mathcal {B}} ^ {s t r o n g - r s a} (\\lambda) + \\mathbf {A d v} _ {\\mathsf {B B F}, \\mathcal {C}, \\mathsf {X}} ^ {s o u n d} (\\lambda),</span></div>

    <p class="text-gray-300">where  <span class="math">\\mathsf{GGen}</span>  is the group generation algorithm for the RSA quotient group used in AO-KVaC and  <span class="math">\\mathsf{X}</span>  is the knowledge extractor for BBF [BBF19].</p>

    <p class="text-gray-300">Proof sketch. The proof follows closely to that of Theorem 2. Using extractor  <span class="math">\\mathsf{X}</span>  for BBF, we extract values  <span class="math">(\\alpha ,\\beta)</span>  from the</p>

    <p class="text-gray-300">update proof of <span class="math">d</span> from the initial digest <span class="math">(1,g)</span>, giving us: <span class="math">d=C=(g^{\\beta},g^{\\alpha})</span>. We then proceed by considering the following two winning conditions; in each case, a winning adversary can break strong RSA.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\ell_{A}\\neq\\ell_{B}</span></li>

      <li><span class="math">\\exists j,\\enspace v_{A,j}\\neq v_{B,j}</span></li>

    </ol>

    <p class="text-gray-300">Case 1: <span class="math">\\ell_{A}\\neq\\ell_{B}</span></p>

    <p class="text-gray-300">Wlog take any verifying index <span class="math">j&lt;\\ell_{A}&lt;\\ell_{B}</span>. From the verification equations of <span class="math">\\pi_{A,j}</span>, we have that:</p>

    <p class="text-gray-300"><span class="math">\\pi_{A,2}^{z^{\\ell_{A}\\cdot z_{j}}}=C_{2}=g^{\\alpha},\\qquad\\pi_{A,2}^{a_{A}}B_{A}^{z\\cdot z_{j}}=g\\,.</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Thus, by Lemma 3, we know that $z^{\\ell}\\cdot z_{j}\\,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,\\alpha<span class="math">. Similarly, from the verification equations of </span>\\pi_{B,j}$, we have that:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300"><span class="math">\\pi_{B,2}^{z^{\\ell_{B}\\cdot z_{j}}}=C_{2}=g^{\\alpha},\\qquad\\pi_{B,2}^{a_{B}}B_{B}^{z\\cdot z_{j}}=g\\,.</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Again, by Lemma 3, we have that <span class="math">\\gcd(\\alpha/z^{\\ell_{B}}\\cdot z_{j},z\\cdot z_{j})=1</span>. However, this is a contradiction. Wlog say <span class="math">\\ell_{A}&gt;\\ell_{B}</span>, then since $z^{\\ell_{A}}\\cdot z_{j}\\,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\,\\alpha<span class="math">, it cannot be that </span>\\gcd(\\alpha/z^{\\ell_{B}}\\cdot z_{j},z\\cdot z_{j})=1$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Case 2: <span class="math">\\exists j,\\enspace v_{A,j}\\neq v_{B,j}</span></p>

    <p class="text-gray-300">The second case follows from (Case 2) of Theorem 2 setting <span class="math">u_{A}=u_{B}=1</span>.</p>

    <h6 id="sec-57" class="text-base font-medium mt-4">Theorem 12.</h6>

    <p class="text-gray-300">For any adversary <span class="math">\\mathcal{A}</span> against the append-only property of <span class="math">\\mathsf{AO}\\text{-}\\mathsf{KVaC}</span>, we give adversaries <span class="math">\\mathcal{B}</span> and <span class="math">\\mathcal{C}</span> such that</p>

    <p class="text-gray-300"><span class="math">\\mathbf{Adv}_{\\mathsf{AO}\\text{-}\\mathsf{KVaC},\\Phi_{\\mathsf{app}},\\mathcal{A}}^{\\mathsf{inv}}(\\lambda)\\leq\\mathbf{Adv}_{\\mathsf{GGen},\\mathcal{B}}^{\\mathsf{strong}\\text{-}\\mathsf{rea}}(\\lambda)+\\mathbf{Adv}_{\\mathsf{BBF},\\mathcal{C},\\mathsf{X}}^{\\mathsf{sound}}(\\lambda)\\,,</span></p>

    <p class="text-gray-300">where <span class="math">\\mathsf{GGen}</span> is the group generation algorithm for the RSA quotient group used in <span class="math">\\mathsf{AO}\\text{-}\\mathsf{KVaC}</span> and <span class="math">\\mathsf{X}</span> is the knowledge extractor for <span class="math">\\mathsf{BBF}</span> <em>[x1]</em>.</p>

    <h6 id="sec-58" class="text-base font-medium mt-4">Proof sketch.</h6>

    <p class="text-gray-300">The proof proceeds similarly to that of Theorem 1 for version-only security. Consider the two winning conditions:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\ell_{A}&gt;\\ell_{B}</span></li>

      <li><span class="math">\\exists j\\leq\\ell_{A},\\enspace v_{A,j}\\neq v_{B,j}</span></li>

    </ol>

    <p class="text-gray-300">Case 1: <span class="math">\\ell_{A}&gt;\\ell_{B}</span></p>

    <p class="text-gray-300">This case follows analogously to (Case 1) of the proof of Theorem 1 using the same approach as (Case 1) of Theorem 11 of selecting a verifying proof for any verifying index <span class="math">j</span>.</p>

    <p class="text-gray-300">Case 2: <span class="math">\\exists j,\\enspace v_{A,j}\\neq v_{B,j}</span></p>

    <p class="text-gray-300">This case follows analogously to (Case 2) of the proof of Theorem 1 setting <span class="math">u_{A}=u_{B}=1</span>.</p>

    <h2 id="sec-59" class="text-2xl font-bold">Appendix I AHDs from Groth16 SNARK Aggregation</h2>

    <h3 id="sec-60" class="text-xl font-semibold mt-8">I.1 Groth16 SNARK Aggregation</h3>

    <p class="text-gray-300">Here we present protocols for aggregating <span class="math">N</span> Groth16 SNARKs <em>[x10]</em>. These protocols are simplified, more optimized versions of the related aggregation protocols presented in <em>[BMM^{+}21]</em>, since here we focus on the case where the SNARKs are over the same relation and setup.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Bilinear pairing groups. We will make use of the following notation for bilinear pairing groups. (1) Groups <span class="math">\\mathbb{G}_{1},\\mathbb{G}_{2},\\mathbb{G}_{T}</span> are cyclic groups of prime order <span class="math">p</span>. (2) Group element <span class="math">g</span> is a generator of <span class="math">\\mathbb{G}_{1}</span>, <span class="math">h</span> is a generator of <span class="math">\\mathbb{G}_{2}</span>. (3) Pairing function <span class="math">e:\\mathbb{G}_{1}\\times\\mathbb{G}_{2}\\to\\mathbb{G}_{T}</span> is a computable map with the following properties: <em>Bilinearity</em>: <span class="math">\\forall\\enspace u\\in\\mathbb{G}_{1},v\\in\\mathbb{G}_{2},</span> and <span class="math">a,b\\in\\mathbb{Z}</span>, <span class="math">e(u^{a},v^{b})=e(u,v)^{ab}</span>, and <em>Non-degeneracy</em>: <span class="math">e(g,h)\\neq 1</span>. We assume an efficient setup algorithm that on input security parameter <span class="math">\\lambda</span>, generates a bilinear group, <span class="math">(p,\\mathbb{G}_{1},\\mathbb{G}_{2},\\mathbb{G}_{T},g,h,e)\\leftarrow\\mathcal{G}(1^{\\lambda})</span>, where $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">p</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">=\\lambda$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Inner product arguments. We will make use of the inner product arguments <span class="math">\\mathsf{TIPP}</span> and <span class="math">\\mathsf{MIPP}_{k}</span> for the following relations; we refer the reader to <em>[BMM^{+}21]</em> for details on their construction:</p>

    <p class="text-gray-300">\\[ \\mathcal{R}_{\\mathsf{TIPP}}=\\left\\{\\begin{array}[]{ccl}&g^{\\beta}\\in\\mathbb{G}_{1},\\;h^{\\alpha}\\in\\mathbb{G}_{2},\\;T,U,Z\\in\\mathbb{G}_{T},\\;\\gamma\\in\\mathbb{Z}_{p}\\;;\\\\ &[w]_{i}=\\left[g^{\\alpha^{2i}}\\right]_{i=0}^{m-1},[A_{i}]_{i=0}^{m-1}\\in\\mathbb{G}_{1}^{m},[v]_{i}=\\left[h^{\\beta^{2i}}\\right]_{i=0}^{m-1},[B_{i}]_{i=0}^{m-1}\\in\\mathbb{G}_{2}^{m},[r]_{i}=[\\gamma^{2i}]_{i=0}^{m-1}\\in\\mathbb{Z}_{p}^{m}\\\\ &&T=\\prod_{i=0}^{m-1}e(A_{i},v_{i})\\;\\wedge\\;U=\\prod_{i=0}^{m-1}e(w_{i},B_{i})\\;\\wedge\\;Z=\\prod_{i=0}^{m-1}e(A_{i}^{r_{i}},B_{i})\\end{array}\\right\\}\\enspace, \\]</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">AO-KVaC.Setup(λ) (a,b,G)←GGen(λ) g←G Return (a,b,G,g)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">AO-KVaC.ProveIndexMem([(ki,Li=[vi,j]ℓi)i,i,m,jm) [zi]i←[H(ki)i] [zi,j]i←[H(ki</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">j)]i V←(UiaUjℓi{(i,j)})\\{i,m,jm} π1←g(Πi<em>zi)·Σ(i,j)∈V(vi,j·Π(i,j)∈V{((i,j)}zi,j) π2←g(Πi</em>φim zi)·(Π(i,j)∈V zi,j) (a,b)←EEA((Πi*φi zi)·(Π(i,j)∈V zi,j),zimzim,jm) π←((π1,π2),(gk,a),l im) Return π</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">AO-KVaC.Commit([(ki,Li=[vi,j]ℓi)i] [zi]i←[H(ki)i] [zi,j]i←[H(ki</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">j)]i V←UiaUjℓi{(i,j)} C1←g(Πi<em>zi)·Σ(i,j)∈V(vi,j·Π(i,j)∈V{((i,j)}zi,j) C2←g(Πi</em>zi)·(Π(i,j)∈V zi,j) Return (C1,C2)</td>

            <td class="px-3 py-2 border-b border-gray-700">AO-KVaC.VerIndexMem(C,(k,v,j),π) z←H(k);zj←H(k</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">j) ((π1,π2),(B,a),l)←π (C1,C2)←C Return Λ((π1)zj(π2)v·zℓ=C1 (π2)zℓ·zj=C2 (π2)aBz·zj=g j≤l)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">AO-KVaC.Append(C,(k,v,j)) z←H(k);zj←H(k</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">j) (C1,C2)←C C'←(C1z·zjC2·v,C2z·zj) Return C'</td>

            <td class="px-3 py-2 border-b border-gray-700">AO-KVaC.ProveMem([(ki,Li=[vi,j]ℓi)i,m) [πj]i←[AO-KVaC.ProveIndexMem([(ki,Li)],im,j)]i Return [πj]i</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">AO-KVaC.BatchAppend(C,[(ki,vi,ji)i]n)) [zi]i←[H(k)i; [zi,j]i←[H(ki</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">ji)i] (C1,C2)←C Z←Πi zi zi,j Δ←Σi(vi ziΠiφi zi zi,j) C'←(C1Z2C2Δ,C2Z) Return C'</td>

            <td class="px-3 py-2 border-b border-gray-700">KVaC.VerMem(C,(k,L=[vj]ℓi),π=[πj]ℓi Return ℓ=ℓ ∧ ΛjA O-KVaC.VerIndexMem(C,(k,vj,j),πj) AO-KVaC.ProveNonMem([(ki,Li=[vi,j]ℓi)i,k')</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">AO-KVaC.ProveAppend(C,C',Z,Δ)) (C1,C2)←C; (C1',C2')←C' π←BBF.Prove((Z,Δ),(C1,C2,C1',C2'))</td>

            <td class="px-3 py-2 border-b border-gray-700">[z]i←[H(k)i; z'←H(k') (a,b)←EEA(Πi zi)i,z') Return (a,gb)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">KVaC.VerAppend(C,C',π) (C1,C2)←C; (C1',C2')←C' Return BBF.Ver((C1,C2,C1',C2'),π)</td>

            <td class="px-3 py-2 border-b border-gray-700">KVaC.VerNonMem(C,k',π) (a,B)←π z'←H(k'); (C1,C2)←C Return C2aBz'=g</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Figure 18: Append-only authenticated dictionary based on KVaC [AR20]. The AD Lkup (resp. VerLkup) algorithm combines the prove (resp. verify) membership and non-membership algorithms.</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal {R} _ {\\mathrm {M I P P -} k} = \\left\\{ \\begin{array}{c} \\left( \\begin{array}{c} g ^ {\\beta} \\in \\mathbb {G} _ {1}, T \\in \\mathbb {G} _ {T}, Z \\in \\mathbb {G} _ {1}, \\gamma \\in \\mathbb {Z} _ {p}; \\\\ [ A _ {i} ] _ {i = 0} ^ {m - 1} \\in \\mathbb {G} _ {1} ^ {m}, [ v ] _ {i} = \\left[ h ^ {\\beta^ {2 i}} \\right] _ {i = 0} ^ {m - 1}, [ b ] _ {i} = [ \\gamma^ {i} ] _ {i = 0} ^ {m - 1} \\in \\mathbb {Z} _ {p} ^ {m} \\end{array} \\right): \\\\ T = \\prod_ {i = 0} ^ {m - 1} e (A _ {i}, v _ {i}) \\wedge Z = \\prod_ {i = 0} ^ {m - 1} A _ {i} ^ {b _ {i}} \\end{array} \\right\\}.</span></div>

    <p class="text-gray-300">KZG polynomial commitments. The KZG polynomial commitment scheme [KZG10] commits to polynomials of some max degree  <span class="math">n</span> . For polynomial  <span class="math">f(X) = \\sum_{i=0}^{n-1} a_i X^i</span>  where coefficient vector  <span class="math">a = [a_i]_{i=0}^{n-1}</span> , the commitment is computed with an trapdoor commitment key  <span class="math">ck = [g^{a^i}]_{i=0}^{n-1}</span>  as KZG.Commit  <span class="math">(ck, a) = \\prod_i (ck_i)^{a_i}</span> .</p>

    <p class="text-gray-300">To prove that  <span class="math">y = f(x)</span>  at a point  <span class="math">x</span> , KZG uses the polynomial remainder theorem which says  <span class="math">f(x) = y \\Leftrightarrow \\exists q(X): f(X) - y =</span></p>

    <p class="text-gray-300"><span class="math">q(X)(X-x)</span>. The proof is just a KZG commitment to the quotient polynomial <span class="math">q(X)</span> where if <span class="math">q(X)</span> has coefficients <span class="math">b=[b_{i}]_{i}</span>, then <span class="math">\\mathsf{KZG.Open}(ck,a,x)=\\prod_{i}(ck_{i})^{b_{i}}</span>. The verifier key consists of <span class="math">\\mathsf{v}k=h^{\\alpha}</span>, and the verifier runs <span class="math">\\mathsf{KZG.Ver}(h^{\\alpha},C,W,x,y)</span> for commitment <span class="math">C</span> and opening <span class="math">W</span> and checks that <span class="math">e(CW^{x}/g^{y},h)=e(W,h^{\\alpha})</span>.</p>

    <p class="text-gray-300">Groth16 SNARK. We recall some relevant notation for the structure and verification of Groth16 <em>[x13]</em> SNARKS. The verifier’s verification key is as follows:</p>

    <p class="text-gray-300"><span class="math">\\mathsf{v}k_{\\mathsf{G16}}=\\left(h^{\\gamma},h^{\\delta},e(g^{\\alpha},h^{\\beta}),\\Big{[}S_{j}=g^{(\\beta\\cdot u_{j}(\\tau)+\\alpha\\cdot v_{j}(\\tau)-w_{j}(\\tau))/\\gamma}\\Big{]}_{j=0}^{\\ell-1}\\right),</span></p>

    <p class="text-gray-300">where <span class="math">\\alpha,\\beta,\\gamma,\\delta,\\tau\\in\\mathbb{Z}_{p}</span> are secret values and <span class="math">[u_{j}(X),v_{j}(X),w_{j}(X)]_{j=0}^{\\ell-1}</span> are public polynomials that define a circuit relation with a statement of <span class="math">\\ell</span> elements of <span class="math">\\mathbb{Z}_{p}</span>. A proof consists of three group elements, <span class="math">\\pi=(A,B,C)\\in\\mathbb{G}_{1}\\times\\mathbb{G}_{2}\\times\\mathbb{G}_{1}</span> and is verified with a statement <span class="math">[x_{i}]_{i=0}^{\\ell-1}</span> by checking the following pairing product equation:</p>

    <p class="text-gray-300"><span class="math">e(A,B)\\stackrel{{\\scriptstyle?}}{{=}}e(g^{\\alpha},h^{\\beta})\\cdot e\\left(\\prod_{j=0}^{\\ell-1}S_{j}^{x_{j}},h^{\\gamma}\\right)\\cdot e(C,h^{\\delta})\\,.</span></p>

    <p class="text-gray-300">Aggregation. <em>[BMM^{+}21]</em> describe how to aggregate the verification of a vector of proofs <span class="math">[\\pi_{i}=(A_{i},B_{i},C_{i})]_{i=0}^{n-1}</span> for statements <span class="math">\\big{[}[x_{i,j}]_{i=0}^{n-1}\\big{]}_{j=0}^{\\ell-1}</span> into a single pairing product equation by combining them with a random linear combination. More specifically, the verifier samples a random <span class="math">r\\leftarrow\\sharp\\mathbb{Z}_{p}</span> and then checks:</p>

    <p class="text-gray-300"><span class="math">\\prod_{i=0}^{n-1}e\\Big{(}(A_{i})^{r^{i}},B_{i}\\Big{)}\\stackrel{{\\scriptstyle?}}{{=}}e\\big{(}g^{\\alpha},h^{\\beta}\\big{)}^{\\sum_{i=0}^{n-1}r^{i}}\\cdot e\\left(\\prod_{j=0}^{\\ell-1}S_{j}^{\\sum_{i=0}^{n-1}x_{i,j}\\cdot r^{i}},h^{\\gamma}\\right)\\cdot e\\left(\\prod_{i=0}^{n-1}(C_{i})^{r^{i}},h^{\\delta}\\right).</span></p>

    <p class="text-gray-300">We present the details of an aggregation proof that proves that this check succeeds in Figure 19; it is for the following relation:</p>

    <p class="text-gray-300"><span class="math">\\mathcal{R}_{\\mathsf{G16-Aggr}}=\\left\\{\\left(\\mathsf{v}k_{\\mathsf{G16}},\\ \\Big{[}[x_{i,j}]_{j=0}^{\\ell-1}\\Big{]}_{i=0}^{n-1}\\ ;\\quad[\\pi_{i}]_{i=0}^{n-1}\\right)\\ :\\quad\\bigwedge_{i=0}^{n-1}\\mathsf{G16.Ver}(\\mathsf{v}k,[x_{i,j}]_{j=0}^{\\ell-1},\\pi_{i})\\right\\}\\enspace.</span></p>

    <p class="text-gray-300">Aggregation with sequential statements. Verification of the general aggregation protocol from Figure 19 is <span class="math">\\mathcal{O}(\\ell\\cdot n)</span> time since the verifier must compute all of the “aggregate” <span class="math">Z_{j}</span> values from the <span class="math">n</span> statements <span class="math">[x_{i}]_{i}</span>. Here we present a modified aggregation protocol that allows for <span class="math">\\mathcal{O}(\\ell+\\log n)</span> verification time for statements that follow a specific “sequential” structure.</p>

    <p class="text-gray-300">The sequential structure that we require is that each statement <span class="math">x_{i}</span> is made up of two parts <span class="math">x_{i}=(a_{i},b_{i})</span>. The first part is shared as the second part of the previous statement, <span class="math">x_{i-1}=(a_{i-1},b_{i-1})</span> where <span class="math">b_{i-1}=a_{i}</span>, and the second part is shared as the first part of the following statement, <span class="math">x_{i+1}=(a_{i+1},b_{i+1})</span> where <span class="math">a_{i+1}=b_{i}</span>. In other words, there exists a sequence of values <span class="math">[a_{i}]_{i=0}^{n}</span> such that the statements are of the form <span class="math">[x_{i}=(a_{i},a_{i+1})]_{i=0}^{n-1}</span>. Here, each <span class="math">a_{i}=[a_{i,j}]_{j=0}^{\\ell-1}</span> is a vector of <span class="math">\\ell</span> field elements, and the SNARKs are over statements of <span class="math">2\\ell</span> elements.</p>

    <p class="text-gray-300">In this case, we can use the structure of the statements to efficiently prove knowledge of accepting intermediate statements without requiring the verifier to themselves check linear statements. We provide an aggregation protocol for the following relation with details given in Figure 20:</p>

    <p class="text-gray-300"><span class="math">\\mathcal{R}_{\\mathsf{G16-Aggr-Seq}}=\\left\\{\\left(\\mathsf{v}k_{\\mathsf{G16}},\\ [a_{0,j}]_{j=0}^{\\ell-1},\\ [a_{n,j}]_{j=0}^{\\ell-1};\\ \\Big{[}[a_{i,j}]_{j=0}^{\\ell-1}\\Big{]}_{i=1}^{n-1},[\\pi_{i}]_{i=0}^{n-1}\\right)\\ :\\ \\bigwedge_{i=0}^{n-1}\\mathsf{G16.Ver}(\\mathsf{v}k_{\\mathsf{G16}},([x_{i}=([a_{i,j}],[a_{i+1,j}])]_{j=0}^{\\ell-1},\\pi_{i})\\right\\}\\enspace.</span></p>

    <h3 id="sec-61" class="text-xl font-semibold mt-8">I.2 AHDs from Amortized Aggregation</h3>

    <p class="text-gray-300">Using the above aggregation technique, we propose another generic transform to building AHDs which we will refer to as <span class="math">\\mathsf{AHD_{Aggr}}</span>. Similar to <span class="math">\\mathsf{AHD_{IVC}}</span>, the <span class="math">\\mathsf{AHD_{Aggr}}</span> transform will create a SNARK proof at each epoch that the new digest preserves the invariant from the previous digest, however it does not include recursive verification of validity of the previous digest. Instead of using recursion to prove validity of the full history of digests, in <span class="math">\\mathsf{AHD_{Aggr}}</span>, the validity of the full history of previous digests is attested to by aggregating all of the per-epoch SNARKs. We observe that the statements to aggregate satisfy the sequential property from above, which admits a succinct verifier.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Generate commitment keys:  <span class="math">\\alpha, \\beta \\gets \\mathbb{Z}_p</span> ,  <span class="math">w \\gets \\left[g^{\\alpha^{2i}}\\right]_{i=0}^{n-1}</span> ,  <span class="math">v \\gets \\left[h^{\\beta^{2i}}\\right]_{i=0}^{n-1}</span> .</li>

      <li>Generate shared verification key and proving key for TIPP and  <span class="math">\\mathsf{MIPP}_k</span> :</li>

    </ol>

    <p class="text-gray-300"><span class="math">\\left(vk = (g^{\\beta},h^{\\alpha}),pk = (vk,\\left[g^{\\alpha^{i}}\\right]_{i = 0}^{2n - 2},\\left[h^{\\beta^{i}}\\right]_{i = 0}^{2n - 2})\\right)\\gets \\mathsf{TIPP}.Setup(n,(\\alpha ,\\beta)).</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Return  <span class="math">(vk, pk)</span> . (Notice  <span class="math">w, v</span>  included in  <span class="math">pk</span> )</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Compute  <span class="math">(\\pi ,r)\\gets</span>  AggregateHelper  <span class="math">(pk,[x_i]_{i = 0}^{n - 1},[\\pi_i]_{i = 0}^{n - 1})</span>  , and return  <span class="math">\\pi</span></li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse  <span class="math">\\left(h^{\\gamma}, h^{\\delta}, e(g^{\\alpha}, h^{\\beta}), [S_{j}]_{j=0}^{\\ell-1}\\right) \\gets vk_{G16}</span>  and  <span class="math">((C_{A}, C_{B}, C_{C}), (Z_{AB}, Z_{C}), (\\pi_{AB}, \\pi_{C})) \\gets \\pi</span> .</li>

      <li>Compute  <span class="math">r\\gets \\mathsf{H}([x_i]_{i = 0}^{n - 1},C_A,C_B,C_C)</span>  and  <span class="math">[Z_j]_j\\gets \\left[S_j^{\\sum_{i = 0}^{n - 1}x_{i,j}\\cdot r^i}\\right]_{j = 0}^{\\ell -1}</span></li>

      <li>Return VerifyHelper(vk, vkG16, π, [Zj]j=0, r).</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse  <span class="math">w, v</span>  and  <span class="math">g^{\\beta}, h^{\\alpha}</span>  from  <span class="math">pk</span> .</li>

      <li>Commit to proof elements:  <span class="math">C_A = \\prod_{i=0}^{n-1} e(A_i, v_i)</span> ,  <span class="math">C_B = \\prod_{i=0}^{n-1} e(w_i, B_i)</span> ,  <span class="math">C_C = \\prod_{i=0}^{n-1} e(C_i, v_i)</span> .</li>

      <li>Compute challenge  <span class="math">r\\gets \\mathsf{H}(X,C_A,C_B,C_C)</span></li>

      <li>Compute inner products  <span class="math">Z_{AB} \\gets \\prod_{i=0}^{n-1} e((A_i)^{r^i}, B_i)</span> ,  <span class="math">Z_C \\gets \\prod_{i=0}^{n-1} (C_i)^{r^i}</span> .</li>

      <li>Prove using TIPP and  <span class="math">\\mathsf{MIPP}_k</span>  correct computation of inner products with respect to commitments:</li>

    </ol>

    <p class="text-gray-300"><span class="math">\\pi_{AB}\\gets \\mathsf{TIPP.Prove}\\big(pk,(g^{\\beta},h^{\\alpha},C_{A},C_{B},Z_{AB},r),(w,[A_{i}]_{i},v,[B_{i}]_{i},[r^{i}]_{i})\\big),</span></p>

    <p class="text-gray-300"><span class="math">\\pi_C \\gets \\mathsf{MIPP}_k</span> . Prove  <span class="math">(pk, (g^\\beta, C_C, Z_C, r), (v, [C_i]_i, [r^i]_i))</span> .</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Return  <span class="math">\\pi \\gets ((C_A, C_B, C_C), (Z_{AB}, Z_C), (\\pi_{AB}, \\pi_C))</span> .</li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse  <span class="math">\\left(h^{\\gamma}, h^{\\delta}, e(g^{\\alpha}, h^{\\beta}), [S_{j}]_{j=0}^{\\ell-1}\\right) \\gets vk_{G16}</span>  and  <span class="math">((C_{A}, C_{B}, C_{C}), (Z_{AB}, Z_{C}), (\\pi_{AB}, \\pi_{C})) \\gets \\pi</span> .</li>

      <li>Check inner product proofs:</li>

    </ol>

    <p class="text-gray-300">TIPP.Ver(vk,  <span class="math">(g^{\\beta}, h^{\\alpha}, C_A, C_B, Z_{AB}, r), \\pi_{AB}) \\stackrel{?}{=} 1</span> ,</p>

    <p class="text-gray-300"><span class="math">\\mathsf{MIPP}_k</span>  .Ver  <span class="math">(pk,(g^{\\beta},C_C,Z_C,r),\\pi_C)\\stackrel {?}{=}1</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Check aggregate pairing product equation:</li>

    </ol>

    <p class="text-gray-300"><span class="math">Z_{AB}\\stackrel {?}{=}e(g^{\\alpha},h^{\\beta})\\frac{c^{\\alpha} - 1}{r - 1}\\cdot e(\\prod_{j = 0}^{\\ell -1}Z_{j},h^{\\gamma})\\cdot e(Z_{C},h^{\\delta}).</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Return 1 if above checks pass otherwise 0.</li>

    </ol>

    <p class="text-gray-300">Figure 19: Aggregation of Groth16 [Gro16] SNARKs.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Generate  <span class="math">(\\nu k_{\\mathrm{G16 - Aggr}},pk_{\\mathrm{G16 - Aggr}})\\gets \\mathrm{G16 - Aggr}.Setup(n)</span>  and  <span class="math">(\\nu k_{\\mathrm{KZG}},ck_{\\mathrm{KZG}})\\gets \\mathrm{KZG}.Setup(n - 1)</span></li>

      <li>Return  <span class="math">(\\nu k = (\\nu k_{\\mathrm{G16 - Aggr}},\\nu k_{\\mathrm{KZG}}),pk = (pk_{\\mathrm{G16 - Aggr}},ck_{\\mathrm{KZG}}))</span></li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Commit to statements:  <span class="math">\\left[C_{S,j}\\right]_j\\gets \\left[\\mathsf{KZG. Commit}(ck_{\\mathsf{KZG}},\\left[a_{i,j}\\right]_{i = 1}^{n - 1})\\right]_{j = 0}^{\\ell -1}</span></li>

      <li>Compute  <span class="math">(\\pi_{\\mathrm{Aggr}},r)\\gets \\mathrm{AggregateHelper}(pk_{\\mathrm{G16 - Aggr}},(a_0,a_n,\\left[C_{S,j}\\right]_{j = 0}^{\\ell -1}),[\\pi_i]_{i = 0}^{n - 1})</span></li>

      <li>Compute statement scalar inner products (exponents of  <span class="math">S_{j}</span> ):  <span class="math">[z_{j}]_{j} \\gets \\left[\\sum_{i=1}^{n-1} a_{i,j} \\cdot r^{i}\\right]_{j=0}^{\\ell-1}</span> .</li>

      <li>Prove correct computation of inner product by opening KZG commitment:  <span class="math">[W_j]_j\\gets \\left[\\mathsf{KZG. Open}(ck_{\\mathsf{KZG}},[a_{i,j}]_{i = 1}^{n - 1},r)\\right]_{j = 0}^{\\ell -1}</span></li>

      <li>Return  <span class="math">\\pi \\gets (\\pi_{\\mathrm{Aggr}},\\left[(C_{S,j},W_j,z_j)\\right]_{j = 0}^{\\ell -1})</span></li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse  <span class="math">\\left(h^{\\gamma}, h^{\\delta}, e(g^{\\alpha}, h^{\\beta}), [S_{j}]_{j=0}^{\\ell-1}\\right) \\gets vk_{G16}</span> ,  <span class="math">(\\pi_{\\text{Aggr}}, [(C_{S,j}, W_{j}, z_{j})]_{j=0}^{\\ell-1}) \\gets \\pi</span> , and  <span class="math">((C_{A}, C_{B}, C_{C}), (Z_{AB}, Z_{C}), (\\pi_{AB}, \\pi_{C})) \\gets \\pi_{\\text{Aggr}}</span> .</li>

      <li>Compute challenge  <span class="math">r\\gets \\mathsf{H}((a_0,a_n,\\left[C_{S,j}\\right]_{j = 0}^{\\ell -1}),C_A,C_B,C_C)</span></li>

      <li>Compute statement elements taking advantage of sequential property:  <span class="math">[Z_j]_{j=0}^{\\ell-1} \\gets \\left[ S_j^{a_{0,j} + z_j \\cdot r} \\right]_{j=0}^{\\ell-1}, [Z_j]_{j=\\ell}^{2\\ell-1} \\gets \\left[ S_j^{z_j + a_{n,j} \\cdot r^{n-1}} \\right]_{j=0}^{\\ell-1}</span> .</li>

      <li>Check VerifyHelper(vkG16-Aggr, vkG16,  <span class="math">\\pi_{\\mathrm{Aggr}}</span> ,  <span class="math">[Z_j]_{j=0}^{2\\ell-1}, r) \\stackrel{?}{=} 1</span> .</li>

      <li>Check KZG proofs:  <span class="math">\\left[\\mathsf{KZG.Ver}(\\mathsf{vk}_{\\mathsf{KZG}},C_{S,j},W_j,r,z_j)\\right]_{j = 0}^{\\ell -1}\\stackrel {?}{=}[1]_j.</span></li>

      <li>Return 1 if above checks pass otherwise 0.</li>

    </ol>

    <p class="text-gray-300">Figure 20: Aggregation of Groth16 [Gro16] SNARKs with sequential statements.</p>

    <p class="text-gray-300">Producing the aggregated proof is still linear in the number of proofs being aggregated, so it will not be feasible to produce an aggregate proof for every possible range. Instead, as in <span class="math">\\text{AHD}_{\\text{Amtz}}</span>, aggregate proofs will only be computed for compact subranges. Again, this can be done in an amortized-efficient time of <span class="math">\\mathcal{O}(\\lg N)</span> work per epoch (for <span class="math">N</span> epochs). We provide pseudocode details for the protocol in Figure 21.</p>

    <p class="text-gray-300">Protocol:  <span class="math">\\mathrm{AHD}_{\\mathrm{Aggr}}[\\mathrm{AD},\\mathrm{VC}]</span></p>

    <pre><code class="language-txt">Setup: The public parameters of the scheme consist of the public parameters of its underlying components and Groth16 proving and aggregation protocols:  $pp \\gets (pp_{\\mathrm{AD}}, pp_{\\mathrm{VC}}, pp_{\\mathrm{G16}}, pp_{\\mathrm{G16 - Aggr - Seq}})$ .
Init: The dictionary is initialized with an empty authenticated dictionary and empty vector commitment, returning an initial digest  $d_0 = (d_{\\mathrm{AD},0}, d_{\\mathrm{VC},0})$ . It stores the following as its current state  $st_i$ :
-  $L_{\\mathrm{AD}} = [d_{\\mathrm{AD},\\ell}]_\\ell^i$ : digest of the AD at each epoch.
-  $st_{\\mathrm{VC},i}$ : state of the VC representing list of previous epoch digests.
-  $L_{\\mathrm{G16}} = [\\pi_{\\mathrm{G16},\\ell}]_\\ell^i$ : Groth16 invariant proof for each epoch.
-  $T_\\Phi$ : table of precomputed invariant proofs for all compact subranges.
Upd([kj, vj]j : st_i):
(1) The AD is updated with the new key-value mappings:  $(d_{\\mathrm{AD},i+1}, \\pi_\\Phi, st_{\\mathrm{AD},i+1}) \\gets \\mathrm{AD}.\\mathrm{Upd}([kj, v_j]_j : st_{\\mathrm{AD},i})$ .
(2) The new AD digest is appended to the history commitment:  $(d_{\\mathrm{VC},i+1}, st_{\\mathrm{VC},i+1}) \\gets \\mathrm{Upd}([d_{\\mathrm{AD},i+1} : st_{\\mathrm{VC},i})$ .
(3) A new Groth16 proof  $\\pi_{\\mathrm{G16},i}$  is computed attesting to invariant preservation for new digest  $d_{\\mathrm{AD},i+1}$  with respect to  $d_{\\mathrm{AD},i}$ , proving the following relation:
$\\mathcal{R}_{\\mathrm{G16}} = \\left\\{\\left( (d_{\\mathrm{AD},i}, d_{\\mathrm{AD},i+1}), \\pi_\\Phi \\right): \\mathrm{AD}.\\mathrm{VerUpd}(d_{\\mathrm{AD},i}, d_{\\mathrm{AD},i+1}, \\pi_\\Phi) \\right\\}$ .
(4) Compute and store an aggregated invariant proof for the Groth16 proofs of every compact subrange of epochs that  $i+1$  closes, i.e.,  $[L_j]_j^m$  such that there exists  $(a_j, b_j)$  where  $L_j = a_j \\cdot 2^{b_j}$  and  $L_j + 2^{b_j} = i+1$ :
$T_\\Phi[L_j, i+1] \\gets \\mathrm{G16-Aggr-Seq.Aggregate}(pk_{\\mathrm{G16-Aggr-Seq}}, [d_{\\mathrm{AD},\\ell}]_{l=L_j}^{i+1}, [\\pi_\\ell]_{l=L_j}^i)$ .
(5) The new digest  $d_{i+1} = (d_{\\mathrm{AD},i+1}, d_{VC,i+1})$  is returned.
ProveInv([c_j]m : st_i): For each checkpoint pair  $(c_j, c_{j+1})$  for  $1 \\leq j &amp;lt; m$  compute  $\\pi_\\Phi, j$  then return  $\\pi_\\Phi \\gets [\\pi_\\Phi, j]_j^m$ :
(1) Compute the  $n_j$  compact subranges that span  $(c_j, c_{j+1}]$ :
$\\left[(L_{j,\\ell}, R_{j,\\ell})\\right]_{\\ell}^{n_j} \\gets \\text{CompactR}((c_j, c_{j+1}))$ .
(2) Construct an invariant proof for  $(c_j, c_{j+1})$  with the precomputed aggregated invariant proofs of each compact subrange:
$\\pi_\\Phi, j = \\left[T_\\Phi[L_{j,\\ell}, R_{j,\\ell}], d_{L_{j,\\ell}}\\right]_{\\ell}^{n_j}$ .
$\\text{VerInv}(d_i, [(c_j, d_{c_j})]_j^m, \\pi_\\Phi = \\left[\\left[(\\pi_\\Phi, j, \\ell), d_{\\mathrm{AD},j,\\ell}\\right]_{\\ell}^{n_j}\\right]_j^m)$ : For each checkpoint pair  $(c_j, c_{j+1})$  for  $1 \\leq j &amp;lt; m$ :
(1) Verify compact range endpoints:  $d_{c_j} = d_\\Phi, j, 1$  and  $d_{c_{j+1}} = d_\\Phi, j, n_j$ .
(2) Verify each compact subrange invariant proof:
$\\left[\\mathrm{G16 - Aggr - Seq.Ver}(\\mathrm{vk}_{\\mathrm{G16 - Aggr - Seq}}, \\mathrm{vk}_{\\mathrm{G16}}, d_\\Phi, j, \\ell, d_\\Phi, j, \\ell+1, \\pi_\\Phi, j, \\ell)\\right]_{\\ell}^{n_j-1}$ .</code></pre>

    <p class="text-gray-300">Figure 21: Generic construction of an AHD from an AD using amortized SNARK aggregation of invariant proofs over compact subranges.</p>

    <p class="text-gray-300">!<a href="img-22.jpeg">img-22.jpeg</a> Figure 22: Server epoch update costs including VeRSA-Aggr. The key update throughput is computed as the number of key updates per epoch divided by the epoch latency.</p>

    <p class="text-gray-300">The aggregation protocol and, as a result,  <span class="math">\\mathrm{AHD}_{\\mathrm{Aggr}}</span> , are specific to the Groth16 SNARK [Gro16] which requires a trusted setup, and thus may not be suitable for all deployment scenarios. However, when appropriate, it results in a generic transform that does not rely on SNARK recursion, thus avoiding the expensive cycles of pairing-friendly curves [BCTV14] used by many SNARK recursion approaches. We implemented the aggregation protocol and evaluated it using KVaC as the underlying AD; we term the resulting registry VeRSA-Aggr. Figure 22 plots the update throughput of VeRSA-Aggr compared to our two alternate proposed constructions VeRSA-IVC and VeRSA-Amtz. We find that the savings of avoiding recursion-friendly cycles of curves translates to an approximately  <span class="math">2.5\\times</span>  throughput gain in VeRSA-Aggr over VeRSA-IVC for shorter latency — the maximum throughput in the limit is the same across approaches.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Amortized prover-efficient IVC. This novel combination of SNARK aggregation with amortization also admits a new approach to IVC, which may be of independent interest. For a computation of depth  <span class="math">N</span> , our approach is verifier-efficient with proofs and verifier time of size  <span class="math">\\mathcal{O}(\\log^2 N)</span> . It is also amortized-prover-efficient where the prover does amortized  $\\mathcal{O}(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+ \\log N)<span class="math">  work for each step of computation, where  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">C</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  is the size of the computation circuit, but requires  </span>\\mathcal{O}(N)$  storage long term to store the individual SNARKs for each step.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>`;
---

<BaseLayout title="VeRSA: Verifiable Registries with Efficient Client Audits fr... (2021/627)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2021 &middot; eprint 2021/627
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
