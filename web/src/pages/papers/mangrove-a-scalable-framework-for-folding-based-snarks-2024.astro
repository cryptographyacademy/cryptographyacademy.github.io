---
import BaseLayout from '../../layouts/BaseLayout.astro';

const EPRINT_URL = 'https://eprint.iacr.org/2024/416';
const CRAWLER = 'mistral';
const CONVERTED_DATE = '2026-02-16';
const TITLE_HTML = 'Mangrove: A Scalable Framework for Folding-based SNARKs';
const AUTHORS_HTML = 'Wilson Nguyen, Trisha Datta, Binyi Chen, Nirvan Tyagi, Dan Boneh';

const CONTENT = `    <p class="text-gray-300">Wilson Nguyen Trisha Datta Binyi Chen Nirvan Tyagi Dan Boneh</p>

    <p class="text-gray-300">{wdnguyen,tcdatta,binyi,tyagi,dabo}@cs.stanford.edu</p>

    <p class="text-gray-300">Stanford University</p>

    <p class="text-gray-300">Abstract. We present a framework for building efficient folding-based SNARKs. First we develop a new "uniformizing" compiler for NP statements that converts any poly-time computation to a sequence of identical simple steps. The resulting uniform computation is especially well-suited to be processed by a folding-based IVC scheme. Second, we develop two optimizations to folding-based IVC. The first reduces the recursive overhead of the IVC by restructuring the relation to which folding is applied. The second employs a "commit-and-fold" strategy to further simplify the relation. Together, these optimizations result in a folding-based SNARK that has a number of attractive features. First, the scheme uses a constant-size transparent common reference string (CRS). Second, the prover has (i) low memory footprint, (ii) makes only two passes over the data, (iii) is highly parallelizable, and (iv) is concretely efficient. Microbenchmarks indicate that proving time is competitive with leading monolithic SNARKs, and significantly faster than other streaming SNARKs. For  <span class="math">2^{24}</span>  ( <span class="math">2^{32}</span> ) gates, the Mangrove prover is estimated to take 2 minutes (8 hours) with peak memory usage approximately 390 MB (800 MB) on a laptop.</p>

    <p class="text-gray-300">1 Introduction 4 2 Technical Overview 8 2.1 A Uniform Compiler for NP Statements 9 2.2 SNARK from Proof-Carrying Data 11 2.3 Proof-Carrying Data with Reduced Overhead 13 Decoupling PCD Computation Tree and Control Tree 15 Folding Polynomial Relations for Commit-and-Prove PCD 17 2.4 Overview Summary 20 3 Preliminaries 20 3.1 Interactive Protocols and Arguments 21 Interactive Arguments 21 Non-Interactive Arguments 21 3.2 Cryptographic Primitives 23 Folding Schemes 25 Proof Carrying Data 26 3.3 Algorithms 28 3.4 Algebra 28 4 Generalization of Folding Schemes 29 4.1 Polynomial Relations 29 4.2 Polynomial Witness Testing 31 5 Folding Schemes for Polynomial Relations 31 5.1 A Folding Scheme for Homogeneous Maps 32 5.2 A Folding Scheme for Arbitrary Polynomial Maps 33 5.3 Heuristic Security of Folding Schemes 34 6 SNARKs for Plonkish Arithmetization 35 6.1 Plonkish Arithmetization 35 6.2 NARK for Plonkish 36 6.3 SNARK for Plonkish 37 Foldable Leaf Relation 37 SNARK PCD Predicate and Prover Helper Function 38 SNARK Construction 40 6.4 SNARK Performance Evaluation 42 7 Extensions: Lookups and Commit &amp; Prove 45 7.1 Lookup Tables in Arithmetization 45 7.2 Commit-and-Prove SNARK 48 A Deferred Proofs 57 A.1 Deferred Proof of Lemma 5 57 A.2 Deferred Proof of Theorem 2 57 A.3 Deferred Proof of Theorem 3 59</p>

    <p class="text-gray-300">A.4 Multi-Instance Folding Extraction 62 A.5 Deferred Proof of Theorem 4 62 A.6 Deferred Proof of Theorem 5 64 A.7 Proof of Knowledge Soundness 64</p>

    <p class="text-gray-300">1 Introduction</p>

    <p class="text-gray-300">Succinct non-interactive arguments of knowledge (SNARKs) <em>[x1]</em> enable efficient verification of NP statements. While early research focused on reducing argument size and verification time, the focus in recent years has shifted to reducing the running time and memory requirements of the proving algorithm. This is essential for scaling SNARK proof systems to support large statements.</p>

    <p class="text-gray-300">Scalability limitations in existing SNARKs. Most existing SNARK constructions require that the prover write down the full computation trace. For example, when proving satisfaction of an arithmetic circuit <span class="math">C</span>, the prover needs access to the values of all the wires in <span class="math">C</span>, and performs a global computation over the entire trace. We will refer collectively to SNARKs that fall into this category as <em>monolithic</em> SNARKs. In modern monolithic SNARKs <em>[x1, x11, x12, x22, x19, x20, x21, x22, x10, x11, x12, x13, x23]</em> this often amounts to producing commitments to polynomials of degree on the order of the computation trace and providing opening proofs for certain evaluation points. With our existing techniques, this translates to global computations that include some combination of fast Fourier transforms (FFTs), multi-scalar multi-exponentiations (MSMs), and/or proofs of proximity for linear error-correcting codes.</p>

    <p class="text-gray-300">While the computations are global, in that they operate over the full trace, strategies for reducing memory costs for the prover exist. One approach is to chunk global computations into smaller components <em>[WZC+18]</em> storing intermediate results, rerunning the computation trace (or reading from disk) to reproduce the next chunk, and merge intermediate results at the end. Another approach, proposed in recent work <em>[BHR+20, BHR+21, x2]</em>, is to design polynomial commitment schemes and tailor the associated proving protocol to be suitable for streaming. Both of these approaches reduce prover space complexity but incur overhead on the prover’s time complexity.</p>

    <p class="text-gray-300">Improving prover scalability via IVC. Instead of chunking the prover computation needed for the proof system, an alternate approach for proving large statements is to chunk the statement itself into smaller more manageable pieces, prove each piece individually, and then combine the piecewise proofs in some manner; we will refer to SNARKs falling under this overarching strategy as <em>piecewise</em> SNARKs. A classic example of a piecewise SNARK would be SNARKs implementing incrementally-verifiable computation (IVC) <em>[x24]</em> through recursive proof composition <em>[x1, x2]</em> or proof aggregation <em>[BMM+21, TFZ+22]</em>. IVC enables proving a long sequence of small computation steps, by having step <span class="math">i</span> recursively verify the proof for step <span class="math">i-1</span>. The final proof is as short as verifying a single computation step, plus some overhead.</p>

    <p class="text-gray-300">IVC has been proposed for proving generic NP statements. To do this, the statement must first be represented as a computation that is repeatedly applied; we call this representation uniform computation. Previous works have explored using a universal circuit or CPU for this purpose, representing the NP statement as a program to be executed <em>[BCG+13, x1, x2]</em>. This approach is memory-efficient — the SNARK prover only needs memory on the order of the universal circuit size and program state — however overheads in (1) encoding the NP statement as a program, (2) running a universal circuit for each step (partially addressed in recent work <em>[x16]</em>), and (3) verifying program state, have limited the prover time efficiency of such an approach. In addition to the overhead incurred by the universal circuit, the predominant strategy for IVC of using recursive proof composition <em>[x1]</em> incurs its own set of expensive overheads.</p>

    <p class="text-gray-300">Folding schemes for IVC. The state of affairs has changed with a line of recent work on designing <em>folding schemes</em> (or accumulation schemes) to build IVC <em>[x2, x3, BCL+21, x14, x15, x2]</em>,</p>

    <p class="text-gray-300">EG23, KS23, NBS23, BC24]<em> with greatly improved efficiency over preexisting constructions based on recursive proof composition. A folding scheme enables a prover to reduce the task of checking two (or more) instances of a relation into the task of checking one folded instance for that same relation with a succinct proof of folding </em>[x13]<em>. Intuitively, folding is used to build IVC by, at each step, folding instances for a relation encoding (1) one step of repeated computation, and (2) verification of the folding proof for the previous step </em>[BCL^{+}21, x13]*. This approach has led to vast improvements in the efficiency of IVC because verification of folding proofs is inexpensive (compared to verification of monolithic SNARKs) and because generating folding proofs is inexpensive (compared to generation of monolithic SNARKs). In fact, even without considering the memory-efficiency benefits, folding-based IVC proofs for repeated computation are competitive in prover time with monolithic SNARKs for repeated computation.</p>

    <p class="text-gray-300">Our contributions. We propose a new framework for scalable SNARKs for NP that allows for constant-size prover memory-efficiency without compromising on concretely efficient linear prover computation. At a high level, we will be following the same classic strategy of applying IVC to a uniform computation representing the NP statement. However, we make improvements to both parts of this strategy:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Uniform compiler for NP: As discussed, previous works use universal circuits to encode NP statements as the uniform computation for IVC. This encoding is inefficient and results in large overhead. Instead, by looking closely at arithmetizations of NP statements used in monolithic SNARKs, we find existing uniform structure that we can take advantage of. We propose a new randomized uniform compiler for NP that takes NP statements in the Plonk arithmetization <em>[x10]</em> and produces chunks of uniform computation to use with IVC. Thus, we eliminate the need for universal circuits or virtual machines when using folding to prove a general NP statement.</li>

      <li>Optimizations to folding-based IVC: Folding has emerged as a prover efficient route to construct IVC. We propose two improvements to folding-based IVC constructions to push prover efficiency even further. More precisely, we consider improvements for folding-based proof-carrying data constructions <em>[BCL^{+}21]</em>, a generalization of IVC <em>[x7, x3]</em>. Our first optimization decouples the core uniform computation from the recursive computation of verifying folding proofs, greatly reducing recursive overhead. Reducing recursive overhead is especially important when considering memory-constrained settings, allowing a larger percentage of memory to be used on useful work. Our second optimization is a generalization of folding schemes to allow folding a relation over committed values, i.e., “commit-and-fold” following the notion of commit-and-prove SNARKs <em>[x6]</em>. We estimate by removing the constraints for commitment opening in the IVC relation (e.g., scalar multiplication for Pedersen commitments), we achieve about a 100 times improvement to prover time over applying folding directly to the output of the uniform compiler. This is essential to bring our concrete prover time in line with monolithic SNARKs.</li>

    </ul>

    <p class="text-gray-300">Following our uniform compiler for NP and applying our optimized folding-based PCD scheme, we end up with an extremely efficient SNARK for NP. As motivated, the resulting SNARK has a number of nice properties, mostly stemming from our use of tree-based PCD (in which the uniform computation is organized at the leaves of a tree and merged together), summarized in Figure 1:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Streaming/memory-efficiency: Our SNARK requires only two passes over the prover witness and supports a tunable memory and parallelism parameters, denoted <span class="math">m</span> and <span class="math">k</span> respectively . The memory usage of the streaming SNARK is <span class="math">O(k(m+k)\\log_{k}(n/m))</span> where <span class="math">n/m</span> is the number of chunks for an NP statement of size <span class="math">n</span>. By setting parameters <span class="math">m=O_{\\lambda}(1)</span> (a constant that is independent of <span class="math">n</span>) and <span class="math">k=O(\\lambda)</span> (linear in the security parameter), we achieve a prover with constant memory complexity <span class="math">O_{\\lambda}(1)</span> with only 2</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Protocol</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Prover Time</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Verifier Time</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Prover Memory</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Input passes</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">CRS</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Spartan [Set20] w/ Hyrax-PC [WTx+18]</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(n)</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(√n)</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(n)</td>

            <td class="px-3 py-2 border-b border-gray-700">-</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(√n)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">DARK-variant [BHR+21, BFS20]</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(n polylog n)</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(log(n))</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(polylog n)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(log(n))</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(1)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Gemini [BCHO22]</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(n log2 n)</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(log(n))</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(log(n))</td>

            <td class="px-3 py-2 border-b border-gray-700">O(log(n))</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(n)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Nova w/ UC [KST22]</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(n)</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(C)</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(C log(n))</td>

            <td class="px-3 py-2 border-b border-gray-700">1</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(C)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Mangrove (this work)</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(n)</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(1)</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(1)</td>

            <td class="px-3 py-2 border-b border-gray-700">2</td>

            <td class="px-3 py-2 border-b border-gray-700">Oλ(1)</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Fig. 1: Comparison table of prover characteristics for SNARK constructions supporting memory-efficiency where  <span class="math">n</span>  is the length of the NP statement. Spartan [Set20] is provided as a baseline comparison as a monolithic SNARK without memory-efficiency, yet Mangrove achieves comparable concrete prover time. Among memory-efficient proof systems, Mangrove compares favorably in every category: linear prover, constant memory, constant input passes, and constant-sized common reference string (CRS). Nova with a universal circuit (UC), where  <span class="math">C</span>  is the constraint size of the universal circuit (including the implementation of linear-sized memory), is only secure for constant-length computation and incurs poor concrete constants due to the use of a universal circuit.</p>

    <p class="text-gray-300">passes over the input. In comparison, other streaming SNARKs  <span class="math">\\left[\\mathrm{BHR}^{+}21\\right.</span> , BCHO22] use  <span class="math">O_{\\lambda}(\\mathrm{polylog}(n))</span>  memory and require  <span class="math">O(\\log n)</span>  passes over the input, where the logarithm base is a constant independent of the security parameter.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parallelism: The PCD proof is built up as a tree where each node is only dependent on its children. This admits a natural highly-parallel proving strategy that can be distributed across machines.</li>

      <li>Constant-size transparent CRS: Monolithic SNARKs typically require a common reference string (CRS) roughly the size of the NP statement. A large CRS, even if transparent, is a deployment hurdle as it needs to be stored and accessed (or recomputed on-the-fly) repeatedly during the proving protocol. Our SNARK uses a transparent CRS with size linear in the memory and arity parameter, which are constants  <span class="math">m = O_{\\lambda}(1)</span>  (independent of  <span class="math">n</span> ) and  <span class="math">k = O(\\lambda)</span> . Thus, the CRS is constant sized  <span class="math">O_{\\lambda}(1)</span> .</li>

      <li>Commit-and-prove: A key efficiency contribution of our SNARK is the use of folding over committed elements that represent the NP statement and the prover witness. A side effect of this approach is that our SNARK is also a commit-and-prove SNARK in which commitments to prover witness components can be reused and connected across proofs for different statements.</li>

      <li>Concrete prover efficiency: We estimate the concrete efficiency of our construction in Section 6.4 and find that it is competitive with popular monolithic SNARKs like Spartan [Set20] and significantly faster than other streaming SNARKs like Gemini [BCHO22]. On a laptop, for  <span class="math">2^{24}</span>  ( <span class="math">2^{32}</span> ) gates, we estimate the Mangrove prover takes approximately 2 minutes (8 hours) with peak memory usage approximately 390 MB (800 MB).</li>

    </ul>

    <p class="text-gray-300">In this work, we present our results as a SNARK and do not explicitly encode the common zero-knowledge property to obtain a zkSNARK. However, we stress that the constructions can be easily adapted to provide zero knowledge using existing techniques without much impact on prover characteristics.</p>

    <p class="text-gray-300">As a last note, we want to highlight the generality of our approach as a "commit-and-prove" PCD paradigm. We provide a uniform compiler for a SNARK arithmetization, but other uniform compilers for different computations can be slotted in as well.</p>

    <p class="text-gray-300">Practical SNARK configurations. The techniques we introduce (summarized above) result in a couple SNARK configurations for NP worth exploring — all of which derive from folding-based IVC. Prior to this</p>

    <p class="text-gray-300">work, the only approach for proving NP statements using IVC was to go through a universal circuit. Using a state-of-the-art folding-based IVC protocol <em>[x10]</em>, we might refer to such a construction as Nova-UC (see Table 1). Nova-UC is only secure for constant length computation and suffers from high concrete overhead incurred by the use of a universal circuit. Our uniform compiler allows us to do better.</p>

    <p class="text-gray-300">The immediate construction that follows from the uniform compiler is to directly apply a folding-based IVC scheme like Nova. However, as noted above, naively applying IVC to the output of the uniform compiler also incurs high overhead in the form of constraints for commitment opening. Thus, the first practical construction worth considering is a folding IVC scheme supporting our commit-and-fold optimization with the uniform compiler; call this Mangrove-Basic. Here, we consider the folding IVC to be done in a straight line, as described by Nova and depicted for Mangrove-Basic in Figure 2 (left). Mangrove-Basic avoids the cost incurred by the universal circuit, but is similarly limited to constant-length computation.</p>

    <p class="text-gray-300">Alternatively, we can consider a tree-based folding construction (from PCD) that we term Mangrove-Tree (depicted in Figure 2 (right)). As part of Mangrove-Tree, we introduce a decoupling technique to further improve the prover efficiency. Here, the statement proved within each tree PCD node is a verification of the folding of chunk computations rather than the chunk computation itself, reducing recursive overhead. Even with this optimization, Mangrove-Tree will always incur greater total prover cost than Mangrove-Basic due to the additional nodes of the tree over a line; high tree arity somewhat alleviates this overhead as the number of internal nodes of the tree are dominated by the number of leaves. However, Mangrove-Tree has two other benefits over Mangrove-Basic. First, Mangrove-Tree has a better approach to parallelism than Mangrove-Basic. Mangrove-Basic can parallelize the work of a single chunk, but must work sequentially in the line. Mangrove-Basic is limited then by the parallelism of a single chunk. In practice, this strategy for Mangrove-Basic amounts to the computation of a large MSM which can be chunked and computed in parallel but with an overall efficiency loss as MSM algorithms require large chunks <em>[x16, x2]</em>. In contrast, Mangrove-Tree admits a natural parallel strategy in which PCD nodes can be computed independently blocked only by the computation of its children. Second, a tree organization has theoretical benefits in that it supports a more efficient extraction procedure, enabling soundness for computations with a polynomial (in the security parameter) number of chunks; straight-line approaches are only sound for a constant. As such, our formal proofs and construction description are with respect to the tree-based construction, giving us a SNARK for polynomial length computation.</p>

    <p class="text-gray-300">Additional related work. In addition to the recent work on accumulation and folding schemes discussed earlier, several recent works build VOLE-based designated-verifier non-interactive zero-knowledge proof systems that have a linear-time and low-memory prover <em>[x14, x11, x15, x16, x3]</em> as surveyed in <em>[x2]</em>. Some even provide sublinear proof size by observing uniformity in NP statement arithmetization. Several monolithic SNARKs provide a linear-time prover <em>[GLS^{+}23, x19]</em>, but the prover is not low-memory or streaming.</p>

    <p class="text-gray-300">Several SNARKs systems, such as DIZK <em>[WZC^{+}18]</em> and Pianist <em>[LXZ^{+}23]</em>, scale to large size statements by distributing the prover’s work across many servers. In addition to the time savings, these systems also</p>

    <p class="text-gray-300">!<a href="img-0.jpeg">img-0.jpeg</a> Fig. 2: Depiction of Mangrove SNARK configurations for NP that apply folding to uniform chunks produced by a randomized uniform compiler. The uniform chunk computation is represented by the purple horizontally-hatched boxes. The IVC/PCD recursive computation is represented by the black cross-hatched boxes. (Left) Mangrove-Basic employs straight-line folding IVC in which each recursive step proves one chunk computation. (Right) Mangrove-Tree employs a folding  <span class="math">k</span> -arity PCD tree in which chunk computation is performed at the leaves. Also depicted is our decoupling optimization in which chunk computation is folded separately from the recursive computation. The recursive computation includes a verifier for the chunk folding, depicted with the purple V box.</p>

    <p class="text-gray-300">!<a href="img-1.jpeg">img-1.jpeg</a></p>

    <p class="text-gray-300">greatly reduce the memory footprint on each of the proving servers. The proof system in this paper, Mangrove, exhibits a low memory footprint even when the entire proving job runs on a single server. The Mangrove prover can also be distributed across several servers.</p>

    <p class="text-gray-300">Several post-quantum monolithic SNARKs are built from hash-based Merkle commitments: Stark [BBHR18], Ligero [AHIV17], Aurora  <span class="math">\\left[\\mathrm{BCR}^{+}19\\right]</span> , Brakedown  <span class="math">\\left[\\mathrm{GLS}^{+}23\\right]</span> , BaseFold [ZCF23] and Fractal [COS20]. Their proof sizes scale sublinearly with the witness size. In practice they require a significant amount of memory when proving a large statement. Several elegant post-quantum lattice-based proof systems offer sublinear proof size  <span class="math">\\left[\\mathrm{BBC}^{+}18\\right.</span> , BLNS20, ACK21,  <span class="math">\\left.\\mathrm{ACL}^{+}22\\right.</span> , BCS23], however the resulting proofs are larger than the hash-based schemes. One exception is LaBRADOR [BS23] that produces relatively short proofs, but has a linear time verifier. Other lattice-based proof systems, such as [ENS20, LNP22], perform well for small statements, but their proof size is linear in the size of the witness. We also mention LatticeFold [BC24] which is an efficient lattice-based folding scheme.</p>

    <p class="text-gray-300">In a forum post, [Sou23] sketches a technique for loading arbitrary data per IVC step. This enables folding executions of different circuits efficiently, leading to a way to efficiently prove VM executions, as in Supernova [KS22] and Protostar [BC23]. By applying appropriate changes and our uniform compiler, this loading data technique from [Sou23] also leads to a SNARK similar to our Mangrove-Basic construction. However, they do not provide a formal construction or security analysis.</p>

    <p class="text-gray-300">Several recent works study the question of constructing succinct proof systems in the standard model, without relying on random oracles [CJJ21, CJJ22, WW22, KLVW22]. The resulting proof systems are for polynomial-time computation (not NP). While some of these works also compose proofs along a tree, as we do here, the resulting proof systems are very different from the ones presented in this paper. We also mention the tree folding scheme due to Råfols and Zacharakis [RZ22], which we discuss in more detail in the next section.</p>

    <p class="text-gray-300">Our strategy for succinct proving of any statement in NP follows from two high level steps which we will explain in order. First, we introduce a general compiler for representing any statement in NP by "chunking"</p>

    <p class="text-gray-300">it into a sequence of statements for a smaller uniform indexed relation, which we will refer to as the <em>chunk relation</em>. By doing this, we can take advantage of existing techniques to more efficiently prove statements with this repeated uniform structure, sometimes referred to as data parallel or “single instruction, multiple data” (SIMD) computations <em>[x27, WHG^{+}16, x28]</em>. Recently, a promising set of techniques for this structure has emerged, collectively referred to as <em>folding</em> (or <em>accumulation</em>) schemes <em>[BCL^{+}21, x15, x1, x1, x13, x16]</em>. These schemes allow a succinct verification step to reduce the task of checking two statements for a relation to checking only a single folded statement for that relation. Generally speaking, one can only fold statements for the same relation (with some exceptions <em>[x14]</em>).</p>

    <p class="text-gray-300">After this compilation, in our second step, we use folding to build new efficient proof systems for statements with the compiled uniform structure. Our approach goes through the more powerful intermediate abstraction of <em>proof-carrying data</em> (PCD) <em>[x10, x3]</em> which will bring our efficiency improvements to other settings that PCD can be applied to as well (e.g., for machine computation <em>[BFR^{+}13, x2]</em>). Folding techniques have been previously proposed for constructing PCD <em>[BCL^{+}21, x1]</em>; in these works, a PCD tree is constructed in which each node represents a recursive relation folding together its children, and the root of the tree represents a proof for the computation in the full tree (see Section 2.2 for description of PCD tree). Looking forward, all of our new techniques aim to optimize the size of this recursive relation, reducing recursive overhead and greatly improving proving efficiency.</p>

    <p class="text-gray-300">Lastly, we apply our new compiler and efficient PCD scheme to build a new family of scalable SNARKs that are well-suited for <em>streaming</em> (memory-efficiency) and <em>distributed computing</em> (parallelism efficiency).</p>

    <h3 id="sec-4" class="text-xl font-semibold mt-8">2.1 A Uniform Compiler for NP Statements</h3>

    <p class="text-gray-300">Introduced in <em>[x12]</em>, the “Plonk” arithmetization is a natural encoding of computation in NP that possesses a close to uniform structure. For concreteness, let us review the specific arithmetization of Plonk to capture arithmetic circuits. Consider an arithmetic circuit with <span class="math">n</span> gates indexed from <span class="math">1</span> to <span class="math">n</span>. The computation trace of this circuit can be encoded as a vector of wire values <span class="math">v\\in\\mathbb{F}^{3n}</span>:</p>

    <p class="text-gray-300"><span class="math">v=\\Big{(}(v_{l}^{(1)},v_{r}^{(1)},v_{o}^{(1)}),\\ (v_{l}^{(2)},v_{r}^{(2)},v_{o}^{(2)}),\\ \\ldots,\\ (v_{l}^{(n)},v_{r}^{(n)},v_{o}^{(n)})\\Big{)}</span></p>

    <p class="text-gray-300">The wire values are indexed such that the left, right, and output wires of gate <span class="math">i</span> are <span class="math">v_{l}^{(i)}</span>, <span class="math">v_{r}^{(i)}</span>, and <span class="math">v_{o}^{(i)}</span>, respectively. In this encoding of arithmetic circuits, we consider binary gates, but the Plonk arithmetization can be extended to include gates with more inputs and outputs. The arithmetization further consists of two vectors, a selector vector <span class="math">\\mathsf{s}\\in\\mathbb{F}^{n}</span> and a copy vector <span class="math">\\sigma\\in\\mathbb{F}^{3n}</span> such that <span class="math">\\{\\sigma_{i}\\mid i\\in[3n]\\}=[3n]</span>, and a gate polynomial <span class="math">G</span>. Together, these encode essential constraints on the wire values. Informally, the selector vector, <span class="math">\\mathsf{s}</span>, specifies the type of gate at each index. The copy vector <span class="math">\\sigma</span> specifies how wires are connected within the circuit. The gate polynomial <span class="math">G</span> checks if the wire values satisfy the gates specified by <span class="math">\\mathsf{s}</span>. More precisely, a computation trace satisfies the constraints if and only if the following conditions hold:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><em>Local gate constraints</em>: For all <span class="math">i\\in[n]</span>, <span class="math">G\\Big{(}\\mathsf{s}^{(i)},v_{l}^{(i)},v_{r}^{(i)},v_{o}^{(i)}\\Big{)}=0</span>. An arithmetic circuit consisting of only addition and multiplication gates can be encoded with the following gate polynomial,</li>

    </ul>

    <p class="text-gray-300"><span class="math">G\\Big{(}\\mathsf{s}^{(i)},v_{l}^{(i)},v_{r}^{(i)},v_{o}^{(i)}\\Big{)}=\\mathsf{s}^{(i)}\\cdot\\Big{(}v_{\\ell}^{(i)}+v_{r}^{(i)}\\Big{)}+\\Big{(}1-\\mathsf{s}^{(i)}\\Big{)}\\cdot v_{\\ell}^{(i)}\\cdot v_{r}^{(i)}-v_{o}^{(i)}\\,.</span></p>

    <p class="text-gray-300">where <span class="math">\\mathsf{s}^{(i)}=1</span> indicates gate <span class="math">i</span> is an addition gate and <span class="math">\\mathsf{s}^{(i)}=0</span> indicates gate <span class="math">i</span> is a multiplication gate.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><em>Global copy constraints</em>: For all <span class="math">i\\in[3n]</span>, <span class="math">v^{(i)}=v^{(\\sigma^{(i)})}</span>. These constraints enforce that the wire values are invariant under the permutation induced by <span class="math">\\sigma</span>. Thus, the wire value <span class="math">v^{(i)}</span> is identical to the wire value <span class="math">v^{(\\sigma^{(i)})}</span>. In this way, the copy vector <span class="math">\\sigma</span> encodes the connectivity of the circuit.</li>

    </ul>

    <p class="text-gray-300">Natural uniform chunking of local gate constraints. Recall our goal is to come up with a uniform chunking of the above constraints. We first observe the local gate constraints admit a natural chunking strategy of simply chunking by gate. In particular, we can partition the selector vector and wire values into <span class="math">T</span> chunks of equal size (<span class="math">m=n/T</span> and <span class="math">3m</span> respectively), and check the gate constraints for the indices <span class="math">[m(j-1)+1,mj]</span> for each chunk <span class="math">j\\in[T]</span> independently.</p>

    <p class="text-gray-300">Barriers to uniformity in global copy constraints. Uniformly chunking the gate constraints has been performed in prior work <em>[WYY+22, BCC+23]</em> to reduce communication complexity of proof systems. Unfortunately, chunking by gate <em>does not</em> carry over as a valid chunking strategy for the global copy constraints. It is a global constraint: a gate in one chunk can be connected to a gate in another chunk. To see where this difficulty arises more concretely, a chunk <span class="math">j\\in[T]</span> would contain indices <span class="math">[3m(j-1)+1,3mj]</span> of <span class="math">v</span> and <span class="math">\\sigma</span>. Then, for <span class="math">i\\in[3m(j-1)+1,3mj]</span>, it may not be possible to check the copy constraint <span class="math">v^{(i)}=v^{(\\sigma^{(i)})}</span>, as <span class="math">v^{(\\sigma^{(i)})}</span> may belong to a different chunk, i.e., <span class="math">\\sigma^{(i)}\\not\\in[3m(j-1)+1,3m]</span>.</p>

    <p class="text-gray-300">Randomized compiler for uniform chunking of global copy constraints. An alternate strategy is to consider an approach taken by many proof systems in proving the global copy constraints <em>[x10]</em>. Instead of proving each copy constraint individually, the full set of global copy constraints is reduced to a set equality of the following sets:</p>

    <p class="text-gray-300"><span class="math">\\bigcup_{i=1}^{3n}\\{(v^{(i)},i)\\}=\\bigcup_{i=1}^{3n}\\{(v^{(i)},\\sigma^{(i)})\\}\\,.</span></p>

    <p class="text-gray-300">In prior work, this set equality check (or <em>permutation check</em>) <em>[x2, x10]</em> is performed by computing and comparing the evaluations of a multiset hash function <em>[CDv+03]</em> which takes the following grand product form using hash function <span class="math">\\mathsf{H}</span>:</p>

    <p class="text-gray-300"><span class="math">\\prod_{i=1}^{3n}\\mathsf{H}(v^{(i)},i)=\\prod_{i=1}^{3n}\\mathsf{H}(v^{(i)},\\sigma^{(i)})\\quad\\Rightarrow\\quad\\prod_{i=1}^{3n}\\frac{\\mathsf{H}(v^{(i)},i)}{\\mathsf{H}(v^{(i)},\\sigma^{(i)})}=1\\,.</span></p>

    <p class="text-gray-300">Once translated into this grand product, the chunking by gate indices strategy can be recovered. For each chunk <span class="math">j\\in[T]</span>, a partial product for the indices <span class="math">[3m(j-1)+1,3m]</span> can be computed as part of the uniform chunk relation; this would only rely on values that are already present in the chunk:</p>

    <p class="text-gray-300"><span class="math">\\prod_{i=1}^{3n}\\frac{\\mathsf{H}(v^{(i)},i)}{\\mathsf{H}(v^{(i)},\\sigma^{(i)})}=\\prod_{i=1}^{3m}\\frac{\\mathsf{H}(v^{(i)},i)}{\\mathsf{H}(v^{(i)},\\sigma^{(i)})}\\prod_{i=3m+1}^{6m}\\frac{\\mathsf{H}(v^{(i)},i)}{\\mathsf{H}(v^{(i)},\\sigma^{(i)})}\\cdots\\prod_{i=3n-3m+1}^{3n}\\frac{\\mathsf{H}(v^{(i)},i)}{\\mathsf{H}(v^{(i)},\\sigma^{(i)})}</span></p>

    <p class="text-gray-300">The partial product for an individual chunk would not evaluate to one, but it can be propagated during PCD and combined with the product of other chunks, such that the product at the root of the PCD tree should equal one. We will explain our PCD approach shortly.</p>

    <p class="text-gray-300">In practice, for efficiency reasons, a universal hash function <span class="math">\\mathsf{H}_{\\alpha,\\beta}(x,y)=(x+\\alpha\\cdot y)+\\beta</span> is used where challenges <span class="math">\\alpha,\\beta\\in\\mathbb{F}</span> are sampled by the verifier after the prover has committed to witness inputs <span class="math">v</span>. Looking forward, this step of the randomized compiler is what results in two passes on the witness for our eventual SNARK prover. In the first pass, the prover computes a commitment to the witness wire vector <span class="math">v</span>, and, in the second pass, the prover uses PCD over the chunks. Alternatively, one might use a deterministic hash function modeled as a random oracle as proposed by Clarke et al. <em>[CDv+03]</em> to produce a single pass streaming SNARK for NP; however, due to the concrete overheads of such an approach, we do not consider it further in this work.</p>

    <p class="text-gray-300">All together, the chunk relation takes as input a chunk of gate wires, selectors, and copy values and (1) checks the local gate constraints for each gate in the chunk and (2) computes a partial product representing a piece of the global copy constraints permutation check. Next, we describe how to apply PCD to combine these uniform chunks.</p>

    <p class="text-gray-300">Extension: Supporting lookup arguments. As a brief aside, we note that our uniform compiler also easily supports a common extension to the Plonk arithmetization known as lookup arguments. Lookup arguments allow for encoding that certain wire values are set to values that appear in a precomputed table <em>[BCG+18, x11]</em>. They are used to greatly reduce constraint overhead for representing computations without clean arithmetic structure, e.g., in hash functions like SHA256 or for range checks.</p>

    <p class="text-gray-300">The popular Plookup protocol <em>[x11]</em> reduces the lookup argument to a grand product check of multiset equality much like the permutation argument described earlier; this approach can be easily chunked into partial products in the same way. Unfortunately, Plookup is not amenable to streaming. The prover must run the full computation and then produce a sorted list of the union of wire values and table values, incurring a logarithmic number of passes on the list in the memory-constrained streaming setting.</p>

    <p class="text-gray-300">Instead, we propose the use of an alternate lookup protocol recently proposed by Haböck <em>[x14]</em> that does not rely on sorted values, where it is observed that logarithmic derivatives can translate products into summations of their reciprocals. Haböck’s approach conceptually still relies on computing universal hashes for a multiset equality check, however, it manifests as a grand summation check (instead of a grand product check); the grand summation can again be easily chunked into partial summations. By avoiding the required sorting of Plookup, the chunked Haböck lookup preserves our two-pass SNARK prover. We discuss the precise lookup details and chunking approach in Section 6.4.</p>

    <p class="text-gray-300">There exist other extensions to the arithmetization and model of computation that can reduce concrete constraints for certain computations. For example, these include forwarding constraints for Plonkish <em>[x1]</em>, rank-1 constraint systems (R1CS) or their high-degree generalization <em>[x26]</em>, random access memory <em>[BFR+13, x20, x28]</em>, or lookups into large tables <em>[x26, x1]</em>. We leave the task of constructing uniform compilers for these useful extensions to future work.</p>

    <h3 id="sec-5" class="text-xl font-semibold mt-8">2.2 SNARK from Proof-Carrying Data</h3>

    <p class="text-gray-300">In this section, we show how to apply PCD to provide a SNARK for the satisfaction of all uniform chunks, and in turn, satisfaction of the original NP statement. PCD allows for proving satisfaction of a compliance predicate <span class="math">\\varphi</span> over a computation organized as a directed acyclic graph <em>[x7, x3]</em>. For example, in a tree graph with edges pointing from children nodes to parent node, the PCD proof for the root node represents satisfaction of the compliance predicate for all internal nodes and leaf nodes of the tree. Typically, the compliance predicate is defined with a base case for leaf nodes and a recursive case for internal nodes.</p>

    <p class="text-gray-300">Our starting point for applying PCD to our uniformly-chunked NP statement is the classic PCD tree application to incrementally-verifiable computation (IVC) <em>[x29]</em> by Bitansky et al. <em>[x3]</em> where the task is to prove correct evaluation of repeated function evaluation. The compliance predicate <span class="math">\\varphi_{\\text{ivc}}</span> for this construction is roughly as follows. For simplicity, we consider a binary PCD tree and discuss higher arity later:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The base case for the <span class="math">i^{th}</span> leaf node takes a claimed <span class="math">(i-1)^{th}</span> repeated evaluation of <span class="math">F</span>, <span class="math">x^{(i-1)}</span>, and computes <span class="math">x^{(i)}\\leftarrow F(x^{(i-1)})</span>. The leaf node is represented by the range <span class="math">[i-1,i]</span> and the claimed input-output evaluations <span class="math">(x^{(i-1)},x^{(i)})</span></li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The recursive case for an internal node takes two input-output pairs for claimed ranges of repeated evaluation of <span class="math">F</span>, <span class="math">[([s_{b},t_{b}],x^{(s_{b})},x^{(t_{b})})]_{b\\in\\{0,1\\}}</span>. It merges the ranges by checking that <span class="math">t_{0}=s_{1}</span> and <span class="math">x^{(t_{0})}=x^{(s_{1})}</span>. If the check succeeds, the internal node is represented by the merged range <span class="math">[s_{0},t_{1}]</span> and the claimed input-output evaluations <span class="math">(x^{(s_{0})},x^{(t_{1})})</span>.</li>

    </ul>

    <p class="text-gray-300">With <span class="math">\\varphi_{\\mathsf{ivc}}</span>, the PCD tree is built up such that the PCD proof at the root attests to a range <span class="math">[0,t]</span> proving that <span class="math">F^{t}(x^{(0)})=x^{(t)}</span>.</p>

    <p class="text-gray-300">Our application of building a SNARK from uniform chunks shares many similarities with the IVC application. In the base case, each leaf node will indeed represent the correct computation of a uniform chunk function <span class="math">F</span>. However, the recursive case will need to perform different accounting to track the merging of uniform chunks.</p>

    <p class="text-gray-300">First, the verifier needs to check that the chunks of the copy vector <span class="math">\\sigma</span> and selector vector <span class="math">\\mathsf{s}</span> used by the prover do indeed correspond to those of the original NP statement. Similarly, recall that the <span class="math">\\alpha,\\beta</span> verifier challenges for the permutation argument are sampled after the prover commits to the wire values <span class="math">v</span>. The verifier must also then check that the chunks of the wire vector <span class="math">v</span> used by the prover correspond to what was previously committed to. Lastly, the partial products for each chunk must be merged appropriately to check the final grand product permuation argument.</p>

    <p class="text-gray-300">Consider the following <span class="math">T</span> chunks of the selector vector <span class="math">\\mathsf{s}</span>, the copy vector <span class="math">\\sigma</span>, and the wire value vector <span class="math">v</span>:</p>

    <p class="text-gray-300"><span class="math">\\Big{[}(\\mathsf{s}_{j}\\in\\mathbb{F}^{m},\\sigma_{j}\\in\\mathbb{F}^{3m},v_{j}=(v^{(1)}_{\\ell,j},v^{(1)}_{r,j},v^{(1)}_{o,j},\\ldots,v^{(m)}_{\\ell,j},v^{(m)}_{r,j},v^{(m)}_{o,j})\\in\\mathbb{F}^{3m})\\Big{]}_{j=1}^{T}</span></p>

    <p class="text-gray-300">Let us address the accounting challenges in turn. First, to track the validity of the index components and wire values used in each chunk, we construct a Merkle tree commitment to each that mirrors the tree format of PCD. Consider commitments to the index components of each chunk, <span class="math">[\\overline{\\mathsf{plk}}_{j}\\leftarrow\\mathsf{Commit}(j,\\sigma_{j},\\mathsf{s}_{j})]_{j=1}^{T}</span>, and commitments to the wire values of each chunk, <span class="math">[\\overline{v}_{j}\\leftarrow\\mathsf{Commit}(v_{j})]_{j=1}^{T}</span>. The chunk index commitments and wire commitments are each combined into a single commitment using a Merkle tree commitment, <span class="math">\\mathsf{hplk}\\leftarrow\\mathsf{MT.Commit}([\\overline{\\mathsf{plk}}_{j}]_{j=1}^{T})</span> and <span class="math">\\mathsf{hv}\\leftarrow\\mathsf{MT.Commit}([\\overline{v}_{j}]_{j=1}^{T})</span>. The index Merkle commitment <span class="math">\\mathsf{hplk}</span> is computed during preprocessing and encodes the NP statement. The wire Merkle commitment <span class="math">\\mathsf{hv}</span> is computed by the prover on its first pass over the witness, after which the <span class="math">\\alpha,\\beta</span> verifier challenges are sampled. Again, we assume the Merkle tree arity matches that of the PCD tree. The compliance predicate for our SNARK <span class="math">\\varphi_{\\mathsf{snark}}</span> checks the Merkle hash of children nodes during merges, thus the validity of the index and wire values can be confirmed by checking that the Merkle hash computed at the root of the PCD tree matches the Merkle root of the preprocessed index commitment and the prover-committed wire value commitment, respectively.</p>

    <p class="text-gray-300">To address the challenge of tracking and merging partial products of the permutation argument, each node is simply associated with a claimed partial product for the subtree of leaves rooted at that node. During a merge, the merged node sets its own partial product by taking the product of the partial products of its children. All together, the PCD compliance predicate for producing a SNARK from uniform chunks is described in Figure 3.</p>

    <p class="text-gray-300">Informally, the syntax for a PCD compliance predicate is <span class="math">\\varphi(\\mathsf{Z},\\mathsf{loc},[\\mathsf{Z}_{b}]_{b\\in\\{0,1\\}})</span>. Here <span class="math">\\mathsf{Z}</span> represents the statement of the node and <span class="math">[\\mathsf{Z}_{b}]_{b\\in\\{0,1\\}}</span> represent the statements of the children nodes in the recursive case. There is also some auxiliary local data specific to the node stored in <span class="math">\\mathsf{loc}</span>. This informal treatment does not adress higher PCD arity; we defer the full details to the main body of the paper.</p>

    <p class="text-gray-300">Given this PCD predicate for combining uniform chunks, one can apply any construction of PCD to produce a SNARK for the initial NP statement. Unfortunately, as is, any generic application of PCD would not result in an efficient protocol. The main inefficiency comes from the need to open the commitment to the</p>

    <p class="text-gray-300">!<a href="img-2.jpeg">img-2.jpeg</a> Fig. 3: PCD compliance predicate for producing a SNARK with our proposed uniform compiler.</p>

    <p class="text-gray-300">index values as part of the chunk computation. Commitments require hashing or group operations which are expensive to represent as algebraic constraints. In the next sections, we will address this inefficiency along with other sources of overhead in the application of PCD.</p>

    <p class="text-gray-300">We now step through a series of optimizations for reducing the computational overhead of PCD; these improvements are of general interest for any application of PCD.</p>

    <p class="text-gray-300">In the following, to concretely discuss the prover efficiency gains for each optimization, it will be useful to consider a specific PCD scheme. We will consider a folding-based PCD scheme similar to that of Bünz et al.  <span class="math">\\left[\\mathrm{BCL}^{+}21\\right]</span>  as it is the most prover-efficient to-date and works well with the further folding-based optimizations that we propose. Bünz et al. cast the PCD scheme using their formalism of "split accumulation"; we will modify the presentation to a notion of folding following the approach of Kothapalli et al. [KST22].</p>

    <p class="text-gray-300">First, a brief detour to describe the notion of folding that we will use. Put simply, a folding scheme for a relation  <span class="math">\\mathsf{R}</span>  folds two instances of a relation into a single instance for the same relation and provides a proof of folding. Security dictates that if the proof verifies, then membership of the folded instance in the relation implies membership of the two original instances in the relation as well. To introduce some useful notation:</p>

    <p class="text-gray-300">Definition 1 (Folding Schemes (informal)). A folding scheme Fold for a relation  <span class="math">\\mathsf{R}</span>  is a tuple of algorithms (Fold.P, Fold.V). The proving algorithm Fold.P([(xi, w_i)]_{i=1}^k) takes as input  <span class="math">k</span>  instance-witness pairs</p>

    <p class="text-gray-300">claimed to be in  <span class="math">\\mathsf{R}</span> . It outputs a folded instance-witness pair  <span class="math">(x, w)</span>  along with a folding proof  <span class="math">\\pi</span> . The verify algorithm  <span class="math">\\mathsf{Fold}.\\mathsf{V}([x_i]_{i=1}^k, x, \\pi)</span>  verifies the proof with respect to the initial instances and the folded instance such that the following properties are satisfied:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Completeness: If all initial instance-witness pairs are in the relation,  <span class="math">[(x_i, w_i) \\in \\mathsf{R}]_{i=1}^k</span> , then it holds that the folding verifier will accept and the folded instance-witness pair also belongs to  <span class="math">\\mathsf{R}</span> ,  <span class="math">(x, w) \\in \\mathsf{R}</span> .</li>

      <li>Knowledge soundness: If an adversary  <span class="math">\\hat{\\mathcal{P}}</span>  produces folded instances  <span class="math">(x_{i})_{i = 1}^{k},(x,w)</span>  and folding proof  <span class="math">\\pi</span>  that are accepted by the verifier,  <span class="math">\\mathsf{Fold.V}([x_i]_{i = 1}^k,x,\\pi) = 1</span> , and  <span class="math">(x,w)\\in \\mathsf{R}</span>  then with all but negligible probability, an extractor can find witnesses  <span class="math">[w_i]_{i = 1}^k</span>  such that  <span class="math">[(x_i,w_i)\\in \\mathsf{R}]_{i = 1}^k</span> .</li>

    </ul>

    <p class="text-gray-300">The above informal definition and syntax omit many details including treatment of indexed relations and specification of the extractor. We defer the full details to the main body of the paper.</p>

    <p class="text-gray-300">With this notion of folding, we can recast the main recursive relation  <span class="math">\\mathsf{R}_{\\mathsf{pcd}}</span>  used to construct PCD in [BCL+21]. Conceptually, the relation  <span class="math">\\mathsf{R}_{\\mathsf{pcd}}</span>  simply checks the PCD predicate  <span class="math">\\varphi</span>  and recursively verifies a folding proof for itself. However, we do not know of folding schemes for directly folding  <span class="math">\\mathsf{R}_{\\mathsf{pcd}}</span> ; we must encode an instance-witness pair for  <span class="math">\\mathsf{R}_{\\mathsf{pcd}}</span>  as an instance-witness pair for a different but related relation  <span class="math">\\mathsf{R}_{\\mathsf{pcd-poly}}</span>  and fold instances of  <span class="math">\\mathsf{R}_{\\mathsf{pcd-poly}}</span> . Shortly in Section 2.3 we will introduce the family of relations from which  <span class="math">\\mathsf{R}_{\\mathsf{pcd-poly}}</span>  comes from as polynomial relations which have a number of useful properties that we will take advantage of.</p>

    <p class="text-gray-300">For now, we need to make clear that there are two classes of instances that can belong to  <span class="math">\\mathsf{R}_{\\mathsf{pcd - poly}}</span> , strict and relaxed. Our treatment and notation for strict and relaxed instances for polynomial relations mirrors that of Kothapalli et al. [KST22] where in their search for a folding scheme for R1CS (an NP-complete relation), instead propose a folding scheme for a related superset relation they term "relaxed" R1CS. A strict instance for  <span class="math">(X,W)\\in \\mathsf{R}_{\\mathsf{pcd - poly}}</span>  has an efficiently-computable canonical bidirectional mapping to an instance in  <span class="math">(x,w)\\in \\mathsf{R}_{\\mathsf{pcd}}</span> . We denote the algorithm isStrict(X) as an efficient check if an instance in  <span class="math">\\mathsf{R}_{\\mathsf{pcd - poly}}</span>  is strict and denote the algorithm checkMap(X,x) to check if  <span class="math">X</span>  encodes  <span class="math">x</span> . In contrast, a relaxed instance,  <span class="math">(X&#x27;,W&#x27;)\\in \\mathsf{R}_{\\mathsf{pcd - poly}}</span> , does not have a mapping to instances in  <span class="math">\\mathsf{R}_{\\mathsf{pcd}}</span> . Relaxed instances are created as outputs of folding together instances of  <span class="math">\\mathsf{R}_{\\mathsf{pcd - poly}}</span> , strict or relaxed.</p>

    <p class="text-gray-300">All together, using the same notation  <span class="math">\\mathsf{Z},\\mathsf{loc},[\\mathsf{Z}_b]_{b\\in \\{0,1\\}}</span>  as above and where  <span class="math">\\mathsf{Fold}_{\\mathsf{pcd - poly}}</span>  is a folding scheme for  <span class="math">\\mathsf{R}_{\\mathsf{pcd - poly}}</span> :</p>

    <div class="my-4 text-center"><span class="math-block">\\mathsf {R} _ {\\mathsf {p c d}} = \\left\\{\\left. \\begin{array}{c} h = \\mathsf {H} (z, X ^ {\\prime}) \\text {a n d} \\varphi (\\mathsf {Z}, \\mathsf {l o c}, [ \\mathsf {Z} _ {b} ] _ {b \\in \\{0, 1 \\}}) = 1 \\\\ \\text {I f} \\underset {b \\in \\{0, 1 \\}} {\\bigwedge} \\neg \\varphi . \\mathsf {i s B a s e} (z _ {b}): \\\\ \\left(h, \\left( \\begin{array}{c} (\\mathsf {Z}, X ^ {\\prime}), \\mathsf {l o c}, \\pi \\\\ [ (Z _ {b}, X _ {b} ^ {\\prime}, X _ {b}) ] _ {b \\in \\{0, 1 \\}} \\end{array} \\right)\\right): \\quad \\begin{array}{c} (\\mathsf {i s S t r i c t} (X _ {b}) = 1) _ {b \\in \\{0, 1 \\}} \\\\ (\\mathsf {c h e c k M a p} (X _ {b}, \\mathsf {H} (\\mathsf {Z} _ {b}, X _ {b} ^ {\\prime})) = 1) _ {b \\in \\{0, 1 \\}} \\\\ \\mathsf {F o l d} _ {\\mathsf {p c d - p o l y}}. \\mathsf {V} ([ X _ {0}, X _ {0} ^ {\\prime}, X _ {1}, X _ {1} ^ {\\prime} ], X ^ {\\prime}, \\pi) = 1 \\end{array} \\right\\} \\right\\}</span></div>

    <p class="text-gray-300">In the non-base case, the PCD relation captures merging two children subtrees. The isBase predicate performs a check on the children to determine if the PCD predicate is in a base case. For concreteness, a standard base case check, as is used in  <span class="math">\\varphi_{\\mathrm{snark}}</span>  is simply checking if  <span class="math">Z_0 = \\bot \\wedge Z_1 = \\bot</span> . Here,  <span class="math">X_b&#x27;</span>  is a relaxed instance representing the folded constraints of all nodes from one child subtree not including the child itself. In contrast,  <span class="math">X_b</span>  is a strict instance for  <span class="math">\\mathsf{R}_{\\mathsf{pcd - poly}}</span>  representing the satisfaction of  <span class="math">\\mathsf{R}_{\\mathsf{pcd}}</span>  for the child node represented by  <span class="math">Z_b</span> , as such the strict mapping is checked for  <span class="math">X_b</span>  with respect to the instance  <span class="math">\\mathsf{H}(Z_b, X_b&#x27;)</span>  for  <span class="math">\\mathsf{R}_{\\mathsf{pcd}}</span> . Lastly, a new relaxed instance  <span class="math">X&#x27;</span>  folds together  <span class="math">X_b, X_b&#x27;</span>  for both children, which now represents the folded constraints of all nodes in the subtree for the parent.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Protocol</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Prover work / node</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"># of nodes</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Rpcd</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Rleaf</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Baseline [BCL+21, KST22]</td>

            <td class="px-3 py-2 border-b border-gray-700">(k+1)·</td>

            <td class="px-3 py-2 border-b border-gray-700">Rpcd</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">T + T-1/k-1</td>

            <td class="px-3 py-2 border-b border-gray-700">cchunk + cchunk-com + cchunk-merge + ck-vfold(Rpcd)</td>

            <td class="px-3 py-2 border-b border-gray-700">n/a</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">w/ decoupling (Sec. 2.3)</td>

            <td class="px-3 py-2 border-b border-gray-700">(k+1)·</td>

            <td class="px-3 py-2 border-b border-gray-700">Rpcd</td>

            <td class="px-3 py-2 border-b border-gray-700">+ k·</td>

            <td class="px-3 py-2 border-b border-gray-700">Rleaf</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">T-1/k-1</td>

            <td class="px-3 py-2 border-b border-gray-700">cchunk-merge + ck-vfold(Rpcd) + ck-vfold(Rleaf)</td>

            <td class="px-3 py-2 border-b border-gray-700">cchunk + cchunk-com</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">w/ commit-and-prove (Sec. 2.3)</td>

            <td class="px-3 py-2 border-b border-gray-700">(k+1)·</td>

            <td class="px-3 py-2 border-b border-gray-700">Rpcd</td>

            <td class="px-3 py-2 border-b border-gray-700">+ k·</td>

            <td class="px-3 py-2 border-b border-gray-700">Rleaf</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">T-1/k-1</td>

            <td class="px-3 py-2 border-b border-gray-700">cchunk-merge + ck-vfold(Rpcd) + ck-vfold(Rleaf)</td>

            <td class="px-3 py-2 border-b border-gray-700">cchunk</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Fig. 4: Summary table of improvements to prover work in building a  <span class="math">k</span> -arity PCD tree for  <span class="math">T</span>  uniform chunks of a NP statement. The size of the main control PCD relation  <span class="math">\\mathsf{R}_{\\mathsf{pcd}}</span>  and the computation leaf relation  <span class="math">\\mathsf{R}_{\\mathsf{leaf}}</span>  are given with respect to size of constraints for uniform chunk  <span class="math">c_{\\mathsf{chunk}}</span> , for opening commitment to chunk  <span class="math">c_{\\mathsf{chunk - com}}</span> , for merging chunks  <span class="math">c_{\\mathsf{chunk - merge}}</span> , and for verifying a  <span class="math">k</span> -folding proof  <span class="math">c_{k - vfold}</span> . The targeted improvement of each optimization is highlighted in a red box.</p>

    <p class="text-gray-300">To build up each node of the PCD tree, the PCD prover must (1) compute a folding proof  <span class="math">\\pi</span>  for the children subtree instances, and (2) compute a strict instance for the parent node. Computing the strict instance and folding instances take prover work (creation of homomorphic commitments) on the order of the relation size (and the number of instances folded together). Figure 4 provides a summary of the PCD prover costs. The costs are with respect to a  <span class="math">k</span> -arity PCD tree. In the next sections, we will improve the prover costs by reducing the size of  <span class="math">\\mathsf{R}_{\\mathsf{pcd}}</span> , also summarized in Figure 4.</p>

    <p class="text-gray-300">Decoupling PCD Computation Tree and Control Tree Our first optimization applies to PCD predicates that take the common structure of a base case for leaf nodes where the core computation is performed and a recursive case for internal nodes where a lightweight merging computation is performed; both  <span class="math">\\varphi_{\\mathrm{ivc}}</span>  for IVC [BCCT13] and  <span class="math">\\varphi_{\\mathrm{snark}}</span>  for our uniformly-chunked NP statement take this structure.</p>

    <p class="text-gray-300">Notice that the prover performs work on the order of the size of the PCD relation  <span class="math">\\mathsf{R}_{\\mathsf{pcd}}</span>  at every node, including leaves. In the structured PCD relations described, the merging logic consists of wasted work at the leaf level. Looking forward, when using a high PCD arity, the dominating majority of the work is performed at the leaf level so avoiding extra work at the leaf level will result in significant concrete gains. For example, for arity  <span class="math">k = 128</span>  with number of leaves  <span class="math">T = 2^{21}</span> , the number of internal nodes  <span class="math">(T - 1) / (k - 1) = 16513</span>  is less than  <span class="math">1/100</span>  the number of leaf nodes.</p>

    <p class="text-gray-300">With this motivation in mind, we propose a solution to decouple the core leaf computation from the control merging computation performed as part of PCD. Instead of having a special-case "leaf" computation check in the PCD predicate, we will define a new PCD predicate that verifies a folding proof of a leaf relation. Note that conceptually this means that the prover work for the first level of the tree is switching from generating a folding proof for the old PCD relation (which includes leaf and control logic) to a folding proof just for the leaf relation. This ensures that the overhead of the control logic is avoided at the leaves. The decoupling optimization is depicted in Figure 5.</p>

    <p class="text-gray-300">More specifically, consider the following abstract PCD predicate  <span class="math">\\varphi_{\\mathrm{couple}}</span>  where the leaf logic and merge logic are coupled together within the same predicate, defined as predicates  <span class="math">\\psi_{\\mathrm{leaf}}</span>  and  <span class="math">\\psi_{\\mathrm{recursive}}</span> , respectively. Observe that this abstraction captures  <span class="math">\\varphi_{\\mathrm{snark}}</span>  from Section 2.3 where  <span class="math">\\psi_{\\mathrm{leaf}}</span>  would encode (Case 1) and  <span class="math">\\psi_{\\mathrm{recursive}}</span>  would encode (Case 2).</p>

    <p class="text-gray-300">!<a href="img-3.jpeg">img-3.jpeg</a> Folding PCD without decoupling  <span class="math">\\left[\\mathrm{BCL}^{+}21\\right]</span></p>

    <p class="text-gray-300">!<a href="img-4.jpeg">img-4.jpeg</a> Folding PCD with decoupling Fig. 5: Depiction of decoupling optimization for folding PCD  <span class="math">k</span> -arity trees in which the computation folding tree is decoupled from the recursive folding tree. Core chunk computation is represented by purple horizontally-hatched boxes and PCD recursive computation is black cross-hatched boxes. (Left) Prior PCD tree approaches incur the cost of the PCD recursive computation at every node of the tree since the PCD recursive relation includes the core computation itself. (Right) Our decoupling optimization decouples the core computation and starts PCD recursive computation after an initial folding round of the core computation. The recursive computation includes a verifier for the chunk folding, depicted with the purple V box.</p>

    <pre><code class="language-latex">Predicate  $\\varphi_{\\mathrm{couple}}(\\mathsf{Z},\\mathsf{loc},[\\mathsf{Z}_b]_{b\\in \\{0,1\\}})$
If  $(\\mathsf{Z}_0 = \\bot \\land \\mathsf{Z}_1 = \\bot)$  then  $\\psi_{\\mathrm{leaf}}(\\mathsf{Z},\\mathsf{loc}) = 1$
Else  $\\psi_{\\mathrm{recursive}}(\\mathsf{Z},\\mathsf{loc},[\\mathsf{Z}_b]_{b\\in \\{0,1\\}}) = 1$
Predicate  $\\varphi_{\\mathrm{couple}}$  isBase(Z)
Check  $\\mathsf{Z} = \\bot$</code></pre>

    <p class="text-gray-300">Now to decouple the PCD predicate, we will separate out a leaf relation:  <span class="math">\\mathsf{R}_{\\mathrm{leaf}} = \\{(Z,\\mathrm{loc}):\\psi_{\\mathrm{leaf}}(Z,\\mathrm{loc}) = 1\\}</span> . Similar to before, we will construct a related relation  <span class="math">\\mathsf{R}_{\\mathrm{leaf - poly}}</span>  that can be folded and for which we have a bidirectional mapping of instances in  <span class="math">\\mathsf{R}_{\\mathrm{leaf}}</span>  with strict instances in  <span class="math">\\mathsf{R}_{\\mathrm{leaf - poly}}</span> . We construct a new PCD predicate  <span class="math">\\varphi_{\\mathrm{decouple}}</span>  that decouples the leaf logic by only verifying a folding proof for leaf computation. The PCD instance for  <span class="math">\\varphi_{\\mathrm{decouple}}</span>  will consist of  <span class="math">Z\\gets (Z^{\\prime},X)</span>  where  <span class="math">Z^{\\prime}</span>  is the PCD instance of  <span class="math">\\varphi_{\\mathrm{couple}}</span>  and  <span class="math">X</span>  is an instance for  <span class="math">\\mathsf{R}_{\\mathrm{leaf - poly}}</span> . Again, here we present the 2-ary case, but recall the true savings of this approach occur for high arity PCD trees.</p>

    <pre><code class="language-latex">Predicate  $\\varphi_{\\mathrm{decouple}}(\\mathsf{Z},\\mathsf{loc},[\\mathsf{Z}_b]_{b\\in \\{0,1\\}})$</code></pre>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse folding proof,  <span class="math">\\pi \\gets \\mathsf{loc}</span> , and PCD statements  <span class="math">(Z&#x27;, X) \\gets Z</span> ,  <span class="math">[(Z_b&#x27;, X_b) \\gets Z_b]_{b \\in \\{0,1\\}}</span> .</li>

      <li>Verify folding proof,  <span class="math">\\mathsf{Fold}_{\\mathrm{leaf - poly}}</span> .  <span class="math">\\mathsf{V}([X_0,X_1],X,\\pi)</span> .</li>

      <li>Check the merging constraints,  <span class="math">\\psi_{\\mathrm{recursive}}(Z&#x27;,\\mathrm{loc},[\\mathsf{Z}_b&#x27;]_{b\\in \\{0,1\\}}) = 1</span></li>

    </ol>

    <p class="text-gray-300">Predicate  <span class="math">\\varphi_{\\mathrm{decouple}}</span>  isBase(Z)</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse  <span class="math">(Z&#x27;, X) \\gets Z</span> .</li>

      <li>Check the instance is strict and maps to the given instance for  <span class="math">\\mathsf{R}_{\\mathrm{leaf}}</span> : isStrict(X)  <span class="math">\\wedge</span>  checkMap(X,Z').</li>

    </ol>

    <p class="text-gray-300">With this PCD predicate, every PCD node performs the same checks of verifying the leaf folding proof and checking the merging constraints. Interestingly, now the base case check for the PCD relation is not trivial. Previously, the check would simply check if the children instances are  <span class="math">\\perp</span> . Now, in the base case, the children correspond to leaf computations. As such, the base case requires checking that the instances of  <span class="math">\\mathsf{R}_{\\mathrm{leaf - poly}}</span>  correspond to instances of  <span class="math">\\mathsf{R}_{\\mathrm{leaf}}</span> , i.e., that they are strict. This check is only for the base case, as the instances passed into higher levels of the tree will correspond to relaxed instances of  <span class="math">\\mathsf{R}_{\\mathrm{leaf - poly}}</span> —the result of (possibly many rounds of) folding.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">In summary, using folding to decouple the leaf computation from the merging computation in a PCD tree reduces the number of PCD nodes for which merging overhead is incurred. As highlighted in Figure 4, the number of PCD nodes falls from  <span class="math">T + \\frac{T - 1}{k - 1}</span>  to  <span class="math">\\frac{T - 1}{k - 1}</span>  in a  <span class="math">k</span> -arity PCD tree with  <span class="math">T</span>  leaves. Further, the prover work per node remains approximately the same  $(</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathsf{R}_{\\mathsf{pcd}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathsf{R}_{\\mathsf{leaf}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  in decoupling is approximately the same as  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathsf{R}_{\\mathsf{pcd}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$  in the baseline). In the next section, we will take a closer look at the structure of the leaf computation.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Folding Polynomial Relations for Commit-and-Prove PCD Now that the leaf computation logic is separated into its own relation, let us revisit this leaf relation for  <span class="math">\\varphi_{\\mathrm{snark}}</span>  that checks local gate constraints and partial copy constraints for a uniform chunk (following from (Case 1)). Recall  <span class="math">\\alpha, \\beta \\in \\mathbb{F}</span>  are verifier challenges sampled ahead of PCD:</p>

    <div class="my-4 text-center"><span class="math-block">R _ {\\text {l e a f - s n a r k}} = \\left\\{ \\begin{array}{l} \\left( \\begin{array}{c} Z = (p, j, \\mathsf {h p l k}, \\mathsf {h v}) \\\\ \\mathsf {l o c} = \\left(\\mathsf {s}, \\sigma , v _ {=} (v _ {\\ell} ^ {(1)}, v _ {r} ^ {(1)}, v _ {o} ^ {(1)}, \\ldots , v _ {\\ell} ^ {(m)}, v _ {r} ^ {(m)}, v _ {o} ^ {(m)})\\right) \\end{array} \\right), \\\\ \\bigwedge_ {i = 1} ^ {m} \\mathsf {s} ^ {(i)} \\cdot \\left(v _ {\\ell} ^ {(i)} + v _ {r} ^ {(i)}\\right) + \\left(1 - \\mathsf {s} ^ {(i)}\\right) \\cdot v _ {\\ell} ^ {(i)} \\cdot v _ {r} ^ {(i)} - v _ {o} ^ {(i)} = 0 \\\\ p = \\prod_ {i = 1} ^ {3 m} \\frac {\\mathsf {H} _ {\\alpha , \\beta} (v ^ {(i)} , 3 m (j - 1) + i)}{\\mathsf {H} _ {\\alpha , \\beta} (v ^ {(i)} , \\sigma^ {(i)})} \\\\ \\boxed {\\mathsf {h p l k} = \\mathsf {M T . H (C o m m i t} (j, \\mathsf {s}, \\sigma))} \\\\ \\boxed {\\mathsf {h v} = \\mathsf {M T . H (C o m m i t} (v))} \\end{array} \\right\\}.</span></div>

    <p class="text-gray-300">The dominant contributor when encoding the above relation as a set of constraints is the commitment check where the vectors  <span class="math">\\mathsf{s}</span> ,  <span class="math">\\sigma</span> , and  <span class="math">v</span>  in the witness are shown to be openings for the commitments  <span class="math">\\overline{\\mathrm{idx}}</span>  and  <span class="math">\\overline{v}</span>  in the instance. In practice, if using a Pedersen commitment or a hash commitment (e.g., Poseidon), the constraints for commitment opening amount to  <span class="math">100 - 200 \\times</span>  that of the actual gate and copy constraint checks (using the latest optimized estimates of high degree constraints for Poseidon hashing and scalar multiplication [XCZ+22, KMN23]). In this section, we will describe a generalized foldable relation that supports proving over committed values without explicitly encoding the commitment opening constraints.</p>

    <p class="text-gray-300">Existing formalisms of folding have been specified with respect to a relation that checks some function directly over the elements in the relation instance, e.g., a rank-1 constraint system in Nova [KST22] and a polynomial map in Protostar [BC23]. With this formalism, if the relation instance includes a commitment to elements and the goal is to check some function over the committed elements, then the function must encode commitment opening as well—an undesirable additional cost. We observe that the techniques used for folding do not inherently restrict the use of commitments to elements in the instance, instead it is a limitation of the formalism. We introduce a generalization of folding relations based on polynomial map deciders (building on Protostar [BC23]) that supports the instance as any linearly-homomorphic commitment to the inputs of the polynomial map.</p>

    <p class="text-gray-300">Let us first introduce some notation for polynomial maps and the specific polynomial relation that we will be folding.</p>

    <p class="text-gray-300">Definition 2 (Polynomial Maps). A polynomial map of degree  <span class="math">d</span>  is a map  <span class="math">f: \\mathbb{F}^m \\to \\mathbb{F}^n</span>  that can be expressed as  <span class="math">f(\\mathbf{X}) \\coloneqq \\big(f^{(1)}(\\mathbf{X}), f^{(2)}(\\mathbf{X}), \\ldots, f^{(n)}(\\mathbf{X})\\big)</span>  where for all  <span class="math">i \\in [n]</span> ,  <span class="math">f_i(\\mathbf{X})</span>  is a multivariate polynomial in  <span class="math">m</span>  variables with  <span class="math">\\deg(f_i) \\leq d</span> .</p>

    <p class="text-gray-300">Consider a relation decided by a polynomial map <span class="math">\\mathsf{R}^{\\prime}=\\{(x,w)\\;:\\;f(x,w)=0\\}</span>. This relation <span class="math">\\mathsf{R}^{\\prime}</span> is NP-complete and generalizes rank-1 constraint systems which can be represented as a polynomial map of degree two. To capture commitments to instance and witness elements, we extend the relation to map <span class="math">(x,w)</span> using a collision-resistant linear map <span class="math">\\mathcal{L}_{\\mathrm{x}}</span> to some vector space <span class="math">\\mathbb{X}</span>; standard linearly-homomorphic commitments like Pedersen commitments are an example of such a map. This gives us <span class="math">\\mathsf{R}=\\{(\\overline{x}\\in\\mathbb{X},(x,w))\\;\\mid\\mathcal{L}_{\\mathrm{x}}(x,w)=\\overline{x}\\;\\wedge\\;f(x,w)=0\\}\\,,</span> representing our goal of avoiding encoding the commitment constraints <span class="math">\\mathcal{L}_{\\mathrm{x}}</span> within the polynomial relation <span class="math">f</span>.</p>

    <p class="text-gray-300">Unfortunately, we do not have techniques for folding <span class="math">\\mathsf{R}</span> directly. Recall the discussion at the beginning of Section 2.3 on building the PCD folding relation in which it was claimed that we can map relation <span class="math">\\mathsf{R}</span> to another related relation <span class="math">\\mathsf{R}_{\\mathsf{poly}}</span> which is foldable; we will explain that now.</p>

    <p class="text-gray-300">Following the techniques of Nova <em>[x10]</em> and Protostar <em>[x2]</em>, there are two relaxations that can be made to produce a relation amenable to folding. First, the polynomial map needs to be made <em>homogeneous</em>, meaning that each polynomial <span class="math">f_{i}</span> for <span class="math">i\\in[n]</span> of the map is homogeneous (i.e., every monomial in the polynomial is of the same degree <span class="math">d</span>) and all <span class="math">f_{i}</span> have the same degree <span class="math">d</span>. Luckily, any polynomial map <span class="math">f</span> of degree <span class="math">d</span> for <span class="math">(x,w)\\in\\mathbb{F}^{m}</span> can be transformed into a homogeneous polynomial map <span class="math">\\hat{f}</span> of same degree <span class="math">d</span> for <span class="math">(x,w,\\mu)\\in\\mathbb{F}^{m+1}</span> such that <span class="math">f(x,w)=\\hat{f}(x,w,1)</span>:</p>

    <p class="text-gray-300"><span class="math">f(x)=\\textstyle\\sum_{j=0}^{d}f_{j}(x,w)\\quad\\mapsto\\quad\\hat{f}(x,w,\\mu)\\vcentcolon=\\sum_{j=0}^{d}\\mu^{d-j}f_{j}(x)</span></p>

    <p class="text-gray-300">where <span class="math">f_{j}</span> is the <span class="math">j</span>-th degree homogeneous component of <span class="math">f</span> (i.e. the portion of the map consisting of only degree <span class="math">j</span> terms).</p>

    <p class="text-gray-300">Second, the polynomial map decider cannot be with respect to a fixed evaluation test, e.g., checking <span class="math">\\hat{f}(x,w,\\mu)=0</span>. Instead, an evaluation term <span class="math">e\\in\\mathbb{F}^{n}</span> is added to the instance to represent the check <span class="math">\\hat{f}(x,w,\\mu)=e</span>. In practice, we would also like the instance to be succinct in <span class="math">e</span>, so we allow for a second linear map <span class="math">\\mathcal{L}_{\\mathrm{e}}:\\mathbb{F}^{n}\\to\\mathbb{E}</span> to compress the evaluation term. All together, this results in the following foldable relation:</p>

    <h6 id="sec-7" class="text-base font-medium mt-4">Definition 3 (Relaxed Polynomial Map Relation (informal)).</h6>

    <p class="text-gray-300">Let <span class="math">\\hat{f}:\\mathbb{F}^{m}\\to\\mathbb{F}^{n}</span> be a homogeneous polynomial map of degree <span class="math">d</span>, <span class="math">\\mathcal{L}_{\\mathrm{x}}:\\mathbb{F}^{m}\\to\\mathbb{X}</span> and <span class="math">\\mathcal{L}_{\\mathrm{e}}:\\mathbb{F}^{m}\\to\\mathbb{E}</span> be linear maps. We define the following relation</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\mathsf{R}_{\\mathsf{poly}}=\\left\\{((\\overline{x}\\in\\mathbb{X},\\,\\overline{e}\\in\\mathbb{E},\\,\\mu),\\,(x,w))\\;\\;\\middle</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\;\\;(\\overline{x},\\,\\overline{e})=(\\,\\mathcal{L}_{\\mathrm{x}}(x,w),\\,\\,\\mathcal{L}_{\\mathrm{e}}(\\hat{f}(x,w,\\mu))\\,)\\right\\}\\,.$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Recall that for this foldable relation <span class="math">\\mathsf{R}_{\\mathsf{poly}}</span>, we consider (1) strict instances that are mapped from instances of <span class="math">\\mathsf{R}</span>, and (2) relaxed instances that are the result of folding. The mapping of an instance-witness pair <span class="math">(x,w)\\in\\mathsf{R}</span> to a strict instance-witness pair in <span class="math">(X,W)\\in\\mathsf{R}_{\\mathsf{poly}}</span> is straightforward:</p>

    <p class="text-gray-300"><span class="math">(x=\\overline{x},w=(x,w))\\in\\mathsf{R}\\;\\mapsto\\;(X=(\\overline{x},\\,\\overline{e}=\\mathcal{L}_{\\mathrm{e}}(0),\\,\\mu=1),\\,W=(x,w))\\in\\mathsf{R}_{\\mathsf{poly}}\\,.</span></p>

    <p class="text-gray-300">By setting <span class="math">\\overline{e}=\\mathcal{L}_{\\mathrm{e}}(0)</span> and <span class="math">\\mu=1</span>, we recover the check for <span class="math">f(x,w)=0</span> from <span class="math">\\hat{f}(x,w,\\mu)=e</span>. Thus, the <span class="math">\\mathsf{isStrict}(X=(\\overline{x},\\overline{e},\\mu))</span> algorithm checks <span class="math">X.\\overline{e}=\\mathcal{L}_{\\mathrm{e}}(0)</span> and <span class="math">X.\\mu=1</span>. Similarly, the <span class="math">\\mathsf{checkMap}(X=(\\overline{x},\\overline{e},\\mu),x=\\overline{x})</span> algorithm checks the encoding of <span class="math">x</span> in the strict instance by checking <span class="math">X.\\overline{x}=x</span>.</p>

    <p class="text-gray-300">Now that we have defined the mapping of <span class="math">\\mathsf{R}</span> to strict instance-witness pairs of <span class="math">\\mathsf{R}_{\\mathsf{poly}}</span>, we can observe the necessity of relaxed instances from the folding algorithm <span class="math">\\mathsf{Fold}_{\\mathsf{poly}}</span> for <span class="math">\\mathsf{R}_{\\mathsf{poly}}</span>. The folding algorithm for folding <span class="math">k</span> instances proceeds recursively, constructing a folding tree from two-to-one folds. In the first round, <span class="math">k/2</span> pairwise two-to-one foldings are performed to result in <span class="math">k/2</span> instances to fold in the next round. The protocol terminates at a base case when a single instance remains. Note, that for <span class="math">k=2</span>, the folding algorithm and the approach for handling cross-terms follows similarly to Protostar <em>[x2]</em>, which is a single round, two-to-one</p>

    <p class="text-gray-300">folding scheme. When considering  <span class="math">k &amp;gt; 2</span> , we generalize the approach to remain knowledge-sound even for  <span class="math">k = \\mathsf{poly}(\\lambda)</span>  by constructing a logarithmic-round special-sound protocol. More discussion on this approach follows. For ease of presentation, we will present the protocol as an interactive protocol which can be made non-interactive using the Fiat-Shamir heuristic to match the syntax of folding schemes described earlier.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Foldpoly.P([((x̅i, x̅i, μi), (xi, wi))]k i=1)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Foldpoly.V([(x̅i, x̅i, μi)]k i=1)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  [zi←(xi, wi, μi)]k i=1 |   |   |</p>

    <p class="text-gray-300">|  For i ∈ [k/2], compute (vi,j)d-1/2 such that for indeterminate Y: f(Y·zi + zi+k/2) = Yd f(zi) + ∑j=1d-1Yj·vi,j + f(zi+k/2) |   |   |</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">[ [x̅i,j ← Lv(vi,j)]d-1j=1]k/2</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">[ [x̅i,j]d-1j=1]k/2</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">|  x̅i' = r^d · x̅i + ∑i=1d-1(r^j · x̅i,j) + x̅i+k/2 |   |   |</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">μi' = r · μi + μi+k/2</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">[ x̅i' = r · x̅i + x̅i+k/2</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">w_i' = r · wi + wi+k/2</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">μ_i' = r · μi + μi+k/2</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">If k/2 = 1 then return ((x̅1', x̅1', μ1'), (x1', w1'))</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">If k/2 = 1 then return (x̅1', x̅1', μ1')</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Else recurse on [((x̅i', x̅i', μi'), (x1', wi'))]k/2i=1</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">Else recurse on [(x̅i', x̅i', μi')]k/2i=1</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Folding proceeds by taking random linear combinations of  <span class="math">x, w, \\mu</span>  and reducing the cross-terms from the computation of  <span class="math">\\hat{f}</span>  to the evaluation term  <span class="math">e</span> . As such, the strictness structure of the instance, i.e.  <span class="math">\\mu = 1</span>  and  <span class="math">e = 0</span> , will be destroyed after folding.</p>

    <p class="text-gray-300">The above folding tree construction is similar to the one proposed recently by Ràfols and Zacharakis [RZ22]. However, there is a key difference that leads to a different security guarantee. [RZ22] constructs an k-to-1 folding scheme for R, by recursively composing a 2-to-1 black-box folding scheme in a tree, where each layer reduces the number of relation pairs in half by calling the 2-to-1 folding scheme repeatedly. A limitation in the security proof of Ràfols and Zacharakis is that knowledge soundness only holds for a constant  <span class="math">k</span> . This stems from the fact that recursive extraction with a black-box folding scheme only holds up to a constant number of iterations (otherwise, the extractor runtime is super-polynomial). To address the limitation, we instead directly construct k-to-1 folding scheme by the Fiat-Shamir transform of a logarithmic-round, special-sound protocol. This allows us to leverage a key result from [AFK22], which constructs an efficient extractor for the Fiat-Shamir transform of a multi-round, special-sound protocol. In this manner, we are able to avoid this barrier to fold a polynomial number of pairs. For our SNARK application, we will need a folding scheme capable of handing an arity at least  <span class="math">k = O(\\lambda)</span> , linear in the security parameter.</p>

    <p class="text-gray-300">In addition to the above folding tree construction, we introduce another multi-instance folding scheme (Protocol 2 in Section 5.2). This scheme adapts ideas from Protogalaxy [EG23] and offers several advantages over the folding tree construction. Protocol 2 directly supports arbitrary polynomial maps, requires only two rounds of communication, and features a folding verifier with half the size. As a tradeoff, the folding prover in Protocol 2 requires  <span class="math">O(k^2 m)</span>  field operations <span class="math">^2</span>  and  <span class="math">O(km)</span>  group operations, whereas the folding tree construction requires only  <span class="math">O(km)</span>  field and group operations.</p>

    <p class="text-gray-300">Lastly, backtracking to the original motivation for folding on committed instances, we can recast <span class="math">\\mathsf{R}_{\\mathsf{leaf}\\text{-}\\mathsf{snark}}</span> defining <span class="math">\\hat{f}</span> as the homogeneous map that takes <span class="math">(x,w)=(p,j,\\mathsf{s},\\sigma,v)\\in\\mathbb{F}^{7m+2}</span> and outputs <span class="math">0</span> if the following leaf constraints are satisfied:</p>

    <p class="text-gray-300"><span class="math">\\bigwedge_{i=1}^{m}\\mathsf{s}^{(i)}\\cdot\\left(v_{\\ell}^{(i)}+v_{r}^{(i)}\\right)+\\left(1-\\mathsf{s}^{(i)}\\right)\\cdot v_{\\ell}^{(i)}\\cdot v_{r}^{(i)}-v_{o}^{(i)}=0,\\;\\;p=\\prod_{i=1}^{3m}\\frac{\\mathsf{H}_{\\alpha,\\beta}(v^{(i)},3m(j-1)+i)}{\\mathsf{H}_{\\alpha,\\beta}(v^{(i)},\\sigma^{(i)})}</span></p>

    <p class="text-gray-300">This is not quite complete, as the above constraints are not polynomials; a product of rational fractions is included. In the main body, we show how to translate this constraint into a polynomial map of low degree. A naive translation might result in a polynomial of degree <span class="math">3m</span>, but keeping a low degree is important as the proof size and prover computation of the folding protocol scales with degree.</p>

    <p class="text-gray-300">We define <span class="math">\\mathcal{L}_{\\mathrm{x}}:\\mathbb{F}^{7m+3}\\to(\\mathbb{F}^{2}\\times\\mathbb{G}^{2})</span> that passes the partial product directly and commits to the index values and wire values using a Pedersen commitment.</p>

    <p class="text-gray-300"><span class="math">\\mathcal{L}_{\\mathrm{x}}:(j,\\mathsf{s},\\sigma,v,p,\\mu)\\mapsto(\\,\\overline{\\mathsf{p}\\mathsf{I}\\mathsf{k}}=\\mathsf{Ped.}\\mathsf{Commit}(j,\\mathsf{s},\\sigma),\\,\\overline{v}=\\mathsf{Ped.}\\mathsf{Commit}(v),p,\\mu)\\,.</span></p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">The partial product is exposed in the instance of the polynomial relation since they will need to be accessed by the PCD predicate for checking merging constraints. Note, <span class="math">\\mathcal{L}_{\\mathrm{x}}</span> satisfies the collision-resistance property due to the binding of the Pedersen commitment. The full details for the leaf polynomial relation and PCD relation are deferred to Section 6.3. Altogether, this gives us a leaf relation represented by a much smaller number of constraints as the commitment opening constraints have been removed, shown in Figure 4 as a reduction in $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathsf{R}_{\\mathsf{leaf}}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$. The cost of folding the leaf relation is incurred at every PCD node, so this reduction in constraint size leads to prover savings throughout the entire PCD tree construction.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <h3 id="sec-8" class="text-xl font-semibold mt-8">2.4 Overview Summary</h3>

    <p class="text-gray-300">Altogether, our techniques result in a piecewise SNARK with tunable memory usage and high parallelism that does not come at the cost of increased prover time; our cost accounting estimates our SNARK incurs similar prover computation costs to state-of-the-art monolithic SNARKs <em>[x10]</em>. We provide an evaluation of our proposed constructions in Section 6.4.</p>

    <p class="text-gray-300">Section 4 introduces our new generalization of folding to polynomial relations and accompanying folding construction that underlies the efficiency improvements of the commit-and-prove optimization from Section 2.3. Section 6 presents our SNARK construction from PCD for a Plonk arithmetization of NP statements. The details on the leaf relation for uniform chunks as part of the leaf decoupling optimization are discussed in Section 6.3 and Section 6.3.</p>

    <h2 id="sec-9" class="text-2xl font-bold">3 Preliminaries</h2>

    <h5 id="sec-10" class="text-base font-semibold mt-4">Notation.</h5>

    <p class="text-gray-300">For an integer <span class="math">n\\in\\mathbb{N}</span> we denote by <span class="math">[n]</span> the set <span class="math">\\{1,\\ldots,n\\}</span>. For a finite set <span class="math">X</span> we denote by <span class="math">x\\leftarrow X</span> the random variable defined as a uniform random sample from <span class="math">X</span>. For a distribution <span class="math">\\mathcal{D}</span> we denote by <span class="math">x\\leftarrow\\mathcal{D}</span> a random variable sampled from <span class="math">\\mathcal{D}</span>. We use <span class="math">\\mathbb{F}</span> to denote a field of prime order, and use <span class="math">\\mathbb{F}^{\\leq d}[X_{1},\\ldots,X_{m}]</span> to denote the set of <span class="math">m</span>-variate polynomials over <span class="math">\\mathbb{F}</span> of degree at most <span class="math">d</span>, For any vector <span class="math">v\\in\\mathbb{F}^{n}</span>, we index the elements as <span class="math">\\{v_{i}\\}_{i=1}^{n}</span>. Define a range function <span class="math">\\mathsf{rn}(i,k):=[(i-1)\\cdot k+1,\\;i\\cdot k]</span>. For a vector <span class="math">v</span>, we denote <span class="math">v^{\\mathsf{rn}(i,k)}</span> as the subvector of <span class="math">v</span> containing the elements in the range <span class="math">\\mathsf{rn}(i,k)</span>. Informally, this is the <span class="math">i</span> chunk (of size <span class="math">k</span>) of <span class="math">v</span>. <span class="math">\\mathsf{PPT}</span> refers to the class of probabilistic algorithms that run in polynomial time, while expected <span class="math">\\mathsf{PPT}</span> refers to the class of probabilistic algorithms that run in expected polynomial time.</p>

    <p class="text-gray-300">Definition 4 (Interactive Argument ([AFK22, ACK21, BC23])). Consider  <span class="math">\\mu, k_1, \\ldots, k_\\mu \\in \\mathbb{N}</span>  and a challenge space  <span class="math">\\mathcal{R}</span> . An interactive argument for a family of binary relations  <span class="math">\\{R_{\\mathfrak{pp}}\\}_{\\mathfrak{pp}}</span>  is a tuple of PPT algorithms  <span class="math">\\Pi := (\\mathcal{G}, \\mathcal{P}, \\mathcal{V})</span>  with the following interface:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{G}(1^{\\lambda})\\to \\mathfrak{pp}</span> : Given security parameter  <span class="math">1^{\\lambda}</span> , outputs public parameters  <span class="math">\\mathfrak{pp}</span> .</li>

      <li><span class="math">\\langle \\mathcal{P}(\\mathfrak{pp},x,w),\\mathcal{V}(\\mathfrak{pp},x)\\rangle \\to 0 / 1</span> : A  <span class="math">(2\\mu +1)</span> -move interactive protocol between two PPT algorithms, a prover  <span class="math">\\mathcal{P}</span>  and a verifier  <span class="math">\\mathcal{V}</span> . Both  <span class="math">\\mathcal{P}</span>  and  <span class="math">\\mathcal{V}</span>  are given as input public parameters  <span class="math">\\mathfrak{pp}</span>  and instance  <span class="math">x</span> . In addition,  <span class="math">\\mathcal{P}</span>  is given a witness  <span class="math">w</span>  such that  <span class="math">(x,w)\\in R_{\\mathfrak{pp}}</span> . At the end of the protocol, the verifier outputs accept or reject. Accordingly, the corresponding transcript is accepting or rejecting.</li>

    </ul>

    <p class="text-gray-300">!<a href="img-5.jpeg">img-5.jpeg</a> A Public Coin Interactive Argument</p>

    <p class="text-gray-300">An interactive argument is public coin if all of the verifier's random coins are made public. In particular, a verifier consists of two subroutines—an interactive algorithm which sends the prover random messages  <span class="math">r_i \\gets \\mathbb{S} \\mathcal{R}</span>  and a decision algorithm which outputs accept or reject given the transcript  <span class="math">(m_1, r_1, \\ldots, r_\\mu, m_{\\mu+1})</span> .</p>

    <p class="text-gray-300">A  <span class="math">(k_{1},\\ldots ,k_{\\mu})</span>  -tree of transcripts for a  <span class="math">(2\\mu +1)</span>  -move protocol is a set of  <span class="math">K = \\prod_{i = 1}^{\\mu}k_{i}</span>  transcripts arranged in a tree structure. The nodes in this tree correspond to the prover's messages and the edges correspond to the verifier's messages. Every node at depth  <span class="math">i</span>  has precisely  <span class="math">k_{i}</span>  children corresponding to  <span class="math">k_{i}</span>  pairwise distinct verifier messages. Every transcript corresponds to exactly one path from the root node to a leaf node.</p>

    <p class="text-gray-300">A interactive argument  <span class="math">\\Pi</span>  is secure if it satisfies the following properties:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Completeness: For all  <span class="math">\\mathfrak{pp} \\in \\mathcal{G}(1^{\\lambda})</span>  and  <span class="math">(x, w) \\in R_{\\mathfrak{pp}}</span> ,  <span class="math">\\operatorname*{Pr}[\\langle \\mathcal{P}(\\mathfrak{pp}, x, w), \\mathcal{V}(\\mathfrak{pp}, x) \\rangle = 1] = 1</span> .</li>

      <li><span class="math">(k_{1},\\ldots ,k_{\\mu})</span>  -Special Soundness: An interactive argument  <span class="math">\\Pi</span>  is  <span class="math">(k_{1},\\ldots ,k_{\\mu})</span>  -special sound if there exists an PPT algorithm  <span class="math">w\\gets \\mathcal{E}(\\mathsf{pp},x,\\mathsf{tree})</span>  that given public parameters  <span class="math">\\mathsf{pp}</span> , an instance  <span class="math">x</span> , and a  <span class="math">(k_{1},\\ldots ,k_{\\mu})</span>  -tree of accepting transcripts tree, outputs a witness  <span class="math">w</span>  such that  <span class="math">(x,w)\\in R_{\\mathsf{pp}}</span> .</li>

    </ul>

    <p class="text-gray-300">Random Oracles We denote by  <span class="math">\\mathcal{O}(\\lambda)</span>  the set of all functions that map  <span class="math">\\{0,1\\}^<em></span>  to  <span class="math">\\{0,1\\}^\\lambda</span> . A random oracle  <span class="math">\\mathsf{ro}:\\{0,1\\}^</em>\\to \\{0,1\\}^\\lambda</span>  is a function sampled uniformly at random from  <span class="math">\\mathcal{O}(\\lambda)</span> .</p>

    <p class="text-gray-300">Index Relations An index relation  <span class="math">\\mathsf{R}</span>  is a set of triples  <span class="math">(\\mathrm{idx}, x, w)</span>  where  <span class="math">\\mathrm{idx}</span>  is the index,  <span class="math">x</span>  is the instance, and  <span class="math">w</span>  is the witness.</p>

    <p class="text-gray-300">Definition 5 (NARKs ([AFK22, BCL <span class="math">^{+}</span> 21, BC23])). A (preprocessing) non-interactive argument in the random oracle model (ROM) for a family of index relations  <span class="math">\\{\\mathsf{R}_{\\mathsf{pp}}\\}_{\\mathsf{pp}}</span>  is a tuple of PPT algorithms NARK =  <span class="math">(\\mathcal{G}_{\\mathsf{nark}}, \\mathcal{I}_{\\mathsf{nark}}, \\mathcal{P}_{\\mathsf{nark}}, \\mathcal{V}_{\\mathsf{nark}})</span>  with the following interface:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{G}_{\\mathrm{nark}}(1^{\\lambda}) \\to \\mathsf{pp}</span> : Given security parameter  <span class="math">1^{\\lambda}</span> , outputs public parameters  <span class="math">\\mathsf{pp}</span> .</li>

      <li><span class="math">\\mathcal{I}_{\\mathrm{nark}}(\\mathsf{pp},\\mathsf{idx})\\to (\\mathsf{npk},\\mathsf{nvk})</span>  : Given public parameters pp and an index idx, outputs a proving key npk and verification key nvk.</li>

      <li><span class="math">\\mathcal{P}_{\\mathrm{nark}}^{\\mathrm{ro}}(\\mathsf{npk},x,w)\\to \\pi</span>  : Given proving key npk and oracle access to a random oracle ro, instance  <span class="math">x</span>  , and witness  <span class="math">w</span>  , outputs a proof  <span class="math">\\pi</span></li>

      <li><span class="math">\\mathcal{V}_{\\mathrm{nark}}^{\\mathrm{ro}}(\\mathsf{nvk},x,\\pi)\\to 0 / 1</span>  : Given verification key nvk and oracle access to a random oracle ro, instance  <span class="math">x</span>  and a proof  <span class="math">\\pi</span>  , outputs accept or reject.</li>

    </ul>

    <p class="text-gray-300">A non-interactive argument NARK is secure if the following properties hold:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Completeness: For all  <span class="math">\\mathsf{pp} \\in \\mathcal{G}_{\\mathsf{nark}}(1^{\\lambda})</span>  and  <span class="math">(\\mathrm{idx}, x, w) \\in R_{\\mathsf{pp}}</span> ,</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} &amp;amp; \\mathsf {r o} \\leftarrow \\mathcal {O} (\\lambda) \\\\ \\mathcal {V} _ {\\mathsf {n a r k}} ^ {\\mathsf {r o}} (\\mathsf {n v k}, x, \\pi) = 1: &amp;amp; (\\mathsf {n p k}, \\mathsf {n v k}) \\leftarrow \\mathcal {I} _ {\\mathsf {n a r k}} (\\mathsf {p p}, \\mathsf {i d x}) \\\\ &amp;amp; \\pi \\leftarrow \\mathcal {P} _ {\\mathsf {n a r k}} ^ {\\mathsf {r o}} (\\mathsf {n p k}, x, w) \\end{array} \\right] \\geq 1 - \\mathsf {n e g l} (\\lambda)</span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Knowledge Soundness: With respect to an auxiliary input distribution  <span class="math">\\mathcal{D}</span> , a non-interactive argument NARK is knowledge sound with knowledge error  <span class="math">\\kappa : \\mathbb{N} \\times \\mathbb{N} \\to [0,1]</span>  if for every expected PPT adversary  <span class="math">\\hat{\\mathcal{P}}</span>  who makes at most a polynomial number  <span class="math">Q</span>  queries to  <span class="math">\\mathsf{ro}</span> , there exists a positive polynomial  <span class="math">q</span>  and an expected PPT extractor  <span class="math">\\mathcal{E}_{\\hat{\\mathcal{P}}}</span>  such that for every distinguishing predicate  <span class="math">\\rho</span> ,</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Pr \\left[ \\begin{array}{c c} &amp; \\mathsf {r o} \\leftarrow \\mathcal {O} (\\lambda) \\\\ \\rho \\big (\\mathsf {p p}, \\mathsf {a i}, \\mathsf {a o}, \\mathsf {i d x}, x \\big) = 1 &amp; \\mathsf {p p} \\leftarrow \\mathcal {G} _ {\\mathsf {n a r k}} (1 ^ {\\lambda}) \\\\ \\wedge (\\mathsf {i d x}, x, w) \\in R _ {\\mathsf {p p}} &amp; : \\mathsf {a i} \\leftarrow \\mathcal {D} (\\mathsf {p p}) \\\\ &amp; (\\mathsf {i d x}, x, w, \\mathsf {a o}) \\\\ &amp; \\leftarrow \\mathcal {E} _ {\\hat {\\mathcal {P}}} ^ {\\mathsf {r o}} (\\mathsf {p p}, \\mathsf {a i}) \\end{array} \\right] \\geq \\frac {\\epsilon (\\hat {\\mathcal {P}}) - \\kappa (</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, Q)}{q (</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)}</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">where  <span class="math">\\epsilon (\\tilde{\\mathcal{P}})</span>  is defined as the probability:</p>

    <div class="my-4 text-center"><span class="math-block">\\epsilon (\\tilde {\\mathcal {P}}) := \\Pr \\left[ \\begin{array}{c c} &amp;amp; \\mathsf {r o} \\leftarrow \\mathcal {O} (\\lambda) \\\\ &amp;amp; \\mathsf {p p} \\leftarrow \\mathcal {G} _ {\\mathsf {n a r k}} (1 ^ {\\lambda}) \\\\ \\rho \\big (\\mathsf {p p}, \\mathsf {a i}, \\mathsf {a o}, \\mathsf {i d x}, x \\big) = 1 \\\\ \\wedge \\mathcal {V} _ {\\mathsf {n a r k}} ^ {\\mathsf {r o}} (\\mathsf {n v k}, x, \\pi) = 1 \\\\ &amp;amp; (\\mathsf {n p k}, \\mathsf {n v k}) \\leftarrow \\mathcal {I} _ {\\mathsf {n a r k}} (\\mathsf {p p}, \\mathsf {i d x}) \\\\ &amp;amp; (\\mathsf {i d x}, x, \\pi , \\mathsf {a o}) \\leftarrow \\tilde {\\mathcal {P}} ^ {\\mathsf {r o}} (\\mathsf {p p}, \\mathsf {a i}) \\end{array} \\right]</span></div>

    <p class="text-gray-300">And, the runtime of  <span class="math">\\mathcal{E}_{\\tilde{\\mathcal{P}}}</span>  is at most a polynomial in the runtime of  <span class="math">\\tilde{\\mathcal{P}}</span> .</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">A NARK can optionally be succinct if the size of the proof  <span class="math">\\pi</span>  is  <span class="math">\\mathsf{poly}(\\lambda)</span>  and the running time of  <span class="math">\\mathcal{V}_{\\mathsf{nark}}(\\mathsf{nvk},x)</span>  is  $\\mathsf{poly}(\\lambda +</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> . These quantities must be independent of size of the index  </span>\\mathsf{idx}<span class="math">  used to derive  </span>\\mathsf{nvk}$ . A NARK that is succinct is called a SNARK.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Remark 1. The definition of knowledge soundness above captures the fact that for every adversarial prover  <span class="math">\\tilde{\\mathcal{P}}</span>  that outputs an index-statement pair  <span class="math">(\\mathrm{idx},x)</span>  and a valid proof  <span class="math">\\pi</span>  for this pair, there is an extractor  <span class="math">\\mathcal{E}_{\\tilde{\\mathcal{P}}}</span>  that extracts a valid witness  <span class="math">w</span>  from  <span class="math">\\tilde{\\mathcal{P}}</span>  such that  <span class="math">(\\mathrm{idx},x,w)\\in R_{\\mathrm{pp}}</span> . The purpose of the distinguisher  <span class="math">\\rho</span>  is to ensure that the extractor  <span class="math">\\mathcal{E}_{\\tilde{\\mathcal{P}}}</span>  extracts a witness on a distribution  <span class="math">(\\mathrm{idx},x)</span>  that is statistically close to the distribution of  <span class="math">(\\mathrm{idx},x)</span>  for which the prover  <span class="math">\\tilde{\\mathcal{P}}</span>  generates proofs.</p>

    <p class="text-gray-300">Note that we can convert a special-sound interactive argument (Definition 4) into a non-interactive argument (with knowledge soundness) via the adaptive Fiat-Shamir transform [AFK22] (where the verifier's challenges are derived non-interactively by querying the random oracle successively on the instance and current transcript).</p>

    <p class="text-gray-300">Lemma 1 (Theorem 4 of [AFK22]). The adaptive Fiat-Shamir transformation  <span class="math">\\mathsf{FS}[\\varPi]</span>  of a  <span class="math">(k_{1},\\ldots ,k_{\\mu})</span>  special-sound interactive argument  <span class="math">\\varPi</span> , in which all challenges are sampled from a set  <span class="math">\\mathcal{C}</span>  of size  <span class="math">N</span> , is a NARK (with the knowledge soundness defined in Definition 5) that has knowledge error  <span class="math">(Q + 1)\\kappa</span>  where  <span class="math">\\kappa</span>  is the knowledge error of the interactive argument  <span class="math">\\varPi</span>  and  <span class="math">Q</span>  is the number of RO queries made by the adversary.</p>

    <p class="text-gray-300">Definition 6 (Collision Resistant Hash Functions). Let  <span class="math">\\ell(\\lambda)</span>  be a polynomial in the security parameter. A hash function is a pair of PPT algorithms  <span class="math">(\\mathsf{Setup}_{\\mathsf{H}}, \\mathsf{H})</span>  with the following interface:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{Setup}_{\\mathsf{H}}(1^{\\lambda})\\to \\mathsf{pp}_{\\mathsf{H}}</span>  : Given a security parameter  <span class="math">1^{\\lambda}\\in 1^{\\mathbb{N}}</span>  , outputs public parameters  <span class="math">\\mathsf{pp}_{\\mathsf{H}}</span></li>

      <li><span class="math">\\mathsf{H}(\\mathsf{pp}_{\\mathsf{H}},m)\\to \\{0,1\\}^{\\lambda}</span>  : Given public parameters  <span class="math">\\mathsf{pp}_{\\mathsf{H}}</span>  and input  <span class="math">m\\in \\{0,1\\}^{\\ell (\\lambda)}</span>  , outputs a hash  <span class="math">h\\in \\{0,1\\}^{\\lambda}</span></li>

    </ul>

    <p class="text-gray-300">With respect to an auxiliary input distribution  <span class="math">\\mathcal{D}</span> , a hash function is collision resistant if for every expected PPT adversary  <span class="math">\\mathcal{A}</span></p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} \\mathsf {H} (\\mathsf {p p} _ {\\mathsf {H}}, m _ {0}) = \\mathsf {H} (\\mathsf {p p} _ {\\mathsf {H}}, m _ {1}) \\wedge &amp;amp; \\mathsf {p p} _ {\\mathsf {H}} \\leftarrow \\mathsf {S e t u p} _ {\\mathsf {H}} (1 ^ {\\lambda}) \\\\ m _ {0} \\neq m _ {1} &amp;amp; : \\mathsf {a i} \\leftarrow \\mathcal {D} (\\mathsf {p p} _ {\\mathsf {H}}) \\\\ &amp;amp; (m _ {0}, m _ {1}) \\leftarrow \\mathcal {A} (\\mathsf {p p} _ {\\mathsf {H}}, \\mathsf {a i}) \\end{array} \\right] \\leq \\mathsf {n e g l} (\\lambda).</span></div>

    <p class="text-gray-300">Definition 7 (Commitment Scheme). A commitment scheme over an input space  <span class="math">\\mathcal{M}</span>  and commitment space  <span class="math">\\mathcal{C}</span>  is a pair of PPT algorithms (Setupcom, Commit) with the following interface:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\operatorname{Setup}_{\\mathrm{com}}(1^{\\lambda}) \\to \\mathsf{ck}</span> : Given a security parameter  <span class="math">1^{\\lambda} \\in 1^{\\mathbb{N}}</span> , outputs public parameters  <span class="math">\\mathsf{ck}</span> .</li>

      <li>Commit(ck, m) → c: A deterministic algorithm that takes as input the public parameters ck and input  <span class="math">m \\in \\mathcal{M}</span> , outputs a commitment  <span class="math">c \\in \\mathcal{C}</span> .</li>

    </ul>

    <p class="text-gray-300">With respect to an auxiliary input distribution  <span class="math">\\mathcal{D}</span> , a commitment scheme is binding, if for every expected PPT adversary  <span class="math">\\mathcal{A}</span> ,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} \\mathsf {C o m m i t} (\\mathsf {c k}, m _ {0}) = \\mathsf {C o m m i t} (\\mathsf {c k}, m _ {1}) \\wedge &amp;amp; \\mathsf {c k} \\leftarrow \\mathsf {S e t u p} _ {\\mathsf {c o m}} (1 ^ {\\lambda}) \\\\ m _ {0} \\neq m _ {1} &amp;amp; : \\mathsf {a i} \\leftarrow \\mathcal {D} (\\mathsf {c k}) \\\\ &amp;amp; (m _ {0}, m _ {1}) \\leftarrow \\mathcal {A} (\\mathsf {c k}, \\mathsf {a i}) \\end{array} \\right] \\leq \\mathsf {n e g l} (\\lambda)</span></div>

    <p class="text-gray-300">A commitment scheme can optionally satisfy the following property,</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Linearly Homomorphic: Suppose the input space  <span class="math">\\mathcal{M}</span>  and output space  <span class="math">\\mathcal{C}</span>  are vector spaces over a field  <span class="math">\\mathbb{F}</span> , then the commitment scheme is linearly homomorphic if  <span class="math">\\operatorname{Commit}(\\mathsf{ck}, \\cdot): \\mathcal{M} \\to \\mathcal{C}</span>  is a linear map, for any  <span class="math">\\mathsf{ck}</span>  produced by  <span class="math">\\operatorname{Setup}_{\\mathsf{com}}(1^{\\lambda})</span> .</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- Succinct: For any  <span class="math">m \\in \\mathcal{M}</span> , the commitment  <span class="math">c \\gets \\operatorname{Commit}(\\mathsf{ck}, m)</span>  must have size  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">c</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq \\mathsf{poly}(\\lambda)<span class="math"> , independent of  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">m</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The following technical lemma will be used in proving soundness of our NARKs. The lemma says that an expected PPT adversary cannot find a non-zero polynomial  <span class="math">p \\in \\mathbb{F}^{\\leq d}[X_1, \\ldots, X_m]</span>  such that the random oracle applied to a commitment to  <span class="math">p</span>  gives a root of  <span class="math">p</span> .</p>

    <p class="text-gray-300">Lemma 2 (Zero Finding Game [BCL <span class="math">^{+}</span> 21, BCMS20b, CCS22]). Let  <span class="math">(\\mathsf{Setup}_{\\mathsf{com}}, \\mathsf{Commit})</span>  be a binding commitment scheme for a message space  <span class="math">\\mathcal{M}</span> . Further, fix a number of variables  <span class="math">t \\in \\mathbb{N}</span>  and degree bound  <span class="math">d \\in \\mathbb{N}</span> . Then, for every function  <span class="math">f: \\mathcal{M} \\to \\mathbb{F}^{\\leq d}[X_1, \\ldots, X_t]</span> , and for every expected PPT algorithm  <span class="math">\\mathcal{A}</span>  that makes  <span class="math">Q</span>  queries to the random oracle, the following probabilistic statement holds,</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Pr \\left[ \\begin{array}{c c c} &amp; &amp; \\mathsf {r o} \\leftarrow \\mathcal {O} (\\lambda) \\\\ &amp; &amp; \\mathsf {c k} \\leftarrow \\mathsf {C o m m i t} (1 ^ {\\lambda}) \\\\ p \\neq 0 &amp; &amp; m \\leftarrow \\mathcal {A} ^ {\\mathsf {r o}} (\\mathsf {c k}) \\\\ \\wedge &amp; : &amp; \\overline {{m}} \\leftarrow \\mathsf {C o m m i t} (\\mathsf {c k}, m) \\\\ p (r) = 0 &amp; &amp; r \\leftarrow \\mathsf {r o} (\\overline {{m}}) \\in \\mathbb {F} ^ {t} \\\\ &amp; &amp; p \\leftarrow f (m) \\in \\mathbb {F} ^ {\\leq d} [ X _ {1}, \\ldots , X _ {t} ] \\end{array} \\right] \\leq \\sqrt {(Q + 1) \\cdot \\frac {t d}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}} + \\mathsf {n e g l} (\\lambda)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">Merkle commitments. The Merkle Commitment Scheme [Mer90] provides a way to commit to a vector of messages, so that can later provably open a subset of messages in the vector. A Merkle Tree is a tree of hash values where the leaves are the messages in the vector and every intermediate node is the hash of its children. The Merkle commitment is the root of the Merkle tree. Here we define the Merkle commitment scheme with an arbitrary arity parameter  <span class="math">k</span> , which defines the arity of the Merkle tree.</p>

    <p class="text-gray-300">Definition 8 (Merkle Commitment Scheme). Let  <span class="math">\\mathcal{M} \\subseteq \\{0,1\\}^{\\ell(\\lambda)}</span>  be a message space. Further, let  <span class="math">k \\in \\mathbb{N}</span>  be an arity parameter. Given a collision resistant hash function  <span class="math">(\\text{Setup}_H, H)</span> , a Merkle commitment scheme is a tuple of PPT algorithms (MT.Commit, MT.Open, MT.Verify) with the following interface:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>MT.Commit <span class="math">_k</span>  ( <span class="math">\\mathsf{pp}_H, m) \\to c</span> : Given public parameters  <span class="math">\\mathsf{pp}_H</span>  and a vector  <span class="math">m \\in \\mathcal{M}^n</span> , outputs a merkle commitment  <span class="math">h \\in \\{0,1\\}^\\lambda</span> .</li>

      <li>MT.Open <span class="math">_k</span>  ( <span class="math">\\mathsf{pp}_H, \\mathcal{Q}, m) \\to \\pi_{\\mathsf{MT}}</span> : Given public parameters  <span class="math">\\mathsf{pp}_H</span> , a subset of indices  <span class="math">Q \\subseteq [n]</span> , a vector  <span class="math">m \\in \\mathcal{M}^n</span> , outputs a merkle proof  <span class="math">\\pi_{\\mathsf{MT}}</span> .</li>

      <li>MT.Verify <span class="math">_k</span>  ( <span class="math">\\mathsf{pp}_H, c, \\mathcal{Q}, \\{m_i\\}_{i \\in \\mathcal{Q}}, \\pi_{\\mathsf{MT}}</span> ) →  <span class="math">\\{0,1\\}</span> : Given public parameters  <span class="math">\\mathsf{pp}_H</span> , a subset of indices  <span class="math">\\mathcal{Q} \\subseteq [n]</span> , claimed openings  <span class="math">\\{m_i \\in \\mathcal{M}\\}_{i \\in \\mathcal{Q}}</span>  and a merkle proof  <span class="math">\\pi_{\\mathsf{MT}}</span> , outputs accept or reject.</li>

    </ul>

    <p class="text-gray-300">A Merkle commitment scheme satisfies the following properties:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Correctness: For all  <span class="math">\\mathsf{pp}_H \\in \\mathsf{Setup}_H(1^\\lambda)</span> ,  <span class="math">m \\in \\mathcal{M}^n</span> , and  <span class="math">\\mathcal{Q} \\subseteq [n]</span></li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} &amp;amp; \\mathsf {p p} _ {\\mathsf {H}} \\leftarrow \\mathsf {S e t u p} _ {\\mathsf {H}} (1 ^ {\\lambda}) \\\\ \\mathsf {M T . V e r i f y} (\\mathsf {p p} _ {\\mathsf {H}}, c, \\mathcal {Q}, \\{m _ {i} \\} _ {i \\in \\mathcal {Q}}, \\pi_ {\\mathsf {M T}}) = 1: &amp;amp; c \\leftarrow \\mathsf {M T . C o m m i t} (\\mathsf {p p} _ {\\mathsf {H}}, m) \\\\ &amp;amp; \\pi_ {\\mathsf {M T}} \\leftarrow \\mathsf {M T . O p e n} (\\mathsf {p p} _ {\\mathsf {H}}, \\mathcal {Q}, m) \\end{array} \\right] = 1</span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Binding: The pair  <span class="math">(\\mathsf{Setup}_{\\mathsf{H}}, \\mathsf{MT}.\\mathsf{Commit})</span>  is a binding commitment scheme for the message space  <span class="math">\\mathcal{M}^n</span> .</li>

      <li>Positional Binding: With respect to an auxiliary input distribution  <span class="math">\\mathcal{D}</span> , for every expected PPT  <span class="math">\\mathcal{A}</span></li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} \\mathsf {M T . V e r i f y} (\\mathsf {p p} _ {\\mathsf {H}}, c, \\mathcal {Q}, \\{m _ {i} \\} _ {i \\in \\mathcal {Q}}, \\pi_ {\\mathsf {M T}}) = 1 \\wedge &amp;amp; \\mathsf {p p} _ {\\mathsf {H}} \\leftarrow \\mathsf {S e t u p} _ {\\mathsf {H}} (1 ^ {\\lambda}) \\\\ \\mathsf {M T . V e r i f y} (\\mathsf {p p} _ {\\mathsf {H}}, c, \\mathcal {Q} ^ {\\prime}, \\{m _ {i} ^ {\\prime} \\} _ {i \\in \\mathcal {Q} ^ {\\prime}}, \\pi_ {\\mathsf {M T}} ^ {\\prime}) = 1 \\wedge : &amp;amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (\\mathsf {p p} _ {\\mathsf {H}}) \\\\ \\exists i \\in \\mathcal {Q} \\cap \\mathcal {Q} ^ {\\prime}, m _ {i} \\neq m _ {i} ^ {\\prime} &amp;amp; (c, \\mathcal {Q}, \\mathcal {Q} ^ {\\prime}, \\{m _ {i} \\} _ {i \\in \\mathcal {Q}}, \\{m _ {i} ^ {\\prime} \\} _ {i \\in \\mathcal {Q} ^ {\\prime}}, \\\\ &amp;amp; \\pi_ {\\mathsf {M T}}, \\pi_ {\\mathsf {M T}} ^ {\\prime}) \\leftarrow \\mathcal {A} (\\mathsf {p p} _ {\\mathsf {H}}, \\mathsf {a i}) \\end{array} \\right] \\leq \\mathsf {n e g l} (\\lambda).</span></div>

    <p class="text-gray-300">Folding Schemes We next define a generalization of folding schemes [BCL+21, KST22]. Let  <span class="math">n = \\mathrm{poly}(\\lambda)</span>  be polynomial.</p>

    <p class="text-gray-300">Definition 9 (Folding Scheme). A Folding Scheme in the random oracle model for a family of relations  <span class="math">\\{R_{\\mathrm{fpp}}\\}_{\\mathrm{fpp}}</span>  is a tuple of PPT algorithms  <span class="math">\\mathsf{Fold} := (\\mathcal{G}_{\\mathsf{Fold}}, \\mathcal{P}_{\\mathsf{Fold}}, \\mathcal{V}_{\\mathsf{Fold}})</span>  with the following interface:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{G}_{\\mathrm{Fold}}(1^{\\lambda}) \\to \\mathrm{fpp}</span> : Given security parameter, outputs public parameters  <span class="math">\\mathrm{fpp} := (\\mathrm{fpk}, \\mathrm{fvk})</span> , which consists of a proving key  <span class="math">\\mathrm{fpk}</span>  and verification key  <span class="math">\\mathrm{fvk}</span> .</li>

      <li><span class="math">\\mathcal{P}_{\\mathrm{Fold}}^{\\mathrm{ro}}(\\mathrm{fpk},(x_i,w_i)_{i = 1}^n)\\to (x,w,\\mathrm{pf})</span>  : Given a folding prover key fpk and  <span class="math">n</span>  instance-witness pairs  <span class="math">(x_{i},w_{i})_{i = 1}^{n}</span>  outputs a new instance-witness pair  <span class="math">(x_{i},w_{i})</span>  , and folding proof pf.</li>

      <li><span class="math">\\mathcal{V}_{\\mathrm{Fold}}^{\\mathrm{ro}}(\\mathrm{fvk},(x_i)_{i = 1}^n,x,\\mathrm{pf})\\to \\{0,1\\}</span> : Given a folding verifier key fvk,  <span class="math">n</span>  instances  <span class="math">[x_i)_{i = 1}^n</span> , and a folding proof pf, outputs accept or reject.</li>

    </ul>

    <p class="text-gray-300">Define the  <span class="math">n</span> -composition of  <span class="math">\\{R_{\\mathrm{fpp}}\\}_{\\mathrm{fpp}}</span>  as the family of relations  <span class="math">\\{R_{\\mathrm{fpp}}^n\\}_{\\mathrm{fpp}}</span>  for</p>

    <div class="my-4 text-center"><span class="math-block">R _ {\\mathrm {f p p}} ^ {n} := \\left\\{\\left(\\left(x _ {i}\\right) _ {i = 1} ^ {n}, \\left(w _ {i}\\right) _ {i = 1} ^ {n}\\right) \\mid \\forall i \\in [ n ], \\left(x _ {i}, w _ {i}\\right) \\in R _ {\\mathrm {f p p}} \\right\\}</span></div>

    <p class="text-gray-300">A folding scheme Fold is secure if the following properties hold:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Correctness: For all  <span class="math">\\mathsf{fpp} \\in \\mathcal{G}_{\\mathsf{Fold}}(1^{\\lambda})</span>  and  <span class="math">(x_i, w_i)_{i=1}^n \\in R_{\\mathsf{fpp}}^n</span> ,</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} \\mathcal {V} _ {\\mathsf {F o l d}} ^ {\\mathsf {r o}} (\\mathsf {f k}, (x _ {i}) _ {i = 1} ^ {n}, x, \\mathsf {p f}) = 1 &amp;amp; : \\quad \\mathsf {r o} \\leftarrow \\mathcal {O} (\\lambda) \\\\ \\wedge (x, w) \\in R _ {\\mathsf {f p p}} &amp;amp; : \\quad (x, w, \\mathsf {p f}) \\leftarrow \\mathcal {P} _ {\\mathsf {F o l d}} ^ {\\mathsf {r o}} (\\mathsf {f p k}, (x _ {i}, w _ {i}) _ {i = 1} ^ {n}) \\end{array} \\right] = 1</span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Knowledge Soundness: With respect to an auxiliary input distribution  <span class="math">\\mathcal{D}</span> , a folding scheme Fold is knowledge sound with knowledge error  <span class="math">\\kappa : \\mathbb{N} \\times \\mathbb{N} \\to [0,1]</span>  if for every expected PPT adversary  <span class="math">\\tilde{\\mathcal{P}}</span>  who makes at most a polynomial  <span class="math">Q</span>  queries to ro, there exists a positive polynomial  <span class="math">q</span>  and an expected PPT extractor  <span class="math">\\mathcal{E}</span>  such that for every predicate  <span class="math">\\rho</span> ,</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\Pr \\left[ \\begin{array}{c c} &amp; \\mathsf {r o} \\leftarrow \\mathcal {O} (\\lambda) \\\\ \\rho \\big (\\mathsf {f p p}, \\mathsf {a i}, \\mathsf {a o}, (x _ {i}) _ {i = 1} ^ {n} \\big) = 1 &amp; \\mathsf {f p p} \\leftarrow \\mathcal {G} _ {\\mathsf {F o l d}} (1 ^ {\\lambda}) \\\\ \\wedge ((x _ {i}) _ {i = 1} ^ {n}, (w _ {i}) _ {i = 1} ^ {n}) \\in R _ {\\mathsf {f p p}} ^ {n} &amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (\\mathsf {f p p}) \\\\ &amp; ((x _ {i}, w _ {i}) _ {i = 1} ^ {n}, \\mathsf {a o}) \\leftarrow \\mathcal {E} _ {\\tilde {\\mathcal {P}}} ^ {\\mathsf {r o}} (\\mathsf {p p}, \\mathsf {a i}) \\end{array} \\right] \\geq \\frac {\\epsilon (\\tilde {\\mathcal {P}}) - \\kappa (</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">, Q)}{q (</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)}</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">where  <span class="math">\\epsilon (\\tilde{\\mathcal{P}})</span>  is the following probability:</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} &amp;amp; \\mathsf {r o} \\leftarrow \\mathcal {O} (\\lambda) \\\\ \\rho \\big (\\mathsf {f p p}, \\mathsf {a i}, \\mathsf {a o}, (x _ {i}) _ {i = 1} ^ {n} \\big) = 1 &amp;amp; \\mathsf {f p p} \\leftarrow \\mathcal {G} _ {\\mathsf {F o l d}} (1 ^ {\\lambda}) \\\\ \\wedge \\mathcal {V} _ {\\mathsf {F o l d}} ^ {\\mathsf {r o}} (\\mathsf {f k}, (x _ {i}) _ {i = 1} ^ {n}, x, \\mathsf {p f}) = 1 &amp;amp; : \\quad \\mathsf {a i} \\leftarrow \\mathcal {D} (\\mathsf {f p p}) \\\\ \\wedge (x, w) \\in R _ {\\mathsf {f p p}} &amp;amp; ((x _ {i}) _ {i = 1} ^ {n}, x, w, \\mathsf {p f}, \\mathsf {a o}) \\leftarrow \\tilde {\\mathcal {P}} ^ {\\mathsf {r o}} (\\mathsf {f p p}, \\mathsf {a i}) \\end{array} \\right]</span></div>

    <p class="text-gray-300">And, the runtime of  <span class="math">\\mathcal{E}_{\\tilde{\\mathcal{P}}}</span>  is at most a polynomial in the runtime of  <span class="math">\\tilde{\\mathcal{P}}</span> .</p>

    <p class="text-gray-300">Remark 2. Definition 9 is stated for the random oracle model, but one can obtain the definition for a folding scheme in the standard model by trivially omitting the random oracle from the definition.</p>

    <p class="text-gray-300">Proof Carrying Data Next, we review the concept of proof carrying data or PCD [BCL+21, BDFG21, CCG+23, CT10, BCCT13, COS20]. Informally, PCD allows for a potentially distributed set of provers to jointly prove the outcome of a structured graph of computation (MapReduce, distributed computations, and more). In particular, every intermediate prover in the graph produces a proof that the output of the computation at that node is correct. This proof is then used by the next prover in the graph to produce a proof of correctness for the next node in the graph, and so on.</p>

    <p class="text-gray-300">More specifically, consider a finite directed acyclic graph  <span class="math">\\mathsf{T}</span>  where every node  <span class="math">v</span>  in the graph corresponds to a prover  <span class="math">\\mathcal{P}_v</span> . Suppose a node  <span class="math">v</span>  has  <span class="math">k</span>  incoming edges that are labeled with data  <span class="math">z^{(e_1)}, \\ldots, z^{(e_k)}</span> . Every outgoing edge from node  <span class="math">v</span>  is labeled with data  <span class="math">z^{(e)}</span>  and the node itself is labeled with some local data loc. We say that the output  <span class="math">z^{(e)}</span>  is  <span class="math">\\varphi</span> -compliant at node  <span class="math">v</span>  if the tuple  <span class="math">(z^{(e)}, \\mathsf{loc}, z^{(e_1)}, \\ldots, z^{(e_k)})</span>  satisfies some compliance predicate  <span class="math">\\varphi</span> . The prover  <span class="math">\\mathcal{P}_v</span>  takes as input  <span class="math">k</span>  pairs  <span class="math">(z^{(e_i)}, \\pi_i)</span>  for  <span class="math">i = 1, \\ldots, k</span>  along with the local data loc and the output data  <span class="math">z^{(e)}</span> . The prover outputs a proof  <span class="math">\\pi</span>  that shows that (i) for all  <span class="math">i \\in [k]</span> , the incoming proof  <span class="math">\\pi_i</span>  is a valid proof that  <span class="math">z^{(e_i)}</span>  is  <span class="math">\\varphi</span> -compliant at the predecessor node, and (ii)  <span class="math">z^{(e)}</span>  is  <span class="math">\\varphi</span> -compliant at node  <span class="math">v</span> . The PCD provers operate one after the other in a topological sort ordering of the</p>

    <p class="text-gray-300">graph. When this process completes, the output of every sink node in the graph is accompanied with a proof that shows that at every intermediate node the output is  <span class="math">\\varphi</span> -compliant at that node. What follows is a formal description of Proof Carrying Data (PCD) and a PCD scheme.</p>

    <p class="text-gray-300">Definition 10 (Data Graph). A data graph  <span class="math">\\mathsf{T}</span>  is a directed acyclic graph where each vertex  <span class="math">u\\in V(\\mathsf{T})</span>  is labeled by local data  <span class="math">\\mathsf{loc}^{(u)}\\in \\mathcal{L}</span>  and each edge  <span class="math">e\\in E(\\mathsf{T})</span>  is labeled by a message  <span class="math">z^{(e)}\\in \\mathcal{Z}</span> . The output of a data graph  <span class="math">\\mathsf{T}</span> , denoted  <span class="math">\\mathsf{o}(\\mathsf{T})</span> , is  <span class="math">z^{(e)}</span>  where  <span class="math">e = (u,v)</span>  is the lexicographically-first edge such that  <span class="math">v</span>  is a sink.</p>

    <p class="text-gray-300">Definition 11 (Compliance). We denote by  <span class="math">\\mathsf{F}</span>  a class of compliance predicates  <span class="math">\\varphi : \\mathcal{Z} \\times \\mathcal{L} \\times \\mathcal{Z}^m \\to \\{0,1\\}</span> . A vertex  <span class="math">u \\in V(\\mathsf{T})</span>  is  <span class="math">\\varphi</span> -compliant for  <span class="math">\\varphi \\in \\mathsf{F}</span>  if for all outgoing edges  <span class="math">e = (u,v) \\in E(\\mathsf{T})</span>  either:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>(base case)  <span class="math">u</span>  has no incoming edges;</li>

      <li>(recursive case)  <span class="math">u</span>  has incoming edges  <span class="math">e_1, \\ldots, e_m</span>  such that  <span class="math">\\varphi(z^{(e)}, \\mathsf{loc}^{(u)}, z^{(e_1)}, \\ldots, z^{(e_k)})</span>  accepts.</li>

    </ul>

    <p class="text-gray-300">A data graph  <span class="math">\\mathsf{T}</span>  is  <span class="math">\\varphi</span> -compliant if all of its vertices are  <span class="math">\\varphi</span> -compliant.</p>

    <p class="text-gray-300">Definition 12 (Proof Carrying Data Scheme ([BCL <span class="math">^{+}</span> 21, BCMS20b])). Fix a message space  <span class="math">\\mathcal{Z}</span>  with a predicate isBase:  <span class="math">\\mathcal{Z} \\to \\{0,1\\}</span>  and local data space  <span class="math">\\mathcal{L}</span> . A proof-carrying data scheme for a class of compliance predicates  <span class="math">\\mathsf{F}</span>  is a tuple of PPT algorithms  <span class="math">\\mathsf{pcd} := (\\mathcal{G}_{\\mathsf{pcd}}, \\mathcal{I}_{\\mathsf{pcd}}, \\mathcal{P}_{\\mathsf{pcd}}, \\mathcal{V}_{\\mathsf{pcd}})</span>  with the following interface:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{G}_{\\mathrm{pcd}}(1^{\\lambda}) \\to \\mathsf{pp}_{\\mathrm{pcd}}</span> : Given security parameter  <span class="math">1^{\\lambda}</span> , outputs public parameters  <span class="math">\\mathsf{pp}_{\\mathrm{pcd}}</span> .</li>

      <li><span class="math">\\mathcal{I}_{\\mathrm{pcd}}(\\mathsf{pp}_{\\mathrm{pcd}},\\varphi)\\to (\\mathsf{pk}_{\\mathrm{pcd}},\\mathsf{vk}_{\\mathrm{pcd}})</span> : Given public parameters  <span class="math">\\mathsf{pp}_{\\mathrm{pcd}}</span>  and compliance predicate  <span class="math">\\varphi \\in \\mathsf{F}</span> , outputs a proving key  <span class="math">\\mathsf{pk}_{\\mathrm{pcd}}</span>  and verification key  <span class="math">\\mathsf{vk}_{\\mathrm{pcd}}</span> .</li>

      <li><span class="math">\\mathcal{P}_{\\mathrm{pcd}}(\\mathsf{pk}_{\\mathrm{pcd}}, Z, \\mathsf{loc}, [(Z_i, \\pi_i)]_{i=1}^k) \\to \\pi</span> : Given a proving key  <span class="math">\\mathsf{pk}_{\\mathrm{pcd}}</span> , message  <span class="math">Z \\in \\mathcal{Z}</span> , local data  <span class="math">\\mathsf{loc} \\in \\mathcal{L}</span> , a collection of  <span class="math">m</span>  message-proof pairs  <span class="math">[(Z_i, \\pi_i)]_{i=1}^k</span> , outputs a proof  <span class="math">\\pi</span> .</li>

      <li><span class="math">\\mathcal{V}_{\\mathrm{pcd}}(\\mathsf{vk}_{\\mathrm{pcd}}, Z, \\pi) \\to 0/1</span> : Given a verification key  <span class="math">\\mathsf{vk}_{\\mathrm{pcd}}</span> , message  <span class="math">z \\in \\mathcal{Z}</span> , and a proof  <span class="math">\\pi</span> , outputs accept or reject.</li>

    </ul>

    <p class="text-gray-300">A proof-carrying data scheme pcd is secure if the following properties hold:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Completeness: For every  <span class="math">\\varphi \\in \\mathsf{F}</span> ,  <span class="math">\\mathsf{pp}_{\\mathsf{pcd}} \\in \\mathcal{G}_{\\mathsf{pcd}}(1^{\\lambda})</span> , and collection of elements  <span class="math">(Z, \\mathsf{loc}, [(Z_i, \\pi_i)]_{i=1}^k)</span>  such that  <span class="math">\\varphi(Z, \\mathsf{loc}, Z_1, \\ldots, Z_k) = 1</span> ,</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} \\left( \\begin{array}{c c} \\forall i \\in [ k ], \\text {i s B a s e} (Z _ {i}) = 1 &amp;amp; \\vee \\\\ \\forall i \\in [ m ], \\mathcal {V} _ {\\mathsf {p c d}} (\\mathsf {v k} _ {\\mathsf {p c d}}, Z _ {i}, \\pi_ {i}) = 1 \\end{array} \\right) &amp;amp; : \\begin{array}{c} (\\mathsf {p k} _ {\\mathsf {p c d}}, \\mathsf {v k} _ {\\mathsf {p c d}}) \\leftarrow \\mathcal {I} _ {\\mathsf {p c d}} (\\mathsf {p p}, \\varphi) \\\\ \\Downarrow &amp;amp; \\pi \\leftarrow \\mathcal {P} _ {\\mathsf {p c d}} (\\mathsf {p k} _ {\\mathsf {p c d}}, Z, \\mathsf {l o c}, [ (Z _ {i}, \\pi_ {i}) ] _ {i = 1} ^ {k}) \\\\ \\mathcal {V} _ {\\mathsf {p c d}} (\\mathsf {v k} _ {\\mathsf {p c d}}, Z, \\pi) = 1 \\end{array} \\right) = 1</span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Knowledge soundness: With respect to auxiliary input distribution  <span class="math">\\mathcal{D}</span> , a proof-carrying data scheme  <span class="math">\\mathsf{pcd}</span>  is knowledge sound if for every expected PPT adversary  <span class="math">\\hat{\\mathcal{P}}</span> , there exists an expected PPT extractor</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\mathcal{E}_{\\tilde{\\mathcal{P}}}</span>  such that for every distinguishing predicate  <span class="math">\\rho</span></p>

    <div class="my-4 text-center"><span class="math-block">\\begin{array}{l} \\Pr \\left[ \\begin{array}{c c} \\varphi \\in \\mathsf {F} \\wedge &amp;amp; \\mathsf {p p} _ {\\mathsf {p c d}} \\leftarrow \\mathcal {G} _ {\\mathsf {p c d}} (1 ^ {\\lambda}) \\\\ \\rho \\big (\\mathsf {p p} _ {\\mathsf {p c d}}, \\mathsf {a i}, \\mathsf {a o}, \\varphi , \\mathsf {o} (\\mathsf {T}) \\big) = 1 \\wedge : &amp;amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (\\mathsf {p p} _ {\\mathsf {p c d}}) \\\\ \\mathsf {T} \\text {i s} \\varphi \\text {- c o m p l i a n t} &amp;amp; (\\varphi , \\mathsf {T}, \\mathsf {a o}) \\leftarrow \\mathcal {E} _ {\\tilde {\\mathcal {P}}} (\\mathsf {p p} _ {\\mathsf {p c d}}, \\mathsf {a i}) \\end{array} \\right] \\\\ \\geq \\Pr \\left[ \\begin{array}{c c} \\varphi \\in \\mathsf {F} \\wedge &amp;amp; \\mathsf {p p} _ {\\mathsf {p c d}} \\leftarrow \\mathcal {G} _ {\\mathsf {p c d}} (1 ^ {\\lambda}) \\\\ \\rho \\big (\\mathsf {p p} _ {\\mathsf {p c d}}, \\mathsf {a i}, \\mathsf {a o}, \\varphi , \\mathsf {Z} \\big) = 1 \\wedge : &amp;amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (\\mathsf {p p} _ {\\mathsf {p c d}}) \\\\ \\mathcal {V} _ {\\mathsf {p c d}} (\\mathsf {v k} _ {\\mathsf {p c d}}, \\mathsf {Z}, \\pi) = 1 &amp;amp; (\\varphi , \\mathsf {Z}, \\pi , \\mathsf {a o}) \\leftarrow \\hat {\\mathcal {P}} (\\mathsf {p p}, \\mathsf {a i}) \\\\ &amp;amp; (\\cdot , \\mathsf {v k} _ {\\mathsf {p c d}}) \\leftarrow \\mathcal {I} _ {\\mathsf {p c d}} (\\mathsf {p p} _ {\\mathsf {p c d}}, \\varphi) \\end{array} \\right] - \\mathsf {n e g l} (\\lambda) \\\\ \\end{array}</span></div>

    <p class="text-gray-300">And, the runtime of  <span class="math">\\mathcal{E}_{\\tilde{\\mathcal{P}}}</span>  is at most a polynomial in the runtime of  <span class="math">\\tilde{\\mathcal{P}}</span> .</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- Efficiency: Every proof  <span class="math">\\pi</span>  has size  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\pi</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq \\mathrm{poly}(\\lambda,</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\varphi</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math"> . The size must be independent of the number of applications of  </span>\\mathcal{P}_{\\mathrm{pcd}}$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Remark 3 (Differences from PCD in  <span class="math">[BCL^{+}21])</span> . The definition of a PCD scheme in  <span class="math">[BCL^{+}21]</span>  is similar to the one we have presented here, but there are some key differences to the message space  <span class="math">\\mathcal{Z}</span>  and  <span class="math">\\varphi</span> -compliance.  <span class="math">[BCL^{+}21]</span>  implicitly requires that the message space  <span class="math">\\mathcal{Z}</span>  has a special symbol  <span class="math">\\perp</span>  that acts as a base case message. Their definition and construction (Sec 5.1) requires checking if edge values  <span class="math">Z_{i} = \\perp</span>  or  <span class="math">Z_{i} \\neq \\perp</span> . We formalize this by introducing a predicate isBase:  <span class="math">\\mathcal{Z} \\to \\{0,1\\}</span> , which labels whether a message is a base case value or not. By not requiring  <span class="math">\\mathcal{Z}</span>  to have a special symbol  <span class="math">\\perp</span>  and replacing  <span class="math">Z_{i} = \\perp</span>  and  <span class="math">Z_{i} \\neq \\perp</span>  with isBase  <span class="math">(Z_{i}) = 1</span>  and isBase  <span class="math">(Z_{i}) = 0</span>  respectively, we can directly recover a PCD scheme that satisfies our definition of PCD from the construction in  <span class="math">[BCL^{+}21]</span> . This allows for a more flexible notion of a base case message.</p>

    <p class="text-gray-300">Definition 13 (Tree Evaluation Problem). Consider an arbitrary space  <span class="math">\\mathcal{M}</span>  and a function  <span class="math">J: \\mathcal{M}^k \\to \\mathcal{M}</span> . Consider a  <span class="math">k</span> -ary tree with nodes labeled with values in  <span class="math">\\mathcal{M}</span>  such that every parent node with children  <span class="math">(m_1, \\ldots, m_k)</span>  is labeled with  <span class="math">J(m_1, \\ldots, m_k)</span> . The tree evaluation problem is to compute the root value of the tree given streaming access to the sequence of leaf values.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Theorem 1 (Tree Evaluation Algorithm). Let  <span class="math">k \\in \\mathbb{N}</span>  and  <span class="math">n \\in \\mathbb{N}</span>  be a power of  <span class="math">k</span> . Consider an arbitrary space  <span class="math">\\mathcal{M}</span>  and a function  <span class="math">J: \\mathcal{M}^k \\to \\mathcal{M}</span> . Let us consider the tree evaluation problem Definition 13 for  <span class="math">J</span>  over  <span class="math">\\mathcal{M}</span> , where the sequence of  <span class="math">n</span>  leaves is  <span class="math">(m_i)_{i=1}^n</span> . There exists a streaming algorithm TreeEval  <span class="math">(J, S(m))</span> , given streaming access to the sequence, that solves the tree evaluation problem with  $O(\\log_k(n) \\cdot k \\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">m</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">J</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">  space complexity and makes  </span>O(n/k)<span class="math">  calls to  </span>J<span class="math"> , where  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">m</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  and  </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">J</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">  are the space complexity of an element  </span>m \\in \\mathcal{M}<span class="math">  and the function  </span>J$  respectively.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Proof Sketch. This folklore pebbling algorithm [PTC76] can be directly recovered from the binary tree algorithm in Gemini [BCHO22] but now for the  <span class="math">k</span> -ary case.  <span class="math">\\square</span></p>

    <p class="text-gray-300">Lemma 3 ((Set Inclusion) Lemma 5 of [Hab22]). Let  <span class="math">\\mathbb{F}</span>  be a field with  <span class="math">\\mathrm{char}(\\mathbb{F}) &amp;gt; \\max (\\ell ,T)</span> . Suppose  <span class="math">(a_{i})_{i = 1}^{\\ell}</span>  and  <span class="math">(b_{i})_{i = 1}^{T}</span>  are sequences of elements in  <span class="math">\\mathbb{F}</span> . Then,  <span class="math">\\{a_i\\}_{i = 1}^{\\ell}\\subseteq \\{b_i\\}_{i = 1}^{T}</span>  if and only if there exists a</p>

    <p class="text-gray-300">sequence of field elements <span class="math">(m_{i})_{i=1}^{T}</span> such that</p>

    <p class="text-gray-300"><span class="math">\\sum_{i=1}^{\\ell}\\frac{1}{X-a_{i}}=\\sum_{i=1}^{T}\\frac{m_{i}}{X-b_{i}}</span></p>

    <h6 id="sec-17" class="text-base font-medium mt-4">Lemma 4 (Claim A.1 <em>[x10]</em>).</h6>

    <p class="text-gray-300">Consider vectors <span class="math">z,\\sigma\\in\\mathbb{F}^{n}</span>. Then, the following statements are equivalent:</p>

    <p class="text-gray-300"><span class="math">\\{(i,z_{i})\\}_{i=1}^{n}=\\{(\\sigma_{i},z_{i})\\}_{i=1}^{n}\\quad\\text{ if and only if }\\quad\\prod_{i=1}^{n}(z_{i}+i\\cdot Y+X)=\\prod_{i=1}^{n}(z_{i}+\\sigma_{i}\\cdot Y+X)</span></p>

    <h6 id="sec-18" class="text-base font-medium mt-4">Definition 14 (Polynomial Maps).</h6>

    <p class="text-gray-300">Let <span class="math">m,n,d\\in\\mathbb{N}</span> and <span class="math">\\mathbb{F}</span> be a field. A polynomial map of degree <span class="math">d</span> is a map <span class="math">f:\\mathbb{F}^{m}\\to\\mathbb{F}^{n}</span> that can be expressed as</p>

    <p class="text-gray-300"><span class="math">f(\\mathbf{X})\\vcentcolon=\\Big{(}f^{(1)}(\\mathbf{X}),\\ f^{(2)}(\\mathbf{X}),\\ \\ldots,\\ f^{(n)}(\\mathbf{X})\\Big{)}</span></p>

    <p class="text-gray-300">where for all <span class="math">i\\in[n]</span>, <span class="math">f^{(i)}(\\mathbf{X})\\in\\mathbb{F}[X_{1},\\ldots,X_{m}]</span> is a multivariate polynomial in <span class="math">m</span> variables with <span class="math">\\deg(f^{(i)})\\leq d</span>.</p>

    <p class="text-gray-300">A polynomial map is homogeneous if all the polynomials <span class="math">f^{(1)}(\\mathbf{X}),\\ldots,f^{(n)}(\\mathbf{X})</span> are homogeneous polynomials of the same degree.</p>

    <p class="text-gray-300">Given an arbitrary polynomial map <span class="math">f:\\mathbb{F}^{m}\\to\\mathbb{F}^{n}</span> of degree <span class="math">d</span>, we define the j-th degree homogeneous component <span class="math">f_{j}(\\mathbf{X})</span> as the homogeneous map of degree <span class="math">j</span> consisting exactly of the monomials of degree <span class="math">j</span> in <span class="math">f(\\mathbf{X})</span>. In particular, we can express the map <span class="math">f(\\mathbf{X})=\\sum_{j=0}^{d}f_{j}(\\mathbf{X})</span>.</p>

    <h2 id="sec-19" class="text-2xl font-bold">4 Generalization of Folding Schemes</h2>

    <p class="text-gray-300">In this section, we develop a generalization of folding and accumulation schemes <em>[x17, x3, BCL^{+}21, x16, x18, x19]</em> that not only captures most prior schemes, but allows for a commit-and-prove style of relation. We begin by defining the notion of a polynomial opening relation, which is a relation that is readily amenable to folding and sufficient for our SNARK construction. We then show a general transformation from non-homogeneous to homogeneous polynomial maps, which will enable us to fold relations with non-homogeneous polynomial maps, by first compiling them into homogeneous polynomial maps. This will be useful for our first folding scheme (Definition 17), which is restricted to homogeneous polynomial maps. However, looking ahead, our second folding scheme (Protocol 2) directly handles arbitrary polynomial maps without the need for this transformation. Next, we introduce the concept of <em>witness testing</em> for polynomial relations, which lets one test if a witness satisfies certain properties. This will be needed in the SNARK construction. Next, we introduce our two concrete folding schemes, which fold pairs of the polynomial opening relation. Finally, we conclude with a discussion on the heuristic security of our folding schemes in the standard model, when instantiated with a concrete hash function.</p>

    <h3 id="sec-20" class="text-xl font-semibold mt-8">4.1 Polynomial Relations</h3>

    <p class="text-gray-300">We begin by defining a generalization of the relations used in folding schemes. In Nova <em>[x17]</em>, they fold a family of relations called <em>relaxed R1CS</em>, which roughly corresponds to opening a witness commitment to see if a specific degree-2 polynomial map evaluates to an error vector <span class="math">e</span>, which is the opening of a</p>

    <p class="text-gray-300">o-called error commitment <span class="math">\\overline{e}</span>. In Protostar <em>[x1]</em>, they fold instances as committed transcripts of special-sound protocols, and the family of relations being folded corresponds to the high-degree polynomial map checked by the special-sound protocol verifiers. Both of these can be viewed as a special case of the following polynomial opening relation. Informally, a polynomial opening relation is a relation that allows one to check if a commitment to a witness <span class="math">x</span> is consistent with a commitment to the output <span class="math">f(x)</span> of a polynomial map <span class="math">f</span>. Here we choose to define the relation in terms of linear maps <span class="math">\\mathcal{L}_{\\mathrm{x}}</span> and <span class="math">\\mathcal{L}_{\\mathrm{e}}</span> that commit to the witness <span class="math">x</span> and the polynomial map output <span class="math">f(x)</span>, respectively. By considering arbitrary linear maps and polynomial maps, we capture a wide range of relations that are amenable to folding rather than restricting ourselves to committed special-sound transcripts or relaxed R1CS instances.</p>

    <h6 id="sec-21" class="text-base font-medium mt-4">Definition 15 (Polynomial Opening Relation).</h6>

    <p class="text-gray-300">Let <span class="math">m,n,d\\in\\mathbb{N}</span>, let <span class="math">\\mathbb{F}</span> be a field, and let <span class="math">\\mathbb{X},\\mathbb{E}</span> be vector spaces over <span class="math">\\mathbb{F}</span>. Further, let <span class="math">f:\\mathbb{F}^{m}\\to\\mathbb{F}^{n}</span> be a polynomial map of degree <span class="math">d</span>, <span class="math">\\mathcal{L}_{\\mathrm{x}}:\\mathbb{F}^{m}\\to\\mathbb{X}</span> and <span class="math">\\mathcal{L}_{\\mathrm{e}}:\\mathbb{F}^{n}\\to\\mathbb{E}</span> be linear maps. We define the following instance-witness relations <span class="math">\\mathcal{R}_{\\mathsf{open}}\\left(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f\\right)</span> and <span class="math">\\mathcal{R}_{\\mathsf{collision}}(\\mathcal{L}_{\\mathrm{x}})</span>:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math">\\mathcal{R}_{\\mathsf{open}}\\left(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f\\right)</span> $:=\\left\\{\\left(\\left(\\overline{x}\\in\\mathbb{X},\\,\\overline{e}\\in\\mathbb{E}\\right);\\,\\,x\\in\\mathbb{F}^{m}\\right)\\ \\ \\big{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\ \\ \\left(\\overline{x},\\,\\overline{e}\\right)=\\big{(}\\,\\mathcal{L}_{\\mathrm{x}}(x),\\,\\,\\mathcal{L}_{\\mathrm{e}}(f(x))\\,\\big{)}\\ \\right\\}$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">For any <span class="math">\\ell\\in\\mathbb{N}</span>, we define <span class="math">\\mathcal{R}_{\\mathsf{open}}^{\\ell}\\left(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f\\right)</span> as the set of tuples <span class="math">\\left(\\left(\\overline{x}_{i},\\overline{e}_{i}\\right);\\,x_{i}\\right)^{\\ell}_{i=1}</span> such that <span class="math">\\left(\\left(\\overline{x}_{i},\\overline{e}_{i}\\right);\\,x_{i}\\right)</span> is in <span class="math">\\mathcal{R}_{\\mathsf{open}}\\left(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f\\right)</span> for all <span class="math">i\\in[\\ell]</span>.</p>

    <h6 id="sec-22" class="text-base font-medium mt-4">Example 1.</h6>

    <p class="text-gray-300">In Nova <em>[x10]</em>, <span class="math">\\mathcal{L}_{\\mathrm{x}}(x)</span> is the Pedersen commitment to the witness <span class="math">x</span>, and <span class="math">\\mathcal{L}_{\\mathrm{e}}(f(x))</span> is the error commitment. Here <span class="math">f</span> is a degree-2 polynomial map related to R1CS. In <em>[x1]</em>, a commitment <span class="math">C</span> to a special-sound transcript <span class="math">T=(m_{1},r_{1},m_{2},r_{2},\\dots)</span> consists of individual commitments to each prover message <span class="math">m_{i\\,i}</span> and verifier challenges <span class="math">r_{i\\,i}</span>. The verifier receives the message commitment openings and accepts if these commitment openings are valid and that a polynomial map <span class="math">f(m_{i\\,i},r_{i\\,i})=0</span>. In our generalization, the commitment <span class="math">C</span> to the transcript <span class="math">T</span> can be viewed as the output of a linear map <span class="math">\\mathcal{L}_{\\mathrm{x}}</span> (i.e. <span class="math">C=\\mathcal{L}_{\\mathrm{x}}(T)</span>), which is simply the piece-wise composition of the individual message commitment algorithms. Our polynomial relation exactly checks that <span class="math">C=\\mathcal{L}_{\\mathrm{x}}(T)</span> and that <span class="math">f(T)=0</span>, when <span class="math">\\overline{e}</span> is a commitment to zero.</p>

    <p class="text-gray-300">The polynomial opening relation <span class="math">\\mathcal{R}_{\\mathsf{open}}^{\\ell}\\left(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f\\right)</span> from Definition 15 requires that the polynomial map <span class="math">f</span> is homogeneous. To handle non-homogeneous polynomial maps we define a transform that lets us convert a non-homogeneous polynomial map into a homogeneous one. The transform increases the arity of <span class="math">f</span> by one by introducing one auxiliary variable. The method is used implicitly in Nova <em>[x10]</em> to convert R1CS into relaxed R1CS. Protostar <em>[x1]</em> avoids the need for this transform by assuming that the verifier of a special-sound protocol is already homogeneous.</p>

    <h6 id="sec-23" class="text-base font-medium mt-4">Definition 16 (Homogeneous Transform).</h6>

    <p class="text-gray-300">Given a polynomial map <span class="math">f:\\mathbb{F}^{m}\\to\\mathbb{F}^{n}</span> of degree <span class="math">d</span>, define the following homogeneous polynomial map <span class="math">\\hat{f}:\\mathbb{F}^{m+1}\\to\\mathbb{F}^{n}</span> of degree <span class="math">d</span> such that <span class="math">f(x)=\\hat{f}(x,1)</span>. The transformation is:</p>

    <p class="text-gray-300"><span class="math">f(x)=\\sum_{j=0}^{d}f_{j}(x)\\quad\\mapsto\\quad\\hat{f}(x,\\mu):=\\sum_{j=0}^{d}\\mu^{d-j}f_{j}(x)</span></p>

    <p class="text-gray-300">where <span class="math">f_{j}(x)</span> is the <span class="math">j</span>-th degree homogeneous component of <span class="math">f(x)</span>.</p>

    <p class="text-gray-300">######</p>

    <p class="text-gray-300">!<a href="img-6.jpeg">img-6.jpeg</a> Fig. 6: Commutative Diagram for Polynomial Witness Testing</p>

    <p class="text-gray-300">Let  <span class="math">f: \\mathbb{F}^m \\to \\mathbb{F}^n</span>  be a homogeneous polynomial map. Given an instance  <span class="math">(\\overline{x}, \\overline{e})</span>  in the language of  <span class="math">\\mathcal{R}_{\\mathrm{open}}(\\mathcal{L}_{\\mathrm{x}}, \\mathcal{L}_{\\mathrm{e}}, f)</span> , it will be useful to test whether there exists a witness  <span class="math">x \\in \\mathbb{F}^m</span>  such that a subset of  <span class="math">b</span>  elements of  <span class="math">x</span>  is equal to some fixed  <span class="math">x&#x27; \\in \\mathbb{F}^b</span> . This will help us test that part of the extended witness is consistent with the public input of the SNARK statement. More generally, if  <span class="math">\\psi: \\mathbb{F}^m \\to \\mathbb{F}^b</span>  is a projection map, we would like to test that  <span class="math">\\psi(x) = x&#x27;</span> .</p>

    <p class="text-gray-300">Since we cannot do direct checks on a witness  <span class="math">x</span>  given only the instance  <span class="math">(\\overline{x},\\overline{e})</span>  in the language of  <span class="math">\\mathcal{R}_{\\mathrm{open}}</span> , we must check if certain elements of  <span class="math">\\overline{x} = \\mathcal{L}_{\\mathrm{x}}(x)</span>  have certain values. For example, if  <span class="math">\\mathcal{L}_{\\mathrm{x}}</span>  commits to each element of  <span class="math">x</span>  separately, then to test if the last element of  <span class="math">x</span>  is 1, we could check if the last element of  <span class="math">\\mathcal{L}_{\\mathrm{x}}(x)</span>  is a commitment to 1. Looking ahead, in the SNARK context, this will help us check if certain subsets of the extended witness are consistent with the witness commitment.</p>

    <p class="text-gray-300">To formalize this idea, we introduce projection maps  <span class="math">\\psi</span>  and  <span class="math">\\varPsi</span>  and linear map  <span class="math">\\mathcal{L}_{\\mathrm{x}}^{\\prime}</span> . Informally,  <span class="math">\\psi</span>  selects the elements of  <span class="math">x</span>  we want to check,  <span class="math">\\varPsi</span>  selects the corresponding elements of  <span class="math">\\mathcal{L}_{\\mathrm{x}}(x)</span> , and  <span class="math">\\mathcal{L}_{\\mathrm{x}}^{\\prime}</span>  computes  <span class="math">\\mathcal{L}_{\\mathrm{x}}</span>  on the elements of  <span class="math">x</span>  selected by  <span class="math">\\psi</span> . The following lemma describes our problem as an adversarial game.</p>

    <p class="text-gray-300">Lemma 5 (Polynomial Witness Testing). Let  <span class="math">\\psi : \\mathbb{F}^n \\to \\mathbb{F}^b</span>  and  <span class="math">\\varPsi : \\mathbb{X} \\to \\mathbb{X}&#x27;</span>  be a projection maps,  <span class="math">\\mathcal{L}_{\\mathrm{x}} : \\mathbb{F}^m \\to \\mathbb{X}</span> ,  <span class="math">\\mathcal{L}_{\\mathrm{x}}&#x27; : \\mathbb{F}^b \\to \\mathbb{X}&#x27;</span> , and  <span class="math">\\mathcal{L}_{\\mathrm{e}}</span>  be linear maps which are binding commitments schemes, and  <span class="math">f : \\mathbb{F}^m \\to \\mathbb{F}^n</span>  be a polynomial map. Further, assume  <span class="math">\\varPsi \\circ \\mathcal{L}_{\\mathrm{x}} = \\mathcal{L}_{\\mathrm{x}}&#x27; \\circ \\psi</span> . Then, for all expected PPT adversaries  <span class="math">\\mathcal{A}</span> , the following holds:</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname * {P r} \\left[ \\left( \\begin{array}{c c} ((\\overline {{x}}, \\overline {{e}}), x) \\in \\mathcal {R} _ {\\mathrm {o p e n}} (\\mathcal {L} _ {\\mathrm {x}}, \\mathcal {L} _ {\\mathrm {e}}) \\wedge \\\\ \\varPsi (\\overline {{x}}) = \\mathcal {L} _ {\\mathrm {x}} ^ {\\prime} (x ^ {\\prime}) \\wedge \\overline {{e}} = \\mathcal {L} _ {\\mathrm {e}} (e) \\end{array} \\right)  :   \\begin{array}{c} ((\\overline {{x}}, \\overline {{e}}), x), \\\\ x ^ {\\prime}, e \\end{array} \\leftarrow \\mathcal {A} (\\mathcal {L} _ {\\mathrm {x}}, \\mathcal {L} _ {\\mathrm {x}} ^ {\\prime}, \\mathcal {L} _ {\\mathrm {e}}) \\right] \\geq 1 - \\mathsf {n e g l} (\\lambda)</span></div>

    <p class="text-gray-300">Proof Sketch. We construct an adversary  <span class="math">\\mathcal{B}</span>  that breaks the binding property of  <span class="math">\\mathcal{L}_{\\mathrm{x}}^{\\prime}</span> , or  <span class="math">\\mathcal{L}_{\\mathrm{e}}</span> . Then, we show that the success probability of  <span class="math">\\mathcal{B}</span>  bounds the success probability of  <span class="math">\\mathcal{A}</span> . We can conclude by union bound that the probability in (5) is negligibly close to 1. We defer the full proof to Appendix A.1.</p>

    <p class="text-gray-300">In this section, we present two folding schemes for polynomial opening relations. The first scheme (Protocol 1) supports only homogeneous polynomial maps. To support an arbitrary polynomial map, we must first apply the homogeneous transform from Definition 16 to convert the map into a homogeneous one. In contrast, the second scheme (Protocol 2) can directly support arbitrary polynomial maps. The two protocols also differ</p>

    <p class="text-gray-300">in round complexity and efficiency: (i) Protocol 1 requires logarithmic rounds of communication whereas Protocol 2 has only two rounds. (ii) The folding verifier of Protocol 2 performs half as many operations as the verifier in Protocol 1. (iii) As a tradeoff, the folding prover of Protocol 2 requires  <span class="math">O(k^2 m)</span>  field operations and  <span class="math">O(km)</span>  group operations while Protocol 2 performs only  <span class="math">O(km)</span>  field and group operations.</p>

    <p class="text-gray-300">Next we describe an interactive protocol for the polynomial opening relation  <span class="math">\\mathcal{R}_{\\mathrm{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)</span>  from Definition 15, which reduces the relation to a smaller instance of the same relation. We can use this protocol to construct a folding scheme for the relation  <span class="math">\\mathcal{R}_{\\mathrm{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)</span>  by recursively applying the protocol. Without loss of generality we assume that  <span class="math">\\ell \\in \\mathbb{N}</span>  is a power-of-two.</p>

    <p class="text-gray-300">Protocol 1 ( <span class="math">\\Pi_{\\text{open}}^{(\\ell)}</span> : Interactive Protocol for  <span class="math">\\mathcal{R}_{\\text{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}}, \\mathcal{L}_{\\mathrm{e}}, f) \\cup \\mathcal{R}_{\\text{collision}}(\\mathcal{L}_{\\mathrm{x}})</span> )</p>

    <p class="text-gray-300">Prover  <span class="math">\\mathcal{P}\\big((\\overline{x}_i,\\overline{e}_i)_{i = 1}^{\\ell};(x_i)_{i = 1}^{\\ell}\\big)\\leftrightarrow</span>  Verifier  <span class="math">\\mathcal{V}\\big((\\overline{x}_i,\\overline{e}_i)_{i = 1}^{\\ell}\\big)</span></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{P}</span> : For  <span class="math">j \\in [\\ell/2]</span> , compute  <span class="math">(v_{1,j}, \\ldots, v_{d-1,j}) \\in \\mathbb{F}^{d-1}</span>  such that for indeterminate  <span class="math">Y</span></li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">f (Y \\cdot x _ {j} + x _ {j + \\ell / 2}) = Y ^ {d} f (x _ {j}) + \\sum_ {i = 1} ^ {d - 1} Y ^ {i} \\cdot v _ {i, j} + f (x _ {j + \\ell / 2})</span></div>

    <p class="text-gray-300">Set  <span class="math">\\overline{v}_{i,j} \\gets \\mathcal{L}_{\\mathrm{e}}(v_{i,j})</span>  for all  <span class="math">j \\in [\\ell/2]</span>  and  <span class="math">i \\in [d-1]</span> ; Send the matrix  <span class="math">(\\overline{v}_{i,j})_{i,j}</span>  to  <span class="math">\\mathcal{V}</span> .</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}</span> : Sample random challenge  <span class="math">r \\gets \\mathbb{S} \\mathbb{F}</span> , and send  <span class="math">r</span>  to  <span class="math">\\mathcal{P}</span> .</li>

      <li><span class="math">\\mathcal{P}</span> : For  <span class="math">j \\in [\\ell/2]</span> , compute  <span class="math">x_j&#x27; \\gets r \\cdot x_j + x_{j+\\ell/2}</span> . Send  <span class="math">(x_1&#x27;, \\ldots, x_{\\ell/2}&#x27;) \\in \\mathbb{F}^{\\ell/2}</span>  to  <span class="math">\\mathcal{V}</span> .</li>

      <li><span class="math">\\mathcal{V}</span> : For  <span class="math">j \\in [\\ell/2]</span> , assign</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\overline{x}_j^{\\prime}\\gets r\\cdot \\overline{x}_j + \\overline{x}_{j + \\ell /2}\\quad \\mathrm{and}\\quad \\overline{e}_j^{\\prime}\\gets r^d\\cdot \\overline{e}_j + \\sum_{i = 1}^{d - 1}r^i\\cdot \\overline{v}_{i,j} + \\overline{e}_{j + \\ell /2}</span></p>

    <p class="text-gray-300">Check if  <span class="math">\\left((\\overline{x}_j&#x27;,\\overline{e}_j&#x27;)_{j = 1}^{\\ell /2};(x_i&#x27;)_{j = 1}^{\\ell /2}\\right)\\in \\mathcal{R}_{\\mathrm{open}}^{\\ell /2}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f).</span></p>

    <p class="text-gray-300">Definition 17 (Homogeneous Opening Protocol). Let  <span class="math">\\ell \\in \\mathbb{N}</span>  be a power-of-two. We define the protocol  <span class="math">\\Pi_{\\mathrm{open}}^{\\mathrm{H}} := \\Pi_{\\mathrm{open}}^{(\\ell)} \\circ \\Pi_{\\mathrm{open}}^{(\\ell/2)} \\circ \\dots \\circ \\Pi_{\\mathrm{open}}^{(2)}</span> , where  <span class="math">\\circ</span>  denotes the sequential composition of protocols. In particular, for  <span class="math">k &amp;gt; 2</span> , the protocol  <span class="math">\\Pi_{\\mathrm{open}}^{k/2}</span>  takes in the instance-witness pair  <span class="math">((\\overline{x}_j&#x27;, \\overline{e}_j&#x27;)_{j=1}^{k/2}; (x_i&#x27;)_{j=1}^{k/2})</span>  derived by the prior protocol  <span class="math">\\Pi_{\\mathrm{open}}^{k}</span> .</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Theorem 2. Let  <span class="math">m, n, d, \\ell \\in \\mathbb{N}</span>  (where  <span class="math">\\ell = \\mathrm{poly}(\\lambda)</span>  is a power-of-two),  <span class="math">\\mathbb{F}</span>  be a field whose size is exponential in the security parameter (i.e.  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\approx 2^{\\lambda}<span class="math"> ), and  </span>\\mathbb{X}, \\mathbb{E}<span class="math">  be vector spaces. Further, let  </span>f: \\mathbb{F}^m \\to \\mathbb{F}^n<span class="math">  be a homogeneous polynomial map of degree  </span>d<span class="math">  (Definition 14), and  </span>\\mathcal{L}_{\\mathrm{x}}: \\mathbb{F}^m \\to \\mathbb{X}<span class="math">  and  </span>\\mathcal{L}_{\\mathrm{e}}: \\mathbb{F}^m \\to \\mathbb{E}<span class="math">  be linear maps. And, suppose the linear map  </span>\\mathcal{L}_{\\mathrm{x}}: \\mathbb{F}^m \\to \\mathbb{X}<span class="math">  is a binding commitment scheme for message space  </span>\\mathbb{F}^m<span class="math"> . Then, there exists a secure folding scheme (Definition 9) for the relation  </span>\\mathcal{R}_{\\mathrm{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}}, \\mathcal{L}_{\\mathrm{e}}, f)$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Proof Sketch. Informally, the folding scheme is the adaptive Fiat-Shamir transformation [ACK21] of the opening protocol  <span class="math">\\Pi_{\\mathrm{open}}^{\\mathrm{H}}</span>  (Definition 17). First, we show that  <span class="math">\\Pi_{\\mathrm{open}}^{\\mathrm{H}}</span>  is a  <span class="math">(d + 1)^{\\log (\\ell)}</span> -special sound protocol for the relation  <span class="math">\\mathcal{R}_{\\mathrm{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)\\cup \\mathcal{R}_{\\mathrm{collision}}(\\mathcal{L}_{\\mathrm{x}})</span>  (Theorem 6). By applying the adaptive Fiat-Shamir transformation (Lemma 1) and leveraging the fact that  <span class="math">\\mathcal{L}_{\\mathrm{x}}</span>  is binding, we obtain a secure NARK (Definition 5) for  <span class="math">\\mathcal{R}_{\\mathrm{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)</span> . In this NARK, the prover takes as input  <span class="math">\\mathcal{P}\\big((\\overline{x}_i,\\overline{e}_i)_{i = 1}^\\ell ;(x_i)_{i = 1}^\\ell \\big)</span>  and the verifier  <span class="math">\\mathcal{V}\\big((\\overline{x}_i,\\overline{e}_i)_{i = 1}^\\ell \\big)</span> . We can trivially convert this NARK into a folding scheme by simplying setting the folding proof  <span class="math">\\mathsf{pf}</span>  to be the transcript up until the last message of the prover. The output relation pair of the folding</p>

    <p class="text-gray-300">scheme prover is the same as the output pair <span class="math">((\\overline{x}^{\\prime},\\overline{e}^{\\prime}),x^{\\prime})</span> of the NARK. The folding scheme verifier simply runs the NARK verifier to derive the output instance <span class="math">\\overline{x}^{\\prime}</span>, and checks if it’s input <span class="math">\\overline{x}=\\overline{x}^{\\prime}</span>. We defer the full proof to Appendix A.2. ∎</p>

    <h3 id="sec-27" class="text-xl font-semibold mt-8">5.2 A Folding Scheme for Arbitrary Polynomial Maps</h3>

    <p class="text-gray-300">In this section, we describe a folding scheme for the relation <span class="math">\\mathcal{R}^{\\ell}_{\\mathsf{open}}(\\mathcal{L}_{\\mathsf{x}},\\mathcal{L}_{\\mathsf{e}},f)</span> for arbitrary polynomial maps <span class="math">f</span>. The prior section described a folding scheme restricted to only homogeneous maps, which are a special case of polynomial maps. This protocol can be viewed as a generalization of recent work that fold instances of NARKs derived from code-based IOPs <em>[x1]</em> and special-sound protocol transcripts <em>[x10]</em>, where the algebraic verifier is restricted to a multivariate polynomial. To work around this restriction, Protogalaxy <em>[x10]</em> describes a transform from special-sound protocol with algebraic verifiers that can be represented as polynomial maps <span class="math">f:\\mathbb{F}^{m}\\to\\mathbb{F}^{n}</span> to a special-sound protocol where the verifier is a multivariate polynomial <span class="math">\\hat{f}:\\mathbb{F}^{m+\\log(n)}\\to\\mathbb{F}</span>. Similarly to the homogeneous transform (Definition 16), this transformation introduces additional variables to the polynomial map; in particular, a logarithmic number. Here, instead, we directly handle the general case of arbitrary polynomial maps <span class="math">f:\\mathbb{F}^{m}\\to\\mathbb{F}^{n}</span>; for which the multivariate polynomial is a special case. As mentioned earlier, by considering arbitrary linear maps and polynomial maps, we capture a wide range of relations that are amenable to folding rather than restricting ourselves to committed special-sound transcripts.</p>

    <h6 id="sec-28" class="text-base font-medium mt-4">Notation</h6>

    <p class="text-gray-300">Let <span class="math">\\mathbb{H}:=\\{h_{1},\\ldots,h_{\\ell}\\}\\subseteq\\mathbb{F}</span> denote <span class="math">\\ell</span> distinct field elements. Denote <span class="math">v_{\\mathbb{H}}(Y)=\\prod_{h\\in\\mathbb{H}}(Y-h)</span> to be the vanishing polynomial over <span class="math">\\mathbb{H}</span>. Further, let <span class="math">\\{L_{1}^{\\mathbb{H}},\\ldots,L_{\\ell}^{\\mathbb{H}}\\}</span> denote the Lagrange basis for <span class="math">\\mathbb{H}</span>, which have the form <span class="math">L_{i}^{\\mathbb{H}}(Y)=c_{i}\\cdot v_{\\mathbb{H}}(Y)/(Y-h_{i})</span> for some <span class="math">c_{i}\\in\\mathbb{F}</span>. For all <span class="math">i\\in[\\ell]</span>, <span class="math">L_{i}^{\\mathbb{H}}(Y)</span> is a polynomial of degree <span class="math">\\ell-1</span> that evaluates to <span class="math">1</span> at <span class="math">h_{i}</span> and <span class="math">0</span> at all other points in <span class="math">\\mathbb{H}</span>.</p>

    <p class="text-gray-300">The following lemma, Lemma 6, describes how to derive the required cross-terms, whose evaluations under <span class="math">\\mathcal{L}_{\\mathsf{e}}</span> will be sent by the prover in our folding scheme (<span class="math">\\Pi_{\\mathsf{open}}</span>).</p>

    <h6 id="sec-29" class="text-base font-medium mt-4">Lemma 6.</h6>

    <p class="text-gray-300">Consider a polynomial map <span class="math">f:\\mathbb{F}^{m}\\to\\mathbb{F}^{n}</span> of degree <span class="math">d</span>. Further, consider vectors <span class="math">x_{1},\\ldots,x_{\\ell}\\in\\mathbb{F}^{m}</span>. There exists vectors <span class="math">q_{0},\\ldots,q_{d(\\ell-1)-\\ell}\\in\\mathbb{F}^{n}</span> such that the following expression holds over indeterminate <span class="math">Y</span>:</p>

    <p class="text-gray-300"><span class="math">f\\left(\\sum_{i=1}^{\\ell}L_{i}^{\\mathbb{H}}(Y)\\cdot x_{i}\\right)-\\sum_{i=1}^{\\ell}L_{i}^{\\mathbb{H}}(Y)\\cdot f(x_{i})=v_{\\mathbb{H}}(Y)\\cdot\\left(\\sum_{j=0}^{d(\\ell-1)-\\ell}Y^{j}\\cdot q_{j}\\right)</span> (1)</p>

    <h6 id="sec-30" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Let us refer to the expression on the left hand side of (1) as <span class="math">F(Y)</span>. Observe that <span class="math">F(Y)</span> is a polynomial in <span class="math">Y</span> whose coefficients are in <span class="math">\\mathbb{F}^{n}</span> and has degree at most <span class="math">d(\\ell-1)</span> in <span class="math">Y</span>. Furthermore, observe that <span class="math">F(Y)</span> vanishes (evaluates to <span class="math">0^{n}</span>) at the <span class="math">\\ell</span> distinct points in <span class="math">\\mathbb{H}</span>. Therefore, for all <span class="math">i\\in[n]</span>, <span class="math">v_{\\mathbb{H}}(Y)</span> must divide <span class="math">F^{(i)}(Y)</span> (the <span class="math">i</span>-th polynomial of the polynomial map <span class="math">F(Y)</span>). Define, for all <span class="math">i\\in[n]</span>, <span class="math">q^{(i)}(Y)=F^{(i)}(Y)/v_{\\mathbb{H}}(Y)</span> whose degree is <span class="math">d(\\ell-1)-\\ell</span>; let <span class="math">q_{j}^{(i)}</span> denote the <span class="math">j</span>-th coefficient of <span class="math">q^{(i)}(Y)</span>. Further, define vectors <span class="math">q_{j}=(q_{j}^{(1)},\\ldots,q_{j}^{(n)})</span>. Then, by construction, we must have that <span class="math">F(Y)=v_{\\mathbb{H}}(Y)\\cdot\\left(\\sum_{j=0}^{d(\\ell-1)-\\ell}Y^{j}\\cdot q_{j}\\right)</span>. ∎</p>

    <p class="text-gray-300">Protocol 2 (<span class="math">\\Pi_{\\mathsf{open}}</span>: Interactive Protocol for <span class="math">\\mathcal{R}^{\\ell}_{\\mathsf{open}}(\\mathcal{L}_{\\mathsf{x}},\\mathcal{L}_{\\mathsf{e}},f)\\cup\\mathcal{R}_{\\mathsf{collision}}(\\mathcal{L}_{\\mathsf{x}})</span>)</p>

    <p class="text-gray-300">Prover <span class="math">\\mathcal{P}\\big{(}(\\overline{x}_{i},\\overline{e}_{i})_{i=1}^{\\ell};\\ (x_{i})_{i=1}^{\\ell}\\big{)}\\leftrightarrow\\text{Verifier }\\mathcal{V}\\big{(}(\\overline{x}_{i},\\overline{e}_{i})_{i=1}^{\\ell}\\big{)}</span></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{P}</span>: As in Lemma 6, compute vectors <span class="math">q_0, \\ldots, q_{d(\\ell - 1) - \\ell} \\in \\mathbb{F}^n</span> s.t. for indeterminate <span class="math">Y</span></li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">f \\left(\\sum_ {i = 1} ^ {\\ell} L _ {i} ^ {\\mathbb {H}} (Y) \\cdot x _ {i}\\right) - \\sum_ {i = 1} ^ {\\ell} L _ {i} ^ {\\mathbb {H}} (Y) \\cdot f (x _ {i}) = v _ {\\mathbb {H}} (Y) \\cdot \\left(\\sum_ {j = 0} ^ {d (\\ell - 1) - \\ell} Y ^ {j} \\cdot q _ {j}\\right)</span></div>

    <p class="text-gray-300">Set <span class="math">\\overline{q}_j \\gets \\mathcal{L}_{\\mathrm{e}}(q_j)</span> for all <span class="math">j \\in \\{0, \\dots, d(\\ell - 1) - \\ell\\}</span> and send <span class="math">(\\overline{q}_j)_j</span> to <span class="math">\\mathcal{V}</span>.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathcal{V}</span>: Sample random challenge <span class="math">r \\gets \\S \\mathbb{F}</span>, and send <span class="math">r</span> to <span class="math">\\mathcal{P}</span>.</li>

      <li><span class="math">\\mathcal{P}</span>: Compute <span class="math">x = \\sum_{i=1}^{\\ell} L_i^{\\mathbb{H}}(r) \\cdot x_i</span>. Send <span class="math">x</span> to <span class="math">\\mathcal{V}</span>.</li>

      <li><span class="math">\\mathcal{V}</span>: Assign</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\overline {{x}} \\leftarrow \\sum_ {i = 1} ^ {\\ell} L _ {i} ^ {\\mathbb {H}} (r) \\cdot \\overline {{x}} _ {i} \\text { and } \\overline {{e}} \\leftarrow v _ {\\mathbb {H}} (r) \\cdot \\left(\\sum_ {j = 0} ^ {d (\\ell - 1) - \\ell} r ^ {j} \\cdot \\overline {{q}} _ {j}\\right) + \\left(\\sum_ {i = 1} ^ {\\ell} L _ {i} ^ {\\mathbb {H}} (r) \\cdot \\overline {{e}} _ {i}\\right)</span></div>

    <p class="text-gray-300">Check if <span class="math">((\\overline{x},\\overline{e});x)\\in \\mathcal{R}_{\\mathrm{open}}(\\mathcal{L}_x,\\mathcal{L}_e,f)</span>.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Theorem 3. Let <span class="math">m, n, d, \\ell \\in \\mathbb{N}</span>, <span class="math">\\mathbb{F}</span> be a field whose size is exponential in the security parameter (i.e. $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\approx 2^{\\lambda}<span class="math">), and </span>\\mathbb{X}, \\mathbb{E}<span class="math"> be vector spaces. Further, let </span>f: \\mathbb{F}^m \\to \\mathbb{F}^n<span class="math"> be an arbitrary polynomial map of degree </span>d<span class="math"> (Definition 14), and </span>\\mathcal{L}_{\\mathrm{x}}: \\mathbb{F}^m \\to \\mathbb{X}<span class="math"> and </span>\\mathcal{L}_{\\mathrm{e}}: \\mathbb{F}^m \\to \\mathbb{E}<span class="math"> be linear maps. And, suppose the linear map </span>\\mathcal{L}_{\\mathrm{x}}: \\mathbb{F}^m \\to \\mathbb{X}<span class="math"> is a binding commitment scheme for message space </span>\\mathbb{F}^m<span class="math">. Then, there exists a secure folding scheme (Definition 9) for the relation </span>\\mathcal{R}_{\\mathrm{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}}, \\mathcal{L}_{\\mathrm{e}}, f)$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Proof Sketch. We follow a similar construction and proof strategy as in Theorem 2. The folding scheme is the adaptive Fiat-Shamir transformation [ACK21] of the opening protocol <span class="math">\\Pi_{\\mathrm{open}}</span> (Protocol 17). First, we show that <span class="math">\\Pi_{\\mathrm{open}}</span> is a <span class="math">d(\\ell - 1) + 1</span>-special sound protocol for the relation <span class="math">\\mathcal{R}_{\\mathrm{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}}, \\mathcal{L}_{\\mathrm{e}}, f) \\cup \\mathcal{R}_{\\mathrm{collision}}(\\mathcal{L}_{\\mathrm{x}})</span> (Theorem 7). By applying the adaptive Fiat-Shamir transformation (Lemma 1) and leveraging the fact that <span class="math">\\mathcal{L}_{\\mathrm{x}}</span> is binding, we obtain a secure NARK (Definition 5) for <span class="math">\\mathcal{R}_{\\mathrm{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}}, \\mathcal{L}_{\\mathrm{e}}, f)</span>, which can be trivially converted into a folding scheme, as was done in Theorem 2. We defer the full proof to Appendix A.3.</p>

    <p class="text-gray-300">Remark 4 (Comparison of Protocols <span class="math">\\Pi_{\\mathrm{open}}^{\\mathrm{H}}</span> ((Protocol 1)) and <span class="math">\\Pi_{\\mathrm{open}}</span> (Protocol 2)). Both <span class="math">\\Pi_{\\mathrm{open}}^{\\mathrm{H}}</span> and <span class="math">\\Pi_{\\mathrm{open}}</span> send the same number of crossterms. To see this, observe that <span class="math">\\Pi_{\\mathrm{open}}^{\\mathrm{H}}</span> sends <span class="math">(d - 1)(\\ell /2) + (d - 1)(\\ell /4) + \\dots + (d - 1) = (2(\\ell /2) - 1)(d - 1) = (\\ell -1)(d - 1) = d(\\ell -1) - \\ell +1</span> cross terms, which is exactly the same number of cross terms sent in <span class="math">\\Pi_{\\mathrm{open}}</span>. The protocols differ beyond supporting homogeneous versus arbitrary polynomial maps. Their round complexity and concretely their efficiency also differ. The protocol <span class="math">\\Pi_{\\mathrm{open}}^{\\mathrm{H}}</span> has logarithmic rounds of communication, while <span class="math">\\Pi_{\\mathrm{open}}</span> has only two rounds. Despite both protocols sending the same number of crossterms, <span class="math">\\Pi_{\\mathrm{open}}</span> performs half as many homomorphic operations, since it no longer produces and manipulates intermediate pairs <span class="math">\\left((\\overline{x}_j&#x27;,\\overline{e}_j&#x27;);x_j&#x27;\\right)_j</span> for every round (for logarithmic rounds).</p>

    <h2 id="sec-31" class="text-2xl font-bold">5.3 Heuristic Security of Folding Schemes</h2>

    <p class="text-gray-300">Looking ahead, we will require a folding scheme for the relation <span class="math">\\mathcal{R}_{\\mathrm{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)</span> in the standard model, in order to encode the folding scheme in a concrete predicate <span class="math">\\varphi</span> for PCD (Definition 12). In prior work [BCL+21, BCMS20a, COS20], they require a folding scheme (or accumulation scheme) for NARKs in the standard model to construct PCD. They show the existence of such a folding scheme in the random oracle model, and then obtain a folding scheme in the standard model with heuristic security by instantiating the random oracle with an appropriate hash function. The security of the folding scheme in the standard model</p>

    <p class="text-gray-300">is a conjecture, due to a well-known limitation of the random oracle methodology <em>[x10, x21]</em>, but there is evidence to suggest this limitation may not be inherent <em>[x13]</em>. We can follow the same approach to obtain a folding scheme for the relation <span class="math">\\mathcal{R}_{\\mathsf{open}}^{\\ell}(\\mathcal{L}_{\\mathsf{x}},\\mathcal{L}_{\\mathsf{e}},f)</span> in the standard model. Here, we state this as Conjecture 1.</p>

    <h6 id="sec-32" class="text-base font-medium mt-4">Conjecture 1.</h6>

    <p class="text-gray-300">Consider the parameters, maps, and assumptions as in Theorem 3. If there exists a secure folding scheme for the relation <span class="math">\\mathcal{R}_{\\mathsf{open}}^{\\ell}(\\mathcal{L}_{\\mathsf{x}},\\mathcal{L}_{\\mathsf{e}},f)</span> in the random oracle model, then there exists a folding scheme for the relation <span class="math">\\mathcal{R}_{\\mathsf{open}}^{\\ell}(\\mathcal{L}_{\\mathsf{x}},\\mathcal{L}_{\\mathsf{e}},f)</span> in the standard model.</p>

    <p class="text-gray-300">From Conjecture 1 and Theorem 3, we obtain a folding scheme for the relation <span class="math">\\mathcal{R}_{\\mathsf{open}}^{\\ell}(\\mathcal{L}_{\\mathsf{x}},\\mathcal{L}_{\\mathsf{e}},f)</span> in the standard model.</p>

    <h2 id="sec-33" class="text-2xl font-bold">6 SNARKs for Plonkish Arithmetization</h2>

    <p class="text-gray-300">In this section we describe our new SNARK construction. The construction implements the outline from Section 2.2 and implements the optimizations described in Section 2.3. First, in Section 6.1 we describe the arithmetization that our SNARK targets, a form of Plonkish arithmetization <em>[x11]</em>. Section 6.2 describes a simple NARK whose verifier has a nice uniform structure amenable to folding and PCD.Finally, Section 6.3 describes how to use PCD to “outsource” some of the verification work to the prover to enable sublinear verification time.</p>

    <h3 id="sec-34" class="text-xl font-semibold mt-8">6.1 Plonkish Arithmetization</h3>

    <p class="text-gray-300">Plonkish arithmetization <em>[x22, x11]</em> is a convenient way to represent a computation trace. We review this format in the next definition.</p>

    <h6 id="sec-35" class="text-base font-medium mt-4">Notation.</h6>

    <p class="text-gray-300">Define a range function <span class="math">\\mathsf{rn}(i,k)\\coloneqq[(i-1)\\cdot k+1,\\ i\\cdot k]</span>. For a vector <span class="math">v</span>, we denote <span class="math">v^{\\mathsf{rn}(i,k)}</span> as the subvector of <span class="math">v</span> containing the elements in the range <span class="math">\\mathsf{rn}(i,k)</span>. Informally, this is the <span class="math">i</span> chunk (of size <span class="math">k</span>) of <span class="math">v</span>.</p>

    <h6 id="sec-36" class="text-base font-medium mt-4">Definition 18 (Plonkish Arithmetization).</h6>

    <p class="text-gray-300">Let <span class="math">b,c,t&gt;b,m,n\\in\\mathbb{N}</span> such that <span class="math">c=n/t\\in\\mathbb{N}</span> and <span class="math">\\mathbb{F}</span> be a finite field. A plonkish arithmetization is a tuple <span class="math">\\mathsf{plk}\\coloneqq(\\sigma,\\ \\mathsf{s},\\ G)</span> where <span class="math">\\sigma\\in\\mathbb{F}^{n}</span> is a permutation vector on <span class="math">[n]</span> (i.e. <span class="math">\\{1,\\ldots,n\\}=\\{\\sigma_{i}\\}_{i\\in[n]}</span>), <span class="math">\\mathsf{s}\\in\\mathbb{F}^{c\\cdot b}</span> is a selector vector, and <span class="math">G:\\mathbb{F}^{b}\\times\\mathbb{F}^{t}\\to\\mathbb{F}</span> is a gate polynomial, which can represent arbitrary custom gate constraints.</p>

    <p class="text-gray-300">A value vector <span class="math">z\\in\\mathbb{F}^{n}</span> satisfies a Plonkish Arithmetization <span class="math">\\mathsf{plk}\\coloneqq(\\sigma,\\ \\mathsf{s},\\ G)</span> if</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Global Copy Constraints: For all <span class="math">i\\in[n]</span>, <span class="math">z_{i}=z_{\\sigma_{i}}</span>.</li>

      <li>Local Gate Constraints: For all <span class="math">i\\in[c]</span>, <span class="math">G\\left(\\mathsf{s}^{\\mathsf{rn}(i,b)},\\ z^{\\mathsf{rn}(i,t)}\\right)=0</span>.</li>

    </ul>

    <p class="text-gray-300">We define the following index relation <span class="math">\\mathfrak{R}_{\\mathsf{plk}}</span>:</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\[ \\mathfrak{R}_{\\mathsf{plk}}\\coloneqq\\left\\{\\left(\\mathsf{plk},\\ x\\in\\mathbb{F}^{m},\\ w\\in\\mathbb{F}^{n-m}\\right)\\ \\middle</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\ \\begin{array}[]{l}\\text{For}\\ z\\coloneqq(x,w),\\\\</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">z\\ \\text{satisfies}\\ \\mathsf{plk}\\end{array}\\right\\} \\]</p>

    <p class="text-gray-300">Construction 1 presents a NARK for <span class="math">\\mathfrak{R}_{\\mathsf{plk}}</span>. To prove that some <span class="math">(\\mathsf{plk},x,w)\\in\\mathfrak{R}_{\\mathsf{plk}}</span>, the prover must prove that <span class="math">z=(x,w)</span> satisfies both the global copy constraints and the local gate constraints of <span class="math">\\mathsf{plk}</span>. To prove <span class="math">z=(x,w)</span> satisfies global copy constraints, the prover calculates partial products corresponding to the standard grand product permutation check from past work <em>[CDv^{+}03, x22]</em>. To prove <span class="math">z</span> satisfies local gate constraints, the prover simply provides <span class="math">z</span> to the verifier, who manually checks them.</p>

    <p class="text-gray-300">###</p>

    <p class="text-gray-300">6.2 NARK for Plonkish</p>

    <p class="text-gray-300">In this section we describe a somewhat trivial NARK for <span class="math">\\mathfrak{R}_{\\mathsf{plk}}</span>. The NARK prover outputs the extended witness <span class="math">z := (x, w)</span> as part of the proof, along with two other terms <span class="math">L</span> and <span class="math">R</span> that come from the permutation argument. In the next section we will show how to obtain a SNARK by applying folding to this NARK verifier. The point is that this NARK verifier has a uniform structure that makes it amenable to folding.</p>

    <pre><code class="language-prolog">Construction 1 (NARK for $\\mathfrak{R}_{\\mathrm{plk}}$)
- $\\mathcal{G}_{\\mathrm{nark}}(1^{\\lambda})$: Output ck $\\leftarrow$ Setupcom(1λ).
- $\\mathcal{I}_{\\mathrm{nark}}(\\mathsf{pp},(\\sigma ,\\mathsf{s},G))$: Output (npk := (pp, σ, s, G), nvk := (pp, σ, s, G)).
- $\\mathcal{P}_{\\mathrm{nark}}^{\\mathrm{m}}(\\mathsf{npk},x,w)$:
1. Parse (ck, σ, s, G) $\\leftarrow$ npk and assign $z \\leftarrow (x,w)$.
2. Commit $\\overline{\\mathsf{plk}} \\leftarrow$ Commit(ck, (σ, s)) and $\\overline{z} \\leftarrow$ Commit(ck, z).
3. Derive challenges $\\alpha, \\beta \\leftarrow$ ro( $\\overline{\\mathsf{plk}},x,\\overline{z}$ ).
4. Compute vectors $L,R$ such that
- $L_{1} = (z_{1} + \\alpha +\\beta)$ and $R_{1} = (z_{1} + \\sigma_{1}\\cdot \\alpha +\\beta)$.
- For all $i\\in \\{2,\\ldots ,n\\}$, $L_{i} = L_{i - 1}\\cdot [(z_{i} + i\\cdot \\alpha) + \\beta ]$ and $R_{i} = R_{i - 1}\\cdot [(z_{i} + \\sigma_{i}\\cdot \\alpha) + \\beta ]$.
5. Output proof $\\pi := (z,L,R)$.
- $\\mathcal{V}_{\\mathrm{nark}}^{\\mathrm{m}}(\\mathsf{nvk},x,\\pi)$:
1. Parse (ck, σ, s, G) $\\leftarrow$ nvk and proof (z, L, R) $\\leftarrow$ π.
2. Commit $\\overline{\\mathsf{plk}} \\leftarrow$ Commit(ck, (σ, s)) and $\\overline{z} \\leftarrow$ Commit(ck, z).
3. Derive challenges $\\alpha, \\beta \\leftarrow$ ro( $\\overline{\\mathsf{plk}},x,\\overline{z}$ ).
4. Check if $x = (z_{1},\\dots ,z_{|x|})$.
5. Check if
- $L_{1} = (z_{1} + \\alpha +\\beta)$ and $R_{1} = (z_{1} + \\sigma_{1}\\cdot \\alpha +\\beta)$.
- For all $i\\in \\{2,\\ldots ,n\\}$, $L_{i} = L_{i - 1}\\cdot [(z_{i} + i\\cdot \\alpha) + \\beta ]$ and $R_{i} = R_{i - 1}\\cdot [(z_{i} + \\sigma_{i}\\cdot \\alpha) + \\beta ]$.
6. Check $L_{n} = R_{n}$ and for all $i\\in [c]$, $G\\left(\\mathsf{s}^{m(i,b)},z^{m(i,t)}\\right) = 0$.
7. Output accept if all checks pass otherwise reject.</code></pre>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Theorem 4. Let <span class="math">\\mathbb{F}</span> be a field whose size is exponential in the security parameter (i.e. $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\approx 2^{\\lambda}<span class="math">). Let </span>(\\mathrm{Setup}_{\\mathrm{com}}, \\mathrm{Commit})<span class="math"> be a binding commitment scheme (Definition 7) for vectors over </span>\\mathbb{F}<span class="math">. Then, Construction 1 is a secure NARK (Definition 5) for </span>\\mathfrak{R}_{\\mathrm{plk}}$ (Definition 18).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Proof idea. Completeness follows almost immediately from the construction; the gate check is identical to the relation and the product check follows from Lemma 4. To prove knowledge soundness, we construct the trivial extractor which output the witness <span class="math">w</span> from parsing <span class="math">z</span> given in the proof. To argue the extractor is correct, we bound the probability the prover succeeds by constructing an adversary against the Zero Finding Game (Lemma 2) with respect to commitments hz and hplk. We defer the full proof to Appendix A.5.</p>

    <p class="text-gray-300">Note that our NARK verifier work can be naturally separated into uniform chunks (see Section 2.1). In particular, our NARK verifier checks local gate constraints for one chunk of indices at a time. We can similarly chunk the global permutation product check by computing partial products for one chunk of indices at a time. The verifier can perform the final product check by multiplying the chunked partial products.</p>

    <p class="text-gray-300">The verifier can similarly compute the commitments to <span class="math">z</span>, <span class="math">\\sigma</span>, and <span class="math">\\mathsf{s}</span> in a chunked manner using a Merkle tree commitment: the verifier commits to chunks of <span class="math">z</span>, <span class="math">\\sigma</span>, and <span class="math">\\mathsf{s}</span> and then computes the final commitment by creating a Merkle tree whose leaves are the chunked commitments.</p>

    <h3 id="sec-37" class="text-xl font-semibold mt-8">6.3 SNARK for Plonkish</h3>

    <p class="text-gray-300">This section describes how to apply PCD to our NARK (Construction 1) from the previous section to create a SNARK. We expand on the outline from Section 2.2 on how to use PCD to produce a SNARK from uniform chunks. We can separate the NARK verifier work into core leaf computation and control merging computation. Core leaf computation consists of the checks whose inputs are contained with one chunk (e.g., local gate constraints and local permutation partial product calculations). Control merging computation consists of the checks that make guarantees across several chunks (e.g., checking that the permutation partial products from chunks are multiplied together, checking that the Merkle tree hashes from chunks are properly combined). Section 6.3 describes how to use Section 4 to create a foldable leaf relation that captures the core leaf computation. Section 6.3 describes our PCD tree predicate and a helper function for our prover. Section 6.3 describes the construction of our final SNARK. Section 6.4 gives efficiency estimates. We will denote in blue text parameters or steps necessary when the folding scheme used requires the homogeneous transformation from Definition 16 to handle arbitary polynomial maps. For example, the folding scheme constructed in Section 5.1. These can be omitted for folding schemes that handle arbitrary polynomial maps such as in Section 5.2.</p>

    <h4 id="sec-38" class="text-lg font-semibold mt-6">6.3.1 Foldable Leaf Relation</h4>

    <p class="text-gray-300">Here we describe our foldable leaf relation. We first create a non-homogeneous polynomial map that is <span class="math">0</span> if all leaf constraints are satisfied (i.e., all checks in a chunk pass). Then we directly apply Section 4, which describes how to transform a non-homogeneous polynomial into a pair of relations amenable to folding.</p>

    <p class="text-gray-300">In Section 2.3, we gave an informal description of the non-homogeneous map that is <span class="math">0</span> if the leaf constraints are satisfied. Definition 19 gives the formal definition. Recall that each leaf node represents a uniform chunk. Let <span class="math">i\\in\\mathbb{N}</span> denote the starting index of the leaf node <span class="math">(1,m+1,\\dots)</span>, and <span class="math">p\\in\\mathbb{F}</span> denote the partial product for the permutation argument for the chunk represented by the leaf node. Let <span class="math">\\sigma,z,L,R\\in\\mathbb{F}^{m}</span> and <span class="math">\\mathsf{s}\\in\\mathbb{F}^{b(m/t)}</span> be the corresponding permutation, value, partial product vectors, and selector vectors for the chunk represented by the leaf node. Let <span class="math">\\mu</span> denote the parameter introduced by the homogeneous transformation (Definition 16).</p>

    <h6 id="sec-39" class="text-base font-medium mt-4">Definition 19 (Leaf Polynomial Map).</h6>

    <p class="text-gray-300">Assume <span class="math">G:\\mathbb{F}^{b}\\times\\mathbb{F}^{t}\\to\\mathbb{F}</span> is a gate polynomial. Let <span class="math">m\\in\\mathbb{N}</span> be a memory parameter. Here define a non-homogeneous polynomial map <span class="math">f_{\\alpha,\\beta}:\\mathbb{F}^{4m+b(m/t)+2}\\to\\mathbb{F}^{2m+(m/t)+1}</span>, which represents the core leaf computation.</p>

    <p class="text-gray-300">\\[ f_{\\alpha,\\beta}^{G}(i,\\sigma,\\mathsf{s},z,L,R,p):=\\begin{pmatrix}L_{1}-(\\beta+\\alpha\\cdot i+z_{1}),\\\\ R_{1}-(\\beta+\\alpha\\cdot\\sigma_{1}+z_{1}),\\\\ \\forall j\\in[m-1],\\\\ L_{j+1}=L_{j}\\cdot(\\beta+\\alpha\\cdot(i+j)+z_{j+1}),\\\\ R_{j+1}=R_{j}\\cdot(\\beta+\\alpha\\cdot\\sigma_{j+1}+z_{j+1}),\\\\ L_{n}-p\\cdot R_{n},\\\\ \\forall j\\in[m/t],\\\\ G\\left(\\mathsf{s}^{m(j,b)},\\ z^{m(j,t)}\\right)\\end{pmatrix} \\]</p>

    <p class="text-gray-300">We define <span class="math">\\widehat{f}_{\\alpha,\\beta}^{G}(i,\\sigma,\\mathsf{s},z,L,R,p,\\mu)</span> to be the homogeneous polynomial map, obtained by applying the transformation from Definition 16.</p>

    <p class="text-gray-300"><span class="math">f_{\\alpha,\\beta}</span> evaluates to <span class="math">0</span> on <span class="math">\\sigma,\\mathsf{s},z,L,R,i,p</span> for a given uniform chunk, then the the gate constraints for that chunk are satisfied and the partial product <span class="math">p</span> for the permutation argument for that chunk has been calculated correctly. In the informal definition of <span class="math">f</span>, we express the permutation check in terms of rational fractions, but here we express it as a polynomial check because we are defining a polynomial map.</p>

    <p class="text-gray-300">We now define a pair of relations amenable to folding that captures the constraints specified by <span class="math">\\widehat{f}_{\\alpha,\\beta}</span> using the transformations from Section 4. Definition 20 gives concrete instantiations for the linear maps and projections required for these transformations. More specifically, Section 4.1 describes how to define a pair of foldable relations <span class="math">\\mathcal{R}_{\\mathsf{open}}</span> and <span class="math">\\mathcal{R}_{\\mathsf{collision}}</span> for any homogeneous polynomial map <span class="math">\\hat{f}</span> using some linear maps <span class="math">\\mathcal{L}_{\\mathsf{x}}</span> and <span class="math">\\mathcal{L}_{\\mathsf{e}}</span>. In Definition 20, we define <span class="math">\\mathcal{L}_{\\mathsf{x}}</span> and <span class="math">\\mathcal{L}_{\\mathsf{e}}</span> to be binding linear maps constructed from any binding and linearly homomorphic commitment scheme. Additionally, in Section 4.2, we explained that we can define projection functions <span class="math">\\Psi</span> and <span class="math">\\psi</span> and linear map <span class="math">\\mathcal{L}_{\\mathsf{x}}^{\\prime}</span> to test that certain elements of a witness to <span class="math">\\mathcal{R}_{\\mathsf{open}}</span> have certain values. In our SNARK, these checks correspond to the control merging logic. In particular, we need to check that we are multiplying the permutation partial product <span class="math">p</span> into our grand permutation product check and that the commitments output by <span class="math">\\mathcal{L}_{\\mathsf{x}}</span> are commitments to certain elements. We thus define <span class="math">\\Psi</span> and <span class="math">\\psi</span> as projection maps that select the relevant commitments and elements respectively, and we define <span class="math">\\mathcal{L}_{\\mathsf{x}}^{\\prime}</span> as selecting <span class="math">p</span> and committing to other elements output by <span class="math">\\psi</span>.</p>

    <h6 id="sec-40" class="text-base font-medium mt-4">Definition 20 (Leaf Linear Maps and Projections).</h6>

    <p class="text-gray-300">Let <span class="math">(\\mathsf{Setup}_{\\mathsf{com}},\\mathsf{Commit})</span> be a binding commitment scheme that is linearly homomorphic. Let <span class="math">i,m\\in\\mathbb{N}</span> and <span class="math">\\sigma,z,L,R\\in\\mathbb{F}^{m}</span> and <span class="math">\\mathsf{s}\\in\\mathbb{F}^{b(m/t)}</span>.</p>

    <p class="text-gray-300">Assume the commitment key <span class="math">\\mathsf{ck}\\leftarrow\\mathsf{Setup}_{\\mathsf{com}}(1^{\\lambda})</span> is outputted by setup.</p>

    <p class="text-gray-300">\\[ \\mathcal{L}_{\\mathsf{x}}(i,\\sigma,\\mathsf{s},z,L,R,p,\\mu):=\\begin{pmatrix}\\overline{\\mathsf{plk}}:=\\mathsf{Commit}(\\mathsf{ck},(i,\\sigma,\\mathsf{s})),\\\\ \\overline{z}:=\\mathsf{Commit}(\\mathsf{ck},z),\\\\ \\overline{w}:=\\mathsf{Commit}(\\mathsf{ck},(L,R))\\\\ p,\\ \\mu\\end{pmatrix}\\qquad\\mathcal{L}_{\\mathsf{e}}(e):=\\mathsf{Commit}(\\mathsf{ck},e) \\]</p>

    <p class="text-gray-300">Further, we define the following projection functions and linear maps used for the polynomial witness testing (Lemma 5).</p>

    <p class="text-gray-300">\\[ \\begin{array}[]{ll}\\Psi(\\overline{\\mathsf{plk}},\\overline{z},\\overline{w},p,\\mu):=(\\overline{\\mathsf{plk}},\\overline{z},p,\\mu)&\\mathcal{L}_{\\mathsf{x}}^{\\prime}(i,\\sigma,\\mathsf{s},z,p,\\mu):=\\left(\\begin{array}[]{c}\\mathsf{Commit}(\\mathsf{ck},(i,\\sigma,\\mathsf{s})),\\\\ \\mathsf{Commit}(\\mathsf{ck},z),\\\\ p,\\mu\\end{array}\\right)\\\\ \\end{array} \\]</p>

    <p class="text-gray-300">SNARK PCD Predicate and Prover Helper Function Now we describe our PCD predicate. We can parse each PCD node message <span class="math">\\mathsf{Z}=(p,\\mathsf{hplk},\\mathsf{hz},X)</span>. <span class="math">p</span> is a permutation partial product, and <span class="math">X</span> is a foldable leaf relation instance. <span class="math">\\mathsf{hplk}</span> and <span class="math">\\mathsf{hz}</span> are Merkle tree commitments to subvectors of the plonkish arithmetization <span class="math">\\sigma,\\mathsf{s}</span> vectors and the value vector <span class="math">z</span> respectively.</p>

    <p class="text-gray-300">The PCD predicate enforces the following three checks from our control merging logic over <span class="math">(p,\\mathsf{hplk},\\mathsf{hz},X)</span> for a given node. First, the predicate enforces that the <span class="math">\\mathsf{hplk}</span> (<span class="math">\\mathsf{hz}</span>) values of a given node are the results of hashing together the <span class="math">\\mathsf{hplk}</span> (<span class="math">\\mathsf{hz}</span>) values from the given node’s children. This ensures that the PCD tree honestly computes the Merkle tree commitments to the arithmetization and value commitments at the leaf nodes. At each leaf node, our prover sets <span class="math">\\mathsf{hplk}</span> to a commitment of a chunk of <span class="math">(\\sigma,\\mathsf{s})</span>, and our prover sets <span class="math">\\mathsf{hz}</span> to a commitment to a chunk of <span class="math">z</span>, so this predicate enforces that the root node of the tree has two Merkle Tree commitments to two vectors of commitments to chunks of <span class="math">(\\sigma,\\mathsf{s})</span> and <span class="math">z</span> respectively. Second, the PCD</p>

    <p class="text-gray-300">predicate verifies that folding of the leaf computation is done appropriately. In other words, it checks that each parent  <span class="math">X</span>  is the result of folding the  <span class="math">X</span>  values of the given node's children. Third, the PCD predicate checks that  <span class="math">p</span>  is the product of the  <span class="math">p</span>  values of the given node's children. This ensures that the root node of the PCD tree has the final total value for grand product permutation check.</p>

    <p class="text-gray-300">Definition 21 (SNARK PCD Predicate). Consider the maps in Definition 20. Let  <span class="math">(\\mathsf{Setup}_{\\mathsf{H}},\\mathsf{H})</span>  be a collision-resistant hash function and  <span class="math">(\\mathcal{G}_{\\mathrm{Fold}},\\mathcal{P}_{\\mathrm{Fold}},\\mathcal{V}_{\\mathrm{Fold}})</span>  be a secure folding scheme in the standard model. Here we define a PCD predicate  <span class="math">\\varphi_{\\mathsf{pp}_{\\mathsf{H}},\\mathsf{fvk}}</span> , where  <span class="math">\\mathsf{pp}_{\\mathsf{H}}\\gets \\mathsf{Setup}_{\\mathsf{H}}</span>  and  <span class="math">(.,fvk)\\gets \\mathcal{G}_{\\mathrm{Fold}}(1^{\\lambda})</span>  are parameters.</p>

    <p class="text-gray-300">|  φppH,fvk(Z,loc,Z1,...,Zk):  |</p>

    <p class="text-gray-300">| --- |</p>

    <p class="text-gray-300">|  1. Parse (p,hplk,hz,X)←Z and pf←loc.  |</p>

    <p class="text-gray-300">|  2. Parse ∀i∈[k], (pi,hplk,i,hz,i,Xi)←Zi and (x̅i, x̅i)←Xi.  |</p>

    <p class="text-gray-300">|  3. Assign ∀i∈[k], (p̅lk,i, x̅i, p̅i, μi)← Ψ(x̅i).  |</p>

    <p class="text-gray-300">|  4. If ∀i∈[k], x̅i = Lv(0) and μi = 1: // isBase  |</p>

    <p class="text-gray-300">|  - ∀i∈[k], check if pi = p̅i.  |</p>

    <p class="text-gray-300">|  - Check if hplk = H(ppH, p̅lk1, ..., p̅lkk).  |</p>

    <p class="text-gray-300">|  - Check if hz = H(ppH, x̅1, ..., x̅k).  |</p>

    <p class="text-gray-300">|  5. Else:  |</p>

    <p class="text-gray-300">|  - Check if hplk = H(ppH, hplk1, ..., hplk).  |</p>

    <p class="text-gray-300">|  - Check if hz = H(ppH, hz1, ..., hzk).  |</p>

    <p class="text-gray-300">|  6. Check Vfold(fvk, (Xi)i=1, X, pf) accepts and p = ∏i=1k pi.  |</p>

    <p class="text-gray-300">|  7. If all checks pass, output accept, otherwise reject.  |</p>

    <p class="text-gray-300">Here we describe a helper function  <span class="math">J</span>  for the SNARK prover that exactly mirrors the PCD predicate. In particular, it performs the analogous computation to construct a PCD tree that is  <span class="math">\\varphi_{\\mathsf{pp}_{\\mathsf{H}},\\mathsf{fvk}}</span>  compliant, along with accompanying folding relation witnesses. Informally, we can think of this function as taking in the data labels of children and producing the data labels of the parent.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">This function corresponds exactly to the required function for the Tree Evaluation Problem (Definition 13). That is, when given streaming access to the sequence of leaf values the prover can calculate the values at the root node of the PCD tree using the Tree Evaluation Algorithm (Theorem 13) with  $O(\\log_k(n) \\cdot k \\cdot</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">(\\mathsf{Z}, \\pi, W)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">+</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">J</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">)<span class="math">  space complexity and making  </span>O(n / k)<span class="math">  calls to  </span>J$ .</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">Definition 22 (Tree Evaluation Function). Consider the parameters and algorithms from Definition 21. Here we define a helper function  <span class="math">J</span>  for the prover to compute the data labels for each node of the PCD tree.</p>

    <p class="text-gray-300">|  Jnpk((Zi,πi,Wi)i=1) → (Z,π,W):  |</p>

    <p class="text-gray-300">| --- |</p>

    <p class="text-gray-300">|  1. Parse (ppH,fpk,pkprod,...) ← npk.  |</p>

    <p class="text-gray-300">|  2. Parse ∀i ∈ [k], (pi,hplk,i,hz,i,Xi) ← Zi and (x̅i, x̅i) ← Xi.  |</p>

    <p class="text-gray-300">|  3. Assign ∀i ∈ [k], (p̅lk,i, x̅i, p̅i, μi) ← Ψ(x̅i).  |</p>

    <p class="text-gray-300">|  4. If ∀i ∈ [k], x̅i = Lv(0) and μi = 1: - ∀i ∈ [k], Assign pi ← p̅i.  |</p>

    <p class="text-gray-300">|  - Assign hplk ← H(ppH, p̅lk1, ..., p̅lkk).  |</p>

    <p class="text-gray-300">|  - Assign hz ← H(ppH, x̅1, ..., x̅k).  |</p>

    <p class="text-gray-300">|  5. Else:  |</p>

    <p class="text-gray-300">|  - Assign hplk ← H(ppH, hplk1, ..., hplk).  |</p>

    <p class="text-gray-300">|  - Assign hz ← H(ppH, hz1, ..., hzk).  |</p>

    <p class="text-gray-300">|  6. Assign p ← ∏i=1k pi.  |</p>

    <p class="text-gray-300">|  7. Assign (X,W,pf) ← Pfold(fpk, (Xi,Wi)i=1).  |</p>

    <p class="text-gray-300">|  8. Assign Z ← (p, hplk, hz, X) and loc ← pf.  |</p>

    <p class="text-gray-300">|  9. Assign π ← Pprod(fpk,Z,loc, (Zi,πi)i=1).  |</p>

    <p class="text-gray-300">|  10. Output (Z,π,W).  |</p>

    <p class="text-gray-300">SNARK Construction</p>

    <p class="text-gray-300">Here we describe the SNARK construction for the Plonk arithmetization. At a high level, <span class="math">\\mathcal{I}_{\\mathsf{nark}}</span> produces PCD parameters specialized to <span class="math">\\varphi_{\\mathsf{pp}_{\\mathsf{H}},\\mathsf{fvk}}</span> and Merkle commits to chunks of <span class="math">(\\sigma,\\mathsf{s})</span> in the arithmetization as <span class="math">\\mathsf{hplk}</span>. These commitments will restrict the <span class="math">\\mathcal{P}</span> to the appropriate computation in each leaf. The prover commits to chunks of the extended witness <span class="math">z=(x,w)</span> as <span class="math">\\mathsf{hz}</span> and uses the random oracle to calculate <span class="math">\\alpha,\\beta</span> for the grand product permutation argument. The prover then computes the instance-witness pairs <span class="math">(X,W)</span> for the polynomial relation <span class="math">\\mathcal{R}_{\\mathsf{open}}(\\mathcal{L}_{\\mathsf{x}},\\mathcal{L}_{\\mathsf{e}},\\widehat{f}_{\\alpha,\\beta}^{G})</span> (15) with respect to the leaf map 19 and linear maps 20. The prover then uses the helper function <span class="math">J</span> to calculate the PCD tree. To prove <span class="math">z</span> coincides with some vector <span class="math">(x,w)</span>, the prover sends the first chunk of <span class="math">z^{(1)}</span> and and opens the Merkle Tree commitment at its first index. The SNARK verifier checks that the grand product is <span class="math">1</span>, checks that the merkle commitment <span class="math">\\mathsf{hplk}^{\\prime}</span> is consistent with the commitment <span class="math">\\mathsf{hplk}</span> to <span class="math">(\\sigma,\\mathsf{s})</span> produced in preprocessing, checks that the PCD verifier accepts, rederives <span class="math">\\alpha,\\beta</span>, verifies the final folded leaf relation pair, and then checks that the instance <span class="math">x</span> belongs to the first index of the Merkle Tree commitment <span class="math">\\mathsf{hz}</span> to the value vector. Together, these verify the control merging logic.</p>

    <h4 id="sec-41" class="text-lg font-semibold mt-6">Parameters.</h4>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Let $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> denote the instance size and </span>n<span class="math"> the length of the extended witness </span>z:=(x,w)<span class="math">. We denote a memory parameter </span>m\\in\\mathbb{N}<span class="math"> such that </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq m\\leq n<span class="math">, which determines the memory requirement for the prover and verifier. Additionally, we denote a parallelism parameter </span>k\\in\\mathbb{N}<span class="math"> such that </span>k=O(\\lambda)<span class="math"> is linear in the security parameter. The parameter </span>k$ will also be the arity of the corresponding Merkle commitments and the PCD tree.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">⬇ <span class="math">\\mathcal{G}_{\\mathsf{nark}}(1^{\\lambda})</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run the setup algorithms:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\mathsf{ck}\\leftarrow\\mathsf{Setup}_{\\mathsf{com}}(1^{\\lambda}),\\ \\mathsf{pp}_{\\mathsf{H}}\\leftarrow\\mathsf{Setup}_{\\mathsf{H}}(1^{\\lambda})</span>.</li>

      <li><span class="math">\\mathsf{pp}_{\\mathsf{pcd}}\\leftarrow\\mathcal{G}_{\\mathsf{pcd}}(1^{\\lambda}),\\ \\mathsf{fpp}\\leftarrow\\mathcal{G}_{\\mathsf{Fold}}(1^{\\lambda})</span>.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Output <span class="math">\\mathsf{pp}:=(\\mathsf{ck},\\mathsf{pp}_{\\mathsf{pcd}},\\mathsf{fpp},\\mathsf{pp}_{\\mathsf{H}})</span></li>

    </ol>

    <p class="text-gray-300"><span class="math">\\mathcal{I}_{\\mathsf{nark}}(\\mathsf{pp},(\\sigma,\\mathsf{s},G),m,k)</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse parameters <span class="math">(\\mathsf{ck},\\mathsf{pp}_{\\mathsf{pcd}},\\mathsf{fpp},\\mathsf{pp}_{\\mathsf{H}})\\leftarrow\\mathsf{pp}</span>.</li>

      <li>Parse <span class="math">(\\mathsf{fpk},\\mathsf{fvk})\\leftarrow\\mathsf{fpp}</span>.</li>

      <li>Compute <span class="math">(\\mathsf{pk}_{\\mathsf{pcd}},\\mathsf{vk}_{\\mathsf{pcd}})\\leftarrow\\mathcal{I}_{\\mathsf{pcd}}\\left(\\mathsf{pp}_{\\mathsf{pcd}},\\ \\varphi_{\\mathsf{pp}_{\\mathsf{H}},\\mathsf{fvk}}\\right)</span>.</li>

      <li><span class="math">\\forall i\\in[n/m],\\widehat{\\mathsf{plk}}_{i}:=\\mathsf{Commit}(\\mathsf{ck},(1+m\\cdot(i-1),\\ \\sigma^{\\mathsf{rn}(i,m)},\\ \\mathsf{s}^{\\mathsf{rn}(i,b(m/t))}))</span>.</li>

      <li>Compute <span class="math">\\mathsf{hplk}:=\\mathsf{MT.Commit}_{k}\\left(\\mathsf{pp}_{\\mathsf{H}},\\left(\\widehat{\\mathsf{plk}}_{i}\\right)_{i=1}^{n/m}\\right)</span>.</li>

      <li>Assign <span class="math">\\mathsf{npk}:=(\\mathsf{ck},\\mathsf{pp}_{\\mathsf{H}},\\mathsf{pk}_{\\mathsf{pcd}},\\mathsf{fpk},\\mathsf{hplk},\\sigma,\\mathsf{s},G,m,k)</span>.</li>

      <li>Assign <span class="math">\\mathsf{nvk}:=(\\mathsf{ck},\\mathsf{pp}_{\\mathsf{H}},\\mathsf{vk}_{\\mathsf{pcd}},\\mathsf{hplk},G,m,k)</span>.</li>

      <li>Output <span class="math">(\\mathsf{npk},\\ \\mathsf{nvk})</span>.</li>

    </ol>

    <p class="text-gray-300"><span class="math">\\mathcal{P}_{\\mathsf{nark}}^{\\mathsf{ro}}(\\mathsf{npk},x,w)</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse <span class="math">(\\mathsf{ck},\\mathsf{pp}_{\\mathsf{H}},\\mathsf{pk}_{\\mathsf{pcd}},\\mathsf{fpk},\\mathsf{hplk},\\sigma,\\mathsf{s},G,m,k)\\leftarrow\\mathsf{npk}</span>.</li>

      <li>Assign <span class="math">z\\leftarrow(x,w)</span>.</li>

      <li>Compute <span class="math">\\forall i\\in[n/m],\\ \\overline{z}_{i}:=\\mathsf{Commit}(\\mathsf{ck},z^{\\mathsf{rn}(i,m)})</span>.</li>

      <li>Compute <span class="math">\\mathsf{hz}:=\\mathsf{MT.Commit}_{k}(\\mathsf{pp}_{\\mathsf{H}},\\left(\\overline{z}_{i}\\right)_{i=1}^{n/m})</span>.</li>

      <li>Derive challenges <span class="math">\\alpha,\\beta\\leftarrow\\mathsf{ro}(\\mathsf{hplk},x,\\mathsf{hz})</span>.</li>

      <li>Compute vectors <span class="math">L,R</span> such that</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">L_{1} = (z_{1} + \\alpha + \\beta)</span> and <span class="math">R_{1} = (z_{1} + \\sigma_{1} \\cdot \\alpha + \\beta)</span>.</li>

      <li>For all <span class="math">i \\in \\{2, \\dots, n\\}</span>, <span class="math">L_i = L_{i-1} \\cdot [(z_i + i \\cdot \\alpha) + \\beta]</span> and <span class="math">R_i = R_{i-1} \\cdot [(z_i + \\sigma_i \\cdot \\alpha) + \\beta]</span>.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Assign <span class="math">\\forall i \\in [n/m]</span>,</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">p_i := L_n^{\\mathsf{m}(i,m)} / R_n^{\\mathsf{m}(i,m)}</span>.</li>

      <li><span class="math">W_i \\gets (1 + m \\cdot (i - 1),\\sigma^{\\mathsf{m}(i,m)},\\mathsf{s}^{\\mathsf{m}(i,b(m/t))},z^{\\mathsf{m}(i,m)},L^{\\mathsf{m}(i,m)},R^{\\mathsf{m}(i,m)},p_i,1).</span></li>

      <li><span class="math">X_{i}\\coloneqq (\\mathcal{L}_{\\mathrm{x}}(W_{i}),\\mathcal{L}_{\\mathrm{c}}(\\widehat{f}_{\\alpha ,\\beta}^{G}(W_{i}))).</span></li>

      <li><span class="math">Z^{(i)}\\coloneqq (p_i,\\bot ,\\bot ,X_i).</span></li>

      <li><span class="math">m_{i}\\gets (Z^{(i)},\\bot ,W_{i})</span></li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Compute <span class="math">(Z,\\pi_{\\mathsf{pcd}},W)\\gets \\mathsf{TreeEval}(J_{\\mathsf{npk}},(m_i)_{i = 1}^{n / m})</span></li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Prove <span class="math">\\pi_{\\mathsf{MT}}\\gets \\mathsf{MT.Open}_{\\&amp;amp;}(\\mathsf{pp}_{\\mathsf{H}},\\{1\\},\\{\\overline{z}_i\\}_{i = 1}^{n / m})</span></li>

    </ol>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Output proof <span class="math">\\pi \\coloneqq (\\mathsf{hz},\\mathsf{Z},\\pi_{\\mathsf{pcd}},W,z^{\\mathsf{m}(1,m)},\\pi_{\\mathsf{MT}})</span></li>

    </ol>

    <p class="text-gray-300"><span class="math">\\mathcal{V}_{\\mathrm{nark}}^{\\mathrm{ms}}(\\mathrm{nvk},x,\\pi)</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse <span class="math">(\\mathsf{ck},\\mathsf{pp}_{\\mathsf{H}},\\mathsf{vk}_{\\mathsf{pcd}},\\mathsf{hplk},G,m,k)\\gets \\mathsf{nvk}</span></li>

      <li>Parse proof <span class="math">(\\mathsf{hz},\\mathsf{Z},\\pi_{\\mathsf{pcd}},W,z^{(1)},\\pi_{\\mathsf{MT}})\\gets \\pi</span></li>

      <li>Parse <span class="math">(p, \\mathsf{hplk}&#x27;, \\mathsf{hz}&#x27;, X) \\gets Z.</span></li>

      <li>Check if <span class="math">(p, \\mathsf{hplk}&#x27;, \\mathsf{hz}&#x27;) = (1, \\mathsf{hplk}, \\mathsf{hz})</span>.</li>

      <li>Check if <span class="math">\\mathcal{V}_{\\mathrm{pcd}}(\\mathsf{vk}_{\\mathrm{pcd}},\\mathsf{Z},\\pi_{\\mathrm{pcd}})</span> accepts.</li>

      <li>Derive challenges <span class="math">\\alpha, \\beta \\gets \\mathsf{ro}(\\mathsf{hplk}, x, \\mathsf{hz})</span>.</li>

      <li>Check if <span class="math">(X,W)\\in \\mathcal{R}_{\\mathrm{open}}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{c}},\\widehat{f}_{\\alpha ,\\beta}^{G})</span> accepts.</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">8. Check if $x = (z_1^{(1)},\\ldots ,z_{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}^{(1)})$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Compute <span class="math">\\overline{z}_1\\gets \\mathsf{Commit}(\\mathsf{ck},z^{(1)})</span></li>

      <li>Check if <span class="math">\\mathsf{MT.Verify}_{\\&amp;amp;}(\\mathsf{pp}_{\\mathsf{H}},\\mathsf{hz},\\{1\\},\\overline{z}_1,\\pi_{\\mathsf{MT}})</span> accepts.</li>

      <li>Output accept if all checks pass otherwise reject.</li>

    </ol>

    <p class="text-gray-300">Remark 5 (Optimizations). For simplicity, Construction 2 requires the prover to send a Merkle tree opening proof <span class="math">\\pi_{\\mathsf{MT}}</span> for the first vector commitment <span class="math">\\overline{z}_1</span> which corresponds the first chunk of <span class="math">z</span>. With minor changes, we remark that the Merkle tree opening proof can be omitted from the SNARK proof <span class="math">\\pi</span>; as such, the verifier will not need to check the corresponding Merkle tree opening proof. Intuitively, the prover already verifies this Merkle tree opening proof implicitly by recomputing the whole Merkle tree in the PCD computation. Hence, it suffices to just modify the PCD predicate <span class="math">\\varphi_{\\mathsf{pp}_{\\mathsf{H}},\\mathsf{fvk}}</span> (Definition 21) to additionally propagate the first commitment <span class="math">\\overline{z}_1</span> up the tree by including an additional commitment in the PCD message <span class="math">Z</span>, which now has the following form: <span class="math">Z := (p, \\mathsf{hplk}, \\mathsf{hz}, X, \\overline{z})</span>. Then, the verifier can just check the vector commitment opening <span class="math">z^{(1)} := z^{\\mathsf{m}(1,m)}</span> with respect to the commitment <span class="math">\\overline{z}_1 \\in Z</span>. We expand upon further optimization strategies in Remark 6, in our discussion of the practical efficiency of the SNARK.</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Theorem 5. Let $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">&lt; m = \\mathsf{poly}(\\lambda) \\ll n<span class="math">, </span>k = O(\\lambda) \\in \\mathbb{N}<span class="math"> be a memory and arity parameter. Further, let </span>\\mathbb{F}<span class="math"> be a field such that </span></th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\approx 2^{\\lambda}$ and the algorithms:</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>(Setupcom, Commit) be a binding, linearly homomorphic, and succinct commitment scheme (Definition 7) for vectors over <span class="math">\\mathbb{F}</span>,</li>

      <li>(SetupH, H) be a collision-resistant hash function (Definition 6),</li>

      <li>(MT.Commit, MT.Open, MT.Verify) be the merkle tree commitment scheme (Definition 8) instantiated with arity <span class="math">k</span> and the prior hash function,</li>

      <li><span class="math">(\\mathcal{G}_{\\mathrm{Fold}}, \\mathcal{P}_{\\mathrm{Fold}}, \\mathcal{V}_{\\mathrm{Fold}})</span> be a secure folding scheme (Definition 9) for polynomial opening relations (Definition 15) in the standard model,</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>and  <span class="math">(\\mathcal{G}_{\\mathrm{pcd}},\\mathcal{I}_{\\mathrm{pcd}},\\mathcal{P}_{\\mathrm{pcd}},\\mathcal{V}_{\\mathrm{pcd}})</span>  be a secure PCD scheme (Definition 12).</li>

    </ul>

    <p class="text-gray-300">Then, Construction 2 is a secure SNARK (Definition 5) for  <span class="math">\\Re_{\\mathrm{plk}}</span>  (Definition 18).</p>

    <p class="text-gray-300">Proof Sketch. Completeness. Observe that the SNARK prover essentially computes the work of the NARK verifier from Construction 1. In particular, the construction of the PCD predicate Definition 21 recomputes the commitments to the plonkish arithmetization  <span class="math">(\\sigma, \\mathsf{s})</span>  and the extended witness  <span class="math">z = (x, w)</span> . The helper function Definition 22 exactly mirrors the computation required by the PCD predicate. Furthermore, by folding instances of Definition 19, the SNARK prover essentially proves the gate polynomial checks and the permutation product checks from the NARK verifier. Thus, completeness follows almost immediately from the completeness of the NARK (Theorem 4) and the respective sub-algorithms.</p>

    <p class="text-gray-300">Succinctness. The proof consists of a constant number of Merkle commitments (hash values), a Merkle opening proof (consisting of  <span class="math">O(k \\log_k(n / m))</span>  hashes), an instance-witness pair  <span class="math">(X, W)</span>  for the leaf map (a constant number of commitments and  <span class="math">O(m)</span>  field elements), a chunk opening  <span class="math">(z^{(1)}</span>  of size  <span class="math">m</span> ), and a PCD proof (linear in the predicate complexity). Thus, the proof size is  <span class="math">O(m + k \\log_k(n / m)) \\ll O(n)</span> , which is sublinear. Since  <span class="math">k = O(\\lambda)</span> , if  <span class="math">m = O_{\\lambda}(1)</span> , then the proof size is  <span class="math">O_{\\lambda}(1)</span> . We give a more explicit estimate in Section 6.4.</p>

    <p class="text-gray-300">Knowledge soundness. We construct an extractor for the SNARK, by constructing a series of adversaries and sub-extractors by applying the knowledge soundness of the PCD scheme and folding scheme. In particular, we construct a PCD adversary from the SNARK adversary. By invoking the knowledge soundness of the PCD scheme, we are able to extract a full PCD graph  <span class="math">\\mathsf{T}</span>  that satisfies the PCD predicate  <span class="math">\\varphi_{\\mathsf{ppu},\\mathsf{fvk}}</span> . From this PCD extractor, we recursively construct a series of folding adversaries and extractors for every layer of the PCD graph. Once, we obtain the folding witnesses at the base of the graph, we can parse them to extract the witness for the SNARK adversary. Correctness of the extractor will follow by knowledge soundness of the PCD and folding schemes, the binding of the Merkle and commitment schemes, and the advantage of adversaries for Lemma 5 and the NARK from Construction 1. We defer the full proof to Appendix A.6</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Prover native</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Prover native (per leaf)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Prover native (per node)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Prover recursive (per node)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Prover memory</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Verifier work</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Proof size</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">G-ops: O(n)</td>

            <td class="px-3 py-2 border-b border-gray-700">G-ops: O(m)</td>

            <td class="px-3 py-2 border-b border-gray-700">G-ops: O(km)</td>

            <td class="px-3 py-2 border-b border-gray-700">G-ops: O(kd)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(k(m+k)·logk(n/m))</td>

            <td class="px-3 py-2 border-b border-gray-700">G-ops: O(m+k)</td>

            <td class="px-3 py-2 border-b border-gray-700">O(m+k) F+ O(1) G</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">F-ops: O(n)</td>

            <td class="px-3 py-2 border-b border-gray-700">F-ops: O(m)</td>

            <td class="px-3 py-2 border-b border-gray-700">F-ops: O(km)</td>

            <td class="px-3 py-2 border-b border-gray-700">F-ops: O(k)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">F-ops: O(m+k)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Hash: O(n/m)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">Hash: O(k)</td>

            <td class="px-3 py-2 border-b border-gray-700">Hash: O(k)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

            <td class="px-3 py-2 border-b border-gray-700">Hash: O(</td>

            <td class="px-3 py-2 border-b border-gray-700">x</td>

            <td class="px-3 py-2 border-b border-gray-700">)</td>

            <td class="px-3 py-2 border-b border-gray-700"></td>

          </tr>

        </tbody>

      </table>

    </div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Fig. 7: The asymptotic efficiency of our SNARK construction, when instantiated as in Section 6.4 with the folding scheme from Section 5.1. The number of leaf instances is  <span class="math">n / m</span>  and the number of nodes in the PCD tree is  <span class="math">\\frac{(n / m) - 1}{k - 1}</span> . Native prover costs refers to the number of native operations performed by the prover; Recursive prover costs refers to the number of operations that each PCD node needs to simulate in the recursive circuit where  <span class="math">n</span>  is the length of the extended witness;  <span class="math">m</span>  is the memory parameter such that  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\leq m \\leq n<span class="math"> ;  </span>k = O(\\lambda)<span class="math">  is the arity of the PCD tree;  </span>d = 2<span class="math">  is the degree of the gate polynomial. G-ops denotes elliptic curve scalar multiplications; F-ops denotes field multiplications; Hash is a 2-to-1 hash function, which outputs  </span>\\mathbb{F}$  elements.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">In this section, we describe both the asymptotic performance and concrete performance estimate of our SNARK construction, when instantiated with particular choices of PCD and folding schemes, along with several optimizations.</p>

    <p class="text-gray-300">Instantiation. When estimating the performance of our SNARK, we have to pick a specific instantiation of a PCD scheme and a folding (accumulation) scheme. For our PCD scheme, we use the generic PCD construction of <em>[BCL^{+}21]</em>, which requires a generic folding scheme to be instantiated. We use our generalization of the folding (accumulation) scheme (Section 5) of <em>[x23, x1, x18]</em> to instantiate this generic folding scheme. We limit our attention to Plonkish circuits with gate degree <span class="math">d=2</span> (specifically, only addition and multiplication gates). We denote the choice of memory parameter by <span class="math">m</span> and PCD tree arity by <span class="math">k</span>.</p>

    <h6 id="sec-43" class="text-base font-medium mt-4">Remark 6 (Optimizations & Evaluation Strategy)</h6>

    <p class="text-gray-300">As noted in Remark 5, we can omit the Merkle tree inclusion proof for the first witness commitment, <span class="math">\\overline{z}^{(1)}</span> from the overall SNARK proof. Furthermore, we can omit the opening <span class="math">z^{(1)}:=z^{\\mathsf{m}(1,m)}</span> to this commitment by setting the first chunk of the extended witness <span class="math">z</span> to a canonical chunk consisting of <span class="math">z^{(1)}:=(x,0)</span> (i.e. padding the first chunk with zeroes). We use the TreeEval algorithm (Theorem 1) to evaluate the PCD tree in a streaming fashion, which allows us to reduce the peak memory usage of the prover. For this instantiation along with these optimizations, we describe the asymptotic efficiency of our SNARK construction in Figure 7.</p>

    <p class="text-gray-300">Evaluation methodology. For concrete performance benchmarks, we bootstrap the existing implementation of Nova <em>[x23, x25]</em> to estimate the cost of our SNARK construction. Their implementation instantiates the Nova IVC scheme over a generic 2-cycle of elliptic curves, which is described in <em>[x18]</em>. Here, we use the Pallas-Vesta cycle of curves <em>[x20]</em>. As a result, we must factor in the cost of the PCD scheme over this cycle; a similar strategy is used in the implementation of <em>[BCL^{+}21, x16]</em>.</p>

    <p class="text-gray-300">In particular, we estimate three core circuits: a leaf circuit which constrains the leaf polynomial map relation (Definition 19), a primary circuit which constrains the PCD predicate (Definition 21) and folds secondary circuit instances, and a secondary circuit which only folds primary circuit instances. Figure 8 shows an estimate of the number of constraints in each of these circuits for different values of memory parameter <span class="math">m</span> and arity parameter <span class="math">k</span>. These numbers were obtained by synthesizing the circuits using <em>[x25]</em> and recording number of constraints produced in their respective R1CS shapes.</p>

    <p class="text-gray-300">Using our modified Nova implementation, we benchmark the time to prove and fold instances of each of these circuits, and compute the memory required to do so. This allows us to estimate the total time and peak memory required for our SNARK instantiated with a variety of parameters.The experiments are conducted on a MacBook Pro (Apple M2 Pro Chip, 16 GB).</p>

    <p class="text-gray-300">Evaluation. We aim to evaluate the scalability of the Mangrove prover over increasing instance sizes (the number of deg-2 constraints). We report the effects of scaling instance size on the proving time, memory usage, and proof size while tuning the memory parameter <span class="math">m</span> and PCD tree arity parameter <span class="math">k</span> of the Mangrove prover.</p>

    <h6 id="sec-44" class="text-base font-medium mt-4">Prover time</h6>

    <p class="text-gray-300">Our benchmarks indicate the Mangrove prover is competitive in proving time to leading monolithic SNARKs (that do not target memory-efficiency). For arity parameter <span class="math">k=4</span>, and instance size <span class="math">2^{24}</span>, the prover takes approximately 2 minutes (with 390 MB memory). In comparison, to prove the same sized instance, the Spartan SNARK <em>[x26]</em> prover takes <span class="math">\\approx 10</span> minutes and the Gemini streaming SNARK <em>[x6]</em> takes <span class="math">\\approx 19</span> minutes with logarithmic passes. Next, we consider a larger instance size of <span class="math">2^{32}</span>. Monolithic</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">PCD arity (k)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Primary circuit (# constraints)</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Secondary circuit (# constraints)</th>

          </tr>

        </thead>

        <tbody>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">4</td>

            <td class="px-3 py-2 border-b border-gray-700">94969</td>

            <td class="px-3 py-2 border-b border-gray-700">38705</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">8</td>

            <td class="px-3 py-2 border-b border-gray-700">205047</td>

            <td class="px-3 py-2 border-b border-gray-700">75817</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">16</td>

            <td class="px-3 py-2 border-b border-gray-700">423051</td>

            <td class="px-3 py-2 border-b border-gray-700">148185</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">32</td>

            <td class="px-3 py-2 border-b border-gray-700">856907</td>

            <td class="px-3 py-2 border-b border-gray-700">292619</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">Memory parameter (m)</td>

            <td class="px-3 py-2 border-b border-gray-700">Leaf circuit (# constraints)</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">---</td>

            <td class="px-3 py-2 border-b border-gray-700">---</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">3072</td>

            <td class="px-3 py-2 border-b border-gray-700">7174</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">12288</td>

            <td class="px-3 py-2 border-b border-gray-700">28678</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">49152</td>

            <td class="px-3 py-2 border-b border-gray-700">114694</td>

          </tr>

          <tr>

            <td class="px-3 py-2 border-b border-gray-700">196608</td>

            <td class="px-3 py-2 border-b border-gray-700">458758</td>

          </tr>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">!<a href="img-7.jpeg">img-7.jpeg</a> Fig. 8: Estimates of the number of constraints in the primary and secondary circuits for different values of arity parameter  <span class="math">k</span>  (left), and the number of constraints in the leaf circuit for different values of memory parameter  <span class="math">m</span>  (right). Fig. 9: Estimated proving time for prover for different sized Plonkish instances with memory parameter  <span class="math">m</span>  and PCD tree arity  <span class="math">k</span> .</p>

    <p class="text-gray-300">SNARKs like Spartan incur prohibitive memory usage for instances of this size; indeed, prover running time is not reported. Streaming provers can handle instances of this size: Mangrove takes  <span class="math">\\approx 8</span>  hours with  <span class="math">800\\mathrm{MB}</span>  memory usage, while Gemini takes over 80 hours.</p>

    <p class="text-gray-300">Figure 9 provides more comparison points. Notice that the prover time improves significantly with increases to the memory parameter  <span class="math">m</span>  as larger memory parameter means less leaf proofs and PCD nodes. Higher PCD arity also improves prover time by reducing PCD nodes, but the savings are not large as the majority of the work is done at the leaf layer.</p>

    <p class="text-gray-300">Prover memory usage. The prover memory usage is tuned with the memory parameter  <span class="math">m</span> . The effect of which is shown in Figure 10. At a high level, memory usage grows in arity parameter  <span class="math">k</span> , as the prover must store all children when proving a parent PCD node.</p>

    <p class="text-gray-300">Proof size. The size of Mangrove proofs are dominated by the size of folding witnesses for the leaf, primary, and secondary circuits at the root of the PCD graph, which depend only on the memory parameter  <span class="math">m</span>  and arity  <span class="math">k</span> . With the optimizations described in Remark 6, the proof size is independent of the original instance size. For the configurations described above, the Mangrove prover produces a proof of size 34 MB. Figure 11 (left) provides proof sizes for other configurations. We also note that one can further compress proof size by applying the standard approach of wrapping the proof within a SNARK as done in [KST22, Nov22]. When compressing with Spartan [Set20], the above proof size drops to 12 KB, shown in Figure 11 (right). The</p>

    <p class="text-gray-300">!<a href="img-8.jpeg">img-8.jpeg</a> Fig. 10: Estimated peak memory usage for prover for different sized Plonkish instances with memory parameter  <span class="math">m</span>  and PCD tree arity  <span class="math">k</span> .</p>

    <p class="text-gray-300">!<a href="img-9.jpeg">img-9.jpeg</a> Fig. 11: Proof size (left) and compressed proof size with Spartan SNARK (right) for memory parameter  <span class="math">m</span>  and PCD tree arity parameter  <span class="math">k</span> .</p>

    <p class="text-gray-300">Spartan compression step for all parameters took less than one minute and is insignificant compared to other proving costs.</p>

    <p class="text-gray-300">We can readily extend our SNARK (Construction 2) to support Lookups as described in [Hab22] and Commit &amp; Prove [CFQ19].</p>

    <p class="text-gray-300">Here we define an extension of the Plonk arithmetization defined in Section 6 that allows us to additionally encode lookup tables. The functionality of lookup tables that we are targeting is checking that for a list of witness-computed elements  <span class="math">A \\in \\mathbb{F}^n</span>  and a fixed table of elements  <span class="math">\\mathsf{T} \\in \\mathbb{F}^{\\tau}</span> , we have that the set of elements in  <span class="math">A</span>  is a subset of the set of elements in  <span class="math">\\mathsf{T}</span> :</p>

    <div class="my-4 text-center"><span class="math-block">\\left\\{a: a \\in A \\right\\} \\subseteq \\left\\{t: t \\in \\mathsf {T} \\right\\}.</span></div>

    <p class="text-gray-300">To incorporate the above into our arithmetization, we loosely follow the treatment of Chen et al. [CBBZ23].</p>

    <p class="text-gray-300"><strong>Definition 23 (Plonk Arithmetization with Lookup Tables).</strong> Let <span class="math">b, c, t, m, n, \\tau \\in \\mathbb{N}</span> such that <span class="math">c = n / t \\in \\mathbb{N}</span> and <span class="math">\\mathbb{F}</span> be a finite field. Define a range function <span class="math">\\mathsf{rn}(i, k) := [(i - 1) \\cdot k + 1, i \\cdot k]</span>. A plonk arithmetization with lookup tables is a tuple <span class="math">\\mathsf{plook} := (\\sigma, \\mathsf{s}, G, \\mathsf{T}, G_{\\mathsf{T}})</span> where <span class="math">\\sigma \\in \\mathbb{F}^n</span> is a permutation vector on <span class="math">[n]</span> (i.e. <span class="math">[n] = \\{\\sigma_i\\}_{i \\in [n]}</span>), <span class="math">\\mathsf{s} \\in \\mathbb{F}^{c \\cdot b}</span> is a selector vector, <span class="math">G: \\mathbb{F}^b \\times \\mathbb{F}^t \\to \\mathbb{F}</span> is a gate polynomial, <span class="math">\\mathsf{T} \\in \\mathbb{F}^\\tau</span> is a table vector, and <span class="math">G_{\\mathsf{T}}: \\mathbb{F}^b \\times \\mathbb{F}^t \\to \\mathbb{F}</span> is a table gate polynomial.</p>

    <p class="text-gray-300">A value vector <span class="math">z = (x \\in \\mathbb{F}^m, w \\in \\mathbb{F}^{n - m})</span> and <span class="math">\\mathsf{tid} \\in \\mathbb{F}^c</span> is a table index vector over <span class="math">[\\tau]</span> satisfies a plonk arithmetization with lookup tables <span class="math">(\\sigma, \\mathsf{s}, G, \\mathsf{T}, G_{\\mathsf{T}})</span> if</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><strong>Global Copy Constraints</strong> and <strong>Local Gate Constraints</strong>: The plonk arithmetization from Section 6.1 is satisfied, <span class="math">(\\mathsf{plk} = (\\sigma, \\mathsf{s}, G), x, w) \\in \\mathfrak{R}_{\\mathsf{plk}}</span>.</li>

      <li><strong>Lookup Constraints</strong>: For all <span class="math">i \\in [c]</span>, <span class="math">G_{\\mathsf{T}}\\left(\\mathsf{s}^{\\mathsf{rn}(i,b)}, z^{\\mathsf{rn}(i,t)}\\right) = \\mathsf{T}_{\\mathsf{tid}_i}</span>.</li>

    </ul>

    <p class="text-gray-300">We define the following index relation <span class="math">\\mathfrak{R}_{\\mathrm{plook}}</span>:</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathfrak{R}_{\\text{plook}} := \\left\\{ \\begin{array}{l} \\left( \\text{plook}, x \\in \\mathbb{F}^m, \\left( w \\in \\mathbb{F}^{n - m}, \\mathsf{tid} \\in \\mathbb{F}^c \\right) \\right</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\quad \\text{For } z := (x, w), \\\\ \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad (z, \\mathsf{tid}) \\text{ satisfies } \\mathsf{plook} \\end{array} \\right\\}</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300"><strong>Remark 7.</strong> We can further generalize <span class="math">\\mathfrak{R}_{\\mathrm{plook}}</span> to support element vector lookups where the table gate polynomial is now a polynomial map <span class="math">G_{\\mathsf{T}}: \\mathbb{F}^b \\times \\mathbb{F}^t \\to \\mathbb{F}^\\nu</span> and the table vector contains rows of <span class="math">\\nu</span> elements, <span class="math">\\mathsf{T} \\in \\mathbb{F}^{\\tau \\times \\nu}</span>.</p>

    <p class="text-gray-300">The basis of our construction is the Haböck [Hab22] lookup argument which we chunk into uniform components to incorporate into our SNARK. The main technical lemma is Lemma 3 which states that if <span class="math">(a_i)_{i=1}^n</span> and <span class="math">(t_i)_{i=1}^\\tau</span> are sequences of elements in <span class="math">\\mathbb{F}</span>, then, <span class="math">\\{a_i\\}_{i=1}^n \\subseteq \\{t_i\\}_{i=1}^\\tau</span> if and only if there exists a sequence of field elements <span class="math">(m_i)_{i=1}^\\tau</span> (where <span class="math">m_i</span> is the multiplicity of <span class="math">t_i</span> in the sequence <span class="math">(a_i)_{i=1}^n</span>), such that</p>

    <div class="my-4 text-center"><span class="math-block">\\sum_{i=1}^n \\frac{1}{X - a_i} = \\sum_{i=1}^\\tau \\frac{m_i}{X - t_i}.</span></div>

    <p class="text-gray-300">As in our NARK for <span class="math">\\mathfrak{R}_{\\mathrm{plk}}</span> (Section 6.2) to check the permutation argument of the global copy constraints, we use a randomized lookup argument in which the prover commits to its witness elements, and a verifier random challenge <span class="math">\\alpha \\gets \\mathbb{F}</span> is used to check the following, where <span class="math">\\mathsf{mul} \\in \\mathbb{F}^\\tau</span> is a vector encoding the multiplicities provided by the prover (it can be computed by counting the multiplicities in the table index vector <span class="math">\\mathsf{tid}</span>):</p>

    <div class="my-4 text-center"><span class="math-block">\\sum_{i=1}^c \\frac{1}{\\alpha - G_{\\mathsf{T}} \\left(\\mathsf{s}^{\\mathsf{rn}(i,b)}, z^{\\mathsf{rn}(i,t)}\\right)} = \\sum_{i=1}^\\tau \\frac{\\mathsf{mul}_i}{\\alpha - \\mathsf{T}_i}.</span></div>

    <p class="text-gray-300">Again analogous to our chunking of the permutation argument grand product, each of these grand summations can be chunked via the memory parameter as well by computing partial summations. Instead of rewriting our SNARK construction for <span class="math">\\mathfrak{R}_{\\mathrm{plk}}</span> to include the chunks for the lookup argument, we will simply describe the modifications needed for each component of the pipeline.</p>

    <p class="text-gray-300"><strong>Modifications to the NARK.</strong> First, consider the NARK construction in Section 6.2 from which the SNARK is derived from. We describe the changes to build a NARK for <span class="math">\\mathfrak{R}_{\\mathrm{plook}}</span>. Notice that for the global</p>

    <p class="text-gray-300">4Informally, c is the number of gates and t is the input arity of each gate.</p>

    <p class="text-gray-300">46</p>

    <p class="text-gray-300">copy constraints permutation argument, the prover witness is already committed to, and verifier challenges <span class="math">\\alpha, \\beta</span> are computed. The witness commitment works for the lookup argument as well, and the verifier challenges can be reused.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The indexer <span class="math">\\mathcal{I}_{\\mathrm{nark}}</span> is updated appropriately to include the additional components of the <span class="math">\\Re_{\\mathrm{plook}}</span> index: <span class="math">\\mathsf{npk} := (\\mathsf{ck}, \\sigma, \\mathsf{s}, G, \\mathsf{T}, G_{\\mathsf{T}})</span> and <span class="math">\\mathsf{nvk} := (\\mathsf{ck}, \\sigma, \\mathsf{s}, G, \\mathsf{T}, G_{\\mathsf{T}})</span>.</li>

      <li>The prover <span class="math">\\mathcal{P}_{\\mathrm{nark}}</span> computes the multiplicity vector <span class="math">\\mathsf{mul} \\in \\mathbb{F}^{\\tau}</span> from <span class="math">\\mathsf{tid} \\in \\mathbb{F}^{c}</span>. The prover computes intermediate values for the summations <span class="math">L&#x27; \\in \\mathbb{F}^{c}</span> and <span class="math">R&#x27; \\in \\mathbb{F}^{\\tau}</span> as follows and outputs <span class="math">\\pi := (z, L, R, L&#x27;, R&#x27;, \\mathsf{mul})</span>.</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For <span class="math">i \\in [c]</span>,</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">L_i&#x27; = \\frac{1}{\\alpha - G_{\\mathsf{T}} \\left(\\mathsf{s}^{\\mathsf{m}(i,b)}, z^{\\mathsf{m}(i,t)}\\right)}.</span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>For <span class="math">i \\in [\\tau]</span>,</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">R_i&#x27; = \\frac{\\mathsf{mul}_i}{\\alpha - \\mathsf{T}_i}.</span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The verifier <span class="math">\\mathcal{V}_{\\mathrm{nark}}</span> checks that <span class="math">L&#x27;</span> and <span class="math">R&#x27;</span> are constructed as above and then checks the grand summation equality:</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\sum_{i=1}^{c} L_i&#x27; = \\sum_{i=1}^{\\tau} R_i&#x27;.</span></div>

    <p class="text-gray-300">Modifications to the leaf relation. Next, we describe changes to the leaf relation from Section 6.3 representing the computation for the uniform chunk as a polynomial map.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The polynomial map defined in Definition 19 is extended to take chunks of <span class="math">\\mathsf{T}, L&#x27;, R&#x27;, \\mathsf{mul}</span> and <span class="math">p&#x27; \\in \\mathbb{F}</span> representing the partial summation. Note that from our previous presentation, with memory parameter <span class="math">m</span> and plonk instance size <span class="math">n</span>, we have <span class="math">n/m</span> chunks. However, now the table of size <span class="math">\\tau</span> is also chunked into <span class="math">n/m</span> chunks each of size <span class="math">m\\tau/n</span>. We assume, <span class="math">\\tau = O(n)</span> so that chunks remain of size <span class="math">O(m)</span>. We add the following constraints to <span class="math">f_{\\alpha,\\beta}^{G,G_{\\mathsf{T}}}</span> giving us a polynomial map <span class="math">f_{\\alpha,\\beta}^{G,G_{\\mathsf{T}}} : \\mathbb{F}^{4m + (b + 1)(m/t) + (3m\\tau/n) + 3} \\to \\mathbb{F}^{2m + (2m/t) + (m\\tau/n) + 2}</span>:</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\forall j \\in [m/t], L_j&#x27; \\cdot \\left(\\alpha - G_{\\mathsf{T}} \\left(\\mathsf{s}^{\\mathsf{m}(j,b)}, z^{\\mathsf{m}(j,t)}\\right)\\right) = 1, $$ $$ \\forall j \\in [m\\tau/n], R_j&#x27; \\cdot (\\alpha - \\mathsf{T}_j) = \\mathsf{mul}_j, $$ $$ \\sum_{j=1}^{m/t} L_j&#x27; - \\sum_{j=1}^{m\\tau/n} R_j&#x27; = p&#x27;.</span></div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The leaf linear map <span class="math">\\mathcal{L}_x</span> from Definition 20 includes <span class="math">\\mathsf{T}</span> in <span class="math">\\overline{\\mathsf{plk}}</span>, includes <span class="math">L&#x27;, R&#x27;, \\mathsf{mul}</span> in <span class="math">\\overline{w}</span>, and passes <span class="math">p&#x27;</span> directly. The projection <span class="math">\\psi</span> includes <span class="math">\\mathsf{T}</span> and <span class="math">p&#x27;</span> and the analogous updates are made to <span class="math">\\mathcal{L}_x&#x27;</span>. The projection <span class="math">\\Psi</span> includes <span class="math">p&#x27;</span>.</li>

    </ul>

    <p class="text-gray-300">Remark 8 (Achieving perfect completeness). The above constraints in the polynomial map <span class="math">f_{\\alpha,\\beta}^{G,G_{\\mathsf{T}}}</span> does not have perfect completeness. If <span class="math">\\alpha = G_{\\mathsf{T}}\\left(\\mathsf{s}^{\\mathsf{m}(j,b)}, z^{\\mathsf{m}(j,t)}\\right)</span> for some <span class="math">j \\in [m/t]</span> or <span class="math">\\alpha = T_j</span> for some <span class="math">j \\in [m\\tau/n]</span>, the left hand side of the equations will be zeros and the constraints won't be satisfied anymore. To achieve perfect completeness, we can set <span class="math">L_j&#x27;</span> and <span class="math">R_j&#x27;</span> to zeros in the this bad event, and change the constraints to <span class="math-block"> \\forall j \\in [m/t], \\left(\\alpha - G_{\\mathsf{T}} \\left(\\mathsf{s}^{\\mathsf{m}(j,b)}, z^{\\mathsf{m}(j,t)}\\right)\\right) \\cdot \\left(L_j&#x27; \\cdot \\left(\\alpha - G_{\\mathsf{T}} \\left(\\mathsf{s}^{\\mathsf{m}(j,b)}, z^{\\mathsf{m}(j,t)}\\right)\\right) - 1\\right) = 0, </span> <span class="math-block"> \\forall j \\in [m\\tau/n], (\\alpha - \\mathsf{T}_j) \\cdot \\left(R_j&#x27; \\cdot (\\alpha - \\mathsf{T}_j) - \\mathsf{mul}_j\\right) = 0. </span></p>

    <p class="text-gray-300">5The vectors <span class="math">L,R\\in \\mathbb{F}^n</span> are defined in Construction 1.</p>

    <p class="text-gray-300">This ensures that either the original constraints hold or the bad event described previously happens.</p>

    <p class="text-gray-300">Modifications to the PCD predicate. We only make minimal changes to the PCD predicate in Section 6.3 given the above definitions for the leaf relation.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>In the base case check for strict leaf instances (step 6), in addition to checking the partial product <span class="math">p</span> matches, the the partial summation <span class="math">p^{\\prime}</span> is also checked to match.</li>

      <li>The propagation of the partial summation <span class="math">p^{\\prime}=\\sum_{i=1}^{k}p_{i}^{\\prime}</span> is checked.</li>

    </ul>

    <p class="text-gray-300">Analogous modifications are also made to the prover helper function <span class="math">J_{\\mathsf{npk}}</span>.</p>

    <p class="text-gray-300">Modifications to the final SNARK construction. The changes to the SNARK protocol mirror those already described for the NARK.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The indexer <span class="math">\\mathcal{I}_{\\mathsf{nark}}</span> includes chunks of <span class="math">\\mathsf{T}^{\\mathsf{m}(i,m\\tau/n)}</span> in the chunk index commitments <span class="math">\\overline{\\mathsf{plk}}_{i}</span> and includes the table gate polynomial <span class="math">G_{\\mathsf{T}}</span> in <span class="math">\\mathsf{npk}</span> and <span class="math">\\mathsf{nvk}</span>.</li>

      <li>The prover <span class="math">\\mathcal{P}_{\\mathsf{nark}}</span> computes <span class="math">\\mathsf{mul},L^{\\prime},R^{\\prime}</span> as before and for each chunk, for <span class="math">i\\in[n/m]</span>,</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Computes the partial summation, <span class="math">p_{i}^{\\prime}=\\sum_{j=1}^{m/t}L_{j}^{\\prime\\mathsf{m}(i,m/t)}-\\sum_{j=1}^{m\\tau/n}R_{j}^{\\prime\\mathsf{m}(i,m\\tau/n)}</span>.</li>

      <li>Includes in <span class="math">W_{i}</span>, the partial summation and chunked vectors:</li>

    </ul>

    <p class="text-gray-300"><span class="math">(p_{i}^{\\prime},\\mathsf{T}^{\\mathsf{m}(i,m\\tau/n)},L^{\\prime\\mathsf{m}(i,m/t)},R^{\\prime\\mathsf{m}(i,m\\tau/n)},\\mathsf{mul}^{\\mathsf{m}(i,m\\tau/n)})\\,.</span></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Includes partial summation <span class="math">p_{i}^{\\prime}</span> in <span class="math">\\mathsf{Z}^{(i)}</span>.</li>

      <li>The verifier <span class="math">\\mathcal{V}_{\\mathsf{nark}}</span> is unchanged aside from using the modified leaf polynomial relation and linear maps.</li>

    </ul>

    <p class="text-gray-300">Implications of modifications. The sketch of knowledge soundness for the above modifications follows exactly the same as for the base SNARK. The partial summations added to the PCD compute exactly the grand summation check of the NARK of which the soundness follows from the Haböck lookup argument <em>[x10]</em> and Lemma 3.</p>

    <p class="text-gray-300">The prover efficiency remains asymptotically the same as before. As discussed, because the Haböck lookup argument requires a computation on the order of the table size, we also must chunk the table into our memory. If the table is very large and the rest of the computation is small, it may be desirable to build a uniform compiler for a sublinear lookup protocol <em>[x11]</em>. The highest degree on the polynomial map incurred by the new constraints is of degree <span class="math">\\deg(G_{\\mathsf{T}})+1</span>.</p>

    <h3 id="sec-47" class="text-xl font-semibold mt-8">7.2 Commit-and-Prove SNARK</h3>

    <p class="text-gray-300">Here we describe how our base SNARK satisifies a notion of commit-and-prove which allows for connecting and reusing (parts of) witnesses across proofs. We provide a modified definition of commit-and-prove NARKs (CP-NARKs) as presented by Campanelli et al. <em>[x7]</em>.</p>

    <h6 id="sec-48" class="text-base font-medium mt-4">Definition 24 (CP-NARKs (<em>[x7]</em>)).</h6>

    <p class="text-gray-300">A (preprocessing) commit-and-prove non-interactive argument (CP-NARK) for a family of index relations <span class="math">\\{\\mathsf{R}_{\\mathsf{pp}}\\}_{\\mathsf{pp}}</span> where the witness space <span class="math">\\mathcal{W}\\coloneqq\\mathcal{W}_{u}\\times\\mathcal{W}_{\\omega}</span> is split into two domains, where <span class="math">\\mathcal{W}_{u}</span> represents committed elements and <span class="math">\\mathcal{W}_{\\omega}</span> represents uncommitted elements. The committed domain <span class="math">\\mathcal{W}_{u}</span> can be further split into <span class="math">\\ell</span> arbitrary subdomains, <span class="math">\\mathcal{W}_{u,1},\\ldots,\\mathcal{W}_{u,\\ell}</span>. Assume a commitment scheme with commitment space <span class="math">\\mathcal{C}</span> such that for all <span class="math">i\\in[\\ell]</span>, <span class="math">\\mathcal{W}_{u,i}\\subseteq\\mathcal{C}</span>. A CP-NARK is a NARK for the family of index relations <span class="math">\\{\\mathsf{R}_{\\mathsf{pp}}^{\\mathsf{cp}}\\}_{\\mathsf{pp}}</span> where for all <span class="math">\\mathsf{R}^{\\mathsf{cp}}\\in\\mathsf{R}_{\\mathsf{pp}}^{\\mathsf{cp}}</span></p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>The parameter generation algorithm <span class="math">\\mathcal{G}_{\\mathrm{nark}}(1^{\\lambda}) \\to \\mathbb{P}\\mathbb{P}</span> is such that <span class="math">\\mathbb{P}\\mathbb{P}</span> contains a commitment key <span class="math">\\mathsf{ck} \\gets \\mathsf{Setup}_{\\mathrm{com}}(1^{\\lambda})</span>.</li>

      <li>The relation <span class="math">\\mathsf{R}^{\\mathsf{cp}}</span> over <span class="math">(\\mathsf{idx}, X, W)</span> is defined by a relation <span class="math">\\mathsf{R} \\in \\{\\mathsf{R}_{\\mathsf{pp}}\\}_{\\mathsf{pp}}</span>, where if the statement takes the form <span class="math">X := (x, [c_i]_{i=1}^{\\ell})</span>, the witness takes the form <span class="math">W := ([u_i]_{i=1}^{\\ell}, \\omega)</span>, then</li>

    </ul>

    <div class="my-4 text-center"><span class="math-block">\\mathsf{R}^{\\mathsf{cp}} := \\left\\{ \\begin{pmatrix} \\mathsf{idx}, &amp;amp; (\\mathsf{idx}, x, W) \\in \\mathsf{R} \\\\ X := (x, [c_i]_{i=1}^{\\ell}), &amp;amp; \\bigwedge_{i=1}^{\\ell} c_i = \\mathsf{Commit}(\\mathsf{ck}, u_i) \\\\ W := ([u_i]_{i=1}^{\\ell}, \\omega) \\end{pmatrix} \\right\\}</span></div>

    <p class="text-gray-300">Modifications to the SNARK. Now recall that our base SNARK already commits to the prover witness chunk by chunk and combines these commitments within a Merkle hash in <span class="math">\\mathcal{P}_{\\mathrm{nark}}</span> of Construction 2. These prover witness commitments can simply be pulled out from the proving protocol and passed in as part of the statement. The witness commitments are combined with the statement commitment as before to produce hz. Then as part of the proof <span class="math">\\pi</span>, analogous to how the current prover provides a Merkle path opening proof of hz for the statement <span class="math">x</span>, the prover can also provide Merkle path opening proofs for each witness commitment in hz.</p>

    <p class="text-gray-300">The implications of this direct extension to CP-SNARKs is that the committed witness space subdomains must align with a subtree of chunks and the PCD tree must match the witness commitments. This means that if the committed witness are of very uneven size, the PCD tree would also be unbalanced and prover parallelism may be reduced.</p>

    <p class="text-gray-300">Acknowledgments. We thank Lev Soukhanov for noting his forum post about loading arbitrary data for IVCs. This work was funded by NSF, DARPA, the Simons Foundation, UBRI, NTT Research, and the Stanford Future of Digital Currency Initiative (FDCI). Opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA.</p>

    <p class="text-gray-300">49</p>

    <p class="text-gray-300">Bibliography</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[ACK21] Thomas Attema, Ronald Cramer, and Lisa Kohl. A compressed <span class="math">\\Sigma</span>-protocol theory for lattices. In Tal Malkin and Chris Peikert, editors, Advances in Cryptology – CRYPTO 2021, Part II, volume 12826 of Lecture Notes in Computer Science, pages 549–579, Virtual Event, August 16–20, 2021. Springer, Heidelberg, Germany.</li>

      <li>[ACL^{+}22] Martin R. Albrecht, Valerio Cini, Russell W. F. Lai, Giulio Malavolta, and Sri Aravinda Krishnan Thyagarajan. Lattice-based SNARKs: Publicly verifiable, preprocessing, and recursively composable - (extended abstract). In Yevgeniy Dodis and Thomas Shrimpton, editors, Advances in Cryptology – CRYPTO 2022, Part II, volume 13508 of Lecture Notes in Computer Science, pages 102–132, Santa Barbara, CA, USA, August 15–18, 2022. Springer, Heidelberg, Germany.</li>

      <li>[AFK22] Thomas Attema, Serge Fehr, and Michael Klooß. Fiat-shamir transformation of multi-round interactive proofs. In Eike Kiltz and Vinod Vaikuntanathan, editors, TCC 2022: 20th Theory of Cryptography Conference, Part I, volume 13747 of Lecture Notes in Computer Science, pages 113–142, Chicago, IL, USA, November 7–10, 2022. Springer, Heidelberg, Germany.</li>

      <li>[AHIV17] Scott Ames, Carmit Hazay, Yuval Ishai, and Muthuramakrishnan Venkitasubramaniam. Ligero: Lightweight sublinear arguments without a trusted setup. In Bhavani M. Thuraisingham, David Evans, Tal Malkin, and Dongyan Xu, editors, ACM CCS 2017: 24th Conference on Computer and Communications Security, pages 2087–2104, Dallas, TX, USA, October 31 – November 2, 2017. ACM Press.</li>

      <li>[AST23] Arasu Arun, Srinath Setty, and Justin Thaler. Jolt: SNARKs for virtual machines via lookups. Cryptology ePrint Archive, Paper 2023/1217, 2023. https://eprint.iacr.org/2023/1217.</li>

      <li>[BBC^{+}18] Carsten Baum, Jonathan Bootle, Andrea Cerulli, Rafaël del Pino, Jens Groth, and Vadim Lyuba- shevsky. Sub-linear lattice-based zero-knowledge arguments for arithmetic circuits. In Hovav Shacham and Alexandra Boldyreva, editors, Advances in Cryptology – CRYPTO 2018, Part II, volume 10992 of Lecture Notes in Computer Science, pages 669–699, Santa Barbara, CA, USA, August 19–23, 2018. Springer, Heidelberg, Germany.</li>

      <li>[BBHR18] Eli Ben-Sasson, Iddo Bentov, Yinon Horesh, and Michael Riabzev. Scalable, transparent, and post-quantum secure computational integrity. Cryptology ePrint Archive, Report 2018/046, 2018. https://eprint.iacr.org/2018/046.</li>

      <li>[BC23] Benedikt Bünz and Binyi Chen. ProtoStar: Generic efficient accumulation/folding for special sound protocols. Cryptology ePrint Archive, Paper 2023/620, 2023. https://eprint.iacr.org/2023/620.</li>

      <li>[BC24] Dan Boneh and Binyi Chen. Latticefold: A lattice-based folding scheme and its applications to succinct proof systems. Cryptology ePrint Archive, Paper 2024/257, 2024. https://eprint.iacr.org/2024/257.</li>

      <li>[BCC^{+}23] Dung Bui, Haotian Chu, Geoffroy Couteau, Xiao Wang, Chenkai Weng, Kang Yang, and Yu Yu. An efficient ZK compiler from SIMD circuits to general circuits. Cryptology ePrint Archive, Paper 2023/1610, 2023. https://eprint.iacr.org/2023/1610.</li>

      <li>[BCCT12] Nir Bitansky, Ran Canetti, Alessandro Chiesa, and Eran Tromer. From extractable collision resistance to succinct non-interactive arguments of knowledge, and back again. In Shafi Goldwasser, editor, ITCS 2012: 3rd Innovations in Theoretical Computer Science, pages 326–349, Cambridge, MA, USA, January 8–10, 2012. Association for Computing Machinery.</li>

      <li>[BCCT13] Nir Bitansky, Ran Canetti, Alessandro Chiesa, and Eran Tromer. Recursive composition and bootstrapping for SNARKS and proof-carrying data. In Dan Boneh, Tim Roughgarden, and Joan Feigenbaum, editors, 45th Annual ACM Symposium on Theory of Computing, pages 111–120, Palo Alto, CA, USA, June 1–4, 2013. ACM Press.</li>

      <li>[BCG^{+}13] Eli Ben-Sasson, Alessandro Chiesa, Daniel Genkin, Eran Tromer, and Madars Virza. SNARKs for C: Verifying program executions succinctly and in zero knowledge. In Ran Canetti and Juan A. Garay,</li>

    </ul>

    <p class="text-gray-300">editors, Advances in Cryptology – CRYPTO 2013, Part II, volume 8043 of Lecture Notes in Computer Science, pages 90–108, Santa Barbara, CA, USA, August 18–22, 2013. Springer, Heidelberg, Germany.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[BCG^{+}18] Jonathan Bootle, Andrea Cerulli, Jens Groth, Sune K. Jakobsen, and Mary Maller. Arya: Nearly linear-time zero-knowledge proofs for correct program execution. In Thomas Peyrin and Steven Galbraith, editors, Advances in Cryptology – ASIACRYPT 2018, Part I, volume 11272 of Lecture Notes in Computer Science, pages 595–626, Brisbane, Queensland, Australia, December 2–6, 2018. Springer, Heidelberg, Germany.</li>

      <li>[BCHO22] Jonathan Bootle, Alessandro Chiesa, Yuncong Hu, and Michele Orrù. Gemini: Elastic SNARKs for diverse environments. In Orr Dunkelman and Stefan Dziembowski, editors, Advances in Cryptology – EUROCRYPT 2022, Part II, volume 13276 of Lecture Notes in Computer Science, pages 427–457, Trondheim, Norway, May 30 – June 3, 2022. Springer, Heidelberg, Germany.</li>

      <li>[BCL^{+}21] Benedikt Bünz, Alessandro Chiesa, William Lin, Pratyush Mishra, and Nicholas Spooner. Proof-carrying data without succinct arguments. In Tal Malkin and Chris Peikert, editors, Advances in Cryptology – CRYPTO 2021, Part I, volume 12825 of Lecture Notes in Computer Science, pages 681–710, Virtual Event, August 16–20, 2021. Springer, Heidelberg, Germany.</li>

      <li>[BCMS20a] Benedikt Bünz, Alessandro Chiesa, Pratyush Mishra, and Nicholas Spooner. Proof-carrying data from accumulation schemes. Cryptology ePrint Archive, Report 2020/499, 2020. https://eprint.iacr.org/2020/499.</li>

      <li>[BCMS20b] Benedikt Bünz, Alessandro Chiesa, Pratyush Mishra, and Nicholas Spooner. Recursive proof composition from accumulation schemes. In Rafael Pass and Krzysztof Pietrzak, editors, TCC 2020: 18th Theory of Cryptography Conference, Part II, volume 12551 of Lecture Notes in Computer Science, pages 1–18, Durham, NC, USA, November 16–19, 2020. Springer, Heidelberg, Germany.</li>

      <li>[BCR^{+}19] Eli Ben-Sasson, Alessandro Chiesa, Michael Riabzev, Nicholas Spooner, Madars Virza, and Nicholas P. Ward. Aurora: Transparent succinct arguments for R1CS. In Yuval Ishai and Vincent Rijmen, editors, Advances in Cryptology – EUROCRYPT 2019, Part I, volume 11476 of Lecture Notes in Computer Science, pages 103–128, Darmstadt, Germany, May 19–23, 2019. Springer, Heidelberg, Germany.</li>

      <li>[BCS23] Jonathan Bootle, Alessandro Chiesa, and Katerina Sotiraki. Lattice-based succinct arguments for NP with polylogarithmic-time verification. In Helena Handschuh and Anna Lysyanskaya, editors, Advances in Cryptology – CRYPTO 2023, Part II, volume 14082 of Lecture Notes in Computer Science, pages 227–251, Santa Barbara, CA, USA, August 20–24, 2023. Springer, Heidelberg, Germany.</li>

      <li>[BCTV14a] Eli Ben-Sasson, Alessandro Chiesa, Eran Tromer, and Madars Virza. Scalable zero knowledge via cycles of elliptic curves. In Juan A. Garay and Rosario Gennaro, editors, Advances in Cryptology – CRYPTO 2014, Part II, volume 8617 of Lecture Notes in Computer Science, pages 276–294, Santa Barbara, CA, USA, August 17–21, 2014. Springer, Heidelberg, Germany.</li>

      <li>[BCTV14b] Eli Ben-Sasson, Alessandro Chiesa, Eran Tromer, and Madars Virza. Succinct non-interactive zero knowledge for a von neumann architecture. In Kevin Fu and Jaeyeon Jung, editors, USENIX Security 2014: 23rd USENIX Security Symposium, pages 781–796, San Diego, CA, USA, August 20–22, 2014. USENIX Association.</li>

      <li>[BDFG21] Dan Boneh, Justin Drake, Ben Fisch, and Ariel Gabizon. Halo infinite: Proof-carrying data from additive polynomial commitments. In Tal Malkin and Chris Peikert, editors, Advances in Cryptology – CRYPTO 2021, Part I, volume 12825 of Lecture Notes in Computer Science, pages 649–680, Virtual Event, August 16–20, 2021. Springer, Heidelberg, Germany.</li>

      <li>[BDSW23] Carsten Baum, Samuel Dittmer, Peter Scholl, and Xiao Wang. SOK: vector OLE-based zero-knowledge protocols. Des. Codes Cryptogr., 91(11):3527–3561, 2023.</li>

      <li>[BFR^{+}13] Benjamin Braun, Ariel J. Feldman, Zuocheng Ren, Srinath T. V. Setty, Andrew J. Blumberg, and Michael Walfish. Verifying computations with state. In Michael Kaminsky and Mike Dahlin, editors, ACM SIGOPS 24th Symposium on Operating Systems Principles, SOSP ’13, Farmington, PA, USA, November 3-6, 2013, pages 341–357. ACM, 2013.</li>

    </ul>

    <p class="text-gray-300">[BFS20] Benedikt Bünz, Ben Fisch, and Alan Szepieniec. Transparent SNARKs from DARK compilers. In Anne Canteaut and Yuval Ishai, editors, Advances in Cryptology – EUROCRYPT 2020, Part I, volume 12105 of Lecture Notes in Computer Science, pages 677–706, Zagreb, Croatia, May 10–14, 2020. Springer, Heidelberg, Germany.</p>

    <p class="text-gray-300">[BG12] Stephanie Bayer and Jens Groth. Efficient zero-knowledge argument for correctness of a shuffle. In David Pointcheval and Thomas Johansson, editors, Advances in Cryptology – EUROCRYPT 2012, volume 7237 of Lecture Notes in Computer Science, pages 263–280, Cambridge, UK, April 15–19, 2012. Springer, Heidelberg, Germany.</p>

    <p class="text-gray-300">[BGH19] Sean Bowe, Jack Grigg, and Daira Hopwood. Halo: Recursive proof composition without a trusted setup. Cryptology ePrint Archive, Report 2019/1021, 2019. https://eprint.iacr.org/2019/1021.</p>

    <p class="text-gray-300">[BHR⁺20] Alexander R. Block, Justin Holmgren, Alon Rosen, Ron D. Rothblum, and Pratik Soni. Public-coin zero-knowledge arguments with (almost) minimal time and space overheads. In Rafael Pass and Krzysztof Pietrzak, editors, TCC 2020: 18th Theory of Cryptography Conference, Part II, volume 12551 of Lecture Notes in Computer Science, pages 168–197, Durham, NC, USA, November 16–19, 2020. Springer, Heidelberg, Germany.</p>

    <p class="text-gray-300">[BHR⁺21] Alexander R. Block, Justin Holmgren, Alon Rosen, Ron D. Rothblum, and Pratik Soni. Time- and space-efficient arguments from groups of unknown order. In Tal Malkin and Chris Peikert, editors, Advances in Cryptology – CRYPTO 2021, Part IV, volume 12828 of Lecture Notes in Computer Science, pages 123–152, Virtual Event, August 16–20, 2021. Springer, Heidelberg, Germany.</p>

    <p class="text-gray-300">[BLNS20] Jonathan Bootle, Vadim Lyubashevsky, Ngoc Khanh Nguyen, and Gregor Seiler. A non-PCP approach to succinct quantum-safe zero-knowledge. In Daniele Micciancio and Thomas Ristenpart, editors, Advances in Cryptology – CRYPTO 2020, Part II, volume 12171 of Lecture Notes in Computer Science, pages 441–469, Santa Barbara, CA, USA, August 17–21, 2020. Springer, Heidelberg, Germany.</p>

    <p class="text-gray-300">[BMM⁺21] Benedikt Bünz, Mary Maller, Pratyush Mishra, Nirvan Tyagi, and Psi Vesely. Proofs for inner pairing products and applications. In Mehdi Tibouchi and Huaxiong Wang, editors, Advances in Cryptology – ASIACRYPT 2021, Part III, volume 13092 of Lecture Notes in Computer Science, pages 65–97, Singapore, December 6–10, 2021. Springer, Heidelberg, Germany.</p>

    <p class="text-gray-300">[BMNW24] Benedikt Bünz, Pratyush Mishra, Wilson Nguyen, and William Wang. Accumulation without homomorphism. Cryptology ePrint Archive, Paper 2024/474, 2024. https://eprint.iacr.org/2024/474.</p>

    <p class="text-gray-300">[BMRS21] Carsten Baum, Alex J. Malozemoff, Marc B. Rosen, and Peter Scholl. Mac'n'cheese: Zero-knowledge proofs for boolean and arithmetic circuits with nested disjunctions. In Tal Malkin and Chris Peikert, editors, Advances in Cryptology – CRYPTO 2021, Part IV, volume 12828 of Lecture Notes in Computer Science, pages 92–122, Virtual Event, August 16–20, 2021. Springer, Heidelberg, Germany.</p>

    <p class="text-gray-300">[Boo] Bootle. Efficient multi-exponentiation. https://jbootle.github.io/Misc/pippenger.pdf.</p>

    <p class="text-gray-300">[BS23] Ward Beullens and Gregor Seiler. LaBRADOR: Compact proofs for R1CS from module-SIS. In Helena Handschuh and Anna Lysyanskaya, editors, Advances in Cryptology – CRYPTO 2023, Part V, volume 14085 of Lecture Notes in Computer Science, pages 518–548, Santa Barbara, CA, USA, August 20–24, 2023. Springer, Heidelberg, Germany.</p>

    <p class="text-gray-300">[CBBZ23] Binyi Chen, Benedikt Bünz, Dan Boneh, and Zhenfei Zhang. HyperPlonk: Plonk with linear-time prover and high-degree custom gates. In Carmit Hazay and Martijn Stam, editors, Advances in Cryptology – EUROCRYPT 2023, Part II, volume 14005 of Lecture Notes in Computer Science, pages 499–530, Lyon, France, April 23–27, 2023. Springer, Heidelberg, Germany.</p>

    <p class="text-gray-300">[CCG⁺23] Megan Chen, Alessandro Chiesa, Tom Gur, Jack O'Connor, and Nicholas Spooner. Proof-carrying data from arithmetized random oracles. In Carmit Hazay and Martijn Stam, editors, Advances in Cryptology – EUROCRYPT 2023, Part II, volume 14005 of Lecture Notes in Computer Science, pages 379–404, Lyon, France, April 23–27, 2023. Springer, Heidelberg, Germany.</p>

    <p class="text-gray-300">[CCS22] Megan Chen, Alessandro Chiesa, and Nicholas Spooner. On succinct non-interactive arguments in relativized worlds. In Orr Dunkelman and Stefan Dziembowski, editors, Advances in Cryptology –</p>

    <p class="text-gray-300">EUROCRYPT 2022, Part II, volume 13276 of Lecture Notes in Computer Science, pages 336–366, Trondheim, Norway, May 30 – June 3, 2022. Springer, Heidelberg, Germany.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[CDv^{+}03] Dwaine E. Clarke, Srinivas Devadas, Marten van Dijk, Blaise Gassend, and G. Edward Suh. Incremental multiset hash functions and their application to memory integrity checking. In Chi-Sung Laih, editor, Advances in Cryptology – ASIACRYPT 2003, volume 2894 of Lecture Notes in Computer Science, pages 188–207, Taipei, Taiwan, November 30 – December 4, 2003. Springer, Heidelberg, Germany.</li>

      <li>[CFQ19] Matteo Campanelli, Dario Fiore, and Anaïs Querol. LegoSNARK: Modular design and composition of succinct zero-knowledge proofs. In Lorenzo Cavallaro, Johannes Kinder, XiaoFeng Wang, and Jonathan Katz, editors, ACM CCS 2019: 26th Conference on Computer and Communications Security, pages 2075–2092, London, UK, November 11–15, 2019. ACM Press.</li>

      <li>[CGH04] Ran Canetti, Oded Goldreich, and Shai Halevi. The random oracle methodology, revisited. Journal of the ACM (JACM), 51(4):557–594, 2004.</li>

      <li>[CHM^{+}20] Alessandro Chiesa, Yuncong Hu, Mary Maller, Pratyush Mishra, Psi Vesely, and Nicholas P. Ward. Marlin: Preprocessing zkSNARKs with universal and updatable SRS. In Anne Canteaut and Yuval Ishai, editors, Advances in Cryptology – EUROCRYPT 2020, Part I, volume 12105 of Lecture Notes in Computer Science, pages 738–768, Zagreb, Croatia, May 10–14, 2020. Springer, Heidelberg, Germany.</li>

      <li>[CJJ21] Arka Rai Choudhuri, Abhishek Jain, and Zhengzhong Jin. Non-interactive batch arguments for NP from standard assumptions. In Tal Malkin and Chris Peikert, editors, Advances in Cryptology – CRYPTO 2021, Part IV, volume 12828 of Lecture Notes in Computer Science, pages 394–423, Virtual Event, August 16–20, 2021. Springer, Heidelberg, Germany.</li>

      <li>[CJJ22] Arka Rai Choudhuri, Abhishek Jain, and Zhengzhong Jin. SNARGs for <span class="math">\\mathcal{P}</span> from LWE. In 62nd Annual Symposium on Foundations of Computer Science, pages 68–79, Denver, CO, USA, February 7–10, 2022. IEEE Computer Society Press.</li>

      <li>[CL19] Alessandro Chiesa and Siqi Liu. On the impossibility of probabilistic proofs in relativized worlds. Cryptology ePrint Archive, 2019.</li>

      <li>[COS20] Alessandro Chiesa, Dev Ojha, and Nicholas Spooner. Fractal: Post-quantum and transparent recursive proofs from holography. In Anne Canteaut and Yuval Ishai, editors, Advances in Cryptology – EUROCRYPT 2020, Part I, volume 12105 of Lecture Notes in Computer Science, pages 769–793, Zagreb, Croatia, May 10–14, 2020. Springer, Heidelberg, Germany.</li>

      <li>[CT10] Alessandro Chiesa and Eran Tromer. Proof-carrying data and hearsay arguments from signature cards. In Andrew Chi-Chih Yao, editor, ICS 2010: 1st Innovations in Computer Science, pages 310–331, Tsinghua University, Beijing, China, January 5–7, 2010. Tsinghua University Press.</li>

      <li>[DILO22] Samuel Dittmer, Yuval Ishai, Steve Lu, and Rafail Ostrovsky. Improving line-point zero knowledge: Two multiplications for the price of one. In Heng Yin, Angelos Stavrou, Cas Cremers, and Elaine Shi, editors, ACM CCS 2022: 29th Conference on Computer and Communications Security, pages 829–841, Los Angeles, CA, USA, November 7–11, 2022. ACM Press.</li>

      <li>[DIO20] Samuel Dittmer, Yuval Ishai, and Rafail Ostrovsky. Line-point zero knowledge and its applications. Cryptology ePrint Archive, Report 2020/1446, 2020. https://eprint.iacr.org/2020/1446.</li>

      <li>[EFG22] Liam Eagen, Dario Fiore, and Ariel Gabizon. cq: Cached quotients for fast lookups. Cryptology ePrint Archive, Paper 2022/1763, 2022. https://eprint.iacr.org/2022/1763.</li>

      <li>[EG23] Liam Eagen and Ariel Gabizon. ProtoGalaxy: Efficient protostar-style folding of multiple instances. Cryptology ePrint Archive, Paper 2023/1106, 2023. https://eprint.iacr.org/2023/1106.</li>

      <li>[ENS20] Muhammed F. Esgin, Ngoc Khanh Nguyen, and Gregor Seiler. Practical exact proofs from lattices: New techniques to exploit fully-splitting rings. In Shiho Moriai and Huaxiong Wang, editors, Advances in Cryptology – ASIACRYPT 2020, Part II, volume 12492 of Lecture Notes in Computer Science, pages 259–288, Daejeon, South Korea, December 7–11, 2020. Springer, Heidelberg, Germany.</li>

    </ul>

    <p class="text-gray-300">[GK03] Shafi Goldwasser and Yael Tauman Kalai. On the (in) security of the fiat-shamir paradigm. In 44th Annual IEEE Symposium on Foundations of Computer Science, 2003. Proceedings., pages 102–113. IEEE, 2003.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[GLS^{+}23] Alexander Golovnev, Jonathan Lee, Srinath T. V. Setty, Justin Thaler, and Riad S. Wahby. Brakedown: Linear-time and field-agnostic SNARKs for R1CS. In Helena Handschuh and Anna Lysyanskaya, editors, Advances in Cryptology – CRYPTO 2023, Part II, volume 14082 of Lecture Notes in Computer Science, pages 193–226, Santa Barbara, CA, USA, August 20–24, 2023. Springer, Heidelberg, Germany.</li>

      <li>[GW20] Ariel Gabizon and Zachary J. Williamson. plookup: A simplified polynomial protocol for lookup tables. Cryptology ePrint Archive, Report 2020/315, 2020. https://eprint.iacr.org/2020/315.</li>

      <li>[GWC19] Ariel Gabizon, Zachary J. Williamson, and Oana Ciobotaru. PLONK: Permutations over lagrange-bases for oecumenical noninteractive arguments of knowledge. Cryptology ePrint Archive, Report 2019/953, 2019. https://eprint.iacr.org/2019/953.</li>

      <li>[Hab22] Ulrich Haböck. Multivariate lookups based on logarithmic derivatives. Cryptology ePrint Archive, Report 2022/1530, 2022. https://eprint.iacr.org/2022/1530.</li>

      <li>[KLVW22] Yael Tauman Kalai, Alex Lombardi, Vinod Vaikuntanathan, and Daniel Wichs. Boosting batch arguments and RAM delegation. Cryptology ePrint Archive, Report 2022/1320, 2022. https://eprint.iacr.org/2022/1320.</li>

      <li>[KMN23] George Kadianakis, Mary Maller, and Andrija Novakovic. Sigmabus: Binding sigmas in circuits for fast curve operations. Cryptology ePrint Archive, Paper 2023/1406, 2023. https://eprint.iacr.org/2023/1406.</li>

      <li>[KS22] Abhiram Kothapalli and Srinath Setty. SuperNova: Proving universal machine executions without universal circuits. Cryptology ePrint Archive, Report 2022/1758, 2022. https://eprint.iacr.org/2022/1758.</li>

      <li>[KS23] Abhiram Kothapalli and Srinath Setty. HyperNova: Recursive arguments for customizable constraint systems. Cryptology ePrint Archive, Paper 2023/573, 2023. https://eprint.iacr.org/2023/573.</li>

      <li>[KST22] Abhiram Kothapalli, Srinath Setty, and Ioanna Tzialla. Nova: Recursive zero-knowledge arguments from folding schemes. In Yevgeniy Dodis and Thomas Shrimpton, editors, Advances in Cryptology – CRYPTO 2022, Part IV, volume 13510 of Lecture Notes in Computer Science, pages 359–388, Santa Barbara, CA, USA, August 15–18, 2022. Springer, Heidelberg, Germany.</li>

      <li>[Lee20] Jonathan Lee. Dory: Efficient, transparent arguments for generalised inner products and polynomial commitments. Cryptology ePrint Archive, Report 2020/1274, 2020. https://eprint.iacr.org/2020/1274.</li>

      <li>[LNP22] Vadim Lyubashevsky, Ngoc Khanh Nguyen, and Maxime Plançon. Lattice-based zero-knowledge proofs and applications: Shorter, simpler, and more general. In Yevgeniy Dodis and Thomas Shrimpton, editors, Advances in Cryptology – CRYPTO 2022, Part II, volume 13508 of Lecture Notes in Computer Science, pages 71–101, Santa Barbara, CA, USA, August 15–18, 2022. Springer, Heidelberg, Germany.</li>

      <li>[LXZ^{+}23] Tianyi Liu, Tiancheng Xie, Jiaheng Zhang, Dawn Song, and Yupeng Zhang. Pianist: Scalable zkrollups via fully distributed zero-knowledge proofs. Cryptology ePrint Archive, Paper 2023/1271, 2023. https://eprint.iacr.org/2023/1271.</li>

      <li>[Mer90] Ralph C. Merkle. A certified digital signature. In Gilles Brassard, editor, Advances in Cryptology – CRYPTO’89, volume 435 of Lecture Notes in Computer Science, pages 218–238, Santa Barbara, CA, USA, August 20–24, 1990. Springer, Heidelberg, Germany.</li>

      <li>[Moh23] Nicholas Mohnblatt. Sangria: A folding scheme for PLONK, 2023. link.</li>

      <li>[NBS23] Wilson Nguyen, Dan Boneh, and Srinath Setty. Revisiting the nova proof system on a cycle of curves. Cryptology ePrint Archive, Paper 2023/969, 2023. https://eprint.iacr.org/2023/969.</li>

      <li>[Nov22] Nova Contributors. Nova implementation, 2022. https://github.com/Microsoft/Nova.</li>

      <li>[Pas20] Pasta Contributors. Pasta curves, 2020. https://github.com/zcash/pasta_curves.</li>

    </ul>

    <p class="text-gray-300">[pcd21] pcd Contributors. Implementation of bclms21, 2021. https://github.com/arkworks-rs/pcd.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[Pip80] Nicholas Pippenger. On the evaluation of powers and monomials. SIAM Journal on Computing, 9(2):230–250, 1980.</li>

      <li>[PTC76] Wolfgang Paul, Robert Tarjan, and James Celoni. Space bounds for a game on graphs. In Proceedings of STOC 1976, pages 149–160. ACM, 1976.</li>

      <li>[RZ22] Carla Ràfols and Alexandros Zacharakis. Folding schemes with selective verification. Cryptology ePrint Archive, Paper 2022/1576, 2022. https://eprint.iacr.org/2022/1576.</li>

      <li>[SAGL18] Srinath T. V. Setty, Sebastian Angel, Trinabh Gupta, and Jonathan Lee. Proving the correct execution of concurrent services in zero-knowledge. In Andrea C. Arpaci-Dusseau and Geoff Voelker, editors, 13th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2018, Carlsbad, CA, USA, October 8-10, 2018, pages 339–356. USENIX Association, 2018.</li>

      <li>[Set20] Srinath Setty. Spartan: Efficient and general-purpose zkSNARKs without trusted setup. In Daniele Micciancio and Thomas Ristenpart, editors, Advances in Cryptology – CRYPTO 2020, Part III, volume 12172 of Lecture Notes in Computer Science, pages 704–737, Santa Barbara, CA, USA, August 17–21, 2020. Springer, Heidelberg, Germany.</li>

      <li>[Sou23] Lev Soukhanov. Folding endgame, 2023. https://zkresear.ch/t/folding-endgame/106.</li>

      <li>[STW23a] Srinath Setty, Justin Thaler, and Riad Wahby. Customizable constraint systems for succinct arguments. Cryptology ePrint Archive, Paper 2023/552, 2023. https://eprint.iacr.org/2023/552.</li>

      <li>[STW23b] Srinath Setty, Justin Thaler, and Riad Wahby. Unlocking the lookup singularity with lasso. Cryptology ePrint Archive, Paper 2023/1216, 2023. https://eprint.iacr.org/2023/1216.</li>

      <li>[TFZ^{+}22] Nirvan Tyagi, Ben Fisch, Andrew Zitek, Joseph Bonneau, and Stefano Tessaro. VeRSA: Verifiable registries with efficient client audits from RSA authenticated dictionaries. In Heng Yin, Angelos Stavrou, Cas Cremers, and Elaine Shi, editors, ACM CCS 2022: 29th Conference on Computer and Communications Security, pages 2793–2807, Los Angeles, CA, USA, November 7–11, 2022. ACM Press.</li>

      <li>[Tha13] Justin Thaler. Time-optimal interactive proofs for circuit evaluation. In Ran Canetti and Juan A. Garay, editors, Advances in Cryptology – CRYPTO 2013, Part II, volume 8043 of Lecture Notes in Computer Science, pages 71–89, Santa Barbara, CA, USA, August 18–22, 2013. Springer, Heidelberg, Germany.</li>

      <li>[TKPS22] Ioanna Tzialla, Abhiram Kothapalli, Bryan Parno, and Srinath T. V. Setty. Transparency dictionaries with succinct proofs of correct operation. In 29th Annual Network and Distributed System Security Symposium, NDSS 2022, San Diego, California, USA, April 24-28, 2022. The Internet Society, 2022.</li>

      <li>[Val08] Paul Valiant. Incrementally verifiable computation or proofs of knowledge imply time/space efficiency. In Ran Canetti, editor, TCC 2008: 5th Theory of Cryptography Conference, volume 4948 of Lecture Notes in Computer Science, pages 1–18, San Francisco, CA, USA, March 19–21, 2008. Springer, Heidelberg, Germany.</li>

      <li>[WHG^{+}16] Riad S. Wahby, Max Howald, Siddharth J. Garg, abhi shelat, and Michael Walfish. Verifiable ASICs. In 2016 IEEE Symposium on Security and Privacy, pages 759–778, San Jose, CA, USA, May 22–26, 2016. IEEE Computer Society Press.</li>

      <li>[WTs^{+}18] Riad S. Wahby, Ioanna Tzialla, abhi shelat, Justin Thaler, and Michael Walfish. Doubly-efficient zkSNARKs without trusted setup. In 2018 IEEE Symposium on Security and Privacy, pages 926–943, San Francisco, CA, USA, May 21–23, 2018. IEEE Computer Society Press.</li>

      <li>[WW22] Brent Waters and David J. Wu. Batch arguments for sfNP and more from standard bilinear group assumptions. In Yevgeniy Dodis and Thomas Shrimpton, editors, Advances in Cryptology – CRYPTO 2022, Part II, volume 13508 of Lecture Notes in Computer Science, pages 433–463, Santa Barbara, CA, USA, August 15–18, 2022. Springer, Heidelberg, Germany.</li>

      <li>[WYKW21] Chenkai Weng, Kang Yang, Jonathan Katz, and Xiao Wang. Wolverine: Fast, scalable, and communication-efficient zero-knowledge proofs for boolean and arithmetic circuits. In 2021 IEEE Symposium on Security and Privacy, pages 1074–1091, San Francisco, CA, USA, May 24–27, 2021. IEEE Computer Society Press.</li>

    </ul>

    <p class="text-gray-300">[WYY^{+}22] Chenkai Weng, Kang Yang, Zhaomin Yang, Xiang Xie, and Xiao Wang. AntMan: Interactive zero-knowledge proofs with sublinear communication. In Heng Yin, Angelos Stavrou, Cas Cremers, and Elaine Shi, editors, ACM CCS 2022: 29th Conference on Computer and Communications Security, pages 2901–2914, Los Angeles, CA, USA, November 7–11, 2022. ACM Press.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>[WZC^{+}18] Howard Wu, Wenting Zheng, Alessandro Chiesa, Raluca Ada Popa, and Ion Stoica. DIZK: A distributed zero knowledge proof system. In William Enck and Adrienne Porter Felt, editors, USENIX Security 2018: 27th USENIX Security Symposium, pages 675–692, Baltimore, MD, USA, August 15–17, 2018. USENIX Association.</li>

      <li>[XCZ^{+}22] Alex Luoyuan Xiong, Binyi Chen, Zhenfei Zhang, Benedikt Bünz, Ben Fisch, Fernando Krell, and Philippe Camacho. VERI-ZEXE: Decentralized private computation with universal setup. Cryptology ePrint Archive, Report 2022/802, 2022. https://eprint.iacr.org/2022/802.</li>

      <li>[XZS22] Tiancheng Xie, Yupeng Zhang, and Dawn Song. Orion: Zero knowledge proof with linear prover time. In Yevgeniy Dodis and Thomas Shrimpton, editors, Advances in Cryptology – CRYPTO 2022, Part IV, volume 13510 of Lecture Notes in Computer Science, pages 299–328, Santa Barbara, CA, USA, August 15–18, 2022. Springer, Heidelberg, Germany.</li>

      <li>[XZZ^{+}19] Tiancheng Xie, Jiaheng Zhang, Yupeng Zhang, Charalampos Papamanthou, and Dawn Song. Libra: Succinct zero-knowledge proofs with optimal prover computation. In Alexandra Boldyreva and Daniele Micciancio, editors, Advances in Cryptology – CRYPTO 2019, Part III, volume 11694 of Lecture Notes in Computer Science, pages 733–764, Santa Barbara, CA, USA, August 18–22, 2019. Springer, Heidelberg, Germany.</li>

      <li>[YH23] Yibin Yang and David Heath. Two shuffles make a RAM: Improved constant overhead zero knowledge ram. Cryptology ePrint Archive, Paper 2023/1115, 2023. https://eprint.iacr.org/2023/1115.</li>

      <li>[YSWW21] Kang Yang, Pratik Sarkar, Chenkai Weng, and Xiao Wang. QuickSilver: Efficient and affordable zero-knowledge proofs for circuits and polynomials over any field. In Giovanni Vigna and Elaine Shi, editors, ACM CCS 2021: 28th Conference on Computer and Communications Security, pages 2986–3001, Virtual Event, Republic of Korea, November 15–19, 2021. ACM Press.</li>

      <li>[ZCF23] Hadas Zeilberger, Binyi Chen, and Ben Fisch. Basefold: Efficient field-agnostic polynomial commitment schemes from foldable codes. Cryptology ePrint Archive, 2023.</li>

    </ul>

    <p class="text-gray-300">A Deferred Proofs</p>

    <p class="text-gray-300">A.1 Deferred Proof of Lemma 5</p>

    <p class="text-gray-300">Proof. First, we construct an adversary <span class="math">\\mathcal{B}</span> that breaks the binding property of <span class="math">\\mathcal{L}_{\\mathrm{x}}^{\\prime}</span>, or <span class="math">\\mathcal{L}_{\\mathrm{e}}</span>.</p>

    <p class="text-gray-300"><span class="math">\\mathcal{B}(\\mathcal{L}_{\\mathrm{x}}^{\\prime},\\mathcal{L}_{\\mathrm{e}})</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run <span class="math">\\mathcal{A}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{x}}^{\\prime},\\mathcal{L}_{\\mathrm{e}})</span> to obtain <span class="math">((\\overline{x},\\overline{e}),\\ x),x^{\\prime},e</span>.</li>

      <li>If <span class="math">\\psi(x)\\neq x^{\\prime}</span>, then output <span class="math">(\\psi(x),x^{\\prime})</span> as a collision pair for <span class="math">\\mathcal{L}_{\\mathrm{x}}^{\\prime}</span>.</li>

      <li>If <span class="math">f(x)\\neq e</span>, then output <span class="math">(f(x),e)</span> as a collision pair for <span class="math">\\mathcal{L}_{\\mathrm{e}}</span>.</li>

    </ol>

    <p class="text-gray-300">Now assume <span class="math">((\\overline{x},\\overline{e}),\\ x)\\in\\mathcal{R}_{\\mathsf{open}}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}})</span>, <span class="math">\\varPsi(\\overline{x})=\\mathcal{L}_{\\mathrm{x}}^{\\prime}(x^{\\prime})</span>, and <span class="math">\\overline{e}=\\mathcal{L}_{\\mathrm{e}}(e)</span>. Then, we have the following:</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Since the pair is in the relation, we must have <span class="math">\\overline{x}=\\mathcal{L}_{\\mathrm{x}}(x)</span> and <span class="math">\\overline{e}=\\mathcal{L}_{\\mathrm{e}}(f(x))</span>. Therefore, we immediately have <span class="math">\\mathcal{L}_{\\mathrm{e}}(f(x))=\\mathcal{L}_{\\mathrm{e}}(e)</span>.</li>

      <li>Since <span class="math">\\varPsi\\circ\\mathcal{L}_{\\mathrm{x}}=\\mathcal{L}_{\\mathrm{x}}^{\\prime}\\circ\\psi</span>, we have <span class="math">\\varPsi(\\mathcal{L}_{\\mathrm{x}}(x))=\\mathcal{L}_{\\mathrm{x}}^{\\prime}(\\psi(x))</span>. By substitution, we have <span class="math">\\mathcal{L}_{\\mathrm{x}}^{\\prime}(x^{\\prime})=\\mathcal{L}_{\\mathrm{x}}^{\\prime}(\\psi(x))</span>.</li>

    </ul>

    <p class="text-gray-300">Therefore, we can conclude that if <span class="math">\\psi(x)\\neq x^{\\prime}</span> or <span class="math">f(x)\\neq e</span>, then <span class="math">\\mathcal{B}</span> outputs a collision pair for <span class="math">\\mathcal{L}_{\\mathrm{x}}^{\\prime}</span> or <span class="math">\\mathcal{L}_{\\mathrm{e}}</span>. Since the success probability of the binding adversary <span class="math">\\mathcal{B}</span> bounds the success probability of <span class="math">\\mathcal{A}</span>, we can conclude by union bound that the probability in (5) is negligibly close to 1. <span class="math">\\square</span></p>

    <p class="text-gray-300">A.2 Deferred Proof of Theorem 2</p>

    <p class="text-gray-300">Completeness: Completeness of <span class="math">\\Pi_{\\mathsf{open}}^{\\mathrm{H}}</span> follows from the completeness of <span class="math">\\Pi_{\\mathsf{open}}^{(k)}</span> for all <span class="math">k\\in\\{\\ell,\\ell/2,\\ldots,2\\}</span>. Consider an arbitrary <span class="math">k</span> in the set above. Once the prover computes the appropriate <span class="math">(v_{i,j})</span>’s, the verifier’s checks will trivially pass by the linear homomorphism property of <span class="math">\\mathcal{L}_{\\mathrm{x}}</span> and <span class="math">\\mathcal{L}_{\\mathrm{e}}</span>. The prover can compute the <span class="math">(v_{i,j})</span>’s that satisfy the required polynomial equation in indeterminate <span class="math">Y</span>, because the polynomial map <span class="math">f</span> is a homogeneous polynomial map of degree <span class="math">d</span>.</p>

    <p class="text-gray-300">Theorem 6 (Special Soundness of <span class="math">\\Pi_{\\mathsf{open}}^{\\mathrm{H}}</span> (Definition 17)). Let <span class="math">m,n,d,\\ell\\in\\mathbb{N}</span> (where <span class="math">\\ell</span> is a power-of-two), <span class="math">\\mathbb{F}</span> be a field, and <span class="math">\\mathbb{X},\\mathbb{E}</span> be vector spaces. Further, let <span class="math">f:\\mathbb{F}^{m}\\to\\mathbb{F}^{n}</span> be a homogeneous polynomial map of degree <span class="math">d</span> (Definition 14), and <span class="math">\\mathcal{L}_{\\mathrm{x}}:\\mathbb{F}^{m}\\to\\mathbb{X}</span> and <span class="math">\\mathcal{L}_{\\mathrm{e}}:\\mathbb{F}^{m}\\to\\mathbb{E}</span> be linear maps. Then, <span class="math">\\Pi_{\\mathsf{open}}^{\\mathrm{H}}</span> is a <span class="math">(d+1)^{\\log(\\ell)}</span>-special sound protocol for <span class="math">\\mathcal{R}_{\\mathsf{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)\\cup\\mathcal{R}_{\\mathsf{collision}}(\\mathcal{L}_{\\mathrm{x}})</span>.</p>

    <p class="text-gray-300">Proof. To prove <span class="math">\\Pi_{\\mathsf{open}}^{\\mathrm{H}}</span> is <span class="math">(d+1)^{\\log(\\ell)}</span>-special sound, it suffices to show that <span class="math">\\Pi_{\\mathsf{open}}^{(k)}</span> is <span class="math">(d+1)</span>-special sound protocol for <span class="math">\\mathcal{R}_{\\mathsf{open}}^{k}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)\\cup\\mathcal{R}_{\\mathsf{collision}}(\\mathcal{L}_{\\mathrm{x}})</span> for all <span class="math">k\\in\\{\\ell,\\ell/2,\\ldots,2\\}</span>.</p>

    <p class="text-gray-300">Assume we are given <span class="math">(d+1)</span> accepting transcripts <span class="math">t^{(1)},\\ldots,t^{(d+1)}</span> of <span class="math">\\Pi_{\\mathsf{open}}^{(k)}</span>,</p>

    <p class="text-gray-300"><span class="math">t^{(c)}=\\left(\\left\\{(\\overline{v}_{i,j})_{i=1}^{d-1}\\right\\}_{j=1}^{k/2},\\ r^{(c)},\\ \\left(x_{j}^{\\prime(c)}\\right)_{j=1}^{k/2}\\right)</span></p>

    <p class="text-gray-300">which each have the same initial message <span class="math">\\left\\{(\\overline{v}_{i,j})_{i=1}^{d-1}\\right\\}_{j=1}^{k/2}</span> and distinct verifier challenge <span class="math">r^{(c)}</span>. Consider an arbitrary <span class="math">j\\in[k/2]</span>, we will show that we can either</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>extract <span class="math">x_{j}^{\\prime(c)}</span> and <span class="math">x_{j+k/2}^{\\prime(c)}</span> such that <span class="math">\\left((\\overline{x}_{j}^{\\prime},\\overline{e}_{j}^{\\prime}),\\ (\\overline{x}_{j+k/2}^{\\prime},\\overline{e}_{j+k/2}^{\\prime});\\ x_{j}^{\\prime},\\ x_{j+k/2}^{\\prime}\\right)\\in\\mathcal{R}_{\\mathsf{open}}^{2}\\left(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f\\right)</span></li>

      <li>or <span class="math">a,a^{\\prime}\\in\\mathbb{F}^{m}</span> such that <span class="math">\\mathcal{L}_{\\mathrm{x}}(a)=\\mathcal{L}_{\\mathrm{x}}(a^{\\prime})</span>.</li>

    </ul>

    <p class="text-gray-300">Proof.</p>

    <p class="text-gray-300">For simplicity of notation, we will drop the subscript <span class="math">j</span> and <span class="math">j + k/2</span> by restricting our attention to the <span class="math">j</span>-th index of the transcripts:</p>

    <div class="my-4 text-center"><span class="math-block">\\left((\\overline{v}_i)_{i=1}^{d-1}, r^{(c)}, x&#x27;^{(c)}\\right) := t_j^{(c)}</span></div>

    <p class="text-gray-300">Furthermore, we will replace the subscripts <span class="math">j</span> and <span class="math">j + k/2</span> with subscripts 1 and 2 respectively.</p>

    <p class="text-gray-300"><strong>Single Extraction</strong>: Since <span class="math">r^{(1)} \\neq r^{(2)}</span>, we can solve for candidate openings <span class="math">x_1, x_2</span> in the following linear system:</p>

    <div class="my-4 text-center"><span class="math-block">\\left[ \\begin{array}{l} x&#x27;^{(1)} \\\\ x&#x27;^{(2)} \\end{array} \\right] = \\left[ \\begin{array}{cc} r^{(1)} &amp;amp; 1 \\\\ r^{(2)} &amp;amp; 1 \\end{array} \\right] \\left[ \\begin{array}{l} x_1 \\\\ x_2 \\end{array} \\right] \\tag{2}</span></div>

    <p class="text-gray-300">For every <span class="math">c \\in \\{3, \\ldots, d + 1\\}</span>, we can check if <span class="math">x&#x27;^{(c)} = r^{(c)} \\cdot x_1 + x_2</span>. If a single check fails for an index <span class="math">c</span>, we output a candidate collision <span class="math">a := x&#x27;^{(c)}</span> and <span class="math">a&#x27; := r^{(c)} \\cdot x_1 + x_2</span>. Otherwise, we output <span class="math">x_1, x_2</span> as candidate openings.</p>

    <p class="text-gray-300"><strong>Single Correctness</strong>: By (2) and linearity, we have</p>

    <div class="my-4 text-center"><span class="math-block">\\left[ \\begin{array}{l} \\mathcal{L}_{\\mathrm{x}}(x&#x27;^{(1)}) \\\\ \\mathcal{L}_{\\mathrm{x}}(x&#x27;^{(2)}) \\end{array} \\right] = \\left[ \\begin{array}{l} \\mathcal{L}_{\\mathrm{x}}(r^{(1)} \\cdot x_1 + x_2) \\\\ \\mathcal{L}_{\\mathrm{x}}(r^{(2)} \\cdot x_1 + x_2) \\end{array} \\right] = \\left[ \\begin{array}{cc} r^{(1)} &amp;amp; 1 \\\\ r^{(2)} &amp;amp; 1 \\end{array} \\right] \\left[ \\begin{array}{l} \\mathcal{L}_{\\mathrm{x}}(x_1) \\\\ \\mathcal{L}_{\\mathrm{x}}(x_2) \\end{array} \\right] \\tag{3}</span></div>

    <p class="text-gray-300">Furthermore, since the transcripts are accepting, we know for all <span class="math">c \\in [d + 1]</span>,</p>

    <div class="my-4 text-center"><span class="math-block">(r^{(c)} \\cdot \\bar{x}_1 + \\bar{x}_2) = \\mathcal{L}_{\\mathrm{x}}(x&#x27;^{(c)}) \\tag{4}</span></div>

    <p class="text-gray-300">Therefore, by (3) and (4), we must have</p>

    <div class="my-4 text-center"><span class="math-block">\\left[ \\begin{array}{cc} r^{(1)} &amp;amp; 1 \\\\ r^{(2)} &amp;amp; 1 \\end{array} \\right] \\left[ \\begin{array}{l} \\bar{x}_1 \\\\ \\bar{x}_2 \\end{array} \\right] = \\left[ \\begin{array}{cc} r^{(1)} &amp;amp; 1 \\\\ r^{(2)} &amp;amp; 1 \\end{array} \\right] \\left[ \\begin{array}{l} \\mathcal{L}_{\\mathrm{x}}(x_1) \\\\ \\mathcal{L}_{\\mathrm{x}}(x_2) \\end{array} \\right] \\quad \\Longrightarrow \\quad \\left[ \\begin{array}{l} \\bar{x}_1 \\\\ \\bar{x}_2 \\end{array} \\right] = \\left[ \\begin{array}{l} \\mathcal{L}_{\\mathrm{x}}(x_1) \\\\ \\mathcal{L}_{\\mathrm{x}}(x_2) \\end{array} \\right] \\tag{5}</span></div>

    <p class="text-gray-300">Thus, by (4) and (5), we have for all <span class="math">c \\in [d + 1]</span>,</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal{L}_{\\mathrm{x}}(x&#x27;^{(c)}) = r^{(c)} \\cdot \\bar{x}_1 + \\bar{x}_2 = r^{(c)} \\cdot \\mathcal{L}_{\\mathrm{x}}(x_1) + \\mathcal{L}_{\\mathrm{x}}(x_2) = \\mathcal{L}_{\\mathrm{x}}(r^{(c)} \\cdot x_1 + x_2) \\tag{6}</span></div>

    <p class="text-gray-300">Therefore, if there exists a <span class="math">c \\in \\{3, \\ldots, d + 1\\}</span> such that <span class="math">x&#x27;^{(c)} \\neq r^{(c)} \\cdot x_1 + x_2</span>. We output a valid collision <span class="math">a := x&#x27;^{(c)}</span> and <span class="math">a&#x27; := r^{(c)} \\cdot x_1 + x_2</span>.</p>

    <p class="text-gray-300">Otherwise, we must have for all <span class="math">c \\in [d + 1]</span>, <span class="math">x&#x27;^{(c)} = r^{(c)} \\cdot x_1 + x_2</span>, which, along with the linearity of <span class="math">\\mathcal{L}_{\\mathrm{e}}</span>, implies for some <span class="math">v_1, \\ldots, v_{d-1} \\in \\mathbb{F}^n</span>,</p>

    <div class="my-4 text-center"><span class="math-block">f(x&#x27;^{(c)}) = f(r^{(c)} \\cdot x_1 + x_2) = (r^{(c)})^d \\cdot f(x_1) + \\sum_{i=1}^{d-1} (r^{(c)})^i \\cdot v_i + f(x_2),</span></div>

    <div class="my-4 text-center"><span class="math-block">\\mathcal{L}_{\\mathrm{e}}(f(x&#x27;^{(c)})) = (r^{(c)})^d \\cdot \\mathcal{L}_{\\mathrm{e}}(f(x_1)) + \\sum_{i=1}^{d-1} (r^{(c)})^i \\cdot \\mathcal{L}_{\\mathrm{e}}(v_i) + \\mathcal{L}_{\\mathrm{e}}(f(x_2)). \\tag{7}</span></div>

    <p class="text-gray-300">Since the transcripts are accepting, we know for all <span class="math">c \\in [d + 1]</span>,</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal{L}_{\\mathrm{e}}(f(x&#x27;^{(c)})) = (r^{(c)})^d \\cdot \\bar{e}_1 + \\sum_{i=1}^{d-1} (r^{(c)})^i \\cdot \\bar{v}_i^{(c)} + \\bar{e}_2 \\tag{8}</span></div>

    <p class="text-gray-300">Therefore, both polynomials (7) and (8) of degree <span class="math">d</span> are equal at <span class="math">d+1</span> distinct points <span class="math">r^{(c)}</span> for <span class="math">c\\in[d+1]</span>, which implies their coefficients must be equal. Thus, we have</p>

    <p class="text-gray-300"><span class="math">\\overline{e}_{1}=\\mathcal{L}_{\\mathrm{e}}(f(x_{1}))\\quad\\text{and}\\quad\\overline{e}_{2}=\\mathcal{L}_{\\mathrm{e}}(f(x_{2}))</span> (9)</p>

    <p class="text-gray-300">By (5) and (9), we must have <span class="math">((\\overline{x}_{1},\\overline{e}_{1}),(\\overline{x}_{2},\\overline{e}_{2});\\;x_{1},x_{2})\\in\\mathcal{R}^{2}_{\\mathsf{open}}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)</span>.</p>

    <p class="text-gray-300">Full Extraction and Correctness: Since we considered an arbitrary <span class="math">j\\in[k/2]</span>, we can repeat the above procedure for all <span class="math">j\\in[k/2]</span>. Furthermore, our correctness argument trivially holds for all <span class="math">j\\in[k/2]</span>. Thus, we can extract <span class="math">\\left((\\overline{x}_{i},\\,\\overline{e}_{i})_{i=1}^{k}\\,;\\;(x_{i})_{i=1}^{k}\\right)\\in\\mathcal{R}^{k}_{\\mathsf{open}}\\,(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)</span> or <span class="math">(\\bot\\,;\\,a,a^{\\prime})\\in\\mathcal{R}_{\\mathsf{collision}}\\,(\\mathcal{L}_{\\mathrm{x}})</span>. This shows that <span class="math">\\Pi_{\\mathsf{open}}^{(k)}</span> is a <span class="math">(d+1)</span>-special sound protocol for <span class="math">\\mathcal{R}^{k}_{\\mathsf{open}}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)\\cup\\mathcal{R}_{\\mathsf{collision}}(\\mathcal{L}_{\\mathrm{x}})</span>. ∎</p>

    <h6 id="sec-49" class="text-base font-medium mt-4">Corollary 1 (FS(<span class="math">\\Pi_{\\mathsf{open}}^{\\mathrm{H}}</span>) is a folding scheme).</h6>

    <p class="text-gray-300">Let <span class="math">\\mathsf{FS}(\\Pi_{\\mathsf{open}}^{\\mathrm{H}})</span> denote the adaptive Fiat-Shamir transformation of the opening protocol <span class="math">\\Pi_{\\mathsf{open}}^{\\mathrm{H}}</span> (Definition 17), where the setup phase of <span class="math">\\mathsf{FS}(\\Pi_{\\mathsf{open}}^{\\mathrm{H}})</span> is the same as that of <span class="math">\\Pi_{\\mathsf{open}}^{\\mathrm{H}}</span> and the prover and verifier further have the access to a random oracle. Suppose the linear map <span class="math">\\mathcal{L}_{\\mathrm{x}}:\\mathbb{F}^{m}\\to\\mathbb{X}</span> further satisfies the binding property. Then <span class="math">\\mathsf{FS}(\\Pi_{\\mathsf{open}}^{\\mathrm{H}})</span> is an <span class="math">\\ell</span>-to-<span class="math">1</span> folding scheme (Definition 9) for the relation <span class="math">\\mathcal{R}_{\\mathsf{open}}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)</span>.</p>

    <h6 id="sec-50" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">The correctness follows from the completeness of the interactive argument <span class="math">\\Pi_{\\mathsf{open}}^{\\mathrm{H}}</span>. Next, we show the knowledge soundness property. From Theorem 6, <span class="math">\\Pi_{\\mathsf{open}}^{\\mathrm{H}}</span> is <span class="math">(d+1)^{\\log(\\ell)}</span>-special sound for relation <span class="math">\\mathcal{R}^{\\ell}_{\\mathsf{open}}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)\\cup\\mathcal{R}_{\\mathsf{collision}}(\\mathcal{L}_{\\mathrm{x}})</span>, thus by <em>[x1]</em> (which shows special-soundness tightly implies knowledge soundness), <span class="math">\\Pi_{\\mathsf{open}}^{\\mathrm{H}}</span> has knowledge error</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">$\\kappa_{\\mathsf{open}}:=1-\\left(1-\\frac{d}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\right)^{\\log\\ell}\\leq 1-\\left(1-\\frac{d\\log\\ell}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}\\right)=\\mathsf{negl}(\\lambda)$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">where the inequality holds because <span class="math">(1-x)^{n}\\geq 1-nx</span> for all <span class="math">0&lt;x&lt;1</span>. By Lemma 1, <span class="math">\\mathsf{FS}(\\Pi_{\\mathsf{open}}^{\\mathrm{H}})</span> is a NARK for the relation <span class="math">\\mathcal{R}^{\\ell}_{\\mathsf{open}}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)\\cup\\mathcal{R}_{\\mathsf{collision}}(\\mathcal{L}_{\\mathrm{x}})</span> with knowledge error <span class="math">(Q+1)\\cdot\\kappa_{\\mathsf{open}}=\\mathsf{negl}(\\lambda)</span>. Finally, by the binding property of <span class="math">\\mathcal{L}_{\\mathrm{x}}</span>, the extractor will output a witness for <span class="math">\\mathcal{R}_{\\mathsf{collision}}(\\mathcal{L}_{\\mathrm{x}})</span> only with negligible probability, that means if the extractor’s success probability is <span class="math">\\epsilon</span>, then with probability at least <span class="math">\\epsilon-\\mathsf{negl}(\\lambda)</span> the extracted witness is in the relation <span class="math">\\mathcal{R}^{\\ell}_{\\mathsf{open}}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)</span>. Therefore, we have that <span class="math">\\mathsf{FS}(\\Pi_{\\mathsf{open}}^{\\mathrm{H}})</span> is a NARK for the relation <span class="math">\\mathcal{R}^{\\ell}_{\\mathsf{open}}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)</span> with knowledge error <span class="math">(Q+1)\\cdot\\kappa_{\\mathsf{open}}+\\mathsf{negl}(\\lambda)=\\mathsf{negl}(\\lambda)</span>. And <span class="math">\\mathsf{FS}(\\Pi_{\\mathsf{open}}^{\\mathrm{H}})</span> satisfies knowledge soundness as an <span class="math">\\ell</span>-to-<span class="math">1</span> folding scheme for <span class="math">\\mathcal{R}_{\\mathsf{open}}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)</span>, which completes the proof. ∎</p>

    <h3 id="sec-51" class="text-xl font-semibold mt-8">A.3 Deferred Proof of Theorem 3</h3>

    <p class="text-gray-300"><em>Completeness:</em> Completeness of <span class="math">\\Pi_{\\mathsf{open}}</span> follows immediately from the linear homomorphism property of <span class="math">\\mathcal{L}_{\\mathrm{x}}</span> and <span class="math">\\mathcal{L}_{\\mathrm{e}}</span> and Lemma 6. In particular, the verifier’s checks will trivially pass by linearity. By Lemma 6, the prover can compute the vectors <span class="math">(q_{j})_{j\\in\\{0,\\ldots,d(\\ell-1)-\\ell\\}}</span> that satisfy the required polynomial expression in indeterminate <span class="math">Y</span>.</p>

    <h6 id="sec-52" class="text-base font-medium mt-4">Theorem 7 (Special Soundness of <span class="math">\\Pi_{\\mathsf{open}}</span> (Protocol 2)).</h6>

    <p class="text-gray-300">Let <span class="math">m,n,d,\\ell\\in\\mathbb{N}</span>, <span class="math">\\mathbb{F}</span> be a field, and <span class="math">\\mathbb{X},\\mathbb{E}</span> be vector spaces. Further, let <span class="math">f:\\mathbb{F}^{m}\\to\\mathbb{F}^{n}</span> be a polynomial map of degree <span class="math">d</span> (Definition 14), and <span class="math">\\mathcal{L}_{\\mathrm{x}}:\\mathbb{F}^{m}\\to\\mathbb{X}</span> and <span class="math">\\mathcal{L}_{\\mathrm{e}}:\\mathbb{F}^{m}\\to\\mathbb{E}</span> be linear maps. Then, <span class="math">\\Pi_{\\mathsf{open}}</span> is a <span class="math">d(\\ell-1)+1</span>-special sound protocol for <span class="math">\\mathcal{R}^{\\ell}_{\\mathsf{open}}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)\\cup\\mathcal{R}_{\\mathsf{collision}}(\\mathcal{L}_{\\mathrm{x}})</span>.</p>

    <h6 id="sec-53" class="text-base font-medium mt-4">Proof.</h6>

    <p class="text-gray-300">Assume we are given <span class="math">d(\\ell-1)+1</span> accepting transcripts <span class="math">t^{(1)},\\ldots,t^{(d(\\ell-1)+1)}</span> of <span class="math">\\Pi_{\\mathsf{open}}</span>,</p>

    <p class="text-gray-300"><span class="math">t^{(c)}=\\left((\\overline{q}_{j})_{j\\in\\{0,\\ldots,d(\\ell-1)-\\ell\\}},\\;r^{(c)},\\;x^{(c)}\\right)</span></p>

    <p class="text-gray-300">which each have the same initial message <span class="math">(\\overline{q}_j)_j</span> and distinct verifier challenge <span class="math">r^{(c)}</span>. We will show that we can either</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>extract <span class="math">(x_{i})_{i = 1}^{\\ell}</span> such that <span class="math">((\\overline{x}_i,\\overline{e}_i);x_i)_{i = 1}^\\ell \\in \\mathcal{R}_{\\mathrm{open}}^\\ell (\\mathcal{L}_x,\\mathcal{L}_e,f)</span></li>

      <li>or <span class="math">a, a&#x27; \\in \\mathbb{F}^m</span> such that <span class="math">\\mathcal{L}_{\\mathrm{x}}(a) = \\mathcal{L}_{\\mathrm{x}}(a&#x27;)</span>.</li>

    </ul>

    <p class="text-gray-300"><strong>Extraction</strong>: First, we solve for candidate openings <span class="math">(x_{i})_{i}</span> in the following linear system of equations:</p>

    <div class="my-4 text-center"><span class="math-block">\\left[ \\begin{array}{c} x ^ {(1)} \\\\ \\vdots \\\\ x ^ {(\\ell)} \\end{array} \\right] = \\left[ \\begin{array}{c c c} L _ {1} ^ {\\mathbb {H}} \\left(r ^ {(1)}\\right) &amp;amp; \\dots &amp;amp; L _ {\\ell} ^ {\\mathbb {H}} \\left(r ^ {(1)}\\right) \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ L _ {1} ^ {\\mathbb {H}} \\left(r ^ {(\\ell)}\\right) &amp;amp; \\dots &amp;amp; L _ {\\ell} ^ {\\mathbb {H}} \\left(r ^ {(\\ell)}\\right) \\end{array} \\right] \\left[ \\begin{array}{c} x _ {1} \\\\ \\vdots \\\\ x _ {\\ell} \\end{array} \\right] \\tag {10}</span></div>

    <p class="text-gray-300"><strong>Correctness</strong>: By (10) and linearity, we have that</p>

    <div class="my-4 text-center"><span class="math-block">\\left[ \\begin{array}{c} \\mathcal {L} _ {\\mathrm {x}} \\left(x ^ {(1)}\\right) \\\\ \\vdots \\\\ \\mathcal {L} _ {\\mathrm {x}} \\left(x ^ {(\\ell)}\\right) \\end{array} \\right] = \\left[ \\begin{array}{c c c} L _ {1} ^ {\\mathbb {H}} \\left(r ^ {(1)}\\right) &amp;amp; \\dots &amp;amp; L _ {\\ell} ^ {\\mathbb {H}} \\left(r ^ {(1)}\\right) \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ L _ {1} ^ {\\mathbb {H}} \\left(r ^ {(\\ell)}\\right) &amp;amp; \\dots &amp;amp; L _ {\\ell} ^ {\\mathbb {H}} \\left(r ^ {(\\ell)}\\right) \\end{array} \\right] \\left[ \\begin{array}{c} \\mathcal {L} _ {\\mathrm {x}} \\left(x _ {1}\\right) \\\\ \\vdots \\\\ \\mathcal {L} _ {\\mathrm {x}} \\left(x _ {\\ell}\\right) \\end{array} \\right] \\tag {11}</span></div>

    <p class="text-gray-300">Furthermore, since the transcripts are accepting, we must have that</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal {L} _ {\\mathrm {x}} \\left(x ^ {(c)}\\right) = \\sum_ {i = 1} ^ {\\ell} L _ {i} ^ {\\mathbb {H}} \\left(r ^ {(c)}\\right) \\cdot \\bar {x} _ {i} \\tag {12}</span></div>

    <p class="text-gray-300">for all <span class="math">c \\in [d(\\ell - 1) + 1]</span>. Thus, by (11) and (12), we have that</p>

    <div class="my-4 text-center"><span class="math-block">\\left[ \\begin{array}{c c c} L _ {1} ^ {\\mathbb {H}} (r ^ {(1)}) &amp;amp; \\ldots &amp;amp; L _ {\\ell} ^ {\\mathbb {H}} (r ^ {(1)}) \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ L _ {1} ^ {\\mathbb {H}} (r ^ {(\\ell)}) &amp;amp; \\ldots &amp;amp; L _ {\\ell} ^ {\\mathbb {H}} (r ^ {(\\ell)}) \\end{array} \\right] \\left[ \\begin{array}{c} \\overline {{x}} _ {1} \\\\ \\vdots \\\\ \\overline {{x}} _ {\\ell} \\end{array} \\right] = \\left[ \\begin{array}{c c c} L _ {1} ^ {\\mathbb {H}} (r ^ {(1)}) &amp;amp; \\ldots &amp;amp; L _ {\\ell} ^ {\\mathbb {H}} (r ^ {(1)}) \\\\ \\vdots &amp;amp; \\ddots &amp;amp; \\vdots \\\\ L _ {1} ^ {\\mathbb {H}} (r ^ {(\\ell)}) &amp;amp; \\ldots &amp;amp; L _ {\\ell} ^ {\\mathbb {H}} (r ^ {(\\ell)}) \\end{array} \\right] \\left[ \\begin{array}{c} \\mathcal {L} _ {\\mathrm {x}} (x _ {1}) \\\\ \\vdots \\\\ \\mathcal {L} _ {\\mathrm {x}} (x _ {\\ell}) \\end{array} \\right]</span></div>

    <div class="my-4 text-center"><span class="math-block">\\Downarrow</span></div>

    <div class="my-4 text-center"><span class="math-block">\\left[ \\begin{array}{c} \\bar {x} _ {1} \\\\ \\vdots \\\\ \\bar {x} _ {\\ell} \\end{array} \\right] = \\left[ \\begin{array}{c} \\mathcal {L} _ {\\mathrm {x}} \\left(x _ {1}\\right) \\\\ \\vdots \\\\ \\mathcal {L} _ {\\mathrm {x}} \\left(x _ {\\ell}\\right) \\end{array} \\right] \\tag {13}</span></div>

    <p class="text-gray-300">where (13) holds because the lagrange matrix is invertible for distinct values <span class="math">r^{(1)}, \\ldots, r^{(\\ell)}</span>. Thus, by (12) and (13), we have for all <span class="math">c \\in [d(\\ell - 1) + 1]</span>,</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal {L} _ {\\mathrm {x}} \\left(x ^ {(c)}\\right) = \\sum_ {i = 1} ^ {\\ell} L _ {i} ^ {\\mathbb {H}} \\left(r ^ {(c)}\\right) \\cdot \\bar {x} _ {i} = \\sum_ {i = 1} ^ {\\ell} L _ {i} ^ {\\mathbb {H}} \\left(r ^ {(c)}\\right) \\cdot \\mathcal {L} _ {\\mathrm {x}} \\left(x _ {i}\\right) = \\mathcal {L} _ {\\mathrm {x}} \\left(\\sum_ {i = 1} ^ {\\ell} L _ {i} ^ {\\mathbb {H}} \\left(r ^ {(c)}\\right) \\cdot x _ {i}\\right) \\tag {14}</span></div>

    <p class="text-gray-300">Therefore, if there exists a <span class="math">c \\in \\{\\ell + 1, \\dots, d(\\ell - 1) + 1\\}</span> such that <span class="math">x^{(c)} \\neq \\sum_{i=1}^{\\ell} L_i^{\\mathbb{H}}(r^{(c)}) \\cdot x_i</span>, we can output a valid collision <span class="math">a := x^{(c)}</span> and <span class="math">a&#x27; := \\sum_{i=1}^{\\ell} L_i^{\\mathbb{H}}(r^{(c)}) \\cdot x_i</span>.</p>

    <p class="text-gray-300">Otherwise, we must have for all <span class="math">c \\in [d(\\ell - 1) + 1]</span>, <span class="math">x^{(c)} = \\sum_{i=1}^{\\ell} L_i^{\\mathbb{H}}(r^{(c)}) \\cdot x_i</span>. Therefore, by Lemma 6 and the linearity of <span class="math">\\mathcal{L}_{\\mathrm{e}}</span>, this implies for some <span class="math">q_0, \\ldots, q_{d(\\ell - 1) - \\ell} \\in \\mathbb{F}^n</span>,</p>

    <div class="my-4 text-center"><span class="math-block">f(x^{(c)}) = f\\left(\\sum_{i=1}^{\\ell} L_i^{\\mathbb{H}}(r^{(c)}) \\cdot x_i\\right) = v_{\\mathbb{H}}(r^{(c)}) \\cdot \\left(\\sum_{j=0}^{d(\\ell-1)-\\ell} (r^{(c)})^j \\cdot q_j\\right) + \\sum_{i=1}^{\\ell} L_i^{\\mathbb{H}}(r^{(c)}) \\cdot f(x_i),</span></div>

    <div class="my-4 text-center"><span class="math-block">\\mathcal{L}_{\\mathrm{e}}(f(x^{(c)})) = v_{\\mathbb{H}}(r^{(c)}) \\cdot \\left(\\sum_{j=0}^{d(\\ell-1)-\\ell} (r^{(c)})^j \\cdot \\mathcal{L}_{\\mathrm{e}}(q_j)\\right) + \\sum_{i=1}^{\\ell} L_i^{\\mathbb{H}}(r^{(c)}) \\cdot \\mathcal{L}_{\\mathrm{e}}(f(x_i)). \\tag{15}</span></div>

    <p class="text-gray-300">Since the transcripts are accepting, we know for all <span class="math">c \\in [d(\\ell - 1) + 1]</span>,</p>

    <div class="my-4 text-center"><span class="math-block">\\mathcal{L}_{\\mathrm{e}}(f(x^{(c)})) = v_{\\mathbb{H}}(r^{(c)}) \\cdot \\left(\\sum_{j=0}^{d(\\ell-1)-\\ell} (r^{(c)})^j \\cdot \\bar{q}_j\\right) + \\left(\\sum_{i=1}^{\\ell} L_i^{\\mathbb{H}}(r^{(c)}) \\cdot \\bar{e}_i\\right) \\tag{16}</span></div>

    <p class="text-gray-300">Consider the polynomials</p>

    <div class="my-4 text-center"><span class="math-block">v_{\\mathbb{H}}(Y) \\cdot \\left(\\sum_{j=0}^{d(\\ell-1)-\\ell} Y^j \\cdot \\mathcal{L}_{\\mathrm{e}}(q_j)\\right) + \\sum_{i=1}^{\\ell} L_i^{\\mathbb{H}}(Y) \\cdot \\mathcal{L}_{\\mathrm{e}}(f(x_i))</span></div>

    <div class="my-4 text-center"><span class="math-block">v_{\\mathbb{H}}(Y) \\cdot \\left(\\sum_{j=0}^{d(\\ell-1)-\\ell} Y^j \\cdot \\bar{q}_j\\right) + \\sum_{i=1}^{\\ell} L_i^{\\mathbb{H}}(Y) \\cdot \\bar{e}_i</span></div>

    <p class="text-gray-300">of degree <span class="math">d(\\ell - 1)</span>. By equations (15) and (16), we know both polynomials are equal at <span class="math">d(\\ell - 1) + 1</span> distinct points <span class="math">\\{r^{(c)}\\}_c</span>, which implies they are equal. Since <span class="math">v_{\\mathbb{H}}(Y)</span> is degree <span class="math">\\ell</span> and <span class="math">L_i^{\\mathbb{H}}(Y)</span> is degree <span class="math">\\ell - 1</span> for all <span class="math">i \\in [\\ell]</span>, the polynomials being equal implies that,</p>

    <div class="my-4 text-center"><span class="math-block">\\bar{q}_j = \\mathcal{L}_{\\mathrm{e}}(q_j) \\text{ for all } j \\in \\{0, \\dots, d(\\ell-1)-\\ell\\} \\quad \\text{and} \\quad \\bar{e}_i = \\mathcal{L}_{\\mathrm{e}}(f(x_i)) \\text{ for all } i \\in [\\ell] \\tag{17}</span></div>

    <p class="text-gray-300">By (13) and (17), we must have <span class="math">((\\bar{x}_i, \\bar{e}_i); x_i)_{i=1}^\\ell \\in \\mathcal{R}_{\\mathrm{open}}^\\ell(\\mathcal{L}_x, \\mathcal{L}_e, f)</span>.</p>

    <p class="text-gray-300">Corollary 2 (FS(<span class="math">\\Pi_{\\mathrm{open}}</span>) is a folding scheme). Let <span class="math">\\mathsf{FS}(\\Pi_{\\mathrm{open}})</span> denote the adaptive Fiat-Shamir transformation of the opening protocol <span class="math">\\Pi_{\\mathrm{open}}</span> (Protocol 2), where the setup phase of <span class="math">\\mathsf{FS}(\\Pi_{\\mathrm{open}})</span> is the same as that of <span class="math">\\Pi_{\\mathrm{open}}</span> and the prover and verifier further have the access to a random oracle. Suppose the linear map <span class="math">\\mathcal{L}_x: \\mathbb{F}^m \\to \\mathbb{X}</span> further satisfies the binding property. Then <span class="math">\\mathsf{FS}(\\Pi_{\\mathrm{open}})</span> is an <span class="math">\\ell</span>-to-1 folding scheme (Definition 9) for the relation <span class="math">\\mathcal{R}_{\\mathrm{open}}(\\mathcal{L}_x, \\mathcal{L}_e, f)</span>.</p>

    <p class="text-gray-300">Proof. The correctness follows from the completeness of the interactive argument <span class="math">\\Pi_{\\mathrm{open}}</span>. Next, we show the knowledge soundness property. From Theorem 7, <span class="math">\\Pi_{\\mathrm{open}}</span> is a <span class="math">d(\\ell - 1) + 1</span>-special sound protocol for relation <span class="math">\\mathcal{R}_{\\mathrm{open}}^{\\ell}(\\mathcal{L}_x, \\mathcal{L}_e, f) \\cup \\mathcal{R}_{\\mathrm{collision}}(\\mathcal{L}_x)</span>, thus by [ACK21] (which shows special-soundness tightly implies knowledge soundness), <span class="math">\\Pi_{\\mathrm{open}}</span> has knowledge error</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\kappa_{\\mathrm{open}} := \\frac{d(\\ell-1)}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">} = \\mathrm{negl}(\\lambda).</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <p class="text-gray-300">By Lemma 1,  <span class="math">\\mathsf{FS}(\\Pi_{\\mathrm{open}})</span>  is a NARK for the relation  <span class="math">\\mathcal{R}_{\\mathrm{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)\\cup \\mathcal{R}_{\\mathrm{collision}}(\\mathcal{L}_{\\mathrm{x}})</span>  with knowledge error  <span class="math">(Q + 1)\\cdot \\kappa_{\\mathrm{open}} = \\mathrm{negl}(\\lambda)</span> . Finally, by the binding property of  <span class="math">\\mathcal{L}_{\\mathrm{x}}</span> , the extractor will output a witness for  <span class="math">\\mathcal{R}_{\\mathrm{collision}}(\\mathcal{L}_{\\mathrm{x}})</span>  only with negligible probability, that means if the extractor's success probability is  <span class="math">\\epsilon</span> , then with probability at least  <span class="math">\\epsilon -\\mathrm{negl}(\\lambda)</span>  the extracted witness is in the relation  <span class="math">\\mathcal{R}_{\\mathrm{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)</span> . Therefore, we have that  <span class="math">\\mathsf{FS}(\\Pi_{\\mathrm{open}})</span>  is a NARK for the relation  <span class="math">\\mathcal{R}_{\\mathrm{open}}^{\\ell}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)</span>  with knowledge error  <span class="math">(Q + 1)\\cdot \\kappa_{\\mathrm{open}} + \\mathrm{negl}(\\lambda) = \\mathrm{negl}(\\lambda)</span> . And  <span class="math">\\mathsf{FS}(\\Pi_{\\mathrm{open}})</span>  satisfies knowledge soundness as an  <span class="math">\\ell</span> -to-1 folding scheme for  <span class="math">\\mathcal{R}_{\\mathrm{open}}(\\mathcal{L}_{\\mathrm{x}},\\mathcal{L}_{\\mathrm{e}},f)</span> , which completes the proof.</p>

    <p class="text-gray-300">As noted in prior work [BCL+21, COS20], the definition of folding scheme knowledge soundness in Definition 9 implies a weaker notion of knowledge soundness called multi-instance extraction. Here is the definition of multi-instance extraction, we will use in the proof of SNARK knowledge soundness.</p>

    <p class="text-gray-300">Theorem 8 (Multi-Instance Folding Extraction). Given a knowledge sound folding scheme Fold (Definition 9) in the standard model for family of relations  <span class="math">\\mathcal{R}_{\\mathrm{fpp}}</span> . With respect to an auxiliary input distribution  <span class="math">\\mathcal{D}</span> , for every expected PPT adversary  <span class="math">\\tilde{\\mathcal{P}}</span> , there exists a positive polynomial  <span class="math">q</span>  and an expected PPT extractor  <span class="math">\\mathcal{E}</span>  such that for every predicate  <span class="math">\\rho</span> ,</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname * {P r} \\left[ \\begin{array}{c c} &amp;amp; \\rho \\big (\\mathsf {f p p}, \\mathsf {a i}, \\mathsf {a o}, [ (x _ {i} ^ {(j)}) _ {i = 1} ^ {n} ] _ {j = 1} ^ {\\ell} \\big) = 1 &amp;amp; \\mathsf {f p p} \\leftarrow \\mathcal {G} _ {\\mathsf {F o l d}} (1 ^ {\\lambda}) \\\\ \\wedge \\forall j \\in [ \\ell ], \\left((x _ {i} ^ {(j)}) _ {i = 1} ^ {n}, (w _ {i} ^ {(j)}) _ {i = 1} ^ {n}\\right) \\in R _ {\\mathsf {f p p}} ^ {n} &amp;amp; : \\mathsf {a i} \\leftarrow \\mathcal {D} (\\mathsf {f p p}) \\\\ &amp;amp; \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad ([ (x _ {i} ^ {(j)}, w _ {i} ^ {(j)}) _ {i = 1} ^ {n} ] _ {j = 1} ^ {\\ell}, \\mathsf {a o}) \\leftarrow \\mathcal {E} _ {\\tilde {\\mathcal {P}}} (\\mathsf {p p}, \\mathsf {a i}) \\end{array} \\right] \\geq \\frac {\\epsilon (\\tilde {\\mathcal {P}}) - \\mathsf {n e g l} (\\lambda)}{\\mathsf {p o l y} (\\lambda)}</span></div>

    <p class="text-gray-300">where  <span class="math">\\epsilon (\\tilde{\\mathcal{P}})</span>  is the following probability:</p>

    <div class="my-4 text-center"><span class="math-block">\\operatorname * {P r} \\left[ \\begin{array}{c c} &amp;amp; \\mathsf {f p p} \\leftarrow \\mathcal {G} _ {\\mathsf {F o l d}} (1 ^ {\\lambda}) \\\\ \\rho \\big (\\mathsf {f p p}, \\mathsf {a i}, \\mathsf {a o}, [ (x _ {i} ^ {(j)}) _ {i = 1} ^ {n} ] _ {j = 1} ^ {\\ell} \\big) = 1 &amp;amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (\\mathsf {f p p}) \\\\ \\wedge \\forall j \\in [ \\ell ], \\mathcal {V} _ {\\mathsf {F o l d}} (\\mathsf {f k}, (x _ {i} ^ {(j)}) _ {i = 1} ^ {n}, x ^ {(j)}, \\mathsf {p f} ^ {(j)}) = 1: \\left( \\begin{array}{c} [ (x _ {i} ^ {(j)}) _ {i = 1} ^ {n} ] _ {j = 1} ^ {\\ell}, \\\\ [ x ^ {(j)} ] _ {j = 1} ^ {\\ell}, [ w ^ {(j)} ] _ {j = 1} ^ {\\ell}, \\\\ [ \\mathsf {p f} ^ {(j)} ] _ {j = 1} ^ {\\ell}, \\mathsf {a o} \\end{array} \\right) \\leftarrow \\tilde {\\mathcal {P}} (\\mathsf {f p p}, \\mathsf {a i}) \\end{array} \\right]</span></div>

    <p class="text-gray-300">And, the runtime of  <span class="math">\\mathcal{E}_{\\tilde{\\mathcal{P}}}</span>  is at most a polynomial in the runtime of  <span class="math">\\tilde{\\mathcal{P}}</span> .</p>

    <p class="text-gray-300">Proof. First, define the following trivial extraction algorithm,</p>

    <p class="text-gray-300"><span class="math">\\mathcal{E}^{\\mathrm{ro}}(\\mathsf{pp},\\mathsf{ai})</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run the adversary  <span class="math">((\\sigma, \\mathsf{s}, G), x, (z, L, R)) \\gets \\tilde{\\mathcal{P}}^{\\mathrm{ro}}(\\mathsf{pp}, \\mathsf{ai})</span> .</li>

      <li>Parse  <span class="math">(x&#x27;, w) \\gets z</span> .</li>

      <li>Output  <span class="math">w</span> .</li>

    </ol>

    <p class="text-gray-300">As noted in prior work [BCL+21], the definition of knowledge soundness in Definition 5 is implied by the following stronger notion of knowledge soundness. With respect to an auxiliary distribution  <span class="math">\\mathcal{D}</span> , we want to</p>

    <p class="text-gray-300">show that the following probability is negligible for all expected polynomial time adversaries  <span class="math">\\tilde{\\mathcal{P}}^{\\mathrm{ro}}</span>  who make at most  <span class="math">Q</span>  queries to the random oracle ro,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} &amp;amp; \\operatorname {r o} \\leftarrow \\mathcal {O} (\\lambda) \\\\ \\mathcal {V} _ {\\text {n a r k}} ^ {\\text {r o}} (\\mathrm {n v k}, x, \\pi) = 1 &amp;amp; \\mathrm {p p} \\leftarrow \\mathcal {G} _ {\\text {n a r k}} \\left(1 ^ {\\lambda}\\right) \\\\ \\wedge &amp;amp; \\text {a i} \\leftarrow \\mathcal {D} (\\mathrm {p p}) \\\\ (i, x, w) \\notin \\mathrm {R} &amp;amp; (i, x, \\pi) \\leftarrow \\tilde {\\mathcal {P}} ^ {\\text {r o}} (\\mathrm {p p}, \\mathrm {a i}) \\\\ &amp;amp; w \\leftarrow \\mathcal {E} ^ {\\text {r o}} (\\mathrm {p p}, \\mathrm {a i}) \\\\ &amp;amp; (\\mathrm {n p k}, \\mathrm {n v k}) \\leftarrow \\mathcal {I} _ {\\text {n a r k}} (\\mathrm {p p}, i) \\end{array} \\right] \\leq \\operatorname {n e g l} (\\lambda) \\tag {18}</span></div>

    <p class="text-gray-300">By the construction of  <span class="math">\\mathcal{I}_{\\mathrm{nark}}</span>  and  <span class="math">\\mathcal{E}</span> , we have the probability in (18) is equivalent to the following,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} &amp;amp; \\operatorname {r o} \\leftarrow \\mathcal {O} (\\lambda) \\\\ \\mathcal {V} _ {\\text {n a r k}} ^ {\\text {r o}} \\left(\\left(\\mathrm {c k}, \\sigma , \\mathrm {s}, G\\right), x, (z, L, R)\\right) = 1 &amp;amp; \\mathrm {c k} \\leftarrow \\operatorname {S e t u p} _ {\\operatorname {c o m}} \\left(1 ^ {\\lambda}\\right) \\\\ \\wedge &amp;amp; : \\mathrm {a i} \\leftarrow \\mathcal {D} (\\mathrm {c k}) \\\\ \\left(\\left(\\sigma , \\mathrm {s}, G\\right), x, w\\right) \\notin \\mathfrak {R} _ {\\mathrm {p l k}} &amp;amp; \\left(\\left(\\sigma , \\mathrm {s}, G\\right), x, (z, L, R)\\right) \\leftarrow \\tilde {\\mathcal {P}} ^ {\\text {r o}} (\\mathrm {c k}, \\mathrm {a i}) \\\\ &amp;amp; \\left(x ^ {\\prime}, w\\right) \\leftarrow z \\end{array} \\right] \\tag {19}</span></div>

    <p class="text-gray-300">Given the verifier accepts, we must have that, for  <span class="math">\\alpha, \\beta \\stackrel{\\S}{\\leftarrow} \\mathsf{ro}(\\overline{\\sigma}, \\overline{\\mathsf{s}}, x, \\overline{z})</span>  as defined in the verifier construction, the following conditions hold,</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">1.  $x = (z_{1},\\ldots ,z_{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">})<span class="math">  , which implies  </span>z = (x,w)$</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">L_{1} = (z_{1} + \\alpha +\\beta)</span>  and  <span class="math">R_{1} = (z_{1} + \\sigma_{1}\\cdot \\alpha +\\beta)</span></li>

      <li>For all  <span class="math">i\\in \\{2,\\ldots ,n\\}</span> <span class="math">L_{i} = L_{i - 1}\\cdot [(z_{i} + i\\cdot \\alpha) + \\beta ]</span>  and  <span class="math">R_{i} = R_{i - 1}\\cdot [(z_{i} + \\sigma_{i}\\cdot \\alpha) + \\beta ]</span></li>

      <li><span class="math">L_{n} = R_{n}</span></li>

      <li>For all  <span class="math">i\\in [c]</span> <span class="math">G\\left(\\mathsf{s}^{\\mathsf{rn}(i,b)},z^{\\mathsf{rn}(i,t)}\\right) = 0.</span></li>

    </ol>

    <p class="text-gray-300">Thus, we must have the probability (19) is bounded by,</p>

    <div class="my-4 text-center"><span class="math-block">\\Pr \\left[ \\begin{array}{c c} &amp;amp; \\operatorname {r o} \\leftarrow \\mathcal {O} (\\lambda) \\\\ &amp;amp; \\operatorname {c k} \\leftarrow \\operatorname {S e t u p} _ {\\operatorname {c o m}} \\left(1 ^ {\\lambda}\\right) \\\\ \\prod_ {i = 1} ^ {n} \\left(z _ {i} + i \\cdot \\alpha + \\beta\\right) = \\prod_ {i = 1} ^ {n} \\left(z _ {i} + \\sigma_ {i} \\cdot \\alpha + \\beta\\right) &amp;amp; \\operatorname {a i} \\leftarrow \\mathcal {D} (\\operatorname {c k}) \\\\ \\wedge &amp;amp; : \\quad \\left(\\left(\\sigma , \\mathrm {s}, G\\right), x, (z, L, R)\\right) \\leftarrow \\tilde {\\mathcal {P}} ^ {\\text {r o}} (\\operatorname {c k}, \\operatorname {a i}) \\\\ \\{(i, z _ {i}) \\} _ {i = 1} ^ {n} \\neq \\left\\{\\left(\\sigma_ {i}, z _ {i}\\right) \\right\\} _ {i = 1} ^ {n} &amp;amp; \\overline {{\\operatorname {p l k}}} \\leftarrow \\operatorname {C o m m i t} (\\operatorname {c k}, (\\sigma , \\mathrm {s})) \\\\ &amp;amp; \\overline {{z}} \\leftarrow \\operatorname {C o m m i t} (\\operatorname {c k}, z) \\\\ &amp;amp; \\alpha , \\beta \\stackrel {\\S} {\\leftarrow} \\operatorname {r o} (\\overline {{\\sigma}}, \\overline {{\\mathrm {s}}}, x, \\overline {{z}}) \\end{array} \\right] \\tag {20}</span></div>

    <p class="text-gray-300">We will bound (20) by using Lemma 2, which bounds the probability an adversary wins the zero-finding game. To do so, we define the following adversary  <span class="math">\\mathcal{A}^{\\mathrm{ro}}(\\mathrm{ck},\\mathrm{ai})</span>  and function  <span class="math">f(\\sigma ,\\mathsf{s},x,z)</span>  for the zero-finding game.</p>

    <p class="text-gray-300"><span class="math">\\mathcal{A}^{\\mathrm{ro}}(\\mathsf{ck},\\mathsf{ai})</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run the prover  <span class="math">((\\sigma, \\mathsf{s}, G), x, (z, L, R)) \\gets \\tilde{\\mathcal{P}}^{\\mathrm{ro}}(\\mathsf{ck}, \\mathsf{ai})</span> .</li>

      <li>Output  <span class="math">(\\sigma, \\mathsf{s}, x, z)</span> .</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">f (\\sigma , \\mathsf {s}, x, z) := \\prod_ {i = 1} ^ {n} (z _ {i} + i \\cdot Y + X) - \\prod_ {i = 1} ^ {n} (z _ {i} + \\sigma_ {i} \\cdot Y + X)</span></div>

    <p class="text-gray-300">Notice the mapping from message  <span class="math">(\\sigma, \\mathsf{s}, x, z)</span>  to commitments  <span class="math">(\\overline{\\mathsf{plk}}, x, \\overline{z})</span>  is itself a binding commitment scheme. Thus, by Lemma 2 and Lemma 4, we have that the probability in (20) is bounded by the following,</p>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\operatorname * {P r} \\left[ \\begin{array}{c c} &amp; \\mathsf {r o} \\leftarrow \\mathcal {O} (\\lambda) \\\\ &amp; \\mathsf {c k} \\leftarrow \\mathsf {S e t u p} _ {\\mathsf {c o m}} (1 ^ {\\lambda}) \\\\ &amp; \\mathsf {a i} \\leftarrow \\mathcal {D} (\\mathsf {c k}) \\\\ p (\\alpha , \\beta) = 0 &amp; (\\sigma , \\mathsf {s}, x, z) \\leftarrow \\mathcal {A} ^ {\\mathsf {r o}} (\\mathsf {c k}, \\mathsf {a i}) \\\\ \\wedge &amp; \\overline {{\\mathsf {p l k}}} \\leftarrow \\mathsf {C o m m i t} (\\mathsf {c k}, (\\sigma , \\mathsf {s})) \\\\ p \\neq 0 &amp; \\overline {{\\mathsf {z}}} \\leftarrow \\mathsf {C o m m i t} (\\mathsf {c k}, z) \\\\ &amp; \\alpha , \\beta \\stackrel {\\S} {\\leftarrow} \\mathsf {r o} (\\overline {{\\sigma}}, \\overline {{\\mathsf {s}}}, x, \\overline {{\\mathsf {z}}}) \\\\ &amp; p \\leftarrow f (\\sigma , \\mathsf {s}, x, z) \\end{array} \\right] \\leq \\sqrt {(Q + 1) \\cdot \\frac {2 n}{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb {F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}} + \\mathsf {n e g l} (\\lambda)</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <div class="my-4 text-center"><span class="math-block"></span></div>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">Since  $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\mathbb{F}</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">\\approx 2^{\\lambda}<span class="math">  and  </span>Q$  is a polynomial number of queries, the bound must be negligible in the security parameter. This completes our proof.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <p class="text-gray-300">The PCD extractor in  <span class="math">\\left[\\mathrm{BCL}^{+}21\\right]</span>  extracts a PCD graph  <span class="math">\\mathsf{T}</span>  that is a tree, where every node is labeled with  <span class="math">(Z,\\mathsf{loc})</span> . Without loss of generality, this tree can be used to construct a PCD graph as in Definition 12. We use the notation  <span class="math">L_{\\mathsf{T}}(j)</span>  to denote the set of nodes at depth  <span class="math">j</span>  in the tree and  <span class="math">\\mathsf{o}(\\mathsf{T})</span>  to denote the root node label of the tree.</p>

    <p class="text-gray-300">Extractor Construction: Given a malicious snark prover  <span class="math">\\tilde{\\mathcal{P}}</span> , we will construction an extractor  <span class="math">\\mathsf{Ext}</span>  that extracts a witness from a malicious prover.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>First, we construct a malicious PCD prover  <span class="math">\\tilde{\\mathcal{P}}_{\\mathrm{pcd}}(\\mathrm{fpp},\\mathrm{ai}_{\\mathrm{pcd}})</span>  (Definition 12) as follows:</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\tilde{\\mathcal{P}}_{\\mathrm{pcd}}(\\mathsf{pp}_{\\mathrm{pcd}},(\\mathsf{fpp},\\mathsf{pp}_{\\mathsf{H}},\\mathsf{ck},\\mathsf{ai}))</span></p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Assign  <span class="math">\\mathsf{pp} \\gets (\\mathsf{ck}, \\mathsf{pp}_{\\mathsf{pcd}}, \\mathsf{fpp}, \\mathsf{pp}_{\\mathsf{H}})</span> .</li>

      <li>Run the malicious NARK prover  <span class="math">(\\mathrm{idx},x,\\pi ,\\mathrm{aux})\\gets \\tilde{\\mathcal{P}}^{\\mathrm{ro}}(\\mathrm{pp},\\mathrm{ai})</span></li>

      <li>Run the folding scheme indexer  <span class="math">(\\mathsf{fpk},\\mathsf{fvk})\\gets \\mathcal{I}_{\\mathsf{Fold}}(\\mathsf{pp})</span></li>

      <li>Run the NARK indexer  <span class="math">(\\mathsf{npk},\\mathsf{nvk})\\gets \\mathcal{I}_{\\mathsf{nark}}(\\mathsf{pp},\\mathsf{idx})</span></li>

      <li>Parse nvk to obtain hplk.</li>

      <li>Parse proof  <span class="math">(\\mathsf{hz},\\mathsf{Z},\\pi_{\\mathsf{pcd}},W,z^{(1)},\\pi_{\\mathsf{MT}})\\gets \\pi</span></li>

      <li>Assign PCD auxiliary output  <span class="math">\\mathsf{aux}_{\\mathsf{pcd}} \\coloneqq (\\mathsf{idx}, x, W, z^{(1)}, \\pi_{\\mathsf{MT}}, \\mathsf{aux})</span></li>

      <li>Output the following tuple (Definition 12),  <span class="math">(\\varphi_{\\mathsf{pp}_{\\mathsf{H}},\\mathsf{fvk}},\\mathsf{Z},\\pi_{\\mathsf{pcd}},\\mathsf{aux}_{\\mathsf{pcd}})</span>  where  <span class="math">\\varphi_{\\mathsf{pp}_{\\mathsf{H}},\\mathsf{fvk}}</span>  is the predicate defined in Definition 21.</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let <span class="math">\\mathsf{Ext}_{\\mathsf{pcd}}</span> be the extractor that corresponds to the PCD prover <span class="math">\\tilde{\\mathcal{P}}_{\\mathsf{pcd}}</span> from the knowledge soundness of the PCD scheme (Definition 12).</li>

      <li>Next, we construct <span class="math">\\mathsf{Ext}^{(0)}(\\mathsf{pp},\\mathsf{ai})</span> as follows:</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\mathsf{Ext}^{(0)}(\\mathsf{pp},\\mathsf{ai})</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse <span class="math">(\\mathsf{ck},\\mathsf{pp}_{\\mathsf{pcd}},\\mathsf{fpp},\\mathsf{pp}_{\\mathsf{H}})\\leftarrow \\mathsf{pp}</span>.</li>

      <li>Assign <span class="math">\\mathsf{ai}_{\\mathsf{pcd}} \\gets (\\mathsf{fpp}, \\mathsf{pp}_{\\mathsf{H}}, \\mathsf{ck}, \\mathsf{ai})</span>.</li>

      <li>Run the PCD extractor <span class="math">(\\varphi, \\mathsf{T}, \\mathsf{aux}_{\\mathsf{pcd}}) \\gets \\mathsf{Ext}_{\\mathsf{pcd}}(\\mathsf{pp}_{\\mathsf{pcd}}, \\mathsf{ai}_{\\mathsf{pcd}})</span>.</li>

      <li>Parse <span class="math">(\\mathsf{idx},x,W,z^{(1)},\\pi_{\\mathsf{MT}},\\mathsf{aux})\\gets \\mathsf{aux}_{\\mathsf{pcd}}</span>.</li>

      <li>Denote <span class="math">(Z, \\mathsf{loc})</span> to be the root label of <span class="math">T</span>. Append the folding relation witness <span class="math">W</span> to the root label <span class="math">(Z, \\mathsf{loc}, W)</span>. We refer to this new graph as <span class="math">T&#x27;</span>.</li>

      <li>Output the following tuple, <span class="math">(\\varphi, T&#x27;, \\mathsf{aux}_{\\mathsf{pcd}})</span>.</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Next, we construct a malicious folding prover <span class="math">\\tilde{\\mathcal{P}}_{\\mathsf{Fold}}^{(j)}(\\mathsf{fpp},\\mathsf{ai}_{\\mathsf{Fold}})</span> (Definition 9) as follows:</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\tilde{\\mathcal{P}}_{\\mathsf{Fold}}^{(j)}(\\mathsf{fpp},(\\mathsf{pp}_{\\mathsf{pcd}},\\mathsf{pp}_{\\mathsf{H}},\\mathsf{ck},\\mathsf{ai}))</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Assign <span class="math">\\mathsf{pp} \\gets (\\mathsf{ck}, \\mathsf{pp}_{\\mathsf{pcd}}, \\mathsf{fpp}, \\mathsf{pp}_{\\mathsf{H}})</span>.</li>

      <li>Run the extractor <span class="math">(\\varphi, \\mathsf{T}, \\mathsf{aux}_{\\mathsf{pcd}}) \\gets \\mathsf{Ext}^{(j-1)}(\\mathsf{pp}, \\mathsf{ai})</span>.</li>

      <li>For every vertex <span class="math">v \\in L_T(j - 1)</span>,</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Denote <span class="math">(Z^{(v)}, \\mathsf{loc}^{(v)}, W^{(v)})</span> to be the label of <span class="math">v</span> and <span class="math">(Z_i^{(v)}, \\mathsf{loc}_i^{(v)})</span> to be the label of the <span class="math">i</span>-th child.</li>

      <li>Parse <span class="math">(p^{(v)}, \\mathsf{hplk}^{(v)}, \\mathsf{hz}^{(v)}, X^{(v)}) \\gets Z</span> and <span class="math">\\mathsf{pf}^{(v)} \\gets \\mathsf{loc}</span>.</li>

      <li>For each child, parse <span class="math">(p_i^{(v)}, \\mathsf{hplk}_i^{(v)}, \\mathsf{hz}_i^{(v)}, X_i^{(v)}) \\gets Z_i</span>.</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Assign folding auxiliary output <span class="math">\\mathsf{aux}_{\\mathsf{Fold}} := (\\varphi, \\mathsf{T}, \\mathsf{aux}_{\\mathsf{pcd}})</span>.</li>

      <li>Output the following tuple (Definition 9),</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\left(\\left(X _ {i} ^ {(v)}\\right) _ {i = 1} ^ {k}\\right) _ {v}, \\left(X ^ {(v)}\\right) _ {v}, \\left(W ^ {(v)}\\right) _ {v}, \\left(\\mathsf {p f} ^ {(v)}\\right) _ {v}, \\mathsf {a u x} _ {\\mathsf {F o l d}}\\right).</span></div>

    <p class="text-gray-300">where index <span class="math">v</span> denotes every <span class="math">v \\in L_T(j)</span>.</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Let <span class="math">\\mathsf{Ext}_{\\mathsf{Fold}}</span> be the extractor that corresponds to the folding prover <span class="math">\\tilde{\\mathcal{P}}_{\\mathsf{Fold}}</span> from the knowledge soundness of the folding scheme (Definition 9).</li>

      <li>Next, we construct <span class="math">\\mathsf{Ext}^{(j)}(\\mathsf{pp},\\mathsf{ai})</span> as follows:</li>

    </ul>

    <p class="text-gray-300"><span class="math">\\mathsf{Ext}^{(j)}(\\mathsf{pp},\\mathsf{ai})</span>:</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse <span class="math">(\\mathsf{ck},\\mathsf{pp}_{\\mathsf{pcd}},\\mathsf{fpp},\\mathsf{pp}_{\\mathsf{H}})\\gets \\mathsf{pp}</span>.</li>

      <li>Assign <span class="math">\\mathsf{ai}_{\\mathsf{Fold}} \\gets (\\mathsf{pp}_{\\mathsf{pcd}}, \\mathsf{pp}_{\\mathsf{H}}, \\mathsf{ck}, \\mathsf{ai})</span>.</li>

      <li>Run the folding extractor <span class="math">\\mathsf{Ext}_{\\mathsf{Fold}}(\\mathsf{fpp}, \\mathsf{ai}_{\\mathsf{Fold}})</span> to obtain the following tuple,</li>

    </ol>

    <div class="my-4 text-center"><span class="math-block">\\left(\\left(\\left(X _ {i} ^ {(v)}, W _ {i} ^ {(v)}\\right) _ {i = 1} ^ {k}\\right) _ {v}, \\mathbf {a u x} _ {\\text {F o l d}}\\right). \\tag {21}</span></div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse <span class="math">(\\varphi, \\mathsf{T}, \\mathsf{aux}_{\\mathsf{pcd}}) \\gets \\mathsf{aux}_{\\mathsf{Fold}}</span>.</li>

      <li>For every vertex <span class="math">v \\in L_T(j - 1)</span>,</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Denote by <span class="math">(Z_i^{(v)}, \\mathsf{loc}_i^{(v)})</span> to be the label of the <span class="math">i</span>-th child of <span class="math">v</span>.</li>

      <li>For every child, append the corresponding folding relation witness <span class="math">W_{i}^{(v)}</span> to its label <span class="math">(Z_{i}^{(v)}, \\mathsf{loc}_{i}^{(v)}, W_{i}^{(v)})</span>.</li>

    </ul>

    <p class="text-gray-300">We refer to this new graph as <span class="math">\\mathsf{T}&#x27;</span>.</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Output the following tuple, <span class="math">(\\varphi, \\mathsf{T}&#x27;, \\mathsf{aux}_{\\mathsf{pcd}})</span>.</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Setting <span class="math">d = \\log_k(n / m)</span>, a constant for <span class="math">k = O(\\lambda)</span>. We define the SNARK extractor <span class="math">\\mathsf{Ext}</span> as follows:</li>

    </ul>

    <p class="text-gray-300">Ext(pp, ai):</p>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Run the extractor <span class="math">(\\varphi, \\mathsf{T}, \\mathsf{aux}_{\\mathsf{pcd}}) \\leftarrow \\mathsf{Ext}^{(d)}(\\mathsf{pp}, \\mathsf{ai})</span>.</li>

      <li>Parse <span class="math">(\\mathsf{idx}, x, W, z^{(1)}, \\pi_{\\mathsf{MT}}, \\mathsf{aux}) \\leftarrow \\mathsf{aux}_{\\mathsf{pcd}}</span>.</li>

      <li>For every vertex <span class="math">v \\in \\mathsf{L}_T(d)</span>, denote it's label as <span class="math">(Z^{(v)}, \\mathsf{loc}^{(v)}, W^{(v)})</span>. Parse the folding witness <span class="math">W^{(v)}</span> to obtain <span class="math">z^{(v)}</span>.</li>

      <li>Assign <span class="math">z</span> to be the concatenation of all <span class="math">(z^{(v)})_{v \\in \\mathsf{L}_T(d)}</span>.</li>

    </ol>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">5. Assign <span class="math">w</span> to be the last $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> elements of </span>z$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Output the following tuple, <span class="math">(\\mathsf{idx}, x, w, \\mathsf{aux})</span></li>

    </ol>

    <p class="text-gray-300">Distinguishing Predicates: By the knowledge soundness of PCD (Definition 12) and Folding (Definition 9), we are able to choose arbitrary distinguishing predicates <span class="math">\\rho_{\\mathsf{pcd}}</span> and <span class="math">\\rho_{\\mathsf{Fold}}</span>. We will use these to constrain the output of our intermediate extractors and adversaries. This will be essential to for the correctness proof of our SNARK extractor (Definition 5).</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\rho_{\\mathsf{pcd}}(\\mathsf{pp}_{\\mathsf{pcd}}, \\mathsf{ai}_{\\mathsf{pcd}}, \\mathsf{aux}_{\\mathsf{pcd}}, \\varphi, Z)</span>:</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse PCD auxiliary input <span class="math">(\\mathsf{fpp}, \\mathsf{pp}_{\\mathsf{H}}, \\mathsf{ck}, \\mathsf{ai}) \\leftarrow \\mathsf{ai}_{\\mathsf{pcd}}</span>.</li>

      <li>Parse PCD auxiliary output <span class="math">(\\mathsf{idx}, x, W, z^{(1)}, \\pi_{\\mathsf{MT}}, \\mathsf{aux}) \\leftarrow \\mathsf{aux}_{\\mathsf{pcd}}</span>.</li>

      <li>Parse PCD output <span class="math">(p, \\mathsf{hplk}&#x27;, \\mathsf{hz}, X) \\leftarrow Z</span>.</li>

      <li>Assign folding verifier key <span class="math">(\\cdot, \\mathsf{fvk}) \\leftarrow \\mathcal{I}_{\\mathsf{Fold}}(\\mathsf{fpp})</span>.</li>

      <li>Assign NARK parameters <span class="math">\\mathsf{pp} \\leftarrow (\\mathsf{ck}, \\mathsf{pp}_{\\mathsf{pcd}}, \\mathsf{fpp}, \\mathsf{pp}_{\\mathsf{H}})</span>.</li>

      <li>Assign NARK verifier key <span class="math">(\\cdot, \\mathsf{nvk}) \\leftarrow \\mathcal{I}_{\\mathsf{nark}}(\\mathsf{pp}, \\mathsf{idx})</span>.</li>

      <li>Parse <span class="math">\\mathsf{nvk}</span> to obtain commitment to index <span class="math">\\mathsf{hplk}</span>.</li>

      <li>Derive challenges <span class="math">\\alpha, \\beta \\leftarrow \\mathsf{ro}(\\mathsf{hplk}, x, \\mathsf{hz})</span>.</li>

      <li>Derive commitment <span class="math">\\overline{z}_1 \\leftarrow \\mathsf{Commit}(\\mathsf{ck}, z^{(1)})</span>.</li>

      <li>Output 1 if and only if the following conditions hold:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>NARK predicate agrees <span class="math">\\rho(\\mathsf{pp}, \\mathsf{ai}, \\mathsf{aux}, \\mathsf{idx}, x) = 1</span> (Definition 5).</li>

      <li>Commitment to index agrees <span class="math">\\mathsf{hplk}&#x27; = \\mathsf{hplk}</span>.</li>

      <li>PCD Predicate <span class="math">\\varphi = \\varphi_{\\mathsf{pp}_{\\mathsf{H}},\\mathsf{fvk}}</span> (Definition 21).</li>

      <li>Product <span class="math">p = 1</span>.</li>

    </ul>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- Instance $x = (z_1^{(1)}, \\ldots, z_{</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">}^{(1)})$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>MT verifier <span class="math">\\mathsf{MT.Verify}_k(\\mathsf{pp}_{\\mathsf{H}}, \\mathsf{hz}, \\{1\\}, \\overline{z}_1, \\pi_{\\mathsf{MT}})</span> accepts.</li>

      <li>Valid pair <span class="math">(X, W) \\in \\mathcal{R}_{\\mathrm{open}}(\\mathcal{L}_\\kappa, \\mathcal{L}_\\kappa, \\tilde{f}_{\\alpha,\\beta}^G)</span> (Definition 20, Definition 19).</li>

    </ul>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\rho_{\\mathsf{Fold}}(\\mathsf{fpp}, \\mathsf{ai}_{\\mathsf{Fold}}, \\mathsf{aux}_{\\mathsf{Fold}}, (x_i^{(j)})_{i,j \\in [k]})</span>:</li>

    </ul>

    <ol class="list-decimal list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>Parse folding auxiliary input <span class="math">(\\mathsf{pp}_{\\mathsf{pcd}}, \\mathsf{pp}_{\\mathsf{H}}, \\mathsf{ck}, \\mathsf{ai}) \\leftarrow \\mathsf{ai}_{\\mathsf{Fold}}</span>.</li>

      <li>Parse folding auxiliary output <span class="math">(\\varphi, \\mathsf{T}, \\mathsf{aux}_{\\mathsf{pcd}}) \\leftarrow \\mathsf{aux}_{\\mathsf{Fold}}</span>.</li>

      <li>Assign <span class="math">\\mathsf{ai}_{\\mathsf{pcd}} \\leftarrow (\\mathsf{fpp}, \\mathsf{pp}_{\\mathsf{H}}, \\mathsf{ck}, \\mathsf{ai})</span>.</li>

      <li>Output 1 if and only if the following conditions hold:</li>

    </ol>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\rho_{\\mathsf{pcd}}(\\mathsf{pp}_{\\mathsf{pcd}}, \\mathsf{ai}_{\\mathsf{pcd}}, \\mathsf{aux}_{\\mathsf{pcd}}, \\varphi, Z) = 1</span>.</li>

      <li><span class="math">\\mathsf{T}</span> is <span class="math">\\varphi</span>-compliant (Definition 12).</li>

    </ul>

    <p class="text-gray-300">66</p>

    <p class="text-gray-300">Correctness of Extractor: We want to show that our SNARK is knowledge sound (Definition 5). Consider an arbitrary predicate  <span class="math">\\rho</span> . Define  <span class="math">\\epsilon(\\tilde{\\mathcal{P}})</span>  to be the following probability:</p>

    <div class="my-4 text-center"><span class="math-block">\\epsilon (\\tilde {\\mathcal {P}}) := \\Pr \\left[ \\begin{array}{c c} &amp;amp; \\mathsf {r o} \\leftarrow \\mathcal {O} (\\lambda) \\\\ &amp;amp; \\mathsf {p p} \\leftarrow \\mathcal {G} _ {\\mathsf {n a r k}} (1 ^ {\\lambda}) \\\\ \\rho \\big (\\mathsf {p p}, \\mathsf {a i}, \\mathsf {a o}, \\mathsf {i d x}, x \\big) = 1 &amp;amp; : \\mathsf {a i} \\leftarrow \\mathcal {D} (\\mathsf {p p}) \\\\ \\wedge \\mathcal {V} _ {\\mathsf {n a r k}} ^ {\\mathsf {r o}} (\\mathsf {n v k}, x, \\pi) = 1 &amp;amp; : \\mathsf {n p k}, \\mathsf {n v k}) \\leftarrow \\mathcal {I} _ {\\mathsf {n a r k}} (\\mathsf {p p}, \\mathsf {i d x}) \\\\ &amp;amp; (\\mathsf {i d x}, x, \\pi , \\mathsf {a o}) \\leftarrow \\tilde {\\mathcal {P}} ^ {\\mathsf {r o}} (\\mathsf {p p}, \\mathsf {a i}) \\end{array} \\right]</span></div>

    <p class="text-gray-300">Extracting the PCD Tree: We will first argue that the output of  <span class="math">\\tilde{\\mathcal{P}}_{\\mathrm{pcd}}</span>  satisfies  <span class="math">\\rho_{\\mathrm{pcd}}</span>  with probability at least  <span class="math">\\epsilon (\\tilde{\\mathcal{P}})</span> . By definition of  <span class="math">\\epsilon (\\tilde{\\mathcal{P}})</span> , the output of the prover  <span class="math">\\tilde{\\mathcal{P}}</span>  satisfies the NARK predicate  <span class="math">\\rho</span>  and causes the NARK verifier  <span class="math">\\nu_{\\mathrm{nark}}</span>  to accept with probability  <span class="math">\\epsilon (\\tilde{\\mathcal{P}})</span> . Thus, by construction of  <span class="math">\\nu_{\\mathrm{nark}}</span> , the conditions of  <span class="math">\\rho_{\\mathrm{pcd}}</span>  are satisfied with probability at least  <span class="math">\\epsilon (\\tilde{\\mathcal{P}})</span> . By knowledge soundness of the PCD scheme (Definition 12), the PCD extractor  <span class="math">\\mathsf{Ext}_{\\mathrm{pcd}}</span>  outputs  <span class="math">(\\varphi ,\\mathsf{T},\\mathsf{aux}_{\\mathrm{pcd}})</span>  such that  <span class="math">\\rho_{\\mathrm{pcd}}</span>  accepts (for  <span class="math">Z = o(T)</span> ) and  <span class="math">\\mathsf{T}</span>  is  <span class="math">\\varphi</span> -compliant with probability at least  <span class="math">\\epsilon (\\tilde{\\mathcal{P}}) - \\mathsf{negl}(\\lambda)</span> . By induction, for  <span class="math">j = 0,\\ldots ,d = \\log_k(n / m)</span> , we will now argue that  <span class="math">\\mathsf{Ext}^{(j)}</span>  outputs  <span class="math">(\\varphi ,\\mathsf{T},\\mathsf{aux}_{\\mathrm{pcd}})</span>  such that</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\rho_{\\mathrm{pcd}}</span>  accepts (with argument  <span class="math">Z = o(T)</span> ) on the output.</li>

      <li><span class="math">\\mathsf{T}</span>  is  <span class="math">\\varphi</span> -compliant.</li>

      <li>For every vertex  <span class="math">v \\in \\mathsf{L}_{\\mathsf{T}}(j - 1)</span> , the label  <span class="math">((\\ldots, X^{(v)}) \\leftarrow \\mathsf{Z}^{(v)}, \\mathsf{loc}^{(v)}, W^{(v)})</span>  must have  <span class="math">(X^{(v)}, W^{(v)}) \\in \\mathcal{R}_{\\mathrm{open}}(\\mathcal{L}_{\\mathbf{x}}, \\mathcal{L}_{\\mathbf{e}}, \\widehat{f}_{\\alpha, \\beta}^{G})</span> .</li>

    </ul>

    <p class="text-gray-300">with probability at least  <span class="math">(\\epsilon (\\tilde{\\mathcal{P}}) - \\mathrm{negl}(\\lambda)) / \\mathrm{poly}(\\lambda)</span> .</p>

    <p class="text-gray-300">Base Case: Note, by construction,  <span class="math">\\mathsf{Ext}^{(0)}</span>  trivially appends a witness value to the output of  <span class="math">\\mathsf{Ext}_{\\mathsf{pcd}}</span> . Thus, by our argument above, the  <span class="math">\\mathsf{Ext}^{(0)}</span>  outputs  <span class="math">(\\varphi, \\mathsf{T}, \\mathsf{aux}_{\\mathsf{pcd}})</span>  such that  <span class="math">\\rho_{\\mathsf{pcd}}</span>  accepts and  <span class="math">\\mathsf{T}&#x27;</span>  is  <span class="math">\\varphi</span> -compliant with probability at least  <span class="math">\\epsilon(\\tilde{\\mathcal{P}}) - \\mathsf{negl}(\\lambda)</span> . By definition of  <span class="math">\\rho_{\\mathsf{pcd}}</span> , we must have that the root node label  <span class="math">((\\ldots, X) := Z, \\mathsf{loc}, W)</span>  contains  <span class="math">(X, W) \\in \\mathcal{R}_{\\mathsf{open}}(\\mathcal{L}_{\\mathbf{x}}, \\mathcal{L}_{\\mathbf{e}}, \\widehat{f}_{\\alpha, \\beta}^{G})</span> .</p>

    <p class="text-gray-300">Inductive Step: Assume  <span class="math">(\\varphi, \\mathsf{T}, \\mathsf{aux}_{\\mathsf{pcd}}) \\gets \\mathsf{Ext}^{(j-1)}</span>  satisfies the inductive hypothesis for  <span class="math">j-1</span> . By definition of  <span class="math">\\rho_{\\mathsf{pcd}}</span> , we must have that  <span class="math">\\varphi = \\varphi_{\\mathsf{pp}_{\\mathsf{H}}, \\mathsf{fvk}}</span>  (Definition 21). Thus, we must have that  <span class="math">\\mathsf{T}</span>  is  <span class="math">\\varphi_{\\mathsf{pp}_{\\mathsf{H}}, \\mathsf{fvk}}</span> -compliant. By definition of  <span class="math">\\varphi_{\\mathsf{pp}_{\\mathsf{H}}, \\mathsf{fvk}}</span> , we must have that for every vertex  <span class="math">v \\in \\mathsf{L}_{\\mathsf{T}}(j-1)</span> ,</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>the label  <span class="math">((\\ldots, X^{(v)}) \\leftarrow Z^{(v)}, \\mathsf{loc}^{(v)}, W^{(v)})</span>  must have  <span class="math">(X^{(v)}, W^{(v)}) \\in \\mathcal{R}_{\\mathrm{open}}(\\mathcal{L}_{\\mathbf{x}}, \\mathcal{L}_{\\mathbf{e}}, \\hat{f}_{\\alpha, \\beta}^{G})</span> ;</li>

      <li>the local data contains a folding proof  <span class="math">\\mathsf{pf}^{(v)}\\gets \\mathsf{loc}^{(v)}</span></li>

      <li>the children node labels contains instance  <span class="math">(X_{i}^{(v)})_{i = 1}^{k}</span>  such that  <span class="math">\\mathcal{V}_{\\mathrm{Fold}}(\\mathrm{fvk},(X_i^{(v)})_{i = 1}^k,X^{(v)},\\mathrm{pf}^{(v)})</span>  accepts.</li>

    </ul>

    <p class="text-gray-300">Thus, by construction, the output of  <span class="math">\\tilde{\\mathcal{P}}_{\\mathrm{Fold}}^{(j)}</span>  satisfies the predicate  <span class="math">\\rho_{\\mathrm{Fold}}</span> , causes the folding verifier to accept, and for every  <span class="math">v \\in \\mathsf{L}_{\\mathsf{T}}(j - 1)</span>  ( <span class="math">X^{(v)}, W^{(v)}) \\in \\mathcal{R}_{\\mathrm{open}}(\\mathcal{L}_{\\mathbf{x}}, \\mathcal{L}_{\\mathbf{e}}, \\widehat{f}_{\\alpha, \\beta}^{G})</span>  with probability at least  <span class="math">(\\epsilon(\\tilde{\\mathcal{P}}) - \\mathrm{negl}(\\lambda)) / \\mathrm{poly}(\\lambda)</span> ). Therefore, by knowledge soundness of the folding scheme (Definition 9, Theorem 8),  <span class="math">\\mathrm{Ext}_{\\mathrm{Fold}}</span>  outputs  <span class="math">((X_i^{(v)}, W_i^{(v)})_{i=1}^k)_v, \\mathrm{aux}_{\\mathrm{Fold}})</span>  such that  <span class="math">\\rho_{\\mathrm{Fold}}</span>  accepts and  <span class="math">((X_i^{(v)}, W_i^{(v)})_{i=1}^k)_v \\in \\mathcal{R}_{\\mathrm{open}}(\\mathcal{L}_{\\mathbf{x}}, \\mathcal{L}_{\\mathbf{e}}, \\widehat{f}_{\\alpha, \\beta}^{G})</span>  with probability  <span class="math">(\\epsilon(\\tilde{\\mathcal{P}}) - \\mathrm{negl}(\\lambda)) / \\mathrm{poly}(\\lambda) - \\mathrm{negl}(\\lambda) = (\\epsilon(\\tilde{\\mathcal{P}}) - \\mathrm{negl}(\\lambda)) / \\mathrm{poly}(\\lambda)</span> . By construction,  <span class="math">(\\varphi, \\mathsf{T}, \\mathrm{aux}_{\\mathrm{pcd}}) \\gets \\mathrm{Ext}^{(j)}</span>  is a simple wrapper around  <span class="math">\\mathrm{Ext}_{\\mathrm{Fold}}^{(j)}</span>  that appends the folding witnesses to the labels of the children nodes of layer  <span class="math">j - 1</span> . Thus, we must have for every vertex  <span class="math">v \\in \\mathsf{L}_{\\mathsf{T}}(j)</span> , the label  <span class="math">((\\ldots, X^{(v)}) \\leftarrow Z^{(v)}, \\mathrm{loc}^{(v)}, W^{(v)})</span>  must have  <span class="math">(X^{(v)}, W^{(v)}) \\in \\mathcal{R}_{\\mathrm{open}}(\\mathcal{L}_{\\mathbf{x}}, \\mathcal{L}_{\\mathbf{e}}, \\widehat{f}_{\\alpha, \\beta}^{G})</span> . Furthermore, since the output of  <span class="math">\\mathrm{Ext}_{\\mathrm{Fold}}^{(j)}</span>  satisfies  <span class="math">\\rho_{\\mathrm{Fold}}</span> , we must have that</p>

    <p class="text-gray-300"><span class="math">\\rho_{\\mathsf{pcd}}</span> accepts on <span class="math">\\mathsf{Ext}^{(j)}</span>’s outputs and that <span class="math">\\mathsf{T}</span> is <span class="math">\\varphi</span>-compliant. These conditions hold with probability at least <span class="math">(\\epsilon(\\tilde{\\mathcal{P}})-\\mathsf{negl}(\\lambda))/\\mathsf{poly}(\\lambda)</span>, which completes the inductive step.</p>

    <p class="text-gray-300">Therefore, by induction, we have <span class="math">\\mathsf{Ext}^{(d)}</span> outputs <span class="math">(\\varphi,\\mathsf{T},\\mathsf{aux}_{\\mathsf{pcd}})</span> such that</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\rho_{\\mathsf{pcd}}</span> accepts (with argument <span class="math">\\mathsf{Z}=\\mathsf{o}(\\mathsf{T})</span>) on the output.</li>

      <li><span class="math">\\mathsf{T}</span> is <span class="math">\\varphi</span>-compliant.</li>

      <li>For every vertex <span class="math">v\\in\\mathsf{L}_{\\mathsf{T}}(j-1)</span>, the label <span class="math">((\\ldots,X^{(v)})\\leftarrow\\mathsf{Z}^{(v)},\\mathsf{loc}^{(v)},W^{(v)})</span> must have <span class="math">(X^{(v)},W^{(v)})\\in\\mathcal{R}_{\\mathsf{open}}(\\mathcal{L}_{\\mathsf{x}},\\mathcal{L}_{\\mathsf{e}},\\widetilde{f}_{\\alpha,\\beta}^{G})</span>.</li>

    </ul>

    <p class="text-gray-300">with probability at least <span class="math">(\\epsilon(\\tilde{\\mathcal{P}})-\\mathsf{negl}(\\lambda))/\\mathsf{poly}(\\lambda)</span>.</p>

    <h4 id="sec-58" class="text-lg font-semibold mt-6">Final Extractor</h4>

    <p class="text-gray-300">The SNARK extractor <span class="math">\\mathsf{Ext}</span> is a simple wrapper around <span class="math">\\mathsf{Ext}^{(d)}</span> that concatenates the folding witness to obtain the final SNARK witness <span class="math">w</span>. We will now argue that the output of <span class="math">\\mathsf{Ext}</span> satisfies the knowledge soundness definition of the SNARK (Definition 5) in particular, the output must satisfy the NARK predicate <span class="math">\\rho</span> and <span class="math">(\\mathsf{idx},x,w)\\in\\mathfrak{R}_{\\mathsf{plk}}</span> with probability <span class="math">(\\epsilon(\\tilde{\\mathcal{P}})-\\mathsf{negl}(\\lambda))/\\mathsf{poly}(\\lambda)</span>. Assume the conditions we showed above hold for the output of <span class="math">\\mathsf{Ext}^{(d)}</span>. We will show that the required conditions on <span class="math">\\mathsf{Ext}</span> hold with only a <span class="math">\\mathsf{negl}(\\lambda)</span> loss in probability. The NARK predicate <span class="math">\\rho</span> is trivially satisfied, since the output of <span class="math">\\mathsf{Ext}^{(d)}</span> satisfies <span class="math">\\rho_{\\mathsf{pcd}}</span>. Now we need to show is that <span class="math">(\\mathsf{idx},x,w)\\in\\mathfrak{R}_{\\mathsf{plk}}</span>. We show this occurs with only <span class="math">\\mathsf{negl}(\\lambda)</span> probabilty loss, otherwise we could construct either adversaries for the Merkle commitment scheme, commitment scheme, an adversary against the polynomial witness testing game, or finally an adversary against the knowledge soundness of the NARK from Section 6.2.</p>

    <p class="text-gray-300">Let <span class="math">(\\varphi,\\mathsf{T},\\mathsf{aux}_{\\mathsf{pcd}})</span> be the output of <span class="math">\\mathsf{Ext}^{(d)}</span>. For every leaf node <span class="math">v\\in\\mathsf{L}_{\\mathsf{T}}(d)</span>,</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>denote its label <span class="math">(\\mathsf{Z}^{(v)},\\mathsf{loc}^{(v)},W^{(v)})</span>,</li>

      <li>define <span class="math">(\\ldots,X^{(v)}):=\\mathsf{Z}^{(v)}</span>, <span class="math">(\\overline{x}^{(v)},\\overline{e}^{(v)})\\leftarrow X^{(v)}</span>, and <span class="math">(\\overline{\\mathsf{plk}}^{(v)},\\overline{z}^{(v)},p^{(v)},\\mu^{(v)})\\leftarrow\\Psi(\\overline{x}^{(v)})</span> (Definition 20).</li>

    </ul>

    <p class="text-gray-300">Assume these conditions hold, we will argue a series of implications that will allow us to show that the output of <span class="math">\\mathsf{Ext}</span> satisfies the knowledge soundness definition of the SNARK (Definition 5). Further, denote the root node label <span class="math">(\\mathsf{Z},\\mathsf{loc},W^{(v)}):=\\mathsf{o}(\\mathsf{T})</span>. Since <span class="math">\\rho_{\\mathsf{pcd}}</span> accepts (with argument <span class="math">\\mathsf{Z}=\\mathsf{o}(\\mathsf{T})</span>) on the output of <span class="math">\\mathsf{Ext}^{d}</span>, we must have that <span class="math">\\varphi=\\varphi_{\\mathsf{pp}_{\\mathsf{H}},\\mathsf{fvk}}</span>, which implies <span class="math">\\mathsf{T}</span> is <span class="math">\\varphi_{\\mathsf{pp}_{\\mathsf{H}},\\mathsf{fvk}}</span>-compliant and <span class="math">\\mathsf{Z}=(1,\\mathsf{hplk}^{\\prime},\\mathsf{hz},X)</span>. Thus, by the definition of <span class="math">\\varphi_{\\mathsf{pp}_{\\mathsf{H}},\\mathsf{fvk}}</span> and Merkle commitments, we must have</p>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li><span class="math">\\prod_{v}p^{(v)}=1</span>.</li>

      <li><span class="math">\\overline{e}^{(v)}=\\mathcal{L}_{\\mathsf{e}}(0)</span> and <span class="math">\\mu^{(v)}=1</span>.</li>

      <li><span class="math">\\mathsf{hplk}^{\\prime}=\\mathsf{MT.Commit}(\\mathsf{pp}_{\\mathsf{H}},(\\overline{\\mathsf{plk}}^{(v)})_{v})</span>.</li>

      <li><span class="math">\\mathsf{hz}=\\mathsf{MT.Commit}(\\mathsf{pp}_{\\mathsf{H}},(\\overline{z}^{(v)})_{v})</span>.</li>

    </ul>

    <p class="text-gray-300">Since <span class="math">\\rho_{\\mathsf{pcd}}</span> produces <span class="math">\\mathsf{hplk}</span> honestly from <span class="math">\\mathsf{idx}=(\\sigma,\\mathsf{s},G)</span> and checks <span class="math">\\mathsf{hplk}=\\mathsf{hplk}^{\\prime}</span>, we must have that <span class="math">(\\overline{\\mathsf{plk}}^{(v)})_{v}=(\\mathsf{Commit}(\\mathsf{ck},(i,\\ \\sigma^{\\mathsf{rn}(i,m)},\\ \\mathsf{s}^{\\mathsf{rn}(i,b(m/t))})))_{i\\in[n/m]}</span>; otherwise, we could produce an adversary that breaks the binding property of the Merkle commitment scheme. Thus, we can change the corresponding indices from <span class="math">v\\in\\mathsf{L}_{\\mathsf{T}}(d)</span> to <span class="math">i\\in[n/m]</span>. Therefore, we have for all <span class="math">i\\in[n/m]</span>, <span class="math">(\\mathsf{Commit}(\\mathsf{ck},(i,\\ \\sigma^{\\mathsf{rn}(i,m)},\\ \\mathsf{s}^{\\mathsf{rn}(i,b(m/t))})),\\overline{z}^{(i)},p^{(i)},1)\\leftarrow\\Psi(\\overline{x}^{(i)})</span>. By the polynomial witness testing lemma (Lemma 5) with corresponding choice of maps in Definition 20 and that both <span class="math">(X_{i},W_{i})\\in\\mathcal{R}_{\\mathsf{open}}(\\mathcal{L}_{\\mathsf{x}},\\mathcal{L}_{\\mathsf{e}},\\hat{f}_{\\alpha,\\beta}^{G})</span> and <span class="math">\\overline{e}_{i}=\\mathcal{L}_{\\mathsf{e}}(0)</span> and <span class="math">\\mu^{(v)}=1</span> for all <span class="math">i\\in[n/m]</span>, we must have that the polynomial witness <span class="math">W_{i}=(i,\\sigma^{\\mathsf{rn}(i,m)},\\ \\mathsf{s}^{\\mathsf{rn}(i,b(m/t))},z_{i},p_{i},1)</span> and that <span class="math">\\widetilde{f}_{\\alpha,\\beta}^{G}(W_{i})=0</span> for all <span class="math">i</span>. Otherwise, we could produce an adversary that beats the polynomial witness testing game. Furthermore, since <span class="math">\\rho_{\\mathsf{pcd}}</span> checks <span class="math">\\mathsf{MT.Verify}_{k}(\\mathsf{pp}_{\\mathsf{H}},\\mathsf{hz},\\{1\\},\\overline{z}_{1},\\pi_{\\mathsf{MT}})</span> accepts, where <span class="math">\\overline{z}_{1}=\\mathsf{Commit}(\\mathsf{ck},(x,\\ldots))</span> (as defined in the</p>

    <p class="text-gray-300"><span class="math">\\rho_{\\mathsf{pcd}})</span>. By the position binding property of the Merkle commitment scheme and binding of Commit, we must have that <span class="math">z_{1} = (x,\\ldots)</span>. Otherwise, we could construct an adversary that breaks either binding property of the respective schemes. Define <span class="math">z</span> to be the concatenation of all <span class="math">z_{i}</span>. Therefore, we must have that</p>

    <div class="overflow-x-auto my-4">

      <table class="min-w-full text-sm text-gray-300">

        <thead>

          <tr>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">- <span class="math">z = (x, w)</span> where <span class="math">w</span> is the last $</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">z</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">-</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600">x</th>

            <th class="px-3 py-2 text-left font-semibold border-b border-gray-600"><span class="math"> elements of </span>z$.</th>

          </tr>

        </thead>

        <tbody>

        </tbody>

      </table>

    </div>

    <ul class="list-disc list-inside space-y-1 text-gray-300 my-2 ml-4">

      <li>By definition of <span class="math">\\hat{f}_{\\alpha,\\beta}^{G}</span> (Definition 19), we must have that</li>

      <li>For all <span class="math">i \\in [c]</span>, <span class="math">G\\left(\\mathsf{s}^{\\mathsf{rn}(i,b)}, z^{\\mathsf{rn}(i,t)}\\right) = 0</span>.</li>

      <li><span class="math">\\prod_{i=1}^{n}(z_i + i \\cdot \\alpha + \\beta) / \\prod_{i=1}^{n}(z_i + \\sigma_i \\cdot \\alpha + \\beta) = 1</span> for <span class="math">\\alpha, \\beta \\gets \\mathsf{ro}(\\mathsf{hplk}, x, \\mathsf{hz})</span>.</li>

    </ul>

    <p class="text-gray-300">Therefore, we must have that <span class="math">(\\mathsf{idx}, x, w) \\in \\Re_{\\mathsf{plk}}</span>; otherwise, we could construct an adversary that breaks the knowledge soundness of the NARK from Section 6.2 with respect to index commitment <span class="math">\\overline{\\mathsf{plk}} = \\mathsf{hplk}</span> and <span class="math">z</span> commitment <span class="math">\\overline{z} = \\mathsf{hz}</span>. Thus, the output of Ext satisfies the knowledge soundness definition of the SNARK (Definition 5) with probability at least <span class="math">(\\epsilon(\\tilde{\\mathcal{P}}) - \\mathsf{negl}(\\lambda)) / \\mathsf{poly}(\\lambda) - \\mathsf{negl}(\\lambda) = (\\epsilon(\\tilde{\\mathcal{P}}) - \\mathsf{negl}(\\lambda)) / \\mathsf{poly}(\\lambda)</span>.</p>

    <p class="text-gray-300">Running Time of Extractor: By the definition of knowledge soundness for the PCD scheme and folding scheme (Definition 12, Definition 9), the running time of the respective extractors runs in time at most expected polynomial of the running time of the respective provers. Since we recursively extract over a tree of depth <span class="math">d = \\log_k(n / m)</span> (a constant, since <span class="math">k = O(\\lambda)</span>), the running time of the SNARK extractor Ext is at most expected polynomial of the running time of the malicious NARK prover <span class="math">\\tilde{\\mathcal{P}}</span>. Since the NARK prover runs in expected polynomial time, the SNARK extractor Ext runs in expected polynomial time.</p>

    <p class="text-gray-300">69</p>`;
---

<BaseLayout title="Mangrove: A Scalable Framework for Folding-based SNARKs (2024/416)">
  <article class="max-w-4xl mx-auto article-prose">
    <nav class="mb-8">
      <a href="/papers" class="text-blue-400 hover:text-blue-300">
        &larr; Back to Papers
      </a>
    </nav>

    <header class="mb-12">
      <h1 class="text-3xl font-bold mb-4"
        set:html={TITLE_HTML} />
      <p class="text-gray-400 mb-2"
        set:html={AUTHORS_HTML} />
      <p class="text-gray-500 text-sm mb-4">
        2024 &middot; eprint 2024/416
      </p>
      <div class="flex gap-4 text-sm">
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >
          Paper (eprint) &rarr;
        </a>
      </div>
      <p class="mt-4 text-xs text-gray-500">
        All content below belongs to the original authors. This page
        reproduces the paper for educational purposes. Always
        <a
          href={EPRINT_URL}
          target="_blank"
          rel="noopener noreferrer"
          class="text-blue-400 hover:text-blue-300"
        >cite the original</a>.
      </p>
      <p class="mt-1 text-xs text-gray-600">
        Converted with: {CRAWLER} &middot; {CONVERTED_DATE}
      </p>
    </header>

    <Fragment set:html={CONTENT} />

  </article>
</BaseLayout>
